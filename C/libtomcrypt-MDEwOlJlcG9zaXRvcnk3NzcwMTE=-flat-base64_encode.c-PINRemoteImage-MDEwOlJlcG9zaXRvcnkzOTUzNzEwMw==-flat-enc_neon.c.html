
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 2.336448598130841%, Tokens: 10, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>libtomcrypt-MDEwOlJlcG9zaXRvcnk3NzcwMTE=-flat-base64_encode.c</h3>
            <pre><code>1  #include "tomcrypt_private.h"
2  #if defined(LTC_BASE64) || defined (LTC_BASE64_URL)
3  #if defined(LTC_BASE64)
4  static const char * const codes_base64 =
5  "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
6  #endif &bsol;* LTC_BASE64 */
7  #if defined(LTC_BASE64_URL)
8  static const char * const codes_base64url =
9  "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_";
10  #endif &bsol;* LTC_BASE64_URL */
11  enum mode {
12     nopad = 0,
13     pad = 1,
14     lf = 2,
15     cr = 4,
16     ssh = 8,
17     crlf = lf | cr,
18  };
19  static int s_base64_encode_internal(const unsigned char *in,    unsigned long inlen,
20                                                     char *out,   unsigned long *outlen,
21                                      const          char *codes, unsigned int  mode)
22  {
23     unsigned long i, len2, leven, linelen;
24     char *p;
25     LTC_ARGCHK(outlen != NULL);
26     linelen = (mode & ssh) ? 72 : 64;
27     len2 = 4 * ((inlen + 2) / 3);
28     if ((mode & crlf) == lf) {
29        len2 += len2 / linelen;
30     } else if ((mode & crlf) == crlf) {
31        len2 += (len2 / linelen) * 2;
32     }
33     if (*outlen < len2 + 1) {
34        *outlen = len2 + 1;
35        return CRYPT_BUFFER_OVERFLOW;
36     }
37     LTC_ARGCHK(in  != NULL);
38     LTC_ARGCHK(out != NULL);
39     if ((void*)in == out) {
40        return CRYPT_INVALID_ARG;
41     }
42     p = out;
43     leven = 3*(inlen / 3);
<span onclick='openModal()' class='match'>44     for (i = 0; i < leven; i += 3) {
45         *p++ = codes[(in[0] >> 2) & 0x3F];
46         *p++ = codes[(((in[0] & 3) << 4) + (in[1] >> 4)) & 0x3F];
47         *p++ = codes[(((in[1] & 0xf) << 2) + (in[2] >> 6)) & 0x3F];
48         *p++ = codes[in[2] & 0x3F];
49         in += 3;
</span>50         if ((p - out) % linelen == 0) {
51            if (mode & cr) *p++ = '\r';
52            if (mode & lf) *p++ = '\n';
53         }
54     }
55     if (i < inlen) {
56         unsigned a = in[0];
57         unsigned b = (i+1 < inlen) ? in[1] : 0;
58         *p++ = codes[(a >> 2) & 0x3F];
59         *p++ = codes[(((a & 3) << 4) + (b >> 4)) & 0x3F];
60         if (mode & pad) {
61           *p++ = (i+1 < inlen) ? codes[(((b & 0xf) << 2)) & 0x3F] : '=';
62           *p++ = '=';
63         }
64         else {
65           if (i+1 < inlen) *p++ = codes[(((b & 0xf) << 2)) & 0x3F];
66         }
67     }
68     *p = '\0';
69     *outlen = (unsigned long)(p - out); &bsol;* the length without terminating NUL */
70     return CRYPT_OK;
71  }
72  #if defined(LTC_BASE64)
73  int base64_encode(const unsigned char *in,  unsigned long inlen,
74                                   char *out, unsigned long *outlen)
75  {
76      return s_base64_encode_internal(in, inlen, out, outlen, codes_base64, pad);
77  }
78  int base64_encode_pem(const unsigned char *in,  unsigned long inlen,
79                                       char *out, unsigned long *outlen,
80                              unsigned int  flags)
81  {
82      int use_crlf = flags & BASE64_PEM_CRLF ? pad | crlf : pad | lf;
83      int ssh_style = flags & BASE64_PEM_SSH ? ssh : 0;
84      return s_base64_encode_internal(in, inlen, out, outlen, codes_base64, ssh_style | use_crlf);
85  }
86  #endif &bsol;* LTC_BASE64 */
87  #if defined(LTC_BASE64_URL)
88  int base64url_encode(const unsigned char *in,  unsigned long inlen,
89                                      char *out, unsigned long *outlen)
90  {
91      return s_base64_encode_internal(in, inlen, out, outlen, codes_base64url, nopad);
92  }
93  int base64url_strict_encode(const unsigned char *in,  unsigned long inlen,
94                                             char *out, unsigned long *outlen)
95  {
96      return s_base64_encode_internal(in, inlen, out, outlen, codes_base64url, pad);
97  }
98  #endif &bsol;* LTC_BASE64_URL */
99  #endif
</code></pre>
        </div>
        <div class="column">
            <h3>PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-enc_neon.c</h3>
            <pre><code>1  #include "src/dsp/dsp.h"
2  #if defined(WEBP_USE_NEON)
3  #include <assert.h>
4  #include "src/dsp/neon.h"
5  #include "src/enc/vp8i_enc.h"
6  static const int16_t kC1 = 20091;
7  static const int16_t kC2 = 17734;  
8  #if defined(WEBP_USE_INTRINSICS)
9  static WEBP_INLINE int16x8_t ConvertU8ToS16_NEON(uint32x2_t v) {
10    return vreinterpretq_s16_u16(vmovl_u8(vreinterpret_u8_u32(v)));
11  }
12  static WEBP_INLINE void SaturateAndStore4x4_NEON(uint8_t* const dst,
13                                                   const int16x8_t dst01,
14                                                   const int16x8_t dst23) {
15    const uint8x8_t dst01_u8 = vqmovun_s16(dst01);
16    const uint8x8_t dst23_u8 = vqmovun_s16(dst23);
17    vst1_lane_u32((uint32_t*)(dst + 0 * BPS), vreinterpret_u32_u8(dst01_u8), 0);
18    vst1_lane_u32((uint32_t*)(dst + 1 * BPS), vreinterpret_u32_u8(dst01_u8), 1);
19    vst1_lane_u32((uint32_t*)(dst + 2 * BPS), vreinterpret_u32_u8(dst23_u8), 0);
20    vst1_lane_u32((uint32_t*)(dst + 3 * BPS), vreinterpret_u32_u8(dst23_u8), 1);
21  }
22  static WEBP_INLINE void Add4x4_NEON(const int16x8_t row01,
23                                      const int16x8_t row23,
24                                      const uint8_t* const ref,
25                                      uint8_t* const dst) {
26    uint32x2_t dst01 = vdup_n_u32(0);
27    uint32x2_t dst23 = vdup_n_u32(0);
28    dst01 = vld1_lane_u32((uint32_t*)(ref + 0 * BPS), dst01, 0);
29    dst23 = vld1_lane_u32((uint32_t*)(ref + 2 * BPS), dst23, 0);
30    dst01 = vld1_lane_u32((uint32_t*)(ref + 1 * BPS), dst01, 1);
31    dst23 = vld1_lane_u32((uint32_t*)(ref + 3 * BPS), dst23, 1);
32    {
33      const int16x8_t dst01_s16 = ConvertU8ToS16_NEON(dst01);
34      const int16x8_t dst23_s16 = ConvertU8ToS16_NEON(dst23);
35      const int16x8_t out01 = vrsraq_n_s16(dst01_s16, row01, 3);
36      const int16x8_t out23 = vrsraq_n_s16(dst23_s16, row23, 3);
37      SaturateAndStore4x4_NEON(dst, out01, out23);
38    }
39  }
40  static WEBP_INLINE void Transpose8x2_NEON(const int16x8_t in0,
41                                            const int16x8_t in1,
42                                            int16x8x2_t* const out) {
43    const int16x8x2_t tmp0 = vzipq_s16(in0, in1);   
44    *out = vzipq_s16(tmp0.val[0], tmp0.val[1]);
45  }
46  static WEBP_INLINE void TransformPass_NEON(int16x8x2_t* const rows) {
47    const int16x8_t B1 =
48        vcombine_s16(vget_high_s16(rows->val[0]), vget_high_s16(rows->val[1]));
49    const int16x8_t C0 = vsraq_n_s16(B1, vqdmulhq_n_s16(B1, kC1), 1);
50    const int16x8_t C1 = vqdmulhq_n_s16(B1, kC2);
51    const int16x4_t a = vqadd_s16(vget_low_s16(rows->val[0]),
52                                  vget_low_s16(rows->val[1]));   
53    const int16x4_t b = vqsub_s16(vget_low_s16(rows->val[0]),
54                                  vget_low_s16(rows->val[1]));   
55    const int16x4_t c = vqsub_s16(vget_low_s16(C1), vget_high_s16(C0));
56    const int16x4_t d = vqadd_s16(vget_low_s16(C0), vget_high_s16(C1));
57    const int16x8_t D0 = vcombine_s16(a, b);      
58    const int16x8_t D1 = vcombine_s16(d, c);      
59    const int16x8_t E0 = vqaddq_s16(D0, D1);      
60    const int16x8_t E_tmp = vqsubq_s16(D0, D1);   
61    const int16x8_t E1 = vcombine_s16(vget_high_s16(E_tmp), vget_low_s16(E_tmp));
62    Transpose8x2_NEON(E0, E1, rows);
63  }
64  static void ITransformOne_NEON(const uint8_t* ref,
65                                 const int16_t* in, uint8_t* dst) {
66    int16x8x2_t rows;
67    INIT_VECTOR2(rows, vld1q_s16(in + 0), vld1q_s16(in + 8));
68    TransformPass_NEON(&rows);
69    TransformPass_NEON(&rows);
70    Add4x4_NEON(rows.val[0], rows.val[1], ref, dst);
71  }
72  #else
73  static void ITransformOne_NEON(const uint8_t* ref,
74                                 const int16_t* in, uint8_t* dst) {
75    const int kBPS = BPS;
76    const int16_t kC1C2[] = { kC1, kC2, 0, 0 };
77    __asm__ volatile (
78      "vld1.16         {q1, q2}, [%[in]]           \n"
79      "vld1.16         {d0}, [%[kC1C2]]            \n"
80      "vswp            d3, d4                      \n"
81      "vqdmulh.s16     q8, q2, d0[0]               \n"
82      "vqdmulh.s16     q9, q2, d0[1]               \n"
83      "vqadd.s16       d22, d2, d3                 \n"
84      "vqsub.s16       d23, d2, d3                 \n"
85      "vshr.s16        q8, q8, #1                  \n"
86      "vqadd.s16       q8, q2, q8                  \n"
87      "vqsub.s16       d20, d18, d17               \n"
88      "vqadd.s16       d21, d19, d16               \n"
89      "vqadd.s16       d2, d22, d21                \n"
90      "vqadd.s16       d3, d23, d20                \n"
91      "vqsub.s16       d4, d23, d20                \n"
92      "vqsub.s16       d5, d22, d21                \n"
93      "vzip.16         q1, q2                      \n"
94      "vzip.16         q1, q2                      \n"
95      "vswp            d3, d4                      \n"
96      "vqdmulh.s16     q8, q2, d0[0]               \n"
97      "vqdmulh.s16     q9, q2, d0[1]               \n"
98      "vqadd.s16       d22, d2, d3                 \n"
99      "vqsub.s16       d23, d2, d3                 \n"
100      "vshr.s16        q8, q8, #1                  \n"
101      "vqadd.s16       q8, q2, q8                  \n"
102      "vqsub.s16       d20, d18, d17               \n"
103      "vqadd.s16       d21, d19, d16               \n"
104      "vqadd.s16       d2, d22, d21                \n"
105      "vqadd.s16       d3, d23, d20                \n"
106      "vqsub.s16       d4, d23, d20                \n"
107      "vqsub.s16       d5, d22, d21                \n"
108      "vld1.32         d6[0], [%[ref]], %[kBPS]    \n"
109      "vld1.32         d6[1], [%[ref]], %[kBPS]    \n"
110      "vld1.32         d7[0], [%[ref]], %[kBPS]    \n"
111      "vld1.32         d7[1], [%[ref]], %[kBPS]    \n"
112      "sub         %[ref], %[ref], %[kBPS], lsl #2 \n"
113      "vrshr.s16       d2, d2, #3                  \n"
114      "vrshr.s16       d3, d3, #3                  \n"
115      "vrshr.s16       d4, d4, #3                  \n"
116      "vrshr.s16       d5, d5, #3                  \n"
117      "vzip.16         q1, q2                      \n"
118      "vzip.16         q1, q2                      \n"
119      "vmovl.u8        q8, d6                      \n"
120      "vmovl.u8        q9, d7                      \n"
121      "vqadd.s16       q1, q1, q8                  \n"
122      "vqadd.s16       q2, q2, q9                  \n"
123      "vqmovun.s16     d0, q1                      \n"
124      "vqmovun.s16     d1, q2                      \n"
125      "vst1.32         d0[0], [%[dst]], %[kBPS]    \n"
126      "vst1.32         d0[1], [%[dst]], %[kBPS]    \n"
127      "vst1.32         d1[0], [%[dst]], %[kBPS]    \n"
128      "vst1.32         d1[1], [%[dst]]             \n"
129      : [in] "+r"(in), [dst] "+r"(dst)               
130      : [kBPS] "r"(kBPS), [kC1C2] "r"(kC1C2), [ref] "r"(ref)  
131      : "memory", "q0", "q1", "q2", "q8", "q9", "q10", "q11"  
132    );
133  }
134  #endif    
135  static void ITransform_NEON(const uint8_t* ref,
136                              const int16_t* in, uint8_t* dst, int do_two) {
137    ITransformOne_NEON(ref, in, dst);
138    if (do_two) {
139      ITransformOne_NEON(ref + 4, in + 16, dst + 4);
140    }
141  }
142  static uint8x16_t Load4x4_NEON(const uint8_t* src) {
143    uint32x4_t out = vdupq_n_u32(0);
144    out = vld1q_lane_u32((const uint32_t*)(src + 0 * BPS), out, 0);
145    out = vld1q_lane_u32((const uint32_t*)(src + 1 * BPS), out, 1);
146    out = vld1q_lane_u32((const uint32_t*)(src + 2 * BPS), out, 2);
147    out = vld1q_lane_u32((const uint32_t*)(src + 3 * BPS), out, 3);
148    return vreinterpretq_u8_u32(out);
149  }
150  #if defined(WEBP_USE_INTRINSICS)
151  static WEBP_INLINE void Transpose4x4_S16_NEON(const int16x4_t A,
152                                                const int16x4_t B,
153                                                const int16x4_t C,
154                                                const int16x4_t D,
155                                                int16x8_t* const out01,
156                                                int16x8_t* const out32) {
157    const int16x4x2_t AB = vtrn_s16(A, B);
158    const int16x4x2_t CD = vtrn_s16(C, D);
159    const int32x2x2_t tmp02 = vtrn_s32(vreinterpret_s32_s16(AB.val[0]),
160                                       vreinterpret_s32_s16(CD.val[0]));
161    const int32x2x2_t tmp13 = vtrn_s32(vreinterpret_s32_s16(AB.val[1]),
162                                       vreinterpret_s32_s16(CD.val[1]));
163    *out01 = vreinterpretq_s16_s64(
164        vcombine_s64(vreinterpret_s64_s32(tmp02.val[0]),
165                     vreinterpret_s64_s32(tmp13.val[0])));
166    *out32 = vreinterpretq_s16_s64(
167        vcombine_s64(vreinterpret_s64_s32(tmp13.val[1]),
168                     vreinterpret_s64_s32(tmp02.val[1])));
169  }
170  static WEBP_INLINE int16x8_t DiffU8ToS16_NEON(const uint8x8_t a,
171                                                const uint8x8_t b) {
172    return vreinterpretq_s16_u16(vsubl_u8(a, b));
173  }
174  static void FTransform_NEON(const uint8_t* src, const uint8_t* ref,
175                              int16_t* out) {
176    int16x8_t d0d1, d3d2;   
177    {
178      const uint8x16_t S0 = Load4x4_NEON(src);
179      const uint8x16_t R0 = Load4x4_NEON(ref);
180      const int16x8_t D0D1 = DiffU8ToS16_NEON(vget_low_u8(S0), vget_low_u8(R0));
181      const int16x8_t D2D3 = DiffU8ToS16_NEON(vget_high_u8(S0), vget_high_u8(R0));
182      const int16x4_t D0 = vget_low_s16(D0D1);
183      const int16x4_t D1 = vget_high_s16(D0D1);
184      const int16x4_t D2 = vget_low_s16(D2D3);
185      const int16x4_t D3 = vget_high_s16(D2D3);
186      Transpose4x4_S16_NEON(D0, D1, D2, D3, &d0d1, &d3d2);
187    }
188    {    
189      const int32x4_t kCst937 = vdupq_n_s32(937);
190      const int32x4_t kCst1812 = vdupq_n_s32(1812);
191      const int16x8_t a0a1 = vaddq_s16(d0d1, d3d2);   
192      const int16x8_t a3a2 = vsubq_s16(d0d1, d3d2);   
193      const int16x8_t a0a1_2 = vshlq_n_s16(a0a1, 3);
194      const int16x4_t tmp0 = vadd_s16(vget_low_s16(a0a1_2),
195                                      vget_high_s16(a0a1_2));
196      const int16x4_t tmp2 = vsub_s16(vget_low_s16(a0a1_2),
197                                      vget_high_s16(a0a1_2));
198      const int32x4_t a3_2217 = vmull_n_s16(vget_low_s16(a3a2), 2217);
199      const int32x4_t a2_2217 = vmull_n_s16(vget_high_s16(a3a2), 2217);
200      const int32x4_t a2_p_a3 = vmlal_n_s16(a2_2217, vget_low_s16(a3a2), 5352);
201      const int32x4_t a3_m_a2 = vmlsl_n_s16(a3_2217, vget_high_s16(a3a2), 5352);
202      const int16x4_t tmp1 = vshrn_n_s32(vaddq_s32(a2_p_a3, kCst1812), 9);
203      const int16x4_t tmp3 = vshrn_n_s32(vaddq_s32(a3_m_a2, kCst937), 9);
204      Transpose4x4_S16_NEON(tmp0, tmp1, tmp2, tmp3, &d0d1, &d3d2);
205    }
206    {    
207      const int32x4_t kCst12000 = vdupq_n_s32(12000 + (1 << 16));
208      const int32x4_t kCst51000 = vdupq_n_s32(51000);
209      const int16x8_t a0a1 = vaddq_s16(d0d1, d3d2);   
210      const int16x8_t a3a2 = vsubq_s16(d0d1, d3d2);   
211      const int16x4_t a0_k7 = vadd_s16(vget_low_s16(a0a1), vdup_n_s16(7));
212      const int16x4_t out0 = vshr_n_s16(vadd_s16(a0_k7, vget_high_s16(a0a1)), 4);
213      const int16x4_t out2 = vshr_n_s16(vsub_s16(a0_k7, vget_high_s16(a0a1)), 4);
214      const int32x4_t a3_2217 = vmull_n_s16(vget_low_s16(a3a2), 2217);
215      const int32x4_t a2_2217 = vmull_n_s16(vget_high_s16(a3a2), 2217);
216      const int32x4_t a2_p_a3 = vmlal_n_s16(a2_2217, vget_low_s16(a3a2), 5352);
217      const int32x4_t a3_m_a2 = vmlsl_n_s16(a3_2217, vget_high_s16(a3a2), 5352);
218      const int16x4_t tmp1 = vaddhn_s32(a2_p_a3, kCst12000);
219      const int16x4_t out3 = vaddhn_s32(a3_m_a2, kCst51000);
220      const int16x4_t a3_eq_0 =
221          vreinterpret_s16_u16(vceq_s16(vget_low_s16(a3a2), vdup_n_s16(0)));
222      const int16x4_t out1 = vadd_s16(tmp1, a3_eq_0);
223      vst1_s16(out +  0, out0);
224      vst1_s16(out +  4, out1);
225      vst1_s16(out +  8, out2);
226      vst1_s16(out + 12, out3);
227    }
228  }
229  #else
230  static const int16_t kCoeff16[] = {
231    5352,  5352,  5352, 5352, 2217,  2217,  2217, 2217
232  };
233  static const int32_t kCoeff32[] = {
234     1812,  1812,  1812,  1812,
235      937,   937,   937,   937,
236    12000, 12000, 12000, 12000,
237    51000, 51000, 51000, 51000
238  };
239  static void FTransform_NEON(const uint8_t* src, const uint8_t* ref,
240                              int16_t* out) {
241    const int kBPS = BPS;
242    const uint8_t* src_ptr = src;
243    const uint8_t* ref_ptr = ref;
244    const int16_t* coeff16 = kCoeff16;
245    const int32_t* coeff32 = kCoeff32;
246    __asm__ volatile (
247      "vld1.8 {d8},  [%[src_ptr]], %[kBPS]      \n"
248      "vld1.8 {d10}, [%[src_ptr]], %[kBPS]      \n"
249      "vld1.8 {d9},  [%[src_ptr]], %[kBPS]      \n"
250      "vld1.8 {d11}, [%[src_ptr]]               \n"
251      "vld1.8 {d12}, [%[ref_ptr]], %[kBPS]      \n"
252      "vld1.8 {d14}, [%[ref_ptr]], %[kBPS]      \n"
253      "vld1.8 {d13}, [%[ref_ptr]], %[kBPS]      \n"
254      "vld1.8 {d15}, [%[ref_ptr]]               \n"
255      "vtrn.32     q4, q5                       \n"
256      "vtrn.32     q6, q7                       \n"
257      "vsubl.u8    q0, d8, d12                  \n"
258      "vsubl.u8    q1, d9, d13                  \n"
259      "vld1.16     {q8}, [%[coeff16]]           \n"
260      "vld1.32     {q9, q10}, [%[coeff32]]!     \n"
261      "vld1.32     {q11,q12}, [%[coeff32]]      \n"
262      "vtrn.32         d0, d2                   \n"
263      "vtrn.32         d1, d3                   \n"
264      "vtrn.16         d0, d1                   \n"
265      "vtrn.16         d2, d3                   \n"
266      "vadd.s16        d4, d0, d3               \n" 
267      "vadd.s16        d5, d1, d2               \n" 
268      "vsub.s16        d6, d1, d2               \n" 
269      "vsub.s16        d7, d0, d3               \n" 
270      "vadd.s16        d0, d4, d5               \n" 
271      "vshl.s16        d0, d0, #3               \n" 
272      "vsub.s16        d2, d4, d5               \n" 
273      "vshl.s16        d2, d2, #3               \n" 
274      "vmlal.s16       q9, d7, d16              \n" 
275      "vmlal.s16       q10, d7, d17             \n" 
276      "vmlal.s16       q9, d6, d17              \n" 
277      "vmlsl.s16       q10, d6, d16             \n" 
278      "vshrn.s32       d1, q9, #9               \n"
279      "vshrn.s32       d3, q10, #9              \n"
280      "vtrn.32         d0, d2                   \n"
281      "vtrn.32         d1, d3                   \n"
282      "vtrn.16         d0, d1                   \n"
283      "vtrn.16         d2, d3                   \n"
284      "vmov.s16        d26, #7                  \n"
285      "vadd.s16        d4, d0, d3               \n" 
286      "vadd.s16        d5, d1, d2               \n" 
287      "vsub.s16        d6, d1, d2               \n" 
288      "vadd.s16        d4, d4, d26              \n" 
289      "vsub.s16        d7, d0, d3               \n" 
290      "vadd.s16        d0, d4, d5               \n" 
291      "vsub.s16        d2, d4, d5               \n" 
292      "vmlal.s16       q11, d7, d16             \n" 
293      "vmlal.s16       q12, d7, d17             \n" 
294      "vceq.s16        d4, d7, #0               \n"
295      "vshr.s16        d0, d0, #4               \n"
296      "vshr.s16        d2, d2, #4               \n"
297      "vmlal.s16       q11, d6, d17             \n" 
298      "vmlsl.s16       q12, d6, d16             \n" 
299      "vmvn            d4, d4                   \n" 
300      "vshrn.s32       d1, q11, #16             \n"
301      "vsub.s16        d1, d1, d4               \n"
302      "vshrn.s32       d3, q12, #16             \n"
303      "vst1.16         {q0, q1}, [%[out]]   \n"
304      : [src_ptr] "+r"(src_ptr), [ref_ptr] "+r"(ref_ptr),
305        [coeff32] "+r"(coeff32)          
306      : [kBPS] "r"(kBPS), [coeff16] "r"(coeff16),
307        [out] "r"(out)                   
308      : "memory", "q0", "q1", "q2", "q3", "q4", "q5", "q6", "q7", "q8", "q9",
309        "q10", "q11", "q12", "q13"       
310    );
311  }
312  #endif
313  #define LOAD_LANE_16b(VALUE, LANE) do {             \
314    (VALUE) = vld1_lane_s16(src, (VALUE), (LANE));    \
315    src += stride;                                    \
316  } while (0)
317  static void FTransformWHT_NEON(const int16_t* src, int16_t* out) {
318    const int stride = 16;
319    const int16x4_t zero = vdup_n_s16(0);
320    int32x4x4_t tmp0;
321    int16x4x4_t in;
322    INIT_VECTOR4(in, zero, zero, zero, zero);
323    LOAD_LANE_16b(in.val[0], 0);
324    LOAD_LANE_16b(in.val[1], 0);
325    LOAD_LANE_16b(in.val[2], 0);
326    LOAD_LANE_16b(in.val[3], 0);
327    LOAD_LANE_16b(in.val[0], 1);
328    LOAD_LANE_16b(in.val[1], 1);
329    LOAD_LANE_16b(in.val[2], 1);
330    LOAD_LANE_16b(in.val[3], 1);
331    LOAD_LANE_16b(in.val[0], 2);
332    LOAD_LANE_16b(in.val[1], 2);
333    LOAD_LANE_16b(in.val[2], 2);
334    LOAD_LANE_16b(in.val[3], 2);
335    LOAD_LANE_16b(in.val[0], 3);
336    LOAD_LANE_16b(in.val[1], 3);
337    LOAD_LANE_16b(in.val[2], 3);
338    LOAD_LANE_16b(in.val[3], 3);
339    {
340      const int32x4_t a0 = vaddl_s16(in.val[0], in.val[2]);
341      const int32x4_t a1 = vaddl_s16(in.val[1], in.val[3]);
342      const int32x4_t a2 = vsubl_s16(in.val[1], in.val[3]);
343      const int32x4_t a3 = vsubl_s16(in.val[0], in.val[2]);
344      tmp0.val[0] = vaddq_s32(a0, a1);
345      tmp0.val[1] = vaddq_s32(a3, a2);
346      tmp0.val[2] = vsubq_s32(a3, a2);
347      tmp0.val[3] = vsubq_s32(a0, a1);
348    }
349    {
350      const int32x4x4_t tmp1 = Transpose4x4_NEON(tmp0);
351      const int32x4_t a0 = vaddq_s32(tmp1.val[0], tmp1.val[2]);
352      const int32x4_t a1 = vaddq_s32(tmp1.val[1], tmp1.val[3]);
353      const int32x4_t a2 = vsubq_s32(tmp1.val[1], tmp1.val[3]);
354      const int32x4_t a3 = vsubq_s32(tmp1.val[0], tmp1.val[2]);
355      const int32x4_t b0 = vhaddq_s32(a0, a1);  
356      const int32x4_t b1 = vhaddq_s32(a3, a2);  
357      const int32x4_t b2 = vhsubq_s32(a3, a2);  
358      const int32x4_t b3 = vhsubq_s32(a0, a1);  
359      const int16x4_t out0 = vmovn_s32(b0);
360      const int16x4_t out1 = vmovn_s32(b1);
361      const int16x4_t out2 = vmovn_s32(b2);
362      const int16x4_t out3 = vmovn_s32(b3);
363      vst1_s16(out +  0, out0);
364      vst1_s16(out +  4, out1);
365      vst1_s16(out +  8, out2);
366      vst1_s16(out + 12, out3);
367    }
368  }
369  #undef LOAD_LANE_16b
370  static WEBP_INLINE int16x8x4_t DistoTranspose4x4S16_NEON(int16x8x4_t q4_in) {
371    const int16x8x2_t q2_tmp0 = vtrnq_s16(q4_in.val[0], q4_in.val[1]);
372    const int16x8x2_t q2_tmp1 = vtrnq_s16(q4_in.val[2], q4_in.val[3]);
373    const int32x4x2_t q2_tmp2 = vtrnq_s32(vreinterpretq_s32_s16(q2_tmp0.val[0]),
374                                          vreinterpretq_s32_s16(q2_tmp1.val[0]));
375    const int32x4x2_t q2_tmp3 = vtrnq_s32(vreinterpretq_s32_s16(q2_tmp0.val[1]),
376                                          vreinterpretq_s32_s16(q2_tmp1.val[1]));
377    q4_in.val[0] = vreinterpretq_s16_s32(q2_tmp2.val[0]);
378    q4_in.val[2] = vreinterpretq_s16_s32(q2_tmp2.val[1]);
379    q4_in.val[1] = vreinterpretq_s16_s32(q2_tmp3.val[0]);
380    q4_in.val[3] = vreinterpretq_s16_s32(q2_tmp3.val[1]);
381    return q4_in;
382  }
383  static WEBP_INLINE int16x8x4_t DistoHorizontalPass_NEON(
384      const int16x8x4_t q4_in) {
385    const int16x8_t q_a0 = vaddq_s16(q4_in.val[0], q4_in.val[2]);
386    const int16x8_t q_a1 = vaddq_s16(q4_in.val[1], q4_in.val[3]);
387    const int16x8_t q_a3 = vsubq_s16(q4_in.val[0], q4_in.val[2]);
388    const int16x8_t q_a2 = vsubq_s16(q4_in.val[1], q4_in.val[3]);
389    int16x8x4_t q4_out;
390    INIT_VECTOR4(q4_out,
391                 vabsq_s16(vaddq_s16(q_a0, q_a1)),
392                 vabsq_s16(vaddq_s16(q_a3, q_a2)),
393                 vabdq_s16(q_a3, q_a2), vabdq_s16(q_a0, q_a1));
394    return q4_out;
395  }
396  static WEBP_INLINE int16x8x4_t DistoVerticalPass_NEON(const uint8x8x4_t q4_in) {
397    const int16x8_t q_a0 = vreinterpretq_s16_u16(vaddl_u8(q4_in.val[0],
398                                                          q4_in.val[2]));
399    const int16x8_t q_a1 = vreinterpretq_s16_u16(vaddl_u8(q4_in.val[1],
400                                                          q4_in.val[3]));
401    const int16x8_t q_a2 = vreinterpretq_s16_u16(vsubl_u8(q4_in.val[1],
402                                                          q4_in.val[3]));
403    const int16x8_t q_a3 = vreinterpretq_s16_u16(vsubl_u8(q4_in.val[0],
404                                                          q4_in.val[2]));
405    int16x8x4_t q4_out;
406    INIT_VECTOR4(q4_out,
407                 vaddq_s16(q_a0, q_a1), vaddq_s16(q_a3, q_a2),
408                 vsubq_s16(q_a3, q_a2), vsubq_s16(q_a0, q_a1));
409    return q4_out;
410  }
411  static WEBP_INLINE int16x4x4_t DistoLoadW_NEON(const uint16_t* w) {
412    const uint16x8_t q_w07 = vld1q_u16(&w[0]);
413    const uint16x8_t q_w8f = vld1q_u16(&w[8]);
414    int16x4x4_t d4_w;
415    INIT_VECTOR4(d4_w,
416                 vget_low_s16(vreinterpretq_s16_u16(q_w07)),
417                 vget_high_s16(vreinterpretq_s16_u16(q_w07)),
418                 vget_low_s16(vreinterpretq_s16_u16(q_w8f)),
419                 vget_high_s16(vreinterpretq_s16_u16(q_w8f)));
420    return d4_w;
421  }
422  static WEBP_INLINE int32x2_t DistoSum_NEON(const int16x8x4_t q4_in,
<span onclick='openModal()' class='match'>423                                             const int16x4x4_t d4_w) {
424    int32x2_t d_sum;
425    int32x4_t q_sum0 = vmull_s16(d4_w.val[0], vget_low_s16(q4_in.val[0]));
426    int32x4_t q_sum1 = vmull_s16(d4_w.val[1], vget_low_s16(q4_in.val[1]));
427    int32x4_t q_sum2 = vmull_s16(d4_w.val[2], vget_low_s16(q4_in.val[2]));
428    int32x4_t q_sum3 = vmull_s16(d4_w.val[3], vget_low_s16(q4_in.val[3]));
429    q_sum0 = vmlsl_s16(q_sum0, d4_w.val[0], vget_high_s16(q4_in.val[0]));
430    q_sum1 = vmlsl_s16(q_sum1, d4_w.val[1], vget_high_s16(q4_in.val[1]));
431    q_sum2 = vmlsl_s16(q_sum2, d4_w.val[2], vget_high_s16(q4_in.val[2]));
432    q_sum3 = vmlsl_s16(q_sum3, d4_w.val[3], vget_high_s16(q4_in.val[3]));
433    q_sum0 = vaddq_s32(q_sum0, q_sum1);
</span>434    q_sum2 = vaddq_s32(q_sum2, q_sum3);
435    q_sum2 = vaddq_s32(q_sum0, q_sum2);
436    d_sum = vpadd_s32(vget_low_s32(q_sum2), vget_high_s32(q_sum2));
437    d_sum = vpadd_s32(d_sum, d_sum);
438    return d_sum;
439  }
440  #define LOAD_LANE_32b(src, VALUE, LANE) \
441      (VALUE) = vld1_lane_u32((const uint32_t*)(src), (VALUE), (LANE))
442  static int Disto4x4_NEON(const uint8_t* const a, const uint8_t* const b,
443                           const uint16_t* const w) {
444    uint32x2_t d_in_ab_0123 = vdup_n_u32(0);
445    uint32x2_t d_in_ab_4567 = vdup_n_u32(0);
446    uint32x2_t d_in_ab_89ab = vdup_n_u32(0);
447    uint32x2_t d_in_ab_cdef = vdup_n_u32(0);
448    uint8x8x4_t d4_in;
449    LOAD_LANE_32b(a + 0 * BPS, d_in_ab_0123, 0);
450    LOAD_LANE_32b(a + 1 * BPS, d_in_ab_4567, 0);
451    LOAD_LANE_32b(a + 2 * BPS, d_in_ab_89ab, 0);
452    LOAD_LANE_32b(a + 3 * BPS, d_in_ab_cdef, 0);
453    LOAD_LANE_32b(b + 0 * BPS, d_in_ab_0123, 1);
454    LOAD_LANE_32b(b + 1 * BPS, d_in_ab_4567, 1);
455    LOAD_LANE_32b(b + 2 * BPS, d_in_ab_89ab, 1);
456    LOAD_LANE_32b(b + 3 * BPS, d_in_ab_cdef, 1);
457    INIT_VECTOR4(d4_in,
458                 vreinterpret_u8_u32(d_in_ab_0123),
459                 vreinterpret_u8_u32(d_in_ab_4567),
460                 vreinterpret_u8_u32(d_in_ab_89ab),
461                 vreinterpret_u8_u32(d_in_ab_cdef));
462    {
463      const int16x8x4_t q4_v = DistoVerticalPass_NEON(d4_in);
464      const int16x4x4_t d4_w = DistoLoadW_NEON(w);
465      const int16x8x4_t q4_t = DistoTranspose4x4S16_NEON(q4_v);
466      const int16x8x4_t q4_h = DistoHorizontalPass_NEON(q4_t);
467      int32x2_t d_sum = DistoSum_NEON(q4_h, d4_w);
468      d_sum = vabs_s32(d_sum);
469      d_sum = vshr_n_s32(d_sum, 5);
470      return vget_lane_s32(d_sum, 0);
471    }
472  }
473  #undef LOAD_LANE_32b
474  static int Disto16x16_NEON(const uint8_t* const a, const uint8_t* const b,
475                             const uint16_t* const w) {
476    int D = 0;
477    int x, y;
478    for (y = 0; y < 16 * BPS; y += 4 * BPS) {
479      for (x = 0; x < 16; x += 4) {
480        D += Disto4x4_NEON(a + x + y, b + x + y, w);
481      }
482    }
483    return D;
484  }
485  static void CollectHistogram_NEON(const uint8_t* ref, const uint8_t* pred,
486                                    int start_block, int end_block,
487                                    VP8Histogram* const histo) {
488    const uint16x8_t max_coeff_thresh = vdupq_n_u16(MAX_COEFF_THRESH);
489    int j;
490    int distribution[MAX_COEFF_THRESH + 1] = { 0 };
491    for (j = start_block; j < end_block; ++j) {
492      int16_t out[16];
493      FTransform_NEON(ref + VP8DspScan[j], pred + VP8DspScan[j], out);
494      {
495        int k;
496        const int16x8_t a0 = vld1q_s16(out + 0);
497        const int16x8_t b0 = vld1q_s16(out + 8);
498        const uint16x8_t a1 = vreinterpretq_u16_s16(vabsq_s16(a0));
499        const uint16x8_t b1 = vreinterpretq_u16_s16(vabsq_s16(b0));
500        const uint16x8_t a2 = vshrq_n_u16(a1, 3);
501        const uint16x8_t b2 = vshrq_n_u16(b1, 3);
502        const uint16x8_t a3 = vminq_u16(a2, max_coeff_thresh);
503        const uint16x8_t b3 = vminq_u16(b2, max_coeff_thresh);
504        vst1q_s16(out + 0, vreinterpretq_s16_u16(a3));
505        vst1q_s16(out + 8, vreinterpretq_s16_u16(b3));
506        for (k = 0; k < 16; ++k) {
507          ++distribution[out[k]];
508        }
509      }
510    }
511    VP8SetHistogramData(distribution, histo);
512  }
513  static WEBP_INLINE void AccumulateSSE16_NEON(const uint8_t* const a,
514                                               const uint8_t* const b,
515                                               uint32x4_t* const sum) {
516    const uint8x16_t a0 = vld1q_u8(a);
517    const uint8x16_t b0 = vld1q_u8(b);
518    const uint8x16_t abs_diff = vabdq_u8(a0, b0);
519    const uint16x8_t prod1 = vmull_u8(vget_low_u8(abs_diff),
520                                      vget_low_u8(abs_diff));
521    const uint16x8_t prod2 = vmull_u8(vget_high_u8(abs_diff),
522                                      vget_high_u8(abs_diff));
523    const uint32x4_t sum1 = vpaddlq_u16(prod1);
524    const uint32x4_t sum2 = vpaddlq_u16(prod2);
525    *sum = vaddq_u32(*sum, vaddq_u32(sum1, sum2));
526  }
527  static int SumToInt_NEON(uint32x4_t sum) {
528    const uint64x2_t sum2 = vpaddlq_u32(sum);
529    const uint64_t sum3 = vgetq_lane_u64(sum2, 0) + vgetq_lane_u64(sum2, 1);
530    return (int)sum3;
531  }
532  static int SSE16x16_NEON(const uint8_t* a, const uint8_t* b) {
533    uint32x4_t sum = vdupq_n_u32(0);
534    int y;
535    for (y = 0; y < 16; ++y) {
536      AccumulateSSE16_NEON(a + y * BPS, b + y * BPS, &sum);
537    }
538    return SumToInt_NEON(sum);
539  }
540  static int SSE16x8_NEON(const uint8_t* a, const uint8_t* b) {
541    uint32x4_t sum = vdupq_n_u32(0);
542    int y;
543    for (y = 0; y < 8; ++y) {
544      AccumulateSSE16_NEON(a + y * BPS, b + y * BPS, &sum);
545    }
546    return SumToInt_NEON(sum);
547  }
548  static int SSE8x8_NEON(const uint8_t* a, const uint8_t* b) {
549    uint32x4_t sum = vdupq_n_u32(0);
550    int y;
551    for (y = 0; y < 8; ++y) {
552      const uint8x8_t a0 = vld1_u8(a + y * BPS);
553      const uint8x8_t b0 = vld1_u8(b + y * BPS);
554      const uint8x8_t abs_diff = vabd_u8(a0, b0);
555      const uint16x8_t prod = vmull_u8(abs_diff, abs_diff);
556      sum = vpadalq_u16(sum, prod);
557    }
558    return SumToInt_NEON(sum);
559  }
560  static int SSE4x4_NEON(const uint8_t* a, const uint8_t* b) {
561    const uint8x16_t a0 = Load4x4_NEON(a);
562    const uint8x16_t b0 = Load4x4_NEON(b);
563    const uint8x16_t abs_diff = vabdq_u8(a0, b0);
564    const uint16x8_t prod1 = vmull_u8(vget_low_u8(abs_diff),
565                                      vget_low_u8(abs_diff));
566    const uint16x8_t prod2 = vmull_u8(vget_high_u8(abs_diff),
567                                      vget_high_u8(abs_diff));
568    const uint32x4_t sum1 = vpaddlq_u16(prod1);
569    const uint32x4_t sum2 = vpaddlq_u16(prod2);
570    return SumToInt_NEON(vaddq_u32(sum1, sum2));
571  }
572  #if !defined(WORK_AROUND_GCC)
573  static int16x8_t Quantize_NEON(int16_t* const in,
574                                 const VP8Matrix* const mtx, int offset) {
575    const uint16x8_t sharp = vld1q_u16(&mtx->sharpen_[offset]);
576    const uint16x8_t q = vld1q_u16(&mtx->q_[offset]);
577    const uint16x8_t iq = vld1q_u16(&mtx->iq_[offset]);
578    const uint32x4_t bias0 = vld1q_u32(&mtx->bias_[offset + 0]);
579    const uint32x4_t bias1 = vld1q_u32(&mtx->bias_[offset + 4]);
580    const int16x8_t a = vld1q_s16(in + offset);                
581    const uint16x8_t b = vreinterpretq_u16_s16(vabsq_s16(a));  
582    const int16x8_t sign = vshrq_n_s16(a, 15);                 
583    const uint16x8_t c = vaddq_u16(b, sharp);                  
584    const uint32x4_t m0 = vmull_u16(vget_low_u16(c), vget_low_u16(iq));
585    const uint32x4_t m1 = vmull_u16(vget_high_u16(c), vget_high_u16(iq));
586    const uint32x4_t m2 = vhaddq_u32(m0, bias0);
587    const uint32x4_t m3 = vhaddq_u32(m1, bias1);     
588    const uint16x8_t c0 = vcombine_u16(vshrn_n_u32(m2, 16),
589                                       vshrn_n_u32(m3, 16));   
590    const uint16x8_t c1 = vminq_u16(c0, vdupq_n_u16(MAX_LEVEL));
591    const int16x8_t c2 = veorq_s16(vreinterpretq_s16_u16(c1), sign);
592    const int16x8_t c3 = vsubq_s16(c2, sign);                  
593    const int16x8_t c4 = vmulq_s16(c3, vreinterpretq_s16_u16(q));
594    vst1q_s16(in + offset, c4);
595    assert(QFIX == 17);  
596    return c3;
597  }
598  static const uint8_t kShuffles[4][8] = {
599    { 0,   1,  2,  3,  8,  9, 16, 17 },
600    { 10, 11,  4,  5,  6,  7, 12, 13 },
601    { 18, 19, 24, 25, 26, 27, 20, 21 },
602    { 14, 15, 22, 23, 28, 29, 30, 31 }
603  };
604  static int QuantizeBlock_NEON(int16_t in[16], int16_t out[16],
605                                const VP8Matrix* const mtx) {
606    const int16x8_t out0 = Quantize_NEON(in, mtx, 0);
607    const int16x8_t out1 = Quantize_NEON(in, mtx, 8);
608    uint8x8x4_t shuffles;
609  #if defined(__APPLE__) && defined(__aarch64__) && \
610      defined(__apple_build_version__) && (__apple_build_version__< 6020037)
611    uint8x16x2_t all_out;
612    INIT_VECTOR2(all_out, vreinterpretq_u8_s16(out0), vreinterpretq_u8_s16(out1));
613    INIT_VECTOR4(shuffles,
614                 vtbl2q_u8(all_out, vld1_u8(kShuffles[0])),
615                 vtbl2q_u8(all_out, vld1_u8(kShuffles[1])),
616                 vtbl2q_u8(all_out, vld1_u8(kShuffles[2])),
617                 vtbl2q_u8(all_out, vld1_u8(kShuffles[3])));
618  #else
619    uint8x8x4_t all_out;
620    INIT_VECTOR4(all_out,
621                 vreinterpret_u8_s16(vget_low_s16(out0)),
622                 vreinterpret_u8_s16(vget_high_s16(out0)),
623                 vreinterpret_u8_s16(vget_low_s16(out1)),
624                 vreinterpret_u8_s16(vget_high_s16(out1)));
625    INIT_VECTOR4(shuffles,
626                 vtbl4_u8(all_out, vld1_u8(kShuffles[0])),
627                 vtbl4_u8(all_out, vld1_u8(kShuffles[1])),
628                 vtbl4_u8(all_out, vld1_u8(kShuffles[2])),
629                 vtbl4_u8(all_out, vld1_u8(kShuffles[3])));
630  #endif
631    vst1_u8((uint8_t*)(out +  0), shuffles.val[0]);
632    vst1_u8((uint8_t*)(out +  4), shuffles.val[1]);
633    vst1_u8((uint8_t*)(out +  8), shuffles.val[2]);
634    vst1_u8((uint8_t*)(out + 12), shuffles.val[3]);
635    if (*(uint64_t*)(out +  0) != 0) return 1;
636    if (*(uint64_t*)(out +  4) != 0) return 1;
637    if (*(uint64_t*)(out +  8) != 0) return 1;
638    if (*(uint64_t*)(out + 12) != 0) return 1;
639    return 0;
640  }
641  static int Quantize2Blocks_NEON(int16_t in[32], int16_t out[32],
642                                  const VP8Matrix* const mtx) {
643    int nz;
644    nz  = QuantizeBlock_NEON(in + 0 * 16, out + 0 * 16, mtx) << 0;
645    nz |= QuantizeBlock_NEON(in + 1 * 16, out + 1 * 16, mtx) << 1;
646    return nz;
647  }
648  #endif   
649  extern void VP8EncDspInitNEON(void);
650  WEBP_TSAN_IGNORE_FUNCTION void VP8EncDspInitNEON(void) {
651    VP8ITransform = ITransform_NEON;
652    VP8FTransform = FTransform_NEON;
653    VP8FTransformWHT = FTransformWHT_NEON;
654    VP8TDisto4x4 = Disto4x4_NEON;
655    VP8TDisto16x16 = Disto16x16_NEON;
656    VP8CollectHistogram = CollectHistogram_NEON;
657    VP8SSE16x16 = SSE16x16_NEON;
658    VP8SSE16x8 = SSE16x8_NEON;
659    VP8SSE8x8 = SSE8x8_NEON;
660    VP8SSE4x4 = SSE4x4_NEON;
661  #if !defined(WORK_AROUND_GCC)
662    VP8EncQuantizeBlock = QuantizeBlock_NEON;
663    VP8EncQuantize2Blocks = Quantize2Blocks_NEON;
664  #endif
665  }
666  #else  
667  WEBP_DSP_INIT_STUB(VP8EncDspInitNEON)
668  #endif  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from libtomcrypt-MDEwOlJlcG9zaXRvcnk3NzcwMTE=-flat-base64_encode.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-enc_neon.c</div>
                </div>
                <div class="column column_space"><pre><code>44     for (i = 0; i < leven; i += 3) {
45         *p++ = codes[(in[0] >> 2) & 0x3F];
46         *p++ = codes[(((in[0] & 3) << 4) + (in[1] >> 4)) & 0x3F];
47         *p++ = codes[(((in[1] & 0xf) << 2) + (in[2] >> 6)) & 0x3F];
48         *p++ = codes[in[2] & 0x3F];
49         in += 3;
</pre></code></div>
                <div class="column column_space"><pre><code>423                                             const int16x4x4_t d4_w) {
424    int32x2_t d_sum;
425    int32x4_t q_sum0 = vmull_s16(d4_w.val[0], vget_low_s16(q4_in.val[0]));
426    int32x4_t q_sum1 = vmull_s16(d4_w.val[1], vget_low_s16(q4_in.val[1]));
427    int32x4_t q_sum2 = vmull_s16(d4_w.val[2], vget_low_s16(q4_in.val[2]));
428    int32x4_t q_sum3 = vmull_s16(d4_w.val[3], vget_low_s16(q4_in.val[3]));
429    q_sum0 = vmlsl_s16(q_sum0, d4_w.val[0], vget_high_s16(q4_in.val[0]));
430    q_sum1 = vmlsl_s16(q_sum1, d4_w.val[1], vget_high_s16(q4_in.val[1]));
431    q_sum2 = vmlsl_s16(q_sum2, d4_w.val[2], vget_high_s16(q4_in.val[2]));
432    q_sum3 = vmlsl_s16(q_sum3, d4_w.val[3], vget_high_s16(q4_in.val[3]));
433    q_sum0 = vaddq_s32(q_sum0, q_sum1);
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    