
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 21, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-topology.c</h3>
            <pre><code>1  #include "private/autogen/config.h"
2  #define _ATFILE_SOURCE
3  #include <assert.h>
4  #include <sys/types.h>
5  #ifdef HAVE_DIRENT_H
6  #include <dirent.h>
7  #endif
8  #ifdef HAVE_UNISTD_H
9  #include <unistd.h>
10  #endif
11  #include <string.h>
12  #include <errno.h>
13  #include <stdio.h>
14  #include <sys/stat.h>
15  #include <fcntl.h>
16  #include <limits.h>
17  #include <float.h>
18  #include "hwloc.h"
19  #include "private/private.h"
20  #include "private/debug.h"
21  #include "private/misc.h"
22  #ifdef HAVE_MACH_MACH_INIT_H
23  #include <mach/mach_init.h>
24  #endif
25  #ifdef HAVE_MACH_INIT_H
26  #include <mach_init.h>
27  #endif
28  #ifdef HAVE_MACH_MACH_HOST_H
29  #include <mach/mach_host.h>
30  #endif
31  #ifdef HAVE_SYS_PARAM_H
32  #include <sys/param.h>
33  #endif
34  #ifdef HAVE_SYS_SYSCTL_H
35  #include <sys/sysctl.h>
36  #endif
37  #ifdef HWLOC_WIN_SYS
38  #include <windows.h>
39  #endif
40  #ifdef HWLOC_HAVE_LEVELZERO
41  #if HWLOC_HAVE_ATTRIBUTE_CONSTRUCTOR
42  static void hwloc_constructor(void) __attribute__((constructor));
43  static void hwloc_constructor(void)
44  {
45    if (!getenv("ZES_ENABLE_SYSMAN"))
46  #ifdef HWLOC_WIN_SYS
47      putenv("ZES_ENABLE_SYSMAN=1");
48  #else
49      setenv("ZES_ENABLE_SYSMAN", "1", 1);
50  #endif
51  }
52  #endif
53  #ifdef HWLOC_WIN_SYS
54  BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD fdwReason, LPVOID lpReserved)
55  {
56    if (fdwReason == DLL_PROCESS_ATTACH) {
57      if (!getenv("ZES_ENABLE_SYSMAN"))
58        putenv((char *) "ZES_ENABLE_SYSMAN=1");
59    }
60    return TRUE;
61  }
62  #endif
63  #endif &bsol;* HWLOC_HAVE_LEVELZERO */
64  unsigned hwloc_get_api_version(void)
65  {
66    return HWLOC_API_VERSION;
67  }
68  int hwloc_topology_abi_check(hwloc_topology_t topology)
69  {
70    return topology->topology_abi != HWLOC_TOPOLOGY_ABI ? -1 : 0;
71  }
72  int hwloc_hide_errors(void)
73  {
74    static int hide = 1; &bsol;* only show critical errors by default. lstopo will show others */
75    static int checked = 0;
76    if (!checked) {
77      const char *envvar = getenv("HWLOC_HIDE_ERRORS");
78      if (envvar) {
79        hide = atoi(envvar);
80  #ifdef HWLOC_DEBUG
81      } else {
82        envvar = getenv("HWLOC_DEBUG_VERBOSE");
83        if (!envvar || atoi(envvar))
84          hide = 0;
85  #endif
86      }
87      checked = 1;
88    }
89    return hide;
90  }
91  static void
92  report_insert_error_format_obj(char *buf, size_t buflen, hwloc_obj_t obj)
93  {
94    char typestr[64];
95    char *cpusetstr;
96    char *nodesetstr = NULL;
97    hwloc_obj_type_snprintf(typestr, sizeof(typestr), obj, 0);
98    hwloc_bitmap_asprintf(&cpusetstr, obj->cpuset);
99    if (obj->nodeset) &bsol;* may be missing during insert */
100      hwloc_bitmap_asprintf(&nodesetstr, obj->nodeset);
101    if (obj->os_index != HWLOC_UNKNOWN_INDEX)
102      snprintf(buf, buflen, "%s (P#%u cpuset %s%s%s)",
103               typestr, obj->os_index, cpusetstr,
104               nodesetstr ? " nodeset " : "",
105               nodesetstr ? nodesetstr : "");
106    else
107      snprintf(buf, buflen, "%s (cpuset %s%s%s)",
108               typestr, cpusetstr,
109               nodesetstr ? " nodeset " : "",
110               nodesetstr ? nodesetstr : "");
111    free(cpusetstr);
112    free(nodesetstr);
113  }
114  static void report_insert_error(hwloc_obj_t new, hwloc_obj_t old, const char *msg, const char *reason)
115  {
116    static int reported = 0;
117    if (reason && !reported && HWLOC_SHOW_CRITICAL_ERRORS()) {
118      char newstr[512];
119      char oldstr[512];
120      report_insert_error_format_obj(newstr, sizeof(newstr), new);
121      report_insert_error_format_obj(oldstr, sizeof(oldstr), old);
122      fprintf(stderr, "****************************************************************************\n");
123      fprintf(stderr, "* hwloc %s received invalid information from the operating system.\n", HWLOC_VERSION);
124      fprintf(stderr, "*\n");
125      fprintf(stderr, "* Failed with: %s\n", msg);
126      fprintf(stderr, "* while inserting %s at %s\n", newstr, oldstr);
127      fprintf(stderr, "* coming from: %s\n", reason);
128      fprintf(stderr, "*\n");
129      fprintf(stderr, "* The following FAQ entry in the hwloc documentation may help:\n");
130      fprintf(stderr, "*   What should I do when hwloc reports \"operating system\" warnings?\n");
131      fprintf(stderr, "* Otherwise please report this error message to the hwloc user's mailing list,\n");
132  #ifdef HWLOC_LINUX_SYS
133      fprintf(stderr, "* along with the files generated by the hwloc-gather-topology script.\n");
134  #else
135      fprintf(stderr, "* along with any relevant topology information from your platform.\n");
136  #endif
137      fprintf(stderr, "* \n");
138      fprintf(stderr, "* hwloc will now ignore this invalid topology information and continue.\n");
139      fprintf(stderr, "****************************************************************************\n");
140      reported = 1;
141    }
142  }
143  #if defined(HAVE_SYSCTLBYNAME)
144  int hwloc_get_sysctlbyname(const char *name, int64_t *ret)
145  {
146    union {
147      int32_t i32;
148      int64_t i64;
149    } n;
150    size_t size = sizeof(n);
151    if (sysctlbyname(name, &n, &size, NULL, 0))
152      return -1;
153    switch (size) {
154      case sizeof(n.i32):
155        *ret = n.i32;
156        break;
157      case sizeof(n.i64):
158        *ret = n.i64;
159        break;
160      default:
161        return -1;
162    }
163    return 0;
164  }
165  #endif
166  #if defined(HAVE_SYSCTL)
167  int hwloc_get_sysctl(int name[], unsigned namelen, int64_t *ret)
168  {
169    union {
170      int32_t i32;
171      int64_t i64;
172    } n;
173    size_t size = sizeof(n);
174    if (sysctl(name, namelen, &n, &size, NULL, 0))
175      return -1;
176    switch (size) {
177      case sizeof(n.i32):
178        *ret = n.i32;
179        break;
180      case sizeof(n.i64):
181        *ret = n.i64;
182        break;
183      default:
184        return -1;
185    }
186    return 0;
187  }
188  #endif
189  #ifndef HWLOC_WIN_SYS &bsol;* The windows implementation is in topology-windows.c */
190  int
191  hwloc_fallback_nbprocessors(unsigned flags) {
192    int n;
193    if (flags & HWLOC_FALLBACK_NBPROCESSORS_INCLUDE_OFFLINE) {
194  #if HAVE_DECL__SC_NPROCESSORS_CONF
195      n = sysconf(_SC_NPROCESSORS_CONF);
196  #elif HAVE_DECL__SC_NPROC_CONF
197      n = sysconf(_SC_NPROC_CONF);
198  #else
199      n = -1;
200  #endif
201      if (n != -1)
202        return n;
203    }
204  #if HAVE_DECL__SC_NPROCESSORS_ONLN
205    n = sysconf(_SC_NPROCESSORS_ONLN);
206  #elif HAVE_DECL__SC_NPROC_ONLN
207    n = sysconf(_SC_NPROC_ONLN);
208  #elif HAVE_DECL__SC_NPROCESSORS_CONF
209    n = sysconf(_SC_NPROCESSORS_CONF);
210  #elif HAVE_DECL__SC_NPROC_CONF
211    n = sysconf(_SC_NPROC_CONF);
212  #elif defined(HAVE_HOST_INFO) && HAVE_HOST_INFO
213    struct host_basic_info info;
214    mach_msg_type_number_t count = HOST_BASIC_INFO_COUNT;
215    host_info(mach_host_self(), HOST_BASIC_INFO, (integer_t*) &info, &count);
216    n = info.avail_cpus;
217  #elif defined(HAVE_SYSCTLBYNAME)
218    int64_t nn;
219    if (hwloc_get_sysctlbyname("hw.ncpu", &nn))
220      nn = -1;
221    n = nn;
222  #elif defined(HAVE_SYSCTL) && HAVE_DECL_CTL_HW && HAVE_DECL_HW_NCPU
223    static int name[2] = {CTL_HW, HW_NCPU};
224    int64_t nn;
225    if (hwloc_get_sysctl(name, sizeof(name)/sizeof(*name), &nn))
226      n = -1;
227    n = nn;
228  #else
229  #ifdef __GNUC__
230  #warning No known way to discover number of available processors on this system
231  #endif
232    n = -1;
233  #endif
234    return n;
235  }
236  int64_t
237  hwloc_fallback_memsize(void) {
238    int64_t size;
239  #if defined(HAVE_HOST_INFO) && HAVE_HOST_INFO
240    struct host_basic_info info;
241    mach_msg_type_number_t count = HOST_BASIC_INFO_COUNT;
242    host_info(mach_host_self(), HOST_BASIC_INFO, (integer_t*) &info, &count);
243    size = info.memory_size;
244  #elif defined(HAVE_SYSCTL) && HAVE_DECL_CTL_HW && (HAVE_DECL_HW_REALMEM64 || HAVE_DECL_HW_MEMSIZE64 || HAVE_DECL_HW_PHYSMEM64 || HAVE_DECL_HW_USERMEM64 || HAVE_DECL_HW_REALMEM || HAVE_DECL_HW_MEMSIZE || HAVE_DECL_HW_PHYSMEM || HAVE_DECL_HW_USERMEM)
245  #if HAVE_DECL_HW_MEMSIZE64
246    static int name[2] = {CTL_HW, HW_MEMSIZE64};
247  #elif HAVE_DECL_HW_REALMEM64
248    static int name[2] = {CTL_HW, HW_REALMEM64};
249  #elif HAVE_DECL_HW_PHYSMEM64
250    static int name[2] = {CTL_HW, HW_PHYSMEM64};
251  #elif HAVE_DECL_HW_USERMEM64
252    static int name[2] = {CTL_HW, HW_USERMEM64};
253  #elif HAVE_DECL_HW_MEMSIZE
254    static int name[2] = {CTL_HW, HW_MEMSIZE};
255  #elif HAVE_DECL_HW_REALMEM
256    static int name[2] = {CTL_HW, HW_REALMEM};
257  #elif HAVE_DECL_HW_PHYSMEM
258    static int name[2] = {CTL_HW, HW_PHYSMEM};
259  #elif HAVE_DECL_HW_USERMEM
260    static int name[2] = {CTL_HW, HW_USERMEM};
261  #endif
262    if (hwloc_get_sysctl(name, sizeof(name)/sizeof(*name), &size))
263      size = -1;
264  #elif defined(HAVE_SYSCTLBYNAME)
265    if (hwloc_get_sysctlbyname("hw.memsize", &size) &&
266        hwloc_get_sysctlbyname("hw.realmem", &size) &&
267        hwloc_get_sysctlbyname("hw.physmem", &size) &&
268        hwloc_get_sysctlbyname("hw.usermem", &size))
269        size = -1;
270  #else
271    size = -1;
272  #endif
273    return size;
274  }
275  #endif &bsol;* !HWLOC_WIN_SYS */
276  void
277  hwloc_setup_pu_level(struct hwloc_topology *topology,
278  		     unsigned nb_pus)
279  {
280    struct hwloc_obj *obj;
281    unsigned oscpu,cpu;
282    hwloc_debug("%s", "\n\n * CPU cpusets *\n\n");
283    for (cpu=0,oscpu=0; cpu<nb_pus; oscpu++)
284      {
285        obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_PU, oscpu);
286        obj->cpuset = hwloc_bitmap_alloc();
287        hwloc_bitmap_only(obj->cpuset, oscpu);
288        hwloc_debug_2args_bitmap("cpu %u (os %u) has cpuset %s\n",
289  		 cpu, oscpu, obj->cpuset);
290        hwloc__insert_object_by_cpuset(topology, NULL, obj, "core:pulevel");
291        cpu++;
292      }
293  }
294  #define for_each_child_safe(child, parent, pchild) \
295    for (pchild = &(parent)->first_child, child = *pchild; \
296         child; \
297          \
298         (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
299          \
300          child = *pchild)
301  #define for_each_memory_child_safe(child, parent, pchild) \
302    for (pchild = &(parent)->memory_first_child, child = *pchild; \
303         child; \
304          \
305         (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
306          \
307          child = *pchild)
308  #define for_each_io_child_safe(child, parent, pchild) \
309    for (pchild = &(parent)->io_first_child, child = *pchild; \
310         child; \
311          \
312         (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
313          \
314          child = *pchild)
315  #define for_each_misc_child_safe(child, parent, pchild) \
316    for (pchild = &(parent)->misc_first_child, child = *pchild; \
317         child; \
318          \
319         (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
320          \
321          child = *pchild)
322  #ifdef HWLOC_DEBUG
323  static void
324  hwloc_debug_print_object(int indent __hwloc_attribute_unused, hwloc_obj_t obj)
325  {
326    char type[64], idx[12], attr[1024], *cpuset = NULL;
327    hwloc_debug("%*s", 2*indent, "");
328    hwloc_obj_type_snprintf(type, sizeof(type), obj, 1);
329    if (obj->os_index != HWLOC_UNKNOWN_INDEX)
330      snprintf(idx, sizeof(idx), "#%u", obj->os_index);
331    else
332      *idx = '\0';
333    hwloc_obj_attr_snprintf(attr, sizeof(attr), obj, " ", 1);
334    hwloc_debug("%s%s%s%s%s", type, idx, *attr ? "(" : "", attr, *attr ? ")" : "");
335    if (obj->name)
336      hwloc_debug(" name \"%s\"", obj->name);
337    if (obj->subtype)
338      hwloc_debug(" subtype \"%s\"", obj->subtype);
339    if (obj->cpuset) {
340      hwloc_bitmap_asprintf(&cpuset, obj->cpuset);
341      hwloc_debug(" cpuset %s", cpuset);
342      free(cpuset);
343    }
344    if (obj->complete_cpuset) {
345      hwloc_bitmap_asprintf(&cpuset, obj->complete_cpuset);
346      hwloc_debug(" complete %s", cpuset);
347      free(cpuset);
348    }
349    if (obj->nodeset) {
350      hwloc_bitmap_asprintf(&cpuset, obj->nodeset);
351      hwloc_debug(" nodeset %s", cpuset);
352      free(cpuset);
353    }
354    if (obj->complete_nodeset) {
355      hwloc_bitmap_asprintf(&cpuset, obj->complete_nodeset);
356      hwloc_debug(" completeN %s", cpuset);
357      free(cpuset);
358    }
359    if (obj->arity)
360      hwloc_debug(" arity %u", obj->arity);
361    hwloc_debug("%s", "\n");
362  }
363  static void
364  hwloc_debug_print_objects(int indent __hwloc_attribute_unused, hwloc_obj_t obj)
365  {
366    if (hwloc_debug_enabled() >= 2) {
367      hwloc_obj_t child;
368      hwloc_debug_print_object(indent, obj);
369      for_each_child (child, obj)
370        hwloc_debug_print_objects(indent + 1, child);
371      for_each_memory_child (child, obj)
372        hwloc_debug_print_objects(indent + 1, child);
373      for_each_io_child (child, obj)
374        hwloc_debug_print_objects(indent + 1, child);
375      for_each_misc_child (child, obj)
376        hwloc_debug_print_objects(indent + 1, child);
377    }
378  }
379  #else &bsol;* !HWLOC_DEBUG */
380  #define hwloc_debug_print_object(indent, obj) do { &bsol;* nothing */ } while (0)
381  #define hwloc_debug_print_objects(indent, obj) do { &bsol;* nothing */ } while (0)
382  #endif &bsol;* !HWLOC_DEBUG */
383  void hwloc__free_infos(struct hwloc_info_s *infos, unsigned count)
384  {
385    unsigned i;
386    for(i=0; i<count; i++) {
387      free(infos[i].name);
388      free(infos[i].value);
389    }
390    free(infos);
391  }
392  int hwloc__add_info(struct hwloc_info_s **infosp, unsigned *countp, const char *name, const char *value)
393  {
394    unsigned count = *countp;
395    struct hwloc_info_s *infos = *infosp;
396  #define OBJECT_INFO_ALLOC 8
397    unsigned alloccount = (count + 1 + (OBJECT_INFO_ALLOC-1)) & ~(OBJECT_INFO_ALLOC-1);
398    if (count != alloccount) {
399      struct hwloc_info_s *tmpinfos = realloc(infos, alloccount*sizeof(*infos));
400      if (!tmpinfos)
401        goto out_with_array;
402      *infosp = infos = tmpinfos;
403    }
404    infos[count].name = strdup(name);
405    if (!infos[count].name)
406      goto out_with_array;
407    infos[count].value = strdup(value);
408    if (!infos[count].value)
409      goto out_with_name;
410    *countp = count+1;
411    return 0;
412   out_with_name:
413    free(infos[count].name);
414   out_with_array:
415    return -1;
416  }
417  int hwloc__add_info_nodup(struct hwloc_info_s **infosp, unsigned *countp,
418  			  const char *name, const char *value,
419  			  int replace)
420  {
421    struct hwloc_info_s *infos = *infosp;
422    unsigned count = *countp;
423    unsigned i;
424    for(i=0; i<count; i++) {
425      if (!strcmp(infos[i].name, name)) {
426        if (replace) {
427  	char *new = strdup(value);
428  	if (!new)
429  	  return -1;
430  	free(infos[i].value);
431  	infos[i].value = new;
432        }
433        return 0;
434      }
435    }
436    return hwloc__add_info(infosp, countp, name, value);
437  }
438  int hwloc__move_infos(struct hwloc_info_s **dst_infosp, unsigned *dst_countp,
439  		      struct hwloc_info_s **src_infosp, unsigned *src_countp)
440  {
441    unsigned dst_count = *dst_countp;
442    struct hwloc_info_s *dst_infos = *dst_infosp;
443    unsigned src_count = *src_countp;
444    struct hwloc_info_s *src_infos = *src_infosp;
445    unsigned i;
446  #define OBJECT_INFO_ALLOC 8
447    unsigned alloccount = (dst_count + src_count + (OBJECT_INFO_ALLOC-1)) & ~(OBJECT_INFO_ALLOC-1);
448    if (dst_count != alloccount) {
449      struct hwloc_info_s *tmp_infos = realloc(dst_infos, alloccount*sizeof(*dst_infos));
450      if (!tmp_infos)
451        goto drop;
452      dst_infos = tmp_infos;
453    }
454    for(i=0; i<src_count; i++, dst_count++) {
455      dst_infos[dst_count].name = src_infos[i].name;
456      dst_infos[dst_count].value = src_infos[i].value;
457    }
458    *dst_infosp = dst_infos;
459    *dst_countp = dst_count;
460    free(src_infos);
461    *src_infosp = NULL;
462    *src_countp = 0;
463    return 0;
464   drop:
465    for(i=0; i<src_count; i++) {
466      free(src_infos[i].name);
467      free(src_infos[i].value);
468    }
469    free(src_infos);
470    *src_infosp = NULL;
471    *src_countp = 0;
472    return -1;
473  }
474  int hwloc_obj_add_info(hwloc_obj_t obj, const char *name, const char *value)
475  {
476    return hwloc__add_info(&obj->infos, &obj->infos_count, name, value);
477  }
478  int hwloc__tma_dup_infos(struct hwloc_tma *tma,
479                           struct hwloc_info_s **newip, unsigned *newcp,
480                           struct hwloc_info_s *oldi, unsigned oldc)
481  {
482    struct hwloc_info_s *newi;
483    unsigned i, j;
484    newi = hwloc_tma_calloc(tma, oldc * sizeof(*newi));
485    if (!newi)
486      return -1;
487    for(i=0; i<oldc; i++) {
488      newi[i].name = hwloc_tma_strdup(tma, oldi[i].name);
489      newi[i].value = hwloc_tma_strdup(tma, oldi[i].value);
490      if (!newi[i].name || !newi[i].value)
491        goto failed;
492    }
493    *newip = newi;
494    *newcp = oldc;
495    return 0;
496   failed:
497    assert(!tma || !tma->dontfree); &bsol;* this tma cannot fail to allocate */
498    for(j=0; j<=i; j++) {
499      free(newi[i].name);
500      free(newi[i].value);
501    }
502    free(newi);
503    *newip = NULL;
504    return -1;
505  }
506  static void
507  hwloc__free_object_contents(hwloc_obj_t obj)
508  {
509    switch (obj->type) {
510    case HWLOC_OBJ_NUMANODE:
511      free(obj->attr->numanode.page_types);
512      break;
513    default:
514      break;
515    }
516    hwloc__free_infos(obj->infos, obj->infos_count);
517    free(obj->attr);
518    free(obj->children);
519    free(obj->subtype);
520    free(obj->name);
521    hwloc_bitmap_free(obj->cpuset);
522    hwloc_bitmap_free(obj->complete_cpuset);
523    hwloc_bitmap_free(obj->nodeset);
524    hwloc_bitmap_free(obj->complete_nodeset);
525  }
526  void
527  hwloc_free_unlinked_object(hwloc_obj_t obj)
528  {
529    hwloc__free_object_contents(obj);
530    free(obj);
531  }
532  static void
533  hwloc_replace_linked_object(hwloc_obj_t old, hwloc_obj_t new)
534  {
535    hwloc__free_object_contents(old);
536    new->parent = old->parent;
537    new->next_sibling = old->next_sibling;
538    new->first_child = old->first_child;
539    new->memory_first_child = old->memory_first_child;
540    new->io_first_child = old->io_first_child;
541    new->misc_first_child = old->misc_first_child;
542    memcpy(old, new, sizeof(*old));
543    memset(new, 0,sizeof(*new));
544  }
545  static void
546  unlink_and_free_object_and_children(hwloc_obj_t *pobj)
547  {
548    hwloc_obj_t obj = *pobj, child, *pchild;
549    for_each_child_safe(child, obj, pchild)
550      unlink_and_free_object_and_children(pchild);
551    for_each_memory_child_safe(child, obj, pchild)
552      unlink_and_free_object_and_children(pchild);
553    for_each_io_child_safe(child, obj, pchild)
554      unlink_and_free_object_and_children(pchild);
555    for_each_misc_child_safe(child, obj, pchild)
556      unlink_and_free_object_and_children(pchild);
557    *pobj = obj->next_sibling;
558    hwloc_free_unlinked_object(obj);
559  }
560  void
561  hwloc_free_object_and_children(hwloc_obj_t obj)
562  {
563    unlink_and_free_object_and_children(&obj);
564  }
565  void
566  hwloc_free_object_siblings_and_children(hwloc_obj_t obj)
567  {
568    while (obj)
569      unlink_and_free_object_and_children(&obj);
570  }
571  static hwloc_obj_t *
572  insert_siblings_list(hwloc_obj_t *firstp, hwloc_obj_t firstnew, hwloc_obj_t newparent)
573  {
574    hwloc_obj_t tmp;
575    assert(firstnew);
576    *firstp = tmp = firstnew;
577    tmp->parent = newparent;
578    while (tmp->next_sibling) {
579      tmp = tmp->next_sibling;
580      tmp->parent = newparent;
581    }
582    return &tmp->next_sibling;
583  }
584  static void
585  prepend_siblings_list(hwloc_obj_t *firstp, hwloc_obj_t firstnew, hwloc_obj_t newparent)
586  {
587    hwloc_obj_t *tmpp, tmp, last;
588    unsigned length;
589    for(length = 0, tmpp = &firstnew, last = NULL ; *tmpp; length++, last = *tmpp, tmpp = &((*tmpp)->next_sibling))
590      (*tmpp)->parent = newparent;
591    for(tmp = *firstp; tmp; tmp = tmp->next_sibling)
592      tmp->sibling_rank += length; &bsol;* if it wasn't initialized yet, it'll be overwritten later */
593    *tmpp = *firstp;
594    if (*firstp)
595      (*firstp)->prev_sibling = last;
596    *firstp = firstnew;
597  }
598  static void
599  append_siblings_list(hwloc_obj_t *firstp, hwloc_obj_t firstnew, hwloc_obj_t newparent)
600  {
601    hwloc_obj_t *tmpp, tmp, last;
602    unsigned length;
603    for(length = 0, tmpp = firstp, last = NULL ; *tmpp; length++, last = *tmpp, tmpp = &((*tmpp)->next_sibling));
604    for(tmp = firstnew; tmp; tmp = tmp->next_sibling) {
605      tmp->parent = newparent;
606      tmp->sibling_rank += length; &bsol;* if it wasn't set yet, it'll be overwritten later */
607    }
608    *tmpp = firstnew;
609    if (firstnew)
610      firstnew->prev_sibling = last;
611  }
612  static void
613  unlink_and_free_single_object(hwloc_obj_t *pparent)
614  {
615    hwloc_obj_t old = *pparent;
616    hwloc_obj_t *lastp;
617    if (old->type == HWLOC_OBJ_MISC) {
618      assert(!old->first_child);
619      assert(!old->memory_first_child);
620      assert(!old->io_first_child);
621      if (old->misc_first_child)
622        lastp = insert_siblings_list(pparent, old->misc_first_child, old->parent);
623      else
624        lastp = pparent;
625      *lastp = old->next_sibling;
626    } else if (hwloc__obj_type_is_io(old->type)) {
627      assert(!old->first_child);
628      assert(!old->memory_first_child);
629      if (old->io_first_child)
630        lastp = insert_siblings_list(pparent, old->io_first_child, old->parent);
631      else
632        lastp = pparent;
633      *lastp = old->next_sibling;
634      if (old->misc_first_child)
635        append_siblings_list(&old->parent->misc_first_child, old->misc_first_child, old->parent);
636    } else if (hwloc__obj_type_is_memory(old->type)) {
637      assert(!old->first_child);
638      assert(!old->io_first_child);
639      if (old->memory_first_child)
640        lastp = insert_siblings_list(pparent, old->memory_first_child, old->parent);
641      else
642        lastp = pparent;
643      *lastp = old->next_sibling;
644      if (old->misc_first_child)
645        append_siblings_list(&old->parent->misc_first_child, old->misc_first_child, old->parent);
646    } else {
647      if (old->first_child)
648        lastp = insert_siblings_list(pparent, old->first_child, old->parent);
649      else
650        lastp = pparent;
651      *lastp = old->next_sibling;
652      if (old->memory_first_child)
653        append_siblings_list(&old->parent->memory_first_child, old->memory_first_child, old->parent);
654      if (old->io_first_child)
655        append_siblings_list(&old->parent->io_first_child, old->io_first_child, old->parent);
656      if (old->misc_first_child)
657        append_siblings_list(&old->parent->misc_first_child, old->misc_first_child, old->parent);
658    }
659    hwloc_free_unlinked_object(old);
660  }
661  static int
662  hwloc__duplicate_object(struct hwloc_topology *newtopology,
663  			struct hwloc_obj *newparent,
664  			struct hwloc_obj *newobj,
665  			struct hwloc_obj *src)
666  {
667    struct hwloc_tma *tma = newtopology->tma;
668    hwloc_obj_t *level;
669    unsigned level_width;
670    size_t len;
671    unsigned i;
672    hwloc_obj_t child, prev;
673    int err = 0;
674    assert(!newparent == !!newobj);
675    if (!newobj) {
676      newobj = hwloc_alloc_setup_object(newtopology, src->type, src->os_index);
677      if (!newobj)
678        return -1;
679    }
680    newobj->logical_index = src->logical_index;
681    newobj->depth = src->depth;
682    newobj->sibling_rank = src->sibling_rank;
683    newobj->type = src->type;
684    newobj->os_index = src->os_index;
685    newobj->gp_index = src->gp_index;
686    newobj->symmetric_subtree = src->symmetric_subtree;
687    if (src->name)
688      newobj->name = hwloc_tma_strdup(tma, src->name);
689    if (src->subtype)
690      newobj->subtype = hwloc_tma_strdup(tma, src->subtype);
691    newobj->userdata = src->userdata;
692    newobj->total_memory = src->total_memory;
693    memcpy(newobj->attr, src->attr, sizeof(*newobj->attr));
694    if (src->type == HWLOC_OBJ_NUMANODE && src->attr->numanode.page_types_len) {
695      len = src->attr->numanode.page_types_len * sizeof(struct hwloc_memory_page_type_s);
696      newobj->attr->numanode.page_types = hwloc_tma_malloc(tma, len);
697      memcpy(newobj->attr->numanode.page_types, src->attr->numanode.page_types, len);
698    }
699    newobj->cpuset = hwloc_bitmap_tma_dup(tma, src->cpuset);
700    newobj->complete_cpuset = hwloc_bitmap_tma_dup(tma, src->complete_cpuset);
701    newobj->nodeset = hwloc_bitmap_tma_dup(tma, src->nodeset);
702    newobj->complete_nodeset = hwloc_bitmap_tma_dup(tma, src->complete_nodeset);
703    hwloc__tma_dup_infos(tma, &newobj->infos, &newobj->infos_count, src->infos, src->infos_count);
704    if (src->depth < 0) {
705      i = HWLOC_SLEVEL_FROM_DEPTH(src->depth);
706      level = newtopology->slevels[i].objs;
707      level_width = newtopology->slevels[i].nbobjs;
708      if (!newobj->logical_index)
709        newtopology->slevels[i].first = newobj;
710      if (newobj->logical_index == newtopology->slevels[i].nbobjs - 1)
711        newtopology->slevels[i].last = newobj;
712    } else {
713      level = newtopology->levels[src->depth];
714      level_width = newtopology->level_nbobjects[src->depth];
715    }
716    assert(newobj->logical_index < level_width);
717    level[newobj->logical_index] = newobj;
718    if (newobj->logical_index > 0 && level[newobj->logical_index-1]) {
719      newobj->prev_cousin = level[newobj->logical_index-1];
720      level[newobj->logical_index-1]->next_cousin = newobj;
721    }
722    if (newobj->logical_index < level_width-1 && level[newobj->logical_index+1]) {
723      newobj->next_cousin = level[newobj->logical_index+1];
724      level[newobj->logical_index+1]->prev_cousin = newobj;
725    }
726    if (src->arity) {
727      newobj->children = hwloc_tma_malloc(tma, src->arity * sizeof(*newobj->children));
728      if (!newobj->children)
729        return -1;
730    }
731    newobj->arity = src->arity;
732    newobj->memory_arity = src->memory_arity;
733    newobj->io_arity = src->io_arity;
734    newobj->misc_arity = src->misc_arity;
735    for_each_child(child, src) {
736      err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
737      if (err < 0)
738        goto out_with_children;
739    }
740    for_each_memory_child(child, src) {
741      err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
742      if (err < 0)
743        return err;
744    }
745    for_each_io_child(child, src) {
746      err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
747      if (err < 0)
748        goto out_with_children;
749    }
750    for_each_misc_child(child, src) {
751      err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
752      if (err < 0)
753        goto out_with_children;
754    }
755   out_with_children:
756    if (!err) {
757      if (newobj->arity) {
758        newobj->children[0]->prev_sibling = NULL;
759        for(i=1; i<newobj->arity; i++)
760  	newobj->children[i]->prev_sibling = newobj->children[i-1];
761        newobj->last_child = newobj->children[newobj->arity-1];
762      }
763      if (newobj->memory_arity) {
764        child = newobj->memory_first_child;
765        prev = NULL;
766        while (child) {
767  	child->prev_sibling = prev;
768  	prev = child;
769  	child = child->next_sibling;
770        }
771      }
772      if (newobj->io_arity) {
773        child = newobj->io_first_child;
774        prev = NULL;
775        while (child) {
776  	child->prev_sibling = prev;
777  	prev = child;
778  	child = child->next_sibling;
779        }
780      }
781      if (newobj->misc_arity) {
782        child = newobj->misc_first_child;
783        prev = NULL;
784        while (child) {
785  	child->prev_sibling = prev;
786  	prev = child;
787  	child = child->next_sibling;
788        }
789      }
790    }
791    if (newparent) {
792      hwloc_insert_object_by_parent(newtopology, newparent, newobj);
793      if (hwloc__obj_type_is_normal(newobj->type))
794        newparent->children[newobj->sibling_rank] = newobj;
795    }
796    return err;
797  }
798  static int
799  hwloc__topology_init (struct hwloc_topology **topologyp, unsigned nblevels, struct hwloc_tma *tma);
800  int
801  hwloc__topology_dup(hwloc_topology_t *newp,
802  		    hwloc_topology_t old,
803  		    struct hwloc_tma *tma)
804  {
805    hwloc_topology_t new;
806    hwloc_obj_t newroot;
807    hwloc_obj_t oldroot = hwloc_get_root_obj(old);
808    unsigned i;
809    int err;
810    if (!old->is_loaded) {
811      errno = EINVAL;
812      return -1;
813    }
814    err = hwloc__topology_init(&new, old->nb_levels_allocated, tma);
815    if (err < 0)
816      goto out;
817    new->flags = old->flags;
818    memcpy(new->type_filter, old->type_filter, sizeof(old->type_filter));
819    new->is_thissystem = old->is_thissystem;
820    new->is_loaded = 1;
821    new->pid = old->pid;
822    new->next_gp_index = old->next_gp_index;
823    memcpy(&new->binding_hooks, &old->binding_hooks, sizeof(old->binding_hooks));
824    memcpy(new->support.discovery, old->support.discovery, sizeof(*old->support.discovery));
825    memcpy(new->support.cpubind, old->support.cpubind, sizeof(*old->support.cpubind));
826    memcpy(new->support.membind, old->support.membind, sizeof(*old->support.membind));
827    memcpy(new->support.misc, old->support.misc, sizeof(*old->support.misc));
828    new->allowed_cpuset = hwloc_bitmap_tma_dup(tma, old->allowed_cpuset);
829    new->allowed_nodeset = hwloc_bitmap_tma_dup(tma, old->allowed_nodeset);
830    new->userdata_export_cb = old->userdata_export_cb;
831    new->userdata_import_cb = old->userdata_import_cb;
832    new->userdata_not_decoded = old->userdata_not_decoded;
833    assert(!old->machine_memory.local_memory);
834    assert(!old->machine_memory.page_types_len);
835    assert(!old->machine_memory.page_types);
836    for(i = HWLOC_OBJ_TYPE_MIN; i < HWLOC_OBJ_TYPE_MAX; i++)
837      new->type_depth[i] = old->type_depth[i];
838    new->nb_levels = old->nb_levels;
839    assert(new->nb_levels_allocated >= new->nb_levels);
840    for(i=1 &bsol;* root level already allocated */ ; i<new->nb_levels; i++) {
841      new->level_nbobjects[i] = old->level_nbobjects[i];
842      new->levels[i] = hwloc_tma_calloc(tma, new->level_nbobjects[i] * sizeof(*new->levels[i]));
843    }
844    for(i=0; i<HWLOC_NR_SLEVELS; i++) {
845      new->slevels[i].nbobjs = old->slevels[i].nbobjs;
846      if (new->slevels[i].nbobjs)
847        new->slevels[i].objs = hwloc_tma_calloc(tma, new->slevels[i].nbobjs * sizeof(*new->slevels[i].objs));
848    }
849    newroot = hwloc_get_root_obj(new);
850    err = hwloc__duplicate_object(new, NULL, newroot, oldroot);
851    if (err < 0)
852      goto out_with_topology;
853    err = hwloc_internal_distances_dup(new, old);
854    if (err < 0)
855      goto out_with_topology;
856    err = hwloc_internal_memattrs_dup(new, old);
857    if (err < 0)
858      goto out_with_topology;
859    err = hwloc_internal_cpukinds_dup(new, old);
860    if (err < 0)
861      goto out_with_topology;
862    new->modified = 0;
863    new->backends = NULL;
864    new->get_pci_busid_cpuset_backend = NULL;
865  #ifndef HWLOC_DEBUG
866    if (getenv("HWLOC_DEBUG_CHECK"))
867  #endif
868      hwloc_topology_check(new);
869    *newp = new;
870    return 0;
871   out_with_topology:
872    assert(!tma || !tma->dontfree); &bsol;* this tma cannot fail to allocate */
873    hwloc_topology_destroy(new);
874   out:
875    return -1;
876  }
877  int
878  hwloc_topology_dup(hwloc_topology_t *newp,
879  		   hwloc_topology_t old)
880  {
881    return hwloc__topology_dup(newp, old, NULL);
882  }
883  static const unsigned obj_type_order[] = {
884        0,
885        4,
886           14,
887             18,
888        12,
889        10,
890        8,
891        7,
892        6,
893       13,
894       11,
895       9,
896          1,
897       3,
898         15,
899        16,
900         17,
901           19,
902       2,
903            5
904  };
905  #ifndef NDEBUG &bsol;* only used in debug check assert if !NDEBUG */
906  static const hwloc_obj_type_t obj_order_type[] = {
907    HWLOC_OBJ_MACHINE,
908    HWLOC_OBJ_GROUP,
909    HWLOC_OBJ_MEMCACHE,
910    HWLOC_OBJ_NUMANODE,
911    HWLOC_OBJ_PACKAGE,
912    HWLOC_OBJ_DIE,
913    HWLOC_OBJ_L5CACHE,
914    HWLOC_OBJ_L4CACHE,
915    HWLOC_OBJ_L3CACHE,
916    HWLOC_OBJ_L3ICACHE,
917    HWLOC_OBJ_L2CACHE,
918    HWLOC_OBJ_L2ICACHE,
919    HWLOC_OBJ_L1CACHE,
920    HWLOC_OBJ_L1ICACHE,
921    HWLOC_OBJ_CORE,
922    HWLOC_OBJ_BRIDGE,
923    HWLOC_OBJ_PCI_DEVICE,
924    HWLOC_OBJ_OS_DEVICE,
925    HWLOC_OBJ_PU,
926    HWLOC_OBJ_MISC &bsol;* Misc is always a leaf */
927  };
928  #endif
929  static const int obj_type_priority[] = {
930         90,
931         40,
932            60,
933              100,
934         20,
935         20,
936         20,
937         20,
938         20,
939        19,
940        19,
941        19,
942           0,
943        100,
944          0,
945      100,
946       100,
947            0,
948        19,
949             30
950  };
951  int hwloc_compare_types (hwloc_obj_type_t type1, hwloc_obj_type_t type2)
952  {
953    unsigned order1 = obj_type_order[type1];
954    unsigned order2 = obj_type_order[type2];
955    if (!hwloc__obj_type_is_normal(type1)
956        && hwloc__obj_type_is_normal(type2) && type2 != HWLOC_OBJ_MACHINE)
957      return HWLOC_TYPE_UNORDERED;
958    if (!hwloc__obj_type_is_normal(type2)
959        && hwloc__obj_type_is_normal(type1) && type1 != HWLOC_OBJ_MACHINE)
960      return HWLOC_TYPE_UNORDERED;
961    return order1 - order2;
962  }
963  enum hwloc_obj_cmp_e {
964    HWLOC_OBJ_EQUAL = HWLOC_BITMAP_EQUAL,			&bsol;**< \brief Equal */
965    HWLOC_OBJ_INCLUDED = HWLOC_BITMAP_INCLUDED,		&bsol;**< \brief Strictly included into */
966    HWLOC_OBJ_CONTAINS = HWLOC_BITMAP_CONTAINS,		&bsol;**< \brief Strictly contains */
967    HWLOC_OBJ_INTERSECTS = HWLOC_BITMAP_INTERSECTS,	&bsol;**< \brief Intersects, but no inclusion! */
968    HWLOC_OBJ_DIFFERENT = HWLOC_BITMAP_DIFFERENT		&bsol;**< \brief No intersection */
969  };
970  static enum hwloc_obj_cmp_e
971  hwloc_type_cmp(hwloc_obj_t obj1, hwloc_obj_t obj2)
972  {
973    hwloc_obj_type_t type1 = obj1->type;
974    hwloc_obj_type_t type2 = obj2->type;
975    int compare;
976    compare = hwloc_compare_types(type1, type2);
977    if (compare == HWLOC_TYPE_UNORDERED)
978      return HWLOC_OBJ_DIFFERENT; &bsol;* we cannot do better */
979    if (compare > 0)
980      return HWLOC_OBJ_INCLUDED;
981    if (compare < 0)
982      return HWLOC_OBJ_CONTAINS;
983    if (obj1->type == HWLOC_OBJ_GROUP
984        && (obj1->attr->group.kind != obj2->attr->group.kind
985  	  || obj1->attr->group.subkind != obj2->attr->group.subkind))
986      return HWLOC_OBJ_DIFFERENT; &bsol;* we cannot do better */
987    return HWLOC_OBJ_EQUAL;
988  }
989  static int
990  hwloc_obj_cmp_sets(hwloc_obj_t obj1, hwloc_obj_t obj2)
991  {
992    hwloc_bitmap_t set1, set2;
993    assert(!hwloc__obj_type_is_special(obj1->type));
994    assert(!hwloc__obj_type_is_special(obj2->type));
995    if (obj1->complete_cpuset && obj2->complete_cpuset) {
996      set1 = obj1->complete_cpuset;
997      set2 = obj2->complete_cpuset;
998    } else {
999      set1 = obj1->cpuset;
1000      set2 = obj2->cpuset;
1001    }
1002    if (set1 && set2 && !hwloc_bitmap_iszero(set1) && !hwloc_bitmap_iszero(set2))
1003      return hwloc_bitmap_compare_inclusion(set1, set2);
1004    return HWLOC_OBJ_DIFFERENT;
1005  }
1006  int
1007  hwloc__object_cpusets_compare_first(hwloc_obj_t obj1, hwloc_obj_t obj2)
1008  {
1009    if (obj1->complete_cpuset && obj2->complete_cpuset)
1010      return hwloc_bitmap_compare_first(obj1->complete_cpuset, obj2->complete_cpuset);
1011    else if (obj1->cpuset && obj2->cpuset)
1012      return hwloc_bitmap_compare_first(obj1->cpuset, obj2->cpuset);
1013    return 0;
1014  }
1015  static void
1016  merge_insert_equal(hwloc_obj_t new, hwloc_obj_t old)
1017  {
1018    if (old->os_index == HWLOC_UNKNOWN_INDEX)
1019      old->os_index = new->os_index;
1020    if (new->infos_count) {
1021      hwloc__move_infos(&old->infos, &old->infos_count,
1022  		      &new->infos, &new->infos_count);
1023    }
1024    if (new->name && !old->name) {
1025      old->name = new->name;
1026      new->name = NULL;
1027    }
1028    if (new->subtype && !old->subtype) {
1029      old->subtype = new->subtype;
1030      new->subtype = NULL;
1031    }
1032    switch(new->type) {
1033    case HWLOC_OBJ_NUMANODE:
1034      if (new->attr->numanode.local_memory && !old->attr->numanode.local_memory) {
1035        old->attr->numanode.local_memory = new->attr->numanode.local_memory;
1036        free(old->attr->numanode.page_types);
1037        old->attr->numanode.page_types_len = new->attr->numanode.page_types_len;
1038        old->attr->numanode.page_types = new->attr->numanode.page_types;
1039        new->attr->numanode.page_types = NULL;
1040        new->attr->numanode.page_types_len = 0;
1041      }
1042      break;
1043    case HWLOC_OBJ_L1CACHE:
1044    case HWLOC_OBJ_L2CACHE:
1045    case HWLOC_OBJ_L3CACHE:
1046    case HWLOC_OBJ_L4CACHE:
1047    case HWLOC_OBJ_L5CACHE:
1048    case HWLOC_OBJ_L1ICACHE:
1049    case HWLOC_OBJ_L2ICACHE:
1050    case HWLOC_OBJ_L3ICACHE:
1051      if (!old->attr->cache.size)
1052        old->attr->cache.size = new->attr->cache.size;
1053      if (!old->attr->cache.linesize)
1054        old->attr->cache.size = new->attr->cache.linesize;
1055      if (!old->attr->cache.associativity)
1056        old->attr->cache.size = new->attr->cache.linesize;
1057      break;
1058    default:
1059      break;
1060    }
1061  }
1062  static __hwloc_inline hwloc_obj_t
1063  hwloc__insert_try_merge_group(hwloc_topology_t topology, hwloc_obj_t old, hwloc_obj_t new)
1064  {
1065    if (new->type == HWLOC_OBJ_GROUP && old->type == HWLOC_OBJ_GROUP) {
1066      if (new->attr->group.dont_merge) {
1067        if (old->attr->group.dont_merge)
1068  	return NULL;
1069        hwloc_replace_linked_object(old, new);
1070        topology->modified = 1;
1071        return new;
1072      } else {
1073        if (old->attr->group.dont_merge)
1074  	return old;
1075        if (new->attr->group.kind < old->attr->group.kind) {
1076  	hwloc_replace_linked_object(old, new);
1077          topology->modified = 1;
1078        }
1079        return old;
1080      }
1081    }
1082    if (new->type == HWLOC_OBJ_GROUP && !new->attr->group.dont_merge) {
1083      if (old->type == HWLOC_OBJ_PU && new->attr->group.kind == HWLOC_GROUP_KIND_MEMORY)
1084        return NULL;
1085      return old;
1086    } else if (old->type == HWLOC_OBJ_GROUP && !old->attr->group.dont_merge) {
1087      if (new->type == HWLOC_OBJ_PU && old->attr->group.kind == HWLOC_GROUP_KIND_MEMORY)
1088        return NULL;
1089      hwloc_replace_linked_object(old, new);
1090      topology->modified = 1;
1091      return old;
1092    } else {
1093      return NULL;
1094    }
1095  }
1096  static struct hwloc_obj *
1097  hwloc___insert_object_by_cpuset(struct hwloc_topology *topology, hwloc_obj_t cur, hwloc_obj_t obj,
1098  			        const char *reason)
1099  {
1100    hwloc_obj_t child, next_child = NULL, tmp;
1101    hwloc_obj_t *cur_children = &cur->first_child;
1102    hwloc_obj_t *obj_children = &obj->first_child;
1103    hwloc_obj_t *putp = NULL; &bsol;* OBJ position isn't found yet */
1104    assert(!hwloc__obj_type_is_memory(obj->type));
1105    for (child = cur->first_child, child ? next_child = child->next_sibling : NULL;
1106         child;
1107         child = next_child, child ? next_child = child->next_sibling : NULL) {
1108      int res = hwloc_obj_cmp_sets(obj, child);
1109      int setres = res;
1110      if (res == HWLOC_OBJ_EQUAL) {
1111        hwloc_obj_t merged = hwloc__insert_try_merge_group(topology, child, obj);
1112        if (merged)
1113  	return merged;
1114        res = hwloc_type_cmp(obj, child);
1115      }
1116      switch (res) {
1117        case HWLOC_OBJ_EQUAL:
1118  	merge_insert_equal(obj, child);
1119  	return child;
1120        case HWLOC_OBJ_INCLUDED:
1121  	return hwloc___insert_object_by_cpuset(topology, child, obj, reason);
1122        case HWLOC_OBJ_INTERSECTS:
1123          report_insert_error(obj, child, "intersection without inclusion", reason);
1124  	goto putback;
1125        case HWLOC_OBJ_DIFFERENT:
1126  	if (!putp && hwloc__object_cpusets_compare_first(obj, child) < 0)
1127  	  putp = cur_children;
1128  	cur_children = &child->next_sibling;
1129  	break;
1130        case HWLOC_OBJ_CONTAINS:
1131  	*cur_children = child->next_sibling;
1132  	child->next_sibling = NULL;
1133  	*obj_children = child;
1134  	obj_children = &child->next_sibling;
1135  	child->parent = obj;
1136  	if (setres == HWLOC_OBJ_EQUAL) {
1137  	  obj->memory_first_child = child->memory_first_child;
1138  	  child->memory_first_child = NULL;
1139  	  for(tmp=obj->memory_first_child; tmp; tmp = tmp->next_sibling)
1140  	    tmp->parent = obj;
1141  	}
1142  	break;
1143      }
1144    }
1145    assert(!*obj_children);
1146    assert(!*cur_children);
1147    if (!putp)
1148      putp = cur_children;
1149    obj->next_sibling = *putp;
1150    *putp = obj;
1151    obj->parent = cur;
1152    topology->modified = 1;
1153    return obj;
1154   putback:
1155    if (putp)
1156      cur_children = putp; &bsol;* No need to try to insert before where OBJ was supposed to go */
1157    else
1158      cur_children = &cur->first_child; &bsol;* Start from the beginning */
1159    while ((child = obj->first_child) != NULL) {
1160      obj->first_child = child->next_sibling;
1161      while (*cur_children && hwloc__object_cpusets_compare_first(*cur_children, child) < 0)
1162        cur_children = &(*cur_children)->next_sibling;
1163      child->next_sibling = *cur_children;
1164      *cur_children = child;
1165      child->parent = cur;
1166    }
1167    return NULL;
1168  }
1169  static struct hwloc_obj *
1170  hwloc__find_obj_covering_memory_cpuset(struct hwloc_topology *topology, hwloc_obj_t parent, hwloc_bitmap_t cpuset)
1171  {
1172    hwloc_obj_t child = hwloc_get_child_covering_cpuset(topology, cpuset, parent);
1173    if (!child)
1174      return parent;
1175    if (child && hwloc_bitmap_isequal(child->cpuset, cpuset))
1176      return child;
1177    return hwloc__find_obj_covering_memory_cpuset(topology, child, cpuset);
1178  }
1179  static struct hwloc_obj *
1180  hwloc__find_insert_memory_parent(struct hwloc_topology *topology, hwloc_obj_t obj,
1181                                   const char *reason)
1182  {
1183    hwloc_obj_t parent, group, result;
1184    if (hwloc_bitmap_iszero(obj->cpuset)) {
1185      parent = topology->levels[0][0];
1186    } else {
1187      parent = hwloc__find_obj_covering_memory_cpuset(topology, topology->levels[0][0], obj->cpuset);
1188      if (!parent) {
1189        parent = hwloc_get_root_obj(topology);
1190      }
1191      if (parent->type == HWLOC_OBJ_PU) {
1192        parent = parent->parent;
1193        assert(parent);
1194      }
1195      if (parent != topology->levels[0][0] && hwloc_bitmap_isequal(parent->cpuset, obj->cpuset))
1196        return parent;
1197    }
1198    if (!hwloc_filter_check_keep_object_type(topology, HWLOC_OBJ_GROUP))
1199      return parent;
1200    group = hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
1201    if (!group)
1202      return parent;
1203    group->attr->group.kind = HWLOC_GROUP_KIND_MEMORY;
1204    group->cpuset = hwloc_bitmap_dup(obj->cpuset);
1205    group->complete_cpuset = hwloc_bitmap_dup(obj->complete_cpuset);
1206    if (!group->cpuset != !obj->cpuset
1207        || !group->complete_cpuset != !obj->complete_cpuset) {
1208      hwloc_free_unlinked_object(group);
1209      return parent;
1210    }
1211    result = hwloc__insert_object_by_cpuset(topology, parent, group, reason);
1212    if (!result) {
1213      return parent;
1214    }
1215    assert(result == group);
1216    return group;
1217  }
1218  static hwloc_obj_t
1219  hwloc___attach_memory_object_by_nodeset(struct hwloc_topology *topology, hwloc_obj_t parent,
1220  					hwloc_obj_t obj, const char *reason)
1221  {
1222    hwloc_obj_t *curp = &parent->memory_first_child;
1223    unsigned first = hwloc_bitmap_first(obj->nodeset);
1224    while (*curp) {
1225      hwloc_obj_t cur = *curp;
1226      unsigned curfirst = hwloc_bitmap_first(cur->nodeset);
1227      if (first < curfirst) {
1228        obj->next_sibling = cur;
1229        *curp = obj;
1230        obj->memory_first_child = NULL;
1231        obj->parent = parent;
1232        topology->modified = 1;
1233        return obj;
1234      }
1235      if (first == curfirst) {
1236        if (obj->type == HWLOC_OBJ_NUMANODE) {
1237  	if (cur->type == HWLOC_OBJ_NUMANODE) {
1238            report_insert_error(obj, cur, "NUMAnodes with identical nodesets", reason);
1239  	  return NULL;
1240  	}
1241  	assert(cur->type == HWLOC_OBJ_MEMCACHE);
1242  	return hwloc___attach_memory_object_by_nodeset(topology, cur, obj, reason);
1243        } else {
1244  	assert(obj->type == HWLOC_OBJ_MEMCACHE);
1245  	if (cur->type == HWLOC_OBJ_MEMCACHE) {
1246  	  if (cur->attr->cache.depth == obj->attr->cache.depth)
1247  	    return NULL;
1248  	  if (cur->attr->cache.depth > obj->attr->cache.depth)
1249  	    return hwloc___attach_memory_object_by_nodeset(topology, cur, obj, reason);
1250  	}
1251  	obj->next_sibling = cur->next_sibling;
1252  	cur->next_sibling = NULL;
1253  	obj->memory_first_child = cur;
1254  	cur->parent = obj;
1255  	*curp = obj;
1256  	obj->parent = parent;
1257  	topology->modified = 1;
1258  	return obj;
1259        }
1260      }
1261      curp = &cur->next_sibling;
1262    }
1263    obj->next_sibling = NULL;
1264    *curp = obj;
1265    obj->memory_first_child = NULL;
1266    obj->parent = parent;
1267    topology->modified = 1;
1268    return obj;
1269  }
1270  struct hwloc_obj *
1271  hwloc__attach_memory_object(struct hwloc_topology *topology, hwloc_obj_t parent,
1272  			    hwloc_obj_t obj, const char *reason)
1273  {
1274    hwloc_obj_t result;
1275    assert(parent);
1276    assert(hwloc__obj_type_is_normal(parent->type));
1277    if (!obj->nodeset || hwloc_bitmap_iszero(obj->nodeset))
1278      return NULL;
1279    if (!obj->complete_nodeset) {
1280      obj->complete_nodeset = hwloc_bitmap_dup(obj->nodeset);
1281    } else if (!hwloc_bitmap_isincluded(obj->nodeset, obj->complete_nodeset)) {
1282      return NULL;
1283    }
1284    assert(hwloc_bitmap_weight(obj->nodeset) == 1);
1285  #if 0
1286    hwloc_bitmap_copy(obj->cpuset, parent->cpuset);
1287    hwloc_bitmap_copy(obj->complete_cpuset, parent->complete_cpuset);
1288  #endif
1289    result = hwloc___attach_memory_object_by_nodeset(topology, parent, obj, reason);
1290    if (result == obj) {
1291      if (obj->type == HWLOC_OBJ_NUMANODE) {
1292        hwloc_bitmap_set(topology->levels[0][0]->nodeset, obj->os_index);
1293        hwloc_bitmap_set(topology->levels[0][0]->complete_nodeset, obj->os_index);
1294      }
1295    }
1296    if (result != obj) {
1297      hwloc_free_unlinked_object(obj);
1298    }
1299    return result;
1300  }
1301  struct hwloc_obj *
1302  hwloc__insert_object_by_cpuset(struct hwloc_topology *topology, hwloc_obj_t root,
1303  			       hwloc_obj_t obj, const char *reason)
1304  {
1305    struct hwloc_obj *result;
1306  #ifdef HWLOC_DEBUG
1307    assert(!hwloc__obj_type_is_special(obj->type));
1308    assert(obj->cpuset || obj->complete_cpuset || obj->nodeset || obj->complete_nodeset);
1309  #endif
1310    if (hwloc__obj_type_is_memory(obj->type)) {
1311      if (!root) {
1312        root = hwloc__find_insert_memory_parent(topology, obj, reason);
1313        if (!root) {
1314  	hwloc_free_unlinked_object(obj);
1315  	return NULL;
1316        }
1317      }
1318      return hwloc__attach_memory_object(topology, root, obj, reason);
1319    }
1320    if (!root)
1321      root = topology->levels[0][0];
1322    result = hwloc___insert_object_by_cpuset(topology, root, obj, reason);
1323    if (result && result->type == HWLOC_OBJ_PU) {
1324        if (hwloc_bitmap_isset(result->cpuset, result->os_index))
1325  	hwloc_bitmap_set(topology->levels[0][0]->cpuset, result->os_index);
1326        hwloc_bitmap_set(topology->levels[0][0]->complete_cpuset, result->os_index);
1327    }
1328    if (result != obj) {
1329      hwloc_free_unlinked_object(obj);
1330    }
1331    return result;
1332  }
1333  void
1334  hwloc_insert_object_by_parent(struct hwloc_topology *topology, hwloc_obj_t parent, hwloc_obj_t obj)
1335  {
1336    hwloc_obj_t *current;
1337    if (obj->type == HWLOC_OBJ_MISC) {
1338      for (current = &parent->misc_first_child; *current; current = &(*current)->next_sibling);
1339    } else if (hwloc__obj_type_is_io(obj->type)) {
1340      for (current = &parent->io_first_child; *current; current = &(*current)->next_sibling);
1341    } else if (hwloc__obj_type_is_memory(obj->type)) {
1342      for (current = &parent->memory_first_child; *current; current = &(*current)->next_sibling);
1343      if (obj->type == HWLOC_OBJ_NUMANODE) {
1344        if (hwloc_bitmap_isset(obj->nodeset, obj->os_index))
1345  	hwloc_bitmap_set(topology->levels[0][0]->nodeset, obj->os_index);
1346        hwloc_bitmap_set(topology->levels[0][0]->complete_nodeset, obj->os_index);
1347      }
1348    } else {
1349      for (current = &parent->first_child; *current; current = &(*current)->next_sibling);
1350      if (obj->type == HWLOC_OBJ_PU) {
1351        if (hwloc_bitmap_isset(obj->cpuset, obj->os_index))
1352  	hwloc_bitmap_set(topology->levels[0][0]->cpuset, obj->os_index);
1353        hwloc_bitmap_set(topology->levels[0][0]->complete_cpuset, obj->os_index);
1354      }
1355    }
1356    *current = obj;
1357    obj->parent = parent;
1358    obj->next_sibling = NULL;
1359    topology->modified = 1;
1360  }
1361  hwloc_obj_t
1362  hwloc_alloc_setup_object(hwloc_topology_t topology,
1363  			 hwloc_obj_type_t type, unsigned os_index)
1364  {
1365    struct hwloc_obj *obj = hwloc_tma_malloc(topology->tma, sizeof(*obj));
1366    if (!obj)
1367      return NULL;
1368    memset(obj, 0, sizeof(*obj));
1369    obj->type = type;
1370    obj->os_index = os_index;
1371    obj->gp_index = topology->next_gp_index++;
1372    obj->attr = hwloc_tma_malloc(topology->tma, sizeof(*obj->attr));
1373    if (!obj->attr) {
1374      assert(!topology->tma || !topology->tma->dontfree); &bsol;* this tma cannot fail to allocate */
1375      free(obj);
1376      return NULL;
1377    }
1378    memset(obj->attr, 0, sizeof(*obj->attr));
1379    return obj;
1380  }
1381  hwloc_obj_t
1382  hwloc_topology_alloc_group_object(struct hwloc_topology *topology)
1383  {
1384    if (!topology->is_loaded) {
1385      errno = EINVAL;
1386      return NULL;
1387    }
1388    if (topology->adopted_shmem_addr) {
1389      errno = EPERM;
1390      return NULL;
1391    }
1392    return hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
1393  }
1394  static void hwloc_propagate_symmetric_subtree(hwloc_topology_t topology, hwloc_obj_t root);
1395  static void propagate_total_memory(hwloc_obj_t obj);
1396  static void hwloc_set_group_depth(hwloc_topology_t topology);
1397  static void hwloc_connect_children(hwloc_obj_t parent);
1398  static int hwloc_connect_levels(hwloc_topology_t topology);
1399  static int hwloc_connect_special_levels(hwloc_topology_t topology);
1400  hwloc_obj_t
1401  hwloc_topology_insert_group_object(struct hwloc_topology *topology, hwloc_obj_t obj)
1402  {
1403    hwloc_obj_t res, root;
1404    int cmp;
1405    if (!topology->is_loaded) {
1406      hwloc_free_unlinked_object(obj);
1407      errno = EINVAL;
1408      return NULL;
1409    }
1410    if (topology->adopted_shmem_addr) {
1411      errno = EPERM;
1412      return NULL;
1413    }
1414    if (topology->type_filter[HWLOC_OBJ_GROUP] == HWLOC_TYPE_FILTER_KEEP_NONE) {
1415      hwloc_free_unlinked_object(obj);
1416      errno = EINVAL;
1417      return NULL;
1418    }
1419    root = hwloc_get_root_obj(topology);
1420    if (obj->cpuset)
1421      hwloc_bitmap_and(obj->cpuset, obj->cpuset, root->cpuset);
1422    if (obj->complete_cpuset)
1423      hwloc_bitmap_and(obj->complete_cpuset, obj->complete_cpuset, root->complete_cpuset);
1424    if (obj->nodeset)
1425      hwloc_bitmap_and(obj->nodeset, obj->nodeset, root->nodeset);
1426    if (obj->complete_nodeset)
1427      hwloc_bitmap_and(obj->complete_nodeset, obj->complete_nodeset, root->complete_nodeset);
1428    if ((!obj->cpuset || hwloc_bitmap_iszero(obj->cpuset))
1429        && (!obj->complete_cpuset || hwloc_bitmap_iszero(obj->complete_cpuset))) {
1430      hwloc_const_bitmap_t nodeset = obj->nodeset ? obj->nodeset : obj->complete_nodeset;
1431      hwloc_obj_t numa;
1432      if ((!obj->nodeset || hwloc_bitmap_iszero(obj->nodeset))
1433  	&& (!obj->complete_nodeset || hwloc_bitmap_iszero(obj->complete_nodeset))) {
1434        hwloc_free_unlinked_object(obj);
1435        errno = EINVAL;
1436        return NULL;
1437      }
1438      if (!obj->cpuset) {
1439        obj->cpuset = hwloc_bitmap_alloc();
1440        if (!obj->cpuset) {
1441  	hwloc_free_unlinked_object(obj);
1442  	return NULL;
1443        }
1444      }
1445      numa = NULL;
1446      while ((numa = hwloc_get_next_obj_by_type(topology, HWLOC_OBJ_NUMANODE, numa)) != NULL)
1447        if (hwloc_bitmap_isset(nodeset, numa->os_index))
1448  	hwloc_bitmap_or(obj->cpuset, obj->cpuset, numa->cpuset);
1449    }
1450    cmp = hwloc_obj_cmp_sets(obj, root);
1451    if (cmp == HWLOC_OBJ_INCLUDED) {
1452      res = hwloc__insert_object_by_cpuset(topology, NULL, obj, NULL &bsol;* do not show errors on stdout */);
1453    } else {
1454      res = root;
1455    }
1456    if (!res)
1457      return NULL;
1458    if (res != obj && res->type != HWLOC_OBJ_GROUP)
1459      return res;
1460    hwloc_obj_add_children_sets(res);
1461    if (hwloc_topology_reconnect(topology, 0) < 0)
1462      return NULL;
1463    hwloc_propagate_symmetric_subtree(topology, topology->levels[0][0]);
1464    hwloc_set_group_depth(topology);
1465  #ifndef HWLOC_DEBUG
1466    if (getenv("HWLOC_DEBUG_CHECK"))
1467  #endif
1468      hwloc_topology_check(topology);
1469    return res;
1470  }
1471  hwloc_obj_t
1472  hwloc_topology_insert_misc_object(struct hwloc_topology *topology, hwloc_obj_t parent, const char *name)
1473  {
1474    hwloc_obj_t obj;
1475    if (topology->type_filter[HWLOC_OBJ_MISC] == HWLOC_TYPE_FILTER_KEEP_NONE) {
1476      errno = EINVAL;
1477      return NULL;
1478    }
1479    if (!topology->is_loaded) {
1480      errno = EINVAL;
1481      return NULL;
1482    }
1483    if (topology->adopted_shmem_addr) {
1484      errno = EPERM;
1485      return NULL;
1486    }
1487    obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_MISC, HWLOC_UNKNOWN_INDEX);
1488    if (name)
1489      obj->name = strdup(name);
1490    hwloc_insert_object_by_parent(topology, parent, obj);
1491    hwloc_topology_reconnect(topology, 0);
1492  #ifndef HWLOC_DEBUG
1493    if (getenv("HWLOC_DEBUG_CHECK"))
1494  #endif
1495      hwloc_topology_check(topology);
1496    return obj;
1497  }
1498  static hwloc_obj_t
1499  hwloc_get_highest_obj_covering_complete_cpuset (hwloc_topology_t topology, hwloc_const_cpuset_t set)
1500  {
1501    hwloc_obj_t current = hwloc_get_root_obj(topology);
1502    hwloc_obj_t child;
1503    if (hwloc_bitmap_isequal(set, current->complete_cpuset))
1504      return current;
1505   recurse:
1506    for_each_child(child, current) {
1507      if (hwloc_bitmap_isequal(set, child->complete_cpuset))
1508        return child;
1509      if (!hwloc_bitmap_iszero(child->complete_cpuset) && hwloc_bitmap_isincluded(set, child->complete_cpuset))
1510        break;
1511    }
1512    if (child) {
1513      current = child;
1514      goto recurse;
1515    }
1516    return current;
1517  }
1518  hwloc_obj_t
1519  hwloc_find_insert_io_parent_by_complete_cpuset(struct hwloc_topology *topology, hwloc_cpuset_t cpuset)
1520  {
1521    hwloc_obj_t group_obj, largeparent, parent;
1522    hwloc_bitmap_and(cpuset, cpuset, hwloc_topology_get_complete_cpuset(topology));
1523    if (hwloc_bitmap_iszero(cpuset))
1524      return NULL;
1525    largeparent = hwloc_get_highest_obj_covering_complete_cpuset(topology, cpuset);
1526    if (hwloc_bitmap_isequal(largeparent->complete_cpuset, cpuset)
1527        || !hwloc_filter_check_keep_object_type(topology, HWLOC_OBJ_GROUP))
1528      return largeparent;
1529    group_obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
1530    if (!group_obj)
1531      return largeparent;
1532    group_obj->complete_cpuset = hwloc_bitmap_dup(cpuset);
1533    hwloc_bitmap_and(cpuset, cpuset, hwloc_topology_get_topology_cpuset(topology));
1534    group_obj->cpuset = hwloc_bitmap_dup(cpuset);
1535    group_obj->attr->group.kind = HWLOC_GROUP_KIND_IO;
1536    parent = hwloc__insert_object_by_cpuset(topology, largeparent, group_obj, "topology:io_parent");
1537    if (!parent)
1538      return largeparent;
1539    assert(parent == group_obj);
1540    hwloc_obj_add_children_sets(group_obj);
1541    return parent;
1542  }
1543  static int hwloc_memory_page_type_compare(const void *_a, const void *_b)
1544  {
1545    const struct hwloc_memory_page_type_s *a = _a;
1546    const struct hwloc_memory_page_type_s *b = _b;
1547    if (!b->size)
1548      return -1;
1549    if (b->size == a->size)
1550      return 0;
1551    return a->size < b->size ? -1 : 1;
1552  }
1553  static void
1554  propagate_total_memory(hwloc_obj_t obj)
1555  {
1556    hwloc_obj_t child;
1557    unsigned i;
1558    obj->total_memory = 0;
1559    for_each_child(child, obj) {
1560      propagate_total_memory(child);
1561      obj->total_memory += child->total_memory;
1562    }
1563    for_each_memory_child(child, obj) {
1564      propagate_total_memory(child);
1565      obj->total_memory += child->total_memory;
1566    }
1567    if (obj->type == HWLOC_OBJ_NUMANODE) {
1568      obj->total_memory += obj->attr->numanode.local_memory;
1569      if (obj->attr->numanode.page_types_len) {
1570        qsort(obj->attr->numanode.page_types, obj->attr->numanode.page_types_len, sizeof(*obj->attr->numanode.page_types), hwloc_memory_page_type_compare);
1571        for(i=obj->attr->numanode.page_types_len; i>=1; i--)
1572  	if (obj->attr->numanode.page_types[i-1].size)
1573  	  break;
1574        obj->attr->numanode.page_types_len = i;
1575      }
1576    }
1577  }
1578  static void
1579  fixup_sets(hwloc_obj_t obj)
1580  {
1581    int in_memory_list;
1582    hwloc_obj_t child;
1583    child = obj->first_child;
1584    in_memory_list = 0;
1585   iterate:
1586    while (child) {
1587      hwloc_bitmap_and(child->cpuset, child->cpuset, obj->cpuset);
1588      hwloc_bitmap_and(child->nodeset, child->nodeset, obj->nodeset);
1589      if (child->complete_cpuset) {
1590        hwloc_bitmap_and(child->complete_cpuset, child->complete_cpuset, obj->complete_cpuset);
1591      } else {
1592        child->complete_cpuset = hwloc_bitmap_dup(child->cpuset);
1593      }
1594      if (child->complete_nodeset) {
1595        hwloc_bitmap_and(child->complete_nodeset, child->complete_nodeset, obj->complete_nodeset);
1596      } else {
1597        child->complete_nodeset = hwloc_bitmap_dup(child->nodeset);
1598      }
1599      if (hwloc_obj_type_is_memory(child->type)) {
1600        hwloc_bitmap_copy(child->cpuset, obj->cpuset);
1601        hwloc_bitmap_copy(child->complete_cpuset, obj->complete_cpuset);
1602      }
1603      fixup_sets(child);
1604      child = child->next_sibling;
1605    }
1606    if (!in_memory_list && obj->memory_first_child) {
1607      child = obj->memory_first_child;
1608      in_memory_list = 1;
1609      goto iterate;
1610    }
1611  }
1612  int
1613  hwloc_obj_add_other_obj_sets(hwloc_obj_t dst, hwloc_obj_t src)
1614  {
1615  #define ADD_OTHER_OBJ_SET(_dst, _src, _set)			\
1616    if ((_src)->_set) {						\
1617      if (!(_dst)->_set)						\
1618        (_dst)->_set = hwloc_bitmap_alloc();			\
1619      hwloc_bitmap_or((_dst)->_set, (_dst)->_set, (_src)->_set);	\
1620    }
1621    ADD_OTHER_OBJ_SET(dst, src, cpuset);
1622    ADD_OTHER_OBJ_SET(dst, src, complete_cpuset);
1623    ADD_OTHER_OBJ_SET(dst, src, nodeset);
1624    ADD_OTHER_OBJ_SET(dst, src, complete_nodeset);
1625    return 0;
1626  }
1627  int
1628  hwloc_obj_add_children_sets(hwloc_obj_t obj)
1629  {
1630    hwloc_obj_t child;
1631    for_each_child(child, obj) {
1632      hwloc_obj_add_other_obj_sets(obj, child);
1633    }
1634    return 0;
1635  }
1636  static void
1637  propagate_nodeset(hwloc_obj_t obj)
1638  {
1639    hwloc_obj_t child;
1640    if (!obj->nodeset)
1641      obj->nodeset = hwloc_bitmap_alloc();
1642    if (obj->parent)
1643      hwloc_bitmap_copy(obj->nodeset, obj->parent->nodeset);
1644    else
1645      hwloc_bitmap_zero(obj->nodeset);
1646    if (!obj->complete_nodeset)
1647      obj->complete_nodeset = hwloc_bitmap_dup(obj->nodeset);
1648    else
1649      hwloc_bitmap_or(obj->complete_nodeset, obj->complete_nodeset, obj->nodeset);
1650    for_each_memory_child(child, obj) {
1651      hwloc_bitmap_or(obj->nodeset, obj->nodeset, child->nodeset);
1652      hwloc_bitmap_or(obj->complete_nodeset, obj->complete_nodeset, child->complete_nodeset);
1653    }
1654    for_each_child(child, obj) {
1655      propagate_nodeset(child);
1656    }
1657    for_each_child(child, obj) {
1658      hwloc_bitmap_or(obj->nodeset, obj->nodeset, child->nodeset);
1659      hwloc_bitmap_or(obj->complete_nodeset, obj->complete_nodeset, child->complete_nodeset);
1660    }
1661  }
1662  static void
1663  remove_unused_sets(hwloc_topology_t topology, hwloc_obj_t obj)
1664  {
1665    hwloc_obj_t child;
1666    hwloc_bitmap_and(obj->cpuset, obj->cpuset, topology->allowed_cpuset);
1667    hwloc_bitmap_and(obj->nodeset, obj->nodeset, topology->allowed_nodeset);
1668    for_each_child(child, obj)
1669      remove_unused_sets(topology, child);
1670    for_each_memory_child(child, obj)
1671      remove_unused_sets(topology, child);
1672  }
1673  static void
1674  hwloc__filter_bridges(hwloc_topology_t topology, hwloc_obj_t root, unsigned depth)
1675  {
1676    hwloc_obj_t child, *pchild;
1677    for_each_io_child_safe(child, root, pchild) {
1678      enum hwloc_type_filter_e filter = topology->type_filter[child->type];
1679      hwloc__filter_bridges(topology, child, depth+1);
1680      child->attr->bridge.depth = depth;
1681      if (filter == HWLOC_TYPE_FILTER_KEEP_IMPORTANT
1682  	&& !child->io_first_child
1683          && (child->type == HWLOC_OBJ_BRIDGE
1684              || (child->type == HWLOC_OBJ_PCI_DEVICE && (child->attr->pcidev.class_id >> 8) == 0x06
1685                  && (!child->subtype || strcmp(child->subtype, "NVSwitch"))))) {
1686        unlink_and_free_single_object(pchild);
1687        topology->modified = 1;
1688      }
1689    }
1690  }
1691  static void
1692  hwloc_filter_bridges(hwloc_topology_t topology, hwloc_obj_t parent)
1693  {
1694    hwloc_obj_t child = parent->first_child;
1695    while (child) {
1696      hwloc_filter_bridges(topology, child);
1697      child = child->next_sibling;
1698    }
1699    hwloc__filter_bridges(topology, parent, 0);
1700  }
1701  void
1702  hwloc__reorder_children(hwloc_obj_t parent)
1703  {
1704    hwloc_obj_t *prev, child, children = parent->first_child;
1705    parent->first_child = NULL;
1706    while (children) {
1707      child = children;
1708      children = child->next_sibling;
1709      prev = &parent->first_child;
1710      while (*prev && hwloc__object_cpusets_compare_first(child, *prev) > 0)
1711        prev = &((*prev)->next_sibling);
1712      child->next_sibling = *prev;
1713      *prev = child;
1714    }
1715  }
1716  static void
1717  remove_empty(hwloc_topology_t topology, hwloc_obj_t *pobj)
1718  {
1719    hwloc_obj_t obj = *pobj, child, *pchild;
1720    for_each_child_safe(child, obj, pchild)
1721      remove_empty(topology, pchild);
1722    for_each_memory_child_safe(child, obj, pchild)
1723      remove_empty(topology, pchild);
1724    if (obj->first_child &bsol;* only remove if all children were removed above, so that we don't remove parents of NUMAnode */
1725        || obj->memory_first_child &bsol;* only remove if no memory attached there */
1726        || obj->io_first_child &bsol;* only remove if no I/O is attached there */)
1727      return;
1728    if (hwloc__obj_type_is_normal(obj->type)) {
1729      if (!hwloc_bitmap_iszero(obj->cpuset))
1730        return;
1731    } else {
1732      assert(hwloc__obj_type_is_memory(obj->type));
1733      if (!hwloc_bitmap_iszero(obj->nodeset))
1734        return;
1735    }
1736    hwloc_debug("%s", "\nRemoving empty object ");
1737    hwloc_debug_print_object(0, obj);
1738    unlink_and_free_single_object(pobj);
1739    topology->modified = 1;
1740  }
1741  static void
1742  hwloc_reset_normal_type_depths(hwloc_topology_t topology)
1743  {
1744    unsigned i;
1745    for (i=HWLOC_OBJ_TYPE_MIN; i<=HWLOC_OBJ_GROUP; i++)
1746      topology->type_depth[i] = HWLOC_TYPE_DEPTH_UNKNOWN;
1747    topology->type_depth[HWLOC_OBJ_DIE] = HWLOC_TYPE_DEPTH_UNKNOWN;
1748  }
1749  static int
1750  hwloc_dont_merge_group_level(hwloc_topology_t topology, unsigned i)
1751  {
1752    unsigned j;
1753    for(j=0; j<topology->level_nbobjects[i]; j++)
1754      if (topology->levels[i][j]->attr->group.dont_merge)
1755        return 1;
1756    return 0;
1757  }
1758  static int
1759  hwloc_compare_levels_structure(hwloc_topology_t topology, unsigned i)
1760  {
1761    int checkmemory = (topology->levels[i][0]->type == HWLOC_OBJ_PU);
1762    unsigned j;
1763    if (topology->level_nbobjects[i-1] != topology->level_nbobjects[i])
1764      return -1;
1765    for(j=0; j<topology->level_nbobjects[i]; j++) {
1766      if (topology->levels[i-1][j] != topology->levels[i][j]->parent)
1767        return -1;
1768      if (topology->levels[i-1][j]->arity != 1)
1769        return -1;
1770      if (checkmemory && topology->levels[i-1][j]->memory_arity)
1771        return -1;
1772    }
1773    return 0;
1774  }
1775  static int
1776  hwloc_filter_levels_keep_structure(hwloc_topology_t topology)
1777  {
1778    unsigned i, j;
1779    int res = 0;
1780    if (topology->modified) {
1781      hwloc_connect_children(topology->levels[0][0]);
1782      if (hwloc_connect_levels(topology) < 0)
1783        return -1;
1784    }
1785    for(i=topology->nb_levels-1; i>0; i--) {
1786      int replacechild = 0, replaceparent = 0;
1787      hwloc_obj_t obj1 = topology->levels[i-1][0];
1788      hwloc_obj_t obj2 = topology->levels[i][0];
1789      hwloc_obj_type_t type1 = obj1->type;
1790      hwloc_obj_type_t type2 = obj2->type;
1791      if (topology->type_filter[type1] == HWLOC_TYPE_FILTER_KEEP_STRUCTURE) {
1792        replaceparent = 1;
1793        if (type1 == HWLOC_OBJ_GROUP && hwloc_dont_merge_group_level(topology, i-1))
1794  	replaceparent = 0;
1795      }
1796      if (topology->type_filter[type2] == HWLOC_TYPE_FILTER_KEEP_STRUCTURE) {
1797        replacechild = 1;
1798        if (type1 == HWLOC_OBJ_GROUP && hwloc_dont_merge_group_level(topology, i))
1799  	replacechild = 0;
1800      }
1801      if (!replacechild && !replaceparent)
1802        continue;
1803      if (replaceparent && replacechild) {
1804        if (obj_type_priority[type1] >= obj_type_priority[type2])
1805  	replaceparent = 0;
1806        else
1807  	replacechild = 0;
1808      }
1809      if (hwloc_compare_levels_structure(topology, i) < 0)
1810        continue;
1811      hwloc_debug("may merge levels #%u=%s and #%u=%s\n",
1812  		i-1, hwloc_obj_type_string(type1), i, hwloc_obj_type_string(type2));
1813      for(j=0; j<topology->level_nbobjects[i]; j++) {
1814        hwloc_obj_t parent = topology->levels[i-1][j];
1815        hwloc_obj_t child = topology->levels[i][j];
1816        unsigned k;
1817        if (replacechild) {
1818  	parent->first_child = child->first_child;
1819  	parent->last_child = child->last_child;
1820  	parent->arity = child->arity;
1821  	free(parent->children);
1822  	parent->children = child->children;
1823  	child->children = NULL;
1824  	for(k=0; k<parent->arity; k++)
1825  	  parent->children[k]->parent = parent;
1826  	if (child->memory_first_child) {
1827  	  append_siblings_list(&parent->memory_first_child, child->memory_first_child, parent);
1828  	  parent->memory_arity += child->memory_arity;
1829  	}
1830  	if (child->io_first_child) {
1831  	  append_siblings_list(&parent->io_first_child, child->io_first_child, parent);
1832  	  parent->io_arity += child->io_arity;
1833  	}
1834  	if (child->misc_first_child) {
1835  	  append_siblings_list(&parent->misc_first_child, child->misc_first_child, parent);
1836  	  parent->misc_arity += child->misc_arity;
1837  	}
1838  	hwloc_free_unlinked_object(child);
1839        } else {
1840  	if (parent->parent) {
1841  	  parent->parent->children[parent->sibling_rank] = child;
1842  	  child->sibling_rank = parent->sibling_rank;
1843  	  if (!parent->sibling_rank) {
1844  	    parent->parent->first_child = child;
1845  	  } else {
1846  	    child->prev_sibling = parent->parent->children[parent->sibling_rank-1];
1847  	    child->prev_sibling->next_sibling = child;
1848  	  }
1849  	  if (parent->sibling_rank == parent->parent->arity-1) {
1850  	    parent->parent->last_child = child;
1851  	  } else {
1852  	    child->next_sibling = parent->parent->children[parent->sibling_rank+1];
1853  	    child->next_sibling->prev_sibling = child;
1854  	  }
1855  	  child->parent = parent->parent;
1856  	} else {
1857  	  topology->levels[0][0] = child;
1858  	  child->parent = NULL;
1859  	}
1860  	if (parent->memory_first_child) {
1861  	  prepend_siblings_list(&child->memory_first_child, parent->memory_first_child, child);
1862  	  child->memory_arity += parent->memory_arity;
1863  	}
1864  	if (parent->io_first_child) {
1865  	  prepend_siblings_list(&child->io_first_child, parent->io_first_child, child);
1866  	  child->io_arity += parent->io_arity;
1867  	}
1868  	if (parent->misc_first_child) {
1869  	  prepend_siblings_list(&child->misc_first_child, parent->misc_first_child, child);
1870  	  child->misc_arity += parent->misc_arity;
1871  	}
1872  	hwloc_free_unlinked_object(parent);
1873        }
1874      }
1875      if (replaceparent && i>1) {
1876        for(j=0; j<topology->level_nbobjects[i]; j++) {
1877  	hwloc_obj_t child = topology->levels[i][j];
1878  	unsigned rank = child->sibling_rank;
1879  	child->prev_sibling = rank > 0 ? child->parent->children[rank-1] : NULL;
1880  	child->next_sibling = rank < child->parent->arity-1 ? child->parent->children[rank+1] : NULL;
1881        }
1882      }
1883      if (replaceparent) {
1884        free(topology->levels[i-1]);
1885        memmove(&topology->levels[i-1],
1886  	      &topology->levels[i],
1887  	      (topology->nb_levels-i)*sizeof(topology->levels[i]));
1888        memmove(&topology->level_nbobjects[i-1],
1889  	      &topology->level_nbobjects[i],
1890  	      (topology->nb_levels-i)*sizeof(topology->level_nbobjects[i]));
1891        hwloc_debug("removed parent level %s at depth %u\n",
1892  		  hwloc_obj_type_string(type1), i-1);
1893      } else {
1894        free(topology->levels[i]);
1895        memmove(&topology->levels[i],
1896  	      &topology->levels[i+1],
1897  	      (topology->nb_levels-1-i)*sizeof(topology->levels[i]));
1898        memmove(&topology->level_nbobjects[i],
1899  	      &topology->level_nbobjects[i+1],
1900  	      (topology->nb_levels-1-i)*sizeof(topology->level_nbobjects[i]));
1901        hwloc_debug("removed child level %s at depth %u\n",
1902  		  hwloc_obj_type_string(type2), i);
1903      }
1904      topology->level_nbobjects[topology->nb_levels-1] = 0;
1905      topology->levels[topology->nb_levels-1] = NULL;
1906      topology->nb_levels--;
1907      res++;
1908    }
1909    if (res > 0) {
1910      hwloc_reset_normal_type_depths(topology);
1911      for(i=0; i<topology->nb_levels; i++) {
1912        hwloc_obj_type_t type = topology->levels[i][0]->type;
1913        for(j=0; j<topology->level_nbobjects[i]; j++)
1914  	topology->levels[i][j]->depth = (int)i;
1915        if (topology->type_depth[type] == HWLOC_TYPE_DEPTH_UNKNOWN)
1916  	topology->type_depth[type] = (int)i;
1917        else
1918  	topology->type_depth[type] = HWLOC_TYPE_DEPTH_MULTIPLE;
1919      }
1920    }
1921    if (res > 0 || topology-> modified) {
1922      if (hwloc_connect_special_levels(topology) < 0)
1923        return -1;
1924      topology->modified = 0;
1925    }
1926    return 0;
1927  }
1928  static void
1929  hwloc_propagate_symmetric_subtree(hwloc_topology_t topology, hwloc_obj_t root)
1930  {
1931    hwloc_obj_t child;
1932    unsigned arity = root->arity;
1933    hwloc_obj_t *array;
1934    int ok;
1935    root->symmetric_subtree = 0;
1936    if (!arity)
1937      goto good;
1938    ok = 1;
1939    for_each_child(child, root) {
1940      hwloc_propagate_symmetric_subtree(topology, child);
1941      if (!child->symmetric_subtree)
1942        ok = 0;
1943    }
1944    if (!ok)
1945      return;
1946    if (arity == 1)
1947      goto good;
1948    array = malloc(arity * sizeof(*array));
1949    if (!array)
1950      return;
1951    memcpy(array, root->children, arity * sizeof(*array));
1952    while (1) {
1953      unsigned i;
1954      for(i=1; i<arity; i++)
1955        if (array[i]->depth != array[0]->depth
1956  	  || array[i]->arity != array[0]->arity) {
1957  	free(array);
1958  	return;
1959        }
1960      if (!array[0]->arity)
1961        break;
1962      for(i=0; i<arity; i++)
1963        array[i] = array[i]->first_child;
1964    }
1965    free(array);
1966   good:
1967    root->symmetric_subtree = 1;
1968  }
1969  static void hwloc_set_group_depth(hwloc_topology_t topology)
1970  {
1971    unsigned groupdepth = 0;
1972    unsigned i, j;
1973    for(i=0; i<topology->nb_levels; i++)
1974      if (topology->levels[i][0]->type == HWLOC_OBJ_GROUP) {
1975        for (j = 0; j < topology->level_nbobjects[i]; j++)
1976  	topology->levels[i][j]->attr->group.depth = groupdepth;
1977        groupdepth++;
1978      }
1979  }
1980  static void
1981  hwloc_connect_children(hwloc_obj_t parent)
1982  {
1983    unsigned n, oldn = parent->arity;
1984    hwloc_obj_t child, prev_child;
1985    int ok;
1986    ok = 1;
1987    prev_child = NULL;
1988    for (n = 0, child = parent->first_child;
1989         child;
1990         n++,   prev_child = child, child = child->next_sibling) {
1991      child->sibling_rank = n;
1992      child->prev_sibling = prev_child;
1993      if (n >= oldn || parent->children[n] != child)
1994        ok = 0;
1995      hwloc_connect_children(child);
1996    }
1997    parent->last_child = prev_child;
1998    parent->arity = n;
1999    if (!n) {
2000      free(parent->children);
2001      parent->children = NULL;
2002      goto memory;
2003    }
2004    if (ok)
2005      goto memory;
2006    if (oldn < n) {
2007      free(parent->children);
2008      parent->children = malloc(n * sizeof(*parent->children));
2009    }
2010    for (n = 0, child = parent->first_child;
2011         child;
2012         n++,   child = child->next_sibling) {
2013      parent->children[n] = child;
2014    }
2015   memory:
2016    prev_child = NULL;
2017    for (n = 0, child = parent->memory_first_child;
2018         child;
2019         n++,   prev_child = child, child = child->next_sibling) {
2020      child->parent = parent;
2021      child->sibling_rank = n;
2022      child->prev_sibling = prev_child;
2023      hwloc_connect_children(child);
2024    }
2025    parent->memory_arity = n;
2026    prev_child = NULL;
2027    for (n = 0, child = parent->io_first_child;
2028         child;
2029         n++,   prev_child = child, child = child->next_sibling) {
2030      child->parent = parent;
2031      child->sibling_rank = n;
2032      child->prev_sibling = prev_child;
2033      hwloc_connect_children(child);
2034    }
2035    parent->io_arity = n;
2036    prev_child = NULL;
2037    for (n = 0, child = parent->misc_first_child;
2038         child;
2039         n++,   prev_child = child, child = child->next_sibling) {
2040      child->parent = parent;
2041      child->sibling_rank = n;
2042      child->prev_sibling = prev_child;
2043      hwloc_connect_children(child);
2044    }
2045    parent->misc_arity = n;
2046  }
2047  static int
2048  find_same_type(hwloc_obj_t root, hwloc_obj_t obj)
2049  {
2050    hwloc_obj_t child;
2051    for_each_child (child, root) {
2052      if (hwloc_type_cmp(child, obj) == HWLOC_OBJ_EQUAL)
2053        return 1;
2054      if (find_same_type(child, obj))
2055        return 1;
2056    }
2057    return 0;
2058  }
2059  static int
2060  hwloc_build_level_from_list(struct hwloc_special_level_s *slevel)
2061  {
2062    unsigned i, nb;
2063    struct hwloc_obj * obj;
2064    obj = slevel->first;
2065    i = 0;
2066    while (obj) {
2067      i++;
2068      obj = obj->next_cousin;
2069    }
2070    nb = i;
2071    if (nb) {
2072      slevel->objs = malloc(nb * sizeof(struct hwloc_obj *));
2073      if (!slevel->objs)
2074        return -1;
2075      obj = slevel->first;
2076      i = 0;
2077      while (obj) {
2078        obj->logical_index = i;
2079        slevel->objs[i] = obj;
2080        i++;
2081        obj = obj->next_cousin;
2082      }
2083    }
2084    slevel->nbobjs = nb;
2085    return 0;
2086  }
2087  static void
2088  hwloc_append_special_object(struct hwloc_special_level_s *level, hwloc_obj_t obj)
2089  {
2090    if (level->first) {
2091      obj->prev_cousin = level->last;
2092      obj->prev_cousin->next_cousin = obj;
2093      level->last = obj;
2094    } else {
2095      obj->prev_cousin = NULL;
2096      level->first = level->last = obj;
2097    }
2098  }
2099  static void
2100  hwloc_list_special_objects(hwloc_topology_t topology, hwloc_obj_t obj)
2101  {
2102    hwloc_obj_t child;
2103    if (obj->type == HWLOC_OBJ_NUMANODE) {
2104      obj->next_cousin = NULL;
2105      obj->depth = HWLOC_TYPE_DEPTH_NUMANODE;
2106      hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_NUMANODE], obj);
2107      for_each_misc_child(child, obj)
2108        hwloc_list_special_objects(topology, child);
2109    } else if (obj->type == HWLOC_OBJ_MEMCACHE) {
2110      obj->next_cousin = NULL;
2111      obj->depth = HWLOC_TYPE_DEPTH_MEMCACHE;
2112      hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_MEMCACHE], obj);
2113      for_each_memory_child(child, obj)
2114        hwloc_list_special_objects(topology, child);
2115      for_each_misc_child(child, obj)
2116        hwloc_list_special_objects(topology, child);
2117    } else if (obj->type == HWLOC_OBJ_MISC) {
2118      obj->next_cousin = NULL;
2119      obj->depth = HWLOC_TYPE_DEPTH_MISC;
2120      hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_MISC], obj);
2121      for_each_misc_child(child, obj)
2122        hwloc_list_special_objects(topology, child);
2123    } else if (hwloc__obj_type_is_io(obj->type)) {
2124      obj->next_cousin = NULL;
2125      if (obj->type == HWLOC_OBJ_BRIDGE) {
2126        obj->depth = HWLOC_TYPE_DEPTH_BRIDGE;
2127        hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_BRIDGE], obj);
2128      } else if (obj->type == HWLOC_OBJ_PCI_DEVICE) {
2129        obj->depth = HWLOC_TYPE_DEPTH_PCI_DEVICE;
2130        hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_PCIDEV], obj);
2131      } else if (obj->type == HWLOC_OBJ_OS_DEVICE) {
2132        obj->depth = HWLOC_TYPE_DEPTH_OS_DEVICE;
2133        hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_OSDEV], obj);
2134      }
2135      for_each_io_child(child, obj)
2136        hwloc_list_special_objects(topology, child);
2137      for_each_misc_child(child, obj)
2138        hwloc_list_special_objects(topology, child);
2139    } else {
2140      for_each_child(child, obj)
2141        hwloc_list_special_objects(topology, child);
2142      for_each_memory_child(child, obj)
2143        hwloc_list_special_objects(topology, child);
2144      for_each_io_child(child, obj)
2145        hwloc_list_special_objects(topology, child);
2146      for_each_misc_child(child, obj)
2147        hwloc_list_special_objects(topology, child);
2148    }
2149  }
2150  static int
2151  hwloc_connect_special_levels(hwloc_topology_t topology)
2152  {
2153    unsigned i;
2154    for(i=0; i<HWLOC_NR_SLEVELS; i++)
2155      free(topology->slevels[i].objs);
2156    memset(&topology->slevels, 0, sizeof(topology->slevels));
2157    hwloc_list_special_objects(topology, topology->levels[0][0]);
2158    for(i=0; i<HWLOC_NR_SLEVELS; i++) {
2159      if (hwloc_build_level_from_list(&topology->slevels[i]) < 0)
2160        return -1;
2161    }
2162    return 0;
2163  }
2164  static int
2165  hwloc_connect_levels(hwloc_topology_t topology)
2166  {
2167    unsigned l, i=0;
2168    hwloc_obj_t *objs, *taken_objs, *new_objs, top_obj, root;
2169    unsigned n_objs, n_taken_objs, n_new_objs;
2170    for(l=1; l<topology->nb_levels; l++)
2171      free(topology->levels[l]);
2172    memset(topology->levels+1, 0, (topology->nb_levels-1)*sizeof(*topology->levels));
2173    memset(topology->level_nbobjects+1, 0, (topology->nb_levels-1)*sizeof(*topology->level_nbobjects));
2174    topology->nb_levels = 1;
2175    hwloc_reset_normal_type_depths(topology);
2176    root = topology->levels[0][0];
2177    root->depth = 0;
2178    topology->type_depth[root->type] = 0;
2179    root->logical_index = 0;
2180    root->prev_cousin = NULL;
2181    root->next_cousin = NULL;
2182    root->parent = NULL;
2183    root->sibling_rank = 0;
2184    root->prev_sibling = NULL;
2185    root->next_sibling = NULL;
2186    n_objs = topology->levels[0][0]->arity;
2187    objs = malloc(n_objs * sizeof(objs[0]));
2188    if (!objs) {
2189      errno = ENOMEM;
2190      return -1;
2191    }
2192    memcpy(objs, topology->levels[0][0]->children, n_objs*sizeof(objs[0]));
2193    while (n_objs) {
2194      for (i = 0; i < n_objs; i++)
2195        if (objs[i]->type != HWLOC_OBJ_PU)
2196          break;
2197      top_obj = i == n_objs ? objs[0] : objs[i];
2198      for (i = 0; i < n_objs; i++) {
2199        if (hwloc_type_cmp(top_obj, objs[i]) != HWLOC_OBJ_EQUAL) {
2200  	if (find_same_type(objs[i], top_obj)) {
2201  	  top_obj = objs[i];
2202  	}
2203        }
2204      }
2205      taken_objs = malloc((n_objs+1) * sizeof(taken_objs[0]));
2206      if (!taken_objs) {
2207        free(objs);
2208        errno = ENOMEM;
2209        return -1;
2210      }
2211      n_new_objs = 0;
2212      for (i = 0; i < n_objs; i++) {
2213        if (objs[i]->arity)
2214  	n_new_objs += objs[i]->arity;
2215        else
2216  	n_new_objs++;
2217      }
2218      new_objs = malloc(n_new_objs * sizeof(new_objs[0]));
2219      if (!new_objs) {
2220        free(objs);
2221        free(taken_objs);
2222        errno = ENOMEM;
2223        return -1;
2224      }
2225      n_new_objs = 0;
2226      n_taken_objs = 0;
2227      for (i = 0; i < n_objs; i++)
2228        if (hwloc_type_cmp(top_obj, objs[i]) == HWLOC_OBJ_EQUAL) {
2229  	taken_objs[n_taken_objs++] = objs[i];
2230  	if (objs[i]->arity)
2231  	  memcpy(&new_objs[n_new_objs], objs[i]->children, objs[i]->arity * sizeof(new_objs[0]));
2232  	n_new_objs += objs[i]->arity;
2233        } else {
2234  	new_objs[n_new_objs++] = objs[i];
2235        }
2236      if (!n_new_objs) {
2237        free(new_objs);
2238        new_objs = NULL;
2239      }
2240      for (i = 0; i < n_taken_objs; i++) {
2241        taken_objs[i]->depth = (int) topology->nb_levels;
2242        taken_objs[i]->logical_index = i;
2243        if (i) {
2244  	taken_objs[i]->prev_cousin = taken_objs[i-1];
2245  	taken_objs[i-1]->next_cousin = taken_objs[i];
2246        }
2247      }
2248      taken_objs[0]->prev_cousin = NULL;
2249      taken_objs[n_taken_objs-1]->next_cousin = NULL;
2250      hwloc_debug("--- %s level", hwloc_obj_type_string(top_obj->type));
2251      hwloc_debug(" has number %u\n\n", topology->nb_levels);
2252      if (topology->type_depth[top_obj->type] == HWLOC_TYPE_DEPTH_UNKNOWN)
2253        topology->type_depth[top_obj->type] = (int) topology->nb_levels;
2254      else
2255        topology->type_depth[top_obj->type] = HWLOC_TYPE_DEPTH_MULTIPLE; &bsol;* mark as unknown */
2256      taken_objs[n_taken_objs] = NULL;
2257      if (topology->nb_levels == topology->nb_levels_allocated) {
2258        void *tmplevels, *tmpnbobjs;
2259        tmplevels = realloc(topology->levels,
2260  			  2 * topology->nb_levels_allocated * sizeof(*topology->levels));
2261        tmpnbobjs = realloc(topology->level_nbobjects,
2262  			  2 * topology->nb_levels_allocated * sizeof(*topology->level_nbobjects));
2263        if (!tmplevels || !tmpnbobjs) {
2264          if (HWLOC_SHOW_CRITICAL_ERRORS())
2265            fprintf(stderr, "hwloc: failed to realloc level arrays to %u\n", topology->nb_levels_allocated * 2);
2266  	if (tmplevels)
2267  	  topology->levels = tmplevels;
2268  	if (tmpnbobjs)
2269  	  topology->level_nbobjects = tmpnbobjs;
2270  	free(objs);
2271  	free(taken_objs);
2272  	free(new_objs);
2273  	errno = ENOMEM;
2274  	return -1;
2275        }
2276        topology->levels = tmplevels;
2277        topology->level_nbobjects = tmpnbobjs;
2278        memset(topology->levels + topology->nb_levels_allocated,
2279  	     0, topology->nb_levels_allocated * sizeof(*topology->levels));
2280        memset(topology->level_nbobjects + topology->nb_levels_allocated,
2281  	     0, topology->nb_levels_allocated * sizeof(*topology->level_nbobjects));
2282        topology->nb_levels_allocated *= 2;
2283      }
2284      topology->level_nbobjects[topology->nb_levels] = n_taken_objs;
2285      topology->levels[topology->nb_levels] = taken_objs;
2286      topology->nb_levels++;
2287      free(objs);
2288      objs = new_objs;
2289      n_objs = n_new_objs;
2290    }
2291    free(objs);
2292    return 0;
2293  }
2294  int
2295  hwloc_topology_reconnect(struct hwloc_topology *topology, unsigned long flags)
2296  {
2297    if (flags) {
2298      errno = EINVAL;
2299      return -1;
2300    }
2301    if (!topology->modified)
2302      return 0;
2303    hwloc_connect_children(topology->levels[0][0]);
2304    if (hwloc_connect_levels(topology) < 0)
2305      return -1;
2306    if (hwloc_connect_special_levels(topology) < 0)
2307      return -1;
2308    topology->modified = 0;
2309    return 0;
2310  }
2311  static hwloc_obj_t
2312  hwloc_debug_insert_osdev_sorted(hwloc_obj_t queue, hwloc_obj_t obj)
2313  {
2314    hwloc_obj_t *pcur = &queue;
2315    while (*pcur && strcmp((*pcur)->name, obj->name) < 0)
2316      pcur = &((*pcur)->next_sibling);
2317    obj->next_sibling = *pcur;
2318    *pcur = obj;
2319    return queue;
2320  }
2321  static void
2322  hwloc_debug_sort_children(hwloc_obj_t root)
2323  {
2324    hwloc_obj_t child;
2325    if (root->io_first_child) {
2326      hwloc_obj_t osdevqueue, *pchild;
2327      pchild = &root->io_first_child;
2328      osdevqueue = NULL;
2329      while ((child = *pchild) != NULL) {
2330        if (child->type != HWLOC_OBJ_OS_DEVICE) {
2331  	pchild = &child->next_sibling;
2332  	continue;
2333        }
2334        *pchild = child->next_sibling;
2335        child->next_sibling = NULL;
2336        osdevqueue = hwloc_debug_insert_osdev_sorted(osdevqueue, child);
2337      }
2338      *pchild = osdevqueue;
2339    }
2340    for_each_child(child, root)
2341      hwloc_debug_sort_children(child);
2342    for_each_memory_child(child, root)
2343      hwloc_debug_sort_children(child);
2344    for_each_io_child(child, root)
2345      hwloc_debug_sort_children(child);
2346  }
2347  void hwloc_alloc_root_sets(hwloc_obj_t root)
2348  {
2349    if (!root->cpuset)
2350       root->cpuset = hwloc_bitmap_alloc();
2351    if (!root->complete_cpuset)
2352       root->complete_cpuset = hwloc_bitmap_alloc();
2353    if (!root->nodeset)
2354      root->nodeset = hwloc_bitmap_alloc();
2355    if (!root->complete_nodeset)
2356      root->complete_nodeset = hwloc_bitmap_alloc();
2357  }
2358  static void
2359  hwloc_discover_by_phase(struct hwloc_topology *topology,
2360  			struct hwloc_disc_status *dstatus,
2361  			const char *phasename __hwloc_attribute_unused)
2362  {
2363    struct hwloc_backend *backend;
2364    hwloc_debug("%s phase discovery...\n", phasename);
2365    for(backend = topology->backends; backend; backend = backend->next) {
2366      if (dstatus->phase & dstatus->excluded_phases)
2367        break;
2368      if (!(backend->phases & dstatus->phase))
2369        continue;
2370      if (!backend->discover)
2371        continue;
2372      hwloc_debug("%s phase discovery in component %s...\n", phasename, backend->component->name);
2373      backend->discover(backend, dstatus);
2374      hwloc_debug_print_objects(0, topology->levels[0][0]);
2375    }
2376  }
2377  static int
2378  hwloc_discover(struct hwloc_topology *topology,
2379  	       struct hwloc_disc_status *dstatus)
2380  {
2381    const char *env;
2382    topology->modified = 0; &bsol;* no need to reconnect yet */
2383    topology->allowed_cpuset = hwloc_bitmap_alloc_full();
2384    topology->allowed_nodeset = hwloc_bitmap_alloc_full();
2385    if (topology->backend_phases & HWLOC_DISC_PHASE_GLOBAL) {
2386      struct hwloc_backend *global_backend = topology->backends;
2387      assert(global_backend);
2388      assert(global_backend->phases == HWLOC_DISC_PHASE_GLOBAL);
2389      hwloc_debug("GLOBAL phase discovery...\n");
2390      hwloc_debug("GLOBAL phase discovery with component %s...\n", global_backend->component->name);
2391      dstatus->phase = HWLOC_DISC_PHASE_GLOBAL;
2392      global_backend->discover(global_backend, dstatus);
2393      hwloc_debug_print_objects(0, topology->levels[0][0]);
2394    }
2395    if (topology->backend_phases & HWLOC_DISC_PHASE_CPU) {
2396      dstatus->phase = HWLOC_DISC_PHASE_CPU;
2397      hwloc_discover_by_phase(topology, dstatus, "CPU");
2398    }
2399    if (!(topology->backend_phases & (HWLOC_DISC_PHASE_GLOBAL|HWLOC_DISC_PHASE_CPU))) {
2400      hwloc_debug("No GLOBAL or CPU component phase found\n");
2401    }
2402    if (!topology->levels[0][0]->cpuset || hwloc_bitmap_iszero(topology->levels[0][0]->cpuset)) {
2403      hwloc_debug("%s", "No PU added by any CPU or GLOBAL component phase\n");
2404      errno = EINVAL;
2405      return -1;
2406    }
2407    if (topology->backend_phases & HWLOC_DISC_PHASE_MEMORY) {
2408      dstatus->phase = HWLOC_DISC_PHASE_MEMORY;
2409      hwloc_discover_by_phase(topology, dstatus, "MEMORY");
2410    }
2411    if (&bsol;* check if getting the sets of locally allowed resources is possible */
2412        topology->binding_hooks.get_allowed_resources
2413        && topology->is_thissystem
2414        && !(dstatus->flags & HWLOC_DISC_STATUS_FLAG_GOT_ALLOWED_RESOURCES)
2415        && ((topology->flags & HWLOC_TOPOLOGY_FLAG_THISSYSTEM_ALLOWED_RESOURCES) != 0
2416  	  || ((env = getenv("HWLOC_THISSYSTEM_ALLOWED_RESOURCES")) != NULL && atoi(env)))) {
2417      topology->binding_hooks.get_allowed_resources(topology);
2418      dstatus->flags |= HWLOC_DISC_STATUS_FLAG_GOT_ALLOWED_RESOURCES;
2419    }
2420    if (hwloc_bitmap_iszero(topology->levels[0][0]->complete_nodeset)) {
2421      hwloc_obj_t node;
2422      hwloc_debug("%s", "\nAdd missing single NUMA node\n");
2423      node = hwloc_alloc_setup_object(topology, HWLOC_OBJ_NUMANODE, 0);
2424      node->cpuset = hwloc_bitmap_dup(topology->levels[0][0]->cpuset);
2425      node->nodeset = hwloc_bitmap_alloc();
2426      hwloc_bitmap_set(node->nodeset, 0);
2427      memcpy(&node->attr->numanode, &topology->machine_memory, sizeof(topology->machine_memory));
2428      memset(&topology->machine_memory, 0, sizeof(topology->machine_memory));
2429      hwloc__insert_object_by_cpuset(topology, NULL, node, "core:defaultnumanode");
2430    } else {
2431      free(topology->machine_memory.page_types);
2432      memset(&topology->machine_memory, 0, sizeof(topology->machine_memory));
2433    }
2434    hwloc_debug("%s", "\nFixup root sets\n");
2435    hwloc_bitmap_and(topology->levels[0][0]->cpuset, topology->levels[0][0]->cpuset, topology->levels[0][0]->complete_cpuset);
2436    hwloc_bitmap_and(topology->levels[0][0]->nodeset, topology->levels[0][0]->nodeset, topology->levels[0][0]->complete_nodeset);
2437    hwloc_bitmap_and(topology->allowed_cpuset, topology->allowed_cpuset, topology->levels[0][0]->cpuset);
2438    hwloc_bitmap_and(topology->allowed_nodeset, topology->allowed_nodeset, topology->levels[0][0]->nodeset);
2439    hwloc_debug("%s", "\nPropagate sets\n");
2440    propagate_nodeset(topology->levels[0][0]);
2441    fixup_sets(topology->levels[0][0]);
2442    hwloc_debug_print_objects(0, topology->levels[0][0]);
2443    if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED)) {
2444      hwloc_debug("%s", "\nRemoving unauthorized sets from all sets\n");
2445      remove_unused_sets(topology, topology->levels[0][0]);
2446      hwloc_debug_print_objects(0, topology->levels[0][0]);
2447    }
2448    if (!hwloc_filter_check_keep_object(topology, topology->levels[0][0])
2449        && topology->levels[0][0]->first_child && !topology->levels[0][0]->first_child->next_sibling) {
2450      hwloc_obj_t oldroot = topology->levels[0][0];
2451      hwloc_obj_t newroot = oldroot->first_child;
2452      newroot->parent = NULL;
2453      topology->levels[0][0] = newroot;
2454      if (oldroot->memory_first_child)
2455        prepend_siblings_list(&newroot->memory_first_child, oldroot->memory_first_child, newroot);
2456      if (oldroot->io_first_child)
2457        prepend_siblings_list(&newroot->io_first_child, oldroot->io_first_child, newroot);
2458      if (oldroot->misc_first_child)
2459        prepend_siblings_list(&newroot->misc_first_child, oldroot->misc_first_child, newroot);
2460      hwloc_free_unlinked_object(oldroot);
2461    }
2462    hwloc_debug("%s", "\nOk, finished tweaking, now connect\n");
2463    if (hwloc_topology_reconnect(topology, 0) < 0)
2464      return -1;
2465    hwloc_debug_print_objects(0, topology->levels[0][0]);
2466    hwloc_pci_discovery_prepare(topology);
2467    if (topology->backend_phases & HWLOC_DISC_PHASE_PCI) {
2468      dstatus->phase = HWLOC_DISC_PHASE_PCI;
2469      hwloc_discover_by_phase(topology, dstatus, "PCI");
2470    }
2471    if (topology->backend_phases & HWLOC_DISC_PHASE_IO) {
2472      dstatus->phase = HWLOC_DISC_PHASE_IO;
2473      hwloc_discover_by_phase(topology, dstatus, "IO");
2474    }
2475    if (topology->backend_phases & HWLOC_DISC_PHASE_MISC) {
2476      dstatus->phase = HWLOC_DISC_PHASE_MISC;
2477      hwloc_discover_by_phase(topology, dstatus, "MISC");
2478    }
2479    if (topology->backend_phases & HWLOC_DISC_PHASE_ANNOTATE) {
2480      dstatus->phase = HWLOC_DISC_PHASE_ANNOTATE;
2481      hwloc_discover_by_phase(topology, dstatus, "ANNOTATE");
2482    }
2483    hwloc_pci_discovery_exit(topology); &bsol;* pci needed up to annotate */
2484    if (getenv("HWLOC_DEBUG_SORT_CHILDREN"))
2485      hwloc_debug_sort_children(topology->levels[0][0]);
2486    hwloc_debug("%s", "\nRemoving bridge objects if needed\n");
2487    hwloc_filter_bridges(topology, topology->levels[0][0]);
2488    hwloc_debug_print_objects(0, topology->levels[0][0]);
2489    hwloc_debug("%s", "\nRemoving empty objects\n");
2490    remove_empty(topology, &topology->levels[0][0]);
2491    if (!topology->levels[0][0]) {
2492      if (HWLOC_SHOW_CRITICAL_ERRORS())
2493        fprintf(stderr, "hwloc: Topology became empty, aborting!\n");
2494      return -1;
2495    }
2496    if (hwloc_bitmap_iszero(topology->levels[0][0]->cpuset)) {
2497      if (HWLOC_SHOW_CRITICAL_ERRORS())
2498        fprintf(stderr, "hwloc: Topology does not contain any PU, aborting!\n");
2499      return -1;
2500    }
2501    if (hwloc_bitmap_iszero(topology->levels[0][0]->nodeset)) {
2502      if (HWLOC_SHOW_CRITICAL_ERRORS())
2503        fprintf(stderr, "hwloc: Topology does not contain any NUMA node, aborting!\n");
2504      return -1;
2505    }
2506    hwloc_debug_print_objects(0, topology->levels[0][0]);
2507    hwloc_debug("%s", "\nRemoving levels with HWLOC_TYPE_FILTER_KEEP_STRUCTURE\n");
2508    if (hwloc_filter_levels_keep_structure(topology) < 0)
2509      return -1;
2510    hwloc_debug_print_objects(0, topology->levels[0][0]);
2511    hwloc_debug("%s", "\nPropagate total memory up\n");
2512    propagate_total_memory(topology->levels[0][0]);
2513    hwloc_propagate_symmetric_subtree(topology, topology->levels[0][0]);
2514    hwloc_set_group_depth(topology);
2515    if (topology->backends
2516        && strcmp(topology->backends->component->name, "xml")
2517        && !getenv("HWLOC_DONT_ADD_VERSION_INFO")) {
2518      char *value;
2519      hwloc_obj_add_info(topology->levels[0][0], "hwlocVersion", HWLOC_VERSION);
2520      value = hwloc_progname(topology);
2521      if (value) {
2522        hwloc_obj_add_info(topology->levels[0][0], "ProcessName", value);
2523        free(value);
2524      }
2525    }
2526    return 0;
2527  }
2528  void
2529  hwloc_topology_setup_defaults(struct hwloc_topology *topology)
2530  {
2531    struct hwloc_obj *root_obj;
2532    memset(&topology->binding_hooks, 0, sizeof(topology->binding_hooks));
2533    memset(topology->support.discovery, 0, sizeof(*topology->support.discovery));
2534    memset(topology->support.cpubind, 0, sizeof(*topology->support.cpubind));
2535    memset(topology->support.membind, 0, sizeof(*topology->support.membind));
<span onclick='openModal()' class='match'>2536    memset(topology->support.misc, 0, sizeof(*topology->support.misc));
2537    topology->next_gp_index = 1; &bsol;* keep 0 as an invalid value */
</span>2538    topology->nb_levels = 1; &bsol;* there's at least SYSTEM */
2539    topology->levels[0] = hwloc_tma_malloc (topology->tma, sizeof (hwloc_obj_t));
2540    topology->level_nbobjects[0] = 1;
2541    topology->machine_memory.local_memory = 0;
2542    topology->machine_memory.page_types_len = 0;
2543    topology->machine_memory.page_types = NULL;
2544    topology->allowed_cpuset = NULL;
2545    topology->allowed_nodeset = NULL;
2546    memset(&topology->slevels, 0, sizeof(topology->slevels));
2547    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_NUMANODE == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_NUMANODE));
2548    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_MISC == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_MISC));
2549    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_BRIDGE == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_BRIDGE));
2550    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_PCIDEV == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_PCI_DEVICE));
2551    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_OSDEV == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_OS_DEVICE));
2552    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_MEMCACHE == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_MEMCACHE));
2553    hwloc_reset_normal_type_depths(topology);
2554    topology->type_depth[HWLOC_OBJ_NUMANODE] = HWLOC_TYPE_DEPTH_NUMANODE;
2555    topology->type_depth[HWLOC_OBJ_MISC] = HWLOC_TYPE_DEPTH_MISC;
2556    topology->type_depth[HWLOC_OBJ_BRIDGE] = HWLOC_TYPE_DEPTH_BRIDGE;
2557    topology->type_depth[HWLOC_OBJ_PCI_DEVICE] = HWLOC_TYPE_DEPTH_PCI_DEVICE;
2558    topology->type_depth[HWLOC_OBJ_OS_DEVICE] = HWLOC_TYPE_DEPTH_OS_DEVICE;
2559    topology->type_depth[HWLOC_OBJ_MEMCACHE] = HWLOC_TYPE_DEPTH_MEMCACHE;
2560    root_obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_MACHINE, 0);
2561    topology->levels[0][0] = root_obj;
2562  }
2563  static void hwloc__topology_filter_init(struct hwloc_topology *topology);
2564  static int
2565  hwloc__topology_init (struct hwloc_topology **topologyp,
2566  		      unsigned nblevels,
2567  		      struct hwloc_tma *tma)
2568  {
2569    struct hwloc_topology *topology;
2570    topology = hwloc_tma_malloc (tma, sizeof (struct hwloc_topology));
2571    if(!topology)
2572      return -1;
2573    topology->tma = tma;
2574    hwloc_components_init(); &bsol;* uses malloc without tma, but won't need it since dup() caller already took a reference */
2575    hwloc_topology_components_init(topology);
2576    hwloc_pci_discovery_init(topology); &bsol;* make sure both dup() and load() get sane variables */
2577    topology->is_loaded = 0;
2578    topology->flags = 0;
2579    topology->is_thissystem = 1;
2580    topology->pid = 0;
2581    topology->userdata = NULL;
2582    topology->topology_abi = HWLOC_TOPOLOGY_ABI;
2583    topology->adopted_shmem_addr = NULL;
2584    topology->adopted_shmem_length = 0;
2585    topology->support.discovery = hwloc_tma_malloc(tma, sizeof(*topology->support.discovery));
2586    topology->support.cpubind = hwloc_tma_malloc(tma, sizeof(*topology->support.cpubind));
2587    topology->support.membind = hwloc_tma_malloc(tma, sizeof(*topology->support.membind));
2588    topology->support.misc = hwloc_tma_malloc(tma, sizeof(*topology->support.misc));
2589    topology->nb_levels_allocated = nblevels; &bsol;* enough for default 10 levels = Mach+Pack+Die+NUMA+L3+L2+L1d+L1i+Co+PU */
2590    topology->levels = hwloc_tma_calloc(tma, topology->nb_levels_allocated * sizeof(*topology->levels));
2591    topology->level_nbobjects = hwloc_tma_calloc(tma, topology->nb_levels_allocated * sizeof(*topology->level_nbobjects));
2592    hwloc__topology_filter_init(topology);
2593    hwloc_internal_distances_init(topology);
2594    hwloc_internal_memattrs_init(topology);
2595    hwloc_internal_cpukinds_init(topology);
2596    topology->userdata_export_cb = NULL;
2597    topology->userdata_import_cb = NULL;
2598    topology->userdata_not_decoded = 0;
2599    hwloc_topology_setup_defaults(topology);
2600    *topologyp = topology;
2601    return 0;
2602  }
2603  int
2604  hwloc_topology_init (struct hwloc_topology **topologyp)
2605  {
2606    return hwloc__topology_init(topologyp,
2607  			      16, &bsol;* 16 is enough for default 10 levels = Mach+Pack+Die+NUMA+L3+L2+L1d+L1i+Co+PU */
2608  			      NULL); &bsol;* no TMA for normal topologies, too many allocations to fix */
2609  }
2610  int
2611  hwloc_topology_set_pid(struct hwloc_topology *topology __hwloc_attribute_unused,
2612                         hwloc_pid_t pid __hwloc_attribute_unused)
2613  {
2614    if (topology->is_loaded) {
2615      errno = EBUSY;
2616      return -1;
2617    }
2618  #ifdef HWLOC_LINUX_SYS
2619    topology->pid = pid;
2620    return 0;
2621  #else &bsol;* HWLOC_LINUX_SYS */
2622    errno = ENOSYS;
2623    return -1;
2624  #endif &bsol;* HWLOC_LINUX_SYS */
2625  }
2626  int
2627  hwloc_topology_set_synthetic(struct hwloc_topology *topology, const char *description)
2628  {
2629    if (topology->is_loaded) {
2630      errno = EBUSY;
2631      return -1;
2632    }
2633    return hwloc_disc_component_force_enable(topology,
2634  					   0 &bsol;* api */,
2635  					   "synthetic",
2636  					   description, NULL, NULL);
2637  }
2638  int
2639  hwloc_topology_set_xml(struct hwloc_topology *topology,
2640  		       const char *xmlpath)
2641  {
2642    if (topology->is_loaded) {
2643      errno = EBUSY;
2644      return -1;
2645    }
2646    return hwloc_disc_component_force_enable(topology,
2647  					   0 &bsol;* api */,
2648  					   "xml",
2649  					   xmlpath, NULL, NULL);
2650  }
2651  int
2652  hwloc_topology_set_xmlbuffer(struct hwloc_topology *topology,
2653                               const char *xmlbuffer,
2654                               int size)
2655  {
2656    if (topology->is_loaded) {
2657      errno = EBUSY;
2658      return -1;
2659    }
2660    return hwloc_disc_component_force_enable(topology,
2661  					   0 &bsol;* api */,
2662  					   "xml", NULL,
2663  					   xmlbuffer, (void*) (uintptr_t) size);
2664  }
2665  int
2666  hwloc_topology_set_flags (struct hwloc_topology *topology, unsigned long flags)
2667  {
2668    if (topology->is_loaded) {
2669      errno = EBUSY;
2670      return -1;
2671    }
2672    if (flags & ~(HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED
2673                  |HWLOC_TOPOLOGY_FLAG_IS_THISSYSTEM
2674                  |HWLOC_TOPOLOGY_FLAG_THISSYSTEM_ALLOWED_RESOURCES
2675                  |HWLOC_TOPOLOGY_FLAG_IMPORT_SUPPORT
2676                  |HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING
2677                  |HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING
2678                  |HWLOC_TOPOLOGY_FLAG_DONT_CHANGE_BINDING
2679                  |HWLOC_TOPOLOGY_FLAG_NO_DISTANCES
2680                  |HWLOC_TOPOLOGY_FLAG_NO_MEMATTRS
2681                  |HWLOC_TOPOLOGY_FLAG_NO_CPUKINDS)) {
2682      errno = EINVAL;
2683      return -1;
2684    }
2685    if ((flags & (HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING|HWLOC_TOPOLOGY_FLAG_IS_THISSYSTEM)) == HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING) {
2686      errno = EINVAL;
2687      return -1;
2688    }
2689    if ((flags & (HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING|HWLOC_TOPOLOGY_FLAG_IS_THISSYSTEM)) == HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING) {
2690      errno = EINVAL;
2691      return -1;
2692    }
2693    topology->flags = flags;
2694    return 0;
2695  }
2696  unsigned long
2697  hwloc_topology_get_flags (struct hwloc_topology *topology)
2698  {
2699    return topology->flags;
2700  }
2701  static void
2702  hwloc__topology_filter_init(struct hwloc_topology *topology)
2703  {
2704    hwloc_obj_type_t type;
2705    for(type = HWLOC_OBJ_TYPE_MIN; type < HWLOC_OBJ_TYPE_MAX; type++)
2706      topology->type_filter[type] = HWLOC_TYPE_FILTER_KEEP_ALL;
2707    topology->type_filter[HWLOC_OBJ_L1ICACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2708    topology->type_filter[HWLOC_OBJ_L2ICACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2709    topology->type_filter[HWLOC_OBJ_L3ICACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2710    topology->type_filter[HWLOC_OBJ_MEMCACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2711    topology->type_filter[HWLOC_OBJ_GROUP] = HWLOC_TYPE_FILTER_KEEP_STRUCTURE;
2712    topology->type_filter[HWLOC_OBJ_MISC] = HWLOC_TYPE_FILTER_KEEP_NONE;
2713    topology->type_filter[HWLOC_OBJ_BRIDGE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2714    topology->type_filter[HWLOC_OBJ_PCI_DEVICE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2715    topology->type_filter[HWLOC_OBJ_OS_DEVICE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2716  }
2717  static int
2718  hwloc__topology_set_type_filter(struct hwloc_topology *topology, hwloc_obj_type_t type, enum hwloc_type_filter_e filter)
2719  {
2720    if (type == HWLOC_OBJ_PU || type == HWLOC_OBJ_NUMANODE || type == HWLOC_OBJ_MACHINE) {
2721      if (filter != HWLOC_TYPE_FILTER_KEEP_ALL) {
2722        errno = EINVAL;
2723        return -1;
2724      }
2725    } else if (hwloc__obj_type_is_special(type)) {
2726      if (filter == HWLOC_TYPE_FILTER_KEEP_STRUCTURE) {
2727        errno = EINVAL;
2728        return -1;
2729      }
2730    } else if (type == HWLOC_OBJ_GROUP) {
2731      if (filter == HWLOC_TYPE_FILTER_KEEP_ALL) {
2732        errno = EINVAL;
2733        return -1;
2734      }
2735    }
2736    if (!hwloc__obj_type_is_special(type) && filter == HWLOC_TYPE_FILTER_KEEP_IMPORTANT)
2737      filter = HWLOC_TYPE_FILTER_KEEP_ALL;
2738    topology->type_filter[type] = filter;
2739    return 0;
2740  }
2741  int
2742  hwloc_topology_set_type_filter(struct hwloc_topology *topology, hwloc_obj_type_t type, enum hwloc_type_filter_e filter)
2743  {
2744    HWLOC_BUILD_ASSERT(HWLOC_OBJ_TYPE_MIN == 0);
2745    if ((unsigned) type >= HWLOC_OBJ_TYPE_MAX) {
2746      errno = EINVAL;
2747      return -1;
2748    }
2749    if (topology->is_loaded) {
2750      errno = EBUSY;
2751      return -1;
2752    }
2753    return hwloc__topology_set_type_filter(topology, type, filter);
2754  }
2755  int
2756  hwloc_topology_set_all_types_filter(struct hwloc_topology *topology, enum hwloc_type_filter_e filter)
2757  {
2758    hwloc_obj_type_t type;
2759    if (topology->is_loaded) {
2760      errno = EBUSY;
2761      return -1;
2762    }
2763    for(type = HWLOC_OBJ_TYPE_MIN; type < HWLOC_OBJ_TYPE_MAX; type++)
2764      hwloc__topology_set_type_filter(topology, type, filter);
2765    return 0;
2766  }
2767  int
2768  hwloc_topology_set_cache_types_filter(hwloc_topology_t topology, enum hwloc_type_filter_e filter)
2769  {
2770    unsigned i;
2771    for(i=HWLOC_OBJ_L1CACHE; i<HWLOC_OBJ_L3ICACHE; i++)
2772      hwloc_topology_set_type_filter(topology, (hwloc_obj_type_t) i, filter);
2773    return 0;
2774  }
2775  int
2776  hwloc_topology_set_icache_types_filter(hwloc_topology_t topology, enum hwloc_type_filter_e filter)
2777  {
2778    unsigned i;
2779    for(i=HWLOC_OBJ_L1ICACHE; i<HWLOC_OBJ_L3ICACHE; i++)
2780      hwloc_topology_set_type_filter(topology, (hwloc_obj_type_t) i, filter);
2781    return 0;
2782  }
2783  int
2784  hwloc_topology_set_io_types_filter(hwloc_topology_t topology, enum hwloc_type_filter_e filter)
2785  {
2786    hwloc_topology_set_type_filter(topology, HWLOC_OBJ_BRIDGE, filter);
2787    hwloc_topology_set_type_filter(topology, HWLOC_OBJ_PCI_DEVICE, filter);
2788    hwloc_topology_set_type_filter(topology, HWLOC_OBJ_OS_DEVICE, filter);
2789    return 0;
2790  }
2791  int
2792  hwloc_topology_get_type_filter(struct hwloc_topology *topology, hwloc_obj_type_t type, enum hwloc_type_filter_e *filterp)
2793  {
2794    HWLOC_BUILD_ASSERT(HWLOC_OBJ_TYPE_MIN == 0);
2795    if ((unsigned) type >= HWLOC_OBJ_TYPE_MAX) {
2796      errno = EINVAL;
2797      return -1;
2798    }
2799    *filterp = topology->type_filter[type];
2800    return 0;
2801  }
2802  void
2803  hwloc_topology_clear (struct hwloc_topology *topology)
2804  {
2805    unsigned l;
2806    hwloc_internal_cpukinds_destroy(topology);
2807    hwloc_internal_distances_destroy(topology);
2808    hwloc_internal_memattrs_destroy(topology);
2809    hwloc_free_object_and_children(topology->levels[0][0]);
2810    hwloc_bitmap_free(topology->allowed_cpuset);
2811    hwloc_bitmap_free(topology->allowed_nodeset);
2812    for (l=0; l<topology->nb_levels; l++)
2813      free(topology->levels[l]);
2814    for(l=0; l<HWLOC_NR_SLEVELS; l++)
2815      free(topology->slevels[l].objs);
2816    free(topology->machine_memory.page_types);
2817  }
2818  void
2819  hwloc_topology_destroy (struct hwloc_topology *topology)
2820  {
2821    if (topology->adopted_shmem_addr) {
2822      hwloc__topology_disadopt(topology);
2823      return;
2824    }
2825    hwloc_backends_disable_all(topology);
2826    hwloc_topology_components_fini(topology);
2827    hwloc_components_fini();
2828    hwloc_topology_clear(topology);
2829    free(topology->levels);
2830    free(topology->level_nbobjects);
2831    free(topology->support.discovery);
2832    free(topology->support.cpubind);
2833    free(topology->support.membind);
2834    free(topology->support.misc);
2835    free(topology);
2836  }
2837  int
2838  hwloc_topology_load (struct hwloc_topology *topology)
2839  {
2840    struct hwloc_disc_status dstatus;
2841    const char *env;
2842    int err;
2843    if (topology->is_loaded) {
2844      errno = EBUSY;
2845      return -1;
2846    }
2847    hwloc_internal_distances_prepare(topology);
2848    hwloc_internal_memattrs_prepare(topology);
2849    if (getenv("HWLOC_XML_USERDATA_NOT_DECODED"))
2850      topology->userdata_not_decoded = 1;
2851    if (!getenv("HWLOC_COMPONENTS")) {
2852      if (!topology->backends) {
2853        const char *fsroot_path_env = getenv("HWLOC_FSROOT");
2854        if (fsroot_path_env)
2855  	hwloc_disc_component_force_enable(topology,
2856  					  1 &bsol;* env force */,
2857  					  "linux",
2858  					  NULL &bsol;* backend will getenv again */, NULL, NULL);
2859      }
2860      if (!topology->backends) {
2861        const char *cpuid_path_env = getenv("HWLOC_CPUID_PATH");
2862        if (cpuid_path_env)
2863  	hwloc_disc_component_force_enable(topology,
2864  					  1 &bsol;* env force */,
2865  					  "x86",
2866  					  NULL &bsol;* backend will getenv again */, NULL, NULL);
2867      }
2868      if (!topology->backends) {
2869        const char *synthetic_env = getenv("HWLOC_SYNTHETIC");
2870        if (synthetic_env)
2871  	hwloc_disc_component_force_enable(topology,
2872  					  1 &bsol;* env force */,
2873  					  "synthetic",
2874  					  synthetic_env, NULL, NULL);
2875      }
2876      if (!topology->backends) {
2877        const char *xmlpath_env = getenv("HWLOC_XMLFILE");
2878        if (xmlpath_env)
2879  	hwloc_disc_component_force_enable(topology,
2880  					  1 &bsol;* env force */,
2881  					  "xml",
2882  					  xmlpath_env, NULL, NULL);
2883      }
2884    }
2885    dstatus.excluded_phases = 0;
2886    dstatus.flags = 0; &bsol;* did nothing yet */
2887    env = getenv("HWLOC_ALLOW");
2888    if (env && !strcmp(env, "all"))
2889      dstatus.flags |= HWLOC_DISC_STATUS_FLAG_GOT_ALLOWED_RESOURCES;
2890    hwloc_disc_components_enable_others(topology);
2891    hwloc_backends_is_thissystem(topology);
2892    hwloc_backends_find_callbacks(topology);
2893    hwloc_set_binding_hooks(topology);
2894    err = hwloc_discover(topology, &dstatus);
2895    if (err < 0)
2896      goto out;
2897  #ifndef HWLOC_DEBUG
2898    if (getenv("HWLOC_DEBUG_CHECK"))
2899  #endif
2900      hwloc_topology_check(topology);
2901    hwloc_internal_cpukinds_rank(topology);
2902    hwloc_internal_distances_invalidate_cached_objs(topology);
2903    hwloc_internal_distances_refresh(topology);
2904    hwloc_internal_memattrs_need_refresh(topology);
2905    hwloc_internal_memattrs_refresh(topology);
2906    hwloc_internal_memattrs_guess_memory_tiers(topology);
2907    topology->is_loaded = 1;
2908    if (topology->flags & HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING) {
2909      hwloc_bitmap_t set = hwloc_bitmap_alloc();
2910      if (set) {
2911        err = hwloc_get_cpubind(topology, set, HWLOC_CPUBIND_STRICT);
2912        if (!err)
2913          hwloc_topology_restrict(topology, set, 0);
2914        hwloc_bitmap_free(set);
2915      }
2916    }
2917    if (topology->flags & HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING) {
2918      hwloc_bitmap_t set = hwloc_bitmap_alloc();
2919      hwloc_membind_policy_t policy;
2920      if (set) {
2921        err = hwloc_get_membind(topology, set, &policy, HWLOC_MEMBIND_STRICT | HWLOC_MEMBIND_BYNODESET);
2922        if (!err)
2923          hwloc_topology_restrict(topology, set, HWLOC_RESTRICT_FLAG_BYNODESET);
2924        hwloc_bitmap_free(set);
2925      }
2926    }
2927    if (topology->backend_phases & HWLOC_DISC_PHASE_TWEAK) {
2928      dstatus.phase = HWLOC_DISC_PHASE_TWEAK;
2929      hwloc_discover_by_phase(topology, &dstatus, "TWEAK");
2930    }
2931    return 0;
2932   out:
2933    hwloc_pci_discovery_exit(topology);
2934    hwloc_topology_clear(topology);
2935    hwloc_topology_setup_defaults(topology);
2936    hwloc_backends_disable_all(topology);
2937    return -1;
2938  }
2939  static void
2940  restrict_object_by_cpuset(hwloc_topology_t topology, unsigned long flags, hwloc_obj_t *pobj,
2941  			  hwloc_bitmap_t droppedcpuset, hwloc_bitmap_t droppednodeset)
2942  {
2943    hwloc_obj_t obj = *pobj, child, *pchild;
2944    int modified = 0;
2945    if (hwloc_bitmap_intersects(obj->complete_cpuset, droppedcpuset)) {
2946      hwloc_bitmap_andnot(obj->cpuset, obj->cpuset, droppedcpuset);
2947      hwloc_bitmap_andnot(obj->complete_cpuset, obj->complete_cpuset, droppedcpuset);
2948      modified = 1;
2949    } else {
2950      if ((flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS)
2951  	&& hwloc_bitmap_iszero(obj->complete_cpuset)) {
2952        modified = 1;
2953      }
2954      if (droppednodeset)
2955        assert(!hwloc_bitmap_intersects(obj->complete_nodeset, droppednodeset)
2956  	     || hwloc_bitmap_iszero(obj->complete_cpuset));
2957    }
2958    if (droppednodeset) {
2959      hwloc_bitmap_andnot(obj->nodeset, obj->nodeset, droppednodeset);
2960      hwloc_bitmap_andnot(obj->complete_nodeset, obj->complete_nodeset, droppednodeset);
2961    }
2962    if (modified) {
2963      for_each_child_safe(child, obj, pchild)
2964        restrict_object_by_cpuset(topology, flags, pchild, droppedcpuset, droppednodeset);
2965      hwloc__reorder_children(obj);
2966      for_each_memory_child_safe(child, obj, pchild)
2967        restrict_object_by_cpuset(topology, flags, pchild, droppedcpuset, droppednodeset);
2968    }
2969    if (!obj->first_child && !obj->memory_first_child &bsol;* arity not updated before connect_children() */
2970        && hwloc_bitmap_iszero(obj->cpuset)
2971        && (obj->type != HWLOC_OBJ_NUMANODE || (flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS))) {
2972      hwloc_debug("%s", "\nRemoving object during restrict by cpuset");
2973      hwloc_debug_print_object(0, obj);
2974      if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_IO)) {
2975        hwloc_free_object_siblings_and_children(obj->io_first_child);
2976        obj->io_first_child = NULL;
2977      }
2978      if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_MISC)) {
2979        hwloc_free_object_siblings_and_children(obj->misc_first_child);
2980        obj->misc_first_child = NULL;
2981      }
2982      assert(!obj->first_child);
2983      assert(!obj->memory_first_child);
2984      unlink_and_free_single_object(pobj);
2985      topology->modified = 1;
2986    }
2987  }
2988  static void
2989  restrict_object_by_nodeset(hwloc_topology_t topology, unsigned long flags, hwloc_obj_t *pobj,
2990  			   hwloc_bitmap_t droppedcpuset, hwloc_bitmap_t droppednodeset)
2991  {
2992    hwloc_obj_t obj = *pobj, child, *pchild;
2993    int modified = 0;
2994    if (hwloc_bitmap_intersects(obj->complete_nodeset, droppednodeset)) {
2995      hwloc_bitmap_andnot(obj->nodeset, obj->nodeset, droppednodeset);
2996      hwloc_bitmap_andnot(obj->complete_nodeset, obj->complete_nodeset, droppednodeset);
2997      modified = 1;
2998    } else {
2999      if ((flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)
3000  	&& hwloc_bitmap_iszero(obj->complete_nodeset)) {
3001        modified = 1;
3002      }
3003      if (droppedcpuset)
3004        assert(!hwloc_bitmap_intersects(obj->complete_cpuset, droppedcpuset)
3005  	     || hwloc_bitmap_iszero(obj->complete_nodeset));
3006    }
3007    if (droppedcpuset) {
3008      hwloc_bitmap_andnot(obj->cpuset, obj->cpuset, droppedcpuset);
3009      hwloc_bitmap_andnot(obj->complete_cpuset, obj->complete_cpuset, droppedcpuset);
3010    }
3011    if (modified) {
3012      for_each_child_safe(child, obj, pchild)
3013        restrict_object_by_nodeset(topology, flags, pchild, droppedcpuset, droppednodeset);
3014      if (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)
3015        hwloc__reorder_children(obj);
3016      for_each_memory_child_safe(child, obj, pchild)
3017        restrict_object_by_nodeset(topology, flags, pchild, droppedcpuset, droppednodeset);
3018    }
3019    if (!obj->first_child && !obj->memory_first_child &bsol;* arity not updated before connect_children() */
3020        && hwloc_bitmap_iszero(obj->nodeset)
3021        && (obj->type != HWLOC_OBJ_PU || (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS))) {
3022      hwloc_debug("%s", "\nRemoving object during restrict by nodeset");
3023      hwloc_debug_print_object(0, obj);
3024      if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_IO)) {
3025        hwloc_free_object_siblings_and_children(obj->io_first_child);
3026        obj->io_first_child = NULL;
3027      }
3028      if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_MISC)) {
3029        hwloc_free_object_siblings_and_children(obj->misc_first_child);
3030        obj->misc_first_child = NULL;
3031      }
3032      assert(!obj->first_child);
3033      assert(!obj->memory_first_child);
3034      unlink_and_free_single_object(pobj);
3035      topology->modified = 1;
3036    }
3037  }
3038  int
3039  hwloc_topology_restrict(struct hwloc_topology *topology, hwloc_const_bitmap_t set, unsigned long flags)
3040  {
3041    hwloc_bitmap_t droppedcpuset, droppednodeset;
3042    if (!topology->is_loaded) {
3043      errno = EINVAL;
3044      return -1;
3045    }
3046    if (topology->adopted_shmem_addr) {
3047      errno = EPERM;
3048      return -1;
3049    }
3050    if (flags & ~(HWLOC_RESTRICT_FLAG_REMOVE_CPULESS
3051  		|HWLOC_RESTRICT_FLAG_ADAPT_MISC|HWLOC_RESTRICT_FLAG_ADAPT_IO
3052  		|HWLOC_RESTRICT_FLAG_BYNODESET|HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)) {
3053      errno = EINVAL;
3054      return -1;
3055    }
3056    if (flags & HWLOC_RESTRICT_FLAG_BYNODESET) {
3057      if (flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS) {
3058        errno = EINVAL;
3059        return -1;
3060      }
3061    } else {
3062      if (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS) {
3063        errno = EINVAL;
3064        return -1;
3065      }
3066    }
3067    if (((flags & HWLOC_RESTRICT_FLAG_BYNODESET) && !hwloc_bitmap_intersects(set, topology->allowed_nodeset))
3068        || (!(flags & HWLOC_RESTRICT_FLAG_BYNODESET) && !hwloc_bitmap_intersects(set, topology->allowed_cpuset))) {
3069      errno = EINVAL; &bsol;* easy failure, just don't touch the topology */
3070      return -1;
3071    }
3072    droppedcpuset = hwloc_bitmap_alloc();
3073    droppednodeset = hwloc_bitmap_alloc();
3074    if (!droppedcpuset || !droppednodeset) {
3075      hwloc_bitmap_free(droppedcpuset);
3076      hwloc_bitmap_free(droppednodeset);
3077      return -1;
3078    }
3079    if (flags & HWLOC_RESTRICT_FLAG_BYNODESET) {
3080      hwloc_bitmap_not(droppednodeset, set);
3081      if (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS) {
3082        hwloc_obj_t pu = hwloc_get_obj_by_type(topology, HWLOC_OBJ_PU, 0);
3083        assert(pu);
3084        do {
3085  	if (hwloc_bitmap_iszero(pu->cpuset)
3086  	    || hwloc_bitmap_isincluded(pu->nodeset, droppednodeset))
3087  	  hwloc_bitmap_set(droppedcpuset, pu->os_index);
3088  	pu = pu->next_cousin;
3089        } while (pu);
3090        if (hwloc_bitmap_isincluded(topology->allowed_cpuset, droppedcpuset)) {
3091  	errno = EINVAL; &bsol;* easy failure, just don't touch the topology */
3092  	hwloc_bitmap_free(droppedcpuset);
3093  	hwloc_bitmap_free(droppednodeset);
3094  	return -1;
3095        }
3096      }
3097      if (!(flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)
3098  	|| hwloc_bitmap_iszero(droppedcpuset)) {
3099        hwloc_bitmap_free(droppedcpuset);
3100        droppedcpuset = NULL;
3101      }
3102      restrict_object_by_nodeset(topology, flags, &topology->levels[0][0], droppedcpuset, droppednodeset);
3103      hwloc_bitmap_andnot(topology->allowed_nodeset, topology->allowed_nodeset, droppednodeset);
3104      if (droppedcpuset)
3105        hwloc_bitmap_andnot(topology->allowed_cpuset, topology->allowed_cpuset, droppedcpuset);
3106    } else {
3107      hwloc_bitmap_not(droppedcpuset, set);
3108      if (flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS) {
3109        hwloc_obj_t node = hwloc_get_obj_by_type(topology, HWLOC_OBJ_NUMANODE, 0);
3110        assert(node);
3111        do {
3112  	if (hwloc_bitmap_iszero(node->cpuset)
3113  	    || hwloc_bitmap_isincluded(node->cpuset, droppedcpuset))
3114  	  hwloc_bitmap_set(droppednodeset, node->os_index);
3115  	node = node->next_cousin;
3116        } while (node);
3117        if (hwloc_bitmap_isincluded(topology->allowed_nodeset, droppednodeset)) {
3118  	errno = EINVAL; &bsol;* easy failure, just don't touch the topology */
3119  	hwloc_bitmap_free(droppedcpuset);
3120  	hwloc_bitmap_free(droppednodeset);
3121  	return -1;
3122        }
3123      }
3124      if (!(flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS)
3125  	|| hwloc_bitmap_iszero(droppednodeset)) {
3126        hwloc_bitmap_free(droppednodeset);
3127        droppednodeset = NULL;
3128      }
3129      restrict_object_by_cpuset(topology, flags, &topology->levels[0][0], droppedcpuset, droppednodeset);
3130      hwloc_bitmap_andnot(topology->allowed_cpuset, topology->allowed_cpuset, droppedcpuset);
3131      if (droppednodeset)
3132        hwloc_bitmap_andnot(topology->allowed_nodeset, topology->allowed_nodeset, droppednodeset);
3133    }
3134    hwloc_bitmap_free(droppedcpuset);
3135    hwloc_bitmap_free(droppednodeset);
3136    if (hwloc_filter_levels_keep_structure(topology) < 0) &bsol;* takes care of reconnecting internally */
3137      goto out;
3138    hwloc_internal_distances_invalidate_cached_objs(topology);
3139    hwloc_internal_memattrs_need_refresh(topology);
3140    hwloc_propagate_symmetric_subtree(topology, topology->levels[0][0]);
3141    propagate_total_memory(topology->levels[0][0]);
3142    hwloc_internal_cpukinds_restrict(topology);
3143  #ifndef HWLOC_DEBUG
3144    if (getenv("HWLOC_DEBUG_CHECK"))
3145  #endif
3146      hwloc_topology_check(topology);
3147    return 0;
3148   out:
3149     hwloc_topology_clear(topology);
3150     hwloc_topology_setup_defaults(topology);
3151     return -1;
3152  }
3153  int
3154  hwloc_topology_allow(struct hwloc_topology *topology,
3155  		     hwloc_const_cpuset_t cpuset, hwloc_const_nodeset_t nodeset,
3156  		     unsigned long flags)
3157  {
3158    if (!topology->is_loaded)
3159      goto einval;
3160    if (topology->adopted_shmem_addr) {
3161      errno = EPERM;
3162      goto error;
3163    }
3164    if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED))
3165      goto einval;
3166    if (flags & ~(HWLOC_ALLOW_FLAG_ALL|HWLOC_ALLOW_FLAG_LOCAL_RESTRICTIONS|HWLOC_ALLOW_FLAG_CUSTOM))
3167      goto einval;
3168    switch (flags) {
3169    case HWLOC_ALLOW_FLAG_ALL: {
3170      if (cpuset || nodeset)
3171        goto einval;
3172      hwloc_bitmap_copy(topology->allowed_cpuset, hwloc_get_root_obj(topology)->complete_cpuset);
3173      hwloc_bitmap_copy(topology->allowed_nodeset, hwloc_get_root_obj(topology)->complete_nodeset);
3174      break;
3175    }
3176    case HWLOC_ALLOW_FLAG_LOCAL_RESTRICTIONS: {
3177      if (cpuset || nodeset)
3178        goto einval;
3179      if (!topology->is_thissystem)
3180        goto einval;
3181      if (!topology->binding_hooks.get_allowed_resources) {
3182        errno = ENOSYS;
3183        goto error;
3184      }
3185      topology->binding_hooks.get_allowed_resources(topology);
3186      hwloc_bitmap_and(topology->allowed_cpuset, topology->allowed_cpuset, hwloc_get_root_obj(topology)->cpuset);
3187      hwloc_bitmap_and(topology->allowed_nodeset, topology->allowed_nodeset, hwloc_get_root_obj(topology)->nodeset);
3188      break;
3189    }
3190    case HWLOC_ALLOW_FLAG_CUSTOM: {
3191      if (cpuset) {
3192        if (!hwloc_bitmap_intersects(hwloc_get_root_obj(topology)->cpuset, cpuset))
3193  	goto einval;
3194        hwloc_bitmap_and(topology->allowed_cpuset, hwloc_get_root_obj(topology)->cpuset, cpuset);
3195      }
3196      if (nodeset) {
3197        if (!hwloc_bitmap_intersects(hwloc_get_root_obj(topology)->nodeset, nodeset))
3198  	goto einval;
3199        hwloc_bitmap_and(topology->allowed_nodeset, hwloc_get_root_obj(topology)->nodeset, nodeset);
3200      }
3201      break;
3202    }
3203    default:
3204      goto einval;
3205    }
3206    return 0;
3207   einval:
3208    errno = EINVAL;
3209   error:
3210    return -1;
3211  }
3212  int
3213  hwloc_topology_refresh(struct hwloc_topology *topology)
3214  {
3215    hwloc_internal_cpukinds_rank(topology);
3216    hwloc_internal_distances_refresh(topology);
3217    hwloc_internal_memattrs_refresh(topology);
3218    return 0;
3219  }
3220  int
3221  hwloc_topology_is_thissystem(struct hwloc_topology *topology)
3222  {
3223    return topology->is_thissystem;
3224  }
3225  int
3226  hwloc_topology_get_depth(struct hwloc_topology *topology)
3227  {
3228    return (int) topology->nb_levels;
3229  }
3230  const struct hwloc_topology_support *
3231  hwloc_topology_get_support(struct hwloc_topology * topology)
3232  {
3233    return &topology->support;
3234  }
3235  void hwloc_topology_set_userdata(struct hwloc_topology * topology, const void *userdata)
3236  {
3237    topology->userdata = (void *) userdata;
3238  }
3239  void * hwloc_topology_get_userdata(struct hwloc_topology * topology)
3240  {
3241    return topology->userdata;
3242  }
3243  hwloc_const_cpuset_t
3244  hwloc_topology_get_complete_cpuset(hwloc_topology_t topology)
3245  {
3246    return hwloc_get_root_obj(topology)->complete_cpuset;
3247  }
3248  hwloc_const_cpuset_t
3249  hwloc_topology_get_topology_cpuset(hwloc_topology_t topology)
3250  {
3251    return hwloc_get_root_obj(topology)->cpuset;
3252  }
3253  hwloc_const_cpuset_t
3254  hwloc_topology_get_allowed_cpuset(hwloc_topology_t topology)
3255  {
3256    return topology->allowed_cpuset;
3257  }
3258  hwloc_const_nodeset_t
3259  hwloc_topology_get_complete_nodeset(hwloc_topology_t topology)
3260  {
3261    return hwloc_get_root_obj(topology)->complete_nodeset;
3262  }
3263  hwloc_const_nodeset_t
3264  hwloc_topology_get_topology_nodeset(hwloc_topology_t topology)
3265  {
3266    return hwloc_get_root_obj(topology)->nodeset;
3267  }
3268  hwloc_const_nodeset_t
3269  hwloc_topology_get_allowed_nodeset(hwloc_topology_t topology)
3270  {
3271    return topology->allowed_nodeset;
3272  }
3273  #ifndef NDEBUG &bsol;* assert only enabled if !NDEBUG */
3274  static void
3275  hwloc__check_child_siblings(hwloc_obj_t parent, hwloc_obj_t *array,
3276  			    unsigned arity, unsigned i,
3277  			    hwloc_obj_t child, hwloc_obj_t prev)
3278  {
3279    assert(child->parent == parent);
3280    assert(child->sibling_rank == i);
3281    if (array)
3282      assert(child == array[i]);
3283    if (prev)
3284      assert(prev->next_sibling == child);
3285    assert(child->prev_sibling == prev);
3286    if (!i)
3287      assert(child->prev_sibling == NULL);
3288    else
3289      assert(child->prev_sibling != NULL);
3290    if (i == arity-1)
3291      assert(child->next_sibling == NULL);
3292    else
3293      assert(child->next_sibling != NULL);
3294  }
3295  static void
3296  hwloc__check_object(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t obj);
3297  static void
3298  hwloc__check_normal_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
3299  {
3300    hwloc_obj_t child, prev;
3301    unsigned j;
3302    if (!parent->arity) {
3303      assert(!parent->children);
3304      assert(!parent->first_child);
3305      assert(!parent->last_child);
3306      return;
3307    }
3308    assert(parent->children);
3309    assert(parent->first_child);
3310    assert(parent->last_child);
3311    for(prev = NULL, child = parent->first_child, j = 0;
3312        child;
3313        prev = child, child = child->next_sibling, j++) {
3314      assert(hwloc__obj_type_is_normal(child->type));
3315      assert(child->depth > parent->depth);
3316      hwloc__check_child_siblings(parent, parent->children, parent->arity, j, child, prev);
3317      hwloc__check_object(topology, gp_indexes, child);
3318    }
3319    assert(j == parent->arity);
3320    assert(parent->first_child == parent->children[0]);
3321    assert(parent->last_child == parent->children[parent->arity-1]);
3322    if (parent->type == HWLOC_OBJ_PU)
3323      assert(!parent->arity);
3324  }
3325  static void
3326  hwloc__check_children_cpusets(hwloc_topology_t topology __hwloc_attribute_unused, hwloc_obj_t obj)
3327  {
3328    hwloc_obj_t child;
3329    int prev_first, prev_empty;
3330    if (obj->type == HWLOC_OBJ_PU) {
3331      assert(hwloc_bitmap_weight(obj->cpuset) == 1);
3332      assert(hwloc_bitmap_first(obj->cpuset) == (int) obj->os_index);
3333      assert(hwloc_bitmap_weight(obj->complete_cpuset) == 1);
3334      assert(hwloc_bitmap_first(obj->complete_cpuset) == (int) obj->os_index);
3335      if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED)) {
3336        assert(hwloc_bitmap_isset(topology->allowed_cpuset, (int) obj->os_index));
3337      }
3338      assert(!obj->arity);
3339    } else if (hwloc__obj_type_is_memory(obj->type)) {
3340      assert(hwloc_bitmap_isequal(obj->parent->cpuset, obj->cpuset));
3341      assert(!obj->arity);
3342    } else if (!hwloc__obj_type_is_special(obj->type)) {
3343      hwloc_bitmap_t set;
3344      set = hwloc_bitmap_alloc();
3345      for_each_child(child, obj) {
3346        assert(!hwloc_bitmap_intersects(set, child->cpuset));
3347        hwloc_bitmap_or(set, set, child->cpuset);
3348      }
3349      assert(hwloc_bitmap_isequal(set, obj->cpuset));
3350      hwloc_bitmap_free(set);
3351    }
3352    for_each_memory_child(child, obj)
3353      assert(hwloc_bitmap_isequal(obj->cpuset, child->cpuset));
3354    prev_first = -1; &bsol;* -1 works fine with first comparisons below */
3355    prev_empty = 0; &bsol;* no empty cpuset in previous children */
3356    for_each_child(child, obj) {
3357      int first = hwloc_bitmap_first(child->complete_cpuset);
3358      if (first >= 0) {
3359        assert(!prev_empty); &bsol;* no objects with CPU after objects without CPU */
3360        assert(prev_first < first);
3361      } else {
3362        prev_empty = 1;
3363      }
3364      prev_first = first;
3365    }
3366  }
3367  static void
3368  hwloc__check_memory_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
3369  {
3370    unsigned j;
3371    hwloc_obj_t child, prev;
3372    if (!parent->memory_arity) {
3373      assert(!parent->memory_first_child);
3374      return;
3375    }
3376    assert(parent->memory_first_child);
3377    for(prev = NULL, child = parent->memory_first_child, j = 0;
3378        child;
3379        prev = child, child = child->next_sibling, j++) {
3380      assert(hwloc__obj_type_is_memory(child->type));
3381      hwloc__check_child_siblings(parent, NULL, parent->memory_arity, j, child, prev);
3382      assert(!child->first_child);
3383      assert(!child->io_first_child);
3384      hwloc__check_object(topology, gp_indexes, child);
3385    }
3386    assert(j == parent->memory_arity);
3387    if (parent->type == HWLOC_OBJ_NUMANODE)
3388      assert(!parent->memory_arity);
3389  }
3390  static void
3391  hwloc__check_io_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
3392  {
3393    unsigned j;
3394    hwloc_obj_t child, prev;
3395    if (!parent->io_arity) {
3396      assert(!parent->io_first_child);
3397      return;
3398    }
3399    assert(parent->io_first_child);
3400    for(prev = NULL, child = parent->io_first_child, j = 0;
3401        child;
3402        prev = child, child = child->next_sibling, j++) {
3403      assert(hwloc__obj_type_is_io(child->type));
3404      hwloc__check_child_siblings(parent, NULL, parent->io_arity, j, child, prev);
3405      assert(!child->first_child);
3406      assert(!child->memory_first_child);
3407      hwloc__check_object(topology, gp_indexes, child);
3408    }
3409    assert(j == parent->io_arity);
3410  }
3411  static void
3412  hwloc__check_misc_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
3413  {
3414    unsigned j;
3415    hwloc_obj_t child, prev;
3416    if (!parent->misc_arity) {
3417      assert(!parent->misc_first_child);
3418      return;
3419    }
3420    assert(parent->misc_first_child);
3421    for(prev = NULL, child = parent->misc_first_child, j = 0;
3422        child;
3423        prev = child, child = child->next_sibling, j++) {
3424      assert(child->type == HWLOC_OBJ_MISC);
3425      hwloc__check_child_siblings(parent, NULL, parent->misc_arity, j, child, prev);
3426      assert(!child->first_child);
3427      assert(!child->memory_first_child);
3428      assert(!child->io_first_child);
3429      hwloc__check_object(topology, gp_indexes, child);
3430    }
3431    assert(j == parent->misc_arity);
3432  }
3433  static void
3434  hwloc__check_object(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t obj)
3435  {
3436    hwloc_uint64_t total_memory;
3437    hwloc_obj_t child;
3438    assert(!hwloc_bitmap_isset(gp_indexes, obj->gp_index));
3439    hwloc_bitmap_set(gp_indexes, obj->gp_index);
3440    HWLOC_BUILD_ASSERT(HWLOC_OBJ_TYPE_MIN == 0);
3441    assert((unsigned) obj->type < HWLOC_OBJ_TYPE_MAX);
3442    assert(hwloc_filter_check_keep_object(topology, obj));
3443    if (hwloc__obj_type_is_special(obj->type)) {
3444      assert(!obj->cpuset);
3445      if (obj->type == HWLOC_OBJ_BRIDGE)
3446        assert(obj->depth == HWLOC_TYPE_DEPTH_BRIDGE);
3447      else if (obj->type == HWLOC_OBJ_PCI_DEVICE)
3448        assert(obj->depth == HWLOC_TYPE_DEPTH_PCI_DEVICE);
3449      else if (obj->type == HWLOC_OBJ_OS_DEVICE)
3450        assert(obj->depth == HWLOC_TYPE_DEPTH_OS_DEVICE);
3451      else if (obj->type == HWLOC_OBJ_MISC)
3452        assert(obj->depth == HWLOC_TYPE_DEPTH_MISC);
3453    } else {
3454      assert(obj->cpuset);
3455      if (obj->type == HWLOC_OBJ_NUMANODE)
3456        assert(obj->depth == HWLOC_TYPE_DEPTH_NUMANODE);
3457      else if (obj->type == HWLOC_OBJ_MEMCACHE)
3458        assert(obj->depth == HWLOC_TYPE_DEPTH_MEMCACHE);
3459      else
3460        assert(obj->depth >= 0);
3461    }
3462    if (obj->type == HWLOC_OBJ_GROUP) {
3463      assert(obj->attr->group.depth != (unsigned) -1);
3464    }
3465    assert(!!obj->cpuset == !!obj->complete_cpuset);
3466    assert(!!obj->cpuset == !!obj->nodeset);
3467    assert(!!obj->nodeset == !!obj->complete_nodeset);
3468    if (obj->cpuset) {
3469      assert(hwloc_bitmap_isincluded(obj->cpuset, obj->complete_cpuset));
3470      assert(hwloc_bitmap_isincluded(obj->nodeset, obj->complete_nodeset));
3471    }
3472    if (hwloc__obj_type_is_cache(obj->type)) {
3473      if (hwloc__obj_type_is_icache(obj->type))
3474        assert(obj->attr->cache.type == HWLOC_OBJ_CACHE_INSTRUCTION);
3475      else if (hwloc__obj_type_is_dcache(obj->type))
3476        assert(obj->attr->cache.type == HWLOC_OBJ_CACHE_DATA
3477  	     || obj->attr->cache.type == HWLOC_OBJ_CACHE_UNIFIED);
3478      else
3479        assert(0);
3480      assert(hwloc_cache_type_by_depth_type(obj->attr->cache.depth, obj->attr->cache.type) == obj->type);
3481    }
3482    total_memory = 0;
3483    if (obj->type == HWLOC_OBJ_NUMANODE)
3484      total_memory += obj->attr->numanode.local_memory;
3485    for_each_child(child, obj) {
3486      total_memory += child->total_memory;
3487    }
3488    for_each_memory_child(child, obj) {
3489      total_memory += child->total_memory;
3490    }
3491    assert(total_memory == obj->total_memory);
3492    hwloc__check_normal_children(topology, gp_indexes, obj);
3493    hwloc__check_memory_children(topology, gp_indexes, obj);
3494    hwloc__check_io_children(topology, gp_indexes, obj);
3495    hwloc__check_misc_children(topology, gp_indexes, obj);
3496    hwloc__check_children_cpusets(topology, obj);
3497  }
3498  static void
3499  hwloc__check_nodesets(hwloc_topology_t topology, hwloc_obj_t obj, hwloc_bitmap_t parentset)
3500  {
3501    hwloc_obj_t child;
3502    int prev_first;
3503    if (obj->type == HWLOC_OBJ_NUMANODE) {
3504      assert(hwloc_bitmap_weight(obj->nodeset) == 1);
3505      assert(hwloc_bitmap_first(obj->nodeset) == (int) obj->os_index);
3506      assert(hwloc_bitmap_weight(obj->complete_nodeset) == 1);
3507      assert(hwloc_bitmap_first(obj->complete_nodeset) == (int) obj->os_index);
3508      if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED)) {
3509        assert(hwloc_bitmap_isset(topology->allowed_nodeset, (int) obj->os_index));
3510      }
3511      assert(!obj->arity);
3512      assert(!obj->memory_arity);
3513      assert(hwloc_bitmap_isincluded(obj->nodeset, parentset));
3514    } else {
3515      hwloc_bitmap_t myset;
3516      hwloc_bitmap_t childset;
3517      myset = hwloc_bitmap_alloc();
3518      for_each_memory_child(child, obj) {
3519        assert(!hwloc_bitmap_intersects(myset, child->nodeset));
3520        hwloc_bitmap_or(myset, myset, child->nodeset);
3521      }
3522      assert(!hwloc_bitmap_intersects(myset, parentset));
3523      hwloc_bitmap_or(parentset, parentset, myset);
3524      hwloc_bitmap_free(myset);
3525      childset = hwloc_bitmap_alloc();
3526      for_each_child(child, obj) {
3527        hwloc_bitmap_t set = hwloc_bitmap_dup(parentset); &bsol;* don't touch parentset, we don't want to propagate the first child contribution to other children */
3528        hwloc__check_nodesets(topology, child, set);
3529        hwloc_bitmap_andnot(set, set, parentset);
3530        assert(!hwloc_bitmap_intersects(childset, set));
3531        hwloc_bitmap_or(childset, childset, set);
3532        hwloc_bitmap_free(set);
3533      }
3534      assert(!hwloc_bitmap_intersects(parentset, childset));
3535      hwloc_bitmap_or(parentset, parentset, childset);
3536      hwloc_bitmap_free(childset);
3537      assert(hwloc_bitmap_isequal(obj->nodeset, parentset));
3538    }
3539    prev_first = -1; &bsol;* -1 works fine with first comparisons below */
3540    for_each_memory_child(child, obj) {
3541      int first = hwloc_bitmap_first(child->complete_nodeset);
3542      assert(prev_first < first);
3543      prev_first = first;
3544    }
3545  }
3546  static void
3547  hwloc__check_level(struct hwloc_topology *topology, int depth,
3548  		   hwloc_obj_t first, hwloc_obj_t last)
3549  {
3550    unsigned width = hwloc_get_nbobjs_by_depth(topology, depth);
3551    struct hwloc_obj *prev = NULL;
3552    hwloc_obj_t obj;
3553    unsigned j;
3554    for(j=0; j<width; j++) {
3555      obj = hwloc_get_obj_by_depth(topology, depth, j);
3556      assert(obj);
3557      assert(obj->depth == depth);
3558      assert(obj->logical_index == j);
3559      if (prev) {
3560        assert(hwloc_type_cmp(obj, prev) == HWLOC_OBJ_EQUAL);
3561        assert(prev->next_cousin == obj);
3562      }
3563      assert(obj->prev_cousin == prev);
3564      if (obj->type == HWLOC_OBJ_NUMANODE) {
3565        assert(hwloc_bitmap_weight(obj->complete_nodeset) == 1);
3566        assert(hwloc_bitmap_first(obj->complete_nodeset) == (int) obj->os_index);
3567      }
3568      prev = obj;
3569    }
3570    if (prev)
3571      assert(prev->next_cousin == NULL);
3572    if (width) {
3573      obj = hwloc_get_obj_by_depth(topology, depth, 0);
3574      assert(obj);
3575      assert(!obj->prev_cousin);
3576      assert(hwloc_get_depth_type(topology, depth) == obj->type);
3577      assert(depth == hwloc_get_type_depth(topology, obj->type)
3578  	   || HWLOC_TYPE_DEPTH_MULTIPLE == hwloc_get_type_depth(topology, obj->type));
3579      obj = hwloc_get_obj_by_depth(topology, depth, width-1);
3580      assert(obj);
3581      assert(!obj->next_cousin);
3582    }
3583    if (depth < 0) {
3584      assert(first == hwloc_get_obj_by_depth(topology, depth, 0));
3585      assert(last == hwloc_get_obj_by_depth(topology, depth, width-1));
3586    } else {
3587      assert(!first);
3588      assert(!last);
3589    }
3590    obj = hwloc_get_obj_by_depth(topology, depth, width);
3591    assert(!obj);
3592  }
3593  void
3594  hwloc_topology_check(struct hwloc_topology *topology)
3595  {
3596    struct hwloc_obj *obj;
3597    hwloc_bitmap_t gp_indexes, set;
3598    hwloc_obj_type_t type;
3599    unsigned i;
3600    int j, depth;
3601    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L2CACHE == HWLOC_OBJ_L1CACHE + 1);
3602    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L3CACHE == HWLOC_OBJ_L2CACHE + 1);
3603    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L4CACHE == HWLOC_OBJ_L3CACHE + 1);
3604    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L5CACHE == HWLOC_OBJ_L4CACHE + 1);
3605    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L1ICACHE == HWLOC_OBJ_L5CACHE + 1);
3606    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L2ICACHE == HWLOC_OBJ_L1ICACHE + 1);
3607    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L3ICACHE == HWLOC_OBJ_L2ICACHE + 1);
3608    HWLOC_BUILD_ASSERT(HWLOC_OBJ_NUMANODE   + 1 == HWLOC_OBJ_BRIDGE);
3609    HWLOC_BUILD_ASSERT(HWLOC_OBJ_BRIDGE     + 1 == HWLOC_OBJ_PCI_DEVICE);
3610    HWLOC_BUILD_ASSERT(HWLOC_OBJ_PCI_DEVICE + 1 == HWLOC_OBJ_OS_DEVICE);
3611    HWLOC_BUILD_ASSERT(HWLOC_OBJ_OS_DEVICE  + 1 == HWLOC_OBJ_MISC);
3612    HWLOC_BUILD_ASSERT(HWLOC_OBJ_MISC       + 1 == HWLOC_OBJ_MEMCACHE);
3613    HWLOC_BUILD_ASSERT(HWLOC_OBJ_MEMCACHE   + 1 == HWLOC_OBJ_DIE);
3614    HWLOC_BUILD_ASSERT(HWLOC_OBJ_DIE        + 1 == HWLOC_OBJ_TYPE_MAX);
3615    HWLOC_BUILD_ASSERT(sizeof(obj_type_order)/sizeof(*obj_type_order) == HWLOC_OBJ_TYPE_MAX);
3616    HWLOC_BUILD_ASSERT(sizeof(obj_order_type)/sizeof(*obj_order_type) == HWLOC_OBJ_TYPE_MAX);
3617    HWLOC_BUILD_ASSERT(sizeof(obj_type_priority)/sizeof(*obj_type_priority) == HWLOC_OBJ_TYPE_MAX);
3618    assert(topology->type_filter[HWLOC_OBJ_GROUP] != HWLOC_TYPE_FILTER_KEEP_ALL);
3619    for(type=HWLOC_OBJ_TYPE_MIN; type<HWLOC_OBJ_TYPE_MAX; type++)
3620      assert(obj_order_type[obj_type_order[type]] == type);
3621    for(i=HWLOC_OBJ_TYPE_MIN; i<HWLOC_OBJ_TYPE_MAX; i++)
3622      assert(obj_type_order[obj_order_type[i]] == i);
3623    depth = hwloc_topology_get_depth(topology);
3624    assert(!topology->modified);
3625    assert(hwloc_get_depth_type(topology, 0) == HWLOC_OBJ_MACHINE);
3626    assert(hwloc_get_depth_type(topology, depth-1) == HWLOC_OBJ_PU);
3627    assert(hwloc_get_nbobjs_by_depth(topology, depth-1) > 0);
3628    for(i=0; i<hwloc_get_nbobjs_by_depth(topology, depth-1); i++) {
3629      obj = hwloc_get_obj_by_depth(topology, depth-1, i);
3630      assert(obj);
3631      assert(obj->type == HWLOC_OBJ_PU);
3632      assert(!obj->memory_first_child);
3633    }
3634    for(j=1; j<depth-1; j++) {
3635      assert(hwloc_get_depth_type(topology, j) != HWLOC_OBJ_PU);
3636      assert(hwloc_get_depth_type(topology, j) != HWLOC_OBJ_MACHINE);
3637    }
3638    for(j=0; j<depth; j++) {
3639      int d;
3640      type = hwloc_get_depth_type(topology, j);
3641      assert(type != HWLOC_OBJ_NUMANODE);
3642      assert(type != HWLOC_OBJ_MEMCACHE);
3643      assert(type != HWLOC_OBJ_PCI_DEVICE);
3644      assert(type != HWLOC_OBJ_BRIDGE);
3645      assert(type != HWLOC_OBJ_OS_DEVICE);
3646      assert(type != HWLOC_OBJ_MISC);
3647      d = hwloc_get_type_depth(topology, type);
3648      assert(d == j || d == HWLOC_TYPE_DEPTH_MULTIPLE);
3649    }
3650    for(type=HWLOC_OBJ_TYPE_MIN; type<HWLOC_OBJ_TYPE_MAX; type++) {
3651      int d;
3652      d = hwloc_get_type_depth(topology, type);
3653      if (type == HWLOC_OBJ_NUMANODE) {
3654        assert(d == HWLOC_TYPE_DEPTH_NUMANODE);
3655        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_NUMANODE);
3656      } else if (type == HWLOC_OBJ_MEMCACHE) {
3657        assert(d == HWLOC_TYPE_DEPTH_MEMCACHE);
3658        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_MEMCACHE);
3659      } else if (type == HWLOC_OBJ_BRIDGE) {
3660        assert(d == HWLOC_TYPE_DEPTH_BRIDGE);
3661        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_BRIDGE);
3662      } else if (type == HWLOC_OBJ_PCI_DEVICE) {
3663        assert(d == HWLOC_TYPE_DEPTH_PCI_DEVICE);
3664        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_PCI_DEVICE);
3665      } else if (type == HWLOC_OBJ_OS_DEVICE) {
3666        assert(d == HWLOC_TYPE_DEPTH_OS_DEVICE);
3667        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_OS_DEVICE);
3668      } else if (type == HWLOC_OBJ_MISC) {
3669        assert(d == HWLOC_TYPE_DEPTH_MISC);
3670        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_MISC);
3671      } else {
3672        assert(d >=0 || d == HWLOC_TYPE_DEPTH_UNKNOWN || d == HWLOC_TYPE_DEPTH_MULTIPLE);
3673      }
3674    }
3675    assert(hwloc_get_nbobjs_by_depth(topology, 0) == 1);
3676    obj = hwloc_get_root_obj(topology);
3677    assert(obj);
3678    assert(!obj->parent);
3679    assert(obj->cpuset);
3680    assert(!obj->depth);
3681    if (topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED) {
3682      assert(hwloc_bitmap_isincluded(topology->allowed_cpuset, obj->cpuset));
3683      assert(hwloc_bitmap_isincluded(topology->allowed_nodeset, obj->nodeset));
3684    } else {
3685      assert(hwloc_bitmap_isequal(topology->allowed_cpuset, obj->cpuset));
3686      assert(hwloc_bitmap_isequal(topology->allowed_nodeset, obj->nodeset));
3687    }
3688    for(j=0; j<depth; j++)
3689      hwloc__check_level(topology, j, NULL, NULL);
3690    for(j=0; j<HWLOC_NR_SLEVELS; j++)
3691      hwloc__check_level(topology, HWLOC_SLEVEL_TO_DEPTH(j), topology->slevels[j].first, topology->slevels[j].last);
3692    gp_indexes = hwloc_bitmap_alloc(); &bsol;* TODO prealloc to topology->next_gp_index */
3693    hwloc__check_object(topology, gp_indexes, obj);
3694    hwloc_bitmap_free(gp_indexes);
3695    set = hwloc_bitmap_alloc();
3696    hwloc__check_nodesets(topology, obj, set);
3697    hwloc_bitmap_free(set);
3698  }
3699  #else &bsol;* NDEBUG */
3700  void
3701  hwloc_topology_check(struct hwloc_topology *topology __hwloc_attribute_unused)
3702  {
3703  }
3704  #endif &bsol;* NDEBUG */
</code></pre>
        </div>
        <div class="column">
            <h3>xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-topology.c</h3>
            <pre><code>1  #include "private/autogen/config.h"
2  #define _ATFILE_SOURCE
3  #include <assert.h>
4  #include <sys/types.h>
5  #ifdef HAVE_DIRENT_H
6  #include <dirent.h>
7  #endif
8  #ifdef HAVE_UNISTD_H
9  #include <unistd.h>
10  #endif
11  #include <string.h>
12  #include <errno.h>
13  #include <stdio.h>
14  #include <sys/stat.h>
15  #include <fcntl.h>
16  #include <limits.h>
17  #include <float.h>
18  #include "hwloc.h"
19  #include "private/private.h"
20  #include "private/debug.h"
21  #include "private/misc.h"
22  #ifdef HAVE_MACH_MACH_INIT_H
23  #include <mach/mach_init.h>
24  #endif
25  #ifdef HAVE_MACH_INIT_H
26  #include <mach_init.h>
27  #endif
28  #ifdef HAVE_MACH_MACH_HOST_H
29  #include <mach/mach_host.h>
30  #endif
31  #ifdef HAVE_SYS_PARAM_H
32  #include <sys/param.h>
33  #endif
34  #ifdef HAVE_SYS_SYSCTL_H
35  #include <sys/sysctl.h>
36  #endif
37  #ifdef HWLOC_WIN_SYS
38  #include <windows.h>
39  #endif
40  #ifdef HWLOC_HAVE_LEVELZERO
41  #if HWLOC_HAVE_ATTRIBUTE_CONSTRUCTOR
42  static void hwloc_constructor(void) __attribute__((constructor));
43  static void hwloc_constructor(void)
44  {
45    if (!getenv("ZES_ENABLE_SYSMAN"))
46  #ifdef HWLOC_WIN_SYS
47      putenv("ZES_ENABLE_SYSMAN=1");
48  #else
49      setenv("ZES_ENABLE_SYSMAN", "1", 1);
50  #endif
51  }
52  #endif
53  #ifdef HWLOC_WIN_SYS
54  BOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD fdwReason, LPVOID lpReserved)
55  {
56    if (fdwReason == DLL_PROCESS_ATTACH) {
57      if (!getenv("ZES_ENABLE_SYSMAN"))
58        putenv((char *) "ZES_ENABLE_SYSMAN=1");
59    }
60    return TRUE;
61  }
62  #endif
63  #endif &bsol;* HWLOC_HAVE_LEVELZERO */
64  unsigned hwloc_get_api_version(void)
65  {
66    return HWLOC_API_VERSION;
67  }
68  int hwloc_topology_abi_check(hwloc_topology_t topology)
69  {
70    return topology->topology_abi != HWLOC_TOPOLOGY_ABI ? -1 : 0;
71  }
72  int hwloc_hide_errors(void)
73  {
74    static int hide = 1; &bsol;* only show critical errors by default. lstopo will show others */
75    static int checked = 0;
76    if (!checked) {
77      const char *envvar = getenv("HWLOC_HIDE_ERRORS");
78      if (envvar) {
79        hide = atoi(envvar);
80  #ifdef HWLOC_DEBUG
81      } else {
82        envvar = getenv("HWLOC_DEBUG_VERBOSE");
83        if (!envvar || atoi(envvar))
84          hide = 0;
85  #endif
86      }
87      checked = 1;
88    }
89    return hide;
90  }
91  static void
92  report_insert_error_format_obj(char *buf, size_t buflen, hwloc_obj_t obj)
93  {
94    char typestr[64];
95    char *cpusetstr;
96    char *nodesetstr = NULL;
97    hwloc_obj_type_snprintf(typestr, sizeof(typestr), obj, 0);
98    hwloc_bitmap_asprintf(&cpusetstr, obj->cpuset);
99    if (obj->nodeset) &bsol;* may be missing during insert */
100      hwloc_bitmap_asprintf(&nodesetstr, obj->nodeset);
101    if (obj->os_index != HWLOC_UNKNOWN_INDEX)
102      snprintf(buf, buflen, "%s (P#%u cpuset %s%s%s)",
103               typestr, obj->os_index, cpusetstr,
104               nodesetstr ? " nodeset " : "",
105               nodesetstr ? nodesetstr : "");
106    else
107      snprintf(buf, buflen, "%s (cpuset %s%s%s)",
108               typestr, cpusetstr,
109               nodesetstr ? " nodeset " : "",
110               nodesetstr ? nodesetstr : "");
111    free(cpusetstr);
112    free(nodesetstr);
113  }
114  static void report_insert_error(hwloc_obj_t new, hwloc_obj_t old, const char *msg, const char *reason)
115  {
116    static int reported = 0;
117    if (reason && !reported && HWLOC_SHOW_CRITICAL_ERRORS()) {
118      char newstr[512];
119      char oldstr[512];
120      report_insert_error_format_obj(newstr, sizeof(newstr), new);
121      report_insert_error_format_obj(oldstr, sizeof(oldstr), old);
122      fprintf(stderr, "****************************************************************************\n");
123      fprintf(stderr, "* hwloc %s received invalid information from the operating system.\n", HWLOC_VERSION);
124      fprintf(stderr, "*\n");
125      fprintf(stderr, "* Failed with: %s\n", msg);
126      fprintf(stderr, "* while inserting %s at %s\n", newstr, oldstr);
127      fprintf(stderr, "* coming from: %s\n", reason);
128      fprintf(stderr, "*\n");
129      fprintf(stderr, "* The following FAQ entry in the hwloc documentation may help:\n");
130      fprintf(stderr, "*   What should I do when hwloc reports \"operating system\" warnings?\n");
131      fprintf(stderr, "* Otherwise please report this error message to the hwloc user's mailing list,\n");
132  #ifdef HWLOC_LINUX_SYS
133      fprintf(stderr, "* along with the files generated by the hwloc-gather-topology script.\n");
134  #else
135      fprintf(stderr, "* along with any relevant topology information from your platform.\n");
136  #endif
137      fprintf(stderr, "* \n");
138      fprintf(stderr, "* hwloc will now ignore this invalid topology information and continue.\n");
139      fprintf(stderr, "****************************************************************************\n");
140      reported = 1;
141    }
142  }
143  #if defined(HAVE_SYSCTLBYNAME)
144  int hwloc_get_sysctlbyname(const char *name, int64_t *ret)
145  {
146    union {
147      int32_t i32;
148      int64_t i64;
149    } n;
150    size_t size = sizeof(n);
151    if (sysctlbyname(name, &n, &size, NULL, 0))
152      return -1;
153    switch (size) {
154      case sizeof(n.i32):
155        *ret = n.i32;
156        break;
157      case sizeof(n.i64):
158        *ret = n.i64;
159        break;
160      default:
161        return -1;
162    }
163    return 0;
164  }
165  #endif
166  #if defined(HAVE_SYSCTL)
167  int hwloc_get_sysctl(int name[], unsigned namelen, int64_t *ret)
168  {
169    union {
170      int32_t i32;
171      int64_t i64;
172    } n;
173    size_t size = sizeof(n);
174    if (sysctl(name, namelen, &n, &size, NULL, 0))
175      return -1;
176    switch (size) {
177      case sizeof(n.i32):
178        *ret = n.i32;
179        break;
180      case sizeof(n.i64):
181        *ret = n.i64;
182        break;
183      default:
184        return -1;
185    }
186    return 0;
187  }
188  #endif
189  #ifndef HWLOC_WIN_SYS &bsol;* The windows implementation is in topology-windows.c */
190  int
191  hwloc_fallback_nbprocessors(unsigned flags) {
192    int n;
193    if (flags & HWLOC_FALLBACK_NBPROCESSORS_INCLUDE_OFFLINE) {
194  #if HAVE_DECL__SC_NPROCESSORS_CONF
195      n = sysconf(_SC_NPROCESSORS_CONF);
196  #elif HAVE_DECL__SC_NPROC_CONF
197      n = sysconf(_SC_NPROC_CONF);
198  #else
199      n = -1;
200  #endif
201      if (n != -1)
202        return n;
203    }
204  #if HAVE_DECL__SC_NPROCESSORS_ONLN
205    n = sysconf(_SC_NPROCESSORS_ONLN);
206  #elif HAVE_DECL__SC_NPROC_ONLN
207    n = sysconf(_SC_NPROC_ONLN);
208  #elif HAVE_DECL__SC_NPROCESSORS_CONF
209    n = sysconf(_SC_NPROCESSORS_CONF);
210  #elif HAVE_DECL__SC_NPROC_CONF
211    n = sysconf(_SC_NPROC_CONF);
212  #elif defined(HAVE_HOST_INFO) && HAVE_HOST_INFO
213    struct host_basic_info info;
214    mach_msg_type_number_t count = HOST_BASIC_INFO_COUNT;
215    host_info(mach_host_self(), HOST_BASIC_INFO, (integer_t*) &info, &count);
216    n = info.avail_cpus;
217  #elif defined(HAVE_SYSCTLBYNAME)
218    int64_t nn;
219    if (hwloc_get_sysctlbyname("hw.ncpu", &nn))
220      nn = -1;
221    n = nn;
222  #elif defined(HAVE_SYSCTL) && HAVE_DECL_CTL_HW && HAVE_DECL_HW_NCPU
223    static int name[2] = {CTL_HW, HW_NCPU};
224    int64_t nn;
225    if (hwloc_get_sysctl(name, sizeof(name)/sizeof(*name), &nn))
226      n = -1;
227    n = nn;
228  #else
229  #ifdef __GNUC__
230  #warning No known way to discover number of available processors on this system
231  #endif
232    n = -1;
233  #endif
234    return n;
235  }
236  int64_t
237  hwloc_fallback_memsize(void) {
238    int64_t size;
239  #if defined(HAVE_HOST_INFO) && HAVE_HOST_INFO
240    struct host_basic_info info;
241    mach_msg_type_number_t count = HOST_BASIC_INFO_COUNT;
242    host_info(mach_host_self(), HOST_BASIC_INFO, (integer_t*) &info, &count);
243    size = info.memory_size;
244  #elif defined(HAVE_SYSCTL) && HAVE_DECL_CTL_HW && (HAVE_DECL_HW_REALMEM64 || HAVE_DECL_HW_MEMSIZE64 || HAVE_DECL_HW_PHYSMEM64 || HAVE_DECL_HW_USERMEM64 || HAVE_DECL_HW_REALMEM || HAVE_DECL_HW_MEMSIZE || HAVE_DECL_HW_PHYSMEM || HAVE_DECL_HW_USERMEM)
245  #if HAVE_DECL_HW_MEMSIZE64
246    static int name[2] = {CTL_HW, HW_MEMSIZE64};
247  #elif HAVE_DECL_HW_REALMEM64
248    static int name[2] = {CTL_HW, HW_REALMEM64};
249  #elif HAVE_DECL_HW_PHYSMEM64
250    static int name[2] = {CTL_HW, HW_PHYSMEM64};
251  #elif HAVE_DECL_HW_USERMEM64
252    static int name[2] = {CTL_HW, HW_USERMEM64};
253  #elif HAVE_DECL_HW_MEMSIZE
254    static int name[2] = {CTL_HW, HW_MEMSIZE};
255  #elif HAVE_DECL_HW_REALMEM
256    static int name[2] = {CTL_HW, HW_REALMEM};
257  #elif HAVE_DECL_HW_PHYSMEM
258    static int name[2] = {CTL_HW, HW_PHYSMEM};
259  #elif HAVE_DECL_HW_USERMEM
260    static int name[2] = {CTL_HW, HW_USERMEM};
261  #endif
262    if (hwloc_get_sysctl(name, sizeof(name)/sizeof(*name), &size))
263      size = -1;
264  #elif defined(HAVE_SYSCTLBYNAME)
265    if (hwloc_get_sysctlbyname("hw.memsize", &size) &&
266        hwloc_get_sysctlbyname("hw.realmem", &size) &&
267        hwloc_get_sysctlbyname("hw.physmem", &size) &&
268        hwloc_get_sysctlbyname("hw.usermem", &size))
269        size = -1;
270  #else
271    size = -1;
272  #endif
273    return size;
274  }
275  #endif &bsol;* !HWLOC_WIN_SYS */
276  void
277  hwloc_setup_pu_level(struct hwloc_topology *topology,
278  		     unsigned nb_pus)
279  {
280    struct hwloc_obj *obj;
281    unsigned oscpu,cpu;
282    hwloc_debug("%s", "\n\n * CPU cpusets *\n\n");
283    for (cpu=0,oscpu=0; cpu<nb_pus; oscpu++)
284      {
285        obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_PU, oscpu);
286        obj->cpuset = hwloc_bitmap_alloc();
287        hwloc_bitmap_only(obj->cpuset, oscpu);
288        hwloc_debug_2args_bitmap("cpu %u (os %u) has cpuset %s\n",
289  		 cpu, oscpu, obj->cpuset);
290        hwloc__insert_object_by_cpuset(topology, NULL, obj, "core:pulevel");
291        cpu++;
292      }
293  }
294  #define for_each_child_safe(child, parent, pchild) \
295    for (pchild = &(parent)->first_child, child = *pchild; \
296         child; \
297          \
298         (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
299          \
300          child = *pchild)
301  #define for_each_memory_child_safe(child, parent, pchild) \
302    for (pchild = &(parent)->memory_first_child, child = *pchild; \
303         child; \
304          \
305         (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
306          \
307          child = *pchild)
308  #define for_each_io_child_safe(child, parent, pchild) \
309    for (pchild = &(parent)->io_first_child, child = *pchild; \
310         child; \
311          \
312         (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
313          \
314          child = *pchild)
315  #define for_each_misc_child_safe(child, parent, pchild) \
316    for (pchild = &(parent)->misc_first_child, child = *pchild; \
317         child; \
318          \
319         (*pchild == child ? pchild = &(child->next_sibling) : NULL), \
320          \
321          child = *pchild)
322  #ifdef HWLOC_DEBUG
323  static void
324  hwloc_debug_print_object(int indent __hwloc_attribute_unused, hwloc_obj_t obj)
325  {
326    char type[64], idx[12], attr[1024], *cpuset = NULL;
327    hwloc_debug("%*s", 2*indent, "");
328    hwloc_obj_type_snprintf(type, sizeof(type), obj, 1);
329    if (obj->os_index != HWLOC_UNKNOWN_INDEX)
330      snprintf(idx, sizeof(idx), "#%u", obj->os_index);
331    else
332      *idx = '\0';
333    hwloc_obj_attr_snprintf(attr, sizeof(attr), obj, " ", 1);
334    hwloc_debug("%s%s%s%s%s", type, idx, *attr ? "(" : "", attr, *attr ? ")" : "");
335    if (obj->name)
336      hwloc_debug(" name \"%s\"", obj->name);
337    if (obj->subtype)
338      hwloc_debug(" subtype \"%s\"", obj->subtype);
339    if (obj->cpuset) {
340      hwloc_bitmap_asprintf(&cpuset, obj->cpuset);
341      hwloc_debug(" cpuset %s", cpuset);
342      free(cpuset);
343    }
344    if (obj->complete_cpuset) {
345      hwloc_bitmap_asprintf(&cpuset, obj->complete_cpuset);
346      hwloc_debug(" complete %s", cpuset);
347      free(cpuset);
348    }
349    if (obj->nodeset) {
350      hwloc_bitmap_asprintf(&cpuset, obj->nodeset);
351      hwloc_debug(" nodeset %s", cpuset);
352      free(cpuset);
353    }
354    if (obj->complete_nodeset) {
355      hwloc_bitmap_asprintf(&cpuset, obj->complete_nodeset);
356      hwloc_debug(" completeN %s", cpuset);
357      free(cpuset);
358    }
359    if (obj->arity)
360      hwloc_debug(" arity %u", obj->arity);
361    hwloc_debug("%s", "\n");
362  }
363  static void
364  hwloc_debug_print_objects(int indent __hwloc_attribute_unused, hwloc_obj_t obj)
365  {
366    if (hwloc_debug_enabled() >= 2) {
367      hwloc_obj_t child;
368      hwloc_debug_print_object(indent, obj);
369      for_each_child (child, obj)
370        hwloc_debug_print_objects(indent + 1, child);
371      for_each_memory_child (child, obj)
372        hwloc_debug_print_objects(indent + 1, child);
373      for_each_io_child (child, obj)
374        hwloc_debug_print_objects(indent + 1, child);
375      for_each_misc_child (child, obj)
376        hwloc_debug_print_objects(indent + 1, child);
377    }
378  }
379  #else &bsol;* !HWLOC_DEBUG */
380  #define hwloc_debug_print_object(indent, obj) do { &bsol;* nothing */ } while (0)
381  #define hwloc_debug_print_objects(indent, obj) do { &bsol;* nothing */ } while (0)
382  #endif &bsol;* !HWLOC_DEBUG */
383  void hwloc__free_infos(struct hwloc_info_s *infos, unsigned count)
384  {
385    unsigned i;
386    for(i=0; i<count; i++) {
387      free(infos[i].name);
388      free(infos[i].value);
389    }
390    free(infos);
391  }
392  int hwloc__add_info(struct hwloc_info_s **infosp, unsigned *countp, const char *name, const char *value)
393  {
394    unsigned count = *countp;
395    struct hwloc_info_s *infos = *infosp;
396  #define OBJECT_INFO_ALLOC 8
397    unsigned alloccount = (count + 1 + (OBJECT_INFO_ALLOC-1)) & ~(OBJECT_INFO_ALLOC-1);
398    if (count != alloccount) {
399      struct hwloc_info_s *tmpinfos = realloc(infos, alloccount*sizeof(*infos));
400      if (!tmpinfos)
401        goto out_with_array;
402      *infosp = infos = tmpinfos;
403    }
404    infos[count].name = strdup(name);
405    if (!infos[count].name)
406      goto out_with_array;
407    infos[count].value = strdup(value);
408    if (!infos[count].value)
409      goto out_with_name;
410    *countp = count+1;
411    return 0;
412   out_with_name:
413    free(infos[count].name);
414   out_with_array:
415    return -1;
416  }
417  int hwloc__add_info_nodup(struct hwloc_info_s **infosp, unsigned *countp,
418  			  const char *name, const char *value,
419  			  int replace)
420  {
421    struct hwloc_info_s *infos = *infosp;
422    unsigned count = *countp;
423    unsigned i;
424    for(i=0; i<count; i++) {
425      if (!strcmp(infos[i].name, name)) {
426        if (replace) {
427  	char *new = strdup(value);
428  	if (!new)
429  	  return -1;
430  	free(infos[i].value);
431  	infos[i].value = new;
432        }
433        return 0;
434      }
435    }
436    return hwloc__add_info(infosp, countp, name, value);
437  }
438  int hwloc__move_infos(struct hwloc_info_s **dst_infosp, unsigned *dst_countp,
439  		      struct hwloc_info_s **src_infosp, unsigned *src_countp)
440  {
441    unsigned dst_count = *dst_countp;
442    struct hwloc_info_s *dst_infos = *dst_infosp;
443    unsigned src_count = *src_countp;
444    struct hwloc_info_s *src_infos = *src_infosp;
445    unsigned i;
446  #define OBJECT_INFO_ALLOC 8
447    unsigned alloccount = (dst_count + src_count + (OBJECT_INFO_ALLOC-1)) & ~(OBJECT_INFO_ALLOC-1);
448    if (dst_count != alloccount) {
449      struct hwloc_info_s *tmp_infos = realloc(dst_infos, alloccount*sizeof(*dst_infos));
450      if (!tmp_infos)
451        goto drop;
452      dst_infos = tmp_infos;
453    }
454    for(i=0; i<src_count; i++, dst_count++) {
455      dst_infos[dst_count].name = src_infos[i].name;
456      dst_infos[dst_count].value = src_infos[i].value;
457    }
458    *dst_infosp = dst_infos;
459    *dst_countp = dst_count;
460    free(src_infos);
461    *src_infosp = NULL;
462    *src_countp = 0;
463    return 0;
464   drop:
465    for(i=0; i<src_count; i++) {
466      free(src_infos[i].name);
467      free(src_infos[i].value);
468    }
469    free(src_infos);
470    *src_infosp = NULL;
471    *src_countp = 0;
472    return -1;
473  }
474  int hwloc_obj_add_info(hwloc_obj_t obj, const char *name, const char *value)
475  {
476    return hwloc__add_info(&obj->infos, &obj->infos_count, name, value);
477  }
478  int hwloc__tma_dup_infos(struct hwloc_tma *tma,
479                           struct hwloc_info_s **newip, unsigned *newcp,
480                           struct hwloc_info_s *oldi, unsigned oldc)
481  {
482    struct hwloc_info_s *newi;
483    unsigned i, j;
484    newi = hwloc_tma_calloc(tma, oldc * sizeof(*newi));
485    if (!newi)
486      return -1;
487    for(i=0; i<oldc; i++) {
488      newi[i].name = hwloc_tma_strdup(tma, oldi[i].name);
489      newi[i].value = hwloc_tma_strdup(tma, oldi[i].value);
490      if (!newi[i].name || !newi[i].value)
491        goto failed;
492    }
493    *newip = newi;
494    *newcp = oldc;
495    return 0;
496   failed:
497    assert(!tma || !tma->dontfree); &bsol;* this tma cannot fail to allocate */
498    for(j=0; j<=i; j++) {
499      free(newi[i].name);
500      free(newi[i].value);
501    }
502    free(newi);
503    *newip = NULL;
504    return -1;
505  }
506  static void
507  hwloc__free_object_contents(hwloc_obj_t obj)
508  {
509    switch (obj->type) {
510    case HWLOC_OBJ_NUMANODE:
511      free(obj->attr->numanode.page_types);
512      break;
513    default:
514      break;
515    }
516    hwloc__free_infos(obj->infos, obj->infos_count);
517    free(obj->attr);
518    free(obj->children);
519    free(obj->subtype);
520    free(obj->name);
521    hwloc_bitmap_free(obj->cpuset);
522    hwloc_bitmap_free(obj->complete_cpuset);
523    hwloc_bitmap_free(obj->nodeset);
524    hwloc_bitmap_free(obj->complete_nodeset);
525  }
526  void
527  hwloc_free_unlinked_object(hwloc_obj_t obj)
528  {
529    hwloc__free_object_contents(obj);
530    free(obj);
531  }
532  static void
533  hwloc_replace_linked_object(hwloc_obj_t old, hwloc_obj_t new)
534  {
535    hwloc__free_object_contents(old);
536    new->parent = old->parent;
537    new->next_sibling = old->next_sibling;
538    new->first_child = old->first_child;
539    new->memory_first_child = old->memory_first_child;
540    new->io_first_child = old->io_first_child;
541    new->misc_first_child = old->misc_first_child;
542    memcpy(old, new, sizeof(*old));
543    memset(new, 0,sizeof(*new));
544  }
545  static void
546  unlink_and_free_object_and_children(hwloc_obj_t *pobj)
547  {
548    hwloc_obj_t obj = *pobj, child, *pchild;
549    for_each_child_safe(child, obj, pchild)
550      unlink_and_free_object_and_children(pchild);
551    for_each_memory_child_safe(child, obj, pchild)
552      unlink_and_free_object_and_children(pchild);
553    for_each_io_child_safe(child, obj, pchild)
554      unlink_and_free_object_and_children(pchild);
555    for_each_misc_child_safe(child, obj, pchild)
556      unlink_and_free_object_and_children(pchild);
557    *pobj = obj->next_sibling;
558    hwloc_free_unlinked_object(obj);
559  }
560  void
561  hwloc_free_object_and_children(hwloc_obj_t obj)
562  {
563    unlink_and_free_object_and_children(&obj);
564  }
565  void
566  hwloc_free_object_siblings_and_children(hwloc_obj_t obj)
567  {
568    while (obj)
569      unlink_and_free_object_and_children(&obj);
570  }
571  static hwloc_obj_t *
572  insert_siblings_list(hwloc_obj_t *firstp, hwloc_obj_t firstnew, hwloc_obj_t newparent)
573  {
574    hwloc_obj_t tmp;
575    assert(firstnew);
576    *firstp = tmp = firstnew;
577    tmp->parent = newparent;
578    while (tmp->next_sibling) {
579      tmp = tmp->next_sibling;
580      tmp->parent = newparent;
581    }
582    return &tmp->next_sibling;
583  }
584  static void
585  prepend_siblings_list(hwloc_obj_t *firstp, hwloc_obj_t firstnew, hwloc_obj_t newparent)
586  {
587    hwloc_obj_t *tmpp, tmp, last;
588    unsigned length;
589    for(length = 0, tmpp = &firstnew, last = NULL ; *tmpp; length++, last = *tmpp, tmpp = &((*tmpp)->next_sibling))
590      (*tmpp)->parent = newparent;
591    for(tmp = *firstp; tmp; tmp = tmp->next_sibling)
592      tmp->sibling_rank += length; &bsol;* if it wasn't initialized yet, it'll be overwritten later */
593    *tmpp = *firstp;
594    if (*firstp)
595      (*firstp)->prev_sibling = last;
596    *firstp = firstnew;
597  }
598  static void
599  append_siblings_list(hwloc_obj_t *firstp, hwloc_obj_t firstnew, hwloc_obj_t newparent)
600  {
601    hwloc_obj_t *tmpp, tmp, last;
602    unsigned length;
603    for(length = 0, tmpp = firstp, last = NULL ; *tmpp; length++, last = *tmpp, tmpp = &((*tmpp)->next_sibling));
604    for(tmp = firstnew; tmp; tmp = tmp->next_sibling) {
605      tmp->parent = newparent;
606      tmp->sibling_rank += length; &bsol;* if it wasn't set yet, it'll be overwritten later */
607    }
608    *tmpp = firstnew;
609    if (firstnew)
610      firstnew->prev_sibling = last;
611  }
612  static void
613  unlink_and_free_single_object(hwloc_obj_t *pparent)
614  {
615    hwloc_obj_t old = *pparent;
616    hwloc_obj_t *lastp;
617    if (old->type == HWLOC_OBJ_MISC) {
618      assert(!old->first_child);
619      assert(!old->memory_first_child);
620      assert(!old->io_first_child);
621      if (old->misc_first_child)
622        lastp = insert_siblings_list(pparent, old->misc_first_child, old->parent);
623      else
624        lastp = pparent;
625      *lastp = old->next_sibling;
626    } else if (hwloc__obj_type_is_io(old->type)) {
627      assert(!old->first_child);
628      assert(!old->memory_first_child);
629      if (old->io_first_child)
630        lastp = insert_siblings_list(pparent, old->io_first_child, old->parent);
631      else
632        lastp = pparent;
633      *lastp = old->next_sibling;
634      if (old->misc_first_child)
635        append_siblings_list(&old->parent->misc_first_child, old->misc_first_child, old->parent);
636    } else if (hwloc__obj_type_is_memory(old->type)) {
637      assert(!old->first_child);
638      assert(!old->io_first_child);
639      if (old->memory_first_child)
640        lastp = insert_siblings_list(pparent, old->memory_first_child, old->parent);
641      else
642        lastp = pparent;
643      *lastp = old->next_sibling;
644      if (old->misc_first_child)
645        append_siblings_list(&old->parent->misc_first_child, old->misc_first_child, old->parent);
646    } else {
647      if (old->first_child)
648        lastp = insert_siblings_list(pparent, old->first_child, old->parent);
649      else
650        lastp = pparent;
651      *lastp = old->next_sibling;
652      if (old->memory_first_child)
653        append_siblings_list(&old->parent->memory_first_child, old->memory_first_child, old->parent);
654      if (old->io_first_child)
655        append_siblings_list(&old->parent->io_first_child, old->io_first_child, old->parent);
656      if (old->misc_first_child)
657        append_siblings_list(&old->parent->misc_first_child, old->misc_first_child, old->parent);
658    }
659    hwloc_free_unlinked_object(old);
660  }
661  static int
662  hwloc__duplicate_object(struct hwloc_topology *newtopology,
663  			struct hwloc_obj *newparent,
664  			struct hwloc_obj *newobj,
665  			struct hwloc_obj *src)
666  {
667    struct hwloc_tma *tma = newtopology->tma;
668    hwloc_obj_t *level;
669    unsigned level_width;
670    size_t len;
671    unsigned i;
672    hwloc_obj_t child, prev;
673    int err = 0;
674    assert(!newparent == !!newobj);
675    if (!newobj) {
676      newobj = hwloc_alloc_setup_object(newtopology, src->type, src->os_index);
677      if (!newobj)
678        return -1;
679    }
680    newobj->logical_index = src->logical_index;
681    newobj->depth = src->depth;
682    newobj->sibling_rank = src->sibling_rank;
683    newobj->type = src->type;
684    newobj->os_index = src->os_index;
685    newobj->gp_index = src->gp_index;
686    newobj->symmetric_subtree = src->symmetric_subtree;
687    if (src->name)
688      newobj->name = hwloc_tma_strdup(tma, src->name);
689    if (src->subtype)
690      newobj->subtype = hwloc_tma_strdup(tma, src->subtype);
691    newobj->userdata = src->userdata;
692    newobj->total_memory = src->total_memory;
693    memcpy(newobj->attr, src->attr, sizeof(*newobj->attr));
694    if (src->type == HWLOC_OBJ_NUMANODE && src->attr->numanode.page_types_len) {
695      len = src->attr->numanode.page_types_len * sizeof(struct hwloc_memory_page_type_s);
696      newobj->attr->numanode.page_types = hwloc_tma_malloc(tma, len);
697      memcpy(newobj->attr->numanode.page_types, src->attr->numanode.page_types, len);
698    }
699    newobj->cpuset = hwloc_bitmap_tma_dup(tma, src->cpuset);
700    newobj->complete_cpuset = hwloc_bitmap_tma_dup(tma, src->complete_cpuset);
701    newobj->nodeset = hwloc_bitmap_tma_dup(tma, src->nodeset);
702    newobj->complete_nodeset = hwloc_bitmap_tma_dup(tma, src->complete_nodeset);
703    hwloc__tma_dup_infos(tma, &newobj->infos, &newobj->infos_count, src->infos, src->infos_count);
704    if (src->depth < 0) {
705      i = HWLOC_SLEVEL_FROM_DEPTH(src->depth);
706      level = newtopology->slevels[i].objs;
707      level_width = newtopology->slevels[i].nbobjs;
708      if (!newobj->logical_index)
709        newtopology->slevels[i].first = newobj;
710      if (newobj->logical_index == newtopology->slevels[i].nbobjs - 1)
711        newtopology->slevels[i].last = newobj;
712    } else {
713      level = newtopology->levels[src->depth];
714      level_width = newtopology->level_nbobjects[src->depth];
715    }
716    assert(newobj->logical_index < level_width);
717    level[newobj->logical_index] = newobj;
718    if (newobj->logical_index > 0 && level[newobj->logical_index-1]) {
719      newobj->prev_cousin = level[newobj->logical_index-1];
720      level[newobj->logical_index-1]->next_cousin = newobj;
721    }
722    if (newobj->logical_index < level_width-1 && level[newobj->logical_index+1]) {
723      newobj->next_cousin = level[newobj->logical_index+1];
724      level[newobj->logical_index+1]->prev_cousin = newobj;
725    }
726    if (src->arity) {
727      newobj->children = hwloc_tma_malloc(tma, src->arity * sizeof(*newobj->children));
728      if (!newobj->children)
729        return -1;
730    }
731    newobj->arity = src->arity;
732    newobj->memory_arity = src->memory_arity;
733    newobj->io_arity = src->io_arity;
734    newobj->misc_arity = src->misc_arity;
735    for_each_child(child, src) {
736      err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
737      if (err < 0)
738        goto out_with_children;
739    }
740    for_each_memory_child(child, src) {
741      err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
742      if (err < 0)
743        return err;
744    }
745    for_each_io_child(child, src) {
746      err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
747      if (err < 0)
748        goto out_with_children;
749    }
750    for_each_misc_child(child, src) {
751      err = hwloc__duplicate_object(newtopology, newobj, NULL, child);
752      if (err < 0)
753        goto out_with_children;
754    }
755   out_with_children:
756    if (!err) {
757      if (newobj->arity) {
758        newobj->children[0]->prev_sibling = NULL;
759        for(i=1; i<newobj->arity; i++)
760  	newobj->children[i]->prev_sibling = newobj->children[i-1];
761        newobj->last_child = newobj->children[newobj->arity-1];
762      }
763      if (newobj->memory_arity) {
764        child = newobj->memory_first_child;
765        prev = NULL;
766        while (child) {
767  	child->prev_sibling = prev;
768  	prev = child;
769  	child = child->next_sibling;
770        }
771      }
772      if (newobj->io_arity) {
773        child = newobj->io_first_child;
774        prev = NULL;
775        while (child) {
776  	child->prev_sibling = prev;
777  	prev = child;
778  	child = child->next_sibling;
779        }
780      }
781      if (newobj->misc_arity) {
782        child = newobj->misc_first_child;
783        prev = NULL;
784        while (child) {
785  	child->prev_sibling = prev;
786  	prev = child;
787  	child = child->next_sibling;
788        }
789      }
790    }
791    if (newparent) {
792      hwloc_insert_object_by_parent(newtopology, newparent, newobj);
793      if (hwloc__obj_type_is_normal(newobj->type))
794        newparent->children[newobj->sibling_rank] = newobj;
795    }
796    return err;
797  }
798  static int
799  hwloc__topology_init (struct hwloc_topology **topologyp, unsigned nblevels, struct hwloc_tma *tma);
800  int
801  hwloc__topology_dup(hwloc_topology_t *newp,
802  		    hwloc_topology_t old,
803  		    struct hwloc_tma *tma)
804  {
805    hwloc_topology_t new;
806    hwloc_obj_t newroot;
807    hwloc_obj_t oldroot = hwloc_get_root_obj(old);
808    unsigned i;
809    int err;
810    if (!old->is_loaded) {
811      errno = EINVAL;
812      return -1;
813    }
814    err = hwloc__topology_init(&new, old->nb_levels_allocated, tma);
815    if (err < 0)
816      goto out;
817    new->flags = old->flags;
818    memcpy(new->type_filter, old->type_filter, sizeof(old->type_filter));
819    new->is_thissystem = old->is_thissystem;
820    new->is_loaded = 1;
821    new->pid = old->pid;
822    new->next_gp_index = old->next_gp_index;
823    memcpy(&new->binding_hooks, &old->binding_hooks, sizeof(old->binding_hooks));
824    memcpy(new->support.discovery, old->support.discovery, sizeof(*old->support.discovery));
825    memcpy(new->support.cpubind, old->support.cpubind, sizeof(*old->support.cpubind));
826    memcpy(new->support.membind, old->support.membind, sizeof(*old->support.membind));
827    memcpy(new->support.misc, old->support.misc, sizeof(*old->support.misc));
828    new->allowed_cpuset = hwloc_bitmap_tma_dup(tma, old->allowed_cpuset);
829    new->allowed_nodeset = hwloc_bitmap_tma_dup(tma, old->allowed_nodeset);
830    new->userdata_export_cb = old->userdata_export_cb;
831    new->userdata_import_cb = old->userdata_import_cb;
832    new->userdata_not_decoded = old->userdata_not_decoded;
833    assert(!old->machine_memory.local_memory);
834    assert(!old->machine_memory.page_types_len);
835    assert(!old->machine_memory.page_types);
836    for(i = HWLOC_OBJ_TYPE_MIN; i < HWLOC_OBJ_TYPE_MAX; i++)
837      new->type_depth[i] = old->type_depth[i];
838    new->nb_levels = old->nb_levels;
839    assert(new->nb_levels_allocated >= new->nb_levels);
840    for(i=1 &bsol;* root level already allocated */ ; i<new->nb_levels; i++) {
841      new->level_nbobjects[i] = old->level_nbobjects[i];
842      new->levels[i] = hwloc_tma_calloc(tma, new->level_nbobjects[i] * sizeof(*new->levels[i]));
843    }
844    for(i=0; i<HWLOC_NR_SLEVELS; i++) {
845      new->slevels[i].nbobjs = old->slevels[i].nbobjs;
846      if (new->slevels[i].nbobjs)
847        new->slevels[i].objs = hwloc_tma_calloc(tma, new->slevels[i].nbobjs * sizeof(*new->slevels[i].objs));
848    }
849    newroot = hwloc_get_root_obj(new);
850    err = hwloc__duplicate_object(new, NULL, newroot, oldroot);
851    if (err < 0)
852      goto out_with_topology;
853    err = hwloc_internal_distances_dup(new, old);
854    if (err < 0)
855      goto out_with_topology;
856    err = hwloc_internal_memattrs_dup(new, old);
857    if (err < 0)
858      goto out_with_topology;
859    err = hwloc_internal_cpukinds_dup(new, old);
860    if (err < 0)
861      goto out_with_topology;
862    new->modified = 0;
863    new->backends = NULL;
864    new->get_pci_busid_cpuset_backend = NULL;
865  #ifndef HWLOC_DEBUG
866    if (getenv("HWLOC_DEBUG_CHECK"))
867  #endif
868      hwloc_topology_check(new);
869    *newp = new;
870    return 0;
871   out_with_topology:
872    assert(!tma || !tma->dontfree); &bsol;* this tma cannot fail to allocate */
873    hwloc_topology_destroy(new);
874   out:
875    return -1;
876  }
877  int
878  hwloc_topology_dup(hwloc_topology_t *newp,
879  		   hwloc_topology_t old)
880  {
881    return hwloc__topology_dup(newp, old, NULL);
882  }
883  static const unsigned obj_type_order[] = {
884        0,
885        4,
886           14,
887             18,
888        12,
889        10,
890        8,
891        7,
892        6,
893       13,
894       11,
895       9,
896          1,
897       3,
898         15,
899        16,
900         17,
901           19,
902       2,
903            5
904  };
905  #ifndef NDEBUG &bsol;* only used in debug check assert if !NDEBUG */
906  static const hwloc_obj_type_t obj_order_type[] = {
907    HWLOC_OBJ_MACHINE,
908    HWLOC_OBJ_GROUP,
909    HWLOC_OBJ_MEMCACHE,
910    HWLOC_OBJ_NUMANODE,
911    HWLOC_OBJ_PACKAGE,
912    HWLOC_OBJ_DIE,
913    HWLOC_OBJ_L5CACHE,
914    HWLOC_OBJ_L4CACHE,
915    HWLOC_OBJ_L3CACHE,
916    HWLOC_OBJ_L3ICACHE,
917    HWLOC_OBJ_L2CACHE,
918    HWLOC_OBJ_L2ICACHE,
919    HWLOC_OBJ_L1CACHE,
920    HWLOC_OBJ_L1ICACHE,
921    HWLOC_OBJ_CORE,
922    HWLOC_OBJ_BRIDGE,
923    HWLOC_OBJ_PCI_DEVICE,
924    HWLOC_OBJ_OS_DEVICE,
925    HWLOC_OBJ_PU,
926    HWLOC_OBJ_MISC &bsol;* Misc is always a leaf */
927  };
928  #endif
929  static const int obj_type_priority[] = {
930         90,
931         40,
932            60,
933              100,
934         20,
935         20,
936         20,
937         20,
938         20,
939        19,
940        19,
941        19,
942           0,
943        100,
944          0,
945      100,
946       100,
947            0,
948        19,
949             30
950  };
951  int hwloc_compare_types (hwloc_obj_type_t type1, hwloc_obj_type_t type2)
952  {
953    unsigned order1 = obj_type_order[type1];
954    unsigned order2 = obj_type_order[type2];
955    if (!hwloc__obj_type_is_normal(type1)
956        && hwloc__obj_type_is_normal(type2) && type2 != HWLOC_OBJ_MACHINE)
957      return HWLOC_TYPE_UNORDERED;
958    if (!hwloc__obj_type_is_normal(type2)
959        && hwloc__obj_type_is_normal(type1) && type1 != HWLOC_OBJ_MACHINE)
960      return HWLOC_TYPE_UNORDERED;
961    return order1 - order2;
962  }
963  enum hwloc_obj_cmp_e {
964    HWLOC_OBJ_EQUAL = HWLOC_BITMAP_EQUAL,			&bsol;**< \brief Equal */
965    HWLOC_OBJ_INCLUDED = HWLOC_BITMAP_INCLUDED,		&bsol;**< \brief Strictly included into */
966    HWLOC_OBJ_CONTAINS = HWLOC_BITMAP_CONTAINS,		&bsol;**< \brief Strictly contains */
967    HWLOC_OBJ_INTERSECTS = HWLOC_BITMAP_INTERSECTS,	&bsol;**< \brief Intersects, but no inclusion! */
968    HWLOC_OBJ_DIFFERENT = HWLOC_BITMAP_DIFFERENT		&bsol;**< \brief No intersection */
969  };
970  static enum hwloc_obj_cmp_e
971  hwloc_type_cmp(hwloc_obj_t obj1, hwloc_obj_t obj2)
972  {
973    hwloc_obj_type_t type1 = obj1->type;
974    hwloc_obj_type_t type2 = obj2->type;
975    int compare;
976    compare = hwloc_compare_types(type1, type2);
977    if (compare == HWLOC_TYPE_UNORDERED)
978      return HWLOC_OBJ_DIFFERENT; &bsol;* we cannot do better */
979    if (compare > 0)
980      return HWLOC_OBJ_INCLUDED;
981    if (compare < 0)
982      return HWLOC_OBJ_CONTAINS;
983    if (obj1->type == HWLOC_OBJ_GROUP
984        && (obj1->attr->group.kind != obj2->attr->group.kind
985  	  || obj1->attr->group.subkind != obj2->attr->group.subkind))
986      return HWLOC_OBJ_DIFFERENT; &bsol;* we cannot do better */
987    return HWLOC_OBJ_EQUAL;
988  }
989  static int
990  hwloc_obj_cmp_sets(hwloc_obj_t obj1, hwloc_obj_t obj2)
991  {
992    hwloc_bitmap_t set1, set2;
993    assert(!hwloc__obj_type_is_special(obj1->type));
994    assert(!hwloc__obj_type_is_special(obj2->type));
995    if (obj1->complete_cpuset && obj2->complete_cpuset) {
996      set1 = obj1->complete_cpuset;
997      set2 = obj2->complete_cpuset;
998    } else {
999      set1 = obj1->cpuset;
1000      set2 = obj2->cpuset;
1001    }
1002    if (set1 && set2 && !hwloc_bitmap_iszero(set1) && !hwloc_bitmap_iszero(set2))
1003      return hwloc_bitmap_compare_inclusion(set1, set2);
1004    return HWLOC_OBJ_DIFFERENT;
1005  }
1006  int
1007  hwloc__object_cpusets_compare_first(hwloc_obj_t obj1, hwloc_obj_t obj2)
1008  {
1009    if (obj1->complete_cpuset && obj2->complete_cpuset)
1010      return hwloc_bitmap_compare_first(obj1->complete_cpuset, obj2->complete_cpuset);
1011    else if (obj1->cpuset && obj2->cpuset)
1012      return hwloc_bitmap_compare_first(obj1->cpuset, obj2->cpuset);
1013    return 0;
1014  }
1015  static void
1016  merge_insert_equal(hwloc_obj_t new, hwloc_obj_t old)
1017  {
1018    if (old->os_index == HWLOC_UNKNOWN_INDEX)
1019      old->os_index = new->os_index;
1020    if (new->infos_count) {
1021      hwloc__move_infos(&old->infos, &old->infos_count,
1022  		      &new->infos, &new->infos_count);
1023    }
1024    if (new->name && !old->name) {
1025      old->name = new->name;
1026      new->name = NULL;
1027    }
1028    if (new->subtype && !old->subtype) {
1029      old->subtype = new->subtype;
1030      new->subtype = NULL;
1031    }
1032    switch(new->type) {
1033    case HWLOC_OBJ_NUMANODE:
1034      if (new->attr->numanode.local_memory && !old->attr->numanode.local_memory) {
1035        old->attr->numanode.local_memory = new->attr->numanode.local_memory;
1036        free(old->attr->numanode.page_types);
1037        old->attr->numanode.page_types_len = new->attr->numanode.page_types_len;
1038        old->attr->numanode.page_types = new->attr->numanode.page_types;
1039        new->attr->numanode.page_types = NULL;
1040        new->attr->numanode.page_types_len = 0;
1041      }
1042      break;
1043    case HWLOC_OBJ_L1CACHE:
1044    case HWLOC_OBJ_L2CACHE:
1045    case HWLOC_OBJ_L3CACHE:
1046    case HWLOC_OBJ_L4CACHE:
1047    case HWLOC_OBJ_L5CACHE:
1048    case HWLOC_OBJ_L1ICACHE:
1049    case HWLOC_OBJ_L2ICACHE:
1050    case HWLOC_OBJ_L3ICACHE:
1051      if (!old->attr->cache.size)
1052        old->attr->cache.size = new->attr->cache.size;
1053      if (!old->attr->cache.linesize)
1054        old->attr->cache.size = new->attr->cache.linesize;
1055      if (!old->attr->cache.associativity)
1056        old->attr->cache.size = new->attr->cache.linesize;
1057      break;
1058    default:
1059      break;
1060    }
1061  }
1062  static __hwloc_inline hwloc_obj_t
1063  hwloc__insert_try_merge_group(hwloc_topology_t topology, hwloc_obj_t old, hwloc_obj_t new)
1064  {
1065    if (new->type == HWLOC_OBJ_GROUP && old->type == HWLOC_OBJ_GROUP) {
1066      if (new->attr->group.dont_merge) {
1067        if (old->attr->group.dont_merge)
1068  	return NULL;
1069        hwloc_replace_linked_object(old, new);
1070        topology->modified = 1;
1071        return new;
1072      } else {
1073        if (old->attr->group.dont_merge)
1074  	return old;
1075        if (new->attr->group.kind < old->attr->group.kind) {
1076  	hwloc_replace_linked_object(old, new);
1077          topology->modified = 1;
1078        }
1079        return old;
1080      }
1081    }
1082    if (new->type == HWLOC_OBJ_GROUP && !new->attr->group.dont_merge) {
1083      if (old->type == HWLOC_OBJ_PU && new->attr->group.kind == HWLOC_GROUP_KIND_MEMORY)
1084        return NULL;
1085      return old;
1086    } else if (old->type == HWLOC_OBJ_GROUP && !old->attr->group.dont_merge) {
1087      if (new->type == HWLOC_OBJ_PU && old->attr->group.kind == HWLOC_GROUP_KIND_MEMORY)
1088        return NULL;
1089      hwloc_replace_linked_object(old, new);
1090      topology->modified = 1;
1091      return old;
1092    } else {
1093      return NULL;
1094    }
1095  }
1096  static struct hwloc_obj *
1097  hwloc___insert_object_by_cpuset(struct hwloc_topology *topology, hwloc_obj_t cur, hwloc_obj_t obj,
1098  			        const char *reason)
1099  {
1100    hwloc_obj_t child, next_child = NULL, tmp;
1101    hwloc_obj_t *cur_children = &cur->first_child;
1102    hwloc_obj_t *obj_children = &obj->first_child;
1103    hwloc_obj_t *putp = NULL; &bsol;* OBJ position isn't found yet */
1104    assert(!hwloc__obj_type_is_memory(obj->type));
1105    for (child = cur->first_child, child ? next_child = child->next_sibling : NULL;
1106         child;
1107         child = next_child, child ? next_child = child->next_sibling : NULL) {
1108      int res = hwloc_obj_cmp_sets(obj, child);
1109      int setres = res;
1110      if (res == HWLOC_OBJ_EQUAL) {
1111        hwloc_obj_t merged = hwloc__insert_try_merge_group(topology, child, obj);
1112        if (merged)
1113  	return merged;
1114        res = hwloc_type_cmp(obj, child);
1115      }
1116      switch (res) {
1117        case HWLOC_OBJ_EQUAL:
1118  	merge_insert_equal(obj, child);
1119  	return child;
1120        case HWLOC_OBJ_INCLUDED:
1121  	return hwloc___insert_object_by_cpuset(topology, child, obj, reason);
1122        case HWLOC_OBJ_INTERSECTS:
1123          report_insert_error(obj, child, "intersection without inclusion", reason);
1124  	goto putback;
1125        case HWLOC_OBJ_DIFFERENT:
1126  	if (!putp && hwloc__object_cpusets_compare_first(obj, child) < 0)
1127  	  putp = cur_children;
1128  	cur_children = &child->next_sibling;
1129  	break;
1130        case HWLOC_OBJ_CONTAINS:
1131  	*cur_children = child->next_sibling;
1132  	child->next_sibling = NULL;
1133  	*obj_children = child;
1134  	obj_children = &child->next_sibling;
1135  	child->parent = obj;
1136  	if (setres == HWLOC_OBJ_EQUAL) {
1137  	  obj->memory_first_child = child->memory_first_child;
1138  	  child->memory_first_child = NULL;
1139  	  for(tmp=obj->memory_first_child; tmp; tmp = tmp->next_sibling)
1140  	    tmp->parent = obj;
1141  	}
1142  	break;
1143      }
1144    }
1145    assert(!*obj_children);
1146    assert(!*cur_children);
1147    if (!putp)
1148      putp = cur_children;
1149    obj->next_sibling = *putp;
1150    *putp = obj;
1151    obj->parent = cur;
1152    topology->modified = 1;
1153    return obj;
1154   putback:
1155    if (putp)
1156      cur_children = putp; &bsol;* No need to try to insert before where OBJ was supposed to go */
1157    else
1158      cur_children = &cur->first_child; &bsol;* Start from the beginning */
1159    while ((child = obj->first_child) != NULL) {
1160      obj->first_child = child->next_sibling;
1161      while (*cur_children && hwloc__object_cpusets_compare_first(*cur_children, child) < 0)
1162        cur_children = &(*cur_children)->next_sibling;
1163      child->next_sibling = *cur_children;
1164      *cur_children = child;
1165      child->parent = cur;
1166    }
1167    return NULL;
1168  }
1169  static struct hwloc_obj *
1170  hwloc__find_obj_covering_memory_cpuset(struct hwloc_topology *topology, hwloc_obj_t parent, hwloc_bitmap_t cpuset)
1171  {
1172    hwloc_obj_t child = hwloc_get_child_covering_cpuset(topology, cpuset, parent);
1173    if (!child)
1174      return parent;
1175    if (child && hwloc_bitmap_isequal(child->cpuset, cpuset))
1176      return child;
1177    return hwloc__find_obj_covering_memory_cpuset(topology, child, cpuset);
1178  }
1179  static struct hwloc_obj *
1180  hwloc__find_insert_memory_parent(struct hwloc_topology *topology, hwloc_obj_t obj,
1181                                   const char *reason)
1182  {
1183    hwloc_obj_t parent, group, result;
1184    if (hwloc_bitmap_iszero(obj->cpuset)) {
1185      parent = topology->levels[0][0];
1186    } else {
1187      parent = hwloc__find_obj_covering_memory_cpuset(topology, topology->levels[0][0], obj->cpuset);
1188      if (!parent) {
1189        parent = hwloc_get_root_obj(topology);
1190      }
1191      if (parent->type == HWLOC_OBJ_PU) {
1192        parent = parent->parent;
1193        assert(parent);
1194      }
1195      if (parent != topology->levels[0][0] && hwloc_bitmap_isequal(parent->cpuset, obj->cpuset))
1196        return parent;
1197    }
1198    if (!hwloc_filter_check_keep_object_type(topology, HWLOC_OBJ_GROUP))
1199      return parent;
1200    group = hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
1201    if (!group)
1202      return parent;
1203    group->attr->group.kind = HWLOC_GROUP_KIND_MEMORY;
1204    group->cpuset = hwloc_bitmap_dup(obj->cpuset);
1205    group->complete_cpuset = hwloc_bitmap_dup(obj->complete_cpuset);
1206    if (!group->cpuset != !obj->cpuset
1207        || !group->complete_cpuset != !obj->complete_cpuset) {
1208      hwloc_free_unlinked_object(group);
1209      return parent;
1210    }
1211    result = hwloc__insert_object_by_cpuset(topology, parent, group, reason);
1212    if (!result) {
1213      return parent;
1214    }
1215    assert(result == group);
1216    return group;
1217  }
1218  static hwloc_obj_t
1219  hwloc___attach_memory_object_by_nodeset(struct hwloc_topology *topology, hwloc_obj_t parent,
1220  					hwloc_obj_t obj, const char *reason)
1221  {
1222    hwloc_obj_t *curp = &parent->memory_first_child;
1223    unsigned first = hwloc_bitmap_first(obj->nodeset);
1224    while (*curp) {
1225      hwloc_obj_t cur = *curp;
1226      unsigned curfirst = hwloc_bitmap_first(cur->nodeset);
1227      if (first < curfirst) {
1228        obj->next_sibling = cur;
1229        *curp = obj;
1230        obj->memory_first_child = NULL;
1231        obj->parent = parent;
1232        topology->modified = 1;
1233        return obj;
1234      }
1235      if (first == curfirst) {
1236        if (obj->type == HWLOC_OBJ_NUMANODE) {
1237  	if (cur->type == HWLOC_OBJ_NUMANODE) {
1238            report_insert_error(obj, cur, "NUMAnodes with identical nodesets", reason);
1239  	  return NULL;
1240  	}
1241  	assert(cur->type == HWLOC_OBJ_MEMCACHE);
1242  	return hwloc___attach_memory_object_by_nodeset(topology, cur, obj, reason);
1243        } else {
1244  	assert(obj->type == HWLOC_OBJ_MEMCACHE);
1245  	if (cur->type == HWLOC_OBJ_MEMCACHE) {
1246  	  if (cur->attr->cache.depth == obj->attr->cache.depth)
1247  	    return NULL;
1248  	  if (cur->attr->cache.depth > obj->attr->cache.depth)
1249  	    return hwloc___attach_memory_object_by_nodeset(topology, cur, obj, reason);
1250  	}
1251  	obj->next_sibling = cur->next_sibling;
1252  	cur->next_sibling = NULL;
1253  	obj->memory_first_child = cur;
1254  	cur->parent = obj;
1255  	*curp = obj;
1256  	obj->parent = parent;
1257  	topology->modified = 1;
1258  	return obj;
1259        }
1260      }
1261      curp = &cur->next_sibling;
1262    }
1263    obj->next_sibling = NULL;
1264    *curp = obj;
1265    obj->memory_first_child = NULL;
1266    obj->parent = parent;
1267    topology->modified = 1;
1268    return obj;
1269  }
1270  struct hwloc_obj *
1271  hwloc__attach_memory_object(struct hwloc_topology *topology, hwloc_obj_t parent,
1272  			    hwloc_obj_t obj, const char *reason)
1273  {
1274    hwloc_obj_t result;
1275    assert(parent);
1276    assert(hwloc__obj_type_is_normal(parent->type));
1277    if (!obj->nodeset || hwloc_bitmap_iszero(obj->nodeset))
1278      return NULL;
1279    if (!obj->complete_nodeset) {
1280      obj->complete_nodeset = hwloc_bitmap_dup(obj->nodeset);
1281    } else if (!hwloc_bitmap_isincluded(obj->nodeset, obj->complete_nodeset)) {
1282      return NULL;
1283    }
1284    assert(hwloc_bitmap_weight(obj->nodeset) == 1);
1285  #if 0
1286    hwloc_bitmap_copy(obj->cpuset, parent->cpuset);
1287    hwloc_bitmap_copy(obj->complete_cpuset, parent->complete_cpuset);
1288  #endif
1289    result = hwloc___attach_memory_object_by_nodeset(topology, parent, obj, reason);
1290    if (result == obj) {
1291      if (obj->type == HWLOC_OBJ_NUMANODE) {
1292        hwloc_bitmap_set(topology->levels[0][0]->nodeset, obj->os_index);
1293        hwloc_bitmap_set(topology->levels[0][0]->complete_nodeset, obj->os_index);
1294      }
1295    }
1296    if (result != obj) {
1297      hwloc_free_unlinked_object(obj);
1298    }
1299    return result;
1300  }
1301  struct hwloc_obj *
1302  hwloc__insert_object_by_cpuset(struct hwloc_topology *topology, hwloc_obj_t root,
1303  			       hwloc_obj_t obj, const char *reason)
1304  {
1305    struct hwloc_obj *result;
1306  #ifdef HWLOC_DEBUG
1307    assert(!hwloc__obj_type_is_special(obj->type));
1308    assert(obj->cpuset || obj->complete_cpuset || obj->nodeset || obj->complete_nodeset);
1309  #endif
1310    if (hwloc__obj_type_is_memory(obj->type)) {
1311      if (!root) {
1312        root = hwloc__find_insert_memory_parent(topology, obj, reason);
1313        if (!root) {
1314  	hwloc_free_unlinked_object(obj);
1315  	return NULL;
1316        }
1317      }
1318      return hwloc__attach_memory_object(topology, root, obj, reason);
1319    }
1320    if (!root)
1321      root = topology->levels[0][0];
1322    result = hwloc___insert_object_by_cpuset(topology, root, obj, reason);
1323    if (result && result->type == HWLOC_OBJ_PU) {
1324        if (hwloc_bitmap_isset(result->cpuset, result->os_index))
1325  	hwloc_bitmap_set(topology->levels[0][0]->cpuset, result->os_index);
1326        hwloc_bitmap_set(topology->levels[0][0]->complete_cpuset, result->os_index);
1327    }
1328    if (result != obj) {
1329      hwloc_free_unlinked_object(obj);
1330    }
1331    return result;
1332  }
1333  void
1334  hwloc_insert_object_by_parent(struct hwloc_topology *topology, hwloc_obj_t parent, hwloc_obj_t obj)
1335  {
1336    hwloc_obj_t *current;
1337    if (obj->type == HWLOC_OBJ_MISC) {
1338      for (current = &parent->misc_first_child; *current; current = &(*current)->next_sibling);
1339    } else if (hwloc__obj_type_is_io(obj->type)) {
1340      for (current = &parent->io_first_child; *current; current = &(*current)->next_sibling);
1341    } else if (hwloc__obj_type_is_memory(obj->type)) {
1342      for (current = &parent->memory_first_child; *current; current = &(*current)->next_sibling);
1343      if (obj->type == HWLOC_OBJ_NUMANODE) {
1344        if (hwloc_bitmap_isset(obj->nodeset, obj->os_index))
1345  	hwloc_bitmap_set(topology->levels[0][0]->nodeset, obj->os_index);
1346        hwloc_bitmap_set(topology->levels[0][0]->complete_nodeset, obj->os_index);
1347      }
1348    } else {
1349      for (current = &parent->first_child; *current; current = &(*current)->next_sibling);
1350      if (obj->type == HWLOC_OBJ_PU) {
1351        if (hwloc_bitmap_isset(obj->cpuset, obj->os_index))
1352  	hwloc_bitmap_set(topology->levels[0][0]->cpuset, obj->os_index);
1353        hwloc_bitmap_set(topology->levels[0][0]->complete_cpuset, obj->os_index);
1354      }
1355    }
1356    *current = obj;
1357    obj->parent = parent;
1358    obj->next_sibling = NULL;
1359    topology->modified = 1;
1360  }
1361  hwloc_obj_t
1362  hwloc_alloc_setup_object(hwloc_topology_t topology,
1363  			 hwloc_obj_type_t type, unsigned os_index)
1364  {
1365    struct hwloc_obj *obj = hwloc_tma_malloc(topology->tma, sizeof(*obj));
1366    if (!obj)
1367      return NULL;
1368    memset(obj, 0, sizeof(*obj));
1369    obj->type = type;
1370    obj->os_index = os_index;
1371    obj->gp_index = topology->next_gp_index++;
1372    obj->attr = hwloc_tma_malloc(topology->tma, sizeof(*obj->attr));
1373    if (!obj->attr) {
1374      assert(!topology->tma || !topology->tma->dontfree); &bsol;* this tma cannot fail to allocate */
1375      free(obj);
1376      return NULL;
1377    }
1378    memset(obj->attr, 0, sizeof(*obj->attr));
1379    return obj;
1380  }
1381  hwloc_obj_t
1382  hwloc_topology_alloc_group_object(struct hwloc_topology *topology)
1383  {
1384    if (!topology->is_loaded) {
1385      errno = EINVAL;
1386      return NULL;
1387    }
1388    if (topology->adopted_shmem_addr) {
1389      errno = EPERM;
1390      return NULL;
1391    }
1392    return hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
1393  }
1394  static void hwloc_propagate_symmetric_subtree(hwloc_topology_t topology, hwloc_obj_t root);
1395  static void propagate_total_memory(hwloc_obj_t obj);
1396  static void hwloc_set_group_depth(hwloc_topology_t topology);
1397  static void hwloc_connect_children(hwloc_obj_t parent);
1398  static int hwloc_connect_levels(hwloc_topology_t topology);
1399  static int hwloc_connect_special_levels(hwloc_topology_t topology);
1400  hwloc_obj_t
1401  hwloc_topology_insert_group_object(struct hwloc_topology *topology, hwloc_obj_t obj)
1402  {
1403    hwloc_obj_t res, root;
1404    int cmp;
1405    if (!topology->is_loaded) {
1406      hwloc_free_unlinked_object(obj);
1407      errno = EINVAL;
1408      return NULL;
1409    }
1410    if (topology->adopted_shmem_addr) {
1411      errno = EPERM;
1412      return NULL;
1413    }
1414    if (topology->type_filter[HWLOC_OBJ_GROUP] == HWLOC_TYPE_FILTER_KEEP_NONE) {
1415      hwloc_free_unlinked_object(obj);
1416      errno = EINVAL;
1417      return NULL;
1418    }
1419    root = hwloc_get_root_obj(topology);
1420    if (obj->cpuset)
1421      hwloc_bitmap_and(obj->cpuset, obj->cpuset, root->cpuset);
1422    if (obj->complete_cpuset)
1423      hwloc_bitmap_and(obj->complete_cpuset, obj->complete_cpuset, root->complete_cpuset);
1424    if (obj->nodeset)
1425      hwloc_bitmap_and(obj->nodeset, obj->nodeset, root->nodeset);
1426    if (obj->complete_nodeset)
1427      hwloc_bitmap_and(obj->complete_nodeset, obj->complete_nodeset, root->complete_nodeset);
1428    if ((!obj->cpuset || hwloc_bitmap_iszero(obj->cpuset))
1429        && (!obj->complete_cpuset || hwloc_bitmap_iszero(obj->complete_cpuset))) {
1430      hwloc_const_bitmap_t nodeset = obj->nodeset ? obj->nodeset : obj->complete_nodeset;
1431      hwloc_obj_t numa;
1432      if ((!obj->nodeset || hwloc_bitmap_iszero(obj->nodeset))
1433  	&& (!obj->complete_nodeset || hwloc_bitmap_iszero(obj->complete_nodeset))) {
1434        hwloc_free_unlinked_object(obj);
1435        errno = EINVAL;
1436        return NULL;
1437      }
1438      if (!obj->cpuset) {
1439        obj->cpuset = hwloc_bitmap_alloc();
1440        if (!obj->cpuset) {
1441  	hwloc_free_unlinked_object(obj);
1442  	return NULL;
1443        }
1444      }
1445      numa = NULL;
1446      while ((numa = hwloc_get_next_obj_by_type(topology, HWLOC_OBJ_NUMANODE, numa)) != NULL)
1447        if (hwloc_bitmap_isset(nodeset, numa->os_index))
1448  	hwloc_bitmap_or(obj->cpuset, obj->cpuset, numa->cpuset);
1449    }
1450    cmp = hwloc_obj_cmp_sets(obj, root);
1451    if (cmp == HWLOC_OBJ_INCLUDED) {
1452      res = hwloc__insert_object_by_cpuset(topology, NULL, obj, NULL &bsol;* do not show errors on stdout */);
1453    } else {
1454      res = root;
1455    }
1456    if (!res)
1457      return NULL;
1458    if (res != obj && res->type != HWLOC_OBJ_GROUP)
1459      return res;
1460    hwloc_obj_add_children_sets(res);
1461    if (hwloc_topology_reconnect(topology, 0) < 0)
1462      return NULL;
1463    hwloc_propagate_symmetric_subtree(topology, topology->levels[0][0]);
1464    hwloc_set_group_depth(topology);
1465  #ifndef HWLOC_DEBUG
1466    if (getenv("HWLOC_DEBUG_CHECK"))
1467  #endif
1468      hwloc_topology_check(topology);
1469    return res;
1470  }
1471  hwloc_obj_t
1472  hwloc_topology_insert_misc_object(struct hwloc_topology *topology, hwloc_obj_t parent, const char *name)
1473  {
1474    hwloc_obj_t obj;
1475    if (topology->type_filter[HWLOC_OBJ_MISC] == HWLOC_TYPE_FILTER_KEEP_NONE) {
1476      errno = EINVAL;
1477      return NULL;
1478    }
1479    if (!topology->is_loaded) {
1480      errno = EINVAL;
1481      return NULL;
1482    }
1483    if (topology->adopted_shmem_addr) {
1484      errno = EPERM;
1485      return NULL;
1486    }
1487    obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_MISC, HWLOC_UNKNOWN_INDEX);
1488    if (name)
1489      obj->name = strdup(name);
1490    hwloc_insert_object_by_parent(topology, parent, obj);
1491    hwloc_topology_reconnect(topology, 0);
1492  #ifndef HWLOC_DEBUG
1493    if (getenv("HWLOC_DEBUG_CHECK"))
1494  #endif
1495      hwloc_topology_check(topology);
1496    return obj;
1497  }
1498  static hwloc_obj_t
1499  hwloc_get_highest_obj_covering_complete_cpuset (hwloc_topology_t topology, hwloc_const_cpuset_t set)
1500  {
1501    hwloc_obj_t current = hwloc_get_root_obj(topology);
1502    hwloc_obj_t child;
1503    if (hwloc_bitmap_isequal(set, current->complete_cpuset))
1504      return current;
1505   recurse:
1506    for_each_child(child, current) {
1507      if (hwloc_bitmap_isequal(set, child->complete_cpuset))
1508        return child;
1509      if (!hwloc_bitmap_iszero(child->complete_cpuset) && hwloc_bitmap_isincluded(set, child->complete_cpuset))
1510        break;
1511    }
1512    if (child) {
1513      current = child;
1514      goto recurse;
1515    }
1516    return current;
1517  }
1518  hwloc_obj_t
1519  hwloc_find_insert_io_parent_by_complete_cpuset(struct hwloc_topology *topology, hwloc_cpuset_t cpuset)
1520  {
1521    hwloc_obj_t group_obj, largeparent, parent;
1522    hwloc_bitmap_and(cpuset, cpuset, hwloc_topology_get_complete_cpuset(topology));
1523    if (hwloc_bitmap_iszero(cpuset))
1524      return NULL;
1525    largeparent = hwloc_get_highest_obj_covering_complete_cpuset(topology, cpuset);
1526    if (hwloc_bitmap_isequal(largeparent->complete_cpuset, cpuset)
1527        || !hwloc_filter_check_keep_object_type(topology, HWLOC_OBJ_GROUP))
1528      return largeparent;
1529    group_obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
1530    if (!group_obj)
1531      return largeparent;
1532    group_obj->complete_cpuset = hwloc_bitmap_dup(cpuset);
1533    hwloc_bitmap_and(cpuset, cpuset, hwloc_topology_get_topology_cpuset(topology));
1534    group_obj->cpuset = hwloc_bitmap_dup(cpuset);
1535    group_obj->attr->group.kind = HWLOC_GROUP_KIND_IO;
1536    parent = hwloc__insert_object_by_cpuset(topology, largeparent, group_obj, "topology:io_parent");
1537    if (!parent)
1538      return largeparent;
1539    assert(parent == group_obj);
1540    hwloc_obj_add_children_sets(group_obj);
1541    return parent;
1542  }
1543  static int hwloc_memory_page_type_compare(const void *_a, const void *_b)
1544  {
1545    const struct hwloc_memory_page_type_s *a = _a;
1546    const struct hwloc_memory_page_type_s *b = _b;
1547    if (!b->size)
1548      return -1;
1549    if (b->size == a->size)
1550      return 0;
1551    return a->size < b->size ? -1 : 1;
1552  }
1553  static void
1554  propagate_total_memory(hwloc_obj_t obj)
1555  {
1556    hwloc_obj_t child;
1557    unsigned i;
1558    obj->total_memory = 0;
1559    for_each_child(child, obj) {
1560      propagate_total_memory(child);
1561      obj->total_memory += child->total_memory;
1562    }
1563    for_each_memory_child(child, obj) {
1564      propagate_total_memory(child);
1565      obj->total_memory += child->total_memory;
1566    }
1567    if (obj->type == HWLOC_OBJ_NUMANODE) {
1568      obj->total_memory += obj->attr->numanode.local_memory;
1569      if (obj->attr->numanode.page_types_len) {
1570        qsort(obj->attr->numanode.page_types, obj->attr->numanode.page_types_len, sizeof(*obj->attr->numanode.page_types), hwloc_memory_page_type_compare);
1571        for(i=obj->attr->numanode.page_types_len; i>=1; i--)
1572  	if (obj->attr->numanode.page_types[i-1].size)
1573  	  break;
1574        obj->attr->numanode.page_types_len = i;
1575      }
1576    }
1577  }
1578  static void
1579  fixup_sets(hwloc_obj_t obj)
1580  {
1581    int in_memory_list;
1582    hwloc_obj_t child;
1583    child = obj->first_child;
1584    in_memory_list = 0;
1585   iterate:
1586    while (child) {
1587      hwloc_bitmap_and(child->cpuset, child->cpuset, obj->cpuset);
1588      hwloc_bitmap_and(child->nodeset, child->nodeset, obj->nodeset);
1589      if (child->complete_cpuset) {
1590        hwloc_bitmap_and(child->complete_cpuset, child->complete_cpuset, obj->complete_cpuset);
1591      } else {
1592        child->complete_cpuset = hwloc_bitmap_dup(child->cpuset);
1593      }
1594      if (child->complete_nodeset) {
1595        hwloc_bitmap_and(child->complete_nodeset, child->complete_nodeset, obj->complete_nodeset);
1596      } else {
1597        child->complete_nodeset = hwloc_bitmap_dup(child->nodeset);
1598      }
1599      if (hwloc_obj_type_is_memory(child->type)) {
1600        hwloc_bitmap_copy(child->cpuset, obj->cpuset);
1601        hwloc_bitmap_copy(child->complete_cpuset, obj->complete_cpuset);
1602      }
1603      fixup_sets(child);
1604      child = child->next_sibling;
1605    }
1606    if (!in_memory_list && obj->memory_first_child) {
1607      child = obj->memory_first_child;
1608      in_memory_list = 1;
1609      goto iterate;
1610    }
1611  }
1612  int
1613  hwloc_obj_add_other_obj_sets(hwloc_obj_t dst, hwloc_obj_t src)
1614  {
1615  #define ADD_OTHER_OBJ_SET(_dst, _src, _set)			\
1616    if ((_src)->_set) {						\
1617      if (!(_dst)->_set)						\
1618        (_dst)->_set = hwloc_bitmap_alloc();			\
1619      hwloc_bitmap_or((_dst)->_set, (_dst)->_set, (_src)->_set);	\
1620    }
1621    ADD_OTHER_OBJ_SET(dst, src, cpuset);
1622    ADD_OTHER_OBJ_SET(dst, src, complete_cpuset);
1623    ADD_OTHER_OBJ_SET(dst, src, nodeset);
1624    ADD_OTHER_OBJ_SET(dst, src, complete_nodeset);
1625    return 0;
1626  }
1627  int
1628  hwloc_obj_add_children_sets(hwloc_obj_t obj)
1629  {
1630    hwloc_obj_t child;
1631    for_each_child(child, obj) {
1632      hwloc_obj_add_other_obj_sets(obj, child);
1633    }
1634    return 0;
1635  }
1636  static void
1637  propagate_nodeset(hwloc_obj_t obj)
1638  {
1639    hwloc_obj_t child;
1640    if (!obj->nodeset)
1641      obj->nodeset = hwloc_bitmap_alloc();
1642    if (obj->parent)
1643      hwloc_bitmap_copy(obj->nodeset, obj->parent->nodeset);
1644    else
1645      hwloc_bitmap_zero(obj->nodeset);
1646    if (!obj->complete_nodeset)
1647      obj->complete_nodeset = hwloc_bitmap_dup(obj->nodeset);
1648    else
1649      hwloc_bitmap_or(obj->complete_nodeset, obj->complete_nodeset, obj->nodeset);
1650    for_each_memory_child(child, obj) {
1651      hwloc_bitmap_or(obj->nodeset, obj->nodeset, child->nodeset);
1652      hwloc_bitmap_or(obj->complete_nodeset, obj->complete_nodeset, child->complete_nodeset);
1653    }
1654    for_each_child(child, obj) {
1655      propagate_nodeset(child);
1656    }
1657    for_each_child(child, obj) {
1658      hwloc_bitmap_or(obj->nodeset, obj->nodeset, child->nodeset);
1659      hwloc_bitmap_or(obj->complete_nodeset, obj->complete_nodeset, child->complete_nodeset);
1660    }
1661  }
1662  static void
1663  remove_unused_sets(hwloc_topology_t topology, hwloc_obj_t obj)
1664  {
1665    hwloc_obj_t child;
1666    hwloc_bitmap_and(obj->cpuset, obj->cpuset, topology->allowed_cpuset);
1667    hwloc_bitmap_and(obj->nodeset, obj->nodeset, topology->allowed_nodeset);
1668    for_each_child(child, obj)
1669      remove_unused_sets(topology, child);
1670    for_each_memory_child(child, obj)
1671      remove_unused_sets(topology, child);
1672  }
1673  static void
1674  hwloc__filter_bridges(hwloc_topology_t topology, hwloc_obj_t root, unsigned depth)
1675  {
1676    hwloc_obj_t child, *pchild;
1677    for_each_io_child_safe(child, root, pchild) {
1678      enum hwloc_type_filter_e filter = topology->type_filter[child->type];
1679      hwloc__filter_bridges(topology, child, depth+1);
1680      child->attr->bridge.depth = depth;
1681      if (filter == HWLOC_TYPE_FILTER_KEEP_IMPORTANT
1682  	&& !child->io_first_child
1683          && (child->type == HWLOC_OBJ_BRIDGE
1684              || (child->type == HWLOC_OBJ_PCI_DEVICE && (child->attr->pcidev.class_id >> 8) == 0x06
1685                  && (!child->subtype || strcmp(child->subtype, "NVSwitch"))))) {
1686        unlink_and_free_single_object(pchild);
1687        topology->modified = 1;
1688      }
1689    }
1690  }
1691  static void
1692  hwloc_filter_bridges(hwloc_topology_t topology, hwloc_obj_t parent)
1693  {
1694    hwloc_obj_t child = parent->first_child;
1695    while (child) {
1696      hwloc_filter_bridges(topology, child);
1697      child = child->next_sibling;
1698    }
1699    hwloc__filter_bridges(topology, parent, 0);
1700  }
1701  void
1702  hwloc__reorder_children(hwloc_obj_t parent)
1703  {
1704    hwloc_obj_t *prev, child, children = parent->first_child;
1705    parent->first_child = NULL;
1706    while (children) {
1707      child = children;
1708      children = child->next_sibling;
1709      prev = &parent->first_child;
1710      while (*prev && hwloc__object_cpusets_compare_first(child, *prev) > 0)
1711        prev = &((*prev)->next_sibling);
1712      child->next_sibling = *prev;
1713      *prev = child;
1714    }
1715  }
1716  static void
1717  remove_empty(hwloc_topology_t topology, hwloc_obj_t *pobj)
1718  {
1719    hwloc_obj_t obj = *pobj, child, *pchild;
1720    for_each_child_safe(child, obj, pchild)
1721      remove_empty(topology, pchild);
1722    for_each_memory_child_safe(child, obj, pchild)
1723      remove_empty(topology, pchild);
1724    if (obj->first_child &bsol;* only remove if all children were removed above, so that we don't remove parents of NUMAnode */
1725        || obj->memory_first_child &bsol;* only remove if no memory attached there */
1726        || obj->io_first_child &bsol;* only remove if no I/O is attached there */)
1727      return;
1728    if (hwloc__obj_type_is_normal(obj->type)) {
1729      if (!hwloc_bitmap_iszero(obj->cpuset))
1730        return;
1731    } else {
1732      assert(hwloc__obj_type_is_memory(obj->type));
1733      if (!hwloc_bitmap_iszero(obj->nodeset))
1734        return;
1735    }
1736    hwloc_debug("%s", "\nRemoving empty object ");
1737    hwloc_debug_print_object(0, obj);
1738    unlink_and_free_single_object(pobj);
1739    topology->modified = 1;
1740  }
1741  static void
1742  hwloc_reset_normal_type_depths(hwloc_topology_t topology)
1743  {
1744    unsigned i;
1745    for (i=HWLOC_OBJ_TYPE_MIN; i<=HWLOC_OBJ_GROUP; i++)
1746      topology->type_depth[i] = HWLOC_TYPE_DEPTH_UNKNOWN;
1747    topology->type_depth[HWLOC_OBJ_DIE] = HWLOC_TYPE_DEPTH_UNKNOWN;
1748  }
1749  static int
1750  hwloc_dont_merge_group_level(hwloc_topology_t topology, unsigned i)
1751  {
1752    unsigned j;
1753    for(j=0; j<topology->level_nbobjects[i]; j++)
1754      if (topology->levels[i][j]->attr->group.dont_merge)
1755        return 1;
1756    return 0;
1757  }
1758  static int
1759  hwloc_compare_levels_structure(hwloc_topology_t topology, unsigned i)
1760  {
1761    int checkmemory = (topology->levels[i][0]->type == HWLOC_OBJ_PU);
1762    unsigned j;
1763    if (topology->level_nbobjects[i-1] != topology->level_nbobjects[i])
1764      return -1;
1765    for(j=0; j<topology->level_nbobjects[i]; j++) {
1766      if (topology->levels[i-1][j] != topology->levels[i][j]->parent)
1767        return -1;
1768      if (topology->levels[i-1][j]->arity != 1)
1769        return -1;
1770      if (checkmemory && topology->levels[i-1][j]->memory_arity)
1771        return -1;
1772    }
1773    return 0;
1774  }
1775  static int
1776  hwloc_filter_levels_keep_structure(hwloc_topology_t topology)
1777  {
1778    unsigned i, j;
1779    int res = 0;
1780    if (topology->modified) {
1781      hwloc_connect_children(topology->levels[0][0]);
1782      if (hwloc_connect_levels(topology) < 0)
1783        return -1;
1784    }
1785    for(i=topology->nb_levels-1; i>0; i--) {
1786      int replacechild = 0, replaceparent = 0;
1787      hwloc_obj_t obj1 = topology->levels[i-1][0];
1788      hwloc_obj_t obj2 = topology->levels[i][0];
1789      hwloc_obj_type_t type1 = obj1->type;
1790      hwloc_obj_type_t type2 = obj2->type;
1791      if (topology->type_filter[type1] == HWLOC_TYPE_FILTER_KEEP_STRUCTURE) {
1792        replaceparent = 1;
1793        if (type1 == HWLOC_OBJ_GROUP && hwloc_dont_merge_group_level(topology, i-1))
1794  	replaceparent = 0;
1795      }
1796      if (topology->type_filter[type2] == HWLOC_TYPE_FILTER_KEEP_STRUCTURE) {
1797        replacechild = 1;
1798        if (type1 == HWLOC_OBJ_GROUP && hwloc_dont_merge_group_level(topology, i))
1799  	replacechild = 0;
1800      }
1801      if (!replacechild && !replaceparent)
1802        continue;
1803      if (replaceparent && replacechild) {
1804        if (obj_type_priority[type1] >= obj_type_priority[type2])
1805  	replaceparent = 0;
1806        else
1807  	replacechild = 0;
1808      }
1809      if (hwloc_compare_levels_structure(topology, i) < 0)
1810        continue;
1811      hwloc_debug("may merge levels #%u=%s and #%u=%s\n",
1812  		i-1, hwloc_obj_type_string(type1), i, hwloc_obj_type_string(type2));
1813      for(j=0; j<topology->level_nbobjects[i]; j++) {
1814        hwloc_obj_t parent = topology->levels[i-1][j];
1815        hwloc_obj_t child = topology->levels[i][j];
1816        unsigned k;
1817        if (replacechild) {
1818  	parent->first_child = child->first_child;
1819  	parent->last_child = child->last_child;
1820  	parent->arity = child->arity;
1821  	free(parent->children);
1822  	parent->children = child->children;
1823  	child->children = NULL;
1824  	for(k=0; k<parent->arity; k++)
1825  	  parent->children[k]->parent = parent;
1826  	if (child->memory_first_child) {
1827  	  append_siblings_list(&parent->memory_first_child, child->memory_first_child, parent);
1828  	  parent->memory_arity += child->memory_arity;
1829  	}
1830  	if (child->io_first_child) {
1831  	  append_siblings_list(&parent->io_first_child, child->io_first_child, parent);
1832  	  parent->io_arity += child->io_arity;
1833  	}
1834  	if (child->misc_first_child) {
1835  	  append_siblings_list(&parent->misc_first_child, child->misc_first_child, parent);
1836  	  parent->misc_arity += child->misc_arity;
1837  	}
1838  	hwloc_free_unlinked_object(child);
1839        } else {
1840  	if (parent->parent) {
1841  	  parent->parent->children[parent->sibling_rank] = child;
1842  	  child->sibling_rank = parent->sibling_rank;
1843  	  if (!parent->sibling_rank) {
1844  	    parent->parent->first_child = child;
1845  	  } else {
1846  	    child->prev_sibling = parent->parent->children[parent->sibling_rank-1];
1847  	    child->prev_sibling->next_sibling = child;
1848  	  }
1849  	  if (parent->sibling_rank == parent->parent->arity-1) {
1850  	    parent->parent->last_child = child;
1851  	  } else {
1852  	    child->next_sibling = parent->parent->children[parent->sibling_rank+1];
1853  	    child->next_sibling->prev_sibling = child;
1854  	  }
1855  	  child->parent = parent->parent;
1856  	} else {
1857  	  topology->levels[0][0] = child;
1858  	  child->parent = NULL;
1859  	}
1860  	if (parent->memory_first_child) {
1861  	  prepend_siblings_list(&child->memory_first_child, parent->memory_first_child, child);
1862  	  child->memory_arity += parent->memory_arity;
1863  	}
1864  	if (parent->io_first_child) {
1865  	  prepend_siblings_list(&child->io_first_child, parent->io_first_child, child);
1866  	  child->io_arity += parent->io_arity;
1867  	}
1868  	if (parent->misc_first_child) {
1869  	  prepend_siblings_list(&child->misc_first_child, parent->misc_first_child, child);
1870  	  child->misc_arity += parent->misc_arity;
1871  	}
1872  	hwloc_free_unlinked_object(parent);
1873        }
1874      }
1875      if (replaceparent && i>1) {
1876        for(j=0; j<topology->level_nbobjects[i]; j++) {
1877  	hwloc_obj_t child = topology->levels[i][j];
1878  	unsigned rank = child->sibling_rank;
1879  	child->prev_sibling = rank > 0 ? child->parent->children[rank-1] : NULL;
1880  	child->next_sibling = rank < child->parent->arity-1 ? child->parent->children[rank+1] : NULL;
1881        }
1882      }
1883      if (replaceparent) {
1884        free(topology->levels[i-1]);
1885        memmove(&topology->levels[i-1],
1886  	      &topology->levels[i],
1887  	      (topology->nb_levels-i)*sizeof(topology->levels[i]));
1888        memmove(&topology->level_nbobjects[i-1],
1889  	      &topology->level_nbobjects[i],
1890  	      (topology->nb_levels-i)*sizeof(topology->level_nbobjects[i]));
1891        hwloc_debug("removed parent level %s at depth %u\n",
1892  		  hwloc_obj_type_string(type1), i-1);
1893      } else {
1894        free(topology->levels[i]);
1895        memmove(&topology->levels[i],
1896  	      &topology->levels[i+1],
1897  	      (topology->nb_levels-1-i)*sizeof(topology->levels[i]));
1898        memmove(&topology->level_nbobjects[i],
1899  	      &topology->level_nbobjects[i+1],
1900  	      (topology->nb_levels-1-i)*sizeof(topology->level_nbobjects[i]));
1901        hwloc_debug("removed child level %s at depth %u\n",
1902  		  hwloc_obj_type_string(type2), i);
1903      }
1904      topology->level_nbobjects[topology->nb_levels-1] = 0;
1905      topology->levels[topology->nb_levels-1] = NULL;
1906      topology->nb_levels--;
1907      res++;
1908    }
1909    if (res > 0) {
1910      hwloc_reset_normal_type_depths(topology);
1911      for(i=0; i<topology->nb_levels; i++) {
1912        hwloc_obj_type_t type = topology->levels[i][0]->type;
1913        for(j=0; j<topology->level_nbobjects[i]; j++)
1914  	topology->levels[i][j]->depth = (int)i;
1915        if (topology->type_depth[type] == HWLOC_TYPE_DEPTH_UNKNOWN)
1916  	topology->type_depth[type] = (int)i;
1917        else
1918  	topology->type_depth[type] = HWLOC_TYPE_DEPTH_MULTIPLE;
1919      }
1920    }
1921    if (res > 0 || topology-> modified) {
1922      if (hwloc_connect_special_levels(topology) < 0)
1923        return -1;
1924      topology->modified = 0;
1925    }
1926    return 0;
1927  }
1928  static void
1929  hwloc_propagate_symmetric_subtree(hwloc_topology_t topology, hwloc_obj_t root)
1930  {
1931    hwloc_obj_t child;
1932    unsigned arity = root->arity;
1933    hwloc_obj_t *array;
1934    int ok;
1935    root->symmetric_subtree = 0;
1936    if (!arity)
1937      goto good;
1938    ok = 1;
1939    for_each_child(child, root) {
1940      hwloc_propagate_symmetric_subtree(topology, child);
1941      if (!child->symmetric_subtree)
1942        ok = 0;
1943    }
1944    if (!ok)
1945      return;
1946    if (arity == 1)
1947      goto good;
1948    array = malloc(arity * sizeof(*array));
1949    if (!array)
1950      return;
1951    memcpy(array, root->children, arity * sizeof(*array));
1952    while (1) {
1953      unsigned i;
1954      for(i=1; i<arity; i++)
1955        if (array[i]->depth != array[0]->depth
1956  	  || array[i]->arity != array[0]->arity) {
1957  	free(array);
1958  	return;
1959        }
1960      if (!array[0]->arity)
1961        break;
1962      for(i=0; i<arity; i++)
1963        array[i] = array[i]->first_child;
1964    }
1965    free(array);
1966   good:
1967    root->symmetric_subtree = 1;
1968  }
1969  static void hwloc_set_group_depth(hwloc_topology_t topology)
1970  {
1971    unsigned groupdepth = 0;
1972    unsigned i, j;
1973    for(i=0; i<topology->nb_levels; i++)
1974      if (topology->levels[i][0]->type == HWLOC_OBJ_GROUP) {
1975        for (j = 0; j < topology->level_nbobjects[i]; j++)
1976  	topology->levels[i][j]->attr->group.depth = groupdepth;
1977        groupdepth++;
1978      }
1979  }
1980  static void
1981  hwloc_connect_children(hwloc_obj_t parent)
1982  {
1983    unsigned n, oldn = parent->arity;
1984    hwloc_obj_t child, prev_child;
1985    int ok;
1986    ok = 1;
1987    prev_child = NULL;
1988    for (n = 0, child = parent->first_child;
1989         child;
1990         n++,   prev_child = child, child = child->next_sibling) {
1991      child->sibling_rank = n;
1992      child->prev_sibling = prev_child;
1993      if (n >= oldn || parent->children[n] != child)
1994        ok = 0;
1995      hwloc_connect_children(child);
1996    }
1997    parent->last_child = prev_child;
1998    parent->arity = n;
1999    if (!n) {
2000      free(parent->children);
2001      parent->children = NULL;
2002      goto memory;
2003    }
2004    if (ok)
2005      goto memory;
2006    if (oldn < n) {
2007      free(parent->children);
2008      parent->children = malloc(n * sizeof(*parent->children));
2009    }
2010    for (n = 0, child = parent->first_child;
2011         child;
2012         n++,   child = child->next_sibling) {
2013      parent->children[n] = child;
2014    }
2015   memory:
2016    prev_child = NULL;
2017    for (n = 0, child = parent->memory_first_child;
2018         child;
2019         n++,   prev_child = child, child = child->next_sibling) {
2020      child->parent = parent;
2021      child->sibling_rank = n;
2022      child->prev_sibling = prev_child;
2023      hwloc_connect_children(child);
2024    }
2025    parent->memory_arity = n;
2026    prev_child = NULL;
2027    for (n = 0, child = parent->io_first_child;
2028         child;
2029         n++,   prev_child = child, child = child->next_sibling) {
2030      child->parent = parent;
2031      child->sibling_rank = n;
2032      child->prev_sibling = prev_child;
2033      hwloc_connect_children(child);
2034    }
2035    parent->io_arity = n;
2036    prev_child = NULL;
2037    for (n = 0, child = parent->misc_first_child;
2038         child;
2039         n++,   prev_child = child, child = child->next_sibling) {
2040      child->parent = parent;
2041      child->sibling_rank = n;
2042      child->prev_sibling = prev_child;
2043      hwloc_connect_children(child);
2044    }
2045    parent->misc_arity = n;
2046  }
2047  static int
2048  find_same_type(hwloc_obj_t root, hwloc_obj_t obj)
2049  {
2050    hwloc_obj_t child;
2051    for_each_child (child, root) {
2052      if (hwloc_type_cmp(child, obj) == HWLOC_OBJ_EQUAL)
2053        return 1;
2054      if (find_same_type(child, obj))
2055        return 1;
2056    }
2057    return 0;
2058  }
2059  static int
2060  hwloc_build_level_from_list(struct hwloc_special_level_s *slevel)
2061  {
2062    unsigned i, nb;
2063    struct hwloc_obj * obj;
2064    obj = slevel->first;
2065    i = 0;
2066    while (obj) {
2067      i++;
2068      obj = obj->next_cousin;
2069    }
2070    nb = i;
2071    if (nb) {
2072      slevel->objs = malloc(nb * sizeof(struct hwloc_obj *));
2073      if (!slevel->objs)
2074        return -1;
2075      obj = slevel->first;
2076      i = 0;
2077      while (obj) {
2078        obj->logical_index = i;
2079        slevel->objs[i] = obj;
2080        i++;
2081        obj = obj->next_cousin;
2082      }
2083    }
2084    slevel->nbobjs = nb;
2085    return 0;
2086  }
2087  static void
2088  hwloc_append_special_object(struct hwloc_special_level_s *level, hwloc_obj_t obj)
2089  {
2090    if (level->first) {
2091      obj->prev_cousin = level->last;
2092      obj->prev_cousin->next_cousin = obj;
2093      level->last = obj;
2094    } else {
2095      obj->prev_cousin = NULL;
2096      level->first = level->last = obj;
2097    }
2098  }
2099  static void
2100  hwloc_list_special_objects(hwloc_topology_t topology, hwloc_obj_t obj)
2101  {
2102    hwloc_obj_t child;
2103    if (obj->type == HWLOC_OBJ_NUMANODE) {
2104      obj->next_cousin = NULL;
2105      obj->depth = HWLOC_TYPE_DEPTH_NUMANODE;
2106      hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_NUMANODE], obj);
2107      for_each_misc_child(child, obj)
2108        hwloc_list_special_objects(topology, child);
2109    } else if (obj->type == HWLOC_OBJ_MEMCACHE) {
2110      obj->next_cousin = NULL;
2111      obj->depth = HWLOC_TYPE_DEPTH_MEMCACHE;
2112      hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_MEMCACHE], obj);
2113      for_each_memory_child(child, obj)
2114        hwloc_list_special_objects(topology, child);
2115      for_each_misc_child(child, obj)
2116        hwloc_list_special_objects(topology, child);
2117    } else if (obj->type == HWLOC_OBJ_MISC) {
2118      obj->next_cousin = NULL;
2119      obj->depth = HWLOC_TYPE_DEPTH_MISC;
2120      hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_MISC], obj);
2121      for_each_misc_child(child, obj)
2122        hwloc_list_special_objects(topology, child);
2123    } else if (hwloc__obj_type_is_io(obj->type)) {
2124      obj->next_cousin = NULL;
2125      if (obj->type == HWLOC_OBJ_BRIDGE) {
2126        obj->depth = HWLOC_TYPE_DEPTH_BRIDGE;
2127        hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_BRIDGE], obj);
2128      } else if (obj->type == HWLOC_OBJ_PCI_DEVICE) {
2129        obj->depth = HWLOC_TYPE_DEPTH_PCI_DEVICE;
2130        hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_PCIDEV], obj);
2131      } else if (obj->type == HWLOC_OBJ_OS_DEVICE) {
2132        obj->depth = HWLOC_TYPE_DEPTH_OS_DEVICE;
2133        hwloc_append_special_object(&topology->slevels[HWLOC_SLEVEL_OSDEV], obj);
2134      }
2135      for_each_io_child(child, obj)
2136        hwloc_list_special_objects(topology, child);
2137      for_each_misc_child(child, obj)
2138        hwloc_list_special_objects(topology, child);
2139    } else {
2140      for_each_child(child, obj)
2141        hwloc_list_special_objects(topology, child);
2142      for_each_memory_child(child, obj)
2143        hwloc_list_special_objects(topology, child);
2144      for_each_io_child(child, obj)
2145        hwloc_list_special_objects(topology, child);
2146      for_each_misc_child(child, obj)
2147        hwloc_list_special_objects(topology, child);
2148    }
2149  }
2150  static int
2151  hwloc_connect_special_levels(hwloc_topology_t topology)
2152  {
2153    unsigned i;
2154    for(i=0; i<HWLOC_NR_SLEVELS; i++)
2155      free(topology->slevels[i].objs);
2156    memset(&topology->slevels, 0, sizeof(topology->slevels));
2157    hwloc_list_special_objects(topology, topology->levels[0][0]);
2158    for(i=0; i<HWLOC_NR_SLEVELS; i++) {
2159      if (hwloc_build_level_from_list(&topology->slevels[i]) < 0)
2160        return -1;
2161    }
2162    return 0;
2163  }
2164  static int
2165  hwloc_connect_levels(hwloc_topology_t topology)
2166  {
2167    unsigned l, i=0;
2168    hwloc_obj_t *objs, *taken_objs, *new_objs, top_obj, root;
2169    unsigned n_objs, n_taken_objs, n_new_objs;
2170    for(l=1; l<topology->nb_levels; l++)
2171      free(topology->levels[l]);
2172    memset(topology->levels+1, 0, (topology->nb_levels-1)*sizeof(*topology->levels));
2173    memset(topology->level_nbobjects+1, 0, (topology->nb_levels-1)*sizeof(*topology->level_nbobjects));
2174    topology->nb_levels = 1;
2175    hwloc_reset_normal_type_depths(topology);
2176    root = topology->levels[0][0];
2177    root->depth = 0;
2178    topology->type_depth[root->type] = 0;
2179    root->logical_index = 0;
2180    root->prev_cousin = NULL;
2181    root->next_cousin = NULL;
2182    root->parent = NULL;
2183    root->sibling_rank = 0;
2184    root->prev_sibling = NULL;
2185    root->next_sibling = NULL;
2186    n_objs = topology->levels[0][0]->arity;
2187    objs = malloc(n_objs * sizeof(objs[0]));
2188    if (!objs) {
2189      errno = ENOMEM;
2190      return -1;
2191    }
2192    memcpy(objs, topology->levels[0][0]->children, n_objs*sizeof(objs[0]));
2193    while (n_objs) {
2194      for (i = 0; i < n_objs; i++)
2195        if (objs[i]->type != HWLOC_OBJ_PU)
2196          break;
2197      top_obj = i == n_objs ? objs[0] : objs[i];
2198      for (i = 0; i < n_objs; i++) {
2199        if (hwloc_type_cmp(top_obj, objs[i]) != HWLOC_OBJ_EQUAL) {
2200  	if (find_same_type(objs[i], top_obj)) {
2201  	  top_obj = objs[i];
2202  	}
2203        }
2204      }
2205      taken_objs = malloc((n_objs+1) * sizeof(taken_objs[0]));
2206      if (!taken_objs) {
2207        free(objs);
2208        errno = ENOMEM;
2209        return -1;
2210      }
2211      n_new_objs = 0;
2212      for (i = 0; i < n_objs; i++) {
2213        if (objs[i]->arity)
2214  	n_new_objs += objs[i]->arity;
2215        else
2216  	n_new_objs++;
2217      }
2218      new_objs = malloc(n_new_objs * sizeof(new_objs[0]));
2219      if (!new_objs) {
2220        free(objs);
2221        free(taken_objs);
2222        errno = ENOMEM;
2223        return -1;
2224      }
2225      n_new_objs = 0;
2226      n_taken_objs = 0;
2227      for (i = 0; i < n_objs; i++)
2228        if (hwloc_type_cmp(top_obj, objs[i]) == HWLOC_OBJ_EQUAL) {
2229  	taken_objs[n_taken_objs++] = objs[i];
2230  	if (objs[i]->arity)
2231  	  memcpy(&new_objs[n_new_objs], objs[i]->children, objs[i]->arity * sizeof(new_objs[0]));
2232  	n_new_objs += objs[i]->arity;
2233        } else {
2234  	new_objs[n_new_objs++] = objs[i];
2235        }
2236      if (!n_new_objs) {
2237        free(new_objs);
2238        new_objs = NULL;
2239      }
2240      for (i = 0; i < n_taken_objs; i++) {
2241        taken_objs[i]->depth = (int) topology->nb_levels;
2242        taken_objs[i]->logical_index = i;
2243        if (i) {
2244  	taken_objs[i]->prev_cousin = taken_objs[i-1];
2245  	taken_objs[i-1]->next_cousin = taken_objs[i];
2246        }
2247      }
2248      taken_objs[0]->prev_cousin = NULL;
2249      taken_objs[n_taken_objs-1]->next_cousin = NULL;
2250      hwloc_debug("--- %s level", hwloc_obj_type_string(top_obj->type));
2251      hwloc_debug(" has number %u\n\n", topology->nb_levels);
2252      if (topology->type_depth[top_obj->type] == HWLOC_TYPE_DEPTH_UNKNOWN)
2253        topology->type_depth[top_obj->type] = (int) topology->nb_levels;
2254      else
2255        topology->type_depth[top_obj->type] = HWLOC_TYPE_DEPTH_MULTIPLE; &bsol;* mark as unknown */
2256      taken_objs[n_taken_objs] = NULL;
2257      if (topology->nb_levels == topology->nb_levels_allocated) {
2258        void *tmplevels, *tmpnbobjs;
2259        tmplevels = realloc(topology->levels,
2260  			  2 * topology->nb_levels_allocated * sizeof(*topology->levels));
2261        tmpnbobjs = realloc(topology->level_nbobjects,
2262  			  2 * topology->nb_levels_allocated * sizeof(*topology->level_nbobjects));
2263        if (!tmplevels || !tmpnbobjs) {
2264          if (HWLOC_SHOW_CRITICAL_ERRORS())
2265            fprintf(stderr, "hwloc: failed to realloc level arrays to %u\n", topology->nb_levels_allocated * 2);
2266  	if (tmplevels)
2267  	  topology->levels = tmplevels;
2268  	if (tmpnbobjs)
2269  	  topology->level_nbobjects = tmpnbobjs;
2270  	free(objs);
2271  	free(taken_objs);
2272  	free(new_objs);
2273  	errno = ENOMEM;
2274  	return -1;
2275        }
2276        topology->levels = tmplevels;
2277        topology->level_nbobjects = tmpnbobjs;
2278        memset(topology->levels + topology->nb_levels_allocated,
2279  	     0, topology->nb_levels_allocated * sizeof(*topology->levels));
2280        memset(topology->level_nbobjects + topology->nb_levels_allocated,
2281  	     0, topology->nb_levels_allocated * sizeof(*topology->level_nbobjects));
2282        topology->nb_levels_allocated *= 2;
2283      }
2284      topology->level_nbobjects[topology->nb_levels] = n_taken_objs;
2285      topology->levels[topology->nb_levels] = taken_objs;
2286      topology->nb_levels++;
2287      free(objs);
2288      objs = new_objs;
2289      n_objs = n_new_objs;
2290    }
2291    free(objs);
2292    return 0;
2293  }
2294  int
2295  hwloc_topology_reconnect(struct hwloc_topology *topology, unsigned long flags)
2296  {
2297    if (flags) {
2298      errno = EINVAL;
2299      return -1;
2300    }
2301    if (!topology->modified)
2302      return 0;
2303    hwloc_connect_children(topology->levels[0][0]);
2304    if (hwloc_connect_levels(topology) < 0)
2305      return -1;
2306    if (hwloc_connect_special_levels(topology) < 0)
2307      return -1;
2308    topology->modified = 0;
2309    return 0;
2310  }
2311  static hwloc_obj_t
2312  hwloc_debug_insert_osdev_sorted(hwloc_obj_t queue, hwloc_obj_t obj)
2313  {
2314    hwloc_obj_t *pcur = &queue;
2315    while (*pcur && strcmp((*pcur)->name, obj->name) < 0)
2316      pcur = &((*pcur)->next_sibling);
2317    obj->next_sibling = *pcur;
2318    *pcur = obj;
2319    return queue;
2320  }
2321  static void
2322  hwloc_debug_sort_children(hwloc_obj_t root)
2323  {
2324    hwloc_obj_t child;
2325    if (root->io_first_child) {
2326      hwloc_obj_t osdevqueue, *pchild;
2327      pchild = &root->io_first_child;
2328      osdevqueue = NULL;
2329      while ((child = *pchild) != NULL) {
2330        if (child->type != HWLOC_OBJ_OS_DEVICE) {
2331  	pchild = &child->next_sibling;
2332  	continue;
2333        }
2334        *pchild = child->next_sibling;
2335        child->next_sibling = NULL;
2336        osdevqueue = hwloc_debug_insert_osdev_sorted(osdevqueue, child);
2337      }
2338      *pchild = osdevqueue;
2339    }
2340    for_each_child(child, root)
2341      hwloc_debug_sort_children(child);
2342    for_each_memory_child(child, root)
2343      hwloc_debug_sort_children(child);
2344    for_each_io_child(child, root)
2345      hwloc_debug_sort_children(child);
2346  }
2347  void hwloc_alloc_root_sets(hwloc_obj_t root)
2348  {
2349    if (!root->cpuset)
2350       root->cpuset = hwloc_bitmap_alloc();
2351    if (!root->complete_cpuset)
2352       root->complete_cpuset = hwloc_bitmap_alloc();
2353    if (!root->nodeset)
2354      root->nodeset = hwloc_bitmap_alloc();
2355    if (!root->complete_nodeset)
2356      root->complete_nodeset = hwloc_bitmap_alloc();
2357  }
2358  static void
2359  hwloc_discover_by_phase(struct hwloc_topology *topology,
2360  			struct hwloc_disc_status *dstatus,
2361  			const char *phasename __hwloc_attribute_unused)
2362  {
2363    struct hwloc_backend *backend;
2364    hwloc_debug("%s phase discovery...\n", phasename);
2365    for(backend = topology->backends; backend; backend = backend->next) {
2366      if (dstatus->phase & dstatus->excluded_phases)
2367        break;
2368      if (!(backend->phases & dstatus->phase))
2369        continue;
2370      if (!backend->discover)
2371        continue;
2372      hwloc_debug("%s phase discovery in component %s...\n", phasename, backend->component->name);
2373      backend->discover(backend, dstatus);
2374      hwloc_debug_print_objects(0, topology->levels[0][0]);
2375    }
2376  }
2377  static int
2378  hwloc_discover(struct hwloc_topology *topology,
2379  	       struct hwloc_disc_status *dstatus)
2380  {
2381    const char *env;
2382    topology->modified = 0; &bsol;* no need to reconnect yet */
2383    topology->allowed_cpuset = hwloc_bitmap_alloc_full();
2384    topology->allowed_nodeset = hwloc_bitmap_alloc_full();
2385    if (topology->backend_phases & HWLOC_DISC_PHASE_GLOBAL) {
2386      struct hwloc_backend *global_backend = topology->backends;
2387      assert(global_backend);
2388      assert(global_backend->phases == HWLOC_DISC_PHASE_GLOBAL);
2389      hwloc_debug("GLOBAL phase discovery...\n");
2390      hwloc_debug("GLOBAL phase discovery with component %s...\n", global_backend->component->name);
2391      dstatus->phase = HWLOC_DISC_PHASE_GLOBAL;
2392      global_backend->discover(global_backend, dstatus);
2393      hwloc_debug_print_objects(0, topology->levels[0][0]);
2394    }
2395    if (topology->backend_phases & HWLOC_DISC_PHASE_CPU) {
2396      dstatus->phase = HWLOC_DISC_PHASE_CPU;
2397      hwloc_discover_by_phase(topology, dstatus, "CPU");
2398    }
2399    if (!(topology->backend_phases & (HWLOC_DISC_PHASE_GLOBAL|HWLOC_DISC_PHASE_CPU))) {
2400      hwloc_debug("No GLOBAL or CPU component phase found\n");
2401    }
2402    if (!topology->levels[0][0]->cpuset || hwloc_bitmap_iszero(topology->levels[0][0]->cpuset)) {
2403      hwloc_debug("%s", "No PU added by any CPU or GLOBAL component phase\n");
2404      errno = EINVAL;
2405      return -1;
2406    }
2407    if (topology->backend_phases & HWLOC_DISC_PHASE_MEMORY) {
2408      dstatus->phase = HWLOC_DISC_PHASE_MEMORY;
2409      hwloc_discover_by_phase(topology, dstatus, "MEMORY");
2410    }
2411    if (&bsol;* check if getting the sets of locally allowed resources is possible */
2412        topology->binding_hooks.get_allowed_resources
2413        && topology->is_thissystem
2414        && !(dstatus->flags & HWLOC_DISC_STATUS_FLAG_GOT_ALLOWED_RESOURCES)
2415        && ((topology->flags & HWLOC_TOPOLOGY_FLAG_THISSYSTEM_ALLOWED_RESOURCES) != 0
2416  	  || ((env = getenv("HWLOC_THISSYSTEM_ALLOWED_RESOURCES")) != NULL && atoi(env)))) {
2417      topology->binding_hooks.get_allowed_resources(topology);
2418      dstatus->flags |= HWLOC_DISC_STATUS_FLAG_GOT_ALLOWED_RESOURCES;
2419    }
2420    if (hwloc_bitmap_iszero(topology->levels[0][0]->complete_nodeset)) {
2421      hwloc_obj_t node;
2422      hwloc_debug("%s", "\nAdd missing single NUMA node\n");
2423      node = hwloc_alloc_setup_object(topology, HWLOC_OBJ_NUMANODE, 0);
2424      node->cpuset = hwloc_bitmap_dup(topology->levels[0][0]->cpuset);
2425      node->nodeset = hwloc_bitmap_alloc();
2426      hwloc_bitmap_set(node->nodeset, 0);
2427      memcpy(&node->attr->numanode, &topology->machine_memory, sizeof(topology->machine_memory));
2428      memset(&topology->machine_memory, 0, sizeof(topology->machine_memory));
2429      hwloc__insert_object_by_cpuset(topology, NULL, node, "core:defaultnumanode");
2430    } else {
2431      free(topology->machine_memory.page_types);
2432      memset(&topology->machine_memory, 0, sizeof(topology->machine_memory));
2433    }
2434    hwloc_debug("%s", "\nFixup root sets\n");
2435    hwloc_bitmap_and(topology->levels[0][0]->cpuset, topology->levels[0][0]->cpuset, topology->levels[0][0]->complete_cpuset);
2436    hwloc_bitmap_and(topology->levels[0][0]->nodeset, topology->levels[0][0]->nodeset, topology->levels[0][0]->complete_nodeset);
2437    hwloc_bitmap_and(topology->allowed_cpuset, topology->allowed_cpuset, topology->levels[0][0]->cpuset);
2438    hwloc_bitmap_and(topology->allowed_nodeset, topology->allowed_nodeset, topology->levels[0][0]->nodeset);
2439    hwloc_debug("%s", "\nPropagate sets\n");
2440    propagate_nodeset(topology->levels[0][0]);
2441    fixup_sets(topology->levels[0][0]);
2442    hwloc_debug_print_objects(0, topology->levels[0][0]);
2443    if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED)) {
2444      hwloc_debug("%s", "\nRemoving unauthorized sets from all sets\n");
2445      remove_unused_sets(topology, topology->levels[0][0]);
2446      hwloc_debug_print_objects(0, topology->levels[0][0]);
2447    }
2448    if (!hwloc_filter_check_keep_object(topology, topology->levels[0][0])
2449        && topology->levels[0][0]->first_child && !topology->levels[0][0]->first_child->next_sibling) {
2450      hwloc_obj_t oldroot = topology->levels[0][0];
2451      hwloc_obj_t newroot = oldroot->first_child;
2452      newroot->parent = NULL;
2453      topology->levels[0][0] = newroot;
2454      if (oldroot->memory_first_child)
2455        prepend_siblings_list(&newroot->memory_first_child, oldroot->memory_first_child, newroot);
2456      if (oldroot->io_first_child)
2457        prepend_siblings_list(&newroot->io_first_child, oldroot->io_first_child, newroot);
2458      if (oldroot->misc_first_child)
2459        prepend_siblings_list(&newroot->misc_first_child, oldroot->misc_first_child, newroot);
2460      hwloc_free_unlinked_object(oldroot);
2461    }
2462    hwloc_debug("%s", "\nOk, finished tweaking, now connect\n");
2463    if (hwloc_topology_reconnect(topology, 0) < 0)
2464      return -1;
2465    hwloc_debug_print_objects(0, topology->levels[0][0]);
2466    hwloc_pci_discovery_prepare(topology);
2467    if (topology->backend_phases & HWLOC_DISC_PHASE_PCI) {
2468      dstatus->phase = HWLOC_DISC_PHASE_PCI;
2469      hwloc_discover_by_phase(topology, dstatus, "PCI");
2470    }
2471    if (topology->backend_phases & HWLOC_DISC_PHASE_IO) {
2472      dstatus->phase = HWLOC_DISC_PHASE_IO;
2473      hwloc_discover_by_phase(topology, dstatus, "IO");
2474    }
2475    if (topology->backend_phases & HWLOC_DISC_PHASE_MISC) {
2476      dstatus->phase = HWLOC_DISC_PHASE_MISC;
2477      hwloc_discover_by_phase(topology, dstatus, "MISC");
2478    }
2479    if (topology->backend_phases & HWLOC_DISC_PHASE_ANNOTATE) {
2480      dstatus->phase = HWLOC_DISC_PHASE_ANNOTATE;
2481      hwloc_discover_by_phase(topology, dstatus, "ANNOTATE");
2482    }
2483    hwloc_pci_discovery_exit(topology); &bsol;* pci needed up to annotate */
2484    if (getenv("HWLOC_DEBUG_SORT_CHILDREN"))
2485      hwloc_debug_sort_children(topology->levels[0][0]);
2486    hwloc_debug("%s", "\nRemoving bridge objects if needed\n");
2487    hwloc_filter_bridges(topology, topology->levels[0][0]);
2488    hwloc_debug_print_objects(0, topology->levels[0][0]);
2489    hwloc_debug("%s", "\nRemoving empty objects\n");
2490    remove_empty(topology, &topology->levels[0][0]);
2491    if (!topology->levels[0][0]) {
2492      if (HWLOC_SHOW_CRITICAL_ERRORS())
2493        fprintf(stderr, "hwloc: Topology became empty, aborting!\n");
2494      return -1;
2495    }
2496    if (hwloc_bitmap_iszero(topology->levels[0][0]->cpuset)) {
2497      if (HWLOC_SHOW_CRITICAL_ERRORS())
2498        fprintf(stderr, "hwloc: Topology does not contain any PU, aborting!\n");
2499      return -1;
2500    }
2501    if (hwloc_bitmap_iszero(topology->levels[0][0]->nodeset)) {
2502      if (HWLOC_SHOW_CRITICAL_ERRORS())
2503        fprintf(stderr, "hwloc: Topology does not contain any NUMA node, aborting!\n");
2504      return -1;
2505    }
2506    hwloc_debug_print_objects(0, topology->levels[0][0]);
2507    hwloc_debug("%s", "\nRemoving levels with HWLOC_TYPE_FILTER_KEEP_STRUCTURE\n");
2508    if (hwloc_filter_levels_keep_structure(topology) < 0)
2509      return -1;
2510    hwloc_debug_print_objects(0, topology->levels[0][0]);
2511    hwloc_debug("%s", "\nPropagate total memory up\n");
2512    propagate_total_memory(topology->levels[0][0]);
2513    hwloc_propagate_symmetric_subtree(topology, topology->levels[0][0]);
2514    hwloc_set_group_depth(topology);
2515    if (topology->backends
2516        && strcmp(topology->backends->component->name, "xml")
2517        && !getenv("HWLOC_DONT_ADD_VERSION_INFO")) {
2518      char *value;
2519      hwloc_obj_add_info(topology->levels[0][0], "hwlocVersion", HWLOC_VERSION);
2520      value = hwloc_progname(topology);
2521      if (value) {
2522        hwloc_obj_add_info(topology->levels[0][0], "ProcessName", value);
2523        free(value);
2524      }
2525    }
2526    return 0;
2527  }
2528  void
2529  hwloc_topology_setup_defaults(struct hwloc_topology *topology)
2530  {
2531    struct hwloc_obj *root_obj;
2532    memset(&topology->binding_hooks, 0, sizeof(topology->binding_hooks));
2533    memset(topology->support.discovery, 0, sizeof(*topology->support.discovery));
<span onclick='openModal()' class='match'>2534    memset(topology->support.cpubind, 0, sizeof(*topology->support.cpubind));
2535    memset(topology->support.membind, 0, sizeof(*topology->support.membind));
</span>2536    memset(topology->support.misc, 0, sizeof(*topology->support.misc));
2537    topology->next_gp_index = 1; &bsol;* keep 0 as an invalid value */
2538    topology->nb_levels = 1; &bsol;* there's at least SYSTEM */
2539    topology->levels[0] = hwloc_tma_malloc (topology->tma, sizeof (hwloc_obj_t));
2540    topology->level_nbobjects[0] = 1;
2541    topology->machine_memory.local_memory = 0;
2542    topology->machine_memory.page_types_len = 0;
2543    topology->machine_memory.page_types = NULL;
2544    topology->allowed_cpuset = NULL;
2545    topology->allowed_nodeset = NULL;
2546    memset(&topology->slevels, 0, sizeof(topology->slevels));
2547    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_NUMANODE == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_NUMANODE));
2548    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_MISC == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_MISC));
2549    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_BRIDGE == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_BRIDGE));
2550    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_PCIDEV == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_PCI_DEVICE));
2551    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_OSDEV == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_OS_DEVICE));
2552    HWLOC_BUILD_ASSERT(HWLOC_SLEVEL_MEMCACHE == HWLOC_SLEVEL_FROM_DEPTH(HWLOC_TYPE_DEPTH_MEMCACHE));
2553    hwloc_reset_normal_type_depths(topology);
2554    topology->type_depth[HWLOC_OBJ_NUMANODE] = HWLOC_TYPE_DEPTH_NUMANODE;
2555    topology->type_depth[HWLOC_OBJ_MISC] = HWLOC_TYPE_DEPTH_MISC;
2556    topology->type_depth[HWLOC_OBJ_BRIDGE] = HWLOC_TYPE_DEPTH_BRIDGE;
2557    topology->type_depth[HWLOC_OBJ_PCI_DEVICE] = HWLOC_TYPE_DEPTH_PCI_DEVICE;
2558    topology->type_depth[HWLOC_OBJ_OS_DEVICE] = HWLOC_TYPE_DEPTH_OS_DEVICE;
2559    topology->type_depth[HWLOC_OBJ_MEMCACHE] = HWLOC_TYPE_DEPTH_MEMCACHE;
2560    root_obj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_MACHINE, 0);
2561    topology->levels[0][0] = root_obj;
2562  }
2563  static void hwloc__topology_filter_init(struct hwloc_topology *topology);
2564  static int
2565  hwloc__topology_init (struct hwloc_topology **topologyp,
2566  		      unsigned nblevels,
2567  		      struct hwloc_tma *tma)
2568  {
2569    struct hwloc_topology *topology;
2570    topology = hwloc_tma_malloc (tma, sizeof (struct hwloc_topology));
2571    if(!topology)
2572      return -1;
2573    topology->tma = tma;
2574    hwloc_components_init(); &bsol;* uses malloc without tma, but won't need it since dup() caller already took a reference */
2575    hwloc_topology_components_init(topology);
2576    hwloc_pci_discovery_init(topology); &bsol;* make sure both dup() and load() get sane variables */
2577    topology->is_loaded = 0;
2578    topology->flags = 0;
2579    topology->is_thissystem = 1;
2580    topology->pid = 0;
2581    topology->userdata = NULL;
2582    topology->topology_abi = HWLOC_TOPOLOGY_ABI;
2583    topology->adopted_shmem_addr = NULL;
2584    topology->adopted_shmem_length = 0;
2585    topology->support.discovery = hwloc_tma_malloc(tma, sizeof(*topology->support.discovery));
2586    topology->support.cpubind = hwloc_tma_malloc(tma, sizeof(*topology->support.cpubind));
2587    topology->support.membind = hwloc_tma_malloc(tma, sizeof(*topology->support.membind));
2588    topology->support.misc = hwloc_tma_malloc(tma, sizeof(*topology->support.misc));
2589    topology->nb_levels_allocated = nblevels; &bsol;* enough for default 10 levels = Mach+Pack+Die+NUMA+L3+L2+L1d+L1i+Co+PU */
2590    topology->levels = hwloc_tma_calloc(tma, topology->nb_levels_allocated * sizeof(*topology->levels));
2591    topology->level_nbobjects = hwloc_tma_calloc(tma, topology->nb_levels_allocated * sizeof(*topology->level_nbobjects));
2592    hwloc__topology_filter_init(topology);
2593    hwloc_internal_distances_init(topology);
2594    hwloc_internal_memattrs_init(topology);
2595    hwloc_internal_cpukinds_init(topology);
2596    topology->userdata_export_cb = NULL;
2597    topology->userdata_import_cb = NULL;
2598    topology->userdata_not_decoded = 0;
2599    hwloc_topology_setup_defaults(topology);
2600    *topologyp = topology;
2601    return 0;
2602  }
2603  int
2604  hwloc_topology_init (struct hwloc_topology **topologyp)
2605  {
2606    return hwloc__topology_init(topologyp,
2607  			      16, &bsol;* 16 is enough for default 10 levels = Mach+Pack+Die+NUMA+L3+L2+L1d+L1i+Co+PU */
2608  			      NULL); &bsol;* no TMA for normal topologies, too many allocations to fix */
2609  }
2610  int
2611  hwloc_topology_set_pid(struct hwloc_topology *topology __hwloc_attribute_unused,
2612                         hwloc_pid_t pid __hwloc_attribute_unused)
2613  {
2614    if (topology->is_loaded) {
2615      errno = EBUSY;
2616      return -1;
2617    }
2618  #ifdef HWLOC_LINUX_SYS
2619    topology->pid = pid;
2620    return 0;
2621  #else &bsol;* HWLOC_LINUX_SYS */
2622    errno = ENOSYS;
2623    return -1;
2624  #endif &bsol;* HWLOC_LINUX_SYS */
2625  }
2626  int
2627  hwloc_topology_set_synthetic(struct hwloc_topology *topology, const char *description)
2628  {
2629    if (topology->is_loaded) {
2630      errno = EBUSY;
2631      return -1;
2632    }
2633    return hwloc_disc_component_force_enable(topology,
2634  					   0 &bsol;* api */,
2635  					   "synthetic",
2636  					   description, NULL, NULL);
2637  }
2638  int
2639  hwloc_topology_set_xml(struct hwloc_topology *topology,
2640  		       const char *xmlpath)
2641  {
2642    if (topology->is_loaded) {
2643      errno = EBUSY;
2644      return -1;
2645    }
2646    return hwloc_disc_component_force_enable(topology,
2647  					   0 &bsol;* api */,
2648  					   "xml",
2649  					   xmlpath, NULL, NULL);
2650  }
2651  int
2652  hwloc_topology_set_xmlbuffer(struct hwloc_topology *topology,
2653                               const char *xmlbuffer,
2654                               int size)
2655  {
2656    if (topology->is_loaded) {
2657      errno = EBUSY;
2658      return -1;
2659    }
2660    return hwloc_disc_component_force_enable(topology,
2661  					   0 &bsol;* api */,
2662  					   "xml", NULL,
2663  					   xmlbuffer, (void*) (uintptr_t) size);
2664  }
2665  int
2666  hwloc_topology_set_flags (struct hwloc_topology *topology, unsigned long flags)
2667  {
2668    if (topology->is_loaded) {
2669      errno = EBUSY;
2670      return -1;
2671    }
2672    if (flags & ~(HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED
2673                  |HWLOC_TOPOLOGY_FLAG_IS_THISSYSTEM
2674                  |HWLOC_TOPOLOGY_FLAG_THISSYSTEM_ALLOWED_RESOURCES
2675                  |HWLOC_TOPOLOGY_FLAG_IMPORT_SUPPORT
2676                  |HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING
2677                  |HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING
2678                  |HWLOC_TOPOLOGY_FLAG_DONT_CHANGE_BINDING
2679                  |HWLOC_TOPOLOGY_FLAG_NO_DISTANCES
2680                  |HWLOC_TOPOLOGY_FLAG_NO_MEMATTRS
2681                  |HWLOC_TOPOLOGY_FLAG_NO_CPUKINDS)) {
2682      errno = EINVAL;
2683      return -1;
2684    }
2685    if ((flags & (HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING|HWLOC_TOPOLOGY_FLAG_IS_THISSYSTEM)) == HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING) {
2686      errno = EINVAL;
2687      return -1;
2688    }
2689    if ((flags & (HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING|HWLOC_TOPOLOGY_FLAG_IS_THISSYSTEM)) == HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING) {
2690      errno = EINVAL;
2691      return -1;
2692    }
2693    topology->flags = flags;
2694    return 0;
2695  }
2696  unsigned long
2697  hwloc_topology_get_flags (struct hwloc_topology *topology)
2698  {
2699    return topology->flags;
2700  }
2701  static void
2702  hwloc__topology_filter_init(struct hwloc_topology *topology)
2703  {
2704    hwloc_obj_type_t type;
2705    for(type = HWLOC_OBJ_TYPE_MIN; type < HWLOC_OBJ_TYPE_MAX; type++)
2706      topology->type_filter[type] = HWLOC_TYPE_FILTER_KEEP_ALL;
2707    topology->type_filter[HWLOC_OBJ_L1ICACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2708    topology->type_filter[HWLOC_OBJ_L2ICACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2709    topology->type_filter[HWLOC_OBJ_L3ICACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2710    topology->type_filter[HWLOC_OBJ_MEMCACHE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2711    topology->type_filter[HWLOC_OBJ_GROUP] = HWLOC_TYPE_FILTER_KEEP_STRUCTURE;
2712    topology->type_filter[HWLOC_OBJ_MISC] = HWLOC_TYPE_FILTER_KEEP_NONE;
2713    topology->type_filter[HWLOC_OBJ_BRIDGE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2714    topology->type_filter[HWLOC_OBJ_PCI_DEVICE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2715    topology->type_filter[HWLOC_OBJ_OS_DEVICE] = HWLOC_TYPE_FILTER_KEEP_NONE;
2716  }
2717  static int
2718  hwloc__topology_set_type_filter(struct hwloc_topology *topology, hwloc_obj_type_t type, enum hwloc_type_filter_e filter)
2719  {
2720    if (type == HWLOC_OBJ_PU || type == HWLOC_OBJ_NUMANODE || type == HWLOC_OBJ_MACHINE) {
2721      if (filter != HWLOC_TYPE_FILTER_KEEP_ALL) {
2722        errno = EINVAL;
2723        return -1;
2724      }
2725    } else if (hwloc__obj_type_is_special(type)) {
2726      if (filter == HWLOC_TYPE_FILTER_KEEP_STRUCTURE) {
2727        errno = EINVAL;
2728        return -1;
2729      }
2730    } else if (type == HWLOC_OBJ_GROUP) {
2731      if (filter == HWLOC_TYPE_FILTER_KEEP_ALL) {
2732        errno = EINVAL;
2733        return -1;
2734      }
2735    }
2736    if (!hwloc__obj_type_is_special(type) && filter == HWLOC_TYPE_FILTER_KEEP_IMPORTANT)
2737      filter = HWLOC_TYPE_FILTER_KEEP_ALL;
2738    topology->type_filter[type] = filter;
2739    return 0;
2740  }
2741  int
2742  hwloc_topology_set_type_filter(struct hwloc_topology *topology, hwloc_obj_type_t type, enum hwloc_type_filter_e filter)
2743  {
2744    HWLOC_BUILD_ASSERT(HWLOC_OBJ_TYPE_MIN == 0);
2745    if ((unsigned) type >= HWLOC_OBJ_TYPE_MAX) {
2746      errno = EINVAL;
2747      return -1;
2748    }
2749    if (topology->is_loaded) {
2750      errno = EBUSY;
2751      return -1;
2752    }
2753    return hwloc__topology_set_type_filter(topology, type, filter);
2754  }
2755  int
2756  hwloc_topology_set_all_types_filter(struct hwloc_topology *topology, enum hwloc_type_filter_e filter)
2757  {
2758    hwloc_obj_type_t type;
2759    if (topology->is_loaded) {
2760      errno = EBUSY;
2761      return -1;
2762    }
2763    for(type = HWLOC_OBJ_TYPE_MIN; type < HWLOC_OBJ_TYPE_MAX; type++)
2764      hwloc__topology_set_type_filter(topology, type, filter);
2765    return 0;
2766  }
2767  int
2768  hwloc_topology_set_cache_types_filter(hwloc_topology_t topology, enum hwloc_type_filter_e filter)
2769  {
2770    unsigned i;
2771    for(i=HWLOC_OBJ_L1CACHE; i<HWLOC_OBJ_L3ICACHE; i++)
2772      hwloc_topology_set_type_filter(topology, (hwloc_obj_type_t) i, filter);
2773    return 0;
2774  }
2775  int
2776  hwloc_topology_set_icache_types_filter(hwloc_topology_t topology, enum hwloc_type_filter_e filter)
2777  {
2778    unsigned i;
2779    for(i=HWLOC_OBJ_L1ICACHE; i<HWLOC_OBJ_L3ICACHE; i++)
2780      hwloc_topology_set_type_filter(topology, (hwloc_obj_type_t) i, filter);
2781    return 0;
2782  }
2783  int
2784  hwloc_topology_set_io_types_filter(hwloc_topology_t topology, enum hwloc_type_filter_e filter)
2785  {
2786    hwloc_topology_set_type_filter(topology, HWLOC_OBJ_BRIDGE, filter);
2787    hwloc_topology_set_type_filter(topology, HWLOC_OBJ_PCI_DEVICE, filter);
2788    hwloc_topology_set_type_filter(topology, HWLOC_OBJ_OS_DEVICE, filter);
2789    return 0;
2790  }
2791  int
2792  hwloc_topology_get_type_filter(struct hwloc_topology *topology, hwloc_obj_type_t type, enum hwloc_type_filter_e *filterp)
2793  {
2794    HWLOC_BUILD_ASSERT(HWLOC_OBJ_TYPE_MIN == 0);
2795    if ((unsigned) type >= HWLOC_OBJ_TYPE_MAX) {
2796      errno = EINVAL;
2797      return -1;
2798    }
2799    *filterp = topology->type_filter[type];
2800    return 0;
2801  }
2802  void
2803  hwloc_topology_clear (struct hwloc_topology *topology)
2804  {
2805    unsigned l;
2806    hwloc_internal_cpukinds_destroy(topology);
2807    hwloc_internal_distances_destroy(topology);
2808    hwloc_internal_memattrs_destroy(topology);
2809    hwloc_free_object_and_children(topology->levels[0][0]);
2810    hwloc_bitmap_free(topology->allowed_cpuset);
2811    hwloc_bitmap_free(topology->allowed_nodeset);
2812    for (l=0; l<topology->nb_levels; l++)
2813      free(topology->levels[l]);
2814    for(l=0; l<HWLOC_NR_SLEVELS; l++)
2815      free(topology->slevels[l].objs);
2816    free(topology->machine_memory.page_types);
2817  }
2818  void
2819  hwloc_topology_destroy (struct hwloc_topology *topology)
2820  {
2821    if (topology->adopted_shmem_addr) {
2822      hwloc__topology_disadopt(topology);
2823      return;
2824    }
2825    hwloc_backends_disable_all(topology);
2826    hwloc_topology_components_fini(topology);
2827    hwloc_components_fini();
2828    hwloc_topology_clear(topology);
2829    free(topology->levels);
2830    free(topology->level_nbobjects);
2831    free(topology->support.discovery);
2832    free(topology->support.cpubind);
2833    free(topology->support.membind);
2834    free(topology->support.misc);
2835    free(topology);
2836  }
2837  int
2838  hwloc_topology_load (struct hwloc_topology *topology)
2839  {
2840    struct hwloc_disc_status dstatus;
2841    const char *env;
2842    int err;
2843    if (topology->is_loaded) {
2844      errno = EBUSY;
2845      return -1;
2846    }
2847    hwloc_internal_distances_prepare(topology);
2848    hwloc_internal_memattrs_prepare(topology);
2849    if (getenv("HWLOC_XML_USERDATA_NOT_DECODED"))
2850      topology->userdata_not_decoded = 1;
2851    if (!getenv("HWLOC_COMPONENTS")) {
2852      if (!topology->backends) {
2853        const char *fsroot_path_env = getenv("HWLOC_FSROOT");
2854        if (fsroot_path_env)
2855  	hwloc_disc_component_force_enable(topology,
2856  					  1 &bsol;* env force */,
2857  					  "linux",
2858  					  NULL &bsol;* backend will getenv again */, NULL, NULL);
2859      }
2860      if (!topology->backends) {
2861        const char *cpuid_path_env = getenv("HWLOC_CPUID_PATH");
2862        if (cpuid_path_env)
2863  	hwloc_disc_component_force_enable(topology,
2864  					  1 &bsol;* env force */,
2865  					  "x86",
2866  					  NULL &bsol;* backend will getenv again */, NULL, NULL);
2867      }
2868      if (!topology->backends) {
2869        const char *synthetic_env = getenv("HWLOC_SYNTHETIC");
2870        if (synthetic_env)
2871  	hwloc_disc_component_force_enable(topology,
2872  					  1 &bsol;* env force */,
2873  					  "synthetic",
2874  					  synthetic_env, NULL, NULL);
2875      }
2876      if (!topology->backends) {
2877        const char *xmlpath_env = getenv("HWLOC_XMLFILE");
2878        if (xmlpath_env)
2879  	hwloc_disc_component_force_enable(topology,
2880  					  1 &bsol;* env force */,
2881  					  "xml",
2882  					  xmlpath_env, NULL, NULL);
2883      }
2884    }
2885    dstatus.excluded_phases = 0;
2886    dstatus.flags = 0; &bsol;* did nothing yet */
2887    env = getenv("HWLOC_ALLOW");
2888    if (env && !strcmp(env, "all"))
2889      dstatus.flags |= HWLOC_DISC_STATUS_FLAG_GOT_ALLOWED_RESOURCES;
2890    hwloc_disc_components_enable_others(topology);
2891    hwloc_backends_is_thissystem(topology);
2892    hwloc_backends_find_callbacks(topology);
2893    hwloc_set_binding_hooks(topology);
2894    err = hwloc_discover(topology, &dstatus);
2895    if (err < 0)
2896      goto out;
2897  #ifndef HWLOC_DEBUG
2898    if (getenv("HWLOC_DEBUG_CHECK"))
2899  #endif
2900      hwloc_topology_check(topology);
2901    hwloc_internal_cpukinds_rank(topology);
2902    hwloc_internal_distances_invalidate_cached_objs(topology);
2903    hwloc_internal_distances_refresh(topology);
2904    hwloc_internal_memattrs_need_refresh(topology);
2905    hwloc_internal_memattrs_refresh(topology);
2906    hwloc_internal_memattrs_guess_memory_tiers(topology);
2907    topology->is_loaded = 1;
2908    if (topology->flags & HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_CPUBINDING) {
2909      hwloc_bitmap_t set = hwloc_bitmap_alloc();
2910      if (set) {
2911        err = hwloc_get_cpubind(topology, set, HWLOC_CPUBIND_STRICT);
2912        if (!err)
2913          hwloc_topology_restrict(topology, set, 0);
2914        hwloc_bitmap_free(set);
2915      }
2916    }
2917    if (topology->flags & HWLOC_TOPOLOGY_FLAG_RESTRICT_TO_MEMBINDING) {
2918      hwloc_bitmap_t set = hwloc_bitmap_alloc();
2919      hwloc_membind_policy_t policy;
2920      if (set) {
2921        err = hwloc_get_membind(topology, set, &policy, HWLOC_MEMBIND_STRICT | HWLOC_MEMBIND_BYNODESET);
2922        if (!err)
2923          hwloc_topology_restrict(topology, set, HWLOC_RESTRICT_FLAG_BYNODESET);
2924        hwloc_bitmap_free(set);
2925      }
2926    }
2927    if (topology->backend_phases & HWLOC_DISC_PHASE_TWEAK) {
2928      dstatus.phase = HWLOC_DISC_PHASE_TWEAK;
2929      hwloc_discover_by_phase(topology, &dstatus, "TWEAK");
2930    }
2931    return 0;
2932   out:
2933    hwloc_pci_discovery_exit(topology);
2934    hwloc_topology_clear(topology);
2935    hwloc_topology_setup_defaults(topology);
2936    hwloc_backends_disable_all(topology);
2937    return -1;
2938  }
2939  static void
2940  restrict_object_by_cpuset(hwloc_topology_t topology, unsigned long flags, hwloc_obj_t *pobj,
2941  			  hwloc_bitmap_t droppedcpuset, hwloc_bitmap_t droppednodeset)
2942  {
2943    hwloc_obj_t obj = *pobj, child, *pchild;
2944    int modified = 0;
2945    if (hwloc_bitmap_intersects(obj->complete_cpuset, droppedcpuset)) {
2946      hwloc_bitmap_andnot(obj->cpuset, obj->cpuset, droppedcpuset);
2947      hwloc_bitmap_andnot(obj->complete_cpuset, obj->complete_cpuset, droppedcpuset);
2948      modified = 1;
2949    } else {
2950      if ((flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS)
2951  	&& hwloc_bitmap_iszero(obj->complete_cpuset)) {
2952        modified = 1;
2953      }
2954      if (droppednodeset)
2955        assert(!hwloc_bitmap_intersects(obj->complete_nodeset, droppednodeset)
2956  	     || hwloc_bitmap_iszero(obj->complete_cpuset));
2957    }
2958    if (droppednodeset) {
2959      hwloc_bitmap_andnot(obj->nodeset, obj->nodeset, droppednodeset);
2960      hwloc_bitmap_andnot(obj->complete_nodeset, obj->complete_nodeset, droppednodeset);
2961    }
2962    if (modified) {
2963      for_each_child_safe(child, obj, pchild)
2964        restrict_object_by_cpuset(topology, flags, pchild, droppedcpuset, droppednodeset);
2965      hwloc__reorder_children(obj);
2966      for_each_memory_child_safe(child, obj, pchild)
2967        restrict_object_by_cpuset(topology, flags, pchild, droppedcpuset, droppednodeset);
2968    }
2969    if (!obj->first_child && !obj->memory_first_child &bsol;* arity not updated before connect_children() */
2970        && hwloc_bitmap_iszero(obj->cpuset)
2971        && (obj->type != HWLOC_OBJ_NUMANODE || (flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS))) {
2972      hwloc_debug("%s", "\nRemoving object during restrict by cpuset");
2973      hwloc_debug_print_object(0, obj);
2974      if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_IO)) {
2975        hwloc_free_object_siblings_and_children(obj->io_first_child);
2976        obj->io_first_child = NULL;
2977      }
2978      if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_MISC)) {
2979        hwloc_free_object_siblings_and_children(obj->misc_first_child);
2980        obj->misc_first_child = NULL;
2981      }
2982      assert(!obj->first_child);
2983      assert(!obj->memory_first_child);
2984      unlink_and_free_single_object(pobj);
2985      topology->modified = 1;
2986    }
2987  }
2988  static void
2989  restrict_object_by_nodeset(hwloc_topology_t topology, unsigned long flags, hwloc_obj_t *pobj,
2990  			   hwloc_bitmap_t droppedcpuset, hwloc_bitmap_t droppednodeset)
2991  {
2992    hwloc_obj_t obj = *pobj, child, *pchild;
2993    int modified = 0;
2994    if (hwloc_bitmap_intersects(obj->complete_nodeset, droppednodeset)) {
2995      hwloc_bitmap_andnot(obj->nodeset, obj->nodeset, droppednodeset);
2996      hwloc_bitmap_andnot(obj->complete_nodeset, obj->complete_nodeset, droppednodeset);
2997      modified = 1;
2998    } else {
2999      if ((flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)
3000  	&& hwloc_bitmap_iszero(obj->complete_nodeset)) {
3001        modified = 1;
3002      }
3003      if (droppedcpuset)
3004        assert(!hwloc_bitmap_intersects(obj->complete_cpuset, droppedcpuset)
3005  	     || hwloc_bitmap_iszero(obj->complete_nodeset));
3006    }
3007    if (droppedcpuset) {
3008      hwloc_bitmap_andnot(obj->cpuset, obj->cpuset, droppedcpuset);
3009      hwloc_bitmap_andnot(obj->complete_cpuset, obj->complete_cpuset, droppedcpuset);
3010    }
3011    if (modified) {
3012      for_each_child_safe(child, obj, pchild)
3013        restrict_object_by_nodeset(topology, flags, pchild, droppedcpuset, droppednodeset);
3014      if (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)
3015        hwloc__reorder_children(obj);
3016      for_each_memory_child_safe(child, obj, pchild)
3017        restrict_object_by_nodeset(topology, flags, pchild, droppedcpuset, droppednodeset);
3018    }
3019    if (!obj->first_child && !obj->memory_first_child &bsol;* arity not updated before connect_children() */
3020        && hwloc_bitmap_iszero(obj->nodeset)
3021        && (obj->type != HWLOC_OBJ_PU || (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS))) {
3022      hwloc_debug("%s", "\nRemoving object during restrict by nodeset");
3023      hwloc_debug_print_object(0, obj);
3024      if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_IO)) {
3025        hwloc_free_object_siblings_and_children(obj->io_first_child);
3026        obj->io_first_child = NULL;
3027      }
3028      if (!(flags & HWLOC_RESTRICT_FLAG_ADAPT_MISC)) {
3029        hwloc_free_object_siblings_and_children(obj->misc_first_child);
3030        obj->misc_first_child = NULL;
3031      }
3032      assert(!obj->first_child);
3033      assert(!obj->memory_first_child);
3034      unlink_and_free_single_object(pobj);
3035      topology->modified = 1;
3036    }
3037  }
3038  int
3039  hwloc_topology_restrict(struct hwloc_topology *topology, hwloc_const_bitmap_t set, unsigned long flags)
3040  {
3041    hwloc_bitmap_t droppedcpuset, droppednodeset;
3042    if (!topology->is_loaded) {
3043      errno = EINVAL;
3044      return -1;
3045    }
3046    if (topology->adopted_shmem_addr) {
3047      errno = EPERM;
3048      return -1;
3049    }
3050    if (flags & ~(HWLOC_RESTRICT_FLAG_REMOVE_CPULESS
3051  		|HWLOC_RESTRICT_FLAG_ADAPT_MISC|HWLOC_RESTRICT_FLAG_ADAPT_IO
3052  		|HWLOC_RESTRICT_FLAG_BYNODESET|HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)) {
3053      errno = EINVAL;
3054      return -1;
3055    }
3056    if (flags & HWLOC_RESTRICT_FLAG_BYNODESET) {
3057      if (flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS) {
3058        errno = EINVAL;
3059        return -1;
3060      }
3061    } else {
3062      if (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS) {
3063        errno = EINVAL;
3064        return -1;
3065      }
3066    }
3067    if (((flags & HWLOC_RESTRICT_FLAG_BYNODESET) && !hwloc_bitmap_intersects(set, topology->allowed_nodeset))
3068        || (!(flags & HWLOC_RESTRICT_FLAG_BYNODESET) && !hwloc_bitmap_intersects(set, topology->allowed_cpuset))) {
3069      errno = EINVAL; &bsol;* easy failure, just don't touch the topology */
3070      return -1;
3071    }
3072    droppedcpuset = hwloc_bitmap_alloc();
3073    droppednodeset = hwloc_bitmap_alloc();
3074    if (!droppedcpuset || !droppednodeset) {
3075      hwloc_bitmap_free(droppedcpuset);
3076      hwloc_bitmap_free(droppednodeset);
3077      return -1;
3078    }
3079    if (flags & HWLOC_RESTRICT_FLAG_BYNODESET) {
3080      hwloc_bitmap_not(droppednodeset, set);
3081      if (flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS) {
3082        hwloc_obj_t pu = hwloc_get_obj_by_type(topology, HWLOC_OBJ_PU, 0);
3083        assert(pu);
3084        do {
3085  	if (hwloc_bitmap_iszero(pu->cpuset)
3086  	    || hwloc_bitmap_isincluded(pu->nodeset, droppednodeset))
3087  	  hwloc_bitmap_set(droppedcpuset, pu->os_index);
3088  	pu = pu->next_cousin;
3089        } while (pu);
3090        if (hwloc_bitmap_isincluded(topology->allowed_cpuset, droppedcpuset)) {
3091  	errno = EINVAL; &bsol;* easy failure, just don't touch the topology */
3092  	hwloc_bitmap_free(droppedcpuset);
3093  	hwloc_bitmap_free(droppednodeset);
3094  	return -1;
3095        }
3096      }
3097      if (!(flags & HWLOC_RESTRICT_FLAG_REMOVE_MEMLESS)
3098  	|| hwloc_bitmap_iszero(droppedcpuset)) {
3099        hwloc_bitmap_free(droppedcpuset);
3100        droppedcpuset = NULL;
3101      }
3102      restrict_object_by_nodeset(topology, flags, &topology->levels[0][0], droppedcpuset, droppednodeset);
3103      hwloc_bitmap_andnot(topology->allowed_nodeset, topology->allowed_nodeset, droppednodeset);
3104      if (droppedcpuset)
3105        hwloc_bitmap_andnot(topology->allowed_cpuset, topology->allowed_cpuset, droppedcpuset);
3106    } else {
3107      hwloc_bitmap_not(droppedcpuset, set);
3108      if (flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS) {
3109        hwloc_obj_t node = hwloc_get_obj_by_type(topology, HWLOC_OBJ_NUMANODE, 0);
3110        assert(node);
3111        do {
3112  	if (hwloc_bitmap_iszero(node->cpuset)
3113  	    || hwloc_bitmap_isincluded(node->cpuset, droppedcpuset))
3114  	  hwloc_bitmap_set(droppednodeset, node->os_index);
3115  	node = node->next_cousin;
3116        } while (node);
3117        if (hwloc_bitmap_isincluded(topology->allowed_nodeset, droppednodeset)) {
3118  	errno = EINVAL; &bsol;* easy failure, just don't touch the topology */
3119  	hwloc_bitmap_free(droppedcpuset);
3120  	hwloc_bitmap_free(droppednodeset);
3121  	return -1;
3122        }
3123      }
3124      if (!(flags & HWLOC_RESTRICT_FLAG_REMOVE_CPULESS)
3125  	|| hwloc_bitmap_iszero(droppednodeset)) {
3126        hwloc_bitmap_free(droppednodeset);
3127        droppednodeset = NULL;
3128      }
3129      restrict_object_by_cpuset(topology, flags, &topology->levels[0][0], droppedcpuset, droppednodeset);
3130      hwloc_bitmap_andnot(topology->allowed_cpuset, topology->allowed_cpuset, droppedcpuset);
3131      if (droppednodeset)
3132        hwloc_bitmap_andnot(topology->allowed_nodeset, topology->allowed_nodeset, droppednodeset);
3133    }
3134    hwloc_bitmap_free(droppedcpuset);
3135    hwloc_bitmap_free(droppednodeset);
3136    if (hwloc_filter_levels_keep_structure(topology) < 0) &bsol;* takes care of reconnecting internally */
3137      goto out;
3138    hwloc_internal_distances_invalidate_cached_objs(topology);
3139    hwloc_internal_memattrs_need_refresh(topology);
3140    hwloc_propagate_symmetric_subtree(topology, topology->levels[0][0]);
3141    propagate_total_memory(topology->levels[0][0]);
3142    hwloc_internal_cpukinds_restrict(topology);
3143  #ifndef HWLOC_DEBUG
3144    if (getenv("HWLOC_DEBUG_CHECK"))
3145  #endif
3146      hwloc_topology_check(topology);
3147    return 0;
3148   out:
3149     hwloc_topology_clear(topology);
3150     hwloc_topology_setup_defaults(topology);
3151     return -1;
3152  }
3153  int
3154  hwloc_topology_allow(struct hwloc_topology *topology,
3155  		     hwloc_const_cpuset_t cpuset, hwloc_const_nodeset_t nodeset,
3156  		     unsigned long flags)
3157  {
3158    if (!topology->is_loaded)
3159      goto einval;
3160    if (topology->adopted_shmem_addr) {
3161      errno = EPERM;
3162      goto error;
3163    }
3164    if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED))
3165      goto einval;
3166    if (flags & ~(HWLOC_ALLOW_FLAG_ALL|HWLOC_ALLOW_FLAG_LOCAL_RESTRICTIONS|HWLOC_ALLOW_FLAG_CUSTOM))
3167      goto einval;
3168    switch (flags) {
3169    case HWLOC_ALLOW_FLAG_ALL: {
3170      if (cpuset || nodeset)
3171        goto einval;
3172      hwloc_bitmap_copy(topology->allowed_cpuset, hwloc_get_root_obj(topology)->complete_cpuset);
3173      hwloc_bitmap_copy(topology->allowed_nodeset, hwloc_get_root_obj(topology)->complete_nodeset);
3174      break;
3175    }
3176    case HWLOC_ALLOW_FLAG_LOCAL_RESTRICTIONS: {
3177      if (cpuset || nodeset)
3178        goto einval;
3179      if (!topology->is_thissystem)
3180        goto einval;
3181      if (!topology->binding_hooks.get_allowed_resources) {
3182        errno = ENOSYS;
3183        goto error;
3184      }
3185      topology->binding_hooks.get_allowed_resources(topology);
3186      hwloc_bitmap_and(topology->allowed_cpuset, topology->allowed_cpuset, hwloc_get_root_obj(topology)->cpuset);
3187      hwloc_bitmap_and(topology->allowed_nodeset, topology->allowed_nodeset, hwloc_get_root_obj(topology)->nodeset);
3188      break;
3189    }
3190    case HWLOC_ALLOW_FLAG_CUSTOM: {
3191      if (cpuset) {
3192        if (!hwloc_bitmap_intersects(hwloc_get_root_obj(topology)->cpuset, cpuset))
3193  	goto einval;
3194        hwloc_bitmap_and(topology->allowed_cpuset, hwloc_get_root_obj(topology)->cpuset, cpuset);
3195      }
3196      if (nodeset) {
3197        if (!hwloc_bitmap_intersects(hwloc_get_root_obj(topology)->nodeset, nodeset))
3198  	goto einval;
3199        hwloc_bitmap_and(topology->allowed_nodeset, hwloc_get_root_obj(topology)->nodeset, nodeset);
3200      }
3201      break;
3202    }
3203    default:
3204      goto einval;
3205    }
3206    return 0;
3207   einval:
3208    errno = EINVAL;
3209   error:
3210    return -1;
3211  }
3212  int
3213  hwloc_topology_refresh(struct hwloc_topology *topology)
3214  {
3215    hwloc_internal_cpukinds_rank(topology);
3216    hwloc_internal_distances_refresh(topology);
3217    hwloc_internal_memattrs_refresh(topology);
3218    return 0;
3219  }
3220  int
3221  hwloc_topology_is_thissystem(struct hwloc_topology *topology)
3222  {
3223    return topology->is_thissystem;
3224  }
3225  int
3226  hwloc_topology_get_depth(struct hwloc_topology *topology)
3227  {
3228    return (int) topology->nb_levels;
3229  }
3230  const struct hwloc_topology_support *
3231  hwloc_topology_get_support(struct hwloc_topology * topology)
3232  {
3233    return &topology->support;
3234  }
3235  void hwloc_topology_set_userdata(struct hwloc_topology * topology, const void *userdata)
3236  {
3237    topology->userdata = (void *) userdata;
3238  }
3239  void * hwloc_topology_get_userdata(struct hwloc_topology * topology)
3240  {
3241    return topology->userdata;
3242  }
3243  hwloc_const_cpuset_t
3244  hwloc_topology_get_complete_cpuset(hwloc_topology_t topology)
3245  {
3246    return hwloc_get_root_obj(topology)->complete_cpuset;
3247  }
3248  hwloc_const_cpuset_t
3249  hwloc_topology_get_topology_cpuset(hwloc_topology_t topology)
3250  {
3251    return hwloc_get_root_obj(topology)->cpuset;
3252  }
3253  hwloc_const_cpuset_t
3254  hwloc_topology_get_allowed_cpuset(hwloc_topology_t topology)
3255  {
3256    return topology->allowed_cpuset;
3257  }
3258  hwloc_const_nodeset_t
3259  hwloc_topology_get_complete_nodeset(hwloc_topology_t topology)
3260  {
3261    return hwloc_get_root_obj(topology)->complete_nodeset;
3262  }
3263  hwloc_const_nodeset_t
3264  hwloc_topology_get_topology_nodeset(hwloc_topology_t topology)
3265  {
3266    return hwloc_get_root_obj(topology)->nodeset;
3267  }
3268  hwloc_const_nodeset_t
3269  hwloc_topology_get_allowed_nodeset(hwloc_topology_t topology)
3270  {
3271    return topology->allowed_nodeset;
3272  }
3273  #ifndef NDEBUG &bsol;* assert only enabled if !NDEBUG */
3274  static void
3275  hwloc__check_child_siblings(hwloc_obj_t parent, hwloc_obj_t *array,
3276  			    unsigned arity, unsigned i,
3277  			    hwloc_obj_t child, hwloc_obj_t prev)
3278  {
3279    assert(child->parent == parent);
3280    assert(child->sibling_rank == i);
3281    if (array)
3282      assert(child == array[i]);
3283    if (prev)
3284      assert(prev->next_sibling == child);
3285    assert(child->prev_sibling == prev);
3286    if (!i)
3287      assert(child->prev_sibling == NULL);
3288    else
3289      assert(child->prev_sibling != NULL);
3290    if (i == arity-1)
3291      assert(child->next_sibling == NULL);
3292    else
3293      assert(child->next_sibling != NULL);
3294  }
3295  static void
3296  hwloc__check_object(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t obj);
3297  static void
3298  hwloc__check_normal_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
3299  {
3300    hwloc_obj_t child, prev;
3301    unsigned j;
3302    if (!parent->arity) {
3303      assert(!parent->children);
3304      assert(!parent->first_child);
3305      assert(!parent->last_child);
3306      return;
3307    }
3308    assert(parent->children);
3309    assert(parent->first_child);
3310    assert(parent->last_child);
3311    for(prev = NULL, child = parent->first_child, j = 0;
3312        child;
3313        prev = child, child = child->next_sibling, j++) {
3314      assert(hwloc__obj_type_is_normal(child->type));
3315      assert(child->depth > parent->depth);
3316      hwloc__check_child_siblings(parent, parent->children, parent->arity, j, child, prev);
3317      hwloc__check_object(topology, gp_indexes, child);
3318    }
3319    assert(j == parent->arity);
3320    assert(parent->first_child == parent->children[0]);
3321    assert(parent->last_child == parent->children[parent->arity-1]);
3322    if (parent->type == HWLOC_OBJ_PU)
3323      assert(!parent->arity);
3324  }
3325  static void
3326  hwloc__check_children_cpusets(hwloc_topology_t topology __hwloc_attribute_unused, hwloc_obj_t obj)
3327  {
3328    hwloc_obj_t child;
3329    int prev_first, prev_empty;
3330    if (obj->type == HWLOC_OBJ_PU) {
3331      assert(hwloc_bitmap_weight(obj->cpuset) == 1);
3332      assert(hwloc_bitmap_first(obj->cpuset) == (int) obj->os_index);
3333      assert(hwloc_bitmap_weight(obj->complete_cpuset) == 1);
3334      assert(hwloc_bitmap_first(obj->complete_cpuset) == (int) obj->os_index);
3335      if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED)) {
3336        assert(hwloc_bitmap_isset(topology->allowed_cpuset, (int) obj->os_index));
3337      }
3338      assert(!obj->arity);
3339    } else if (hwloc__obj_type_is_memory(obj->type)) {
3340      assert(hwloc_bitmap_isequal(obj->parent->cpuset, obj->cpuset));
3341      assert(!obj->arity);
3342    } else if (!hwloc__obj_type_is_special(obj->type)) {
3343      hwloc_bitmap_t set;
3344      set = hwloc_bitmap_alloc();
3345      for_each_child(child, obj) {
3346        assert(!hwloc_bitmap_intersects(set, child->cpuset));
3347        hwloc_bitmap_or(set, set, child->cpuset);
3348      }
3349      assert(hwloc_bitmap_isequal(set, obj->cpuset));
3350      hwloc_bitmap_free(set);
3351    }
3352    for_each_memory_child(child, obj)
3353      assert(hwloc_bitmap_isequal(obj->cpuset, child->cpuset));
3354    prev_first = -1; &bsol;* -1 works fine with first comparisons below */
3355    prev_empty = 0; &bsol;* no empty cpuset in previous children */
3356    for_each_child(child, obj) {
3357      int first = hwloc_bitmap_first(child->complete_cpuset);
3358      if (first >= 0) {
3359        assert(!prev_empty); &bsol;* no objects with CPU after objects without CPU */
3360        assert(prev_first < first);
3361      } else {
3362        prev_empty = 1;
3363      }
3364      prev_first = first;
3365    }
3366  }
3367  static void
3368  hwloc__check_memory_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
3369  {
3370    unsigned j;
3371    hwloc_obj_t child, prev;
3372    if (!parent->memory_arity) {
3373      assert(!parent->memory_first_child);
3374      return;
3375    }
3376    assert(parent->memory_first_child);
3377    for(prev = NULL, child = parent->memory_first_child, j = 0;
3378        child;
3379        prev = child, child = child->next_sibling, j++) {
3380      assert(hwloc__obj_type_is_memory(child->type));
3381      hwloc__check_child_siblings(parent, NULL, parent->memory_arity, j, child, prev);
3382      assert(!child->first_child);
3383      assert(!child->io_first_child);
3384      hwloc__check_object(topology, gp_indexes, child);
3385    }
3386    assert(j == parent->memory_arity);
3387    if (parent->type == HWLOC_OBJ_NUMANODE)
3388      assert(!parent->memory_arity);
3389  }
3390  static void
3391  hwloc__check_io_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
3392  {
3393    unsigned j;
3394    hwloc_obj_t child, prev;
3395    if (!parent->io_arity) {
3396      assert(!parent->io_first_child);
3397      return;
3398    }
3399    assert(parent->io_first_child);
3400    for(prev = NULL, child = parent->io_first_child, j = 0;
3401        child;
3402        prev = child, child = child->next_sibling, j++) {
3403      assert(hwloc__obj_type_is_io(child->type));
3404      hwloc__check_child_siblings(parent, NULL, parent->io_arity, j, child, prev);
3405      assert(!child->first_child);
3406      assert(!child->memory_first_child);
3407      hwloc__check_object(topology, gp_indexes, child);
3408    }
3409    assert(j == parent->io_arity);
3410  }
3411  static void
3412  hwloc__check_misc_children(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t parent)
3413  {
3414    unsigned j;
3415    hwloc_obj_t child, prev;
3416    if (!parent->misc_arity) {
3417      assert(!parent->misc_first_child);
3418      return;
3419    }
3420    assert(parent->misc_first_child);
3421    for(prev = NULL, child = parent->misc_first_child, j = 0;
3422        child;
3423        prev = child, child = child->next_sibling, j++) {
3424      assert(child->type == HWLOC_OBJ_MISC);
3425      hwloc__check_child_siblings(parent, NULL, parent->misc_arity, j, child, prev);
3426      assert(!child->first_child);
3427      assert(!child->memory_first_child);
3428      assert(!child->io_first_child);
3429      hwloc__check_object(topology, gp_indexes, child);
3430    }
3431    assert(j == parent->misc_arity);
3432  }
3433  static void
3434  hwloc__check_object(hwloc_topology_t topology, hwloc_bitmap_t gp_indexes, hwloc_obj_t obj)
3435  {
3436    hwloc_uint64_t total_memory;
3437    hwloc_obj_t child;
3438    assert(!hwloc_bitmap_isset(gp_indexes, obj->gp_index));
3439    hwloc_bitmap_set(gp_indexes, obj->gp_index);
3440    HWLOC_BUILD_ASSERT(HWLOC_OBJ_TYPE_MIN == 0);
3441    assert((unsigned) obj->type < HWLOC_OBJ_TYPE_MAX);
3442    assert(hwloc_filter_check_keep_object(topology, obj));
3443    if (hwloc__obj_type_is_special(obj->type)) {
3444      assert(!obj->cpuset);
3445      if (obj->type == HWLOC_OBJ_BRIDGE)
3446        assert(obj->depth == HWLOC_TYPE_DEPTH_BRIDGE);
3447      else if (obj->type == HWLOC_OBJ_PCI_DEVICE)
3448        assert(obj->depth == HWLOC_TYPE_DEPTH_PCI_DEVICE);
3449      else if (obj->type == HWLOC_OBJ_OS_DEVICE)
3450        assert(obj->depth == HWLOC_TYPE_DEPTH_OS_DEVICE);
3451      else if (obj->type == HWLOC_OBJ_MISC)
3452        assert(obj->depth == HWLOC_TYPE_DEPTH_MISC);
3453    } else {
3454      assert(obj->cpuset);
3455      if (obj->type == HWLOC_OBJ_NUMANODE)
3456        assert(obj->depth == HWLOC_TYPE_DEPTH_NUMANODE);
3457      else if (obj->type == HWLOC_OBJ_MEMCACHE)
3458        assert(obj->depth == HWLOC_TYPE_DEPTH_MEMCACHE);
3459      else
3460        assert(obj->depth >= 0);
3461    }
3462    if (obj->type == HWLOC_OBJ_GROUP) {
3463      assert(obj->attr->group.depth != (unsigned) -1);
3464    }
3465    assert(!!obj->cpuset == !!obj->complete_cpuset);
3466    assert(!!obj->cpuset == !!obj->nodeset);
3467    assert(!!obj->nodeset == !!obj->complete_nodeset);
3468    if (obj->cpuset) {
3469      assert(hwloc_bitmap_isincluded(obj->cpuset, obj->complete_cpuset));
3470      assert(hwloc_bitmap_isincluded(obj->nodeset, obj->complete_nodeset));
3471    }
3472    if (hwloc__obj_type_is_cache(obj->type)) {
3473      if (hwloc__obj_type_is_icache(obj->type))
3474        assert(obj->attr->cache.type == HWLOC_OBJ_CACHE_INSTRUCTION);
3475      else if (hwloc__obj_type_is_dcache(obj->type))
3476        assert(obj->attr->cache.type == HWLOC_OBJ_CACHE_DATA
3477  	     || obj->attr->cache.type == HWLOC_OBJ_CACHE_UNIFIED);
3478      else
3479        assert(0);
3480      assert(hwloc_cache_type_by_depth_type(obj->attr->cache.depth, obj->attr->cache.type) == obj->type);
3481    }
3482    total_memory = 0;
3483    if (obj->type == HWLOC_OBJ_NUMANODE)
3484      total_memory += obj->attr->numanode.local_memory;
3485    for_each_child(child, obj) {
3486      total_memory += child->total_memory;
3487    }
3488    for_each_memory_child(child, obj) {
3489      total_memory += child->total_memory;
3490    }
3491    assert(total_memory == obj->total_memory);
3492    hwloc__check_normal_children(topology, gp_indexes, obj);
3493    hwloc__check_memory_children(topology, gp_indexes, obj);
3494    hwloc__check_io_children(topology, gp_indexes, obj);
3495    hwloc__check_misc_children(topology, gp_indexes, obj);
3496    hwloc__check_children_cpusets(topology, obj);
3497  }
3498  static void
3499  hwloc__check_nodesets(hwloc_topology_t topology, hwloc_obj_t obj, hwloc_bitmap_t parentset)
3500  {
3501    hwloc_obj_t child;
3502    int prev_first;
3503    if (obj->type == HWLOC_OBJ_NUMANODE) {
3504      assert(hwloc_bitmap_weight(obj->nodeset) == 1);
3505      assert(hwloc_bitmap_first(obj->nodeset) == (int) obj->os_index);
3506      assert(hwloc_bitmap_weight(obj->complete_nodeset) == 1);
3507      assert(hwloc_bitmap_first(obj->complete_nodeset) == (int) obj->os_index);
3508      if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED)) {
3509        assert(hwloc_bitmap_isset(topology->allowed_nodeset, (int) obj->os_index));
3510      }
3511      assert(!obj->arity);
3512      assert(!obj->memory_arity);
3513      assert(hwloc_bitmap_isincluded(obj->nodeset, parentset));
3514    } else {
3515      hwloc_bitmap_t myset;
3516      hwloc_bitmap_t childset;
3517      myset = hwloc_bitmap_alloc();
3518      for_each_memory_child(child, obj) {
3519        assert(!hwloc_bitmap_intersects(myset, child->nodeset));
3520        hwloc_bitmap_or(myset, myset, child->nodeset);
3521      }
3522      assert(!hwloc_bitmap_intersects(myset, parentset));
3523      hwloc_bitmap_or(parentset, parentset, myset);
3524      hwloc_bitmap_free(myset);
3525      childset = hwloc_bitmap_alloc();
3526      for_each_child(child, obj) {
3527        hwloc_bitmap_t set = hwloc_bitmap_dup(parentset); &bsol;* don't touch parentset, we don't want to propagate the first child contribution to other children */
3528        hwloc__check_nodesets(topology, child, set);
3529        hwloc_bitmap_andnot(set, set, parentset);
3530        assert(!hwloc_bitmap_intersects(childset, set));
3531        hwloc_bitmap_or(childset, childset, set);
3532        hwloc_bitmap_free(set);
3533      }
3534      assert(!hwloc_bitmap_intersects(parentset, childset));
3535      hwloc_bitmap_or(parentset, parentset, childset);
3536      hwloc_bitmap_free(childset);
3537      assert(hwloc_bitmap_isequal(obj->nodeset, parentset));
3538    }
3539    prev_first = -1; &bsol;* -1 works fine with first comparisons below */
3540    for_each_memory_child(child, obj) {
3541      int first = hwloc_bitmap_first(child->complete_nodeset);
3542      assert(prev_first < first);
3543      prev_first = first;
3544    }
3545  }
3546  static void
3547  hwloc__check_level(struct hwloc_topology *topology, int depth,
3548  		   hwloc_obj_t first, hwloc_obj_t last)
3549  {
3550    unsigned width = hwloc_get_nbobjs_by_depth(topology, depth);
3551    struct hwloc_obj *prev = NULL;
3552    hwloc_obj_t obj;
3553    unsigned j;
3554    for(j=0; j<width; j++) {
3555      obj = hwloc_get_obj_by_depth(topology, depth, j);
3556      assert(obj);
3557      assert(obj->depth == depth);
3558      assert(obj->logical_index == j);
3559      if (prev) {
3560        assert(hwloc_type_cmp(obj, prev) == HWLOC_OBJ_EQUAL);
3561        assert(prev->next_cousin == obj);
3562      }
3563      assert(obj->prev_cousin == prev);
3564      if (obj->type == HWLOC_OBJ_NUMANODE) {
3565        assert(hwloc_bitmap_weight(obj->complete_nodeset) == 1);
3566        assert(hwloc_bitmap_first(obj->complete_nodeset) == (int) obj->os_index);
3567      }
3568      prev = obj;
3569    }
3570    if (prev)
3571      assert(prev->next_cousin == NULL);
3572    if (width) {
3573      obj = hwloc_get_obj_by_depth(topology, depth, 0);
3574      assert(obj);
3575      assert(!obj->prev_cousin);
3576      assert(hwloc_get_depth_type(topology, depth) == obj->type);
3577      assert(depth == hwloc_get_type_depth(topology, obj->type)
3578  	   || HWLOC_TYPE_DEPTH_MULTIPLE == hwloc_get_type_depth(topology, obj->type));
3579      obj = hwloc_get_obj_by_depth(topology, depth, width-1);
3580      assert(obj);
3581      assert(!obj->next_cousin);
3582    }
3583    if (depth < 0) {
3584      assert(first == hwloc_get_obj_by_depth(topology, depth, 0));
3585      assert(last == hwloc_get_obj_by_depth(topology, depth, width-1));
3586    } else {
3587      assert(!first);
3588      assert(!last);
3589    }
3590    obj = hwloc_get_obj_by_depth(topology, depth, width);
3591    assert(!obj);
3592  }
3593  void
3594  hwloc_topology_check(struct hwloc_topology *topology)
3595  {
3596    struct hwloc_obj *obj;
3597    hwloc_bitmap_t gp_indexes, set;
3598    hwloc_obj_type_t type;
3599    unsigned i;
3600    int j, depth;
3601    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L2CACHE == HWLOC_OBJ_L1CACHE + 1);
3602    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L3CACHE == HWLOC_OBJ_L2CACHE + 1);
3603    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L4CACHE == HWLOC_OBJ_L3CACHE + 1);
3604    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L5CACHE == HWLOC_OBJ_L4CACHE + 1);
3605    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L1ICACHE == HWLOC_OBJ_L5CACHE + 1);
3606    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L2ICACHE == HWLOC_OBJ_L1ICACHE + 1);
3607    HWLOC_BUILD_ASSERT(HWLOC_OBJ_L3ICACHE == HWLOC_OBJ_L2ICACHE + 1);
3608    HWLOC_BUILD_ASSERT(HWLOC_OBJ_NUMANODE   + 1 == HWLOC_OBJ_BRIDGE);
3609    HWLOC_BUILD_ASSERT(HWLOC_OBJ_BRIDGE     + 1 == HWLOC_OBJ_PCI_DEVICE);
3610    HWLOC_BUILD_ASSERT(HWLOC_OBJ_PCI_DEVICE + 1 == HWLOC_OBJ_OS_DEVICE);
3611    HWLOC_BUILD_ASSERT(HWLOC_OBJ_OS_DEVICE  + 1 == HWLOC_OBJ_MISC);
3612    HWLOC_BUILD_ASSERT(HWLOC_OBJ_MISC       + 1 == HWLOC_OBJ_MEMCACHE);
3613    HWLOC_BUILD_ASSERT(HWLOC_OBJ_MEMCACHE   + 1 == HWLOC_OBJ_DIE);
3614    HWLOC_BUILD_ASSERT(HWLOC_OBJ_DIE        + 1 == HWLOC_OBJ_TYPE_MAX);
3615    HWLOC_BUILD_ASSERT(sizeof(obj_type_order)/sizeof(*obj_type_order) == HWLOC_OBJ_TYPE_MAX);
3616    HWLOC_BUILD_ASSERT(sizeof(obj_order_type)/sizeof(*obj_order_type) == HWLOC_OBJ_TYPE_MAX);
3617    HWLOC_BUILD_ASSERT(sizeof(obj_type_priority)/sizeof(*obj_type_priority) == HWLOC_OBJ_TYPE_MAX);
3618    assert(topology->type_filter[HWLOC_OBJ_GROUP] != HWLOC_TYPE_FILTER_KEEP_ALL);
3619    for(type=HWLOC_OBJ_TYPE_MIN; type<HWLOC_OBJ_TYPE_MAX; type++)
3620      assert(obj_order_type[obj_type_order[type]] == type);
3621    for(i=HWLOC_OBJ_TYPE_MIN; i<HWLOC_OBJ_TYPE_MAX; i++)
3622      assert(obj_type_order[obj_order_type[i]] == i);
3623    depth = hwloc_topology_get_depth(topology);
3624    assert(!topology->modified);
3625    assert(hwloc_get_depth_type(topology, 0) == HWLOC_OBJ_MACHINE);
3626    assert(hwloc_get_depth_type(topology, depth-1) == HWLOC_OBJ_PU);
3627    assert(hwloc_get_nbobjs_by_depth(topology, depth-1) > 0);
3628    for(i=0; i<hwloc_get_nbobjs_by_depth(topology, depth-1); i++) {
3629      obj = hwloc_get_obj_by_depth(topology, depth-1, i);
3630      assert(obj);
3631      assert(obj->type == HWLOC_OBJ_PU);
3632      assert(!obj->memory_first_child);
3633    }
3634    for(j=1; j<depth-1; j++) {
3635      assert(hwloc_get_depth_type(topology, j) != HWLOC_OBJ_PU);
3636      assert(hwloc_get_depth_type(topology, j) != HWLOC_OBJ_MACHINE);
3637    }
3638    for(j=0; j<depth; j++) {
3639      int d;
3640      type = hwloc_get_depth_type(topology, j);
3641      assert(type != HWLOC_OBJ_NUMANODE);
3642      assert(type != HWLOC_OBJ_MEMCACHE);
3643      assert(type != HWLOC_OBJ_PCI_DEVICE);
3644      assert(type != HWLOC_OBJ_BRIDGE);
3645      assert(type != HWLOC_OBJ_OS_DEVICE);
3646      assert(type != HWLOC_OBJ_MISC);
3647      d = hwloc_get_type_depth(topology, type);
3648      assert(d == j || d == HWLOC_TYPE_DEPTH_MULTIPLE);
3649    }
3650    for(type=HWLOC_OBJ_TYPE_MIN; type<HWLOC_OBJ_TYPE_MAX; type++) {
3651      int d;
3652      d = hwloc_get_type_depth(topology, type);
3653      if (type == HWLOC_OBJ_NUMANODE) {
3654        assert(d == HWLOC_TYPE_DEPTH_NUMANODE);
3655        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_NUMANODE);
3656      } else if (type == HWLOC_OBJ_MEMCACHE) {
3657        assert(d == HWLOC_TYPE_DEPTH_MEMCACHE);
3658        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_MEMCACHE);
3659      } else if (type == HWLOC_OBJ_BRIDGE) {
3660        assert(d == HWLOC_TYPE_DEPTH_BRIDGE);
3661        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_BRIDGE);
3662      } else if (type == HWLOC_OBJ_PCI_DEVICE) {
3663        assert(d == HWLOC_TYPE_DEPTH_PCI_DEVICE);
3664        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_PCI_DEVICE);
3665      } else if (type == HWLOC_OBJ_OS_DEVICE) {
3666        assert(d == HWLOC_TYPE_DEPTH_OS_DEVICE);
3667        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_OS_DEVICE);
3668      } else if (type == HWLOC_OBJ_MISC) {
3669        assert(d == HWLOC_TYPE_DEPTH_MISC);
3670        assert(hwloc_get_depth_type(topology, d) == HWLOC_OBJ_MISC);
3671      } else {
3672        assert(d >=0 || d == HWLOC_TYPE_DEPTH_UNKNOWN || d == HWLOC_TYPE_DEPTH_MULTIPLE);
3673      }
3674    }
3675    assert(hwloc_get_nbobjs_by_depth(topology, 0) == 1);
3676    obj = hwloc_get_root_obj(topology);
3677    assert(obj);
3678    assert(!obj->parent);
3679    assert(obj->cpuset);
3680    assert(!obj->depth);
3681    if (topology->flags & HWLOC_TOPOLOGY_FLAG_INCLUDE_DISALLOWED) {
3682      assert(hwloc_bitmap_isincluded(topology->allowed_cpuset, obj->cpuset));
3683      assert(hwloc_bitmap_isincluded(topology->allowed_nodeset, obj->nodeset));
3684    } else {
3685      assert(hwloc_bitmap_isequal(topology->allowed_cpuset, obj->cpuset));
3686      assert(hwloc_bitmap_isequal(topology->allowed_nodeset, obj->nodeset));
3687    }
3688    for(j=0; j<depth; j++)
3689      hwloc__check_level(topology, j, NULL, NULL);
3690    for(j=0; j<HWLOC_NR_SLEVELS; j++)
3691      hwloc__check_level(topology, HWLOC_SLEVEL_TO_DEPTH(j), topology->slevels[j].first, topology->slevels[j].last);
3692    gp_indexes = hwloc_bitmap_alloc(); &bsol;* TODO prealloc to topology->next_gp_index */
3693    hwloc__check_object(topology, gp_indexes, obj);
3694    hwloc_bitmap_free(gp_indexes);
3695    set = hwloc_bitmap_alloc();
3696    hwloc__check_nodesets(topology, obj, set);
3697    hwloc_bitmap_free(set);
3698  }
3699  #else &bsol;* NDEBUG */
3700  void
3701  hwloc_topology_check(struct hwloc_topology *topology __hwloc_attribute_unused)
3702  {
3703  }
3704  #endif &bsol;* NDEBUG */
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-topology.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-topology.c</div>
                </div>
                <div class="column column_space"><pre><code>2536    memset(topology->support.misc, 0, sizeof(*topology->support.misc));
2537    topology->next_gp_index = 1; &bsol;* keep 0 as an invalid value */
</pre></code></div>
                <div class="column column_space"><pre><code>2534    memset(topology->support.cpubind, 0, sizeof(*topology->support.cpubind));
2535    memset(topology->support.membind, 0, sizeof(*topology->support.membind));
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    