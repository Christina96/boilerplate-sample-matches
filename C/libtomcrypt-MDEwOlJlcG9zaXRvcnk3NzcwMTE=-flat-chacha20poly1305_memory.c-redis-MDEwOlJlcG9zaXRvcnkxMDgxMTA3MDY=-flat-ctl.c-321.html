
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 15, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>libtomcrypt-MDEwOlJlcG9zaXRvcnk3NzcwMTE=-flat-chacha20poly1305_memory.c</h3>
            <pre><code>1  #include &quot;tomcrypt_private.h&quot;
2  #ifdef LTC_CHACHA20POLY1305_MODE
3  int chacha20poly1305_memory(const unsigned char *key, unsigned long keylen,
4                              const unsigned char *iv,  unsigned long ivlen,
5                              const unsigned char *aad, unsigned long aadlen,
6                              const unsigned char *in,  unsigned long inlen,
7                                    unsigned char *out,
8                                    unsigned char *tag, unsigned long *taglen,
9                              int direction)
10  {
11     chacha20poly1305_state st;
12     int err;
13     LTC_ARGCHK(key != NULL);
14     LTC_ARGCHK(iv  != NULL);
15     LTC_ARGCHK(in  != NULL);
16     LTC_ARGCHK(out != NULL);
17     LTC_ARGCHK(tag != NULL);
18     LTC_ARGCHK(taglen != NULL);
19     if ((err = chacha20poly1305_init(&amp;st, key, keylen)) != CRYPT_OK)          { goto LBL_ERR; }
20     if ((err = chacha20poly1305_setiv(&amp;st, iv, ivlen)) != CRYPT_OK)           { goto LBL_ERR; }
21     if (aad &amp;&amp; aadlen &gt; 0) {
22        if ((err = chacha20poly1305_add_aad(&amp;st, aad, aadlen)) != CRYPT_OK)    { goto LBL_ERR; }
23     }
24     if (direction == CHACHA20POLY1305_ENCRYPT) {
25        if ((err = chacha20poly1305_encrypt(&amp;st, in, inlen, out)) != CRYPT_OK) { goto LBL_ERR; }
26        if ((err = chacha20poly1305_done(&amp;st, tag, taglen)) != CRYPT_OK)       { goto LBL_ERR; }
27     }
28     else if (direction == CHACHA20POLY1305_DECRYPT) {
29        unsigned char buf[MAXBLOCKSIZE];
30        unsigned long buflen = sizeof(buf);
31        if ((err = chacha20poly1305_decrypt(&amp;st, in, inlen, out)) != CRYPT_OK) { goto LBL_ERR; }
32        if ((err = chacha20poly1305_done(&amp;st, buf, &amp;buflen)) != CRYPT_OK)      { goto LBL_ERR; }
33        if (buflen != *taglen || XMEM_NEQ(buf, tag, buflen) != 0) {
<span onclick='openModal()' class='match'>34           err = CRYPT_ERROR;
35           goto LBL_ERR;
36        }
37     }
38     else {
39        err = CRYPT_INVALID_ARG;
40        goto LBL_ERR;
</span>41     }
42  LBL_ERR:
43  #ifdef LTC_CLEAN_STACK
44     zeromem(&amp;st, sizeof(chacha20poly1305_state));
45  #endif
46     return err;
47  }
48  #endif
</code></pre>
        </div>
        <div class="column">
            <h3>redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-ctl.c</h3>
            <pre><code>1  #define JEMALLOC_CTL_C_
2  #include &quot;jemalloc/internal/jemalloc_preamble.h&quot;
3  #include &quot;jemalloc/internal/jemalloc_internal_includes.h&quot;
4  #include &quot;jemalloc/internal/assert.h&quot;
5  #include &quot;jemalloc/internal/ctl.h&quot;
6  #include &quot;jemalloc/internal/extent_dss.h&quot;
7  #include &quot;jemalloc/internal/extent_mmap.h&quot;
8  #include &quot;jemalloc/internal/mutex.h&quot;
9  #include &quot;jemalloc/internal/nstime.h&quot;
10  #include &quot;jemalloc/internal/sc.h&quot;
11  #include &quot;jemalloc/internal/util.h&quot;
12  static malloc_mutex_t	ctl_mtx;
13  static bool		ctl_initialized;
14  static ctl_stats_t	*ctl_stats;
15  static ctl_arenas_t	*ctl_arenas;
16  static const ctl_named_node_t *
17  ctl_named_node(const ctl_node_t *node) {
18  	return ((node-&gt;named) ? (const ctl_named_node_t *)node : NULL);
19  }
20  static const ctl_named_node_t *
21  ctl_named_children(const ctl_named_node_t *node, size_t index) {
22  	const ctl_named_node_t *children = ctl_named_node(node-&gt;children);
23  	return (children ? &amp;children[index] : NULL);
24  }
25  static const ctl_indexed_node_t *
26  ctl_indexed_node(const ctl_node_t *node) {
27  	return (!node-&gt;named ? (const ctl_indexed_node_t *)node : NULL);
28  }
29  #define CTL_PROTO(n)							\
30  static int	n##_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,	\
31      void *oldp, size_t *oldlenp, void *newp, size_t newlen);
32  #define INDEX_PROTO(n)							\
33  static const ctl_named_node_t	*n##_index(tsdn_t *tsdn,		\
34      const size_t *mib, size_t miblen, size_t i);
35  CTL_PROTO(version)
36  CTL_PROTO(epoch)
37  CTL_PROTO(background_thread)
38  CTL_PROTO(max_background_threads)
39  CTL_PROTO(thread_tcache_enabled)
40  CTL_PROTO(thread_tcache_flush)
41  CTL_PROTO(thread_prof_name)
42  CTL_PROTO(thread_prof_active)
43  CTL_PROTO(thread_arena)
44  CTL_PROTO(thread_allocated)
45  CTL_PROTO(thread_allocatedp)
46  CTL_PROTO(thread_deallocated)
47  CTL_PROTO(thread_deallocatedp)
48  CTL_PROTO(config_cache_oblivious)
49  CTL_PROTO(config_debug)
50  CTL_PROTO(config_fill)
51  CTL_PROTO(config_lazy_lock)
52  CTL_PROTO(config_malloc_conf)
53  CTL_PROTO(config_opt_safety_checks)
54  CTL_PROTO(config_prof)
55  CTL_PROTO(config_prof_libgcc)
56  CTL_PROTO(config_prof_libunwind)
57  CTL_PROTO(config_stats)
58  CTL_PROTO(config_utrace)
59  CTL_PROTO(config_xmalloc)
60  CTL_PROTO(opt_abort)
61  CTL_PROTO(opt_abort_conf)
62  CTL_PROTO(opt_confirm_conf)
63  CTL_PROTO(opt_metadata_thp)
64  CTL_PROTO(opt_retain)
65  CTL_PROTO(opt_dss)
66  CTL_PROTO(opt_narenas)
67  CTL_PROTO(opt_percpu_arena)
68  CTL_PROTO(opt_oversize_threshold)
69  CTL_PROTO(opt_background_thread)
70  CTL_PROTO(opt_max_background_threads)
71  CTL_PROTO(opt_dirty_decay_ms)
72  CTL_PROTO(opt_muzzy_decay_ms)
73  CTL_PROTO(opt_stats_print)
74  CTL_PROTO(opt_stats_print_opts)
75  CTL_PROTO(opt_junk)
76  CTL_PROTO(opt_zero)
77  CTL_PROTO(opt_utrace)
78  CTL_PROTO(opt_xmalloc)
79  CTL_PROTO(opt_tcache)
80  CTL_PROTO(opt_thp)
81  CTL_PROTO(opt_lg_extent_max_active_fit)
82  CTL_PROTO(opt_lg_tcache_max)
83  CTL_PROTO(opt_prof)
84  CTL_PROTO(opt_prof_prefix)
85  CTL_PROTO(opt_prof_active)
86  CTL_PROTO(opt_prof_thread_active_init)
87  CTL_PROTO(opt_lg_prof_sample)
88  CTL_PROTO(opt_lg_prof_interval)
89  CTL_PROTO(opt_prof_gdump)
90  CTL_PROTO(opt_prof_final)
91  CTL_PROTO(opt_prof_leak)
92  CTL_PROTO(opt_prof_accum)
93  CTL_PROTO(tcache_create)
94  CTL_PROTO(tcache_flush)
95  CTL_PROTO(tcache_destroy)
96  CTL_PROTO(arena_i_initialized)
97  CTL_PROTO(arena_i_decay)
98  CTL_PROTO(arena_i_purge)
99  CTL_PROTO(arena_i_reset)
100  CTL_PROTO(arena_i_destroy)
101  CTL_PROTO(arena_i_dss)
102  CTL_PROTO(arena_i_dirty_decay_ms)
103  CTL_PROTO(arena_i_muzzy_decay_ms)
104  CTL_PROTO(arena_i_extent_hooks)
105  CTL_PROTO(arena_i_retain_grow_limit)
106  INDEX_PROTO(arena_i)
107  CTL_PROTO(arenas_bin_i_size)
108  CTL_PROTO(arenas_bin_i_nregs)
109  CTL_PROTO(arenas_bin_i_slab_size)
110  CTL_PROTO(arenas_bin_i_nshards)
111  INDEX_PROTO(arenas_bin_i)
112  CTL_PROTO(arenas_lextent_i_size)
113  INDEX_PROTO(arenas_lextent_i)
114  CTL_PROTO(arenas_narenas)
115  CTL_PROTO(arenas_dirty_decay_ms)
116  CTL_PROTO(arenas_muzzy_decay_ms)
117  CTL_PROTO(arenas_quantum)
118  CTL_PROTO(arenas_page)
119  CTL_PROTO(arenas_tcache_max)
120  CTL_PROTO(arenas_nbins)
121  CTL_PROTO(arenas_nhbins)
122  CTL_PROTO(arenas_nlextents)
123  CTL_PROTO(arenas_create)
124  CTL_PROTO(arenas_lookup)
125  CTL_PROTO(prof_thread_active_init)
126  CTL_PROTO(prof_active)
127  CTL_PROTO(prof_dump)
128  CTL_PROTO(prof_gdump)
129  CTL_PROTO(prof_reset)
130  CTL_PROTO(prof_interval)
131  CTL_PROTO(lg_prof_sample)
132  CTL_PROTO(prof_log_start)
133  CTL_PROTO(prof_log_stop)
134  CTL_PROTO(stats_arenas_i_small_allocated)
135  CTL_PROTO(stats_arenas_i_small_nmalloc)
136  CTL_PROTO(stats_arenas_i_small_ndalloc)
137  CTL_PROTO(stats_arenas_i_small_nrequests)
138  CTL_PROTO(stats_arenas_i_small_nfills)
139  CTL_PROTO(stats_arenas_i_small_nflushes)
140  CTL_PROTO(stats_arenas_i_large_allocated)
141  CTL_PROTO(stats_arenas_i_large_nmalloc)
142  CTL_PROTO(stats_arenas_i_large_ndalloc)
143  CTL_PROTO(stats_arenas_i_large_nrequests)
144  CTL_PROTO(stats_arenas_i_large_nfills)
145  CTL_PROTO(stats_arenas_i_large_nflushes)
146  CTL_PROTO(stats_arenas_i_bins_j_nmalloc)
147  CTL_PROTO(stats_arenas_i_bins_j_ndalloc)
148  CTL_PROTO(stats_arenas_i_bins_j_nrequests)
149  CTL_PROTO(stats_arenas_i_bins_j_curregs)
150  CTL_PROTO(stats_arenas_i_bins_j_nfills)
151  CTL_PROTO(stats_arenas_i_bins_j_nflushes)
152  CTL_PROTO(stats_arenas_i_bins_j_nslabs)
153  CTL_PROTO(stats_arenas_i_bins_j_nreslabs)
154  CTL_PROTO(stats_arenas_i_bins_j_curslabs)
155  CTL_PROTO(stats_arenas_i_bins_j_nonfull_slabs)
156  INDEX_PROTO(stats_arenas_i_bins_j)
157  CTL_PROTO(stats_arenas_i_lextents_j_nmalloc)
158  CTL_PROTO(stats_arenas_i_lextents_j_ndalloc)
159  CTL_PROTO(stats_arenas_i_lextents_j_nrequests)
160  CTL_PROTO(stats_arenas_i_lextents_j_curlextents)
161  INDEX_PROTO(stats_arenas_i_lextents_j)
162  CTL_PROTO(stats_arenas_i_extents_j_ndirty)
163  CTL_PROTO(stats_arenas_i_extents_j_nmuzzy)
164  CTL_PROTO(stats_arenas_i_extents_j_nretained)
165  CTL_PROTO(stats_arenas_i_extents_j_dirty_bytes)
166  CTL_PROTO(stats_arenas_i_extents_j_muzzy_bytes)
167  CTL_PROTO(stats_arenas_i_extents_j_retained_bytes)
168  INDEX_PROTO(stats_arenas_i_extents_j)
169  CTL_PROTO(stats_arenas_i_nthreads)
170  CTL_PROTO(stats_arenas_i_uptime)
171  CTL_PROTO(stats_arenas_i_dss)
172  CTL_PROTO(stats_arenas_i_dirty_decay_ms)
173  CTL_PROTO(stats_arenas_i_muzzy_decay_ms)
174  CTL_PROTO(stats_arenas_i_pactive)
175  CTL_PROTO(stats_arenas_i_pdirty)
176  CTL_PROTO(stats_arenas_i_pmuzzy)
177  CTL_PROTO(stats_arenas_i_mapped)
178  CTL_PROTO(stats_arenas_i_retained)
179  CTL_PROTO(stats_arenas_i_extent_avail)
180  CTL_PROTO(stats_arenas_i_dirty_npurge)
181  CTL_PROTO(stats_arenas_i_dirty_nmadvise)
182  CTL_PROTO(stats_arenas_i_dirty_purged)
183  CTL_PROTO(stats_arenas_i_muzzy_npurge)
184  CTL_PROTO(stats_arenas_i_muzzy_nmadvise)
185  CTL_PROTO(stats_arenas_i_muzzy_purged)
186  CTL_PROTO(stats_arenas_i_base)
187  CTL_PROTO(stats_arenas_i_internal)
188  CTL_PROTO(stats_arenas_i_metadata_thp)
189  CTL_PROTO(stats_arenas_i_tcache_bytes)
190  CTL_PROTO(stats_arenas_i_resident)
191  CTL_PROTO(stats_arenas_i_abandoned_vm)
192  INDEX_PROTO(stats_arenas_i)
193  CTL_PROTO(stats_allocated)
194  CTL_PROTO(stats_active)
195  CTL_PROTO(stats_background_thread_num_threads)
196  CTL_PROTO(stats_background_thread_num_runs)
197  CTL_PROTO(stats_background_thread_run_interval)
198  CTL_PROTO(stats_metadata)
199  CTL_PROTO(stats_metadata_thp)
200  CTL_PROTO(stats_resident)
201  CTL_PROTO(stats_mapped)
202  CTL_PROTO(stats_retained)
203  CTL_PROTO(experimental_hooks_install)
204  CTL_PROTO(experimental_hooks_remove)
205  CTL_PROTO(experimental_utilization_query)
206  CTL_PROTO(experimental_utilization_batch_query)
207  CTL_PROTO(experimental_arenas_i_pactivep)
208  INDEX_PROTO(experimental_arenas_i)
209  #define MUTEX_STATS_CTL_PROTO_GEN(n)					\
210  CTL_PROTO(stats_##n##_num_ops)						\
211  CTL_PROTO(stats_##n##_num_wait)						\
212  CTL_PROTO(stats_##n##_num_spin_acq)					\
213  CTL_PROTO(stats_##n##_num_owner_switch)					\
214  CTL_PROTO(stats_##n##_total_wait_time)					\
215  CTL_PROTO(stats_##n##_max_wait_time)					\
216  CTL_PROTO(stats_##n##_max_num_thds)
217  #define OP(mtx) MUTEX_STATS_CTL_PROTO_GEN(mutexes_##mtx)
218  MUTEX_PROF_GLOBAL_MUTEXES
219  #undef OP
220  #define OP(mtx) MUTEX_STATS_CTL_PROTO_GEN(arenas_i_mutexes_##mtx)
221  MUTEX_PROF_ARENA_MUTEXES
222  #undef OP
223  MUTEX_STATS_CTL_PROTO_GEN(arenas_i_bins_j_mutex)
224  #undef MUTEX_STATS_CTL_PROTO_GEN
225  CTL_PROTO(stats_mutexes_reset)
226  #define NAME(n)	{true},	n
227  #define CHILD(t, c)							\
228  	sizeof(c##_node) / sizeof(ctl_##t##_node_t),			\
229  	(ctl_node_t *)c##_node,						\
230  	NULL
231  #define CTL(c)	0, NULL, c##_ctl
232  #define INDEX(i)	{false},	i##_index
233  static const ctl_named_node_t	thread_tcache_node[] = {
234  	{NAME(&quot;enabled&quot;),	CTL(thread_tcache_enabled)},
235  	{NAME(&quot;flush&quot;),		CTL(thread_tcache_flush)}
236  };
237  static const ctl_named_node_t	thread_prof_node[] = {
238  	{NAME(&quot;name&quot;),		CTL(thread_prof_name)},
239  	{NAME(&quot;active&quot;),	CTL(thread_prof_active)}
240  };
241  static const ctl_named_node_t	thread_node[] = {
242  	{NAME(&quot;arena&quot;),		CTL(thread_arena)},
243  	{NAME(&quot;allocated&quot;),	CTL(thread_allocated)},
244  	{NAME(&quot;allocatedp&quot;),	CTL(thread_allocatedp)},
245  	{NAME(&quot;deallocated&quot;),	CTL(thread_deallocated)},
246  	{NAME(&quot;deallocatedp&quot;),	CTL(thread_deallocatedp)},
247  	{NAME(&quot;tcache&quot;),	CHILD(named, thread_tcache)},
248  	{NAME(&quot;prof&quot;),		CHILD(named, thread_prof)}
249  };
250  static const ctl_named_node_t	config_node[] = {
251  	{NAME(&quot;cache_oblivious&quot;), CTL(config_cache_oblivious)},
252  	{NAME(&quot;debug&quot;),		CTL(config_debug)},
253  	{NAME(&quot;fill&quot;),		CTL(config_fill)},
254  	{NAME(&quot;lazy_lock&quot;),	CTL(config_lazy_lock)},
255  	{NAME(&quot;malloc_conf&quot;),	CTL(config_malloc_conf)},
256  	{NAME(&quot;opt_safety_checks&quot;),	CTL(config_opt_safety_checks)},
257  	{NAME(&quot;prof&quot;),		CTL(config_prof)},
258  	{NAME(&quot;prof_libgcc&quot;),	CTL(config_prof_libgcc)},
259  	{NAME(&quot;prof_libunwind&quot;), CTL(config_prof_libunwind)},
260  	{NAME(&quot;stats&quot;),		CTL(config_stats)},
261  	{NAME(&quot;utrace&quot;),	CTL(config_utrace)},
262  	{NAME(&quot;xmalloc&quot;),	CTL(config_xmalloc)}
263  };
264  static const ctl_named_node_t opt_node[] = {
265  	{NAME(&quot;abort&quot;),		CTL(opt_abort)},
266  	{NAME(&quot;abort_conf&quot;),	CTL(opt_abort_conf)},
267  	{NAME(&quot;confirm_conf&quot;),	CTL(opt_confirm_conf)},
268  	{NAME(&quot;metadata_thp&quot;),	CTL(opt_metadata_thp)},
269  	{NAME(&quot;retain&quot;),	CTL(opt_retain)},
270  	{NAME(&quot;dss&quot;),		CTL(opt_dss)},
271  	{NAME(&quot;narenas&quot;),	CTL(opt_narenas)},
272  	{NAME(&quot;percpu_arena&quot;),	CTL(opt_percpu_arena)},
273  	{NAME(&quot;oversize_threshold&quot;),	CTL(opt_oversize_threshold)},
274  	{NAME(&quot;background_thread&quot;),	CTL(opt_background_thread)},
275  	{NAME(&quot;max_background_threads&quot;),	CTL(opt_max_background_threads)},
276  	{NAME(&quot;dirty_decay_ms&quot;), CTL(opt_dirty_decay_ms)},
277  	{NAME(&quot;muzzy_decay_ms&quot;), CTL(opt_muzzy_decay_ms)},
278  	{NAME(&quot;stats_print&quot;),	CTL(opt_stats_print)},
279  	{NAME(&quot;stats_print_opts&quot;),	CTL(opt_stats_print_opts)},
280  	{NAME(&quot;junk&quot;),		CTL(opt_junk)},
281  	{NAME(&quot;zero&quot;),		CTL(opt_zero)},
282  	{NAME(&quot;utrace&quot;),	CTL(opt_utrace)},
283  	{NAME(&quot;xmalloc&quot;),	CTL(opt_xmalloc)},
284  	{NAME(&quot;tcache&quot;),	CTL(opt_tcache)},
285  	{NAME(&quot;thp&quot;),		CTL(opt_thp)},
286  	{NAME(&quot;lg_extent_max_active_fit&quot;), CTL(opt_lg_extent_max_active_fit)},
287  	{NAME(&quot;lg_tcache_max&quot;),	CTL(opt_lg_tcache_max)},
288  	{NAME(&quot;prof&quot;),		CTL(opt_prof)},
289  	{NAME(&quot;prof_prefix&quot;),	CTL(opt_prof_prefix)},
290  	{NAME(&quot;prof_active&quot;),	CTL(opt_prof_active)},
291  	{NAME(&quot;prof_thread_active_init&quot;), CTL(opt_prof_thread_active_init)},
292  	{NAME(&quot;lg_prof_sample&quot;), CTL(opt_lg_prof_sample)},
293  	{NAME(&quot;lg_prof_interval&quot;), CTL(opt_lg_prof_interval)},
294  	{NAME(&quot;prof_gdump&quot;),	CTL(opt_prof_gdump)},
295  	{NAME(&quot;prof_final&quot;),	CTL(opt_prof_final)},
296  	{NAME(&quot;prof_leak&quot;),	CTL(opt_prof_leak)},
297  	{NAME(&quot;prof_accum&quot;),	CTL(opt_prof_accum)}
298  };
299  static const ctl_named_node_t	tcache_node[] = {
300  	{NAME(&quot;create&quot;),	CTL(tcache_create)},
301  	{NAME(&quot;flush&quot;),		CTL(tcache_flush)},
302  	{NAME(&quot;destroy&quot;),	CTL(tcache_destroy)}
303  };
304  static const ctl_named_node_t arena_i_node[] = {
305  	{NAME(&quot;initialized&quot;),	CTL(arena_i_initialized)},
306  	{NAME(&quot;decay&quot;),		CTL(arena_i_decay)},
307  	{NAME(&quot;purge&quot;),		CTL(arena_i_purge)},
308  	{NAME(&quot;reset&quot;),		CTL(arena_i_reset)},
309  	{NAME(&quot;destroy&quot;),	CTL(arena_i_destroy)},
310  	{NAME(&quot;dss&quot;),		CTL(arena_i_dss)},
311  	{NAME(&quot;dirty_decay_ms&quot;), CTL(arena_i_dirty_decay_ms)},
312  	{NAME(&quot;muzzy_decay_ms&quot;), CTL(arena_i_muzzy_decay_ms)},
313  	{NAME(&quot;extent_hooks&quot;),	CTL(arena_i_extent_hooks)},
314  	{NAME(&quot;retain_grow_limit&quot;),	CTL(arena_i_retain_grow_limit)}
315  };
316  static const ctl_named_node_t super_arena_i_node[] = {
317  	{NAME(&quot;&quot;),		CHILD(named, arena_i)}
318  };
319  static const ctl_indexed_node_t arena_node[] = {
320  	{INDEX(arena_i)}
321  };
322  static const ctl_named_node_t arenas_bin_i_node[] = {
323  	{NAME(&quot;size&quot;),		CTL(arenas_bin_i_size)},
324  	{NAME(&quot;nregs&quot;),		CTL(arenas_bin_i_nregs)},
325  	{NAME(&quot;slab_size&quot;),	CTL(arenas_bin_i_slab_size)},
326  	{NAME(&quot;nshards&quot;),	CTL(arenas_bin_i_nshards)}
327  };
328  static const ctl_named_node_t super_arenas_bin_i_node[] = {
329  	{NAME(&quot;&quot;),		CHILD(named, arenas_bin_i)}
330  };
331  static const ctl_indexed_node_t arenas_bin_node[] = {
332  	{INDEX(arenas_bin_i)}
333  };
334  static const ctl_named_node_t arenas_lextent_i_node[] = {
335  	{NAME(&quot;size&quot;),		CTL(arenas_lextent_i_size)}
336  };
337  static const ctl_named_node_t super_arenas_lextent_i_node[] = {
338  	{NAME(&quot;&quot;),		CHILD(named, arenas_lextent_i)}
339  };
340  static const ctl_indexed_node_t arenas_lextent_node[] = {
341  	{INDEX(arenas_lextent_i)}
342  };
343  static const ctl_named_node_t arenas_node[] = {
344  	{NAME(&quot;narenas&quot;),	CTL(arenas_narenas)},
345  	{NAME(&quot;dirty_decay_ms&quot;), CTL(arenas_dirty_decay_ms)},
346  	{NAME(&quot;muzzy_decay_ms&quot;), CTL(arenas_muzzy_decay_ms)},
347  	{NAME(&quot;quantum&quot;),	CTL(arenas_quantum)},
348  	{NAME(&quot;page&quot;),		CTL(arenas_page)},
349  	{NAME(&quot;tcache_max&quot;),	CTL(arenas_tcache_max)},
350  	{NAME(&quot;nbins&quot;),		CTL(arenas_nbins)},
351  	{NAME(&quot;nhbins&quot;),	CTL(arenas_nhbins)},
352  	{NAME(&quot;bin&quot;),		CHILD(indexed, arenas_bin)},
353  	{NAME(&quot;nlextents&quot;),	CTL(arenas_nlextents)},
354  	{NAME(&quot;lextent&quot;),	CHILD(indexed, arenas_lextent)},
355  	{NAME(&quot;create&quot;),	CTL(arenas_create)},
356  	{NAME(&quot;lookup&quot;),	CTL(arenas_lookup)}
357  };
358  static const ctl_named_node_t	prof_node[] = {
359  	{NAME(&quot;thread_active_init&quot;), CTL(prof_thread_active_init)},
360  	{NAME(&quot;active&quot;),	CTL(prof_active)},
361  	{NAME(&quot;dump&quot;),		CTL(prof_dump)},
362  	{NAME(&quot;gdump&quot;),		CTL(prof_gdump)},
363  	{NAME(&quot;reset&quot;),		CTL(prof_reset)},
364  	{NAME(&quot;interval&quot;),	CTL(prof_interval)},
365  	{NAME(&quot;lg_sample&quot;),	CTL(lg_prof_sample)},
366  	{NAME(&quot;log_start&quot;),	CTL(prof_log_start)},
367  	{NAME(&quot;log_stop&quot;),	CTL(prof_log_stop)}
368  };
369  static const ctl_named_node_t stats_arenas_i_small_node[] = {
370  	{NAME(&quot;allocated&quot;),	CTL(stats_arenas_i_small_allocated)},
371  	{NAME(&quot;nmalloc&quot;),	CTL(stats_arenas_i_small_nmalloc)},
372  	{NAME(&quot;ndalloc&quot;),	CTL(stats_arenas_i_small_ndalloc)},
373  	{NAME(&quot;nrequests&quot;),	CTL(stats_arenas_i_small_nrequests)},
374  	{NAME(&quot;nfills&quot;),	CTL(stats_arenas_i_small_nfills)},
375  	{NAME(&quot;nflushes&quot;),	CTL(stats_arenas_i_small_nflushes)}
376  };
377  static const ctl_named_node_t stats_arenas_i_large_node[] = {
378  	{NAME(&quot;allocated&quot;),	CTL(stats_arenas_i_large_allocated)},
379  	{NAME(&quot;nmalloc&quot;),	CTL(stats_arenas_i_large_nmalloc)},
380  	{NAME(&quot;ndalloc&quot;),	CTL(stats_arenas_i_large_ndalloc)},
381  	{NAME(&quot;nrequests&quot;),	CTL(stats_arenas_i_large_nrequests)},
382  	{NAME(&quot;nfills&quot;),	CTL(stats_arenas_i_large_nfills)},
383  	{NAME(&quot;nflushes&quot;),	CTL(stats_arenas_i_large_nflushes)}
384  };
385  #define MUTEX_PROF_DATA_NODE(prefix)					\
386  static const ctl_named_node_t stats_##prefix##_node[] = {		\
387  	{NAME(&quot;num_ops&quot;),						\
388  	 CTL(stats_##prefix##_num_ops)},				\
389  	{NAME(&quot;num_wait&quot;),						\
390  	 CTL(stats_##prefix##_num_wait)},				\
391  	{NAME(&quot;num_spin_acq&quot;),						\
392  	 CTL(stats_##prefix##_num_spin_acq)},				\
393  	{NAME(&quot;num_owner_switch&quot;),					\
394  	 CTL(stats_##prefix##_num_owner_switch)},			\
395  	{NAME(&quot;total_wait_time&quot;),					\
396  	 CTL(stats_##prefix##_total_wait_time)},			\
397  	{NAME(&quot;max_wait_time&quot;),						\
398  	 CTL(stats_##prefix##_max_wait_time)},				\
399  	{NAME(&quot;max_num_thds&quot;),						\
400  	 CTL(stats_##prefix##_max_num_thds)}				\
401  		\
402  };
403  MUTEX_PROF_DATA_NODE(arenas_i_bins_j_mutex)
404  static const ctl_named_node_t stats_arenas_i_bins_j_node[] = {
405  	{NAME(&quot;nmalloc&quot;),	CTL(stats_arenas_i_bins_j_nmalloc)},
406  	{NAME(&quot;ndalloc&quot;),	CTL(stats_arenas_i_bins_j_ndalloc)},
407  	{NAME(&quot;nrequests&quot;),	CTL(stats_arenas_i_bins_j_nrequests)},
408  	{NAME(&quot;curregs&quot;),	CTL(stats_arenas_i_bins_j_curregs)},
409  	{NAME(&quot;nfills&quot;),	CTL(stats_arenas_i_bins_j_nfills)},
410  	{NAME(&quot;nflushes&quot;),	CTL(stats_arenas_i_bins_j_nflushes)},
411  	{NAME(&quot;nslabs&quot;),	CTL(stats_arenas_i_bins_j_nslabs)},
412  	{NAME(&quot;nreslabs&quot;),	CTL(stats_arenas_i_bins_j_nreslabs)},
413  	{NAME(&quot;curslabs&quot;),	CTL(stats_arenas_i_bins_j_curslabs)},
414  	{NAME(&quot;nonfull_slabs&quot;),	CTL(stats_arenas_i_bins_j_nonfull_slabs)},
415  	{NAME(&quot;mutex&quot;),		CHILD(named, stats_arenas_i_bins_j_mutex)}
416  };
417  static const ctl_named_node_t super_stats_arenas_i_bins_j_node[] = {
418  	{NAME(&quot;&quot;),		CHILD(named, stats_arenas_i_bins_j)}
419  };
420  static const ctl_indexed_node_t stats_arenas_i_bins_node[] = {
421  	{INDEX(stats_arenas_i_bins_j)}
422  };
423  static const ctl_named_node_t stats_arenas_i_lextents_j_node[] = {
424  	{NAME(&quot;nmalloc&quot;),	CTL(stats_arenas_i_lextents_j_nmalloc)},
425  	{NAME(&quot;ndalloc&quot;),	CTL(stats_arenas_i_lextents_j_ndalloc)},
426  	{NAME(&quot;nrequests&quot;),	CTL(stats_arenas_i_lextents_j_nrequests)},
427  	{NAME(&quot;curlextents&quot;),	CTL(stats_arenas_i_lextents_j_curlextents)}
428  };
429  static const ctl_named_node_t super_stats_arenas_i_lextents_j_node[] = {
430  	{NAME(&quot;&quot;),		CHILD(named, stats_arenas_i_lextents_j)}
431  };
432  static const ctl_indexed_node_t stats_arenas_i_lextents_node[] = {
433  	{INDEX(stats_arenas_i_lextents_j)}
434  };
435  static const ctl_named_node_t stats_arenas_i_extents_j_node[] = {
436  	{NAME(&quot;ndirty&quot;),	CTL(stats_arenas_i_extents_j_ndirty)},
437  	{NAME(&quot;nmuzzy&quot;),	CTL(stats_arenas_i_extents_j_nmuzzy)},
438  	{NAME(&quot;nretained&quot;),	CTL(stats_arenas_i_extents_j_nretained)},
439  	{NAME(&quot;dirty_bytes&quot;),	CTL(stats_arenas_i_extents_j_dirty_bytes)},
440  	{NAME(&quot;muzzy_bytes&quot;),	CTL(stats_arenas_i_extents_j_muzzy_bytes)},
441  	{NAME(&quot;retained_bytes&quot;), CTL(stats_arenas_i_extents_j_retained_bytes)}
442  };
443  static const ctl_named_node_t super_stats_arenas_i_extents_j_node[] = {
444  	{NAME(&quot;&quot;),		CHILD(named, stats_arenas_i_extents_j)}
445  };
446  static const ctl_indexed_node_t stats_arenas_i_extents_node[] = {
447  	{INDEX(stats_arenas_i_extents_j)}
448  };
449  #define OP(mtx)  MUTEX_PROF_DATA_NODE(arenas_i_mutexes_##mtx)
450  MUTEX_PROF_ARENA_MUTEXES
451  #undef OP
452  static const ctl_named_node_t stats_arenas_i_mutexes_node[] = {
453  #define OP(mtx) {NAME(#mtx), CHILD(named, stats_arenas_i_mutexes_##mtx)},
454  MUTEX_PROF_ARENA_MUTEXES
455  #undef OP
456  };
457  static const ctl_named_node_t stats_arenas_i_node[] = {
458  	{NAME(&quot;nthreads&quot;),	CTL(stats_arenas_i_nthreads)},
459  	{NAME(&quot;uptime&quot;),	CTL(stats_arenas_i_uptime)},
460  	{NAME(&quot;dss&quot;),		CTL(stats_arenas_i_dss)},
461  	{NAME(&quot;dirty_decay_ms&quot;), CTL(stats_arenas_i_dirty_decay_ms)},
462  	{NAME(&quot;muzzy_decay_ms&quot;), CTL(stats_arenas_i_muzzy_decay_ms)},
463  	{NAME(&quot;pactive&quot;),	CTL(stats_arenas_i_pactive)},
464  	{NAME(&quot;pdirty&quot;),	CTL(stats_arenas_i_pdirty)},
465  	{NAME(&quot;pmuzzy&quot;),	CTL(stats_arenas_i_pmuzzy)},
466  	{NAME(&quot;mapped&quot;),	CTL(stats_arenas_i_mapped)},
467  	{NAME(&quot;retained&quot;),	CTL(stats_arenas_i_retained)},
468  	{NAME(&quot;extent_avail&quot;),	CTL(stats_arenas_i_extent_avail)},
469  	{NAME(&quot;dirty_npurge&quot;),	CTL(stats_arenas_i_dirty_npurge)},
470  	{NAME(&quot;dirty_nmadvise&quot;), CTL(stats_arenas_i_dirty_nmadvise)},
471  	{NAME(&quot;dirty_purged&quot;),	CTL(stats_arenas_i_dirty_purged)},
472  	{NAME(&quot;muzzy_npurge&quot;),	CTL(stats_arenas_i_muzzy_npurge)},
473  	{NAME(&quot;muzzy_nmadvise&quot;), CTL(stats_arenas_i_muzzy_nmadvise)},
474  	{NAME(&quot;muzzy_purged&quot;),	CTL(stats_arenas_i_muzzy_purged)},
475  	{NAME(&quot;base&quot;),		CTL(stats_arenas_i_base)},
476  	{NAME(&quot;internal&quot;),	CTL(stats_arenas_i_internal)},
477  	{NAME(&quot;metadata_thp&quot;),	CTL(stats_arenas_i_metadata_thp)},
478  	{NAME(&quot;tcache_bytes&quot;),	CTL(stats_arenas_i_tcache_bytes)},
479  	{NAME(&quot;resident&quot;),	CTL(stats_arenas_i_resident)},
480  	{NAME(&quot;abandoned_vm&quot;),	CTL(stats_arenas_i_abandoned_vm)},
481  	{NAME(&quot;small&quot;),		CHILD(named, stats_arenas_i_small)},
482  	{NAME(&quot;large&quot;),		CHILD(named, stats_arenas_i_large)},
483  	{NAME(&quot;bins&quot;),		CHILD(indexed, stats_arenas_i_bins)},
484  	{NAME(&quot;lextents&quot;),	CHILD(indexed, stats_arenas_i_lextents)},
485  	{NAME(&quot;extents&quot;),	CHILD(indexed, stats_arenas_i_extents)},
486  	{NAME(&quot;mutexes&quot;),	CHILD(named, stats_arenas_i_mutexes)}
487  };
488  static const ctl_named_node_t super_stats_arenas_i_node[] = {
489  	{NAME(&quot;&quot;),		CHILD(named, stats_arenas_i)}
490  };
491  static const ctl_indexed_node_t stats_arenas_node[] = {
492  	{INDEX(stats_arenas_i)}
493  };
494  static const ctl_named_node_t stats_background_thread_node[] = {
495  	{NAME(&quot;num_threads&quot;),	CTL(stats_background_thread_num_threads)},
496  	{NAME(&quot;num_runs&quot;),	CTL(stats_background_thread_num_runs)},
497  	{NAME(&quot;run_interval&quot;),	CTL(stats_background_thread_run_interval)}
498  };
499  #define OP(mtx) MUTEX_PROF_DATA_NODE(mutexes_##mtx)
500  MUTEX_PROF_GLOBAL_MUTEXES
501  #undef OP
502  static const ctl_named_node_t stats_mutexes_node[] = {
503  #define OP(mtx) {NAME(#mtx), CHILD(named, stats_mutexes_##mtx)},
504  MUTEX_PROF_GLOBAL_MUTEXES
505  #undef OP
506  	{NAME(&quot;reset&quot;),		CTL(stats_mutexes_reset)}
507  };
508  #undef MUTEX_PROF_DATA_NODE
509  static const ctl_named_node_t stats_node[] = {
510  	{NAME(&quot;allocated&quot;),	CTL(stats_allocated)},
511  	{NAME(&quot;active&quot;),	CTL(stats_active)},
512  	{NAME(&quot;metadata&quot;),	CTL(stats_metadata)},
513  	{NAME(&quot;metadata_thp&quot;),	CTL(stats_metadata_thp)},
514  	{NAME(&quot;resident&quot;),	CTL(stats_resident)},
515  	{NAME(&quot;mapped&quot;),	CTL(stats_mapped)},
516  	{NAME(&quot;retained&quot;),	CTL(stats_retained)},
517  	{NAME(&quot;background_thread&quot;),
518  	 CHILD(named, stats_background_thread)},
519  	{NAME(&quot;mutexes&quot;),	CHILD(named, stats_mutexes)},
520  	{NAME(&quot;arenas&quot;),	CHILD(indexed, stats_arenas)}
521  };
522  static const ctl_named_node_t experimental_hooks_node[] = {
523  	{NAME(&quot;install&quot;),	CTL(experimental_hooks_install)},
524  	{NAME(&quot;remove&quot;),	CTL(experimental_hooks_remove)}
525  };
526  static const ctl_named_node_t experimental_utilization_node[] = {
527  	{NAME(&quot;query&quot;),		CTL(experimental_utilization_query)},
528  	{NAME(&quot;batch_query&quot;),	CTL(experimental_utilization_batch_query)}
529  };
530  static const ctl_named_node_t experimental_arenas_i_node[] = {
531  	{NAME(&quot;pactivep&quot;),	CTL(experimental_arenas_i_pactivep)}
532  };
533  static const ctl_named_node_t super_experimental_arenas_i_node[] = {
534  	{NAME(&quot;&quot;),		CHILD(named, experimental_arenas_i)}
535  };
536  static const ctl_indexed_node_t experimental_arenas_node[] = {
537  	{INDEX(experimental_arenas_i)}
538  };
539  static const ctl_named_node_t experimental_node[] = {
540  	{NAME(&quot;hooks&quot;),		CHILD(named, experimental_hooks)},
541  	{NAME(&quot;utilization&quot;),	CHILD(named, experimental_utilization)},
542  	{NAME(&quot;arenas&quot;),	CHILD(indexed, experimental_arenas)}
543  };
544  static const ctl_named_node_t	root_node[] = {
545  	{NAME(&quot;version&quot;),	CTL(version)},
546  	{NAME(&quot;epoch&quot;),		CTL(epoch)},
547  	{NAME(&quot;background_thread&quot;),	CTL(background_thread)},
548  	{NAME(&quot;max_background_threads&quot;),	CTL(max_background_threads)},
549  	{NAME(&quot;thread&quot;),	CHILD(named, thread)},
550  	{NAME(&quot;config&quot;),	CHILD(named, config)},
551  	{NAME(&quot;opt&quot;),		CHILD(named, opt)},
552  	{NAME(&quot;tcache&quot;),	CHILD(named, tcache)},
553  	{NAME(&quot;arena&quot;),		CHILD(indexed, arena)},
554  	{NAME(&quot;arenas&quot;),	CHILD(named, arenas)},
555  	{NAME(&quot;prof&quot;),		CHILD(named, prof)},
556  	{NAME(&quot;stats&quot;),		CHILD(named, stats)},
557  	{NAME(&quot;experimental&quot;),	CHILD(named, experimental)}
558  };
559  static const ctl_named_node_t super_root_node[] = {
560  	{NAME(&quot;&quot;),		CHILD(named, root)}
561  };
562  #undef NAME
563  #undef CHILD
564  #undef CTL
565  #undef INDEX
566  static void
567  ctl_accum_arena_stats_u64(arena_stats_u64_t *dst, arena_stats_u64_t *src) {
568  #ifdef JEMALLOC_ATOMIC_U64
569  	uint64_t cur_dst = atomic_load_u64(dst, ATOMIC_RELAXED);
570  	uint64_t cur_src = atomic_load_u64(src, ATOMIC_RELAXED);
571  	atomic_store_u64(dst, cur_dst + cur_src, ATOMIC_RELAXED);
572  #else
573  	*dst += *src;
574  #endif
575  }
576  static uint64_t
577  ctl_arena_stats_read_u64(arena_stats_u64_t *p) {
578  #ifdef JEMALLOC_ATOMIC_U64
579  	return atomic_load_u64(p, ATOMIC_RELAXED);
580  #else
581  	return *p;
582  #endif
583  }
584  static void
585  accum_atomic_zu(atomic_zu_t *dst, atomic_zu_t *src) {
586  	size_t cur_dst = atomic_load_zu(dst, ATOMIC_RELAXED);
587  	size_t cur_src = atomic_load_zu(src, ATOMIC_RELAXED);
588  	atomic_store_zu(dst, cur_dst + cur_src, ATOMIC_RELAXED);
589  }
590  static unsigned
591  arenas_i2a_impl(size_t i, bool compat, bool validate) {
592  	unsigned a;
593  	switch (i) {
594  	case MALLCTL_ARENAS_ALL:
595  		a = 0;
596  		break;
597  	case MALLCTL_ARENAS_DESTROYED:
598  		a = 1;
599  		break;
600  	default:
601  		if (compat &amp;&amp; i == ctl_arenas-&gt;narenas) {
602  			a = 0;
603  		} else if (validate &amp;&amp; i &gt;= ctl_arenas-&gt;narenas) {
604  			a = UINT_MAX;
605  		} else {
606  			assert(i &lt; ctl_arenas-&gt;narenas || (!validate &amp;&amp; i ==
607  			    ctl_arenas-&gt;narenas));
608  			a = (unsigned)i + 2;
609  		}
610  		break;
611  	}
612  	return a;
613  }
614  static unsigned
615  arenas_i2a(size_t i) {
616  	return arenas_i2a_impl(i, true, false);
617  }
618  static ctl_arena_t *
619  arenas_i_impl(tsd_t *tsd, size_t i, bool compat, bool init) {
620  	ctl_arena_t *ret;
621  	assert(!compat || !init);
622  	ret = ctl_arenas-&gt;arenas[arenas_i2a_impl(i, compat, false)];
623  	if (init &amp;&amp; ret == NULL) {
624  		if (config_stats) {
625  			struct container_s {
626  				ctl_arena_t		ctl_arena;
627  				ctl_arena_stats_t	astats;
628  			};
629  			struct container_s *cont =
630  			    (struct container_s *)base_alloc(tsd_tsdn(tsd),
631  			    b0get(), sizeof(struct container_s), QUANTUM);
632  			if (cont == NULL) {
633  				return NULL;
634  			}
635  			ret = &amp;cont-&gt;ctl_arena;
636  			ret-&gt;astats = &amp;cont-&gt;astats;
637  		} else {
638  			ret = (ctl_arena_t *)base_alloc(tsd_tsdn(tsd), b0get(),
639  			    sizeof(ctl_arena_t), QUANTUM);
640  			if (ret == NULL) {
641  				return NULL;
642  			}
643  		}
644  		ret-&gt;arena_ind = (unsigned)i;
645  		ctl_arenas-&gt;arenas[arenas_i2a_impl(i, compat, false)] = ret;
646  	}
647  	assert(ret == NULL || arenas_i2a(ret-&gt;arena_ind) == arenas_i2a(i));
648  	return ret;
649  }
650  static ctl_arena_t *
651  arenas_i(size_t i) {
652  	ctl_arena_t *ret = arenas_i_impl(tsd_fetch(), i, true, false);
653  	assert(ret != NULL);
654  	return ret;
655  }
656  static void
657  ctl_arena_clear(ctl_arena_t *ctl_arena) {
658  	ctl_arena-&gt;nthreads = 0;
659  	ctl_arena-&gt;dss = dss_prec_names[dss_prec_limit];
660  	ctl_arena-&gt;dirty_decay_ms = -1;
661  	ctl_arena-&gt;muzzy_decay_ms = -1;
662  	ctl_arena-&gt;pactive = 0;
663  	ctl_arena-&gt;pdirty = 0;
664  	ctl_arena-&gt;pmuzzy = 0;
665  	if (config_stats) {
666  		memset(&amp;ctl_arena-&gt;astats-&gt;astats, 0, sizeof(arena_stats_t));
667  		ctl_arena-&gt;astats-&gt;allocated_small = 0;
668  		ctl_arena-&gt;astats-&gt;nmalloc_small = 0;
669  		ctl_arena-&gt;astats-&gt;ndalloc_small = 0;
670  		ctl_arena-&gt;astats-&gt;nrequests_small = 0;
671  		ctl_arena-&gt;astats-&gt;nfills_small = 0;
672  		ctl_arena-&gt;astats-&gt;nflushes_small = 0;
673  		memset(ctl_arena-&gt;astats-&gt;bstats, 0, SC_NBINS *
674  		    sizeof(bin_stats_t));
675  		memset(ctl_arena-&gt;astats-&gt;lstats, 0, (SC_NSIZES - SC_NBINS) *
676  		    sizeof(arena_stats_large_t));
677  		memset(ctl_arena-&gt;astats-&gt;estats, 0, SC_NPSIZES *
678  		    sizeof(arena_stats_extents_t));
679  	}
680  }
681  static void
682  ctl_arena_stats_amerge(tsdn_t *tsdn, ctl_arena_t *ctl_arena, arena_t *arena) {
683  	unsigned i;
684  	if (config_stats) {
685  		arena_stats_merge(tsdn, arena, &amp;ctl_arena-&gt;nthreads,
686  		    &amp;ctl_arena-&gt;dss, &amp;ctl_arena-&gt;dirty_decay_ms,
687  		    &amp;ctl_arena-&gt;muzzy_decay_ms, &amp;ctl_arena-&gt;pactive,
688  		    &amp;ctl_arena-&gt;pdirty, &amp;ctl_arena-&gt;pmuzzy,
689  		    &amp;ctl_arena-&gt;astats-&gt;astats, ctl_arena-&gt;astats-&gt;bstats,
690  		    ctl_arena-&gt;astats-&gt;lstats, ctl_arena-&gt;astats-&gt;estats);
691  		for (i = 0; i &lt; SC_NBINS; i++) {
692  			ctl_arena-&gt;astats-&gt;allocated_small +=
693  			    ctl_arena-&gt;astats-&gt;bstats[i].curregs *
694  			    sz_index2size(i);
695  			ctl_arena-&gt;astats-&gt;nmalloc_small +=
696  			    ctl_arena-&gt;astats-&gt;bstats[i].nmalloc;
697  			ctl_arena-&gt;astats-&gt;ndalloc_small +=
698  			    ctl_arena-&gt;astats-&gt;bstats[i].ndalloc;
699  			ctl_arena-&gt;astats-&gt;nrequests_small +=
700  			    ctl_arena-&gt;astats-&gt;bstats[i].nrequests;
701  			ctl_arena-&gt;astats-&gt;nfills_small +=
702  			    ctl_arena-&gt;astats-&gt;bstats[i].nfills;
703  			ctl_arena-&gt;astats-&gt;nflushes_small +=
704  			    ctl_arena-&gt;astats-&gt;bstats[i].nflushes;
705  		}
706  	} else {
707  		arena_basic_stats_merge(tsdn, arena, &amp;ctl_arena-&gt;nthreads,
708  		    &amp;ctl_arena-&gt;dss, &amp;ctl_arena-&gt;dirty_decay_ms,
709  		    &amp;ctl_arena-&gt;muzzy_decay_ms, &amp;ctl_arena-&gt;pactive,
710  		    &amp;ctl_arena-&gt;pdirty, &amp;ctl_arena-&gt;pmuzzy);
711  	}
712  }
713  static void
714  ctl_arena_stats_sdmerge(ctl_arena_t *ctl_sdarena, ctl_arena_t *ctl_arena,
715      bool destroyed) {
716  	unsigned i;
717  	if (!destroyed) {
718  		ctl_sdarena-&gt;nthreads += ctl_arena-&gt;nthreads;
719  		ctl_sdarena-&gt;pactive += ctl_arena-&gt;pactive;
720  		ctl_sdarena-&gt;pdirty += ctl_arena-&gt;pdirty;
721  		ctl_sdarena-&gt;pmuzzy += ctl_arena-&gt;pmuzzy;
722  	} else {
723  		assert(ctl_arena-&gt;nthreads == 0);
724  		assert(ctl_arena-&gt;pactive == 0);
725  		assert(ctl_arena-&gt;pdirty == 0);
726  		assert(ctl_arena-&gt;pmuzzy == 0);
727  	}
728  	if (config_stats) {
729  		ctl_arena_stats_t *sdstats = ctl_sdarena-&gt;astats;
730  		ctl_arena_stats_t *astats = ctl_arena-&gt;astats;
731  		if (!destroyed) {
732  			accum_atomic_zu(&amp;sdstats-&gt;astats.mapped,
733  			    &amp;astats-&gt;astats.mapped);
734  			accum_atomic_zu(&amp;sdstats-&gt;astats.retained,
735  			    &amp;astats-&gt;astats.retained);
736  			accum_atomic_zu(&amp;sdstats-&gt;astats.extent_avail,
737  			    &amp;astats-&gt;astats.extent_avail);
738  		}
739  		ctl_accum_arena_stats_u64(&amp;sdstats-&gt;astats.decay_dirty.npurge,
740  		    &amp;astats-&gt;astats.decay_dirty.npurge);
741  		ctl_accum_arena_stats_u64(&amp;sdstats-&gt;astats.decay_dirty.nmadvise,
742  		    &amp;astats-&gt;astats.decay_dirty.nmadvise);
743  		ctl_accum_arena_stats_u64(&amp;sdstats-&gt;astats.decay_dirty.purged,
744  		    &amp;astats-&gt;astats.decay_dirty.purged);
745  		ctl_accum_arena_stats_u64(&amp;sdstats-&gt;astats.decay_muzzy.npurge,
746  		    &amp;astats-&gt;astats.decay_muzzy.npurge);
747  		ctl_accum_arena_stats_u64(&amp;sdstats-&gt;astats.decay_muzzy.nmadvise,
748  		    &amp;astats-&gt;astats.decay_muzzy.nmadvise);
749  		ctl_accum_arena_stats_u64(&amp;sdstats-&gt;astats.decay_muzzy.purged,
750  		    &amp;astats-&gt;astats.decay_muzzy.purged);
751  #define OP(mtx) malloc_mutex_prof_merge(				\
752  		    &amp;(sdstats-&gt;astats.mutex_prof_data[			\
753  		        arena_prof_mutex_##mtx]),			\
754  		    &amp;(astats-&gt;astats.mutex_prof_data[			\
755  		        arena_prof_mutex_##mtx]));
756  MUTEX_PROF_ARENA_MUTEXES
757  #undef OP
758  		if (!destroyed) {
759  			accum_atomic_zu(&amp;sdstats-&gt;astats.base,
760  			    &amp;astats-&gt;astats.base);
761  			accum_atomic_zu(&amp;sdstats-&gt;astats.internal,
762  			    &amp;astats-&gt;astats.internal);
763  			accum_atomic_zu(&amp;sdstats-&gt;astats.resident,
764  			    &amp;astats-&gt;astats.resident);
765  			accum_atomic_zu(&amp;sdstats-&gt;astats.metadata_thp,
766  			    &amp;astats-&gt;astats.metadata_thp);
767  		} else {
768  			assert(atomic_load_zu(
769  			    &amp;astats-&gt;astats.internal, ATOMIC_RELAXED) == 0);
770  		}
771  		if (!destroyed) {
772  			sdstats-&gt;allocated_small += astats-&gt;allocated_small;
773  		} else {
774  			assert(astats-&gt;allocated_small == 0);
775  		}
776  		sdstats-&gt;nmalloc_small += astats-&gt;nmalloc_small;
777  		sdstats-&gt;ndalloc_small += astats-&gt;ndalloc_small;
778  		sdstats-&gt;nrequests_small += astats-&gt;nrequests_small;
779  		sdstats-&gt;nfills_small += astats-&gt;nfills_small;
780  		sdstats-&gt;nflushes_small += astats-&gt;nflushes_small;
781  		if (!destroyed) {
782  			accum_atomic_zu(&amp;sdstats-&gt;astats.allocated_large,
783  			    &amp;astats-&gt;astats.allocated_large);
784  		} else {
785  			assert(atomic_load_zu(&amp;astats-&gt;astats.allocated_large,
786  			    ATOMIC_RELAXED) == 0);
787  		}
788  		ctl_accum_arena_stats_u64(&amp;sdstats-&gt;astats.nmalloc_large,
789  		    &amp;astats-&gt;astats.nmalloc_large);
790  		ctl_accum_arena_stats_u64(&amp;sdstats-&gt;astats.ndalloc_large,
791  		    &amp;astats-&gt;astats.ndalloc_large);
792  		ctl_accum_arena_stats_u64(&amp;sdstats-&gt;astats.nrequests_large,
793  		    &amp;astats-&gt;astats.nrequests_large);
794  		accum_atomic_zu(&amp;sdstats-&gt;astats.abandoned_vm,
795  		    &amp;astats-&gt;astats.abandoned_vm);
796  		accum_atomic_zu(&amp;sdstats-&gt;astats.tcache_bytes,
797  		    &amp;astats-&gt;astats.tcache_bytes);
798  		if (ctl_arena-&gt;arena_ind == 0) {
799  			sdstats-&gt;astats.uptime = astats-&gt;astats.uptime;
800  		}
801  		for (i = 0; i &lt; SC_NBINS; i++) {
802  			sdstats-&gt;bstats[i].nmalloc += astats-&gt;bstats[i].nmalloc;
803  			sdstats-&gt;bstats[i].ndalloc += astats-&gt;bstats[i].ndalloc;
804  			sdstats-&gt;bstats[i].nrequests +=
805  			    astats-&gt;bstats[i].nrequests;
806  			if (!destroyed) {
807  				sdstats-&gt;bstats[i].curregs +=
808  				    astats-&gt;bstats[i].curregs;
809  			} else {
810  				assert(astats-&gt;bstats[i].curregs == 0);
811  			}
812  			sdstats-&gt;bstats[i].nfills += astats-&gt;bstats[i].nfills;
813  			sdstats-&gt;bstats[i].nflushes +=
814  			    astats-&gt;bstats[i].nflushes;
815  			sdstats-&gt;bstats[i].nslabs += astats-&gt;bstats[i].nslabs;
816  			sdstats-&gt;bstats[i].reslabs += astats-&gt;bstats[i].reslabs;
817  			if (!destroyed) {
818  				sdstats-&gt;bstats[i].curslabs +=
819  				    astats-&gt;bstats[i].curslabs;
820  				sdstats-&gt;bstats[i].nonfull_slabs +=
821  				    astats-&gt;bstats[i].nonfull_slabs;
822  			} else {
823  				assert(astats-&gt;bstats[i].curslabs == 0);
824  				assert(astats-&gt;bstats[i].nonfull_slabs == 0);
825  			}
826  			malloc_mutex_prof_merge(&amp;sdstats-&gt;bstats[i].mutex_data,
827  			    &amp;astats-&gt;bstats[i].mutex_data);
828  		}
829  		for (i = 0; i &lt; SC_NSIZES - SC_NBINS; i++) {
830  			ctl_accum_arena_stats_u64(&amp;sdstats-&gt;lstats[i].nmalloc,
831  			    &amp;astats-&gt;lstats[i].nmalloc);
832  			ctl_accum_arena_stats_u64(&amp;sdstats-&gt;lstats[i].ndalloc,
833  			    &amp;astats-&gt;lstats[i].ndalloc);
834  			ctl_accum_arena_stats_u64(&amp;sdstats-&gt;lstats[i].nrequests,
835  			    &amp;astats-&gt;lstats[i].nrequests);
836  			if (!destroyed) {
837  				sdstats-&gt;lstats[i].curlextents +=
838  				    astats-&gt;lstats[i].curlextents;
839  			} else {
840  				assert(astats-&gt;lstats[i].curlextents == 0);
841  			}
842  		}
843  		for (i = 0; i &lt; SC_NPSIZES; i++) {
844  			accum_atomic_zu(&amp;sdstats-&gt;estats[i].ndirty,
845  			    &amp;astats-&gt;estats[i].ndirty);
846  			accum_atomic_zu(&amp;sdstats-&gt;estats[i].nmuzzy,
847  			    &amp;astats-&gt;estats[i].nmuzzy);
848  			accum_atomic_zu(&amp;sdstats-&gt;estats[i].nretained,
849  			    &amp;astats-&gt;estats[i].nretained);
850  			accum_atomic_zu(&amp;sdstats-&gt;estats[i].dirty_bytes,
851  			    &amp;astats-&gt;estats[i].dirty_bytes);
852  			accum_atomic_zu(&amp;sdstats-&gt;estats[i].muzzy_bytes,
853  			    &amp;astats-&gt;estats[i].muzzy_bytes);
854  			accum_atomic_zu(&amp;sdstats-&gt;estats[i].retained_bytes,
855  			    &amp;astats-&gt;estats[i].retained_bytes);
856  		}
857  	}
858  }
859  static void
860  ctl_arena_refresh(tsdn_t *tsdn, arena_t *arena, ctl_arena_t *ctl_sdarena,
861      unsigned i, bool destroyed) {
862  	ctl_arena_t *ctl_arena = arenas_i(i);
863  	ctl_arena_clear(ctl_arena);
864  	ctl_arena_stats_amerge(tsdn, ctl_arena, arena);
865  	ctl_arena_stats_sdmerge(ctl_sdarena, ctl_arena, destroyed);
866  }
867  static unsigned
868  ctl_arena_init(tsd_t *tsd, extent_hooks_t *extent_hooks) {
869  	unsigned arena_ind;
870  	ctl_arena_t *ctl_arena;
871  	if ((ctl_arena = ql_last(&amp;ctl_arenas-&gt;destroyed, destroyed_link)) !=
872  	    NULL) {
873  		ql_remove(&amp;ctl_arenas-&gt;destroyed, ctl_arena, destroyed_link);
874  		arena_ind = ctl_arena-&gt;arena_ind;
875  	} else {
876  		arena_ind = ctl_arenas-&gt;narenas;
877  	}
878  	if (arenas_i_impl(tsd, arena_ind, false, true) == NULL) {
879  		return UINT_MAX;
880  	}
881  	if (arena_init(tsd_tsdn(tsd), arena_ind, extent_hooks) == NULL) {
882  		return UINT_MAX;
883  	}
884  	if (arena_ind == ctl_arenas-&gt;narenas) {
885  		ctl_arenas-&gt;narenas++;
886  	}
887  	return arena_ind;
888  }
889  static void
890  ctl_background_thread_stats_read(tsdn_t *tsdn) {
891  	background_thread_stats_t *stats = &amp;ctl_stats-&gt;background_thread;
892  	if (!have_background_thread ||
893  	    background_thread_stats_read(tsdn, stats)) {
894  		memset(stats, 0, sizeof(background_thread_stats_t));
895  		nstime_init(&amp;stats-&gt;run_interval, 0);
896  	}
897  }
898  static void
899  ctl_refresh(tsdn_t *tsdn) {
900  	unsigned i;
901  	ctl_arena_t *ctl_sarena = arenas_i(MALLCTL_ARENAS_ALL);
902  	VARIABLE_ARRAY(arena_t *, tarenas, ctl_arenas-&gt;narenas);
903  	ctl_arena_clear(ctl_sarena);
904  	for (i = 0; i &lt; ctl_arenas-&gt;narenas; i++) {
905  		tarenas[i] = arena_get(tsdn, i, false);
906  	}
907  	for (i = 0; i &lt; ctl_arenas-&gt;narenas; i++) {
908  		ctl_arena_t *ctl_arena = arenas_i(i);
909  		bool initialized = (tarenas[i] != NULL);
910  		ctl_arena-&gt;initialized = initialized;
911  		if (initialized) {
912  			ctl_arena_refresh(tsdn, tarenas[i], ctl_sarena, i,
913  			    false);
914  		}
915  	}
916  	if (config_stats) {
917  		ctl_stats-&gt;allocated = ctl_sarena-&gt;astats-&gt;allocated_small +
918  		    atomic_load_zu(&amp;ctl_sarena-&gt;astats-&gt;astats.allocated_large,
919  			ATOMIC_RELAXED);
920  		ctl_stats-&gt;active = (ctl_sarena-&gt;pactive &lt;&lt; LG_PAGE);
921  		ctl_stats-&gt;metadata = atomic_load_zu(
922  		    &amp;ctl_sarena-&gt;astats-&gt;astats.base, ATOMIC_RELAXED) +
923  		    atomic_load_zu(&amp;ctl_sarena-&gt;astats-&gt;astats.internal,
924  			ATOMIC_RELAXED);
925  		ctl_stats-&gt;metadata_thp = atomic_load_zu(
926  		    &amp;ctl_sarena-&gt;astats-&gt;astats.metadata_thp, ATOMIC_RELAXED);
927  		ctl_stats-&gt;resident = atomic_load_zu(
928  		    &amp;ctl_sarena-&gt;astats-&gt;astats.resident, ATOMIC_RELAXED);
929  		ctl_stats-&gt;mapped = atomic_load_zu(
930  		    &amp;ctl_sarena-&gt;astats-&gt;astats.mapped, ATOMIC_RELAXED);
931  		ctl_stats-&gt;retained = atomic_load_zu(
932  		    &amp;ctl_sarena-&gt;astats-&gt;astats.retained, ATOMIC_RELAXED);
933  		ctl_background_thread_stats_read(tsdn);
934  #define READ_GLOBAL_MUTEX_PROF_DATA(i, mtx)				\
935      malloc_mutex_lock(tsdn, &amp;mtx);					\
936      malloc_mutex_prof_read(tsdn, &amp;ctl_stats-&gt;mutex_prof_data[i], &amp;mtx);	\
937      malloc_mutex_unlock(tsdn, &amp;mtx);
938  		if (config_prof &amp;&amp; opt_prof) {
939  			READ_GLOBAL_MUTEX_PROF_DATA(global_prof_mutex_prof,
940  			    bt2gctx_mtx);
941  		}
942  		if (have_background_thread) {
943  			READ_GLOBAL_MUTEX_PROF_DATA(
944  			    global_prof_mutex_background_thread,
945  			    background_thread_lock);
946  		} else {
947  			memset(&amp;ctl_stats-&gt;mutex_prof_data[
948  			    global_prof_mutex_background_thread], 0,
949  			    sizeof(mutex_prof_data_t));
950  		}
951  		malloc_mutex_prof_read(tsdn,
952  		    &amp;ctl_stats-&gt;mutex_prof_data[global_prof_mutex_ctl],
953  		    &amp;ctl_mtx);
954  #undef READ_GLOBAL_MUTEX_PROF_DATA
955  	}
956  	ctl_arenas-&gt;epoch++;
957  }
958  static bool
959  ctl_init(tsd_t *tsd) {
960  	bool ret;
961  	tsdn_t *tsdn = tsd_tsdn(tsd);
962  	malloc_mutex_lock(tsdn, &amp;ctl_mtx);
963  	if (!ctl_initialized) {
964  		ctl_arena_t *ctl_sarena, *ctl_darena;
965  		unsigned i;
966  		if (ctl_arenas == NULL) {
967  			ctl_arenas = (ctl_arenas_t *)base_alloc(tsdn,
968  			    b0get(), sizeof(ctl_arenas_t), QUANTUM);
969  			if (ctl_arenas == NULL) {
970  				ret = true;
971  				goto label_return;
972  			}
973  		}
974  		if (config_stats &amp;&amp; ctl_stats == NULL) {
975  			ctl_stats = (ctl_stats_t *)base_alloc(tsdn, b0get(),
976  			    sizeof(ctl_stats_t), QUANTUM);
977  			if (ctl_stats == NULL) {
978  				ret = true;
979  				goto label_return;
980  			}
981  		}
982  		if ((ctl_sarena = arenas_i_impl(tsd, MALLCTL_ARENAS_ALL, false,
983  		    true)) == NULL) {
984  			ret = true;
985  			goto label_return;
986  		}
987  		ctl_sarena-&gt;initialized = true;
988  		if ((ctl_darena = arenas_i_impl(tsd, MALLCTL_ARENAS_DESTROYED,
989  		    false, true)) == NULL) {
990  			ret = true;
991  			goto label_return;
992  		}
993  		ctl_arena_clear(ctl_darena);
994  		ctl_arenas-&gt;narenas = narenas_total_get();
995  		for (i = 0; i &lt; ctl_arenas-&gt;narenas; i++) {
996  			if (arenas_i_impl(tsd, i, false, true) == NULL) {
997  				ret = true;
998  				goto label_return;
999  			}
1000  		}
1001  		ql_new(&amp;ctl_arenas-&gt;destroyed);
1002  		ctl_refresh(tsdn);
1003  		ctl_initialized = true;
1004  	}
1005  	ret = false;
1006  label_return:
1007  	malloc_mutex_unlock(tsdn, &amp;ctl_mtx);
1008  	return ret;
1009  }
1010  static int
1011  ctl_lookup(tsdn_t *tsdn, const char *name, ctl_node_t const **nodesp,
1012      size_t *mibp, size_t *depthp) {
1013  	int ret;
1014  	const char *elm, *tdot, *dot;
1015  	size_t elen, i, j;
1016  	const ctl_named_node_t *node;
1017  	elm = name;
1018  	dot = ((tdot = strchr(elm, &#x27;.&#x27;)) != NULL) ? tdot : strchr(elm, &#x27;\0&#x27;);
1019  	elen = (size_t)((uintptr_t)dot - (uintptr_t)elm);
1020  	if (elen == 0) {
1021  		ret = ENOENT;
1022  		goto label_return;
1023  	}
1024  	node = super_root_node;
1025  	for (i = 0; i &lt; *depthp; i++) {
1026  		assert(node);
1027  		assert(node-&gt;nchildren &gt; 0);
1028  		if (ctl_named_node(node-&gt;children) != NULL) {
1029  			const ctl_named_node_t *pnode = node;
1030  			for (j = 0; j &lt; node-&gt;nchildren; j++) {
1031  				const ctl_named_node_t *child =
1032  				    ctl_named_children(node, j);
1033  				if (strlen(child-&gt;name) == elen &amp;&amp;
1034  				    strncmp(elm, child-&gt;name, elen) == 0) {
1035  					node = child;
1036  					if (nodesp != NULL) {
1037  						nodesp[i] =
1038  						    (const ctl_node_t *)node;
1039  					}
1040  					mibp[i] = j;
1041  					break;
1042  				}
1043  			}
1044  			if (node == pnode) {
1045  				ret = ENOENT;
1046  				goto label_return;
1047  			}
1048  		} else {
1049  			uintmax_t index;
1050  			const ctl_indexed_node_t *inode;
1051  			index = malloc_strtoumax(elm, NULL, 10);
1052  			if (index == UINTMAX_MAX || index &gt; SIZE_T_MAX) {
1053  				ret = ENOENT;
1054  				goto label_return;
1055  			}
1056  			inode = ctl_indexed_node(node-&gt;children);
1057  			node = inode-&gt;index(tsdn, mibp, *depthp, (size_t)index);
1058  			if (node == NULL) {
1059  				ret = ENOENT;
1060  				goto label_return;
1061  			}
1062  			if (nodesp != NULL) {
1063  				nodesp[i] = (const ctl_node_t *)node;
1064  			}
1065  			mibp[i] = (size_t)index;
1066  		}
1067  		if (node-&gt;ctl != NULL) {
1068  			if (*dot != &#x27;\0&#x27;) {
1069  				ret = ENOENT;
1070  				goto label_return;
1071  			}
1072  			*depthp = i + 1;
1073  			break;
1074  		}
1075  		if (*dot == &#x27;\0&#x27;) {
1076  			ret = ENOENT;
1077  			goto label_return;
1078  		}
1079  		elm = &amp;dot[1];
1080  		dot = ((tdot = strchr(elm, &#x27;.&#x27;)) != NULL) ? tdot :
1081  		    strchr(elm, &#x27;\0&#x27;);
1082  		elen = (size_t)((uintptr_t)dot - (uintptr_t)elm);
1083  	}
1084  	ret = 0;
1085  label_return:
1086  	return ret;
1087  }
1088  int
1089  ctl_byname(tsd_t *tsd, const char *name, void *oldp, size_t *oldlenp,
1090      void *newp, size_t newlen) {
1091  	int ret;
1092  	size_t depth;
1093  	ctl_node_t const *nodes[CTL_MAX_DEPTH];
1094  	size_t mib[CTL_MAX_DEPTH];
1095  	const ctl_named_node_t *node;
1096  	if (!ctl_initialized &amp;&amp; ctl_init(tsd)) {
1097  		ret = EAGAIN;
1098  		goto label_return;
1099  	}
1100  	depth = CTL_MAX_DEPTH;
1101  	ret = ctl_lookup(tsd_tsdn(tsd), name, nodes, mib, &amp;depth);
1102  	if (ret != 0) {
1103  		goto label_return;
1104  	}
1105  	node = ctl_named_node(nodes[depth-1]);
1106  	if (node != NULL &amp;&amp; node-&gt;ctl) {
1107  		ret = node-&gt;ctl(tsd, mib, depth, oldp, oldlenp, newp, newlen);
1108  	} else {
1109  		ret = ENOENT;
1110  	}
1111  label_return:
1112  	return(ret);
1113  }
1114  int
1115  ctl_nametomib(tsd_t *tsd, const char *name, size_t *mibp, size_t *miblenp) {
1116  	int ret;
1117  	if (!ctl_initialized &amp;&amp; ctl_init(tsd)) {
1118  		ret = EAGAIN;
1119  		goto label_return;
1120  	}
1121  	ret = ctl_lookup(tsd_tsdn(tsd), name, NULL, mibp, miblenp);
1122  label_return:
1123  	return(ret);
1124  }
1125  int
1126  ctl_bymib(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,
1127      size_t *oldlenp, void *newp, size_t newlen) {
1128  	int ret;
1129  	const ctl_named_node_t *node;
1130  	size_t i;
1131  	if (!ctl_initialized &amp;&amp; ctl_init(tsd)) {
1132  		ret = EAGAIN;
1133  		goto label_return;
1134  	}
1135  	node = super_root_node;
1136  	for (i = 0; i &lt; miblen; i++) {
1137  		assert(node);
1138  		assert(node-&gt;nchildren &gt; 0);
1139  		if (ctl_named_node(node-&gt;children) != NULL) {
1140  			if (node-&gt;nchildren &lt;= mib[i]) {
1141  				ret = ENOENT;
1142  				goto label_return;
1143  			}
1144  			node = ctl_named_children(node, mib[i]);
1145  		} else {
1146  			const ctl_indexed_node_t *inode;
1147  			inode = ctl_indexed_node(node-&gt;children);
1148  			node = inode-&gt;index(tsd_tsdn(tsd), mib, miblen, mib[i]);
1149  			if (node == NULL) {
1150  				ret = ENOENT;
1151  				goto label_return;
1152  			}
1153  		}
1154  	}
1155  	if (node &amp;&amp; node-&gt;ctl) {
1156  		ret = node-&gt;ctl(tsd, mib, miblen, oldp, oldlenp, newp, newlen);
1157  	} else {
1158  		ret = ENOENT;
1159  	}
1160  label_return:
1161  	return(ret);
1162  }
1163  bool
1164  ctl_boot(void) {
1165  	if (malloc_mutex_init(&amp;ctl_mtx, &quot;ctl&quot;, WITNESS_RANK_CTL,
1166  	    malloc_mutex_rank_exclusive)) {
1167  		return true;
1168  	}
1169  	ctl_initialized = false;
1170  	return false;
1171  }
1172  void
1173  ctl_prefork(tsdn_t *tsdn) {
1174  	malloc_mutex_prefork(tsdn, &amp;ctl_mtx);
1175  }
1176  void
1177  ctl_postfork_parent(tsdn_t *tsdn) {
1178  	malloc_mutex_postfork_parent(tsdn, &amp;ctl_mtx);
1179  }
1180  void
1181  ctl_postfork_child(tsdn_t *tsdn) {
1182  	malloc_mutex_postfork_child(tsdn, &amp;ctl_mtx);
1183  }
1184  #define READONLY()	do {						\
1185  	if (newp != NULL || newlen != 0) {				\
1186  		ret = EPERM;						\
1187  		goto label_return;					\
1188  	}								\
1189  } while (0)
1190  #define WRITEONLY()	do {						\
1191  	if (oldp != NULL || oldlenp != NULL) {				\
1192  		ret = EPERM;						\
1193  		goto label_return;					\
1194  	}								\
1195  } while (0)
1196  #define READ_XOR_WRITE()	do {					\
1197  	if ((oldp != NULL &amp;&amp; oldlenp != NULL) &amp;&amp; (newp != NULL ||	\
1198  	    newlen != 0)) {						\
1199  		ret = EPERM;						\
1200  		goto label_return;					\
1201  	}								\
1202  } while (0)
1203  #define READ(v, t)	do {						\
1204  	if (oldp != NULL &amp;&amp; oldlenp != NULL) {				\
1205  		if (*oldlenp != sizeof(t)) {				\
1206  			size_t	copylen = (sizeof(t) &lt;= *oldlenp)	\
1207  			    ? sizeof(t) : *oldlenp;			\
1208  			memcpy(oldp, (void *)&amp;(v), copylen);		\
1209  			ret = EINVAL;					\
1210  			goto label_return;				\
1211  		}							\
1212  		*(t *)oldp = (v);					\
1213  	}								\
1214  } while (0)
1215  #define WRITE(v, t)	do {						\
1216  	if (newp != NULL) {						\
1217  		if (newlen != sizeof(t)) {				\
1218  			ret = EINVAL;					\
1219  			goto label_return;				\
1220  		}							\
1221  		(v) = *(t *)newp;					\
1222  	}								\
1223  } while (0)
1224  #define MIB_UNSIGNED(v, i) do {						\
1225  	if (mib[i] &gt; UINT_MAX) {					\
1226  		ret = EFAULT;						\
1227  		goto label_return;					\
1228  	}								\
1229  	v = (unsigned)mib[i];						\
1230  } while (0)
1231  #define CTL_RO_CLGEN(c, l, n, v, t)					\
1232  static int								\
1233  n##_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,	\
1234      size_t *oldlenp, void *newp, size_t newlen) {			\
1235  	int ret;							\
1236  	t oldval;							\
1237  									\
1238  	if (!(c)) {							\
1239  		return ENOENT;						\
1240  	}								\
1241  	if (l) {							\
1242  		malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);		\
1243  	}								\
1244  	READONLY();							\
1245  	oldval = (v);							\
1246  	READ(oldval, t);						\
1247  									\
1248  	ret = 0;							\
1249  label_return:								\
1250  	if (l) {							\
1251  		malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);		\
1252  	}								\
1253  	return ret;							\
1254  }
1255  #define CTL_RO_CGEN(c, n, v, t)						\
1256  static int								\
1257  n##_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, \
1258      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {			\
1259  	int ret;							\
1260  	t oldval;							\
1261  									\
1262  	if (!(c)) {							\
1263  		return ENOENT;						\
1264  	}								\
1265  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);			\
1266  	READONLY();							\
1267  	oldval = (v);							\
1268  	READ(oldval, t);						\
1269  									\
1270  	ret = 0;							\
1271  label_return:								\
1272  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);			\
1273  	return ret;							\
1274  }
1275  #define CTL_RO_GEN(n, v, t)						\
1276  static int								\
1277  n##_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,	\
1278      size_t *oldlenp, void *newp, size_t newlen) {			\
1279  	int ret;							\
1280  	t oldval;							\
1281  									\
1282  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);			\
1283  	READONLY();							\
1284  	oldval = (v);							\
1285  	READ(oldval, t);						\
1286  									\
1287  	ret = 0;							\
1288  label_return:								\
1289  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);			\
1290  	return ret;							\
1291  }
1292  #define CTL_RO_NL_CGEN(c, n, v, t)					\
1293  static int								\
1294  n##_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, \
1295      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {			\
1296  	int ret;							\
1297  	t oldval;							\
1298  									\
1299  	if (!(c)) {							\
1300  		return ENOENT;						\
1301  	}								\
1302  	READONLY();							\
1303  	oldval = (v);							\
1304  	READ(oldval, t);						\
1305  									\
1306  	ret = 0;							\
1307  label_return:								\
1308  	return ret;							\
1309  }
1310  #define CTL_RO_NL_GEN(n, v, t)						\
1311  static int								\
1312  n##_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, \
1313      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {			\
1314  	int ret;							\
1315  	t oldval;							\
1316  									\
1317  	READONLY();							\
1318  	oldval = (v);							\
1319  	READ(oldval, t);						\
1320  									\
1321  	ret = 0;							\
1322  label_return:								\
1323  	return ret;							\
1324  }
1325  #define CTL_TSD_RO_NL_CGEN(c, n, m, t)					\
1326  static int								\
1327  n##_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,	\
1328      size_t *oldlenp, void *newp, size_t newlen) {			\
1329  	int ret;							\
1330  	t oldval;							\
1331  									\
1332  	if (!(c)) {							\
1333  		return ENOENT;						\
1334  	}								\
1335  	READONLY();							\
1336  	oldval = (m(tsd));						\
1337  	READ(oldval, t);						\
1338  									\
1339  	ret = 0;							\
1340  label_return:								\
1341  	return ret;							\
1342  }
1343  #define CTL_RO_CONFIG_GEN(n, t)						\
1344  static int								\
1345  n##_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, \
1346      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {			\
1347  	int ret;							\
1348  	t oldval;							\
1349  									\
1350  	READONLY();							\
1351  	oldval = n;							\
1352  	READ(oldval, t);						\
1353  									\
1354  	ret = 0;							\
1355  label_return:								\
1356  	return ret;							\
1357  }
1358  CTL_RO_NL_GEN(version, JEMALLOC_VERSION, const char *)
1359  static int
1360  epoch_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
1361      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
1362  	int ret;
1363  	UNUSED uint64_t newval;
1364  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);
1365  	WRITE(newval, uint64_t);
1366  	if (newp != NULL) {
1367  		ctl_refresh(tsd_tsdn(tsd));
1368  	}
1369  	READ(ctl_arenas-&gt;epoch, uint64_t);
1370  	ret = 0;
1371  label_return:
1372  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);
1373  	return ret;
1374  }
1375  static int
1376  background_thread_ctl(tsd_t *tsd, const size_t *mib,
1377      size_t miblen, void *oldp, size_t *oldlenp,
1378      void *newp, size_t newlen) {
1379  	int ret;
1380  	bool oldval;
1381  	if (!have_background_thread) {
1382  		return ENOENT;
1383  	}
1384  	background_thread_ctl_init(tsd_tsdn(tsd));
1385  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);
1386  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;background_thread_lock);
1387  	if (newp == NULL) {
1388  		oldval = background_thread_enabled();
1389  		READ(oldval, bool);
1390  	} else {
1391  		if (newlen != sizeof(bool)) {
1392  			ret = EINVAL;
1393  			goto label_return;
1394  		}
1395  		oldval = background_thread_enabled();
1396  		READ(oldval, bool);
1397  		bool newval = *(bool *)newp;
1398  		if (newval == oldval) {
1399  			ret = 0;
1400  			goto label_return;
1401  		}
1402  		background_thread_enabled_set(tsd_tsdn(tsd), newval);
1403  		if (newval) {
1404  			if (background_threads_enable(tsd)) {
1405  				ret = EFAULT;
1406  				goto label_return;
1407  			}
1408  		} else {
1409  			if (background_threads_disable(tsd)) {
1410  				ret = EFAULT;
1411  				goto label_return;
1412  			}
1413  		}
1414  	}
1415  	ret = 0;
1416  label_return:
1417  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;background_thread_lock);
1418  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);
1419  	return ret;
1420  }
1421  static int
1422  max_background_threads_ctl(tsd_t *tsd, const size_t *mib,
1423      size_t miblen, void *oldp, size_t *oldlenp, void *newp,
1424      size_t newlen) {
1425  	int ret;
1426  	size_t oldval;
1427  	if (!have_background_thread) {
1428  		return ENOENT;
1429  	}
1430  	background_thread_ctl_init(tsd_tsdn(tsd));
1431  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);
1432  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;background_thread_lock);
1433  	if (newp == NULL) {
1434  		oldval = max_background_threads;
1435  		READ(oldval, size_t);
1436  	} else {
1437  		if (newlen != sizeof(size_t)) {
1438  			ret = EINVAL;
1439  			goto label_return;
1440  		}
1441  		oldval = max_background_threads;
1442  		READ(oldval, size_t);
1443  		size_t newval = *(size_t *)newp;
1444  		if (newval == oldval) {
1445  			ret = 0;
1446  			goto label_return;
1447  		}
1448  		if (newval &gt; opt_max_background_threads) {
1449  			ret = EINVAL;
1450  			goto label_return;
1451  		}
1452  		if (background_thread_enabled()) {
1453  			background_thread_enabled_set(tsd_tsdn(tsd), false);
1454  			if (background_threads_disable(tsd)) {
1455  				ret = EFAULT;
1456  				goto label_return;
1457  			}
1458  			max_background_threads = newval;
1459  			background_thread_enabled_set(tsd_tsdn(tsd), true);
1460  			if (background_threads_enable(tsd)) {
<span onclick='openModal()' class='match'>1461  				ret = EFAULT;
1462  				goto label_return;
1463  			}
1464  		} else {
1465  			max_background_threads = newval;
1466  		}
</span>1467  	}
1468  	ret = 0;
1469  label_return:
1470  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;background_thread_lock);
1471  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);
1472  	return ret;
1473  }
1474  CTL_RO_CONFIG_GEN(config_cache_oblivious, bool)
1475  CTL_RO_CONFIG_GEN(config_debug, bool)
1476  CTL_RO_CONFIG_GEN(config_fill, bool)
1477  CTL_RO_CONFIG_GEN(config_lazy_lock, bool)
1478  CTL_RO_CONFIG_GEN(config_malloc_conf, const char *)
1479  CTL_RO_CONFIG_GEN(config_opt_safety_checks, bool)
1480  CTL_RO_CONFIG_GEN(config_prof, bool)
1481  CTL_RO_CONFIG_GEN(config_prof_libgcc, bool)
1482  CTL_RO_CONFIG_GEN(config_prof_libunwind, bool)
1483  CTL_RO_CONFIG_GEN(config_stats, bool)
1484  CTL_RO_CONFIG_GEN(config_utrace, bool)
1485  CTL_RO_CONFIG_GEN(config_xmalloc, bool)
1486  CTL_RO_NL_GEN(opt_abort, opt_abort, bool)
1487  CTL_RO_NL_GEN(opt_abort_conf, opt_abort_conf, bool)
1488  CTL_RO_NL_GEN(opt_confirm_conf, opt_confirm_conf, bool)
1489  CTL_RO_NL_GEN(opt_metadata_thp, metadata_thp_mode_names[opt_metadata_thp],
1490      const char *)
1491  CTL_RO_NL_GEN(opt_retain, opt_retain, bool)
1492  CTL_RO_NL_GEN(opt_dss, opt_dss, const char *)
1493  CTL_RO_NL_GEN(opt_narenas, opt_narenas, unsigned)
1494  CTL_RO_NL_GEN(opt_percpu_arena, percpu_arena_mode_names[opt_percpu_arena],
1495      const char *)
1496  CTL_RO_NL_GEN(opt_oversize_threshold, opt_oversize_threshold, size_t)
1497  CTL_RO_NL_GEN(opt_background_thread, opt_background_thread, bool)
1498  CTL_RO_NL_GEN(opt_max_background_threads, opt_max_background_threads, size_t)
1499  CTL_RO_NL_GEN(opt_dirty_decay_ms, opt_dirty_decay_ms, ssize_t)
1500  CTL_RO_NL_GEN(opt_muzzy_decay_ms, opt_muzzy_decay_ms, ssize_t)
1501  CTL_RO_NL_GEN(opt_stats_print, opt_stats_print, bool)
1502  CTL_RO_NL_GEN(opt_stats_print_opts, opt_stats_print_opts, const char *)
1503  CTL_RO_NL_CGEN(config_fill, opt_junk, opt_junk, const char *)
1504  CTL_RO_NL_CGEN(config_fill, opt_zero, opt_zero, bool)
1505  CTL_RO_NL_CGEN(config_utrace, opt_utrace, opt_utrace, bool)
1506  CTL_RO_NL_CGEN(config_xmalloc, opt_xmalloc, opt_xmalloc, bool)
1507  CTL_RO_NL_GEN(opt_tcache, opt_tcache, bool)
1508  CTL_RO_NL_GEN(opt_thp, thp_mode_names[opt_thp], const char *)
1509  CTL_RO_NL_GEN(opt_lg_extent_max_active_fit, opt_lg_extent_max_active_fit,
1510      size_t)
1511  CTL_RO_NL_GEN(opt_lg_tcache_max, opt_lg_tcache_max, ssize_t)
1512  CTL_RO_NL_CGEN(config_prof, opt_prof, opt_prof, bool)
1513  CTL_RO_NL_CGEN(config_prof, opt_prof_prefix, opt_prof_prefix, const char *)
1514  CTL_RO_NL_CGEN(config_prof, opt_prof_active, opt_prof_active, bool)
1515  CTL_RO_NL_CGEN(config_prof, opt_prof_thread_active_init,
1516      opt_prof_thread_active_init, bool)
1517  CTL_RO_NL_CGEN(config_prof, opt_lg_prof_sample, opt_lg_prof_sample, size_t)
1518  CTL_RO_NL_CGEN(config_prof, opt_prof_accum, opt_prof_accum, bool)
1519  CTL_RO_NL_CGEN(config_prof, opt_lg_prof_interval, opt_lg_prof_interval, ssize_t)
1520  CTL_RO_NL_CGEN(config_prof, opt_prof_gdump, opt_prof_gdump, bool)
1521  CTL_RO_NL_CGEN(config_prof, opt_prof_final, opt_prof_final, bool)
1522  CTL_RO_NL_CGEN(config_prof, opt_prof_leak, opt_prof_leak, bool)
1523  static int
1524  thread_arena_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
1525      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
1526  	int ret;
1527  	arena_t *oldarena;
1528  	unsigned newind, oldind;
1529  	oldarena = arena_choose(tsd, NULL);
1530  	if (oldarena == NULL) {
1531  		return EAGAIN;
1532  	}
1533  	newind = oldind = arena_ind_get(oldarena);
1534  	WRITE(newind, unsigned);
1535  	READ(oldind, unsigned);
1536  	if (newind != oldind) {
1537  		arena_t *newarena;
1538  		if (newind &gt;= narenas_total_get()) {
1539  			ret = EFAULT;
1540  			goto label_return;
1541  		}
1542  		if (have_percpu_arena &amp;&amp;
1543  		    PERCPU_ARENA_ENABLED(opt_percpu_arena)) {
1544  			if (newind &lt; percpu_arena_ind_limit(opt_percpu_arena)) {
1545  				ret = EPERM;
1546  				goto label_return;
1547  			}
1548  		}
1549  		newarena = arena_get(tsd_tsdn(tsd), newind, true);
1550  		if (newarena == NULL) {
1551  			ret = EAGAIN;
1552  			goto label_return;
1553  		}
1554  		arena_migrate(tsd, oldind, newind);
1555  		if (tcache_available(tsd)) {
1556  			tcache_arena_reassociate(tsd_tsdn(tsd),
1557  			    tsd_tcachep_get(tsd), newarena);
1558  		}
1559  	}
1560  	ret = 0;
1561  label_return:
1562  	return ret;
1563  }
1564  CTL_TSD_RO_NL_CGEN(config_stats, thread_allocated, tsd_thread_allocated_get,
1565      uint64_t)
1566  CTL_TSD_RO_NL_CGEN(config_stats, thread_allocatedp, tsd_thread_allocatedp_get,
1567      uint64_t *)
1568  CTL_TSD_RO_NL_CGEN(config_stats, thread_deallocated, tsd_thread_deallocated_get,
1569      uint64_t)
1570  CTL_TSD_RO_NL_CGEN(config_stats, thread_deallocatedp,
1571      tsd_thread_deallocatedp_get, uint64_t *)
1572  static int
1573  thread_tcache_enabled_ctl(tsd_t *tsd, const size_t *mib,
1574      size_t miblen, void *oldp, size_t *oldlenp, void *newp,
1575      size_t newlen) {
1576  	int ret;
1577  	bool oldval;
1578  	oldval = tcache_enabled_get(tsd);
1579  	if (newp != NULL) {
1580  		if (newlen != sizeof(bool)) {
1581  			ret = EINVAL;
1582  			goto label_return;
1583  		}
1584  		tcache_enabled_set(tsd, *(bool *)newp);
1585  	}
1586  	READ(oldval, bool);
1587  	ret = 0;
1588  label_return:
1589  	return ret;
1590  }
1591  static int
1592  thread_tcache_flush_ctl(tsd_t *tsd, const size_t *mib,
1593      size_t miblen, void *oldp, size_t *oldlenp, void *newp,
1594      size_t newlen) {
1595  	int ret;
1596  	if (!tcache_available(tsd)) {
1597  		ret = EFAULT;
1598  		goto label_return;
1599  	}
1600  	READONLY();
1601  	WRITEONLY();
1602  	tcache_flush(tsd);
1603  	ret = 0;
1604  label_return:
1605  	return ret;
1606  }
1607  static int
1608  thread_prof_name_ctl(tsd_t *tsd, const size_t *mib,
1609      size_t miblen, void *oldp, size_t *oldlenp, void *newp,
1610      size_t newlen) {
1611  	int ret;
1612  	if (!config_prof) {
1613  		return ENOENT;
1614  	}
1615  	READ_XOR_WRITE();
1616  	if (newp != NULL) {
1617  		if (newlen != sizeof(const char *)) {
1618  			ret = EINVAL;
1619  			goto label_return;
1620  		}
1621  		if ((ret = prof_thread_name_set(tsd, *(const char **)newp)) !=
1622  		    0) {
1623  			goto label_return;
1624  		}
1625  	} else {
1626  		const char *oldname = prof_thread_name_get(tsd);
1627  		READ(oldname, const char *);
1628  	}
1629  	ret = 0;
1630  label_return:
1631  	return ret;
1632  }
1633  static int
1634  thread_prof_active_ctl(tsd_t *tsd, const size_t *mib,
1635      size_t miblen, void *oldp, size_t *oldlenp, void *newp,
1636      size_t newlen) {
1637  	int ret;
1638  	bool oldval;
1639  	if (!config_prof) {
1640  		return ENOENT;
1641  	}
1642  	oldval = prof_thread_active_get(tsd);
1643  	if (newp != NULL) {
1644  		if (newlen != sizeof(bool)) {
1645  			ret = EINVAL;
1646  			goto label_return;
1647  		}
1648  		if (prof_thread_active_set(tsd, *(bool *)newp)) {
1649  			ret = EAGAIN;
1650  			goto label_return;
1651  		}
1652  	}
1653  	READ(oldval, bool);
1654  	ret = 0;
1655  label_return:
1656  	return ret;
1657  }
1658  static int
1659  tcache_create_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
1660      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
1661  	int ret;
1662  	unsigned tcache_ind;
1663  	READONLY();
1664  	if (tcaches_create(tsd, &amp;tcache_ind)) {
1665  		ret = EFAULT;
1666  		goto label_return;
1667  	}
1668  	READ(tcache_ind, unsigned);
1669  	ret = 0;
1670  label_return:
1671  	return ret;
1672  }
1673  static int
1674  tcache_flush_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
1675      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
1676  	int ret;
1677  	unsigned tcache_ind;
1678  	WRITEONLY();
1679  	tcache_ind = UINT_MAX;
1680  	WRITE(tcache_ind, unsigned);
1681  	if (tcache_ind == UINT_MAX) {
1682  		ret = EFAULT;
1683  		goto label_return;
1684  	}
1685  	tcaches_flush(tsd, tcache_ind);
1686  	ret = 0;
1687  label_return:
1688  	return ret;
1689  }
1690  static int
1691  tcache_destroy_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
1692      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
1693  	int ret;
1694  	unsigned tcache_ind;
1695  	WRITEONLY();
1696  	tcache_ind = UINT_MAX;
1697  	WRITE(tcache_ind, unsigned);
1698  	if (tcache_ind == UINT_MAX) {
1699  		ret = EFAULT;
1700  		goto label_return;
1701  	}
1702  	tcaches_destroy(tsd, tcache_ind);
1703  	ret = 0;
1704  label_return:
1705  	return ret;
1706  }
1707  static int
1708  arena_i_initialized_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
1709      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
1710  	int ret;
1711  	tsdn_t *tsdn = tsd_tsdn(tsd);
1712  	unsigned arena_ind;
1713  	bool initialized;
1714  	READONLY();
1715  	MIB_UNSIGNED(arena_ind, 1);
1716  	malloc_mutex_lock(tsdn, &amp;ctl_mtx);
1717  	initialized = arenas_i(arena_ind)-&gt;initialized;
1718  	malloc_mutex_unlock(tsdn, &amp;ctl_mtx);
1719  	READ(initialized, bool);
1720  	ret = 0;
1721  label_return:
1722  	return ret;
1723  }
1724  static void
1725  arena_i_decay(tsdn_t *tsdn, unsigned arena_ind, bool all) {
1726  	malloc_mutex_lock(tsdn, &amp;ctl_mtx);
1727  	{
1728  		unsigned narenas = ctl_arenas-&gt;narenas;
1729  		if (arena_ind == MALLCTL_ARENAS_ALL || arena_ind == narenas) {
1730  			unsigned i;
1731  			VARIABLE_ARRAY(arena_t *, tarenas, narenas);
1732  			for (i = 0; i &lt; narenas; i++) {
1733  				tarenas[i] = arena_get(tsdn, i, false);
1734  			}
1735  			malloc_mutex_unlock(tsdn, &amp;ctl_mtx);
1736  			for (i = 0; i &lt; narenas; i++) {
1737  				if (tarenas[i] != NULL) {
1738  					arena_decay(tsdn, tarenas[i], false,
1739  					    all);
1740  				}
1741  			}
1742  		} else {
1743  			arena_t *tarena;
1744  			assert(arena_ind &lt; narenas);
1745  			tarena = arena_get(tsdn, arena_ind, false);
1746  			malloc_mutex_unlock(tsdn, &amp;ctl_mtx);
1747  			if (tarena != NULL) {
1748  				arena_decay(tsdn, tarena, false, all);
1749  			}
1750  		}
1751  	}
1752  }
1753  static int
1754  arena_i_decay_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,
1755      size_t *oldlenp, void *newp, size_t newlen) {
1756  	int ret;
1757  	unsigned arena_ind;
1758  	READONLY();
1759  	WRITEONLY();
1760  	MIB_UNSIGNED(arena_ind, 1);
1761  	arena_i_decay(tsd_tsdn(tsd), arena_ind, false);
1762  	ret = 0;
1763  label_return:
1764  	return ret;
1765  }
1766  static int
1767  arena_i_purge_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,
1768      size_t *oldlenp, void *newp, size_t newlen) {
1769  	int ret;
1770  	unsigned arena_ind;
1771  	READONLY();
1772  	WRITEONLY();
1773  	MIB_UNSIGNED(arena_ind, 1);
1774  	arena_i_decay(tsd_tsdn(tsd), arena_ind, true);
1775  	ret = 0;
1776  label_return:
1777  	return ret;
1778  }
1779  static int
1780  arena_i_reset_destroy_helper(tsd_t *tsd, const size_t *mib, size_t miblen,
1781      void *oldp, size_t *oldlenp, void *newp, size_t newlen, unsigned *arena_ind,
1782      arena_t **arena) {
1783  	int ret;
1784  	READONLY();
1785  	WRITEONLY();
1786  	MIB_UNSIGNED(*arena_ind, 1);
1787  	*arena = arena_get(tsd_tsdn(tsd), *arena_ind, false);
1788  	if (*arena == NULL || arena_is_auto(*arena)) {
1789  		ret = EFAULT;
1790  		goto label_return;
1791  	}
1792  	ret = 0;
1793  label_return:
1794  	return ret;
1795  }
1796  static void
1797  arena_reset_prepare_background_thread(tsd_t *tsd, unsigned arena_ind) {
1798  	if (have_background_thread) {
1799  		malloc_mutex_lock(tsd_tsdn(tsd), &amp;background_thread_lock);
1800  		if (background_thread_enabled()) {
1801  			background_thread_info_t *info =
1802  			    background_thread_info_get(arena_ind);
1803  			assert(info-&gt;state == background_thread_started);
1804  			malloc_mutex_lock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
1805  			info-&gt;state = background_thread_paused;
1806  			malloc_mutex_unlock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
1807  		}
1808  	}
1809  }
1810  static void
1811  arena_reset_finish_background_thread(tsd_t *tsd, unsigned arena_ind) {
1812  	if (have_background_thread) {
1813  		if (background_thread_enabled()) {
1814  			background_thread_info_t *info =
1815  			    background_thread_info_get(arena_ind);
1816  			assert(info-&gt;state == background_thread_paused);
1817  			malloc_mutex_lock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
1818  			info-&gt;state = background_thread_started;
1819  			malloc_mutex_unlock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
1820  		}
1821  		malloc_mutex_unlock(tsd_tsdn(tsd), &amp;background_thread_lock);
1822  	}
1823  }
1824  static int
1825  arena_i_reset_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,
1826      size_t *oldlenp, void *newp, size_t newlen) {
1827  	int ret;
1828  	unsigned arena_ind;
1829  	arena_t *arena;
1830  	ret = arena_i_reset_destroy_helper(tsd, mib, miblen, oldp, oldlenp,
1831  	    newp, newlen, &amp;arena_ind, &amp;arena);
1832  	if (ret != 0) {
1833  		return ret;
1834  	}
1835  	arena_reset_prepare_background_thread(tsd, arena_ind);
1836  	arena_reset(tsd, arena);
1837  	arena_reset_finish_background_thread(tsd, arena_ind);
1838  	return ret;
1839  }
1840  static int
1841  arena_i_destroy_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,
1842      size_t *oldlenp, void *newp, size_t newlen) {
1843  	int ret;
1844  	unsigned arena_ind;
1845  	arena_t *arena;
1846  	ctl_arena_t *ctl_darena, *ctl_arena;
1847  	ret = arena_i_reset_destroy_helper(tsd, mib, miblen, oldp, oldlenp,
1848  	    newp, newlen, &amp;arena_ind, &amp;arena);
1849  	if (ret != 0) {
1850  		goto label_return;
1851  	}
1852  	if (arena_nthreads_get(arena, false) != 0 || arena_nthreads_get(arena,
1853  	    true) != 0) {
1854  		ret = EFAULT;
1855  		goto label_return;
1856  	}
1857  	arena_reset_prepare_background_thread(tsd, arena_ind);
1858  	arena_reset(tsd, arena);
1859  	arena_decay(tsd_tsdn(tsd), arena, false, true);
1860  	ctl_darena = arenas_i(MALLCTL_ARENAS_DESTROYED);
1861  	ctl_darena-&gt;initialized = true;
1862  	ctl_arena_refresh(tsd_tsdn(tsd), arena, ctl_darena, arena_ind, true);
1863  	arena_destroy(tsd, arena);
1864  	ctl_arena = arenas_i(arena_ind);
1865  	ctl_arena-&gt;initialized = false;
1866  	ql_elm_new(ctl_arena, destroyed_link);
1867  	ql_tail_insert(&amp;ctl_arenas-&gt;destroyed, ctl_arena, destroyed_link);
1868  	arena_reset_finish_background_thread(tsd, arena_ind);
1869  	assert(ret == 0);
1870  label_return:
1871  	return ret;
1872  }
1873  static int
1874  arena_i_dss_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,
1875      size_t *oldlenp, void *newp, size_t newlen) {
1876  	int ret;
1877  	const char *dss = NULL;
1878  	unsigned arena_ind;
1879  	dss_prec_t dss_prec_old = dss_prec_limit;
1880  	dss_prec_t dss_prec = dss_prec_limit;
1881  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);
1882  	WRITE(dss, const char *);
1883  	MIB_UNSIGNED(arena_ind, 1);
1884  	if (dss != NULL) {
1885  		int i;
1886  		bool match = false;
1887  		for (i = 0; i &lt; dss_prec_limit; i++) {
1888  			if (strcmp(dss_prec_names[i], dss) == 0) {
1889  				dss_prec = i;
1890  				match = true;
1891  				break;
1892  			}
1893  		}
1894  		if (!match) {
1895  			ret = EINVAL;
1896  			goto label_return;
1897  		}
1898  	}
1899  	if (arena_ind == MALLCTL_ARENAS_ALL || arena_ind ==
1900  	    ctl_arenas-&gt;narenas) {
1901  		if (dss_prec != dss_prec_limit &amp;&amp;
1902  		    extent_dss_prec_set(dss_prec)) {
1903  			ret = EFAULT;
1904  			goto label_return;
1905  		}
1906  		dss_prec_old = extent_dss_prec_get();
1907  	} else {
1908  		arena_t *arena = arena_get(tsd_tsdn(tsd), arena_ind, false);
1909  		if (arena == NULL || (dss_prec != dss_prec_limit &amp;&amp;
1910  		    arena_dss_prec_set(arena, dss_prec))) {
1911  			ret = EFAULT;
1912  			goto label_return;
1913  		}
1914  		dss_prec_old = arena_dss_prec_get(arena);
1915  	}
1916  	dss = dss_prec_names[dss_prec_old];
1917  	READ(dss, const char *);
1918  	ret = 0;
1919  label_return:
1920  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);
1921  	return ret;
1922  }
1923  static int
1924  arena_i_decay_ms_ctl_impl(tsd_t *tsd, const size_t *mib, size_t miblen,
1925      void *oldp, size_t *oldlenp, void *newp, size_t newlen, bool dirty) {
1926  	int ret;
1927  	unsigned arena_ind;
1928  	arena_t *arena;
1929  	MIB_UNSIGNED(arena_ind, 1);
1930  	arena = arena_get(tsd_tsdn(tsd), arena_ind, false);
1931  	if (arena == NULL) {
1932  		ret = EFAULT;
1933  		goto label_return;
1934  	}
1935  	if (oldp != NULL &amp;&amp; oldlenp != NULL) {
1936  		size_t oldval = dirty ? arena_dirty_decay_ms_get(arena) :
1937  		    arena_muzzy_decay_ms_get(arena);
1938  		READ(oldval, ssize_t);
1939  	}
1940  	if (newp != NULL) {
1941  		if (newlen != sizeof(ssize_t)) {
1942  			ret = EINVAL;
1943  			goto label_return;
1944  		}
1945  		if (arena_is_huge(arena_ind) &amp;&amp; *(ssize_t *)newp &gt; 0) {
1946  			if (background_thread_create(tsd, arena_ind)) {
1947  				ret = EFAULT;
1948  				goto label_return;
1949  			}
1950  		}
1951  		if (dirty ? arena_dirty_decay_ms_set(tsd_tsdn(tsd), arena,
1952  		    *(ssize_t *)newp) : arena_muzzy_decay_ms_set(tsd_tsdn(tsd),
1953  		    arena, *(ssize_t *)newp)) {
1954  			ret = EFAULT;
1955  			goto label_return;
1956  		}
1957  	}
1958  	ret = 0;
1959  label_return:
1960  	return ret;
1961  }
1962  static int
1963  arena_i_dirty_decay_ms_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
1964      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
1965  	return arena_i_decay_ms_ctl_impl(tsd, mib, miblen, oldp, oldlenp, newp,
1966  	    newlen, true);
1967  }
1968  static int
1969  arena_i_muzzy_decay_ms_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
1970      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
1971  	return arena_i_decay_ms_ctl_impl(tsd, mib, miblen, oldp, oldlenp, newp,
1972  	    newlen, false);
1973  }
1974  static int
1975  arena_i_extent_hooks_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
1976      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
1977  	int ret;
1978  	unsigned arena_ind;
1979  	arena_t *arena;
1980  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);
1981  	MIB_UNSIGNED(arena_ind, 1);
1982  	if (arena_ind &lt; narenas_total_get()) {
1983  		extent_hooks_t *old_extent_hooks;
1984  		arena = arena_get(tsd_tsdn(tsd), arena_ind, false);
1985  		if (arena == NULL) {
1986  			if (arena_ind &gt;= narenas_auto) {
1987  				ret = EFAULT;
1988  				goto label_return;
1989  			}
1990  			old_extent_hooks =
1991  			    (extent_hooks_t *)&amp;extent_hooks_default;
1992  			READ(old_extent_hooks, extent_hooks_t *);
1993  			if (newp != NULL) {
1994  				extent_hooks_t *new_extent_hooks
1995  				    JEMALLOC_CC_SILENCE_INIT(NULL);
1996  				WRITE(new_extent_hooks, extent_hooks_t *);
1997  				arena = arena_init(tsd_tsdn(tsd), arena_ind,
1998  				    new_extent_hooks);
1999  				if (arena == NULL) {
2000  					ret = EFAULT;
2001  					goto label_return;
2002  				}
2003  			}
2004  		} else {
2005  			if (newp != NULL) {
2006  				extent_hooks_t *new_extent_hooks
2007  				    JEMALLOC_CC_SILENCE_INIT(NULL);
2008  				WRITE(new_extent_hooks, extent_hooks_t *);
2009  				old_extent_hooks = extent_hooks_set(tsd, arena,
2010  				    new_extent_hooks);
2011  				READ(old_extent_hooks, extent_hooks_t *);
2012  			} else {
2013  				old_extent_hooks = extent_hooks_get(arena);
2014  				READ(old_extent_hooks, extent_hooks_t *);
2015  			}
2016  		}
2017  	} else {
2018  		ret = EFAULT;
2019  		goto label_return;
2020  	}
2021  	ret = 0;
2022  label_return:
2023  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);
2024  	return ret;
2025  }
2026  static int
2027  arena_i_retain_grow_limit_ctl(tsd_t *tsd, const size_t *mib,
2028      size_t miblen, void *oldp, size_t *oldlenp, void *newp,
2029      size_t newlen) {
2030  	int ret;
2031  	unsigned arena_ind;
2032  	arena_t *arena;
2033  	if (!opt_retain) {
2034  		return ENOENT;
2035  	}
2036  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);
2037  	MIB_UNSIGNED(arena_ind, 1);
2038  	if (arena_ind &lt; narenas_total_get() &amp;&amp; (arena =
2039  	    arena_get(tsd_tsdn(tsd), arena_ind, false)) != NULL) {
2040  		size_t old_limit, new_limit;
2041  		if (newp != NULL) {
2042  			WRITE(new_limit, size_t);
2043  		}
2044  		bool err = arena_retain_grow_limit_get_set(tsd, arena,
2045  		    &amp;old_limit, newp != NULL ? &amp;new_limit : NULL);
2046  		if (!err) {
2047  			READ(old_limit, size_t);
2048  			ret = 0;
2049  		} else {
2050  			ret = EFAULT;
2051  		}
2052  	} else {
2053  		ret = EFAULT;
2054  	}
2055  label_return:
2056  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);
2057  	return ret;
2058  }
2059  static const ctl_named_node_t *
2060  arena_i_index(tsdn_t *tsdn, const size_t *mib, size_t miblen,
2061      size_t i) {
2062  	const ctl_named_node_t *ret;
2063  	malloc_mutex_lock(tsdn, &amp;ctl_mtx);
2064  	switch (i) {
2065  	case MALLCTL_ARENAS_ALL:
2066  	case MALLCTL_ARENAS_DESTROYED:
2067  		break;
2068  	default:
2069  		if (i &gt; ctl_arenas-&gt;narenas) {
2070  			ret = NULL;
2071  			goto label_return;
2072  		}
2073  		break;
2074  	}
2075  	ret = super_arena_i_node;
2076  label_return:
2077  	malloc_mutex_unlock(tsdn, &amp;ctl_mtx);
2078  	return ret;
2079  }
2080  static int
2081  arenas_narenas_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
2082      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2083  	int ret;
2084  	unsigned narenas;
2085  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);
2086  	READONLY();
2087  	if (*oldlenp != sizeof(unsigned)) {
2088  		ret = EINVAL;
2089  		goto label_return;
2090  	}
2091  	narenas = ctl_arenas-&gt;narenas;
2092  	READ(narenas, unsigned);
2093  	ret = 0;
2094  label_return:
2095  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);
2096  	return ret;
2097  }
2098  static int
2099  arenas_decay_ms_ctl_impl(tsd_t *tsd, const size_t *mib,
2100      size_t miblen, void *oldp, size_t *oldlenp, void *newp,
2101      size_t newlen, bool dirty) {
2102  	int ret;
2103  	if (oldp != NULL &amp;&amp; oldlenp != NULL) {
2104  		size_t oldval = (dirty ? arena_dirty_decay_ms_default_get() :
2105  		    arena_muzzy_decay_ms_default_get());
2106  		READ(oldval, ssize_t);
2107  	}
2108  	if (newp != NULL) {
2109  		if (newlen != sizeof(ssize_t)) {
2110  			ret = EINVAL;
2111  			goto label_return;
2112  		}
2113  		if (dirty ? arena_dirty_decay_ms_default_set(*(ssize_t *)newp)
2114  		    : arena_muzzy_decay_ms_default_set(*(ssize_t *)newp)) {
2115  			ret = EFAULT;
2116  			goto label_return;
2117  		}
2118  	}
2119  	ret = 0;
2120  label_return:
2121  	return ret;
2122  }
2123  static int
2124  arenas_dirty_decay_ms_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
2125      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2126  	return arenas_decay_ms_ctl_impl(tsd, mib, miblen, oldp, oldlenp, newp,
2127  	    newlen, true);
2128  }
2129  static int
2130  arenas_muzzy_decay_ms_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
2131      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2132  	return arenas_decay_ms_ctl_impl(tsd, mib, miblen, oldp, oldlenp, newp,
2133  	    newlen, false);
2134  }
2135  CTL_RO_NL_GEN(arenas_quantum, QUANTUM, size_t)
2136  CTL_RO_NL_GEN(arenas_page, PAGE, size_t)
2137  CTL_RO_NL_GEN(arenas_tcache_max, tcache_maxclass, size_t)
2138  CTL_RO_NL_GEN(arenas_nbins, SC_NBINS, unsigned)
2139  CTL_RO_NL_GEN(arenas_nhbins, nhbins, unsigned)
2140  CTL_RO_NL_GEN(arenas_bin_i_size, bin_infos[mib[2]].reg_size, size_t)
2141  CTL_RO_NL_GEN(arenas_bin_i_nregs, bin_infos[mib[2]].nregs, uint32_t)
2142  CTL_RO_NL_GEN(arenas_bin_i_slab_size, bin_infos[mib[2]].slab_size, size_t)
2143  CTL_RO_NL_GEN(arenas_bin_i_nshards, bin_infos[mib[2]].n_shards, uint32_t)
2144  static const ctl_named_node_t *
2145  arenas_bin_i_index(tsdn_t *tsdn, const size_t *mib,
2146      size_t miblen, size_t i) {
2147  	if (i &gt; SC_NBINS) {
2148  		return NULL;
2149  	}
2150  	return super_arenas_bin_i_node;
2151  }
2152  CTL_RO_NL_GEN(arenas_nlextents, SC_NSIZES - SC_NBINS, unsigned)
2153  CTL_RO_NL_GEN(arenas_lextent_i_size, sz_index2size(SC_NBINS+(szind_t)mib[2]),
2154      size_t)
2155  static const ctl_named_node_t *
2156  arenas_lextent_i_index(tsdn_t *tsdn, const size_t *mib,
2157      size_t miblen, size_t i) {
2158  	if (i &gt; SC_NSIZES - SC_NBINS) {
2159  		return NULL;
2160  	}
2161  	return super_arenas_lextent_i_node;
2162  }
2163  static int
2164  arenas_create_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
2165      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2166  	int ret;
2167  	extent_hooks_t *extent_hooks;
2168  	unsigned arena_ind;
2169  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);
2170  	extent_hooks = (extent_hooks_t *)&amp;extent_hooks_default;
2171  	WRITE(extent_hooks, extent_hooks_t *);
2172  	if ((arena_ind = ctl_arena_init(tsd, extent_hooks)) == UINT_MAX) {
2173  		ret = EAGAIN;
2174  		goto label_return;
2175  	}
2176  	READ(arena_ind, unsigned);
2177  	ret = 0;
2178  label_return:
2179  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);
2180  	return ret;
2181  }
2182  static int
2183  arenas_lookup_ctl(tsd_t *tsd, const size_t *mib,
2184      size_t miblen, void *oldp, size_t *oldlenp, void *newp,
2185      size_t newlen) {
2186  	int ret;
2187  	unsigned arena_ind;
2188  	void *ptr;
2189  	extent_t *extent;
2190  	arena_t *arena;
2191  	ptr = NULL;
2192  	ret = EINVAL;
2193  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);
2194  	WRITE(ptr, void *);
2195  	extent = iealloc(tsd_tsdn(tsd), ptr);
2196  	if (extent == NULL)
2197  		goto label_return;
2198  	arena = extent_arena_get(extent);
2199  	if (arena == NULL)
2200  		goto label_return;
2201  	arena_ind = arena_ind_get(arena);
2202  	READ(arena_ind, unsigned);
2203  	ret = 0;
2204  label_return:
2205  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);
2206  	return ret;
2207  }
2208  static int
2209  prof_thread_active_init_ctl(tsd_t *tsd, const size_t *mib,
2210      size_t miblen, void *oldp, size_t *oldlenp, void *newp,
2211      size_t newlen) {
2212  	int ret;
2213  	bool oldval;
2214  	if (!config_prof) {
2215  		return ENOENT;
2216  	}
2217  	if (newp != NULL) {
2218  		if (newlen != sizeof(bool)) {
2219  			ret = EINVAL;
2220  			goto label_return;
2221  		}
2222  		oldval = prof_thread_active_init_set(tsd_tsdn(tsd),
2223  		    *(bool *)newp);
2224  	} else {
2225  		oldval = prof_thread_active_init_get(tsd_tsdn(tsd));
2226  	}
2227  	READ(oldval, bool);
2228  	ret = 0;
2229  label_return:
2230  	return ret;
2231  }
2232  static int
2233  prof_active_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
2234      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2235  	int ret;
2236  	bool oldval;
2237  	if (!config_prof) {
2238  		return ENOENT;
2239  	}
2240  	if (newp != NULL) {
2241  		if (newlen != sizeof(bool)) {
2242  			ret = EINVAL;
2243  			goto label_return;
2244  		}
2245  		oldval = prof_active_set(tsd_tsdn(tsd), *(bool *)newp);
2246  	} else {
2247  		oldval = prof_active_get(tsd_tsdn(tsd));
2248  	}
2249  	READ(oldval, bool);
2250  	ret = 0;
2251  label_return:
2252  	return ret;
2253  }
2254  static int
2255  prof_dump_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
2256      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2257  	int ret;
2258  	const char *filename = NULL;
2259  	if (!config_prof) {
2260  		return ENOENT;
2261  	}
2262  	WRITEONLY();
2263  	WRITE(filename, const char *);
2264  	if (prof_mdump(tsd, filename)) {
2265  		ret = EFAULT;
2266  		goto label_return;
2267  	}
2268  	ret = 0;
2269  label_return:
2270  	return ret;
2271  }
2272  static int
2273  prof_gdump_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
2274      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2275  	int ret;
2276  	bool oldval;
2277  	if (!config_prof) {
2278  		return ENOENT;
2279  	}
2280  	if (newp != NULL) {
2281  		if (newlen != sizeof(bool)) {
2282  			ret = EINVAL;
2283  			goto label_return;
2284  		}
2285  		oldval = prof_gdump_set(tsd_tsdn(tsd), *(bool *)newp);
2286  	} else {
2287  		oldval = prof_gdump_get(tsd_tsdn(tsd));
2288  	}
2289  	READ(oldval, bool);
2290  	ret = 0;
2291  label_return:
2292  	return ret;
2293  }
2294  static int
2295  prof_reset_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
2296      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2297  	int ret;
2298  	size_t lg_sample = lg_prof_sample;
2299  	if (!config_prof) {
2300  		return ENOENT;
2301  	}
2302  	WRITEONLY();
2303  	WRITE(lg_sample, size_t);
2304  	if (lg_sample &gt;= (sizeof(uint64_t) &lt;&lt; 3)) {
2305  		lg_sample = (sizeof(uint64_t) &lt;&lt; 3) - 1;
2306  	}
2307  	prof_reset(tsd, lg_sample);
2308  	ret = 0;
2309  label_return:
2310  	return ret;
2311  }
2312  CTL_RO_NL_CGEN(config_prof, prof_interval, prof_interval, uint64_t)
2313  CTL_RO_NL_CGEN(config_prof, lg_prof_sample, lg_prof_sample, size_t)
2314  static int
2315  prof_log_start_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,
2316      size_t *oldlenp, void *newp, size_t newlen) {
2317  	int ret;
2318  	const char *filename = NULL;
2319  	if (!config_prof) {
2320  		return ENOENT;
2321  	}
2322  	WRITEONLY();
2323  	WRITE(filename, const char *);
2324  	if (prof_log_start(tsd_tsdn(tsd), filename)) {
2325  		ret = EFAULT;
2326  		goto label_return;
2327  	}
2328  	ret = 0;
2329  label_return:
2330  	return ret;
2331  }
2332  static int
2333  prof_log_stop_ctl(tsd_t *tsd, const size_t *mib, size_t miblen, void *oldp,
2334      size_t *oldlenp, void *newp, size_t newlen) {
2335  	if (!config_prof) {
2336  		return ENOENT;
2337  	}
2338  	if (prof_log_stop(tsd_tsdn(tsd))) {
2339  		return EFAULT;
2340  	}
2341  	return 0;
2342  }
2343  CTL_RO_CGEN(config_stats, stats_allocated, ctl_stats-&gt;allocated, size_t)
2344  CTL_RO_CGEN(config_stats, stats_active, ctl_stats-&gt;active, size_t)
2345  CTL_RO_CGEN(config_stats, stats_metadata, ctl_stats-&gt;metadata, size_t)
2346  CTL_RO_CGEN(config_stats, stats_metadata_thp, ctl_stats-&gt;metadata_thp, size_t)
2347  CTL_RO_CGEN(config_stats, stats_resident, ctl_stats-&gt;resident, size_t)
2348  CTL_RO_CGEN(config_stats, stats_mapped, ctl_stats-&gt;mapped, size_t)
2349  CTL_RO_CGEN(config_stats, stats_retained, ctl_stats-&gt;retained, size_t)
2350  CTL_RO_CGEN(config_stats, stats_background_thread_num_threads,
2351      ctl_stats-&gt;background_thread.num_threads, size_t)
2352  CTL_RO_CGEN(config_stats, stats_background_thread_num_runs,
2353      ctl_stats-&gt;background_thread.num_runs, uint64_t)
2354  CTL_RO_CGEN(config_stats, stats_background_thread_run_interval,
2355      nstime_ns(&amp;ctl_stats-&gt;background_thread.run_interval), uint64_t)
2356  CTL_RO_GEN(stats_arenas_i_dss, arenas_i(mib[2])-&gt;dss, const char *)
2357  CTL_RO_GEN(stats_arenas_i_dirty_decay_ms, arenas_i(mib[2])-&gt;dirty_decay_ms,
2358      ssize_t)
2359  CTL_RO_GEN(stats_arenas_i_muzzy_decay_ms, arenas_i(mib[2])-&gt;muzzy_decay_ms,
2360      ssize_t)
2361  CTL_RO_GEN(stats_arenas_i_nthreads, arenas_i(mib[2])-&gt;nthreads, unsigned)
2362  CTL_RO_GEN(stats_arenas_i_uptime,
2363      nstime_ns(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.uptime), uint64_t)
2364  CTL_RO_GEN(stats_arenas_i_pactive, arenas_i(mib[2])-&gt;pactive, size_t)
2365  CTL_RO_GEN(stats_arenas_i_pdirty, arenas_i(mib[2])-&gt;pdirty, size_t)
2366  CTL_RO_GEN(stats_arenas_i_pmuzzy, arenas_i(mib[2])-&gt;pmuzzy, size_t)
2367  CTL_RO_CGEN(config_stats, stats_arenas_i_mapped,
2368      atomic_load_zu(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.mapped, ATOMIC_RELAXED),
2369      size_t)
2370  CTL_RO_CGEN(config_stats, stats_arenas_i_retained,
2371      atomic_load_zu(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.retained, ATOMIC_RELAXED),
2372      size_t)
2373  CTL_RO_CGEN(config_stats, stats_arenas_i_extent_avail,
2374      atomic_load_zu(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.extent_avail,
2375          ATOMIC_RELAXED),
2376      size_t)
2377  CTL_RO_CGEN(config_stats, stats_arenas_i_dirty_npurge,
2378      ctl_arena_stats_read_u64(
2379      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.decay_dirty.npurge), uint64_t)
2380  CTL_RO_CGEN(config_stats, stats_arenas_i_dirty_nmadvise,
2381      ctl_arena_stats_read_u64(
2382      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.decay_dirty.nmadvise), uint64_t)
2383  CTL_RO_CGEN(config_stats, stats_arenas_i_dirty_purged,
2384      ctl_arena_stats_read_u64(
2385      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.decay_dirty.purged), uint64_t)
2386  CTL_RO_CGEN(config_stats, stats_arenas_i_muzzy_npurge,
2387      ctl_arena_stats_read_u64(
2388      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.decay_muzzy.npurge), uint64_t)
2389  CTL_RO_CGEN(config_stats, stats_arenas_i_muzzy_nmadvise,
2390      ctl_arena_stats_read_u64(
2391      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.decay_muzzy.nmadvise), uint64_t)
2392  CTL_RO_CGEN(config_stats, stats_arenas_i_muzzy_purged,
2393      ctl_arena_stats_read_u64(
2394      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.decay_muzzy.purged), uint64_t)
2395  CTL_RO_CGEN(config_stats, stats_arenas_i_base,
2396      atomic_load_zu(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.base, ATOMIC_RELAXED),
2397      size_t)
2398  CTL_RO_CGEN(config_stats, stats_arenas_i_internal,
2399      atomic_load_zu(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.internal, ATOMIC_RELAXED),
2400      size_t)
2401  CTL_RO_CGEN(config_stats, stats_arenas_i_metadata_thp,
2402      atomic_load_zu(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.metadata_thp,
2403      ATOMIC_RELAXED), size_t)
2404  CTL_RO_CGEN(config_stats, stats_arenas_i_tcache_bytes,
2405      atomic_load_zu(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.tcache_bytes,
2406      ATOMIC_RELAXED), size_t)
2407  CTL_RO_CGEN(config_stats, stats_arenas_i_resident,
2408      atomic_load_zu(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.resident, ATOMIC_RELAXED),
2409      size_t)
2410  CTL_RO_CGEN(config_stats, stats_arenas_i_abandoned_vm,
2411      atomic_load_zu(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.abandoned_vm,
2412      ATOMIC_RELAXED), size_t)
2413  CTL_RO_CGEN(config_stats, stats_arenas_i_small_allocated,
2414      arenas_i(mib[2])-&gt;astats-&gt;allocated_small, size_t)
2415  CTL_RO_CGEN(config_stats, stats_arenas_i_small_nmalloc,
2416      arenas_i(mib[2])-&gt;astats-&gt;nmalloc_small, uint64_t)
2417  CTL_RO_CGEN(config_stats, stats_arenas_i_small_ndalloc,
2418      arenas_i(mib[2])-&gt;astats-&gt;ndalloc_small, uint64_t)
2419  CTL_RO_CGEN(config_stats, stats_arenas_i_small_nrequests,
2420      arenas_i(mib[2])-&gt;astats-&gt;nrequests_small, uint64_t)
2421  CTL_RO_CGEN(config_stats, stats_arenas_i_small_nfills,
2422      arenas_i(mib[2])-&gt;astats-&gt;nfills_small, uint64_t)
2423  CTL_RO_CGEN(config_stats, stats_arenas_i_small_nflushes,
2424      arenas_i(mib[2])-&gt;astats-&gt;nflushes_small, uint64_t)
2425  CTL_RO_CGEN(config_stats, stats_arenas_i_large_allocated,
2426      atomic_load_zu(&amp;arenas_i(mib[2])-&gt;astats-&gt;astats.allocated_large,
2427      ATOMIC_RELAXED), size_t)
2428  CTL_RO_CGEN(config_stats, stats_arenas_i_large_nmalloc,
2429      ctl_arena_stats_read_u64(
2430      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.nmalloc_large), uint64_t)
2431  CTL_RO_CGEN(config_stats, stats_arenas_i_large_ndalloc,
2432      ctl_arena_stats_read_u64(
2433      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.ndalloc_large), uint64_t)
2434  CTL_RO_CGEN(config_stats, stats_arenas_i_large_nrequests,
2435      ctl_arena_stats_read_u64(
2436      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.nrequests_large), uint64_t)
2437  CTL_RO_CGEN(config_stats, stats_arenas_i_large_nfills,
2438      ctl_arena_stats_read_u64(
2439      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.nmalloc_large), uint64_t)
2440  CTL_RO_CGEN(config_stats, stats_arenas_i_large_nflushes,
2441      ctl_arena_stats_read_u64(
2442      &amp;arenas_i(mib[2])-&gt;astats-&gt;astats.nflushes_large), uint64_t)
2443  #define RO_MUTEX_CTL_GEN(n, l)						\
2444  CTL_RO_CGEN(config_stats, stats_##n##_num_ops,				\
2445      l.n_lock_ops, uint64_t)						\
2446  CTL_RO_CGEN(config_stats, stats_##n##_num_wait,				\
2447      l.n_wait_times, uint64_t)						\
2448  CTL_RO_CGEN(config_stats, stats_##n##_num_spin_acq,			\
2449      l.n_spin_acquired, uint64_t)					\
2450  CTL_RO_CGEN(config_stats, stats_##n##_num_owner_switch,			\
2451      l.n_owner_switches, uint64_t) 					\
2452  CTL_RO_CGEN(config_stats, stats_##n##_total_wait_time,			\
2453      nstime_ns(&amp;l.tot_wait_time), uint64_t)				\
2454  CTL_RO_CGEN(config_stats, stats_##n##_max_wait_time,			\
2455      nstime_ns(&amp;l.max_wait_time), uint64_t)				\
2456  CTL_RO_CGEN(config_stats, stats_##n##_max_num_thds,			\
2457      l.max_n_thds, uint32_t)
2458  #define OP(mtx)								\
2459      RO_MUTEX_CTL_GEN(mutexes_##mtx,					\
2460          ctl_stats-&gt;mutex_prof_data[global_prof_mutex_##mtx])
2461  MUTEX_PROF_GLOBAL_MUTEXES
2462  #undef OP
2463  #define OP(mtx) RO_MUTEX_CTL_GEN(arenas_i_mutexes_##mtx,		\
2464      arenas_i(mib[2])-&gt;astats-&gt;astats.mutex_prof_data[arena_prof_mutex_##mtx])
2465  MUTEX_PROF_ARENA_MUTEXES
2466  #undef OP
2467  RO_MUTEX_CTL_GEN(arenas_i_bins_j_mutex,
2468      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].mutex_data)
2469  #undef RO_MUTEX_CTL_GEN
2470  static int
2471  stats_mutexes_reset_ctl(tsd_t *tsd, const size_t *mib,
2472      size_t miblen, void *oldp, size_t *oldlenp,
2473      void *newp, size_t newlen) {
2474  	if (!config_stats) {
2475  		return ENOENT;
2476  	}
2477  	tsdn_t *tsdn = tsd_tsdn(tsd);
2478  #define MUTEX_PROF_RESET(mtx)						\
2479      malloc_mutex_lock(tsdn, &amp;mtx);					\
2480      malloc_mutex_prof_data_reset(tsdn, &amp;mtx);				\
2481      malloc_mutex_unlock(tsdn, &amp;mtx);
2482  	MUTEX_PROF_RESET(ctl_mtx);
2483  	if (have_background_thread) {
2484  		MUTEX_PROF_RESET(background_thread_lock);
2485  	}
2486  	if (config_prof &amp;&amp; opt_prof) {
2487  		MUTEX_PROF_RESET(bt2gctx_mtx);
2488  	}
2489  	unsigned n = narenas_total_get();
2490  	for (unsigned i = 0; i &lt; n; i++) {
2491  		arena_t *arena = arena_get(tsdn, i, false);
2492  		if (!arena) {
2493  			continue;
2494  		}
2495  		MUTEX_PROF_RESET(arena-&gt;large_mtx);
2496  		MUTEX_PROF_RESET(arena-&gt;extent_avail_mtx);
2497  		MUTEX_PROF_RESET(arena-&gt;extents_dirty.mtx);
2498  		MUTEX_PROF_RESET(arena-&gt;extents_muzzy.mtx);
2499  		MUTEX_PROF_RESET(arena-&gt;extents_retained.mtx);
2500  		MUTEX_PROF_RESET(arena-&gt;decay_dirty.mtx);
2501  		MUTEX_PROF_RESET(arena-&gt;decay_muzzy.mtx);
2502  		MUTEX_PROF_RESET(arena-&gt;tcache_ql_mtx);
2503  		MUTEX_PROF_RESET(arena-&gt;base-&gt;mtx);
2504  		for (szind_t i = 0; i &lt; SC_NBINS; i++) {
2505  			for (unsigned j = 0; j &lt; bin_infos[i].n_shards; j++) {
2506  				bin_t *bin = &amp;arena-&gt;bins[i].bin_shards[j];
2507  				MUTEX_PROF_RESET(bin-&gt;lock);
2508  			}
2509  		}
2510  	}
2511  #undef MUTEX_PROF_RESET
2512  	return 0;
2513  }
2514  CTL_RO_CGEN(config_stats, stats_arenas_i_bins_j_nmalloc,
2515      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].nmalloc, uint64_t)
2516  CTL_RO_CGEN(config_stats, stats_arenas_i_bins_j_ndalloc,
2517      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].ndalloc, uint64_t)
2518  CTL_RO_CGEN(config_stats, stats_arenas_i_bins_j_nrequests,
2519      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].nrequests, uint64_t)
2520  CTL_RO_CGEN(config_stats, stats_arenas_i_bins_j_curregs,
2521      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].curregs, size_t)
2522  CTL_RO_CGEN(config_stats, stats_arenas_i_bins_j_nfills,
2523      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].nfills, uint64_t)
2524  CTL_RO_CGEN(config_stats, stats_arenas_i_bins_j_nflushes,
2525      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].nflushes, uint64_t)
2526  CTL_RO_CGEN(config_stats, stats_arenas_i_bins_j_nslabs,
2527      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].nslabs, uint64_t)
2528  CTL_RO_CGEN(config_stats, stats_arenas_i_bins_j_nreslabs,
2529      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].reslabs, uint64_t)
2530  CTL_RO_CGEN(config_stats, stats_arenas_i_bins_j_curslabs,
2531      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].curslabs, size_t)
2532  CTL_RO_CGEN(config_stats, stats_arenas_i_bins_j_nonfull_slabs,
2533      arenas_i(mib[2])-&gt;astats-&gt;bstats[mib[4]].nonfull_slabs, size_t)
2534  static const ctl_named_node_t *
2535  stats_arenas_i_bins_j_index(tsdn_t *tsdn, const size_t *mib,
2536      size_t miblen, size_t j) {
2537  	if (j &gt; SC_NBINS) {
2538  		return NULL;
2539  	}
2540  	return super_stats_arenas_i_bins_j_node;
2541  }
2542  CTL_RO_CGEN(config_stats, stats_arenas_i_lextents_j_nmalloc,
2543      ctl_arena_stats_read_u64(
2544      &amp;arenas_i(mib[2])-&gt;astats-&gt;lstats[mib[4]].nmalloc), uint64_t)
2545  CTL_RO_CGEN(config_stats, stats_arenas_i_lextents_j_ndalloc,
2546      ctl_arena_stats_read_u64(
2547      &amp;arenas_i(mib[2])-&gt;astats-&gt;lstats[mib[4]].ndalloc), uint64_t)
2548  CTL_RO_CGEN(config_stats, stats_arenas_i_lextents_j_nrequests,
2549      ctl_arena_stats_read_u64(
2550      &amp;arenas_i(mib[2])-&gt;astats-&gt;lstats[mib[4]].nrequests), uint64_t)
2551  CTL_RO_CGEN(config_stats, stats_arenas_i_lextents_j_curlextents,
2552      arenas_i(mib[2])-&gt;astats-&gt;lstats[mib[4]].curlextents, size_t)
2553  static const ctl_named_node_t *
2554  stats_arenas_i_lextents_j_index(tsdn_t *tsdn, const size_t *mib,
2555      size_t miblen, size_t j) {
2556  	if (j &gt; SC_NSIZES - SC_NBINS) {
2557  		return NULL;
2558  	}
2559  	return super_stats_arenas_i_lextents_j_node;
2560  }
2561  CTL_RO_CGEN(config_stats, stats_arenas_i_extents_j_ndirty,
2562      atomic_load_zu(
2563          &amp;arenas_i(mib[2])-&gt;astats-&gt;estats[mib[4]].ndirty,
2564  	ATOMIC_RELAXED), size_t);
2565  CTL_RO_CGEN(config_stats, stats_arenas_i_extents_j_nmuzzy,
2566      atomic_load_zu(
2567          &amp;arenas_i(mib[2])-&gt;astats-&gt;estats[mib[4]].nmuzzy,
2568  	ATOMIC_RELAXED), size_t);
2569  CTL_RO_CGEN(config_stats, stats_arenas_i_extents_j_nretained,
2570      atomic_load_zu(
2571          &amp;arenas_i(mib[2])-&gt;astats-&gt;estats[mib[4]].nretained,
2572  	ATOMIC_RELAXED), size_t);
2573  CTL_RO_CGEN(config_stats, stats_arenas_i_extents_j_dirty_bytes,
2574      atomic_load_zu(
2575          &amp;arenas_i(mib[2])-&gt;astats-&gt;estats[mib[4]].dirty_bytes,
2576  	ATOMIC_RELAXED), size_t);
2577  CTL_RO_CGEN(config_stats, stats_arenas_i_extents_j_muzzy_bytes,
2578      atomic_load_zu(
2579          &amp;arenas_i(mib[2])-&gt;astats-&gt;estats[mib[4]].muzzy_bytes,
2580  	ATOMIC_RELAXED), size_t);
2581  CTL_RO_CGEN(config_stats, stats_arenas_i_extents_j_retained_bytes,
2582      atomic_load_zu(
2583          &amp;arenas_i(mib[2])-&gt;astats-&gt;estats[mib[4]].retained_bytes,
2584  	ATOMIC_RELAXED), size_t);
2585  static const ctl_named_node_t *
2586  stats_arenas_i_extents_j_index(tsdn_t *tsdn, const size_t *mib,
2587      size_t miblen, size_t j) {
2588  	if (j &gt;= SC_NPSIZES) {
2589  		return NULL;
2590  	}
2591  	return super_stats_arenas_i_extents_j_node;
2592  }
2593  static bool
2594  ctl_arenas_i_verify(size_t i) {
2595  	size_t a = arenas_i2a_impl(i, true, true);
2596  	if (a == UINT_MAX || !ctl_arenas-&gt;arenas[a]-&gt;initialized) {
2597  		return true;
2598  	}
2599  	return false;
2600  }
2601  static const ctl_named_node_t *
2602  stats_arenas_i_index(tsdn_t *tsdn, const size_t *mib,
2603      size_t miblen, size_t i) {
2604  	const ctl_named_node_t *ret;
2605  	malloc_mutex_lock(tsdn, &amp;ctl_mtx);
2606  	if (ctl_arenas_i_verify(i)) {
2607  		ret = NULL;
2608  		goto label_return;
2609  	}
2610  	ret = super_stats_arenas_i_node;
2611  label_return:
2612  	malloc_mutex_unlock(tsdn, &amp;ctl_mtx);
2613  	return ret;
2614  }
2615  static int
2616  experimental_hooks_install_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
2617      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2618  	int ret;
2619  	if (oldp == NULL || oldlenp == NULL|| newp == NULL) {
2620  		ret = EINVAL;
2621  		goto label_return;
2622  	}
2623  	hooks_t hooks;
2624  	WRITE(hooks, hooks_t);
2625  	void *handle = hook_install(tsd_tsdn(tsd), &amp;hooks);
2626  	if (handle == NULL) {
2627  		ret = EAGAIN;
2628  		goto label_return;
2629  	}
2630  	READ(handle, void *);
2631  	ret = 0;
2632  label_return:
2633  	return ret;
2634  }
2635  static int
2636  experimental_hooks_remove_ctl(tsd_t *tsd, const size_t *mib, size_t miblen,
2637      void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2638  	int ret;
2639  	WRITEONLY();
2640  	void *handle = NULL;
2641  	WRITE(handle, void *);
2642  	if (handle == NULL) {
2643  		ret = EINVAL;
2644  		goto label_return;
2645  	}
2646  	hook_remove(tsd_tsdn(tsd), handle);
2647  	ret = 0;
2648  label_return:
2649  	return ret;
2650  }
2651  static int
2652  experimental_utilization_query_ctl(tsd_t *tsd, const size_t *mib,
2653      size_t miblen, void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2654  	int ret;
2655  	assert(sizeof(extent_util_stats_verbose_t)
2656  	    == sizeof(void *) + sizeof(size_t) * 5);
2657  	if (oldp == NULL || oldlenp == NULL
2658  	    || *oldlenp != sizeof(extent_util_stats_verbose_t)
2659  	    || newp == NULL) {
2660  		ret = EINVAL;
2661  		goto label_return;
2662  	}
2663  	void *ptr = NULL;
2664  	WRITE(ptr, void *);
2665  	extent_util_stats_verbose_t *util_stats
2666  	    = (extent_util_stats_verbose_t *)oldp;
2667  	extent_util_stats_verbose_get(tsd_tsdn(tsd), ptr,
2668  	    &amp;util_stats-&gt;nfree, &amp;util_stats-&gt;nregs, &amp;util_stats-&gt;size,
2669  	    &amp;util_stats-&gt;bin_nfree, &amp;util_stats-&gt;bin_nregs,
2670  	    &amp;util_stats-&gt;slabcur_addr);
2671  	ret = 0;
2672  label_return:
2673  	return ret;
2674  }
2675  static int
2676  experimental_utilization_batch_query_ctl(tsd_t *tsd, const size_t *mib,
2677      size_t miblen, void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2678  	int ret;
2679  	assert(sizeof(extent_util_stats_t) == sizeof(size_t) * 3);
2680  	const size_t len = newlen / sizeof(const void *);
2681  	if (oldp == NULL || oldlenp == NULL || newp == NULL || newlen == 0
2682  	    || newlen != len * sizeof(const void *)
2683  	    || *oldlenp != len * sizeof(extent_util_stats_t)) {
2684  		ret = EINVAL;
2685  		goto label_return;
2686  	}
2687  	void **ptrs = (void **)newp;
2688  	extent_util_stats_t *util_stats = (extent_util_stats_t *)oldp;
2689  	size_t i;
2690  	for (i = 0; i &lt; len; ++i) {
2691  		extent_util_stats_get(tsd_tsdn(tsd), ptrs[i],
2692  		    &amp;util_stats[i].nfree, &amp;util_stats[i].nregs,
2693  		    &amp;util_stats[i].size);
2694  	}
2695  	ret = 0;
2696  label_return:
2697  	return ret;
2698  }
2699  static const ctl_named_node_t *
2700  experimental_arenas_i_index(tsdn_t *tsdn, const size_t *mib,
2701      size_t miblen, size_t i) {
2702  	const ctl_named_node_t *ret;
2703  	malloc_mutex_lock(tsdn, &amp;ctl_mtx);
2704  	if (ctl_arenas_i_verify(i)) {
2705  		ret = NULL;
2706  		goto label_return;
2707  	}
2708  	ret = super_experimental_arenas_i_node;
2709  label_return:
2710  	malloc_mutex_unlock(tsdn, &amp;ctl_mtx);
2711  	return ret;
2712  }
2713  static int
2714  experimental_arenas_i_pactivep_ctl(tsd_t *tsd, const size_t *mib,
2715      size_t miblen, void *oldp, size_t *oldlenp, void *newp, size_t newlen) {
2716  	if (!config_stats) {
2717  		return ENOENT;
2718  	}
2719  	if (oldp == NULL || oldlenp == NULL || *oldlenp != sizeof(size_t *)) {
2720  		return EINVAL;
2721  	}
2722  	unsigned arena_ind;
2723  	arena_t *arena;
2724  	int ret;
2725  	size_t *pactivep;
2726  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;ctl_mtx);
2727  	READONLY();
2728  	MIB_UNSIGNED(arena_ind, 2);
2729  	if (arena_ind &lt; narenas_total_get() &amp;&amp; (arena =
2730  	    arena_get(tsd_tsdn(tsd), arena_ind, false)) != NULL) {
2731  #if defined(JEMALLOC_GCC_ATOMIC_ATOMICS) ||				\
2732      defined(JEMALLOC_GCC_SYNC_ATOMICS) || defined(_MSC_VER)
2733  		pactivep = (size_t *)&amp;(arena-&gt;nactive.repr);
2734  		READ(pactivep, size_t *);
2735  		ret = 0;
2736  #else
2737  		ret = EFAULT;
2738  #endif
2739  	} else {
2740  		ret = EFAULT;
2741  	}
2742  label_return:
2743  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;ctl_mtx);
2744  	return ret;
2745  }
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from libtomcrypt-MDEwOlJlcG9zaXRvcnk3NzcwMTE=-flat-chacha20poly1305_memory.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-ctl.c</div>
                </div>
                <div class="column column_space"><pre><code>34           err = CRYPT_ERROR;
35           goto LBL_ERR;
36        }
37     }
38     else {
39        err = CRYPT_INVALID_ARG;
40        goto LBL_ERR;
</pre></code></div>
                <div class="column column_space"><pre><code>1461  				ret = EFAULT;
1462  				goto label_return;
1463  			}
1464  		} else {
1465  			max_background_threads = newval;
1466  		}
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    