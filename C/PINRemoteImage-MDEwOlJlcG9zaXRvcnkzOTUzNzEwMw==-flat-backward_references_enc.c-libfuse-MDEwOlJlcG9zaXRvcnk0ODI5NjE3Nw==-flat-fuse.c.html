
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 18, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-backward_references_enc.c</h3>
            <pre><code>1  #include <assert.h>
2  #include <math.h>
3  #include "src/enc/backward_references_enc.h"
4  #include "src/enc/histogram_enc.h"
5  #include "src/dsp/lossless.h"
6  #include "src/dsp/lossless_common.h"
7  #include "src/dsp/dsp.h"
8  #include "src/utils/color_cache_utils.h"
9  #include "src/utils/utils.h"
10  #define MIN_BLOCK_SIZE 256  
11  #define MAX_ENTROPY    (1e30f)
12  #define WINDOW_SIZE ((1 << WINDOW_SIZE_BITS) - 120)
13  #define MIN_LENGTH 4
14  static const uint8_t plane_to_code_lut[128] = {
15   96,   73,  55,  39,  23,  13,   5,  1,  255, 255, 255, 255, 255, 255, 255, 255,
16   101,  78,  58,  42,  26,  16,   8,  2,    0,   3,  9,   17,  27,  43,  59,  79,
17   102,  86,  62,  46,  32,  20,  10,  6,    4,   7,  11,  21,  33,  47,  63,  87,
18   105,  90,  70,  52,  37,  28,  18,  14,  12,  15,  19,  29,  38,  53,  71,  91,
19   110,  99,  82,  66,  48,  35,  30,  24,  22,  25,  31,  36,  49,  67,  83, 100,
20   115, 108,  94,  76,  64,  50,  44,  40,  34,  41,  45,  51,  65,  77,  95, 109,
21   118, 113, 103,  92,  80,  68,  60,  56,  54,  57,  61,  69,  81,  93, 104, 114,
22   119, 116, 111, 106,  97,  88,  84,  74,  72,  75,  85,  89,  98, 107, 112, 117
23  };
24  extern int VP8LDistanceToPlaneCode(int xsize, int dist);
25  int VP8LDistanceToPlaneCode(int xsize, int dist) {
26    const int yoffset = dist / xsize;
27    const int xoffset = dist - yoffset * xsize;
28    if (xoffset <= 8 && yoffset < 8) {
29      return plane_to_code_lut[yoffset * 16 + 8 - xoffset] + 1;
30    } else if (xoffset > xsize - 8 && yoffset < 7) {
31      return plane_to_code_lut[(yoffset + 1) * 16 + 8 + (xsize - xoffset)] + 1;
32    }
33    return dist + 120;
34  }
35  static WEBP_INLINE int FindMatchLength(const uint32_t* const array1,
36                                         const uint32_t* const array2,
37                                         int best_len_match, int max_limit) {
38    if (array1[best_len_match] != array2[best_len_match]) return 0;
39    return VP8LVectorMismatch(array1, array2, max_limit);
40  }
41  struct PixOrCopyBlock {
42    PixOrCopyBlock* next_;   
43    PixOrCopy* start_;       
44    int size_;               
45  };
46  extern void VP8LClearBackwardRefs(VP8LBackwardRefs* const refs);
47  void VP8LClearBackwardRefs(VP8LBackwardRefs* const refs) {
48    assert(refs != NULL);
49    if (refs->tail_ != NULL) {
50      *refs->tail_ = refs->free_blocks_;  
51    }
52    refs->free_blocks_ = refs->refs_;
53    refs->tail_ = &refs->refs_;
54    refs->last_block_ = NULL;
55    refs->refs_ = NULL;
56  }
57  void VP8LBackwardRefsClear(VP8LBackwardRefs* const refs) {
58    assert(refs != NULL);
59    VP8LClearBackwardRefs(refs);
60    while (refs->free_blocks_ != NULL) {
61      PixOrCopyBlock* const next = refs->free_blocks_->next_;
62      WebPSafeFree(refs->free_blocks_);
63      refs->free_blocks_ = next;
64    }
65  }
66  void VP8LBackwardRefsInit(VP8LBackwardRefs* const refs, int block_size) {
67    assert(refs != NULL);
68    memset(refs, 0, sizeof(*refs));
69    refs->tail_ = &refs->refs_;
70    refs->block_size_ =
71        (block_size < MIN_BLOCK_SIZE) ? MIN_BLOCK_SIZE : block_size;
72  }
73  VP8LRefsCursor VP8LRefsCursorInit(const VP8LBackwardRefs* const refs) {
74    VP8LRefsCursor c;
75    c.cur_block_ = refs->refs_;
76    if (refs->refs_ != NULL) {
77      c.cur_pos = c.cur_block_->start_;
78      c.last_pos_ = c.cur_pos + c.cur_block_->size_;
79    } else {
80      c.cur_pos = NULL;
81      c.last_pos_ = NULL;
82    }
83    return c;
84  }
85  void VP8LRefsCursorNextBlock(VP8LRefsCursor* const c) {
86    PixOrCopyBlock* const b = c->cur_block_->next_;
87    c->cur_pos = (b == NULL) ? NULL : b->start_;
88    c->last_pos_ = (b == NULL) ? NULL : b->start_ + b->size_;
89    c->cur_block_ = b;
90  }
91  static PixOrCopyBlock* BackwardRefsNewBlock(VP8LBackwardRefs* const refs) {
92    PixOrCopyBlock* b = refs->free_blocks_;
93    if (b == NULL) {   
94      const size_t total_size =
95          sizeof(*b) + refs->block_size_ * sizeof(*b->start_);
96      b = (PixOrCopyBlock*)WebPSafeMalloc(1ULL, total_size);
97      if (b == NULL) {
98        refs->error_ |= 1;
99        return NULL;
100      }
101      b->start_ = (PixOrCopy*)((uint8_t*)b + sizeof(*b));  
102    } else {  
103      refs->free_blocks_ = b->next_;
104    }
105    *refs->tail_ = b;
106    refs->tail_ = &b->next_;
107    refs->last_block_ = b;
108    b->next_ = NULL;
109    b->size_ = 0;
110    return b;
111  }
112  extern void VP8LBackwardRefsCursorAdd(VP8LBackwardRefs* const refs,
113                                        const PixOrCopy v);
114  void VP8LBackwardRefsCursorAdd(VP8LBackwardRefs* const refs,
115                                 const PixOrCopy v) {
116    PixOrCopyBlock* b = refs->last_block_;
117    if (b == NULL || b->size_ == refs->block_size_) {
118      b = BackwardRefsNewBlock(refs);
119      if (b == NULL) return;   
120    }
121    b->start_[b->size_++] = v;
122  }
123  int VP8LHashChainInit(VP8LHashChain* const p, int size) {
124    assert(p->size_ == 0);
125    assert(p->offset_length_ == NULL);
126    assert(size > 0);
127    p->offset_length_ =
128        (uint32_t*)WebPSafeMalloc(size, sizeof(*p->offset_length_));
129    if (p->offset_length_ == NULL) return 0;
130    p->size_ = size;
131    return 1;
132  }
133  void VP8LHashChainClear(VP8LHashChain* const p) {
134    assert(p != NULL);
135    WebPSafeFree(p->offset_length_);
136    p->size_ = 0;
137    p->offset_length_ = NULL;
138  }
139  static const uint32_t kHashMultiplierHi = 0xc6a4a793u;
140  static const uint32_t kHashMultiplierLo = 0x5bd1e996u;
141  static WEBP_UBSAN_IGNORE_UNSIGNED_OVERFLOW WEBP_INLINE
142  uint32_t GetPixPairHash64(const uint32_t* const argb) {
143    uint32_t key;
144    key  = argb[1] * kHashMultiplierHi;
145    key += argb[0] * kHashMultiplierLo;
146    key = key >> (32 - HASH_BITS);
147    return key;
148  }
149  static int GetMaxItersForQuality(int quality) {
150    return 8 + (quality * quality) / 128;
151  }
152  static int GetWindowSizeForHashChain(int quality, int xsize) {
153    const int max_window_size = (quality > 75) ? WINDOW_SIZE
154                              : (quality > 50) ? (xsize << 8)
155                              : (quality > 25) ? (xsize << 6)
156                              : (xsize << 4);
157    assert(xsize > 0);
158    return (max_window_size > WINDOW_SIZE) ? WINDOW_SIZE : max_window_size;
159  }
160  static WEBP_INLINE int MaxFindCopyLength(int len) {
161    return (len < MAX_LENGTH) ? len : MAX_LENGTH;
162  }
163  int VP8LHashChainFill(VP8LHashChain* const p, int quality,
164                        const uint32_t* const argb, int xsize, int ysize,
165                        int low_effort) {
166    const int size = xsize * ysize;
167    const int iter_max = GetMaxItersForQuality(quality);
168    const uint32_t window_size = GetWindowSizeForHashChain(quality, xsize);
169    int pos;
170    int argb_comp;
171    uint32_t base_position;
172    int32_t* hash_to_first_index;
173    int32_t* chain = (int32_t*)p->offset_length_;
174    assert(size > 0);
<span onclick='openModal()' class='match'>175    assert(p->size_ != 0);
176    assert(p->offset_length_ != NULL);
177    if (size <= 2) {
</span>178      p->offset_length_[0] = p->offset_length_[size - 1] = 0;
179      return 1;
180    }
181    hash_to_first_index =
182        (int32_t*)WebPSafeMalloc(HASH_SIZE, sizeof(*hash_to_first_index));
183    if (hash_to_first_index == NULL) return 0;
184    memset(hash_to_first_index, 0xff, HASH_SIZE * sizeof(*hash_to_first_index));
185    argb_comp = (argb[0] == argb[1]);
186    for (pos = 0; pos < size - 2;) {
187      uint32_t hash_code;
188      const int argb_comp_next = (argb[pos + 1] == argb[pos + 2]);
189      if (argb_comp && argb_comp_next) {
190        uint32_t tmp[2];
191        uint32_t len = 1;
192        tmp[0] = argb[pos];
193        while (pos + (int)len + 2 < size && argb[pos + len + 2] == argb[pos]) {
194          ++len;
195        }
196        if (len > MAX_LENGTH) {
197          memset(chain + pos, 0xff, (len - MAX_LENGTH) * sizeof(*chain));
198          pos += len - MAX_LENGTH;
199          len = MAX_LENGTH;
200        }
201        while (len) {
202          tmp[1] = len--;
203          hash_code = GetPixPairHash64(tmp);
204          chain[pos] = hash_to_first_index[hash_code];
205          hash_to_first_index[hash_code] = pos++;
206        }
207        argb_comp = 0;
208      } else {
209        hash_code = GetPixPairHash64(argb + pos);
210        chain[pos] = hash_to_first_index[hash_code];
211        hash_to_first_index[hash_code] = pos++;
212        argb_comp = argb_comp_next;
213      }
214    }
215    chain[pos] = hash_to_first_index[GetPixPairHash64(argb + pos)];
216    WebPSafeFree(hash_to_first_index);
217    assert(size > 2);
218    p->offset_length_[0] = p->offset_length_[size - 1] = 0;
219    for (base_position = size - 2; base_position > 0;) {
220      const int max_len = MaxFindCopyLength(size - 1 - base_position);
221      const uint32_t* const argb_start = argb + base_position;
222      int iter = iter_max;
223      int best_length = 0;
224      uint32_t best_distance = 0;
225      uint32_t best_argb;
226      const int min_pos =
227          (base_position > window_size) ? base_position - window_size : 0;
228      const int length_max = (max_len < 256) ? max_len : 256;
229      uint32_t max_base_position;
230      pos = chain[base_position];
231      if (!low_effort) {
232        int curr_length;
233        if (base_position >= (uint32_t)xsize) {
234          curr_length = FindMatchLength(argb_start - xsize, argb_start,
235                                        best_length, max_len);
236          if (curr_length > best_length) {
237            best_length = curr_length;
238            best_distance = xsize;
239          }
240          --iter;
241        }
242        curr_length =
243            FindMatchLength(argb_start - 1, argb_start, best_length, max_len);
244        if (curr_length > best_length) {
245          best_length = curr_length;
246          best_distance = 1;
247        }
248        --iter;
249        if (best_length == MAX_LENGTH) pos = min_pos - 1;
250      }
251      best_argb = argb_start[best_length];
252      for (; pos >= min_pos && --iter; pos = chain[pos]) {
253        int curr_length;
254        assert(base_position > (uint32_t)pos);
255        if (argb[pos + best_length] != best_argb) continue;
256        curr_length = VP8LVectorMismatch(argb + pos, argb_start, max_len);
257        if (best_length < curr_length) {
258          best_length = curr_length;
259          best_distance = base_position - pos;
260          best_argb = argb_start[best_length];
261          if (best_length >= length_max) break;
262        }
263      }
264      max_base_position = base_position;
265      while (1) {
266        assert(best_length <= MAX_LENGTH);
267        assert(best_distance <= WINDOW_SIZE);
268        p->offset_length_[base_position] =
269            (best_distance << MAX_LENGTH_BITS) | (uint32_t)best_length;
270        --base_position;
271        if (best_distance == 0 || base_position == 0) break;
272        if (base_position < best_distance ||
273            argb[base_position - best_distance] != argb[base_position]) {
274          break;
275        }
276        if (best_length == MAX_LENGTH && best_distance != 1 &&
277            base_position + MAX_LENGTH < max_base_position) {
278          break;
279        }
280        if (best_length < MAX_LENGTH) {
281          ++best_length;
282          max_base_position = base_position;
283        }
284      }
285    }
286    return 1;
287  }
288  static WEBP_INLINE void AddSingleLiteral(uint32_t pixel, int use_color_cache,
289                                           VP8LColorCache* const hashers,
290                                           VP8LBackwardRefs* const refs) {
291    PixOrCopy v;
292    if (use_color_cache) {
293      const uint32_t key = VP8LColorCacheGetIndex(hashers, pixel);
294      if (VP8LColorCacheLookup(hashers, key) == pixel) {
295        v = PixOrCopyCreateCacheIdx(key);
296      } else {
297        v = PixOrCopyCreateLiteral(pixel);
298        VP8LColorCacheSet(hashers, key, pixel);
299      }
300    } else {
301      v = PixOrCopyCreateLiteral(pixel);
302    }
303    VP8LBackwardRefsCursorAdd(refs, v);
304  }
305  static int BackwardReferencesRle(int xsize, int ysize,
306                                   const uint32_t* const argb,
307                                   int cache_bits, VP8LBackwardRefs* const refs) {
308    const int pix_count = xsize * ysize;
309    int i, k;
310    const int use_color_cache = (cache_bits > 0);
311    VP8LColorCache hashers;
312    if (use_color_cache && !VP8LColorCacheInit(&hashers, cache_bits)) {
313      return 0;
314    }
315    VP8LClearBackwardRefs(refs);
316    AddSingleLiteral(argb[0], use_color_cache, &hashers, refs);
317    i = 1;
318    while (i < pix_count) {
319      const int max_len = MaxFindCopyLength(pix_count - i);
320      const int rle_len = FindMatchLength(argb + i, argb + i - 1, 0, max_len);
321      const int prev_row_len = (i < xsize) ? 0 :
322          FindMatchLength(argb + i, argb + i - xsize, 0, max_len);
323      if (rle_len >= prev_row_len && rle_len >= MIN_LENGTH) {
324        VP8LBackwardRefsCursorAdd(refs, PixOrCopyCreateCopy(1, rle_len));
325        i += rle_len;
326      } else if (prev_row_len >= MIN_LENGTH) {
327        VP8LBackwardRefsCursorAdd(refs, PixOrCopyCreateCopy(xsize, prev_row_len));
328        if (use_color_cache) {
329          for (k = 0; k < prev_row_len; ++k) {
330            VP8LColorCacheInsert(&hashers, argb[i + k]);
331          }
332        }
333        i += prev_row_len;
334      } else {
335        AddSingleLiteral(argb[i], use_color_cache, &hashers, refs);
336        i++;
337      }
338    }
339    if (use_color_cache) VP8LColorCacheClear(&hashers);
340    return !refs->error_;
341  }
342  static int BackwardReferencesLz77(int xsize, int ysize,
343                                    const uint32_t* const argb, int cache_bits,
344                                    const VP8LHashChain* const hash_chain,
345                                    VP8LBackwardRefs* const refs) {
346    int i;
347    int i_last_check = -1;
348    int ok = 0;
349    int cc_init = 0;
350    const int use_color_cache = (cache_bits > 0);
351    const int pix_count = xsize * ysize;
352    VP8LColorCache hashers;
353    if (use_color_cache) {
354      cc_init = VP8LColorCacheInit(&hashers, cache_bits);
355      if (!cc_init) goto Error;
356    }
357    VP8LClearBackwardRefs(refs);
358    for (i = 0; i < pix_count;) {
359      int offset = 0;
360      int len = 0;
361      int j;
362      VP8LHashChainFindCopy(hash_chain, i, &offset, &len);
363      if (len >= MIN_LENGTH) {
364        const int len_ini = len;
365        int max_reach = 0;
366        const int j_max =
367            (i + len_ini >= pix_count) ? pix_count - 1 : i + len_ini;
368        i_last_check = (i > i_last_check) ? i : i_last_check;
369        for (j = i_last_check + 1; j <= j_max; ++j) {
370          const int len_j = VP8LHashChainFindLength(hash_chain, j);
371          const int reach =
372              j + (len_j >= MIN_LENGTH ? len_j : 1);  
373          if (reach > max_reach) {
374            len = j - i;
375            max_reach = reach;
376            if (max_reach >= pix_count) break;
377          }
378        }
379      } else {
380        len = 1;
381      }
382      assert(len > 0);
383      if (len == 1) {
384        AddSingleLiteral(argb[i], use_color_cache, &hashers, refs);
385      } else {
386        VP8LBackwardRefsCursorAdd(refs, PixOrCopyCreateCopy(offset, len));
387        if (use_color_cache) {
388          for (j = i; j < i + len; ++j) VP8LColorCacheInsert(&hashers, argb[j]);
389        }
390      }
391      i += len;
392    }
393    ok = !refs->error_;
394   Error:
395    if (cc_init) VP8LColorCacheClear(&hashers);
396    return ok;
397  }
398  #define WINDOW_OFFSETS_SIZE_MAX 32
399  static int BackwardReferencesLz77Box(int xsize, int ysize,
400                                       const uint32_t* const argb, int cache_bits,
401                                       const VP8LHashChain* const hash_chain_best,
402                                       VP8LHashChain* hash_chain,
403                                       VP8LBackwardRefs* const refs) {
404    int i;
405    const int pix_count = xsize * ysize;
406    uint16_t* counts;
407    int window_offsets[WINDOW_OFFSETS_SIZE_MAX] = {0};
408    int window_offsets_new[WINDOW_OFFSETS_SIZE_MAX] = {0};
409    int window_offsets_size = 0;
410    int window_offsets_new_size = 0;
411    uint16_t* const counts_ini =
412        (uint16_t*)WebPSafeMalloc(xsize * ysize, sizeof(*counts_ini));
413    int best_offset_prev = -1, best_length_prev = -1;
414    if (counts_ini == NULL) return 0;
415    i = pix_count - 2;
416    counts = counts_ini + i;
417    counts[1] = 1;
418    for (; i >= 0; --i, --counts) {
419      if (argb[i] == argb[i + 1]) {
420        counts[0] = counts[1] + (counts[1] != MAX_LENGTH);
421      } else {
422        counts[0] = 1;
423      }
424    }
425    {
426      int x, y;
427      for (y = 0; y <= 6; ++y) {
428        for (x = -6; x <= 6; ++x) {
429          const int offset = y * xsize + x;
430          int plane_code;
431          if (offset <= 0) continue;
432          plane_code = VP8LDistanceToPlaneCode(xsize, offset) - 1;
433          if (plane_code >= WINDOW_OFFSETS_SIZE_MAX) continue;
434          window_offsets[plane_code] = offset;
435        }
436      }
437      for (i = 0; i < WINDOW_OFFSETS_SIZE_MAX; ++i) {
438        if (window_offsets[i] == 0) continue;
439        window_offsets[window_offsets_size++] = window_offsets[i];
440      }
441      for (i = 0; i < window_offsets_size; ++i) {
442        int j;
443        int is_reachable = 0;
444        for (j = 0; j < window_offsets_size && !is_reachable; ++j) {
445          is_reachable |= (window_offsets[i] == window_offsets[j] + 1);
446        }
447        if (!is_reachable) {
448          window_offsets_new[window_offsets_new_size] = window_offsets[i];
449          ++window_offsets_new_size;
450        }
451      }
452    }
453    hash_chain->offset_length_[0] = 0;
454    for (i = 1; i < pix_count; ++i) {
455      int ind;
456      int best_length = VP8LHashChainFindLength(hash_chain_best, i);
457      int best_offset;
458      int do_compute = 1;
459      if (best_length >= MAX_LENGTH) {
460        best_offset = VP8LHashChainFindOffset(hash_chain_best, i);
461        for (ind = 0; ind < window_offsets_size; ++ind) {
462          if (best_offset == window_offsets[ind]) {
463            do_compute = 0;
464            break;
465          }
466        }
467      }
468      if (do_compute) {
469        const int use_prev =
470            (best_length_prev > 1) && (best_length_prev < MAX_LENGTH);
471        const int num_ind =
472            use_prev ? window_offsets_new_size : window_offsets_size;
473        best_length = use_prev ? best_length_prev - 1 : 0;
474        best_offset = use_prev ? best_offset_prev : 0;
475        for (ind = 0; ind < num_ind; ++ind) {
476          int curr_length = 0;
477          int j = i;
478          int j_offset =
479              use_prev ? i - window_offsets_new[ind] : i - window_offsets[ind];
480          if (j_offset < 0 || argb[j_offset] != argb[i]) continue;
481          do {
482            const int counts_j_offset = counts_ini[j_offset];
483            const int counts_j = counts_ini[j];
484            if (counts_j_offset != counts_j) {
485              curr_length +=
486                  (counts_j_offset < counts_j) ? counts_j_offset : counts_j;
487              break;
488            }
489            curr_length += counts_j_offset;
490            j_offset += counts_j_offset;
491            j += counts_j_offset;
492          } while (curr_length <= MAX_LENGTH && j < pix_count &&
493                   argb[j_offset] == argb[j]);
494          if (best_length < curr_length) {
495            best_offset =
496                use_prev ? window_offsets_new[ind] : window_offsets[ind];
497            if (curr_length >= MAX_LENGTH) {
498              best_length = MAX_LENGTH;
499              break;
500            } else {
501              best_length = curr_length;
502            }
503          }
504        }
505      }
506      assert(i + best_length <= pix_count);
507      assert(best_length <= MAX_LENGTH);
508      if (best_length <= MIN_LENGTH) {
509        hash_chain->offset_length_[i] = 0;
510        best_offset_prev = 0;
511        best_length_prev = 0;
512      } else {
513        hash_chain->offset_length_[i] =
514            (best_offset << MAX_LENGTH_BITS) | (uint32_t)best_length;
515        best_offset_prev = best_offset;
516        best_length_prev = best_length;
517      }
518    }
519    hash_chain->offset_length_[0] = 0;
520    WebPSafeFree(counts_ini);
521    return BackwardReferencesLz77(xsize, ysize, argb, cache_bits, hash_chain,
522                                  refs);
523  }
524  static void BackwardReferences2DLocality(int xsize,
525                                           const VP8LBackwardRefs* const refs) {
526    VP8LRefsCursor c = VP8LRefsCursorInit(refs);
527    while (VP8LRefsCursorOk(&c)) {
528      if (PixOrCopyIsCopy(c.cur_pos)) {
529        const int dist = c.cur_pos->argb_or_distance;
530        const int transformed_dist = VP8LDistanceToPlaneCode(xsize, dist);
531        c.cur_pos->argb_or_distance = transformed_dist;
532      }
533      VP8LRefsCursorNext(&c);
534    }
535  }
536  static int CalculateBestCacheSize(const uint32_t* argb, int quality,
537                                    const VP8LBackwardRefs* const refs,
538                                    int* const best_cache_bits) {
539    int i;
540    const int cache_bits_max = (quality <= 25) ? 0 : *best_cache_bits;
541    double entropy_min = MAX_ENTROPY;
542    int cc_init[MAX_COLOR_CACHE_BITS + 1] = { 0 };
543    VP8LColorCache hashers[MAX_COLOR_CACHE_BITS + 1];
544    VP8LRefsCursor c = VP8LRefsCursorInit(refs);
545    VP8LHistogram* histos[MAX_COLOR_CACHE_BITS + 1] = { NULL };
546    int ok = 0;
547    assert(cache_bits_max >= 0 && cache_bits_max <= MAX_COLOR_CACHE_BITS);
548    if (cache_bits_max == 0) {
549      *best_cache_bits = 0;
550      return 1;
551    }
552    for (i = 0; i <= cache_bits_max; ++i) {
553      histos[i] = VP8LAllocateHistogram(i);
554      if (histos[i] == NULL) goto Error;
555      VP8LHistogramInit(histos[i], i, &bsol;*init_arrays=*/ 1);
556      if (i == 0) continue;
557      cc_init[i] = VP8LColorCacheInit(&hashers[i], i);
558      if (!cc_init[i]) goto Error;
559    }
560    while (VP8LRefsCursorOk(&c)) {
561      const PixOrCopy* const v = c.cur_pos;
562      if (PixOrCopyIsLiteral(v)) {
563        const uint32_t pix = *argb++;
564        const uint32_t a = (pix >> 24) & 0xff;
565        const uint32_t r = (pix >> 16) & 0xff;
566        const uint32_t g = (pix >>  8) & 0xff;
567        const uint32_t b = (pix >>  0) & 0xff;
568        int key = VP8LHashPix(pix, 32 - cache_bits_max);
569        ++histos[0]->blue_[b];
570        ++histos[0]->literal_[g];
571        ++histos[0]->red_[r];
572        ++histos[0]->alpha_[a];
573        for (i = cache_bits_max; i >= 1; --i, key >>= 1) {
574          if (VP8LColorCacheLookup(&hashers[i], key) == pix) {
575            ++histos[i]->literal_[NUM_LITERAL_CODES + NUM_LENGTH_CODES + key];
576          } else {
577            VP8LColorCacheSet(&hashers[i], key, pix);
578            ++histos[i]->blue_[b];
579            ++histos[i]->literal_[g];
580            ++histos[i]->red_[r];
581            ++histos[i]->alpha_[a];
582          }
583        }
584      } else {
585        int len = PixOrCopyLength(v);
586        uint32_t argb_prev = *argb ^ 0xffffffffu;
587        do {
588          if (*argb != argb_prev) {
589            int key = VP8LHashPix(*argb, 32 - cache_bits_max);
590            for (i = cache_bits_max; i >= 1; --i, key >>= 1) {
591              hashers[i].colors_[key] = *argb;
592            }
593            argb_prev = *argb;
594          }
595          argb++;
596        } while (--len != 0);
597      }
598      VP8LRefsCursorNext(&c);
599    }
600    for (i = 0; i <= cache_bits_max; ++i) {
601      const double entropy = VP8LHistogramEstimateBits(histos[i]);
602      if (i == 0 || entropy < entropy_min) {
603        entropy_min = entropy;
604        *best_cache_bits = i;
605      }
606    }
607    ok = 1;
608  Error:
609    for (i = 0; i <= cache_bits_max; ++i) {
610      if (cc_init[i]) VP8LColorCacheClear(&hashers[i]);
611      VP8LFreeHistogram(histos[i]);
612    }
613    return ok;
614  }
615  static int BackwardRefsWithLocalCache(const uint32_t* const argb,
616                                        int cache_bits,
617                                        VP8LBackwardRefs* const refs) {
618    int pixel_index = 0;
619    VP8LColorCache hashers;
620    VP8LRefsCursor c = VP8LRefsCursorInit(refs);
621    if (!VP8LColorCacheInit(&hashers, cache_bits)) return 0;
622    while (VP8LRefsCursorOk(&c)) {
623      PixOrCopy* const v = c.cur_pos;
624      if (PixOrCopyIsLiteral(v)) {
625        const uint32_t argb_literal = v->argb_or_distance;
626        const int ix = VP8LColorCacheContains(&hashers, argb_literal);
627        if (ix >= 0) {
628          *v = PixOrCopyCreateCacheIdx(ix);
629        } else {
630          VP8LColorCacheInsert(&hashers, argb_literal);
631        }
632        ++pixel_index;
633      } else {
634        int k;
635        assert(PixOrCopyIsCopy(v));
636        for (k = 0; k < v->len; ++k) {
637          VP8LColorCacheInsert(&hashers, argb[pixel_index++]);
638        }
639      }
640      VP8LRefsCursorNext(&c);
641    }
642    VP8LColorCacheClear(&hashers);
643    return 1;
644  }
645  static VP8LBackwardRefs* GetBackwardReferencesLowEffort(
646      int width, int height, const uint32_t* const argb,
647      int* const cache_bits, const VP8LHashChain* const hash_chain,
648      VP8LBackwardRefs* const refs_lz77) {
649    *cache_bits = 0;
650    if (!BackwardReferencesLz77(width, height, argb, 0, hash_chain, refs_lz77)) {
651      return NULL;
652    }
653    BackwardReferences2DLocality(width, refs_lz77);
654    return refs_lz77;
655  }
656  extern int VP8LBackwardReferencesTraceBackwards(
657      int xsize, int ysize, const uint32_t* const argb, int cache_bits,
658      const VP8LHashChain* const hash_chain,
659      const VP8LBackwardRefs* const refs_src, VP8LBackwardRefs* const refs_dst);
660  static VP8LBackwardRefs* GetBackwardReferences(
661      int width, int height, const uint32_t* const argb, int quality,
662      int lz77_types_to_try, int* const cache_bits,
663      const VP8LHashChain* const hash_chain, VP8LBackwardRefs* best,
664      VP8LBackwardRefs* worst) {
665    const int cache_bits_initial = *cache_bits;
666    double bit_cost_best = -1;
667    VP8LHistogram* histo = NULL;
668    int lz77_type, lz77_type_best = 0;
669    VP8LHashChain hash_chain_box;
670    memset(&hash_chain_box, 0, sizeof(hash_chain_box));
671    histo = VP8LAllocateHistogram(MAX_COLOR_CACHE_BITS);
672    if (histo == NULL) goto Error;
673    for (lz77_type = 1; lz77_types_to_try;
674         lz77_types_to_try &= ~lz77_type, lz77_type <<= 1) {
675      int res = 0;
676      double bit_cost;
677      int cache_bits_tmp = cache_bits_initial;
678      if ((lz77_types_to_try & lz77_type) == 0) continue;
679      switch (lz77_type) {
680        case kLZ77RLE:
681          res = BackwardReferencesRle(width, height, argb, 0, worst);
682          break;
683        case kLZ77Standard:
684          res = BackwardReferencesLz77(width, height, argb, 0, hash_chain, worst);
685          break;
686        case kLZ77Box:
687          if (!VP8LHashChainInit(&hash_chain_box, width * height)) goto Error;
688          res = BackwardReferencesLz77Box(width, height, argb, 0, hash_chain,
689                                          &hash_chain_box, worst);
690          break;
691        default:
692          assert(0);
693      }
694      if (!res) goto Error;
695      if (!CalculateBestCacheSize(argb, quality, worst, &cache_bits_tmp)) {
696        goto Error;
697      }
698      if (cache_bits_tmp > 0) {
699        if (!BackwardRefsWithLocalCache(argb, cache_bits_tmp, worst)) {
700          goto Error;
701        }
702      }
703      VP8LHistogramCreate(histo, worst, cache_bits_tmp);
704      bit_cost = VP8LHistogramEstimateBits(histo);
705      if (lz77_type_best == 0 || bit_cost < bit_cost_best) {
706        VP8LBackwardRefs* const tmp = worst;
707        worst = best;
708        best = tmp;
709        bit_cost_best = bit_cost;
710        *cache_bits = cache_bits_tmp;
711        lz77_type_best = lz77_type;
712      }
713    }
714    assert(lz77_type_best > 0);
715    if ((lz77_type_best == kLZ77Standard || lz77_type_best == kLZ77Box) &&
716        quality >= 25) {
717      const VP8LHashChain* const hash_chain_tmp =
718          (lz77_type_best == kLZ77Standard) ? hash_chain : &hash_chain_box;
719      if (VP8LBackwardReferencesTraceBackwards(width, height, argb, *cache_bits,
720                                               hash_chain_tmp, best, worst)) {
721        double bit_cost_trace;
722        VP8LHistogramCreate(histo, worst, *cache_bits);
723        bit_cost_trace = VP8LHistogramEstimateBits(histo);
724        if (bit_cost_trace < bit_cost_best) best = worst;
725      }
726    }
727    BackwardReferences2DLocality(width, best);
728  Error:
729    VP8LHashChainClear(&hash_chain_box);
730    VP8LFreeHistogram(histo);
731    return best;
732  }
733  VP8LBackwardRefs* VP8LGetBackwardReferences(
734      int width, int height, const uint32_t* const argb, int quality,
735      int low_effort, int lz77_types_to_try, int* const cache_bits,
736      const VP8LHashChain* const hash_chain, VP8LBackwardRefs* const refs_tmp1,
737      VP8LBackwardRefs* const refs_tmp2) {
738    if (low_effort) {
739      return GetBackwardReferencesLowEffort(width, height, argb, cache_bits,
740                                            hash_chain, refs_tmp1);
741    } else {
742      return GetBackwardReferences(width, height, argb, quality,
743                                   lz77_types_to_try, cache_bits, hash_chain,
744                                   refs_tmp1, refs_tmp2);
745    }
746  }
</code></pre>
        </div>
        <div class="column">
            <h3>libfuse-MDEwOlJlcG9zaXRvcnk0ODI5NjE3Nw==-flat-fuse.c</h3>
            <pre><code>1  #include "fuse_config.h"
2  #include "fuse_i.h"
3  #include "fuse_lowlevel.h"
4  #include "fuse_opt.h"
5  #include "fuse_misc.h"
6  #include "fuse_kernel.h"
7  #include <stdio.h>
8  #include <string.h>
9  #include <stdlib.h>
10  #include <stddef.h>
11  #include <stdbool.h>
12  #include <unistd.h>
13  #include <time.h>
14  #include <fcntl.h>
15  #include <limits.h>
16  #include <errno.h>
17  #include <signal.h>
18  #include <dlfcn.h>
19  #include <assert.h>
20  #include <poll.h>
21  #include <sys/param.h>
22  #include <sys/uio.h>
23  #include <sys/time.h>
24  #include <sys/mman.h>
25  #include <sys/file.h>
26  #define FUSE_NODE_SLAB 1
27  #ifndef MAP_ANONYMOUS
28  #undef FUSE_NODE_SLAB
29  #endif
30  #ifndef RENAME_EXCHANGE
31  #define RENAME_EXCHANGE		(1 << 1)	&bsol;* Exchange source and dest */
32  #endif
33  #define FUSE_DEFAULT_INTR_SIGNAL SIGUSR1
34  #define FUSE_UNKNOWN_INO 0xffffffff
35  #define OFFSET_MAX 0x7fffffffffffffffLL
36  #define NODE_TABLE_MIN_SIZE 8192
37  struct fuse_fs {
38  	struct fuse_operations op;
39  	void *user_data;
40  	int debug;
41  };
42  struct fusemod_so {
43  	void *handle;
44  	int ctr;
45  };
46  struct lock_queue_element {
47  	struct lock_queue_element *next;
48  	pthread_cond_t cond;
49  	fuse_ino_t nodeid1;
50  	const char *name1;
51  	char **path1;
52  	struct node **wnode1;
53  	fuse_ino_t nodeid2;
54  	const char *name2;
55  	char **path2;
56  	struct node **wnode2;
57  	int err;
58  	bool done : 1;
59  };
60  struct node_table {
61  	struct node **array;
62  	size_t use;
63  	size_t size;
64  	size_t split;
65  };
66  #define container_of(ptr, type, member) ({                              \
67  			const typeof( ((type *)0)->member ) *__mptr = (ptr); \
68  			(type *)( (char *)__mptr - offsetof(type,member) );})
69  #define list_entry(ptr, type, member)           \
70  	container_of(ptr, type, member)
71  struct list_head {
72  	struct list_head *next;
73  	struct list_head *prev;
74  };
75  struct node_slab {
76  	struct list_head list;  &bsol;* must be the first member */
77  	struct list_head freelist;
78  	int used;
79  };
80  struct fuse {
81  	struct fuse_session *se;
82  	struct node_table name_table;
83  	struct node_table id_table;
84  	struct list_head lru_table;
85  	fuse_ino_t ctr;
86  	unsigned int generation;
87  	unsigned int hidectr;
88  	pthread_mutex_t lock;
89  	struct fuse_config conf;
90  	int intr_installed;
91  	struct fuse_fs *fs;
92  	struct lock_queue_element *lockq;
93  	int pagesize;
94  	struct list_head partial_slabs;
95  	struct list_head full_slabs;
96  	pthread_t prune_thread;
97  };
98  struct lock {
99  	int type;
100  	off_t start;
101  	off_t end;
102  	pid_t pid;
103  	uint64_t owner;
104  	struct lock *next;
105  };
106  struct node {
107  	struct node *name_next;
108  	struct node *id_next;
109  	fuse_ino_t nodeid;
110  	unsigned int generation;
111  	int refctr;
112  	struct node *parent;
113  	char *name;
114  	uint64_t nlookup;
115  	int open_count;
116  	struct timespec stat_updated;
117  	struct timespec mtime;
118  	off_t size;
119  	struct lock *locks;
120  	unsigned int is_hidden : 1;
121  	unsigned int cache_valid : 1;
122  	int treelock;
123  	char inline_name[32];
124  };
125  #define TREELOCK_WRITE -1
126  #define TREELOCK_WAIT_OFFSET INT_MIN
127  struct node_lru {
128  	struct node node;
129  	struct list_head lru;
130  	struct timespec forget_time;
131  };
132  struct fuse_direntry {
133  	struct stat stat;
134  	char *name;
135  	struct fuse_direntry *next;
136  };
137  struct fuse_dh {
138  	pthread_mutex_t lock;
139  	struct fuse *fuse;
140  	fuse_req_t req;
141  	char *contents;
142  	struct fuse_direntry *first;
143  	struct fuse_direntry **last;
144  	unsigned len;
145  	unsigned size;
146  	unsigned needlen;
147  	int filled;
148  	uint64_t fh;
149  	int error;
150  	fuse_ino_t nodeid;
151  };
152  struct fuse_context_i {
153  	struct fuse_context ctx;
154  	fuse_req_t req;
155  };
156  extern fuse_module_factory_t fuse_module_subdir_factory;
157  #ifdef HAVE_ICONV
158  extern fuse_module_factory_t fuse_module_iconv_factory;
159  #endif
160  static pthread_key_t fuse_context_key;
161  static pthread_mutex_t fuse_context_lock = PTHREAD_MUTEX_INITIALIZER;
162  static int fuse_context_ref;
163  static struct fuse_module *fuse_modules = NULL;
164  static int fuse_register_module(const char *name,
165  				fuse_module_factory_t factory,
166  				struct fusemod_so *so)
167  {
168  	struct fuse_module *mod;
169  	mod = calloc(1, sizeof(struct fuse_module));
170  	if (!mod) {
171  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate module\n");
172  		return -1;
173  	}
174  	mod->name = strdup(name);
175  	if (!mod->name) {
176  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate module name\n");
177  		free(mod);
178  		return -1;
179  	}
180  	mod->factory = factory;
181  	mod->ctr = 0;
182  	mod->so = so;
183  	if (mod->so)
184  		mod->so->ctr++;
185  	mod->next = fuse_modules;
186  	fuse_modules = mod;
187  	return 0;
188  }
189  static void fuse_unregister_module(struct fuse_module *m)
190  {
191  	struct fuse_module **mp;
192  	for (mp = &fuse_modules; *mp; mp = &(*mp)->next) {
193  		if (*mp == m) {
194  			*mp = (*mp)->next;
195  			break;
196  		}
197  	}
198  	free(m->name);
199  	free(m);
200  }
201  static int fuse_load_so_module(const char *module)
202  {
203  	int ret = -1;
204  	char *tmp;
205  	struct fusemod_so *so;
206  	fuse_module_factory_t *factory;
207  	tmp = malloc(strlen(module) + 64);
208  	if (!tmp) {
209  		fuse_log(FUSE_LOG_ERR, "fuse: memory allocation failed\n");
210  		return -1;
211  	}
212  	sprintf(tmp, "libfusemod_%s.so", module);
213  	so = calloc(1, sizeof(struct fusemod_so));
214  	if (!so) {
215  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate module so\n");
216  		goto out;
217  	}
218  	so->handle = dlopen(tmp, RTLD_NOW);
219  	if (so->handle == NULL) {
220  		fuse_log(FUSE_LOG_ERR, "fuse: dlopen(%s) failed: %s\n",
221  			tmp, dlerror());
222  		goto out_free_so;
223  	}
224  	sprintf(tmp, "fuse_module_%s_factory", module);
225  	factory = (fuse_module_factory_t*)dlsym(so->handle, tmp);
226  	if (factory == NULL) {
227  		fuse_log(FUSE_LOG_ERR, "fuse: symbol <%s> not found in module: %s\n",
228  			tmp, dlerror());
229  		goto out_dlclose;
230  	}
231  	ret = fuse_register_module(module, *factory, so);
232  	if (ret)
233  		goto out_dlclose;
234  out:
235  	free(tmp);
236  	return ret;
237  out_dlclose:
238  	dlclose(so->handle);
239  out_free_so:
240  	free(so);
241  	goto out;
242  }
243  static struct fuse_module *fuse_find_module(const char *module)
244  {
245  	struct fuse_module *m;
246  	for (m = fuse_modules; m; m = m->next) {
247  		if (strcmp(module, m->name) == 0) {
248  			m->ctr++;
249  			break;
250  		}
251  	}
252  	return m;
253  }
254  static struct fuse_module *fuse_get_module(const char *module)
255  {
256  	struct fuse_module *m;
257  	pthread_mutex_lock(&fuse_context_lock);
258  	m = fuse_find_module(module);
259  	if (!m) {
260  		int err = fuse_load_so_module(module);
261  		if (!err)
262  			m = fuse_find_module(module);
263  	}
264  	pthread_mutex_unlock(&fuse_context_lock);
265  	return m;
266  }
267  static void fuse_put_module(struct fuse_module *m)
268  {
269  	pthread_mutex_lock(&fuse_context_lock);
270  	if (m->so)
271  		assert(m->ctr > 0);
272  	if (m->ctr > 0)
273  		m->ctr--;
274  	if (!m->ctr && m->so) {
275  		struct fusemod_so *so = m->so;
276  		assert(so->ctr > 0);
277  		so->ctr--;
278  		if (!so->ctr) {
279  			struct fuse_module **mp;
280  			for (mp = &fuse_modules; *mp;) {
281  				if ((*mp)->so == so)
282  					fuse_unregister_module(*mp);
283  				else
284  					mp = &(*mp)->next;
285  			}
286  			dlclose(so->handle);
287  			free(so);
288  		}
289  	} else if (!m->ctr) {
290  		fuse_unregister_module(m);
291  	}
292  	pthread_mutex_unlock(&fuse_context_lock);
293  }
294  static void init_list_head(struct list_head *list)
295  {
296  	list->next = list;
297  	list->prev = list;
298  }
299  static int list_empty(const struct list_head *head)
300  {
301  	return head->next == head;
302  }
303  static void list_add(struct list_head *new, struct list_head *prev,
304  		     struct list_head *next)
305  {
306  	next->prev = new;
307  	new->next = next;
308  	new->prev = prev;
309  	prev->next = new;
310  }
311  static inline void list_add_head(struct list_head *new, struct list_head *head)
312  {
313  	list_add(new, head, head->next);
314  }
315  static inline void list_add_tail(struct list_head *new, struct list_head *head)
316  {
317  	list_add(new, head->prev, head);
318  }
319  static inline void list_del(struct list_head *entry)
320  {
321  	struct list_head *prev = entry->prev;
322  	struct list_head *next = entry->next;
323  	next->prev = prev;
324  	prev->next = next;
325  }
326  static inline int lru_enabled(struct fuse *f)
327  {
328  	return f->conf.remember > 0;
329  }
330  static struct node_lru *node_lru(struct node *node)
331  {
332  	return (struct node_lru *) node;
333  }
334  static size_t get_node_size(struct fuse *f)
335  {
336  	if (lru_enabled(f))
337  		return sizeof(struct node_lru);
338  	else
339  		return sizeof(struct node);
340  }
341  #ifdef FUSE_NODE_SLAB
342  static struct node_slab *list_to_slab(struct list_head *head)
343  {
344  	return (struct node_slab *) head;
345  }
346  static struct node_slab *node_to_slab(struct fuse *f, struct node *node)
347  {
348  	return (struct node_slab *) (((uintptr_t) node) & ~((uintptr_t) f->pagesize - 1));
349  }
350  static int alloc_slab(struct fuse *f)
351  {
352  	void *mem;
353  	struct node_slab *slab;
354  	char *start;
355  	size_t num;
356  	size_t i;
357  	size_t node_size = get_node_size(f);
358  	mem = mmap(NULL, f->pagesize, PROT_READ | PROT_WRITE,
359  		   MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
360  	if (mem == MAP_FAILED)
361  		return -1;
362  	slab = mem;
363  	init_list_head(&slab->freelist);
364  	slab->used = 0;
365  	num = (f->pagesize - sizeof(struct node_slab)) / node_size;
366  	start = (char *) mem + f->pagesize - num * node_size;
367  	for (i = 0; i < num; i++) {
368  		struct list_head *n;
369  		n = (struct list_head *) (start + i * node_size);
370  		list_add_tail(n, &slab->freelist);
371  	}
372  	list_add_tail(&slab->list, &f->partial_slabs);
373  	return 0;
374  }
375  static struct node *alloc_node(struct fuse *f)
376  {
377  	struct node_slab *slab;
378  	struct list_head *node;
379  	if (list_empty(&f->partial_slabs)) {
380  		int res = alloc_slab(f);
381  		if (res != 0)
382  			return NULL;
383  	}
384  	slab = list_to_slab(f->partial_slabs.next);
385  	slab->used++;
386  	node = slab->freelist.next;
387  	list_del(node);
388  	if (list_empty(&slab->freelist)) {
389  		list_del(&slab->list);
390  		list_add_tail(&slab->list, &f->full_slabs);
391  	}
392  	memset(node, 0, sizeof(struct node));
393  	return (struct node *) node;
394  }
395  static void free_slab(struct fuse *f, struct node_slab *slab)
396  {
397  	int res;
398  	list_del(&slab->list);
399  	res = munmap(slab, f->pagesize);
400  	if (res == -1)
401  		fuse_log(FUSE_LOG_WARNING, "fuse warning: munmap(%p) failed\n",
402  			 slab);
403  }
404  static void free_node_mem(struct fuse *f, struct node *node)
405  {
406  	struct node_slab *slab = node_to_slab(f, node);
407  	struct list_head *n = (struct list_head *) node;
408  	slab->used--;
409  	if (slab->used) {
410  		if (list_empty(&slab->freelist)) {
411  			list_del(&slab->list);
412  			list_add_tail(&slab->list, &f->partial_slabs);
413  		}
414  		list_add_head(n, &slab->freelist);
415  	} else {
416  		free_slab(f, slab);
417  	}
418  }
419  #else
420  static struct node *alloc_node(struct fuse *f)
421  {
422  	return (struct node *) calloc(1, get_node_size(f));
423  }
424  static void free_node_mem(struct fuse *f, struct node *node)
425  {
426  	(void) f;
427  	free(node);
428  }
429  #endif
430  static size_t id_hash(struct fuse *f, fuse_ino_t ino)
431  {
432  	uint64_t hash = ((uint32_t) ino * 2654435761U) % f->id_table.size;
433  	uint64_t oldhash = hash % (f->id_table.size / 2);
434  	if (oldhash >= f->id_table.split)
435  		return oldhash;
436  	else
437  		return hash;
438  }
439  static struct node *get_node_nocheck(struct fuse *f, fuse_ino_t nodeid)
440  {
441  	size_t hash = id_hash(f, nodeid);
442  	struct node *node;
443  	for (node = f->id_table.array[hash]; node != NULL; node = node->id_next)
444  		if (node->nodeid == nodeid)
445  			return node;
446  	return NULL;
447  }
448  static struct node *get_node(struct fuse *f, fuse_ino_t nodeid)
449  {
450  	struct node *node = get_node_nocheck(f, nodeid);
451  	if (!node) {
452  		fuse_log(FUSE_LOG_ERR, "fuse internal error: node %llu not found\n",
453  			(unsigned long long) nodeid);
454  		abort();
455  	}
456  	return node;
457  }
458  static void curr_time(struct timespec *now);
459  static double diff_timespec(const struct timespec *t1,
460  			   const struct timespec *t2);
461  static void remove_node_lru(struct node *node)
462  {
463  	struct node_lru *lnode = node_lru(node);
464  	list_del(&lnode->lru);
465  	init_list_head(&lnode->lru);
466  }
467  static void set_forget_time(struct fuse *f, struct node *node)
468  {
469  	struct node_lru *lnode = node_lru(node);
470  	list_del(&lnode->lru);
471  	list_add_tail(&lnode->lru, &f->lru_table);
472  	curr_time(&lnode->forget_time);
473  }
474  static void free_node(struct fuse *f, struct node *node)
475  {
476  	if (node->name != node->inline_name)
477  		free(node->name);
478  	free_node_mem(f, node);
479  }
480  static void node_table_reduce(struct node_table *t)
481  {
482  	size_t newsize = t->size / 2;
483  	void *newarray;
484  	if (newsize < NODE_TABLE_MIN_SIZE)
485  		return;
486  	newarray = realloc(t->array, sizeof(struct node *) * newsize);
487  	if (newarray != NULL)
488  		t->array = newarray;
489  	t->size = newsize;
490  	t->split = t->size / 2;
491  }
492  static void remerge_id(struct fuse *f)
493  {
494  	struct node_table *t = &f->id_table;
495  	int iter;
496  	if (t->split == 0)
497  		node_table_reduce(t);
498  	for (iter = 8; t->split > 0 && iter; iter--) {
499  		struct node **upper;
500  		t->split--;
501  		upper = &t->array[t->split + t->size / 2];
502  		if (*upper) {
503  			struct node **nodep;
504  			for (nodep = &t->array[t->split]; *nodep;
505  			     nodep = &(*nodep)->id_next);
506  			*nodep = *upper;
507  			*upper = NULL;
508  			break;
509  		}
510  	}
511  }
512  static void unhash_id(struct fuse *f, struct node *node)
513  {
514  	struct node **nodep = &f->id_table.array[id_hash(f, node->nodeid)];
515  	for (; *nodep != NULL; nodep = &(*nodep)->id_next)
516  		if (*nodep == node) {
517  			*nodep = node->id_next;
518  			f->id_table.use--;
519  			if(f->id_table.use < f->id_table.size / 4)
520  				remerge_id(f);
521  			return;
522  		}
523  }
524  static int node_table_resize(struct node_table *t)
525  {
526  	size_t newsize = t->size * 2;
527  	void *newarray;
528  	newarray = realloc(t->array, sizeof(struct node *) * newsize);
529  	if (newarray == NULL)
530  		return -1;
531  	t->array = newarray;
532  	memset(t->array + t->size, 0, t->size * sizeof(struct node *));
533  	t->size = newsize;
534  	t->split = 0;
535  	return 0;
536  }
537  static void rehash_id(struct fuse *f)
538  {
539  	struct node_table *t = &f->id_table;
540  	struct node **nodep;
541  	struct node **next;
542  	size_t hash;
543  	if (t->split == t->size / 2)
544  		return;
545  	hash = t->split;
546  	t->split++;
547  	for (nodep = &t->array[hash]; *nodep != NULL; nodep = next) {
548  		struct node *node = *nodep;
549  		size_t newhash = id_hash(f, node->nodeid);
550  		if (newhash != hash) {
551  			next = nodep;
552  			*nodep = node->id_next;
553  			node->id_next = t->array[newhash];
554  			t->array[newhash] = node;
555  		} else {
556  			next = &node->id_next;
557  		}
558  	}
559  	if (t->split == t->size / 2)
560  		node_table_resize(t);
561  }
562  static void hash_id(struct fuse *f, struct node *node)
563  {
564  	size_t hash = id_hash(f, node->nodeid);
565  	node->id_next = f->id_table.array[hash];
566  	f->id_table.array[hash] = node;
567  	f->id_table.use++;
568  	if (f->id_table.use >= f->id_table.size / 2)
569  		rehash_id(f);
570  }
571  static size_t name_hash(struct fuse *f, fuse_ino_t parent,
572  			const char *name)
573  {
574  	uint64_t hash = parent;
575  	uint64_t oldhash;
576  	for (; *name; name++)
577  		hash = hash * 31 + (unsigned char) *name;
578  	hash %= f->name_table.size;
579  	oldhash = hash % (f->name_table.size / 2);
580  	if (oldhash >= f->name_table.split)
581  		return oldhash;
582  	else
583  		return hash;
584  }
585  static void unref_node(struct fuse *f, struct node *node);
586  static void remerge_name(struct fuse *f)
587  {
588  	struct node_table *t = &f->name_table;
589  	int iter;
590  	if (t->split == 0)
591  		node_table_reduce(t);
592  	for (iter = 8; t->split > 0 && iter; iter--) {
593  		struct node **upper;
594  		t->split--;
595  		upper = &t->array[t->split + t->size / 2];
596  		if (*upper) {
597  			struct node **nodep;
598  			for (nodep = &t->array[t->split]; *nodep;
599  			     nodep = &(*nodep)->name_next);
600  			*nodep = *upper;
601  			*upper = NULL;
602  			break;
603  		}
604  	}
605  }
606  static void unhash_name(struct fuse *f, struct node *node)
607  {
608  	if (node->name) {
609  		size_t hash = name_hash(f, node->parent->nodeid, node->name);
610  		struct node **nodep = &f->name_table.array[hash];
611  		for (; *nodep != NULL; nodep = &(*nodep)->name_next)
612  			if (*nodep == node) {
613  				*nodep = node->name_next;
614  				node->name_next = NULL;
615  				unref_node(f, node->parent);
616  				if (node->name != node->inline_name)
617  					free(node->name);
618  				node->name = NULL;
619  				node->parent = NULL;
620  				f->name_table.use--;
621  				if (f->name_table.use < f->name_table.size / 4)
622  					remerge_name(f);
623  				return;
624  			}
625  		fuse_log(FUSE_LOG_ERR,
626  			"fuse internal error: unable to unhash node: %llu\n",
627  			(unsigned long long) node->nodeid);
628  		abort();
629  	}
630  }
631  static void rehash_name(struct fuse *f)
632  {
633  	struct node_table *t = &f->name_table;
634  	struct node **nodep;
635  	struct node **next;
636  	size_t hash;
637  	if (t->split == t->size / 2)
638  		return;
639  	hash = t->split;
640  	t->split++;
641  	for (nodep = &t->array[hash]; *nodep != NULL; nodep = next) {
642  		struct node *node = *nodep;
643  		size_t newhash = name_hash(f, node->parent->nodeid, node->name);
644  		if (newhash != hash) {
645  			next = nodep;
646  			*nodep = node->name_next;
647  			node->name_next = t->array[newhash];
648  			t->array[newhash] = node;
649  		} else {
650  			next = &node->name_next;
651  		}
652  	}
653  	if (t->split == t->size / 2)
654  		node_table_resize(t);
655  }
656  static int hash_name(struct fuse *f, struct node *node, fuse_ino_t parentid,
657  		     const char *name)
658  {
659  	size_t hash = name_hash(f, parentid, name);
660  	struct node *parent = get_node(f, parentid);
661  	if (strlen(name) < sizeof(node->inline_name)) {
662  		strcpy(node->inline_name, name);
663  		node->name = node->inline_name;
664  	} else {
665  		node->name = strdup(name);
666  		if (node->name == NULL)
667  			return -1;
668  	}
669  	parent->refctr ++;
670  	node->parent = parent;
671  	node->name_next = f->name_table.array[hash];
672  	f->name_table.array[hash] = node;
673  	f->name_table.use++;
674  	if (f->name_table.use >= f->name_table.size / 2)
675  		rehash_name(f);
676  	return 0;
677  }
678  static void delete_node(struct fuse *f, struct node *node)
679  {
680  	if (f->conf.debug)
681  		fuse_log(FUSE_LOG_DEBUG, "DELETE: %llu\n",
682  			(unsigned long long) node->nodeid);
683  	assert(node->treelock == 0);
684  	unhash_name(f, node);
685  	if (lru_enabled(f))
686  		remove_node_lru(node);
687  	unhash_id(f, node);
688  	free_node(f, node);
689  }
690  static void unref_node(struct fuse *f, struct node *node)
691  {
692  	assert(node->refctr > 0);
693  	node->refctr --;
694  	if (!node->refctr)
695  		delete_node(f, node);
696  }
697  static fuse_ino_t next_id(struct fuse *f)
698  {
699  	do {
700  		f->ctr = (f->ctr + 1) & 0xffffffff;
701  		if (!f->ctr)
702  			f->generation ++;
703  	} while (f->ctr == 0 || f->ctr == FUSE_UNKNOWN_INO ||
704  		 get_node_nocheck(f, f->ctr) != NULL);
705  	return f->ctr;
706  }
707  static struct node *lookup_node(struct fuse *f, fuse_ino_t parent,
708  				const char *name)
709  {
710  	size_t hash = name_hash(f, parent, name);
711  	struct node *node;
712  	for (node = f->name_table.array[hash]; node != NULL; node = node->name_next)
713  		if (node->parent->nodeid == parent &&
714  		    strcmp(node->name, name) == 0)
715  			return node;
716  	return NULL;
717  }
718  static void inc_nlookup(struct node *node)
719  {
720  	if (!node->nlookup)
721  		node->refctr++;
722  	node->nlookup++;
723  }
724  static struct node *find_node(struct fuse *f, fuse_ino_t parent,
725  			      const char *name)
726  {
727  	struct node *node;
728  	pthread_mutex_lock(&f->lock);
729  	if (!name)
730  		node = get_node(f, parent);
731  	else
732  		node = lookup_node(f, parent, name);
733  	if (node == NULL) {
734  		node = alloc_node(f);
735  		if (node == NULL)
736  			goto out_err;
737  		node->nodeid = next_id(f);
738  		node->generation = f->generation;
739  		if (f->conf.remember)
740  			inc_nlookup(node);
741  		if (hash_name(f, node, parent, name) == -1) {
742  			free_node(f, node);
743  			node = NULL;
744  			goto out_err;
745  		}
746  		hash_id(f, node);
747  		if (lru_enabled(f)) {
748  			struct node_lru *lnode = node_lru(node);
749  			init_list_head(&lnode->lru);
750  		}
751  	} else if (lru_enabled(f) && node->nlookup == 1) {
752  		remove_node_lru(node);
753  	}
754  	inc_nlookup(node);
755  out_err:
756  	pthread_mutex_unlock(&f->lock);
757  	return node;
758  }
759  static int lookup_path_in_cache(struct fuse *f,
760  		const char *path, fuse_ino_t *inop)
761  {
762  	char *tmp = strdup(path);
763  	if (!tmp)
764  		return -ENOMEM;
765  	pthread_mutex_lock(&f->lock);
766  	fuse_ino_t ino = FUSE_ROOT_ID;
767  	int err = 0;
768  	char *save_ptr;
769  	char *path_element = strtok_r(tmp, "/", &save_ptr);
770  	while (path_element != NULL) {
771  		struct node *node = lookup_node(f, ino, path_element);
772  		if (node == NULL) {
773  			err = -ENOENT;
774  			break;
775  		}
776  		ino = node->nodeid;
777  		path_element = strtok_r(NULL, "/", &save_ptr);
778  	}
779  	pthread_mutex_unlock(&f->lock);
780  	free(tmp);
781  	if (!err)
782  		*inop = ino;
783  	return err;
784  }
785  static char *add_name(char **buf, unsigned *bufsize, char *s, const char *name)
786  {
787  	size_t len = strlen(name);
788  	if (s - len <= *buf) {
789  		unsigned pathlen = *bufsize - (s - *buf);
790  		unsigned newbufsize = *bufsize;
791  		char *newbuf;
792  		while (newbufsize < pathlen + len + 1) {
793  			if (newbufsize >= 0x80000000)
794  				newbufsize = 0xffffffff;
795  			else
796  				newbufsize *= 2;
797  		}
798  		newbuf = realloc(*buf, newbufsize);
799  		if (newbuf == NULL)
800  			return NULL;
801  		*buf = newbuf;
802  		s = newbuf + newbufsize - pathlen;
803  		memmove(s, newbuf + *bufsize - pathlen, pathlen);
804  		*bufsize = newbufsize;
805  	}
806  	s -= len;
807  	memcpy(s, name, len);
808  	s--;
809  	*s = '/';
810  	return s;
811  }
812  static void unlock_path(struct fuse *f, fuse_ino_t nodeid, struct node *wnode,
813  			struct node *end)
814  {
815  	struct node *node;
816  	if (wnode) {
817  		assert(wnode->treelock == TREELOCK_WRITE);
818  		wnode->treelock = 0;
819  	}
820  	for (node = get_node(f, nodeid);
821  	     node != end && node->nodeid != FUSE_ROOT_ID; node = node->parent) {
<span onclick='openModal()' class='match'>822  		assert(node->treelock != 0);
823  		assert(node->treelock != TREELOCK_WAIT_OFFSET);
824  		assert(node->treelock != TREELOCK_WRITE);
</span>825  		node->treelock--;
826  		if (node->treelock == TREELOCK_WAIT_OFFSET)
827  			node->treelock = 0;
828  	}
829  }
830  static int try_get_path(struct fuse *f, fuse_ino_t nodeid, const char *name,
831  			char **path, struct node **wnodep, bool need_lock)
832  {
833  	unsigned bufsize = 256;
834  	char *buf;
835  	char *s;
836  	struct node *node;
837  	struct node *wnode = NULL;
838  	int err;
839  	*path = NULL;
840  	err = -ENOMEM;
841  	buf = malloc(bufsize);
842  	if (buf == NULL)
843  		goto out_err;
844  	s = buf + bufsize - 1;
845  	*s = '\0';
846  	if (name != NULL) {
847  		s = add_name(&buf, &bufsize, s, name);
848  		err = -ENOMEM;
849  		if (s == NULL)
850  			goto out_free;
851  	}
852  	if (wnodep) {
853  		assert(need_lock);
854  		wnode = lookup_node(f, nodeid, name);
855  		if (wnode) {
856  			if (wnode->treelock != 0) {
857  				if (wnode->treelock > 0)
858  					wnode->treelock += TREELOCK_WAIT_OFFSET;
859  				err = -EAGAIN;
860  				goto out_free;
861  			}
862  			wnode->treelock = TREELOCK_WRITE;
863  		}
864  	}
865  	for (node = get_node(f, nodeid); node->nodeid != FUSE_ROOT_ID;
866  	     node = node->parent) {
867  		err = -ESTALE;
868  		if (node->name == NULL || node->parent == NULL)
869  			goto out_unlock;
870  		err = -ENOMEM;
871  		s = add_name(&buf, &bufsize, s, node->name);
872  		if (s == NULL)
873  			goto out_unlock;
874  		if (need_lock) {
875  			err = -EAGAIN;
876  			if (node->treelock < 0)
877  				goto out_unlock;
878  			node->treelock++;
879  		}
880  	}
881  	if (s[0])
882  		memmove(buf, s, bufsize - (s - buf));
883  	else
884  		strcpy(buf, "/");
885  	*path = buf;
886  	if (wnodep)
887  		*wnodep = wnode;
888  	return 0;
889   out_unlock:
890  	if (need_lock)
891  		unlock_path(f, nodeid, wnode, node);
892   out_free:
893  	free(buf);
894   out_err:
895  	return err;
896  }
897  static int try_get_path2(struct fuse *f, fuse_ino_t nodeid1, const char *name1,
898  			 fuse_ino_t nodeid2, const char *name2,
899  			 char **path1, char **path2,
900  			 struct node **wnode1, struct node **wnode2)
901  {
902  	int err;
903  	err = try_get_path(f, nodeid1, name1, path1, wnode1, true);
904  	if (!err) {
905  		err = try_get_path(f, nodeid2, name2, path2, wnode2, true);
906  		if (err) {
907  			struct node *wn1 = wnode1 ? *wnode1 : NULL;
908  			unlock_path(f, nodeid1, wn1, NULL);
909  			free(*path1);
910  		}
911  	}
912  	return err;
913  }
914  static void queue_element_wakeup(struct fuse *f, struct lock_queue_element *qe)
915  {
916  	int err;
917  	if (!qe->path1) {
918  		if (get_node(f, qe->nodeid1)->treelock == 0)
919  			pthread_cond_signal(&qe->cond);
920  		return;
921  	}
922  	if (qe->done)
923  		return;  
924  	if (!qe->path2) {
925  		err = try_get_path(f, qe->nodeid1, qe->name1, qe->path1,
926  				   qe->wnode1, true);
927  	} else {
928  		err = try_get_path2(f, qe->nodeid1, qe->name1, qe->nodeid2,
929  				    qe->name2, qe->path1, qe->path2, qe->wnode1,
930  				    qe->wnode2);
931  	}
932  	if (err == -EAGAIN)
933  		return;  &bsol;* keep trying */
934  	qe->err = err;
935  	qe->done = true;
936  	pthread_cond_signal(&qe->cond);
937  }
938  static void wake_up_queued(struct fuse *f)
939  {
940  	struct lock_queue_element *qe;
941  	for (qe = f->lockq; qe != NULL; qe = qe->next)
942  		queue_element_wakeup(f, qe);
943  }
944  static void debug_path(struct fuse *f, const char *msg, fuse_ino_t nodeid,
945  		       const char *name, bool wr)
946  {
947  	if (f->conf.debug) {
948  		struct node *wnode = NULL;
949  		if (wr)
950  			wnode = lookup_node(f, nodeid, name);
951  		if (wnode) {
952  			fuse_log(FUSE_LOG_DEBUG, "%s %llu (w)\n",
953  				msg, (unsigned long long) wnode->nodeid);
954  		} else {
955  			fuse_log(FUSE_LOG_DEBUG, "%s %llu\n",
956  				msg, (unsigned long long) nodeid);
957  		}
958  	}
959  }
960  static void queue_path(struct fuse *f, struct lock_queue_element *qe)
961  {
962  	struct lock_queue_element **qp;
963  	qe->done = false;
964  	pthread_cond_init(&qe->cond, NULL);
965  	qe->next = NULL;
966  	for (qp = &f->lockq; *qp != NULL; qp = &(*qp)->next);
967  	*qp = qe;
968  }
969  static void dequeue_path(struct fuse *f, struct lock_queue_element *qe)
970  {
971  	struct lock_queue_element **qp;
972  	pthread_cond_destroy(&qe->cond);
973  	for (qp = &f->lockq; *qp != qe; qp = &(*qp)->next);
974  	*qp = qe->next;
975  }
976  static int wait_path(struct fuse *f, struct lock_queue_element *qe)
977  {
978  	queue_path(f, qe);
979  	do {
980  		pthread_cond_wait(&qe->cond, &f->lock);
981  	} while (!qe->done);
982  	dequeue_path(f, qe);
983  	return qe->err;
984  }
985  static int get_path_common(struct fuse *f, fuse_ino_t nodeid, const char *name,
986  			   char **path, struct node **wnode)
987  {
988  	int err;
989  	pthread_mutex_lock(&f->lock);
990  	err = try_get_path(f, nodeid, name, path, wnode, true);
991  	if (err == -EAGAIN) {
992  		struct lock_queue_element qe = {
993  			.nodeid1 = nodeid,
994  			.name1 = name,
995  			.path1 = path,
996  			.wnode1 = wnode,
997  		};
998  		debug_path(f, "QUEUE PATH", nodeid, name, !!wnode);
999  		err = wait_path(f, &qe);
1000  		debug_path(f, "DEQUEUE PATH", nodeid, name, !!wnode);
1001  	}
1002  	pthread_mutex_unlock(&f->lock);
1003  	return err;
1004  }
1005  static int get_path(struct fuse *f, fuse_ino_t nodeid, char **path)
1006  {
1007  	return get_path_common(f, nodeid, NULL, path, NULL);
1008  }
1009  static int get_path_nullok(struct fuse *f, fuse_ino_t nodeid, char **path)
1010  {
1011  	int err = 0;
1012  	if (f->conf.nullpath_ok) {
1013  		*path = NULL;
1014  	} else {
1015  		err = get_path_common(f, nodeid, NULL, path, NULL);
1016  		if (err == -ESTALE)
1017  			err = 0;
1018  	}
1019  	return err;
1020  }
1021  static int get_path_name(struct fuse *f, fuse_ino_t nodeid, const char *name,
1022  			 char **path)
1023  {
1024  	return get_path_common(f, nodeid, name, path, NULL);
1025  }
1026  static int get_path_wrlock(struct fuse *f, fuse_ino_t nodeid, const char *name,
1027  			   char **path, struct node **wnode)
1028  {
1029  	return get_path_common(f, nodeid, name, path, wnode);
1030  }
1031  #if defined(__FreeBSD__)
1032  #define CHECK_DIR_LOOP
1033  #endif
1034  #if defined(CHECK_DIR_LOOP)
1035  static int check_dir_loop(struct fuse *f,
1036  			  fuse_ino_t nodeid1, const char *name1,
1037  			  fuse_ino_t nodeid2, const char *name2)
1038  {
1039  	struct node *node, *node1, *node2;
1040  	fuse_ino_t id1, id2;
1041  	node1 = lookup_node(f, nodeid1, name1);
1042  	id1 = node1 ? node1->nodeid : nodeid1;
1043  	node2 = lookup_node(f, nodeid2, name2);
1044  	id2 = node2 ? node2->nodeid : nodeid2;
1045  	for (node = get_node(f, id2); node->nodeid != FUSE_ROOT_ID;
1046  	     node = node->parent) {
1047  		if (node->name == NULL || node->parent == NULL)
1048  			break;
1049  		if (node->nodeid != id2 && node->nodeid == id1)
1050  			return -EINVAL;
1051  	}
1052  	if (node2)
1053  	{
1054  		for (node = get_node(f, id1); node->nodeid != FUSE_ROOT_ID;
1055  		     node = node->parent) {
1056  			if (node->name == NULL || node->parent == NULL)
1057  				break;
1058  			if (node->nodeid != id1 && node->nodeid == id2)
1059  				return -ENOTEMPTY;
1060  		}
1061  	}
1062  	return 0;
1063  }
1064  #endif
1065  static int get_path2(struct fuse *f, fuse_ino_t nodeid1, const char *name1,
1066  		     fuse_ino_t nodeid2, const char *name2,
1067  		     char **path1, char **path2,
1068  		     struct node **wnode1, struct node **wnode2)
1069  {
1070  	int err;
1071  	pthread_mutex_lock(&f->lock);
1072  #if defined(CHECK_DIR_LOOP)
1073  	if (name1)
1074  	{
1075  		err = check_dir_loop(f, nodeid1, name1, nodeid2, name2);
1076  		if (err)
1077  			goto out_unlock;
1078  	}
1079  #endif
1080  	err = try_get_path2(f, nodeid1, name1, nodeid2, name2,
1081  			    path1, path2, wnode1, wnode2);
1082  	if (err == -EAGAIN) {
1083  		struct lock_queue_element qe = {
1084  			.nodeid1 = nodeid1,
1085  			.name1 = name1,
1086  			.path1 = path1,
1087  			.wnode1 = wnode1,
1088  			.nodeid2 = nodeid2,
1089  			.name2 = name2,
1090  			.path2 = path2,
1091  			.wnode2 = wnode2,
1092  		};
1093  		debug_path(f, "QUEUE PATH1", nodeid1, name1, !!wnode1);
1094  		debug_path(f, "      PATH2", nodeid2, name2, !!wnode2);
1095  		err = wait_path(f, &qe);
1096  		debug_path(f, "DEQUEUE PATH1", nodeid1, name1, !!wnode1);
1097  		debug_path(f, "        PATH2", nodeid2, name2, !!wnode2);
1098  	}
1099  #if defined(CHECK_DIR_LOOP)
1100  out_unlock:
1101  #endif
1102  	pthread_mutex_unlock(&f->lock);
1103  	return err;
1104  }
1105  static void free_path_wrlock(struct fuse *f, fuse_ino_t nodeid,
1106  			     struct node *wnode, char *path)
1107  {
1108  	pthread_mutex_lock(&f->lock);
1109  	unlock_path(f, nodeid, wnode, NULL);
1110  	if (f->lockq)
1111  		wake_up_queued(f);
1112  	pthread_mutex_unlock(&f->lock);
1113  	free(path);
1114  }
1115  static void free_path(struct fuse *f, fuse_ino_t nodeid, char *path)
1116  {
1117  	if (path)
1118  		free_path_wrlock(f, nodeid, NULL, path);
1119  }
1120  static void free_path2(struct fuse *f, fuse_ino_t nodeid1, fuse_ino_t nodeid2,
1121  		       struct node *wnode1, struct node *wnode2,
1122  		       char *path1, char *path2)
1123  {
1124  	pthread_mutex_lock(&f->lock);
1125  	unlock_path(f, nodeid1, wnode1, NULL);
1126  	unlock_path(f, nodeid2, wnode2, NULL);
1127  	wake_up_queued(f);
1128  	pthread_mutex_unlock(&f->lock);
1129  	free(path1);
1130  	free(path2);
1131  }
1132  static void forget_node(struct fuse *f, fuse_ino_t nodeid, uint64_t nlookup)
1133  {
1134  	struct node *node;
1135  	if (nodeid == FUSE_ROOT_ID)
1136  		return;
1137  	pthread_mutex_lock(&f->lock);
1138  	node = get_node(f, nodeid);
1139  	while (node->nlookup == nlookup && node->treelock) {
1140  		struct lock_queue_element qe = {
1141  			.nodeid1 = nodeid,
1142  		};
1143  		debug_path(f, "QUEUE PATH (forget)", nodeid, NULL, false);
1144  		queue_path(f, &qe);
1145  		do {
1146  			pthread_cond_wait(&qe.cond, &f->lock);
1147  		} while (node->nlookup == nlookup && node->treelock);
1148  		dequeue_path(f, &qe);
1149  		debug_path(f, "DEQUEUE_PATH (forget)", nodeid, NULL, false);
1150  	}
1151  	assert(node->nlookup >= nlookup);
1152  	node->nlookup -= nlookup;
1153  	if (!node->nlookup) {
1154  		unref_node(f, node);
1155  	} else if (lru_enabled(f) && node->nlookup == 1) {
1156  		set_forget_time(f, node);
1157  	}
1158  	pthread_mutex_unlock(&f->lock);
1159  }
1160  static void unlink_node(struct fuse *f, struct node *node)
1161  {
1162  	if (f->conf.remember) {
1163  		assert(node->nlookup > 1);
1164  		node->nlookup--;
1165  	}
1166  	unhash_name(f, node);
1167  }
1168  static void remove_node(struct fuse *f, fuse_ino_t dir, const char *name)
1169  {
1170  	struct node *node;
1171  	pthread_mutex_lock(&f->lock);
1172  	node = lookup_node(f, dir, name);
1173  	if (node != NULL)
1174  		unlink_node(f, node);
1175  	pthread_mutex_unlock(&f->lock);
1176  }
1177  static int rename_node(struct fuse *f, fuse_ino_t olddir, const char *oldname,
1178  		       fuse_ino_t newdir, const char *newname, int hide)
1179  {
1180  	struct node *node;
1181  	struct node *newnode;
1182  	int err = 0;
1183  	pthread_mutex_lock(&f->lock);
1184  	node  = lookup_node(f, olddir, oldname);
1185  	newnode	 = lookup_node(f, newdir, newname);
1186  	if (node == NULL)
1187  		goto out;
1188  	if (newnode != NULL) {
1189  		if (hide) {
1190  			fuse_log(FUSE_LOG_ERR, "fuse: hidden file got created during hiding\n");
1191  			err = -EBUSY;
1192  			goto out;
1193  		}
1194  		unlink_node(f, newnode);
1195  	}
1196  	unhash_name(f, node);
1197  	if (hash_name(f, node, newdir, newname) == -1) {
1198  		err = -ENOMEM;
1199  		goto out;
1200  	}
1201  	if (hide)
1202  		node->is_hidden = 1;
1203  out:
1204  	pthread_mutex_unlock(&f->lock);
1205  	return err;
1206  }
1207  static int exchange_node(struct fuse *f, fuse_ino_t olddir, const char *oldname,
1208  			 fuse_ino_t newdir, const char *newname)
1209  {
1210  	struct node *oldnode;
1211  	struct node *newnode;
1212  	int err;
1213  	pthread_mutex_lock(&f->lock);
1214  	oldnode  = lookup_node(f, olddir, oldname);
1215  	newnode	 = lookup_node(f, newdir, newname);
1216  	if (oldnode)
1217  		unhash_name(f, oldnode);
1218  	if (newnode)
1219  		unhash_name(f, newnode);
1220  	err = -ENOMEM;
1221  	if (oldnode) {
1222  		if (hash_name(f, oldnode, newdir, newname) == -1)
1223  			goto out;
1224  	}
1225  	if (newnode) {
1226  		if (hash_name(f, newnode, olddir, oldname) == -1)
1227  			goto out;
1228  	}
1229  	err = 0;
1230  out:
1231  	pthread_mutex_unlock(&f->lock);
1232  	return err;
1233  }
1234  static void set_stat(struct fuse *f, fuse_ino_t nodeid, struct stat *stbuf)
1235  {
1236  	if (!f->conf.use_ino)
1237  		stbuf->st_ino = nodeid;
1238  	if (f->conf.set_mode)
1239  		stbuf->st_mode = (stbuf->st_mode & S_IFMT) |
1240  				 (0777 & ~f->conf.umask);
1241  	if (f->conf.set_uid)
1242  		stbuf->st_uid = f->conf.uid;
1243  	if (f->conf.set_gid)
1244  		stbuf->st_gid = f->conf.gid;
1245  }
1246  static struct fuse *req_fuse(fuse_req_t req)
1247  {
1248  	return (struct fuse *) fuse_req_userdata(req);
1249  }
1250  static void fuse_intr_sighandler(int sig)
1251  {
1252  	(void) sig;
1253  }
1254  struct fuse_intr_data {
1255  	pthread_t id;
1256  	pthread_cond_t cond;
1257  	int finished;
1258  };
1259  static void fuse_interrupt(fuse_req_t req, void *d_)
1260  {
1261  	struct fuse_intr_data *d = d_;
1262  	struct fuse *f = req_fuse(req);
1263  	if (d->id == pthread_self())
1264  		return;
1265  	pthread_mutex_lock(&f->lock);
1266  	while (!d->finished) {
1267  		struct timeval now;
1268  		struct timespec timeout;
1269  		pthread_kill(d->id, f->conf.intr_signal);
1270  		gettimeofday(&now, NULL);
1271  		timeout.tv_sec = now.tv_sec + 1;
1272  		timeout.tv_nsec = now.tv_usec * 1000;
1273  		pthread_cond_timedwait(&d->cond, &f->lock, &timeout);
1274  	}
1275  	pthread_mutex_unlock(&f->lock);
1276  }
1277  static void fuse_do_finish_interrupt(struct fuse *f, fuse_req_t req,
1278  				     struct fuse_intr_data *d)
1279  {
1280  	pthread_mutex_lock(&f->lock);
1281  	d->finished = 1;
1282  	pthread_cond_broadcast(&d->cond);
1283  	pthread_mutex_unlock(&f->lock);
1284  	fuse_req_interrupt_func(req, NULL, NULL);
1285  	pthread_cond_destroy(&d->cond);
1286  }
1287  static void fuse_do_prepare_interrupt(fuse_req_t req, struct fuse_intr_data *d)
1288  {
1289  	d->id = pthread_self();
1290  	pthread_cond_init(&d->cond, NULL);
1291  	d->finished = 0;
1292  	fuse_req_interrupt_func(req, fuse_interrupt, d);
1293  }
1294  static inline void fuse_finish_interrupt(struct fuse *f, fuse_req_t req,
1295  					 struct fuse_intr_data *d)
1296  {
1297  	if (f->conf.intr)
1298  		fuse_do_finish_interrupt(f, req, d);
1299  }
1300  static inline void fuse_prepare_interrupt(struct fuse *f, fuse_req_t req,
1301  					  struct fuse_intr_data *d)
1302  {
1303  	if (f->conf.intr)
1304  		fuse_do_prepare_interrupt(req, d);
1305  }
1306  static const char* file_info_string(struct fuse_file_info *fi,
1307  			      char* buf, size_t len)
1308  {
1309  	if(fi == NULL)
1310  		return "NULL";
1311  	snprintf(buf, len, "%llu", (unsigned long long) fi->fh);
1312  	return buf;
1313  }
1314  int fuse_fs_getattr(struct fuse_fs *fs, const char *path, struct stat *buf,
1315  		    struct fuse_file_info *fi)
1316  {
1317  	fuse_get_context()->private_data = fs->user_data;
1318  	if (fs->op.getattr) {
1319  		if (fs->debug) {
1320  			char buf[10];
1321  			fuse_log(FUSE_LOG_DEBUG, "getattr[%s] %s\n",
1322  				file_info_string(fi, buf, sizeof(buf)),
1323  				path);
1324  		}
1325  		return fs->op.getattr(path, buf, fi);
1326  	} else {
1327  		return -ENOSYS;
1328  	}
1329  }
1330  int fuse_fs_rename(struct fuse_fs *fs, const char *oldpath,
1331  		   const char *newpath, unsigned int flags)
1332  {
1333  	fuse_get_context()->private_data = fs->user_data;
1334  	if (fs->op.rename) {
1335  		if (fs->debug)
1336  			fuse_log(FUSE_LOG_DEBUG, "rename %s %s 0x%x\n", oldpath, newpath,
1337  				flags);
1338  		return fs->op.rename(oldpath, newpath, flags);
1339  	} else {
1340  		return -ENOSYS;
1341  	}
1342  }
1343  int fuse_fs_unlink(struct fuse_fs *fs, const char *path)
1344  {
1345  	fuse_get_context()->private_data = fs->user_data;
1346  	if (fs->op.unlink) {
1347  		if (fs->debug)
1348  			fuse_log(FUSE_LOG_DEBUG, "unlink %s\n", path);
1349  		return fs->op.unlink(path);
1350  	} else {
1351  		return -ENOSYS;
1352  	}
1353  }
1354  int fuse_fs_rmdir(struct fuse_fs *fs, const char *path)
1355  {
1356  	fuse_get_context()->private_data = fs->user_data;
1357  	if (fs->op.rmdir) {
1358  		if (fs->debug)
1359  			fuse_log(FUSE_LOG_DEBUG, "rmdir %s\n", path);
1360  		return fs->op.rmdir(path);
1361  	} else {
1362  		return -ENOSYS;
1363  	}
1364  }
1365  int fuse_fs_symlink(struct fuse_fs *fs, const char *linkname, const char *path)
1366  {
1367  	fuse_get_context()->private_data = fs->user_data;
1368  	if (fs->op.symlink) {
1369  		if (fs->debug)
1370  			fuse_log(FUSE_LOG_DEBUG, "symlink %s %s\n", linkname, path);
1371  		return fs->op.symlink(linkname, path);
1372  	} else {
1373  		return -ENOSYS;
1374  	}
1375  }
1376  int fuse_fs_link(struct fuse_fs *fs, const char *oldpath, const char *newpath)
1377  {
1378  	fuse_get_context()->private_data = fs->user_data;
1379  	if (fs->op.link) {
1380  		if (fs->debug)
1381  			fuse_log(FUSE_LOG_DEBUG, "link %s %s\n", oldpath, newpath);
1382  		return fs->op.link(oldpath, newpath);
1383  	} else {
1384  		return -ENOSYS;
1385  	}
1386  }
1387  int fuse_fs_release(struct fuse_fs *fs,	 const char *path,
1388  		    struct fuse_file_info *fi)
1389  {
1390  	fuse_get_context()->private_data = fs->user_data;
1391  	if (fs->op.release) {
1392  		if (fs->debug)
1393  			fuse_log(FUSE_LOG_DEBUG, "release%s[%llu] flags: 0x%x\n",
1394  				fi->flush ? "+flush" : "",
1395  				(unsigned long long) fi->fh, fi->flags);
1396  		return fs->op.release(path, fi);
1397  	} else {
1398  		return 0;
1399  	}
1400  }
1401  int fuse_fs_opendir(struct fuse_fs *fs, const char *path,
1402  		    struct fuse_file_info *fi)
1403  {
1404  	fuse_get_context()->private_data = fs->user_data;
1405  	if (fs->op.opendir) {
1406  		int err;
1407  		if (fs->debug)
1408  			fuse_log(FUSE_LOG_DEBUG, "opendir flags: 0x%x %s\n", fi->flags,
1409  				path);
1410  		err = fs->op.opendir(path, fi);
1411  		if (fs->debug && !err)
1412  			fuse_log(FUSE_LOG_DEBUG, "   opendir[%llu] flags: 0x%x %s\n",
1413  				(unsigned long long) fi->fh, fi->flags, path);
1414  		return err;
1415  	} else {
1416  		return 0;
1417  	}
1418  }
1419  int fuse_fs_open(struct fuse_fs *fs, const char *path,
1420  		 struct fuse_file_info *fi)
1421  {
1422  	fuse_get_context()->private_data = fs->user_data;
1423  	if (fs->op.open) {
1424  		int err;
1425  		if (fs->debug)
1426  			fuse_log(FUSE_LOG_DEBUG, "open flags: 0x%x %s\n", fi->flags,
1427  				path);
1428  		err = fs->op.open(path, fi);
1429  		if (fs->debug && !err)
1430  			fuse_log(FUSE_LOG_DEBUG, "   open[%llu] flags: 0x%x %s\n",
1431  				(unsigned long long) fi->fh, fi->flags, path);
1432  		return err;
1433  	} else {
1434  		return 0;
1435  	}
1436  }
1437  static void fuse_free_buf(struct fuse_bufvec *buf)
1438  {
1439  	if (buf != NULL) {
1440  		size_t i;
1441  		for (i = 0; i < buf->count; i++)
1442  			if (!(buf->buf[i].flags & FUSE_BUF_IS_FD))
1443  				free(buf->buf[i].mem);
1444  		free(buf);
1445  	}
1446  }
1447  int fuse_fs_read_buf(struct fuse_fs *fs, const char *path,
1448  		     struct fuse_bufvec **bufp, size_t size, off_t off,
1449  		     struct fuse_file_info *fi)
1450  {
1451  	fuse_get_context()->private_data = fs->user_data;
1452  	if (fs->op.read || fs->op.read_buf) {
1453  		int res;
1454  		if (fs->debug)
1455  			fuse_log(FUSE_LOG_DEBUG,
1456  				"read[%llu] %zu bytes from %llu flags: 0x%x\n",
1457  				(unsigned long long) fi->fh,
1458  				size, (unsigned long long) off, fi->flags);
1459  		if (fs->op.read_buf) {
1460  			res = fs->op.read_buf(path, bufp, size, off, fi);
1461  		} else {
1462  			struct fuse_bufvec *buf;
1463  			void *mem;
1464  			buf = malloc(sizeof(struct fuse_bufvec));
1465  			if (buf == NULL)
1466  				return -ENOMEM;
1467  			mem = malloc(size);
1468  			if (mem == NULL) {
1469  				free(buf);
1470  				return -ENOMEM;
1471  			}
1472  			*buf = FUSE_BUFVEC_INIT(size);
1473  			buf->buf[0].mem = mem;
1474  			*bufp = buf;
1475  			res = fs->op.read(path, mem, size, off, fi);
1476  			if (res >= 0)
1477  				buf->buf[0].size = res;
1478  		}
1479  		if (fs->debug && res >= 0)
1480  			fuse_log(FUSE_LOG_DEBUG, "   read[%llu] %zu bytes from %llu\n",
1481  				(unsigned long long) fi->fh,
1482  				fuse_buf_size(*bufp),
1483  				(unsigned long long) off);
1484  		if (res >= 0 && fuse_buf_size(*bufp) > size)
1485  			fuse_log(FUSE_LOG_ERR, "fuse: read too many bytes\n");
1486  		if (res < 0)
1487  			return res;
1488  		return 0;
1489  	} else {
1490  		return -ENOSYS;
1491  	}
1492  }
1493  int fuse_fs_read(struct fuse_fs *fs, const char *path, char *mem, size_t size,
1494  		 off_t off, struct fuse_file_info *fi)
1495  {
1496  	fuse_get_context()->private_data = fs->user_data;
1497  	if (fs->op.read || fs->op.read_buf) {
1498  		int res;
1499  		if (fs->debug)
1500  			fuse_log(FUSE_LOG_DEBUG,
1501  				"read[%llu] %zu bytes from %llu flags: 0x%x\n",
1502  				(unsigned long long) fi->fh,
1503  				size, (unsigned long long) off, fi->flags);
1504  		if (fs->op.read_buf) {
1505  			struct fuse_bufvec *buf = NULL;
1506  			res = fs->op.read_buf(path, &buf, size, off, fi);
1507  			if (res == 0) {
1508  				struct fuse_bufvec dst = FUSE_BUFVEC_INIT(size);
1509  				dst.buf[0].mem = mem;
1510  				res = fuse_buf_copy(&dst, buf, 0);
1511  			}
1512  			fuse_free_buf(buf);
1513  		} else {
1514  			res = fs->op.read(path, mem, size, off, fi);
1515  		}
1516  		if (fs->debug && res >= 0)
1517  			fuse_log(FUSE_LOG_DEBUG, "   read[%llu] %u bytes from %llu\n",
1518  				(unsigned long long) fi->fh,
1519  				res,
1520  				(unsigned long long) off);
1521  		if (res >= 0 && res > (int) size)
1522  			fuse_log(FUSE_LOG_ERR, "fuse: read too many bytes\n");
1523  		return res;
1524  	} else {
1525  		return -ENOSYS;
1526  	}
1527  }
1528  int fuse_fs_write_buf(struct fuse_fs *fs, const char *path,
1529  		      struct fuse_bufvec *buf, off_t off,
1530  		      struct fuse_file_info *fi)
1531  {
1532  	fuse_get_context()->private_data = fs->user_data;
1533  	if (fs->op.write_buf || fs->op.write) {
1534  		int res;
1535  		size_t size = fuse_buf_size(buf);
1536  		assert(buf->idx == 0 && buf->off == 0);
1537  		if (fs->debug)
1538  			fuse_log(FUSE_LOG_DEBUG,
1539  				"write%s[%llu] %zu bytes to %llu flags: 0x%x\n",
1540  				fi->writepage ? "page" : "",
1541  				(unsigned long long) fi->fh,
1542  				size,
1543  				(unsigned long long) off,
1544  				fi->flags);
1545  		if (fs->op.write_buf) {
1546  			res = fs->op.write_buf(path, buf, off, fi);
1547  		} else {
1548  			void *mem = NULL;
1549  			struct fuse_buf *flatbuf;
1550  			struct fuse_bufvec tmp = FUSE_BUFVEC_INIT(size);
1551  			if (buf->count == 1 &&
1552  			    !(buf->buf[0].flags & FUSE_BUF_IS_FD)) {
1553  				flatbuf = &buf->buf[0];
1554  			} else {
1555  				res = -ENOMEM;
1556  				mem = malloc(size);
1557  				if (mem == NULL)
1558  					goto out;
1559  				tmp.buf[0].mem = mem;
1560  				res = fuse_buf_copy(&tmp, buf, 0);
1561  				if (res <= 0)
1562  					goto out_free;
1563  				tmp.buf[0].size = res;
1564  				flatbuf = &tmp.buf[0];
1565  			}
1566  			res = fs->op.write(path, flatbuf->mem, flatbuf->size,
1567  					   off, fi);
1568  out_free:
1569  			free(mem);
1570  		}
1571  out:
1572  		if (fs->debug && res >= 0)
1573  			fuse_log(FUSE_LOG_DEBUG, "   write%s[%llu] %u bytes to %llu\n",
1574  				fi->writepage ? "page" : "",
1575  				(unsigned long long) fi->fh, res,
1576  				(unsigned long long) off);
1577  		if (res > (int) size)
1578  			fuse_log(FUSE_LOG_ERR, "fuse: wrote too many bytes\n");
1579  		return res;
1580  	} else {
1581  		return -ENOSYS;
1582  	}
1583  }
1584  int fuse_fs_write(struct fuse_fs *fs, const char *path, const char *mem,
1585  		  size_t size, off_t off, struct fuse_file_info *fi)
1586  {
1587  	struct fuse_bufvec bufv = FUSE_BUFVEC_INIT(size);
1588  	bufv.buf[0].mem = (void *) mem;
1589  	return fuse_fs_write_buf(fs, path, &bufv, off, fi);
1590  }
1591  int fuse_fs_fsync(struct fuse_fs *fs, const char *path, int datasync,
1592  		  struct fuse_file_info *fi)
1593  {
1594  	fuse_get_context()->private_data = fs->user_data;
1595  	if (fs->op.fsync) {
1596  		if (fs->debug)
1597  			fuse_log(FUSE_LOG_DEBUG, "fsync[%llu] datasync: %i\n",
1598  				(unsigned long long) fi->fh, datasync);
1599  		return fs->op.fsync(path, datasync, fi);
1600  	} else {
1601  		return -ENOSYS;
1602  	}
1603  }
1604  int fuse_fs_fsyncdir(struct fuse_fs *fs, const char *path, int datasync,
1605  		     struct fuse_file_info *fi)
1606  {
1607  	fuse_get_context()->private_data = fs->user_data;
1608  	if (fs->op.fsyncdir) {
1609  		if (fs->debug)
1610  			fuse_log(FUSE_LOG_DEBUG, "fsyncdir[%llu] datasync: %i\n",
1611  				(unsigned long long) fi->fh, datasync);
1612  		return fs->op.fsyncdir(path, datasync, fi);
1613  	} else {
1614  		return -ENOSYS;
1615  	}
1616  }
1617  int fuse_fs_flush(struct fuse_fs *fs, const char *path,
1618  		  struct fuse_file_info *fi)
1619  {
1620  	fuse_get_context()->private_data = fs->user_data;
1621  	if (fs->op.flush) {
1622  		if (fs->debug)
1623  			fuse_log(FUSE_LOG_DEBUG, "flush[%llu]\n",
1624  				(unsigned long long) fi->fh);
1625  		return fs->op.flush(path, fi);
1626  	} else {
1627  		return -ENOSYS;
1628  	}
1629  }
1630  int fuse_fs_statfs(struct fuse_fs *fs, const char *path, struct statvfs *buf)
1631  {
1632  	fuse_get_context()->private_data = fs->user_data;
1633  	if (fs->op.statfs) {
1634  		if (fs->debug)
1635  			fuse_log(FUSE_LOG_DEBUG, "statfs %s\n", path);
1636  		return fs->op.statfs(path, buf);
1637  	} else {
1638  		buf->f_namemax = 255;
1639  		buf->f_bsize = 512;
1640  		return 0;
1641  	}
1642  }
1643  int fuse_fs_releasedir(struct fuse_fs *fs, const char *path,
1644  		       struct fuse_file_info *fi)
1645  {
1646  	fuse_get_context()->private_data = fs->user_data;
1647  	if (fs->op.releasedir) {
1648  		if (fs->debug)
1649  			fuse_log(FUSE_LOG_DEBUG, "releasedir[%llu] flags: 0x%x\n",
1650  				(unsigned long long) fi->fh, fi->flags);
1651  		return fs->op.releasedir(path, fi);
1652  	} else {
1653  		return 0;
1654  	}
1655  }
1656  int fuse_fs_readdir(struct fuse_fs *fs, const char *path, void *buf,
1657  		    fuse_fill_dir_t filler, off_t off,
1658  		    struct fuse_file_info *fi,
1659  		    enum fuse_readdir_flags flags)
1660  {
1661  	fuse_get_context()->private_data = fs->user_data;
1662  	if (fs->op.readdir) {
1663  		if (fs->debug) {
1664  			fuse_log(FUSE_LOG_DEBUG, "readdir%s[%llu] from %llu\n",
1665  				(flags & FUSE_READDIR_PLUS) ? "plus" : "",
1666  				(unsigned long long) fi->fh,
1667  				(unsigned long long) off);
1668  		}
1669  		return fs->op.readdir(path, buf, filler, off, fi, flags);
1670  	} else {
1671  		return -ENOSYS;
1672  	}
1673  }
1674  int fuse_fs_create(struct fuse_fs *fs, const char *path, mode_t mode,
1675  		   struct fuse_file_info *fi)
1676  {
1677  	fuse_get_context()->private_data = fs->user_data;
1678  	if (fs->op.create) {
1679  		int err;
1680  		if (fs->debug)
1681  			fuse_log(FUSE_LOG_DEBUG,
1682  				"create flags: 0x%x %s 0%o umask=0%03o\n",
1683  				fi->flags, path, mode,
1684  				fuse_get_context()->umask);
1685  		err = fs->op.create(path, mode, fi);
1686  		if (fs->debug && !err)
1687  			fuse_log(FUSE_LOG_DEBUG, "   create[%llu] flags: 0x%x %s\n",
1688  				(unsigned long long) fi->fh, fi->flags, path);
1689  		return err;
1690  	} else {
1691  		return -ENOSYS;
1692  	}
1693  }
1694  int fuse_fs_lock(struct fuse_fs *fs, const char *path,
1695  		 struct fuse_file_info *fi, int cmd, struct flock *lock)
1696  {
1697  	fuse_get_context()->private_data = fs->user_data;
1698  	if (fs->op.lock) {
1699  		if (fs->debug)
1700  			fuse_log(FUSE_LOG_DEBUG, "lock[%llu] %s %s start: %llu len: %llu pid: %llu\n",
1701  				(unsigned long long) fi->fh,
1702  				(cmd == F_GETLK ? "F_GETLK" :
1703  				 (cmd == F_SETLK ? "F_SETLK" :
1704  				  (cmd == F_SETLKW ? "F_SETLKW" : "???"))),
1705  				(lock->l_type == F_RDLCK ? "F_RDLCK" :
1706  				 (lock->l_type == F_WRLCK ? "F_WRLCK" :
1707  				  (lock->l_type == F_UNLCK ? "F_UNLCK" :
1708  				   "???"))),
1709  				(unsigned long long) lock->l_start,
1710  				(unsigned long long) lock->l_len,
1711  				(unsigned long long) lock->l_pid);
1712  		return fs->op.lock(path, fi, cmd, lock);
1713  	} else {
1714  		return -ENOSYS;
1715  	}
1716  }
1717  int fuse_fs_flock(struct fuse_fs *fs, const char *path,
1718  		  struct fuse_file_info *fi, int op)
1719  {
1720  	fuse_get_context()->private_data = fs->user_data;
1721  	if (fs->op.flock) {
1722  		if (fs->debug) {
1723  			int xop = op & ~LOCK_NB;
1724  			fuse_log(FUSE_LOG_DEBUG, "lock[%llu] %s%s\n",
1725  				(unsigned long long) fi->fh,
1726  				xop == LOCK_SH ? "LOCK_SH" :
1727  				(xop == LOCK_EX ? "LOCK_EX" :
1728  				 (xop == LOCK_UN ? "LOCK_UN" : "???")),
1729  				(op & LOCK_NB) ? "|LOCK_NB" : "");
1730  		}
1731  		return fs->op.flock(path, fi, op);
1732  	} else {
1733  		return -ENOSYS;
1734  	}
1735  }
1736  int fuse_fs_chown(struct fuse_fs *fs, const char *path, uid_t uid,
1737  		  gid_t gid, struct fuse_file_info *fi)
1738  {
1739  	fuse_get_context()->private_data = fs->user_data;
1740  	if (fs->op.chown) {
1741  		if (fs->debug) {
1742  			char buf[10];
1743  			fuse_log(FUSE_LOG_DEBUG, "chown[%s] %s %lu %lu\n",
1744  				file_info_string(fi, buf, sizeof(buf)),
1745  				path, (unsigned long) uid, (unsigned long) gid);
1746  		}
1747  		return fs->op.chown(path, uid, gid, fi);
1748  	} else {
1749  		return -ENOSYS;
1750  	}
1751  }
1752  int fuse_fs_truncate(struct fuse_fs *fs, const char *path, off_t size,
1753  		      struct fuse_file_info *fi)
1754  {
1755  	fuse_get_context()->private_data = fs->user_data;
1756  	if (fs->op.truncate) {
1757  		if (fs->debug) {
1758  			char buf[10];
1759  			fuse_log(FUSE_LOG_DEBUG, "truncate[%s] %llu\n",
1760  				file_info_string(fi, buf, sizeof(buf)),
1761  				(unsigned long long) size);
1762  		}
1763  		return fs->op.truncate(path, size, fi);
1764  	} else {
1765  		return -ENOSYS;
1766  	}
1767  }
1768  int fuse_fs_utimens(struct fuse_fs *fs, const char *path,
1769  		    const struct timespec tv[2], struct fuse_file_info *fi)
1770  {
1771  	fuse_get_context()->private_data = fs->user_data;
1772  	if (fs->op.utimens) {
1773  		if (fs->debug) {
1774  			char buf[10];
1775  			fuse_log(FUSE_LOG_DEBUG, "utimens[%s] %s %li.%09lu %li.%09lu\n",
1776  				file_info_string(fi, buf, sizeof(buf)),
1777  				path, tv[0].tv_sec, tv[0].tv_nsec,
1778  				tv[1].tv_sec, tv[1].tv_nsec);
1779  		}
1780  		return fs->op.utimens(path, tv, fi);
1781  	} else {
1782  		return -ENOSYS;
1783  	}
1784  }
1785  int fuse_fs_access(struct fuse_fs *fs, const char *path, int mask)
1786  {
1787  	fuse_get_context()->private_data = fs->user_data;
1788  	if (fs->op.access) {
1789  		if (fs->debug)
1790  			fuse_log(FUSE_LOG_DEBUG, "access %s 0%o\n", path, mask);
1791  		return fs->op.access(path, mask);
1792  	} else {
1793  		return -ENOSYS;
1794  	}
1795  }
1796  int fuse_fs_readlink(struct fuse_fs *fs, const char *path, char *buf,
1797  		     size_t len)
1798  {
1799  	fuse_get_context()->private_data = fs->user_data;
1800  	if (fs->op.readlink) {
1801  		if (fs->debug)
1802  			fuse_log(FUSE_LOG_DEBUG, "readlink %s %lu\n", path,
1803  				(unsigned long) len);
1804  		return fs->op.readlink(path, buf, len);
1805  	} else {
1806  		return -ENOSYS;
1807  	}
1808  }
1809  int fuse_fs_mknod(struct fuse_fs *fs, const char *path, mode_t mode,
1810  		  dev_t rdev)
1811  {
1812  	fuse_get_context()->private_data = fs->user_data;
1813  	if (fs->op.mknod) {
1814  		if (fs->debug)
1815  			fuse_log(FUSE_LOG_DEBUG, "mknod %s 0%o 0x%llx umask=0%03o\n",
1816  				path, mode, (unsigned long long) rdev,
1817  				fuse_get_context()->umask);
1818  		return fs->op.mknod(path, mode, rdev);
1819  	} else {
1820  		return -ENOSYS;
1821  	}
1822  }
1823  int fuse_fs_mkdir(struct fuse_fs *fs, const char *path, mode_t mode)
1824  {
1825  	fuse_get_context()->private_data = fs->user_data;
1826  	if (fs->op.mkdir) {
1827  		if (fs->debug)
1828  			fuse_log(FUSE_LOG_DEBUG, "mkdir %s 0%o umask=0%03o\n",
1829  				path, mode, fuse_get_context()->umask);
1830  		return fs->op.mkdir(path, mode);
1831  	} else {
1832  		return -ENOSYS;
1833  	}
1834  }
1835  int fuse_fs_setxattr(struct fuse_fs *fs, const char *path, const char *name,
1836  		     const char *value, size_t size, int flags)
1837  {
1838  	fuse_get_context()->private_data = fs->user_data;
1839  	if (fs->op.setxattr) {
1840  		if (fs->debug)
1841  			fuse_log(FUSE_LOG_DEBUG, "setxattr %s %s %lu 0x%x\n",
1842  				path, name, (unsigned long) size, flags);
1843  		return fs->op.setxattr(path, name, value, size, flags);
1844  	} else {
1845  		return -ENOSYS;
1846  	}
1847  }
1848  int fuse_fs_getxattr(struct fuse_fs *fs, const char *path, const char *name,
1849  		     char *value, size_t size)
1850  {
1851  	fuse_get_context()->private_data = fs->user_data;
1852  	if (fs->op.getxattr) {
1853  		if (fs->debug)
1854  			fuse_log(FUSE_LOG_DEBUG, "getxattr %s %s %lu\n",
1855  				path, name, (unsigned long) size);
1856  		return fs->op.getxattr(path, name, value, size);
1857  	} else {
1858  		return -ENOSYS;
1859  	}
1860  }
1861  int fuse_fs_listxattr(struct fuse_fs *fs, const char *path, char *list,
1862  		      size_t size)
1863  {
1864  	fuse_get_context()->private_data = fs->user_data;
1865  	if (fs->op.listxattr) {
1866  		if (fs->debug)
1867  			fuse_log(FUSE_LOG_DEBUG, "listxattr %s %lu\n",
1868  				path, (unsigned long) size);
1869  		return fs->op.listxattr(path, list, size);
1870  	} else {
1871  		return -ENOSYS;
1872  	}
1873  }
1874  int fuse_fs_bmap(struct fuse_fs *fs, const char *path, size_t blocksize,
1875  		 uint64_t *idx)
1876  {
1877  	fuse_get_context()->private_data = fs->user_data;
1878  	if (fs->op.bmap) {
1879  		if (fs->debug)
1880  			fuse_log(FUSE_LOG_DEBUG, "bmap %s blocksize: %lu index: %llu\n",
1881  				path, (unsigned long) blocksize,
1882  				(unsigned long long) *idx);
1883  		return fs->op.bmap(path, blocksize, idx);
1884  	} else {
1885  		return -ENOSYS;
1886  	}
1887  }
1888  int fuse_fs_removexattr(struct fuse_fs *fs, const char *path, const char *name)
1889  {
1890  	fuse_get_context()->private_data = fs->user_data;
1891  	if (fs->op.removexattr) {
1892  		if (fs->debug)
1893  			fuse_log(FUSE_LOG_DEBUG, "removexattr %s %s\n", path, name);
1894  		return fs->op.removexattr(path, name);
1895  	} else {
1896  		return -ENOSYS;
1897  	}
1898  }
1899  int fuse_fs_ioctl(struct fuse_fs *fs, const char *path, unsigned int cmd,
1900  		  void *arg, struct fuse_file_info *fi, unsigned int flags,
1901  		  void *data)
1902  {
1903  	fuse_get_context()->private_data = fs->user_data;
1904  	if (fs->op.ioctl) {
1905  		if (fs->debug)
1906  			fuse_log(FUSE_LOG_DEBUG, "ioctl[%llu] 0x%x flags: 0x%x\n",
1907  				(unsigned long long) fi->fh, cmd, flags);
1908  		return fs->op.ioctl(path, cmd, arg, fi, flags, data);
1909  	} else
1910  		return -ENOSYS;
1911  }
1912  int fuse_fs_poll(struct fuse_fs *fs, const char *path,
1913  		 struct fuse_file_info *fi, struct fuse_pollhandle *ph,
1914  		 unsigned *reventsp)
1915  {
1916  	fuse_get_context()->private_data = fs->user_data;
1917  	if (fs->op.poll) {
1918  		int res;
1919  		if (fs->debug)
1920  			fuse_log(FUSE_LOG_DEBUG, "poll[%llu] ph: %p, events 0x%x\n",
1921  				(unsigned long long) fi->fh, ph,
1922  				fi->poll_events);
1923  		res = fs->op.poll(path, fi, ph, reventsp);
1924  		if (fs->debug && !res)
1925  			fuse_log(FUSE_LOG_DEBUG, "   poll[%llu] revents: 0x%x\n",
1926  				(unsigned long long) fi->fh, *reventsp);
1927  		return res;
1928  	} else
1929  		return -ENOSYS;
1930  }
1931  int fuse_fs_fallocate(struct fuse_fs *fs, const char *path, int mode,
1932  		off_t offset, off_t length, struct fuse_file_info *fi)
1933  {
1934  	fuse_get_context()->private_data = fs->user_data;
1935  	if (fs->op.fallocate) {
1936  		if (fs->debug)
1937  			fuse_log(FUSE_LOG_DEBUG, "fallocate %s mode %x, offset: %llu, length: %llu\n",
1938  				path,
1939  				mode,
1940  				(unsigned long long) offset,
1941  				(unsigned long long) length);
1942  		return fs->op.fallocate(path, mode, offset, length, fi);
1943  	} else
1944  		return -ENOSYS;
1945  }
1946  ssize_t fuse_fs_copy_file_range(struct fuse_fs *fs, const char *path_in,
1947  				struct fuse_file_info *fi_in, off_t off_in,
1948  				const char *path_out,
1949  				struct fuse_file_info *fi_out, off_t off_out,
1950  				size_t len, int flags)
1951  {
1952  	fuse_get_context()->private_data = fs->user_data;
1953  	if (fs->op.copy_file_range) {
1954  		if (fs->debug)
1955  			fuse_log(FUSE_LOG_DEBUG, "copy_file_range from %s:%llu to "
1956  			                "%s:%llu, length: %llu\n",
1957  				path_in,
1958  				(unsigned long long) off_in,
1959  				path_out,
1960  				(unsigned long long) off_out,
1961  				(unsigned long long) len);
1962  		return fs->op.copy_file_range(path_in, fi_in, off_in, path_out,
1963  					      fi_out, off_out, len, flags);
1964  	} else
1965  		return -ENOSYS;
1966  }
1967  off_t fuse_fs_lseek(struct fuse_fs *fs, const char *path, off_t off, int whence,
1968  		    struct fuse_file_info *fi)
1969  {
1970  	fuse_get_context()->private_data = fs->user_data;
1971  	if (fs->op.lseek) {
1972  		if (fs->debug) {
1973  			char buf[10];
1974  			fuse_log(FUSE_LOG_DEBUG, "lseek[%s] %llu %d\n",
1975  				file_info_string(fi, buf, sizeof(buf)),
1976  				(unsigned long long) off, whence);
1977  		}
1978  		return fs->op.lseek(path, off, whence, fi);
1979  	} else {
1980  		return -ENOSYS;
1981  	}
1982  }
1983  static int is_open(struct fuse *f, fuse_ino_t dir, const char *name)
1984  {
1985  	struct node *node;
1986  	int isopen = 0;
1987  	pthread_mutex_lock(&f->lock);
1988  	node = lookup_node(f, dir, name);
1989  	if (node && node->open_count > 0)
1990  		isopen = 1;
1991  	pthread_mutex_unlock(&f->lock);
1992  	return isopen;
1993  }
1994  static char *hidden_name(struct fuse *f, fuse_ino_t dir, const char *oldname,
1995  			 char *newname, size_t bufsize)
1996  {
1997  	struct stat buf;
1998  	struct node *node;
1999  	struct node *newnode;
2000  	char *newpath;
2001  	int res;
2002  	int failctr = 10;
2003  	do {
2004  		pthread_mutex_lock(&f->lock);
2005  		node = lookup_node(f, dir, oldname);
2006  		if (node == NULL) {
2007  			pthread_mutex_unlock(&f->lock);
2008  			return NULL;
2009  		}
2010  		do {
2011  			f->hidectr ++;
2012  			snprintf(newname, bufsize, ".fuse_hidden%08x%08x",
2013  				 (unsigned int) node->nodeid, f->hidectr);
2014  			newnode = lookup_node(f, dir, newname);
2015  		} while(newnode);
2016  		res = try_get_path(f, dir, newname, &newpath, NULL, false);
2017  		pthread_mutex_unlock(&f->lock);
2018  		if (res)
2019  			break;
2020  		memset(&buf, 0, sizeof(buf));
2021  		res = fuse_fs_getattr(f->fs, newpath, &buf, NULL);
2022  		if (res == -ENOENT)
2023  			break;
2024  		free(newpath);
2025  		newpath = NULL;
2026  	} while(res == 0 && --failctr);
2027  	return newpath;
2028  }
2029  static int hide_node(struct fuse *f, const char *oldpath,
2030  		     fuse_ino_t dir, const char *oldname)
2031  {
2032  	char newname[64];
2033  	char *newpath;
2034  	int err = -EBUSY;
2035  	newpath = hidden_name(f, dir, oldname, newname, sizeof(newname));
2036  	if (newpath) {
2037  		err = fuse_fs_rename(f->fs, oldpath, newpath, 0);
2038  		if (!err)
2039  			err = rename_node(f, dir, oldname, dir, newname, 1);
2040  		free(newpath);
2041  	}
2042  	return err;
2043  }
2044  static int mtime_eq(const struct stat *stbuf, const struct timespec *ts)
2045  {
2046  	return stbuf->st_mtime == ts->tv_sec &&
2047  		ST_MTIM_NSEC(stbuf) == ts->tv_nsec;
2048  }
2049  #ifndef CLOCK_MONOTONIC
2050  #define CLOCK_MONOTONIC CLOCK_REALTIME
2051  #endif
2052  static void curr_time(struct timespec *now)
2053  {
2054  	static clockid_t clockid = CLOCK_MONOTONIC;
2055  	int res = clock_gettime(clockid, now);
2056  	if (res == -1 && errno == EINVAL) {
2057  		clockid = CLOCK_REALTIME;
2058  		res = clock_gettime(clockid, now);
2059  	}
2060  	if (res == -1) {
2061  		perror("fuse: clock_gettime");
2062  		abort();
2063  	}
2064  }
2065  static void update_stat(struct node *node, const struct stat *stbuf)
2066  {
2067  	if (node->cache_valid && (!mtime_eq(stbuf, &node->mtime) ||
2068  				  stbuf->st_size != node->size))
2069  		node->cache_valid = 0;
2070  	node->mtime.tv_sec = stbuf->st_mtime;
2071  	node->mtime.tv_nsec = ST_MTIM_NSEC(stbuf);
2072  	node->size = stbuf->st_size;
2073  	curr_time(&node->stat_updated);
2074  }
2075  static int do_lookup(struct fuse *f, fuse_ino_t nodeid, const char *name,
2076  		     struct fuse_entry_param *e)
2077  {
2078  	struct node *node;
2079  	node = find_node(f, nodeid, name);
2080  	if (node == NULL)
2081  		return -ENOMEM;
2082  	e->ino = node->nodeid;
2083  	e->generation = node->generation;
2084  	e->entry_timeout = f->conf.entry_timeout;
2085  	e->attr_timeout = f->conf.attr_timeout;
2086  	if (f->conf.auto_cache) {
2087  		pthread_mutex_lock(&f->lock);
2088  		update_stat(node, &e->attr);
2089  		pthread_mutex_unlock(&f->lock);
2090  	}
2091  	set_stat(f, e->ino, &e->attr);
2092  	return 0;
2093  }
2094  static int lookup_path(struct fuse *f, fuse_ino_t nodeid,
2095  		       const char *name, const char *path,
2096  		       struct fuse_entry_param *e, struct fuse_file_info *fi)
2097  {
2098  	int res;
2099  	memset(e, 0, sizeof(struct fuse_entry_param));
2100  	res = fuse_fs_getattr(f->fs, path, &e->attr, fi);
2101  	if (res == 0) {
2102  		res = do_lookup(f, nodeid, name, e);
2103  		if (res == 0 && f->conf.debug) {
2104  			fuse_log(FUSE_LOG_DEBUG, "   NODEID: %llu\n",
2105  				(unsigned long long) e->ino);
2106  		}
2107  	}
2108  	return res;
2109  }
2110  static struct fuse_context_i *fuse_get_context_internal(void)
2111  {
2112  	return (struct fuse_context_i *) pthread_getspecific(fuse_context_key);
2113  }
2114  static struct fuse_context_i *fuse_create_context(struct fuse *f)
2115  {
2116  	struct fuse_context_i *c = fuse_get_context_internal();
2117  	if (c == NULL) {
2118  		c = (struct fuse_context_i *)
2119  			calloc(1, sizeof(struct fuse_context_i));
2120  		if (c == NULL) {
2121  			fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate thread specific data\n");
2122  			abort();
2123  		}
2124  		pthread_setspecific(fuse_context_key, c);
2125  	} else {
2126  		memset(c, 0, sizeof(*c));
2127  	}
2128  	c->ctx.fuse = f;
2129  	return c;
2130  }
2131  static void fuse_freecontext(void *data)
2132  {
2133  	free(data);
2134  }
2135  static int fuse_create_context_key(void)
2136  {
2137  	int err = 0;
2138  	pthread_mutex_lock(&fuse_context_lock);
2139  	if (!fuse_context_ref) {
2140  		err = pthread_key_create(&fuse_context_key, fuse_freecontext);
2141  		if (err) {
2142  			fuse_log(FUSE_LOG_ERR, "fuse: failed to create thread specific key: %s\n",
2143  				strerror(err));
2144  			pthread_mutex_unlock(&fuse_context_lock);
2145  			return -1;
2146  		}
2147  	}
2148  	fuse_context_ref++;
2149  	pthread_mutex_unlock(&fuse_context_lock);
2150  	return 0;
2151  }
2152  static void fuse_delete_context_key(void)
2153  {
2154  	pthread_mutex_lock(&fuse_context_lock);
2155  	fuse_context_ref--;
2156  	if (!fuse_context_ref) {
2157  		free(pthread_getspecific(fuse_context_key));
2158  		pthread_key_delete(fuse_context_key);
2159  	}
2160  	pthread_mutex_unlock(&fuse_context_lock);
2161  }
2162  static struct fuse *req_fuse_prepare(fuse_req_t req)
2163  {
2164  	struct fuse_context_i *c = fuse_create_context(req_fuse(req));
2165  	const struct fuse_ctx *ctx = fuse_req_ctx(req);
2166  	c->req = req;
2167  	c->ctx.uid = ctx->uid;
2168  	c->ctx.gid = ctx->gid;
2169  	c->ctx.pid = ctx->pid;
2170  	c->ctx.umask = ctx->umask;
2171  	return c->ctx.fuse;
2172  }
2173  static inline void reply_err(fuse_req_t req, int err)
2174  {
2175  	fuse_reply_err(req, -err);
2176  }
2177  static void reply_entry(fuse_req_t req, const struct fuse_entry_param *e,
2178  			int err)
2179  {
2180  	if (!err) {
2181  		struct fuse *f = req_fuse(req);
2182  		if (fuse_reply_entry(req, e) == -ENOENT) {
2183  			if  (e->ino != 0)
2184  				forget_node(f, e->ino, 1);
2185  		}
2186  	} else
2187  		reply_err(req, err);
2188  }
2189  void fuse_fs_init(struct fuse_fs *fs, struct fuse_conn_info *conn,
2190  		  struct fuse_config *cfg)
2191  {
2192  	fuse_get_context()->private_data = fs->user_data;
2193  	if (!fs->op.write_buf)
2194  		conn->want &= ~FUSE_CAP_SPLICE_READ;
2195  	if (!fs->op.lock)
2196  		conn->want &= ~FUSE_CAP_POSIX_LOCKS;
2197  	if (!fs->op.flock)
2198  		conn->want &= ~FUSE_CAP_FLOCK_LOCKS;
2199  	if (fs->op.init)
2200  		fs->user_data = fs->op.init(conn, cfg);
2201  }
2202  static void fuse_lib_init(void *data, struct fuse_conn_info *conn)
2203  {
2204  	struct fuse *f = (struct fuse *) data;
2205  	fuse_create_context(f);
2206  	if(conn->capable & FUSE_CAP_EXPORT_SUPPORT)
2207  		conn->want |= FUSE_CAP_EXPORT_SUPPORT;
2208  	fuse_fs_init(f->fs, conn, &f->conf);
2209  }
2210  void fuse_fs_destroy(struct fuse_fs *fs)
2211  {
2212  	fuse_get_context()->private_data = fs->user_data;
2213  	if (fs->op.destroy)
2214  		fs->op.destroy(fs->user_data);
2215  }
2216  static void fuse_lib_destroy(void *data)
2217  {
2218  	struct fuse *f = (struct fuse *) data;
2219  	fuse_create_context(f);
2220  	fuse_fs_destroy(f->fs);
2221  }
2222  static void fuse_lib_lookup(fuse_req_t req, fuse_ino_t parent,
2223  			    const char *name)
2224  {
2225  	struct fuse *f = req_fuse_prepare(req);
2226  	struct fuse_entry_param e;
2227  	char *path;
2228  	int err;
2229  	struct node *dot = NULL;
2230  	if (name[0] == '.') {
2231  		int len = strlen(name);
2232  		if (len == 1 || (name[1] == '.' && len == 2)) {
2233  			pthread_mutex_lock(&f->lock);
2234  			if (len == 1) {
2235  				if (f->conf.debug)
2236  					fuse_log(FUSE_LOG_DEBUG, "LOOKUP-DOT\n");
2237  				dot = get_node_nocheck(f, parent);
2238  				if (dot == NULL) {
2239  					pthread_mutex_unlock(&f->lock);
2240  					reply_entry(req, &e, -ESTALE);
2241  					return;
2242  				}
2243  				dot->refctr++;
2244  			} else {
2245  				if (f->conf.debug)
2246  					fuse_log(FUSE_LOG_DEBUG, "LOOKUP-DOTDOT\n");
2247  				parent = get_node(f, parent)->parent->nodeid;
2248  			}
2249  			pthread_mutex_unlock(&f->lock);
2250  			name = NULL;
2251  		}
2252  	}
2253  	err = get_path_name(f, parent, name, &path);
2254  	if (!err) {
2255  		struct fuse_intr_data d;
2256  		if (f->conf.debug)
2257  			fuse_log(FUSE_LOG_DEBUG, "LOOKUP %s\n", path);
2258  		fuse_prepare_interrupt(f, req, &d);
2259  		err = lookup_path(f, parent, name, path, &e, NULL);
2260  		if (err == -ENOENT && f->conf.negative_timeout != 0.0) {
2261  			e.ino = 0;
2262  			e.entry_timeout = f->conf.negative_timeout;
2263  			err = 0;
2264  		}
2265  		fuse_finish_interrupt(f, req, &d);
2266  		free_path(f, parent, path);
2267  	}
2268  	if (dot) {
2269  		pthread_mutex_lock(&f->lock);
2270  		unref_node(f, dot);
2271  		pthread_mutex_unlock(&f->lock);
2272  	}
2273  	reply_entry(req, &e, err);
2274  }
2275  static void do_forget(struct fuse *f, fuse_ino_t ino, uint64_t nlookup)
2276  {
2277  	if (f->conf.debug)
2278  		fuse_log(FUSE_LOG_DEBUG, "FORGET %llu/%llu\n", (unsigned long long)ino,
2279  			(unsigned long long) nlookup);
2280  	forget_node(f, ino, nlookup);
2281  }
2282  static void fuse_lib_forget(fuse_req_t req, fuse_ino_t ino, uint64_t nlookup)
2283  {
2284  	do_forget(req_fuse(req), ino, nlookup);
2285  	fuse_reply_none(req);
2286  }
2287  static void fuse_lib_forget_multi(fuse_req_t req, size_t count,
2288  				  struct fuse_forget_data *forgets)
2289  {
2290  	struct fuse *f = req_fuse(req);
2291  	size_t i;
2292  	for (i = 0; i < count; i++)
2293  		do_forget(f, forgets[i].ino, forgets[i].nlookup);
2294  	fuse_reply_none(req);
2295  }
2296  static void fuse_lib_getattr(fuse_req_t req, fuse_ino_t ino,
2297  			     struct fuse_file_info *fi)
2298  {
2299  	struct fuse *f = req_fuse_prepare(req);
2300  	struct stat buf;
2301  	char *path;
2302  	int err;
2303  	memset(&buf, 0, sizeof(buf));
2304  	if (fi != NULL)
2305  		err = get_path_nullok(f, ino, &path);
2306  	else
2307  		err = get_path(f, ino, &path);
2308  	if (!err) {
2309  		struct fuse_intr_data d;
2310  		fuse_prepare_interrupt(f, req, &d);
2311  		err = fuse_fs_getattr(f->fs, path, &buf, fi);
2312  		fuse_finish_interrupt(f, req, &d);
2313  		free_path(f, ino, path);
2314  	}
2315  	if (!err) {
2316  		struct node *node;
2317  		pthread_mutex_lock(&f->lock);
2318  		node = get_node(f, ino);
2319  		if (node->is_hidden && buf.st_nlink > 0)
2320  			buf.st_nlink--;
2321  		if (f->conf.auto_cache)
2322  			update_stat(node, &buf);
2323  		pthread_mutex_unlock(&f->lock);
2324  		set_stat(f, ino, &buf);
2325  		fuse_reply_attr(req, &buf, f->conf.attr_timeout);
2326  	} else
2327  		reply_err(req, err);
2328  }
2329  int fuse_fs_chmod(struct fuse_fs *fs, const char *path, mode_t mode,
2330  		  struct fuse_file_info *fi)
2331  {
2332  	fuse_get_context()->private_data = fs->user_data;
2333  	if (fs->op.chmod) {
2334  		if (fs->debug) {
2335  			char buf[10];
2336  			fuse_log(FUSE_LOG_DEBUG, "chmod[%s] %s %llo\n",
2337  				file_info_string(fi, buf, sizeof(buf)),
2338  				path, (unsigned long long) mode);
2339  		}
2340  		return fs->op.chmod(path, mode, fi);
2341  	}
2342  	else
2343  		return -ENOSYS;
2344  }
2345  static void fuse_lib_setattr(fuse_req_t req, fuse_ino_t ino, struct stat *attr,
2346  			     int valid, struct fuse_file_info *fi)
2347  {
2348  	struct fuse *f = req_fuse_prepare(req);
2349  	struct stat buf;
2350  	char *path;
2351  	int err;
2352  	memset(&buf, 0, sizeof(buf));
2353  	if (fi != NULL)
2354  		err = get_path_nullok(f, ino, &path);
2355  	else
2356  		err = get_path(f, ino, &path);
2357  	if (!err) {
2358  		struct fuse_intr_data d;
2359  		fuse_prepare_interrupt(f, req, &d);
2360  		err = 0;
2361  		if (!err && (valid & FUSE_SET_ATTR_MODE))
2362  			err = fuse_fs_chmod(f->fs, path, attr->st_mode, fi);
2363  		if (!err && (valid & (FUSE_SET_ATTR_UID | FUSE_SET_ATTR_GID))) {
2364  			uid_t uid = (valid & FUSE_SET_ATTR_UID) ?
2365  				attr->st_uid : (uid_t) -1;
2366  			gid_t gid = (valid & FUSE_SET_ATTR_GID) ?
2367  				attr->st_gid : (gid_t) -1;
2368  			err = fuse_fs_chown(f->fs, path, uid, gid, fi);
2369  		}
2370  		if (!err && (valid & FUSE_SET_ATTR_SIZE)) {
2371  			err = fuse_fs_truncate(f->fs, path,
2372  					       attr->st_size, fi);
2373  		}
2374  #ifdef HAVE_UTIMENSAT
2375  		if (!err &&
2376  		    (valid & (FUSE_SET_ATTR_ATIME | FUSE_SET_ATTR_MTIME))) {
2377  			struct timespec tv[2];
2378  			tv[0].tv_sec = 0;
2379  			tv[1].tv_sec = 0;
2380  			tv[0].tv_nsec = UTIME_OMIT;
2381  			tv[1].tv_nsec = UTIME_OMIT;
2382  			if (valid & FUSE_SET_ATTR_ATIME_NOW)
2383  				tv[0].tv_nsec = UTIME_NOW;
2384  			else if (valid & FUSE_SET_ATTR_ATIME)
2385  				tv[0] = attr->st_atim;
2386  			if (valid & FUSE_SET_ATTR_MTIME_NOW)
2387  				tv[1].tv_nsec = UTIME_NOW;
2388  			else if (valid & FUSE_SET_ATTR_MTIME)
2389  				tv[1] = attr->st_mtim;
2390  			err = fuse_fs_utimens(f->fs, path, tv, fi);
2391  		} else
2392  #endif
2393  		if (!err &&
2394  		    (valid & (FUSE_SET_ATTR_ATIME | FUSE_SET_ATTR_MTIME)) ==
2395  		    (FUSE_SET_ATTR_ATIME | FUSE_SET_ATTR_MTIME)) {
2396  			struct timespec tv[2];
2397  			tv[0].tv_sec = attr->st_atime;
2398  			tv[0].tv_nsec = ST_ATIM_NSEC(attr);
2399  			tv[1].tv_sec = attr->st_mtime;
2400  			tv[1].tv_nsec = ST_MTIM_NSEC(attr);
2401  			err = fuse_fs_utimens(f->fs, path, tv, fi);
2402  		}
2403  		if (!err) {
2404  			err = fuse_fs_getattr(f->fs, path, &buf, fi);
2405  		}
2406  		fuse_finish_interrupt(f, req, &d);
2407  		free_path(f, ino, path);
2408  	}
2409  	if (!err) {
2410  		if (f->conf.auto_cache) {
2411  			pthread_mutex_lock(&f->lock);
2412  			update_stat(get_node(f, ino), &buf);
2413  			pthread_mutex_unlock(&f->lock);
2414  		}
2415  		set_stat(f, ino, &buf);
2416  		fuse_reply_attr(req, &buf, f->conf.attr_timeout);
2417  	} else
2418  		reply_err(req, err);
2419  }
2420  static void fuse_lib_access(fuse_req_t req, fuse_ino_t ino, int mask)
2421  {
2422  	struct fuse *f = req_fuse_prepare(req);
2423  	char *path;
2424  	int err;
2425  	err = get_path(f, ino, &path);
2426  	if (!err) {
2427  		struct fuse_intr_data d;
2428  		fuse_prepare_interrupt(f, req, &d);
2429  		err = fuse_fs_access(f->fs, path, mask);
2430  		fuse_finish_interrupt(f, req, &d);
2431  		free_path(f, ino, path);
2432  	}
2433  	reply_err(req, err);
2434  }
2435  static void fuse_lib_readlink(fuse_req_t req, fuse_ino_t ino)
2436  {
2437  	struct fuse *f = req_fuse_prepare(req);
2438  	char linkname[PATH_MAX + 1];
2439  	char *path;
2440  	int err;
2441  	err = get_path(f, ino, &path);
2442  	if (!err) {
2443  		struct fuse_intr_data d;
2444  		fuse_prepare_interrupt(f, req, &d);
2445  		err = fuse_fs_readlink(f->fs, path, linkname, sizeof(linkname));
2446  		fuse_finish_interrupt(f, req, &d);
2447  		free_path(f, ino, path);
2448  	}
2449  	if (!err) {
2450  		linkname[PATH_MAX] = '\0';
2451  		fuse_reply_readlink(req, linkname);
2452  	} else
2453  		reply_err(req, err);
2454  }
2455  static void fuse_lib_mknod(fuse_req_t req, fuse_ino_t parent, const char *name,
2456  			   mode_t mode, dev_t rdev)
2457  {
2458  	struct fuse *f = req_fuse_prepare(req);
2459  	struct fuse_entry_param e;
2460  	char *path;
2461  	int err;
2462  	err = get_path_name(f, parent, name, &path);
2463  	if (!err) {
2464  		struct fuse_intr_data d;
2465  		fuse_prepare_interrupt(f, req, &d);
2466  		err = -ENOSYS;
2467  		if (S_ISREG(mode)) {
2468  			struct fuse_file_info fi;
2469  			memset(&fi, 0, sizeof(fi));
2470  			fi.flags = O_CREAT | O_EXCL | O_WRONLY;
2471  			err = fuse_fs_create(f->fs, path, mode, &fi);
2472  			if (!err) {
2473  				err = lookup_path(f, parent, name, path, &e,
2474  						  &fi);
2475  				fuse_fs_release(f->fs, path, &fi);
2476  			}
2477  		}
2478  		if (err == -ENOSYS) {
2479  			err = fuse_fs_mknod(f->fs, path, mode, rdev);
2480  			if (!err)
2481  				err = lookup_path(f, parent, name, path, &e,
2482  						  NULL);
2483  		}
2484  		fuse_finish_interrupt(f, req, &d);
2485  		free_path(f, parent, path);
2486  	}
2487  	reply_entry(req, &e, err);
2488  }
2489  static void fuse_lib_mkdir(fuse_req_t req, fuse_ino_t parent, const char *name,
2490  			   mode_t mode)
2491  {
2492  	struct fuse *f = req_fuse_prepare(req);
2493  	struct fuse_entry_param e;
2494  	char *path;
2495  	int err;
2496  	err = get_path_name(f, parent, name, &path);
2497  	if (!err) {
2498  		struct fuse_intr_data d;
2499  		fuse_prepare_interrupt(f, req, &d);
2500  		err = fuse_fs_mkdir(f->fs, path, mode);
2501  		if (!err)
2502  			err = lookup_path(f, parent, name, path, &e, NULL);
2503  		fuse_finish_interrupt(f, req, &d);
2504  		free_path(f, parent, path);
2505  	}
2506  	reply_entry(req, &e, err);
2507  }
2508  static void fuse_lib_unlink(fuse_req_t req, fuse_ino_t parent,
2509  			    const char *name)
2510  {
2511  	struct fuse *f = req_fuse_prepare(req);
2512  	struct node *wnode;
2513  	char *path;
2514  	int err;
2515  	err = get_path_wrlock(f, parent, name, &path, &wnode);
2516  	if (!err) {
2517  		struct fuse_intr_data d;
2518  		fuse_prepare_interrupt(f, req, &d);
2519  		if (!f->conf.hard_remove && is_open(f, parent, name)) {
2520  			err = hide_node(f, path, parent, name);
2521  			if (!err) {
2522  				if (!is_open(f, parent, wnode->name)) {
2523  					char *unlinkpath;
2524  					if (try_get_path(f, wnode->nodeid, NULL, &unlinkpath, NULL, false) == 0) {
2525  						err = fuse_fs_unlink(f->fs, unlinkpath);
2526  						if (!err)
2527  							remove_node(f, parent, wnode->name);
2528  						free(unlinkpath);
2529  					}
2530  				}
2531  			}
2532  		} else {
2533  			err = fuse_fs_unlink(f->fs, path);
2534  			if (!err)
2535  				remove_node(f, parent, name);
2536  		}
2537  		fuse_finish_interrupt(f, req, &d);
2538  		free_path_wrlock(f, parent, wnode, path);
2539  	}
2540  	reply_err(req, err);
2541  }
2542  static void fuse_lib_rmdir(fuse_req_t req, fuse_ino_t parent, const char *name)
2543  {
2544  	struct fuse *f = req_fuse_prepare(req);
2545  	struct node *wnode;
2546  	char *path;
2547  	int err;
2548  	err = get_path_wrlock(f, parent, name, &path, &wnode);
2549  	if (!err) {
2550  		struct fuse_intr_data d;
2551  		fuse_prepare_interrupt(f, req, &d);
2552  		err = fuse_fs_rmdir(f->fs, path);
2553  		fuse_finish_interrupt(f, req, &d);
2554  		if (!err)
2555  			remove_node(f, parent, name);
2556  		free_path_wrlock(f, parent, wnode, path);
2557  	}
2558  	reply_err(req, err);
2559  }
2560  static void fuse_lib_symlink(fuse_req_t req, const char *linkname,
2561  			     fuse_ino_t parent, const char *name)
2562  {
2563  	struct fuse *f = req_fuse_prepare(req);
2564  	struct fuse_entry_param e;
2565  	char *path;
2566  	int err;
2567  	err = get_path_name(f, parent, name, &path);
2568  	if (!err) {
2569  		struct fuse_intr_data d;
2570  		fuse_prepare_interrupt(f, req, &d);
2571  		err = fuse_fs_symlink(f->fs, linkname, path);
2572  		if (!err)
2573  			err = lookup_path(f, parent, name, path, &e, NULL);
2574  		fuse_finish_interrupt(f, req, &d);
2575  		free_path(f, parent, path);
2576  	}
2577  	reply_entry(req, &e, err);
2578  }
2579  static void fuse_lib_rename(fuse_req_t req, fuse_ino_t olddir,
2580  			    const char *oldname, fuse_ino_t newdir,
2581  			    const char *newname, unsigned int flags)
2582  {
2583  	struct fuse *f = req_fuse_prepare(req);
2584  	char *oldpath;
2585  	char *newpath;
2586  	struct node *wnode1;
2587  	struct node *wnode2;
2588  	int err;
2589  	err = get_path2(f, olddir, oldname, newdir, newname,
2590  			&oldpath, &newpath, &wnode1, &wnode2);
2591  	if (!err) {
2592  		struct fuse_intr_data d;
2593  		err = 0;
2594  		fuse_prepare_interrupt(f, req, &d);
2595  		if (!f->conf.hard_remove && !(flags & RENAME_EXCHANGE) &&
2596  		    is_open(f, newdir, newname))
2597  			err = hide_node(f, newpath, newdir, newname);
2598  		if (!err) {
2599  			err = fuse_fs_rename(f->fs, oldpath, newpath, flags);
2600  			if (!err) {
2601  				if (flags & RENAME_EXCHANGE) {
2602  					err = exchange_node(f, olddir, oldname,
2603  							    newdir, newname);
2604  				} else {
2605  					err = rename_node(f, olddir, oldname,
2606  							  newdir, newname, 0);
2607  				}
2608  			}
2609  		}
2610  		fuse_finish_interrupt(f, req, &d);
2611  		free_path2(f, olddir, newdir, wnode1, wnode2, oldpath, newpath);
2612  	}
2613  	reply_err(req, err);
2614  }
2615  static void fuse_lib_link(fuse_req_t req, fuse_ino_t ino, fuse_ino_t newparent,
2616  			  const char *newname)
2617  {
2618  	struct fuse *f = req_fuse_prepare(req);
2619  	struct fuse_entry_param e;
2620  	char *oldpath;
2621  	char *newpath;
2622  	int err;
2623  	err = get_path2(f, ino, NULL, newparent, newname,
2624  			&oldpath, &newpath, NULL, NULL);
2625  	if (!err) {
2626  		struct fuse_intr_data d;
2627  		fuse_prepare_interrupt(f, req, &d);
2628  		err = fuse_fs_link(f->fs, oldpath, newpath);
2629  		if (!err)
2630  			err = lookup_path(f, newparent, newname, newpath,
2631  					  &e, NULL);
2632  		fuse_finish_interrupt(f, req, &d);
2633  		free_path2(f, ino, newparent, NULL, NULL, oldpath, newpath);
2634  	}
2635  	reply_entry(req, &e, err);
2636  }
2637  static void fuse_do_release(struct fuse *f, fuse_ino_t ino, const char *path,
2638  			    struct fuse_file_info *fi)
2639  {
2640  	struct node *node;
2641  	int unlink_hidden = 0;
2642  	fuse_fs_release(f->fs, path, fi);
2643  	pthread_mutex_lock(&f->lock);
2644  	node = get_node(f, ino);
2645  	assert(node->open_count > 0);
2646  	--node->open_count;
2647  	if (node->is_hidden && !node->open_count) {
2648  		unlink_hidden = 1;
2649  		node->is_hidden = 0;
2650  	}
2651  	pthread_mutex_unlock(&f->lock);
2652  	if(unlink_hidden) {
2653  		if (path) {
2654  			fuse_fs_unlink(f->fs, path);
2655  		} else if (f->conf.nullpath_ok) {
2656  			char *unlinkpath;
2657  			if (get_path(f, ino, &unlinkpath) == 0)
2658  				fuse_fs_unlink(f->fs, unlinkpath);
2659  			free_path(f, ino, unlinkpath);
2660  		}
2661  	}
2662  }
2663  static void fuse_lib_create(fuse_req_t req, fuse_ino_t parent,
2664  			    const char *name, mode_t mode,
2665  			    struct fuse_file_info *fi)
2666  {
2667  	struct fuse *f = req_fuse_prepare(req);
2668  	struct fuse_intr_data d;
2669  	struct fuse_entry_param e;
2670  	char *path;
2671  	int err;
2672  	err = get_path_name(f, parent, name, &path);
2673  	if (!err) {
2674  		fuse_prepare_interrupt(f, req, &d);
2675  		err = fuse_fs_create(f->fs, path, mode, fi);
2676  		if (!err) {
2677  			err = lookup_path(f, parent, name, path, &e, fi);
2678  			if (err)
2679  				fuse_fs_release(f->fs, path, fi);
2680  			else if (!S_ISREG(e.attr.st_mode)) {
2681  				err = -EIO;
2682  				fuse_fs_release(f->fs, path, fi);
2683  				forget_node(f, e.ino, 1);
2684  			} else {
2685  				if (f->conf.direct_io)
2686  					fi->direct_io = 1;
2687  				if (f->conf.kernel_cache)
2688  					fi->keep_cache = 1;
2689  				if (fi->direct_io &&
2690  				    f->conf.parallel_direct_writes)
2691  					fi->parallel_direct_writes = 1;
2692  			}
2693  		}
2694  		fuse_finish_interrupt(f, req, &d);
2695  	}
2696  	if (!err) {
2697  		pthread_mutex_lock(&f->lock);
2698  		get_node(f, e.ino)->open_count++;
2699  		pthread_mutex_unlock(&f->lock);
2700  		if (fuse_reply_create(req, &e, fi) == -ENOENT) {
2701  			fuse_do_release(f, e.ino, path, fi);
2702  			forget_node(f, e.ino, 1);
2703  		}
2704  	} else {
2705  		reply_err(req, err);
2706  	}
2707  	free_path(f, parent, path);
2708  }
2709  static double diff_timespec(const struct timespec *t1,
2710  			    const struct timespec *t2)
2711  {
2712  	return (t1->tv_sec - t2->tv_sec) +
2713  		((double) t1->tv_nsec - (double) t2->tv_nsec) / 1000000000.0;
2714  }
2715  static void open_auto_cache(struct fuse *f, fuse_ino_t ino, const char *path,
2716  			    struct fuse_file_info *fi)
2717  {
2718  	struct node *node;
2719  	pthread_mutex_lock(&f->lock);
2720  	node = get_node(f, ino);
2721  	if (node->cache_valid) {
2722  		struct timespec now;
2723  		curr_time(&now);
2724  		if (diff_timespec(&now, &node->stat_updated) >
2725  		    f->conf.ac_attr_timeout) {
2726  			struct stat stbuf;
2727  			int err;
2728  			pthread_mutex_unlock(&f->lock);
2729  			err = fuse_fs_getattr(f->fs, path, &stbuf, fi);
2730  			pthread_mutex_lock(&f->lock);
2731  			if (!err)
2732  				update_stat(node, &stbuf);
2733  			else
2734  				node->cache_valid = 0;
2735  		}
2736  	}
2737  	if (node->cache_valid)
2738  		fi->keep_cache = 1;
2739  	node->cache_valid = 1;
2740  	pthread_mutex_unlock(&f->lock);
2741  }
2742  static void fuse_lib_open(fuse_req_t req, fuse_ino_t ino,
2743  			  struct fuse_file_info *fi)
2744  {
2745  	struct fuse *f = req_fuse_prepare(req);
2746  	struct fuse_intr_data d;
2747  	char *path;
2748  	int err;
2749  	err = get_path(f, ino, &path);
2750  	if (!err) {
2751  		fuse_prepare_interrupt(f, req, &d);
2752  		err = fuse_fs_open(f->fs, path, fi);
2753  		if (!err) {
2754  			if (f->conf.direct_io)
2755  				fi->direct_io = 1;
2756  			if (f->conf.kernel_cache)
2757  				fi->keep_cache = 1;
2758  			if (f->conf.auto_cache)
2759  				open_auto_cache(f, ino, path, fi);
2760  			if (f->conf.no_rofd_flush &&
2761  			    (fi->flags & O_ACCMODE) == O_RDONLY)
2762  				fi->noflush = 1;
2763  			if (fi->direct_io && f->conf.parallel_direct_writes)
2764  				fi->parallel_direct_writes = 1;
2765  		}
2766  		fuse_finish_interrupt(f, req, &d);
2767  	}
2768  	if (!err) {
2769  		pthread_mutex_lock(&f->lock);
2770  		get_node(f, ino)->open_count++;
2771  		pthread_mutex_unlock(&f->lock);
2772  		if (fuse_reply_open(req, fi) == -ENOENT) {
2773  			fuse_do_release(f, ino, path, fi);
2774  		}
2775  	} else
2776  		reply_err(req, err);
2777  	free_path(f, ino, path);
2778  }
2779  static void fuse_lib_read(fuse_req_t req, fuse_ino_t ino, size_t size,
2780  			  off_t off, struct fuse_file_info *fi)
2781  {
2782  	struct fuse *f = req_fuse_prepare(req);
2783  	struct fuse_bufvec *buf = NULL;
2784  	char *path;
2785  	int res;
2786  	res = get_path_nullok(f, ino, &path);
2787  	if (res == 0) {
2788  		struct fuse_intr_data d;
2789  		fuse_prepare_interrupt(f, req, &d);
2790  		res = fuse_fs_read_buf(f->fs, path, &buf, size, off, fi);
2791  		fuse_finish_interrupt(f, req, &d);
2792  		free_path(f, ino, path);
2793  	}
2794  	if (res == 0)
2795  		fuse_reply_data(req, buf, FUSE_BUF_SPLICE_MOVE);
2796  	else
2797  		reply_err(req, res);
2798  	fuse_free_buf(buf);
2799  }
2800  static void fuse_lib_write_buf(fuse_req_t req, fuse_ino_t ino,
2801  			       struct fuse_bufvec *buf, off_t off,
2802  			       struct fuse_file_info *fi)
2803  {
2804  	struct fuse *f = req_fuse_prepare(req);
2805  	char *path;
2806  	int res;
2807  	res = get_path_nullok(f, ino, &path);
2808  	if (res == 0) {
2809  		struct fuse_intr_data d;
2810  		fuse_prepare_interrupt(f, req, &d);
2811  		res = fuse_fs_write_buf(f->fs, path, buf, off, fi);
2812  		fuse_finish_interrupt(f, req, &d);
2813  		free_path(f, ino, path);
2814  	}
2815  	if (res >= 0)
2816  		fuse_reply_write(req, res);
2817  	else
2818  		reply_err(req, res);
2819  }
2820  static void fuse_lib_fsync(fuse_req_t req, fuse_ino_t ino, int datasync,
2821  			   struct fuse_file_info *fi)
2822  {
2823  	struct fuse *f = req_fuse_prepare(req);
2824  	char *path;
2825  	int err;
2826  	err = get_path_nullok(f, ino, &path);
2827  	if (!err) {
2828  		struct fuse_intr_data d;
2829  		fuse_prepare_interrupt(f, req, &d);
2830  		err = fuse_fs_fsync(f->fs, path, datasync, fi);
2831  		fuse_finish_interrupt(f, req, &d);
2832  		free_path(f, ino, path);
2833  	}
2834  	reply_err(req, err);
2835  }
2836  static struct fuse_dh *get_dirhandle(const struct fuse_file_info *llfi,
2837  				     struct fuse_file_info *fi)
2838  {
2839  	struct fuse_dh *dh = (struct fuse_dh *) (uintptr_t) llfi->fh;
2840  	memset(fi, 0, sizeof(struct fuse_file_info));
2841  	fi->fh = dh->fh;
2842  	return dh;
2843  }
2844  static void fuse_lib_opendir(fuse_req_t req, fuse_ino_t ino,
2845  			     struct fuse_file_info *llfi)
2846  {
2847  	struct fuse *f = req_fuse_prepare(req);
2848  	struct fuse_intr_data d;
2849  	struct fuse_dh *dh;
2850  	struct fuse_file_info fi;
2851  	char *path;
2852  	int err;
2853  	dh = (struct fuse_dh *) malloc(sizeof(struct fuse_dh));
2854  	if (dh == NULL) {
2855  		reply_err(req, -ENOMEM);
2856  		return;
2857  	}
2858  	memset(dh, 0, sizeof(struct fuse_dh));
2859  	dh->fuse = f;
2860  	dh->contents = NULL;
2861  	dh->first = NULL;
2862  	dh->len = 0;
2863  	dh->filled = 0;
2864  	dh->nodeid = ino;
2865  	pthread_mutex_init(&dh->lock, NULL);
2866  	llfi->fh = (uintptr_t) dh;
2867  	memset(&fi, 0, sizeof(fi));
2868  	fi.flags = llfi->flags;
2869  	err = get_path(f, ino, &path);
2870  	if (!err) {
2871  		fuse_prepare_interrupt(f, req, &d);
2872  		err = fuse_fs_opendir(f->fs, path, &fi);
2873  		fuse_finish_interrupt(f, req, &d);
2874  		dh->fh = fi.fh;
2875  	}
2876  	if (!err) {
2877  		if (fuse_reply_open(req, llfi) == -ENOENT) {
2878  			fuse_fs_releasedir(f->fs, path, &fi);
2879  			pthread_mutex_destroy(&dh->lock);
2880  			free(dh);
2881  		}
2882  	} else {
2883  		reply_err(req, err);
2884  		pthread_mutex_destroy(&dh->lock);
2885  		free(dh);
2886  	}
2887  	free_path(f, ino, path);
2888  }
2889  static int extend_contents(struct fuse_dh *dh, unsigned minsize)
2890  {
2891  	if (minsize > dh->size) {
2892  		char *newptr;
2893  		unsigned newsize = dh->size;
2894  		if (!newsize)
2895  			newsize = 1024;
2896  		while (newsize < minsize) {
2897  			if (newsize >= 0x80000000)
2898  				newsize = 0xffffffff;
2899  			else
2900  				newsize *= 2;
2901  		}
2902  		newptr = (char *) realloc(dh->contents, newsize);
2903  		if (!newptr) {
2904  			dh->error = -ENOMEM;
2905  			return -1;
2906  		}
2907  		dh->contents = newptr;
2908  		dh->size = newsize;
2909  	}
2910  	return 0;
2911  }
2912  static int fuse_add_direntry_to_dh(struct fuse_dh *dh, const char *name,
2913  				   struct stat *st)
2914  {
2915  	struct fuse_direntry *de;
2916  	de = malloc(sizeof(struct fuse_direntry));
2917  	if (!de) {
2918  		dh->error = -ENOMEM;
2919  		return -1;
2920  	}
2921  	de->name = strdup(name);
2922  	if (!de->name) {
2923  		dh->error = -ENOMEM;
2924  		free(de);
2925  		return -1;
2926  	}
2927  	de->stat = *st;
2928  	de->next = NULL;
2929  	*dh->last = de;
2930  	dh->last = &de->next;
2931  	return 0;
2932  }
2933  static fuse_ino_t lookup_nodeid(struct fuse *f, fuse_ino_t parent,
2934  				const char *name)
2935  {
2936  	struct node *node;
2937  	fuse_ino_t res = FUSE_UNKNOWN_INO;
2938  	pthread_mutex_lock(&f->lock);
2939  	node = lookup_node(f, parent, name);
2940  	if (node)
2941  		res = node->nodeid;
2942  	pthread_mutex_unlock(&f->lock);
2943  	return res;
2944  }
2945  static int fill_dir(void *dh_, const char *name, const struct stat *statp,
2946  		    off_t off, enum fuse_fill_dir_flags flags)
2947  {
2948  	struct fuse_dh *dh = (struct fuse_dh *) dh_;
2949  	struct stat stbuf;
2950  	if ((flags & ~FUSE_FILL_DIR_PLUS) != 0) {
2951  		dh->error = -EIO;
2952  		return 1;
2953  	}
2954  	if (statp)
2955  		stbuf = *statp;
2956  	else {
2957  		memset(&stbuf, 0, sizeof(stbuf));
2958  		stbuf.st_ino = FUSE_UNKNOWN_INO;
2959  	}
2960  	if (!dh->fuse->conf.use_ino) {
2961  		stbuf.st_ino = FUSE_UNKNOWN_INO;
2962  		if (dh->fuse->conf.readdir_ino) {
2963  			stbuf.st_ino = (ino_t)
2964  				lookup_nodeid(dh->fuse, dh->nodeid, name);
2965  		}
2966  	}
2967  	if (off) {
2968  		size_t newlen;
2969  		if (dh->filled) {
2970  			dh->error = -EIO;
2971  			return 1;
2972  		}
2973  		if (dh->first) {
2974  			dh->error = -EIO;
2975  			return 1;
2976  		}
2977  		if (extend_contents(dh, dh->needlen) == -1)
2978  			return 1;
2979  		newlen = dh->len +
2980  			fuse_add_direntry(dh->req, dh->contents + dh->len,
2981  					  dh->needlen - dh->len, name,
2982  					  &stbuf, off);
2983  		if (newlen > dh->needlen)
2984  			return 1;
2985  		dh->len = newlen;
2986  	} else {
2987  		dh->filled = 1;
2988  		if (fuse_add_direntry_to_dh(dh, name, &stbuf) == -1)
2989  			return 1;
2990  	}
2991  	return 0;
2992  }
2993  static int is_dot_or_dotdot(const char *name)
2994  {
2995  	return name[0] == '.' && (name[1] == '\0' ||
2996  				  (name[1] == '.' && name[2] == '\0'));
2997  }
2998  static int fill_dir_plus(void *dh_, const char *name, const struct stat *statp,
2999  			 off_t off, enum fuse_fill_dir_flags flags)
3000  {
3001  	struct fuse_dh *dh = (struct fuse_dh *) dh_;
3002  	struct fuse_entry_param e = {
3003  		.ino = 0,
3004  	};
3005  	struct fuse *f = dh->fuse;
3006  	int res;
3007  	if ((flags & ~FUSE_FILL_DIR_PLUS) != 0) {
3008  		dh->error = -EIO;
3009  		return 1;
3010  	}
3011  	if (statp && (flags & FUSE_FILL_DIR_PLUS)) {
3012  		e.attr = *statp;
3013  		if (!is_dot_or_dotdot(name)) {
3014  			res = do_lookup(f, dh->nodeid, name, &e);
3015  			if (res) {
3016  				dh->error = res;
3017  				return 1;
3018  			}
3019  		}
3020  	} else {
3021  		e.attr.st_ino = FUSE_UNKNOWN_INO;
3022  		if (statp) {
3023  			e.attr.st_mode = statp->st_mode;
3024  			if (f->conf.use_ino)
3025  				e.attr.st_ino = statp->st_ino;
3026  		}
3027  		if (!f->conf.use_ino && f->conf.readdir_ino) {
3028  			e.attr.st_ino = (ino_t)
3029  				lookup_nodeid(f, dh->nodeid, name);
3030  		}
3031  	}
3032  	if (off) {
3033  		size_t newlen;
3034  		if (dh->filled) {
3035  			dh->error = -EIO;
3036  			return 1;
3037  		}
3038  		if (dh->first) {
3039  			dh->error = -EIO;
3040  			return 1;
3041  		}
3042  		if (extend_contents(dh, dh->needlen) == -1)
3043  			return 1;
3044  		newlen = dh->len +
3045  			fuse_add_direntry_plus(dh->req, dh->contents + dh->len,
3046  					       dh->needlen - dh->len, name,
3047  					       &e, off);
3048  		if (newlen > dh->needlen)
3049  			return 1;
3050  		dh->len = newlen;
3051  	} else {
3052  		dh->filled = 1;
3053  		if (fuse_add_direntry_to_dh(dh, name, &e.attr) == -1)
3054  			return 1;
3055  	}
3056  	return 0;
3057  }
3058  static void free_direntries(struct fuse_direntry *de)
3059  {
3060  	while (de) {
3061  		struct fuse_direntry *next = de->next;
3062  		free(de->name);
3063  		free(de);
3064  		de = next;
3065  	}
3066  }
3067  static int readdir_fill(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3068  			size_t size, off_t off, struct fuse_dh *dh,
3069  			struct fuse_file_info *fi,
3070  			enum fuse_readdir_flags flags)
3071  {
3072  	char *path;
3073  	int err;
3074  	if (f->fs->op.readdir)
3075  		err = get_path_nullok(f, ino, &path);
3076  	else
3077  		err = get_path(f, ino, &path);
3078  	if (!err) {
3079  		struct fuse_intr_data d;
3080  		fuse_fill_dir_t filler = fill_dir;
3081  		if (flags & FUSE_READDIR_PLUS)
3082  			filler = fill_dir_plus;
3083  		free_direntries(dh->first);
3084  		dh->first = NULL;
3085  		dh->last = &dh->first;
3086  		dh->len = 0;
3087  		dh->error = 0;
3088  		dh->needlen = size;
3089  		dh->filled = 0;
3090  		dh->req = req;
3091  		fuse_prepare_interrupt(f, req, &d);
3092  		err = fuse_fs_readdir(f->fs, path, dh, filler, off, fi, flags);
3093  		fuse_finish_interrupt(f, req, &d);
3094  		dh->req = NULL;
3095  		if (!err)
3096  			err = dh->error;
3097  		if (err)
3098  			dh->filled = 0;
3099  		free_path(f, ino, path);
3100  	}
3101  	return err;
3102  }
3103  static int readdir_fill_from_list(fuse_req_t req, struct fuse_dh *dh,
3104  				  off_t off, enum fuse_readdir_flags flags)
3105  {
3106  	off_t pos;
3107  	struct fuse_direntry *de = dh->first;
3108  	dh->len = 0;
3109  	if (extend_contents(dh, dh->needlen) == -1)
3110  		return dh->error;
3111  	for (pos = 0; pos < off; pos++) {
3112  		if (!de)
3113  			break;
3114  		de = de->next;
3115  	}
3116  	while (de) {
3117  		char *p = dh->contents + dh->len;
3118  		unsigned rem = dh->needlen - dh->len;
3119  		unsigned thislen;
3120  		unsigned newlen;
3121  		pos++;
3122  		if (flags & FUSE_READDIR_PLUS) {
3123  			struct fuse_entry_param e = {
3124  				.ino = 0,
3125  				.attr = de->stat,
3126  			};
3127  			thislen = fuse_add_direntry_plus(req, p, rem,
3128  							 de->name, &e, pos);
3129  		} else {
3130  			thislen = fuse_add_direntry(req, p, rem,
3131  						    de->name, &de->stat, pos);
3132  		}
3133  		newlen = dh->len + thislen;
3134  		if (newlen > dh->needlen)
3135  			break;
3136  		dh->len = newlen;
3137  		de = de->next;
3138  	}
3139  	return 0;
3140  }
3141  static void fuse_readdir_common(fuse_req_t req, fuse_ino_t ino, size_t size,
3142  				off_t off, struct fuse_file_info *llfi,
3143  				enum fuse_readdir_flags flags)
3144  {
3145  	struct fuse *f = req_fuse_prepare(req);
3146  	struct fuse_file_info fi;
3147  	struct fuse_dh *dh = get_dirhandle(llfi, &fi);
3148  	int err;
3149  	pthread_mutex_lock(&dh->lock);
3150  	if (!off)
3151  		dh->filled = 0;
3152  	if (!dh->filled) {
3153  		err = readdir_fill(f, req, ino, size, off, dh, &fi, flags);
3154  		if (err) {
3155  			reply_err(req, err);
3156  			goto out;
3157  		}
3158  	}
3159  	if (dh->filled) {
3160  		dh->needlen = size;
3161  		err = readdir_fill_from_list(req, dh, off, flags);
3162  		if (err) {
3163  			reply_err(req, err);
3164  			goto out;
3165  		}
3166  	}
3167  	fuse_reply_buf(req, dh->contents, dh->len);
3168  out:
3169  	pthread_mutex_unlock(&dh->lock);
3170  }
3171  static void fuse_lib_readdir(fuse_req_t req, fuse_ino_t ino, size_t size,
3172  			     off_t off, struct fuse_file_info *llfi)
3173  {
3174  	fuse_readdir_common(req, ino, size, off, llfi, 0);
3175  }
3176  static void fuse_lib_readdirplus(fuse_req_t req, fuse_ino_t ino, size_t size,
3177  				  off_t off, struct fuse_file_info *llfi)
3178  {
3179  	fuse_readdir_common(req, ino, size, off, llfi, FUSE_READDIR_PLUS);
3180  }
3181  static void fuse_lib_releasedir(fuse_req_t req, fuse_ino_t ino,
3182  				struct fuse_file_info *llfi)
3183  {
3184  	struct fuse *f = req_fuse_prepare(req);
3185  	struct fuse_intr_data d;
3186  	struct fuse_file_info fi;
3187  	struct fuse_dh *dh = get_dirhandle(llfi, &fi);
3188  	char *path;
3189  	get_path_nullok(f, ino, &path);
3190  	fuse_prepare_interrupt(f, req, &d);
3191  	fuse_fs_releasedir(f->fs, path, &fi);
3192  	fuse_finish_interrupt(f, req, &d);
3193  	free_path(f, ino, path);
3194  	pthread_mutex_lock(&dh->lock);
3195  	pthread_mutex_unlock(&dh->lock);
3196  	pthread_mutex_destroy(&dh->lock);
3197  	free_direntries(dh->first);
3198  	free(dh->contents);
3199  	free(dh);
3200  	reply_err(req, 0);
3201  }
3202  static void fuse_lib_fsyncdir(fuse_req_t req, fuse_ino_t ino, int datasync,
3203  			      struct fuse_file_info *llfi)
3204  {
3205  	struct fuse *f = req_fuse_prepare(req);
3206  	struct fuse_file_info fi;
3207  	char *path;
3208  	int err;
3209  	get_dirhandle(llfi, &fi);
3210  	err = get_path_nullok(f, ino, &path);
3211  	if (!err) {
3212  		struct fuse_intr_data d;
3213  		fuse_prepare_interrupt(f, req, &d);
3214  		err = fuse_fs_fsyncdir(f->fs, path, datasync, &fi);
3215  		fuse_finish_interrupt(f, req, &d);
3216  		free_path(f, ino, path);
3217  	}
3218  	reply_err(req, err);
3219  }
3220  static void fuse_lib_statfs(fuse_req_t req, fuse_ino_t ino)
3221  {
3222  	struct fuse *f = req_fuse_prepare(req);
3223  	struct statvfs buf;
3224  	char *path = NULL;
3225  	int err = 0;
3226  	memset(&buf, 0, sizeof(buf));
3227  	if (ino)
3228  		err = get_path(f, ino, &path);
3229  	if (!err) {
3230  		struct fuse_intr_data d;
3231  		fuse_prepare_interrupt(f, req, &d);
3232  		err = fuse_fs_statfs(f->fs, path ? path : "/", &buf);
3233  		fuse_finish_interrupt(f, req, &d);
3234  		free_path(f, ino, path);
3235  	}
3236  	if (!err)
3237  		fuse_reply_statfs(req, &buf);
3238  	else
3239  		reply_err(req, err);
3240  }
3241  static void fuse_lib_setxattr(fuse_req_t req, fuse_ino_t ino, const char *name,
3242  			      const char *value, size_t size, int flags)
3243  {
3244  	struct fuse *f = req_fuse_prepare(req);
3245  	char *path;
3246  	int err;
3247  	err = get_path(f, ino, &path);
3248  	if (!err) {
3249  		struct fuse_intr_data d;
3250  		fuse_prepare_interrupt(f, req, &d);
3251  		err = fuse_fs_setxattr(f->fs, path, name, value, size, flags);
3252  		fuse_finish_interrupt(f, req, &d);
3253  		free_path(f, ino, path);
3254  	}
3255  	reply_err(req, err);
3256  }
3257  static int common_getxattr(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3258  			   const char *name, char *value, size_t size)
3259  {
3260  	int err;
3261  	char *path;
3262  	err = get_path(f, ino, &path);
3263  	if (!err) {
3264  		struct fuse_intr_data d;
3265  		fuse_prepare_interrupt(f, req, &d);
3266  		err = fuse_fs_getxattr(f->fs, path, name, value, size);
3267  		fuse_finish_interrupt(f, req, &d);
3268  		free_path(f, ino, path);
3269  	}
3270  	return err;
3271  }
3272  static void fuse_lib_getxattr(fuse_req_t req, fuse_ino_t ino, const char *name,
3273  			      size_t size)
3274  {
3275  	struct fuse *f = req_fuse_prepare(req);
3276  	int res;
3277  	if (size) {
3278  		char *value = (char *) malloc(size);
3279  		if (value == NULL) {
3280  			reply_err(req, -ENOMEM);
3281  			return;
3282  		}
3283  		res = common_getxattr(f, req, ino, name, value, size);
3284  		if (res > 0)
3285  			fuse_reply_buf(req, value, res);
3286  		else
3287  			reply_err(req, res);
3288  		free(value);
3289  	} else {
3290  		res = common_getxattr(f, req, ino, name, NULL, 0);
3291  		if (res >= 0)
3292  			fuse_reply_xattr(req, res);
3293  		else
3294  			reply_err(req, res);
3295  	}
3296  }
3297  static int common_listxattr(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3298  			    char *list, size_t size)
3299  {
3300  	char *path;
3301  	int err;
3302  	err = get_path(f, ino, &path);
3303  	if (!err) {
3304  		struct fuse_intr_data d;
3305  		fuse_prepare_interrupt(f, req, &d);
3306  		err = fuse_fs_listxattr(f->fs, path, list, size);
3307  		fuse_finish_interrupt(f, req, &d);
3308  		free_path(f, ino, path);
3309  	}
3310  	return err;
3311  }
3312  static void fuse_lib_listxattr(fuse_req_t req, fuse_ino_t ino, size_t size)
3313  {
3314  	struct fuse *f = req_fuse_prepare(req);
3315  	int res;
3316  	if (size) {
3317  		char *list = (char *) malloc(size);
3318  		if (list == NULL) {
3319  			reply_err(req, -ENOMEM);
3320  			return;
3321  		}
3322  		res = common_listxattr(f, req, ino, list, size);
3323  		if (res > 0)
3324  			fuse_reply_buf(req, list, res);
3325  		else
3326  			reply_err(req, res);
3327  		free(list);
3328  	} else {
3329  		res = common_listxattr(f, req, ino, NULL, 0);
3330  		if (res >= 0)
3331  			fuse_reply_xattr(req, res);
3332  		else
3333  			reply_err(req, res);
3334  	}
3335  }
3336  static void fuse_lib_removexattr(fuse_req_t req, fuse_ino_t ino,
3337  				 const char *name)
3338  {
3339  	struct fuse *f = req_fuse_prepare(req);
3340  	char *path;
3341  	int err;
3342  	err = get_path(f, ino, &path);
3343  	if (!err) {
3344  		struct fuse_intr_data d;
3345  		fuse_prepare_interrupt(f, req, &d);
3346  		err = fuse_fs_removexattr(f->fs, path, name);
3347  		fuse_finish_interrupt(f, req, &d);
3348  		free_path(f, ino, path);
3349  	}
3350  	reply_err(req, err);
3351  }
3352  static struct lock *locks_conflict(struct node *node, const struct lock *lock)
3353  {
3354  	struct lock *l;
3355  	for (l = node->locks; l; l = l->next)
3356  		if (l->owner != lock->owner &&
3357  		    lock->start <= l->end && l->start <= lock->end &&
3358  		    (l->type == F_WRLCK || lock->type == F_WRLCK))
3359  			break;
3360  	return l;
3361  }
3362  static void delete_lock(struct lock **lockp)
3363  {
3364  	struct lock *l = *lockp;
3365  	*lockp = l->next;
3366  	free(l);
3367  }
3368  static void insert_lock(struct lock **pos, struct lock *lock)
3369  {
3370  	lock->next = *pos;
3371  	*pos = lock;
3372  }
3373  static int locks_insert(struct node *node, struct lock *lock)
3374  {
3375  	struct lock **lp;
3376  	struct lock *newl1 = NULL;
3377  	struct lock *newl2 = NULL;
3378  	if (lock->type != F_UNLCK || lock->start != 0 ||
3379  	    lock->end != OFFSET_MAX) {
3380  		newl1 = malloc(sizeof(struct lock));
3381  		newl2 = malloc(sizeof(struct lock));
3382  		if (!newl1 || !newl2) {
3383  			free(newl1);
3384  			free(newl2);
3385  			return -ENOLCK;
3386  		}
3387  	}
3388  	for (lp = &node->locks; *lp;) {
3389  		struct lock *l = *lp;
3390  		if (l->owner != lock->owner)
3391  			goto skip;
3392  		if (lock->type == l->type) {
3393  			if (l->end < lock->start - 1)
3394  				goto skip;
3395  			if (lock->end < l->start - 1)
3396  				break;
3397  			if (l->start <= lock->start && lock->end <= l->end)
3398  				goto out;
3399  			if (l->start < lock->start)
3400  				lock->start = l->start;
3401  			if (lock->end < l->end)
3402  				lock->end = l->end;
3403  			goto delete;
3404  		} else {
3405  			if (l->end < lock->start)
3406  				goto skip;
3407  			if (lock->end < l->start)
3408  				break;
3409  			if (lock->start <= l->start && l->end <= lock->end)
3410  				goto delete;
3411  			if (l->end <= lock->end) {
3412  				l->end = lock->start - 1;
3413  				goto skip;
3414  			}
3415  			if (lock->start <= l->start) {
3416  				l->start = lock->end + 1;
3417  				break;
3418  			}
3419  			*newl2 = *l;
3420  			newl2->start = lock->end + 1;
3421  			l->end = lock->start - 1;
3422  			insert_lock(&l->next, newl2);
3423  			newl2 = NULL;
3424  		}
3425  	skip:
3426  		lp = &l->next;
3427  		continue;
3428  	delete:
3429  		delete_lock(lp);
3430  	}
3431  	if (lock->type != F_UNLCK) {
3432  		*newl1 = *lock;
3433  		insert_lock(lp, newl1);
3434  		newl1 = NULL;
3435  	}
3436  out:
3437  	free(newl1);
3438  	free(newl2);
3439  	return 0;
3440  }
3441  static void flock_to_lock(struct flock *flock, struct lock *lock)
3442  {
3443  	memset(lock, 0, sizeof(struct lock));
3444  	lock->type = flock->l_type;
3445  	lock->start = flock->l_start;
3446  	lock->end =
3447  		flock->l_len ? flock->l_start + flock->l_len - 1 : OFFSET_MAX;
3448  	lock->pid = flock->l_pid;
3449  }
3450  static void lock_to_flock(struct lock *lock, struct flock *flock)
3451  {
3452  	flock->l_type = lock->type;
3453  	flock->l_start = lock->start;
3454  	flock->l_len =
3455  		(lock->end == OFFSET_MAX) ? 0 : lock->end - lock->start + 1;
3456  	flock->l_pid = lock->pid;
3457  }
3458  static int fuse_flush_common(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3459  			     const char *path, struct fuse_file_info *fi)
3460  {
3461  	struct fuse_intr_data d;
3462  	struct flock lock;
3463  	struct lock l;
3464  	int err;
3465  	int errlock;
3466  	fuse_prepare_interrupt(f, req, &d);
3467  	memset(&lock, 0, sizeof(lock));
3468  	lock.l_type = F_UNLCK;
3469  	lock.l_whence = SEEK_SET;
3470  	err = fuse_fs_flush(f->fs, path, fi);
3471  	errlock = fuse_fs_lock(f->fs, path, fi, F_SETLK, &lock);
3472  	fuse_finish_interrupt(f, req, &d);
3473  	if (errlock != -ENOSYS) {
3474  		flock_to_lock(&lock, &l);
3475  		l.owner = fi->lock_owner;
3476  		pthread_mutex_lock(&f->lock);
3477  		locks_insert(get_node(f, ino), &l);
3478  		pthread_mutex_unlock(&f->lock);
3479  		if (err == -ENOSYS)
3480  			err = 0;
3481  	}
3482  	return err;
3483  }
3484  static void fuse_lib_release(fuse_req_t req, fuse_ino_t ino,
3485  			     struct fuse_file_info *fi)
3486  {
3487  	struct fuse *f = req_fuse_prepare(req);
3488  	struct fuse_intr_data d;
3489  	char *path;
3490  	int err = 0;
3491  	get_path_nullok(f, ino, &path);
3492  	if (fi->flush) {
3493  		err = fuse_flush_common(f, req, ino, path, fi);
3494  		if (err == -ENOSYS)
3495  			err = 0;
3496  	}
3497  	fuse_prepare_interrupt(f, req, &d);
3498  	fuse_do_release(f, ino, path, fi);
3499  	fuse_finish_interrupt(f, req, &d);
3500  	free_path(f, ino, path);
3501  	reply_err(req, err);
3502  }
3503  static void fuse_lib_flush(fuse_req_t req, fuse_ino_t ino,
3504  			   struct fuse_file_info *fi)
3505  {
3506  	struct fuse *f = req_fuse_prepare(req);
3507  	char *path;
3508  	int err;
3509  	get_path_nullok(f, ino, &path);
3510  	err = fuse_flush_common(f, req, ino, path, fi);
3511  	free_path(f, ino, path);
3512  	reply_err(req, err);
3513  }
3514  static int fuse_lock_common(fuse_req_t req, fuse_ino_t ino,
3515  			    struct fuse_file_info *fi, struct flock *lock,
3516  			    int cmd)
3517  {
3518  	struct fuse *f = req_fuse_prepare(req);
3519  	char *path;
3520  	int err;
3521  	err = get_path_nullok(f, ino, &path);
3522  	if (!err) {
3523  		struct fuse_intr_data d;
3524  		fuse_prepare_interrupt(f, req, &d);
3525  		err = fuse_fs_lock(f->fs, path, fi, cmd, lock);
3526  		fuse_finish_interrupt(f, req, &d);
3527  		free_path(f, ino, path);
3528  	}
3529  	return err;
3530  }
3531  static void fuse_lib_getlk(fuse_req_t req, fuse_ino_t ino,
3532  			   struct fuse_file_info *fi, struct flock *lock)
3533  {
3534  	int err;
3535  	struct lock l;
3536  	struct lock *conflict;
3537  	struct fuse *f = req_fuse(req);
3538  	flock_to_lock(lock, &l);
3539  	l.owner = fi->lock_owner;
3540  	pthread_mutex_lock(&f->lock);
3541  	conflict = locks_conflict(get_node(f, ino), &l);
3542  	if (conflict)
3543  		lock_to_flock(conflict, lock);
3544  	pthread_mutex_unlock(&f->lock);
3545  	if (!conflict)
3546  		err = fuse_lock_common(req, ino, fi, lock, F_GETLK);
3547  	else
3548  		err = 0;
3549  	if (!err)
3550  		fuse_reply_lock(req, lock);
3551  	else
3552  		reply_err(req, err);
3553  }
3554  static void fuse_lib_setlk(fuse_req_t req, fuse_ino_t ino,
3555  			   struct fuse_file_info *fi, struct flock *lock,
3556  			   int sleep)
3557  {
3558  	int err = fuse_lock_common(req, ino, fi, lock,
3559  				   sleep ? F_SETLKW : F_SETLK);
3560  	if (!err) {
3561  		struct fuse *f = req_fuse(req);
3562  		struct lock l;
3563  		flock_to_lock(lock, &l);
3564  		l.owner = fi->lock_owner;
3565  		pthread_mutex_lock(&f->lock);
3566  		locks_insert(get_node(f, ino), &l);
3567  		pthread_mutex_unlock(&f->lock);
3568  	}
3569  	reply_err(req, err);
3570  }
3571  static void fuse_lib_flock(fuse_req_t req, fuse_ino_t ino,
3572  			   struct fuse_file_info *fi, int op)
3573  {
3574  	struct fuse *f = req_fuse_prepare(req);
3575  	char *path;
3576  	int err;
3577  	err = get_path_nullok(f, ino, &path);
3578  	if (err == 0) {
3579  		struct fuse_intr_data d;
3580  		fuse_prepare_interrupt(f, req, &d);
3581  		err = fuse_fs_flock(f->fs, path, fi, op);
3582  		fuse_finish_interrupt(f, req, &d);
3583  		free_path(f, ino, path);
3584  	}
3585  	reply_err(req, err);
3586  }
3587  static void fuse_lib_bmap(fuse_req_t req, fuse_ino_t ino, size_t blocksize,
3588  			  uint64_t idx)
3589  {
3590  	struct fuse *f = req_fuse_prepare(req);
3591  	struct fuse_intr_data d;
3592  	char *path;
3593  	int err;
3594  	err = get_path(f, ino, &path);
3595  	if (!err) {
3596  		fuse_prepare_interrupt(f, req, &d);
3597  		err = fuse_fs_bmap(f->fs, path, blocksize, &idx);
3598  		fuse_finish_interrupt(f, req, &d);
3599  		free_path(f, ino, path);
3600  	}
3601  	if (!err)
3602  		fuse_reply_bmap(req, idx);
3603  	else
3604  		reply_err(req, err);
3605  }
3606  static void fuse_lib_ioctl(fuse_req_t req, fuse_ino_t ino, unsigned int cmd,
3607  			   void *arg, struct fuse_file_info *llfi,
3608  			   unsigned int flags, const void *in_buf,
3609  			   size_t in_bufsz, size_t out_bufsz)
3610  {
3611  	struct fuse *f = req_fuse_prepare(req);
3612  	struct fuse_intr_data d;
3613  	struct fuse_file_info fi;
3614  	char *path, *out_buf = NULL;
3615  	int err;
3616  	err = -EPERM;
3617  	if (flags & FUSE_IOCTL_UNRESTRICTED)
3618  		goto err;
3619  	if (flags & FUSE_IOCTL_DIR)
3620  		get_dirhandle(llfi, &fi);
3621  	else
3622  		fi = *llfi;
3623  	if (out_bufsz) {
3624  		err = -ENOMEM;
3625  		out_buf = malloc(out_bufsz);
3626  		if (!out_buf)
3627  			goto err;
3628  	}
3629  	assert(!in_bufsz || !out_bufsz || in_bufsz == out_bufsz);
3630  	if (out_buf && in_bufsz)
3631  		memcpy(out_buf, in_buf, in_bufsz);
3632  	err = get_path_nullok(f, ino, &path);
3633  	if (err)
3634  		goto err;
3635  	fuse_prepare_interrupt(f, req, &d);
3636  	err = fuse_fs_ioctl(f->fs, path, cmd, arg, &fi, flags,
3637  			    out_buf ? out_buf : (void *)in_buf);
3638  	fuse_finish_interrupt(f, req, &d);
3639  	free_path(f, ino, path);
3640  	if (err < 0)
3641  		goto err;
3642  	fuse_reply_ioctl(req, err, out_buf, out_bufsz);
3643  	goto out;
3644  err:
3645  	reply_err(req, err);
3646  out:
3647  	free(out_buf);
3648  }
3649  static void fuse_lib_poll(fuse_req_t req, fuse_ino_t ino,
3650  			  struct fuse_file_info *fi, struct fuse_pollhandle *ph)
3651  {
3652  	struct fuse *f = req_fuse_prepare(req);
3653  	struct fuse_intr_data d;
3654  	char *path;
3655  	int err;
3656  	unsigned revents = 0;
3657  	err = get_path_nullok(f, ino, &path);
3658  	if (!err) {
3659  		fuse_prepare_interrupt(f, req, &d);
3660  		err = fuse_fs_poll(f->fs, path, fi, ph, &revents);
3661  		fuse_finish_interrupt(f, req, &d);
3662  		free_path(f, ino, path);
3663  	}
3664  	if (!err)
3665  		fuse_reply_poll(req, revents);
3666  	else
3667  		reply_err(req, err);
3668  }
3669  static void fuse_lib_fallocate(fuse_req_t req, fuse_ino_t ino, int mode,
3670  		off_t offset, off_t length, struct fuse_file_info *fi)
3671  {
3672  	struct fuse *f = req_fuse_prepare(req);
3673  	struct fuse_intr_data d;
3674  	char *path;
3675  	int err;
3676  	err = get_path_nullok(f, ino, &path);
3677  	if (!err) {
3678  		fuse_prepare_interrupt(f, req, &d);
3679  		err = fuse_fs_fallocate(f->fs, path, mode, offset, length, fi);
3680  		fuse_finish_interrupt(f, req, &d);
3681  		free_path(f, ino, path);
3682  	}
3683  	reply_err(req, err);
3684  }
3685  static void fuse_lib_copy_file_range(fuse_req_t req, fuse_ino_t nodeid_in,
3686  				     off_t off_in, struct fuse_file_info *fi_in,
3687  				     fuse_ino_t nodeid_out, off_t off_out,
3688  				     struct fuse_file_info *fi_out, size_t len,
3689  				     int flags)
3690  {
3691  	struct fuse *f = req_fuse_prepare(req);
3692  	struct fuse_intr_data d;
3693  	char *path_in, *path_out;
3694  	int err;
3695  	ssize_t res;
3696  	err = get_path_nullok(f, nodeid_in, &path_in);
3697  	if (err) {
3698  		reply_err(req, err);
3699  		return;
3700  	}
3701  	err = get_path_nullok(f, nodeid_out, &path_out);
3702  	if (err) {
3703  		free_path(f, nodeid_in, path_in);
3704  		reply_err(req, err);
3705  		return;
3706  	}
3707  	fuse_prepare_interrupt(f, req, &d);
3708  	res = fuse_fs_copy_file_range(f->fs, path_in, fi_in, off_in, path_out,
3709  				      fi_out, off_out, len, flags);
3710  	fuse_finish_interrupt(f, req, &d);
3711  	if (res >= 0)
3712  		fuse_reply_write(req, res);
3713  	else
3714  		reply_err(req, res);
3715  	free_path(f, nodeid_in, path_in);
3716  	free_path(f, nodeid_out, path_out);
3717  }
3718  static void fuse_lib_lseek(fuse_req_t req, fuse_ino_t ino, off_t off, int whence,
3719  			   struct fuse_file_info *fi)
3720  {
3721  	struct fuse *f = req_fuse_prepare(req);
3722  	struct fuse_intr_data d;
3723  	char *path;
3724  	int err;
3725  	off_t res;
3726  	err = get_path(f, ino, &path);
3727  	if (err) {
3728  		reply_err(req, err);
3729  		return;
3730  	}
3731  	fuse_prepare_interrupt(f, req, &d);
3732  	res = fuse_fs_lseek(f->fs, path, off, whence, fi);
3733  	fuse_finish_interrupt(f, req, &d);
3734  	free_path(f, ino, path);
3735  	if (res >= 0)
3736  		fuse_reply_lseek(req, res);
3737  	else
3738  		reply_err(req, res);
3739  }
3740  static int clean_delay(struct fuse *f)
3741  {
3742  	int min_sleep = 60;
3743  	int max_sleep = 3600;
3744  	int sleep_time = f->conf.remember / 10;
3745  	if (sleep_time > max_sleep)
3746  		return max_sleep;
3747  	if (sleep_time < min_sleep)
3748  		return min_sleep;
3749  	return sleep_time;
3750  }
3751  int fuse_clean_cache(struct fuse *f)
3752  {
3753  	struct node_lru *lnode;
3754  	struct list_head *curr, *next;
3755  	struct node *node;
3756  	struct timespec now;
3757  	pthread_mutex_lock(&f->lock);
3758  	curr_time(&now);
3759  	for (curr = f->lru_table.next; curr != &f->lru_table; curr = next) {
3760  		double age;
3761  		next = curr->next;
3762  		lnode = list_entry(curr, struct node_lru, lru);
3763  		node = &lnode->node;
3764  		age = diff_timespec(&now, &lnode->forget_time);
3765  		if (age <= f->conf.remember)
3766  			break;
3767  		assert(node->nlookup == 1);
3768  		if (node->refctr > 1)
3769  			continue;
3770  		node->nlookup = 0;
3771  		unhash_name(f, node);
3772  		unref_node(f, node);
3773  	}
3774  	pthread_mutex_unlock(&f->lock);
3775  	return clean_delay(f);
3776  }
3777  static struct fuse_lowlevel_ops fuse_path_ops = {
3778  	.init = fuse_lib_init,
3779  	.destroy = fuse_lib_destroy,
3780  	.lookup = fuse_lib_lookup,
3781  	.forget = fuse_lib_forget,
3782  	.forget_multi = fuse_lib_forget_multi,
3783  	.getattr = fuse_lib_getattr,
3784  	.setattr = fuse_lib_setattr,
3785  	.access = fuse_lib_access,
3786  	.readlink = fuse_lib_readlink,
3787  	.mknod = fuse_lib_mknod,
3788  	.mkdir = fuse_lib_mkdir,
3789  	.unlink = fuse_lib_unlink,
3790  	.rmdir = fuse_lib_rmdir,
3791  	.symlink = fuse_lib_symlink,
3792  	.rename = fuse_lib_rename,
3793  	.link = fuse_lib_link,
3794  	.create = fuse_lib_create,
3795  	.open = fuse_lib_open,
3796  	.read = fuse_lib_read,
3797  	.write_buf = fuse_lib_write_buf,
3798  	.flush = fuse_lib_flush,
3799  	.release = fuse_lib_release,
3800  	.fsync = fuse_lib_fsync,
3801  	.opendir = fuse_lib_opendir,
3802  	.readdir = fuse_lib_readdir,
3803  	.readdirplus = fuse_lib_readdirplus,
3804  	.releasedir = fuse_lib_releasedir,
3805  	.fsyncdir = fuse_lib_fsyncdir,
3806  	.statfs = fuse_lib_statfs,
3807  	.setxattr = fuse_lib_setxattr,
3808  	.getxattr = fuse_lib_getxattr,
3809  	.listxattr = fuse_lib_listxattr,
3810  	.removexattr = fuse_lib_removexattr,
3811  	.getlk = fuse_lib_getlk,
3812  	.setlk = fuse_lib_setlk,
3813  	.flock = fuse_lib_flock,
3814  	.bmap = fuse_lib_bmap,
3815  	.ioctl = fuse_lib_ioctl,
3816  	.poll = fuse_lib_poll,
3817  	.fallocate = fuse_lib_fallocate,
3818  	.copy_file_range = fuse_lib_copy_file_range,
3819  	.lseek = fuse_lib_lseek,
3820  };
3821  int fuse_notify_poll(struct fuse_pollhandle *ph)
3822  {
3823  	return fuse_lowlevel_notify_poll(ph);
3824  }
3825  struct fuse_session *fuse_get_session(struct fuse *f)
3826  {
3827  	return f->se;
3828  }
3829  static int fuse_session_loop_remember(struct fuse *f)
3830  {
3831  	struct fuse_session *se = f->se;
3832  	int res = 0;
3833  	struct timespec now;
3834  	time_t next_clean;
3835  	struct pollfd fds = {
3836  		.fd = se->fd,
3837  		.events = POLLIN
3838  	};
3839  	struct fuse_buf fbuf = {
3840  		.mem = NULL,
3841  	};
3842  	curr_time(&now);
3843  	next_clean = now.tv_sec;
3844  	while (!fuse_session_exited(se)) {
3845  		unsigned timeout;
3846  		curr_time(&now);
3847  		if (now.tv_sec < next_clean)
3848  			timeout = next_clean - now.tv_sec;
3849  		else
3850  			timeout = 0;
3851  		res = poll(&fds, 1, timeout * 1000);
3852  		if (res == -1) {
3853  			if (errno == EINTR)
3854  				continue;
3855  			else
3856  				break;
3857  		} else if (res > 0) {
3858  			res = fuse_session_receive_buf_int(se, &fbuf, NULL);
3859  			if (res == -EINTR)
3860  				continue;
3861  			if (res <= 0)
3862  				break;
3863  			fuse_session_process_buf_int(se, &fbuf, NULL);
3864  		} else {
3865  			timeout = fuse_clean_cache(f);
3866  			curr_time(&now);
3867  			next_clean = now.tv_sec + timeout;
3868  		}
3869  	}
3870  	free(fbuf.mem);
3871  	fuse_session_reset(se);
3872  	return res < 0 ? -1 : 0;
3873  }
3874  int fuse_loop(struct fuse *f)
3875  {
3876  	if (!f)
3877  		return -1;
3878  	if (lru_enabled(f))
3879  		return fuse_session_loop_remember(f);
3880  	return fuse_session_loop(f->se);
3881  }
3882  FUSE_SYMVER("fuse_loop_mt_312", "fuse_loop_mt@@FUSE_3.12")
3883  int fuse_loop_mt_312(struct fuse *f, struct fuse_loop_config *config)
3884  {
3885  	if (f == NULL)
3886  		return -1;
3887  	int res = fuse_start_cleanup_thread(f);
3888  	if (res)
3889  		return -1;
3890  	res = fuse_session_loop_mt_312(fuse_get_session(f), config);
3891  	fuse_stop_cleanup_thread(f);
3892  	return res;
3893  }
3894  int fuse_loop_mt_32(struct fuse *f, struct fuse_loop_config_v1 *config_v1);
3895  FUSE_SYMVER("fuse_loop_mt_32", "fuse_loop_mt@FUSE_3.2")
3896  int fuse_loop_mt_32(struct fuse *f, struct fuse_loop_config_v1 *config_v1)
3897  {
3898  	struct fuse_loop_config *config = fuse_loop_cfg_create();
3899  	if (config == NULL)
3900  		return ENOMEM;
3901  	fuse_loop_cfg_convert(config, config_v1);
3902  	int res = fuse_loop_mt_312(f, config);
3903  	fuse_loop_cfg_destroy(config);
3904  	return res;
3905  }
3906  int fuse_loop_mt_31(struct fuse *f, int clone_fd);
3907  FUSE_SYMVER("fuse_loop_mt_31", "fuse_loop_mt@FUSE_3.0")
3908  int fuse_loop_mt_31(struct fuse *f, int clone_fd)
3909  {
3910  	int err;
3911  	struct fuse_loop_config *config = fuse_loop_cfg_create();
3912  	if (config == NULL)
3913  		return ENOMEM;
3914  	fuse_loop_cfg_set_clone_fd(config, clone_fd);
3915  	err = fuse_loop_mt_312(f, config);
3916  	fuse_loop_cfg_destroy(config);
3917  	return err;
3918  }
3919  void fuse_exit(struct fuse *f)
3920  {
3921  	fuse_session_exit(f->se);
3922  }
3923  struct fuse_context *fuse_get_context(void)
3924  {
3925  	struct fuse_context_i *c = fuse_get_context_internal();
3926  	if (c)
3927  		return &c->ctx;
3928  	else
3929  		return NULL;
3930  }
3931  int fuse_getgroups(int size, gid_t list[])
3932  {
3933  	struct fuse_context_i *c = fuse_get_context_internal();
3934  	if (!c)
3935  		return -EINVAL;
3936  	return fuse_req_getgroups(c->req, size, list);
3937  }
3938  int fuse_interrupted(void)
3939  {
3940  	struct fuse_context_i *c = fuse_get_context_internal();
3941  	if (c)
3942  		return fuse_req_interrupted(c->req);
3943  	else
3944  		return 0;
3945  }
3946  int fuse_invalidate_path(struct fuse *f, const char *path) {
3947  	fuse_ino_t ino;
3948  	int err = lookup_path_in_cache(f, path, &ino);
3949  	if (err) {
3950  		return err;
3951  	}
3952  	return fuse_lowlevel_notify_inval_inode(f->se, ino, 0, 0);
3953  }
3954  #define FUSE_LIB_OPT(t, p, v) { t, offsetof(struct fuse_config, p), v }
3955  static const struct fuse_opt fuse_lib_opts[] = {
3956  	FUSE_OPT_KEY("debug",		      FUSE_OPT_KEY_KEEP),
3957  	FUSE_OPT_KEY("-d",		      FUSE_OPT_KEY_KEEP),
3958  	FUSE_LIB_OPT("debug",		      debug, 1),
3959  	FUSE_LIB_OPT("-d",		      debug, 1),
3960  	FUSE_LIB_OPT("kernel_cache",	      kernel_cache, 1),
3961  	FUSE_LIB_OPT("auto_cache",	      auto_cache, 1),
3962  	FUSE_LIB_OPT("noauto_cache",	      auto_cache, 0),
3963  	FUSE_LIB_OPT("no_rofd_flush",	      no_rofd_flush, 1),
3964  	FUSE_LIB_OPT("umask=",		      set_mode, 1),
3965  	FUSE_LIB_OPT("umask=%o",	      umask, 0),
3966  	FUSE_LIB_OPT("uid=",		      set_uid, 1),
3967  	FUSE_LIB_OPT("uid=%d",		      uid, 0),
3968  	FUSE_LIB_OPT("gid=",		      set_gid, 1),
3969  	FUSE_LIB_OPT("gid=%d",		      gid, 0),
3970  	FUSE_LIB_OPT("entry_timeout=%lf",     entry_timeout, 0),
3971  	FUSE_LIB_OPT("attr_timeout=%lf",      attr_timeout, 0),
3972  	FUSE_LIB_OPT("ac_attr_timeout=%lf",   ac_attr_timeout, 0),
3973  	FUSE_LIB_OPT("ac_attr_timeout=",      ac_attr_timeout_set, 1),
3974  	FUSE_LIB_OPT("negative_timeout=%lf",  negative_timeout, 0),
3975  	FUSE_LIB_OPT("noforget",              remember, -1),
3976  	FUSE_LIB_OPT("remember=%u",           remember, 0),
3977  	FUSE_LIB_OPT("modules=%s",	      modules, 0),
3978  	FUSE_LIB_OPT("parallel_direct_write=%d", parallel_direct_writes, 0),
3979  	FUSE_OPT_END
3980  };
3981  static int fuse_lib_opt_proc(void *data, const char *arg, int key,
3982  			     struct fuse_args *outargs)
3983  {
3984  	(void) arg; (void) outargs; (void) data; (void) key;
3985  	return 1;
3986  }
3987  static const struct fuse_opt fuse_help_opts[] = {
3988  	FUSE_LIB_OPT("modules=%s", modules, 1),
3989  	FUSE_OPT_KEY("modules=%s", FUSE_OPT_KEY_KEEP),
3990  	FUSE_OPT_END
3991  };
3992  static void print_module_help(const char *name,
3993  			      fuse_module_factory_t *fac)
3994  {
3995  	struct fuse_args a = FUSE_ARGS_INIT(0, NULL);
3996  	if (fuse_opt_add_arg(&a, "") == -1 ||
3997  	    fuse_opt_add_arg(&a, "-h") == -1)
3998  		return;
3999  	printf("\nOptions for %s module:\n", name);
4000  	(*fac)(&a, NULL);
4001  	fuse_opt_free_args(&a);
4002  }
4003  void fuse_lib_help(struct fuse_args *args)
4004  {
4005  	printf(
4006  "    -o kernel_cache        cache files in kernel\n"
4007  "    -o [no]auto_cache      enable caching based on modification times (off)\n"
4008  "    -o no_rofd_flush       disable flushing of read-only fd on close (off)\n"
4009  "    -o umask=M             set file permissions (octal)\n"
4010  "    -o uid=N               set file owner\n"
4011  "    -o gid=N               set file group\n"
4012  "    -o entry_timeout=T     cache timeout for names (1.0s)\n"
4013  "    -o negative_timeout=T  cache timeout for deleted names (0.0s)\n"
4014  "    -o attr_timeout=T      cache timeout for attributes (1.0s)\n"
4015  "    -o ac_attr_timeout=T   auto cache timeout for attributes (attr_timeout)\n"
4016  "    -o noforget            never forget cached inodes\n"
4017  "    -o remember=T          remember cached inodes for T seconds (0s)\n"
4018  "    -o modules=M1[:M2...]  names of modules to push onto filesystem stack\n");
4019  	fuse_lowlevel_help();
4020  	print_module_help("subdir", &fuse_module_subdir_factory);
4021  #ifdef HAVE_ICONV
4022  	print_module_help("iconv", &fuse_module_iconv_factory);
4023  #endif
4024  	struct fuse_config conf = { .modules = NULL };
4025  	if (fuse_opt_parse(args, &conf, fuse_help_opts,
4026  			   fuse_lib_opt_proc) == -1
4027  	    || !conf.modules)
4028  		return;
4029  	char *module;
4030  	char *next;
4031  	struct fuse_module *m;
4032  	for (module = conf.modules; module; module = next) {
4033  		char *p;
4034  		for (p = module; *p && *p != ':'; p++);
4035  		next = *p ? p + 1 : NULL;
4036  		*p = '\0';
4037  		m = fuse_get_module(module);
4038  		if (m)
4039  			print_module_help(module, &m->factory);
4040  	}
4041  }
4042  static int fuse_init_intr_signal(int signum, int *installed)
4043  {
4044  	struct sigaction old_sa;
4045  	if (sigaction(signum, NULL, &old_sa) == -1) {
4046  		perror("fuse: cannot get old signal handler");
4047  		return -1;
4048  	}
4049  	if (old_sa.sa_handler == SIG_DFL) {
4050  		struct sigaction sa;
4051  		memset(&sa, 0, sizeof(struct sigaction));
4052  		sa.sa_handler = fuse_intr_sighandler;
4053  		sigemptyset(&sa.sa_mask);
4054  		if (sigaction(signum, &sa, NULL) == -1) {
4055  			perror("fuse: cannot set interrupt signal handler");
4056  			return -1;
4057  		}
4058  		*installed = 1;
4059  	}
4060  	return 0;
4061  }
4062  static void fuse_restore_intr_signal(int signum)
4063  {
4064  	struct sigaction sa;
4065  	memset(&sa, 0, sizeof(struct sigaction));
4066  	sa.sa_handler = SIG_DFL;
4067  	sigaction(signum, &sa, NULL);
4068  }
4069  static int fuse_push_module(struct fuse *f, const char *module,
4070  			    struct fuse_args *args)
4071  {
4072  	struct fuse_fs *fs[2] = { f->fs, NULL };
4073  	struct fuse_fs *newfs;
4074  	struct fuse_module *m = fuse_get_module(module);
4075  	if (!m)
4076  		return -1;
4077  	newfs = m->factory(args, fs);
4078  	if (!newfs) {
4079  		fuse_put_module(m);
4080  		return -1;
4081  	}
4082  	f->fs = newfs;
4083  	return 0;
4084  }
4085  struct fuse_fs *fuse_fs_new(const struct fuse_operations *op, size_t op_size,
4086  			    void *user_data)
4087  {
4088  	struct fuse_fs *fs;
4089  	if (sizeof(struct fuse_operations) < op_size) {
4090  		fuse_log(FUSE_LOG_ERR, "fuse: warning: library too old, some operations may not not work\n");
4091  		op_size = sizeof(struct fuse_operations);
4092  	}
4093  	fs = (struct fuse_fs *) calloc(1, sizeof(struct fuse_fs));
4094  	if (!fs) {
4095  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate fuse_fs object\n");
4096  		return NULL;
4097  	}
4098  	fs->user_data = user_data;
4099  	if (op)
4100  		memcpy(&fs->op, op, op_size);
4101  	return fs;
4102  }
4103  static int node_table_init(struct node_table *t)
4104  {
4105  	t->size = NODE_TABLE_MIN_SIZE;
4106  	t->array = (struct node **) calloc(1, sizeof(struct node *) * t->size);
4107  	if (t->array == NULL) {
4108  		fuse_log(FUSE_LOG_ERR, "fuse: memory allocation failed\n");
4109  		return -1;
4110  	}
4111  	t->use = 0;
4112  	t->split = 0;
4113  	return 0;
4114  }
4115  static void *fuse_prune_nodes(void *fuse)
4116  {
4117  	struct fuse *f = fuse;
4118  	int sleep_time;
4119  	while(1) {
4120  		sleep_time = fuse_clean_cache(f);
4121  		sleep(sleep_time);
4122  	}
4123  	return NULL;
4124  }
4125  int fuse_start_cleanup_thread(struct fuse *f)
4126  {
4127  	if (lru_enabled(f))
4128  		return fuse_start_thread(&f->prune_thread, fuse_prune_nodes, f);
4129  	return 0;
4130  }
4131  void fuse_stop_cleanup_thread(struct fuse *f)
4132  {
4133  	if (lru_enabled(f)) {
4134  		pthread_mutex_lock(&f->lock);
4135  		pthread_cancel(f->prune_thread);
4136  		pthread_mutex_unlock(&f->lock);
4137  		pthread_join(f->prune_thread, NULL);
4138  	}
4139  }
4140  FUSE_SYMVER("fuse_new_31", "fuse_new@@FUSE_3.1")
4141  struct fuse *fuse_new_31(struct fuse_args *args,
4142  		      const struct fuse_operations *op,
4143  		      size_t op_size, void *user_data)
4144  {
4145  	struct fuse *f;
4146  	struct node *root;
4147  	struct fuse_fs *fs;
4148  	struct fuse_lowlevel_ops llop = fuse_path_ops;
4149  	f = (struct fuse *) calloc(1, sizeof(struct fuse));
4150  	if (f == NULL) {
4151  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate fuse object\n");
4152  		goto out;
4153  	}
4154  	f->conf.entry_timeout = 1.0;
4155  	f->conf.attr_timeout = 1.0;
4156  	f->conf.negative_timeout = 0.0;
4157  	f->conf.intr_signal = FUSE_DEFAULT_INTR_SIGNAL;
4158  	if (fuse_opt_parse(args, &f->conf, fuse_lib_opts,
4159  			   fuse_lib_opt_proc) == -1)
4160  		goto out_free;
4161  	pthread_mutex_lock(&fuse_context_lock);
4162  	static int builtin_modules_registered = 0;
4163  	if (builtin_modules_registered == 0) {
4164  		fuse_register_module("subdir", fuse_module_subdir_factory, NULL);
4165  #ifdef HAVE_ICONV
4166  		fuse_register_module("iconv", fuse_module_iconv_factory, NULL);
4167  #endif
4168  		builtin_modules_registered= 1;
4169  	}
4170  	pthread_mutex_unlock(&fuse_context_lock);
4171  	if (fuse_create_context_key() == -1)
4172  		goto out_free;
4173  	fs = fuse_fs_new(op, op_size, user_data);
4174  	if (!fs)
4175  		goto out_delete_context_key;
4176  	f->fs = fs;
4177  	if (!fs->op.lock) {
4178  		llop.getlk = NULL;
4179  		llop.setlk = NULL;
4180  	}
4181  	f->pagesize = getpagesize();
4182  	init_list_head(&f->partial_slabs);
4183  	init_list_head(&f->full_slabs);
4184  	init_list_head(&f->lru_table);
4185  	if (f->conf.modules) {
4186  		char *module;
4187  		char *next;
4188  		for (module = f->conf.modules; module; module = next) {
4189  			char *p;
4190  			for (p = module; *p && *p != ':'; p++);
4191  			next = *p ? p + 1 : NULL;
4192  			*p = '\0';
4193  			if (module[0] &&
4194  			    fuse_push_module(f, module, args) == -1)
4195  				goto out_free_fs;
4196  		}
4197  	}
4198  	if (!f->conf.ac_attr_timeout_set)
4199  		f->conf.ac_attr_timeout = f->conf.attr_timeout;
4200  #if defined(__FreeBSD__) || defined(__NetBSD__)
4201  	f->conf.readdir_ino = 1;
4202  #endif
4203  	f->se = fuse_session_new(args, &llop, sizeof(llop), f);
4204  	if (f->se == NULL)
4205  		goto out_free_fs;
4206  	if (f->conf.debug) {
4207  		fuse_log(FUSE_LOG_DEBUG, "nullpath_ok: %i\n", f->conf.nullpath_ok);
4208  	}
4209  	f->fs->debug = f->conf.debug;
4210  	f->ctr = 0;
4211  	f->generation = 0;
4212  	if (node_table_init(&f->name_table) == -1)
4213  		goto out_free_session;
4214  	if (node_table_init(&f->id_table) == -1)
4215  		goto out_free_name_table;
4216  	pthread_mutex_init(&f->lock, NULL);
4217  	root = alloc_node(f);
4218  	if (root == NULL) {
4219  		fuse_log(FUSE_LOG_ERR, "fuse: memory allocation failed\n");
4220  		goto out_free_id_table;
4221  	}
4222  	if (lru_enabled(f)) {
4223  		struct node_lru *lnode = node_lru(root);
4224  		init_list_head(&lnode->lru);
4225  	}
4226  	strcpy(root->inline_name, "/");
4227  	root->name = root->inline_name;
4228  	if (f->conf.intr &&
4229  	    fuse_init_intr_signal(f->conf.intr_signal,
4230  				  &f->intr_installed) == -1)
4231  		goto out_free_root;
4232  	root->parent = NULL;
4233  	root->nodeid = FUSE_ROOT_ID;
4234  	inc_nlookup(root);
4235  	hash_id(f, root);
4236  	return f;
4237  out_free_root:
4238  	free(root);
4239  out_free_id_table:
4240  	free(f->id_table.array);
4241  out_free_name_table:
4242  	free(f->name_table.array);
4243  out_free_session:
4244  	fuse_session_destroy(f->se);
4245  out_free_fs:
4246  	free(f->fs);
4247  	free(f->conf.modules);
4248  out_delete_context_key:
4249  	fuse_delete_context_key();
4250  out_free:
4251  	free(f);
4252  out:
4253  	return NULL;
4254  }
4255  struct fuse *fuse_new_30(struct fuse_args *args, const struct fuse_operations *op,
4256  			 size_t op_size, void *private_data);
4257  FUSE_SYMVER("fuse_new_30", "fuse_new@FUSE_3.0")
4258  struct fuse *fuse_new_30(struct fuse_args *args,
4259  			 const struct fuse_operations *op,
4260  			 size_t op_size, void *user_data)
4261  {
4262  	struct fuse_config conf;
4263  	memset(&conf, 0, sizeof(conf));
4264  	const struct fuse_opt opts[] = {
4265  		FUSE_LIB_OPT("-h", show_help, 1),
4266  		FUSE_LIB_OPT("--help", show_help, 1),
4267  		FUSE_OPT_END
4268  	};
4269  	if (fuse_opt_parse(args, &conf, opts,
4270  			   fuse_lib_opt_proc) == -1)
4271  		return NULL;
4272  	if (conf.show_help) {
4273  		fuse_lib_help(args);
4274  		return NULL;
4275  	} else
4276  		return fuse_new_31(args, op, op_size, user_data);
4277  }
4278  void fuse_destroy(struct fuse *f)
4279  {
4280  	size_t i;
4281  	if (f->conf.intr && f->intr_installed)
4282  		fuse_restore_intr_signal(f->conf.intr_signal);
4283  	if (f->fs) {
4284  		fuse_create_context(f);
4285  		for (i = 0; i < f->id_table.size; i++) {
4286  			struct node *node;
4287  			for (node = f->id_table.array[i]; node != NULL;
4288  			     node = node->id_next) {
4289  				if (node->is_hidden) {
4290  					char *path;
4291  					if (try_get_path(f, node->nodeid, NULL, &path, NULL, false) == 0) {
4292  						fuse_fs_unlink(f->fs, path);
4293  						free(path);
4294  					}
4295  				}
4296  			}
4297  		}
4298  	}
4299  	for (i = 0; i < f->id_table.size; i++) {
4300  		struct node *node;
4301  		struct node *next;
4302  		for (node = f->id_table.array[i]; node != NULL; node = next) {
4303  			next = node->id_next;
4304  			free_node(f, node);
4305  			f->id_table.use--;
4306  		}
4307  	}
4308  	assert(list_empty(&f->partial_slabs));
4309  	assert(list_empty(&f->full_slabs));
4310  	while (fuse_modules) {
4311  		fuse_put_module(fuse_modules);
4312  	}
4313  	free(f->id_table.array);
4314  	free(f->name_table.array);
4315  	pthread_mutex_destroy(&f->lock);
4316  	fuse_session_destroy(f->se);
4317  	free(f->fs);
4318  	free(f->conf.modules);
4319  	free(f);
4320  	fuse_delete_context_key();
4321  }
4322  int fuse_mount(struct fuse *f, const char *mountpoint) {
4323  	return fuse_session_mount(fuse_get_session(f), mountpoint);
4324  }
4325  void fuse_unmount(struct fuse *f) {
4326  	fuse_session_unmount(fuse_get_session(f));
4327  }
4328  int fuse_version(void)
4329  {
4330  	return FUSE_VERSION;
4331  }
4332  const char *fuse_pkgversion(void)
4333  {
4334  	return PACKAGE_VERSION;
4335  }
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-backward_references_enc.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from libfuse-MDEwOlJlcG9zaXRvcnk0ODI5NjE3Nw==-flat-fuse.c</div>
                </div>
                <div class="column column_space"><pre><code>175    assert(p->size_ != 0);
176    assert(p->offset_length_ != NULL);
177    if (size <= 2) {
</pre></code></div>
                <div class="column column_space"><pre><code>822  		assert(node->treelock != 0);
823  		assert(node->treelock != TREELOCK_WAIT_OFFSET);
824  		assert(node->treelock != TREELOCK_WRITE);
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    