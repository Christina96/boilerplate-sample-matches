
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 65, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-rtree.h</h3>
            <pre><code>1  #ifndef JEMALLOC_INTERNAL_RTREE_H
2  #define JEMALLOC_INTERNAL_RTREE_H
3  #include "jemalloc/internal/atomic.h"
4  #include "jemalloc/internal/mutex.h"
5  #include "jemalloc/internal/rtree_tsd.h"
6  #include "jemalloc/internal/sc.h"
7  #include "jemalloc/internal/tsd.h"
8  #define RTREE_NHIB ((1U << (LG_SIZEOF_PTR+3)) - LG_VADDR)
9  #define RTREE_NLIB LG_PAGE
10  #define RTREE_NSB (LG_VADDR - RTREE_NLIB)
11  #if RTREE_NSB <= 10
12  #  define RTREE_HEIGHT 1
13  #elif RTREE_NSB <= 36
14  #  define RTREE_HEIGHT 2
15  #elif RTREE_NSB <= 52
16  #  define RTREE_HEIGHT 3
17  #else
18  #  error Unsupported number of significant virtual address bits
19  #endif
20  #if RTREE_NHIB >= LG_CEIL(SC_NSIZES)
21  #  define RTREE_LEAF_COMPACT
22  #endif
23  #define RTREE_LEAFKEY_INVALID ((uintptr_t)1)
24  typedef struct rtree_node_elm_s rtree_node_elm_t;
25  struct rtree_node_elm_s {
26  	atomic_p_t	child; &bsol;* (rtree_{node,leaf}_elm_t *) */
27  };
28  struct rtree_leaf_elm_s {
29  #ifdef RTREE_LEAF_COMPACT
30  	atomic_p_t	le_bits;
31  #else
32  	atomic_p_t	le_extent; &bsol;* (extent_t *) */
33  	atomic_u_t	le_szind; &bsol;* (szind_t) */
34  	atomic_b_t	le_slab; &bsol;* (bool) */
35  #endif
36  };
37  typedef struct rtree_level_s rtree_level_t;
38  struct rtree_level_s {
39  	unsigned		bits;
40  	unsigned		cumbits;
41  };
42  typedef struct rtree_s rtree_t;
43  struct rtree_s {
44  	malloc_mutex_t		init_lock;
45  #if RTREE_HEIGHT > 1
46  	rtree_node_elm_t	root[1U << (RTREE_NSB/RTREE_HEIGHT)];
47  #else
48  	rtree_leaf_elm_t	root[1U << (RTREE_NSB/RTREE_HEIGHT)];
49  #endif
50  };
51  static const rtree_level_t rtree_levels[] = {
52  #if RTREE_HEIGHT == 1
53  	{RTREE_NSB, RTREE_NHIB + RTREE_NSB}
54  #elif RTREE_HEIGHT == 2
55  	{RTREE_NSB/2, RTREE_NHIB + RTREE_NSB/2},
56  	{RTREE_NSB/2 + RTREE_NSB%2, RTREE_NHIB + RTREE_NSB}
57  #elif RTREE_HEIGHT == 3
58  	{RTREE_NSB/3, RTREE_NHIB + RTREE_NSB/3},
59  	{RTREE_NSB/3 + RTREE_NSB%3/2,
60  	    RTREE_NHIB + RTREE_NSB/3*2 + RTREE_NSB%3/2},
61  	{RTREE_NSB/3 + RTREE_NSB%3 - RTREE_NSB%3/2, RTREE_NHIB + RTREE_NSB}
62  #else
63  #  error Unsupported rtree height
64  #endif
65  };
66  bool rtree_new(rtree_t *rtree, bool zeroed);
67  typedef rtree_node_elm_t *(rtree_node_alloc_t)(tsdn_t *, rtree_t *, size_t);
68  extern rtree_node_alloc_t *JET_MUTABLE rtree_node_alloc;
69  typedef rtree_leaf_elm_t *(rtree_leaf_alloc_t)(tsdn_t *, rtree_t *, size_t);
70  extern rtree_leaf_alloc_t *JET_MUTABLE rtree_leaf_alloc;
71  typedef void (rtree_node_dalloc_t)(tsdn_t *, rtree_t *, rtree_node_elm_t *);
72  extern rtree_node_dalloc_t *JET_MUTABLE rtree_node_dalloc;
73  typedef void (rtree_leaf_dalloc_t)(tsdn_t *, rtree_t *, rtree_leaf_elm_t *);
74  extern rtree_leaf_dalloc_t *JET_MUTABLE rtree_leaf_dalloc;
75  #ifdef JEMALLOC_JET
76  void rtree_delete(tsdn_t *tsdn, rtree_t *rtree);
77  #endif
78  rtree_leaf_elm_t *rtree_leaf_elm_lookup_hard(tsdn_t *tsdn, rtree_t *rtree,
79      rtree_ctx_t *rtree_ctx, uintptr_t key, bool dependent, bool init_missing);
80  JEMALLOC_ALWAYS_INLINE uintptr_t
81  rtree_leafkey(uintptr_t key) {
82  	unsigned ptrbits = ZU(1) << (LG_SIZEOF_PTR+3);
83  	unsigned cumbits = (rtree_levels[RTREE_HEIGHT-1].cumbits -
84  	    rtree_levels[RTREE_HEIGHT-1].bits);
85  	unsigned maskbits = ptrbits - cumbits;
86  	uintptr_t mask = ~((ZU(1) << maskbits) - 1);
87  	return (key & mask);
88  }
89  JEMALLOC_ALWAYS_INLINE size_t
90  rtree_cache_direct_map(uintptr_t key) {
91  	unsigned ptrbits = ZU(1) << (LG_SIZEOF_PTR+3);
92  	unsigned cumbits = (rtree_levels[RTREE_HEIGHT-1].cumbits -
93  	    rtree_levels[RTREE_HEIGHT-1].bits);
94  	unsigned maskbits = ptrbits - cumbits;
95  	return (size_t)((key >> maskbits) & (RTREE_CTX_NCACHE - 1));
96  }
97  JEMALLOC_ALWAYS_INLINE uintptr_t
98  rtree_subkey(uintptr_t key, unsigned level) {
99  	unsigned ptrbits = ZU(1) << (LG_SIZEOF_PTR+3);
100  	unsigned cumbits = rtree_levels[level].cumbits;
101  	unsigned shiftbits = ptrbits - cumbits;
102  	unsigned maskbits = rtree_levels[level].bits;
103  	uintptr_t mask = (ZU(1) << maskbits) - 1;
104  	return ((key >> shiftbits) & mask);
105  }
106  #  ifdef RTREE_LEAF_COMPACT
107  JEMALLOC_ALWAYS_INLINE uintptr_t
108  rtree_leaf_elm_bits_read(tsdn_t *tsdn, rtree_t *rtree,
109      rtree_leaf_elm_t *elm, bool dependent) {
110  	return (uintptr_t)atomic_load_p(&elm->le_bits, dependent
111  	    ? ATOMIC_RELAXED : ATOMIC_ACQUIRE);
112  }
113  JEMALLOC_ALWAYS_INLINE extent_t *
114  rtree_leaf_elm_bits_extent_get(uintptr_t bits) {
115  #    ifdef __aarch64__
116  	uintptr_t high_bit_mask = ((uintptr_t)1 << LG_VADDR) - 1;
117  	uintptr_t low_bit_mask = ~(uintptr_t)1;
118  	uintptr_t mask = high_bit_mask & low_bit_mask;
119  	return (extent_t *)(bits & mask);
120  #    else
121  	return (extent_t *)((uintptr_t)((intptr_t)(bits << RTREE_NHIB) >>
122  	    RTREE_NHIB) & ~((uintptr_t)0x1));
123  #    endif
124  }
125  JEMALLOC_ALWAYS_INLINE szind_t
126  rtree_leaf_elm_bits_szind_get(uintptr_t bits) {
127  	return (szind_t)(bits >> LG_VADDR);
128  }
129  JEMALLOC_ALWAYS_INLINE bool
130  rtree_leaf_elm_bits_slab_get(uintptr_t bits) {
131  	return (bool)(bits & (uintptr_t)0x1);
132  }
133  #  endif
134  JEMALLOC_ALWAYS_INLINE extent_t *
135  rtree_leaf_elm_extent_read(tsdn_t *tsdn, rtree_t *rtree,
136      rtree_leaf_elm_t *elm, bool dependent) {
137  #ifdef RTREE_LEAF_COMPACT
138  	uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, dependent);
139  	return rtree_leaf_elm_bits_extent_get(bits);
140  #else
141  	extent_t *extent = (extent_t *)atomic_load_p(&elm->le_extent, dependent
142  	    ? ATOMIC_RELAXED : ATOMIC_ACQUIRE);
143  	return extent;
144  #endif
145  }
146  JEMALLOC_ALWAYS_INLINE szind_t
147  rtree_leaf_elm_szind_read(tsdn_t *tsdn, rtree_t *rtree,
148      rtree_leaf_elm_t *elm, bool dependent) {
149  #ifdef RTREE_LEAF_COMPACT
150  	uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, dependent);
151  	return rtree_leaf_elm_bits_szind_get(bits);
152  #else
153  	return (szind_t)atomic_load_u(&elm->le_szind, dependent ? ATOMIC_RELAXED
154  	    : ATOMIC_ACQUIRE);
155  #endif
156  }
157  JEMALLOC_ALWAYS_INLINE bool
158  rtree_leaf_elm_slab_read(tsdn_t *tsdn, rtree_t *rtree,
159      rtree_leaf_elm_t *elm, bool dependent) {
160  #ifdef RTREE_LEAF_COMPACT
161  	uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, dependent);
162  	return rtree_leaf_elm_bits_slab_get(bits);
163  #else
164  	return atomic_load_b(&elm->le_slab, dependent ? ATOMIC_RELAXED :
165  	    ATOMIC_ACQUIRE);
166  #endif
167  }
168  static inline void
169  rtree_leaf_elm_extent_write(tsdn_t *tsdn, rtree_t *rtree,
170      rtree_leaf_elm_t *elm, extent_t *extent) {
171  #ifdef RTREE_LEAF_COMPACT
172  	uintptr_t old_bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, true);
173  	uintptr_t bits = ((uintptr_t)rtree_leaf_elm_bits_szind_get(old_bits) <<
174  	    LG_VADDR) | ((uintptr_t)extent & (((uintptr_t)0x1 << LG_VADDR) - 1))
175  	    | ((uintptr_t)rtree_leaf_elm_bits_slab_get(old_bits));
176  	atomic_store_p(&elm->le_bits, (void *)bits, ATOMIC_RELEASE);
177  #else
178  	atomic_store_p(&elm->le_extent, extent, ATOMIC_RELEASE);
179  #endif
180  }
181  static inline void
182  rtree_leaf_elm_szind_write(tsdn_t *tsdn, rtree_t *rtree,
183      rtree_leaf_elm_t *elm, szind_t szind) {
184  	assert(szind <= SC_NSIZES);
185  #ifdef RTREE_LEAF_COMPACT
186  	uintptr_t old_bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm,
187  	    true);
188  	uintptr_t bits = ((uintptr_t)szind << LG_VADDR) |
189  	    ((uintptr_t)rtree_leaf_elm_bits_extent_get(old_bits) &
190  	    (((uintptr_t)0x1 << LG_VADDR) - 1)) |
191  	    ((uintptr_t)rtree_leaf_elm_bits_slab_get(old_bits));
192  	atomic_store_p(&elm->le_bits, (void *)bits, ATOMIC_RELEASE);
193  #else
194  	atomic_store_u(&elm->le_szind, szind, ATOMIC_RELEASE);
195  #endif
196  }
197  static inline void
198  rtree_leaf_elm_slab_write(tsdn_t *tsdn, rtree_t *rtree,
199      rtree_leaf_elm_t *elm, bool slab) {
200  #ifdef RTREE_LEAF_COMPACT
201  	uintptr_t old_bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm,
202  	    true);
203  	uintptr_t bits = ((uintptr_t)rtree_leaf_elm_bits_szind_get(old_bits) <<
204  	    LG_VADDR) | ((uintptr_t)rtree_leaf_elm_bits_extent_get(old_bits) &
205  	    (((uintptr_t)0x1 << LG_VADDR) - 1)) | ((uintptr_t)slab);
206  	atomic_store_p(&elm->le_bits, (void *)bits, ATOMIC_RELEASE);
207  #else
208  	atomic_store_b(&elm->le_slab, slab, ATOMIC_RELEASE);
209  #endif
210  }
211  static inline void
212  rtree_leaf_elm_write(tsdn_t *tsdn, rtree_t *rtree,
213      rtree_leaf_elm_t *elm, extent_t *extent, szind_t szind, bool slab) {
214  #ifdef RTREE_LEAF_COMPACT
215  	uintptr_t bits = ((uintptr_t)szind << LG_VADDR) |
216  	    ((uintptr_t)extent & (((uintptr_t)0x1 << LG_VADDR) - 1)) |
217  	    ((uintptr_t)slab);
218  	atomic_store_p(&elm->le_bits, (void *)bits, ATOMIC_RELEASE);
219  #else
220  	rtree_leaf_elm_slab_write(tsdn, rtree, elm, slab);
221  	rtree_leaf_elm_szind_write(tsdn, rtree, elm, szind);
222  	rtree_leaf_elm_extent_write(tsdn, rtree, elm, extent);
223  #endif
224  }
225  static inline void
226  rtree_leaf_elm_szind_slab_update(tsdn_t *tsdn, rtree_t *rtree,
227      rtree_leaf_elm_t *elm, szind_t szind, bool slab) {
228  	assert(!slab || szind < SC_NBINS);
229  	rtree_leaf_elm_slab_write(tsdn, rtree, elm, slab);
230  	rtree_leaf_elm_szind_write(tsdn, rtree, elm, szind);
231  }
232  JEMALLOC_ALWAYS_INLINE rtree_leaf_elm_t *
233  rtree_leaf_elm_lookup(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
234      uintptr_t key, bool dependent, bool init_missing) {
235  	assert(key != 0);
236  	assert(!dependent || !init_missing);
237  	size_t slot = rtree_cache_direct_map(key);
238  	uintptr_t leafkey = rtree_leafkey(key);
239  	assert(leafkey != RTREE_LEAFKEY_INVALID);
240  	if (likely(rtree_ctx->cache[slot].leafkey == leafkey)) {
241  		rtree_leaf_elm_t *leaf = rtree_ctx->cache[slot].leaf;
242  		assert(leaf != NULL);
243  		uintptr_t subkey = rtree_subkey(key, RTREE_HEIGHT-1);
244  		return &leaf[subkey];
245  	}
246  #define RTREE_CACHE_CHECK_L2(i) do {					\
247  	if (likely(rtree_ctx->l2_cache[i].leafkey == leafkey)) {	\
248  		rtree_leaf_elm_t *leaf = rtree_ctx->l2_cache[i].leaf;	\
249  		assert(leaf != NULL);					\
250  		if (i > 0) {						\
251  							\
252  			rtree_ctx->l2_cache[i].leafkey =		\
253  				rtree_ctx->l2_cache[i - 1].leafkey;	\
254  			rtree_ctx->l2_cache[i].leaf =			\
255  				rtree_ctx->l2_cache[i - 1].leaf;	\
256  			rtree_ctx->l2_cache[i - 1].leafkey =		\
257  			    rtree_ctx->cache[slot].leafkey;		\
258  			rtree_ctx->l2_cache[i - 1].leaf =		\
259  			    rtree_ctx->cache[slot].leaf;		\
260  		} else {						\
261  			rtree_ctx->l2_cache[0].leafkey =		\
262  			    rtree_ctx->cache[slot].leafkey;		\
263  			rtree_ctx->l2_cache[0].leaf =			\
264  			    rtree_ctx->cache[slot].leaf;		\
265  		}							\
266  		rtree_ctx->cache[slot].leafkey = leafkey;		\
267  		rtree_ctx->cache[slot].leaf = leaf;			\
268  		uintptr_t subkey = rtree_subkey(key, RTREE_HEIGHT-1);	\
269  		return &leaf[subkey];					\
270  	}								\
271  } while (0)
272  	RTREE_CACHE_CHECK_L2(0);
273  	for (unsigned i = 1; i < RTREE_CTX_NCACHE_L2; i++) {
274  		RTREE_CACHE_CHECK_L2(i);
275  	}
276  #undef RTREE_CACHE_CHECK_L2
277  	return rtree_leaf_elm_lookup_hard(tsdn, rtree, rtree_ctx, key,
278  	    dependent, init_missing);
279  }
280  static inline bool
281  rtree_write(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx, uintptr_t key,
282      extent_t *extent, szind_t szind, bool slab) {
283  	assert(extent != NULL);
284  	rtree_leaf_elm_t *elm = rtree_leaf_elm_lookup(tsdn, rtree, rtree_ctx,
285  	    key, false, true);
286  	if (elm == NULL) {
287  		return true;
288  	}
289  	assert(rtree_leaf_elm_extent_read(tsdn, rtree, elm, false) == NULL);
290  	rtree_leaf_elm_write(tsdn, rtree, elm, extent, szind, slab);
291  	return false;
292  }
293  JEMALLOC_ALWAYS_INLINE rtree_leaf_elm_t *
294  rtree_read(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx, uintptr_t key,
295      bool dependent) {
296  	rtree_leaf_elm_t *elm = rtree_leaf_elm_lookup(tsdn, rtree, rtree_ctx,
297  	    key, dependent, false);
298  	if (!dependent && elm == NULL) {
299  		return NULL;
300  	}
301  	assert(elm != NULL);
302  	return elm;
303  }
304  JEMALLOC_ALWAYS_INLINE extent_t *
305  rtree_extent_read(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
306      uintptr_t key, bool dependent) {
307  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key,
308  	    dependent);
309  	if (!dependent && elm == NULL) {
310  		return NULL;
311  	}
312  	return rtree_leaf_elm_extent_read(tsdn, rtree, elm, dependent);
313  }
314  JEMALLOC_ALWAYS_INLINE szind_t
315  rtree_szind_read(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
316      uintptr_t key, bool dependent) {
317  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key,
318  	    dependent);
319  	if (!dependent && elm == NULL) {
320  		return SC_NSIZES;
321  	}
322  	return rtree_leaf_elm_szind_read(tsdn, rtree, elm, dependent);
323  }
324  JEMALLOC_ALWAYS_INLINE bool
325  rtree_extent_szind_read(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
326      uintptr_t key, bool dependent, extent_t **r_extent, szind_t *r_szind) {
327  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key,
328  	    dependent);
329  	if (!dependent && elm == NULL) {
330  		return true;
331  	}
332  	*r_extent = rtree_leaf_elm_extent_read(tsdn, rtree, elm, dependent);
333  	*r_szind = rtree_leaf_elm_szind_read(tsdn, rtree, elm, dependent);
334  	return false;
335  }
336  JEMALLOC_ALWAYS_INLINE bool
337  rtree_szind_slab_read_fast(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
338  			    uintptr_t key, szind_t *r_szind, bool *r_slab) {
339  	rtree_leaf_elm_t *elm;
340  	size_t slot = rtree_cache_direct_map(key);
341  	uintptr_t leafkey = rtree_leafkey(key);
342  	assert(leafkey != RTREE_LEAFKEY_INVALID);
343  	if (likely(rtree_ctx->cache[slot].leafkey == leafkey)) {
344  		rtree_leaf_elm_t *leaf = rtree_ctx->cache[slot].leaf;
345  		assert(leaf != NULL);
346  		uintptr_t subkey = rtree_subkey(key, RTREE_HEIGHT-1);
347  		elm = &leaf[subkey];
348  #ifdef RTREE_LEAF_COMPACT
349  		uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree,
350  							  elm, true);
351  		*r_szind = rtree_leaf_elm_bits_szind_get(bits);
352  		*r_slab = rtree_leaf_elm_bits_slab_get(bits);
353  #else
354  		*r_szind = rtree_leaf_elm_szind_read(tsdn, rtree, elm, true);
355  		*r_slab = rtree_leaf_elm_slab_read(tsdn, rtree, elm, true);
356  #endif
357  		return true;
358  	} else {
359  		return false;
360  	}
361  }
362  JEMALLOC_ALWAYS_INLINE bool
363  rtree_szind_slab_read(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
364      uintptr_t key, bool dependent, szind_t *r_szind, bool *r_slab) {
365  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key,
366  	    dependent);
367  	if (!dependent && elm == NULL) {
368  		return true;
369  	}
370  #ifdef RTREE_LEAF_COMPACT
<span onclick='openModal()' class='match'>371  	uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, dependent);
372  	*r_szind = rtree_leaf_elm_bits_szind_get(bits);
373  	*r_slab = rtree_leaf_elm_bits_slab_get(bits);
374  #else
375  	*r_szind = rtree_leaf_elm_szind_read(tsdn, rtree, elm, dependent);
376  	*r_slab = rtree_leaf_elm_slab_read(tsdn, rtree, elm, dependent);
377  #endif
378  	return false;
379  }
380  static inline void
</span>381  rtree_szind_slab_update(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
382      uintptr_t key, szind_t szind, bool slab) {
383  	assert(!slab || szind < SC_NBINS);
384  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key, true);
385  	rtree_leaf_elm_szind_slab_update(tsdn, rtree, elm, szind, slab);
386  }
387  static inline void
388  rtree_clear(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
389      uintptr_t key) {
390  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key, true);
391  	assert(rtree_leaf_elm_extent_read(tsdn, rtree, elm, false) !=
392  	    NULL);
393  	rtree_leaf_elm_write(tsdn, rtree, elm, NULL, SC_NSIZES, false);
394  }
395  #endif &bsol;* JEMALLOC_INTERNAL_RTREE_H */
</code></pre>
        </div>
        <div class="column">
            <h3>redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-rtree.h</h3>
            <pre><code>1  #ifndef JEMALLOC_INTERNAL_RTREE_H
2  #define JEMALLOC_INTERNAL_RTREE_H
3  #include "jemalloc/internal/atomic.h"
4  #include "jemalloc/internal/mutex.h"
5  #include "jemalloc/internal/rtree_tsd.h"
6  #include "jemalloc/internal/sc.h"
7  #include "jemalloc/internal/tsd.h"
8  #define RTREE_NHIB ((1U << (LG_SIZEOF_PTR+3)) - LG_VADDR)
9  #define RTREE_NLIB LG_PAGE
10  #define RTREE_NSB (LG_VADDR - RTREE_NLIB)
11  #if RTREE_NSB <= 10
12  #  define RTREE_HEIGHT 1
13  #elif RTREE_NSB <= 36
14  #  define RTREE_HEIGHT 2
15  #elif RTREE_NSB <= 52
16  #  define RTREE_HEIGHT 3
17  #else
18  #  error Unsupported number of significant virtual address bits
19  #endif
20  #if RTREE_NHIB >= LG_CEIL(SC_NSIZES)
21  #  define RTREE_LEAF_COMPACT
22  #endif
23  #define RTREE_LEAFKEY_INVALID ((uintptr_t)1)
24  typedef struct rtree_node_elm_s rtree_node_elm_t;
25  struct rtree_node_elm_s {
26  	atomic_p_t	child; &bsol;* (rtree_{node,leaf}_elm_t *) */
27  };
28  struct rtree_leaf_elm_s {
29  #ifdef RTREE_LEAF_COMPACT
30  	atomic_p_t	le_bits;
31  #else
32  	atomic_p_t	le_extent; &bsol;* (extent_t *) */
33  	atomic_u_t	le_szind; &bsol;* (szind_t) */
34  	atomic_b_t	le_slab; &bsol;* (bool) */
35  #endif
36  };
37  typedef struct rtree_level_s rtree_level_t;
38  struct rtree_level_s {
39  	unsigned		bits;
40  	unsigned		cumbits;
41  };
42  typedef struct rtree_s rtree_t;
43  struct rtree_s {
44  	malloc_mutex_t		init_lock;
45  #if RTREE_HEIGHT > 1
46  	rtree_node_elm_t	root[1U << (RTREE_NSB/RTREE_HEIGHT)];
47  #else
48  	rtree_leaf_elm_t	root[1U << (RTREE_NSB/RTREE_HEIGHT)];
49  #endif
50  };
51  static const rtree_level_t rtree_levels[] = {
52  #if RTREE_HEIGHT == 1
53  	{RTREE_NSB, RTREE_NHIB + RTREE_NSB}
54  #elif RTREE_HEIGHT == 2
55  	{RTREE_NSB/2, RTREE_NHIB + RTREE_NSB/2},
56  	{RTREE_NSB/2 + RTREE_NSB%2, RTREE_NHIB + RTREE_NSB}
57  #elif RTREE_HEIGHT == 3
58  	{RTREE_NSB/3, RTREE_NHIB + RTREE_NSB/3},
59  	{RTREE_NSB/3 + RTREE_NSB%3/2,
60  	    RTREE_NHIB + RTREE_NSB/3*2 + RTREE_NSB%3/2},
61  	{RTREE_NSB/3 + RTREE_NSB%3 - RTREE_NSB%3/2, RTREE_NHIB + RTREE_NSB}
62  #else
63  #  error Unsupported rtree height
64  #endif
65  };
66  bool rtree_new(rtree_t *rtree, bool zeroed);
67  typedef rtree_node_elm_t *(rtree_node_alloc_t)(tsdn_t *, rtree_t *, size_t);
68  extern rtree_node_alloc_t *JET_MUTABLE rtree_node_alloc;
69  typedef rtree_leaf_elm_t *(rtree_leaf_alloc_t)(tsdn_t *, rtree_t *, size_t);
70  extern rtree_leaf_alloc_t *JET_MUTABLE rtree_leaf_alloc;
71  typedef void (rtree_node_dalloc_t)(tsdn_t *, rtree_t *, rtree_node_elm_t *);
72  extern rtree_node_dalloc_t *JET_MUTABLE rtree_node_dalloc;
73  typedef void (rtree_leaf_dalloc_t)(tsdn_t *, rtree_t *, rtree_leaf_elm_t *);
74  extern rtree_leaf_dalloc_t *JET_MUTABLE rtree_leaf_dalloc;
75  #ifdef JEMALLOC_JET
76  void rtree_delete(tsdn_t *tsdn, rtree_t *rtree);
77  #endif
78  rtree_leaf_elm_t *rtree_leaf_elm_lookup_hard(tsdn_t *tsdn, rtree_t *rtree,
79      rtree_ctx_t *rtree_ctx, uintptr_t key, bool dependent, bool init_missing);
80  JEMALLOC_ALWAYS_INLINE uintptr_t
81  rtree_leafkey(uintptr_t key) {
82  	unsigned ptrbits = ZU(1) << (LG_SIZEOF_PTR+3);
83  	unsigned cumbits = (rtree_levels[RTREE_HEIGHT-1].cumbits -
84  	    rtree_levels[RTREE_HEIGHT-1].bits);
85  	unsigned maskbits = ptrbits - cumbits;
86  	uintptr_t mask = ~((ZU(1) << maskbits) - 1);
87  	return (key & mask);
88  }
89  JEMALLOC_ALWAYS_INLINE size_t
90  rtree_cache_direct_map(uintptr_t key) {
91  	unsigned ptrbits = ZU(1) << (LG_SIZEOF_PTR+3);
92  	unsigned cumbits = (rtree_levels[RTREE_HEIGHT-1].cumbits -
93  	    rtree_levels[RTREE_HEIGHT-1].bits);
94  	unsigned maskbits = ptrbits - cumbits;
95  	return (size_t)((key >> maskbits) & (RTREE_CTX_NCACHE - 1));
96  }
97  JEMALLOC_ALWAYS_INLINE uintptr_t
98  rtree_subkey(uintptr_t key, unsigned level) {
99  	unsigned ptrbits = ZU(1) << (LG_SIZEOF_PTR+3);
100  	unsigned cumbits = rtree_levels[level].cumbits;
101  	unsigned shiftbits = ptrbits - cumbits;
102  	unsigned maskbits = rtree_levels[level].bits;
103  	uintptr_t mask = (ZU(1) << maskbits) - 1;
104  	return ((key >> shiftbits) & mask);
105  }
106  #  ifdef RTREE_LEAF_COMPACT
107  JEMALLOC_ALWAYS_INLINE uintptr_t
108  rtree_leaf_elm_bits_read(tsdn_t *tsdn, rtree_t *rtree,
109      rtree_leaf_elm_t *elm, bool dependent) {
110  	return (uintptr_t)atomic_load_p(&elm->le_bits, dependent
111  	    ? ATOMIC_RELAXED : ATOMIC_ACQUIRE);
112  }
113  JEMALLOC_ALWAYS_INLINE extent_t *
114  rtree_leaf_elm_bits_extent_get(uintptr_t bits) {
115  #    ifdef __aarch64__
116  	uintptr_t high_bit_mask = ((uintptr_t)1 << LG_VADDR) - 1;
117  	uintptr_t low_bit_mask = ~(uintptr_t)1;
118  	uintptr_t mask = high_bit_mask & low_bit_mask;
119  	return (extent_t *)(bits & mask);
120  #    else
121  	return (extent_t *)((uintptr_t)((intptr_t)(bits << RTREE_NHIB) >>
122  	    RTREE_NHIB) & ~((uintptr_t)0x1));
123  #    endif
124  }
125  JEMALLOC_ALWAYS_INLINE szind_t
126  rtree_leaf_elm_bits_szind_get(uintptr_t bits) {
127  	return (szind_t)(bits >> LG_VADDR);
128  }
129  JEMALLOC_ALWAYS_INLINE bool
130  rtree_leaf_elm_bits_slab_get(uintptr_t bits) {
131  	return (bool)(bits & (uintptr_t)0x1);
132  }
133  #  endif
134  JEMALLOC_ALWAYS_INLINE extent_t *
135  rtree_leaf_elm_extent_read(tsdn_t *tsdn, rtree_t *rtree,
136      rtree_leaf_elm_t *elm, bool dependent) {
137  #ifdef RTREE_LEAF_COMPACT
138  	uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, dependent);
139  	return rtree_leaf_elm_bits_extent_get(bits);
140  #else
141  	extent_t *extent = (extent_t *)atomic_load_p(&elm->le_extent, dependent
142  	    ? ATOMIC_RELAXED : ATOMIC_ACQUIRE);
143  	return extent;
144  #endif
145  }
146  JEMALLOC_ALWAYS_INLINE szind_t
147  rtree_leaf_elm_szind_read(tsdn_t *tsdn, rtree_t *rtree,
148      rtree_leaf_elm_t *elm, bool dependent) {
149  #ifdef RTREE_LEAF_COMPACT
150  	uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, dependent);
151  	return rtree_leaf_elm_bits_szind_get(bits);
152  #else
153  	return (szind_t)atomic_load_u(&elm->le_szind, dependent ? ATOMIC_RELAXED
154  	    : ATOMIC_ACQUIRE);
155  #endif
156  }
157  JEMALLOC_ALWAYS_INLINE bool
158  rtree_leaf_elm_slab_read(tsdn_t *tsdn, rtree_t *rtree,
159      rtree_leaf_elm_t *elm, bool dependent) {
160  #ifdef RTREE_LEAF_COMPACT
161  	uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, dependent);
162  	return rtree_leaf_elm_bits_slab_get(bits);
163  #else
164  	return atomic_load_b(&elm->le_slab, dependent ? ATOMIC_RELAXED :
165  	    ATOMIC_ACQUIRE);
166  #endif
167  }
168  static inline void
169  rtree_leaf_elm_extent_write(tsdn_t *tsdn, rtree_t *rtree,
170      rtree_leaf_elm_t *elm, extent_t *extent) {
171  #ifdef RTREE_LEAF_COMPACT
172  	uintptr_t old_bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, true);
173  	uintptr_t bits = ((uintptr_t)rtree_leaf_elm_bits_szind_get(old_bits) <<
174  	    LG_VADDR) | ((uintptr_t)extent & (((uintptr_t)0x1 << LG_VADDR) - 1))
175  	    | ((uintptr_t)rtree_leaf_elm_bits_slab_get(old_bits));
176  	atomic_store_p(&elm->le_bits, (void *)bits, ATOMIC_RELEASE);
177  #else
178  	atomic_store_p(&elm->le_extent, extent, ATOMIC_RELEASE);
179  #endif
180  }
181  static inline void
182  rtree_leaf_elm_szind_write(tsdn_t *tsdn, rtree_t *rtree,
183      rtree_leaf_elm_t *elm, szind_t szind) {
184  	assert(szind <= SC_NSIZES);
185  #ifdef RTREE_LEAF_COMPACT
186  	uintptr_t old_bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm,
187  	    true);
188  	uintptr_t bits = ((uintptr_t)szind << LG_VADDR) |
189  	    ((uintptr_t)rtree_leaf_elm_bits_extent_get(old_bits) &
190  	    (((uintptr_t)0x1 << LG_VADDR) - 1)) |
191  	    ((uintptr_t)rtree_leaf_elm_bits_slab_get(old_bits));
192  	atomic_store_p(&elm->le_bits, (void *)bits, ATOMIC_RELEASE);
193  #else
194  	atomic_store_u(&elm->le_szind, szind, ATOMIC_RELEASE);
195  #endif
196  }
197  static inline void
198  rtree_leaf_elm_slab_write(tsdn_t *tsdn, rtree_t *rtree,
199      rtree_leaf_elm_t *elm, bool slab) {
200  #ifdef RTREE_LEAF_COMPACT
201  	uintptr_t old_bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm,
202  	    true);
203  	uintptr_t bits = ((uintptr_t)rtree_leaf_elm_bits_szind_get(old_bits) <<
204  	    LG_VADDR) | ((uintptr_t)rtree_leaf_elm_bits_extent_get(old_bits) &
205  	    (((uintptr_t)0x1 << LG_VADDR) - 1)) | ((uintptr_t)slab);
206  	atomic_store_p(&elm->le_bits, (void *)bits, ATOMIC_RELEASE);
207  #else
208  	atomic_store_b(&elm->le_slab, slab, ATOMIC_RELEASE);
209  #endif
210  }
211  static inline void
212  rtree_leaf_elm_write(tsdn_t *tsdn, rtree_t *rtree,
213      rtree_leaf_elm_t *elm, extent_t *extent, szind_t szind, bool slab) {
214  #ifdef RTREE_LEAF_COMPACT
215  	uintptr_t bits = ((uintptr_t)szind << LG_VADDR) |
216  	    ((uintptr_t)extent & (((uintptr_t)0x1 << LG_VADDR) - 1)) |
217  	    ((uintptr_t)slab);
218  	atomic_store_p(&elm->le_bits, (void *)bits, ATOMIC_RELEASE);
219  #else
220  	rtree_leaf_elm_slab_write(tsdn, rtree, elm, slab);
221  	rtree_leaf_elm_szind_write(tsdn, rtree, elm, szind);
222  	rtree_leaf_elm_extent_write(tsdn, rtree, elm, extent);
223  #endif
224  }
225  static inline void
226  rtree_leaf_elm_szind_slab_update(tsdn_t *tsdn, rtree_t *rtree,
227      rtree_leaf_elm_t *elm, szind_t szind, bool slab) {
228  	assert(!slab || szind < SC_NBINS);
229  	rtree_leaf_elm_slab_write(tsdn, rtree, elm, slab);
230  	rtree_leaf_elm_szind_write(tsdn, rtree, elm, szind);
231  }
232  JEMALLOC_ALWAYS_INLINE rtree_leaf_elm_t *
233  rtree_leaf_elm_lookup(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
234      uintptr_t key, bool dependent, bool init_missing) {
235  	assert(key != 0);
236  	assert(!dependent || !init_missing);
237  	size_t slot = rtree_cache_direct_map(key);
238  	uintptr_t leafkey = rtree_leafkey(key);
239  	assert(leafkey != RTREE_LEAFKEY_INVALID);
240  	if (likely(rtree_ctx->cache[slot].leafkey == leafkey)) {
241  		rtree_leaf_elm_t *leaf = rtree_ctx->cache[slot].leaf;
242  		assert(leaf != NULL);
243  		uintptr_t subkey = rtree_subkey(key, RTREE_HEIGHT-1);
244  		return &leaf[subkey];
245  	}
246  #define RTREE_CACHE_CHECK_L2(i) do {					\
247  	if (likely(rtree_ctx->l2_cache[i].leafkey == leafkey)) {	\
248  		rtree_leaf_elm_t *leaf = rtree_ctx->l2_cache[i].leaf;	\
249  		assert(leaf != NULL);					\
250  		if (i > 0) {						\
251  							\
252  			rtree_ctx->l2_cache[i].leafkey =		\
253  				rtree_ctx->l2_cache[i - 1].leafkey;	\
254  			rtree_ctx->l2_cache[i].leaf =			\
255  				rtree_ctx->l2_cache[i - 1].leaf;	\
256  			rtree_ctx->l2_cache[i - 1].leafkey =		\
257  			    rtree_ctx->cache[slot].leafkey;		\
258  			rtree_ctx->l2_cache[i - 1].leaf =		\
259  			    rtree_ctx->cache[slot].leaf;		\
260  		} else {						\
261  			rtree_ctx->l2_cache[0].leafkey =		\
262  			    rtree_ctx->cache[slot].leafkey;		\
263  			rtree_ctx->l2_cache[0].leaf =			\
264  			    rtree_ctx->cache[slot].leaf;		\
265  		}							\
266  		rtree_ctx->cache[slot].leafkey = leafkey;		\
267  		rtree_ctx->cache[slot].leaf = leaf;			\
268  		uintptr_t subkey = rtree_subkey(key, RTREE_HEIGHT-1);	\
269  		return &leaf[subkey];					\
270  	}								\
271  } while (0)
272  	RTREE_CACHE_CHECK_L2(0);
273  	for (unsigned i = 1; i < RTREE_CTX_NCACHE_L2; i++) {
274  		RTREE_CACHE_CHECK_L2(i);
275  	}
276  #undef RTREE_CACHE_CHECK_L2
277  	return rtree_leaf_elm_lookup_hard(tsdn, rtree, rtree_ctx, key,
278  	    dependent, init_missing);
279  }
280  static inline bool
281  rtree_write(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx, uintptr_t key,
282      extent_t *extent, szind_t szind, bool slab) {
283  	assert(extent != NULL);
284  	rtree_leaf_elm_t *elm = rtree_leaf_elm_lookup(tsdn, rtree, rtree_ctx,
285  	    key, false, true);
286  	if (elm == NULL) {
287  		return true;
288  	}
289  	assert(rtree_leaf_elm_extent_read(tsdn, rtree, elm, false) == NULL);
290  	rtree_leaf_elm_write(tsdn, rtree, elm, extent, szind, slab);
291  	return false;
292  }
293  JEMALLOC_ALWAYS_INLINE rtree_leaf_elm_t *
294  rtree_read(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx, uintptr_t key,
295      bool dependent) {
296  	rtree_leaf_elm_t *elm = rtree_leaf_elm_lookup(tsdn, rtree, rtree_ctx,
297  	    key, dependent, false);
298  	if (!dependent && elm == NULL) {
299  		return NULL;
300  	}
301  	assert(elm != NULL);
302  	return elm;
303  }
304  JEMALLOC_ALWAYS_INLINE extent_t *
305  rtree_extent_read(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
306      uintptr_t key, bool dependent) {
307  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key,
308  	    dependent);
309  	if (!dependent && elm == NULL) {
310  		return NULL;
311  	}
312  	return rtree_leaf_elm_extent_read(tsdn, rtree, elm, dependent);
313  }
314  JEMALLOC_ALWAYS_INLINE szind_t
315  rtree_szind_read(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
316      uintptr_t key, bool dependent) {
317  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key,
318  	    dependent);
319  	if (!dependent && elm == NULL) {
320  		return SC_NSIZES;
321  	}
322  	return rtree_leaf_elm_szind_read(tsdn, rtree, elm, dependent);
323  }
324  JEMALLOC_ALWAYS_INLINE bool
325  rtree_extent_szind_read(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
326      uintptr_t key, bool dependent, extent_t **r_extent, szind_t *r_szind) {
327  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key,
328  	    dependent);
329  	if (!dependent && elm == NULL) {
330  		return true;
331  	}
332  	*r_extent = rtree_leaf_elm_extent_read(tsdn, rtree, elm, dependent);
333  	*r_szind = rtree_leaf_elm_szind_read(tsdn, rtree, elm, dependent);
334  	return false;
335  }
336  JEMALLOC_ALWAYS_INLINE bool
337  rtree_szind_slab_read_fast(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
338  			    uintptr_t key, szind_t *r_szind, bool *r_slab) {
339  	rtree_leaf_elm_t *elm;
340  	size_t slot = rtree_cache_direct_map(key);
341  	uintptr_t leafkey = rtree_leafkey(key);
342  	assert(leafkey != RTREE_LEAFKEY_INVALID);
343  	if (likely(rtree_ctx->cache[slot].leafkey == leafkey)) {
344  		rtree_leaf_elm_t *leaf = rtree_ctx->cache[slot].leaf;
345  		assert(leaf != NULL);
346  		uintptr_t subkey = rtree_subkey(key, RTREE_HEIGHT-1);
347  		elm = &leaf[subkey];
348  #ifdef RTREE_LEAF_COMPACT
349  		uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree,
350  							  elm, true);
351  		*r_szind = rtree_leaf_elm_bits_szind_get(bits);
352  		*r_slab = rtree_leaf_elm_bits_slab_get(bits);
353  #else
354  		*r_szind = rtree_leaf_elm_szind_read(tsdn, rtree, elm, true);
355  		*r_slab = rtree_leaf_elm_slab_read(tsdn, rtree, elm, true);
356  #endif
357  		return true;
358  	} else {
359  		return false;
360  	}
361  }
362  JEMALLOC_ALWAYS_INLINE bool
363  rtree_szind_slab_read(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
364      uintptr_t key, bool dependent, szind_t *r_szind, bool *r_slab) {
365  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key,
366  	    dependent);
367  	if (!dependent && elm == NULL) {
368  		return true;
369  	}
370  #ifdef RTREE_LEAF_COMPACT
<span onclick='openModal()' class='match'>371  	uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, dependent);
372  	*r_szind = rtree_leaf_elm_bits_szind_get(bits);
373  	*r_slab = rtree_leaf_elm_bits_slab_get(bits);
374  #else
375  	*r_szind = rtree_leaf_elm_szind_read(tsdn, rtree, elm, dependent);
376  	*r_slab = rtree_leaf_elm_slab_read(tsdn, rtree, elm, dependent);
377  #endif
378  	return false;
379  }
380  static inline void
</span>381  rtree_szind_slab_update(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
382      uintptr_t key, szind_t szind, bool slab) {
383  	assert(!slab || szind < SC_NBINS);
384  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key, true);
385  	rtree_leaf_elm_szind_slab_update(tsdn, rtree, elm, szind, slab);
386  }
387  static inline void
388  rtree_clear(tsdn_t *tsdn, rtree_t *rtree, rtree_ctx_t *rtree_ctx,
389      uintptr_t key) {
390  	rtree_leaf_elm_t *elm = rtree_read(tsdn, rtree, rtree_ctx, key, true);
391  	assert(rtree_leaf_elm_extent_read(tsdn, rtree, elm, false) !=
392  	    NULL);
393  	rtree_leaf_elm_write(tsdn, rtree, elm, NULL, SC_NSIZES, false);
394  }
395  #endif &bsol;* JEMALLOC_INTERNAL_RTREE_H */
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-rtree.h</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-rtree.h</div>
                </div>
                <div class="column column_space"><pre><code>371  	uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, dependent);
372  	*r_szind = rtree_leaf_elm_bits_szind_get(bits);
373  	*r_slab = rtree_leaf_elm_bits_slab_get(bits);
374  #else
375  	*r_szind = rtree_leaf_elm_szind_read(tsdn, rtree, elm, dependent);
376  	*r_slab = rtree_leaf_elm_slab_read(tsdn, rtree, elm, dependent);
377  #endif
378  	return false;
379  }
380  static inline void
</pre></code></div>
                <div class="column column_space"><pre><code>371  	uintptr_t bits = rtree_leaf_elm_bits_read(tsdn, rtree, elm, dependent);
372  	*r_szind = rtree_leaf_elm_bits_szind_get(bits);
373  	*r_slab = rtree_leaf_elm_bits_slab_get(bits);
374  #else
375  	*r_szind = rtree_leaf_elm_szind_read(tsdn, rtree, elm, dependent);
376  	*r_slab = rtree_leaf_elm_slab_read(tsdn, rtree, elm, dependent);
377  #endif
378  	return false;
379  }
380  static inline void
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    