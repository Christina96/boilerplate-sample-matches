
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 215, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-sph_blake.c</h3>
            <pre><code>1  #include <stddef.h>
2  #include <string.h>
3  #include <limits.h>
4  #include "sph_blake.h"
5  #ifdef __cplusplus
6  extern "C"{
7  #endif
8  #if SPH_SMALL_FOOTPRINT && !defined SPH_SMALL_FOOTPRINT_BLAKE
9  #define SPH_SMALL_FOOTPRINT_BLAKE   1
10  #endif
11  #if SPH_SMALL_FOOTPRINT_BLAKE
12  #define SPH_COMPACT_BLAKE_32   1
13  #endif
14  #if SPH_64 && (SPH_SMALL_FOOTPRINT_BLAKE || !SPH_64_TRUE)
15  #define SPH_COMPACT_BLAKE_64   1
16  #endif
17  #ifdef _MSC_VER
18  #pragma warning (disable: 4146)
19  #endif
20  static const sph_u32 IV224[8] = {
21  	SPH_C32(0xC1059ED8), SPH_C32(0x367CD507),
22  	SPH_C32(0x3070DD17), SPH_C32(0xF70E5939),
23  	SPH_C32(0xFFC00B31), SPH_C32(0x68581511),
24  	SPH_C32(0x64F98FA7), SPH_C32(0xBEFA4FA4)
25  };
26  static const sph_u32 IV256[8] = {
27  	SPH_C32(0x6A09E667), SPH_C32(0xBB67AE85),
28  	SPH_C32(0x3C6EF372), SPH_C32(0xA54FF53A),
29  	SPH_C32(0x510E527F), SPH_C32(0x9B05688C),
30  	SPH_C32(0x1F83D9AB), SPH_C32(0x5BE0CD19)
31  };
32  #if SPH_64
33  static const sph_u64 IV384[8] = {
34  	SPH_C64(0xCBBB9D5DC1059ED8), SPH_C64(0x629A292A367CD507),
35  	SPH_C64(0x9159015A3070DD17), SPH_C64(0x152FECD8F70E5939),
36  	SPH_C64(0x67332667FFC00B31), SPH_C64(0x8EB44A8768581511),
37  	SPH_C64(0xDB0C2E0D64F98FA7), SPH_C64(0x47B5481DBEFA4FA4)
38  };
39  static const sph_u64 IV512[8] = {
40  	SPH_C64(0x6A09E667F3BCC908), SPH_C64(0xBB67AE8584CAA73B),
41  	SPH_C64(0x3C6EF372FE94F82B), SPH_C64(0xA54FF53A5F1D36F1),
42  	SPH_C64(0x510E527FADE682D1), SPH_C64(0x9B05688C2B3E6C1F),
43  	SPH_C64(0x1F83D9ABFB41BD6B), SPH_C64(0x5BE0CD19137E2179)
44  };
45  #endif
46  #if SPH_COMPACT_BLAKE_32 || SPH_COMPACT_BLAKE_64
47  static const unsigned sigma[16][16] = {
48  	{  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15 },
49  	{ 14, 10,  4,  8,  9, 15, 13,  6,  1, 12,  0,  2, 11,  7,  5,  3 },
50  	{ 11,  8, 12,  0,  5,  2, 15, 13, 10, 14,  3,  6,  7,  1,  9,  4 },
51  	{  7,  9,  3,  1, 13, 12, 11, 14,  2,  6,  5, 10,  4,  0, 15,  8 },
52  	{  9,  0,  5,  7,  2,  4, 10, 15, 14,  1, 11, 12,  6,  8,  3, 13 },
53  	{  2, 12,  6, 10,  0, 11,  8,  3,  4, 13,  7,  5, 15, 14,  1,  9 },
54  	{ 12,  5,  1, 15, 14, 13,  4, 10,  0,  7,  6,  3,  9,  2,  8, 11 },
55  	{ 13, 11,  7, 14, 12,  1,  3,  9,  5,  0, 15,  4,  8,  6,  2, 10 },
56  	{  6, 15, 14,  9, 11,  3,  0,  8, 12,  2, 13,  7,  1,  4, 10,  5 },
57  	{ 10,  2,  8,  4,  7,  6,  1,  5, 15, 11,  9, 14,  3, 12, 13,  0 },
58  	{  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15 },
59  	{ 14, 10,  4,  8,  9, 15, 13,  6,  1, 12,  0,  2, 11,  7,  5,  3 },
60  	{ 11,  8, 12,  0,  5,  2, 15, 13, 10, 14,  3,  6,  7,  1,  9,  4 },
61  	{  7,  9,  3,  1, 13, 12, 11, 14,  2,  6,  5, 10,  4,  0, 15,  8 },
62  	{  9,  0,  5,  7,  2,  4, 10, 15, 14,  1, 11, 12,  6,  8,  3, 13 },
63  	{  2, 12,  6, 10,  0, 11,  8,  3,  4, 13,  7,  5, 15, 14,  1,  9 }
64  };
65  #endif
66  #define Z00   0
67  #define Z01   1
68  #define Z02   2
69  #define Z03   3
70  #define Z04   4
71  #define Z05   5
72  #define Z06   6
73  #define Z07   7
74  #define Z08   8
75  #define Z09   9
76  #define Z0A   A
77  #define Z0B   B
78  #define Z0C   C
79  #define Z0D   D
80  #define Z0E   E
81  #define Z0F   F
82  #define Z10   E
83  #define Z11   A
84  #define Z12   4
85  #define Z13   8
86  #define Z14   9
87  #define Z15   F
88  #define Z16   D
89  #define Z17   6
90  #define Z18   1
91  #define Z19   C
92  #define Z1A   0
93  #define Z1B   2
94  #define Z1C   B
95  #define Z1D   7
96  #define Z1E   5
97  #define Z1F   3
98  #define Z20   B
99  #define Z21   8
100  #define Z22   C
101  #define Z23   0
102  #define Z24   5
103  #define Z25   2
104  #define Z26   F
105  #define Z27   D
106  #define Z28   A
107  #define Z29   E
108  #define Z2A   3
109  #define Z2B   6
110  #define Z2C   7
111  #define Z2D   1
112  #define Z2E   9
113  #define Z2F   4
114  #define Z30   7
115  #define Z31   9
116  #define Z32   3
117  #define Z33   1
118  #define Z34   D
119  #define Z35   C
120  #define Z36   B
121  #define Z37   E
122  #define Z38   2
123  #define Z39   6
124  #define Z3A   5
125  #define Z3B   A
126  #define Z3C   4
127  #define Z3D   0
128  #define Z3E   F
129  #define Z3F   8
130  #define Z40   9
131  #define Z41   0
132  #define Z42   5
133  #define Z43   7
134  #define Z44   2
135  #define Z45   4
136  #define Z46   A
137  #define Z47   F
138  #define Z48   E
139  #define Z49   1
140  #define Z4A   B
141  #define Z4B   C
142  #define Z4C   6
143  #define Z4D   8
144  #define Z4E   3
145  #define Z4F   D
146  #define Z50   2
147  #define Z51   C
148  #define Z52   6
149  #define Z53   A
150  #define Z54   0
151  #define Z55   B
152  #define Z56   8
153  #define Z57   3
154  #define Z58   4
155  #define Z59   D
156  #define Z5A   7
157  #define Z5B   5
158  #define Z5C   F
159  #define Z5D   E
160  #define Z5E   1
161  #define Z5F   9
162  #define Z60   C
163  #define Z61   5
164  #define Z62   1
165  #define Z63   F
166  #define Z64   E
167  #define Z65   D
168  #define Z66   4
169  #define Z67   A
170  #define Z68   0
171  #define Z69   7
172  #define Z6A   6
173  #define Z6B   3
174  #define Z6C   9
175  #define Z6D   2
176  #define Z6E   8
177  #define Z6F   B
178  #define Z70   D
179  #define Z71   B
180  #define Z72   7
181  #define Z73   E
182  #define Z74   C
183  #define Z75   1
184  #define Z76   3
185  #define Z77   9
186  #define Z78   5
187  #define Z79   0
188  #define Z7A   F
189  #define Z7B   4
190  #define Z7C   8
191  #define Z7D   6
192  #define Z7E   2
193  #define Z7F   A
194  #define Z80   6
195  #define Z81   F
196  #define Z82   E
197  #define Z83   9
198  #define Z84   B
199  #define Z85   3
200  #define Z86   0
201  #define Z87   8
202  #define Z88   C
203  #define Z89   2
204  #define Z8A   D
205  #define Z8B   7
206  #define Z8C   1
207  #define Z8D   4
208  #define Z8E   A
209  #define Z8F   5
210  #define Z90   A
211  #define Z91   2
212  #define Z92   8
213  #define Z93   4
214  #define Z94   7
215  #define Z95   6
216  #define Z96   1
217  #define Z97   5
218  #define Z98   F
219  #define Z99   B
220  #define Z9A   9
221  #define Z9B   E
222  #define Z9C   3
223  #define Z9D   C
224  #define Z9E   D
225  #define Z9F   0
226  #define Mx(r, i)    Mx_(Z ## r ## i)
227  #define Mx_(n)      Mx__(n)
228  #define Mx__(n)     M ## n
229  #define CSx(r, i)   CSx_(Z ## r ## i)
230  #define CSx_(n)     CSx__(n)
231  #define CSx__(n)    CS ## n
232  #define CS0   SPH_C32(0x243F6A88)
233  #define CS1   SPH_C32(0x85A308D3)
234  #define CS2   SPH_C32(0x13198A2E)
235  #define CS3   SPH_C32(0x03707344)
236  #define CS4   SPH_C32(0xA4093822)
237  #define CS5   SPH_C32(0x299F31D0)
238  #define CS6   SPH_C32(0x082EFA98)
239  #define CS7   SPH_C32(0xEC4E6C89)
240  #define CS8   SPH_C32(0x452821E6)
241  #define CS9   SPH_C32(0x38D01377)
242  #define CSA   SPH_C32(0xBE5466CF)
243  #define CSB   SPH_C32(0x34E90C6C)
244  #define CSC   SPH_C32(0xC0AC29B7)
245  #define CSD   SPH_C32(0xC97C50DD)
246  #define CSE   SPH_C32(0x3F84D5B5)
247  #define CSF   SPH_C32(0xB5470917)
248  #if SPH_COMPACT_BLAKE_32
249  static const sph_u32 CS[16] = {
250  	SPH_C32(0x243F6A88), SPH_C32(0x85A308D3),
251  	SPH_C32(0x13198A2E), SPH_C32(0x03707344),
252  	SPH_C32(0xA4093822), SPH_C32(0x299F31D0),
253  	SPH_C32(0x082EFA98), SPH_C32(0xEC4E6C89),
254  	SPH_C32(0x452821E6), SPH_C32(0x38D01377),
255  	SPH_C32(0xBE5466CF), SPH_C32(0x34E90C6C),
256  	SPH_C32(0xC0AC29B7), SPH_C32(0xC97C50DD),
257  	SPH_C32(0x3F84D5B5), SPH_C32(0xB5470917)
258  };
259  #endif
260  #if SPH_64
261  #define CBx(r, i)   CBx_(Z ## r ## i)
262  #define CBx_(n)     CBx__(n)
263  #define CBx__(n)    CB ## n
264  #define CB0   SPH_C64(0x243F6A8885A308D3)
265  #define CB1   SPH_C64(0x13198A2E03707344)
266  #define CB2   SPH_C64(0xA4093822299F31D0)
267  #define CB3   SPH_C64(0x082EFA98EC4E6C89)
268  #define CB4   SPH_C64(0x452821E638D01377)
269  #define CB5   SPH_C64(0xBE5466CF34E90C6C)
270  #define CB6   SPH_C64(0xC0AC29B7C97C50DD)
271  #define CB7   SPH_C64(0x3F84D5B5B5470917)
272  #define CB8   SPH_C64(0x9216D5D98979FB1B)
273  #define CB9   SPH_C64(0xD1310BA698DFB5AC)
274  #define CBA   SPH_C64(0x2FFD72DBD01ADFB7)
275  #define CBB   SPH_C64(0xB8E1AFED6A267E96)
276  #define CBC   SPH_C64(0xBA7C9045F12C7F99)
277  #define CBD   SPH_C64(0x24A19947B3916CF7)
278  #define CBE   SPH_C64(0x0801F2E2858EFC16)
279  #define CBF   SPH_C64(0x636920D871574E69)
280  #if SPH_COMPACT_BLAKE_64
281  static const sph_u64 CB[16] = {
282  	SPH_C64(0x243F6A8885A308D3), SPH_C64(0x13198A2E03707344),
283  	SPH_C64(0xA4093822299F31D0), SPH_C64(0x082EFA98EC4E6C89),
284  	SPH_C64(0x452821E638D01377), SPH_C64(0xBE5466CF34E90C6C),
285  	SPH_C64(0xC0AC29B7C97C50DD), SPH_C64(0x3F84D5B5B5470917),
286  	SPH_C64(0x9216D5D98979FB1B), SPH_C64(0xD1310BA698DFB5AC),
287  	SPH_C64(0x2FFD72DBD01ADFB7), SPH_C64(0xB8E1AFED6A267E96),
288  	SPH_C64(0xBA7C9045F12C7F99), SPH_C64(0x24A19947B3916CF7),
289  	SPH_C64(0x0801F2E2858EFC16), SPH_C64(0x636920D871574E69)
290  };
291  #endif
292  #endif
293  #define GS(m0, m1, c0, c1, a, b, c, d)   do { \
294  		a = SPH_T32(a + b + (m0 ^ c1)); \
295  		d = SPH_ROTR32(d ^ a, 16); \
296  		c = SPH_T32(c + d); \
297  		b = SPH_ROTR32(b ^ c, 12); \
298  		a = SPH_T32(a + b + (m1 ^ c0)); \
299  		d = SPH_ROTR32(d ^ a, 8); \
300  		c = SPH_T32(c + d); \
301  		b = SPH_ROTR32(b ^ c, 7); \
302  	} while (0)
303  #if SPH_COMPACT_BLAKE_32
304  #define ROUND_S(r)   do { \
305  		GS(M[sigma[r][0x0]], M[sigma[r][0x1]], \
306  			CS[sigma[r][0x0]], CS[sigma[r][0x1]], V0, V4, V8, VC); \
307  		GS(M[sigma[r][0x2]], M[sigma[r][0x3]], \
308  			CS[sigma[r][0x2]], CS[sigma[r][0x3]], V1, V5, V9, VD); \
309  		GS(M[sigma[r][0x4]], M[sigma[r][0x5]], \
310  			CS[sigma[r][0x4]], CS[sigma[r][0x5]], V2, V6, VA, VE); \
311  		GS(M[sigma[r][0x6]], M[sigma[r][0x7]], \
312  			CS[sigma[r][0x6]], CS[sigma[r][0x7]], V3, V7, VB, VF); \
313  		GS(M[sigma[r][0x8]], M[sigma[r][0x9]], \
314  			CS[sigma[r][0x8]], CS[sigma[r][0x9]], V0, V5, VA, VF); \
315  		GS(M[sigma[r][0xA]], M[sigma[r][0xB]], \
316  			CS[sigma[r][0xA]], CS[sigma[r][0xB]], V1, V6, VB, VC); \
317  		GS(M[sigma[r][0xC]], M[sigma[r][0xD]], \
318  			CS[sigma[r][0xC]], CS[sigma[r][0xD]], V2, V7, V8, VD); \
319  		GS(M[sigma[r][0xE]], M[sigma[r][0xF]], \
320  			CS[sigma[r][0xE]], CS[sigma[r][0xF]], V3, V4, V9, VE); \
321  	} while (0)
322  #else
323  #define ROUND_S(r)   do { \
324  		GS(Mx(r, 0), Mx(r, 1), CSx(r, 0), CSx(r, 1), V0, V4, V8, VC); \
325  		GS(Mx(r, 2), Mx(r, 3), CSx(r, 2), CSx(r, 3), V1, V5, V9, VD); \
326  		GS(Mx(r, 4), Mx(r, 5), CSx(r, 4), CSx(r, 5), V2, V6, VA, VE); \
327  		GS(Mx(r, 6), Mx(r, 7), CSx(r, 6), CSx(r, 7), V3, V7, VB, VF); \
328  		GS(Mx(r, 8), Mx(r, 9), CSx(r, 8), CSx(r, 9), V0, V5, VA, VF); \
329  		GS(Mx(r, A), Mx(r, B), CSx(r, A), CSx(r, B), V1, V6, VB, VC); \
330  		GS(Mx(r, C), Mx(r, D), CSx(r, C), CSx(r, D), V2, V7, V8, VD); \
331  		GS(Mx(r, E), Mx(r, F), CSx(r, E), CSx(r, F), V3, V4, V9, VE); \
332  	} while (0)
333  #endif
334  #if SPH_64
335  #define GB(m0, m1, c0, c1, a, b, c, d)   do { \
336  		a = SPH_T64(a + b + (m0 ^ c1)); \
337  		d = SPH_ROTR64(d ^ a, 32); \
338  		c = SPH_T64(c + d); \
339  		b = SPH_ROTR64(b ^ c, 25); \
340  		a = SPH_T64(a + b + (m1 ^ c0)); \
341  		d = SPH_ROTR64(d ^ a, 16); \
342  		c = SPH_T64(c + d); \
343  		b = SPH_ROTR64(b ^ c, 11); \
344  	} while (0)
345  #if SPH_COMPACT_BLAKE_64
346  #define ROUND_B(r)   do { \
347  		GB(M[sigma[r][0x0]], M[sigma[r][0x1]], \
348  			CB[sigma[r][0x0]], CB[sigma[r][0x1]], V0, V4, V8, VC); \
349  		GB(M[sigma[r][0x2]], M[sigma[r][0x3]], \
350  			CB[sigma[r][0x2]], CB[sigma[r][0x3]], V1, V5, V9, VD); \
351  		GB(M[sigma[r][0x4]], M[sigma[r][0x5]], \
352  			CB[sigma[r][0x4]], CB[sigma[r][0x5]], V2, V6, VA, VE); \
353  		GB(M[sigma[r][0x6]], M[sigma[r][0x7]], \
354  			CB[sigma[r][0x6]], CB[sigma[r][0x7]], V3, V7, VB, VF); \
355  		GB(M[sigma[r][0x8]], M[sigma[r][0x9]], \
356  			CB[sigma[r][0x8]], CB[sigma[r][0x9]], V0, V5, VA, VF); \
357  		GB(M[sigma[r][0xA]], M[sigma[r][0xB]], \
358  			CB[sigma[r][0xA]], CB[sigma[r][0xB]], V1, V6, VB, VC); \
359  		GB(M[sigma[r][0xC]], M[sigma[r][0xD]], \
360  			CB[sigma[r][0xC]], CB[sigma[r][0xD]], V2, V7, V8, VD); \
361  		GB(M[sigma[r][0xE]], M[sigma[r][0xF]], \
362  			CB[sigma[r][0xE]], CB[sigma[r][0xF]], V3, V4, V9, VE); \
363  	} while (0)
364  #else
365  #define ROUND_B(r)   do { \
366  		GB(Mx(r, 0), Mx(r, 1), CBx(r, 0), CBx(r, 1), V0, V4, V8, VC); \
367  		GB(Mx(r, 2), Mx(r, 3), CBx(r, 2), CBx(r, 3), V1, V5, V9, VD); \
368  		GB(Mx(r, 4), Mx(r, 5), CBx(r, 4), CBx(r, 5), V2, V6, VA, VE); \
369  		GB(Mx(r, 6), Mx(r, 7), CBx(r, 6), CBx(r, 7), V3, V7, VB, VF); \
370  		GB(Mx(r, 8), Mx(r, 9), CBx(r, 8), CBx(r, 9), V0, V5, VA, VF); \
371  		GB(Mx(r, A), Mx(r, B), CBx(r, A), CBx(r, B), V1, V6, VB, VC); \
372  		GB(Mx(r, C), Mx(r, D), CBx(r, C), CBx(r, D), V2, V7, V8, VD); \
373  		GB(Mx(r, E), Mx(r, F), CBx(r, E), CBx(r, F), V3, V4, V9, VE); \
374  	} while (0)
375  #endif
376  #endif
377  #define DECL_STATE32 \
378  	sph_u32 H0, H1, H2, H3, H4, H5, H6, H7; \
379  	sph_u32 S0, S1, S2, S3, T0, T1;
380  #define READ_STATE32(state)   do { \
381  		H0 = (state)->H[0]; \
382  		H1 = (state)->H[1]; \
383  		H2 = (state)->H[2]; \
384  		H3 = (state)->H[3]; \
385  		H4 = (state)->H[4]; \
386  		H5 = (state)->H[5]; \
387  		H6 = (state)->H[6]; \
388  		H7 = (state)->H[7]; \
389  		S0 = (state)->S[0]; \
390  		S1 = (state)->S[1]; \
391  		S2 = (state)->S[2]; \
392  		S3 = (state)->S[3]; \
393  		T0 = (state)->T0; \
394  		T1 = (state)->T1; \
395  	} while (0)
396  #define WRITE_STATE32(state)   do { \
397  		(state)->H[0] = H0; \
398  		(state)->H[1] = H1; \
399  		(state)->H[2] = H2; \
400  		(state)->H[3] = H3; \
401  		(state)->H[4] = H4; \
402  		(state)->H[5] = H5; \
403  		(state)->H[6] = H6; \
404  		(state)->H[7] = H7; \
405  		(state)->S[0] = S0; \
406  		(state)->S[1] = S1; \
407  		(state)->S[2] = S2; \
408  		(state)->S[3] = S3; \
409  		(state)->T0 = T0; \
410  		(state)->T1 = T1; \
411  	} while (0)
412  #ifndef BLAKE32_ROUNDS
413  #define BLAKE32_ROUNDS 14
414  #endif
415  #if SPH_COMPACT_BLAKE_32
416  #define COMPRESS32   do { \
417  		sph_u32 M[16]; \
418  		sph_u32 V0, V1, V2, V3, V4, V5, V6, V7; \
419  		sph_u32 V8, V9, VA, VB, VC, VD, VE, VF; \
420  		unsigned r; \
421  		V0 = H0; \
422  		V1 = H1; \
423  		V2 = H2; \
424  		V3 = H3; \
425  		V4 = H4; \
426  		V5 = H5; \
427  		V6 = H6; \
428  		V7 = H7; \
429  		V8 = S0 ^ CS0; \
430  		V9 = S1 ^ CS1; \
431  		VA = S2 ^ CS2; \
432  		VB = S3 ^ CS3; \
433  		VC = T0 ^ CS4; \
434  		VD = T0 ^ CS5; \
435  		VE = T1 ^ CS6; \
436  		VF = T1 ^ CS7; \
437  		M[0x0] = sph_dec32be_aligned(buf +  0); \
438  		M[0x1] = sph_dec32be_aligned(buf +  4); \
439  		M[0x2] = sph_dec32be_aligned(buf +  8); \
440  		M[0x3] = sph_dec32be_aligned(buf + 12); \
441  		M[0x4] = sph_dec32be_aligned(buf + 16); \
442  		M[0x5] = sph_dec32be_aligned(buf + 20); \
443  		M[0x6] = sph_dec32be_aligned(buf + 24); \
444  		M[0x7] = sph_dec32be_aligned(buf + 28); \
445  		M[0x8] = sph_dec32be_aligned(buf + 32); \
446  		M[0x9] = sph_dec32be_aligned(buf + 36); \
447  		M[0xA] = sph_dec32be_aligned(buf + 40); \
448  		M[0xB] = sph_dec32be_aligned(buf + 44); \
449  		M[0xC] = sph_dec32be_aligned(buf + 48); \
450  		M[0xD] = sph_dec32be_aligned(buf + 52); \
451  		M[0xE] = sph_dec32be_aligned(buf + 56); \
452  		M[0xF] = sph_dec32be_aligned(buf + 60); \
453  		for (r = 0; r < BLAKE32_ROUNDS; r ++) \
454  			ROUND_S(r); \
455  		H0 ^= S0 ^ V0 ^ V8; \
456  		H1 ^= S1 ^ V1 ^ V9; \
457  		H2 ^= S2 ^ V2 ^ VA; \
458  		H3 ^= S3 ^ V3 ^ VB; \
459  		H4 ^= S0 ^ V4 ^ VC; \
460  		H5 ^= S1 ^ V5 ^ VD; \
461  		H6 ^= S2 ^ V6 ^ VE; \
462  		H7 ^= S3 ^ V7 ^ VF; \
463  	} while (0)
464  #else
465  #define COMPRESS32   do { \
466  		sph_u32 M0, M1, M2, M3, M4, M5, M6, M7; \
467  		sph_u32 M8, M9, MA, MB, MC, MD, ME, MF; \
468  		sph_u32 V0, V1, V2, V3, V4, V5, V6, V7; \
469  		sph_u32 V8, V9, VA, VB, VC, VD, VE, VF; \
470  		V0 = H0; \
471  		V1 = H1; \
472  		V2 = H2; \
473  		V3 = H3; \
474  		V4 = H4; \
475  		V5 = H5; \
476  		V6 = H6; \
477  		V7 = H7; \
478  		V8 = S0 ^ CS0; \
479  		V9 = S1 ^ CS1; \
480  		VA = S2 ^ CS2; \
481  		VB = S3 ^ CS3; \
482  		VC = T0 ^ CS4; \
483  		VD = T0 ^ CS5; \
484  		VE = T1 ^ CS6; \
485  		VF = T1 ^ CS7; \
486  		M0 = sph_dec32be_aligned(buf +  0); \
487  		M1 = sph_dec32be_aligned(buf +  4); \
488  		M2 = sph_dec32be_aligned(buf +  8); \
489  		M3 = sph_dec32be_aligned(buf + 12); \
490  		M4 = sph_dec32be_aligned(buf + 16); \
491  		M5 = sph_dec32be_aligned(buf + 20); \
492  		M6 = sph_dec32be_aligned(buf + 24); \
493  		M7 = sph_dec32be_aligned(buf + 28); \
494  		M8 = sph_dec32be_aligned(buf + 32); \
495  		M9 = sph_dec32be_aligned(buf + 36); \
496  		MA = sph_dec32be_aligned(buf + 40); \
497  		MB = sph_dec32be_aligned(buf + 44); \
498  		MC = sph_dec32be_aligned(buf + 48); \
499  		MD = sph_dec32be_aligned(buf + 52); \
500  		ME = sph_dec32be_aligned(buf + 56); \
501  		MF = sph_dec32be_aligned(buf + 60); \
502  		ROUND_S(0); \
503  		ROUND_S(1); \
504  		ROUND_S(2); \
505  		ROUND_S(3); \
506  		ROUND_S(4); \
507  		ROUND_S(5); \
508  		ROUND_S(6); \
509  		ROUND_S(7); \
510  		if (BLAKE32_ROUNDS == 14) { \
511  		ROUND_S(8); \
512  		ROUND_S(9); \
513  		ROUND_S(0); \
514  		ROUND_S(1); \
515  		ROUND_S(2); \
516  		ROUND_S(3); \
517  		} \
518  		H0 ^= S0 ^ V0 ^ V8; \
519  		H1 ^= S1 ^ V1 ^ V9; \
520  		H2 ^= S2 ^ V2 ^ VA; \
521  		H3 ^= S3 ^ V3 ^ VB; \
522  		H4 ^= S0 ^ V4 ^ VC; \
523  		H5 ^= S1 ^ V5 ^ VD; \
524  		H6 ^= S2 ^ V6 ^ VE; \
525  		H7 ^= S3 ^ V7 ^ VF; \
526  	} while (0)
527  #endif
528  #if SPH_64
529  #define DECL_STATE64 \
530  	sph_u64 H0, H1, H2, H3, H4, H5, H6, H7; \
531  	sph_u64 S0, S1, S2, S3, T0, T1;
532  #define READ_STATE64(state)   do { \
533  		H0 = (state)->H[0]; \
534  		H1 = (state)->H[1]; \
535  		H2 = (state)->H[2]; \
536  		H3 = (state)->H[3]; \
537  		H4 = (state)->H[4]; \
538  		H5 = (state)->H[5]; \
539  		H6 = (state)->H[6]; \
540  		H7 = (state)->H[7]; \
541  		S0 = (state)->S[0]; \
542  		S1 = (state)->S[1]; \
543  		S2 = (state)->S[2]; \
544  		S3 = (state)->S[3]; \
545  		T0 = (state)->T0; \
546  		T1 = (state)->T1; \
547  	} while (0)
548  #define WRITE_STATE64(state)   do { \
549  		(state)->H[0] = H0; \
550  		(state)->H[1] = H1; \
551  		(state)->H[2] = H2; \
552  		(state)->H[3] = H3; \
553  		(state)->H[4] = H4; \
554  		(state)->H[5] = H5; \
555  		(state)->H[6] = H6; \
556  		(state)->H[7] = H7; \
557  		(state)->S[0] = S0; \
558  		(state)->S[1] = S1; \
559  		(state)->S[2] = S2; \
560  		(state)->S[3] = S3; \
561  		(state)->T0 = T0; \
562  		(state)->T1 = T1; \
563  	} while (0)
564  #if SPH_COMPACT_BLAKE_64
565  #define COMPRESS64   do { \
566  		sph_u64 M[16]; \
567  		sph_u64 V0, V1, V2, V3, V4, V5, V6, V7; \
568  		sph_u64 V8, V9, VA, VB, VC, VD, VE, VF; \
569  		unsigned r; \
570  		V0 = H0; \
571  		V1 = H1; \
572  		V2 = H2; \
573  		V3 = H3; \
574  		V4 = H4; \
575  		V5 = H5; \
576  		V6 = H6; \
577  		V7 = H7; \
578  		V8 = S0 ^ CB0; \
579  		V9 = S1 ^ CB1; \
580  		VA = S2 ^ CB2; \
581  		VB = S3 ^ CB3; \
582  		VC = T0 ^ CB4; \
583  		VD = T0 ^ CB5; \
584  		VE = T1 ^ CB6; \
585  		VF = T1 ^ CB7; \
586  		M[0x0] = sph_dec64be_aligned(buf +   0); \
587  		M[0x1] = sph_dec64be_aligned(buf +   8); \
588  		M[0x2] = sph_dec64be_aligned(buf +  16); \
589  		M[0x3] = sph_dec64be_aligned(buf +  24); \
590  		M[0x4] = sph_dec64be_aligned(buf +  32); \
591  		M[0x5] = sph_dec64be_aligned(buf +  40); \
592  		M[0x6] = sph_dec64be_aligned(buf +  48); \
593  		M[0x7] = sph_dec64be_aligned(buf +  56); \
594  		M[0x8] = sph_dec64be_aligned(buf +  64); \
595  		M[0x9] = sph_dec64be_aligned(buf +  72); \
596  		M[0xA] = sph_dec64be_aligned(buf +  80); \
597  		M[0xB] = sph_dec64be_aligned(buf +  88); \
598  		M[0xC] = sph_dec64be_aligned(buf +  96); \
599  		M[0xD] = sph_dec64be_aligned(buf + 104); \
600  		M[0xE] = sph_dec64be_aligned(buf + 112); \
601  		M[0xF] = sph_dec64be_aligned(buf + 120); \
602  		for (r = 0; r < 16; r ++) \
603  			ROUND_B(r); \
604  		H0 ^= S0 ^ V0 ^ V8; \
605  		H1 ^= S1 ^ V1 ^ V9; \
606  		H2 ^= S2 ^ V2 ^ VA; \
607  		H3 ^= S3 ^ V3 ^ VB; \
608  		H4 ^= S0 ^ V4 ^ VC; \
609  		H5 ^= S1 ^ V5 ^ VD; \
610  		H6 ^= S2 ^ V6 ^ VE; \
611  		H7 ^= S3 ^ V7 ^ VF; \
612  	} while (0)
613  #else
614  #define COMPRESS64   do { \
615  		sph_u64 M0, M1, M2, M3, M4, M5, M6, M7; \
616  		sph_u64 M8, M9, MA, MB, MC, MD, ME, MF; \
617  		sph_u64 V0, V1, V2, V3, V4, V5, V6, V7; \
618  		sph_u64 V8, V9, VA, VB, VC, VD, VE, VF; \
619  		V0 = H0; \
620  		V1 = H1; \
621  		V2 = H2; \
622  		V3 = H3; \
623  		V4 = H4; \
624  		V5 = H5; \
625  		V6 = H6; \
626  		V7 = H7; \
627  		V8 = S0 ^ CB0; \
628  		V9 = S1 ^ CB1; \
629  		VA = S2 ^ CB2; \
630  		VB = S3 ^ CB3; \
631  		VC = T0 ^ CB4; \
632  		VD = T0 ^ CB5; \
633  		VE = T1 ^ CB6; \
<span onclick='openModal()' class='match'>634  		VF = T1 ^ CB7; \
635  		M0 = sph_dec64be_aligned(buf +   0); \
636  		M1 = sph_dec64be_aligned(buf +   8); \
637  		M2 = sph_dec64be_aligned(buf +  16); \
638  		M3 = sph_dec64be_aligned(buf +  24); \
639  		M4 = sph_dec64be_aligned(buf +  32); \
640  		M5 = sph_dec64be_aligned(buf +  40); \
641  		M6 = sph_dec64be_aligned(buf +  48); \
642  		M7 = sph_dec64be_aligned(buf +  56); \
643  		M8 = sph_dec64be_aligned(buf +  64); \
644  		M9 = sph_dec64be_aligned(buf +  72); \
645  		MA = sph_dec64be_aligned(buf +  80); \
646  		MB = sph_dec64be_aligned(buf +  88); \
647  		MC = sph_dec64be_aligned(buf +  96); \
648  		MD = sph_dec64be_aligned(buf + 104); \
649  		ME = sph_dec64be_aligned(buf + 112); \
650  		MF = sph_dec64be_aligned(buf + 120); \
651  		ROUND_B(0); \
652  		ROUND_B(1); \
653  		ROUND_B(2); \
654  		ROUND_B(3); \
655  		ROUND_B(4); \
656  		ROUND_B(5); \
657  		ROUND_B(6); \
658  		ROUND_B(7); \
659  		ROUND_B(8); \
</span>660  		ROUND_B(9); \
661  		ROUND_B(0); \
662  		ROUND_B(1); \
663  		ROUND_B(2); \
664  		ROUND_B(3); \
665  		ROUND_B(4); \
666  		ROUND_B(5); \
667  		H0 ^= S0 ^ V0 ^ V8; \
668  		H1 ^= S1 ^ V1 ^ V9; \
669  		H2 ^= S2 ^ V2 ^ VA; \
670  		H3 ^= S3 ^ V3 ^ VB; \
671  		H4 ^= S0 ^ V4 ^ VC; \
672  		H5 ^= S1 ^ V5 ^ VD; \
673  		H6 ^= S2 ^ V6 ^ VE; \
674  		H7 ^= S3 ^ V7 ^ VF; \
675  	} while (0)
676  #endif
677  #endif
678  static const sph_u32 salt_zero_small[4] = { 0, 0, 0, 0 };
679  static void
680  blake32_init(sph_blake_small_context *sc,
681  	const sph_u32 *iv, const sph_u32 *salt)
682  {
683  	memcpy(sc->H, iv, 8 * sizeof(sph_u32));
684  	memcpy(sc->S, salt, 4 * sizeof(sph_u32));
685  	sc->T0 = sc->T1 = 0;
686  	sc->ptr = 0;
687  }
688  static void
689  blake32(sph_blake_small_context *sc, const void *data, size_t len)
690  {
691  	unsigned char *buf;
692  	size_t ptr;
693  	DECL_STATE32
694  	buf = sc->buf;
695  	ptr = sc->ptr;
696  	if (len < (sizeof sc->buf) - ptr) {
697  		memcpy(buf + ptr, data, len);
698  		ptr += len;
699  		sc->ptr = ptr;
700  		return;
701  	}
702  	READ_STATE32(sc);
703  	while (len > 0) {
704  		size_t clen;
705  		clen = (sizeof sc->buf) - ptr;
706  		if (clen > len)
707  			clen = len;
708  		memcpy(buf + ptr, data, clen);
709  		ptr += clen;
710  		data = (const unsigned char *)data + clen;
711  		len -= clen;
712  		if (ptr == sizeof sc->buf) {
713  			if ((T0 = SPH_T32(T0 + 512)) < 512)
714  				T1 = SPH_T32(T1 + 1);
715  			COMPRESS32;
716  			ptr = 0;
717  		}
718  	}
719  	WRITE_STATE32(sc);
720  	sc->ptr = ptr;
721  }
722  static void
723  blake32_close(sph_blake_small_context *sc,
724  	unsigned ub, unsigned n, void *dst, size_t out_size_w32)
725  {
726  	union {
727  		unsigned char buf[64];
728  		sph_u32 dummy;
729  	} u;
730  	size_t ptr, k;
731  	unsigned bit_len;
732  	unsigned z;
733  	sph_u32 th, tl;
734  	unsigned char *out;
735  	ptr = sc->ptr;
736  	bit_len = ((unsigned)ptr << 3) + n;
737  	z = 0x80 >> n;
738  	u.buf[ptr] = ((ub & -z) | z) & 0xFF;
739  	tl = sc->T0 + bit_len;
740  	th = sc->T1;
741  	if (ptr == 0 && n == 0) {
742  		sc->T0 = SPH_C32(0xFFFFFE00);
743  		sc->T1 = SPH_C32(0xFFFFFFFF);
744  	} else if (sc->T0 == 0) {
745  		sc->T0 = SPH_C32(0xFFFFFE00) + bit_len;
746  		sc->T1 = SPH_T32(sc->T1 - 1);
747  	} else {
748  		sc->T0 -= 512 - bit_len;
749  	}
750  	if (bit_len <= 446) {
751  		memset(u.buf + ptr + 1, 0, 55 - ptr);
752  		if (out_size_w32 == 8)
753  			u.buf[55] |= 1;
754  		sph_enc32be_aligned(u.buf + 56, th);
755  		sph_enc32be_aligned(u.buf + 60, tl);
756  		blake32(sc, u.buf + ptr, 64 - ptr);
757  	} else {
758  		memset(u.buf + ptr + 1, 0, 63 - ptr);
759  		blake32(sc, u.buf + ptr, 64 - ptr);
760  		sc->T0 = SPH_C32(0xFFFFFE00);
761  		sc->T1 = SPH_C32(0xFFFFFFFF);
762  		memset(u.buf, 0, 56);
763  		if (out_size_w32 == 8)
764  			u.buf[55] = 1;
765  		sph_enc32be_aligned(u.buf + 56, th);
766  		sph_enc32be_aligned(u.buf + 60, tl);
767  		blake32(sc, u.buf, 64);
768  	}
769          out = dst;
770          for (k = 0; k < out_size_w32; k ++)
771                  sph_enc32be(out + (k << 2), sc->H[k]);
772  }
773  #if SPH_64
774  static const sph_u64 salt_zero_big[4] = { 0, 0, 0, 0 };
775  static void
776  blake64_init(sph_blake_big_context *sc,
777  	const sph_u64 *iv, const sph_u64 *salt)
778  {
779  	memcpy(sc->H, iv, 8 * sizeof(sph_u64));
780  	memcpy(sc->S, salt, 4 * sizeof(sph_u64));
781  	sc->T0 = sc->T1 = 0;
782  	sc->ptr = 0;
783  }
784  static void
785  blake64(sph_blake_big_context *sc, const void *data, size_t len)
786  {
787  	unsigned char *buf;
788  	size_t ptr;
789  	DECL_STATE64
790  	buf = sc->buf;
791  	ptr = sc->ptr;
792  	if (len < (sizeof sc->buf) - ptr) {
793  		memcpy(buf + ptr, data, len);
794  		ptr += len;
795  		sc->ptr = ptr;
796  		return;
797  	}
798  	READ_STATE64(sc);
799  	while (len > 0) {
800  		size_t clen;
801  		clen = (sizeof sc->buf) - ptr;
802  		if (clen > len)
803  			clen = len;
804  		memcpy(buf + ptr, data, clen);
805  		ptr += clen;
806  		data = (const unsigned char *)data + clen;
807  		len -= clen;
808  		if (ptr == sizeof sc->buf) {
809  			if ((T0 = SPH_T64(T0 + 1024)) < 1024)
810  				T1 = SPH_T64(T1 + 1);
811  			COMPRESS64;
812  			ptr = 0;
813  		}
814  	}
815  	WRITE_STATE64(sc);
816  	sc->ptr = ptr;
817  }
818  static void
819  blake64_close(sph_blake_big_context *sc,
820  	unsigned ub, unsigned n, void *dst, size_t out_size_w64)
821  {
822  	union {
823  		unsigned char buf[128];
824  		sph_u64 dummy;
825  	} u;
826  	size_t ptr, k;
827  	unsigned bit_len;
828  	unsigned z;
829  	sph_u64 th, tl;
830  	unsigned char *out;
831  	ptr = sc->ptr;
832  	bit_len = ((unsigned)ptr << 3) + n;
833  	z = 0x80 >> n;
834  	u.buf[ptr] = ((ub & -z) | z) & 0xFF;
835  	tl = sc->T0 + bit_len;
836  	th = sc->T1;
837  	if (ptr == 0 && n == 0) {
838  		sc->T0 = SPH_C64(0xFFFFFFFFFFFFFC00);
839  		sc->T1 = SPH_C64(0xFFFFFFFFFFFFFFFF);
840  	} else if (sc->T0 == 0) {
841  		sc->T0 = SPH_C64(0xFFFFFFFFFFFFFC00) + bit_len;
842  		sc->T1 = SPH_T64(sc->T1 - 1);
843  	} else {
844  		sc->T0 -= 1024 - bit_len;
845  	}
846  	if (bit_len <= 894) {
847  		memset(u.buf + ptr + 1, 0, 111 - ptr);
848  		if (out_size_w64 == 8)
849  			u.buf[111] |= 1;
850  		sph_enc64be_aligned(u.buf + 112, th);
851  		sph_enc64be_aligned(u.buf + 120, tl);
852  		blake64(sc, u.buf + ptr, 128 - ptr);
853  	} else {
854  		memset(u.buf + ptr + 1, 0, 127 - ptr);
855  		blake64(sc, u.buf + ptr, 128 - ptr);
856  		sc->T0 = SPH_C64(0xFFFFFFFFFFFFFC00);
857  		sc->T1 = SPH_C64(0xFFFFFFFFFFFFFFFF);
858  		memset(u.buf, 0, 112);
859  		if (out_size_w64 == 8)
860  			u.buf[111] = 1;
861  		sph_enc64be_aligned(u.buf + 112, th);
862  		sph_enc64be_aligned(u.buf + 120, tl);
863  		blake64(sc, u.buf, 128);
864  	}
865  	out = dst;
866  	for (k = 0; k < out_size_w64; k ++)
867  		sph_enc64be(out + (k << 3), sc->H[k]);
868  }
869  #endif
870  void
871  sph_blake224_init(void *cc)
872  {
873  	blake32_init(cc, IV224, salt_zero_small);
874  }
875  void
876  sph_blake224(void *cc, const void *data, size_t len)
877  {
878  	blake32(cc, data, len);
879  }
880  void
881  sph_blake224_close(void *cc, void *dst)
882  {
883  	sph_blake224_addbits_and_close(cc, 0, 0, dst);
884  }
885  void
886  sph_blake224_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
887  {
888  	blake32_close(cc, ub, n, dst, 7);
889  }
890  void
891  sph_blake256_init(void *cc)
892  {
893  	blake32_init(cc, IV256, salt_zero_small);
894  }
895  void
896  sph_blake256(void *cc, const void *data, size_t len)
897  {
898  	blake32(cc, data, len);
899  }
900  void
901  sph_blake256_close(void *cc, void *dst)
902  {
903  	sph_blake256_addbits_and_close(cc, 0, 0, dst);
904  }
905  void
906  sph_blake256_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
907  {
908  	blake32_close(cc, ub, n, dst, 8);
909  }
910  #if SPH_64
911  void
912  sph_blake384_init(void *cc)
913  {
914  	blake64_init(cc, IV384, salt_zero_big);
915  }
916  void
917  sph_blake384(void *cc, const void *data, size_t len)
918  {
919  	blake64(cc, data, len);
920  }
921  void
922  sph_blake384_close(void *cc, void *dst)
923  {
924  	sph_blake384_addbits_and_close(cc, 0, 0, dst);
925  }
926  void
927  sph_blake384_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
928  {
929  	blake64_close(cc, ub, n, dst, 6);
930  }
931  void
932  sph_blake512_init(void *cc)
933  {
934  	blake64_init(cc, IV512, salt_zero_big);
935  }
936  void
937  sph_blake512(void *cc, const void *data, size_t len)
938  {
939  	blake64(cc, data, len);
940  }
941  void
942  sph_blake512_close(void *cc, void *dst)
943  {
944  	sph_blake512_addbits_and_close(cc, 0, 0, dst);
945  }
946  void
947  sph_blake512_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
948  {
949  	blake64_close(cc, ub, n, dst, 8);
950  }
951  #endif
952  #ifdef __cplusplus
953  }
954  #endif
</code></pre>
        </div>
        <div class="column">
            <h3>xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-sph_blake.c</h3>
            <pre><code>1  #include <stddef.h>
2  #include <string.h>
3  #include <limits.h>
4  #include "sph_blake.h"
5  #ifdef __cplusplus
6  extern "C"{
7  #endif
8  #if SPH_SMALL_FOOTPRINT && !defined SPH_SMALL_FOOTPRINT_BLAKE
9  #define SPH_SMALL_FOOTPRINT_BLAKE   1
10  #endif
11  #if SPH_SMALL_FOOTPRINT_BLAKE
12  #define SPH_COMPACT_BLAKE_32   1
13  #endif
14  #if SPH_64 && (SPH_SMALL_FOOTPRINT_BLAKE || !SPH_64_TRUE)
15  #define SPH_COMPACT_BLAKE_64   1
16  #endif
17  #ifdef _MSC_VER
18  #pragma warning (disable: 4146)
19  #endif
20  static const sph_u32 IV224[8] = {
21  	SPH_C32(0xC1059ED8), SPH_C32(0x367CD507),
22  	SPH_C32(0x3070DD17), SPH_C32(0xF70E5939),
23  	SPH_C32(0xFFC00B31), SPH_C32(0x68581511),
24  	SPH_C32(0x64F98FA7), SPH_C32(0xBEFA4FA4)
25  };
26  static const sph_u32 IV256[8] = {
27  	SPH_C32(0x6A09E667), SPH_C32(0xBB67AE85),
28  	SPH_C32(0x3C6EF372), SPH_C32(0xA54FF53A),
29  	SPH_C32(0x510E527F), SPH_C32(0x9B05688C),
30  	SPH_C32(0x1F83D9AB), SPH_C32(0x5BE0CD19)
31  };
32  #if SPH_64
33  static const sph_u64 IV384[8] = {
34  	SPH_C64(0xCBBB9D5DC1059ED8), SPH_C64(0x629A292A367CD507),
35  	SPH_C64(0x9159015A3070DD17), SPH_C64(0x152FECD8F70E5939),
36  	SPH_C64(0x67332667FFC00B31), SPH_C64(0x8EB44A8768581511),
37  	SPH_C64(0xDB0C2E0D64F98FA7), SPH_C64(0x47B5481DBEFA4FA4)
38  };
39  static const sph_u64 IV512[8] = {
40  	SPH_C64(0x6A09E667F3BCC908), SPH_C64(0xBB67AE8584CAA73B),
41  	SPH_C64(0x3C6EF372FE94F82B), SPH_C64(0xA54FF53A5F1D36F1),
42  	SPH_C64(0x510E527FADE682D1), SPH_C64(0x9B05688C2B3E6C1F),
43  	SPH_C64(0x1F83D9ABFB41BD6B), SPH_C64(0x5BE0CD19137E2179)
44  };
45  #endif
46  #if SPH_COMPACT_BLAKE_32 || SPH_COMPACT_BLAKE_64
47  static const unsigned sigma[16][16] = {
48  	{  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15 },
49  	{ 14, 10,  4,  8,  9, 15, 13,  6,  1, 12,  0,  2, 11,  7,  5,  3 },
50  	{ 11,  8, 12,  0,  5,  2, 15, 13, 10, 14,  3,  6,  7,  1,  9,  4 },
51  	{  7,  9,  3,  1, 13, 12, 11, 14,  2,  6,  5, 10,  4,  0, 15,  8 },
52  	{  9,  0,  5,  7,  2,  4, 10, 15, 14,  1, 11, 12,  6,  8,  3, 13 },
53  	{  2, 12,  6, 10,  0, 11,  8,  3,  4, 13,  7,  5, 15, 14,  1,  9 },
54  	{ 12,  5,  1, 15, 14, 13,  4, 10,  0,  7,  6,  3,  9,  2,  8, 11 },
55  	{ 13, 11,  7, 14, 12,  1,  3,  9,  5,  0, 15,  4,  8,  6,  2, 10 },
56  	{  6, 15, 14,  9, 11,  3,  0,  8, 12,  2, 13,  7,  1,  4, 10,  5 },
57  	{ 10,  2,  8,  4,  7,  6,  1,  5, 15, 11,  9, 14,  3, 12, 13,  0 },
58  	{  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15 },
59  	{ 14, 10,  4,  8,  9, 15, 13,  6,  1, 12,  0,  2, 11,  7,  5,  3 },
60  	{ 11,  8, 12,  0,  5,  2, 15, 13, 10, 14,  3,  6,  7,  1,  9,  4 },
61  	{  7,  9,  3,  1, 13, 12, 11, 14,  2,  6,  5, 10,  4,  0, 15,  8 },
62  	{  9,  0,  5,  7,  2,  4, 10, 15, 14,  1, 11, 12,  6,  8,  3, 13 },
63  	{  2, 12,  6, 10,  0, 11,  8,  3,  4, 13,  7,  5, 15, 14,  1,  9 }
64  };
65  #endif
66  #define Z00   0
67  #define Z01   1
68  #define Z02   2
69  #define Z03   3
70  #define Z04   4
71  #define Z05   5
72  #define Z06   6
73  #define Z07   7
74  #define Z08   8
75  #define Z09   9
76  #define Z0A   A
77  #define Z0B   B
78  #define Z0C   C
79  #define Z0D   D
80  #define Z0E   E
81  #define Z0F   F
82  #define Z10   E
83  #define Z11   A
84  #define Z12   4
85  #define Z13   8
86  #define Z14   9
87  #define Z15   F
88  #define Z16   D
89  #define Z17   6
90  #define Z18   1
91  #define Z19   C
92  #define Z1A   0
93  #define Z1B   2
94  #define Z1C   B
95  #define Z1D   7
96  #define Z1E   5
97  #define Z1F   3
98  #define Z20   B
99  #define Z21   8
100  #define Z22   C
101  #define Z23   0
102  #define Z24   5
103  #define Z25   2
104  #define Z26   F
105  #define Z27   D
106  #define Z28   A
107  #define Z29   E
108  #define Z2A   3
109  #define Z2B   6
110  #define Z2C   7
111  #define Z2D   1
112  #define Z2E   9
113  #define Z2F   4
114  #define Z30   7
115  #define Z31   9
116  #define Z32   3
117  #define Z33   1
118  #define Z34   D
119  #define Z35   C
120  #define Z36   B
121  #define Z37   E
122  #define Z38   2
123  #define Z39   6
124  #define Z3A   5
125  #define Z3B   A
126  #define Z3C   4
127  #define Z3D   0
128  #define Z3E   F
129  #define Z3F   8
130  #define Z40   9
131  #define Z41   0
132  #define Z42   5
133  #define Z43   7
134  #define Z44   2
135  #define Z45   4
136  #define Z46   A
137  #define Z47   F
138  #define Z48   E
139  #define Z49   1
140  #define Z4A   B
141  #define Z4B   C
142  #define Z4C   6
143  #define Z4D   8
144  #define Z4E   3
145  #define Z4F   D
146  #define Z50   2
147  #define Z51   C
148  #define Z52   6
149  #define Z53   A
150  #define Z54   0
151  #define Z55   B
152  #define Z56   8
153  #define Z57   3
154  #define Z58   4
155  #define Z59   D
156  #define Z5A   7
157  #define Z5B   5
158  #define Z5C   F
159  #define Z5D   E
160  #define Z5E   1
161  #define Z5F   9
162  #define Z60   C
163  #define Z61   5
164  #define Z62   1
165  #define Z63   F
166  #define Z64   E
167  #define Z65   D
168  #define Z66   4
169  #define Z67   A
170  #define Z68   0
171  #define Z69   7
172  #define Z6A   6
173  #define Z6B   3
174  #define Z6C   9
175  #define Z6D   2
176  #define Z6E   8
177  #define Z6F   B
178  #define Z70   D
179  #define Z71   B
180  #define Z72   7
181  #define Z73   E
182  #define Z74   C
183  #define Z75   1
184  #define Z76   3
185  #define Z77   9
186  #define Z78   5
187  #define Z79   0
188  #define Z7A   F
189  #define Z7B   4
190  #define Z7C   8
191  #define Z7D   6
192  #define Z7E   2
193  #define Z7F   A
194  #define Z80   6
195  #define Z81   F
196  #define Z82   E
197  #define Z83   9
198  #define Z84   B
199  #define Z85   3
200  #define Z86   0
201  #define Z87   8
202  #define Z88   C
203  #define Z89   2
204  #define Z8A   D
205  #define Z8B   7
206  #define Z8C   1
207  #define Z8D   4
208  #define Z8E   A
209  #define Z8F   5
210  #define Z90   A
211  #define Z91   2
212  #define Z92   8
213  #define Z93   4
214  #define Z94   7
215  #define Z95   6
216  #define Z96   1
217  #define Z97   5
218  #define Z98   F
219  #define Z99   B
220  #define Z9A   9
221  #define Z9B   E
222  #define Z9C   3
223  #define Z9D   C
224  #define Z9E   D
225  #define Z9F   0
226  #define Mx(r, i)    Mx_(Z ## r ## i)
227  #define Mx_(n)      Mx__(n)
228  #define Mx__(n)     M ## n
229  #define CSx(r, i)   CSx_(Z ## r ## i)
230  #define CSx_(n)     CSx__(n)
231  #define CSx__(n)    CS ## n
232  #define CS0   SPH_C32(0x243F6A88)
233  #define CS1   SPH_C32(0x85A308D3)
234  #define CS2   SPH_C32(0x13198A2E)
235  #define CS3   SPH_C32(0x03707344)
236  #define CS4   SPH_C32(0xA4093822)
237  #define CS5   SPH_C32(0x299F31D0)
238  #define CS6   SPH_C32(0x082EFA98)
239  #define CS7   SPH_C32(0xEC4E6C89)
240  #define CS8   SPH_C32(0x452821E6)
241  #define CS9   SPH_C32(0x38D01377)
242  #define CSA   SPH_C32(0xBE5466CF)
243  #define CSB   SPH_C32(0x34E90C6C)
244  #define CSC   SPH_C32(0xC0AC29B7)
245  #define CSD   SPH_C32(0xC97C50DD)
246  #define CSE   SPH_C32(0x3F84D5B5)
247  #define CSF   SPH_C32(0xB5470917)
248  #if SPH_COMPACT_BLAKE_32
249  static const sph_u32 CS[16] = {
250  	SPH_C32(0x243F6A88), SPH_C32(0x85A308D3),
251  	SPH_C32(0x13198A2E), SPH_C32(0x03707344),
252  	SPH_C32(0xA4093822), SPH_C32(0x299F31D0),
253  	SPH_C32(0x082EFA98), SPH_C32(0xEC4E6C89),
254  	SPH_C32(0x452821E6), SPH_C32(0x38D01377),
255  	SPH_C32(0xBE5466CF), SPH_C32(0x34E90C6C),
256  	SPH_C32(0xC0AC29B7), SPH_C32(0xC97C50DD),
257  	SPH_C32(0x3F84D5B5), SPH_C32(0xB5470917)
258  };
259  #endif
260  #if SPH_64
261  #define CBx(r, i)   CBx_(Z ## r ## i)
262  #define CBx_(n)     CBx__(n)
263  #define CBx__(n)    CB ## n
264  #define CB0   SPH_C64(0x243F6A8885A308D3)
265  #define CB1   SPH_C64(0x13198A2E03707344)
266  #define CB2   SPH_C64(0xA4093822299F31D0)
267  #define CB3   SPH_C64(0x082EFA98EC4E6C89)
268  #define CB4   SPH_C64(0x452821E638D01377)
269  #define CB5   SPH_C64(0xBE5466CF34E90C6C)
270  #define CB6   SPH_C64(0xC0AC29B7C97C50DD)
271  #define CB7   SPH_C64(0x3F84D5B5B5470917)
272  #define CB8   SPH_C64(0x9216D5D98979FB1B)
273  #define CB9   SPH_C64(0xD1310BA698DFB5AC)
274  #define CBA   SPH_C64(0x2FFD72DBD01ADFB7)
275  #define CBB   SPH_C64(0xB8E1AFED6A267E96)
276  #define CBC   SPH_C64(0xBA7C9045F12C7F99)
277  #define CBD   SPH_C64(0x24A19947B3916CF7)
278  #define CBE   SPH_C64(0x0801F2E2858EFC16)
279  #define CBF   SPH_C64(0x636920D871574E69)
280  #if SPH_COMPACT_BLAKE_64
281  static const sph_u64 CB[16] = {
282  	SPH_C64(0x243F6A8885A308D3), SPH_C64(0x13198A2E03707344),
283  	SPH_C64(0xA4093822299F31D0), SPH_C64(0x082EFA98EC4E6C89),
284  	SPH_C64(0x452821E638D01377), SPH_C64(0xBE5466CF34E90C6C),
285  	SPH_C64(0xC0AC29B7C97C50DD), SPH_C64(0x3F84D5B5B5470917),
286  	SPH_C64(0x9216D5D98979FB1B), SPH_C64(0xD1310BA698DFB5AC),
287  	SPH_C64(0x2FFD72DBD01ADFB7), SPH_C64(0xB8E1AFED6A267E96),
288  	SPH_C64(0xBA7C9045F12C7F99), SPH_C64(0x24A19947B3916CF7),
289  	SPH_C64(0x0801F2E2858EFC16), SPH_C64(0x636920D871574E69)
290  };
291  #endif
292  #endif
293  #define GS(m0, m1, c0, c1, a, b, c, d)   do { \
294  		a = SPH_T32(a + b + (m0 ^ c1)); \
295  		d = SPH_ROTR32(d ^ a, 16); \
296  		c = SPH_T32(c + d); \
297  		b = SPH_ROTR32(b ^ c, 12); \
298  		a = SPH_T32(a + b + (m1 ^ c0)); \
299  		d = SPH_ROTR32(d ^ a, 8); \
300  		c = SPH_T32(c + d); \
301  		b = SPH_ROTR32(b ^ c, 7); \
302  	} while (0)
303  #if SPH_COMPACT_BLAKE_32
304  #define ROUND_S(r)   do { \
305  		GS(M[sigma[r][0x0]], M[sigma[r][0x1]], \
306  			CS[sigma[r][0x0]], CS[sigma[r][0x1]], V0, V4, V8, VC); \
307  		GS(M[sigma[r][0x2]], M[sigma[r][0x3]], \
308  			CS[sigma[r][0x2]], CS[sigma[r][0x3]], V1, V5, V9, VD); \
309  		GS(M[sigma[r][0x4]], M[sigma[r][0x5]], \
310  			CS[sigma[r][0x4]], CS[sigma[r][0x5]], V2, V6, VA, VE); \
311  		GS(M[sigma[r][0x6]], M[sigma[r][0x7]], \
312  			CS[sigma[r][0x6]], CS[sigma[r][0x7]], V3, V7, VB, VF); \
313  		GS(M[sigma[r][0x8]], M[sigma[r][0x9]], \
314  			CS[sigma[r][0x8]], CS[sigma[r][0x9]], V0, V5, VA, VF); \
315  		GS(M[sigma[r][0xA]], M[sigma[r][0xB]], \
316  			CS[sigma[r][0xA]], CS[sigma[r][0xB]], V1, V6, VB, VC); \
317  		GS(M[sigma[r][0xC]], M[sigma[r][0xD]], \
318  			CS[sigma[r][0xC]], CS[sigma[r][0xD]], V2, V7, V8, VD); \
319  		GS(M[sigma[r][0xE]], M[sigma[r][0xF]], \
320  			CS[sigma[r][0xE]], CS[sigma[r][0xF]], V3, V4, V9, VE); \
321  	} while (0)
322  #else
323  #define ROUND_S(r)   do { \
324  		GS(Mx(r, 0), Mx(r, 1), CSx(r, 0), CSx(r, 1), V0, V4, V8, VC); \
325  		GS(Mx(r, 2), Mx(r, 3), CSx(r, 2), CSx(r, 3), V1, V5, V9, VD); \
326  		GS(Mx(r, 4), Mx(r, 5), CSx(r, 4), CSx(r, 5), V2, V6, VA, VE); \
327  		GS(Mx(r, 6), Mx(r, 7), CSx(r, 6), CSx(r, 7), V3, V7, VB, VF); \
328  		GS(Mx(r, 8), Mx(r, 9), CSx(r, 8), CSx(r, 9), V0, V5, VA, VF); \
329  		GS(Mx(r, A), Mx(r, B), CSx(r, A), CSx(r, B), V1, V6, VB, VC); \
330  		GS(Mx(r, C), Mx(r, D), CSx(r, C), CSx(r, D), V2, V7, V8, VD); \
331  		GS(Mx(r, E), Mx(r, F), CSx(r, E), CSx(r, F), V3, V4, V9, VE); \
332  	} while (0)
333  #endif
334  #if SPH_64
335  #define GB(m0, m1, c0, c1, a, b, c, d)   do { \
336  		a = SPH_T64(a + b + (m0 ^ c1)); \
337  		d = SPH_ROTR64(d ^ a, 32); \
338  		c = SPH_T64(c + d); \
339  		b = SPH_ROTR64(b ^ c, 25); \
340  		a = SPH_T64(a + b + (m1 ^ c0)); \
341  		d = SPH_ROTR64(d ^ a, 16); \
342  		c = SPH_T64(c + d); \
343  		b = SPH_ROTR64(b ^ c, 11); \
344  	} while (0)
345  #if SPH_COMPACT_BLAKE_64
346  #define ROUND_B(r)   do { \
347  		GB(M[sigma[r][0x0]], M[sigma[r][0x1]], \
348  			CB[sigma[r][0x0]], CB[sigma[r][0x1]], V0, V4, V8, VC); \
349  		GB(M[sigma[r][0x2]], M[sigma[r][0x3]], \
350  			CB[sigma[r][0x2]], CB[sigma[r][0x3]], V1, V5, V9, VD); \
351  		GB(M[sigma[r][0x4]], M[sigma[r][0x5]], \
352  			CB[sigma[r][0x4]], CB[sigma[r][0x5]], V2, V6, VA, VE); \
353  		GB(M[sigma[r][0x6]], M[sigma[r][0x7]], \
354  			CB[sigma[r][0x6]], CB[sigma[r][0x7]], V3, V7, VB, VF); \
355  		GB(M[sigma[r][0x8]], M[sigma[r][0x9]], \
356  			CB[sigma[r][0x8]], CB[sigma[r][0x9]], V0, V5, VA, VF); \
357  		GB(M[sigma[r][0xA]], M[sigma[r][0xB]], \
358  			CB[sigma[r][0xA]], CB[sigma[r][0xB]], V1, V6, VB, VC); \
359  		GB(M[sigma[r][0xC]], M[sigma[r][0xD]], \
360  			CB[sigma[r][0xC]], CB[sigma[r][0xD]], V2, V7, V8, VD); \
361  		GB(M[sigma[r][0xE]], M[sigma[r][0xF]], \
362  			CB[sigma[r][0xE]], CB[sigma[r][0xF]], V3, V4, V9, VE); \
363  	} while (0)
364  #else
365  #define ROUND_B(r)   do { \
366  		GB(Mx(r, 0), Mx(r, 1), CBx(r, 0), CBx(r, 1), V0, V4, V8, VC); \
367  		GB(Mx(r, 2), Mx(r, 3), CBx(r, 2), CBx(r, 3), V1, V5, V9, VD); \
368  		GB(Mx(r, 4), Mx(r, 5), CBx(r, 4), CBx(r, 5), V2, V6, VA, VE); \
369  		GB(Mx(r, 6), Mx(r, 7), CBx(r, 6), CBx(r, 7), V3, V7, VB, VF); \
370  		GB(Mx(r, 8), Mx(r, 9), CBx(r, 8), CBx(r, 9), V0, V5, VA, VF); \
371  		GB(Mx(r, A), Mx(r, B), CBx(r, A), CBx(r, B), V1, V6, VB, VC); \
372  		GB(Mx(r, C), Mx(r, D), CBx(r, C), CBx(r, D), V2, V7, V8, VD); \
373  		GB(Mx(r, E), Mx(r, F), CBx(r, E), CBx(r, F), V3, V4, V9, VE); \
374  	} while (0)
375  #endif
376  #endif
377  #define DECL_STATE32 \
378  	sph_u32 H0, H1, H2, H3, H4, H5, H6, H7; \
379  	sph_u32 S0, S1, S2, S3, T0, T1;
380  #define READ_STATE32(state)   do { \
381  		H0 = (state)->H[0]; \
382  		H1 = (state)->H[1]; \
383  		H2 = (state)->H[2]; \
384  		H3 = (state)->H[3]; \
385  		H4 = (state)->H[4]; \
386  		H5 = (state)->H[5]; \
387  		H6 = (state)->H[6]; \
388  		H7 = (state)->H[7]; \
389  		S0 = (state)->S[0]; \
390  		S1 = (state)->S[1]; \
391  		S2 = (state)->S[2]; \
392  		S3 = (state)->S[3]; \
393  		T0 = (state)->T0; \
394  		T1 = (state)->T1; \
395  	} while (0)
396  #define WRITE_STATE32(state)   do { \
397  		(state)->H[0] = H0; \
398  		(state)->H[1] = H1; \
399  		(state)->H[2] = H2; \
400  		(state)->H[3] = H3; \
401  		(state)->H[4] = H4; \
402  		(state)->H[5] = H5; \
403  		(state)->H[6] = H6; \
404  		(state)->H[7] = H7; \
405  		(state)->S[0] = S0; \
406  		(state)->S[1] = S1; \
407  		(state)->S[2] = S2; \
408  		(state)->S[3] = S3; \
409  		(state)->T0 = T0; \
410  		(state)->T1 = T1; \
411  	} while (0)
412  #ifndef BLAKE32_ROUNDS
413  #define BLAKE32_ROUNDS 14
414  #endif
415  #if SPH_COMPACT_BLAKE_32
416  #define COMPRESS32   do { \
417  		sph_u32 M[16]; \
418  		sph_u32 V0, V1, V2, V3, V4, V5, V6, V7; \
419  		sph_u32 V8, V9, VA, VB, VC, VD, VE, VF; \
420  		unsigned r; \
421  		V0 = H0; \
422  		V1 = H1; \
423  		V2 = H2; \
424  		V3 = H3; \
425  		V4 = H4; \
426  		V5 = H5; \
427  		V6 = H6; \
428  		V7 = H7; \
429  		V8 = S0 ^ CS0; \
430  		V9 = S1 ^ CS1; \
431  		VA = S2 ^ CS2; \
432  		VB = S3 ^ CS3; \
433  		VC = T0 ^ CS4; \
434  		VD = T0 ^ CS5; \
435  		VE = T1 ^ CS6; \
436  		VF = T1 ^ CS7; \
437  		M[0x0] = sph_dec32be_aligned(buf +  0); \
438  		M[0x1] = sph_dec32be_aligned(buf +  4); \
439  		M[0x2] = sph_dec32be_aligned(buf +  8); \
440  		M[0x3] = sph_dec32be_aligned(buf + 12); \
441  		M[0x4] = sph_dec32be_aligned(buf + 16); \
442  		M[0x5] = sph_dec32be_aligned(buf + 20); \
443  		M[0x6] = sph_dec32be_aligned(buf + 24); \
444  		M[0x7] = sph_dec32be_aligned(buf + 28); \
445  		M[0x8] = sph_dec32be_aligned(buf + 32); \
446  		M[0x9] = sph_dec32be_aligned(buf + 36); \
447  		M[0xA] = sph_dec32be_aligned(buf + 40); \
448  		M[0xB] = sph_dec32be_aligned(buf + 44); \
449  		M[0xC] = sph_dec32be_aligned(buf + 48); \
450  		M[0xD] = sph_dec32be_aligned(buf + 52); \
451  		M[0xE] = sph_dec32be_aligned(buf + 56); \
452  		M[0xF] = sph_dec32be_aligned(buf + 60); \
453  		for (r = 0; r < BLAKE32_ROUNDS; r ++) \
454  			ROUND_S(r); \
455  		H0 ^= S0 ^ V0 ^ V8; \
456  		H1 ^= S1 ^ V1 ^ V9; \
457  		H2 ^= S2 ^ V2 ^ VA; \
458  		H3 ^= S3 ^ V3 ^ VB; \
459  		H4 ^= S0 ^ V4 ^ VC; \
460  		H5 ^= S1 ^ V5 ^ VD; \
461  		H6 ^= S2 ^ V6 ^ VE; \
462  		H7 ^= S3 ^ V7 ^ VF; \
463  	} while (0)
464  #else
465  #define COMPRESS32   do { \
466  		sph_u32 M0, M1, M2, M3, M4, M5, M6, M7; \
467  		sph_u32 M8, M9, MA, MB, MC, MD, ME, MF; \
468  		sph_u32 V0, V1, V2, V3, V4, V5, V6, V7; \
469  		sph_u32 V8, V9, VA, VB, VC, VD, VE, VF; \
470  		V0 = H0; \
471  		V1 = H1; \
472  		V2 = H2; \
473  		V3 = H3; \
474  		V4 = H4; \
475  		V5 = H5; \
476  		V6 = H6; \
477  		V7 = H7; \
478  		V8 = S0 ^ CS0; \
479  		V9 = S1 ^ CS1; \
480  		VA = S2 ^ CS2; \
481  		VB = S3 ^ CS3; \
482  		VC = T0 ^ CS4; \
483  		VD = T0 ^ CS5; \
484  		VE = T1 ^ CS6; \
485  		VF = T1 ^ CS7; \
486  		M0 = sph_dec32be_aligned(buf +  0); \
487  		M1 = sph_dec32be_aligned(buf +  4); \
488  		M2 = sph_dec32be_aligned(buf +  8); \
489  		M3 = sph_dec32be_aligned(buf + 12); \
490  		M4 = sph_dec32be_aligned(buf + 16); \
491  		M5 = sph_dec32be_aligned(buf + 20); \
492  		M6 = sph_dec32be_aligned(buf + 24); \
493  		M7 = sph_dec32be_aligned(buf + 28); \
494  		M8 = sph_dec32be_aligned(buf + 32); \
495  		M9 = sph_dec32be_aligned(buf + 36); \
496  		MA = sph_dec32be_aligned(buf + 40); \
497  		MB = sph_dec32be_aligned(buf + 44); \
498  		MC = sph_dec32be_aligned(buf + 48); \
499  		MD = sph_dec32be_aligned(buf + 52); \
500  		ME = sph_dec32be_aligned(buf + 56); \
501  		MF = sph_dec32be_aligned(buf + 60); \
502  		ROUND_S(0); \
503  		ROUND_S(1); \
504  		ROUND_S(2); \
505  		ROUND_S(3); \
506  		ROUND_S(4); \
507  		ROUND_S(5); \
508  		ROUND_S(6); \
509  		ROUND_S(7); \
510  		if (BLAKE32_ROUNDS == 14) { \
511  		ROUND_S(8); \
512  		ROUND_S(9); \
513  		ROUND_S(0); \
514  		ROUND_S(1); \
515  		ROUND_S(2); \
516  		ROUND_S(3); \
517  		} \
518  		H0 ^= S0 ^ V0 ^ V8; \
519  		H1 ^= S1 ^ V1 ^ V9; \
520  		H2 ^= S2 ^ V2 ^ VA; \
521  		H3 ^= S3 ^ V3 ^ VB; \
522  		H4 ^= S0 ^ V4 ^ VC; \
523  		H5 ^= S1 ^ V5 ^ VD; \
524  		H6 ^= S2 ^ V6 ^ VE; \
525  		H7 ^= S3 ^ V7 ^ VF; \
526  	} while (0)
527  #endif
528  #if SPH_64
529  #define DECL_STATE64 \
530  	sph_u64 H0, H1, H2, H3, H4, H5, H6, H7; \
531  	sph_u64 S0, S1, S2, S3, T0, T1;
532  #define READ_STATE64(state)   do { \
533  		H0 = (state)->H[0]; \
534  		H1 = (state)->H[1]; \
535  		H2 = (state)->H[2]; \
536  		H3 = (state)->H[3]; \
537  		H4 = (state)->H[4]; \
538  		H5 = (state)->H[5]; \
539  		H6 = (state)->H[6]; \
540  		H7 = (state)->H[7]; \
541  		S0 = (state)->S[0]; \
542  		S1 = (state)->S[1]; \
543  		S2 = (state)->S[2]; \
544  		S3 = (state)->S[3]; \
545  		T0 = (state)->T0; \
546  		T1 = (state)->T1; \
547  	} while (0)
548  #define WRITE_STATE64(state)   do { \
549  		(state)->H[0] = H0; \
550  		(state)->H[1] = H1; \
551  		(state)->H[2] = H2; \
552  		(state)->H[3] = H3; \
553  		(state)->H[4] = H4; \
554  		(state)->H[5] = H5; \
555  		(state)->H[6] = H6; \
556  		(state)->H[7] = H7; \
557  		(state)->S[0] = S0; \
558  		(state)->S[1] = S1; \
559  		(state)->S[2] = S2; \
560  		(state)->S[3] = S3; \
561  		(state)->T0 = T0; \
562  		(state)->T1 = T1; \
563  	} while (0)
564  #if SPH_COMPACT_BLAKE_64
565  #define COMPRESS64   do { \
566  		sph_u64 M[16]; \
567  		sph_u64 V0, V1, V2, V3, V4, V5, V6, V7; \
568  		sph_u64 V8, V9, VA, VB, VC, VD, VE, VF; \
569  		unsigned r; \
570  		V0 = H0; \
571  		V1 = H1; \
572  		V2 = H2; \
573  		V3 = H3; \
574  		V4 = H4; \
575  		V5 = H5; \
576  		V6 = H6; \
577  		V7 = H7; \
578  		V8 = S0 ^ CB0; \
579  		V9 = S1 ^ CB1; \
580  		VA = S2 ^ CB2; \
581  		VB = S3 ^ CB3; \
582  		VC = T0 ^ CB4; \
583  		VD = T0 ^ CB5; \
584  		VE = T1 ^ CB6; \
585  		VF = T1 ^ CB7; \
586  		M[0x0] = sph_dec64be_aligned(buf +   0); \
587  		M[0x1] = sph_dec64be_aligned(buf +   8); \
588  		M[0x2] = sph_dec64be_aligned(buf +  16); \
589  		M[0x3] = sph_dec64be_aligned(buf +  24); \
590  		M[0x4] = sph_dec64be_aligned(buf +  32); \
591  		M[0x5] = sph_dec64be_aligned(buf +  40); \
592  		M[0x6] = sph_dec64be_aligned(buf +  48); \
593  		M[0x7] = sph_dec64be_aligned(buf +  56); \
594  		M[0x8] = sph_dec64be_aligned(buf +  64); \
595  		M[0x9] = sph_dec64be_aligned(buf +  72); \
596  		M[0xA] = sph_dec64be_aligned(buf +  80); \
597  		M[0xB] = sph_dec64be_aligned(buf +  88); \
598  		M[0xC] = sph_dec64be_aligned(buf +  96); \
599  		M[0xD] = sph_dec64be_aligned(buf + 104); \
600  		M[0xE] = sph_dec64be_aligned(buf + 112); \
601  		M[0xF] = sph_dec64be_aligned(buf + 120); \
602  		for (r = 0; r < 16; r ++) \
603  			ROUND_B(r); \
604  		H0 ^= S0 ^ V0 ^ V8; \
605  		H1 ^= S1 ^ V1 ^ V9; \
606  		H2 ^= S2 ^ V2 ^ VA; \
607  		H3 ^= S3 ^ V3 ^ VB; \
608  		H4 ^= S0 ^ V4 ^ VC; \
609  		H5 ^= S1 ^ V5 ^ VD; \
610  		H6 ^= S2 ^ V6 ^ VE; \
611  		H7 ^= S3 ^ V7 ^ VF; \
612  	} while (0)
613  #else
614  #define COMPRESS64   do { \
615  		sph_u64 M0, M1, M2, M3, M4, M5, M6, M7; \
616  		sph_u64 M8, M9, MA, MB, MC, MD, ME, MF; \
617  		sph_u64 V0, V1, V2, V3, V4, V5, V6, V7; \
618  		sph_u64 V8, V9, VA, VB, VC, VD, VE, VF; \
619  		V0 = H0; \
620  		V1 = H1; \
621  		V2 = H2; \
622  		V3 = H3; \
623  		V4 = H4; \
624  		V5 = H5; \
625  		V6 = H6; \
626  		V7 = H7; \
627  		V8 = S0 ^ CB0; \
628  		V9 = S1 ^ CB1; \
629  		VA = S2 ^ CB2; \
630  		VB = S3 ^ CB3; \
631  		VC = T0 ^ CB4; \
632  		VD = T0 ^ CB5; \
633  		VE = T1 ^ CB6; \
<span onclick='openModal()' class='match'>634  		VF = T1 ^ CB7; \
635  		M0 = sph_dec64be_aligned(buf +   0); \
636  		M1 = sph_dec64be_aligned(buf +   8); \
637  		M2 = sph_dec64be_aligned(buf +  16); \
638  		M3 = sph_dec64be_aligned(buf +  24); \
639  		M4 = sph_dec64be_aligned(buf +  32); \
640  		M5 = sph_dec64be_aligned(buf +  40); \
641  		M6 = sph_dec64be_aligned(buf +  48); \
642  		M7 = sph_dec64be_aligned(buf +  56); \
643  		M8 = sph_dec64be_aligned(buf +  64); \
644  		M9 = sph_dec64be_aligned(buf +  72); \
645  		MA = sph_dec64be_aligned(buf +  80); \
646  		MB = sph_dec64be_aligned(buf +  88); \
647  		MC = sph_dec64be_aligned(buf +  96); \
648  		MD = sph_dec64be_aligned(buf + 104); \
649  		ME = sph_dec64be_aligned(buf + 112); \
650  		MF = sph_dec64be_aligned(buf + 120); \
651  		ROUND_B(0); \
652  		ROUND_B(1); \
653  		ROUND_B(2); \
654  		ROUND_B(3); \
655  		ROUND_B(4); \
656  		ROUND_B(5); \
657  		ROUND_B(6); \
658  		ROUND_B(7); \
659  		ROUND_B(8); \
</span>660  		ROUND_B(9); \
661  		ROUND_B(0); \
662  		ROUND_B(1); \
663  		ROUND_B(2); \
664  		ROUND_B(3); \
665  		ROUND_B(4); \
666  		ROUND_B(5); \
667  		H0 ^= S0 ^ V0 ^ V8; \
668  		H1 ^= S1 ^ V1 ^ V9; \
669  		H2 ^= S2 ^ V2 ^ VA; \
670  		H3 ^= S3 ^ V3 ^ VB; \
671  		H4 ^= S0 ^ V4 ^ VC; \
672  		H5 ^= S1 ^ V5 ^ VD; \
673  		H6 ^= S2 ^ V6 ^ VE; \
674  		H7 ^= S3 ^ V7 ^ VF; \
675  	} while (0)
676  #endif
677  #endif
678  static const sph_u32 salt_zero_small[4] = { 0, 0, 0, 0 };
679  static void
680  blake32_init(sph_blake_small_context *sc,
681  	const sph_u32 *iv, const sph_u32 *salt)
682  {
683  	memcpy(sc->H, iv, 8 * sizeof(sph_u32));
684  	memcpy(sc->S, salt, 4 * sizeof(sph_u32));
685  	sc->T0 = sc->T1 = 0;
686  	sc->ptr = 0;
687  }
688  static void
689  blake32(sph_blake_small_context *sc, const void *data, size_t len)
690  {
691  	unsigned char *buf;
692  	size_t ptr;
693  	DECL_STATE32
694  	buf = sc->buf;
695  	ptr = sc->ptr;
696  	if (len < (sizeof sc->buf) - ptr) {
697  		memcpy(buf + ptr, data, len);
698  		ptr += len;
699  		sc->ptr = ptr;
700  		return;
701  	}
702  	READ_STATE32(sc);
703  	while (len > 0) {
704  		size_t clen;
705  		clen = (sizeof sc->buf) - ptr;
706  		if (clen > len)
707  			clen = len;
708  		memcpy(buf + ptr, data, clen);
709  		ptr += clen;
710  		data = (const unsigned char *)data + clen;
711  		len -= clen;
712  		if (ptr == sizeof sc->buf) {
713  			if ((T0 = SPH_T32(T0 + 512)) < 512)
714  				T1 = SPH_T32(T1 + 1);
715  			COMPRESS32;
716  			ptr = 0;
717  		}
718  	}
719  	WRITE_STATE32(sc);
720  	sc->ptr = ptr;
721  }
722  static void
723  blake32_close(sph_blake_small_context *sc,
724  	unsigned ub, unsigned n, void *dst, size_t out_size_w32)
725  {
726  	union {
727  		unsigned char buf[64];
728  		sph_u32 dummy;
729  	} u;
730  	size_t ptr, k;
731  	unsigned bit_len;
732  	unsigned z;
733  	sph_u32 th, tl;
734  	unsigned char *out;
735  	ptr = sc->ptr;
736  	bit_len = ((unsigned)ptr << 3) + n;
737  	z = 0x80 >> n;
738  	u.buf[ptr] = ((ub & -z) | z) & 0xFF;
739  	tl = sc->T0 + bit_len;
740  	th = sc->T1;
741  	if (ptr == 0 && n == 0) {
742  		sc->T0 = SPH_C32(0xFFFFFE00);
743  		sc->T1 = SPH_C32(0xFFFFFFFF);
744  	} else if (sc->T0 == 0) {
745  		sc->T0 = SPH_C32(0xFFFFFE00) + bit_len;
746  		sc->T1 = SPH_T32(sc->T1 - 1);
747  	} else {
748  		sc->T0 -= 512 - bit_len;
749  	}
750  	if (bit_len <= 446) {
751  		memset(u.buf + ptr + 1, 0, 55 - ptr);
752  		if (out_size_w32 == 8)
753  			u.buf[55] |= 1;
754  		sph_enc32be_aligned(u.buf + 56, th);
755  		sph_enc32be_aligned(u.buf + 60, tl);
756  		blake32(sc, u.buf + ptr, 64 - ptr);
757  	} else {
758  		memset(u.buf + ptr + 1, 0, 63 - ptr);
759  		blake32(sc, u.buf + ptr, 64 - ptr);
760  		sc->T0 = SPH_C32(0xFFFFFE00);
761  		sc->T1 = SPH_C32(0xFFFFFFFF);
762  		memset(u.buf, 0, 56);
763  		if (out_size_w32 == 8)
764  			u.buf[55] = 1;
765  		sph_enc32be_aligned(u.buf + 56, th);
766  		sph_enc32be_aligned(u.buf + 60, tl);
767  		blake32(sc, u.buf, 64);
768  	}
769          out = dst;
770          for (k = 0; k < out_size_w32; k ++)
771                  sph_enc32be(out + (k << 2), sc->H[k]);
772  }
773  #if SPH_64
774  static const sph_u64 salt_zero_big[4] = { 0, 0, 0, 0 };
775  static void
776  blake64_init(sph_blake_big_context *sc,
777  	const sph_u64 *iv, const sph_u64 *salt)
778  {
779  	memcpy(sc->H, iv, 8 * sizeof(sph_u64));
780  	memcpy(sc->S, salt, 4 * sizeof(sph_u64));
781  	sc->T0 = sc->T1 = 0;
782  	sc->ptr = 0;
783  }
784  static void
785  blake64(sph_blake_big_context *sc, const void *data, size_t len)
786  {
787  	unsigned char *buf;
788  	size_t ptr;
789  	DECL_STATE64
790  	buf = sc->buf;
791  	ptr = sc->ptr;
792  	if (len < (sizeof sc->buf) - ptr) {
793  		memcpy(buf + ptr, data, len);
794  		ptr += len;
795  		sc->ptr = ptr;
796  		return;
797  	}
798  	READ_STATE64(sc);
799  	while (len > 0) {
800  		size_t clen;
801  		clen = (sizeof sc->buf) - ptr;
802  		if (clen > len)
803  			clen = len;
804  		memcpy(buf + ptr, data, clen);
805  		ptr += clen;
806  		data = (const unsigned char *)data + clen;
807  		len -= clen;
808  		if (ptr == sizeof sc->buf) {
809  			if ((T0 = SPH_T64(T0 + 1024)) < 1024)
810  				T1 = SPH_T64(T1 + 1);
811  			COMPRESS64;
812  			ptr = 0;
813  		}
814  	}
815  	WRITE_STATE64(sc);
816  	sc->ptr = ptr;
817  }
818  static void
819  blake64_close(sph_blake_big_context *sc,
820  	unsigned ub, unsigned n, void *dst, size_t out_size_w64)
821  {
822  	union {
823  		unsigned char buf[128];
824  		sph_u64 dummy;
825  	} u;
826  	size_t ptr, k;
827  	unsigned bit_len;
828  	unsigned z;
829  	sph_u64 th, tl;
830  	unsigned char *out;
831  	ptr = sc->ptr;
832  	bit_len = ((unsigned)ptr << 3) + n;
833  	z = 0x80 >> n;
834  	u.buf[ptr] = ((ub & -z) | z) & 0xFF;
835  	tl = sc->T0 + bit_len;
836  	th = sc->T1;
837  	if (ptr == 0 && n == 0) {
838  		sc->T0 = SPH_C64(0xFFFFFFFFFFFFFC00);
839  		sc->T1 = SPH_C64(0xFFFFFFFFFFFFFFFF);
840  	} else if (sc->T0 == 0) {
841  		sc->T0 = SPH_C64(0xFFFFFFFFFFFFFC00) + bit_len;
842  		sc->T1 = SPH_T64(sc->T1 - 1);
843  	} else {
844  		sc->T0 -= 1024 - bit_len;
845  	}
846  	if (bit_len <= 894) {
847  		memset(u.buf + ptr + 1, 0, 111 - ptr);
848  		if (out_size_w64 == 8)
849  			u.buf[111] |= 1;
850  		sph_enc64be_aligned(u.buf + 112, th);
851  		sph_enc64be_aligned(u.buf + 120, tl);
852  		blake64(sc, u.buf + ptr, 128 - ptr);
853  	} else {
854  		memset(u.buf + ptr + 1, 0, 127 - ptr);
855  		blake64(sc, u.buf + ptr, 128 - ptr);
856  		sc->T0 = SPH_C64(0xFFFFFFFFFFFFFC00);
857  		sc->T1 = SPH_C64(0xFFFFFFFFFFFFFFFF);
858  		memset(u.buf, 0, 112);
859  		if (out_size_w64 == 8)
860  			u.buf[111] = 1;
861  		sph_enc64be_aligned(u.buf + 112, th);
862  		sph_enc64be_aligned(u.buf + 120, tl);
863  		blake64(sc, u.buf, 128);
864  	}
865  	out = dst;
866  	for (k = 0; k < out_size_w64; k ++)
867  		sph_enc64be(out + (k << 3), sc->H[k]);
868  }
869  #endif
870  void
871  sph_blake224_init(void *cc)
872  {
873  	blake32_init(cc, IV224, salt_zero_small);
874  }
875  void
876  sph_blake224(void *cc, const void *data, size_t len)
877  {
878  	blake32(cc, data, len);
879  }
880  void
881  sph_blake224_close(void *cc, void *dst)
882  {
883  	sph_blake224_addbits_and_close(cc, 0, 0, dst);
884  }
885  void
886  sph_blake224_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
887  {
888  	blake32_close(cc, ub, n, dst, 7);
889  }
890  void
891  sph_blake256_init(void *cc)
892  {
893  	blake32_init(cc, IV256, salt_zero_small);
894  }
895  void
896  sph_blake256(void *cc, const void *data, size_t len)
897  {
898  	blake32(cc, data, len);
899  }
900  void
901  sph_blake256_close(void *cc, void *dst)
902  {
903  	sph_blake256_addbits_and_close(cc, 0, 0, dst);
904  }
905  void
906  sph_blake256_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
907  {
908  	blake32_close(cc, ub, n, dst, 8);
909  }
910  #if SPH_64
911  void
912  sph_blake384_init(void *cc)
913  {
914  	blake64_init(cc, IV384, salt_zero_big);
915  }
916  void
917  sph_blake384(void *cc, const void *data, size_t len)
918  {
919  	blake64(cc, data, len);
920  }
921  void
922  sph_blake384_close(void *cc, void *dst)
923  {
924  	sph_blake384_addbits_and_close(cc, 0, 0, dst);
925  }
926  void
927  sph_blake384_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
928  {
929  	blake64_close(cc, ub, n, dst, 6);
930  }
931  void
932  sph_blake512_init(void *cc)
933  {
934  	blake64_init(cc, IV512, salt_zero_big);
935  }
936  void
937  sph_blake512(void *cc, const void *data, size_t len)
938  {
939  	blake64(cc, data, len);
940  }
941  void
942  sph_blake512_close(void *cc, void *dst)
943  {
944  	sph_blake512_addbits_and_close(cc, 0, 0, dst);
945  }
946  void
947  sph_blake512_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
948  {
949  	blake64_close(cc, ub, n, dst, 8);
950  }
951  #endif
952  #ifdef __cplusplus
953  }
954  #endif
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-sph_blake.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-sph_blake.c</div>
                </div>
                <div class="column column_space"><pre><code>634  		VF = T1 ^ CB7; \
635  		M0 = sph_dec64be_aligned(buf +   0); \
636  		M1 = sph_dec64be_aligned(buf +   8); \
637  		M2 = sph_dec64be_aligned(buf +  16); \
638  		M3 = sph_dec64be_aligned(buf +  24); \
639  		M4 = sph_dec64be_aligned(buf +  32); \
640  		M5 = sph_dec64be_aligned(buf +  40); \
641  		M6 = sph_dec64be_aligned(buf +  48); \
642  		M7 = sph_dec64be_aligned(buf +  56); \
643  		M8 = sph_dec64be_aligned(buf +  64); \
644  		M9 = sph_dec64be_aligned(buf +  72); \
645  		MA = sph_dec64be_aligned(buf +  80); \
646  		MB = sph_dec64be_aligned(buf +  88); \
647  		MC = sph_dec64be_aligned(buf +  96); \
648  		MD = sph_dec64be_aligned(buf + 104); \
649  		ME = sph_dec64be_aligned(buf + 112); \
650  		MF = sph_dec64be_aligned(buf + 120); \
651  		ROUND_B(0); \
652  		ROUND_B(1); \
653  		ROUND_B(2); \
654  		ROUND_B(3); \
655  		ROUND_B(4); \
656  		ROUND_B(5); \
657  		ROUND_B(6); \
658  		ROUND_B(7); \
659  		ROUND_B(8); \
</pre></code></div>
                <div class="column column_space"><pre><code>634  		VF = T1 ^ CB7; \
635  		M0 = sph_dec64be_aligned(buf +   0); \
636  		M1 = sph_dec64be_aligned(buf +   8); \
637  		M2 = sph_dec64be_aligned(buf +  16); \
638  		M3 = sph_dec64be_aligned(buf +  24); \
639  		M4 = sph_dec64be_aligned(buf +  32); \
640  		M5 = sph_dec64be_aligned(buf +  40); \
641  		M6 = sph_dec64be_aligned(buf +  48); \
642  		M7 = sph_dec64be_aligned(buf +  56); \
643  		M8 = sph_dec64be_aligned(buf +  64); \
644  		M9 = sph_dec64be_aligned(buf +  72); \
645  		MA = sph_dec64be_aligned(buf +  80); \
646  		MB = sph_dec64be_aligned(buf +  88); \
647  		MC = sph_dec64be_aligned(buf +  96); \
648  		MD = sph_dec64be_aligned(buf + 104); \
649  		ME = sph_dec64be_aligned(buf + 112); \
650  		MF = sph_dec64be_aligned(buf + 120); \
651  		ROUND_B(0); \
652  		ROUND_B(1); \
653  		ROUND_B(2); \
654  		ROUND_B(3); \
655  		ROUND_B(4); \
656  		ROUND_B(5); \
657  		ROUND_B(6); \
658  		ROUND_B(7); \
659  		ROUND_B(8); \
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    