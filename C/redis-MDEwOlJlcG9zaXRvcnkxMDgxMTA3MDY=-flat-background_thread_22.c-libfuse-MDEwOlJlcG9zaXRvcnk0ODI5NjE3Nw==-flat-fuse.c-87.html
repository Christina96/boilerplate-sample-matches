
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 25, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-background_thread_22.c</h3>
            <pre><code>1  #define JEMALLOC_BACKGROUND_THREAD_C_
2  #include &quot;jemalloc/internal/jemalloc_preamble.h&quot;
3  #include &quot;jemalloc/internal/jemalloc_internal_includes.h&quot;
4  #include &quot;jemalloc/internal/assert.h&quot;
5  JEMALLOC_DIAGNOSTIC_DISABLE_SPURIOUS
6  #define BACKGROUND_THREAD_DEFAULT false
7  bool opt_background_thread = BACKGROUND_THREAD_DEFAULT;
8  size_t opt_max_background_threads = MAX_BACKGROUND_THREAD_LIMIT + 1;
9  malloc_mutex_t background_thread_lock;
10  atomic_b_t background_thread_enabled_state;
11  size_t n_background_threads;
12  size_t max_background_threads;
13  background_thread_info_t *background_thread_info;
14  #ifdef JEMALLOC_PTHREAD_CREATE_WRAPPER
15  static int (*pthread_create_fptr)(pthread_t *__restrict, const pthread_attr_t *,
16      void *(*)(void *), void *__restrict);
17  static void
18  pthread_create_wrapper_init(void) {
19  #ifdef JEMALLOC_LAZY_LOCK
20  	if (!isthreaded) {
21  		isthreaded = true;
22  	}
23  #endif
24  }
25  int
26  pthread_create_wrapper(pthread_t *__restrict thread, const pthread_attr_t *attr,
27      void *(*start_routine)(void *), void *__restrict arg) {
28  	pthread_create_wrapper_init();
29  	return pthread_create_fptr(thread, attr, start_routine, arg);
30  }
31  #endif &amp;bsol;* JEMALLOC_PTHREAD_CREATE_WRAPPER */
32  #ifndef JEMALLOC_BACKGROUND_THREAD
33  #define NOT_REACHED { not_reached(); }
34  bool background_thread_create(tsd_t *tsd, unsigned arena_ind) NOT_REACHED
35  bool background_threads_enable(tsd_t *tsd) NOT_REACHED
36  bool background_threads_disable(tsd_t *tsd) NOT_REACHED
37  void background_thread_interval_check(tsdn_t *tsdn, arena_t *arena,
38      arena_decay_t *decay, size_t npages_new) NOT_REACHED
39  void background_thread_prefork0(tsdn_t *tsdn) NOT_REACHED
40  void background_thread_prefork1(tsdn_t *tsdn) NOT_REACHED
41  void background_thread_postfork_parent(tsdn_t *tsdn) NOT_REACHED
42  void background_thread_postfork_child(tsdn_t *tsdn) NOT_REACHED
43  bool background_thread_stats_read(tsdn_t *tsdn,
44      background_thread_stats_t *stats) NOT_REACHED
45  void background_thread_ctl_init(tsdn_t *tsdn) NOT_REACHED
46  #undef NOT_REACHED
47  #else
48  static bool background_thread_enabled_at_fork;
49  static void
50  background_thread_info_init(tsdn_t *tsdn, background_thread_info_t *info) {
51  	background_thread_wakeup_time_set(tsdn, info, 0);
52  	info-&gt;npages_to_purge_new = 0;
53  	if (config_stats) {
54  		info-&gt;tot_n_runs = 0;
55  		nstime_init(&amp;info-&gt;tot_sleep_time, 0);
56  	}
57  }
58  static inline bool
59  set_current_thread_affinity(int cpu) {
60  #if defined(JEMALLOC_HAVE_SCHED_SETAFFINITY)
61  	cpu_set_t cpuset;
62  	CPU_ZERO(&amp;cpuset);
63  	CPU_SET(cpu, &amp;cpuset);
64  	int ret = sched_setaffinity(0, sizeof(cpu_set_t), &amp;cpuset);
65  	return (ret != 0);
66  #else
67  	return false;
68  #endif
69  }
70  #define BACKGROUND_THREAD_NPAGES_THRESHOLD UINT64_C(1024)
71  #define BILLION UINT64_C(1000000000)
72  #define BACKGROUND_THREAD_MIN_INTERVAL_NS (BILLION / 10)
73  static inline size_t
74  decay_npurge_after_interval(arena_decay_t *decay, size_t interval) {
75  	size_t i;
76  	uint64_t sum = 0;
77  	for (i = 0; i &lt; interval; i++) {
78  		sum += decay-&gt;backlog[i] * h_steps[i];
79  	}
80  	for (; i &lt; SMOOTHSTEP_NSTEPS; i++) {
81  		sum += decay-&gt;backlog[i] * (h_steps[i] - h_steps[i - interval]);
82  	}
83  	return (size_t)(sum &gt;&gt; SMOOTHSTEP_BFP);
84  }
85  static uint64_t
86  arena_decay_compute_purge_interval_impl(tsdn_t *tsdn, arena_decay_t *decay,
87      extents_t *extents) {
88  	if (malloc_mutex_trylock(tsdn, &amp;decay-&gt;mtx)) {
89  		return BACKGROUND_THREAD_MIN_INTERVAL_NS;
90  	}
91  	uint64_t interval;
92  	ssize_t decay_time = atomic_load_zd(&amp;decay-&gt;time_ms, ATOMIC_RELAXED);
93  	if (decay_time &lt;= 0) {
94  		interval = BACKGROUND_THREAD_INDEFINITE_SLEEP;
95  		goto label_done;
96  	}
97  	uint64_t decay_interval_ns = nstime_ns(&amp;decay-&gt;interval);
98  	assert(decay_interval_ns &gt; 0);
99  	size_t npages = extents_npages_get(extents);
100  	if (npages == 0) {
101  		unsigned i;
102  		for (i = 0; i &lt; SMOOTHSTEP_NSTEPS; i++) {
103  			if (decay-&gt;backlog[i] &gt; 0) {
104  				break;
105  			}
106  		}
107  		if (i == SMOOTHSTEP_NSTEPS) {
108  			interval = BACKGROUND_THREAD_INDEFINITE_SLEEP;
109  			goto label_done;
110  		}
111  	}
112  	if (npages &lt;= BACKGROUND_THREAD_NPAGES_THRESHOLD) {
113  		interval = decay_interval_ns * SMOOTHSTEP_NSTEPS;
114  		goto label_done;
115  	}
116  	size_t lb = BACKGROUND_THREAD_MIN_INTERVAL_NS / decay_interval_ns;
117  	size_t ub = SMOOTHSTEP_NSTEPS;
118  	lb = (lb &lt; 2) ? 2 : lb;
119  	if ((decay_interval_ns * ub &lt;= BACKGROUND_THREAD_MIN_INTERVAL_NS) ||
120  	    (lb + 2 &gt; ub)) {
121  		interval = BACKGROUND_THREAD_MIN_INTERVAL_NS;
122  		goto label_done;
123  	}
124  	assert(lb + 2 &lt;= ub);
125  	size_t npurge_lb, npurge_ub;
126  	npurge_lb = decay_npurge_after_interval(decay, lb);
127  	if (npurge_lb &gt; BACKGROUND_THREAD_NPAGES_THRESHOLD) {
128  		interval = decay_interval_ns * lb;
129  		goto label_done;
130  	}
131  	npurge_ub = decay_npurge_after_interval(decay, ub);
132  	if (npurge_ub &lt; BACKGROUND_THREAD_NPAGES_THRESHOLD) {
133  		interval = decay_interval_ns * ub;
134  		goto label_done;
135  	}
136  	unsigned n_search = 0;
137  	size_t target, npurge;
138  	while ((npurge_lb + BACKGROUND_THREAD_NPAGES_THRESHOLD &lt; npurge_ub)
139  	    &amp;&amp; (lb + 2 &lt; ub)) {
140  		target = (lb + ub) / 2;
141  		npurge = decay_npurge_after_interval(decay, target);
142  		if (npurge &gt; BACKGROUND_THREAD_NPAGES_THRESHOLD) {
143  			ub = target;
144  			npurge_ub = npurge;
145  		} else {
146  			lb = target;
147  			npurge_lb = npurge;
148  		}
149  		assert(n_search++ &lt; lg_floor(SMOOTHSTEP_NSTEPS) + 1);
150  	}
151  	interval = decay_interval_ns * (ub + lb) / 2;
152  label_done:
153  	interval = (interval &lt; BACKGROUND_THREAD_MIN_INTERVAL_NS) ?
154  	    BACKGROUND_THREAD_MIN_INTERVAL_NS : interval;
155  	malloc_mutex_unlock(tsdn, &amp;decay-&gt;mtx);
156  	return interval;
157  }
158  static uint64_t
159  arena_decay_compute_purge_interval(tsdn_t *tsdn, arena_t *arena) {
160  	uint64_t i1, i2;
161  	i1 = arena_decay_compute_purge_interval_impl(tsdn, &amp;arena-&gt;decay_dirty,
162  	    &amp;arena-&gt;extents_dirty);
163  	if (i1 == BACKGROUND_THREAD_MIN_INTERVAL_NS) {
164  		return i1;
165  	}
166  	i2 = arena_decay_compute_purge_interval_impl(tsdn, &amp;arena-&gt;decay_muzzy,
167  	    &amp;arena-&gt;extents_muzzy);
168  	return i1 &lt; i2 ? i1 : i2;
169  }
170  static void
171  background_thread_sleep(tsdn_t *tsdn, background_thread_info_t *info,
172      uint64_t interval) {
173  	if (config_stats) {
174  		info-&gt;tot_n_runs++;
175  	}
176  	info-&gt;npages_to_purge_new = 0;
177  	struct timeval tv;
178  	gettimeofday(&amp;tv, NULL);
179  	nstime_t before_sleep;
180  	nstime_init2(&amp;before_sleep, tv.tv_sec, tv.tv_usec * 1000);
181  	int ret;
182  	if (interval == BACKGROUND_THREAD_INDEFINITE_SLEEP) {
183  		assert(background_thread_indefinite_sleep(info));
184  		ret = pthread_cond_wait(&amp;info-&gt;cond, &amp;info-&gt;mtx.lock);
185  		assert(ret == 0);
186  	} else {
187  		assert(interval &gt;= BACKGROUND_THREAD_MIN_INTERVAL_NS &amp;&amp;
188  		    interval &lt;= BACKGROUND_THREAD_INDEFINITE_SLEEP);
189  		nstime_t next_wakeup;
190  		nstime_init(&amp;next_wakeup, 0);
191  		nstime_update(&amp;next_wakeup);
192  		nstime_iadd(&amp;next_wakeup, interval);
193  		assert(nstime_ns(&amp;next_wakeup) &lt;
194  		    BACKGROUND_THREAD_INDEFINITE_SLEEP);
195  		background_thread_wakeup_time_set(tsdn, info,
196  		    nstime_ns(&amp;next_wakeup));
197  		nstime_t ts_wakeup;
198  		nstime_copy(&amp;ts_wakeup, &amp;before_sleep);
199  		nstime_iadd(&amp;ts_wakeup, interval);
200  		struct timespec ts;
201  		ts.tv_sec = (size_t)nstime_sec(&amp;ts_wakeup);
202  		ts.tv_nsec = (size_t)nstime_nsec(&amp;ts_wakeup);
203  		assert(!background_thread_indefinite_sleep(info));
204  		ret = pthread_cond_timedwait(&amp;info-&gt;cond, &amp;info-&gt;mtx.lock, &amp;ts);
205  		assert(ret == ETIMEDOUT || ret == 0);
206  		background_thread_wakeup_time_set(tsdn, info,
207  		    BACKGROUND_THREAD_INDEFINITE_SLEEP);
208  	}
209  	if (config_stats) {
210  		gettimeofday(&amp;tv, NULL);
211  		nstime_t after_sleep;
212  		nstime_init2(&amp;after_sleep, tv.tv_sec, tv.tv_usec * 1000);
213  		if (nstime_compare(&amp;after_sleep, &amp;before_sleep) &gt; 0) {
214  			nstime_subtract(&amp;after_sleep, &amp;before_sleep);
215  			nstime_add(&amp;info-&gt;tot_sleep_time, &amp;after_sleep);
216  		}
217  	}
218  }
219  static bool
220  background_thread_pause_check(tsdn_t *tsdn, background_thread_info_t *info) {
221  	if (unlikely(info-&gt;state == background_thread_paused)) {
222  		malloc_mutex_unlock(tsdn, &amp;info-&gt;mtx);
223  		malloc_mutex_lock(tsdn, &amp;background_thread_lock);
224  		malloc_mutex_unlock(tsdn, &amp;background_thread_lock);
225  		malloc_mutex_lock(tsdn, &amp;info-&gt;mtx);
226  		return true;
227  	}
228  	return false;
229  }
230  static inline void
231  background_work_sleep_once(tsdn_t *tsdn, background_thread_info_t *info, unsigned ind) {
232  	uint64_t min_interval = BACKGROUND_THREAD_INDEFINITE_SLEEP;
233  	unsigned narenas = narenas_total_get();
234  	for (unsigned i = ind; i &lt; narenas; i += max_background_threads) {
235  		arena_t *arena = arena_get(tsdn, i, false);
236  		if (!arena) {
237  			continue;
238  		}
239  		arena_decay(tsdn, arena, true, false);
240  		if (min_interval == BACKGROUND_THREAD_MIN_INTERVAL_NS) {
241  			continue;
242  		}
243  		uint64_t interval = arena_decay_compute_purge_interval(tsdn,
244  		    arena);
245  		assert(interval &gt;= BACKGROUND_THREAD_MIN_INTERVAL_NS);
246  		if (min_interval &gt; interval) {
247  			min_interval = interval;
248  		}
249  	}
250  	background_thread_sleep(tsdn, info, min_interval);
251  }
252  static bool
253  background_threads_disable_single(tsd_t *tsd, background_thread_info_t *info) {
254  	if (info == &amp;background_thread_info[0]) {
255  		malloc_mutex_assert_owner(tsd_tsdn(tsd),
256  		    &amp;background_thread_lock);
257  	} else {
258  		malloc_mutex_assert_not_owner(tsd_tsdn(tsd),
259  		    &amp;background_thread_lock);
260  	}
261  	pre_reentrancy(tsd, NULL);
262  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
263  	bool has_thread;
264  	assert(info-&gt;state != background_thread_paused);
265  	if (info-&gt;state == background_thread_started) {
266  		has_thread = true;
267  		info-&gt;state = background_thread_stopped;
268  		pthread_cond_signal(&amp;info-&gt;cond);
269  	} else {
270  		has_thread = false;
271  	}
272  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
273  	if (!has_thread) {
274  		post_reentrancy(tsd);
275  		return false;
276  	}
277  	void *ret;
278  	if (pthread_join(info-&gt;thread, &amp;ret)) {
279  		post_reentrancy(tsd);
280  		return true;
281  	}
282  	assert(ret == NULL);
283  	n_background_threads--;
284  	post_reentrancy(tsd);
285  	return false;
286  }
287  static void *background_thread_entry(void *ind_arg);
288  static int
289  background_thread_create_signals_masked(pthread_t *thread,
290      const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg) {
291  	sigset_t set;
292  	sigfillset(&amp;set);
293  	sigset_t oldset;
294  	int mask_err = pthread_sigmask(SIG_SETMASK, &amp;set, &amp;oldset);
295  	if (mask_err != 0) {
296  		return mask_err;
297  	}
298  	int create_err = pthread_create_wrapper(thread, attr, start_routine,
299  	    arg);
300  	int restore_err = pthread_sigmask(SIG_SETMASK, &amp;oldset, NULL);
301  	if (restore_err != 0) {
302  		malloc_printf(&quot;&lt;jemalloc&gt;: background thread creation &quot;
303  		    &quot;failed (%d), and signal mask restoration failed &quot;
304  		    &quot;(%d)\n&quot;, create_err, restore_err);
305  		if (opt_abort) {
306  			abort();
307  		}
308  	}
309  	return create_err;
310  }
311  static bool
312  check_background_thread_creation(tsd_t *tsd, unsigned *n_created,
313      bool *created_threads) {
314  	bool ret = false;
315  	if (likely(*n_created == n_background_threads)) {
316  		return ret;
317  	}
318  	tsdn_t *tsdn = tsd_tsdn(tsd);
319  	malloc_mutex_unlock(tsdn, &amp;background_thread_info[0].mtx);
320  	for (unsigned i = 1; i &lt; max_background_threads; i++) {
321  		if (created_threads[i]) {
322  			continue;
323  		}
324  		background_thread_info_t *info = &amp;background_thread_info[i];
325  		malloc_mutex_lock(tsdn, &amp;info-&gt;mtx);
326  		bool create = (info-&gt;state == background_thread_started);
327  		malloc_mutex_unlock(tsdn, &amp;info-&gt;mtx);
328  		if (!create) {
329  			continue;
330  		}
331  		pre_reentrancy(tsd, NULL);
332  		int err = background_thread_create_signals_masked(&amp;info-&gt;thread,
333  		    NULL, background_thread_entry, (void *)(uintptr_t)i);
334  		post_reentrancy(tsd);
335  		if (err == 0) {
336  			(*n_created)++;
337  			created_threads[i] = true;
338  		} else {
339  			malloc_printf(&quot;&lt;jemalloc&gt;: background thread &quot;
340  			    &quot;creation failed (%d)\n&quot;, err);
341  			if (opt_abort) {
342  				abort();
343  			}
344  		}
345  		ret = true;
346  		break;
347  	}
348  	malloc_mutex_lock(tsdn, &amp;background_thread_info[0].mtx);
349  	return ret;
350  }
351  static void
352  background_thread0_work(tsd_t *tsd) {
353  	VARIABLE_ARRAY(bool, created_threads, max_background_threads);
354  	unsigned i;
355  	for (i = 1; i &lt; max_background_threads; i++) {
356  		created_threads[i] = false;
357  	}
358  	unsigned n_created = 1;
359  	while (background_thread_info[0].state != background_thread_stopped) {
360  		if (background_thread_pause_check(tsd_tsdn(tsd),
361  		    &amp;background_thread_info[0])) {
362  			continue;
363  		}
364  		if (check_background_thread_creation(tsd, &amp;n_created,
365  		    (bool *)&amp;created_threads)) {
366  			continue;
367  		}
368  		background_work_sleep_once(tsd_tsdn(tsd),
369  		    &amp;background_thread_info[0], 0);
370  	}
371  	assert(!background_thread_enabled());
372  	for (i = 1; i &lt; max_background_threads; i++) {
373  		background_thread_info_t *info = &amp;background_thread_info[i];
374  		assert(info-&gt;state != background_thread_paused);
375  		if (created_threads[i]) {
376  			background_threads_disable_single(tsd, info);
377  		} else {
378  			malloc_mutex_lock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
379  			if (info-&gt;state != background_thread_stopped) {
380  				assert(info-&gt;state ==
381  				    background_thread_started);
382  				n_background_threads--;
383  				info-&gt;state = background_thread_stopped;
384  			}
385  			malloc_mutex_unlock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
386  		}
387  	}
388  	background_thread_info[0].state = background_thread_stopped;
389  	assert(n_background_threads == 1);
390  }
391  static void
392  background_work(tsd_t *tsd, unsigned ind) {
393  	background_thread_info_t *info = &amp;background_thread_info[ind];
394  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
395  	background_thread_wakeup_time_set(tsd_tsdn(tsd), info,
396  	    BACKGROUND_THREAD_INDEFINITE_SLEEP);
397  	if (ind == 0) {
398  		background_thread0_work(tsd);
399  	} else {
400  		while (info-&gt;state != background_thread_stopped) {
401  			if (background_thread_pause_check(tsd_tsdn(tsd),
402  			    info)) {
403  				continue;
404  			}
405  			background_work_sleep_once(tsd_tsdn(tsd), info, ind);
406  		}
407  	}
408  	assert(info-&gt;state == background_thread_stopped);
409  	background_thread_wakeup_time_set(tsd_tsdn(tsd), info, 0);
410  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
411  }
412  static void *
413  background_thread_entry(void *ind_arg) {
414  	unsigned thread_ind = (unsigned)(uintptr_t)ind_arg;
415  	assert(thread_ind &lt; max_background_threads);
416  #ifdef JEMALLOC_HAVE_PTHREAD_SETNAME_NP
417  	pthread_setname_np(pthread_self(), &quot;jemalloc_bg_thd&quot;);
418  #elif defined(__FreeBSD__)
419  	pthread_set_name_np(pthread_self(), &quot;jemalloc_bg_thd&quot;);
420  #endif
421  	if (opt_percpu_arena != percpu_arena_disabled) {
422  		set_current_thread_affinity((int)thread_ind);
423  	}
424  	background_work(tsd_internal_fetch(), thread_ind);
425  	assert(pthread_equal(pthread_self(),
426  	    background_thread_info[thread_ind].thread));
427  	return NULL;
428  }
429  static void
430  background_thread_init(tsd_t *tsd, background_thread_info_t *info) {
431  	malloc_mutex_assert_owner(tsd_tsdn(tsd), &amp;background_thread_lock);
432  	info-&gt;state = background_thread_started;
433  	background_thread_info_init(tsd_tsdn(tsd), info);
434  	n_background_threads++;
435  }
436  static bool
437  background_thread_create_locked(tsd_t *tsd, unsigned arena_ind) {
438  	assert(have_background_thread);
439  	malloc_mutex_assert_owner(tsd_tsdn(tsd), &amp;background_thread_lock);
440  	size_t thread_ind = arena_ind % max_background_threads;
441  	background_thread_info_t *info = &amp;background_thread_info[thread_ind];
442  	bool need_new_thread;
443  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
444  	need_new_thread = background_thread_enabled() &amp;&amp;
445  	    (info-&gt;state == background_thread_stopped);
446  	if (need_new_thread) {
447  		background_thread_init(tsd, info);
448  	}
449  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
450  	if (!need_new_thread) {
451  		return false;
452  	}
453  	if (arena_ind != 0) {
454  		background_thread_info_t *t0 = &amp;background_thread_info[0];
455  		malloc_mutex_lock(tsd_tsdn(tsd), &amp;t0-&gt;mtx);
456  		assert(t0-&gt;state == background_thread_started);
457  		pthread_cond_signal(&amp;t0-&gt;cond);
458  		malloc_mutex_unlock(tsd_tsdn(tsd), &amp;t0-&gt;mtx);
459  		return false;
460  	}
461  	pre_reentrancy(tsd, NULL);
462  	int err = background_thread_create_signals_masked(&amp;info-&gt;thread, NULL,
463  	    background_thread_entry, (void *)thread_ind);
464  	post_reentrancy(tsd);
465  	if (err != 0) {
466  		malloc_printf(&quot;&lt;jemalloc&gt;: arena 0 background thread creation &quot;
467  		    &quot;failed (%d)\n&quot;, err);
468  		malloc_mutex_lock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
469  		info-&gt;state = background_thread_stopped;
470  		n_background_threads--;
471  		malloc_mutex_unlock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
472  		return true;
473  	}
474  	return false;
475  }
476  bool
477  background_thread_create(tsd_t *tsd, unsigned arena_ind) {
478  	assert(have_background_thread);
479  	bool ret;
480  	malloc_mutex_lock(tsd_tsdn(tsd), &amp;background_thread_lock);
481  	ret = background_thread_create_locked(tsd, arena_ind);
482  	malloc_mutex_unlock(tsd_tsdn(tsd), &amp;background_thread_lock);
483  	return ret;
484  }
485  bool
486  background_threads_enable(tsd_t *tsd) {
487  	assert(n_background_threads == 0);
488  	assert(background_thread_enabled());
489  	malloc_mutex_assert_owner(tsd_tsdn(tsd), &amp;background_thread_lock);
490  	VARIABLE_ARRAY(bool, marked, max_background_threads);
491  	unsigned i, nmarked;
492  	for (i = 0; i &lt; max_background_threads; i++) {
493  		marked[i] = false;
494  	}
495  	nmarked = 0;
496  	marked[0] = true;
497  	unsigned n = narenas_total_get();
498  	for (i = 1; i &lt; n; i++) {
499  		if (marked[i % max_background_threads] ||
500  		    arena_get(tsd_tsdn(tsd), i, false) == NULL) {
501  			continue;
502  		}
503  		background_thread_info_t *info = &amp;background_thread_info[
504  		    i % max_background_threads];
505  		malloc_mutex_lock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
506  		assert(info-&gt;state == background_thread_stopped);
507  		background_thread_init(tsd, info);
508  		malloc_mutex_unlock(tsd_tsdn(tsd), &amp;info-&gt;mtx);
509  		marked[i % max_background_threads] = true;
510  		if (++nmarked == max_background_threads) {
511  			break;
512  		}
513  	}
514  	return background_thread_create_locked(tsd, 0);
515  }
516  bool
517  background_threads_disable(tsd_t *tsd) {
518  	assert(!background_thread_enabled());
519  	malloc_mutex_assert_owner(tsd_tsdn(tsd), &amp;background_thread_lock);
520  	if (background_threads_disable_single(tsd,
521  	    &amp;background_thread_info[0])) {
522  		return true;
523  	}
524  	assert(n_background_threads == 0);
525  	return false;
526  }
527  void
528  background_thread_interval_check(tsdn_t *tsdn, arena_t *arena,
529      arena_decay_t *decay, size_t npages_new) {
530  	background_thread_info_t *info = arena_background_thread_info_get(
531  	    arena);
532  	if (malloc_mutex_trylock(tsdn, &amp;info-&gt;mtx)) {
533  		return;
534  	}
535  	if (info-&gt;state != background_thread_started) {
536  		goto label_done;
537  	}
538  	if (malloc_mutex_trylock(tsdn, &amp;decay-&gt;mtx)) {
539  		goto label_done;
540  	}
541  	ssize_t decay_time = atomic_load_zd(&amp;decay-&gt;time_ms, ATOMIC_RELAXED);
542  	if (decay_time &lt;= 0) {
543  		goto label_done_unlock2;
544  	}
545  	uint64_t decay_interval_ns = nstime_ns(&amp;decay-&gt;interval);
546  	assert(decay_interval_ns &gt; 0);
547  	nstime_t diff;
548  	nstime_init(&amp;diff, background_thread_wakeup_time_get(info));
549  	if (nstime_compare(&amp;diff, &amp;decay-&gt;epoch) &lt;= 0) {
550  		goto label_done_unlock2;
551  	}
552  	nstime_subtract(&amp;diff, &amp;decay-&gt;epoch);
553  	if (nstime_ns(&amp;diff) &lt; BACKGROUND_THREAD_MIN_INTERVAL_NS) {
554  		goto label_done_unlock2;
555  	}
556  	if (npages_new &gt; 0) {
557  		size_t n_epoch = (size_t)(nstime_ns(&amp;diff) / decay_interval_ns);
558  		uint64_t npurge_new;
559  		if (n_epoch &gt;= SMOOTHSTEP_NSTEPS) {
560  			npurge_new = npages_new;
561  		} else {
562  			uint64_t h_steps_max = h_steps[SMOOTHSTEP_NSTEPS - 1];
563  			assert(h_steps_max &gt;=
564  			    h_steps[SMOOTHSTEP_NSTEPS - 1 - n_epoch]);
565  			npurge_new = npages_new * (h_steps_max -
566  			    h_steps[SMOOTHSTEP_NSTEPS - 1 - n_epoch]);
567  			npurge_new &gt;&gt;= SMOOTHSTEP_BFP;
568  		}
569  		info-&gt;npages_to_purge_new += npurge_new;
570  	}
571  	bool should_signal;
572  	if (info-&gt;npages_to_purge_new &gt; BACKGROUND_THREAD_NPAGES_THRESHOLD) {
573  		should_signal = true;
574  	} else if (unlikely(background_thread_indefinite_sleep(info)) &amp;&amp;
575  	    (extents_npages_get(&amp;arena-&gt;extents_dirty) &gt; 0 ||
576  	    extents_npages_get(&amp;arena-&gt;extents_muzzy) &gt; 0 ||
577  	    info-&gt;npages_to_purge_new &gt; 0)) {
578  		should_signal = true;
579  	} else {
580  		should_signal = false;
581  	}
582  	if (should_signal) {
583  		info-&gt;npages_to_purge_new = 0;
584  		pthread_cond_signal(&amp;info-&gt;cond);
585  	}
586  label_done_unlock2:
587  	malloc_mutex_unlock(tsdn, &amp;decay-&gt;mtx);
588  label_done:
589  	malloc_mutex_unlock(tsdn, &amp;info-&gt;mtx);
590  }
591  void
592  background_thread_prefork0(tsdn_t *tsdn) {
593  	malloc_mutex_prefork(tsdn, &amp;background_thread_lock);
594  	background_thread_enabled_at_fork = background_thread_enabled();
595  }
596  void
597  background_thread_prefork1(tsdn_t *tsdn) {
598  	for (unsigned i = 0; i &lt; max_background_threads; i++) {
599  		malloc_mutex_prefork(tsdn, &amp;background_thread_info[i].mtx);
600  	}
601  }
602  void
603  background_thread_postfork_parent(tsdn_t *tsdn) {
604  	for (unsigned i = 0; i &lt; max_background_threads; i++) {
605  		malloc_mutex_postfork_parent(tsdn,
606  		    &amp;background_thread_info[i].mtx);
607  	}
608  	malloc_mutex_postfork_parent(tsdn, &amp;background_thread_lock);
609  }
610  void
611  background_thread_postfork_child(tsdn_t *tsdn) {
612  	for (unsigned i = 0; i &lt; max_background_threads; i++) {
613  		malloc_mutex_postfork_child(tsdn,
614  		    &amp;background_thread_info[i].mtx);
615  	}
616  	malloc_mutex_postfork_child(tsdn, &amp;background_thread_lock);
617  	if (!background_thread_enabled_at_fork) {
618  		return;
619  	}
620  	malloc_mutex_lock(tsdn, &amp;background_thread_lock);
621  	n_background_threads = 0;
622  	background_thread_enabled_set(tsdn, false);
623  	for (unsigned i = 0; i &lt; max_background_threads; i++) {
624  		background_thread_info_t *info = &amp;background_thread_info[i];
625  		malloc_mutex_lock(tsdn, &amp;info-&gt;mtx);
626  		info-&gt;state = background_thread_stopped;
627  		int ret = pthread_cond_init(&amp;info-&gt;cond, NULL);
628  		assert(ret == 0);
629  		background_thread_info_init(tsdn, info);
630  		malloc_mutex_unlock(tsdn, &amp;info-&gt;mtx);
631  	}
632  	malloc_mutex_unlock(tsdn, &amp;background_thread_lock);
633  }
634  bool
635  background_thread_stats_read(tsdn_t *tsdn, background_thread_stats_t *stats) {
636  	assert(config_stats);
637  	malloc_mutex_lock(tsdn, &amp;background_thread_lock);
638  	if (!background_thread_enabled()) {
639  		malloc_mutex_unlock(tsdn, &amp;background_thread_lock);
640  		return true;
641  	}
642  	stats-&gt;num_threads = n_background_threads;
643  	uint64_t num_runs = 0;
644  	nstime_init(&amp;stats-&gt;run_interval, 0);
645  	for (unsigned i = 0; i &lt; max_background_threads; i++) {
646  		background_thread_info_t *info = &amp;background_thread_info[i];
647  		if (malloc_mutex_trylock(tsdn, &amp;info-&gt;mtx)) {
648  			continue;
649  		}
650  		if (info-&gt;state != background_thread_stopped) {
651  			num_runs += info-&gt;tot_n_runs;
<span onclick='openModal()' class='match'>652  			nstime_add(&amp;stats-&gt;run_interval, &amp;info-&gt;tot_sleep_time);
653  		}
654  		malloc_mutex_unlock(tsdn, &amp;info-&gt;mtx);
655  	}
656  	stats-&gt;num_runs = num_runs;
</span>657  	if (num_runs &gt; 0) {
658  		nstime_idivide(&amp;stats-&gt;run_interval, num_runs);
659  	}
660  	malloc_mutex_unlock(tsdn, &amp;background_thread_lock);
661  	return false;
662  }
663  #undef BACKGROUND_THREAD_NPAGES_THRESHOLD
664  #undef BILLION
665  #undef BACKGROUND_THREAD_MIN_INTERVAL_NS
666  #ifdef JEMALLOC_HAVE_DLSYM
667  #include &lt;dlfcn.h&gt;
668  #endif
669  static bool
670  pthread_create_fptr_init(void) {
671  	if (pthread_create_fptr != NULL) {
672  		return false;
673  	}
674  #ifdef JEMALLOC_HAVE_DLSYM
675  	pthread_create_fptr = dlsym(RTLD_NEXT, &quot;pthread_create&quot;);
676  #else
677  	pthread_create_fptr = NULL;
678  #endif
679  	if (pthread_create_fptr == NULL) {
680  		if (config_lazy_lock) {
681  			malloc_write(&quot;&lt;jemalloc&gt;: Error in dlsym(RTLD_NEXT, &quot;
682  			    &quot;\&quot;pthread_create\&quot;)\n&quot;);
683  			abort();
684  		} else {
685  			pthread_create_fptr = pthread_create;
686  		}
687  	}
688  	return false;
689  }
690  void
691  background_thread_ctl_init(tsdn_t *tsdn) {
692  	malloc_mutex_assert_not_owner(tsdn, &amp;background_thread_lock);
693  #ifdef JEMALLOC_PTHREAD_CREATE_WRAPPER
694  	pthread_create_fptr_init();
695  	pthread_create_wrapper_init();
696  #endif
697  }
698  #endif &amp;bsol;* defined(JEMALLOC_BACKGROUND_THREAD) */
699  bool
700  background_thread_boot0(void) {
701  	if (!have_background_thread &amp;&amp; opt_background_thread) {
702  		malloc_printf(&quot;&lt;jemalloc&gt;: option background_thread currently &quot;
703  		    &quot;supports pthread only\n&quot;);
704  		return true;
705  	}
706  #ifdef JEMALLOC_PTHREAD_CREATE_WRAPPER
707  	if ((config_lazy_lock || opt_background_thread) &amp;&amp;
708  	    pthread_create_fptr_init()) {
709  		return true;
710  	}
711  #endif
712  	return false;
713  }
714  bool
715  background_thread_boot1(tsdn_t *tsdn) {
716  #ifdef JEMALLOC_BACKGROUND_THREAD
717  	assert(have_background_thread);
718  	assert(narenas_total_get() &gt; 0);
719  	if (opt_max_background_threads &gt; MAX_BACKGROUND_THREAD_LIMIT) {
720  		opt_max_background_threads = DEFAULT_NUM_BACKGROUND_THREAD;
721  	}
722  	max_background_threads = opt_max_background_threads;
723  	background_thread_enabled_set(tsdn, opt_background_thread);
724  	if (malloc_mutex_init(&amp;background_thread_lock,
725  	    &quot;background_thread_global&quot;,
726  	    WITNESS_RANK_BACKGROUND_THREAD_GLOBAL,
727  	    malloc_mutex_rank_exclusive)) {
728  		return true;
729  	}
730  	background_thread_info = (background_thread_info_t *)base_alloc(tsdn,
731  	    b0get(), opt_max_background_threads *
732  	    sizeof(background_thread_info_t), CACHELINE);
733  	if (background_thread_info == NULL) {
734  		return true;
735  	}
736  	for (unsigned i = 0; i &lt; max_background_threads; i++) {
737  		background_thread_info_t *info = &amp;background_thread_info[i];
738  		if (malloc_mutex_init(&amp;info-&gt;mtx, &quot;background_thread&quot;,
739  		    WITNESS_RANK_BACKGROUND_THREAD,
740  		    malloc_mutex_address_ordered)) {
741  			return true;
742  		}
743  		if (pthread_cond_init(&amp;info-&gt;cond, NULL)) {
744  			return true;
745  		}
746  		malloc_mutex_lock(tsdn, &amp;info-&gt;mtx);
747  		info-&gt;state = background_thread_stopped;
748  		background_thread_info_init(tsdn, info);
749  		malloc_mutex_unlock(tsdn, &amp;info-&gt;mtx);
750  	}
751  #endif
752  	return false;
753  }
</code></pre>
        </div>
        <div class="column">
            <h3>libfuse-MDEwOlJlcG9zaXRvcnk0ODI5NjE3Nw==-flat-fuse.c</h3>
            <pre><code>1  #include &quot;fuse_config.h&quot;
2  #include &quot;fuse_i.h&quot;
3  #include &quot;fuse_lowlevel.h&quot;
4  #include &quot;fuse_opt.h&quot;
5  #include &quot;fuse_misc.h&quot;
6  #include &quot;fuse_kernel.h&quot;
7  #include &lt;stdio.h&gt;
8  #include &lt;string.h&gt;
9  #include &lt;stdlib.h&gt;
10  #include &lt;stddef.h&gt;
11  #include &lt;stdbool.h&gt;
12  #include &lt;unistd.h&gt;
13  #include &lt;time.h&gt;
14  #include &lt;fcntl.h&gt;
15  #include &lt;limits.h&gt;
16  #include &lt;errno.h&gt;
17  #include &lt;signal.h&gt;
18  #include &lt;dlfcn.h&gt;
19  #include &lt;assert.h&gt;
20  #include &lt;poll.h&gt;
21  #include &lt;sys/param.h&gt;
22  #include &lt;sys/uio.h&gt;
23  #include &lt;sys/time.h&gt;
24  #include &lt;sys/mman.h&gt;
25  #include &lt;sys/file.h&gt;
26  #define FUSE_NODE_SLAB 1
27  #ifndef MAP_ANONYMOUS
28  #undef FUSE_NODE_SLAB
29  #endif
30  #ifndef RENAME_EXCHANGE
31  #define RENAME_EXCHANGE		(1 &lt;&lt; 1)	&amp;bsol;* Exchange source and dest */
32  #endif
33  #define FUSE_DEFAULT_INTR_SIGNAL SIGUSR1
34  #define FUSE_UNKNOWN_INO 0xffffffff
35  #define OFFSET_MAX 0x7fffffffffffffffLL
36  #define NODE_TABLE_MIN_SIZE 8192
37  struct fuse_fs {
38  	struct fuse_operations op;
39  	void *user_data;
40  	int debug;
41  };
42  struct fusemod_so {
43  	void *handle;
44  	int ctr;
45  };
46  struct lock_queue_element {
47  	struct lock_queue_element *next;
48  	pthread_cond_t cond;
49  	fuse_ino_t nodeid1;
50  	const char *name1;
51  	char **path1;
52  	struct node **wnode1;
53  	fuse_ino_t nodeid2;
54  	const char *name2;
55  	char **path2;
56  	struct node **wnode2;
57  	int err;
58  	bool done : 1;
59  };
60  struct node_table {
61  	struct node **array;
62  	size_t use;
63  	size_t size;
64  	size_t split;
65  };
66  #define container_of(ptr, type, member) ({                              \
67  			const typeof( ((type *)0)-&gt;member ) *__mptr = (ptr); \
68  			(type *)( (char *)__mptr - offsetof(type,member) );})
69  #define list_entry(ptr, type, member)           \
70  	container_of(ptr, type, member)
71  struct list_head {
72  	struct list_head *next;
73  	struct list_head *prev;
74  };
75  struct node_slab {
76  	struct list_head list;  &amp;bsol;* must be the first member */
77  	struct list_head freelist;
78  	int used;
79  };
80  struct fuse {
81  	struct fuse_session *se;
82  	struct node_table name_table;
83  	struct node_table id_table;
84  	struct list_head lru_table;
85  	fuse_ino_t ctr;
86  	unsigned int generation;
87  	unsigned int hidectr;
88  	pthread_mutex_t lock;
89  	struct fuse_config conf;
90  	int intr_installed;
91  	struct fuse_fs *fs;
92  	struct lock_queue_element *lockq;
93  	int pagesize;
94  	struct list_head partial_slabs;
95  	struct list_head full_slabs;
96  	pthread_t prune_thread;
97  };
98  struct lock {
99  	int type;
100  	off_t start;
101  	off_t end;
102  	pid_t pid;
103  	uint64_t owner;
104  	struct lock *next;
105  };
106  struct node {
107  	struct node *name_next;
108  	struct node *id_next;
109  	fuse_ino_t nodeid;
110  	unsigned int generation;
111  	int refctr;
112  	struct node *parent;
113  	char *name;
114  	uint64_t nlookup;
115  	int open_count;
116  	struct timespec stat_updated;
117  	struct timespec mtime;
118  	off_t size;
119  	struct lock *locks;
120  	unsigned int is_hidden : 1;
121  	unsigned int cache_valid : 1;
122  	int treelock;
123  	char inline_name[32];
124  };
125  #define TREELOCK_WRITE -1
126  #define TREELOCK_WAIT_OFFSET INT_MIN
127  struct node_lru {
128  	struct node node;
129  	struct list_head lru;
130  	struct timespec forget_time;
131  };
132  struct fuse_direntry {
133  	struct stat stat;
134  	char *name;
135  	struct fuse_direntry *next;
136  };
137  struct fuse_dh {
138  	pthread_mutex_t lock;
139  	struct fuse *fuse;
140  	fuse_req_t req;
141  	char *contents;
142  	struct fuse_direntry *first;
143  	struct fuse_direntry **last;
144  	unsigned len;
145  	unsigned size;
146  	unsigned needlen;
147  	int filled;
148  	uint64_t fh;
149  	int error;
150  	fuse_ino_t nodeid;
151  };
152  struct fuse_context_i {
153  	struct fuse_context ctx;
154  	fuse_req_t req;
155  };
156  extern fuse_module_factory_t fuse_module_subdir_factory;
157  #ifdef HAVE_ICONV
158  extern fuse_module_factory_t fuse_module_iconv_factory;
159  #endif
160  static pthread_key_t fuse_context_key;
161  static pthread_mutex_t fuse_context_lock = PTHREAD_MUTEX_INITIALIZER;
162  static int fuse_context_ref;
163  static struct fuse_module *fuse_modules = NULL;
164  static int fuse_register_module(const char *name,
165  				fuse_module_factory_t factory,
166  				struct fusemod_so *so)
167  {
168  	struct fuse_module *mod;
169  	mod = calloc(1, sizeof(struct fuse_module));
170  	if (!mod) {
171  		fuse_log(FUSE_LOG_ERR, &quot;fuse: failed to allocate module\n&quot;);
172  		return -1;
173  	}
174  	mod-&gt;name = strdup(name);
175  	if (!mod-&gt;name) {
176  		fuse_log(FUSE_LOG_ERR, &quot;fuse: failed to allocate module name\n&quot;);
177  		free(mod);
178  		return -1;
179  	}
180  	mod-&gt;factory = factory;
181  	mod-&gt;ctr = 0;
182  	mod-&gt;so = so;
183  	if (mod-&gt;so)
184  		mod-&gt;so-&gt;ctr++;
185  	mod-&gt;next = fuse_modules;
186  	fuse_modules = mod;
187  	return 0;
188  }
189  static void fuse_unregister_module(struct fuse_module *m)
190  {
191  	struct fuse_module **mp;
192  	for (mp = &amp;fuse_modules; *mp; mp = &amp;(*mp)-&gt;next) {
193  		if (*mp == m) {
194  			*mp = (*mp)-&gt;next;
195  			break;
196  		}
197  	}
198  	free(m-&gt;name);
199  	free(m);
200  }
201  static int fuse_load_so_module(const char *module)
202  {
203  	int ret = -1;
204  	char *tmp;
205  	struct fusemod_so *so;
206  	fuse_module_factory_t *factory;
207  	tmp = malloc(strlen(module) + 64);
208  	if (!tmp) {
209  		fuse_log(FUSE_LOG_ERR, &quot;fuse: memory allocation failed\n&quot;);
210  		return -1;
211  	}
212  	sprintf(tmp, &quot;libfusemod_%s.so&quot;, module);
213  	so = calloc(1, sizeof(struct fusemod_so));
214  	if (!so) {
215  		fuse_log(FUSE_LOG_ERR, &quot;fuse: failed to allocate module so\n&quot;);
216  		goto out;
217  	}
218  	so-&gt;handle = dlopen(tmp, RTLD_NOW);
219  	if (so-&gt;handle == NULL) {
220  		fuse_log(FUSE_LOG_ERR, &quot;fuse: dlopen(%s) failed: %s\n&quot;,
221  			tmp, dlerror());
222  		goto out_free_so;
223  	}
224  	sprintf(tmp, &quot;fuse_module_%s_factory&quot;, module);
225  	factory = (fuse_module_factory_t*)dlsym(so-&gt;handle, tmp);
226  	if (factory == NULL) {
227  		fuse_log(FUSE_LOG_ERR, &quot;fuse: symbol &lt;%s&gt; not found in module: %s\n&quot;,
228  			tmp, dlerror());
229  		goto out_dlclose;
230  	}
231  	ret = fuse_register_module(module, *factory, so);
232  	if (ret)
233  		goto out_dlclose;
234  out:
235  	free(tmp);
236  	return ret;
237  out_dlclose:
238  	dlclose(so-&gt;handle);
239  out_free_so:
240  	free(so);
241  	goto out;
242  }
243  static struct fuse_module *fuse_find_module(const char *module)
244  {
245  	struct fuse_module *m;
246  	for (m = fuse_modules; m; m = m-&gt;next) {
247  		if (strcmp(module, m-&gt;name) == 0) {
248  			m-&gt;ctr++;
249  			break;
250  		}
251  	}
252  	return m;
253  }
254  static struct fuse_module *fuse_get_module(const char *module)
255  {
256  	struct fuse_module *m;
257  	pthread_mutex_lock(&amp;fuse_context_lock);
258  	m = fuse_find_module(module);
259  	if (!m) {
260  		int err = fuse_load_so_module(module);
261  		if (!err)
262  			m = fuse_find_module(module);
263  	}
264  	pthread_mutex_unlock(&amp;fuse_context_lock);
265  	return m;
266  }
267  static void fuse_put_module(struct fuse_module *m)
268  {
269  	pthread_mutex_lock(&amp;fuse_context_lock);
270  	if (m-&gt;so)
271  		assert(m-&gt;ctr &gt; 0);
272  	if (m-&gt;ctr &gt; 0)
273  		m-&gt;ctr--;
274  	if (!m-&gt;ctr &amp;&amp; m-&gt;so) {
275  		struct fusemod_so *so = m-&gt;so;
276  		assert(so-&gt;ctr &gt; 0);
277  		so-&gt;ctr--;
278  		if (!so-&gt;ctr) {
279  			struct fuse_module **mp;
280  			for (mp = &amp;fuse_modules; *mp;) {
281  				if ((*mp)-&gt;so == so)
282  					fuse_unregister_module(*mp);
283  				else
284  					mp = &amp;(*mp)-&gt;next;
285  			}
286  			dlclose(so-&gt;handle);
287  			free(so);
288  		}
289  	} else if (!m-&gt;ctr) {
290  		fuse_unregister_module(m);
291  	}
292  	pthread_mutex_unlock(&amp;fuse_context_lock);
293  }
294  static void init_list_head(struct list_head *list)
295  {
296  	list-&gt;next = list;
297  	list-&gt;prev = list;
298  }
299  static int list_empty(const struct list_head *head)
300  {
301  	return head-&gt;next == head;
302  }
303  static void list_add(struct list_head *new, struct list_head *prev,
304  		     struct list_head *next)
305  {
306  	next-&gt;prev = new;
307  	new-&gt;next = next;
308  	new-&gt;prev = prev;
309  	prev-&gt;next = new;
310  }
311  static inline void list_add_head(struct list_head *new, struct list_head *head)
312  {
313  	list_add(new, head, head-&gt;next);
314  }
315  static inline void list_add_tail(struct list_head *new, struct list_head *head)
316  {
317  	list_add(new, head-&gt;prev, head);
318  }
319  static inline void list_del(struct list_head *entry)
320  {
321  	struct list_head *prev = entry-&gt;prev;
322  	struct list_head *next = entry-&gt;next;
323  	next-&gt;prev = prev;
324  	prev-&gt;next = next;
325  }
326  static inline int lru_enabled(struct fuse *f)
327  {
328  	return f-&gt;conf.remember &gt; 0;
329  }
330  static struct node_lru *node_lru(struct node *node)
331  {
332  	return (struct node_lru *) node;
333  }
334  static size_t get_node_size(struct fuse *f)
335  {
336  	if (lru_enabled(f))
337  		return sizeof(struct node_lru);
338  	else
339  		return sizeof(struct node);
340  }
341  #ifdef FUSE_NODE_SLAB
342  static struct node_slab *list_to_slab(struct list_head *head)
343  {
344  	return (struct node_slab *) head;
345  }
346  static struct node_slab *node_to_slab(struct fuse *f, struct node *node)
347  {
348  	return (struct node_slab *) (((uintptr_t) node) &amp; ~((uintptr_t) f-&gt;pagesize - 1));
349  }
350  static int alloc_slab(struct fuse *f)
351  {
352  	void *mem;
353  	struct node_slab *slab;
354  	char *start;
355  	size_t num;
356  	size_t i;
357  	size_t node_size = get_node_size(f);
358  	mem = mmap(NULL, f-&gt;pagesize, PROT_READ | PROT_WRITE,
359  		   MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
360  	if (mem == MAP_FAILED)
361  		return -1;
362  	slab = mem;
363  	init_list_head(&amp;slab-&gt;freelist);
364  	slab-&gt;used = 0;
365  	num = (f-&gt;pagesize - sizeof(struct node_slab)) / node_size;
366  	start = (char *) mem + f-&gt;pagesize - num * node_size;
367  	for (i = 0; i &lt; num; i++) {
368  		struct list_head *n;
369  		n = (struct list_head *) (start + i * node_size);
370  		list_add_tail(n, &amp;slab-&gt;freelist);
371  	}
372  	list_add_tail(&amp;slab-&gt;list, &amp;f-&gt;partial_slabs);
373  	return 0;
374  }
375  static struct node *alloc_node(struct fuse *f)
376  {
377  	struct node_slab *slab;
378  	struct list_head *node;
379  	if (list_empty(&amp;f-&gt;partial_slabs)) {
380  		int res = alloc_slab(f);
381  		if (res != 0)
382  			return NULL;
383  	}
384  	slab = list_to_slab(f-&gt;partial_slabs.next);
385  	slab-&gt;used++;
386  	node = slab-&gt;freelist.next;
387  	list_del(node);
388  	if (list_empty(&amp;slab-&gt;freelist)) {
389  		list_del(&amp;slab-&gt;list);
390  		list_add_tail(&amp;slab-&gt;list, &amp;f-&gt;full_slabs);
391  	}
392  	memset(node, 0, sizeof(struct node));
393  	return (struct node *) node;
394  }
395  static void free_slab(struct fuse *f, struct node_slab *slab)
396  {
397  	int res;
398  	list_del(&amp;slab-&gt;list);
399  	res = munmap(slab, f-&gt;pagesize);
400  	if (res == -1)
401  		fuse_log(FUSE_LOG_WARNING, &quot;fuse warning: munmap(%p) failed\n&quot;,
402  			 slab);
403  }
404  static void free_node_mem(struct fuse *f, struct node *node)
405  {
406  	struct node_slab *slab = node_to_slab(f, node);
407  	struct list_head *n = (struct list_head *) node;
408  	slab-&gt;used--;
409  	if (slab-&gt;used) {
410  		if (list_empty(&amp;slab-&gt;freelist)) {
411  			list_del(&amp;slab-&gt;list);
<span onclick='openModal()' class='match'>412  			list_add_tail(&amp;slab-&gt;list, &amp;f-&gt;partial_slabs);
413  		}
414  		list_add_head(n, &amp;slab-&gt;freelist);
415  	} else {
</span>416  		free_slab(f, slab);
417  	}
418  }
419  #else
420  static struct node *alloc_node(struct fuse *f)
421  {
422  	return (struct node *) calloc(1, get_node_size(f));
423  }
424  static void free_node_mem(struct fuse *f, struct node *node)
425  {
426  	(void) f;
427  	free(node);
428  }
429  #endif
430  static size_t id_hash(struct fuse *f, fuse_ino_t ino)
431  {
432  	uint64_t hash = ((uint32_t) ino * 2654435761U) % f-&gt;id_table.size;
433  	uint64_t oldhash = hash % (f-&gt;id_table.size / 2);
434  	if (oldhash &gt;= f-&gt;id_table.split)
435  		return oldhash;
436  	else
437  		return hash;
438  }
439  static struct node *get_node_nocheck(struct fuse *f, fuse_ino_t nodeid)
440  {
441  	size_t hash = id_hash(f, nodeid);
442  	struct node *node;
443  	for (node = f-&gt;id_table.array[hash]; node != NULL; node = node-&gt;id_next)
444  		if (node-&gt;nodeid == nodeid)
445  			return node;
446  	return NULL;
447  }
448  static struct node *get_node(struct fuse *f, fuse_ino_t nodeid)
449  {
450  	struct node *node = get_node_nocheck(f, nodeid);
451  	if (!node) {
452  		fuse_log(FUSE_LOG_ERR, &quot;fuse internal error: node %llu not found\n&quot;,
453  			(unsigned long long) nodeid);
454  		abort();
455  	}
456  	return node;
457  }
458  static void curr_time(struct timespec *now);
459  static double diff_timespec(const struct timespec *t1,
460  			   const struct timespec *t2);
461  static void remove_node_lru(struct node *node)
462  {
463  	struct node_lru *lnode = node_lru(node);
464  	list_del(&amp;lnode-&gt;lru);
465  	init_list_head(&amp;lnode-&gt;lru);
466  }
467  static void set_forget_time(struct fuse *f, struct node *node)
468  {
469  	struct node_lru *lnode = node_lru(node);
470  	list_del(&amp;lnode-&gt;lru);
471  	list_add_tail(&amp;lnode-&gt;lru, &amp;f-&gt;lru_table);
472  	curr_time(&amp;lnode-&gt;forget_time);
473  }
474  static void free_node(struct fuse *f, struct node *node)
475  {
476  	if (node-&gt;name != node-&gt;inline_name)
477  		free(node-&gt;name);
478  	free_node_mem(f, node);
479  }
480  static void node_table_reduce(struct node_table *t)
481  {
482  	size_t newsize = t-&gt;size / 2;
483  	void *newarray;
484  	if (newsize &lt; NODE_TABLE_MIN_SIZE)
485  		return;
486  	newarray = realloc(t-&gt;array, sizeof(struct node *) * newsize);
487  	if (newarray != NULL)
488  		t-&gt;array = newarray;
489  	t-&gt;size = newsize;
490  	t-&gt;split = t-&gt;size / 2;
491  }
492  static void remerge_id(struct fuse *f)
493  {
494  	struct node_table *t = &amp;f-&gt;id_table;
495  	int iter;
496  	if (t-&gt;split == 0)
497  		node_table_reduce(t);
498  	for (iter = 8; t-&gt;split &gt; 0 &amp;&amp; iter; iter--) {
499  		struct node **upper;
500  		t-&gt;split--;
501  		upper = &amp;t-&gt;array[t-&gt;split + t-&gt;size / 2];
502  		if (*upper) {
503  			struct node **nodep;
504  			for (nodep = &amp;t-&gt;array[t-&gt;split]; *nodep;
505  			     nodep = &amp;(*nodep)-&gt;id_next);
506  			*nodep = *upper;
507  			*upper = NULL;
508  			break;
509  		}
510  	}
511  }
512  static void unhash_id(struct fuse *f, struct node *node)
513  {
514  	struct node **nodep = &amp;f-&gt;id_table.array[id_hash(f, node-&gt;nodeid)];
515  	for (; *nodep != NULL; nodep = &amp;(*nodep)-&gt;id_next)
516  		if (*nodep == node) {
517  			*nodep = node-&gt;id_next;
518  			f-&gt;id_table.use--;
519  			if(f-&gt;id_table.use &lt; f-&gt;id_table.size / 4)
520  				remerge_id(f);
521  			return;
522  		}
523  }
524  static int node_table_resize(struct node_table *t)
525  {
526  	size_t newsize = t-&gt;size * 2;
527  	void *newarray;
528  	newarray = realloc(t-&gt;array, sizeof(struct node *) * newsize);
529  	if (newarray == NULL)
530  		return -1;
531  	t-&gt;array = newarray;
532  	memset(t-&gt;array + t-&gt;size, 0, t-&gt;size * sizeof(struct node *));
533  	t-&gt;size = newsize;
534  	t-&gt;split = 0;
535  	return 0;
536  }
537  static void rehash_id(struct fuse *f)
538  {
539  	struct node_table *t = &amp;f-&gt;id_table;
540  	struct node **nodep;
541  	struct node **next;
542  	size_t hash;
543  	if (t-&gt;split == t-&gt;size / 2)
544  		return;
545  	hash = t-&gt;split;
546  	t-&gt;split++;
547  	for (nodep = &amp;t-&gt;array[hash]; *nodep != NULL; nodep = next) {
548  		struct node *node = *nodep;
549  		size_t newhash = id_hash(f, node-&gt;nodeid);
550  		if (newhash != hash) {
551  			next = nodep;
552  			*nodep = node-&gt;id_next;
553  			node-&gt;id_next = t-&gt;array[newhash];
554  			t-&gt;array[newhash] = node;
555  		} else {
556  			next = &amp;node-&gt;id_next;
557  		}
558  	}
559  	if (t-&gt;split == t-&gt;size / 2)
560  		node_table_resize(t);
561  }
562  static void hash_id(struct fuse *f, struct node *node)
563  {
564  	size_t hash = id_hash(f, node-&gt;nodeid);
565  	node-&gt;id_next = f-&gt;id_table.array[hash];
566  	f-&gt;id_table.array[hash] = node;
567  	f-&gt;id_table.use++;
568  	if (f-&gt;id_table.use &gt;= f-&gt;id_table.size / 2)
569  		rehash_id(f);
570  }
571  static size_t name_hash(struct fuse *f, fuse_ino_t parent,
572  			const char *name)
573  {
574  	uint64_t hash = parent;
575  	uint64_t oldhash;
576  	for (; *name; name++)
577  		hash = hash * 31 + (unsigned char) *name;
578  	hash %= f-&gt;name_table.size;
579  	oldhash = hash % (f-&gt;name_table.size / 2);
580  	if (oldhash &gt;= f-&gt;name_table.split)
581  		return oldhash;
582  	else
583  		return hash;
584  }
585  static void unref_node(struct fuse *f, struct node *node);
586  static void remerge_name(struct fuse *f)
587  {
588  	struct node_table *t = &amp;f-&gt;name_table;
589  	int iter;
590  	if (t-&gt;split == 0)
591  		node_table_reduce(t);
592  	for (iter = 8; t-&gt;split &gt; 0 &amp;&amp; iter; iter--) {
593  		struct node **upper;
594  		t-&gt;split--;
595  		upper = &amp;t-&gt;array[t-&gt;split + t-&gt;size / 2];
596  		if (*upper) {
597  			struct node **nodep;
598  			for (nodep = &amp;t-&gt;array[t-&gt;split]; *nodep;
599  			     nodep = &amp;(*nodep)-&gt;name_next);
600  			*nodep = *upper;
601  			*upper = NULL;
602  			break;
603  		}
604  	}
605  }
606  static void unhash_name(struct fuse *f, struct node *node)
607  {
608  	if (node-&gt;name) {
609  		size_t hash = name_hash(f, node-&gt;parent-&gt;nodeid, node-&gt;name);
610  		struct node **nodep = &amp;f-&gt;name_table.array[hash];
611  		for (; *nodep != NULL; nodep = &amp;(*nodep)-&gt;name_next)
612  			if (*nodep == node) {
613  				*nodep = node-&gt;name_next;
614  				node-&gt;name_next = NULL;
615  				unref_node(f, node-&gt;parent);
616  				if (node-&gt;name != node-&gt;inline_name)
617  					free(node-&gt;name);
618  				node-&gt;name = NULL;
619  				node-&gt;parent = NULL;
620  				f-&gt;name_table.use--;
621  				if (f-&gt;name_table.use &lt; f-&gt;name_table.size / 4)
622  					remerge_name(f);
623  				return;
624  			}
625  		fuse_log(FUSE_LOG_ERR,
626  			&quot;fuse internal error: unable to unhash node: %llu\n&quot;,
627  			(unsigned long long) node-&gt;nodeid);
628  		abort();
629  	}
630  }
631  static void rehash_name(struct fuse *f)
632  {
633  	struct node_table *t = &amp;f-&gt;name_table;
634  	struct node **nodep;
635  	struct node **next;
636  	size_t hash;
637  	if (t-&gt;split == t-&gt;size / 2)
638  		return;
639  	hash = t-&gt;split;
640  	t-&gt;split++;
641  	for (nodep = &amp;t-&gt;array[hash]; *nodep != NULL; nodep = next) {
642  		struct node *node = *nodep;
643  		size_t newhash = name_hash(f, node-&gt;parent-&gt;nodeid, node-&gt;name);
644  		if (newhash != hash) {
645  			next = nodep;
646  			*nodep = node-&gt;name_next;
647  			node-&gt;name_next = t-&gt;array[newhash];
648  			t-&gt;array[newhash] = node;
649  		} else {
650  			next = &amp;node-&gt;name_next;
651  		}
652  	}
653  	if (t-&gt;split == t-&gt;size / 2)
654  		node_table_resize(t);
655  }
656  static int hash_name(struct fuse *f, struct node *node, fuse_ino_t parentid,
657  		     const char *name)
658  {
659  	size_t hash = name_hash(f, parentid, name);
660  	struct node *parent = get_node(f, parentid);
661  	if (strlen(name) &lt; sizeof(node-&gt;inline_name)) {
662  		strcpy(node-&gt;inline_name, name);
663  		node-&gt;name = node-&gt;inline_name;
664  	} else {
665  		node-&gt;name = strdup(name);
666  		if (node-&gt;name == NULL)
667  			return -1;
668  	}
669  	parent-&gt;refctr ++;
670  	node-&gt;parent = parent;
671  	node-&gt;name_next = f-&gt;name_table.array[hash];
672  	f-&gt;name_table.array[hash] = node;
673  	f-&gt;name_table.use++;
674  	if (f-&gt;name_table.use &gt;= f-&gt;name_table.size / 2)
675  		rehash_name(f);
676  	return 0;
677  }
678  static void delete_node(struct fuse *f, struct node *node)
679  {
680  	if (f-&gt;conf.debug)
681  		fuse_log(FUSE_LOG_DEBUG, &quot;DELETE: %llu\n&quot;,
682  			(unsigned long long) node-&gt;nodeid);
683  	assert(node-&gt;treelock == 0);
684  	unhash_name(f, node);
685  	if (lru_enabled(f))
686  		remove_node_lru(node);
687  	unhash_id(f, node);
688  	free_node(f, node);
689  }
690  static void unref_node(struct fuse *f, struct node *node)
691  {
692  	assert(node-&gt;refctr &gt; 0);
693  	node-&gt;refctr --;
694  	if (!node-&gt;refctr)
695  		delete_node(f, node);
696  }
697  static fuse_ino_t next_id(struct fuse *f)
698  {
699  	do {
700  		f-&gt;ctr = (f-&gt;ctr + 1) &amp; 0xffffffff;
701  		if (!f-&gt;ctr)
702  			f-&gt;generation ++;
703  	} while (f-&gt;ctr == 0 || f-&gt;ctr == FUSE_UNKNOWN_INO ||
704  		 get_node_nocheck(f, f-&gt;ctr) != NULL);
705  	return f-&gt;ctr;
706  }
707  static struct node *lookup_node(struct fuse *f, fuse_ino_t parent,
708  				const char *name)
709  {
710  	size_t hash = name_hash(f, parent, name);
711  	struct node *node;
712  	for (node = f-&gt;name_table.array[hash]; node != NULL; node = node-&gt;name_next)
713  		if (node-&gt;parent-&gt;nodeid == parent &amp;&amp;
714  		    strcmp(node-&gt;name, name) == 0)
715  			return node;
716  	return NULL;
717  }
718  static void inc_nlookup(struct node *node)
719  {
720  	if (!node-&gt;nlookup)
721  		node-&gt;refctr++;
722  	node-&gt;nlookup++;
723  }
724  static struct node *find_node(struct fuse *f, fuse_ino_t parent,
725  			      const char *name)
726  {
727  	struct node *node;
728  	pthread_mutex_lock(&amp;f-&gt;lock);
729  	if (!name)
730  		node = get_node(f, parent);
731  	else
732  		node = lookup_node(f, parent, name);
733  	if (node == NULL) {
734  		node = alloc_node(f);
735  		if (node == NULL)
736  			goto out_err;
737  		node-&gt;nodeid = next_id(f);
738  		node-&gt;generation = f-&gt;generation;
739  		if (f-&gt;conf.remember)
740  			inc_nlookup(node);
741  		if (hash_name(f, node, parent, name) == -1) {
742  			free_node(f, node);
743  			node = NULL;
744  			goto out_err;
745  		}
746  		hash_id(f, node);
747  		if (lru_enabled(f)) {
748  			struct node_lru *lnode = node_lru(node);
749  			init_list_head(&amp;lnode-&gt;lru);
750  		}
751  	} else if (lru_enabled(f) &amp;&amp; node-&gt;nlookup == 1) {
752  		remove_node_lru(node);
753  	}
754  	inc_nlookup(node);
755  out_err:
756  	pthread_mutex_unlock(&amp;f-&gt;lock);
757  	return node;
758  }
759  static int lookup_path_in_cache(struct fuse *f,
760  		const char *path, fuse_ino_t *inop)
761  {
762  	char *tmp = strdup(path);
763  	if (!tmp)
764  		return -ENOMEM;
765  	pthread_mutex_lock(&amp;f-&gt;lock);
766  	fuse_ino_t ino = FUSE_ROOT_ID;
767  	int err = 0;
768  	char *save_ptr;
769  	char *path_element = strtok_r(tmp, &quot;/&quot;, &amp;save_ptr);
770  	while (path_element != NULL) {
771  		struct node *node = lookup_node(f, ino, path_element);
772  		if (node == NULL) {
773  			err = -ENOENT;
774  			break;
775  		}
776  		ino = node-&gt;nodeid;
777  		path_element = strtok_r(NULL, &quot;/&quot;, &amp;save_ptr);
778  	}
779  	pthread_mutex_unlock(&amp;f-&gt;lock);
780  	free(tmp);
781  	if (!err)
782  		*inop = ino;
783  	return err;
784  }
785  static char *add_name(char **buf, unsigned *bufsize, char *s, const char *name)
786  {
787  	size_t len = strlen(name);
788  	if (s - len &lt;= *buf) {
789  		unsigned pathlen = *bufsize - (s - *buf);
790  		unsigned newbufsize = *bufsize;
791  		char *newbuf;
792  		while (newbufsize &lt; pathlen + len + 1) {
793  			if (newbufsize &gt;= 0x80000000)
794  				newbufsize = 0xffffffff;
795  			else
796  				newbufsize *= 2;
797  		}
798  		newbuf = realloc(*buf, newbufsize);
799  		if (newbuf == NULL)
800  			return NULL;
801  		*buf = newbuf;
802  		s = newbuf + newbufsize - pathlen;
803  		memmove(s, newbuf + *bufsize - pathlen, pathlen);
804  		*bufsize = newbufsize;
805  	}
806  	s -= len;
807  	memcpy(s, name, len);
808  	s--;
809  	*s = &#x27;/&#x27;;
810  	return s;
811  }
812  static void unlock_path(struct fuse *f, fuse_ino_t nodeid, struct node *wnode,
813  			struct node *end)
814  {
815  	struct node *node;
816  	if (wnode) {
817  		assert(wnode-&gt;treelock == TREELOCK_WRITE);
818  		wnode-&gt;treelock = 0;
819  	}
820  	for (node = get_node(f, nodeid);
821  	     node != end &amp;&amp; node-&gt;nodeid != FUSE_ROOT_ID; node = node-&gt;parent) {
822  		assert(node-&gt;treelock != 0);
823  		assert(node-&gt;treelock != TREELOCK_WAIT_OFFSET);
824  		assert(node-&gt;treelock != TREELOCK_WRITE);
825  		node-&gt;treelock--;
826  		if (node-&gt;treelock == TREELOCK_WAIT_OFFSET)
827  			node-&gt;treelock = 0;
828  	}
829  }
830  static int try_get_path(struct fuse *f, fuse_ino_t nodeid, const char *name,
831  			char **path, struct node **wnodep, bool need_lock)
832  {
833  	unsigned bufsize = 256;
834  	char *buf;
835  	char *s;
836  	struct node *node;
837  	struct node *wnode = NULL;
838  	int err;
839  	*path = NULL;
840  	err = -ENOMEM;
841  	buf = malloc(bufsize);
842  	if (buf == NULL)
843  		goto out_err;
844  	s = buf + bufsize - 1;
845  	*s = &#x27;\0&#x27;;
846  	if (name != NULL) {
847  		s = add_name(&amp;buf, &amp;bufsize, s, name);
848  		err = -ENOMEM;
849  		if (s == NULL)
850  			goto out_free;
851  	}
852  	if (wnodep) {
853  		assert(need_lock);
854  		wnode = lookup_node(f, nodeid, name);
855  		if (wnode) {
856  			if (wnode-&gt;treelock != 0) {
857  				if (wnode-&gt;treelock &gt; 0)
858  					wnode-&gt;treelock += TREELOCK_WAIT_OFFSET;
859  				err = -EAGAIN;
860  				goto out_free;
861  			}
862  			wnode-&gt;treelock = TREELOCK_WRITE;
863  		}
864  	}
865  	for (node = get_node(f, nodeid); node-&gt;nodeid != FUSE_ROOT_ID;
866  	     node = node-&gt;parent) {
867  		err = -ESTALE;
868  		if (node-&gt;name == NULL || node-&gt;parent == NULL)
869  			goto out_unlock;
870  		err = -ENOMEM;
871  		s = add_name(&amp;buf, &amp;bufsize, s, node-&gt;name);
872  		if (s == NULL)
873  			goto out_unlock;
874  		if (need_lock) {
875  			err = -EAGAIN;
876  			if (node-&gt;treelock &lt; 0)
877  				goto out_unlock;
878  			node-&gt;treelock++;
879  		}
880  	}
881  	if (s[0])
882  		memmove(buf, s, bufsize - (s - buf));
883  	else
884  		strcpy(buf, &quot;/&quot;);
885  	*path = buf;
886  	if (wnodep)
887  		*wnodep = wnode;
888  	return 0;
889   out_unlock:
890  	if (need_lock)
891  		unlock_path(f, nodeid, wnode, node);
892   out_free:
893  	free(buf);
894   out_err:
895  	return err;
896  }
897  static int try_get_path2(struct fuse *f, fuse_ino_t nodeid1, const char *name1,
898  			 fuse_ino_t nodeid2, const char *name2,
899  			 char **path1, char **path2,
900  			 struct node **wnode1, struct node **wnode2)
901  {
902  	int err;
903  	err = try_get_path(f, nodeid1, name1, path1, wnode1, true);
904  	if (!err) {
905  		err = try_get_path(f, nodeid2, name2, path2, wnode2, true);
906  		if (err) {
907  			struct node *wn1 = wnode1 ? *wnode1 : NULL;
908  			unlock_path(f, nodeid1, wn1, NULL);
909  			free(*path1);
910  		}
911  	}
912  	return err;
913  }
914  static void queue_element_wakeup(struct fuse *f, struct lock_queue_element *qe)
915  {
916  	int err;
917  	if (!qe-&gt;path1) {
918  		if (get_node(f, qe-&gt;nodeid1)-&gt;treelock == 0)
919  			pthread_cond_signal(&amp;qe-&gt;cond);
920  		return;
921  	}
922  	if (qe-&gt;done)
923  		return;  
924  	if (!qe-&gt;path2) {
925  		err = try_get_path(f, qe-&gt;nodeid1, qe-&gt;name1, qe-&gt;path1,
926  				   qe-&gt;wnode1, true);
927  	} else {
928  		err = try_get_path2(f, qe-&gt;nodeid1, qe-&gt;name1, qe-&gt;nodeid2,
929  				    qe-&gt;name2, qe-&gt;path1, qe-&gt;path2, qe-&gt;wnode1,
930  				    qe-&gt;wnode2);
931  	}
932  	if (err == -EAGAIN)
933  		return;  &amp;bsol;* keep trying */
934  	qe-&gt;err = err;
935  	qe-&gt;done = true;
936  	pthread_cond_signal(&amp;qe-&gt;cond);
937  }
938  static void wake_up_queued(struct fuse *f)
939  {
940  	struct lock_queue_element *qe;
941  	for (qe = f-&gt;lockq; qe != NULL; qe = qe-&gt;next)
942  		queue_element_wakeup(f, qe);
943  }
944  static void debug_path(struct fuse *f, const char *msg, fuse_ino_t nodeid,
945  		       const char *name, bool wr)
946  {
947  	if (f-&gt;conf.debug) {
948  		struct node *wnode = NULL;
949  		if (wr)
950  			wnode = lookup_node(f, nodeid, name);
951  		if (wnode) {
952  			fuse_log(FUSE_LOG_DEBUG, &quot;%s %llu (w)\n&quot;,
953  				msg, (unsigned long long) wnode-&gt;nodeid);
954  		} else {
955  			fuse_log(FUSE_LOG_DEBUG, &quot;%s %llu\n&quot;,
956  				msg, (unsigned long long) nodeid);
957  		}
958  	}
959  }
960  static void queue_path(struct fuse *f, struct lock_queue_element *qe)
961  {
962  	struct lock_queue_element **qp;
963  	qe-&gt;done = false;
964  	pthread_cond_init(&amp;qe-&gt;cond, NULL);
965  	qe-&gt;next = NULL;
966  	for (qp = &amp;f-&gt;lockq; *qp != NULL; qp = &amp;(*qp)-&gt;next);
967  	*qp = qe;
968  }
969  static void dequeue_path(struct fuse *f, struct lock_queue_element *qe)
970  {
971  	struct lock_queue_element **qp;
972  	pthread_cond_destroy(&amp;qe-&gt;cond);
973  	for (qp = &amp;f-&gt;lockq; *qp != qe; qp = &amp;(*qp)-&gt;next);
974  	*qp = qe-&gt;next;
975  }
976  static int wait_path(struct fuse *f, struct lock_queue_element *qe)
977  {
978  	queue_path(f, qe);
979  	do {
980  		pthread_cond_wait(&amp;qe-&gt;cond, &amp;f-&gt;lock);
981  	} while (!qe-&gt;done);
982  	dequeue_path(f, qe);
983  	return qe-&gt;err;
984  }
985  static int get_path_common(struct fuse *f, fuse_ino_t nodeid, const char *name,
986  			   char **path, struct node **wnode)
987  {
988  	int err;
989  	pthread_mutex_lock(&amp;f-&gt;lock);
990  	err = try_get_path(f, nodeid, name, path, wnode, true);
991  	if (err == -EAGAIN) {
992  		struct lock_queue_element qe = {
993  			.nodeid1 = nodeid,
994  			.name1 = name,
995  			.path1 = path,
996  			.wnode1 = wnode,
997  		};
998  		debug_path(f, &quot;QUEUE PATH&quot;, nodeid, name, !!wnode);
999  		err = wait_path(f, &amp;qe);
1000  		debug_path(f, &quot;DEQUEUE PATH&quot;, nodeid, name, !!wnode);
1001  	}
1002  	pthread_mutex_unlock(&amp;f-&gt;lock);
1003  	return err;
1004  }
1005  static int get_path(struct fuse *f, fuse_ino_t nodeid, char **path)
1006  {
1007  	return get_path_common(f, nodeid, NULL, path, NULL);
1008  }
1009  static int get_path_nullok(struct fuse *f, fuse_ino_t nodeid, char **path)
1010  {
1011  	int err = 0;
1012  	if (f-&gt;conf.nullpath_ok) {
1013  		*path = NULL;
1014  	} else {
1015  		err = get_path_common(f, nodeid, NULL, path, NULL);
1016  		if (err == -ESTALE)
1017  			err = 0;
1018  	}
1019  	return err;
1020  }
1021  static int get_path_name(struct fuse *f, fuse_ino_t nodeid, const char *name,
1022  			 char **path)
1023  {
1024  	return get_path_common(f, nodeid, name, path, NULL);
1025  }
1026  static int get_path_wrlock(struct fuse *f, fuse_ino_t nodeid, const char *name,
1027  			   char **path, struct node **wnode)
1028  {
1029  	return get_path_common(f, nodeid, name, path, wnode);
1030  }
1031  #if defined(__FreeBSD__)
1032  #define CHECK_DIR_LOOP
1033  #endif
1034  #if defined(CHECK_DIR_LOOP)
1035  static int check_dir_loop(struct fuse *f,
1036  			  fuse_ino_t nodeid1, const char *name1,
1037  			  fuse_ino_t nodeid2, const char *name2)
1038  {
1039  	struct node *node, *node1, *node2;
1040  	fuse_ino_t id1, id2;
1041  	node1 = lookup_node(f, nodeid1, name1);
1042  	id1 = node1 ? node1-&gt;nodeid : nodeid1;
1043  	node2 = lookup_node(f, nodeid2, name2);
1044  	id2 = node2 ? node2-&gt;nodeid : nodeid2;
1045  	for (node = get_node(f, id2); node-&gt;nodeid != FUSE_ROOT_ID;
1046  	     node = node-&gt;parent) {
1047  		if (node-&gt;name == NULL || node-&gt;parent == NULL)
1048  			break;
1049  		if (node-&gt;nodeid != id2 &amp;&amp; node-&gt;nodeid == id1)
1050  			return -EINVAL;
1051  	}
1052  	if (node2)
1053  	{
1054  		for (node = get_node(f, id1); node-&gt;nodeid != FUSE_ROOT_ID;
1055  		     node = node-&gt;parent) {
1056  			if (node-&gt;name == NULL || node-&gt;parent == NULL)
1057  				break;
1058  			if (node-&gt;nodeid != id1 &amp;&amp; node-&gt;nodeid == id2)
1059  				return -ENOTEMPTY;
1060  		}
1061  	}
1062  	return 0;
1063  }
1064  #endif
1065  static int get_path2(struct fuse *f, fuse_ino_t nodeid1, const char *name1,
1066  		     fuse_ino_t nodeid2, const char *name2,
1067  		     char **path1, char **path2,
1068  		     struct node **wnode1, struct node **wnode2)
1069  {
1070  	int err;
1071  	pthread_mutex_lock(&amp;f-&gt;lock);
1072  #if defined(CHECK_DIR_LOOP)
1073  	if (name1)
1074  	{
1075  		err = check_dir_loop(f, nodeid1, name1, nodeid2, name2);
1076  		if (err)
1077  			goto out_unlock;
1078  	}
1079  #endif
1080  	err = try_get_path2(f, nodeid1, name1, nodeid2, name2,
1081  			    path1, path2, wnode1, wnode2);
1082  	if (err == -EAGAIN) {
1083  		struct lock_queue_element qe = {
1084  			.nodeid1 = nodeid1,
1085  			.name1 = name1,
1086  			.path1 = path1,
1087  			.wnode1 = wnode1,
1088  			.nodeid2 = nodeid2,
1089  			.name2 = name2,
1090  			.path2 = path2,
1091  			.wnode2 = wnode2,
1092  		};
1093  		debug_path(f, &quot;QUEUE PATH1&quot;, nodeid1, name1, !!wnode1);
1094  		debug_path(f, &quot;      PATH2&quot;, nodeid2, name2, !!wnode2);
1095  		err = wait_path(f, &amp;qe);
1096  		debug_path(f, &quot;DEQUEUE PATH1&quot;, nodeid1, name1, !!wnode1);
1097  		debug_path(f, &quot;        PATH2&quot;, nodeid2, name2, !!wnode2);
1098  	}
1099  #if defined(CHECK_DIR_LOOP)
1100  out_unlock:
1101  #endif
1102  	pthread_mutex_unlock(&amp;f-&gt;lock);
1103  	return err;
1104  }
1105  static void free_path_wrlock(struct fuse *f, fuse_ino_t nodeid,
1106  			     struct node *wnode, char *path)
1107  {
1108  	pthread_mutex_lock(&amp;f-&gt;lock);
1109  	unlock_path(f, nodeid, wnode, NULL);
1110  	if (f-&gt;lockq)
1111  		wake_up_queued(f);
1112  	pthread_mutex_unlock(&amp;f-&gt;lock);
1113  	free(path);
1114  }
1115  static void free_path(struct fuse *f, fuse_ino_t nodeid, char *path)
1116  {
1117  	if (path)
1118  		free_path_wrlock(f, nodeid, NULL, path);
1119  }
1120  static void free_path2(struct fuse *f, fuse_ino_t nodeid1, fuse_ino_t nodeid2,
1121  		       struct node *wnode1, struct node *wnode2,
1122  		       char *path1, char *path2)
1123  {
1124  	pthread_mutex_lock(&amp;f-&gt;lock);
1125  	unlock_path(f, nodeid1, wnode1, NULL);
1126  	unlock_path(f, nodeid2, wnode2, NULL);
1127  	wake_up_queued(f);
1128  	pthread_mutex_unlock(&amp;f-&gt;lock);
1129  	free(path1);
1130  	free(path2);
1131  }
1132  static void forget_node(struct fuse *f, fuse_ino_t nodeid, uint64_t nlookup)
1133  {
1134  	struct node *node;
1135  	if (nodeid == FUSE_ROOT_ID)
1136  		return;
1137  	pthread_mutex_lock(&amp;f-&gt;lock);
1138  	node = get_node(f, nodeid);
1139  	while (node-&gt;nlookup == nlookup &amp;&amp; node-&gt;treelock) {
1140  		struct lock_queue_element qe = {
1141  			.nodeid1 = nodeid,
1142  		};
1143  		debug_path(f, &quot;QUEUE PATH (forget)&quot;, nodeid, NULL, false);
1144  		queue_path(f, &amp;qe);
1145  		do {
1146  			pthread_cond_wait(&amp;qe.cond, &amp;f-&gt;lock);
1147  		} while (node-&gt;nlookup == nlookup &amp;&amp; node-&gt;treelock);
1148  		dequeue_path(f, &amp;qe);
1149  		debug_path(f, &quot;DEQUEUE_PATH (forget)&quot;, nodeid, NULL, false);
1150  	}
1151  	assert(node-&gt;nlookup &gt;= nlookup);
1152  	node-&gt;nlookup -= nlookup;
1153  	if (!node-&gt;nlookup) {
1154  		unref_node(f, node);
1155  	} else if (lru_enabled(f) &amp;&amp; node-&gt;nlookup == 1) {
1156  		set_forget_time(f, node);
1157  	}
1158  	pthread_mutex_unlock(&amp;f-&gt;lock);
1159  }
1160  static void unlink_node(struct fuse *f, struct node *node)
1161  {
1162  	if (f-&gt;conf.remember) {
1163  		assert(node-&gt;nlookup &gt; 1);
1164  		node-&gt;nlookup--;
1165  	}
1166  	unhash_name(f, node);
1167  }
1168  static void remove_node(struct fuse *f, fuse_ino_t dir, const char *name)
1169  {
1170  	struct node *node;
1171  	pthread_mutex_lock(&amp;f-&gt;lock);
1172  	node = lookup_node(f, dir, name);
1173  	if (node != NULL)
1174  		unlink_node(f, node);
1175  	pthread_mutex_unlock(&amp;f-&gt;lock);
1176  }
1177  static int rename_node(struct fuse *f, fuse_ino_t olddir, const char *oldname,
1178  		       fuse_ino_t newdir, const char *newname, int hide)
1179  {
1180  	struct node *node;
1181  	struct node *newnode;
1182  	int err = 0;
1183  	pthread_mutex_lock(&amp;f-&gt;lock);
1184  	node  = lookup_node(f, olddir, oldname);
1185  	newnode	 = lookup_node(f, newdir, newname);
1186  	if (node == NULL)
1187  		goto out;
1188  	if (newnode != NULL) {
1189  		if (hide) {
1190  			fuse_log(FUSE_LOG_ERR, &quot;fuse: hidden file got created during hiding\n&quot;);
1191  			err = -EBUSY;
1192  			goto out;
1193  		}
1194  		unlink_node(f, newnode);
1195  	}
1196  	unhash_name(f, node);
1197  	if (hash_name(f, node, newdir, newname) == -1) {
1198  		err = -ENOMEM;
1199  		goto out;
1200  	}
1201  	if (hide)
1202  		node-&gt;is_hidden = 1;
1203  out:
1204  	pthread_mutex_unlock(&amp;f-&gt;lock);
1205  	return err;
1206  }
1207  static int exchange_node(struct fuse *f, fuse_ino_t olddir, const char *oldname,
1208  			 fuse_ino_t newdir, const char *newname)
1209  {
1210  	struct node *oldnode;
1211  	struct node *newnode;
1212  	int err;
1213  	pthread_mutex_lock(&amp;f-&gt;lock);
1214  	oldnode  = lookup_node(f, olddir, oldname);
1215  	newnode	 = lookup_node(f, newdir, newname);
1216  	if (oldnode)
1217  		unhash_name(f, oldnode);
1218  	if (newnode)
1219  		unhash_name(f, newnode);
1220  	err = -ENOMEM;
1221  	if (oldnode) {
1222  		if (hash_name(f, oldnode, newdir, newname) == -1)
1223  			goto out;
1224  	}
1225  	if (newnode) {
1226  		if (hash_name(f, newnode, olddir, oldname) == -1)
1227  			goto out;
1228  	}
1229  	err = 0;
1230  out:
1231  	pthread_mutex_unlock(&amp;f-&gt;lock);
1232  	return err;
1233  }
1234  static void set_stat(struct fuse *f, fuse_ino_t nodeid, struct stat *stbuf)
1235  {
1236  	if (!f-&gt;conf.use_ino)
1237  		stbuf-&gt;st_ino = nodeid;
1238  	if (f-&gt;conf.set_mode)
1239  		stbuf-&gt;st_mode = (stbuf-&gt;st_mode &amp; S_IFMT) |
1240  				 (0777 &amp; ~f-&gt;conf.umask);
1241  	if (f-&gt;conf.set_uid)
1242  		stbuf-&gt;st_uid = f-&gt;conf.uid;
1243  	if (f-&gt;conf.set_gid)
1244  		stbuf-&gt;st_gid = f-&gt;conf.gid;
1245  }
1246  static struct fuse *req_fuse(fuse_req_t req)
1247  {
1248  	return (struct fuse *) fuse_req_userdata(req);
1249  }
1250  static void fuse_intr_sighandler(int sig)
1251  {
1252  	(void) sig;
1253  }
1254  struct fuse_intr_data {
1255  	pthread_t id;
1256  	pthread_cond_t cond;
1257  	int finished;
1258  };
1259  static void fuse_interrupt(fuse_req_t req, void *d_)
1260  {
1261  	struct fuse_intr_data *d = d_;
1262  	struct fuse *f = req_fuse(req);
1263  	if (d-&gt;id == pthread_self())
1264  		return;
1265  	pthread_mutex_lock(&amp;f-&gt;lock);
1266  	while (!d-&gt;finished) {
1267  		struct timeval now;
1268  		struct timespec timeout;
1269  		pthread_kill(d-&gt;id, f-&gt;conf.intr_signal);
1270  		gettimeofday(&amp;now, NULL);
1271  		timeout.tv_sec = now.tv_sec + 1;
1272  		timeout.tv_nsec = now.tv_usec * 1000;
1273  		pthread_cond_timedwait(&amp;d-&gt;cond, &amp;f-&gt;lock, &amp;timeout);
1274  	}
1275  	pthread_mutex_unlock(&amp;f-&gt;lock);
1276  }
1277  static void fuse_do_finish_interrupt(struct fuse *f, fuse_req_t req,
1278  				     struct fuse_intr_data *d)
1279  {
1280  	pthread_mutex_lock(&amp;f-&gt;lock);
1281  	d-&gt;finished = 1;
1282  	pthread_cond_broadcast(&amp;d-&gt;cond);
1283  	pthread_mutex_unlock(&amp;f-&gt;lock);
1284  	fuse_req_interrupt_func(req, NULL, NULL);
1285  	pthread_cond_destroy(&amp;d-&gt;cond);
1286  }
1287  static void fuse_do_prepare_interrupt(fuse_req_t req, struct fuse_intr_data *d)
1288  {
1289  	d-&gt;id = pthread_self();
1290  	pthread_cond_init(&amp;d-&gt;cond, NULL);
1291  	d-&gt;finished = 0;
1292  	fuse_req_interrupt_func(req, fuse_interrupt, d);
1293  }
1294  static inline void fuse_finish_interrupt(struct fuse *f, fuse_req_t req,
1295  					 struct fuse_intr_data *d)
1296  {
1297  	if (f-&gt;conf.intr)
1298  		fuse_do_finish_interrupt(f, req, d);
1299  }
1300  static inline void fuse_prepare_interrupt(struct fuse *f, fuse_req_t req,
1301  					  struct fuse_intr_data *d)
1302  {
1303  	if (f-&gt;conf.intr)
1304  		fuse_do_prepare_interrupt(req, d);
1305  }
1306  static const char* file_info_string(struct fuse_file_info *fi,
1307  			      char* buf, size_t len)
1308  {
1309  	if(fi == NULL)
1310  		return &quot;NULL&quot;;
1311  	snprintf(buf, len, &quot;%llu&quot;, (unsigned long long) fi-&gt;fh);
1312  	return buf;
1313  }
1314  int fuse_fs_getattr(struct fuse_fs *fs, const char *path, struct stat *buf,
1315  		    struct fuse_file_info *fi)
1316  {
1317  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1318  	if (fs-&gt;op.getattr) {
1319  		if (fs-&gt;debug) {
1320  			char buf[10];
1321  			fuse_log(FUSE_LOG_DEBUG, &quot;getattr[%s] %s\n&quot;,
1322  				file_info_string(fi, buf, sizeof(buf)),
1323  				path);
1324  		}
1325  		return fs-&gt;op.getattr(path, buf, fi);
1326  	} else {
1327  		return -ENOSYS;
1328  	}
1329  }
1330  int fuse_fs_rename(struct fuse_fs *fs, const char *oldpath,
1331  		   const char *newpath, unsigned int flags)
1332  {
1333  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1334  	if (fs-&gt;op.rename) {
1335  		if (fs-&gt;debug)
1336  			fuse_log(FUSE_LOG_DEBUG, &quot;rename %s %s 0x%x\n&quot;, oldpath, newpath,
1337  				flags);
1338  		return fs-&gt;op.rename(oldpath, newpath, flags);
1339  	} else {
1340  		return -ENOSYS;
1341  	}
1342  }
1343  int fuse_fs_unlink(struct fuse_fs *fs, const char *path)
1344  {
1345  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1346  	if (fs-&gt;op.unlink) {
1347  		if (fs-&gt;debug)
1348  			fuse_log(FUSE_LOG_DEBUG, &quot;unlink %s\n&quot;, path);
1349  		return fs-&gt;op.unlink(path);
1350  	} else {
1351  		return -ENOSYS;
1352  	}
1353  }
1354  int fuse_fs_rmdir(struct fuse_fs *fs, const char *path)
1355  {
1356  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1357  	if (fs-&gt;op.rmdir) {
1358  		if (fs-&gt;debug)
1359  			fuse_log(FUSE_LOG_DEBUG, &quot;rmdir %s\n&quot;, path);
1360  		return fs-&gt;op.rmdir(path);
1361  	} else {
1362  		return -ENOSYS;
1363  	}
1364  }
1365  int fuse_fs_symlink(struct fuse_fs *fs, const char *linkname, const char *path)
1366  {
1367  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1368  	if (fs-&gt;op.symlink) {
1369  		if (fs-&gt;debug)
1370  			fuse_log(FUSE_LOG_DEBUG, &quot;symlink %s %s\n&quot;, linkname, path);
1371  		return fs-&gt;op.symlink(linkname, path);
1372  	} else {
1373  		return -ENOSYS;
1374  	}
1375  }
1376  int fuse_fs_link(struct fuse_fs *fs, const char *oldpath, const char *newpath)
1377  {
1378  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1379  	if (fs-&gt;op.link) {
1380  		if (fs-&gt;debug)
1381  			fuse_log(FUSE_LOG_DEBUG, &quot;link %s %s\n&quot;, oldpath, newpath);
1382  		return fs-&gt;op.link(oldpath, newpath);
1383  	} else {
1384  		return -ENOSYS;
1385  	}
1386  }
1387  int fuse_fs_release(struct fuse_fs *fs,	 const char *path,
1388  		    struct fuse_file_info *fi)
1389  {
1390  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1391  	if (fs-&gt;op.release) {
1392  		if (fs-&gt;debug)
1393  			fuse_log(FUSE_LOG_DEBUG, &quot;release%s[%llu] flags: 0x%x\n&quot;,
1394  				fi-&gt;flush ? &quot;+flush&quot; : &quot;&quot;,
1395  				(unsigned long long) fi-&gt;fh, fi-&gt;flags);
1396  		return fs-&gt;op.release(path, fi);
1397  	} else {
1398  		return 0;
1399  	}
1400  }
1401  int fuse_fs_opendir(struct fuse_fs *fs, const char *path,
1402  		    struct fuse_file_info *fi)
1403  {
1404  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1405  	if (fs-&gt;op.opendir) {
1406  		int err;
1407  		if (fs-&gt;debug)
1408  			fuse_log(FUSE_LOG_DEBUG, &quot;opendir flags: 0x%x %s\n&quot;, fi-&gt;flags,
1409  				path);
1410  		err = fs-&gt;op.opendir(path, fi);
1411  		if (fs-&gt;debug &amp;&amp; !err)
1412  			fuse_log(FUSE_LOG_DEBUG, &quot;   opendir[%llu] flags: 0x%x %s\n&quot;,
1413  				(unsigned long long) fi-&gt;fh, fi-&gt;flags, path);
1414  		return err;
1415  	} else {
1416  		return 0;
1417  	}
1418  }
1419  int fuse_fs_open(struct fuse_fs *fs, const char *path,
1420  		 struct fuse_file_info *fi)
1421  {
1422  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1423  	if (fs-&gt;op.open) {
1424  		int err;
1425  		if (fs-&gt;debug)
1426  			fuse_log(FUSE_LOG_DEBUG, &quot;open flags: 0x%x %s\n&quot;, fi-&gt;flags,
1427  				path);
1428  		err = fs-&gt;op.open(path, fi);
1429  		if (fs-&gt;debug &amp;&amp; !err)
1430  			fuse_log(FUSE_LOG_DEBUG, &quot;   open[%llu] flags: 0x%x %s\n&quot;,
1431  				(unsigned long long) fi-&gt;fh, fi-&gt;flags, path);
1432  		return err;
1433  	} else {
1434  		return 0;
1435  	}
1436  }
1437  static void fuse_free_buf(struct fuse_bufvec *buf)
1438  {
1439  	if (buf != NULL) {
1440  		size_t i;
1441  		for (i = 0; i &lt; buf-&gt;count; i++)
1442  			if (!(buf-&gt;buf[i].flags &amp; FUSE_BUF_IS_FD))
1443  				free(buf-&gt;buf[i].mem);
1444  		free(buf);
1445  	}
1446  }
1447  int fuse_fs_read_buf(struct fuse_fs *fs, const char *path,
1448  		     struct fuse_bufvec **bufp, size_t size, off_t off,
1449  		     struct fuse_file_info *fi)
1450  {
1451  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1452  	if (fs-&gt;op.read || fs-&gt;op.read_buf) {
1453  		int res;
1454  		if (fs-&gt;debug)
1455  			fuse_log(FUSE_LOG_DEBUG,
1456  				&quot;read[%llu] %zu bytes from %llu flags: 0x%x\n&quot;,
1457  				(unsigned long long) fi-&gt;fh,
1458  				size, (unsigned long long) off, fi-&gt;flags);
1459  		if (fs-&gt;op.read_buf) {
1460  			res = fs-&gt;op.read_buf(path, bufp, size, off, fi);
1461  		} else {
1462  			struct fuse_bufvec *buf;
1463  			void *mem;
1464  			buf = malloc(sizeof(struct fuse_bufvec));
1465  			if (buf == NULL)
1466  				return -ENOMEM;
1467  			mem = malloc(size);
1468  			if (mem == NULL) {
1469  				free(buf);
1470  				return -ENOMEM;
1471  			}
1472  			*buf = FUSE_BUFVEC_INIT(size);
1473  			buf-&gt;buf[0].mem = mem;
1474  			*bufp = buf;
1475  			res = fs-&gt;op.read(path, mem, size, off, fi);
1476  			if (res &gt;= 0)
1477  				buf-&gt;buf[0].size = res;
1478  		}
1479  		if (fs-&gt;debug &amp;&amp; res &gt;= 0)
1480  			fuse_log(FUSE_LOG_DEBUG, &quot;   read[%llu] %zu bytes from %llu\n&quot;,
1481  				(unsigned long long) fi-&gt;fh,
1482  				fuse_buf_size(*bufp),
1483  				(unsigned long long) off);
1484  		if (res &gt;= 0 &amp;&amp; fuse_buf_size(*bufp) &gt; size)
1485  			fuse_log(FUSE_LOG_ERR, &quot;fuse: read too many bytes\n&quot;);
1486  		if (res &lt; 0)
1487  			return res;
1488  		return 0;
1489  	} else {
1490  		return -ENOSYS;
1491  	}
1492  }
1493  int fuse_fs_read(struct fuse_fs *fs, const char *path, char *mem, size_t size,
1494  		 off_t off, struct fuse_file_info *fi)
1495  {
1496  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1497  	if (fs-&gt;op.read || fs-&gt;op.read_buf) {
1498  		int res;
1499  		if (fs-&gt;debug)
1500  			fuse_log(FUSE_LOG_DEBUG,
1501  				&quot;read[%llu] %zu bytes from %llu flags: 0x%x\n&quot;,
1502  				(unsigned long long) fi-&gt;fh,
1503  				size, (unsigned long long) off, fi-&gt;flags);
1504  		if (fs-&gt;op.read_buf) {
1505  			struct fuse_bufvec *buf = NULL;
1506  			res = fs-&gt;op.read_buf(path, &amp;buf, size, off, fi);
1507  			if (res == 0) {
1508  				struct fuse_bufvec dst = FUSE_BUFVEC_INIT(size);
1509  				dst.buf[0].mem = mem;
1510  				res = fuse_buf_copy(&amp;dst, buf, 0);
1511  			}
1512  			fuse_free_buf(buf);
1513  		} else {
1514  			res = fs-&gt;op.read(path, mem, size, off, fi);
1515  		}
1516  		if (fs-&gt;debug &amp;&amp; res &gt;= 0)
1517  			fuse_log(FUSE_LOG_DEBUG, &quot;   read[%llu] %u bytes from %llu\n&quot;,
1518  				(unsigned long long) fi-&gt;fh,
1519  				res,
1520  				(unsigned long long) off);
1521  		if (res &gt;= 0 &amp;&amp; res &gt; (int) size)
1522  			fuse_log(FUSE_LOG_ERR, &quot;fuse: read too many bytes\n&quot;);
1523  		return res;
1524  	} else {
1525  		return -ENOSYS;
1526  	}
1527  }
1528  int fuse_fs_write_buf(struct fuse_fs *fs, const char *path,
1529  		      struct fuse_bufvec *buf, off_t off,
1530  		      struct fuse_file_info *fi)
1531  {
1532  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1533  	if (fs-&gt;op.write_buf || fs-&gt;op.write) {
1534  		int res;
1535  		size_t size = fuse_buf_size(buf);
1536  		assert(buf-&gt;idx == 0 &amp;&amp; buf-&gt;off == 0);
1537  		if (fs-&gt;debug)
1538  			fuse_log(FUSE_LOG_DEBUG,
1539  				&quot;write%s[%llu] %zu bytes to %llu flags: 0x%x\n&quot;,
1540  				fi-&gt;writepage ? &quot;page&quot; : &quot;&quot;,
1541  				(unsigned long long) fi-&gt;fh,
1542  				size,
1543  				(unsigned long long) off,
1544  				fi-&gt;flags);
1545  		if (fs-&gt;op.write_buf) {
1546  			res = fs-&gt;op.write_buf(path, buf, off, fi);
1547  		} else {
1548  			void *mem = NULL;
1549  			struct fuse_buf *flatbuf;
1550  			struct fuse_bufvec tmp = FUSE_BUFVEC_INIT(size);
1551  			if (buf-&gt;count == 1 &amp;&amp;
1552  			    !(buf-&gt;buf[0].flags &amp; FUSE_BUF_IS_FD)) {
1553  				flatbuf = &amp;buf-&gt;buf[0];
1554  			} else {
1555  				res = -ENOMEM;
1556  				mem = malloc(size);
1557  				if (mem == NULL)
1558  					goto out;
1559  				tmp.buf[0].mem = mem;
1560  				res = fuse_buf_copy(&amp;tmp, buf, 0);
1561  				if (res &lt;= 0)
1562  					goto out_free;
1563  				tmp.buf[0].size = res;
1564  				flatbuf = &amp;tmp.buf[0];
1565  			}
1566  			res = fs-&gt;op.write(path, flatbuf-&gt;mem, flatbuf-&gt;size,
1567  					   off, fi);
1568  out_free:
1569  			free(mem);
1570  		}
1571  out:
1572  		if (fs-&gt;debug &amp;&amp; res &gt;= 0)
1573  			fuse_log(FUSE_LOG_DEBUG, &quot;   write%s[%llu] %u bytes to %llu\n&quot;,
1574  				fi-&gt;writepage ? &quot;page&quot; : &quot;&quot;,
1575  				(unsigned long long) fi-&gt;fh, res,
1576  				(unsigned long long) off);
1577  		if (res &gt; (int) size)
1578  			fuse_log(FUSE_LOG_ERR, &quot;fuse: wrote too many bytes\n&quot;);
1579  		return res;
1580  	} else {
1581  		return -ENOSYS;
1582  	}
1583  }
1584  int fuse_fs_write(struct fuse_fs *fs, const char *path, const char *mem,
1585  		  size_t size, off_t off, struct fuse_file_info *fi)
1586  {
1587  	struct fuse_bufvec bufv = FUSE_BUFVEC_INIT(size);
1588  	bufv.buf[0].mem = (void *) mem;
1589  	return fuse_fs_write_buf(fs, path, &amp;bufv, off, fi);
1590  }
1591  int fuse_fs_fsync(struct fuse_fs *fs, const char *path, int datasync,
1592  		  struct fuse_file_info *fi)
1593  {
1594  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1595  	if (fs-&gt;op.fsync) {
1596  		if (fs-&gt;debug)
1597  			fuse_log(FUSE_LOG_DEBUG, &quot;fsync[%llu] datasync: %i\n&quot;,
1598  				(unsigned long long) fi-&gt;fh, datasync);
1599  		return fs-&gt;op.fsync(path, datasync, fi);
1600  	} else {
1601  		return -ENOSYS;
1602  	}
1603  }
1604  int fuse_fs_fsyncdir(struct fuse_fs *fs, const char *path, int datasync,
1605  		     struct fuse_file_info *fi)
1606  {
1607  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1608  	if (fs-&gt;op.fsyncdir) {
1609  		if (fs-&gt;debug)
1610  			fuse_log(FUSE_LOG_DEBUG, &quot;fsyncdir[%llu] datasync: %i\n&quot;,
1611  				(unsigned long long) fi-&gt;fh, datasync);
1612  		return fs-&gt;op.fsyncdir(path, datasync, fi);
1613  	} else {
1614  		return -ENOSYS;
1615  	}
1616  }
1617  int fuse_fs_flush(struct fuse_fs *fs, const char *path,
1618  		  struct fuse_file_info *fi)
1619  {
1620  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1621  	if (fs-&gt;op.flush) {
1622  		if (fs-&gt;debug)
1623  			fuse_log(FUSE_LOG_DEBUG, &quot;flush[%llu]\n&quot;,
1624  				(unsigned long long) fi-&gt;fh);
1625  		return fs-&gt;op.flush(path, fi);
1626  	} else {
1627  		return -ENOSYS;
1628  	}
1629  }
1630  int fuse_fs_statfs(struct fuse_fs *fs, const char *path, struct statvfs *buf)
1631  {
1632  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1633  	if (fs-&gt;op.statfs) {
1634  		if (fs-&gt;debug)
1635  			fuse_log(FUSE_LOG_DEBUG, &quot;statfs %s\n&quot;, path);
1636  		return fs-&gt;op.statfs(path, buf);
1637  	} else {
1638  		buf-&gt;f_namemax = 255;
1639  		buf-&gt;f_bsize = 512;
1640  		return 0;
1641  	}
1642  }
1643  int fuse_fs_releasedir(struct fuse_fs *fs, const char *path,
1644  		       struct fuse_file_info *fi)
1645  {
1646  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1647  	if (fs-&gt;op.releasedir) {
1648  		if (fs-&gt;debug)
1649  			fuse_log(FUSE_LOG_DEBUG, &quot;releasedir[%llu] flags: 0x%x\n&quot;,
1650  				(unsigned long long) fi-&gt;fh, fi-&gt;flags);
1651  		return fs-&gt;op.releasedir(path, fi);
1652  	} else {
1653  		return 0;
1654  	}
1655  }
1656  int fuse_fs_readdir(struct fuse_fs *fs, const char *path, void *buf,
1657  		    fuse_fill_dir_t filler, off_t off,
1658  		    struct fuse_file_info *fi,
1659  		    enum fuse_readdir_flags flags)
1660  {
1661  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1662  	if (fs-&gt;op.readdir) {
1663  		if (fs-&gt;debug) {
1664  			fuse_log(FUSE_LOG_DEBUG, &quot;readdir%s[%llu] from %llu\n&quot;,
1665  				(flags &amp; FUSE_READDIR_PLUS) ? &quot;plus&quot; : &quot;&quot;,
1666  				(unsigned long long) fi-&gt;fh,
1667  				(unsigned long long) off);
1668  		}
1669  		return fs-&gt;op.readdir(path, buf, filler, off, fi, flags);
1670  	} else {
1671  		return -ENOSYS;
1672  	}
1673  }
1674  int fuse_fs_create(struct fuse_fs *fs, const char *path, mode_t mode,
1675  		   struct fuse_file_info *fi)
1676  {
1677  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1678  	if (fs-&gt;op.create) {
1679  		int err;
1680  		if (fs-&gt;debug)
1681  			fuse_log(FUSE_LOG_DEBUG,
1682  				&quot;create flags: 0x%x %s 0%o umask=0%03o\n&quot;,
1683  				fi-&gt;flags, path, mode,
1684  				fuse_get_context()-&gt;umask);
1685  		err = fs-&gt;op.create(path, mode, fi);
1686  		if (fs-&gt;debug &amp;&amp; !err)
1687  			fuse_log(FUSE_LOG_DEBUG, &quot;   create[%llu] flags: 0x%x %s\n&quot;,
1688  				(unsigned long long) fi-&gt;fh, fi-&gt;flags, path);
1689  		return err;
1690  	} else {
1691  		return -ENOSYS;
1692  	}
1693  }
1694  int fuse_fs_lock(struct fuse_fs *fs, const char *path,
1695  		 struct fuse_file_info *fi, int cmd, struct flock *lock)
1696  {
1697  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1698  	if (fs-&gt;op.lock) {
1699  		if (fs-&gt;debug)
1700  			fuse_log(FUSE_LOG_DEBUG, &quot;lock[%llu] %s %s start: %llu len: %llu pid: %llu\n&quot;,
1701  				(unsigned long long) fi-&gt;fh,
1702  				(cmd == F_GETLK ? &quot;F_GETLK&quot; :
1703  				 (cmd == F_SETLK ? &quot;F_SETLK&quot; :
1704  				  (cmd == F_SETLKW ? &quot;F_SETLKW&quot; : &quot;???&quot;))),
1705  				(lock-&gt;l_type == F_RDLCK ? &quot;F_RDLCK&quot; :
1706  				 (lock-&gt;l_type == F_WRLCK ? &quot;F_WRLCK&quot; :
1707  				  (lock-&gt;l_type == F_UNLCK ? &quot;F_UNLCK&quot; :
1708  				   &quot;???&quot;))),
1709  				(unsigned long long) lock-&gt;l_start,
1710  				(unsigned long long) lock-&gt;l_len,
1711  				(unsigned long long) lock-&gt;l_pid);
1712  		return fs-&gt;op.lock(path, fi, cmd, lock);
1713  	} else {
1714  		return -ENOSYS;
1715  	}
1716  }
1717  int fuse_fs_flock(struct fuse_fs *fs, const char *path,
1718  		  struct fuse_file_info *fi, int op)
1719  {
1720  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1721  	if (fs-&gt;op.flock) {
1722  		if (fs-&gt;debug) {
1723  			int xop = op &amp; ~LOCK_NB;
1724  			fuse_log(FUSE_LOG_DEBUG, &quot;lock[%llu] %s%s\n&quot;,
1725  				(unsigned long long) fi-&gt;fh,
1726  				xop == LOCK_SH ? &quot;LOCK_SH&quot; :
1727  				(xop == LOCK_EX ? &quot;LOCK_EX&quot; :
1728  				 (xop == LOCK_UN ? &quot;LOCK_UN&quot; : &quot;???&quot;)),
1729  				(op &amp; LOCK_NB) ? &quot;|LOCK_NB&quot; : &quot;&quot;);
1730  		}
1731  		return fs-&gt;op.flock(path, fi, op);
1732  	} else {
1733  		return -ENOSYS;
1734  	}
1735  }
1736  int fuse_fs_chown(struct fuse_fs *fs, const char *path, uid_t uid,
1737  		  gid_t gid, struct fuse_file_info *fi)
1738  {
1739  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1740  	if (fs-&gt;op.chown) {
1741  		if (fs-&gt;debug) {
1742  			char buf[10];
1743  			fuse_log(FUSE_LOG_DEBUG, &quot;chown[%s] %s %lu %lu\n&quot;,
1744  				file_info_string(fi, buf, sizeof(buf)),
1745  				path, (unsigned long) uid, (unsigned long) gid);
1746  		}
1747  		return fs-&gt;op.chown(path, uid, gid, fi);
1748  	} else {
1749  		return -ENOSYS;
1750  	}
1751  }
1752  int fuse_fs_truncate(struct fuse_fs *fs, const char *path, off_t size,
1753  		      struct fuse_file_info *fi)
1754  {
1755  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1756  	if (fs-&gt;op.truncate) {
1757  		if (fs-&gt;debug) {
1758  			char buf[10];
1759  			fuse_log(FUSE_LOG_DEBUG, &quot;truncate[%s] %llu\n&quot;,
1760  				file_info_string(fi, buf, sizeof(buf)),
1761  				(unsigned long long) size);
1762  		}
1763  		return fs-&gt;op.truncate(path, size, fi);
1764  	} else {
1765  		return -ENOSYS;
1766  	}
1767  }
1768  int fuse_fs_utimens(struct fuse_fs *fs, const char *path,
1769  		    const struct timespec tv[2], struct fuse_file_info *fi)
1770  {
1771  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1772  	if (fs-&gt;op.utimens) {
1773  		if (fs-&gt;debug) {
1774  			char buf[10];
1775  			fuse_log(FUSE_LOG_DEBUG, &quot;utimens[%s] %s %li.%09lu %li.%09lu\n&quot;,
1776  				file_info_string(fi, buf, sizeof(buf)),
1777  				path, tv[0].tv_sec, tv[0].tv_nsec,
1778  				tv[1].tv_sec, tv[1].tv_nsec);
1779  		}
1780  		return fs-&gt;op.utimens(path, tv, fi);
1781  	} else {
1782  		return -ENOSYS;
1783  	}
1784  }
1785  int fuse_fs_access(struct fuse_fs *fs, const char *path, int mask)
1786  {
1787  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1788  	if (fs-&gt;op.access) {
1789  		if (fs-&gt;debug)
1790  			fuse_log(FUSE_LOG_DEBUG, &quot;access %s 0%o\n&quot;, path, mask);
1791  		return fs-&gt;op.access(path, mask);
1792  	} else {
1793  		return -ENOSYS;
1794  	}
1795  }
1796  int fuse_fs_readlink(struct fuse_fs *fs, const char *path, char *buf,
1797  		     size_t len)
1798  {
1799  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1800  	if (fs-&gt;op.readlink) {
1801  		if (fs-&gt;debug)
1802  			fuse_log(FUSE_LOG_DEBUG, &quot;readlink %s %lu\n&quot;, path,
1803  				(unsigned long) len);
1804  		return fs-&gt;op.readlink(path, buf, len);
1805  	} else {
1806  		return -ENOSYS;
1807  	}
1808  }
1809  int fuse_fs_mknod(struct fuse_fs *fs, const char *path, mode_t mode,
1810  		  dev_t rdev)
1811  {
1812  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1813  	if (fs-&gt;op.mknod) {
1814  		if (fs-&gt;debug)
1815  			fuse_log(FUSE_LOG_DEBUG, &quot;mknod %s 0%o 0x%llx umask=0%03o\n&quot;,
1816  				path, mode, (unsigned long long) rdev,
1817  				fuse_get_context()-&gt;umask);
1818  		return fs-&gt;op.mknod(path, mode, rdev);
1819  	} else {
1820  		return -ENOSYS;
1821  	}
1822  }
1823  int fuse_fs_mkdir(struct fuse_fs *fs, const char *path, mode_t mode)
1824  {
1825  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1826  	if (fs-&gt;op.mkdir) {
1827  		if (fs-&gt;debug)
1828  			fuse_log(FUSE_LOG_DEBUG, &quot;mkdir %s 0%o umask=0%03o\n&quot;,
1829  				path, mode, fuse_get_context()-&gt;umask);
1830  		return fs-&gt;op.mkdir(path, mode);
1831  	} else {
1832  		return -ENOSYS;
1833  	}
1834  }
1835  int fuse_fs_setxattr(struct fuse_fs *fs, const char *path, const char *name,
1836  		     const char *value, size_t size, int flags)
1837  {
1838  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1839  	if (fs-&gt;op.setxattr) {
1840  		if (fs-&gt;debug)
1841  			fuse_log(FUSE_LOG_DEBUG, &quot;setxattr %s %s %lu 0x%x\n&quot;,
1842  				path, name, (unsigned long) size, flags);
1843  		return fs-&gt;op.setxattr(path, name, value, size, flags);
1844  	} else {
1845  		return -ENOSYS;
1846  	}
1847  }
1848  int fuse_fs_getxattr(struct fuse_fs *fs, const char *path, const char *name,
1849  		     char *value, size_t size)
1850  {
1851  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1852  	if (fs-&gt;op.getxattr) {
1853  		if (fs-&gt;debug)
1854  			fuse_log(FUSE_LOG_DEBUG, &quot;getxattr %s %s %lu\n&quot;,
1855  				path, name, (unsigned long) size);
1856  		return fs-&gt;op.getxattr(path, name, value, size);
1857  	} else {
1858  		return -ENOSYS;
1859  	}
1860  }
1861  int fuse_fs_listxattr(struct fuse_fs *fs, const char *path, char *list,
1862  		      size_t size)
1863  {
1864  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1865  	if (fs-&gt;op.listxattr) {
1866  		if (fs-&gt;debug)
1867  			fuse_log(FUSE_LOG_DEBUG, &quot;listxattr %s %lu\n&quot;,
1868  				path, (unsigned long) size);
1869  		return fs-&gt;op.listxattr(path, list, size);
1870  	} else {
1871  		return -ENOSYS;
1872  	}
1873  }
1874  int fuse_fs_bmap(struct fuse_fs *fs, const char *path, size_t blocksize,
1875  		 uint64_t *idx)
1876  {
1877  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1878  	if (fs-&gt;op.bmap) {
1879  		if (fs-&gt;debug)
1880  			fuse_log(FUSE_LOG_DEBUG, &quot;bmap %s blocksize: %lu index: %llu\n&quot;,
1881  				path, (unsigned long) blocksize,
1882  				(unsigned long long) *idx);
1883  		return fs-&gt;op.bmap(path, blocksize, idx);
1884  	} else {
1885  		return -ENOSYS;
1886  	}
1887  }
1888  int fuse_fs_removexattr(struct fuse_fs *fs, const char *path, const char *name)
1889  {
1890  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1891  	if (fs-&gt;op.removexattr) {
1892  		if (fs-&gt;debug)
1893  			fuse_log(FUSE_LOG_DEBUG, &quot;removexattr %s %s\n&quot;, path, name);
1894  		return fs-&gt;op.removexattr(path, name);
1895  	} else {
1896  		return -ENOSYS;
1897  	}
1898  }
1899  int fuse_fs_ioctl(struct fuse_fs *fs, const char *path, unsigned int cmd,
1900  		  void *arg, struct fuse_file_info *fi, unsigned int flags,
1901  		  void *data)
1902  {
1903  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1904  	if (fs-&gt;op.ioctl) {
1905  		if (fs-&gt;debug)
1906  			fuse_log(FUSE_LOG_DEBUG, &quot;ioctl[%llu] 0x%x flags: 0x%x\n&quot;,
1907  				(unsigned long long) fi-&gt;fh, cmd, flags);
1908  		return fs-&gt;op.ioctl(path, cmd, arg, fi, flags, data);
1909  	} else
1910  		return -ENOSYS;
1911  }
1912  int fuse_fs_poll(struct fuse_fs *fs, const char *path,
1913  		 struct fuse_file_info *fi, struct fuse_pollhandle *ph,
1914  		 unsigned *reventsp)
1915  {
1916  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1917  	if (fs-&gt;op.poll) {
1918  		int res;
1919  		if (fs-&gt;debug)
1920  			fuse_log(FUSE_LOG_DEBUG, &quot;poll[%llu] ph: %p, events 0x%x\n&quot;,
1921  				(unsigned long long) fi-&gt;fh, ph,
1922  				fi-&gt;poll_events);
1923  		res = fs-&gt;op.poll(path, fi, ph, reventsp);
1924  		if (fs-&gt;debug &amp;&amp; !res)
1925  			fuse_log(FUSE_LOG_DEBUG, &quot;   poll[%llu] revents: 0x%x\n&quot;,
1926  				(unsigned long long) fi-&gt;fh, *reventsp);
1927  		return res;
1928  	} else
1929  		return -ENOSYS;
1930  }
1931  int fuse_fs_fallocate(struct fuse_fs *fs, const char *path, int mode,
1932  		off_t offset, off_t length, struct fuse_file_info *fi)
1933  {
1934  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1935  	if (fs-&gt;op.fallocate) {
1936  		if (fs-&gt;debug)
1937  			fuse_log(FUSE_LOG_DEBUG, &quot;fallocate %s mode %x, offset: %llu, length: %llu\n&quot;,
1938  				path,
1939  				mode,
1940  				(unsigned long long) offset,
1941  				(unsigned long long) length);
1942  		return fs-&gt;op.fallocate(path, mode, offset, length, fi);
1943  	} else
1944  		return -ENOSYS;
1945  }
1946  ssize_t fuse_fs_copy_file_range(struct fuse_fs *fs, const char *path_in,
1947  				struct fuse_file_info *fi_in, off_t off_in,
1948  				const char *path_out,
1949  				struct fuse_file_info *fi_out, off_t off_out,
1950  				size_t len, int flags)
1951  {
1952  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1953  	if (fs-&gt;op.copy_file_range) {
1954  		if (fs-&gt;debug)
1955  			fuse_log(FUSE_LOG_DEBUG, &quot;copy_file_range from %s:%llu to &quot;
1956  			                &quot;%s:%llu, length: %llu\n&quot;,
1957  				path_in,
1958  				(unsigned long long) off_in,
1959  				path_out,
1960  				(unsigned long long) off_out,
1961  				(unsigned long long) len);
1962  		return fs-&gt;op.copy_file_range(path_in, fi_in, off_in, path_out,
1963  					      fi_out, off_out, len, flags);
1964  	} else
1965  		return -ENOSYS;
1966  }
1967  off_t fuse_fs_lseek(struct fuse_fs *fs, const char *path, off_t off, int whence,
1968  		    struct fuse_file_info *fi)
1969  {
1970  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
1971  	if (fs-&gt;op.lseek) {
1972  		if (fs-&gt;debug) {
1973  			char buf[10];
1974  			fuse_log(FUSE_LOG_DEBUG, &quot;lseek[%s] %llu %d\n&quot;,
1975  				file_info_string(fi, buf, sizeof(buf)),
1976  				(unsigned long long) off, whence);
1977  		}
1978  		return fs-&gt;op.lseek(path, off, whence, fi);
1979  	} else {
1980  		return -ENOSYS;
1981  	}
1982  }
1983  static int is_open(struct fuse *f, fuse_ino_t dir, const char *name)
1984  {
1985  	struct node *node;
1986  	int isopen = 0;
1987  	pthread_mutex_lock(&amp;f-&gt;lock);
1988  	node = lookup_node(f, dir, name);
1989  	if (node &amp;&amp; node-&gt;open_count &gt; 0)
1990  		isopen = 1;
1991  	pthread_mutex_unlock(&amp;f-&gt;lock);
1992  	return isopen;
1993  }
1994  static char *hidden_name(struct fuse *f, fuse_ino_t dir, const char *oldname,
1995  			 char *newname, size_t bufsize)
1996  {
1997  	struct stat buf;
1998  	struct node *node;
1999  	struct node *newnode;
2000  	char *newpath;
2001  	int res;
2002  	int failctr = 10;
2003  	do {
2004  		pthread_mutex_lock(&amp;f-&gt;lock);
2005  		node = lookup_node(f, dir, oldname);
2006  		if (node == NULL) {
2007  			pthread_mutex_unlock(&amp;f-&gt;lock);
2008  			return NULL;
2009  		}
2010  		do {
2011  			f-&gt;hidectr ++;
2012  			snprintf(newname, bufsize, &quot;.fuse_hidden%08x%08x&quot;,
2013  				 (unsigned int) node-&gt;nodeid, f-&gt;hidectr);
2014  			newnode = lookup_node(f, dir, newname);
2015  		} while(newnode);
2016  		res = try_get_path(f, dir, newname, &amp;newpath, NULL, false);
2017  		pthread_mutex_unlock(&amp;f-&gt;lock);
2018  		if (res)
2019  			break;
2020  		memset(&amp;buf, 0, sizeof(buf));
2021  		res = fuse_fs_getattr(f-&gt;fs, newpath, &amp;buf, NULL);
2022  		if (res == -ENOENT)
2023  			break;
2024  		free(newpath);
2025  		newpath = NULL;
2026  	} while(res == 0 &amp;&amp; --failctr);
2027  	return newpath;
2028  }
2029  static int hide_node(struct fuse *f, const char *oldpath,
2030  		     fuse_ino_t dir, const char *oldname)
2031  {
2032  	char newname[64];
2033  	char *newpath;
2034  	int err = -EBUSY;
2035  	newpath = hidden_name(f, dir, oldname, newname, sizeof(newname));
2036  	if (newpath) {
2037  		err = fuse_fs_rename(f-&gt;fs, oldpath, newpath, 0);
2038  		if (!err)
2039  			err = rename_node(f, dir, oldname, dir, newname, 1);
2040  		free(newpath);
2041  	}
2042  	return err;
2043  }
2044  static int mtime_eq(const struct stat *stbuf, const struct timespec *ts)
2045  {
2046  	return stbuf-&gt;st_mtime == ts-&gt;tv_sec &amp;&amp;
2047  		ST_MTIM_NSEC(stbuf) == ts-&gt;tv_nsec;
2048  }
2049  #ifndef CLOCK_MONOTONIC
2050  #define CLOCK_MONOTONIC CLOCK_REALTIME
2051  #endif
2052  static void curr_time(struct timespec *now)
2053  {
2054  	static clockid_t clockid = CLOCK_MONOTONIC;
2055  	int res = clock_gettime(clockid, now);
2056  	if (res == -1 &amp;&amp; errno == EINVAL) {
2057  		clockid = CLOCK_REALTIME;
2058  		res = clock_gettime(clockid, now);
2059  	}
2060  	if (res == -1) {
2061  		perror(&quot;fuse: clock_gettime&quot;);
2062  		abort();
2063  	}
2064  }
2065  static void update_stat(struct node *node, const struct stat *stbuf)
2066  {
2067  	if (node-&gt;cache_valid &amp;&amp; (!mtime_eq(stbuf, &amp;node-&gt;mtime) ||
2068  				  stbuf-&gt;st_size != node-&gt;size))
2069  		node-&gt;cache_valid = 0;
2070  	node-&gt;mtime.tv_sec = stbuf-&gt;st_mtime;
2071  	node-&gt;mtime.tv_nsec = ST_MTIM_NSEC(stbuf);
2072  	node-&gt;size = stbuf-&gt;st_size;
2073  	curr_time(&amp;node-&gt;stat_updated);
2074  }
2075  static int do_lookup(struct fuse *f, fuse_ino_t nodeid, const char *name,
2076  		     struct fuse_entry_param *e)
2077  {
2078  	struct node *node;
2079  	node = find_node(f, nodeid, name);
2080  	if (node == NULL)
2081  		return -ENOMEM;
2082  	e-&gt;ino = node-&gt;nodeid;
2083  	e-&gt;generation = node-&gt;generation;
2084  	e-&gt;entry_timeout = f-&gt;conf.entry_timeout;
2085  	e-&gt;attr_timeout = f-&gt;conf.attr_timeout;
2086  	if (f-&gt;conf.auto_cache) {
2087  		pthread_mutex_lock(&amp;f-&gt;lock);
2088  		update_stat(node, &amp;e-&gt;attr);
2089  		pthread_mutex_unlock(&amp;f-&gt;lock);
2090  	}
2091  	set_stat(f, e-&gt;ino, &amp;e-&gt;attr);
2092  	return 0;
2093  }
2094  static int lookup_path(struct fuse *f, fuse_ino_t nodeid,
2095  		       const char *name, const char *path,
2096  		       struct fuse_entry_param *e, struct fuse_file_info *fi)
2097  {
2098  	int res;
2099  	memset(e, 0, sizeof(struct fuse_entry_param));
2100  	res = fuse_fs_getattr(f-&gt;fs, path, &amp;e-&gt;attr, fi);
2101  	if (res == 0) {
2102  		res = do_lookup(f, nodeid, name, e);
2103  		if (res == 0 &amp;&amp; f-&gt;conf.debug) {
2104  			fuse_log(FUSE_LOG_DEBUG, &quot;   NODEID: %llu\n&quot;,
2105  				(unsigned long long) e-&gt;ino);
2106  		}
2107  	}
2108  	return res;
2109  }
2110  static struct fuse_context_i *fuse_get_context_internal(void)
2111  {
2112  	return (struct fuse_context_i *) pthread_getspecific(fuse_context_key);
2113  }
2114  static struct fuse_context_i *fuse_create_context(struct fuse *f)
2115  {
2116  	struct fuse_context_i *c = fuse_get_context_internal();
2117  	if (c == NULL) {
2118  		c = (struct fuse_context_i *)
2119  			calloc(1, sizeof(struct fuse_context_i));
2120  		if (c == NULL) {
2121  			fuse_log(FUSE_LOG_ERR, &quot;fuse: failed to allocate thread specific data\n&quot;);
2122  			abort();
2123  		}
2124  		pthread_setspecific(fuse_context_key, c);
2125  	} else {
2126  		memset(c, 0, sizeof(*c));
2127  	}
2128  	c-&gt;ctx.fuse = f;
2129  	return c;
2130  }
2131  static void fuse_freecontext(void *data)
2132  {
2133  	free(data);
2134  }
2135  static int fuse_create_context_key(void)
2136  {
2137  	int err = 0;
2138  	pthread_mutex_lock(&amp;fuse_context_lock);
2139  	if (!fuse_context_ref) {
2140  		err = pthread_key_create(&amp;fuse_context_key, fuse_freecontext);
2141  		if (err) {
2142  			fuse_log(FUSE_LOG_ERR, &quot;fuse: failed to create thread specific key: %s\n&quot;,
2143  				strerror(err));
2144  			pthread_mutex_unlock(&amp;fuse_context_lock);
2145  			return -1;
2146  		}
2147  	}
2148  	fuse_context_ref++;
2149  	pthread_mutex_unlock(&amp;fuse_context_lock);
2150  	return 0;
2151  }
2152  static void fuse_delete_context_key(void)
2153  {
2154  	pthread_mutex_lock(&amp;fuse_context_lock);
2155  	fuse_context_ref--;
2156  	if (!fuse_context_ref) {
2157  		free(pthread_getspecific(fuse_context_key));
2158  		pthread_key_delete(fuse_context_key);
2159  	}
2160  	pthread_mutex_unlock(&amp;fuse_context_lock);
2161  }
2162  static struct fuse *req_fuse_prepare(fuse_req_t req)
2163  {
2164  	struct fuse_context_i *c = fuse_create_context(req_fuse(req));
2165  	const struct fuse_ctx *ctx = fuse_req_ctx(req);
2166  	c-&gt;req = req;
2167  	c-&gt;ctx.uid = ctx-&gt;uid;
2168  	c-&gt;ctx.gid = ctx-&gt;gid;
2169  	c-&gt;ctx.pid = ctx-&gt;pid;
2170  	c-&gt;ctx.umask = ctx-&gt;umask;
2171  	return c-&gt;ctx.fuse;
2172  }
2173  static inline void reply_err(fuse_req_t req, int err)
2174  {
2175  	fuse_reply_err(req, -err);
2176  }
2177  static void reply_entry(fuse_req_t req, const struct fuse_entry_param *e,
2178  			int err)
2179  {
2180  	if (!err) {
2181  		struct fuse *f = req_fuse(req);
2182  		if (fuse_reply_entry(req, e) == -ENOENT) {
2183  			if  (e-&gt;ino != 0)
2184  				forget_node(f, e-&gt;ino, 1);
2185  		}
2186  	} else
2187  		reply_err(req, err);
2188  }
2189  void fuse_fs_init(struct fuse_fs *fs, struct fuse_conn_info *conn,
2190  		  struct fuse_config *cfg)
2191  {
2192  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
2193  	if (!fs-&gt;op.write_buf)
2194  		conn-&gt;want &amp;= ~FUSE_CAP_SPLICE_READ;
2195  	if (!fs-&gt;op.lock)
2196  		conn-&gt;want &amp;= ~FUSE_CAP_POSIX_LOCKS;
2197  	if (!fs-&gt;op.flock)
2198  		conn-&gt;want &amp;= ~FUSE_CAP_FLOCK_LOCKS;
2199  	if (fs-&gt;op.init)
2200  		fs-&gt;user_data = fs-&gt;op.init(conn, cfg);
2201  }
2202  static void fuse_lib_init(void *data, struct fuse_conn_info *conn)
2203  {
2204  	struct fuse *f = (struct fuse *) data;
2205  	fuse_create_context(f);
2206  	if(conn-&gt;capable &amp; FUSE_CAP_EXPORT_SUPPORT)
2207  		conn-&gt;want |= FUSE_CAP_EXPORT_SUPPORT;
2208  	fuse_fs_init(f-&gt;fs, conn, &amp;f-&gt;conf);
2209  }
2210  void fuse_fs_destroy(struct fuse_fs *fs)
2211  {
2212  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
2213  	if (fs-&gt;op.destroy)
2214  		fs-&gt;op.destroy(fs-&gt;user_data);
2215  }
2216  static void fuse_lib_destroy(void *data)
2217  {
2218  	struct fuse *f = (struct fuse *) data;
2219  	fuse_create_context(f);
2220  	fuse_fs_destroy(f-&gt;fs);
2221  }
2222  static void fuse_lib_lookup(fuse_req_t req, fuse_ino_t parent,
2223  			    const char *name)
2224  {
2225  	struct fuse *f = req_fuse_prepare(req);
2226  	struct fuse_entry_param e;
2227  	char *path;
2228  	int err;
2229  	struct node *dot = NULL;
2230  	if (name[0] == &#x27;.&#x27;) {
2231  		int len = strlen(name);
2232  		if (len == 1 || (name[1] == &#x27;.&#x27; &amp;&amp; len == 2)) {
2233  			pthread_mutex_lock(&amp;f-&gt;lock);
2234  			if (len == 1) {
2235  				if (f-&gt;conf.debug)
2236  					fuse_log(FUSE_LOG_DEBUG, &quot;LOOKUP-DOT\n&quot;);
2237  				dot = get_node_nocheck(f, parent);
2238  				if (dot == NULL) {
2239  					pthread_mutex_unlock(&amp;f-&gt;lock);
2240  					reply_entry(req, &amp;e, -ESTALE);
2241  					return;
2242  				}
2243  				dot-&gt;refctr++;
2244  			} else {
2245  				if (f-&gt;conf.debug)
2246  					fuse_log(FUSE_LOG_DEBUG, &quot;LOOKUP-DOTDOT\n&quot;);
2247  				parent = get_node(f, parent)-&gt;parent-&gt;nodeid;
2248  			}
2249  			pthread_mutex_unlock(&amp;f-&gt;lock);
2250  			name = NULL;
2251  		}
2252  	}
2253  	err = get_path_name(f, parent, name, &amp;path);
2254  	if (!err) {
2255  		struct fuse_intr_data d;
2256  		if (f-&gt;conf.debug)
2257  			fuse_log(FUSE_LOG_DEBUG, &quot;LOOKUP %s\n&quot;, path);
2258  		fuse_prepare_interrupt(f, req, &amp;d);
2259  		err = lookup_path(f, parent, name, path, &amp;e, NULL);
2260  		if (err == -ENOENT &amp;&amp; f-&gt;conf.negative_timeout != 0.0) {
2261  			e.ino = 0;
2262  			e.entry_timeout = f-&gt;conf.negative_timeout;
2263  			err = 0;
2264  		}
2265  		fuse_finish_interrupt(f, req, &amp;d);
2266  		free_path(f, parent, path);
2267  	}
2268  	if (dot) {
2269  		pthread_mutex_lock(&amp;f-&gt;lock);
2270  		unref_node(f, dot);
2271  		pthread_mutex_unlock(&amp;f-&gt;lock);
2272  	}
2273  	reply_entry(req, &amp;e, err);
2274  }
2275  static void do_forget(struct fuse *f, fuse_ino_t ino, uint64_t nlookup)
2276  {
2277  	if (f-&gt;conf.debug)
2278  		fuse_log(FUSE_LOG_DEBUG, &quot;FORGET %llu/%llu\n&quot;, (unsigned long long)ino,
2279  			(unsigned long long) nlookup);
2280  	forget_node(f, ino, nlookup);
2281  }
2282  static void fuse_lib_forget(fuse_req_t req, fuse_ino_t ino, uint64_t nlookup)
2283  {
2284  	do_forget(req_fuse(req), ino, nlookup);
2285  	fuse_reply_none(req);
2286  }
2287  static void fuse_lib_forget_multi(fuse_req_t req, size_t count,
2288  				  struct fuse_forget_data *forgets)
2289  {
2290  	struct fuse *f = req_fuse(req);
2291  	size_t i;
2292  	for (i = 0; i &lt; count; i++)
2293  		do_forget(f, forgets[i].ino, forgets[i].nlookup);
2294  	fuse_reply_none(req);
2295  }
2296  static void fuse_lib_getattr(fuse_req_t req, fuse_ino_t ino,
2297  			     struct fuse_file_info *fi)
2298  {
2299  	struct fuse *f = req_fuse_prepare(req);
2300  	struct stat buf;
2301  	char *path;
2302  	int err;
2303  	memset(&amp;buf, 0, sizeof(buf));
2304  	if (fi != NULL)
2305  		err = get_path_nullok(f, ino, &amp;path);
2306  	else
2307  		err = get_path(f, ino, &amp;path);
2308  	if (!err) {
2309  		struct fuse_intr_data d;
2310  		fuse_prepare_interrupt(f, req, &amp;d);
2311  		err = fuse_fs_getattr(f-&gt;fs, path, &amp;buf, fi);
2312  		fuse_finish_interrupt(f, req, &amp;d);
2313  		free_path(f, ino, path);
2314  	}
2315  	if (!err) {
2316  		struct node *node;
2317  		pthread_mutex_lock(&amp;f-&gt;lock);
2318  		node = get_node(f, ino);
2319  		if (node-&gt;is_hidden &amp;&amp; buf.st_nlink &gt; 0)
2320  			buf.st_nlink--;
2321  		if (f-&gt;conf.auto_cache)
2322  			update_stat(node, &amp;buf);
2323  		pthread_mutex_unlock(&amp;f-&gt;lock);
2324  		set_stat(f, ino, &amp;buf);
2325  		fuse_reply_attr(req, &amp;buf, f-&gt;conf.attr_timeout);
2326  	} else
2327  		reply_err(req, err);
2328  }
2329  int fuse_fs_chmod(struct fuse_fs *fs, const char *path, mode_t mode,
2330  		  struct fuse_file_info *fi)
2331  {
2332  	fuse_get_context()-&gt;private_data = fs-&gt;user_data;
2333  	if (fs-&gt;op.chmod) {
2334  		if (fs-&gt;debug) {
2335  			char buf[10];
2336  			fuse_log(FUSE_LOG_DEBUG, &quot;chmod[%s] %s %llo\n&quot;,
2337  				file_info_string(fi, buf, sizeof(buf)),
2338  				path, (unsigned long long) mode);
2339  		}
2340  		return fs-&gt;op.chmod(path, mode, fi);
2341  	}
2342  	else
2343  		return -ENOSYS;
2344  }
2345  static void fuse_lib_setattr(fuse_req_t req, fuse_ino_t ino, struct stat *attr,
2346  			     int valid, struct fuse_file_info *fi)
2347  {
2348  	struct fuse *f = req_fuse_prepare(req);
2349  	struct stat buf;
2350  	char *path;
2351  	int err;
2352  	memset(&amp;buf, 0, sizeof(buf));
2353  	if (fi != NULL)
2354  		err = get_path_nullok(f, ino, &amp;path);
2355  	else
2356  		err = get_path(f, ino, &amp;path);
2357  	if (!err) {
2358  		struct fuse_intr_data d;
2359  		fuse_prepare_interrupt(f, req, &amp;d);
2360  		err = 0;
2361  		if (!err &amp;&amp; (valid &amp; FUSE_SET_ATTR_MODE))
2362  			err = fuse_fs_chmod(f-&gt;fs, path, attr-&gt;st_mode, fi);
2363  		if (!err &amp;&amp; (valid &amp; (FUSE_SET_ATTR_UID | FUSE_SET_ATTR_GID))) {
2364  			uid_t uid = (valid &amp; FUSE_SET_ATTR_UID) ?
2365  				attr-&gt;st_uid : (uid_t) -1;
2366  			gid_t gid = (valid &amp; FUSE_SET_ATTR_GID) ?
2367  				attr-&gt;st_gid : (gid_t) -1;
2368  			err = fuse_fs_chown(f-&gt;fs, path, uid, gid, fi);
2369  		}
2370  		if (!err &amp;&amp; (valid &amp; FUSE_SET_ATTR_SIZE)) {
2371  			err = fuse_fs_truncate(f-&gt;fs, path,
2372  					       attr-&gt;st_size, fi);
2373  		}
2374  #ifdef HAVE_UTIMENSAT
2375  		if (!err &amp;&amp;
2376  		    (valid &amp; (FUSE_SET_ATTR_ATIME | FUSE_SET_ATTR_MTIME))) {
2377  			struct timespec tv[2];
2378  			tv[0].tv_sec = 0;
2379  			tv[1].tv_sec = 0;
2380  			tv[0].tv_nsec = UTIME_OMIT;
2381  			tv[1].tv_nsec = UTIME_OMIT;
2382  			if (valid &amp; FUSE_SET_ATTR_ATIME_NOW)
2383  				tv[0].tv_nsec = UTIME_NOW;
2384  			else if (valid &amp; FUSE_SET_ATTR_ATIME)
2385  				tv[0] = attr-&gt;st_atim;
2386  			if (valid &amp; FUSE_SET_ATTR_MTIME_NOW)
2387  				tv[1].tv_nsec = UTIME_NOW;
2388  			else if (valid &amp; FUSE_SET_ATTR_MTIME)
2389  				tv[1] = attr-&gt;st_mtim;
2390  			err = fuse_fs_utimens(f-&gt;fs, path, tv, fi);
2391  		} else
2392  #endif
2393  		if (!err &amp;&amp;
2394  		    (valid &amp; (FUSE_SET_ATTR_ATIME | FUSE_SET_ATTR_MTIME)) ==
2395  		    (FUSE_SET_ATTR_ATIME | FUSE_SET_ATTR_MTIME)) {
2396  			struct timespec tv[2];
2397  			tv[0].tv_sec = attr-&gt;st_atime;
2398  			tv[0].tv_nsec = ST_ATIM_NSEC(attr);
2399  			tv[1].tv_sec = attr-&gt;st_mtime;
2400  			tv[1].tv_nsec = ST_MTIM_NSEC(attr);
2401  			err = fuse_fs_utimens(f-&gt;fs, path, tv, fi);
2402  		}
2403  		if (!err) {
2404  			err = fuse_fs_getattr(f-&gt;fs, path, &amp;buf, fi);
2405  		}
2406  		fuse_finish_interrupt(f, req, &amp;d);
2407  		free_path(f, ino, path);
2408  	}
2409  	if (!err) {
2410  		if (f-&gt;conf.auto_cache) {
2411  			pthread_mutex_lock(&amp;f-&gt;lock);
2412  			update_stat(get_node(f, ino), &amp;buf);
2413  			pthread_mutex_unlock(&amp;f-&gt;lock);
2414  		}
2415  		set_stat(f, ino, &amp;buf);
2416  		fuse_reply_attr(req, &amp;buf, f-&gt;conf.attr_timeout);
2417  	} else
2418  		reply_err(req, err);
2419  }
2420  static void fuse_lib_access(fuse_req_t req, fuse_ino_t ino, int mask)
2421  {
2422  	struct fuse *f = req_fuse_prepare(req);
2423  	char *path;
2424  	int err;
2425  	err = get_path(f, ino, &amp;path);
2426  	if (!err) {
2427  		struct fuse_intr_data d;
2428  		fuse_prepare_interrupt(f, req, &amp;d);
2429  		err = fuse_fs_access(f-&gt;fs, path, mask);
2430  		fuse_finish_interrupt(f, req, &amp;d);
2431  		free_path(f, ino, path);
2432  	}
2433  	reply_err(req, err);
2434  }
2435  static void fuse_lib_readlink(fuse_req_t req, fuse_ino_t ino)
2436  {
2437  	struct fuse *f = req_fuse_prepare(req);
2438  	char linkname[PATH_MAX + 1];
2439  	char *path;
2440  	int err;
2441  	err = get_path(f, ino, &amp;path);
2442  	if (!err) {
2443  		struct fuse_intr_data d;
2444  		fuse_prepare_interrupt(f, req, &amp;d);
2445  		err = fuse_fs_readlink(f-&gt;fs, path, linkname, sizeof(linkname));
2446  		fuse_finish_interrupt(f, req, &amp;d);
2447  		free_path(f, ino, path);
2448  	}
2449  	if (!err) {
2450  		linkname[PATH_MAX] = &#x27;\0&#x27;;
2451  		fuse_reply_readlink(req, linkname);
2452  	} else
2453  		reply_err(req, err);
2454  }
2455  static void fuse_lib_mknod(fuse_req_t req, fuse_ino_t parent, const char *name,
2456  			   mode_t mode, dev_t rdev)
2457  {
2458  	struct fuse *f = req_fuse_prepare(req);
2459  	struct fuse_entry_param e;
2460  	char *path;
2461  	int err;
2462  	err = get_path_name(f, parent, name, &amp;path);
2463  	if (!err) {
2464  		struct fuse_intr_data d;
2465  		fuse_prepare_interrupt(f, req, &amp;d);
2466  		err = -ENOSYS;
2467  		if (S_ISREG(mode)) {
2468  			struct fuse_file_info fi;
2469  			memset(&amp;fi, 0, sizeof(fi));
2470  			fi.flags = O_CREAT | O_EXCL | O_WRONLY;
2471  			err = fuse_fs_create(f-&gt;fs, path, mode, &amp;fi);
2472  			if (!err) {
2473  				err = lookup_path(f, parent, name, path, &amp;e,
2474  						  &amp;fi);
2475  				fuse_fs_release(f-&gt;fs, path, &amp;fi);
2476  			}
2477  		}
2478  		if (err == -ENOSYS) {
2479  			err = fuse_fs_mknod(f-&gt;fs, path, mode, rdev);
2480  			if (!err)
2481  				err = lookup_path(f, parent, name, path, &amp;e,
2482  						  NULL);
2483  		}
2484  		fuse_finish_interrupt(f, req, &amp;d);
2485  		free_path(f, parent, path);
2486  	}
2487  	reply_entry(req, &amp;e, err);
2488  }
2489  static void fuse_lib_mkdir(fuse_req_t req, fuse_ino_t parent, const char *name,
2490  			   mode_t mode)
2491  {
2492  	struct fuse *f = req_fuse_prepare(req);
2493  	struct fuse_entry_param e;
2494  	char *path;
2495  	int err;
2496  	err = get_path_name(f, parent, name, &amp;path);
2497  	if (!err) {
2498  		struct fuse_intr_data d;
2499  		fuse_prepare_interrupt(f, req, &amp;d);
2500  		err = fuse_fs_mkdir(f-&gt;fs, path, mode);
2501  		if (!err)
2502  			err = lookup_path(f, parent, name, path, &amp;e, NULL);
2503  		fuse_finish_interrupt(f, req, &amp;d);
2504  		free_path(f, parent, path);
2505  	}
2506  	reply_entry(req, &amp;e, err);
2507  }
2508  static void fuse_lib_unlink(fuse_req_t req, fuse_ino_t parent,
2509  			    const char *name)
2510  {
2511  	struct fuse *f = req_fuse_prepare(req);
2512  	struct node *wnode;
2513  	char *path;
2514  	int err;
2515  	err = get_path_wrlock(f, parent, name, &amp;path, &amp;wnode);
2516  	if (!err) {
2517  		struct fuse_intr_data d;
2518  		fuse_prepare_interrupt(f, req, &amp;d);
2519  		if (!f-&gt;conf.hard_remove &amp;&amp; is_open(f, parent, name)) {
2520  			err = hide_node(f, path, parent, name);
2521  			if (!err) {
2522  				if (!is_open(f, parent, wnode-&gt;name)) {
2523  					char *unlinkpath;
2524  					if (try_get_path(f, wnode-&gt;nodeid, NULL, &amp;unlinkpath, NULL, false) == 0) {
2525  						err = fuse_fs_unlink(f-&gt;fs, unlinkpath);
2526  						if (!err)
2527  							remove_node(f, parent, wnode-&gt;name);
2528  						free(unlinkpath);
2529  					}
2530  				}
2531  			}
2532  		} else {
2533  			err = fuse_fs_unlink(f-&gt;fs, path);
2534  			if (!err)
2535  				remove_node(f, parent, name);
2536  		}
2537  		fuse_finish_interrupt(f, req, &amp;d);
2538  		free_path_wrlock(f, parent, wnode, path);
2539  	}
2540  	reply_err(req, err);
2541  }
2542  static void fuse_lib_rmdir(fuse_req_t req, fuse_ino_t parent, const char *name)
2543  {
2544  	struct fuse *f = req_fuse_prepare(req);
2545  	struct node *wnode;
2546  	char *path;
2547  	int err;
2548  	err = get_path_wrlock(f, parent, name, &amp;path, &amp;wnode);
2549  	if (!err) {
2550  		struct fuse_intr_data d;
2551  		fuse_prepare_interrupt(f, req, &amp;d);
2552  		err = fuse_fs_rmdir(f-&gt;fs, path);
2553  		fuse_finish_interrupt(f, req, &amp;d);
2554  		if (!err)
2555  			remove_node(f, parent, name);
2556  		free_path_wrlock(f, parent, wnode, path);
2557  	}
2558  	reply_err(req, err);
2559  }
2560  static void fuse_lib_symlink(fuse_req_t req, const char *linkname,
2561  			     fuse_ino_t parent, const char *name)
2562  {
2563  	struct fuse *f = req_fuse_prepare(req);
2564  	struct fuse_entry_param e;
2565  	char *path;
2566  	int err;
2567  	err = get_path_name(f, parent, name, &amp;path);
2568  	if (!err) {
2569  		struct fuse_intr_data d;
2570  		fuse_prepare_interrupt(f, req, &amp;d);
2571  		err = fuse_fs_symlink(f-&gt;fs, linkname, path);
2572  		if (!err)
2573  			err = lookup_path(f, parent, name, path, &amp;e, NULL);
2574  		fuse_finish_interrupt(f, req, &amp;d);
2575  		free_path(f, parent, path);
2576  	}
2577  	reply_entry(req, &amp;e, err);
2578  }
2579  static void fuse_lib_rename(fuse_req_t req, fuse_ino_t olddir,
2580  			    const char *oldname, fuse_ino_t newdir,
2581  			    const char *newname, unsigned int flags)
2582  {
2583  	struct fuse *f = req_fuse_prepare(req);
2584  	char *oldpath;
2585  	char *newpath;
2586  	struct node *wnode1;
2587  	struct node *wnode2;
2588  	int err;
2589  	err = get_path2(f, olddir, oldname, newdir, newname,
2590  			&amp;oldpath, &amp;newpath, &amp;wnode1, &amp;wnode2);
2591  	if (!err) {
2592  		struct fuse_intr_data d;
2593  		err = 0;
2594  		fuse_prepare_interrupt(f, req, &amp;d);
2595  		if (!f-&gt;conf.hard_remove &amp;&amp; !(flags &amp; RENAME_EXCHANGE) &amp;&amp;
2596  		    is_open(f, newdir, newname))
2597  			err = hide_node(f, newpath, newdir, newname);
2598  		if (!err) {
2599  			err = fuse_fs_rename(f-&gt;fs, oldpath, newpath, flags);
2600  			if (!err) {
2601  				if (flags &amp; RENAME_EXCHANGE) {
2602  					err = exchange_node(f, olddir, oldname,
2603  							    newdir, newname);
2604  				} else {
2605  					err = rename_node(f, olddir, oldname,
2606  							  newdir, newname, 0);
2607  				}
2608  			}
2609  		}
2610  		fuse_finish_interrupt(f, req, &amp;d);
2611  		free_path2(f, olddir, newdir, wnode1, wnode2, oldpath, newpath);
2612  	}
2613  	reply_err(req, err);
2614  }
2615  static void fuse_lib_link(fuse_req_t req, fuse_ino_t ino, fuse_ino_t newparent,
2616  			  const char *newname)
2617  {
2618  	struct fuse *f = req_fuse_prepare(req);
2619  	struct fuse_entry_param e;
2620  	char *oldpath;
2621  	char *newpath;
2622  	int err;
2623  	err = get_path2(f, ino, NULL, newparent, newname,
2624  			&amp;oldpath, &amp;newpath, NULL, NULL);
2625  	if (!err) {
2626  		struct fuse_intr_data d;
2627  		fuse_prepare_interrupt(f, req, &amp;d);
2628  		err = fuse_fs_link(f-&gt;fs, oldpath, newpath);
2629  		if (!err)
2630  			err = lookup_path(f, newparent, newname, newpath,
2631  					  &amp;e, NULL);
2632  		fuse_finish_interrupt(f, req, &amp;d);
2633  		free_path2(f, ino, newparent, NULL, NULL, oldpath, newpath);
2634  	}
2635  	reply_entry(req, &amp;e, err);
2636  }
2637  static void fuse_do_release(struct fuse *f, fuse_ino_t ino, const char *path,
2638  			    struct fuse_file_info *fi)
2639  {
2640  	struct node *node;
2641  	int unlink_hidden = 0;
2642  	fuse_fs_release(f-&gt;fs, path, fi);
2643  	pthread_mutex_lock(&amp;f-&gt;lock);
2644  	node = get_node(f, ino);
2645  	assert(node-&gt;open_count &gt; 0);
2646  	--node-&gt;open_count;
2647  	if (node-&gt;is_hidden &amp;&amp; !node-&gt;open_count) {
2648  		unlink_hidden = 1;
2649  		node-&gt;is_hidden = 0;
2650  	}
2651  	pthread_mutex_unlock(&amp;f-&gt;lock);
2652  	if(unlink_hidden) {
2653  		if (path) {
2654  			fuse_fs_unlink(f-&gt;fs, path);
2655  		} else if (f-&gt;conf.nullpath_ok) {
2656  			char *unlinkpath;
2657  			if (get_path(f, ino, &amp;unlinkpath) == 0)
2658  				fuse_fs_unlink(f-&gt;fs, unlinkpath);
2659  			free_path(f, ino, unlinkpath);
2660  		}
2661  	}
2662  }
2663  static void fuse_lib_create(fuse_req_t req, fuse_ino_t parent,
2664  			    const char *name, mode_t mode,
2665  			    struct fuse_file_info *fi)
2666  {
2667  	struct fuse *f = req_fuse_prepare(req);
2668  	struct fuse_intr_data d;
2669  	struct fuse_entry_param e;
2670  	char *path;
2671  	int err;
2672  	err = get_path_name(f, parent, name, &amp;path);
2673  	if (!err) {
2674  		fuse_prepare_interrupt(f, req, &amp;d);
2675  		err = fuse_fs_create(f-&gt;fs, path, mode, fi);
2676  		if (!err) {
2677  			err = lookup_path(f, parent, name, path, &amp;e, fi);
2678  			if (err)
2679  				fuse_fs_release(f-&gt;fs, path, fi);
2680  			else if (!S_ISREG(e.attr.st_mode)) {
2681  				err = -EIO;
2682  				fuse_fs_release(f-&gt;fs, path, fi);
2683  				forget_node(f, e.ino, 1);
2684  			} else {
2685  				if (f-&gt;conf.direct_io)
2686  					fi-&gt;direct_io = 1;
2687  				if (f-&gt;conf.kernel_cache)
2688  					fi-&gt;keep_cache = 1;
2689  				if (fi-&gt;direct_io &amp;&amp;
2690  				    f-&gt;conf.parallel_direct_writes)
2691  					fi-&gt;parallel_direct_writes = 1;
2692  			}
2693  		}
2694  		fuse_finish_interrupt(f, req, &amp;d);
2695  	}
2696  	if (!err) {
2697  		pthread_mutex_lock(&amp;f-&gt;lock);
2698  		get_node(f, e.ino)-&gt;open_count++;
2699  		pthread_mutex_unlock(&amp;f-&gt;lock);
2700  		if (fuse_reply_create(req, &amp;e, fi) == -ENOENT) {
2701  			fuse_do_release(f, e.ino, path, fi);
2702  			forget_node(f, e.ino, 1);
2703  		}
2704  	} else {
2705  		reply_err(req, err);
2706  	}
2707  	free_path(f, parent, path);
2708  }
2709  static double diff_timespec(const struct timespec *t1,
2710  			    const struct timespec *t2)
2711  {
2712  	return (t1-&gt;tv_sec - t2-&gt;tv_sec) +
2713  		((double) t1-&gt;tv_nsec - (double) t2-&gt;tv_nsec) / 1000000000.0;
2714  }
2715  static void open_auto_cache(struct fuse *f, fuse_ino_t ino, const char *path,
2716  			    struct fuse_file_info *fi)
2717  {
2718  	struct node *node;
2719  	pthread_mutex_lock(&amp;f-&gt;lock);
2720  	node = get_node(f, ino);
2721  	if (node-&gt;cache_valid) {
2722  		struct timespec now;
2723  		curr_time(&amp;now);
2724  		if (diff_timespec(&amp;now, &amp;node-&gt;stat_updated) &gt;
2725  		    f-&gt;conf.ac_attr_timeout) {
2726  			struct stat stbuf;
2727  			int err;
2728  			pthread_mutex_unlock(&amp;f-&gt;lock);
2729  			err = fuse_fs_getattr(f-&gt;fs, path, &amp;stbuf, fi);
2730  			pthread_mutex_lock(&amp;f-&gt;lock);
2731  			if (!err)
2732  				update_stat(node, &amp;stbuf);
2733  			else
2734  				node-&gt;cache_valid = 0;
2735  		}
2736  	}
2737  	if (node-&gt;cache_valid)
2738  		fi-&gt;keep_cache = 1;
2739  	node-&gt;cache_valid = 1;
2740  	pthread_mutex_unlock(&amp;f-&gt;lock);
2741  }
2742  static void fuse_lib_open(fuse_req_t req, fuse_ino_t ino,
2743  			  struct fuse_file_info *fi)
2744  {
2745  	struct fuse *f = req_fuse_prepare(req);
2746  	struct fuse_intr_data d;
2747  	char *path;
2748  	int err;
2749  	err = get_path(f, ino, &amp;path);
2750  	if (!err) {
2751  		fuse_prepare_interrupt(f, req, &amp;d);
2752  		err = fuse_fs_open(f-&gt;fs, path, fi);
2753  		if (!err) {
2754  			if (f-&gt;conf.direct_io)
2755  				fi-&gt;direct_io = 1;
2756  			if (f-&gt;conf.kernel_cache)
2757  				fi-&gt;keep_cache = 1;
2758  			if (f-&gt;conf.auto_cache)
2759  				open_auto_cache(f, ino, path, fi);
2760  			if (f-&gt;conf.no_rofd_flush &amp;&amp;
2761  			    (fi-&gt;flags &amp; O_ACCMODE) == O_RDONLY)
2762  				fi-&gt;noflush = 1;
2763  			if (fi-&gt;direct_io &amp;&amp; f-&gt;conf.parallel_direct_writes)
2764  				fi-&gt;parallel_direct_writes = 1;
2765  		}
2766  		fuse_finish_interrupt(f, req, &amp;d);
2767  	}
2768  	if (!err) {
2769  		pthread_mutex_lock(&amp;f-&gt;lock);
2770  		get_node(f, ino)-&gt;open_count++;
2771  		pthread_mutex_unlock(&amp;f-&gt;lock);
2772  		if (fuse_reply_open(req, fi) == -ENOENT) {
2773  			fuse_do_release(f, ino, path, fi);
2774  		}
2775  	} else
2776  		reply_err(req, err);
2777  	free_path(f, ino, path);
2778  }
2779  static void fuse_lib_read(fuse_req_t req, fuse_ino_t ino, size_t size,
2780  			  off_t off, struct fuse_file_info *fi)
2781  {
2782  	struct fuse *f = req_fuse_prepare(req);
2783  	struct fuse_bufvec *buf = NULL;
2784  	char *path;
2785  	int res;
2786  	res = get_path_nullok(f, ino, &amp;path);
2787  	if (res == 0) {
2788  		struct fuse_intr_data d;
2789  		fuse_prepare_interrupt(f, req, &amp;d);
2790  		res = fuse_fs_read_buf(f-&gt;fs, path, &amp;buf, size, off, fi);
2791  		fuse_finish_interrupt(f, req, &amp;d);
2792  		free_path(f, ino, path);
2793  	}
2794  	if (res == 0)
2795  		fuse_reply_data(req, buf, FUSE_BUF_SPLICE_MOVE);
2796  	else
2797  		reply_err(req, res);
2798  	fuse_free_buf(buf);
2799  }
2800  static void fuse_lib_write_buf(fuse_req_t req, fuse_ino_t ino,
2801  			       struct fuse_bufvec *buf, off_t off,
2802  			       struct fuse_file_info *fi)
2803  {
2804  	struct fuse *f = req_fuse_prepare(req);
2805  	char *path;
2806  	int res;
2807  	res = get_path_nullok(f, ino, &amp;path);
2808  	if (res == 0) {
2809  		struct fuse_intr_data d;
2810  		fuse_prepare_interrupt(f, req, &amp;d);
2811  		res = fuse_fs_write_buf(f-&gt;fs, path, buf, off, fi);
2812  		fuse_finish_interrupt(f, req, &amp;d);
2813  		free_path(f, ino, path);
2814  	}
2815  	if (res &gt;= 0)
2816  		fuse_reply_write(req, res);
2817  	else
2818  		reply_err(req, res);
2819  }
2820  static void fuse_lib_fsync(fuse_req_t req, fuse_ino_t ino, int datasync,
2821  			   struct fuse_file_info *fi)
2822  {
2823  	struct fuse *f = req_fuse_prepare(req);
2824  	char *path;
2825  	int err;
2826  	err = get_path_nullok(f, ino, &amp;path);
2827  	if (!err) {
2828  		struct fuse_intr_data d;
2829  		fuse_prepare_interrupt(f, req, &amp;d);
2830  		err = fuse_fs_fsync(f-&gt;fs, path, datasync, fi);
2831  		fuse_finish_interrupt(f, req, &amp;d);
2832  		free_path(f, ino, path);
2833  	}
2834  	reply_err(req, err);
2835  }
2836  static struct fuse_dh *get_dirhandle(const struct fuse_file_info *llfi,
2837  				     struct fuse_file_info *fi)
2838  {
2839  	struct fuse_dh *dh = (struct fuse_dh *) (uintptr_t) llfi-&gt;fh;
2840  	memset(fi, 0, sizeof(struct fuse_file_info));
2841  	fi-&gt;fh = dh-&gt;fh;
2842  	return dh;
2843  }
2844  static void fuse_lib_opendir(fuse_req_t req, fuse_ino_t ino,
2845  			     struct fuse_file_info *llfi)
2846  {
2847  	struct fuse *f = req_fuse_prepare(req);
2848  	struct fuse_intr_data d;
2849  	struct fuse_dh *dh;
2850  	struct fuse_file_info fi;
2851  	char *path;
2852  	int err;
2853  	dh = (struct fuse_dh *) malloc(sizeof(struct fuse_dh));
2854  	if (dh == NULL) {
2855  		reply_err(req, -ENOMEM);
2856  		return;
2857  	}
2858  	memset(dh, 0, sizeof(struct fuse_dh));
2859  	dh-&gt;fuse = f;
2860  	dh-&gt;contents = NULL;
2861  	dh-&gt;first = NULL;
2862  	dh-&gt;len = 0;
2863  	dh-&gt;filled = 0;
2864  	dh-&gt;nodeid = ino;
2865  	pthread_mutex_init(&amp;dh-&gt;lock, NULL);
2866  	llfi-&gt;fh = (uintptr_t) dh;
2867  	memset(&amp;fi, 0, sizeof(fi));
2868  	fi.flags = llfi-&gt;flags;
2869  	err = get_path(f, ino, &amp;path);
2870  	if (!err) {
2871  		fuse_prepare_interrupt(f, req, &amp;d);
2872  		err = fuse_fs_opendir(f-&gt;fs, path, &amp;fi);
2873  		fuse_finish_interrupt(f, req, &amp;d);
2874  		dh-&gt;fh = fi.fh;
2875  	}
2876  	if (!err) {
2877  		if (fuse_reply_open(req, llfi) == -ENOENT) {
2878  			fuse_fs_releasedir(f-&gt;fs, path, &amp;fi);
2879  			pthread_mutex_destroy(&amp;dh-&gt;lock);
2880  			free(dh);
2881  		}
2882  	} else {
2883  		reply_err(req, err);
2884  		pthread_mutex_destroy(&amp;dh-&gt;lock);
2885  		free(dh);
2886  	}
2887  	free_path(f, ino, path);
2888  }
2889  static int extend_contents(struct fuse_dh *dh, unsigned minsize)
2890  {
2891  	if (minsize &gt; dh-&gt;size) {
2892  		char *newptr;
2893  		unsigned newsize = dh-&gt;size;
2894  		if (!newsize)
2895  			newsize = 1024;
2896  		while (newsize &lt; minsize) {
2897  			if (newsize &gt;= 0x80000000)
2898  				newsize = 0xffffffff;
2899  			else
2900  				newsize *= 2;
2901  		}
2902  		newptr = (char *) realloc(dh-&gt;contents, newsize);
2903  		if (!newptr) {
2904  			dh-&gt;error = -ENOMEM;
2905  			return -1;
2906  		}
2907  		dh-&gt;contents = newptr;
2908  		dh-&gt;size = newsize;
2909  	}
2910  	return 0;
2911  }
2912  static int fuse_add_direntry_to_dh(struct fuse_dh *dh, const char *name,
2913  				   struct stat *st)
2914  {
2915  	struct fuse_direntry *de;
2916  	de = malloc(sizeof(struct fuse_direntry));
2917  	if (!de) {
2918  		dh-&gt;error = -ENOMEM;
2919  		return -1;
2920  	}
2921  	de-&gt;name = strdup(name);
2922  	if (!de-&gt;name) {
2923  		dh-&gt;error = -ENOMEM;
2924  		free(de);
2925  		return -1;
2926  	}
2927  	de-&gt;stat = *st;
2928  	de-&gt;next = NULL;
2929  	*dh-&gt;last = de;
2930  	dh-&gt;last = &amp;de-&gt;next;
2931  	return 0;
2932  }
2933  static fuse_ino_t lookup_nodeid(struct fuse *f, fuse_ino_t parent,
2934  				const char *name)
2935  {
2936  	struct node *node;
2937  	fuse_ino_t res = FUSE_UNKNOWN_INO;
2938  	pthread_mutex_lock(&amp;f-&gt;lock);
2939  	node = lookup_node(f, parent, name);
2940  	if (node)
2941  		res = node-&gt;nodeid;
2942  	pthread_mutex_unlock(&amp;f-&gt;lock);
2943  	return res;
2944  }
2945  static int fill_dir(void *dh_, const char *name, const struct stat *statp,
2946  		    off_t off, enum fuse_fill_dir_flags flags)
2947  {
2948  	struct fuse_dh *dh = (struct fuse_dh *) dh_;
2949  	struct stat stbuf;
2950  	if ((flags &amp; ~FUSE_FILL_DIR_PLUS) != 0) {
2951  		dh-&gt;error = -EIO;
2952  		return 1;
2953  	}
2954  	if (statp)
2955  		stbuf = *statp;
2956  	else {
2957  		memset(&amp;stbuf, 0, sizeof(stbuf));
2958  		stbuf.st_ino = FUSE_UNKNOWN_INO;
2959  	}
2960  	if (!dh-&gt;fuse-&gt;conf.use_ino) {
2961  		stbuf.st_ino = FUSE_UNKNOWN_INO;
2962  		if (dh-&gt;fuse-&gt;conf.readdir_ino) {
2963  			stbuf.st_ino = (ino_t)
2964  				lookup_nodeid(dh-&gt;fuse, dh-&gt;nodeid, name);
2965  		}
2966  	}
2967  	if (off) {
2968  		size_t newlen;
2969  		if (dh-&gt;filled) {
2970  			dh-&gt;error = -EIO;
2971  			return 1;
2972  		}
2973  		if (dh-&gt;first) {
2974  			dh-&gt;error = -EIO;
2975  			return 1;
2976  		}
2977  		if (extend_contents(dh, dh-&gt;needlen) == -1)
2978  			return 1;
2979  		newlen = dh-&gt;len +
2980  			fuse_add_direntry(dh-&gt;req, dh-&gt;contents + dh-&gt;len,
2981  					  dh-&gt;needlen - dh-&gt;len, name,
2982  					  &amp;stbuf, off);
2983  		if (newlen &gt; dh-&gt;needlen)
2984  			return 1;
2985  		dh-&gt;len = newlen;
2986  	} else {
2987  		dh-&gt;filled = 1;
2988  		if (fuse_add_direntry_to_dh(dh, name, &amp;stbuf) == -1)
2989  			return 1;
2990  	}
2991  	return 0;
2992  }
2993  static int is_dot_or_dotdot(const char *name)
2994  {
2995  	return name[0] == &#x27;.&#x27; &amp;&amp; (name[1] == &#x27;\0&#x27; ||
2996  				  (name[1] == &#x27;.&#x27; &amp;&amp; name[2] == &#x27;\0&#x27;));
2997  }
2998  static int fill_dir_plus(void *dh_, const char *name, const struct stat *statp,
2999  			 off_t off, enum fuse_fill_dir_flags flags)
3000  {
3001  	struct fuse_dh *dh = (struct fuse_dh *) dh_;
3002  	struct fuse_entry_param e = {
3003  		.ino = 0,
3004  	};
3005  	struct fuse *f = dh-&gt;fuse;
3006  	int res;
3007  	if ((flags &amp; ~FUSE_FILL_DIR_PLUS) != 0) {
3008  		dh-&gt;error = -EIO;
3009  		return 1;
3010  	}
3011  	if (statp &amp;&amp; (flags &amp; FUSE_FILL_DIR_PLUS)) {
3012  		e.attr = *statp;
3013  		if (!is_dot_or_dotdot(name)) {
3014  			res = do_lookup(f, dh-&gt;nodeid, name, &amp;e);
3015  			if (res) {
3016  				dh-&gt;error = res;
3017  				return 1;
3018  			}
3019  		}
3020  	} else {
3021  		e.attr.st_ino = FUSE_UNKNOWN_INO;
3022  		if (statp) {
3023  			e.attr.st_mode = statp-&gt;st_mode;
3024  			if (f-&gt;conf.use_ino)
3025  				e.attr.st_ino = statp-&gt;st_ino;
3026  		}
3027  		if (!f-&gt;conf.use_ino &amp;&amp; f-&gt;conf.readdir_ino) {
3028  			e.attr.st_ino = (ino_t)
3029  				lookup_nodeid(f, dh-&gt;nodeid, name);
3030  		}
3031  	}
3032  	if (off) {
3033  		size_t newlen;
3034  		if (dh-&gt;filled) {
3035  			dh-&gt;error = -EIO;
3036  			return 1;
3037  		}
3038  		if (dh-&gt;first) {
3039  			dh-&gt;error = -EIO;
3040  			return 1;
3041  		}
3042  		if (extend_contents(dh, dh-&gt;needlen) == -1)
3043  			return 1;
3044  		newlen = dh-&gt;len +
3045  			fuse_add_direntry_plus(dh-&gt;req, dh-&gt;contents + dh-&gt;len,
3046  					       dh-&gt;needlen - dh-&gt;len, name,
3047  					       &amp;e, off);
3048  		if (newlen &gt; dh-&gt;needlen)
3049  			return 1;
3050  		dh-&gt;len = newlen;
3051  	} else {
3052  		dh-&gt;filled = 1;
3053  		if (fuse_add_direntry_to_dh(dh, name, &amp;e.attr) == -1)
3054  			return 1;
3055  	}
3056  	return 0;
3057  }
3058  static void free_direntries(struct fuse_direntry *de)
3059  {
3060  	while (de) {
3061  		struct fuse_direntry *next = de-&gt;next;
3062  		free(de-&gt;name);
3063  		free(de);
3064  		de = next;
3065  	}
3066  }
3067  static int readdir_fill(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3068  			size_t size, off_t off, struct fuse_dh *dh,
3069  			struct fuse_file_info *fi,
3070  			enum fuse_readdir_flags flags)
3071  {
3072  	char *path;
3073  	int err;
3074  	if (f-&gt;fs-&gt;op.readdir)
3075  		err = get_path_nullok(f, ino, &amp;path);
3076  	else
3077  		err = get_path(f, ino, &amp;path);
3078  	if (!err) {
3079  		struct fuse_intr_data d;
3080  		fuse_fill_dir_t filler = fill_dir;
3081  		if (flags &amp; FUSE_READDIR_PLUS)
3082  			filler = fill_dir_plus;
3083  		free_direntries(dh-&gt;first);
3084  		dh-&gt;first = NULL;
3085  		dh-&gt;last = &amp;dh-&gt;first;
3086  		dh-&gt;len = 0;
3087  		dh-&gt;error = 0;
3088  		dh-&gt;needlen = size;
3089  		dh-&gt;filled = 0;
3090  		dh-&gt;req = req;
3091  		fuse_prepare_interrupt(f, req, &amp;d);
3092  		err = fuse_fs_readdir(f-&gt;fs, path, dh, filler, off, fi, flags);
3093  		fuse_finish_interrupt(f, req, &amp;d);
3094  		dh-&gt;req = NULL;
3095  		if (!err)
3096  			err = dh-&gt;error;
3097  		if (err)
3098  			dh-&gt;filled = 0;
3099  		free_path(f, ino, path);
3100  	}
3101  	return err;
3102  }
3103  static int readdir_fill_from_list(fuse_req_t req, struct fuse_dh *dh,
3104  				  off_t off, enum fuse_readdir_flags flags)
3105  {
3106  	off_t pos;
3107  	struct fuse_direntry *de = dh-&gt;first;
3108  	dh-&gt;len = 0;
3109  	if (extend_contents(dh, dh-&gt;needlen) == -1)
3110  		return dh-&gt;error;
3111  	for (pos = 0; pos &lt; off; pos++) {
3112  		if (!de)
3113  			break;
3114  		de = de-&gt;next;
3115  	}
3116  	while (de) {
3117  		char *p = dh-&gt;contents + dh-&gt;len;
3118  		unsigned rem = dh-&gt;needlen - dh-&gt;len;
3119  		unsigned thislen;
3120  		unsigned newlen;
3121  		pos++;
3122  		if (flags &amp; FUSE_READDIR_PLUS) {
3123  			struct fuse_entry_param e = {
3124  				.ino = 0,
3125  				.attr = de-&gt;stat,
3126  			};
3127  			thislen = fuse_add_direntry_plus(req, p, rem,
3128  							 de-&gt;name, &amp;e, pos);
3129  		} else {
3130  			thislen = fuse_add_direntry(req, p, rem,
3131  						    de-&gt;name, &amp;de-&gt;stat, pos);
3132  		}
3133  		newlen = dh-&gt;len + thislen;
3134  		if (newlen &gt; dh-&gt;needlen)
3135  			break;
3136  		dh-&gt;len = newlen;
3137  		de = de-&gt;next;
3138  	}
3139  	return 0;
3140  }
3141  static void fuse_readdir_common(fuse_req_t req, fuse_ino_t ino, size_t size,
3142  				off_t off, struct fuse_file_info *llfi,
3143  				enum fuse_readdir_flags flags)
3144  {
3145  	struct fuse *f = req_fuse_prepare(req);
3146  	struct fuse_file_info fi;
3147  	struct fuse_dh *dh = get_dirhandle(llfi, &amp;fi);
3148  	int err;
3149  	pthread_mutex_lock(&amp;dh-&gt;lock);
3150  	if (!off)
3151  		dh-&gt;filled = 0;
3152  	if (!dh-&gt;filled) {
3153  		err = readdir_fill(f, req, ino, size, off, dh, &amp;fi, flags);
3154  		if (err) {
3155  			reply_err(req, err);
3156  			goto out;
3157  		}
3158  	}
3159  	if (dh-&gt;filled) {
3160  		dh-&gt;needlen = size;
3161  		err = readdir_fill_from_list(req, dh, off, flags);
3162  		if (err) {
3163  			reply_err(req, err);
3164  			goto out;
3165  		}
3166  	}
3167  	fuse_reply_buf(req, dh-&gt;contents, dh-&gt;len);
3168  out:
3169  	pthread_mutex_unlock(&amp;dh-&gt;lock);
3170  }
3171  static void fuse_lib_readdir(fuse_req_t req, fuse_ino_t ino, size_t size,
3172  			     off_t off, struct fuse_file_info *llfi)
3173  {
3174  	fuse_readdir_common(req, ino, size, off, llfi, 0);
3175  }
3176  static void fuse_lib_readdirplus(fuse_req_t req, fuse_ino_t ino, size_t size,
3177  				  off_t off, struct fuse_file_info *llfi)
3178  {
3179  	fuse_readdir_common(req, ino, size, off, llfi, FUSE_READDIR_PLUS);
3180  }
3181  static void fuse_lib_releasedir(fuse_req_t req, fuse_ino_t ino,
3182  				struct fuse_file_info *llfi)
3183  {
3184  	struct fuse *f = req_fuse_prepare(req);
3185  	struct fuse_intr_data d;
3186  	struct fuse_file_info fi;
3187  	struct fuse_dh *dh = get_dirhandle(llfi, &amp;fi);
3188  	char *path;
3189  	get_path_nullok(f, ino, &amp;path);
3190  	fuse_prepare_interrupt(f, req, &amp;d);
3191  	fuse_fs_releasedir(f-&gt;fs, path, &amp;fi);
3192  	fuse_finish_interrupt(f, req, &amp;d);
3193  	free_path(f, ino, path);
3194  	pthread_mutex_lock(&amp;dh-&gt;lock);
3195  	pthread_mutex_unlock(&amp;dh-&gt;lock);
3196  	pthread_mutex_destroy(&amp;dh-&gt;lock);
3197  	free_direntries(dh-&gt;first);
3198  	free(dh-&gt;contents);
3199  	free(dh);
3200  	reply_err(req, 0);
3201  }
3202  static void fuse_lib_fsyncdir(fuse_req_t req, fuse_ino_t ino, int datasync,
3203  			      struct fuse_file_info *llfi)
3204  {
3205  	struct fuse *f = req_fuse_prepare(req);
3206  	struct fuse_file_info fi;
3207  	char *path;
3208  	int err;
3209  	get_dirhandle(llfi, &amp;fi);
3210  	err = get_path_nullok(f, ino, &amp;path);
3211  	if (!err) {
3212  		struct fuse_intr_data d;
3213  		fuse_prepare_interrupt(f, req, &amp;d);
3214  		err = fuse_fs_fsyncdir(f-&gt;fs, path, datasync, &amp;fi);
3215  		fuse_finish_interrupt(f, req, &amp;d);
3216  		free_path(f, ino, path);
3217  	}
3218  	reply_err(req, err);
3219  }
3220  static void fuse_lib_statfs(fuse_req_t req, fuse_ino_t ino)
3221  {
3222  	struct fuse *f = req_fuse_prepare(req);
3223  	struct statvfs buf;
3224  	char *path = NULL;
3225  	int err = 0;
3226  	memset(&amp;buf, 0, sizeof(buf));
3227  	if (ino)
3228  		err = get_path(f, ino, &amp;path);
3229  	if (!err) {
3230  		struct fuse_intr_data d;
3231  		fuse_prepare_interrupt(f, req, &amp;d);
3232  		err = fuse_fs_statfs(f-&gt;fs, path ? path : &quot;/&quot;, &amp;buf);
3233  		fuse_finish_interrupt(f, req, &amp;d);
3234  		free_path(f, ino, path);
3235  	}
3236  	if (!err)
3237  		fuse_reply_statfs(req, &amp;buf);
3238  	else
3239  		reply_err(req, err);
3240  }
3241  static void fuse_lib_setxattr(fuse_req_t req, fuse_ino_t ino, const char *name,
3242  			      const char *value, size_t size, int flags)
3243  {
3244  	struct fuse *f = req_fuse_prepare(req);
3245  	char *path;
3246  	int err;
3247  	err = get_path(f, ino, &amp;path);
3248  	if (!err) {
3249  		struct fuse_intr_data d;
3250  		fuse_prepare_interrupt(f, req, &amp;d);
3251  		err = fuse_fs_setxattr(f-&gt;fs, path, name, value, size, flags);
3252  		fuse_finish_interrupt(f, req, &amp;d);
3253  		free_path(f, ino, path);
3254  	}
3255  	reply_err(req, err);
3256  }
3257  static int common_getxattr(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3258  			   const char *name, char *value, size_t size)
3259  {
3260  	int err;
3261  	char *path;
3262  	err = get_path(f, ino, &amp;path);
3263  	if (!err) {
3264  		struct fuse_intr_data d;
3265  		fuse_prepare_interrupt(f, req, &amp;d);
3266  		err = fuse_fs_getxattr(f-&gt;fs, path, name, value, size);
3267  		fuse_finish_interrupt(f, req, &amp;d);
3268  		free_path(f, ino, path);
3269  	}
3270  	return err;
3271  }
3272  static void fuse_lib_getxattr(fuse_req_t req, fuse_ino_t ino, const char *name,
3273  			      size_t size)
3274  {
3275  	struct fuse *f = req_fuse_prepare(req);
3276  	int res;
3277  	if (size) {
3278  		char *value = (char *) malloc(size);
3279  		if (value == NULL) {
3280  			reply_err(req, -ENOMEM);
3281  			return;
3282  		}
3283  		res = common_getxattr(f, req, ino, name, value, size);
3284  		if (res &gt; 0)
3285  			fuse_reply_buf(req, value, res);
3286  		else
3287  			reply_err(req, res);
3288  		free(value);
3289  	} else {
3290  		res = common_getxattr(f, req, ino, name, NULL, 0);
3291  		if (res &gt;= 0)
3292  			fuse_reply_xattr(req, res);
3293  		else
3294  			reply_err(req, res);
3295  	}
3296  }
3297  static int common_listxattr(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3298  			    char *list, size_t size)
3299  {
3300  	char *path;
3301  	int err;
3302  	err = get_path(f, ino, &amp;path);
3303  	if (!err) {
3304  		struct fuse_intr_data d;
3305  		fuse_prepare_interrupt(f, req, &amp;d);
3306  		err = fuse_fs_listxattr(f-&gt;fs, path, list, size);
3307  		fuse_finish_interrupt(f, req, &amp;d);
3308  		free_path(f, ino, path);
3309  	}
3310  	return err;
3311  }
3312  static void fuse_lib_listxattr(fuse_req_t req, fuse_ino_t ino, size_t size)
3313  {
3314  	struct fuse *f = req_fuse_prepare(req);
3315  	int res;
3316  	if (size) {
3317  		char *list = (char *) malloc(size);
3318  		if (list == NULL) {
3319  			reply_err(req, -ENOMEM);
3320  			return;
3321  		}
3322  		res = common_listxattr(f, req, ino, list, size);
3323  		if (res &gt; 0)
3324  			fuse_reply_buf(req, list, res);
3325  		else
3326  			reply_err(req, res);
3327  		free(list);
3328  	} else {
3329  		res = common_listxattr(f, req, ino, NULL, 0);
3330  		if (res &gt;= 0)
3331  			fuse_reply_xattr(req, res);
3332  		else
3333  			reply_err(req, res);
3334  	}
3335  }
3336  static void fuse_lib_removexattr(fuse_req_t req, fuse_ino_t ino,
3337  				 const char *name)
3338  {
3339  	struct fuse *f = req_fuse_prepare(req);
3340  	char *path;
3341  	int err;
3342  	err = get_path(f, ino, &amp;path);
3343  	if (!err) {
3344  		struct fuse_intr_data d;
3345  		fuse_prepare_interrupt(f, req, &amp;d);
3346  		err = fuse_fs_removexattr(f-&gt;fs, path, name);
3347  		fuse_finish_interrupt(f, req, &amp;d);
3348  		free_path(f, ino, path);
3349  	}
3350  	reply_err(req, err);
3351  }
3352  static struct lock *locks_conflict(struct node *node, const struct lock *lock)
3353  {
3354  	struct lock *l;
3355  	for (l = node-&gt;locks; l; l = l-&gt;next)
3356  		if (l-&gt;owner != lock-&gt;owner &amp;&amp;
3357  		    lock-&gt;start &lt;= l-&gt;end &amp;&amp; l-&gt;start &lt;= lock-&gt;end &amp;&amp;
3358  		    (l-&gt;type == F_WRLCK || lock-&gt;type == F_WRLCK))
3359  			break;
3360  	return l;
3361  }
3362  static void delete_lock(struct lock **lockp)
3363  {
3364  	struct lock *l = *lockp;
3365  	*lockp = l-&gt;next;
3366  	free(l);
3367  }
3368  static void insert_lock(struct lock **pos, struct lock *lock)
3369  {
3370  	lock-&gt;next = *pos;
3371  	*pos = lock;
3372  }
3373  static int locks_insert(struct node *node, struct lock *lock)
3374  {
3375  	struct lock **lp;
3376  	struct lock *newl1 = NULL;
3377  	struct lock *newl2 = NULL;
3378  	if (lock-&gt;type != F_UNLCK || lock-&gt;start != 0 ||
3379  	    lock-&gt;end != OFFSET_MAX) {
3380  		newl1 = malloc(sizeof(struct lock));
3381  		newl2 = malloc(sizeof(struct lock));
3382  		if (!newl1 || !newl2) {
3383  			free(newl1);
3384  			free(newl2);
3385  			return -ENOLCK;
3386  		}
3387  	}
3388  	for (lp = &amp;node-&gt;locks; *lp;) {
3389  		struct lock *l = *lp;
3390  		if (l-&gt;owner != lock-&gt;owner)
3391  			goto skip;
3392  		if (lock-&gt;type == l-&gt;type) {
3393  			if (l-&gt;end &lt; lock-&gt;start - 1)
3394  				goto skip;
3395  			if (lock-&gt;end &lt; l-&gt;start - 1)
3396  				break;
3397  			if (l-&gt;start &lt;= lock-&gt;start &amp;&amp; lock-&gt;end &lt;= l-&gt;end)
3398  				goto out;
3399  			if (l-&gt;start &lt; lock-&gt;start)
3400  				lock-&gt;start = l-&gt;start;
3401  			if (lock-&gt;end &lt; l-&gt;end)
3402  				lock-&gt;end = l-&gt;end;
3403  			goto delete;
3404  		} else {
3405  			if (l-&gt;end &lt; lock-&gt;start)
3406  				goto skip;
3407  			if (lock-&gt;end &lt; l-&gt;start)
3408  				break;
3409  			if (lock-&gt;start &lt;= l-&gt;start &amp;&amp; l-&gt;end &lt;= lock-&gt;end)
3410  				goto delete;
3411  			if (l-&gt;end &lt;= lock-&gt;end) {
3412  				l-&gt;end = lock-&gt;start - 1;
3413  				goto skip;
3414  			}
3415  			if (lock-&gt;start &lt;= l-&gt;start) {
3416  				l-&gt;start = lock-&gt;end + 1;
3417  				break;
3418  			}
3419  			*newl2 = *l;
3420  			newl2-&gt;start = lock-&gt;end + 1;
3421  			l-&gt;end = lock-&gt;start - 1;
3422  			insert_lock(&amp;l-&gt;next, newl2);
3423  			newl2 = NULL;
3424  		}
3425  	skip:
3426  		lp = &amp;l-&gt;next;
3427  		continue;
3428  	delete:
3429  		delete_lock(lp);
3430  	}
3431  	if (lock-&gt;type != F_UNLCK) {
3432  		*newl1 = *lock;
3433  		insert_lock(lp, newl1);
3434  		newl1 = NULL;
3435  	}
3436  out:
3437  	free(newl1);
3438  	free(newl2);
3439  	return 0;
3440  }
3441  static void flock_to_lock(struct flock *flock, struct lock *lock)
3442  {
3443  	memset(lock, 0, sizeof(struct lock));
3444  	lock-&gt;type = flock-&gt;l_type;
3445  	lock-&gt;start = flock-&gt;l_start;
3446  	lock-&gt;end =
3447  		flock-&gt;l_len ? flock-&gt;l_start + flock-&gt;l_len - 1 : OFFSET_MAX;
3448  	lock-&gt;pid = flock-&gt;l_pid;
3449  }
3450  static void lock_to_flock(struct lock *lock, struct flock *flock)
3451  {
3452  	flock-&gt;l_type = lock-&gt;type;
3453  	flock-&gt;l_start = lock-&gt;start;
3454  	flock-&gt;l_len =
3455  		(lock-&gt;end == OFFSET_MAX) ? 0 : lock-&gt;end - lock-&gt;start + 1;
3456  	flock-&gt;l_pid = lock-&gt;pid;
3457  }
3458  static int fuse_flush_common(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3459  			     const char *path, struct fuse_file_info *fi)
3460  {
3461  	struct fuse_intr_data d;
3462  	struct flock lock;
3463  	struct lock l;
3464  	int err;
3465  	int errlock;
3466  	fuse_prepare_interrupt(f, req, &amp;d);
3467  	memset(&amp;lock, 0, sizeof(lock));
3468  	lock.l_type = F_UNLCK;
3469  	lock.l_whence = SEEK_SET;
3470  	err = fuse_fs_flush(f-&gt;fs, path, fi);
3471  	errlock = fuse_fs_lock(f-&gt;fs, path, fi, F_SETLK, &amp;lock);
3472  	fuse_finish_interrupt(f, req, &amp;d);
3473  	if (errlock != -ENOSYS) {
3474  		flock_to_lock(&amp;lock, &amp;l);
3475  		l.owner = fi-&gt;lock_owner;
3476  		pthread_mutex_lock(&amp;f-&gt;lock);
3477  		locks_insert(get_node(f, ino), &amp;l);
3478  		pthread_mutex_unlock(&amp;f-&gt;lock);
3479  		if (err == -ENOSYS)
3480  			err = 0;
3481  	}
3482  	return err;
3483  }
3484  static void fuse_lib_release(fuse_req_t req, fuse_ino_t ino,
3485  			     struct fuse_file_info *fi)
3486  {
3487  	struct fuse *f = req_fuse_prepare(req);
3488  	struct fuse_intr_data d;
3489  	char *path;
3490  	int err = 0;
3491  	get_path_nullok(f, ino, &amp;path);
3492  	if (fi-&gt;flush) {
3493  		err = fuse_flush_common(f, req, ino, path, fi);
3494  		if (err == -ENOSYS)
3495  			err = 0;
3496  	}
3497  	fuse_prepare_interrupt(f, req, &amp;d);
3498  	fuse_do_release(f, ino, path, fi);
3499  	fuse_finish_interrupt(f, req, &amp;d);
3500  	free_path(f, ino, path);
3501  	reply_err(req, err);
3502  }
3503  static void fuse_lib_flush(fuse_req_t req, fuse_ino_t ino,
3504  			   struct fuse_file_info *fi)
3505  {
3506  	struct fuse *f = req_fuse_prepare(req);
3507  	char *path;
3508  	int err;
3509  	get_path_nullok(f, ino, &amp;path);
3510  	err = fuse_flush_common(f, req, ino, path, fi);
3511  	free_path(f, ino, path);
3512  	reply_err(req, err);
3513  }
3514  static int fuse_lock_common(fuse_req_t req, fuse_ino_t ino,
3515  			    struct fuse_file_info *fi, struct flock *lock,
3516  			    int cmd)
3517  {
3518  	struct fuse *f = req_fuse_prepare(req);
3519  	char *path;
3520  	int err;
3521  	err = get_path_nullok(f, ino, &amp;path);
3522  	if (!err) {
3523  		struct fuse_intr_data d;
3524  		fuse_prepare_interrupt(f, req, &amp;d);
3525  		err = fuse_fs_lock(f-&gt;fs, path, fi, cmd, lock);
3526  		fuse_finish_interrupt(f, req, &amp;d);
3527  		free_path(f, ino, path);
3528  	}
3529  	return err;
3530  }
3531  static void fuse_lib_getlk(fuse_req_t req, fuse_ino_t ino,
3532  			   struct fuse_file_info *fi, struct flock *lock)
3533  {
3534  	int err;
3535  	struct lock l;
3536  	struct lock *conflict;
3537  	struct fuse *f = req_fuse(req);
3538  	flock_to_lock(lock, &amp;l);
3539  	l.owner = fi-&gt;lock_owner;
3540  	pthread_mutex_lock(&amp;f-&gt;lock);
3541  	conflict = locks_conflict(get_node(f, ino), &amp;l);
3542  	if (conflict)
3543  		lock_to_flock(conflict, lock);
3544  	pthread_mutex_unlock(&amp;f-&gt;lock);
3545  	if (!conflict)
3546  		err = fuse_lock_common(req, ino, fi, lock, F_GETLK);
3547  	else
3548  		err = 0;
3549  	if (!err)
3550  		fuse_reply_lock(req, lock);
3551  	else
3552  		reply_err(req, err);
3553  }
3554  static void fuse_lib_setlk(fuse_req_t req, fuse_ino_t ino,
3555  			   struct fuse_file_info *fi, struct flock *lock,
3556  			   int sleep)
3557  {
3558  	int err = fuse_lock_common(req, ino, fi, lock,
3559  				   sleep ? F_SETLKW : F_SETLK);
3560  	if (!err) {
3561  		struct fuse *f = req_fuse(req);
3562  		struct lock l;
3563  		flock_to_lock(lock, &amp;l);
3564  		l.owner = fi-&gt;lock_owner;
3565  		pthread_mutex_lock(&amp;f-&gt;lock);
3566  		locks_insert(get_node(f, ino), &amp;l);
3567  		pthread_mutex_unlock(&amp;f-&gt;lock);
3568  	}
3569  	reply_err(req, err);
3570  }
3571  static void fuse_lib_flock(fuse_req_t req, fuse_ino_t ino,
3572  			   struct fuse_file_info *fi, int op)
3573  {
3574  	struct fuse *f = req_fuse_prepare(req);
3575  	char *path;
3576  	int err;
3577  	err = get_path_nullok(f, ino, &amp;path);
3578  	if (err == 0) {
3579  		struct fuse_intr_data d;
3580  		fuse_prepare_interrupt(f, req, &amp;d);
3581  		err = fuse_fs_flock(f-&gt;fs, path, fi, op);
3582  		fuse_finish_interrupt(f, req, &amp;d);
3583  		free_path(f, ino, path);
3584  	}
3585  	reply_err(req, err);
3586  }
3587  static void fuse_lib_bmap(fuse_req_t req, fuse_ino_t ino, size_t blocksize,
3588  			  uint64_t idx)
3589  {
3590  	struct fuse *f = req_fuse_prepare(req);
3591  	struct fuse_intr_data d;
3592  	char *path;
3593  	int err;
3594  	err = get_path(f, ino, &amp;path);
3595  	if (!err) {
3596  		fuse_prepare_interrupt(f, req, &amp;d);
3597  		err = fuse_fs_bmap(f-&gt;fs, path, blocksize, &amp;idx);
3598  		fuse_finish_interrupt(f, req, &amp;d);
3599  		free_path(f, ino, path);
3600  	}
3601  	if (!err)
3602  		fuse_reply_bmap(req, idx);
3603  	else
3604  		reply_err(req, err);
3605  }
3606  static void fuse_lib_ioctl(fuse_req_t req, fuse_ino_t ino, unsigned int cmd,
3607  			   void *arg, struct fuse_file_info *llfi,
3608  			   unsigned int flags, const void *in_buf,
3609  			   size_t in_bufsz, size_t out_bufsz)
3610  {
3611  	struct fuse *f = req_fuse_prepare(req);
3612  	struct fuse_intr_data d;
3613  	struct fuse_file_info fi;
3614  	char *path, *out_buf = NULL;
3615  	int err;
3616  	err = -EPERM;
3617  	if (flags &amp; FUSE_IOCTL_UNRESTRICTED)
3618  		goto err;
3619  	if (flags &amp; FUSE_IOCTL_DIR)
3620  		get_dirhandle(llfi, &amp;fi);
3621  	else
3622  		fi = *llfi;
3623  	if (out_bufsz) {
3624  		err = -ENOMEM;
3625  		out_buf = malloc(out_bufsz);
3626  		if (!out_buf)
3627  			goto err;
3628  	}
3629  	assert(!in_bufsz || !out_bufsz || in_bufsz == out_bufsz);
3630  	if (out_buf &amp;&amp; in_bufsz)
3631  		memcpy(out_buf, in_buf, in_bufsz);
3632  	err = get_path_nullok(f, ino, &amp;path);
3633  	if (err)
3634  		goto err;
3635  	fuse_prepare_interrupt(f, req, &amp;d);
3636  	err = fuse_fs_ioctl(f-&gt;fs, path, cmd, arg, &amp;fi, flags,
3637  			    out_buf ? out_buf : (void *)in_buf);
3638  	fuse_finish_interrupt(f, req, &amp;d);
3639  	free_path(f, ino, path);
3640  	if (err &lt; 0)
3641  		goto err;
3642  	fuse_reply_ioctl(req, err, out_buf, out_bufsz);
3643  	goto out;
3644  err:
3645  	reply_err(req, err);
3646  out:
3647  	free(out_buf);
3648  }
3649  static void fuse_lib_poll(fuse_req_t req, fuse_ino_t ino,
3650  			  struct fuse_file_info *fi, struct fuse_pollhandle *ph)
3651  {
3652  	struct fuse *f = req_fuse_prepare(req);
3653  	struct fuse_intr_data d;
3654  	char *path;
3655  	int err;
3656  	unsigned revents = 0;
3657  	err = get_path_nullok(f, ino, &amp;path);
3658  	if (!err) {
3659  		fuse_prepare_interrupt(f, req, &amp;d);
3660  		err = fuse_fs_poll(f-&gt;fs, path, fi, ph, &amp;revents);
3661  		fuse_finish_interrupt(f, req, &amp;d);
3662  		free_path(f, ino, path);
3663  	}
3664  	if (!err)
3665  		fuse_reply_poll(req, revents);
3666  	else
3667  		reply_err(req, err);
3668  }
3669  static void fuse_lib_fallocate(fuse_req_t req, fuse_ino_t ino, int mode,
3670  		off_t offset, off_t length, struct fuse_file_info *fi)
3671  {
3672  	struct fuse *f = req_fuse_prepare(req);
3673  	struct fuse_intr_data d;
3674  	char *path;
3675  	int err;
3676  	err = get_path_nullok(f, ino, &amp;path);
3677  	if (!err) {
3678  		fuse_prepare_interrupt(f, req, &amp;d);
3679  		err = fuse_fs_fallocate(f-&gt;fs, path, mode, offset, length, fi);
3680  		fuse_finish_interrupt(f, req, &amp;d);
3681  		free_path(f, ino, path);
3682  	}
3683  	reply_err(req, err);
3684  }
3685  static void fuse_lib_copy_file_range(fuse_req_t req, fuse_ino_t nodeid_in,
3686  				     off_t off_in, struct fuse_file_info *fi_in,
3687  				     fuse_ino_t nodeid_out, off_t off_out,
3688  				     struct fuse_file_info *fi_out, size_t len,
3689  				     int flags)
3690  {
3691  	struct fuse *f = req_fuse_prepare(req);
3692  	struct fuse_intr_data d;
3693  	char *path_in, *path_out;
3694  	int err;
3695  	ssize_t res;
3696  	err = get_path_nullok(f, nodeid_in, &amp;path_in);
3697  	if (err) {
3698  		reply_err(req, err);
3699  		return;
3700  	}
3701  	err = get_path_nullok(f, nodeid_out, &amp;path_out);
3702  	if (err) {
3703  		free_path(f, nodeid_in, path_in);
3704  		reply_err(req, err);
3705  		return;
3706  	}
3707  	fuse_prepare_interrupt(f, req, &amp;d);
3708  	res = fuse_fs_copy_file_range(f-&gt;fs, path_in, fi_in, off_in, path_out,
3709  				      fi_out, off_out, len, flags);
3710  	fuse_finish_interrupt(f, req, &amp;d);
3711  	if (res &gt;= 0)
3712  		fuse_reply_write(req, res);
3713  	else
3714  		reply_err(req, res);
3715  	free_path(f, nodeid_in, path_in);
3716  	free_path(f, nodeid_out, path_out);
3717  }
3718  static void fuse_lib_lseek(fuse_req_t req, fuse_ino_t ino, off_t off, int whence,
3719  			   struct fuse_file_info *fi)
3720  {
3721  	struct fuse *f = req_fuse_prepare(req);
3722  	struct fuse_intr_data d;
3723  	char *path;
3724  	int err;
3725  	off_t res;
3726  	err = get_path(f, ino, &amp;path);
3727  	if (err) {
3728  		reply_err(req, err);
3729  		return;
3730  	}
3731  	fuse_prepare_interrupt(f, req, &amp;d);
3732  	res = fuse_fs_lseek(f-&gt;fs, path, off, whence, fi);
3733  	fuse_finish_interrupt(f, req, &amp;d);
3734  	free_path(f, ino, path);
3735  	if (res &gt;= 0)
3736  		fuse_reply_lseek(req, res);
3737  	else
3738  		reply_err(req, res);
3739  }
3740  static int clean_delay(struct fuse *f)
3741  {
3742  	int min_sleep = 60;
3743  	int max_sleep = 3600;
3744  	int sleep_time = f-&gt;conf.remember / 10;
3745  	if (sleep_time &gt; max_sleep)
3746  		return max_sleep;
3747  	if (sleep_time &lt; min_sleep)
3748  		return min_sleep;
3749  	return sleep_time;
3750  }
3751  int fuse_clean_cache(struct fuse *f)
3752  {
3753  	struct node_lru *lnode;
3754  	struct list_head *curr, *next;
3755  	struct node *node;
3756  	struct timespec now;
3757  	pthread_mutex_lock(&amp;f-&gt;lock);
3758  	curr_time(&amp;now);
3759  	for (curr = f-&gt;lru_table.next; curr != &amp;f-&gt;lru_table; curr = next) {
3760  		double age;
3761  		next = curr-&gt;next;
3762  		lnode = list_entry(curr, struct node_lru, lru);
3763  		node = &amp;lnode-&gt;node;
3764  		age = diff_timespec(&amp;now, &amp;lnode-&gt;forget_time);
3765  		if (age &lt;= f-&gt;conf.remember)
3766  			break;
3767  		assert(node-&gt;nlookup == 1);
3768  		if (node-&gt;refctr &gt; 1)
3769  			continue;
3770  		node-&gt;nlookup = 0;
3771  		unhash_name(f, node);
3772  		unref_node(f, node);
3773  	}
3774  	pthread_mutex_unlock(&amp;f-&gt;lock);
3775  	return clean_delay(f);
3776  }
3777  static struct fuse_lowlevel_ops fuse_path_ops = {
3778  	.init = fuse_lib_init,
3779  	.destroy = fuse_lib_destroy,
3780  	.lookup = fuse_lib_lookup,
3781  	.forget = fuse_lib_forget,
3782  	.forget_multi = fuse_lib_forget_multi,
3783  	.getattr = fuse_lib_getattr,
3784  	.setattr = fuse_lib_setattr,
3785  	.access = fuse_lib_access,
3786  	.readlink = fuse_lib_readlink,
3787  	.mknod = fuse_lib_mknod,
3788  	.mkdir = fuse_lib_mkdir,
3789  	.unlink = fuse_lib_unlink,
3790  	.rmdir = fuse_lib_rmdir,
3791  	.symlink = fuse_lib_symlink,
3792  	.rename = fuse_lib_rename,
3793  	.link = fuse_lib_link,
3794  	.create = fuse_lib_create,
3795  	.open = fuse_lib_open,
3796  	.read = fuse_lib_read,
3797  	.write_buf = fuse_lib_write_buf,
3798  	.flush = fuse_lib_flush,
3799  	.release = fuse_lib_release,
3800  	.fsync = fuse_lib_fsync,
3801  	.opendir = fuse_lib_opendir,
3802  	.readdir = fuse_lib_readdir,
3803  	.readdirplus = fuse_lib_readdirplus,
3804  	.releasedir = fuse_lib_releasedir,
3805  	.fsyncdir = fuse_lib_fsyncdir,
3806  	.statfs = fuse_lib_statfs,
3807  	.setxattr = fuse_lib_setxattr,
3808  	.getxattr = fuse_lib_getxattr,
3809  	.listxattr = fuse_lib_listxattr,
3810  	.removexattr = fuse_lib_removexattr,
3811  	.getlk = fuse_lib_getlk,
3812  	.setlk = fuse_lib_setlk,
3813  	.flock = fuse_lib_flock,
3814  	.bmap = fuse_lib_bmap,
3815  	.ioctl = fuse_lib_ioctl,
3816  	.poll = fuse_lib_poll,
3817  	.fallocate = fuse_lib_fallocate,
3818  	.copy_file_range = fuse_lib_copy_file_range,
3819  	.lseek = fuse_lib_lseek,
3820  };
3821  int fuse_notify_poll(struct fuse_pollhandle *ph)
3822  {
3823  	return fuse_lowlevel_notify_poll(ph);
3824  }
3825  struct fuse_session *fuse_get_session(struct fuse *f)
3826  {
3827  	return f-&gt;se;
3828  }
3829  static int fuse_session_loop_remember(struct fuse *f)
3830  {
3831  	struct fuse_session *se = f-&gt;se;
3832  	int res = 0;
3833  	struct timespec now;
3834  	time_t next_clean;
3835  	struct pollfd fds = {
3836  		.fd = se-&gt;fd,
3837  		.events = POLLIN
3838  	};
3839  	struct fuse_buf fbuf = {
3840  		.mem = NULL,
3841  	};
3842  	curr_time(&amp;now);
3843  	next_clean = now.tv_sec;
3844  	while (!fuse_session_exited(se)) {
3845  		unsigned timeout;
3846  		curr_time(&amp;now);
3847  		if (now.tv_sec &lt; next_clean)
3848  			timeout = next_clean - now.tv_sec;
3849  		else
3850  			timeout = 0;
3851  		res = poll(&amp;fds, 1, timeout * 1000);
3852  		if (res == -1) {
3853  			if (errno == EINTR)
3854  				continue;
3855  			else
3856  				break;
3857  		} else if (res &gt; 0) {
3858  			res = fuse_session_receive_buf_int(se, &amp;fbuf, NULL);
3859  			if (res == -EINTR)
3860  				continue;
3861  			if (res &lt;= 0)
3862  				break;
3863  			fuse_session_process_buf_int(se, &amp;fbuf, NULL);
3864  		} else {
3865  			timeout = fuse_clean_cache(f);
3866  			curr_time(&amp;now);
3867  			next_clean = now.tv_sec + timeout;
3868  		}
3869  	}
3870  	free(fbuf.mem);
3871  	fuse_session_reset(se);
3872  	return res &lt; 0 ? -1 : 0;
3873  }
3874  int fuse_loop(struct fuse *f)
3875  {
3876  	if (!f)
3877  		return -1;
3878  	if (lru_enabled(f))
3879  		return fuse_session_loop_remember(f);
3880  	return fuse_session_loop(f-&gt;se);
3881  }
3882  FUSE_SYMVER(&quot;fuse_loop_mt_312&quot;, &quot;fuse_loop_mt@@FUSE_3.12&quot;)
3883  int fuse_loop_mt_312(struct fuse *f, struct fuse_loop_config *config)
3884  {
3885  	if (f == NULL)
3886  		return -1;
3887  	int res = fuse_start_cleanup_thread(f);
3888  	if (res)
3889  		return -1;
3890  	res = fuse_session_loop_mt_312(fuse_get_session(f), config);
3891  	fuse_stop_cleanup_thread(f);
3892  	return res;
3893  }
3894  int fuse_loop_mt_32(struct fuse *f, struct fuse_loop_config_v1 *config_v1);
3895  FUSE_SYMVER(&quot;fuse_loop_mt_32&quot;, &quot;fuse_loop_mt@FUSE_3.2&quot;)
3896  int fuse_loop_mt_32(struct fuse *f, struct fuse_loop_config_v1 *config_v1)
3897  {
3898  	struct fuse_loop_config *config = fuse_loop_cfg_create();
3899  	if (config == NULL)
3900  		return ENOMEM;
3901  	fuse_loop_cfg_convert(config, config_v1);
3902  	int res = fuse_loop_mt_312(f, config);
3903  	fuse_loop_cfg_destroy(config);
3904  	return res;
3905  }
3906  int fuse_loop_mt_31(struct fuse *f, int clone_fd);
3907  FUSE_SYMVER(&quot;fuse_loop_mt_31&quot;, &quot;fuse_loop_mt@FUSE_3.0&quot;)
3908  int fuse_loop_mt_31(struct fuse *f, int clone_fd)
3909  {
3910  	int err;
3911  	struct fuse_loop_config *config = fuse_loop_cfg_create();
3912  	if (config == NULL)
3913  		return ENOMEM;
3914  	fuse_loop_cfg_set_clone_fd(config, clone_fd);
3915  	err = fuse_loop_mt_312(f, config);
3916  	fuse_loop_cfg_destroy(config);
3917  	return err;
3918  }
3919  void fuse_exit(struct fuse *f)
3920  {
3921  	fuse_session_exit(f-&gt;se);
3922  }
3923  struct fuse_context *fuse_get_context(void)
3924  {
3925  	struct fuse_context_i *c = fuse_get_context_internal();
3926  	if (c)
3927  		return &amp;c-&gt;ctx;
3928  	else
3929  		return NULL;
3930  }
3931  int fuse_getgroups(int size, gid_t list[])
3932  {
3933  	struct fuse_context_i *c = fuse_get_context_internal();
3934  	if (!c)
3935  		return -EINVAL;
3936  	return fuse_req_getgroups(c-&gt;req, size, list);
3937  }
3938  int fuse_interrupted(void)
3939  {
3940  	struct fuse_context_i *c = fuse_get_context_internal();
3941  	if (c)
3942  		return fuse_req_interrupted(c-&gt;req);
3943  	else
3944  		return 0;
3945  }
3946  int fuse_invalidate_path(struct fuse *f, const char *path) {
3947  	fuse_ino_t ino;
3948  	int err = lookup_path_in_cache(f, path, &amp;ino);
3949  	if (err) {
3950  		return err;
3951  	}
3952  	return fuse_lowlevel_notify_inval_inode(f-&gt;se, ino, 0, 0);
3953  }
3954  #define FUSE_LIB_OPT(t, p, v) { t, offsetof(struct fuse_config, p), v }
3955  static const struct fuse_opt fuse_lib_opts[] = {
3956  	FUSE_OPT_KEY(&quot;debug&quot;,		      FUSE_OPT_KEY_KEEP),
3957  	FUSE_OPT_KEY(&quot;-d&quot;,		      FUSE_OPT_KEY_KEEP),
3958  	FUSE_LIB_OPT(&quot;debug&quot;,		      debug, 1),
3959  	FUSE_LIB_OPT(&quot;-d&quot;,		      debug, 1),
3960  	FUSE_LIB_OPT(&quot;kernel_cache&quot;,	      kernel_cache, 1),
3961  	FUSE_LIB_OPT(&quot;auto_cache&quot;,	      auto_cache, 1),
3962  	FUSE_LIB_OPT(&quot;noauto_cache&quot;,	      auto_cache, 0),
3963  	FUSE_LIB_OPT(&quot;no_rofd_flush&quot;,	      no_rofd_flush, 1),
3964  	FUSE_LIB_OPT(&quot;umask=&quot;,		      set_mode, 1),
3965  	FUSE_LIB_OPT(&quot;umask=%o&quot;,	      umask, 0),
3966  	FUSE_LIB_OPT(&quot;uid=&quot;,		      set_uid, 1),
3967  	FUSE_LIB_OPT(&quot;uid=%d&quot;,		      uid, 0),
3968  	FUSE_LIB_OPT(&quot;gid=&quot;,		      set_gid, 1),
3969  	FUSE_LIB_OPT(&quot;gid=%d&quot;,		      gid, 0),
3970  	FUSE_LIB_OPT(&quot;entry_timeout=%lf&quot;,     entry_timeout, 0),
3971  	FUSE_LIB_OPT(&quot;attr_timeout=%lf&quot;,      attr_timeout, 0),
3972  	FUSE_LIB_OPT(&quot;ac_attr_timeout=%lf&quot;,   ac_attr_timeout, 0),
3973  	FUSE_LIB_OPT(&quot;ac_attr_timeout=&quot;,      ac_attr_timeout_set, 1),
3974  	FUSE_LIB_OPT(&quot;negative_timeout=%lf&quot;,  negative_timeout, 0),
3975  	FUSE_LIB_OPT(&quot;noforget&quot;,              remember, -1),
3976  	FUSE_LIB_OPT(&quot;remember=%u&quot;,           remember, 0),
3977  	FUSE_LIB_OPT(&quot;modules=%s&quot;,	      modules, 0),
3978  	FUSE_LIB_OPT(&quot;parallel_direct_write=%d&quot;, parallel_direct_writes, 0),
3979  	FUSE_OPT_END
3980  };
3981  static int fuse_lib_opt_proc(void *data, const char *arg, int key,
3982  			     struct fuse_args *outargs)
3983  {
3984  	(void) arg; (void) outargs; (void) data; (void) key;
3985  	return 1;
3986  }
3987  static const struct fuse_opt fuse_help_opts[] = {
3988  	FUSE_LIB_OPT(&quot;modules=%s&quot;, modules, 1),
3989  	FUSE_OPT_KEY(&quot;modules=%s&quot;, FUSE_OPT_KEY_KEEP),
3990  	FUSE_OPT_END
3991  };
3992  static void print_module_help(const char *name,
3993  			      fuse_module_factory_t *fac)
3994  {
3995  	struct fuse_args a = FUSE_ARGS_INIT(0, NULL);
3996  	if (fuse_opt_add_arg(&amp;a, &quot;&quot;) == -1 ||
3997  	    fuse_opt_add_arg(&amp;a, &quot;-h&quot;) == -1)
3998  		return;
3999  	printf(&quot;\nOptions for %s module:\n&quot;, name);
4000  	(*fac)(&amp;a, NULL);
4001  	fuse_opt_free_args(&amp;a);
4002  }
4003  void fuse_lib_help(struct fuse_args *args)
4004  {
4005  	printf(
4006  &quot;    -o kernel_cache        cache files in kernel\n&quot;
4007  &quot;    -o [no]auto_cache      enable caching based on modification times (off)\n&quot;
4008  &quot;    -o no_rofd_flush       disable flushing of read-only fd on close (off)\n&quot;
4009  &quot;    -o umask=M             set file permissions (octal)\n&quot;
4010  &quot;    -o uid=N               set file owner\n&quot;
4011  &quot;    -o gid=N               set file group\n&quot;
4012  &quot;    -o entry_timeout=T     cache timeout for names (1.0s)\n&quot;
4013  &quot;    -o negative_timeout=T  cache timeout for deleted names (0.0s)\n&quot;
4014  &quot;    -o attr_timeout=T      cache timeout for attributes (1.0s)\n&quot;
4015  &quot;    -o ac_attr_timeout=T   auto cache timeout for attributes (attr_timeout)\n&quot;
4016  &quot;    -o noforget            never forget cached inodes\n&quot;
4017  &quot;    -o remember=T          remember cached inodes for T seconds (0s)\n&quot;
4018  &quot;    -o modules=M1[:M2...]  names of modules to push onto filesystem stack\n&quot;);
4019  	fuse_lowlevel_help();
4020  	print_module_help(&quot;subdir&quot;, &amp;fuse_module_subdir_factory);
4021  #ifdef HAVE_ICONV
4022  	print_module_help(&quot;iconv&quot;, &amp;fuse_module_iconv_factory);
4023  #endif
4024  	struct fuse_config conf = { .modules = NULL };
4025  	if (fuse_opt_parse(args, &amp;conf, fuse_help_opts,
4026  			   fuse_lib_opt_proc) == -1
4027  	    || !conf.modules)
4028  		return;
4029  	char *module;
4030  	char *next;
4031  	struct fuse_module *m;
4032  	for (module = conf.modules; module; module = next) {
4033  		char *p;
4034  		for (p = module; *p &amp;&amp; *p != &#x27;:&#x27;; p++);
4035  		next = *p ? p + 1 : NULL;
4036  		*p = &#x27;\0&#x27;;
4037  		m = fuse_get_module(module);
4038  		if (m)
4039  			print_module_help(module, &amp;m-&gt;factory);
4040  	}
4041  }
4042  static int fuse_init_intr_signal(int signum, int *installed)
4043  {
4044  	struct sigaction old_sa;
4045  	if (sigaction(signum, NULL, &amp;old_sa) == -1) {
4046  		perror(&quot;fuse: cannot get old signal handler&quot;);
4047  		return -1;
4048  	}
4049  	if (old_sa.sa_handler == SIG_DFL) {
4050  		struct sigaction sa;
4051  		memset(&amp;sa, 0, sizeof(struct sigaction));
4052  		sa.sa_handler = fuse_intr_sighandler;
4053  		sigemptyset(&amp;sa.sa_mask);
4054  		if (sigaction(signum, &amp;sa, NULL) == -1) {
4055  			perror(&quot;fuse: cannot set interrupt signal handler&quot;);
4056  			return -1;
4057  		}
4058  		*installed = 1;
4059  	}
4060  	return 0;
4061  }
4062  static void fuse_restore_intr_signal(int signum)
4063  {
4064  	struct sigaction sa;
4065  	memset(&amp;sa, 0, sizeof(struct sigaction));
4066  	sa.sa_handler = SIG_DFL;
4067  	sigaction(signum, &amp;sa, NULL);
4068  }
4069  static int fuse_push_module(struct fuse *f, const char *module,
4070  			    struct fuse_args *args)
4071  {
4072  	struct fuse_fs *fs[2] = { f-&gt;fs, NULL };
4073  	struct fuse_fs *newfs;
4074  	struct fuse_module *m = fuse_get_module(module);
4075  	if (!m)
4076  		return -1;
4077  	newfs = m-&gt;factory(args, fs);
4078  	if (!newfs) {
4079  		fuse_put_module(m);
4080  		return -1;
4081  	}
4082  	f-&gt;fs = newfs;
4083  	return 0;
4084  }
4085  struct fuse_fs *fuse_fs_new(const struct fuse_operations *op, size_t op_size,
4086  			    void *user_data)
4087  {
4088  	struct fuse_fs *fs;
4089  	if (sizeof(struct fuse_operations) &lt; op_size) {
4090  		fuse_log(FUSE_LOG_ERR, &quot;fuse: warning: library too old, some operations may not not work\n&quot;);
4091  		op_size = sizeof(struct fuse_operations);
4092  	}
4093  	fs = (struct fuse_fs *) calloc(1, sizeof(struct fuse_fs));
4094  	if (!fs) {
4095  		fuse_log(FUSE_LOG_ERR, &quot;fuse: failed to allocate fuse_fs object\n&quot;);
4096  		return NULL;
4097  	}
4098  	fs-&gt;user_data = user_data;
4099  	if (op)
4100  		memcpy(&amp;fs-&gt;op, op, op_size);
4101  	return fs;
4102  }
4103  static int node_table_init(struct node_table *t)
4104  {
4105  	t-&gt;size = NODE_TABLE_MIN_SIZE;
4106  	t-&gt;array = (struct node **) calloc(1, sizeof(struct node *) * t-&gt;size);
4107  	if (t-&gt;array == NULL) {
4108  		fuse_log(FUSE_LOG_ERR, &quot;fuse: memory allocation failed\n&quot;);
4109  		return -1;
4110  	}
4111  	t-&gt;use = 0;
4112  	t-&gt;split = 0;
4113  	return 0;
4114  }
4115  static void *fuse_prune_nodes(void *fuse)
4116  {
4117  	struct fuse *f = fuse;
4118  	int sleep_time;
4119  	while(1) {
4120  		sleep_time = fuse_clean_cache(f);
4121  		sleep(sleep_time);
4122  	}
4123  	return NULL;
4124  }
4125  int fuse_start_cleanup_thread(struct fuse *f)
4126  {
4127  	if (lru_enabled(f))
4128  		return fuse_start_thread(&amp;f-&gt;prune_thread, fuse_prune_nodes, f);
4129  	return 0;
4130  }
4131  void fuse_stop_cleanup_thread(struct fuse *f)
4132  {
4133  	if (lru_enabled(f)) {
4134  		pthread_mutex_lock(&amp;f-&gt;lock);
4135  		pthread_cancel(f-&gt;prune_thread);
4136  		pthread_mutex_unlock(&amp;f-&gt;lock);
4137  		pthread_join(f-&gt;prune_thread, NULL);
4138  	}
4139  }
4140  FUSE_SYMVER(&quot;fuse_new_31&quot;, &quot;fuse_new@@FUSE_3.1&quot;)
4141  struct fuse *fuse_new_31(struct fuse_args *args,
4142  		      const struct fuse_operations *op,
4143  		      size_t op_size, void *user_data)
4144  {
4145  	struct fuse *f;
4146  	struct node *root;
4147  	struct fuse_fs *fs;
4148  	struct fuse_lowlevel_ops llop = fuse_path_ops;
4149  	f = (struct fuse *) calloc(1, sizeof(struct fuse));
4150  	if (f == NULL) {
4151  		fuse_log(FUSE_LOG_ERR, &quot;fuse: failed to allocate fuse object\n&quot;);
4152  		goto out;
4153  	}
4154  	f-&gt;conf.entry_timeout = 1.0;
4155  	f-&gt;conf.attr_timeout = 1.0;
4156  	f-&gt;conf.negative_timeout = 0.0;
4157  	f-&gt;conf.intr_signal = FUSE_DEFAULT_INTR_SIGNAL;
4158  	if (fuse_opt_parse(args, &amp;f-&gt;conf, fuse_lib_opts,
4159  			   fuse_lib_opt_proc) == -1)
4160  		goto out_free;
4161  	pthread_mutex_lock(&amp;fuse_context_lock);
4162  	static int builtin_modules_registered = 0;
4163  	if (builtin_modules_registered == 0) {
4164  		fuse_register_module(&quot;subdir&quot;, fuse_module_subdir_factory, NULL);
4165  #ifdef HAVE_ICONV
4166  		fuse_register_module(&quot;iconv&quot;, fuse_module_iconv_factory, NULL);
4167  #endif
4168  		builtin_modules_registered= 1;
4169  	}
4170  	pthread_mutex_unlock(&amp;fuse_context_lock);
4171  	if (fuse_create_context_key() == -1)
4172  		goto out_free;
4173  	fs = fuse_fs_new(op, op_size, user_data);
4174  	if (!fs)
4175  		goto out_delete_context_key;
4176  	f-&gt;fs = fs;
4177  	if (!fs-&gt;op.lock) {
4178  		llop.getlk = NULL;
4179  		llop.setlk = NULL;
4180  	}
4181  	f-&gt;pagesize = getpagesize();
4182  	init_list_head(&amp;f-&gt;partial_slabs);
4183  	init_list_head(&amp;f-&gt;full_slabs);
4184  	init_list_head(&amp;f-&gt;lru_table);
4185  	if (f-&gt;conf.modules) {
4186  		char *module;
4187  		char *next;
4188  		for (module = f-&gt;conf.modules; module; module = next) {
4189  			char *p;
4190  			for (p = module; *p &amp;&amp; *p != &#x27;:&#x27;; p++);
4191  			next = *p ? p + 1 : NULL;
4192  			*p = &#x27;\0&#x27;;
4193  			if (module[0] &amp;&amp;
4194  			    fuse_push_module(f, module, args) == -1)
4195  				goto out_free_fs;
4196  		}
4197  	}
4198  	if (!f-&gt;conf.ac_attr_timeout_set)
4199  		f-&gt;conf.ac_attr_timeout = f-&gt;conf.attr_timeout;
4200  #if defined(__FreeBSD__) || defined(__NetBSD__)
4201  	f-&gt;conf.readdir_ino = 1;
4202  #endif
4203  	f-&gt;se = fuse_session_new(args, &amp;llop, sizeof(llop), f);
4204  	if (f-&gt;se == NULL)
4205  		goto out_free_fs;
4206  	if (f-&gt;conf.debug) {
4207  		fuse_log(FUSE_LOG_DEBUG, &quot;nullpath_ok: %i\n&quot;, f-&gt;conf.nullpath_ok);
4208  	}
4209  	f-&gt;fs-&gt;debug = f-&gt;conf.debug;
4210  	f-&gt;ctr = 0;
4211  	f-&gt;generation = 0;
4212  	if (node_table_init(&amp;f-&gt;name_table) == -1)
4213  		goto out_free_session;
4214  	if (node_table_init(&amp;f-&gt;id_table) == -1)
4215  		goto out_free_name_table;
4216  	pthread_mutex_init(&amp;f-&gt;lock, NULL);
4217  	root = alloc_node(f);
4218  	if (root == NULL) {
4219  		fuse_log(FUSE_LOG_ERR, &quot;fuse: memory allocation failed\n&quot;);
4220  		goto out_free_id_table;
4221  	}
4222  	if (lru_enabled(f)) {
4223  		struct node_lru *lnode = node_lru(root);
4224  		init_list_head(&amp;lnode-&gt;lru);
4225  	}
4226  	strcpy(root-&gt;inline_name, &quot;/&quot;);
4227  	root-&gt;name = root-&gt;inline_name;
4228  	if (f-&gt;conf.intr &amp;&amp;
4229  	    fuse_init_intr_signal(f-&gt;conf.intr_signal,
4230  				  &amp;f-&gt;intr_installed) == -1)
4231  		goto out_free_root;
4232  	root-&gt;parent = NULL;
4233  	root-&gt;nodeid = FUSE_ROOT_ID;
4234  	inc_nlookup(root);
4235  	hash_id(f, root);
4236  	return f;
4237  out_free_root:
4238  	free(root);
4239  out_free_id_table:
4240  	free(f-&gt;id_table.array);
4241  out_free_name_table:
4242  	free(f-&gt;name_table.array);
4243  out_free_session:
4244  	fuse_session_destroy(f-&gt;se);
4245  out_free_fs:
4246  	free(f-&gt;fs);
4247  	free(f-&gt;conf.modules);
4248  out_delete_context_key:
4249  	fuse_delete_context_key();
4250  out_free:
4251  	free(f);
4252  out:
4253  	return NULL;
4254  }
4255  struct fuse *fuse_new_30(struct fuse_args *args, const struct fuse_operations *op,
4256  			 size_t op_size, void *private_data);
4257  FUSE_SYMVER(&quot;fuse_new_30&quot;, &quot;fuse_new@FUSE_3.0&quot;)
4258  struct fuse *fuse_new_30(struct fuse_args *args,
4259  			 const struct fuse_operations *op,
4260  			 size_t op_size, void *user_data)
4261  {
4262  	struct fuse_config conf;
4263  	memset(&amp;conf, 0, sizeof(conf));
4264  	const struct fuse_opt opts[] = {
4265  		FUSE_LIB_OPT(&quot;-h&quot;, show_help, 1),
4266  		FUSE_LIB_OPT(&quot;--help&quot;, show_help, 1),
4267  		FUSE_OPT_END
4268  	};
4269  	if (fuse_opt_parse(args, &amp;conf, opts,
4270  			   fuse_lib_opt_proc) == -1)
4271  		return NULL;
4272  	if (conf.show_help) {
4273  		fuse_lib_help(args);
4274  		return NULL;
4275  	} else
4276  		return fuse_new_31(args, op, op_size, user_data);
4277  }
4278  void fuse_destroy(struct fuse *f)
4279  {
4280  	size_t i;
4281  	if (f-&gt;conf.intr &amp;&amp; f-&gt;intr_installed)
4282  		fuse_restore_intr_signal(f-&gt;conf.intr_signal);
4283  	if (f-&gt;fs) {
4284  		fuse_create_context(f);
4285  		for (i = 0; i &lt; f-&gt;id_table.size; i++) {
4286  			struct node *node;
4287  			for (node = f-&gt;id_table.array[i]; node != NULL;
4288  			     node = node-&gt;id_next) {
4289  				if (node-&gt;is_hidden) {
4290  					char *path;
4291  					if (try_get_path(f, node-&gt;nodeid, NULL, &amp;path, NULL, false) == 0) {
4292  						fuse_fs_unlink(f-&gt;fs, path);
4293  						free(path);
4294  					}
4295  				}
4296  			}
4297  		}
4298  	}
4299  	for (i = 0; i &lt; f-&gt;id_table.size; i++) {
4300  		struct node *node;
4301  		struct node *next;
4302  		for (node = f-&gt;id_table.array[i]; node != NULL; node = next) {
4303  			next = node-&gt;id_next;
4304  			free_node(f, node);
4305  			f-&gt;id_table.use--;
4306  		}
4307  	}
4308  	assert(list_empty(&amp;f-&gt;partial_slabs));
4309  	assert(list_empty(&amp;f-&gt;full_slabs));
4310  	while (fuse_modules) {
4311  		fuse_put_module(fuse_modules);
4312  	}
4313  	free(f-&gt;id_table.array);
4314  	free(f-&gt;name_table.array);
4315  	pthread_mutex_destroy(&amp;f-&gt;lock);
4316  	fuse_session_destroy(f-&gt;se);
4317  	free(f-&gt;fs);
4318  	free(f-&gt;conf.modules);
4319  	free(f);
4320  	fuse_delete_context_key();
4321  }
4322  int fuse_mount(struct fuse *f, const char *mountpoint) {
4323  	return fuse_session_mount(fuse_get_session(f), mountpoint);
4324  }
4325  void fuse_unmount(struct fuse *f) {
4326  	fuse_session_unmount(fuse_get_session(f));
4327  }
4328  int fuse_version(void)
4329  {
4330  	return FUSE_VERSION;
4331  }
4332  const char *fuse_pkgversion(void)
4333  {
4334  	return PACKAGE_VERSION;
4335  }
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-background_thread_22.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from libfuse-MDEwOlJlcG9zaXRvcnk0ODI5NjE3Nw==-flat-fuse.c</div>
                </div>
                <div class="column column_space"><pre><code>652  			nstime_add(&amp;stats-&gt;run_interval, &amp;info-&gt;tot_sleep_time);
653  		}
654  		malloc_mutex_unlock(tsdn, &amp;info-&gt;mtx);
655  	}
656  	stats-&gt;num_runs = num_runs;
</pre></code></div>
                <div class="column column_space"><pre><code>412  			list_add_tail(&amp;slab-&gt;list, &amp;f-&gt;partial_slabs);
413  		}
414  		list_add_head(n, &amp;slab-&gt;freelist);
415  	} else {
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    