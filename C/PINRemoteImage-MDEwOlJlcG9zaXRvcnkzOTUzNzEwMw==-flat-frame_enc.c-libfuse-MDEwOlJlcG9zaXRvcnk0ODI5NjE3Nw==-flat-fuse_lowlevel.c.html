
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 2.607626076260763%, Tokens: 8, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-frame_enc.c</h3>
            <pre><code>1  #include <string.h>
2  #include <math.h>
3  #include "src/enc/cost_enc.h"
4  #include "src/enc/vp8i_enc.h"
5  #include "src/dsp/dsp.h"
6  #include "src/webp/format_constants.h"  
7  #define SEGMENT_VISU 0
8  #define DEBUG_SEARCH 0    
9  #define HEADER_SIZE_ESTIMATE (RIFF_HEADER_SIZE + CHUNK_HEADER_SIZE +  \
10                                VP8_FRAME_HEADER_SIZE)
11  #define DQ_LIMIT 0.4  
12  #define PARTITION0_SIZE_LIMIT ((VP8_MAX_PARTITION0_SIZE - 2048ULL) << 11)
13  typedef struct {  
14    int is_first;
15    float dq;
16    float q, last_q;
17    double value, last_value;   
18    double target;
19    int do_size_search;
20  } PassStats;
21  static int InitPassStats(const VP8Encoder* const enc, PassStats* const s) {
22    const uint64_t target_size = (uint64_t)enc->config_->target_size;
23    const int do_size_search = (target_size != 0);
24    const float target_PSNR = enc->config_->target_PSNR;
25    s->is_first = 1;
26    s->dq = 10.f;
27    s->q = s->last_q = enc->config_->quality;
28    s->target = do_size_search ? (double)target_size
29              : (target_PSNR > 0.) ? target_PSNR
30              : 40.;   
31    s->value = s->last_value = 0.;
32    s->do_size_search = do_size_search;
33    return do_size_search;
34  }
35  static float Clamp(float v, float min, float max) {
36    return (v < min) ? min : (v > max) ? max : v;
37  }
38  static float ComputeNextQ(PassStats* const s) {
39    float dq;
40    if (s->is_first) {
41      dq = (s->value > s->target) ? -s->dq : s->dq;
42      s->is_first = 0;
43    } else if (s->value != s->last_value) {
44      const double slope = (s->target - s->value) / (s->last_value - s->value);
45      dq = (float)(slope * (s->last_q - s->q));
46    } else {
47      dq = 0.;  
48    }
49    s->dq = Clamp(dq, -30.f, 30.f);
50    s->last_q = s->q;
51    s->last_value = s->value;
52    s->q = Clamp(s->q + s->dq, 0.f, 100.f);
53    return s->q;
54  }
55  const uint8_t VP8Cat3[] = { 173, 148, 140 };
56  const uint8_t VP8Cat4[] = { 176, 155, 140, 135 };
57  const uint8_t VP8Cat5[] = { 180, 157, 141, 134, 130 };
58  const uint8_t VP8Cat6[] =
59      { 254, 254, 243, 230, 196, 177, 153, 140, 133, 130, 129 };
60  static void ResetStats(VP8Encoder* const enc) {
61    VP8EncProba* const proba = &enc->proba_;
62    VP8CalculateLevelCosts(proba);
63    proba->nb_skip_ = 0;
64  }
65  #define SKIP_PROBA_THRESHOLD 250  
66  static int CalcSkipProba(uint64_t nb, uint64_t total) {
67    return (int)(total ? (total - nb) * 255 / total : 255);
68  }
69  static int FinalizeSkipProba(VP8Encoder* const enc) {
70    VP8EncProba* const proba = &enc->proba_;
71    const int nb_mbs = enc->mb_w_ * enc->mb_h_;
72    const int nb_events = proba->nb_skip_;
73    int size;
74    proba->skip_proba_ = CalcSkipProba(nb_events, nb_mbs);
75    proba->use_skip_proba_ = (proba->skip_proba_ < SKIP_PROBA_THRESHOLD);
76    size = 256;   
77    if (proba->use_skip_proba_) {
78      size +=  nb_events * VP8BitCost(1, proba->skip_proba_)
79           + (nb_mbs - nb_events) * VP8BitCost(0, proba->skip_proba_);
80      size += 8 * 256;   
81    }
82    return size;
83  }
84  static int CalcTokenProba(int nb, int total) {
85    assert(nb <= total);
86    return nb ? (255 - nb * 255 / total) : 255;
87  }
88  static int BranchCost(int nb, int total, int proba) {
89    return nb * VP8BitCost(1, proba) + (total - nb) * VP8BitCost(0, proba);
90  }
91  static void ResetTokenStats(VP8Encoder* const enc) {
92    VP8EncProba* const proba = &enc->proba_;
93    memset(proba->stats_, 0, sizeof(proba->stats_));
94  }
95  static int FinalizeTokenProbas(VP8EncProba* const proba) {
96    int has_changed = 0;
97    int size = 0;
98    int t, b, c, p;
99    for (t = 0; t < NUM_TYPES; ++t) {
100      for (b = 0; b < NUM_BANDS; ++b) {
101        for (c = 0; c < NUM_CTX; ++c) {
102          for (p = 0; p < NUM_PROBAS; ++p) {
103            const proba_t stats = proba->stats_[t][b][c][p];
104            const int nb = (stats >> 0) & 0xffff;
105            const int total = (stats >> 16) & 0xffff;
106            const int update_proba = VP8CoeffsUpdateProba[t][b][c][p];
107            const int old_p = VP8CoeffsProba0[t][b][c][p];
108            const int new_p = CalcTokenProba(nb, total);
109            const int old_cost = BranchCost(nb, total, old_p)
110                               + VP8BitCost(0, update_proba);
111            const int new_cost = BranchCost(nb, total, new_p)
112                               + VP8BitCost(1, update_proba)
113                               + 8 * 256;
114            const int use_new_p = (old_cost > new_cost);
115            size += VP8BitCost(use_new_p, update_proba);
116            if (use_new_p) {  
117              proba->coeffs_[t][b][c][p] = new_p;
118              has_changed |= (new_p != old_p);
119              size += 8 * 256;
120            } else {
121              proba->coeffs_[t][b][c][p] = old_p;
122            }
123          }
124        }
125      }
126    }
127    proba->dirty_ = has_changed;
128    return size;
129  }
130  static int GetProba(int a, int b) {
131    const int total = a + b;
132    return (total == 0) ? 255     
133                        : (255 * a + total / 2) / total;  
134  }
135  static void ResetSegments(VP8Encoder* const enc) {
136    int n;
137    for (n = 0; n < enc->mb_w_ * enc->mb_h_; ++n) {
138      enc->mb_info_[n].segment_ = 0;
139    }
140  }
141  static void SetSegmentProbas(VP8Encoder* const enc) {
142    int p[NUM_MB_SEGMENTS] = { 0 };
143    int n;
144    for (n = 0; n < enc->mb_w_ * enc->mb_h_; ++n) {
145      const VP8MBInfo* const mb = &enc->mb_info_[n];
146      ++p[mb->segment_];
147    }
148  #if !defined(WEBP_DISABLE_STATS)
149    if (enc->pic_->stats != NULL) {
150      for (n = 0; n < NUM_MB_SEGMENTS; ++n) {
151        enc->pic_->stats->segment_size[n] = p[n];
152      }
153    }
154  #endif
155    if (enc->segment_hdr_.num_segments_ > 1) {
156      uint8_t* const probas = enc->proba_.segments_;
157      probas[0] = GetProba(p[0] + p[1], p[2] + p[3]);
158      probas[1] = GetProba(p[0], p[1]);
159      probas[2] = GetProba(p[2], p[3]);
160      enc->segment_hdr_.update_map_ =
161          (probas[0] != 255) || (probas[1] != 255) || (probas[2] != 255);
162      if (!enc->segment_hdr_.update_map_) ResetSegments(enc);
163      enc->segment_hdr_.size_ =
164          p[0] * (VP8BitCost(0, probas[0]) + VP8BitCost(0, probas[1])) +
165          p[1] * (VP8BitCost(0, probas[0]) + VP8BitCost(1, probas[1])) +
166          p[2] * (VP8BitCost(1, probas[0]) + VP8BitCost(0, probas[2])) +
167          p[3] * (VP8BitCost(1, probas[0]) + VP8BitCost(1, probas[2]));
168    } else {
169      enc->segment_hdr_.update_map_ = 0;
170      enc->segment_hdr_.size_ = 0;
171    }
172  }
173  static int PutCoeffs(VP8BitWriter* const bw, int ctx, const VP8Residual* res) {
174    int n = res->first;
175    const uint8_t* p = res->prob[n][ctx];
176    if (!VP8PutBit(bw, res->last >= 0, p[0])) {
177      return 0;
178    }
179    while (n < 16) {
180      const int c = res->coeffs[n++];
181      const int sign = c < 0;
182      int v = sign ? -c : c;
183      if (!VP8PutBit(bw, v != 0, p[1])) {
184        p = res->prob[VP8EncBands[n]][0];
185        continue;
186      }
187      if (!VP8PutBit(bw, v > 1, p[2])) {
188        p = res->prob[VP8EncBands[n]][1];
189      } else {
190        if (!VP8PutBit(bw, v > 4, p[3])) {
191          if (VP8PutBit(bw, v != 2, p[4])) {
192            VP8PutBit(bw, v == 4, p[5]);
193          }
194        } else if (!VP8PutBit(bw, v > 10, p[6])) {
195          if (!VP8PutBit(bw, v > 6, p[7])) {
196            VP8PutBit(bw, v == 6, 159);
197          } else {
198            VP8PutBit(bw, v >= 9, 165);
199            VP8PutBit(bw, !(v & 1), 145);
200          }
201        } else {
202          int mask;
203          const uint8_t* tab;
204          if (v < 3 + (8 << 1)) {          
205            VP8PutBit(bw, 0, p[8]);
206            VP8PutBit(bw, 0, p[9]);
207            v -= 3 + (8 << 0);
208            mask = 1 << 2;
209            tab = VP8Cat3;
210          } else if (v < 3 + (8 << 2)) {   
211            VP8PutBit(bw, 0, p[8]);
212            VP8PutBit(bw, 1, p[9]);
213            v -= 3 + (8 << 1);
214            mask = 1 << 3;
215            tab = VP8Cat4;
216          } else if (v < 3 + (8 << 3)) {   
217            VP8PutBit(bw, 1, p[8]);
218            VP8PutBit(bw, 0, p[10]);
219            v -= 3 + (8 << 2);
220            mask = 1 << 4;
221            tab = VP8Cat5;
222          } else {                         
223            VP8PutBit(bw, 1, p[8]);
224            VP8PutBit(bw, 1, p[10]);
225            v -= 3 + (8 << 3);
226            mask = 1 << 10;
227            tab = VP8Cat6;
228          }
229          while (mask) {
230            VP8PutBit(bw, !!(v & mask), *tab++);
231            mask >>= 1;
232          }
233        }
234        p = res->prob[VP8EncBands[n]][2];
235      }
236      VP8PutBitUniform(bw, sign);
237      if (n == 16 || !VP8PutBit(bw, n <= res->last, p[0])) {
238        return 1;   
239      }
240    }
241    return 1;
242  }
243  static void CodeResiduals(VP8BitWriter* const bw, VP8EncIterator* const it,
244                            const VP8ModeScore* const rd) {
245    int x, y, ch;
246    VP8Residual res;
247    uint64_t pos1, pos2, pos3;
248    const int i16 = (it->mb_->type_ == 1);
249    const int segment = it->mb_->segment_;
250    VP8Encoder* const enc = it->enc_;
251    VP8IteratorNzToBytes(it);
252    pos1 = VP8BitWriterPos(bw);
253    if (i16) {
254      VP8InitResidual(0, 1, enc, &res);
255      VP8SetResidualCoeffs(rd->y_dc_levels, &res);
256      it->top_nz_[8] = it->left_nz_[8] =
257        PutCoeffs(bw, it->top_nz_[8] + it->left_nz_[8], &res);
258      VP8InitResidual(1, 0, enc, &res);
259    } else {
260      VP8InitResidual(0, 3, enc, &res);
261    }
262    for (y = 0; y < 4; ++y) {
263      for (x = 0; x < 4; ++x) {
264        const int ctx = it->top_nz_[x] + it->left_nz_[y];
265        VP8SetResidualCoeffs(rd->y_ac_levels[x + y * 4], &res);
266        it->top_nz_[x] = it->left_nz_[y] = PutCoeffs(bw, ctx, &res);
267      }
268    }
269    pos2 = VP8BitWriterPos(bw);
270    VP8InitResidual(0, 2, enc, &res);
271    for (ch = 0; ch <= 2; ch += 2) {
272      for (y = 0; y < 2; ++y) {
273        for (x = 0; x < 2; ++x) {
274          const int ctx = it->top_nz_[4 + ch + x] + it->left_nz_[4 + ch + y];
275          VP8SetResidualCoeffs(rd->uv_levels[ch * 2 + x + y * 2], &res);
276          it->top_nz_[4 + ch + x] = it->left_nz_[4 + ch + y] =
277              PutCoeffs(bw, ctx, &res);
278        }
279      }
280    }
<span onclick='openModal()' class='match'>281    pos3 = VP8BitWriterPos(bw);
282    it->luma_bits_ = pos2 - pos1;
283    it->uv_bits_ = pos3 - pos2;
284    it->bit_count_[segment][i16] += it->luma_bits_;
285    it->bit_count_[segment][2] += it->uv_bits_;
286    VP8IteratorBytesToNz(it);
287  }
288  static void RecordResiduals(VP8EncIterator* const it,
</span>289                              const VP8ModeScore* const rd) {
290    int x, y, ch;
291    VP8Residual res;
292    VP8Encoder* const enc = it->enc_;
293    VP8IteratorNzToBytes(it);
294    if (it->mb_->type_ == 1) {   
295      VP8InitResidual(0, 1, enc, &res);
296      VP8SetResidualCoeffs(rd->y_dc_levels, &res);
297      it->top_nz_[8] = it->left_nz_[8] =
298        VP8RecordCoeffs(it->top_nz_[8] + it->left_nz_[8], &res);
299      VP8InitResidual(1, 0, enc, &res);
300    } else {
301      VP8InitResidual(0, 3, enc, &res);
302    }
303    for (y = 0; y < 4; ++y) {
304      for (x = 0; x < 4; ++x) {
305        const int ctx = it->top_nz_[x] + it->left_nz_[y];
306        VP8SetResidualCoeffs(rd->y_ac_levels[x + y * 4], &res);
307        it->top_nz_[x] = it->left_nz_[y] = VP8RecordCoeffs(ctx, &res);
308      }
309    }
310    VP8InitResidual(0, 2, enc, &res);
311    for (ch = 0; ch <= 2; ch += 2) {
312      for (y = 0; y < 2; ++y) {
313        for (x = 0; x < 2; ++x) {
314          const int ctx = it->top_nz_[4 + ch + x] + it->left_nz_[4 + ch + y];
315          VP8SetResidualCoeffs(rd->uv_levels[ch * 2 + x + y * 2], &res);
316          it->top_nz_[4 + ch + x] = it->left_nz_[4 + ch + y] =
317              VP8RecordCoeffs(ctx, &res);
318        }
319      }
320    }
321    VP8IteratorBytesToNz(it);
322  }
323  #if !defined(DISABLE_TOKEN_BUFFER)
324  static int RecordTokens(VP8EncIterator* const it, const VP8ModeScore* const rd,
325                          VP8TBuffer* const tokens) {
326    int x, y, ch;
327    VP8Residual res;
328    VP8Encoder* const enc = it->enc_;
329    VP8IteratorNzToBytes(it);
330    if (it->mb_->type_ == 1) {   
331      const int ctx = it->top_nz_[8] + it->left_nz_[8];
332      VP8InitResidual(0, 1, enc, &res);
333      VP8SetResidualCoeffs(rd->y_dc_levels, &res);
334      it->top_nz_[8] = it->left_nz_[8] =
335          VP8RecordCoeffTokens(ctx, &res, tokens);
336      VP8InitResidual(1, 0, enc, &res);
337    } else {
338      VP8InitResidual(0, 3, enc, &res);
339    }
340    for (y = 0; y < 4; ++y) {
341      for (x = 0; x < 4; ++x) {
342        const int ctx = it->top_nz_[x] + it->left_nz_[y];
343        VP8SetResidualCoeffs(rd->y_ac_levels[x + y * 4], &res);
344        it->top_nz_[x] = it->left_nz_[y] =
345            VP8RecordCoeffTokens(ctx, &res, tokens);
346      }
347    }
348    VP8InitResidual(0, 2, enc, &res);
349    for (ch = 0; ch <= 2; ch += 2) {
350      for (y = 0; y < 2; ++y) {
351        for (x = 0; x < 2; ++x) {
352          const int ctx = it->top_nz_[4 + ch + x] + it->left_nz_[4 + ch + y];
353          VP8SetResidualCoeffs(rd->uv_levels[ch * 2 + x + y * 2], &res);
354          it->top_nz_[4 + ch + x] = it->left_nz_[4 + ch + y] =
355              VP8RecordCoeffTokens(ctx, &res, tokens);
356        }
357      }
358    }
359    VP8IteratorBytesToNz(it);
360    return !tokens->error_;
361  }
362  #endif    
363  #if !defined(WEBP_DISABLE_STATS)
364  #if SEGMENT_VISU
365  static void SetBlock(uint8_t* p, int value, int size) {
366    int y;
367    for (y = 0; y < size; ++y) {
368      memset(p, value, size);
369      p += BPS;
370    }
371  }
372  #endif
373  static void ResetSSE(VP8Encoder* const enc) {
374    enc->sse_[0] = 0;
375    enc->sse_[1] = 0;
376    enc->sse_[2] = 0;
377    enc->sse_count_ = 0;
378  }
379  static void StoreSSE(const VP8EncIterator* const it) {
380    VP8Encoder* const enc = it->enc_;
381    const uint8_t* const in = it->yuv_in_;
382    const uint8_t* const out = it->yuv_out_;
383    enc->sse_[0] += VP8SSE16x16(in + Y_OFF_ENC, out + Y_OFF_ENC);
384    enc->sse_[1] += VP8SSE8x8(in + U_OFF_ENC, out + U_OFF_ENC);
385    enc->sse_[2] += VP8SSE8x8(in + V_OFF_ENC, out + V_OFF_ENC);
386    enc->sse_count_ += 16 * 16;
387  }
388  static void StoreSideInfo(const VP8EncIterator* const it) {
389    VP8Encoder* const enc = it->enc_;
390    const VP8MBInfo* const mb = it->mb_;
391    WebPPicture* const pic = enc->pic_;
392    if (pic->stats != NULL) {
393      StoreSSE(it);
394      enc->block_count_[0] += (mb->type_ == 0);
395      enc->block_count_[1] += (mb->type_ == 1);
396      enc->block_count_[2] += (mb->skip_ != 0);
397    }
398    if (pic->extra_info != NULL) {
399      uint8_t* const info = &pic->extra_info[it->x_ + it->y_ * enc->mb_w_];
400      switch (pic->extra_info_type) {
401        case 1: *info = mb->type_; break;
402        case 2: *info = mb->segment_; break;
403        case 3: *info = enc->dqm_[mb->segment_].quant_; break;
404        case 4: *info = (mb->type_ == 1) ? it->preds_[0] : 0xff; break;
405        case 5: *info = mb->uv_mode_; break;
406        case 6: {
407          const int b = (int)((it->luma_bits_ + it->uv_bits_ + 7) >> 3);
408          *info = (b > 255) ? 255 : b; break;
409        }
410        case 7: *info = mb->alpha_; break;
411        default: *info = 0; break;
412      }
413    }
414  #if SEGMENT_VISU  
415    SetBlock(it->yuv_out_ + Y_OFF_ENC, mb->segment_ * 64, 16);
416    SetBlock(it->yuv_out_ + U_OFF_ENC, it->preds_[0] * 64, 8);
417    SetBlock(it->yuv_out_ + V_OFF_ENC, mb->uv_mode_ * 64, 8);
418  #endif
419  }
420  static void ResetSideInfo(const VP8EncIterator* const it) {
421    VP8Encoder* const enc = it->enc_;
422    WebPPicture* const pic = enc->pic_;
423    if (pic->stats != NULL) {
424      memset(enc->block_count_, 0, sizeof(enc->block_count_));
425    }
426    ResetSSE(enc);
427  }
428  #else  
429  static void ResetSSE(VP8Encoder* const enc) {
430    (void)enc;
431  }
432  static void StoreSideInfo(const VP8EncIterator* const it) {
433    VP8Encoder* const enc = it->enc_;
434    WebPPicture* const pic = enc->pic_;
435    if (pic->extra_info != NULL) {
436      if (it->x_ == 0 && it->y_ == 0) {   
437        memset(pic->extra_info, 0,
438               enc->mb_w_ * enc->mb_h_ * sizeof(*pic->extra_info));
439      }
440    }
441  }
442  static void ResetSideInfo(const VP8EncIterator* const it) {
443    (void)it;
444  }
445  #endif  
446  static double GetPSNR(uint64_t mse, uint64_t size) {
447    return (mse > 0 && size > 0) ? 10. * log10(255. * 255. * size / mse) : 99;
448  }
449  static void SetLoopParams(VP8Encoder* const enc, float q) {
450    q = Clamp(q, 0.f, 100.f);
451    VP8SetSegmentParams(enc, q);      
452    SetSegmentProbas(enc);            
453    ResetStats(enc);
454    ResetSSE(enc);
455  }
456  static uint64_t OneStatPass(VP8Encoder* const enc, VP8RDLevel rd_opt,
457                              int nb_mbs, int percent_delta,
458                              PassStats* const s) {
459    VP8EncIterator it;
460    uint64_t size = 0;
461    uint64_t size_p0 = 0;
462    uint64_t distortion = 0;
463    const uint64_t pixel_count = nb_mbs * 384;
464    VP8IteratorInit(enc, &it);
465    SetLoopParams(enc, s->q);
466    do {
467      VP8ModeScore info;
468      VP8IteratorImport(&it, NULL);
469      if (VP8Decimate(&it, &info, rd_opt)) {
470        ++enc->proba_.nb_skip_;
471      }
472      RecordResiduals(&it, &info);
473      size += info.R + info.H;
474      size_p0 += info.H;
475      distortion += info.D;
476      if (percent_delta && !VP8IteratorProgress(&it, percent_delta)) {
477        return 0;
478      }
479      VP8IteratorSaveBoundary(&it);
480    } while (VP8IteratorNext(&it) && --nb_mbs > 0);
481    size_p0 += enc->segment_hdr_.size_;
482    if (s->do_size_search) {
483      size += FinalizeSkipProba(enc);
484      size += FinalizeTokenProbas(&enc->proba_);
485      size = ((size + size_p0 + 1024) >> 11) + HEADER_SIZE_ESTIMATE;
486      s->value = (double)size;
487    } else {
488      s->value = GetPSNR(distortion, pixel_count);
489    }
490    return size_p0;
491  }
492  static int StatLoop(VP8Encoder* const enc) {
493    const int method = enc->method_;
494    const int do_search = enc->do_search_;
495    const int fast_probe = ((method == 0 || method == 3) && !do_search);
496    int num_pass_left = enc->config_->pass;
497    const int task_percent = 20;
498    const int percent_per_pass =
499        (task_percent + num_pass_left / 2) / num_pass_left;
500    const int final_percent = enc->percent_ + task_percent;
501    const VP8RDLevel rd_opt =
502        (method >= 3 || do_search) ? RD_OPT_BASIC : RD_OPT_NONE;
503    int nb_mbs = enc->mb_w_ * enc->mb_h_;
504    PassStats stats;
505    InitPassStats(enc, &stats);
506    ResetTokenStats(enc);
507    if (fast_probe) {
508      if (method == 3) {  
509        nb_mbs = (nb_mbs > 200) ? nb_mbs >> 1 : 100;
510      } else {
511        nb_mbs = (nb_mbs > 200) ? nb_mbs >> 2 : 50;
512      }
513    }
514    while (num_pass_left-- > 0) {
515      const int is_last_pass = (fabs(stats.dq) <= DQ_LIMIT) ||
516                               (num_pass_left == 0) ||
517                               (enc->max_i4_header_bits_ == 0);
518      const uint64_t size_p0 =
519          OneStatPass(enc, rd_opt, nb_mbs, percent_per_pass, &stats);
520      if (size_p0 == 0) return 0;
521  #if (DEBUG_SEARCH > 0)
522      printf("#%d value:%.1lf -> %.1lf   q:%.2f -> %.2f\n",
523             num_pass_left, stats.last_value, stats.value, stats.last_q, stats.q);
524  #endif
525      if (enc->max_i4_header_bits_ > 0 && size_p0 > PARTITION0_SIZE_LIMIT) {
526        ++num_pass_left;
527        enc->max_i4_header_bits_ >>= 1;  
528        continue;                        
529      }
530      if (is_last_pass) {
531        break;
532      }
533      if (do_search) {
534        ComputeNextQ(&stats);
535        if (fabs(stats.dq) <= DQ_LIMIT) break;
536      }
537    }
538    if (!do_search || !stats.do_size_search) {
539      FinalizeSkipProba(enc);
540      FinalizeTokenProbas(&enc->proba_);
541    }
542    VP8CalculateLevelCosts(&enc->proba_);  
543    return WebPReportProgress(enc->pic_, final_percent, &enc->percent_);
544  }
545  static const uint8_t kAverageBytesPerMB[8] = { 50, 24, 16, 9, 7, 5, 3, 2 };
546  static int PreLoopInitialize(VP8Encoder* const enc) {
547    int p;
548    int ok = 1;
549    const int average_bytes_per_MB = kAverageBytesPerMB[enc->base_quant_ >> 4];
550    const int bytes_per_parts =
551        enc->mb_w_ * enc->mb_h_ * average_bytes_per_MB / enc->num_parts_;
552    for (p = 0; ok && p < enc->num_parts_; ++p) {
553      ok = VP8BitWriterInit(enc->parts_ + p, bytes_per_parts);
554    }
555    if (!ok) {
556      VP8EncFreeBitWriters(enc);  
557      WebPEncodingSetError(enc->pic_, VP8_ENC_ERROR_OUT_OF_MEMORY);
558    }
559    return ok;
560  }
561  static int PostLoopFinalize(VP8EncIterator* const it, int ok) {
562    VP8Encoder* const enc = it->enc_;
563    if (ok) {      
564      int p;
565      for (p = 0; p < enc->num_parts_; ++p) {
566        VP8BitWriterFinish(enc->parts_ + p);
567        ok &= !enc->parts_[p].error_;
568      }
569    }
570    if (ok) {      
571  #if !defined(WEBP_DISABLE_STATS)
572      if (enc->pic_->stats != NULL) {  
573        int i, s;
574        for (i = 0; i <= 2; ++i) {
575          for (s = 0; s < NUM_MB_SEGMENTS; ++s) {
576            enc->residual_bytes_[i][s] = (int)((it->bit_count_[s][i] + 7) >> 3);
577          }
578        }
579      }
580  #endif
581      VP8AdjustFilterStrength(it);     
582    } else {
583      VP8EncFreeBitWriters(enc);
584    }
585    return ok;
586  }
587  static void ResetAfterSkip(VP8EncIterator* const it) {
588    if (it->mb_->type_ == 1) {
589      *it->nz_ = 0;  
590      it->left_nz_[8] = 0;
591    } else {
592      *it->nz_ &= (1 << 24);  
593    }
594  }
595  int VP8EncLoop(VP8Encoder* const enc) {
596    VP8EncIterator it;
597    int ok = PreLoopInitialize(enc);
598    if (!ok) return 0;
599    StatLoop(enc);  
600    VP8IteratorInit(enc, &it);
601    VP8InitFilter(&it);
602    do {
603      VP8ModeScore info;
604      const int dont_use_skip = !enc->proba_.use_skip_proba_;
605      const VP8RDLevel rd_opt = enc->rd_opt_level_;
606      VP8IteratorImport(&it, NULL);
607      if (!VP8Decimate(&it, &info, rd_opt) || dont_use_skip) {
608        CodeResiduals(it.bw_, &it, &info);
609      } else {   
610        ResetAfterSkip(&it);
611      }
612      StoreSideInfo(&it);
613      VP8StoreFilterStats(&it);
614      VP8IteratorExport(&it);
615      ok = VP8IteratorProgress(&it, 20);
616      VP8IteratorSaveBoundary(&it);
617    } while (ok && VP8IteratorNext(&it));
618    return PostLoopFinalize(&it, ok);
619  }
620  #if !defined(DISABLE_TOKEN_BUFFER)
621  #define MIN_COUNT 96  
622  int VP8EncTokenLoop(VP8Encoder* const enc) {
623    int max_count = (enc->mb_w_ * enc->mb_h_) >> 3;
624    int num_pass_left = enc->config_->pass;
625    const int do_search = enc->do_search_;
626    VP8EncIterator it;
627    VP8EncProba* const proba = &enc->proba_;
628    const VP8RDLevel rd_opt = enc->rd_opt_level_;
629    const uint64_t pixel_count = enc->mb_w_ * enc->mb_h_ * 384;
630    PassStats stats;
631    int ok;
632    InitPassStats(enc, &stats);
633    ok = PreLoopInitialize(enc);
634    if (!ok) return 0;
635    if (max_count < MIN_COUNT) max_count = MIN_COUNT;
636    assert(enc->num_parts_ == 1);
637    assert(enc->use_tokens_);
638    assert(proba->use_skip_proba_ == 0);
639    assert(rd_opt >= RD_OPT_BASIC);   
640    assert(num_pass_left > 0);
641    while (ok && num_pass_left-- > 0) {
642      const int is_last_pass = (fabs(stats.dq) <= DQ_LIMIT) ||
643                               (num_pass_left == 0) ||
644                               (enc->max_i4_header_bits_ == 0);
645      uint64_t size_p0 = 0;
646      uint64_t distortion = 0;
647      int cnt = max_count;
648      VP8IteratorInit(enc, &it);
649      SetLoopParams(enc, stats.q);
650      if (is_last_pass) {
651        ResetTokenStats(enc);
652        VP8InitFilter(&it);  
653      }
654      VP8TBufferClear(&enc->tokens_);
655      do {
656        VP8ModeScore info;
657        VP8IteratorImport(&it, NULL);
658        if (--cnt < 0) {
659          FinalizeTokenProbas(proba);
660          VP8CalculateLevelCosts(proba);  
661          cnt = max_count;
662        }
663        VP8Decimate(&it, &info, rd_opt);
664        ok = RecordTokens(&it, &info, &enc->tokens_);
665        if (!ok) {
666          WebPEncodingSetError(enc->pic_, VP8_ENC_ERROR_OUT_OF_MEMORY);
667          break;
668        }
669        size_p0 += info.H;
670        distortion += info.D;
671        if (is_last_pass) {
672          StoreSideInfo(&it);
673          VP8StoreFilterStats(&it);
674          VP8IteratorExport(&it);
675          ok = VP8IteratorProgress(&it, 20);
676        }
677        VP8IteratorSaveBoundary(&it);
678      } while (ok && VP8IteratorNext(&it));
679      if (!ok) break;
680      size_p0 += enc->segment_hdr_.size_;
681      if (stats.do_size_search) {
682        uint64_t size = FinalizeTokenProbas(&enc->proba_);
683        size += VP8EstimateTokenSize(&enc->tokens_,
684                                     (const uint8_t*)proba->coeffs_);
685        size = (size + size_p0 + 1024) >> 11;  
686        size += HEADER_SIZE_ESTIMATE;
687        stats.value = (double)size;
688      } else {  
689        stats.value = GetPSNR(distortion, pixel_count);
690      }
691  #if (DEBUG_SEARCH > 0)
692      printf("#%2d metric:%.1lf -> %.1lf   last_q=%.2lf q=%.2lf dq=%.2lf\n",
693             num_pass_left, stats.last_value, stats.value,
694             stats.last_q, stats.q, stats.dq);
695  #endif
696      if (enc->max_i4_header_bits_ > 0 && size_p0 > PARTITION0_SIZE_LIMIT) {
697        ++num_pass_left;
698        enc->max_i4_header_bits_ >>= 1;  
699        if (is_last_pass) {
700          ResetSideInfo(&it);
701        }
702        continue;                        
703      }
704      if (is_last_pass) {
705        break;   
706      }
707      if (do_search) {
708        ComputeNextQ(&stats);  
709      }
710    }
711    if (ok) {
712      if (!stats.do_size_search) {
713        FinalizeTokenProbas(&enc->proba_);
714      }
715      ok = VP8EmitTokens(&enc->tokens_, enc->parts_ + 0,
716                         (const uint8_t*)proba->coeffs_, 1);
717    }
718    ok = ok && WebPReportProgress(enc->pic_, enc->percent_ + 20, &enc->percent_);
719    return PostLoopFinalize(&it, ok);
720  }
721  #else
722  int VP8EncTokenLoop(VP8Encoder* const enc) {
723    (void)enc;
724    return 0;   
725  }
726  #endif    
</code></pre>
        </div>
        <div class="column">
            <h3>libfuse-MDEwOlJlcG9zaXRvcnk0ODI5NjE3Nw==-flat-fuse_lowlevel.c</h3>
            <pre><code>1  #define _GNU_SOURCE
2  #include "fuse_config.h"
3  #include "fuse_i.h"
4  #include "fuse_kernel.h"
5  #include "fuse_opt.h"
6  #include "fuse_misc.h"
7  #include "mount_util.h"
8  #include <stdio.h>
9  #include <stdlib.h>
10  #include <stddef.h>
11  #include <string.h>
12  #include <unistd.h>
13  #include <limits.h>
14  #include <errno.h>
15  #include <assert.h>
16  #include <sys/file.h>
17  #ifndef F_LINUX_SPECIFIC_BASE
18  #define F_LINUX_SPECIFIC_BASE       1024
19  #endif
20  #ifndef F_SETPIPE_SZ
21  #define F_SETPIPE_SZ	(F_LINUX_SPECIFIC_BASE + 7)
22  #endif
23  #define PARAM(inarg) (((char *)(inarg)) + sizeof(*(inarg)))
24  #define OFFSET_MAX 0x7fffffffffffffffLL
25  #define container_of(ptr, type, member) ({				\
26  			const typeof( ((type *)0)->member ) *__mptr = (ptr); \
27  			(type *)( (char *)__mptr - offsetof(type,member) );})
28  struct fuse_pollhandle {
29  	uint64_t kh;
30  	struct fuse_session *se;
31  };
32  static size_t pagesize;
33  static __attribute__((constructor)) void fuse_ll_init_pagesize(void)
34  {
35  	pagesize = getpagesize();
36  }
37  static void convert_stat(const struct stat *stbuf, struct fuse_attr *attr)
38  {
39  	attr->ino	= stbuf->st_ino;
40  	attr->mode	= stbuf->st_mode;
41  	attr->nlink	= stbuf->st_nlink;
42  	attr->uid	= stbuf->st_uid;
43  	attr->gid	= stbuf->st_gid;
44  	attr->rdev	= stbuf->st_rdev;
45  	attr->size	= stbuf->st_size;
46  	attr->blksize	= stbuf->st_blksize;
47  	attr->blocks	= stbuf->st_blocks;
48  	attr->atime	= stbuf->st_atime;
<span onclick='openModal()' class='match'>49  	attr->mtime	= stbuf->st_mtime;
50  	attr->ctime	= stbuf->st_ctime;
51  	attr->atimensec = ST_ATIM_NSEC(stbuf);
52  	attr->mtimensec = ST_MTIM_NSEC(stbuf);
53  	attr->ctimensec = ST_CTIM_NSEC(stbuf);
54  }
55  static void convert_attr(const struct fuse_setattr_in *attr, struct stat *stbuf)
</span>56  {
57  	stbuf->st_mode	       = attr->mode;
58  	stbuf->st_uid	       = attr->uid;
59  	stbuf->st_gid	       = attr->gid;
60  	stbuf->st_size	       = attr->size;
61  	stbuf->st_atime	       = attr->atime;
62  	stbuf->st_mtime	       = attr->mtime;
63  	stbuf->st_ctime        = attr->ctime;
64  	ST_ATIM_NSEC_SET(stbuf, attr->atimensec);
65  	ST_MTIM_NSEC_SET(stbuf, attr->mtimensec);
66  	ST_CTIM_NSEC_SET(stbuf, attr->ctimensec);
67  }
68  static	size_t iov_length(const struct iovec *iov, size_t count)
69  {
70  	size_t seg;
71  	size_t ret = 0;
72  	for (seg = 0; seg < count; seg++)
73  		ret += iov[seg].iov_len;
74  	return ret;
75  }
76  static void list_init_req(struct fuse_req *req)
77  {
78  	req->next = req;
79  	req->prev = req;
80  }
81  static void list_del_req(struct fuse_req *req)
82  {
83  	struct fuse_req *prev = req->prev;
84  	struct fuse_req *next = req->next;
85  	prev->next = next;
86  	next->prev = prev;
87  }
88  static void list_add_req(struct fuse_req *req, struct fuse_req *next)
89  {
90  	struct fuse_req *prev = next->prev;
91  	req->next = next;
92  	req->prev = prev;
93  	prev->next = req;
94  	next->prev = req;
95  }
96  static void destroy_req(fuse_req_t req)
97  {
98  	assert(req->ch == NULL);
99  	pthread_mutex_destroy(&req->lock);
100  	free(req);
101  }
102  void fuse_free_req(fuse_req_t req)
103  {
104  	int ctr;
105  	struct fuse_session *se = req->se;
106  	pthread_mutex_lock(&se->lock);
107  	req->u.ni.func = NULL;
108  	req->u.ni.data = NULL;
109  	list_del_req(req);
110  	ctr = --req->ctr;
111  	fuse_chan_put(req->ch);
112  	req->ch = NULL;
113  	pthread_mutex_unlock(&se->lock);
114  	if (!ctr)
115  		destroy_req(req);
116  }
117  static struct fuse_req *fuse_ll_alloc_req(struct fuse_session *se)
118  {
119  	struct fuse_req *req;
120  	req = (struct fuse_req *) calloc(1, sizeof(struct fuse_req));
121  	if (req == NULL) {
122  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate request\n");
123  	} else {
124  		req->se = se;
125  		req->ctr = 1;
126  		list_init_req(req);
127  		pthread_mutex_init(&req->lock, NULL);
128  	}
129  	return req;
130  }
131  static int fuse_send_msg(struct fuse_session *se, struct fuse_chan *ch,
132  			 struct iovec *iov, int count)
133  {
134  	struct fuse_out_header *out = iov[0].iov_base;
135  	assert(se != NULL);
136  	out->len = iov_length(iov, count);
137  	if (se->debug) {
138  		if (out->unique == 0) {
139  			fuse_log(FUSE_LOG_DEBUG, "NOTIFY: code=%d length=%u\n",
140  				out->error, out->len);
141  		} else if (out->error) {
142  			fuse_log(FUSE_LOG_DEBUG,
143  				"   unique: %llu, error: %i (%s), outsize: %i\n",
144  				(unsigned long long) out->unique, out->error,
145  				strerror(-out->error), out->len);
146  		} else {
147  			fuse_log(FUSE_LOG_DEBUG,
148  				"   unique: %llu, success, outsize: %i\n",
149  				(unsigned long long) out->unique, out->len);
150  		}
151  	}
152  	ssize_t res;
153  	if (se->io != NULL)
154  		res = se->io->writev(ch ? ch->fd : se->fd, iov, count,
155  					   se->userdata);
156  	else
157  		res = writev(ch ? ch->fd : se->fd, iov, count);
158  	int err = errno;
159  	if (res == -1) {
160  		if (!fuse_session_exited(se) && err != ENOENT)
161  			perror("fuse: writing device");
162  		return -err;
163  	}
164  	return 0;
165  }
166  int fuse_send_reply_iov_nofree(fuse_req_t req, int error, struct iovec *iov,
167  			       int count)
168  {
169  	struct fuse_out_header out;
170  	if (error <= -1000 || error > 0) {
171  		fuse_log(FUSE_LOG_ERR, "fuse: bad error value: %i\n",	error);
172  		error = -ERANGE;
173  	}
174  	out.unique = req->unique;
175  	out.error = error;
176  	iov[0].iov_base = &out;
177  	iov[0].iov_len = sizeof(struct fuse_out_header);
178  	return fuse_send_msg(req->se, req->ch, iov, count);
179  }
180  static int send_reply_iov(fuse_req_t req, int error, struct iovec *iov,
181  			  int count)
182  {
183  	int res;
184  	res = fuse_send_reply_iov_nofree(req, error, iov, count);
185  	fuse_free_req(req);
186  	return res;
187  }
188  static int send_reply(fuse_req_t req, int error, const void *arg,
189  		      size_t argsize)
190  {
191  	struct iovec iov[2];
192  	int count = 1;
193  	if (argsize) {
194  		iov[1].iov_base = (void *) arg;
195  		iov[1].iov_len = argsize;
196  		count++;
197  	}
198  	return send_reply_iov(req, error, iov, count);
199  }
200  int fuse_reply_iov(fuse_req_t req, const struct iovec *iov, int count)
201  {
202  	int res;
203  	struct iovec *padded_iov;
204  	padded_iov = malloc((count + 1) * sizeof(struct iovec));
205  	if (padded_iov == NULL)
206  		return fuse_reply_err(req, ENOMEM);
207  	memcpy(padded_iov + 1, iov, count * sizeof(struct iovec));
208  	count++;
209  	res = send_reply_iov(req, 0, padded_iov, count);
210  	free(padded_iov);
211  	return res;
212  }
213  size_t fuse_add_direntry(fuse_req_t req, char *buf, size_t bufsize,
214  			 const char *name, const struct stat *stbuf, off_t off)
215  {
216  	(void)req;
217  	size_t namelen;
218  	size_t entlen;
219  	size_t entlen_padded;
220  	struct fuse_dirent *dirent;
221  	namelen = strlen(name);
222  	entlen = FUSE_NAME_OFFSET + namelen;
223  	entlen_padded = FUSE_DIRENT_ALIGN(entlen);
224  	if ((buf == NULL) || (entlen_padded > bufsize))
225  	  return entlen_padded;
226  	dirent = (struct fuse_dirent*) buf;
227  	dirent->ino = stbuf->st_ino;
228  	dirent->off = off;
229  	dirent->namelen = namelen;
230  	dirent->type = (stbuf->st_mode & S_IFMT) >> 12;
231  	memcpy(dirent->name, name, namelen);
232  	memset(dirent->name + namelen, 0, entlen_padded - entlen);
233  	return entlen_padded;
234  }
235  static void convert_statfs(const struct statvfs *stbuf,
236  			   struct fuse_kstatfs *kstatfs)
237  {
238  	kstatfs->bsize	 = stbuf->f_bsize;
239  	kstatfs->frsize	 = stbuf->f_frsize;
240  	kstatfs->blocks	 = stbuf->f_blocks;
241  	kstatfs->bfree	 = stbuf->f_bfree;
242  	kstatfs->bavail	 = stbuf->f_bavail;
243  	kstatfs->files	 = stbuf->f_files;
244  	kstatfs->ffree	 = stbuf->f_ffree;
245  	kstatfs->namelen = stbuf->f_namemax;
246  }
247  static int send_reply_ok(fuse_req_t req, const void *arg, size_t argsize)
248  {
249  	return send_reply(req, 0, arg, argsize);
250  }
251  int fuse_reply_err(fuse_req_t req, int err)
252  {
253  	return send_reply(req, -err, NULL, 0);
254  }
255  void fuse_reply_none(fuse_req_t req)
256  {
257  	fuse_free_req(req);
258  }
259  static unsigned long calc_timeout_sec(double t)
260  {
261  	if (t > (double) ULONG_MAX)
262  		return ULONG_MAX;
263  	else if (t < 0.0)
264  		return 0;
265  	else
266  		return (unsigned long) t;
267  }
268  static unsigned int calc_timeout_nsec(double t)
269  {
270  	double f = t - (double) calc_timeout_sec(t);
271  	if (f < 0.0)
272  		return 0;
273  	else if (f >= 0.999999999)
274  		return 999999999;
275  	else
276  		return (unsigned int) (f * 1.0e9);
277  }
278  static void fill_entry(struct fuse_entry_out *arg,
279  		       const struct fuse_entry_param *e)
280  {
281  	arg->nodeid = e->ino;
282  	arg->generation = e->generation;
283  	arg->entry_valid = calc_timeout_sec(e->entry_timeout);
284  	arg->entry_valid_nsec = calc_timeout_nsec(e->entry_timeout);
285  	arg->attr_valid = calc_timeout_sec(e->attr_timeout);
286  	arg->attr_valid_nsec = calc_timeout_nsec(e->attr_timeout);
287  	convert_stat(&e->attr, &arg->attr);
288  }
289  size_t fuse_add_direntry_plus(fuse_req_t req, char *buf, size_t bufsize,
290  			      const char *name,
291  			      const struct fuse_entry_param *e, off_t off)
292  {
293  	(void)req;
294  	size_t namelen;
295  	size_t entlen;
296  	size_t entlen_padded;
297  	namelen = strlen(name);
298  	entlen = FUSE_NAME_OFFSET_DIRENTPLUS + namelen;
299  	entlen_padded = FUSE_DIRENT_ALIGN(entlen);
300  	if ((buf == NULL) || (entlen_padded > bufsize))
301  	  return entlen_padded;
302  	struct fuse_direntplus *dp = (struct fuse_direntplus *) buf;
303  	memset(&dp->entry_out, 0, sizeof(dp->entry_out));
304  	fill_entry(&dp->entry_out, e);
305  	struct fuse_dirent *dirent = &dp->dirent;
306  	dirent->ino = e->attr.st_ino;
307  	dirent->off = off;
308  	dirent->namelen = namelen;
309  	dirent->type = (e->attr.st_mode & S_IFMT) >> 12;
310  	memcpy(dirent->name, name, namelen);
311  	memset(dirent->name + namelen, 0, entlen_padded - entlen);
312  	return entlen_padded;
313  }
314  static void fill_open(struct fuse_open_out *arg,
315  		      const struct fuse_file_info *f)
316  {
317  	arg->fh = f->fh;
318  	if (f->direct_io)
319  		arg->open_flags |= FOPEN_DIRECT_IO;
320  	if (f->keep_cache)
321  		arg->open_flags |= FOPEN_KEEP_CACHE;
322  	if (f->cache_readdir)
323  		arg->open_flags |= FOPEN_CACHE_DIR;
324  	if (f->nonseekable)
325  		arg->open_flags |= FOPEN_NONSEEKABLE;
326  	if (f->noflush)
327  		arg->open_flags |= FOPEN_NOFLUSH;
328  	if (f->parallel_direct_writes)
329  		arg->open_flags |= FOPEN_PARALLEL_DIRECT_WRITES;
330  }
331  int fuse_reply_entry(fuse_req_t req, const struct fuse_entry_param *e)
332  {
333  	struct fuse_entry_out arg;
334  	size_t size = req->se->conn.proto_minor < 9 ?
335  		FUSE_COMPAT_ENTRY_OUT_SIZE : sizeof(arg);
336  	if (!e->ino && req->se->conn.proto_minor < 4)
337  		return fuse_reply_err(req, ENOENT);
338  	memset(&arg, 0, sizeof(arg));
339  	fill_entry(&arg, e);
340  	return send_reply_ok(req, &arg, size);
341  }
342  int fuse_reply_create(fuse_req_t req, const struct fuse_entry_param *e,
343  		      const struct fuse_file_info *f)
344  {
345  	char buf[sizeof(struct fuse_entry_out) + sizeof(struct fuse_open_out)];
346  	size_t entrysize = req->se->conn.proto_minor < 9 ?
347  		FUSE_COMPAT_ENTRY_OUT_SIZE : sizeof(struct fuse_entry_out);
348  	struct fuse_entry_out *earg = (struct fuse_entry_out *) buf;
349  	struct fuse_open_out *oarg = (struct fuse_open_out *) (buf + entrysize);
350  	memset(buf, 0, sizeof(buf));
351  	fill_entry(earg, e);
352  	fill_open(oarg, f);
353  	return send_reply_ok(req, buf,
354  			     entrysize + sizeof(struct fuse_open_out));
355  }
356  int fuse_reply_attr(fuse_req_t req, const struct stat *attr,
357  		    double attr_timeout)
358  {
359  	struct fuse_attr_out arg;
360  	size_t size = req->se->conn.proto_minor < 9 ?
361  		FUSE_COMPAT_ATTR_OUT_SIZE : sizeof(arg);
362  	memset(&arg, 0, sizeof(arg));
363  	arg.attr_valid = calc_timeout_sec(attr_timeout);
364  	arg.attr_valid_nsec = calc_timeout_nsec(attr_timeout);
365  	convert_stat(attr, &arg.attr);
366  	return send_reply_ok(req, &arg, size);
367  }
368  int fuse_reply_readlink(fuse_req_t req, const char *linkname)
369  {
370  	return send_reply_ok(req, linkname, strlen(linkname));
371  }
372  int fuse_reply_open(fuse_req_t req, const struct fuse_file_info *f)
373  {
374  	struct fuse_open_out arg;
375  	memset(&arg, 0, sizeof(arg));
376  	fill_open(&arg, f);
377  	return send_reply_ok(req, &arg, sizeof(arg));
378  }
379  int fuse_reply_write(fuse_req_t req, size_t count)
380  {
381  	struct fuse_write_out arg;
382  	memset(&arg, 0, sizeof(arg));
383  	arg.size = count;
384  	return send_reply_ok(req, &arg, sizeof(arg));
385  }
386  int fuse_reply_buf(fuse_req_t req, const char *buf, size_t size)
387  {
388  	return send_reply_ok(req, buf, size);
389  }
390  static int fuse_send_data_iov_fallback(struct fuse_session *se,
391  				       struct fuse_chan *ch,
392  				       struct iovec *iov, int iov_count,
393  				       struct fuse_bufvec *buf,
394  				       size_t len)
395  {
396  	struct fuse_bufvec mem_buf = FUSE_BUFVEC_INIT(len);
397  	void *mbuf;
398  	int res;
399  	if (buf->count == 1 && buf->idx == 0 && buf->off == 0 &&
400  	    !(buf->buf[0].flags & FUSE_BUF_IS_FD)) {
401  		iov[iov_count].iov_base = buf->buf[0].mem;
402  		iov[iov_count].iov_len = len;
403  		iov_count++;
404  		return fuse_send_msg(se, ch, iov, iov_count);
405  	}
406  	res = posix_memalign(&mbuf, pagesize, len);
407  	if (res != 0)
408  		return res;
409  	mem_buf.buf[0].mem = mbuf;
410  	res = fuse_buf_copy(&mem_buf, buf, 0);
411  	if (res < 0) {
412  		free(mbuf);
413  		return -res;
414  	}
415  	len = res;
416  	iov[iov_count].iov_base = mbuf;
417  	iov[iov_count].iov_len = len;
418  	iov_count++;
419  	res = fuse_send_msg(se, ch, iov, iov_count);
420  	free(mbuf);
421  	return res;
422  }
423  struct fuse_ll_pipe {
424  	size_t size;
425  	int can_grow;
426  	int pipe[2];
427  };
428  static void fuse_ll_pipe_free(struct fuse_ll_pipe *llp)
429  {
430  	close(llp->pipe[0]);
431  	close(llp->pipe[1]);
432  	free(llp);
433  }
434  #ifdef HAVE_SPLICE
435  #if !defined(HAVE_PIPE2) || !defined(O_CLOEXEC)
436  static int fuse_pipe(int fds[2])
437  {
438  	int rv = pipe(fds);
439  	if (rv == -1)
440  		return rv;
441  	if (fcntl(fds[0], F_SETFL, O_NONBLOCK) == -1 ||
442  	    fcntl(fds[1], F_SETFL, O_NONBLOCK) == -1 ||
443  	    fcntl(fds[0], F_SETFD, FD_CLOEXEC) == -1 ||
444  	    fcntl(fds[1], F_SETFD, FD_CLOEXEC) == -1) {
445  		close(fds[0]);
446  		close(fds[1]);
447  		rv = -1;
448  	}
449  	return rv;
450  }
451  #else
452  static int fuse_pipe(int fds[2])
453  {
454  	return pipe2(fds, O_CLOEXEC | O_NONBLOCK);
455  }
456  #endif
457  static struct fuse_ll_pipe *fuse_ll_get_pipe(struct fuse_session *se)
458  {
459  	struct fuse_ll_pipe *llp = pthread_getspecific(se->pipe_key);
460  	if (llp == NULL) {
461  		int res;
462  		llp = malloc(sizeof(struct fuse_ll_pipe));
463  		if (llp == NULL)
464  			return NULL;
465  		res = fuse_pipe(llp->pipe);
466  		if (res == -1) {
467  			free(llp);
468  			return NULL;
469  		}
470  		llp->size = pagesize * 16;
471  		llp->can_grow = 1;
472  		pthread_setspecific(se->pipe_key, llp);
473  	}
474  	return llp;
475  }
476  #endif
477  static void fuse_ll_clear_pipe(struct fuse_session *se)
478  {
479  	struct fuse_ll_pipe *llp = pthread_getspecific(se->pipe_key);
480  	if (llp) {
481  		pthread_setspecific(se->pipe_key, NULL);
482  		fuse_ll_pipe_free(llp);
483  	}
484  }
485  #if defined(HAVE_SPLICE) && defined(HAVE_VMSPLICE)
486  static int read_back(int fd, char *buf, size_t len)
487  {
488  	int res;
489  	res = read(fd, buf, len);
490  	if (res == -1) {
491  		fuse_log(FUSE_LOG_ERR, "fuse: internal error: failed to read back from pipe: %s\n", strerror(errno));
492  		return -EIO;
493  	}
494  	if (res != len) {
495  		fuse_log(FUSE_LOG_ERR, "fuse: internal error: short read back from pipe: %i from %zi\n", res, len);
496  		return -EIO;
497  	}
498  	return 0;
499  }
500  static int grow_pipe_to_max(int pipefd)
501  {
502  	int max;
503  	int res;
504  	int maxfd;
505  	char buf[32];
506  	maxfd = open("/proc/sys/fs/pipe-max-size", O_RDONLY);
507  	if (maxfd < 0)
508  		return -errno;
509  	res = read(maxfd, buf, sizeof(buf) - 1);
510  	if (res < 0) {
511  		int saved_errno;
512  		saved_errno = errno;
513  		close(maxfd);
514  		return -saved_errno;
515  	}
516  	close(maxfd);
517  	buf[res] = '\0';
518  	max = atoi(buf);
519  	res = fcntl(pipefd, F_SETPIPE_SZ, max);
520  	if (res < 0)
521  		return -errno;
522  	return max;
523  }
524  static int fuse_send_data_iov(struct fuse_session *se, struct fuse_chan *ch,
525  			       struct iovec *iov, int iov_count,
526  			       struct fuse_bufvec *buf, unsigned int flags)
527  {
528  	int res;
529  	size_t len = fuse_buf_size(buf);
530  	struct fuse_out_header *out = iov[0].iov_base;
531  	struct fuse_ll_pipe *llp;
532  	int splice_flags;
533  	size_t pipesize;
534  	size_t total_buf_size;
535  	size_t idx;
536  	size_t headerlen;
537  	struct fuse_bufvec pipe_buf = FUSE_BUFVEC_INIT(len);
538  	if (se->broken_splice_nonblock)
539  		goto fallback;
540  	if (flags & FUSE_BUF_NO_SPLICE)
541  		goto fallback;
542  	total_buf_size = 0;
543  	for (idx = buf->idx; idx < buf->count; idx++) {
544  		total_buf_size += buf->buf[idx].size;
545  		if (idx == buf->idx)
546  			total_buf_size -= buf->off;
547  	}
548  	if (total_buf_size < 2 * pagesize)
549  		goto fallback;
550  	if (se->conn.proto_minor < 14 ||
551  	    !(se->conn.want & FUSE_CAP_SPLICE_WRITE))
552  		goto fallback;
553  	llp = fuse_ll_get_pipe(se);
554  	if (llp == NULL)
555  		goto fallback;
556  	headerlen = iov_length(iov, iov_count);
557  	out->len = headerlen + len;
558  	pipesize = pagesize * (iov_count + buf->count + 1) + out->len;
559  	if (llp->size < pipesize) {
560  		if (llp->can_grow) {
561  			res = fcntl(llp->pipe[0], F_SETPIPE_SZ, pipesize);
562  			if (res == -1) {
563  				res = grow_pipe_to_max(llp->pipe[0]);
564  				if (res > 0)
565  					llp->size = res;
566  				llp->can_grow = 0;
567  				goto fallback;
568  			}
569  			llp->size = res;
570  		}
571  		if (llp->size < pipesize)
572  			goto fallback;
573  	}
574  	res = vmsplice(llp->pipe[1], iov, iov_count, SPLICE_F_NONBLOCK);
575  	if (res == -1)
576  		goto fallback;
577  	if (res != headerlen) {
578  		res = -EIO;
579  		fuse_log(FUSE_LOG_ERR, "fuse: short vmsplice to pipe: %u/%zu\n", res,
580  			headerlen);
581  		goto clear_pipe;
582  	}
583  	pipe_buf.buf[0].flags = FUSE_BUF_IS_FD;
584  	pipe_buf.buf[0].fd = llp->pipe[1];
585  	res = fuse_buf_copy(&pipe_buf, buf,
586  			    FUSE_BUF_FORCE_SPLICE | FUSE_BUF_SPLICE_NONBLOCK);
587  	if (res < 0) {
588  		if (res == -EAGAIN || res == -EINVAL) {
589  			if (res == -EAGAIN)
590  				se->broken_splice_nonblock = 1;
591  			pthread_setspecific(se->pipe_key, NULL);
592  			fuse_ll_pipe_free(llp);
593  			goto fallback;
594  		}
595  		res = -res;
596  		goto clear_pipe;
597  	}
598  	if (res != 0 && res < len) {
599  		struct fuse_bufvec mem_buf = FUSE_BUFVEC_INIT(len);
600  		void *mbuf;
601  		size_t now_len = res;
602  		res = posix_memalign(&mbuf, pagesize, len);
603  		if (res != 0)
604  			goto clear_pipe;
605  		mem_buf.buf[0].mem = mbuf;
606  		mem_buf.off = now_len;
607  		res = fuse_buf_copy(&mem_buf, buf, 0);
608  		if (res > 0) {
609  			char *tmpbuf;
610  			size_t extra_len = res;
611  			tmpbuf = malloc(headerlen);
612  			if (tmpbuf == NULL) {
613  				free(mbuf);
614  				res = ENOMEM;
615  				goto clear_pipe;
616  			}
617  			res = read_back(llp->pipe[0], tmpbuf, headerlen);
618  			free(tmpbuf);
619  			if (res != 0) {
620  				free(mbuf);
621  				goto clear_pipe;
622  			}
623  			res = read_back(llp->pipe[0], mbuf, now_len);
624  			if (res != 0) {
625  				free(mbuf);
626  				goto clear_pipe;
627  			}
628  			len = now_len + extra_len;
629  			iov[iov_count].iov_base = mbuf;
630  			iov[iov_count].iov_len = len;
631  			iov_count++;
632  			res = fuse_send_msg(se, ch, iov, iov_count);
633  			free(mbuf);
634  			return res;
635  		}
636  		free(mbuf);
637  		res = now_len;
638  	}
639  	len = res;
640  	out->len = headerlen + len;
641  	if (se->debug) {
642  		fuse_log(FUSE_LOG_DEBUG,
643  			"   unique: %llu, success, outsize: %i (splice)\n",
644  			(unsigned long long) out->unique, out->len);
645  	}
646  	splice_flags = 0;
647  	if ((flags & FUSE_BUF_SPLICE_MOVE) &&
648  	    (se->conn.want & FUSE_CAP_SPLICE_MOVE))
649  		splice_flags |= SPLICE_F_MOVE;
650  	if (se->io != NULL && se->io->splice_send != NULL) {
651  		res = se->io->splice_send(llp->pipe[0], NULL,
652  						  ch ? ch->fd : se->fd, NULL, out->len,
653  					  	  splice_flags, se->userdata);
654  	} else {
655  		res = splice(llp->pipe[0], NULL, ch ? ch->fd : se->fd, NULL,
656  			       out->len, splice_flags);
657  	}
658  	if (res == -1) {
659  		res = -errno;
660  		perror("fuse: splice from pipe");
661  		goto clear_pipe;
662  	}
663  	if (res != out->len) {
664  		res = -EIO;
665  		fuse_log(FUSE_LOG_ERR, "fuse: short splice from pipe: %u/%u\n",
666  			res, out->len);
667  		goto clear_pipe;
668  	}
669  	return 0;
670  clear_pipe:
671  	fuse_ll_clear_pipe(se);
672  	return res;
673  fallback:
674  	return fuse_send_data_iov_fallback(se, ch, iov, iov_count, buf, len);
675  }
676  #else
677  static int fuse_send_data_iov(struct fuse_session *se, struct fuse_chan *ch,
678  			       struct iovec *iov, int iov_count,
679  			       struct fuse_bufvec *buf, unsigned int flags)
680  {
681  	size_t len = fuse_buf_size(buf);
682  	(void) flags;
683  	return fuse_send_data_iov_fallback(se, ch, iov, iov_count, buf, len);
684  }
685  #endif
686  int fuse_reply_data(fuse_req_t req, struct fuse_bufvec *bufv,
687  		    enum fuse_buf_copy_flags flags)
688  {
689  	struct iovec iov[2];
690  	struct fuse_out_header out;
691  	int res;
692  	iov[0].iov_base = &out;
693  	iov[0].iov_len = sizeof(struct fuse_out_header);
694  	out.unique = req->unique;
695  	out.error = 0;
696  	res = fuse_send_data_iov(req->se, req->ch, iov, 1, bufv, flags);
697  	if (res <= 0) {
698  		fuse_free_req(req);
699  		return res;
700  	} else {
701  		return fuse_reply_err(req, res);
702  	}
703  }
704  int fuse_reply_statfs(fuse_req_t req, const struct statvfs *stbuf)
705  {
706  	struct fuse_statfs_out arg;
707  	size_t size = req->se->conn.proto_minor < 4 ?
708  		FUSE_COMPAT_STATFS_SIZE : sizeof(arg);
709  	memset(&arg, 0, sizeof(arg));
710  	convert_statfs(stbuf, &arg.st);
711  	return send_reply_ok(req, &arg, size);
712  }
713  int fuse_reply_xattr(fuse_req_t req, size_t count)
714  {
715  	struct fuse_getxattr_out arg;
716  	memset(&arg, 0, sizeof(arg));
717  	arg.size = count;
718  	return send_reply_ok(req, &arg, sizeof(arg));
719  }
720  int fuse_reply_lock(fuse_req_t req, const struct flock *lock)
721  {
722  	struct fuse_lk_out arg;
723  	memset(&arg, 0, sizeof(arg));
724  	arg.lk.type = lock->l_type;
725  	if (lock->l_type != F_UNLCK) {
726  		arg.lk.start = lock->l_start;
727  		if (lock->l_len == 0)
728  			arg.lk.end = OFFSET_MAX;
729  		else
730  			arg.lk.end = lock->l_start + lock->l_len - 1;
731  	}
732  	arg.lk.pid = lock->l_pid;
733  	return send_reply_ok(req, &arg, sizeof(arg));
734  }
735  int fuse_reply_bmap(fuse_req_t req, uint64_t idx)
736  {
737  	struct fuse_bmap_out arg;
738  	memset(&arg, 0, sizeof(arg));
739  	arg.block = idx;
740  	return send_reply_ok(req, &arg, sizeof(arg));
741  }
742  static struct fuse_ioctl_iovec *fuse_ioctl_iovec_copy(const struct iovec *iov,
743  						      size_t count)
744  {
745  	struct fuse_ioctl_iovec *fiov;
746  	size_t i;
747  	fiov = malloc(sizeof(fiov[0]) * count);
748  	if (!fiov)
749  		return NULL;
750  	for (i = 0; i < count; i++) {
751  		fiov[i].base = (uintptr_t) iov[i].iov_base;
752  		fiov[i].len = iov[i].iov_len;
753  	}
754  	return fiov;
755  }
756  int fuse_reply_ioctl_retry(fuse_req_t req,
757  			   const struct iovec *in_iov, size_t in_count,
758  			   const struct iovec *out_iov, size_t out_count)
759  {
760  	struct fuse_ioctl_out arg;
761  	struct fuse_ioctl_iovec *in_fiov = NULL;
762  	struct fuse_ioctl_iovec *out_fiov = NULL;
763  	struct iovec iov[4];
764  	size_t count = 1;
765  	int res;
766  	memset(&arg, 0, sizeof(arg));
767  	arg.flags |= FUSE_IOCTL_RETRY;
768  	arg.in_iovs = in_count;
769  	arg.out_iovs = out_count;
770  	iov[count].iov_base = &arg;
771  	iov[count].iov_len = sizeof(arg);
772  	count++;
773  	if (req->se->conn.proto_minor < 16) {
774  		if (in_count) {
775  			iov[count].iov_base = (void *)in_iov;
776  			iov[count].iov_len = sizeof(in_iov[0]) * in_count;
777  			count++;
778  		}
779  		if (out_count) {
780  			iov[count].iov_base = (void *)out_iov;
781  			iov[count].iov_len = sizeof(out_iov[0]) * out_count;
782  			count++;
783  		}
784  	} else {
785  		if (sizeof(void *) == 4 && req->ioctl_64bit) {
786  			res = fuse_reply_err(req, EINVAL);
787  			goto out;
788  		}
789  		if (in_count) {
790  			in_fiov = fuse_ioctl_iovec_copy(in_iov, in_count);
791  			if (!in_fiov)
792  				goto enomem;
793  			iov[count].iov_base = (void *)in_fiov;
794  			iov[count].iov_len = sizeof(in_fiov[0]) * in_count;
795  			count++;
796  		}
797  		if (out_count) {
798  			out_fiov = fuse_ioctl_iovec_copy(out_iov, out_count);
799  			if (!out_fiov)
800  				goto enomem;
801  			iov[count].iov_base = (void *)out_fiov;
802  			iov[count].iov_len = sizeof(out_fiov[0]) * out_count;
803  			count++;
804  		}
805  	}
806  	res = send_reply_iov(req, 0, iov, count);
807  out:
808  	free(in_fiov);
809  	free(out_fiov);
810  	return res;
811  enomem:
812  	res = fuse_reply_err(req, ENOMEM);
813  	goto out;
814  }
815  int fuse_reply_ioctl(fuse_req_t req, int result, const void *buf, size_t size)
816  {
817  	struct fuse_ioctl_out arg;
818  	struct iovec iov[3];
819  	size_t count = 1;
820  	memset(&arg, 0, sizeof(arg));
821  	arg.result = result;
822  	iov[count].iov_base = &arg;
823  	iov[count].iov_len = sizeof(arg);
824  	count++;
825  	if (size) {
826  		iov[count].iov_base = (char *) buf;
827  		iov[count].iov_len = size;
828  		count++;
829  	}
830  	return send_reply_iov(req, 0, iov, count);
831  }
832  int fuse_reply_ioctl_iov(fuse_req_t req, int result, const struct iovec *iov,
833  			 int count)
834  {
835  	struct iovec *padded_iov;
836  	struct fuse_ioctl_out arg;
837  	int res;
838  	padded_iov = malloc((count + 2) * sizeof(struct iovec));
839  	if (padded_iov == NULL)
840  		return fuse_reply_err(req, ENOMEM);
841  	memset(&arg, 0, sizeof(arg));
842  	arg.result = result;
843  	padded_iov[1].iov_base = &arg;
844  	padded_iov[1].iov_len = sizeof(arg);
845  	memcpy(&padded_iov[2], iov, count * sizeof(struct iovec));
846  	res = send_reply_iov(req, 0, padded_iov, count + 2);
847  	free(padded_iov);
848  	return res;
849  }
850  int fuse_reply_poll(fuse_req_t req, unsigned revents)
851  {
852  	struct fuse_poll_out arg;
853  	memset(&arg, 0, sizeof(arg));
854  	arg.revents = revents;
855  	return send_reply_ok(req, &arg, sizeof(arg));
856  }
857  int fuse_reply_lseek(fuse_req_t req, off_t off)
858  {
859  	struct fuse_lseek_out arg;
860  	memset(&arg, 0, sizeof(arg));
861  	arg.offset = off;
862  	return send_reply_ok(req, &arg, sizeof(arg));
863  }
864  static void do_lookup(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
865  {
866  	char *name = (char *) inarg;
867  	if (req->se->op.lookup)
868  		req->se->op.lookup(req, nodeid, name);
869  	else
870  		fuse_reply_err(req, ENOSYS);
871  }
872  static void do_forget(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
873  {
874  	struct fuse_forget_in *arg = (struct fuse_forget_in *) inarg;
875  	if (req->se->op.forget)
876  		req->se->op.forget(req, nodeid, arg->nlookup);
877  	else
878  		fuse_reply_none(req);
879  }
880  static void do_batch_forget(fuse_req_t req, fuse_ino_t nodeid,
881  			    const void *inarg)
882  {
883  	struct fuse_batch_forget_in *arg = (void *) inarg;
884  	struct fuse_forget_one *param = (void *) PARAM(arg);
885  	unsigned int i;
886  	(void) nodeid;
887  	if (req->se->op.forget_multi) {
888  		req->se->op.forget_multi(req, arg->count,
889  				     (struct fuse_forget_data *) param);
890  	} else if (req->se->op.forget) {
891  		for (i = 0; i < arg->count; i++) {
892  			struct fuse_forget_one *forget = &param[i];
893  			struct fuse_req *dummy_req;
894  			dummy_req = fuse_ll_alloc_req(req->se);
895  			if (dummy_req == NULL)
896  				break;
897  			dummy_req->unique = req->unique;
898  			dummy_req->ctx = req->ctx;
899  			dummy_req->ch = NULL;
900  			req->se->op.forget(dummy_req, forget->nodeid,
901  					  forget->nlookup);
902  		}
903  		fuse_reply_none(req);
904  	} else {
905  		fuse_reply_none(req);
906  	}
907  }
908  static void do_getattr(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
909  {
910  	struct fuse_file_info *fip = NULL;
911  	struct fuse_file_info fi;
912  	if (req->se->conn.proto_minor >= 9) {
913  		struct fuse_getattr_in *arg = (struct fuse_getattr_in *) inarg;
914  		if (arg->getattr_flags & FUSE_GETATTR_FH) {
915  			memset(&fi, 0, sizeof(fi));
916  			fi.fh = arg->fh;
917  			fip = &fi;
918  		}
919  	}
920  	if (req->se->op.getattr)
921  		req->se->op.getattr(req, nodeid, fip);
922  	else
923  		fuse_reply_err(req, ENOSYS);
924  }
925  static void do_setattr(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
926  {
927  	struct fuse_setattr_in *arg = (struct fuse_setattr_in *) inarg;
928  	if (req->se->op.setattr) {
929  		struct fuse_file_info *fi = NULL;
930  		struct fuse_file_info fi_store;
931  		struct stat stbuf;
932  		memset(&stbuf, 0, sizeof(stbuf));
933  		convert_attr(arg, &stbuf);
934  		if (arg->valid & FATTR_FH) {
935  			arg->valid &= ~FATTR_FH;
936  			memset(&fi_store, 0, sizeof(fi_store));
937  			fi = &fi_store;
938  			fi->fh = arg->fh;
939  		}
940  		arg->valid &=
941  			FUSE_SET_ATTR_MODE	|
942  			FUSE_SET_ATTR_UID	|
943  			FUSE_SET_ATTR_GID	|
944  			FUSE_SET_ATTR_SIZE	|
945  			FUSE_SET_ATTR_ATIME	|
946  			FUSE_SET_ATTR_MTIME	|
947  			FUSE_SET_ATTR_KILL_SUID |
948  			FUSE_SET_ATTR_KILL_SGID |
949  			FUSE_SET_ATTR_ATIME_NOW	|
950  			FUSE_SET_ATTR_MTIME_NOW |
951  			FUSE_SET_ATTR_CTIME;
952  		req->se->op.setattr(req, nodeid, &stbuf, arg->valid, fi);
953  	} else
954  		fuse_reply_err(req, ENOSYS);
955  }
956  static void do_access(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
957  {
958  	struct fuse_access_in *arg = (struct fuse_access_in *) inarg;
959  	if (req->se->op.access)
960  		req->se->op.access(req, nodeid, arg->mask);
961  	else
962  		fuse_reply_err(req, ENOSYS);
963  }
964  static void do_readlink(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
965  {
966  	(void) inarg;
967  	if (req->se->op.readlink)
968  		req->se->op.readlink(req, nodeid);
969  	else
970  		fuse_reply_err(req, ENOSYS);
971  }
972  static void do_mknod(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
973  {
974  	struct fuse_mknod_in *arg = (struct fuse_mknod_in *) inarg;
975  	char *name = PARAM(arg);
976  	if (req->se->conn.proto_minor >= 12)
977  		req->ctx.umask = arg->umask;
978  	else
979  		name = (char *) inarg + FUSE_COMPAT_MKNOD_IN_SIZE;
980  	if (req->se->op.mknod)
981  		req->se->op.mknod(req, nodeid, name, arg->mode, arg->rdev);
982  	else
983  		fuse_reply_err(req, ENOSYS);
984  }
985  static void do_mkdir(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
986  {
987  	struct fuse_mkdir_in *arg = (struct fuse_mkdir_in *) inarg;
988  	if (req->se->conn.proto_minor >= 12)
989  		req->ctx.umask = arg->umask;
990  	if (req->se->op.mkdir)
991  		req->se->op.mkdir(req, nodeid, PARAM(arg), arg->mode);
992  	else
993  		fuse_reply_err(req, ENOSYS);
994  }
995  static void do_unlink(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
996  {
997  	char *name = (char *) inarg;
998  	if (req->se->op.unlink)
999  		req->se->op.unlink(req, nodeid, name);
1000  	else
1001  		fuse_reply_err(req, ENOSYS);
1002  }
1003  static void do_rmdir(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1004  {
1005  	char *name = (char *) inarg;
1006  	if (req->se->op.rmdir)
1007  		req->se->op.rmdir(req, nodeid, name);
1008  	else
1009  		fuse_reply_err(req, ENOSYS);
1010  }
1011  static void do_symlink(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1012  {
1013  	char *name = (char *) inarg;
1014  	char *linkname = ((char *) inarg) + strlen((char *) inarg) + 1;
1015  	if (req->se->op.symlink)
1016  		req->se->op.symlink(req, linkname, nodeid, name);
1017  	else
1018  		fuse_reply_err(req, ENOSYS);
1019  }
1020  static void do_rename(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1021  {
1022  	struct fuse_rename_in *arg = (struct fuse_rename_in *) inarg;
1023  	char *oldname = PARAM(arg);
1024  	char *newname = oldname + strlen(oldname) + 1;
1025  	if (req->se->op.rename)
1026  		req->se->op.rename(req, nodeid, oldname, arg->newdir, newname,
1027  				  0);
1028  	else
1029  		fuse_reply_err(req, ENOSYS);
1030  }
1031  static void do_rename2(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1032  {
1033  	struct fuse_rename2_in *arg = (struct fuse_rename2_in *) inarg;
1034  	char *oldname = PARAM(arg);
1035  	char *newname = oldname + strlen(oldname) + 1;
1036  	if (req->se->op.rename)
1037  		req->se->op.rename(req, nodeid, oldname, arg->newdir, newname,
1038  				  arg->flags);
1039  	else
1040  		fuse_reply_err(req, ENOSYS);
1041  }
1042  static void do_link(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1043  {
1044  	struct fuse_link_in *arg = (struct fuse_link_in *) inarg;
1045  	if (req->se->op.link)
1046  		req->se->op.link(req, arg->oldnodeid, nodeid, PARAM(arg));
1047  	else
1048  		fuse_reply_err(req, ENOSYS);
1049  }
1050  static void do_create(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1051  {
1052  	struct fuse_create_in *arg = (struct fuse_create_in *) inarg;
1053  	if (req->se->op.create) {
1054  		struct fuse_file_info fi;
1055  		char *name = PARAM(arg);
1056  		memset(&fi, 0, sizeof(fi));
1057  		fi.flags = arg->flags;
1058  		if (req->se->conn.proto_minor >= 12)
1059  			req->ctx.umask = arg->umask;
1060  		else
1061  			name = (char *) inarg + sizeof(struct fuse_open_in);
1062  		req->se->op.create(req, nodeid, name, arg->mode, &fi);
1063  	} else
1064  		fuse_reply_err(req, ENOSYS);
1065  }
1066  static void do_open(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1067  {
1068  	struct fuse_open_in *arg = (struct fuse_open_in *) inarg;
1069  	struct fuse_file_info fi;
1070  	memset(&fi, 0, sizeof(fi));
1071  	fi.flags = arg->flags;
1072  	if (req->se->op.open)
1073  		req->se->op.open(req, nodeid, &fi);
1074  	else
1075  		fuse_reply_open(req, &fi);
1076  }
1077  static void do_read(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1078  {
1079  	struct fuse_read_in *arg = (struct fuse_read_in *) inarg;
1080  	if (req->se->op.read) {
1081  		struct fuse_file_info fi;
1082  		memset(&fi, 0, sizeof(fi));
1083  		fi.fh = arg->fh;
1084  		if (req->se->conn.proto_minor >= 9) {
1085  			fi.lock_owner = arg->lock_owner;
1086  			fi.flags = arg->flags;
1087  		}
1088  		req->se->op.read(req, nodeid, arg->size, arg->offset, &fi);
1089  	} else
1090  		fuse_reply_err(req, ENOSYS);
1091  }
1092  static void do_write(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1093  {
1094  	struct fuse_write_in *arg = (struct fuse_write_in *) inarg;
1095  	struct fuse_file_info fi;
1096  	char *param;
1097  	memset(&fi, 0, sizeof(fi));
1098  	fi.fh = arg->fh;
1099  	fi.writepage = (arg->write_flags & FUSE_WRITE_CACHE) != 0;
1100  	if (req->se->conn.proto_minor < 9) {
1101  		param = ((char *) arg) + FUSE_COMPAT_WRITE_IN_SIZE;
1102  	} else {
1103  		fi.lock_owner = arg->lock_owner;
1104  		fi.flags = arg->flags;
1105  		param = PARAM(arg);
1106  	}
1107  	if (req->se->op.write)
1108  		req->se->op.write(req, nodeid, param, arg->size,
1109  				 arg->offset, &fi);
1110  	else
1111  		fuse_reply_err(req, ENOSYS);
1112  }
1113  static void do_write_buf(fuse_req_t req, fuse_ino_t nodeid, const void *inarg,
1114  			 const struct fuse_buf *ibuf)
1115  {
1116  	struct fuse_session *se = req->se;
1117  	struct fuse_bufvec bufv = {
1118  		.buf[0] = *ibuf,
1119  		.count = 1,
1120  	};
1121  	struct fuse_write_in *arg = (struct fuse_write_in *) inarg;
1122  	struct fuse_file_info fi;
1123  	memset(&fi, 0, sizeof(fi));
1124  	fi.fh = arg->fh;
1125  	fi.writepage = arg->write_flags & FUSE_WRITE_CACHE;
1126  	if (se->conn.proto_minor < 9) {
1127  		bufv.buf[0].mem = ((char *) arg) + FUSE_COMPAT_WRITE_IN_SIZE;
1128  		bufv.buf[0].size -= sizeof(struct fuse_in_header) +
1129  			FUSE_COMPAT_WRITE_IN_SIZE;
1130  		assert(!(bufv.buf[0].flags & FUSE_BUF_IS_FD));
1131  	} else {
1132  		fi.lock_owner = arg->lock_owner;
1133  		fi.flags = arg->flags;
1134  		if (!(bufv.buf[0].flags & FUSE_BUF_IS_FD))
1135  			bufv.buf[0].mem = PARAM(arg);
1136  		bufv.buf[0].size -= sizeof(struct fuse_in_header) +
1137  			sizeof(struct fuse_write_in);
1138  	}
1139  	if (bufv.buf[0].size < arg->size) {
1140  		fuse_log(FUSE_LOG_ERR, "fuse: do_write_buf: buffer size too small\n");
1141  		fuse_reply_err(req, EIO);
1142  		goto out;
1143  	}
1144  	bufv.buf[0].size = arg->size;
1145  	se->op.write_buf(req, nodeid, &bufv, arg->offset, &fi);
1146  out:
1147  	if ((ibuf->flags & FUSE_BUF_IS_FD) && bufv.idx < bufv.count)
1148  		fuse_ll_clear_pipe(se);
1149  }
1150  static void do_flush(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1151  {
1152  	struct fuse_flush_in *arg = (struct fuse_flush_in *) inarg;
1153  	struct fuse_file_info fi;
1154  	memset(&fi, 0, sizeof(fi));
1155  	fi.fh = arg->fh;
1156  	fi.flush = 1;
1157  	if (req->se->conn.proto_minor >= 7)
1158  		fi.lock_owner = arg->lock_owner;
1159  	if (req->se->op.flush)
1160  		req->se->op.flush(req, nodeid, &fi);
1161  	else
1162  		fuse_reply_err(req, ENOSYS);
1163  }
1164  static void do_release(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1165  {
1166  	struct fuse_release_in *arg = (struct fuse_release_in *) inarg;
1167  	struct fuse_file_info fi;
1168  	memset(&fi, 0, sizeof(fi));
1169  	fi.flags = arg->flags;
1170  	fi.fh = arg->fh;
1171  	if (req->se->conn.proto_minor >= 8) {
1172  		fi.flush = (arg->release_flags & FUSE_RELEASE_FLUSH) ? 1 : 0;
1173  		fi.lock_owner = arg->lock_owner;
1174  	}
1175  	if (arg->release_flags & FUSE_RELEASE_FLOCK_UNLOCK) {
1176  		fi.flock_release = 1;
1177  		fi.lock_owner = arg->lock_owner;
1178  	}
1179  	if (req->se->op.release)
1180  		req->se->op.release(req, nodeid, &fi);
1181  	else
1182  		fuse_reply_err(req, 0);
1183  }
1184  static void do_fsync(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1185  {
1186  	struct fuse_fsync_in *arg = (struct fuse_fsync_in *) inarg;
1187  	struct fuse_file_info fi;
1188  	int datasync = arg->fsync_flags & 1;
1189  	memset(&fi, 0, sizeof(fi));
1190  	fi.fh = arg->fh;
1191  	if (req->se->op.fsync)
1192  		req->se->op.fsync(req, nodeid, datasync, &fi);
1193  	else
1194  		fuse_reply_err(req, ENOSYS);
1195  }
1196  static void do_opendir(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1197  {
1198  	struct fuse_open_in *arg = (struct fuse_open_in *) inarg;
1199  	struct fuse_file_info fi;
1200  	memset(&fi, 0, sizeof(fi));
1201  	fi.flags = arg->flags;
1202  	if (req->se->op.opendir)
1203  		req->se->op.opendir(req, nodeid, &fi);
1204  	else
1205  		fuse_reply_open(req, &fi);
1206  }
1207  static void do_readdir(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1208  {
1209  	struct fuse_read_in *arg = (struct fuse_read_in *) inarg;
1210  	struct fuse_file_info fi;
1211  	memset(&fi, 0, sizeof(fi));
1212  	fi.fh = arg->fh;
1213  	if (req->se->op.readdir)
1214  		req->se->op.readdir(req, nodeid, arg->size, arg->offset, &fi);
1215  	else
1216  		fuse_reply_err(req, ENOSYS);
1217  }
1218  static void do_readdirplus(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1219  {
1220  	struct fuse_read_in *arg = (struct fuse_read_in *) inarg;
1221  	struct fuse_file_info fi;
1222  	memset(&fi, 0, sizeof(fi));
1223  	fi.fh = arg->fh;
1224  	if (req->se->op.readdirplus)
1225  		req->se->op.readdirplus(req, nodeid, arg->size, arg->offset, &fi);
1226  	else
1227  		fuse_reply_err(req, ENOSYS);
1228  }
1229  static void do_releasedir(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1230  {
1231  	struct fuse_release_in *arg = (struct fuse_release_in *) inarg;
1232  	struct fuse_file_info fi;
1233  	memset(&fi, 0, sizeof(fi));
1234  	fi.flags = arg->flags;
1235  	fi.fh = arg->fh;
1236  	if (req->se->op.releasedir)
1237  		req->se->op.releasedir(req, nodeid, &fi);
1238  	else
1239  		fuse_reply_err(req, 0);
1240  }
1241  static void do_fsyncdir(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1242  {
1243  	struct fuse_fsync_in *arg = (struct fuse_fsync_in *) inarg;
1244  	struct fuse_file_info fi;
1245  	int datasync = arg->fsync_flags & 1;
1246  	memset(&fi, 0, sizeof(fi));
1247  	fi.fh = arg->fh;
1248  	if (req->se->op.fsyncdir)
1249  		req->se->op.fsyncdir(req, nodeid, datasync, &fi);
1250  	else
1251  		fuse_reply_err(req, ENOSYS);
1252  }
1253  static void do_statfs(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1254  {
1255  	(void) nodeid;
1256  	(void) inarg;
1257  	if (req->se->op.statfs)
1258  		req->se->op.statfs(req, nodeid);
1259  	else {
1260  		struct statvfs buf = {
1261  			.f_namemax = 255,
1262  			.f_bsize = 512,
1263  		};
1264  		fuse_reply_statfs(req, &buf);
1265  	}
1266  }
1267  static void do_setxattr(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1268  {
1269  	struct fuse_session *se = req->se;
1270  	unsigned int xattr_ext = !!(se->conn.want & FUSE_CAP_SETXATTR_EXT);
1271  	struct fuse_setxattr_in *arg = (struct fuse_setxattr_in *) inarg;
1272  	char *name = xattr_ext ? PARAM(arg) :
1273  		     (char *)arg + FUSE_COMPAT_SETXATTR_IN_SIZE;
1274  	char *value = name + strlen(name) + 1;
1275  	if (req->se->op.setxattr)
1276  		req->se->op.setxattr(req, nodeid, name, value, arg->size,
1277  				    arg->flags);
1278  	else
1279  		fuse_reply_err(req, ENOSYS);
1280  }
1281  static void do_getxattr(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1282  {
1283  	struct fuse_getxattr_in *arg = (struct fuse_getxattr_in *) inarg;
1284  	if (req->se->op.getxattr)
1285  		req->se->op.getxattr(req, nodeid, PARAM(arg), arg->size);
1286  	else
1287  		fuse_reply_err(req, ENOSYS);
1288  }
1289  static void do_listxattr(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1290  {
1291  	struct fuse_getxattr_in *arg = (struct fuse_getxattr_in *) inarg;
1292  	if (req->se->op.listxattr)
1293  		req->se->op.listxattr(req, nodeid, arg->size);
1294  	else
1295  		fuse_reply_err(req, ENOSYS);
1296  }
1297  static void do_removexattr(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1298  {
1299  	char *name = (char *) inarg;
1300  	if (req->se->op.removexattr)
1301  		req->se->op.removexattr(req, nodeid, name);
1302  	else
1303  		fuse_reply_err(req, ENOSYS);
1304  }
1305  static void convert_fuse_file_lock(struct fuse_file_lock *fl,
1306  				   struct flock *flock)
1307  {
1308  	memset(flock, 0, sizeof(struct flock));
1309  	flock->l_type = fl->type;
1310  	flock->l_whence = SEEK_SET;
1311  	flock->l_start = fl->start;
1312  	if (fl->end == OFFSET_MAX)
1313  		flock->l_len = 0;
1314  	else
1315  		flock->l_len = fl->end - fl->start + 1;
1316  	flock->l_pid = fl->pid;
1317  }
1318  static void do_getlk(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1319  {
1320  	struct fuse_lk_in *arg = (struct fuse_lk_in *) inarg;
1321  	struct fuse_file_info fi;
1322  	struct flock flock;
1323  	memset(&fi, 0, sizeof(fi));
1324  	fi.fh = arg->fh;
1325  	fi.lock_owner = arg->owner;
1326  	convert_fuse_file_lock(&arg->lk, &flock);
1327  	if (req->se->op.getlk)
1328  		req->se->op.getlk(req, nodeid, &fi, &flock);
1329  	else
1330  		fuse_reply_err(req, ENOSYS);
1331  }
1332  static void do_setlk_common(fuse_req_t req, fuse_ino_t nodeid,
1333  			    const void *inarg, int sleep)
1334  {
1335  	struct fuse_lk_in *arg = (struct fuse_lk_in *) inarg;
1336  	struct fuse_file_info fi;
1337  	struct flock flock;
1338  	memset(&fi, 0, sizeof(fi));
1339  	fi.fh = arg->fh;
1340  	fi.lock_owner = arg->owner;
1341  	if (arg->lk_flags & FUSE_LK_FLOCK) {
1342  		int op = 0;
1343  		switch (arg->lk.type) {
1344  		case F_RDLCK:
1345  			op = LOCK_SH;
1346  			break;
1347  		case F_WRLCK:
1348  			op = LOCK_EX;
1349  			break;
1350  		case F_UNLCK:
1351  			op = LOCK_UN;
1352  			break;
1353  		}
1354  		if (!sleep)
1355  			op |= LOCK_NB;
1356  		if (req->se->op.flock)
1357  			req->se->op.flock(req, nodeid, &fi, op);
1358  		else
1359  			fuse_reply_err(req, ENOSYS);
1360  	} else {
1361  		convert_fuse_file_lock(&arg->lk, &flock);
1362  		if (req->se->op.setlk)
1363  			req->se->op.setlk(req, nodeid, &fi, &flock, sleep);
1364  		else
1365  			fuse_reply_err(req, ENOSYS);
1366  	}
1367  }
1368  static void do_setlk(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1369  {
1370  	do_setlk_common(req, nodeid, inarg, 0);
1371  }
1372  static void do_setlkw(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1373  {
1374  	do_setlk_common(req, nodeid, inarg, 1);
1375  }
1376  static int find_interrupted(struct fuse_session *se, struct fuse_req *req)
1377  {
1378  	struct fuse_req *curr;
1379  	for (curr = se->list.next; curr != &se->list; curr = curr->next) {
1380  		if (curr->unique == req->u.i.unique) {
1381  			fuse_interrupt_func_t func;
1382  			void *data;
1383  			curr->ctr++;
1384  			pthread_mutex_unlock(&se->lock);
1385  			pthread_mutex_lock(&curr->lock);
1386  			pthread_mutex_lock(&se->lock);
1387  			curr->interrupted = 1;
1388  			func = curr->u.ni.func;
1389  			data = curr->u.ni.data;
1390  			pthread_mutex_unlock(&se->lock);
1391  			if (func)
1392  				func(curr, data);
1393  			pthread_mutex_unlock(&curr->lock);
1394  			pthread_mutex_lock(&se->lock);
1395  			curr->ctr--;
1396  			if (!curr->ctr) {
1397  				fuse_chan_put(req->ch);
1398  				req->ch = NULL;
1399  				destroy_req(curr);
1400  			}
1401  			return 1;
1402  		}
1403  	}
1404  	for (curr = se->interrupts.next; curr != &se->interrupts;
1405  	     curr = curr->next) {
1406  		if (curr->u.i.unique == req->u.i.unique)
1407  			return 1;
1408  	}
1409  	return 0;
1410  }
1411  static void do_interrupt(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1412  {
1413  	struct fuse_interrupt_in *arg = (struct fuse_interrupt_in *) inarg;
1414  	struct fuse_session *se = req->se;
1415  	(void) nodeid;
1416  	if (se->debug)
1417  		fuse_log(FUSE_LOG_DEBUG, "INTERRUPT: %llu\n",
1418  			(unsigned long long) arg->unique);
1419  	req->u.i.unique = arg->unique;
1420  	pthread_mutex_lock(&se->lock);
1421  	if (find_interrupted(se, req)) {
1422  		fuse_chan_put(req->ch);
1423  		req->ch = NULL;
1424  		destroy_req(req);
1425  	} else
1426  		list_add_req(req, &se->interrupts);
1427  	pthread_mutex_unlock(&se->lock);
1428  }
1429  static struct fuse_req *check_interrupt(struct fuse_session *se,
1430  					struct fuse_req *req)
1431  {
1432  	struct fuse_req *curr;
1433  	for (curr = se->interrupts.next; curr != &se->interrupts;
1434  	     curr = curr->next) {
1435  		if (curr->u.i.unique == req->unique) {
1436  			req->interrupted = 1;
1437  			list_del_req(curr);
1438  			fuse_chan_put(curr->ch);
1439  			curr->ch = NULL;
1440  			destroy_req(curr);
1441  			return NULL;
1442  		}
1443  	}
1444  	curr = se->interrupts.next;
1445  	if (curr != &se->interrupts) {
1446  		list_del_req(curr);
1447  		list_init_req(curr);
1448  		return curr;
1449  	} else
1450  		return NULL;
1451  }
1452  static void do_bmap(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1453  {
1454  	struct fuse_bmap_in *arg = (struct fuse_bmap_in *) inarg;
1455  	if (req->se->op.bmap)
1456  		req->se->op.bmap(req, nodeid, arg->blocksize, arg->block);
1457  	else
1458  		fuse_reply_err(req, ENOSYS);
1459  }
1460  static void do_ioctl(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1461  {
1462  	struct fuse_ioctl_in *arg = (struct fuse_ioctl_in *) inarg;
1463  	unsigned int flags = arg->flags;
1464  	void *in_buf = arg->in_size ? PARAM(arg) : NULL;
1465  	struct fuse_file_info fi;
1466  	if (flags & FUSE_IOCTL_DIR &&
1467  	    !(req->se->conn.want & FUSE_CAP_IOCTL_DIR)) {
1468  		fuse_reply_err(req, ENOTTY);
1469  		return;
1470  	}
1471  	memset(&fi, 0, sizeof(fi));
1472  	fi.fh = arg->fh;
1473  	if (sizeof(void *) == 4 && req->se->conn.proto_minor >= 16 &&
1474  	    !(flags & FUSE_IOCTL_32BIT)) {
1475  		req->ioctl_64bit = 1;
1476  	}
1477  	if (req->se->op.ioctl)
1478  		req->se->op.ioctl(req, nodeid, arg->cmd,
1479  				 (void *)(uintptr_t)arg->arg, &fi, flags,
1480  				 in_buf, arg->in_size, arg->out_size);
1481  	else
1482  		fuse_reply_err(req, ENOSYS);
1483  }
1484  void fuse_pollhandle_destroy(struct fuse_pollhandle *ph)
1485  {
1486  	free(ph);
1487  }
1488  static void do_poll(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1489  {
1490  	struct fuse_poll_in *arg = (struct fuse_poll_in *) inarg;
1491  	struct fuse_file_info fi;
1492  	memset(&fi, 0, sizeof(fi));
1493  	fi.fh = arg->fh;
1494  	fi.poll_events = arg->events;
1495  	if (req->se->op.poll) {
1496  		struct fuse_pollhandle *ph = NULL;
1497  		if (arg->flags & FUSE_POLL_SCHEDULE_NOTIFY) {
1498  			ph = malloc(sizeof(struct fuse_pollhandle));
1499  			if (ph == NULL) {
1500  				fuse_reply_err(req, ENOMEM);
1501  				return;
1502  			}
1503  			ph->kh = arg->kh;
1504  			ph->se = req->se;
1505  		}
1506  		req->se->op.poll(req, nodeid, &fi, ph);
1507  	} else {
1508  		fuse_reply_err(req, ENOSYS);
1509  	}
1510  }
1511  static void do_fallocate(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1512  {
1513  	struct fuse_fallocate_in *arg = (struct fuse_fallocate_in *) inarg;
1514  	struct fuse_file_info fi;
1515  	memset(&fi, 0, sizeof(fi));
1516  	fi.fh = arg->fh;
1517  	if (req->se->op.fallocate)
1518  		req->se->op.fallocate(req, nodeid, arg->mode, arg->offset, arg->length, &fi);
1519  	else
1520  		fuse_reply_err(req, ENOSYS);
1521  }
1522  static void do_copy_file_range(fuse_req_t req, fuse_ino_t nodeid_in, const void *inarg)
1523  {
1524  	struct fuse_copy_file_range_in *arg = (struct fuse_copy_file_range_in *) inarg;
1525  	struct fuse_file_info fi_in, fi_out;
1526  	memset(&fi_in, 0, sizeof(fi_in));
1527  	fi_in.fh = arg->fh_in;
1528  	memset(&fi_out, 0, sizeof(fi_out));
1529  	fi_out.fh = arg->fh_out;
1530  	if (req->se->op.copy_file_range)
1531  		req->se->op.copy_file_range(req, nodeid_in, arg->off_in,
1532  					    &fi_in, arg->nodeid_out,
1533  					    arg->off_out, &fi_out, arg->len,
1534  					    arg->flags);
1535  	else
1536  		fuse_reply_err(req, ENOSYS);
1537  }
1538  static void do_lseek(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1539  {
1540  	struct fuse_lseek_in *arg = (struct fuse_lseek_in *) inarg;
1541  	struct fuse_file_info fi;
1542  	memset(&fi, 0, sizeof(fi));
1543  	fi.fh = arg->fh;
1544  	if (req->se->op.lseek)
1545  		req->se->op.lseek(req, nodeid, arg->offset, arg->whence, &fi);
1546  	else
1547  		fuse_reply_err(req, ENOSYS);
1548  }
1549  static __attribute__((no_sanitize("thread")))
1550  void do_init(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1551  {
1552  	struct fuse_init_in *arg = (struct fuse_init_in *) inarg;
1553  	struct fuse_init_out outarg;
1554  	struct fuse_session *se = req->se;
1555  	size_t bufsize = se->bufsize;
1556  	size_t outargsize = sizeof(outarg);
1557  	uint64_t inargflags = 0;
1558  	uint64_t outargflags = 0;
1559  	(void) nodeid;
1560  	if (se->debug) {
1561  		fuse_log(FUSE_LOG_DEBUG, "INIT: %u.%u\n", arg->major, arg->minor);
1562  		if (arg->major == 7 && arg->minor >= 6) {
1563  			fuse_log(FUSE_LOG_DEBUG, "flags=0x%08x\n", arg->flags);
1564  			fuse_log(FUSE_LOG_DEBUG, "max_readahead=0x%08x\n",
1565  				arg->max_readahead);
1566  		}
1567  	}
1568  	se->conn.proto_major = arg->major;
1569  	se->conn.proto_minor = arg->minor;
1570  	se->conn.capable = 0;
1571  	se->conn.want = 0;
1572  	memset(&outarg, 0, sizeof(outarg));
1573  	outarg.major = FUSE_KERNEL_VERSION;
1574  	outarg.minor = FUSE_KERNEL_MINOR_VERSION;
1575  	if (arg->major < 7) {
1576  		fuse_log(FUSE_LOG_ERR, "fuse: unsupported protocol version: %u.%u\n",
1577  			arg->major, arg->minor);
1578  		fuse_reply_err(req, EPROTO);
1579  		return;
1580  	}
1581  	if (arg->major > 7) {
1582  		send_reply_ok(req, &outarg, sizeof(outarg));
1583  		return;
1584  	}
1585  	if (arg->minor >= 6) {
1586  		if (arg->max_readahead < se->conn.max_readahead)
1587  			se->conn.max_readahead = arg->max_readahead;
1588  		inargflags = arg->flags;
1589  		if (inargflags & FUSE_INIT_EXT)
1590  			inargflags = inargflags | (uint64_t) arg->flags2 << 32;
1591  		if (inargflags & FUSE_ASYNC_READ)
1592  			se->conn.capable |= FUSE_CAP_ASYNC_READ;
1593  		if (inargflags & FUSE_POSIX_LOCKS)
1594  			se->conn.capable |= FUSE_CAP_POSIX_LOCKS;
1595  		if (inargflags & FUSE_ATOMIC_O_TRUNC)
1596  			se->conn.capable |= FUSE_CAP_ATOMIC_O_TRUNC;
1597  		if (inargflags & FUSE_EXPORT_SUPPORT)
1598  			se->conn.capable |= FUSE_CAP_EXPORT_SUPPORT;
1599  		if (inargflags & FUSE_DONT_MASK)
1600  			se->conn.capable |= FUSE_CAP_DONT_MASK;
1601  		if (inargflags & FUSE_FLOCK_LOCKS)
1602  			se->conn.capable |= FUSE_CAP_FLOCK_LOCKS;
1603  		if (inargflags & FUSE_AUTO_INVAL_DATA)
1604  			se->conn.capable |= FUSE_CAP_AUTO_INVAL_DATA;
1605  		if (inargflags & FUSE_DO_READDIRPLUS)
1606  			se->conn.capable |= FUSE_CAP_READDIRPLUS;
1607  		if (inargflags & FUSE_READDIRPLUS_AUTO)
1608  			se->conn.capable |= FUSE_CAP_READDIRPLUS_AUTO;
1609  		if (inargflags & FUSE_ASYNC_DIO)
1610  			se->conn.capable |= FUSE_CAP_ASYNC_DIO;
1611  		if (inargflags & FUSE_WRITEBACK_CACHE)
1612  			se->conn.capable |= FUSE_CAP_WRITEBACK_CACHE;
1613  		if (inargflags & FUSE_NO_OPEN_SUPPORT)
1614  			se->conn.capable |= FUSE_CAP_NO_OPEN_SUPPORT;
1615  		if (inargflags & FUSE_PARALLEL_DIROPS)
1616  			se->conn.capable |= FUSE_CAP_PARALLEL_DIROPS;
1617  		if (inargflags & FUSE_POSIX_ACL)
1618  			se->conn.capable |= FUSE_CAP_POSIX_ACL;
1619  		if (inargflags & FUSE_HANDLE_KILLPRIV)
1620  			se->conn.capable |= FUSE_CAP_HANDLE_KILLPRIV;
1621  		if (inargflags & FUSE_CACHE_SYMLINKS)
1622  			se->conn.capable |= FUSE_CAP_CACHE_SYMLINKS;
1623  		if (inargflags & FUSE_NO_OPENDIR_SUPPORT)
1624  			se->conn.capable |= FUSE_CAP_NO_OPENDIR_SUPPORT;
1625  		if (inargflags & FUSE_EXPLICIT_INVAL_DATA)
1626  			se->conn.capable |= FUSE_CAP_EXPLICIT_INVAL_DATA;
1627  		if (inargflags & FUSE_SETXATTR_EXT)
1628  			se->conn.capable |= FUSE_CAP_SETXATTR_EXT;
1629  		if (!(inargflags & FUSE_MAX_PAGES)) {
1630  			size_t max_bufsize =
1631  				FUSE_DEFAULT_MAX_PAGES_PER_REQ * getpagesize()
1632  				+ FUSE_BUFFER_HEADER_SIZE;
1633  			if (bufsize > max_bufsize) {
1634  				bufsize = max_bufsize;
1635  			}
1636  		}
1637  		if (arg->minor >= 38)
1638  			se->conn.capable |= FUSE_CAP_EXPIRE_ONLY;
1639  	} else {
1640  		se->conn.max_readahead = 0;
1641  	}
1642  	if (se->conn.proto_minor >= 14) {
1643  #ifdef HAVE_SPLICE
1644  #ifdef HAVE_VMSPLICE
1645  		if ((se->io == NULL) || (se->io->splice_send != NULL)) {
1646  			se->conn.capable |= FUSE_CAP_SPLICE_WRITE | FUSE_CAP_SPLICE_MOVE;
1647  		}
1648  #endif
1649  		if ((se->io == NULL) || (se->io->splice_receive != NULL)) {
1650  			se->conn.capable |= FUSE_CAP_SPLICE_READ;
1651  		}
1652  #endif
1653  	}
1654  	if (se->conn.proto_minor >= 18)
1655  		se->conn.capable |= FUSE_CAP_IOCTL_DIR;
1656  #define LL_SET_DEFAULT(cond, cap) \
1657  	if ((cond) && (se->conn.capable & (cap))) \
1658  		se->conn.want |= (cap)
1659  	LL_SET_DEFAULT(1, FUSE_CAP_ASYNC_READ);
1660  	LL_SET_DEFAULT(1, FUSE_CAP_PARALLEL_DIROPS);
1661  	LL_SET_DEFAULT(1, FUSE_CAP_AUTO_INVAL_DATA);
1662  	LL_SET_DEFAULT(1, FUSE_CAP_HANDLE_KILLPRIV);
1663  	LL_SET_DEFAULT(1, FUSE_CAP_ASYNC_DIO);
1664  	LL_SET_DEFAULT(1, FUSE_CAP_IOCTL_DIR);
1665  	LL_SET_DEFAULT(1, FUSE_CAP_ATOMIC_O_TRUNC);
1666  	LL_SET_DEFAULT(se->op.write_buf, FUSE_CAP_SPLICE_READ);
1667  	LL_SET_DEFAULT(se->op.getlk && se->op.setlk,
1668  		       FUSE_CAP_POSIX_LOCKS);
1669  	LL_SET_DEFAULT(se->op.flock, FUSE_CAP_FLOCK_LOCKS);
1670  	LL_SET_DEFAULT(se->op.readdirplus, FUSE_CAP_READDIRPLUS);
1671  	LL_SET_DEFAULT(se->op.readdirplus && se->op.readdir,
1672  		       FUSE_CAP_READDIRPLUS_AUTO);
1673  	se->conn.time_gran = 1;
1674  	if (bufsize < FUSE_MIN_READ_BUFFER) {
1675  		fuse_log(FUSE_LOG_ERR, "fuse: warning: buffer size too small: %zu\n",
1676  			bufsize);
1677  		bufsize = FUSE_MIN_READ_BUFFER;
1678  	}
1679  	se->bufsize = bufsize;
1680  	if (se->conn.max_write > bufsize - FUSE_BUFFER_HEADER_SIZE)
1681  		se->conn.max_write = bufsize - FUSE_BUFFER_HEADER_SIZE;
1682  	se->got_init = 1;
1683  	if (se->op.init)
1684  		se->op.init(se->userdata, &se->conn);
1685  	if (se->conn.want & (~se->conn.capable)) {
1686  		fuse_log(FUSE_LOG_ERR, "fuse: error: filesystem requested capabilities "
1687  			"0x%x that are not supported by kernel, aborting.\n",
1688  			se->conn.want & (~se->conn.capable));
1689  		fuse_reply_err(req, EPROTO);
1690  		se->error = -EPROTO;
1691  		fuse_session_exit(se);
1692  		return;
1693  	}
1694  	unsigned max_read_mo = get_max_read(se->mo);
1695  	if (se->conn.max_read != max_read_mo) {
1696  		fuse_log(FUSE_LOG_ERR, "fuse: error: init() and fuse_session_new() "
1697  			"requested different maximum read size (%u vs %u)\n",
1698  			se->conn.max_read, max_read_mo);
1699  		fuse_reply_err(req, EPROTO);
1700  		se->error = -EPROTO;
1701  		fuse_session_exit(se);
1702  		return;
1703  	}
1704  	if (se->conn.max_write < bufsize - FUSE_BUFFER_HEADER_SIZE) {
1705  		se->bufsize = se->conn.max_write + FUSE_BUFFER_HEADER_SIZE;
1706  	}
1707  	if (arg->flags & FUSE_MAX_PAGES) {
1708  		outarg.flags |= FUSE_MAX_PAGES;
1709  		outarg.max_pages = (se->conn.max_write - 1) / getpagesize() + 1;
1710  	}
1711  	outargflags = outarg.flags;
1712  	outargflags |= FUSE_BIG_WRITES;
1713  	if (se->conn.want & FUSE_CAP_ASYNC_READ)
1714  		outargflags |= FUSE_ASYNC_READ;
1715  	if (se->conn.want & FUSE_CAP_POSIX_LOCKS)
1716  		outargflags |= FUSE_POSIX_LOCKS;
1717  	if (se->conn.want & FUSE_CAP_ATOMIC_O_TRUNC)
1718  		outargflags |= FUSE_ATOMIC_O_TRUNC;
1719  	if (se->conn.want & FUSE_CAP_EXPORT_SUPPORT)
1720  		outargflags |= FUSE_EXPORT_SUPPORT;
1721  	if (se->conn.want & FUSE_CAP_DONT_MASK)
1722  		outargflags |= FUSE_DONT_MASK;
1723  	if (se->conn.want & FUSE_CAP_FLOCK_LOCKS)
1724  		outargflags |= FUSE_FLOCK_LOCKS;
1725  	if (se->conn.want & FUSE_CAP_AUTO_INVAL_DATA)
1726  		outargflags |= FUSE_AUTO_INVAL_DATA;
1727  	if (se->conn.want & FUSE_CAP_READDIRPLUS)
1728  		outargflags |= FUSE_DO_READDIRPLUS;
1729  	if (se->conn.want & FUSE_CAP_READDIRPLUS_AUTO)
1730  		outargflags |= FUSE_READDIRPLUS_AUTO;
1731  	if (se->conn.want & FUSE_CAP_ASYNC_DIO)
1732  		outargflags |= FUSE_ASYNC_DIO;
1733  	if (se->conn.want & FUSE_CAP_WRITEBACK_CACHE)
1734  		outargflags |= FUSE_WRITEBACK_CACHE;
1735  	if (se->conn.want & FUSE_CAP_POSIX_ACL)
1736  		outargflags |= FUSE_POSIX_ACL;
1737  	if (se->conn.want & FUSE_CAP_CACHE_SYMLINKS)
1738  		outargflags |= FUSE_CACHE_SYMLINKS;
1739  	if (se->conn.want & FUSE_CAP_EXPLICIT_INVAL_DATA)
1740  		outargflags |= FUSE_EXPLICIT_INVAL_DATA;
1741  	if (se->conn.want & FUSE_CAP_SETXATTR_EXT)
1742  		outargflags |= FUSE_SETXATTR_EXT;
1743  	if (inargflags & FUSE_INIT_EXT) {
1744  		outargflags |= FUSE_INIT_EXT;
1745  		outarg.flags2 = outargflags >> 32;
1746  	}
1747  	outarg.flags = outargflags;
1748  	outarg.max_readahead = se->conn.max_readahead;
1749  	outarg.max_write = se->conn.max_write;
1750  	if (se->conn.proto_minor >= 13) {
1751  		if (se->conn.max_background >= (1 << 16))
1752  			se->conn.max_background = (1 << 16) - 1;
1753  		if (se->conn.congestion_threshold > se->conn.max_background)
1754  			se->conn.congestion_threshold = se->conn.max_background;
1755  		if (!se->conn.congestion_threshold) {
1756  			se->conn.congestion_threshold =
1757  				se->conn.max_background * 3 / 4;
1758  		}
1759  		outarg.max_background = se->conn.max_background;
1760  		outarg.congestion_threshold = se->conn.congestion_threshold;
1761  	}
1762  	if (se->conn.proto_minor >= 23)
1763  		outarg.time_gran = se->conn.time_gran;
1764  	if (se->debug) {
1765  		fuse_log(FUSE_LOG_DEBUG, "   INIT: %u.%u\n", outarg.major, outarg.minor);
1766  		fuse_log(FUSE_LOG_DEBUG, "   flags=0x%08x\n", outarg.flags);
1767  		fuse_log(FUSE_LOG_DEBUG, "   max_readahead=0x%08x\n",
1768  			outarg.max_readahead);
1769  		fuse_log(FUSE_LOG_DEBUG, "   max_write=0x%08x\n", outarg.max_write);
1770  		fuse_log(FUSE_LOG_DEBUG, "   max_background=%i\n",
1771  			outarg.max_background);
1772  		fuse_log(FUSE_LOG_DEBUG, "   congestion_threshold=%i\n",
1773  			outarg.congestion_threshold);
1774  		fuse_log(FUSE_LOG_DEBUG, "   time_gran=%u\n",
1775  			outarg.time_gran);
1776  	}
1777  	if (arg->minor < 5)
1778  		outargsize = FUSE_COMPAT_INIT_OUT_SIZE;
1779  	else if (arg->minor < 23)
1780  		outargsize = FUSE_COMPAT_22_INIT_OUT_SIZE;
1781  	send_reply_ok(req, &outarg, outargsize);
1782  }
1783  static void do_destroy(fuse_req_t req, fuse_ino_t nodeid, const void *inarg)
1784  {
1785  	struct fuse_session *se = req->se;
1786  	(void) nodeid;
1787  	(void) inarg;
1788  	se->got_destroy = 1;
1789  	if (se->op.destroy)
1790  		se->op.destroy(se->userdata);
1791  	send_reply_ok(req, NULL, 0);
1792  }
1793  static void list_del_nreq(struct fuse_notify_req *nreq)
1794  {
1795  	struct fuse_notify_req *prev = nreq->prev;
1796  	struct fuse_notify_req *next = nreq->next;
1797  	prev->next = next;
1798  	next->prev = prev;
1799  }
1800  static void list_add_nreq(struct fuse_notify_req *nreq,
1801  			  struct fuse_notify_req *next)
1802  {
1803  	struct fuse_notify_req *prev = next->prev;
1804  	nreq->next = next;
1805  	nreq->prev = prev;
1806  	prev->next = nreq;
1807  	next->prev = nreq;
1808  }
1809  static void list_init_nreq(struct fuse_notify_req *nreq)
1810  {
1811  	nreq->next = nreq;
1812  	nreq->prev = nreq;
1813  }
1814  static void do_notify_reply(fuse_req_t req, fuse_ino_t nodeid,
1815  			    const void *inarg, const struct fuse_buf *buf)
1816  {
1817  	struct fuse_session *se = req->se;
1818  	struct fuse_notify_req *nreq;
1819  	struct fuse_notify_req *head;
1820  	pthread_mutex_lock(&se->lock);
1821  	head = &se->notify_list;
1822  	for (nreq = head->next; nreq != head; nreq = nreq->next) {
1823  		if (nreq->unique == req->unique) {
1824  			list_del_nreq(nreq);
1825  			break;
1826  		}
1827  	}
1828  	pthread_mutex_unlock(&se->lock);
1829  	if (nreq != head)
1830  		nreq->reply(nreq, req, nodeid, inarg, buf);
1831  }
1832  static int send_notify_iov(struct fuse_session *se, int notify_code,
1833  			   struct iovec *iov, int count)
1834  {
1835  	struct fuse_out_header out;
1836  	if (!se->got_init)
1837  		return -ENOTCONN;
1838  	out.unique = 0;
1839  	out.error = notify_code;
1840  	iov[0].iov_base = &out;
1841  	iov[0].iov_len = sizeof(struct fuse_out_header);
1842  	return fuse_send_msg(se, NULL, iov, count);
1843  }
1844  int fuse_lowlevel_notify_poll(struct fuse_pollhandle *ph)
1845  {
1846  	if (ph != NULL) {
1847  		struct fuse_notify_poll_wakeup_out outarg;
1848  		struct iovec iov[2];
1849  		outarg.kh = ph->kh;
1850  		iov[1].iov_base = &outarg;
1851  		iov[1].iov_len = sizeof(outarg);
1852  		return send_notify_iov(ph->se, FUSE_NOTIFY_POLL, iov, 2);
1853  	} else {
1854  		return 0;
1855  	}
1856  }
1857  int fuse_lowlevel_notify_inval_inode(struct fuse_session *se, fuse_ino_t ino,
1858  				     off_t off, off_t len)
1859  {
1860  	struct fuse_notify_inval_inode_out outarg;
1861  	struct iovec iov[2];
1862  	if (!se)
1863  		return -EINVAL;
1864  	if (se->conn.proto_minor < 12)
1865  		return -ENOSYS;
1866  	outarg.ino = ino;
1867  	outarg.off = off;
1868  	outarg.len = len;
1869  	iov[1].iov_base = &outarg;
1870  	iov[1].iov_len = sizeof(outarg);
1871  	return send_notify_iov(se, FUSE_NOTIFY_INVAL_INODE, iov, 2);
1872  }
1873  int fuse_lowlevel_notify_expire_entry(struct fuse_session *se, fuse_ino_t parent,
1874  				      const char *name, size_t namelen,
1875  				      enum fuse_expire_flags flags)
1876  {
1877  	struct fuse_notify_inval_entry_out outarg;
1878  	struct iovec iov[3];
1879  	if (!se)
1880  		return -EINVAL;
1881  	if (se->conn.proto_minor < 12)
1882  		return -ENOSYS;
1883  	outarg.parent = parent;
1884  	outarg.namelen = namelen;
1885  	outarg.flags = 0;
1886  	if (flags & FUSE_LL_EXPIRE_ONLY)
1887  		outarg.flags |= FUSE_EXPIRE_ONLY;
1888  	iov[1].iov_base = &outarg;
1889  	iov[1].iov_len = sizeof(outarg);
1890  	iov[2].iov_base = (void *)name;
1891  	iov[2].iov_len = namelen + 1;
1892  	return send_notify_iov(se, FUSE_NOTIFY_INVAL_ENTRY, iov, 3);
1893  }
1894  int fuse_lowlevel_notify_inval_entry(struct fuse_session *se, fuse_ino_t parent,
1895  				     const char *name, size_t namelen)
1896  {
1897  	return fuse_lowlevel_notify_expire_entry(se, parent, name, namelen, 0);
1898  }
1899  int fuse_lowlevel_notify_delete(struct fuse_session *se,
1900  				fuse_ino_t parent, fuse_ino_t child,
1901  				const char *name, size_t namelen)
1902  {
1903  	struct fuse_notify_delete_out outarg;
1904  	struct iovec iov[3];
1905  	if (!se)
1906  		return -EINVAL;
1907  	if (se->conn.proto_minor < 18)
1908  		return -ENOSYS;
1909  	outarg.parent = parent;
1910  	outarg.child = child;
1911  	outarg.namelen = namelen;
1912  	outarg.padding = 0;
1913  	iov[1].iov_base = &outarg;
1914  	iov[1].iov_len = sizeof(outarg);
1915  	iov[2].iov_base = (void *)name;
1916  	iov[2].iov_len = namelen + 1;
1917  	return send_notify_iov(se, FUSE_NOTIFY_DELETE, iov, 3);
1918  }
1919  int fuse_lowlevel_notify_store(struct fuse_session *se, fuse_ino_t ino,
1920  			       off_t offset, struct fuse_bufvec *bufv,
1921  			       enum fuse_buf_copy_flags flags)
1922  {
1923  	struct fuse_out_header out;
1924  	struct fuse_notify_store_out outarg;
1925  	struct iovec iov[3];
1926  	size_t size = fuse_buf_size(bufv);
1927  	int res;
1928  	if (!se)
1929  		return -EINVAL;
1930  	if (se->conn.proto_minor < 15)
1931  		return -ENOSYS;
1932  	out.unique = 0;
1933  	out.error = FUSE_NOTIFY_STORE;
1934  	outarg.nodeid = ino;
1935  	outarg.offset = offset;
1936  	outarg.size = size;
1937  	outarg.padding = 0;
1938  	iov[0].iov_base = &out;
1939  	iov[0].iov_len = sizeof(out);
1940  	iov[1].iov_base = &outarg;
1941  	iov[1].iov_len = sizeof(outarg);
1942  	res = fuse_send_data_iov(se, NULL, iov, 2, bufv, flags);
1943  	if (res > 0)
1944  		res = -res;
1945  	return res;
1946  }
1947  struct fuse_retrieve_req {
1948  	struct fuse_notify_req nreq;
1949  	void *cookie;
1950  };
1951  static void fuse_ll_retrieve_reply(struct fuse_notify_req *nreq,
1952  				   fuse_req_t req, fuse_ino_t ino,
1953  				   const void *inarg,
1954  				   const struct fuse_buf *ibuf)
1955  {
1956  	struct fuse_session *se = req->se;
1957  	struct fuse_retrieve_req *rreq =
1958  		container_of(nreq, struct fuse_retrieve_req, nreq);
1959  	const struct fuse_notify_retrieve_in *arg = inarg;
1960  	struct fuse_bufvec bufv = {
1961  		.buf[0] = *ibuf,
1962  		.count = 1,
1963  	};
1964  	if (!(bufv.buf[0].flags & FUSE_BUF_IS_FD))
1965  		bufv.buf[0].mem = PARAM(arg);
1966  	bufv.buf[0].size -= sizeof(struct fuse_in_header) +
1967  		sizeof(struct fuse_notify_retrieve_in);
1968  	if (bufv.buf[0].size < arg->size) {
1969  		fuse_log(FUSE_LOG_ERR, "fuse: retrieve reply: buffer size too small\n");
1970  		fuse_reply_none(req);
1971  		goto out;
1972  	}
1973  	bufv.buf[0].size = arg->size;
1974  	if (se->op.retrieve_reply) {
1975  		se->op.retrieve_reply(req, rreq->cookie, ino,
1976  					  arg->offset, &bufv);
1977  	} else {
1978  		fuse_reply_none(req);
1979  	}
1980  out:
1981  	free(rreq);
1982  	if ((ibuf->flags & FUSE_BUF_IS_FD) && bufv.idx < bufv.count)
1983  		fuse_ll_clear_pipe(se);
1984  }
1985  int fuse_lowlevel_notify_retrieve(struct fuse_session *se, fuse_ino_t ino,
1986  				  size_t size, off_t offset, void *cookie)
1987  {
1988  	struct fuse_notify_retrieve_out outarg;
1989  	struct iovec iov[2];
1990  	struct fuse_retrieve_req *rreq;
1991  	int err;
1992  	if (!se)
1993  		return -EINVAL;
1994  	if (se->conn.proto_minor < 15)
1995  		return -ENOSYS;
1996  	rreq = malloc(sizeof(*rreq));
1997  	if (rreq == NULL)
1998  		return -ENOMEM;
1999  	pthread_mutex_lock(&se->lock);
2000  	rreq->cookie = cookie;
2001  	rreq->nreq.unique = se->notify_ctr++;
2002  	rreq->nreq.reply = fuse_ll_retrieve_reply;
2003  	list_add_nreq(&rreq->nreq, &se->notify_list);
2004  	pthread_mutex_unlock(&se->lock);
2005  	outarg.notify_unique = rreq->nreq.unique;
2006  	outarg.nodeid = ino;
2007  	outarg.offset = offset;
2008  	outarg.size = size;
2009  	outarg.padding = 0;
2010  	iov[1].iov_base = &outarg;
2011  	iov[1].iov_len = sizeof(outarg);
2012  	err = send_notify_iov(se, FUSE_NOTIFY_RETRIEVE, iov, 2);
2013  	if (err) {
2014  		pthread_mutex_lock(&se->lock);
2015  		list_del_nreq(&rreq->nreq);
2016  		pthread_mutex_unlock(&se->lock);
2017  		free(rreq);
2018  	}
2019  	return err;
2020  }
2021  void *fuse_req_userdata(fuse_req_t req)
2022  {
2023  	return req->se->userdata;
2024  }
2025  const struct fuse_ctx *fuse_req_ctx(fuse_req_t req)
2026  {
2027  	return &req->ctx;
2028  }
2029  void fuse_req_interrupt_func(fuse_req_t req, fuse_interrupt_func_t func,
2030  			     void *data)
2031  {
2032  	pthread_mutex_lock(&req->lock);
2033  	pthread_mutex_lock(&req->se->lock);
2034  	req->u.ni.func = func;
2035  	req->u.ni.data = data;
2036  	pthread_mutex_unlock(&req->se->lock);
2037  	if (req->interrupted && func)
2038  		func(req, data);
2039  	pthread_mutex_unlock(&req->lock);
2040  }
2041  int fuse_req_interrupted(fuse_req_t req)
2042  {
2043  	int interrupted;
2044  	pthread_mutex_lock(&req->se->lock);
2045  	interrupted = req->interrupted;
2046  	pthread_mutex_unlock(&req->se->lock);
2047  	return interrupted;
2048  }
2049  static struct {
2050  	void (*func)(fuse_req_t, fuse_ino_t, const void *);
2051  	const char *name;
2052  } fuse_ll_ops[] = {
2053  	[FUSE_LOOKUP]	   = { do_lookup,      "LOOKUP"	     },
2054  	[FUSE_FORGET]	   = { do_forget,      "FORGET"	     },
2055  	[FUSE_GETATTR]	   = { do_getattr,     "GETATTR"     },
2056  	[FUSE_SETATTR]	   = { do_setattr,     "SETATTR"     },
2057  	[FUSE_READLINK]	   = { do_readlink,    "READLINK"    },
2058  	[FUSE_SYMLINK]	   = { do_symlink,     "SYMLINK"     },
2059  	[FUSE_MKNOD]	   = { do_mknod,       "MKNOD"	     },
2060  	[FUSE_MKDIR]	   = { do_mkdir,       "MKDIR"	     },
2061  	[FUSE_UNLINK]	   = { do_unlink,      "UNLINK"	     },
2062  	[FUSE_RMDIR]	   = { do_rmdir,       "RMDIR"	     },
2063  	[FUSE_RENAME]	   = { do_rename,      "RENAME"	     },
2064  	[FUSE_LINK]	   = { do_link,	       "LINK"	     },
2065  	[FUSE_OPEN]	   = { do_open,	       "OPEN"	     },
2066  	[FUSE_READ]	   = { do_read,	       "READ"	     },
2067  	[FUSE_WRITE]	   = { do_write,       "WRITE"	     },
2068  	[FUSE_STATFS]	   = { do_statfs,      "STATFS"	     },
2069  	[FUSE_RELEASE]	   = { do_release,     "RELEASE"     },
2070  	[FUSE_FSYNC]	   = { do_fsync,       "FSYNC"	     },
2071  	[FUSE_SETXATTR]	   = { do_setxattr,    "SETXATTR"    },
2072  	[FUSE_GETXATTR]	   = { do_getxattr,    "GETXATTR"    },
2073  	[FUSE_LISTXATTR]   = { do_listxattr,   "LISTXATTR"   },
2074  	[FUSE_REMOVEXATTR] = { do_removexattr, "REMOVEXATTR" },
2075  	[FUSE_FLUSH]	   = { do_flush,       "FLUSH"	     },
2076  	[FUSE_INIT]	   = { do_init,	       "INIT"	     },
2077  	[FUSE_OPENDIR]	   = { do_opendir,     "OPENDIR"     },
2078  	[FUSE_READDIR]	   = { do_readdir,     "READDIR"     },
2079  	[FUSE_RELEASEDIR]  = { do_releasedir,  "RELEASEDIR"  },
2080  	[FUSE_FSYNCDIR]	   = { do_fsyncdir,    "FSYNCDIR"    },
2081  	[FUSE_GETLK]	   = { do_getlk,       "GETLK"	     },
2082  	[FUSE_SETLK]	   = { do_setlk,       "SETLK"	     },
2083  	[FUSE_SETLKW]	   = { do_setlkw,      "SETLKW"	     },
2084  	[FUSE_ACCESS]	   = { do_access,      "ACCESS"	     },
2085  	[FUSE_CREATE]	   = { do_create,      "CREATE"	     },
2086  	[FUSE_INTERRUPT]   = { do_interrupt,   "INTERRUPT"   },
2087  	[FUSE_BMAP]	   = { do_bmap,	       "BMAP"	     },
2088  	[FUSE_IOCTL]	   = { do_ioctl,       "IOCTL"	     },
2089  	[FUSE_POLL]	   = { do_poll,        "POLL"	     },
2090  	[FUSE_FALLOCATE]   = { do_fallocate,   "FALLOCATE"   },
2091  	[FUSE_DESTROY]	   = { do_destroy,     "DESTROY"     },
2092  	[FUSE_NOTIFY_REPLY] = { (void *) 1,    "NOTIFY_REPLY" },
2093  	[FUSE_BATCH_FORGET] = { do_batch_forget, "BATCH_FORGET" },
2094  	[FUSE_READDIRPLUS] = { do_readdirplus,	"READDIRPLUS"},
2095  	[FUSE_RENAME2]     = { do_rename2,      "RENAME2"    },
2096  	[FUSE_COPY_FILE_RANGE] = { do_copy_file_range, "COPY_FILE_RANGE" },
2097  	[FUSE_LSEEK]	   = { do_lseek,       "LSEEK"	     },
2098  	[CUSE_INIT]	   = { cuse_lowlevel_init, "CUSE_INIT"   },
2099  };
2100  #define FUSE_MAXOP (sizeof(fuse_ll_ops) / sizeof(fuse_ll_ops[0]))
2101  static const char *opname(enum fuse_opcode opcode)
2102  {
2103  	if (opcode >= FUSE_MAXOP || !fuse_ll_ops[opcode].name)
2104  		return "???";
2105  	else
2106  		return fuse_ll_ops[opcode].name;
2107  }
2108  static int fuse_ll_copy_from_pipe(struct fuse_bufvec *dst,
2109  				  struct fuse_bufvec *src)
2110  {
2111  	ssize_t res = fuse_buf_copy(dst, src, 0);
2112  	if (res < 0) {
2113  		fuse_log(FUSE_LOG_ERR, "fuse: copy from pipe: %s\n", strerror(-res));
2114  		return res;
2115  	}
2116  	if ((size_t)res < fuse_buf_size(dst)) {
2117  		fuse_log(FUSE_LOG_ERR, "fuse: copy from pipe: short read\n");
2118  		return -1;
2119  	}
2120  	return 0;
2121  }
2122  void fuse_session_process_buf(struct fuse_session *se,
2123  			      const struct fuse_buf *buf)
2124  {
2125  	fuse_session_process_buf_int(se, buf, NULL);
2126  }
2127  void fuse_session_process_buf_int(struct fuse_session *se,
2128  				  const struct fuse_buf *buf, struct fuse_chan *ch)
2129  {
2130  	const size_t write_header_size = sizeof(struct fuse_in_header) +
2131  		sizeof(struct fuse_write_in);
2132  	struct fuse_bufvec bufv = { .buf[0] = *buf, .count = 1 };
2133  	struct fuse_bufvec tmpbuf = FUSE_BUFVEC_INIT(write_header_size);
2134  	struct fuse_in_header *in;
2135  	const void *inarg;
2136  	struct fuse_req *req;
2137  	void *mbuf = NULL;
2138  	int err;
2139  	int res;
2140  	if (buf->flags & FUSE_BUF_IS_FD) {
2141  		if (buf->size < tmpbuf.buf[0].size)
2142  			tmpbuf.buf[0].size = buf->size;
2143  		mbuf = malloc(tmpbuf.buf[0].size);
2144  		if (mbuf == NULL) {
2145  			fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate header\n");
2146  			goto clear_pipe;
2147  		}
2148  		tmpbuf.buf[0].mem = mbuf;
2149  		res = fuse_ll_copy_from_pipe(&tmpbuf, &bufv);
2150  		if (res < 0)
2151  			goto clear_pipe;
2152  		in = mbuf;
2153  	} else {
2154  		in = buf->mem;
2155  	}
2156  	if (se->debug) {
2157  		fuse_log(FUSE_LOG_DEBUG,
2158  			"unique: %llu, opcode: %s (%i), nodeid: %llu, insize: %zu, pid: %u\n",
2159  			(unsigned long long) in->unique,
2160  			opname((enum fuse_opcode) in->opcode), in->opcode,
2161  			(unsigned long long) in->nodeid, buf->size, in->pid);
2162  	}
2163  	req = fuse_ll_alloc_req(se);
2164  	if (req == NULL) {
2165  		struct fuse_out_header out = {
2166  			.unique = in->unique,
2167  			.error = -ENOMEM,
2168  		};
2169  		struct iovec iov = {
2170  			.iov_base = &out,
2171  			.iov_len = sizeof(struct fuse_out_header),
2172  		};
2173  		fuse_send_msg(se, ch, &iov, 1);
2174  		goto clear_pipe;
2175  	}
2176  	req->unique = in->unique;
2177  	req->ctx.uid = in->uid;
2178  	req->ctx.gid = in->gid;
2179  	req->ctx.pid = in->pid;
2180  	req->ch = ch ? fuse_chan_get(ch) : NULL;
2181  	err = EIO;
2182  	if (!se->got_init) {
2183  		enum fuse_opcode expected;
2184  		expected = se->cuse_data ? CUSE_INIT : FUSE_INIT;
2185  		if (in->opcode != expected)
2186  			goto reply_err;
2187  	} else if (in->opcode == FUSE_INIT || in->opcode == CUSE_INIT)
2188  		goto reply_err;
2189  	err = EACCES;
2190  	if (se->deny_others && in->uid != se->owner && in->uid != 0 &&
2191  		 in->opcode != FUSE_INIT && in->opcode != FUSE_READ &&
2192  		 in->opcode != FUSE_WRITE && in->opcode != FUSE_FSYNC &&
2193  		 in->opcode != FUSE_RELEASE && in->opcode != FUSE_READDIR &&
2194  		 in->opcode != FUSE_FSYNCDIR && in->opcode != FUSE_RELEASEDIR &&
2195  		 in->opcode != FUSE_NOTIFY_REPLY &&
2196  		 in->opcode != FUSE_READDIRPLUS)
2197  		goto reply_err;
2198  	err = ENOSYS;
2199  	if (in->opcode >= FUSE_MAXOP || !fuse_ll_ops[in->opcode].func)
2200  		goto reply_err;
2201  	if (in->opcode != FUSE_INTERRUPT) {
2202  		struct fuse_req *intr;
2203  		pthread_mutex_lock(&se->lock);
2204  		intr = check_interrupt(se, req);
2205  		list_add_req(req, &se->list);
2206  		pthread_mutex_unlock(&se->lock);
2207  		if (intr)
2208  			fuse_reply_err(intr, EAGAIN);
2209  	}
2210  	if ((buf->flags & FUSE_BUF_IS_FD) && write_header_size < buf->size &&
2211  	    (in->opcode != FUSE_WRITE || !se->op.write_buf) &&
2212  	    in->opcode != FUSE_NOTIFY_REPLY) {
2213  		void *newmbuf;
2214  		err = ENOMEM;
2215  		newmbuf = realloc(mbuf, buf->size);
2216  		if (newmbuf == NULL)
2217  			goto reply_err;
2218  		mbuf = newmbuf;
2219  		tmpbuf = FUSE_BUFVEC_INIT(buf->size - write_header_size);
2220  		tmpbuf.buf[0].mem = (char *)mbuf + write_header_size;
2221  		res = fuse_ll_copy_from_pipe(&tmpbuf, &bufv);
2222  		err = -res;
2223  		if (res < 0)
2224  			goto reply_err;
2225  		in = mbuf;
2226  	}
2227  	inarg = (void *) &in[1];
2228  	if (in->opcode == FUSE_WRITE && se->op.write_buf)
2229  		do_write_buf(req, in->nodeid, inarg, buf);
2230  	else if (in->opcode == FUSE_NOTIFY_REPLY)
2231  		do_notify_reply(req, in->nodeid, inarg, buf);
2232  	else
2233  		fuse_ll_ops[in->opcode].func(req, in->nodeid, inarg);
2234  out_free:
2235  	free(mbuf);
2236  	return;
2237  reply_err:
2238  	fuse_reply_err(req, err);
2239  clear_pipe:
2240  	if (buf->flags & FUSE_BUF_IS_FD)
2241  		fuse_ll_clear_pipe(se);
2242  	goto out_free;
2243  }
2244  #define LL_OPTION(n,o,v) \
2245  	{ n, offsetof(struct fuse_session, o), v }
2246  static const struct fuse_opt fuse_ll_opts[] = {
2247  	LL_OPTION("debug", debug, 1),
2248  	LL_OPTION("-d", debug, 1),
2249  	LL_OPTION("--debug", debug, 1),
2250  	LL_OPTION("allow_root", deny_others, 1),
2251  	FUSE_OPT_END
2252  };
2253  void fuse_lowlevel_version(void)
2254  {
2255  	printf("using FUSE kernel interface version %i.%i\n",
2256  	       FUSE_KERNEL_VERSION, FUSE_KERNEL_MINOR_VERSION);
2257  	fuse_mount_version();
2258  }
2259  void fuse_lowlevel_help(void)
2260  {
2261  	printf(
2262  "    -o allow_other         allow access by all users\n"
2263  "    -o allow_root          allow access by root\n"
2264  "    -o auto_unmount        auto unmount on process termination\n");
2265  }
2266  void fuse_session_destroy(struct fuse_session *se)
2267  {
2268  	struct fuse_ll_pipe *llp;
2269  	if (se->got_init && !se->got_destroy) {
2270  		if (se->op.destroy)
2271  			se->op.destroy(se->userdata);
2272  	}
2273  	llp = pthread_getspecific(se->pipe_key);
2274  	if (llp != NULL)
2275  		fuse_ll_pipe_free(llp);
2276  	pthread_key_delete(se->pipe_key);
2277  	pthread_mutex_destroy(&se->lock);
2278  	free(se->cuse_data);
2279  	if (se->fd != -1)
2280  		close(se->fd);
2281  	if (se->io != NULL)
2282  		free(se->io);
2283  	destroy_mount_opts(se->mo);
2284  	free(se);
2285  }
2286  static void fuse_ll_pipe_destructor(void *data)
2287  {
2288  	struct fuse_ll_pipe *llp = data;
2289  	fuse_ll_pipe_free(llp);
2290  }
2291  int fuse_session_receive_buf(struct fuse_session *se, struct fuse_buf *buf)
2292  {
2293  	return fuse_session_receive_buf_int(se, buf, NULL);
2294  }
2295  int fuse_session_receive_buf_int(struct fuse_session *se, struct fuse_buf *buf,
2296  				 struct fuse_chan *ch)
2297  {
2298  	int err;
2299  	ssize_t res;
2300  #ifdef HAVE_SPLICE
2301  	size_t bufsize = se->bufsize;
2302  	struct fuse_ll_pipe *llp;
2303  	struct fuse_buf tmpbuf;
2304  	if (se->conn.proto_minor < 14 || !(se->conn.want & FUSE_CAP_SPLICE_READ))
2305  		goto fallback;
2306  	llp = fuse_ll_get_pipe(se);
2307  	if (llp == NULL)
2308  		goto fallback;
2309  	if (llp->size < bufsize) {
2310  		if (llp->can_grow) {
2311  			res = fcntl(llp->pipe[0], F_SETPIPE_SZ, bufsize);
2312  			if (res == -1) {
2313  				llp->can_grow = 0;
2314  				res = grow_pipe_to_max(llp->pipe[0]);
2315  				if (res > 0)
2316  					llp->size = res;
2317  				goto fallback;
2318  			}
2319  			llp->size = res;
2320  		}
2321  		if (llp->size < bufsize)
2322  			goto fallback;
2323  	}
2324  	if (se->io != NULL && se->io->splice_receive != NULL) {
2325  		res = se->io->splice_receive(ch ? ch->fd : se->fd, NULL,
2326  						     llp->pipe[1], NULL, bufsize, 0,
2327  						     se->userdata);
2328  	} else {
2329  		res = splice(ch ? ch->fd : se->fd, NULL, llp->pipe[1], NULL,
2330  				 bufsize, 0);
2331  	}
2332  	err = errno;
2333  	if (fuse_session_exited(se))
2334  		return 0;
2335  	if (res == -1) {
2336  		if (err == ENODEV) {
2337  			fuse_session_exit(se);
2338  			return 0;
2339  		}
2340  		if (err != EINTR && err != EAGAIN)
2341  			perror("fuse: splice from device");
2342  		return -err;
2343  	}
2344  	if (res < sizeof(struct fuse_in_header)) {
2345  		fuse_log(FUSE_LOG_ERR, "short splice from fuse device\n");
2346  		return -EIO;
2347  	}
2348  	tmpbuf = (struct fuse_buf) {
2349  		.size = res,
2350  		.flags = FUSE_BUF_IS_FD,
2351  		.fd = llp->pipe[0],
2352  	};
2353  	if (res < sizeof(struct fuse_in_header) +
2354  	    sizeof(struct fuse_write_in) + pagesize) {
2355  		struct fuse_bufvec src = { .buf[0] = tmpbuf, .count = 1 };
2356  		struct fuse_bufvec dst = { .count = 1 };
2357  		if (!buf->mem) {
2358  			buf->mem = malloc(se->bufsize);
2359  			if (!buf->mem) {
2360  				fuse_log(FUSE_LOG_ERR,
2361  					"fuse: failed to allocate read buffer\n");
2362  				return -ENOMEM;
2363  			}
2364  		}
2365  		buf->size = se->bufsize;
2366  		buf->flags = 0;
2367  		dst.buf[0] = *buf;
2368  		res = fuse_buf_copy(&dst, &src, 0);
2369  		if (res < 0) {
2370  			fuse_log(FUSE_LOG_ERR, "fuse: copy from pipe: %s\n",
2371  				strerror(-res));
2372  			fuse_ll_clear_pipe(se);
2373  			return res;
2374  		}
2375  		if (res < tmpbuf.size) {
2376  			fuse_log(FUSE_LOG_ERR, "fuse: copy from pipe: short read\n");
2377  			fuse_ll_clear_pipe(se);
2378  			return -EIO;
2379  		}
2380  		assert(res == tmpbuf.size);
2381  	} else {
2382  		buf->fd = tmpbuf.fd;
2383  		buf->flags = tmpbuf.flags;
2384  	}
2385  	buf->size = tmpbuf.size;
2386  	return res;
2387  fallback:
2388  #endif
2389  	if (!buf->mem) {
2390  		buf->mem = malloc(se->bufsize);
2391  		if (!buf->mem) {
2392  			fuse_log(FUSE_LOG_ERR,
2393  				"fuse: failed to allocate read buffer\n");
2394  			return -ENOMEM;
2395  		}
2396  	}
2397  restart:
2398  	if (se->io != NULL) {
2399  		res = se->io->read(ch ? ch->fd : se->fd, buf->mem, se->bufsize,
2400  					 se->userdata);
2401  	} else {
2402  		res = read(ch ? ch->fd : se->fd, buf->mem, se->bufsize);
2403  	}
2404  	err = errno;
2405  	if (fuse_session_exited(se))
2406  		return 0;
2407  	if (res == -1) {
2408  		if (err == ENOENT)
2409  			goto restart;
2410  		if (err == ENODEV) {
2411  			fuse_session_exit(se);
2412  			return 0;
2413  		}
2414  		if (err != EINTR && err != EAGAIN)
2415  			perror("fuse: reading device");
2416  		return -err;
2417  	}
2418  	if ((size_t) res < sizeof(struct fuse_in_header)) {
2419  		fuse_log(FUSE_LOG_ERR, "short read on fuse device\n");
2420  		return -EIO;
2421  	}
2422  	buf->size = res;
2423  	return res;
2424  }
2425  struct fuse_session *fuse_session_new(struct fuse_args *args,
2426  				      const struct fuse_lowlevel_ops *op,
2427  				      size_t op_size, void *userdata)
2428  {
2429  	int err;
2430  	struct fuse_session *se;
2431  	struct mount_opts *mo;
2432  	if (sizeof(struct fuse_lowlevel_ops) < op_size) {
2433  		fuse_log(FUSE_LOG_ERR, "fuse: warning: library too old, some operations may not work\n");
2434  		op_size = sizeof(struct fuse_lowlevel_ops);
2435  	}
2436  	if (args->argc == 0) {
2437  		fuse_log(FUSE_LOG_ERR, "fuse: empty argv passed to fuse_session_new().\n");
2438  		return NULL;
2439  	}
2440  	se = (struct fuse_session *) calloc(1, sizeof(struct fuse_session));
2441  	if (se == NULL) {
2442  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate fuse object\n");
2443  		goto out1;
2444  	}
2445  	se->fd = -1;
2446  	se->conn.max_write = UINT_MAX;
2447  	se->conn.max_readahead = UINT_MAX;
2448  	if(fuse_opt_parse(args, se, fuse_ll_opts, NULL) == -1)
2449  		goto out2;
2450  	if(se->deny_others) {
2451  		if(fuse_opt_add_arg(args, "-oallow_other") == -1)
2452  			goto out2;
2453  	}
2454  	mo = parse_mount_opts(args);
2455  	if (mo == NULL)
2456  		goto out3;
2457  	if(args->argc == 1 &&
2458  	   args->argv[0][0] == '-') {
2459  		fuse_log(FUSE_LOG_ERR, "fuse: warning: argv[0] looks like an option, but "
2460  			"will be ignored\n");
2461  	} else if (args->argc != 1) {
2462  		int i;
2463  		fuse_log(FUSE_LOG_ERR, "fuse: unknown option(s): `");
2464  		for(i = 1; i < args->argc-1; i++)
2465  			fuse_log(FUSE_LOG_ERR, "%s ", args->argv[i]);
2466  		fuse_log(FUSE_LOG_ERR, "%s'\n", args->argv[i]);
2467  		goto out4;
2468  	}
2469  	if (se->debug)
2470  		fuse_log(FUSE_LOG_DEBUG, "FUSE library version: %s\n", PACKAGE_VERSION);
2471  	se->bufsize = FUSE_MAX_MAX_PAGES * getpagesize() +
2472  		FUSE_BUFFER_HEADER_SIZE;
2473  	list_init_req(&se->list);
2474  	list_init_req(&se->interrupts);
2475  	list_init_nreq(&se->notify_list);
2476  	se->notify_ctr = 1;
2477  	pthread_mutex_init(&se->lock, NULL);
2478  	err = pthread_key_create(&se->pipe_key, fuse_ll_pipe_destructor);
2479  	if (err) {
2480  		fuse_log(FUSE_LOG_ERR, "fuse: failed to create thread specific key: %s\n",
2481  			strerror(err));
2482  		goto out5;
2483  	}
2484  	memcpy(&se->op, op, op_size);
2485  	se->owner = getuid();
2486  	se->userdata = userdata;
2487  	se->mo = mo;
2488  	return se;
2489  out5:
2490  	pthread_mutex_destroy(&se->lock);
2491  out4:
2492  	fuse_opt_free_args(args);
2493  out3:
2494  	if (mo != NULL)
2495  		destroy_mount_opts(mo);
2496  out2:
2497  	free(se);
2498  out1:
2499  	return NULL;
2500  }
2501  int fuse_session_custom_io(struct fuse_session *se, const struct fuse_custom_io *io,
2502  			   int fd)
2503  {
2504  	if (fd < 0) {
2505  		fuse_log(FUSE_LOG_ERR, "Invalid file descriptor value %d passed to "
2506  			"fuse_session_custom_io()\n", fd);
2507  		return -EBADF;
2508  	}
2509  	if (io == NULL) {
2510  		fuse_log(FUSE_LOG_ERR, "No custom IO passed to "
2511  			"fuse_session_custom_io()\n");
2512  		return -EINVAL;
2513  	} else if (io->read == NULL || io->writev == NULL) {
2514  		fuse_log(FUSE_LOG_ERR, "io passed to fuse_session_custom_io() must "
2515  			"implement both io->read() and io->writev\n");
2516  		return -EINVAL;
2517  	}
2518  	se->io = malloc(sizeof(struct fuse_custom_io));
2519  	if (se->io == NULL) {
2520  		fuse_log(FUSE_LOG_ERR, "Failed to allocate memory for custom io. "
2521  			"Error: %s\n", strerror(errno));
2522  		return -errno;
2523  	}
2524  	se->fd = fd;
2525  	*se->io = *io;
2526  	return 0;
2527  }
2528  int fuse_session_mount(struct fuse_session *se, const char *mountpoint)
2529  {
2530  	int fd;
2531  	do {
2532  		fd = open("/dev/null", O_RDWR);
2533  		if (fd > 2)
2534  			close(fd);
2535  	} while (fd >= 0 && fd <= 2);
2536  	fd = fuse_mnt_parse_fuse_fd(mountpoint);
2537  	if (fd != -1) {
2538  		if (fcntl(fd, F_GETFD) == -1) {
2539  			fuse_log(FUSE_LOG_ERR,
2540  				"fuse: Invalid file descriptor /dev/fd/%u\n",
2541  				fd);
2542  			return -1;
2543  		}
2544  		se->fd = fd;
2545  		return 0;
2546  	}
2547  	fd = fuse_kern_mount(mountpoint, se->mo);
2548  	if (fd == -1)
2549  		return -1;
2550  	se->fd = fd;
2551  	se->mountpoint = strdup(mountpoint);
2552  	if (se->mountpoint == NULL)
2553  		goto error_out;
2554  	return 0;
2555  error_out:
2556  	fuse_kern_unmount(mountpoint, fd);
2557  	return -1;
2558  }
2559  int fuse_session_fd(struct fuse_session *se)
2560  {
2561  	return se->fd;
2562  }
2563  void fuse_session_unmount(struct fuse_session *se)
2564  {
2565  	if (se->mountpoint != NULL) {
2566  		fuse_kern_unmount(se->mountpoint, se->fd);
2567  		se->fd = -1;
2568  		free(se->mountpoint);
2569  		se->mountpoint = NULL;
2570  	}
2571  }
2572  #ifdef linux
2573  int fuse_req_getgroups(fuse_req_t req, int size, gid_t list[])
2574  {
2575  	char *buf;
2576  	size_t bufsize = 1024;
2577  	char path[128];
2578  	int ret;
2579  	int fd;
2580  	unsigned long pid = req->ctx.pid;
2581  	char *s;
2582  	sprintf(path, "/proc/%lu/task/%lu/status", pid, pid);
2583  retry:
2584  	buf = malloc(bufsize);
2585  	if (buf == NULL)
2586  		return -ENOMEM;
2587  	ret = -EIO;
2588  	fd = open(path, O_RDONLY);
2589  	if (fd == -1)
2590  		goto out_free;
2591  	ret = read(fd, buf, bufsize);
2592  	close(fd);
2593  	if (ret < 0) {
2594  		ret = -EIO;
2595  		goto out_free;
2596  	}
2597  	if ((size_t)ret == bufsize) {
2598  		free(buf);
2599  		bufsize *= 4;
2600  		goto retry;
2601  	}
2602  	ret = -EIO;
2603  	s = strstr(buf, "\nGroups:");
2604  	if (s == NULL)
2605  		goto out_free;
2606  	s += 8;
2607  	ret = 0;
2608  	while (1) {
2609  		char *end;
2610  		unsigned long val = strtoul(s, &end, 0);
2611  		if (end == s)
2612  			break;
2613  		s = end;
2614  		if (ret < size)
2615  			list[ret] = val;
2616  		ret++;
2617  	}
2618  out_free:
2619  	free(buf);
2620  	return ret;
2621  }
2622  #else &bsol;* linux */
2623  int fuse_req_getgroups(fuse_req_t req, int size, gid_t list[])
2624  {
2625  	(void) req; (void) size; (void) list;
2626  	return -ENOSYS;
2627  }
2628  #endif
2629  __attribute__((no_sanitize_thread))
2630  void fuse_session_exit(struct fuse_session *se)
2631  {
2632  	se->exited = 1;
2633  }
2634  __attribute__((no_sanitize_thread))
2635  void fuse_session_reset(struct fuse_session *se)
2636  {
2637  	se->exited = 0;
2638  	se->error = 0;
2639  }
2640  __attribute__((no_sanitize_thread))
2641  int fuse_session_exited(struct fuse_session *se)
2642  {
2643  	return se->exited;
2644  }
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-frame_enc.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from libfuse-MDEwOlJlcG9zaXRvcnk0ODI5NjE3Nw==-flat-fuse_lowlevel.c</div>
                </div>
                <div class="column column_space"><pre><code>281    pos3 = VP8BitWriterPos(bw);
282    it->luma_bits_ = pos2 - pos1;
283    it->uv_bits_ = pos3 - pos2;
284    it->bit_count_[segment][i16] += it->luma_bits_;
285    it->bit_count_[segment][2] += it->uv_bits_;
286    VP8IteratorBytesToNz(it);
287  }
288  static void RecordResiduals(VP8EncIterator* const it,
</pre></code></div>
                <div class="column column_space"><pre><code>49  	attr->mtime	= stbuf->st_mtime;
50  	attr->ctime	= stbuf->st_ctime;
51  	attr->atimensec = ST_ATIM_NSEC(stbuf);
52  	attr->mtimensec = ST_MTIM_NSEC(stbuf);
53  	attr->ctimensec = ST_CTIM_NSEC(stbuf);
54  }
55  static void convert_attr(const struct fuse_setattr_in *attr, struct stat *stbuf)
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    