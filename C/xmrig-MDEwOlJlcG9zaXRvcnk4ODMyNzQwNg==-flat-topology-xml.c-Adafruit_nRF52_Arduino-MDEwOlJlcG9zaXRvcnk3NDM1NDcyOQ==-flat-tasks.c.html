
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 15, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-topology-xml.c</h3>
            <pre><code>1  #include "private/autogen/config.h"
2  #include "hwloc.h"
3  #include "private/xml.h"
4  #include "private/private.h"
5  #include "private/misc.h"
6  #include "private/debug.h"
7  #include <math.h>
8  int
9  hwloc__xml_verbose(void)
10  {
11    static int checked = 0;
12    static int verbose = 0;
13    if (!checked) {
14      const char *env = getenv("HWLOC_XML_VERBOSE");
15      if (env)
16        verbose = atoi(env);
17      checked = 1;
18    }
19    return verbose;
20  }
21  static int
22  hwloc_nolibxml_import(void)
23  {
24    static int checked = 0;
25    static int nolibxml = 0;
26    if (!checked) {
27      const char *env = getenv("HWLOC_LIBXML");
28      if (env) {
29        nolibxml = !atoi(env);
30      } else {
31        env = getenv("HWLOC_LIBXML_IMPORT");
32        if (env)
33  	nolibxml = !atoi(env);
34      }
35      checked = 1;
36    }
37    return nolibxml;
38  }
39  static int
40  hwloc_nolibxml_export(void)
41  {
42    static int checked = 0;
43    static int nolibxml = 0;
44    if (!checked) {
45      const char *env = getenv("HWLOC_LIBXML");
46      if (env) {
47        nolibxml = !atoi(env);
48      } else {
49        env = getenv("HWLOC_LIBXML_EXPORT");
50        if (env)
51  	nolibxml = !atoi(env);
52      }
53      checked = 1;
54    }
55    return nolibxml;
56  }
57  #define BASE64_ENCODED_LENGTH(length) (4*(((length)+2)/3))
58  static struct hwloc_xml_callbacks *hwloc_nolibxml_callbacks = NULL, *hwloc_libxml_callbacks = NULL;
59  void
60  hwloc_xml_callbacks_register(struct hwloc_xml_component *comp)
61  {
62    if (!hwloc_nolibxml_callbacks)
63      hwloc_nolibxml_callbacks = comp->nolibxml_callbacks;
64    if (!hwloc_libxml_callbacks)
65      hwloc_libxml_callbacks = comp->libxml_callbacks;
66  }
67  void
68  hwloc_xml_callbacks_reset(void)
69  {
70    hwloc_nolibxml_callbacks = NULL;
71    hwloc_libxml_callbacks = NULL;
72  }
73  #define _HWLOC_OBJ_CACHE_OLD (HWLOC_OBJ_TYPE_MAX+1) &bsol;* temporarily used when importing pre-v2.0 attribute-less cache types */
74  #define _HWLOC_OBJ_FUTURE    (HWLOC_OBJ_TYPE_MAX+2) &bsol;* temporarily used when ignoring future types */
75  static void
76  hwloc__xml_import_object_attr(struct hwloc_topology *topology,
77  			      struct hwloc_xml_backend_data_s *data,
78  			      struct hwloc_obj *obj,
79  			      const char *name, const char *value,
80  			      hwloc__xml_import_state_t state,
81  			      int *ignore)
82  {
83    if (!strcmp(name, "type")) {
84      return;
85    }
86    else if (!strcmp(name, "os_index"))
87      obj->os_index = strtoul(value, NULL, 10);
88    else if (!strcmp(name, "gp_index")) {
89      obj->gp_index = strtoull(value, NULL, 10);
90      if (!obj->gp_index && hwloc__xml_verbose())
91        fprintf(stderr, "%s: unexpected zero gp_index, topology may be invalid\n", state->global->msgprefix);
92      if (obj->gp_index >= topology->next_gp_index)
93        topology->next_gp_index = obj->gp_index + 1;
94    } else if (!strcmp(name, "id")) { &bsol;* forward compat */
95      if (!strncmp(value, "obj", 3)) {
96        obj->gp_index = strtoull(value+3, NULL, 10);
97        if (!obj->gp_index && hwloc__xml_verbose())
98          fprintf(stderr, "%s: unexpected zero id, topology may be invalid\n", state->global->msgprefix);
99        if (obj->gp_index >= topology->next_gp_index)
100          topology->next_gp_index = obj->gp_index + 1;
101      } else {
102        if (hwloc__xml_verbose())
103          fprintf(stderr, "%s: unexpected id `%s' not-starting with `obj', ignoring\n", state->global->msgprefix, value);
104      }
105    } else if (!strcmp(name, "cpuset")) {
106      if (!obj->cpuset)
107        obj->cpuset = hwloc_bitmap_alloc();
108      hwloc_bitmap_sscanf(obj->cpuset, value);
109    } else if (!strcmp(name, "complete_cpuset")) {
110      if (!obj->complete_cpuset)
111        obj->complete_cpuset = hwloc_bitmap_alloc();
112      hwloc_bitmap_sscanf(obj->complete_cpuset, value);
113    } else if (!strcmp(name, "allowed_cpuset")) {
114      if (!obj->parent)
115        hwloc_bitmap_sscanf(topology->allowed_cpuset, value);
116    } else if (!strcmp(name, "nodeset")) {
117      if (!obj->nodeset)
118        obj->nodeset = hwloc_bitmap_alloc();
119      hwloc_bitmap_sscanf(obj->nodeset, value);
120    } else if (!strcmp(name, "complete_nodeset")) {
121      if (!obj->complete_nodeset)
122        obj->complete_nodeset = hwloc_bitmap_alloc();
123      hwloc_bitmap_sscanf(obj->complete_nodeset, value);
124    } else if (!strcmp(name, "allowed_nodeset")) {
125      if (!obj->parent)
126        hwloc_bitmap_sscanf(topology->allowed_nodeset, value);
127    } else if (!strcmp(name, "name")) {
128      if (obj->name)
129        free(obj->name);
130      obj->name = strdup(value);
131    } else if (!strcmp(name, "subtype")) {
132      if (obj->subtype)
133        free(obj->subtype);
134      obj->subtype = strdup(value);
135    }
136    else if (!strcmp(name, "cache_size")) {
137      unsigned long long lvalue = strtoull(value, NULL, 10);
138      if (hwloc__obj_type_is_cache(obj->type) || obj->type == _HWLOC_OBJ_CACHE_OLD || obj->type == HWLOC_OBJ_MEMCACHE)
139        obj->attr->cache.size = lvalue;
140      else if (hwloc__xml_verbose())
141        fprintf(stderr, "%s: ignoring cache_size attribute for non-cache object type\n",
142  	      state->global->msgprefix);
143    }
144    else if (!strcmp(name, "cache_linesize")) {
145      unsigned long lvalue = strtoul(value, NULL, 10);
146      if (hwloc__obj_type_is_cache(obj->type) || obj->type == _HWLOC_OBJ_CACHE_OLD || obj->type == HWLOC_OBJ_MEMCACHE)
147        obj->attr->cache.linesize = lvalue;
148      else if (hwloc__xml_verbose())
149        fprintf(stderr, "%s: ignoring cache_linesize attribute for non-cache object type\n",
150  	      state->global->msgprefix);
151    }
152    else if (!strcmp(name, "cache_associativity")) {
153      int lvalue = atoi(value);
154      if (hwloc__obj_type_is_cache(obj->type) || obj->type == _HWLOC_OBJ_CACHE_OLD || obj->type == HWLOC_OBJ_MEMCACHE)
155        obj->attr->cache.associativity = lvalue;
156      else if (hwloc__xml_verbose())
157        fprintf(stderr, "%s: ignoring cache_associativity attribute for non-cache object type\n",
158  	      state->global->msgprefix);
159    }
160    else if (!strcmp(name, "cache_type")) {
161      unsigned long lvalue = strtoul(value, NULL, 10);
162      if (hwloc__obj_type_is_cache(obj->type) || obj->type == _HWLOC_OBJ_CACHE_OLD || obj->type == HWLOC_OBJ_MEMCACHE) {
163        if (lvalue == HWLOC_OBJ_CACHE_UNIFIED
164  	  || lvalue == HWLOC_OBJ_CACHE_DATA
165  	  || lvalue == HWLOC_OBJ_CACHE_INSTRUCTION)
166  	obj->attr->cache.type = (hwloc_obj_cache_type_t) lvalue;
167        else
168          if (hwloc__xml_verbose())
169            fprintf(stderr, "%s: ignoring invalid cache_type attribute %lu\n",
170                    state->global->msgprefix, lvalue);
171      } else if (hwloc__xml_verbose())
172        fprintf(stderr, "%s: ignoring cache_type attribute for non-cache object type\n",
173  	      state->global->msgprefix);
174    }
175    else if (!strcmp(name, "local_memory")) {
176      unsigned long long lvalue = strtoull(value, NULL, 10);
177      if (obj->type == HWLOC_OBJ_NUMANODE)
178        obj->attr->numanode.local_memory = lvalue;
179      else if (!obj->parent)
180        topology->machine_memory.local_memory = lvalue;
181      else if (hwloc__xml_verbose())
182        fprintf(stderr, "%s: ignoring local_memory attribute for non-NUMAnode non-root object\n",
183  	      state->global->msgprefix);
184    }
185    else if (!strcmp(name, "depth")) {
186      unsigned long lvalue = strtoul(value, NULL, 10);
187       if (hwloc__obj_type_is_cache(obj->type) || obj->type == _HWLOC_OBJ_CACHE_OLD || obj->type == HWLOC_OBJ_MEMCACHE) {
188  	obj->attr->cache.depth = lvalue;
189       } else if (obj->type == HWLOC_OBJ_GROUP || obj->type == HWLOC_OBJ_BRIDGE) {
190       } else if (hwloc__xml_verbose())
191         fprintf(stderr, "%s: ignoring depth attribute for object type without depth\n",
192  	       state->global->msgprefix);
193    }
194    else if (!strcmp(name, "kind")) {
195      unsigned long lvalue = strtoul(value, NULL, 10);
196      if (obj->type == HWLOC_OBJ_GROUP)
197        obj->attr->group.kind = lvalue;
198      else if (hwloc__xml_verbose())
199        fprintf(stderr, "%s: ignoring kind attribute for non-group object type\n",
200  	      state->global->msgprefix);
201    }
202    else if (!strcmp(name, "subkind")) {
203      unsigned long lvalue = strtoul(value, NULL, 10);
204      if (obj->type == HWLOC_OBJ_GROUP)
205        obj->attr->group.subkind = lvalue;
206      else if (hwloc__xml_verbose())
207        fprintf(stderr, "%s: ignoring subkind attribute for non-group object type\n",
208  	      state->global->msgprefix);
209    }
210    else if (!strcmp(name, "dont_merge")) {
211      unsigned long lvalue = strtoul(value, NULL, 10);
212      if (obj->type == HWLOC_OBJ_GROUP)
213        obj->attr->group.dont_merge = (unsigned char) lvalue;
214      else if (hwloc__xml_verbose())
215        fprintf(stderr, "%s: ignoring dont_merge attribute for non-group object type\n",
216  	      state->global->msgprefix);
217    }
218    else if (!strcmp(name, "pci_busid")) {
219      switch (obj->type) {
220      case HWLOC_OBJ_PCI_DEVICE:
221      case HWLOC_OBJ_BRIDGE: {
222        unsigned domain, bus, dev, func;
223        if (sscanf(value, "%x:%02x:%02x.%01x",
224  		 &domain, &bus, &dev, &func) != 4) {
225  	if (hwloc__xml_verbose())
226  	  fprintf(stderr, "%s: ignoring invalid pci_busid format string %s\n",
227  		  state->global->msgprefix, value);
228  	*ignore = 1;
229  #ifndef HWLOC_HAVE_32BITS_PCI_DOMAIN
230        } else if (domain > 0xffff) {
231  	static int warned = 0;
232  	if (!warned && HWLOC_SHOW_ALL_ERRORS())
233  	  fprintf(stderr, "hwloc/xml: Ignoring PCI device with non-16bit domain.\nPass --enable-32bits-pci-domain to configure to support such devices\n(warning: it would break the library ABI, don't enable unless really needed).\n");
234  	warned = 1;
235  	*ignore = 1;
236  #endif
237        } else {
238  	obj->attr->pcidev.domain = domain;
239  	obj->attr->pcidev.bus = bus;
240  	obj->attr->pcidev.dev = dev;
241  	obj->attr->pcidev.func = func;
242        }
243        break;
244      }
245      default:
246        if (hwloc__xml_verbose())
247  	fprintf(stderr, "%s: ignoring pci_busid attribute for non-PCI object\n",
248  		state->global->msgprefix);
249        break;
250      }
251    }
252    else if (!strcmp(name, "pci_type")) {
253      switch (obj->type) {
254      case HWLOC_OBJ_PCI_DEVICE:
255      case HWLOC_OBJ_BRIDGE: {
256        unsigned classid, vendor, device, subvendor, subdevice, revision;
257        if (sscanf(value, "%x [%04x:%04x] [%04x:%04x] %02x",
258  		 &classid, &vendor, &device, &subvendor, &subdevice, &revision) != 6) {
259  	if (hwloc__xml_verbose())
260  	  fprintf(stderr, "%s: ignoring invalid pci_type format string %s\n",
261  		  state->global->msgprefix, value);
262        } else {
263  	obj->attr->pcidev.class_id = classid;
264  	obj->attr->pcidev.vendor_id = vendor;
265  	obj->attr->pcidev.device_id = device;
266  	obj->attr->pcidev.subvendor_id = subvendor;
267  	obj->attr->pcidev.subdevice_id = subdevice;
268  	obj->attr->pcidev.revision = revision;
269        }
270        break;
271      }
272      default:
273        if (hwloc__xml_verbose())
274  	fprintf(stderr, "%s: ignoring pci_type attribute for non-PCI object\n",
275  		state->global->msgprefix);
276        break;
277      }
278    }
279    else if (!strcmp(name, "pci_link_speed")) {
280      switch (obj->type) {
281      case HWLOC_OBJ_PCI_DEVICE:
282      case HWLOC_OBJ_BRIDGE: {
283        obj->attr->pcidev.linkspeed = (float) atof(value);
284        break;
285      }
286      default:
287        if (hwloc__xml_verbose())
288  	fprintf(stderr, "%s: ignoring pci_link_speed attribute for non-PCI object\n",
289  		state->global->msgprefix);
290        break;
291      }
292    }
293    else if (!strcmp(name, "bridge_type")) {
294      switch (obj->type) {
295      case HWLOC_OBJ_BRIDGE: {
296        unsigned upstream_type, downstream_type;
297        if (sscanf(value, "%u-%u", &upstream_type, &downstream_type) != 2) {
298  	if (hwloc__xml_verbose())
299  	  fprintf(stderr, "%s: ignoring invalid bridge_type format string %s\n",
300  		  state->global->msgprefix, value);
301        } else {
302  	obj->attr->bridge.upstream_type = (hwloc_obj_bridge_type_t) upstream_type;
303  	obj->attr->bridge.downstream_type = (hwloc_obj_bridge_type_t) downstream_type;
304        };
305        break;
306      }
307      default:
308        if (hwloc__xml_verbose())
309  	fprintf(stderr, "%s: ignoring bridge_type attribute for non-bridge object\n",
310  		state->global->msgprefix);
311        break;
312      }
313    }
314    else if (!strcmp(name, "bridge_pci")) {
315      switch (obj->type) {
316      case HWLOC_OBJ_BRIDGE: {
317        unsigned domain, secbus, subbus;
318        if (sscanf(value, "%x:[%02x-%02x]",
319  		 &domain, &secbus, &subbus) != 3) {
320  	if (hwloc__xml_verbose())
321  	  fprintf(stderr, "%s: ignoring invalid bridge_pci format string %s\n",
322  		  state->global->msgprefix, value);
323  	*ignore = 1;
324  #ifndef HWLOC_HAVE_32BITS_PCI_DOMAIN
325        } else if (domain > 0xffff) {
326  	static int warned = 0;
327  	if (!warned && HWLOC_SHOW_ALL_ERRORS())
328  	  fprintf(stderr, "hwloc/xml: Ignoring bridge to PCI with non-16bit domain.\nPass --enable-32bits-pci-domain to configure to support such devices\n(warning: it would break the library ABI, don't enable unless really needed).\n");
329  	warned = 1;
330  	*ignore = 1;
331  #endif
332        } else {
333  	obj->attr->bridge.downstream.pci.domain = domain;
334  	obj->attr->bridge.downstream.pci.secondary_bus = secbus;
335  	obj->attr->bridge.downstream.pci.subordinate_bus = subbus;
336        }
337        break;
338      }
339      default:
340        if (hwloc__xml_verbose())
341  	fprintf(stderr, "%s: ignoring bridge_pci attribute for non-bridge object\n",
342  		state->global->msgprefix);
343        break;
344      }
345    }
346    else if (!strcmp(name, "osdev_type")) {
347      switch (obj->type) {
348      case HWLOC_OBJ_OS_DEVICE: {
349        unsigned osdev_type;
350        if (sscanf(value, "%u", &osdev_type) != 1) {
351  	if (hwloc__xml_verbose())
352  	  fprintf(stderr, "%s: ignoring invalid osdev_type format string %s\n",
353  		  state->global->msgprefix, value);
354        } else
355  	obj->attr->osdev.type = (hwloc_obj_osdev_type_t) osdev_type;
356        break;
357      }
358      default:
359        if (hwloc__xml_verbose())
360  	fprintf(stderr, "%s: ignoring osdev_type attribute for non-osdev object\n",
361  		state->global->msgprefix);
362        break;
363      }
364    }
365    else if (data->version_major < 2) {
366      if (!strcmp(name, "os_level")
367  	|| !strcmp(name, "online_cpuset"))
368        { &bsol;* ignored */ }
369      else if (!strcmp(name, "dmi_board_vendor")) {
370        if (value[0])
371  	hwloc_obj_add_info(obj, "DMIBoardVendor", value);
372      }
373      else if (!strcmp(name, "dmi_board_name")) {
374        if (value[0])
375  	hwloc_obj_add_info(obj, "DMIBoardName", value);
376      }
377      else if (data->version_major < 1) {
378        if (!strcmp(name, "memory_kB")) {
379  	unsigned long long lvalue = strtoull(value, NULL, 10);
380  	if (obj->type == _HWLOC_OBJ_CACHE_OLD)
381  	  obj->attr->cache.size = lvalue << 10;
382  	else if (obj->type == HWLOC_OBJ_NUMANODE)
383  	  obj->attr->numanode.local_memory = lvalue << 10;
384  	else if (!obj->parent)
385  	  topology->machine_memory.local_memory = lvalue << 10;
386  	else if (hwloc__xml_verbose())
387  	  fprintf(stderr, "%s: ignoring memory_kB attribute for non-NUMAnode non-root object\n",
388  		  state->global->msgprefix);
389        }
390        else if (!strcmp(name, "huge_page_size_kB")) {
391  	unsigned long lvalue = strtoul(value, NULL, 10);
392  	if (obj->type == HWLOC_OBJ_NUMANODE || !obj->parent) {
393  	  struct hwloc_numanode_attr_s *memory = obj->type == HWLOC_OBJ_NUMANODE ? &obj->attr->numanode : &topology->machine_memory;
394  	  if (!memory->page_types) {
395  	    memory->page_types = malloc(sizeof(*memory->page_types));
396  	    memory->page_types_len = 1;
397  	  }
398  	  assert(memory->page_types);
399  	  memory->page_types[0].size = lvalue << 10;
400  	} else if (hwloc__xml_verbose()) {
401  	  fprintf(stderr, "%s: ignoring huge_page_size_kB attribute for non-NUMAnode non-root object\n",
402  		  state->global->msgprefix);
403  	}
404        }
405        else if (!strcmp(name, "huge_page_free")) {
406  	unsigned long lvalue = strtoul(value, NULL, 10);
407  	if (obj->type == HWLOC_OBJ_NUMANODE || !obj->parent) {
408  	  struct hwloc_numanode_attr_s *memory = obj->type == HWLOC_OBJ_NUMANODE ? &obj->attr->numanode : &topology->machine_memory;
409  	  if (!memory->page_types) {
410  	    memory->page_types = malloc(sizeof(*memory->page_types));
411  	    memory->page_types_len = 1;
412  	  }
413  	  assert(memory->page_types);
414  	  memory->page_types[0].count = lvalue;
415  	} else if (hwloc__xml_verbose()) {
416  	  fprintf(stderr, "%s: ignoring huge_page_free attribute for non-NUMAnode non-root object\n",
417  		  state->global->msgprefix);
418  	}
419        }
420        else goto unknown;
421      }
422      else goto unknown;
423    }
424    else {
425    unknown:
426      if (hwloc__xml_verbose())
427        fprintf(stderr, "%s: ignoring unknown object attribute %s\n",
428  	      state->global->msgprefix, name);
429    }
430  }
431  static int
432  hwloc___xml_import_info(char **infonamep, char **infovaluep,
433                          hwloc__xml_import_state_t state)
434  {
435    char *infoname = NULL;
436    char *infovalue = NULL;
437    while (1) {
438      char *attrname, *attrvalue;
439      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
440        break;
441      if (!strcmp(attrname, "name"))
442        infoname = attrvalue;
443      else if (!strcmp(attrname, "value"))
444        infovalue = attrvalue;
445      else
446        return -1;
447    }
448    *infonamep = infoname;
449    *infovaluep = infovalue;
450    return state->global->close_tag(state);
451  }
452  static int
453  hwloc__xml_import_obj_info(struct hwloc_xml_backend_data_s *data,
454                             hwloc_obj_t obj,
455                             hwloc__xml_import_state_t state)
456  {
457    char *infoname = NULL;
458    char *infovalue = NULL;
459    int err;
460    err = hwloc___xml_import_info(&infoname, &infovalue, state);
461    if (err < 0)
462      return err;
463    if (infoname) {
464      if (data->version_major < 2 &&
465  	(!strcmp(infoname, "Type") || !strcmp(infoname, "CoProcType"))) {
466        if (infovalue) {
467  	if (obj->subtype)
468  	  free(obj->subtype);
469  	obj->subtype = strdup(infovalue);
470        }
471      } else {
472        if (infovalue)
473  	hwloc_obj_add_info(obj, infoname, infovalue);
474      }
475    }
476    return err;
477  }
478  static int
479  hwloc__xml_import_pagetype(hwloc_topology_t topology __hwloc_attribute_unused, struct hwloc_numanode_attr_s *memory,
480  			   hwloc__xml_import_state_t state)
481  {
482    uint64_t size = 0, count = 0;
483    while (1) {
484      char *attrname, *attrvalue;
485      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
486        break;
487      if (!strcmp(attrname, "size"))
488        size = strtoull(attrvalue, NULL, 10);
489      else if (!strcmp(attrname, "count"))
490        count = strtoull(attrvalue, NULL, 10);
491      else
492        return -1;
493    }
494    if (size) {
495      unsigned idx = memory->page_types_len;
496      struct hwloc_memory_page_type_s *tmp;
497      tmp = realloc(memory->page_types, (idx+1)*sizeof(*memory->page_types));
498      if (tmp) { &bsol;* if failed to allocate, ignore this page_type entry */
499        memory->page_types = tmp;
500        memory->page_types_len = idx+1;
501        memory->page_types[idx].size = size;
502        memory->page_types[idx].count = count;
503      }
504    }
505    return state->global->close_tag(state);
506  }
507  static int
508  hwloc__xml_v1import_distances(struct hwloc_xml_backend_data_s *data,
509  			      hwloc_obj_t obj,
510  			      hwloc__xml_import_state_t state)
511  {
512    unsigned long reldepth = 0, nbobjs = 0;
513    float latbase = 0;
514    char *tag;
515    int ret;
516    while (1) {
517      char *attrname, *attrvalue;
518      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
519        break;
520      if (!strcmp(attrname, "nbobjs"))
521        nbobjs = strtoul(attrvalue, NULL, 10);
522      else if (!strcmp(attrname, "relative_depth"))
523        reldepth = strtoul(attrvalue, NULL, 10);
524      else if (!strcmp(attrname, "latency_base"))
525        latbase = (float) atof(attrvalue);
526      else
527        return -1;
528    }
529    if (nbobjs && reldepth && latbase) {
530      unsigned i;
531      float *matrix;
532      struct hwloc__xml_imported_v1distances_s *v1dist;
533      matrix = malloc(nbobjs*nbobjs*sizeof(float));
534      v1dist = malloc(sizeof(*v1dist));
535      if (!matrix || !v1dist) {
536        if (hwloc__xml_verbose())
537  	fprintf(stderr, "%s: failed to allocate v1distance matrix for %lu objects\n",
538  		state->global->msgprefix, nbobjs);
539        free(v1dist);
540        free(matrix);
541        return -1;
542      }
543      v1dist->kind = HWLOC_DISTANCES_KIND_FROM_OS|HWLOC_DISTANCES_KIND_MEANS_LATENCY;
544      v1dist->nbobjs = nbobjs;
545      v1dist->floats = matrix;
546      for(i=0; i<nbobjs*nbobjs; i++) {
547        struct hwloc__xml_import_state_s childstate;
548        char *attrname, *attrvalue;
549        float val;
550        ret = state->global->find_child(state, &childstate, &tag);
551        if (ret <= 0 || strcmp(tag, "latency")) {
552  	free(matrix);
553  	free(v1dist);
554  	return -1;
555        }
556        ret = state->global->next_attr(&childstate, &attrname, &attrvalue);
557        if (ret < 0 || strcmp(attrname, "value")) {
558  	free(matrix);
559  	free(v1dist);
560  	return -1;
561        }
562        val = (float) atof((char *) attrvalue);
563        matrix[i] = val * latbase;
564        ret = state->global->close_tag(&childstate);
565        if (ret < 0) {
566  	free(matrix);
567  	free(v1dist);
568  	return -1;
569        }
570        state->global->close_child(&childstate);
571      }
572      if (nbobjs < 2) {
573        assert(nbobjs == 1);
574        if (hwloc__xml_verbose())
575  	fprintf(stderr, "%s: ignoring invalid distance matrix with only 1 object\n",
576  		state->global->msgprefix);
577        free(matrix);
578        free(v1dist);
579      } else if (obj->parent) {
580        free(matrix);
581        free(v1dist);
582      } else {
583        v1dist->prev = data->last_v1dist;
584        v1dist->next = NULL;
585        if (data->last_v1dist)
586  	data->last_v1dist->next = v1dist;
587        else
588  	data->first_v1dist = v1dist;
589        data->last_v1dist = v1dist;
590      }
591    }
592    return state->global->close_tag(state);
593  }
594  static int
595  hwloc__xml_import_userdata(hwloc_topology_t topology __hwloc_attribute_unused, hwloc_obj_t obj,
596  			   hwloc__xml_import_state_t state)
597  {
598    size_t length = 0;
599    int encoded = 0;
600    char *name = NULL; &bsol;* optional */
601    int ret;
602    while (1) {
603      char *attrname, *attrvalue;
604      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
605        break;
606      if (!strcmp(attrname, "length"))
607        length = strtoul(attrvalue, NULL, 10);
608      else if (!strcmp(attrname, "encoding"))
609        encoded = !strcmp(attrvalue, "base64");
610      else if (!strcmp(attrname, "name"))
611        name = attrvalue;
612      else
613        return -1;
614    }
615    if (!topology->userdata_import_cb) {
616      const char *buffer;
617      size_t reallength = encoded ? BASE64_ENCODED_LENGTH(length) : length;
618      ret = state->global->get_content(state, &buffer, reallength);
619      if (ret < 0)
620        return -1;
621    } else if (topology->userdata_not_decoded) {
622        const char *buffer;
623        char *fakename;
624        size_t reallength = encoded ? BASE64_ENCODED_LENGTH(length) : length;
625        ret = state->global->get_content(state, &buffer, reallength);
626        if (ret < 0)
627          return -1;
628        fakename = malloc(6 + 1 + (name ? strlen(name) : 4) + 1);
629        if (!fakename)
630  	return -1;
631        sprintf(fakename, encoded ? "base64%c%s" : "normal%c%s", name ? ':' : '-', name ? name : "anon");
632        topology->userdata_import_cb(topology, obj, fakename, buffer, length);
633        free(fakename);
634    } else if (encoded && length) {
635        const char *encoded_buffer;
636        size_t encoded_length = BASE64_ENCODED_LENGTH(length);
637        ret = state->global->get_content(state, &encoded_buffer, encoded_length);
638        if (ret < 0)
639          return -1;
640        if (ret) {
641  	char *decoded_buffer = malloc(length+1);
642  	if (!decoded_buffer)
643  	  return -1;
644  	assert(encoded_buffer[encoded_length] == 0);
645  	ret = hwloc_decode_from_base64(encoded_buffer, decoded_buffer, length+1);
646  	if (ret != (int) length) {
647  	  free(decoded_buffer);
648  	  return -1;
649  	}
650  	topology->userdata_import_cb(topology, obj, name, decoded_buffer, length);
651  	free(decoded_buffer);
652        }
653    } else { &bsol;* always handle length==0 in the non-encoded case */
654        const char *buffer = "";
655        if (length) {
656  	ret = state->global->get_content(state, &buffer, length);
657  	if (ret < 0)
658  	  return -1;
659        }
660        topology->userdata_import_cb(topology, obj, name, buffer, length);
661    }
662    state->global->close_content(state);
663    return state->global->close_tag(state);
664  }
665  static void hwloc__xml_import_report_outoforder(hwloc_topology_t topology, hwloc_obj_t new, hwloc_obj_t old)
666  {
667    char *progname = hwloc_progname(topology);
668    const char *origversion = hwloc_obj_get_info_by_name(topology->levels[0][0], "hwlocVersion");
669    const char *origprogname = hwloc_obj_get_info_by_name(topology->levels[0][0], "ProcessName");
670    char *c1, *cc1, t1[64];
671    char *c2 = NULL, *cc2 = NULL, t2[64];
672    hwloc_bitmap_asprintf(&c1, new->cpuset);
673    hwloc_bitmap_asprintf(&cc1, new->complete_cpuset);
674    hwloc_obj_type_snprintf(t1, sizeof(t1), new, 0);
675    if (old->cpuset)
676      hwloc_bitmap_asprintf(&c2, old->cpuset);
677    if (old->complete_cpuset)
678      hwloc_bitmap_asprintf(&cc2, old->complete_cpuset);
679    hwloc_obj_type_snprintf(t2, sizeof(t2), old, 0);
680    fprintf(stderr, "****************************************************************************\n");
681    fprintf(stderr, "* hwloc has encountered an out-of-order XML topology load.\n");
682    fprintf(stderr, "* Object %s cpuset %s complete %s\n",
683  	  t1, c1, cc1);
684    fprintf(stderr, "* was inserted after object %s with %s and %s.\n",
685  	  t2, c2 ? c2 : "none", cc2 ? cc2 : "none");
686    fprintf(stderr, "* The error occured in hwloc %s inside process `%s', while\n",
687  	  HWLOC_VERSION,
688  	  progname ? progname : "<unknown>");
689    if (origversion || origprogname)
690      fprintf(stderr, "* the input XML was generated by hwloc %s inside process `%s'.\n",
691  	    origversion ? origversion : "(unknown version)",
692  	    origprogname ? origprogname : "<unknown>");
693    else
694      fprintf(stderr, "* the input XML was generated by an unspecified ancient hwloc release.\n");
695    fprintf(stderr, "* Please check that your input topology XML file is valid.\n");
696    fprintf(stderr, "* Set HWLOC_DEBUG_CHECK=1 in the environment to detect further issues.\n");
697    fprintf(stderr, "****************************************************************************\n");
698    free(c1);
699    free(cc1);
700    free(c2);
701    free(cc2);
702    free(progname);
703  }
704  static int
705  hwloc__xml_import_object(hwloc_topology_t topology,
706  			 struct hwloc_xml_backend_data_s *data,
707  			 hwloc_obj_t parent, hwloc_obj_t obj, int *gotignored,
708  			 hwloc__xml_import_state_t state)
709  {
710    int ignored = 0;
711    int childrengotignored = 0;
712    int attribute_less_cache = 0;
713    int numa_was_root = 0;
714    char *tag;
715    struct hwloc__xml_import_state_s childstate;
716    obj->parent = parent;
717    while (1) {
718      char *attrname, *attrvalue;
719      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
720        break;
721      if (!strcmp(attrname, "type")) {
722        if (hwloc_type_sscanf(attrvalue, &obj->type, NULL, 0) < 0) {
723  	if (!strcasecmp(attrvalue, "Cache")) {
724  	  obj->type = _HWLOC_OBJ_CACHE_OLD; &bsol;* will be fixed below */
725  	  attribute_less_cache = 1;
726  	} else if (!strcasecmp(attrvalue, "System")) {
727  	  if (!parent)
728  	    obj->type = HWLOC_OBJ_MACHINE;
729  	  else {
730  	    if (hwloc__xml_verbose())
731  	      fprintf(stderr, "%s: obsolete System object only allowed at root\n",
732  		      state->global->msgprefix);
733  	    goto error_with_object;
734  	  }
735  	} else if (!strcasecmp(attrvalue, "Tile")) {
736  	  obj->type = HWLOC_OBJ_GROUP;
737  	  obj->attr->group.kind = HWLOC_GROUP_KIND_INTEL_TILE;
738  	} else if (!strcasecmp(attrvalue, "Module")) {
739  	  obj->type = HWLOC_OBJ_GROUP;
740  	  obj->attr->group.kind = HWLOC_GROUP_KIND_INTEL_MODULE;
741  	} else if (!strcasecmp(attrvalue, "MemCache")) {
742  	  obj->type = _HWLOC_OBJ_FUTURE;
743  	  ignored = 1;
744  	  if (hwloc__xml_verbose())
745  	    fprintf(stderr, "%s: %s object not-supported, will be ignored\n",
746  		    state->global->msgprefix, attrvalue);
747  	} else {
748  	  if (hwloc__xml_verbose())
749  	    fprintf(stderr, "%s: unrecognized object type string %s\n",
750  		    state->global->msgprefix, attrvalue);
751  	  goto error_with_object;
752  	}
753        }
754      } else {
755        if (obj->type == HWLOC_OBJ_TYPE_NONE) {
756  	if (hwloc__xml_verbose())
757  	  fprintf(stderr, "%s: object attribute %s found before type\n",
758  		  state->global->msgprefix,  attrname);
759  	goto error_with_object;
760        }
761        hwloc__xml_import_object_attr(topology, data, obj, attrname, attrvalue, state, &ignored);
762      }
763    }
764    while (1) {
765      int ret;
766      tag = NULL;
767      ret = state->global->find_child(state, &childstate, &tag);
768      if (ret < 0)
769        goto error;
770      if (!ret)
771        break;
772      if (!strcmp(tag, "object")) {
773        break;
774      } else if (!strcmp(tag, "page_type")) {
775        if (obj->type == HWLOC_OBJ_NUMANODE) {
776  	ret = hwloc__xml_import_pagetype(topology, &obj->attr->numanode, &childstate);
777        } else if (!parent) {
778  	ret = hwloc__xml_import_pagetype(topology, &topology->machine_memory, &childstate);
779        } else {
780  	if (hwloc__xml_verbose())
781  	  fprintf(stderr, "%s: invalid non-NUMAnode object child %s\n",
782  		  state->global->msgprefix, tag);
783  	ret = -1;
784        }
785      } else if (!strcmp(tag, "info")) {
786        ret = hwloc__xml_import_obj_info(data, obj, &childstate);
787      } else if (data->version_major < 2 && !strcmp(tag, "distances")) {
788        ret = hwloc__xml_v1import_distances(data, obj, &childstate);
789      } else if (!strcmp(tag, "userdata")) {
790        ret = hwloc__xml_import_userdata(topology, obj, &childstate);
791      } else {
792        if (hwloc__xml_verbose())
793  	fprintf(stderr, "%s: invalid special object child %s\n",
794  		state->global->msgprefix, tag);
795        ret = -1;
796      }
797      if (ret < 0)
798        goto error;
799      state->global->close_child(&childstate);
800    }
801    if (parent && obj->type == HWLOC_OBJ_MACHINE) {
802      obj->type = HWLOC_OBJ_GROUP;
803    }
804    if (parent && data->version_major >= 2) {
805      if (hwloc__obj_type_is_normal(obj->type)) {
806        if (!hwloc__obj_type_is_normal(parent->type)) {
807  	if (hwloc__xml_verbose())
808  	  fprintf(stderr, "normal object %s cannot be child of non-normal parent %s\n",
809  		  hwloc_obj_type_string(obj->type), hwloc_obj_type_string(parent->type));
810  	goto error_with_object;
811        }
812      } else if (hwloc__obj_type_is_memory(obj->type)) {
813        if (hwloc__obj_type_is_io(parent->type) || HWLOC_OBJ_MISC == parent->type) {
814  	if (hwloc__xml_verbose())
815  	  fprintf(stderr, "Memory object %s cannot be child of non-normal-or-memory parent %s\n",
816  		  hwloc_obj_type_string(obj->type), hwloc_obj_type_string(parent->type));
817  	goto error_with_object;
818        }
819      } else if (hwloc__obj_type_is_io(obj->type)) {
820        if (hwloc__obj_type_is_memory(parent->type) || HWLOC_OBJ_MISC == parent->type) {
821  	if (hwloc__xml_verbose())
822  	  fprintf(stderr, "I/O object %s cannot be child of non-normal-or-I/O parent %s\n",
823  		  hwloc_obj_type_string(obj->type), hwloc_obj_type_string(parent->type));
824  	goto error_with_object;
825        }
826      }
827    } else if (parent && data->version_major < 2) {
828      if (hwloc__obj_type_is_normal(obj->type) || HWLOC_OBJ_NUMANODE == obj->type) {
829        if (hwloc__obj_type_is_special(parent->type)) {
830  	if (hwloc__xml_verbose())
831  	  fprintf(stderr, "v1.x normal v1.x object %s cannot be child of special parent %s\n",
832  		  hwloc_obj_type_string(obj->type), hwloc_obj_type_string(parent->type));
833  	goto error_with_object;
834        }
835      } else if (hwloc__obj_type_is_io(obj->type)) {
836        if (HWLOC_OBJ_MISC == parent->type) {
837  	if (hwloc__xml_verbose())
838  	  fprintf(stderr, "I/O object %s cannot be child of Misc parent\n",
839  		  hwloc_obj_type_string(obj->type));
840  	goto error_with_object;
841        }
842      }
843    }
844    if (data->version_major < 2) {
845      if (parent && parent->type == HWLOC_OBJ_NUMANODE) {
846        parent = parent->parent;
847        assert(parent);
848      }
849      if (obj->type == HWLOC_OBJ_NUMANODE) {
850        if (!parent) {
851  	hwloc_obj_t machine = hwloc_alloc_setup_object(topology, HWLOC_OBJ_MACHINE, HWLOC_UNKNOWN_INDEX);
852  	machine->cpuset = hwloc_bitmap_dup(obj->cpuset);
853  	machine->complete_cpuset = hwloc_bitmap_dup(obj->cpuset);
854  	machine->nodeset = hwloc_bitmap_dup(obj->nodeset);
855  	machine->complete_nodeset = hwloc_bitmap_dup(obj->complete_nodeset);
856  	topology->levels[0][0] = machine;
857  	parent = machine;
858  	numa_was_root = 1;
859        } else if (!hwloc_bitmap_isequal(obj->complete_cpuset, parent->complete_cpuset)) {
860  	int needgroup = 1;
861  	hwloc_obj_t sibling;
862  	sibling = parent->memory_first_child;
863  	if (sibling && !sibling->subtype
864  	    && !sibling->next_sibling
865  	    && obj->subtype && !strcmp(obj->subtype, "MCDRAM")
866  	    && hwloc_bitmap_iszero(obj->complete_cpuset)) {
867  	  needgroup = 0;
868  	}
869  	if (needgroup
870  	    && hwloc_filter_check_keep_object_type(topology, HWLOC_OBJ_GROUP)) {
871  	  hwloc_obj_t group = hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
872  	  group->gp_index = 0; &bsol;* will be initialized at the end of the discovery once we know the max */
873  	  group->cpuset = hwloc_bitmap_dup(obj->cpuset);
874  	  group->complete_cpuset = hwloc_bitmap_dup(obj->cpuset);
875  	  group->nodeset = hwloc_bitmap_dup(obj->nodeset);
876  	  group->complete_nodeset = hwloc_bitmap_dup(obj->complete_nodeset);
877  	  group->attr->group.kind = HWLOC_GROUP_KIND_MEMORY;
878  	  hwloc_insert_object_by_parent(topology, parent, group);
879  	  parent = group;
880  	}
881        }
882      }
883      if (attribute_less_cache) {
884        assert(obj->type == _HWLOC_OBJ_CACHE_OLD);
885        obj->type = hwloc_cache_type_by_depth_type(obj->attr->cache.depth, obj->attr->cache.type);
886      }
887      if (obj->type == HWLOC_OBJ_MISC && obj->cpuset)
888        obj->type = HWLOC_OBJ_GROUP;
889      if (!obj->cpuset != !obj->complete_cpuset) {
890        if (obj->type == HWLOC_OBJ_GROUP) {
891  	ignored = 1;
892        } else {
893  	if (hwloc__xml_verbose())
894  	  fprintf(stderr, "%s: invalid object %s P#%u with some missing cpusets\n",
895  		  state->global->msgprefix, hwloc_obj_type_string(obj->type), obj->os_index);
896  	goto error_with_object;
897        }
898      } else if (!obj->nodeset != !obj->complete_nodeset) {
899        if (obj->type == HWLOC_OBJ_GROUP) {
900  	ignored = 1;
901        } else {
902  	if (hwloc__xml_verbose())
903  	  fprintf(stderr, "%s: invalid object %s P#%u with some missing nodesets\n",
904  		  state->global->msgprefix, hwloc_obj_type_string(obj->type), obj->os_index);
905  	goto error_with_object;
906        }
907      } else if (obj->nodeset && !obj->cpuset) {
908        if (obj->type == HWLOC_OBJ_GROUP) {
909  	ignored = 1;
910        } else {
911  	if (hwloc__xml_verbose())
912  	  fprintf(stderr, "%s: invalid object %s P#%u with either cpuset or nodeset missing\n",
913  		  state->global->msgprefix, hwloc_obj_type_string(obj->type), obj->os_index);
914  	goto error_with_object;
915        }
916      }
917    }
918    if (obj->type == HWLOC_OBJ_GROUP) {
919      if (obj->attr->group.kind == HWLOC_GROUP_KIND_INTEL_DIE
920  	|| (obj->subtype && !strcmp(obj->subtype, "Die")))
921        obj->type = HWLOC_OBJ_DIE;
922    }
923    if (hwloc__obj_type_is_cache(obj->type)
924        && obj->type != hwloc_cache_type_by_depth_type(obj->attr->cache.depth, obj->attr->cache.type)) {
925      if (hwloc__xml_verbose())
926        fprintf(stderr, "%s: invalid cache type %s with attribute depth %u and type %d\n",
927  	      state->global->msgprefix, hwloc_obj_type_string(obj->type), obj->attr->cache.depth, (int) obj->attr->cache.type);
928      goto error_with_object;
929    }
930    if (!obj->cpuset && !hwloc__obj_type_is_special(obj->type)) {
931      if (hwloc__xml_verbose())
932        fprintf(stderr, "%s: invalid normal object %s P#%u without cpuset\n",
933  	      state->global->msgprefix, hwloc_obj_type_string(obj->type), obj->os_index);
934      goto error_with_object;
935    }
936    if (obj->cpuset && hwloc__obj_type_is_special(obj->type)) {
937      if (hwloc__xml_verbose())
938        fprintf(stderr, "%s: invalid special object %s with cpuset\n",
939  	      state->global->msgprefix, hwloc_obj_type_string(obj->type));
940      goto error_with_object;
941    }
942    if (obj->cpuset && parent && !parent->cpuset) {
943      if (hwloc__xml_verbose())
944        fprintf(stderr, "%s: invalid object %s P#%u with cpuset while parent has none\n",
945  	      state->global->msgprefix, hwloc_obj_type_string(obj->type), obj->os_index);
946      goto error_with_object;
947    }
948    if (obj->nodeset && parent && !parent->nodeset) {
949      if (hwloc__xml_verbose())
950        fprintf(stderr, "%s: invalid object %s P#%u with nodeset while parent has none\n",
951  	      state->global->msgprefix, hwloc_obj_type_string(obj->type), obj->os_index);
952      goto error_with_object;
953    }
954    if (obj->type == HWLOC_OBJ_NUMANODE) {
955      if (!obj->nodeset) {
956        if (hwloc__xml_verbose())
957  	fprintf(stderr, "%s: invalid NUMA node object P#%u without nodeset\n",
958  		state->global->msgprefix, obj->os_index);
959        goto error_with_object;
960      }
961      data->nbnumanodes++;
962      obj->prev_cousin = data->last_numanode;
963      obj->next_cousin = NULL;
964      if (data->last_numanode)
965        data->last_numanode->next_cousin = obj;
966      else
967        data->first_numanode = obj;
968      data->last_numanode = obj;
969    }
970    if (!hwloc_filter_check_keep_object(topology, obj)) {
971      if (parent)
972        ignored = 1;
973    }
974    if (parent && !ignored) {
975      hwloc_insert_object_by_parent(topology, parent, obj);
976    }
977    while (tag) {
978      int ret;
979      if (!strcmp(tag, "object")) {
980        hwloc_obj_t childobj = hwloc_alloc_setup_object(topology, HWLOC_OBJ_TYPE_MAX, HWLOC_UNKNOWN_INDEX);
981        childobj->parent = ignored ? parent : obj;
982        ret = hwloc__xml_import_object(topology, data, ignored ? parent : obj, childobj,
983  				     &childrengotignored,
984  				     &childstate);
985      } else {
986        if (hwloc__xml_verbose())
987  	fprintf(stderr, "%s: invalid special object child %s while looking for objects\n",
988  		state->global->msgprefix, tag);
989        ret = -1;
990      }
991      if (ret < 0) {
992        if (parent && !ignored)
993          goto error;
994        else
995          goto error_with_object;
996      }
997      state->global->close_child(&childstate);
998      tag = NULL;
999      ret = state->global->find_child(state, &childstate, &tag);
1000      if (ret < 0) {
1001        if (parent && !ignored)
1002          goto error;
1003        else
1004          goto error_with_object;
1005      }
1006      if (!ret)
1007        break;
1008    }
1009    if (numa_was_root) {
1010      unsigned i;
1011      for(i=0; i<obj->infos_count; i++) {
1012        struct hwloc_info_s *info = &obj->infos[i];
1013        hwloc_obj_add_info(parent, info->name, info->value);
1014      }
1015    }
1016    if (ignored) {
1017      hwloc_free_unlinked_object(obj);
1018      *gotignored = 1;
1019    } else if (obj->first_child) {
1020      hwloc_obj_t cur, next;
1021      for(cur = obj->first_child, next = cur->next_sibling;
1022  	next;
1023  	cur = next, next = next->next_sibling) {
1024        if (hwloc_bitmap_compare_first(next->complete_cpuset, cur->complete_cpuset) < 0) {
1025  	if (!childrengotignored) {
1026  	  static int reported = 0;
1027  	  if (!reported && HWLOC_SHOW_CRITICAL_ERRORS()) {
1028  	    hwloc__xml_import_report_outoforder(topology, next, cur);
1029  	    reported = 1;
1030  	  }
1031  	}
1032  	hwloc__reorder_children(obj);
1033  	break;
1034        }
1035      }
1036    }
1037    return state->global->close_tag(state);
1038   error_with_object:
1039    if (parent)
1040      hwloc_free_unlinked_object(obj);
1041   error:
1042    return -1;
1043  }
1044  static int
1045  hwloc__xml_v2import_support(hwloc_topology_t topology,
1046                              hwloc__xml_import_state_t state)
1047  {
1048    char *name = NULL;
1049    int value = 1; &bsol;* value is optional */
1050    while (1) {
1051      char *attrname, *attrvalue;
1052      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
1053        break;
1054      if (!strcmp(attrname, "name"))
1055        name = attrvalue;
1056      else if (!strcmp(attrname, "value"))
1057        value = atoi(attrvalue);
1058      else {
1059        if (hwloc__xml_verbose())
1060  	fprintf(stderr, "%s: ignoring unknown support attribute %s\n",
1061  		state->global->msgprefix, attrname);
1062      }
1063    }
1064    if (name && topology->flags & HWLOC_TOPOLOGY_FLAG_IMPORT_SUPPORT) {
1065  #ifdef HWLOC_DEBUG
1066      HWLOC_BUILD_ASSERT(sizeof(struct hwloc_topology_support) == 4*sizeof(void*));
1067      HWLOC_BUILD_ASSERT(sizeof(struct hwloc_topology_discovery_support) == 6);
1068      HWLOC_BUILD_ASSERT(sizeof(struct hwloc_topology_cpubind_support) == 11);
1069      HWLOC_BUILD_ASSERT(sizeof(struct hwloc_topology_membind_support) == 15);
1070      HWLOC_BUILD_ASSERT(sizeof(struct hwloc_topology_misc_support) == 1);
1071  #endif
1072  #define DO(_cat,_name) if (!strcmp(#_cat "." #_name, name)) topology->support._cat->_name = value
1073      DO(discovery,pu);
1074      else DO(discovery,numa);
1075      else DO(discovery,numa_memory);
1076      else DO(discovery,disallowed_pu);
1077      else DO(discovery,disallowed_numa);
1078      else DO(discovery,cpukind_efficiency);
1079      else DO(cpubind,set_thisproc_cpubind);
1080      else DO(cpubind,get_thisproc_cpubind);
1081      else DO(cpubind,set_proc_cpubind);
1082      else DO(cpubind,get_proc_cpubind);
1083      else DO(cpubind,set_thisthread_cpubind);
1084      else DO(cpubind,get_thisthread_cpubind);
1085      else DO(cpubind,set_thread_cpubind);
1086      else DO(cpubind,get_thread_cpubind);
1087      else DO(cpubind,get_thisproc_last_cpu_location);
1088      else DO(cpubind,get_proc_last_cpu_location);
1089      else DO(cpubind,get_thisthread_last_cpu_location);
1090      else DO(membind,set_thisproc_membind);
1091      else DO(membind,get_thisproc_membind);
1092      else DO(membind,set_proc_membind);
1093      else DO(membind,get_proc_membind);
1094      else DO(membind,set_thisthread_membind);
1095      else DO(membind,get_thisthread_membind);
1096      else DO(membind,set_area_membind);
1097      else DO(membind,get_area_membind);
1098      else DO(membind,alloc_membind);
1099      else DO(membind,firsttouch_membind);
1100      else DO(membind,bind_membind);
1101      else DO(membind,interleave_membind);
1102      else DO(membind,nexttouch_membind);
1103      else DO(membind,migrate_membind);
1104      else DO(membind,get_area_memlocation);
1105      else if (!strcmp("custom.exported_support", name))
1106        topology->support.misc->imported_support = 1;
1107  #undef DO
1108    }
1109    return 0;
1110  }
1111  static int
1112  hwloc__xml_v2import_distances(hwloc_topology_t topology,
1113  			      hwloc__xml_import_state_t state,
1114  			      int heterotypes)
1115  {
1116    hwloc_obj_type_t unique_type = HWLOC_OBJ_TYPE_NONE;
1117    hwloc_obj_type_t *different_types = NULL;
1118    unsigned nbobjs = 0;
1119    int indexing = heterotypes;
1120    int os_indexing = 0;
1121    int gp_indexing = heterotypes;
1122    char *name = NULL;
1123    unsigned long kind = 0;
1124    unsigned nr_indexes, nr_u64values;
1125    uint64_t *indexes;
1126    uint64_t *u64values;
1127    int ret;
1128  #define _TAG_NAME (heterotypes ? "distances2hetero" : "distances2")
1129    while (1) {
1130      char *attrname, *attrvalue;
1131      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
1132        break;
1133      if (!strcmp(attrname, "nbobjs"))
1134        nbobjs = strtoul(attrvalue, NULL, 10);
1135      else if (!strcmp(attrname, "type")) {
1136        if (hwloc_type_sscanf(attrvalue, &unique_type, NULL, 0) < 0) {
1137  	if (hwloc__xml_verbose())
1138  	  fprintf(stderr, "%s: unrecognized %s type %s\n",
1139  		  state->global->msgprefix, _TAG_NAME, attrvalue);
1140  	goto out;
1141        }
1142      }
1143      else if (!strcmp(attrname, "indexing")) {
1144        indexing = 1;
1145        if (!strcmp(attrvalue, "os"))
1146  	os_indexing = 1;
1147        else if (!strcmp(attrvalue, "gp"))
1148  	gp_indexing = 1;
1149      }
1150      else if (!strcmp(attrname, "kind")) {
1151        kind = strtoul(attrvalue, NULL, 10);
1152      }
1153      else if (!strcmp(attrname, "name")) {
1154        name = attrvalue;
1155      }
1156      else {
1157        if (hwloc__xml_verbose())
1158  	fprintf(stderr, "%s: ignoring unknown %s attribute %s\n",
1159  		state->global->msgprefix, _TAG_NAME, attrname);
1160      }
1161    }
1162    if (!nbobjs || (!heterotypes && unique_type == HWLOC_OBJ_TYPE_NONE) || !indexing || !kind) {
1163      if (hwloc__xml_verbose())
1164        fprintf(stderr, "%s: %s missing some attributes\n",
1165  	      state->global->msgprefix, _TAG_NAME);
1166      goto out;
1167    }
1168    indexes = malloc(nbobjs*sizeof(*indexes));
1169    u64values = malloc(nbobjs*nbobjs*sizeof(*u64values));
1170    if (heterotypes)
1171      different_types = malloc(nbobjs*sizeof(*different_types));
1172    if (!indexes || !u64values || (heterotypes && !different_types)) {
1173      if (hwloc__xml_verbose())
1174        fprintf(stderr, "%s: failed to allocate %s arrays for %u objects\n",
1175  	      state->global->msgprefix, _TAG_NAME, nbobjs);
1176      goto out_with_arrays;
1177    }
1178    nr_indexes = 0;
1179    nr_u64values = 0;
1180    while (1) {
1181      struct hwloc__xml_import_state_s childstate;
1182      char *attrname, *attrvalue, *tag;
1183      const char *buffer;
1184      int length;
1185      int is_index = 0;
1186      int is_u64values = 0;
1187      ret = state->global->find_child(state, &childstate, &tag);
1188      if (ret <= 0)
1189        break;
1190      if (!strcmp(tag, "indexes"))
1191        is_index = 1;
1192      else if (!strcmp(tag, "u64values"))
1193        is_u64values = 1;
1194      if (!is_index && !is_u64values) {
1195        if (hwloc__xml_verbose())
1196  	fprintf(stderr, "%s: %s with unrecognized child %s\n",
1197  		state->global->msgprefix, _TAG_NAME, tag);
1198        goto out_with_arrays;
1199      }
1200      if (state->global->next_attr(&childstate, &attrname, &attrvalue) < 0
1201  	|| strcmp(attrname, "length")) {
1202        if (hwloc__xml_verbose())
1203  	fprintf(stderr, "%s: %s child must have length attribute\n",
1204  		state->global->msgprefix, _TAG_NAME);
1205        goto out_with_arrays;
1206      }
1207      length = atoi(attrvalue);
1208      ret = state->global->get_content(&childstate, &buffer, length);
1209      if (ret < 0) {
1210        if (hwloc__xml_verbose())
1211  	fprintf(stderr, "%s: %s child needs content of length %d\n",
1212  		state->global->msgprefix, _TAG_NAME, length);
1213        goto out_with_arrays;
1214      }
1215      if (is_index) {
1216        const char *tmp, *tmp2;
1217        if (nr_indexes >= nbobjs) {
1218  	if (hwloc__xml_verbose())
1219  	  fprintf(stderr, "%s: %s with more than %u indexes\n",
1220  		  state->global->msgprefix, _TAG_NAME, nbobjs);
1221  	goto out_with_arrays;
1222        }
1223        tmp = buffer;
1224        while (1) {
1225  	char *next;
1226  	unsigned long long u;
1227  	if (heterotypes) {
1228  	  hwloc_obj_type_t t = HWLOC_OBJ_TYPE_NONE;
1229            if (!*tmp)
1230              break;
1231  	  if (hwloc_type_sscanf(tmp, &t, NULL, 0) < 0) {
1232  	    if (hwloc__xml_verbose())
1233  	      fprintf(stderr, "%s: %s with unrecognized heterogeneous type %s\n",
1234  		      state->global->msgprefix, _TAG_NAME, tmp);
1235  	    goto out_with_arrays;
1236  	  }
1237  	  tmp2 = strchr(tmp, ':');
1238  	  if (!tmp2) {
1239  	    if (hwloc__xml_verbose())
1240  	      fprintf(stderr, "%s: %s with missing colon after heterogeneous type %s\n",
1241  		      state->global->msgprefix, _TAG_NAME, tmp);
1242  	    goto out_with_arrays;
1243  	  }
1244  	  tmp = tmp2+1;
1245  	  different_types[nr_indexes] = t;
1246  	}
1247  	u = strtoull(tmp, &next, 0);
1248  	if (next == tmp)
1249  	  break;
1250  	indexes[nr_indexes++] = u;
1251  	if (*next != ' ')
1252  	  break;
1253  	if (nr_indexes == nbobjs)
1254  	  break;
1255  	tmp = next+1;
1256        }
1257      } else if (is_u64values) {
1258        const char *tmp;
1259        if (nr_u64values >= nbobjs*nbobjs) {
1260  	if (hwloc__xml_verbose())
1261  	  fprintf(stderr, "%s: %s with more than %u u64values\n",
1262  		  state->global->msgprefix, _TAG_NAME, nbobjs*nbobjs);
1263  	goto out_with_arrays;
1264        }
1265        tmp = buffer;
1266        while (1) {
1267  	char *next;
1268  	unsigned long long u = strtoull(tmp, &next, 0);
1269  	if (next == tmp)
1270  	  break;
1271  	u64values[nr_u64values++] = u;
1272  	if (*next != ' ')
1273  	  break;
1274  	if (nr_u64values == nbobjs*nbobjs)
1275  	  break;
1276  	tmp = next+1;
1277        }
1278      }
1279      state->global->close_content(&childstate);
1280      ret = state->global->close_tag(&childstate);
1281      if (ret < 0) {
1282        if (hwloc__xml_verbose())
1283  	fprintf(stderr, "%s: %s with more than %u indexes\n",
1284  		state->global->msgprefix, _TAG_NAME, nbobjs);
1285        goto out_with_arrays;
1286      }
1287      state->global->close_child(&childstate);
1288    }
1289    if (nr_indexes != nbobjs) {
1290      if (hwloc__xml_verbose())
1291        fprintf(stderr, "%s: %s with less than %u indexes\n",
1292  	      state->global->msgprefix, _TAG_NAME, nbobjs);
1293      goto out_with_arrays;
1294    }
1295    if (nr_u64values != nbobjs*nbobjs) {
1296      if (hwloc__xml_verbose())
1297        fprintf(stderr, "%s: %s with less than %u u64values\n",
1298  	      state->global->msgprefix, _TAG_NAME, nbobjs*nbobjs);
1299      goto out_with_arrays;
1300    }
1301    if (nbobjs < 2) {
1302      if (hwloc__xml_verbose())
1303        fprintf(stderr, "%s: ignoring %s with only %u objects\n",
1304  	      state->global->msgprefix, _TAG_NAME, nbobjs);
1305      goto out_ignore;
1306    }
1307    if (unique_type == HWLOC_OBJ_PU || unique_type == HWLOC_OBJ_NUMANODE) {
1308      if (!os_indexing) {
1309        if (hwloc__xml_verbose())
1310  	fprintf(stderr, "%s: ignoring PU or NUMA %s without os_indexing\n",
1311  		state->global->msgprefix, _TAG_NAME);
1312        goto out_ignore;
1313      }
1314    } else {
1315      if (!gp_indexing) {
1316        if (hwloc__xml_verbose())
1317  	fprintf(stderr, "%s: ignoring !PU or !NUMA %s without gp_indexing\n",
1318  		state->global->msgprefix, _TAG_NAME);
1319        goto out_ignore;
1320      }
1321    }
1322    if (topology->flags & HWLOC_TOPOLOGY_FLAG_NO_DISTANCES)
1323      goto out_ignore;
1324    hwloc_internal_distances_add_by_index(topology, name, unique_type, different_types, nbobjs, indexes, u64values, kind, 0 &bsol;* assume grouping was applied when this matrix was discovered before exporting to XML */);
1325    indexes = NULL;
1326    u64values = NULL;
1327    different_types = NULL;
1328   out_ignore:
1329    free(different_types);
1330    free(indexes);
1331    free(u64values);
1332    return state->global->close_tag(state);
1333   out_with_arrays:
1334    free(different_types);
1335    free(indexes);
1336    free(u64values);
1337   out:
1338    return -1;
1339  #undef _TAG_NAME
1340  }
1341  static int
1342  hwloc__xml_import_memattr_value(hwloc_topology_t topology,
1343                                  hwloc_memattr_id_t id,
1344                                  unsigned long flags,
1345                                  hwloc__xml_import_state_t state)
1346  {
1347    char *target_obj_gp_index_s = NULL;
1348    char *target_obj_type_s = NULL;
1349    hwloc_uint64_t target_obj_gp_index;
1350    char *value_s = NULL;
1351    hwloc_uint64_t value;
1352    char *initiator_cpuset_s = NULL;
1353    char *initiator_obj_gp_index_s = NULL;
1354    char *initiator_obj_type_s = NULL;
1355    hwloc_obj_type_t target_obj_type = HWLOC_OBJ_TYPE_NONE;
1356    while (1) {
1357      char *attrname, *attrvalue;
1358      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
1359        break;
1360      if (!strcmp(attrname, "target_obj_gp_index"))
1361        target_obj_gp_index_s = attrvalue;
1362      else if (!strcmp(attrname, "target_obj_type"))
1363        target_obj_type_s = attrvalue;
1364      else if (!strcmp(attrname, "value"))
1365        value_s = attrvalue;
1366      else if (!strcmp(attrname, "initiator_cpuset"))
1367        initiator_cpuset_s = attrvalue;
1368      else if (!strcmp(attrname, "initiator_obj_gp_index"))
1369        initiator_obj_gp_index_s = attrvalue;
1370      else if (!strcmp(attrname, "initiator_obj_type"))
1371        initiator_obj_type_s = attrvalue;
1372      else {
1373        if (hwloc__xml_verbose())
1374          fprintf(stderr, "%s: ignoring unknown memattr_value attribute %s\n",
1375                  state->global->msgprefix, attrname);
1376        return -1;
1377      }
1378    }
1379    if (!target_obj_type_s) {
1380      if (hwloc__xml_verbose())
1381        fprintf(stderr, "%s: ignoring memattr_value without target_obj_type.\n",
1382                state->global->msgprefix);
1383      return -1;
1384    }
1385    if (hwloc_type_sscanf(target_obj_type_s, &target_obj_type, NULL, 0) < 0) {
1386      if (hwloc__xml_verbose())
1387        fprintf(stderr, "%s: failed to identify memattr_value target object type %s\n",
1388                state->global->msgprefix, target_obj_type_s);
1389      return -1;
1390    }
1391    if (!value_s || !target_obj_gp_index_s) {
1392      if (hwloc__xml_verbose())
1393        fprintf(stderr, "%s: ignoring memattr_value without value and target_obj_gp_index\n",
1394                state->global->msgprefix);
1395      return -1;
1396    }
1397    target_obj_gp_index = strtoull(target_obj_gp_index_s, NULL, 10);
1398    value = strtoull(value_s, NULL, 10);
1399    if (flags & HWLOC_MEMATTR_FLAG_NEED_INITIATOR) {
1400      struct hwloc_internal_location_s loc;
1401      if (!initiator_cpuset_s && (!initiator_obj_gp_index_s || !initiator_obj_type_s)) {
1402        if (hwloc__xml_verbose())
1403          fprintf(stderr, "%s: ignoring memattr_value without initiator attributes\n",
1404                  state->global->msgprefix);
1405        return -1;
1406      }
1407      if (initiator_cpuset_s) {
1408        loc.type = HWLOC_LOCATION_TYPE_CPUSET;
1409        loc.location.cpuset = hwloc_bitmap_alloc();
1410        if (!loc.location.cpuset) {
1411          if (hwloc__xml_verbose())
1412            fprintf(stderr, "%s: failed to allocated memattr_value initiator cpuset\n",
1413                    state->global->msgprefix);
1414          return -1;
1415        }
1416        hwloc_bitmap_sscanf(loc.location.cpuset, initiator_cpuset_s);
1417      } else {
1418        loc.type = HWLOC_LOCATION_TYPE_OBJECT;
1419        loc.location.object.gp_index = strtoull(initiator_obj_gp_index_s, NULL, 10);
1420        if (hwloc_type_sscanf(initiator_obj_type_s, &loc.location.object.type, NULL, 0) < 0) {
1421          if (hwloc__xml_verbose())
1422            fprintf(stderr, "%s: failed to identify memattr_value initiator object type %s\n",
1423                    state->global->msgprefix, initiator_obj_type_s);
1424          return -1;
1425        }
1426      }
1427      hwloc_internal_memattr_set_value(topology, id, target_obj_type, target_obj_gp_index, (unsigned)-1, &loc, value);
1428      if (loc.type == HWLOC_LOCATION_TYPE_CPUSET)
1429        hwloc_bitmap_free(loc.location.cpuset);
1430    } else {
1431      hwloc_internal_memattr_set_value(topology, id, target_obj_type, target_obj_gp_index, (unsigned)-1, NULL, value);
1432    }
1433    return 0;
1434  }
1435  static int
1436  hwloc__xml_import_memattr(hwloc_topology_t topology,
1437                            hwloc__xml_import_state_t state)
1438  {
1439    char *name = NULL;
1440    unsigned long flags = (unsigned long) -1;
1441    hwloc_memattr_id_t id = (hwloc_memattr_id_t) -1;
1442    int ret;
1443    while (1) {
1444      char *attrname, *attrvalue;
1445      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
1446        break;
1447      if (!strcmp(attrname, "name"))
1448        name = attrvalue;
1449      else if (!strcmp(attrname, "flags"))
1450        flags = strtoul(attrvalue, NULL, 10);
1451      else {
1452        if (hwloc__xml_verbose())
1453          fprintf(stderr, "%s: ignoring unknown memattr attribute %s\n",
1454                  state->global->msgprefix, attrname);
1455        return -1;
1456      }
1457    }
1458    if (name && flags != (unsigned long) -1
1459        && !(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_MEMATTRS)) {
1460      hwloc_memattr_id_t _id;
1461      ret = hwloc_memattr_get_by_name(topology, name, &_id);
1462      if (ret < 0) {
1463        ret = hwloc_memattr_register(topology, name, flags, &_id);
1464        if (!ret)
1465          id = _id;
1466      } else {
1467        unsigned long mflags;
1468        ret = hwloc_memattr_get_flags(topology, _id, &mflags);
1469        if (!ret && mflags == flags)
1470          id = _id;
1471      }
1472    }
1473    while (1) {
1474      struct hwloc__xml_import_state_s childstate;
1475      char *tag;
1476      ret = state->global->find_child(state, &childstate, &tag);
1477      if (ret <= 0)
1478        break;
1479      if (!strcmp(tag, "memattr_value")) {
1480        ret = hwloc__xml_import_memattr_value(topology, id, flags, &childstate);
1481      } else {
1482        if (hwloc__xml_verbose())
1483          fprintf(stderr, "%s: memattr with unrecognized child %s\n",
1484                  state->global->msgprefix, tag);
1485        ret = -1;
1486      }
1487      if (ret < 0)
1488        goto error;
1489      state->global->close_child(&childstate);
1490    }
1491    return state->global->close_tag(state);
1492   error:
1493    return -1;
1494  }
1495  static int
1496  hwloc__xml_import_cpukind(hwloc_topology_t topology,
1497                            hwloc__xml_import_state_t state)
1498  {
1499    hwloc_bitmap_t cpuset = NULL;
1500    int forced_efficiency = HWLOC_CPUKIND_EFFICIENCY_UNKNOWN;
1501    unsigned nr_infos = 0;
1502    struct hwloc_info_s *infos = NULL;
1503    int ret;
1504    while (1) {
1505      char *attrname, *attrvalue;
1506      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
1507        break;
1508      if (!strcmp(attrname, "cpuset")) {
1509        if (!cpuset)
1510          cpuset = hwloc_bitmap_alloc();
1511        hwloc_bitmap_sscanf(cpuset, attrvalue);
1512      } else if (!strcmp(attrname, "forced_efficiency")) {
1513        forced_efficiency = atoi(attrvalue);
1514      } else {
1515        if (hwloc__xml_verbose())
1516          fprintf(stderr, "%s: ignoring unknown cpukind attribute %s\n",
1517                  state->global->msgprefix, attrname);
1518        hwloc_bitmap_free(cpuset);
1519        return -1;
1520      }
1521    }
1522    while (1) {
1523      struct hwloc__xml_import_state_s childstate;
1524      char *tag;
1525      ret = state->global->find_child(state, &childstate, &tag);
1526      if (ret <= 0)
1527        break;
1528      if (!strcmp(tag, "info")) {
1529        char *infoname = NULL;
1530        char *infovalue = NULL;
1531        ret = hwloc___xml_import_info(&infoname, &infovalue, &childstate);
1532        if (!ret && infoname && infovalue)
1533          hwloc__add_info(&infos, &nr_infos, infoname, infovalue);
1534      } else {
1535        if (hwloc__xml_verbose())
1536          fprintf(stderr, "%s: cpukind with unrecognized child %s\n",
1537                  state->global->msgprefix, tag);
1538        ret = -1;
1539      }
1540      if (ret < 0)
1541        goto error;
1542      state->global->close_child(&childstate);
1543    }
1544    if (!cpuset) {
1545      if (hwloc__xml_verbose())
1546        fprintf(stderr, "%s: ignoring cpukind without cpuset\n",
1547                state->global->msgprefix);
1548      goto error;
1549    }
1550    if (topology->flags & HWLOC_TOPOLOGY_FLAG_NO_CPUKINDS) {
1551      hwloc__free_infos(infos, nr_infos);
1552      hwloc_bitmap_free(cpuset);
1553    } else {
1554      hwloc_internal_cpukinds_register(topology, cpuset, forced_efficiency, infos, nr_infos, HWLOC_CPUKINDS_REGISTER_FLAG_OVERWRITE_FORCED_EFFICIENCY);
1555      hwloc__free_infos(infos, nr_infos);
1556    }
1557    return state->global->close_tag(state);
1558   error:
1559    hwloc__free_infos(infos, nr_infos);
1560    hwloc_bitmap_free(cpuset);
1561    return -1;
1562  }
1563  static int
1564  hwloc__xml_import_diff_one(hwloc__xml_import_state_t state,
1565  			   hwloc_topology_diff_t *firstdiffp,
1566  			   hwloc_topology_diff_t *lastdiffp)
1567  {
1568    char *type_s = NULL;
1569    char *obj_depth_s = NULL;
1570    char *obj_index_s = NULL;
1571    char *obj_attr_type_s = NULL;
1572    char *obj_attr_name_s = NULL;
1573    char *obj_attr_oldvalue_s = NULL;
1574    char *obj_attr_newvalue_s = NULL;
1575    while (1) {
1576      char *attrname, *attrvalue;
1577      if (state->global->next_attr(state, &attrname, &attrvalue) < 0)
1578        break;
1579      if (!strcmp(attrname, "type"))
1580        type_s = attrvalue;
1581      else if (!strcmp(attrname, "obj_depth"))
1582        obj_depth_s = attrvalue;
1583      else if (!strcmp(attrname, "obj_index"))
1584        obj_index_s = attrvalue;
1585      else if (!strcmp(attrname, "obj_attr_type"))
1586        obj_attr_type_s = attrvalue;
1587      else if (!strcmp(attrname, "obj_attr_index"))
1588        { &bsol;* obj_attr_index_s = attrvalue; unused for now */ }
1589      else if (!strcmp(attrname, "obj_attr_name"))
1590        obj_attr_name_s = attrvalue;
1591      else if (!strcmp(attrname, "obj_attr_oldvalue"))
1592        obj_attr_oldvalue_s = attrvalue;
1593      else if (!strcmp(attrname, "obj_attr_newvalue"))
1594        obj_attr_newvalue_s = attrvalue;
1595      else {
1596        if (hwloc__xml_verbose())
1597  	fprintf(stderr, "%s: ignoring unknown diff attribute %s\n",
1598  		state->global->msgprefix, attrname);
1599        return -1;
1600      }
1601    }
1602    if (type_s) {
1603      switch (atoi(type_s)) {
1604      default:
1605        break;
1606      case HWLOC_TOPOLOGY_DIFF_OBJ_ATTR: {
1607        hwloc_topology_diff_obj_attr_type_t obj_attr_type;
1608        hwloc_topology_diff_t diff;
1609        if (!obj_depth_s || !obj_index_s || !obj_attr_type_s) {
1610  	if (hwloc__xml_verbose())
1611  	  fprintf(stderr, "%s: missing mandatory obj attr generic attributes\n",
1612  		  state->global->msgprefix);
1613  	break;
1614        }
1615        if (!obj_attr_oldvalue_s || !obj_attr_newvalue_s) {
1616  	if (hwloc__xml_verbose())
1617  	  fprintf(stderr, "%s: missing mandatory obj attr value attributes\n",
1618  		  state->global->msgprefix);
1619  	break;
1620        }
1621        obj_attr_type = atoi(obj_attr_type_s);
1622        if (obj_attr_type == HWLOC_TOPOLOGY_DIFF_OBJ_ATTR_INFO && !obj_attr_name_s) {
1623  	if (hwloc__xml_verbose())
1624  	  fprintf(stderr, "%s: missing mandatory obj attr info name attribute\n",
1625  		  state->global->msgprefix);
1626  	break;
1627        }
1628        diff = malloc(sizeof(*diff));
1629        if (!diff)
1630  	return -1;
1631        diff->obj_attr.type = HWLOC_TOPOLOGY_DIFF_OBJ_ATTR;
1632        diff->obj_attr.obj_depth = atoi(obj_depth_s);
1633        diff->obj_attr.obj_index = atoi(obj_index_s);
1634        memset(&diff->obj_attr.diff, 0, sizeof(diff->obj_attr.diff));
1635        diff->obj_attr.diff.generic.type = obj_attr_type;
1636        switch (obj_attr_type) {
1637        case HWLOC_TOPOLOGY_DIFF_OBJ_ATTR_SIZE:
1638  	diff->obj_attr.diff.uint64.oldvalue = strtoull(obj_attr_oldvalue_s, NULL, 0);
1639  	diff->obj_attr.diff.uint64.newvalue = strtoull(obj_attr_newvalue_s, NULL, 0);
1640  	break;
1641        case HWLOC_TOPOLOGY_DIFF_OBJ_ATTR_INFO:
1642  	diff->obj_attr.diff.string.name = strdup(obj_attr_name_s);
1643        case HWLOC_TOPOLOGY_DIFF_OBJ_ATTR_NAME:
1644  	diff->obj_attr.diff.string.oldvalue = strdup(obj_attr_oldvalue_s);
1645  	diff->obj_attr.diff.string.newvalue = strdup(obj_attr_newvalue_s);
1646  	break;
1647        }
1648        if (*firstdiffp)
1649  	(*lastdiffp)->generic.next = diff;
1650        else
1651          *firstdiffp = diff;
1652        *lastdiffp = diff;
1653        diff->generic.next = NULL;
1654      }
1655      }
1656    }
1657    return state->global->close_tag(state);
1658  }
1659  int
1660  hwloc__xml_import_diff(hwloc__xml_import_state_t state,
1661  		       hwloc_topology_diff_t *firstdiffp)
1662  {
1663    hwloc_topology_diff_t firstdiff = NULL, lastdiff = NULL;
1664    *firstdiffp = NULL;
1665    while (1) {
1666      struct hwloc__xml_import_state_s childstate;
1667      char *tag;
1668      int ret;
1669      ret = state->global->find_child(state, &childstate, &tag);
1670      if (ret < 0)
1671        return -1;
1672      if (!ret)
1673        break;
1674      if (!strcmp(tag, "diff")) {
1675        ret = hwloc__xml_import_diff_one(&childstate, &firstdiff, &lastdiff);
1676      } else
1677        ret = -1;
1678      if (ret < 0)
1679        return ret;
1680      state->global->close_child(&childstate);
1681    }
1682    *firstdiffp = firstdiff;
1683    return 0;
1684  }
1685  static void
1686  hwloc_convert_from_v1dist_floats(hwloc_topology_t topology, unsigned nbobjs, float *floats, uint64_t *u64s)
1687  {
1688    unsigned i;
1689    int is_uint;
1690    char *env;
1691    float scale = 1000.f;
1692    char scalestring[20];
1693    env = getenv("HWLOC_XML_V1DIST_SCALE");
1694    if (env) {
1695      scale = (float) atof(env);
1696      goto scale;
1697    }
1698    is_uint = 1;
1699    for(i=0; i<nbobjs*nbobjs; i++) {
1700      float f, iptr, fptr;
1701      f = floats[i];
1702      if (f < 0.f) {
1703        is_uint = 0;
1704        break;
1705      }
1706      fptr = modff(f, &iptr);
1707      if (fptr > .001f && fptr < .999f) {
1708        is_uint = 0;
1709        break;
1710      }
1711      u64s[i] = (int)(f+.5f);
1712    }
1713    if (is_uint)
1714      return;
1715   scale:
1716    for(i=0; i<nbobjs*nbobjs; i++)
1717      u64s[i] = (uint64_t)(scale * floats[i]);
1718    sprintf(scalestring, "%f", scale);
1719    hwloc_obj_add_info(hwloc_get_root_obj(topology), "xmlv1DistancesScale", scalestring);
1720  }
1721  static int
1722  hwloc_look_xml(struct hwloc_backend *backend, struct hwloc_disc_status *dstatus)
1723  {
1724    struct hwloc_topology *topology = backend->topology;
1725    struct hwloc_xml_backend_data_s *data = backend->private_data;
1726    struct hwloc__xml_import_state_s state, childstate;
1727    struct hwloc_obj *root = topology->levels[0][0];
1728    char *tag;
1729    int gotignored = 0;
1730    hwloc_localeswitch_declare;
1731    int ret;
1732    assert(dstatus->phase == HWLOC_DISC_PHASE_GLOBAL);
1733    state.global = data;
1734    assert(!root->cpuset);
1735    hwloc_localeswitch_init();
1736    data->nbnumanodes = 0;
1737    data->first_numanode = data->last_numanode = NULL;
1738    data->first_v1dist = data->last_v1dist = NULL;
1739    ret = data->look_init(data, &state);
1740    if (ret < 0)
1741      goto failed;
1742    if (data->version_major > 2) {
1743      if (hwloc__xml_verbose())
1744        fprintf(stderr, "%s: cannot import XML version %u.%u > 2\n",
1745  	      data->msgprefix, data->version_major, data->version_minor);
1746      goto err;
1747    }
1748    ret = state.global->find_child(&state, &childstate, &tag);
1749    if (ret < 0 || !ret || strcmp(tag, "object"))
1750      goto failed;
1751    ret = hwloc__xml_import_object(topology, data, NULL &bsol;*  no parent */, root,
1752  				 &gotignored,
1753  				 &childstate);
1754    if (ret < 0)
1755      goto failed;
1756    state.global->close_child(&childstate);
1757    assert(!gotignored);
1758    root = topology->levels[0][0];
1759    if (data->version_major >= 2) {
1760      while (1) {
1761        ret = state.global->find_child(&state, &childstate, &tag);
1762        if (ret < 0)
1763  	goto failed;
1764        if (!ret)
1765  	break;
1766        if (!strcmp(tag, "distances2")) {
1767  	ret = hwloc__xml_v2import_distances(topology, &childstate, 0);
1768  	if (ret < 0)
1769  	  goto failed;
1770        } else if (!strcmp(tag, "distances2hetero")) {
1771  	ret = hwloc__xml_v2import_distances(topology, &childstate, 1);
1772  	if (ret < 0)
1773  	  goto failed;
1774        } else if (!strcmp(tag, "support")) {
1775  	ret = hwloc__xml_v2import_support(topology, &childstate);
1776  	if (ret < 0)
1777  	  goto failed;
1778        } else if (!strcmp(tag, "memattr")) {
1779          ret = hwloc__xml_import_memattr(topology, &childstate);
1780          if (ret < 0)
1781            goto failed;
1782        } else if (!strcmp(tag, "cpukind")) {
1783          ret = hwloc__xml_import_cpukind(topology, &childstate);
1784          if (ret < 0)
1785            goto failed;
1786        } else {
1787  	if (hwloc__xml_verbose())
1788  	  fprintf(stderr, "%s: ignoring unknown tag `%s' after root object.\n",
1789  		  data->msgprefix, tag);
1790  	goto done;
1791        }
1792        state.global->close_child(&childstate);
1793      }
1794    }
1795    state.global->close_tag(&state);
1796  done:
1797    if (!root->cpuset) {
1798      if (hwloc__xml_verbose())
1799        fprintf(stderr, "%s: invalid root object without cpuset\n",
1800  	      data->msgprefix);
1801      goto err;
1802    }
1803    if (data->version_major < 2 && data->first_numanode) {
1804      hwloc_obj_t node = data->first_numanode;
1805      do {
1806        if (node->parent->type == HWLOC_OBJ_GROUP
1807  	  && !node->parent->gp_index)
1808  	node->parent->gp_index = topology->next_gp_index++;
1809        node = node->next_cousin;
1810      } while (node);
1811    }
1812    if (data->version_major < 2 && data->first_v1dist) {
1813      struct hwloc__xml_imported_v1distances_s *v1dist, *v1next = data->first_v1dist;
1814      while ((v1dist = v1next) != NULL) {
1815        unsigned nbobjs = v1dist->nbobjs;
1816        v1next = v1dist->next;
1817        if (nbobjs == data->nbnumanodes
1818            && !(topology->flags & HWLOC_TOPOLOGY_FLAG_NO_DISTANCES)) {
1819  	hwloc_obj_t *objs = malloc(nbobjs*sizeof(hwloc_obj_t));
1820  	uint64_t *values = malloc(nbobjs*nbobjs*sizeof(*values));
1821          assert(data->nbnumanodes > 0); &bsol;* v1dist->nbobjs is >0 after import */
1822          assert(data->first_numanode);
1823  	if (objs && values) {
1824  	  hwloc_obj_t node;
1825  	  unsigned i;
1826  	  for(i=0, node = data->first_numanode;
1827  	      i<nbobjs;
1828  	      i++, node = node->next_cousin)
1829  	    objs[i] = node;
1830  	  hwloc_convert_from_v1dist_floats(topology, nbobjs, v1dist->floats, values);
1831  	  hwloc_internal_distances_add(topology, NULL, nbobjs, objs, values, v1dist->kind, 0);
1832  	} else {
1833  	  free(objs);
1834  	  free(values);
1835  	}
1836        }
1837        free(v1dist->floats);
1838        free(v1dist);
1839      }
1840      data->first_v1dist = data->last_v1dist = NULL;
1841    }
1842    if (data->version_major >= 2) {
1843      if (!root->nodeset) {
1844        if (hwloc__xml_verbose())
1845  	fprintf(stderr, "%s: invalid root object without nodeset\n",
1846  		data->msgprefix);
1847        goto err;
1848      }
1849      if (hwloc_bitmap_iszero(root->nodeset)) {
1850        if (hwloc__xml_verbose())
1851  	fprintf(stderr, "%s: invalid root object with empty nodeset\n",
1852  		data->msgprefix);
1853        goto err;
1854      }
1855    } else {
1856    }
1857    hwloc_alloc_root_sets(root);
1858    if (!(topology->flags & HWLOC_TOPOLOGY_FLAG_IMPORT_SUPPORT)) {
1859      topology->support.discovery->pu = 1;
1860      topology->support.discovery->disallowed_pu = 1;
1861      if (data->nbnumanodes) {
1862        topology->support.discovery->numa = 1;
1863        topology->support.discovery->numa_memory = 1; 
1864        topology->support.discovery->disallowed_numa = 1;
1865      }
1866    }
1867    if (data->look_done)
1868      data->look_done(data, 0);
1869    hwloc_localeswitch_fini();
1870    return 0;
1871   failed:
1872    if (data->look_done)
1873      data->look_done(data, -1);
1874    if (hwloc__xml_verbose())
1875      fprintf(stderr, "%s: XML component discovery failed.\n",
1876  	    data->msgprefix);
1877   err:
1878    hwloc_free_object_siblings_and_children(root->first_child);
1879    root->first_child = NULL;
1880    hwloc_free_object_siblings_and_children(root->memory_first_child);
1881    root->memory_first_child = NULL;
1882    hwloc_free_object_siblings_and_children(root->io_first_child);
1883    root->io_first_child = NULL;
1884    hwloc_free_object_siblings_and_children(root->misc_first_child);
1885    root->misc_first_child = NULL;
1886    if (root->cpuset)
1887      hwloc_bitmap_zero(root->cpuset);
1888    if (root->nodeset)
1889      hwloc_bitmap_zero(root->nodeset);
1890    hwloc_localeswitch_fini();
1891    return -1;
1892  }
1893  int
1894  hwloc_topology_diff_load_xml(const char *xmlpath,
1895  			     hwloc_topology_diff_t *firstdiffp, char **refnamep)
1896  {
1897    struct hwloc__xml_import_state_s state;
1898    struct hwloc_xml_backend_data_s fakedata; &bsol;* only for storing global info during parsing */
1899    hwloc_localeswitch_declare;
1900    const char *local_basename;
1901    int force_nolibxml;
1902    int ret;
1903    state.global = &fakedata;
1904    local_basename = strrchr(xmlpath, '/');
1905    if (local_basename)
1906      local_basename++;
1907    else
1908      local_basename = xmlpath;
1909    fakedata.msgprefix = strdup(local_basename);
1910    hwloc_components_init();
1911    assert(hwloc_nolibxml_callbacks);
1912    hwloc_localeswitch_init();
1913    *firstdiffp = NULL;
1914    force_nolibxml = hwloc_nolibxml_import();
1915  retry:
1916    if (!hwloc_libxml_callbacks || (hwloc_nolibxml_callbacks && force_nolibxml))
1917      ret = hwloc_nolibxml_callbacks->import_diff(&state, xmlpath, NULL, 0, firstdiffp, refnamep);
1918    else {
1919      ret = hwloc_libxml_callbacks->import_diff(&state, xmlpath, NULL, 0, firstdiffp, refnamep);
1920      if (ret < 0 && errno == ENOSYS) {
1921        hwloc_libxml_callbacks = NULL;
1922        goto retry;
1923      }
1924    }
1925    hwloc_localeswitch_fini();
1926    hwloc_components_fini();
1927    free(fakedata.msgprefix);
1928    return ret;
1929  }
1930  int
1931  hwloc_topology_diff_load_xmlbuffer(const char *xmlbuffer, int buflen,
1932  				   hwloc_topology_diff_t *firstdiffp, char **refnamep)
1933  {
1934    struct hwloc__xml_import_state_s state;
1935    struct hwloc_xml_backend_data_s fakedata; &bsol;* only for storing global info during parsing */
1936    hwloc_localeswitch_declare;
1937    int force_nolibxml;
1938    int ret;
1939    state.global = &fakedata;
1940    fakedata.msgprefix = strdup("xmldiffbuffer");
1941    hwloc_components_init();
1942    assert(hwloc_nolibxml_callbacks);
1943    hwloc_localeswitch_init();
1944    *firstdiffp = NULL;
1945    force_nolibxml = hwloc_nolibxml_import();
1946   retry:
1947    if (!hwloc_libxml_callbacks || (hwloc_nolibxml_callbacks && force_nolibxml))
1948      ret = hwloc_nolibxml_callbacks->import_diff(&state, NULL, xmlbuffer, buflen, firstdiffp, refnamep);
1949    else {
1950      ret = hwloc_libxml_callbacks->import_diff(&state, NULL, xmlbuffer, buflen, firstdiffp, refnamep);
1951      if (ret < 0 && errno == ENOSYS) {
1952        hwloc_libxml_callbacks = NULL;
1953        goto retry;
1954      }
1955    }
1956    hwloc_localeswitch_fini();
1957    hwloc_components_fini();
1958    free(fakedata.msgprefix);
1959    return ret;
1960  }
1961  #define HWLOC_XML_CHAR_VALID(c) (((c) >= 32 && (c) <= 126) || (c) == '\t' || (c) == '\n' || (c) == '\r')
1962  static int
1963  hwloc__xml_export_check_buffer(const char *buf, size_t length)
1964  {
1965    unsigned i;
1966    for(i=0; i<length; i++)
1967      if (!HWLOC_XML_CHAR_VALID(buf[i]))
1968        return -1;
1969    return 0;
1970  }
1971  static char*
1972  hwloc__xml_export_safestrdup(const char *old)
1973  {
1974    char *new = malloc(strlen(old)+1);
1975    char *dst = new;
1976    const char *src = old;
1977    if (!new)
1978      return NULL;
1979    while (*src) {
1980      if (HWLOC_XML_CHAR_VALID(*src))
1981        *(dst++) = *src;
1982      src++;
1983    }
1984    *dst = '\0';
1985    return new;
1986  }
1987  static void
1988  hwloc__xml_export_object_contents (hwloc__xml_export_state_t state, hwloc_topology_t topology, hwloc_obj_t obj, unsigned long flags)
1989  {
1990    char *setstring = NULL, *setstring2 = NULL;
1991    char tmp[255];
1992    int v1export = flags & HWLOC_TOPOLOGY_EXPORT_XML_FLAG_V1;
1993    unsigned i,j;
1994    if (v1export && obj->type == HWLOC_OBJ_PACKAGE)
1995      state->new_prop(state, "type", "Socket");
1996    else if (v1export && obj->type == HWLOC_OBJ_DIE)
1997      state->new_prop(state, "type", "Group");
1998    else if (v1export && hwloc__obj_type_is_cache(obj->type))
1999      state->new_prop(state, "type", "Cache");
2000    else
2001      state->new_prop(state, "type", hwloc_obj_type_string(obj->type));
2002    if (obj->os_index != HWLOC_UNKNOWN_INDEX) {
2003      sprintf(tmp, "%u", obj->os_index);
2004      state->new_prop(state, "os_index", tmp);
2005    }
2006    if (obj->cpuset) {
2007      int empty_cpusets = 0;
2008      if (v1export && obj->type == HWLOC_OBJ_NUMANODE) {
2009        hwloc_obj_t parent = obj;
2010        while (!hwloc_obj_type_is_normal(parent->type)) {
2011  	if (parent->sibling_rank > 0) {
2012  	  empty_cpusets = 1;
2013  	  break;
2014  	}
2015  	parent = parent->parent;
2016        }
2017      }
2018      if (empty_cpusets) {
2019        state->new_prop(state, "cpuset", "0x0");
2020        state->new_prop(state, "online_cpuset", "0x0");
2021        state->new_prop(state, "complete_cpuset", "0x0");
2022        state->new_prop(state, "allowed_cpuset", "0x0");
2023      } else {
2024        hwloc_bitmap_asprintf(&setstring, obj->cpuset);
2025        state->new_prop(state, "cpuset", setstring);
2026        hwloc_bitmap_asprintf(&setstring2, obj->complete_cpuset);
2027        state->new_prop(state, "complete_cpuset", setstring2);
2028        free(setstring2);
2029        if (v1export)
2030  	state->new_prop(state, "online_cpuset", setstring);
2031        free(setstring);
2032        if (v1export) {
2033  	hwloc_bitmap_t allowed_cpuset = hwloc_bitmap_dup(obj->cpuset);
2034  	hwloc_bitmap_and(allowed_cpuset, allowed_cpuset, topology->allowed_cpuset);
2035  	hwloc_bitmap_asprintf(&setstring, allowed_cpuset);
2036  	state->new_prop(state, "allowed_cpuset", setstring);
2037  	free(setstring);
2038  	hwloc_bitmap_free(allowed_cpuset);
2039        } else if (!obj->parent) {
2040  	hwloc_bitmap_asprintf(&setstring, topology->allowed_cpuset);
2041  	state->new_prop(state, "allowed_cpuset", setstring);
2042  	free(setstring);
2043        }
2044      }
2045      hwloc_bitmap_asprintf(&setstring, obj->nodeset);
2046      state->new_prop(state, "nodeset", setstring);
2047      free(setstring);
2048      hwloc_bitmap_asprintf(&setstring, obj->complete_nodeset);
2049      state->new_prop(state, "complete_nodeset", setstring);
2050      free(setstring);
2051      if (v1export) {
2052        hwloc_bitmap_t allowed_nodeset = hwloc_bitmap_dup(obj->nodeset);
2053        hwloc_bitmap_and(allowed_nodeset, allowed_nodeset, topology->allowed_nodeset);
2054        hwloc_bitmap_asprintf(&setstring, allowed_nodeset);
2055        state->new_prop(state, "allowed_nodeset", setstring);
2056        free(setstring);
2057        hwloc_bitmap_free(allowed_nodeset);
2058      } else if (!obj->parent) {
2059        hwloc_bitmap_asprintf(&setstring, topology->allowed_nodeset);
2060        state->new_prop(state, "allowed_nodeset", setstring);
2061        free(setstring);
2062      }
2063    }
2064    if (!v1export) {
2065      sprintf(tmp, "%llu", (unsigned long long) obj->gp_index);
2066      state->new_prop(state, "gp_index", tmp);
2067    }
2068    if (obj->name) {
2069      char *name = hwloc__xml_export_safestrdup(obj->name);
2070      if (name) {
2071        state->new_prop(state, "name", name);
2072        free(name);
2073      }
2074    }
2075    if (!v1export && obj->subtype) {
2076      char *subtype = hwloc__xml_export_safestrdup(obj->subtype);
2077      if (subtype) {
2078        state->new_prop(state, "subtype", subtype);
2079        free(subtype);
2080      }
2081    }
2082    switch (obj->type) {
2083    case HWLOC_OBJ_NUMANODE:
2084      if (obj->attr->numanode.local_memory) {
2085        sprintf(tmp, "%llu", (unsigned long long) obj->attr->numanode.local_memory);
2086        state->new_prop(state, "local_memory", tmp);
2087      }
2088      for(i=0; i<obj->attr->numanode.page_types_len; i++) {
2089        struct hwloc__xml_export_state_s childstate;
2090        state->new_child(state, &childstate, "page_type");
2091        sprintf(tmp, "%llu", (unsigned long long) obj->attr->numanode.page_types[i].size);
2092        childstate.new_prop(&childstate, "size", tmp);
2093        sprintf(tmp, "%llu", (unsigned long long) obj->attr->numanode.page_types[i].count);
2094        childstate.new_prop(&childstate, "count", tmp);
2095        childstate.end_object(&childstate, "page_type");
2096      }
2097      break;
2098    case HWLOC_OBJ_L1CACHE:
2099    case HWLOC_OBJ_L2CACHE:
2100    case HWLOC_OBJ_L3CACHE:
2101    case HWLOC_OBJ_L4CACHE:
2102    case HWLOC_OBJ_L5CACHE:
2103    case HWLOC_OBJ_L1ICACHE:
2104    case HWLOC_OBJ_L2ICACHE:
2105    case HWLOC_OBJ_L3ICACHE:
2106    case HWLOC_OBJ_MEMCACHE:
2107      sprintf(tmp, "%llu", (unsigned long long) obj->attr->cache.size);
2108      state->new_prop(state, "cache_size", tmp);
2109      sprintf(tmp, "%u", obj->attr->cache.depth);
2110      state->new_prop(state, "depth", tmp);
2111      sprintf(tmp, "%u", (unsigned) obj->attr->cache.linesize);
2112      state->new_prop(state, "cache_linesize", tmp);
2113      sprintf(tmp, "%d", obj->attr->cache.associativity);
2114      state->new_prop(state, "cache_associativity", tmp);
2115      sprintf(tmp, "%d", (int) obj->attr->cache.type);
2116      state->new_prop(state, "cache_type", tmp);
2117      break;
2118    case HWLOC_OBJ_GROUP:
2119      if (v1export) {
2120        sprintf(tmp, "%u", obj->attr->group.depth);
2121        state->new_prop(state, "depth", tmp);
2122        if (obj->attr->group.dont_merge)
2123          state->new_prop(state, "dont_merge", "1");
2124      } else {
2125        sprintf(tmp, "%u", obj->attr->group.kind);
2126        state->new_prop(state, "kind", tmp);
2127        sprintf(tmp, "%u", obj->attr->group.subkind);
2128        state->new_prop(state, "subkind", tmp);
2129        if (obj->attr->group.dont_merge)
2130          state->new_prop(state, "dont_merge", "1");
2131      }
2132      break;
2133    case HWLOC_OBJ_BRIDGE:
2134      sprintf(tmp, "%d-%d", (int) obj->attr->bridge.upstream_type, (int) obj->attr->bridge.downstream_type);
2135      state->new_prop(state, "bridge_type", tmp);
2136      sprintf(tmp, "%u", obj->attr->bridge.depth);
2137      state->new_prop(state, "depth", tmp);
2138      if (obj->attr->bridge.downstream_type == HWLOC_OBJ_BRIDGE_PCI) {
2139        sprintf(tmp, "%04x:[%02x-%02x]",
2140  	      (unsigned) obj->attr->bridge.downstream.pci.domain,
2141  	      (unsigned) obj->attr->bridge.downstream.pci.secondary_bus,
2142  	      (unsigned) obj->attr->bridge.downstream.pci.subordinate_bus);
2143        state->new_prop(state, "bridge_pci", tmp);
2144      }
2145      if (obj->attr->bridge.upstream_type != HWLOC_OBJ_BRIDGE_PCI)
2146        break;
2147    case HWLOC_OBJ_PCI_DEVICE:
2148      sprintf(tmp, "%04x:%02x:%02x.%01x",
2149  	    (unsigned) obj->attr->pcidev.domain,
2150  	    (unsigned) obj->attr->pcidev.bus,
2151  	    (unsigned) obj->attr->pcidev.dev,
2152  	    (unsigned) obj->attr->pcidev.func);
2153      state->new_prop(state, "pci_busid", tmp);
2154      sprintf(tmp, "%04x [%04x:%04x] [%04x:%04x] %02x",
2155  	    (unsigned) obj->attr->pcidev.class_id,
2156  	    (unsigned) obj->attr->pcidev.vendor_id, (unsigned) obj->attr->pcidev.device_id,
2157  	    (unsigned) obj->attr->pcidev.subvendor_id, (unsigned) obj->attr->pcidev.subdevice_id,
2158  	    (unsigned) obj->attr->pcidev.revision);
2159      state->new_prop(state, "pci_type", tmp);
2160      sprintf(tmp, "%f", obj->attr->pcidev.linkspeed);
2161      state->new_prop(state, "pci_link_speed", tmp);
2162      break;
2163    case HWLOC_OBJ_OS_DEVICE:
2164      sprintf(tmp, "%d", (int) obj->attr->osdev.type);
2165      state->new_prop(state, "osdev_type", tmp);
2166      break;
2167    default:
2168      break;
2169    }
2170    for(i=0; i<obj->infos_count; i++) {
2171      char *name = hwloc__xml_export_safestrdup(obj->infos[i].name);
2172      char *value = hwloc__xml_export_safestrdup(obj->infos[i].value);
2173      if (name && value) {
2174        struct hwloc__xml_export_state_s childstate;
2175        state->new_child(state, &childstate, "info");
2176        childstate.new_prop(&childstate, "name", name);
2177        childstate.new_prop(&childstate, "value", value);
2178        childstate.end_object(&childstate, "info");
2179      }
2180      free(name);
2181      free(value);
2182    }
2183    if (v1export && obj->subtype) {
2184      char *subtype = hwloc__xml_export_safestrdup(obj->subtype);
2185      if (subtype) {
2186        struct hwloc__xml_export_state_s childstate;
2187        int is_coproctype = (obj->type == HWLOC_OBJ_OS_DEVICE && obj->attr->osdev.type == HWLOC_OBJ_OSDEV_COPROC);
2188        state->new_child(state, &childstate, "info");
2189        childstate.new_prop(&childstate, "name", is_coproctype ? "CoProcType" : "Type");
2190        childstate.new_prop(&childstate, "value", subtype);
2191        childstate.end_object(&childstate, "info");
2192        free(subtype);
2193      }
2194    }
2195    if (v1export && obj->type == HWLOC_OBJ_DIE) {
2196      struct hwloc__xml_export_state_s childstate;
2197      state->new_child(state, &childstate, "info");
2198      childstate.new_prop(&childstate, "name", "Type");
2199      childstate.new_prop(&childstate, "value", "Die");
2200      childstate.end_object(&childstate, "info");
2201    }
2202    if (v1export && !obj->parent) {
2203      struct hwloc_internal_distances_s *dist;
2204      hwloc_internal_distances_refresh(topology);
2205      for(dist = topology->first_dist; dist; dist = dist->next) {
2206        struct hwloc__xml_export_state_s childstate;
2207        unsigned nbobjs = dist->nbobjs;
2208        unsigned *logical_to_v2array;
2209        int depth;
2210        if (nbobjs != (unsigned) hwloc_get_nbobjs_by_type(topology, dist->unique_type))
2211  	continue;
2212        if (!(dist->kind & HWLOC_DISTANCES_KIND_MEANS_LATENCY))
2213  	continue;
2214        if (dist->kind & HWLOC_DISTANCES_KIND_HETEROGENEOUS_TYPES)
2215  	continue;
2216        logical_to_v2array = malloc(nbobjs * sizeof(*logical_to_v2array));
2217        if (!logical_to_v2array) {
2218          if (HWLOC_SHOW_ALL_ERRORS())
2219            fprintf(stderr, "hwloc/xml/export/v1: failed to allocated logical_to_v2array\n");
2220  	continue;
2221        }
2222        for(i=0; i<nbobjs; i++)
2223  	logical_to_v2array[dist->objs[i]->logical_index] = i;
2224        if (dist->unique_type == HWLOC_OBJ_NUMANODE) {
2225  	depth = -1;
2226  	for(i=0; i<nbobjs; i++) {
2227  	  hwloc_obj_t parent = dist->objs[i]->parent;
2228  	  while (hwloc__obj_type_is_memory(parent->type))
2229  	    parent = parent->parent;
2230  	  if (parent->depth+1 > depth)
2231  	    depth = parent->depth+1;
2232  	}
2233        } else {
2234  	int parent_with_memory = 0;
2235  	for(i=0; i<nbobjs; i++) {
2236  	  hwloc_obj_t parent = dist->objs[i]->parent;
2237  	  while (parent) {
2238  	    if (parent->memory_first_child) {
2239  	      parent_with_memory = 1;
2240  	      goto done;
2241  	    }
2242  	    parent = parent->parent;
2243  	  }
2244  	}
2245        done:
2246  	depth = hwloc_get_type_depth(topology, dist->unique_type) + parent_with_memory;
2247        }
2248        state->new_child(state, &childstate, "distances");
2249        sprintf(tmp, "%u", nbobjs);
2250        childstate.new_prop(&childstate, "nbobjs", tmp);
2251        sprintf(tmp, "%d", depth);
2252        childstate.new_prop(&childstate, "relative_depth", tmp);
2253        sprintf(tmp, "%f", 1.f);
2254        childstate.new_prop(&childstate, "latency_base", tmp);
2255        for(i=0; i<nbobjs; i++) {
2256          for(j=0; j<nbobjs; j++) {
2257  	  unsigned k = logical_to_v2array[i]*nbobjs+logical_to_v2array[j];
2258  	  struct hwloc__xml_export_state_s greatchildstate;
2259  	  childstate.new_child(&childstate, &greatchildstate, "latency");
2260  	  sprintf(tmp, "%f", (float) dist->values[k]);
2261  	  greatchildstate.new_prop(&greatchildstate, "value", tmp);
2262  	  greatchildstate.end_object(&greatchildstate, "latency");
2263  	}
2264        }
2265        childstate.end_object(&childstate, "distances");
2266        free(logical_to_v2array);
2267      }
2268    }
2269    if (obj->userdata && topology->userdata_export_cb)
2270      topology->userdata_export_cb((void*) state, topology, obj);
2271  }
2272  static void
2273  hwloc__xml_v2export_object (hwloc__xml_export_state_t parentstate, hwloc_topology_t topology, hwloc_obj_t obj, unsigned long flags)
2274  {
2275    struct hwloc__xml_export_state_s state;
2276    hwloc_obj_t child;
2277    parentstate->new_child(parentstate, &state, "object");
2278    hwloc__xml_export_object_contents(&state, topology, obj, flags);
2279    for_each_memory_child(child, obj)
2280      hwloc__xml_v2export_object (&state, topology, child, flags);
2281    for_each_child(child, obj)
2282      hwloc__xml_v2export_object (&state, topology, child, flags);
2283    for_each_io_child(child, obj)
2284      hwloc__xml_v2export_object (&state, topology, child, flags);
2285    for_each_misc_child(child, obj)
2286      hwloc__xml_v2export_object (&state, topology, child, flags);
2287    state.end_object(&state, "object");
2288  }
2289  static void
2290  hwloc__xml_v1export_object (hwloc__xml_export_state_t parentstate, hwloc_topology_t topology, hwloc_obj_t obj, unsigned long flags);
2291  static hwloc_obj_t
2292  hwloc__xml_v1export_object_next_numanode(hwloc_obj_t obj, hwloc_obj_t cur)
2293  {
2294    hwloc_obj_t parent;
2295    if (!cur) {
2296      cur = obj->memory_first_child;
2297      goto find_first;
2298    }
2299    parent = cur;
2300    while (1) {
2301      if (parent->next_sibling) {
2302        cur = parent->next_sibling;
2303        break;
2304      }
2305      parent = parent->parent;
2306      if (parent == obj)
2307        return NULL;
2308    }
2309   find_first:
2310    while (cur->type != HWLOC_OBJ_NUMANODE)
2311      cur = cur->memory_first_child;
2312    assert(cur);
2313    return cur;
2314  }
2315  static unsigned
2316  hwloc__xml_v1export_object_list_numanodes(hwloc_obj_t obj, hwloc_obj_t *first_p, hwloc_obj_t **nodes_p)
2317  {
2318    hwloc_obj_t *nodes, cur;
2319    int nr;
2320    if (!obj->memory_first_child) {
2321      *first_p = NULL;
2322      *nodes_p = NULL;
2323      return 0;
2324    }
2325    nr = hwloc_bitmap_weight(obj->nodeset);
2326    assert(nr > 0);
2327    nodes = calloc(nr, sizeof(*nodes));
2328    if (!nodes) {
2329      cur = hwloc__xml_v1export_object_next_numanode(obj, NULL);
2330      assert(cur);
2331      *first_p = cur;
2332      *nodes_p = NULL;
2333      return 1;
2334    }
2335    nr = 0;
2336    cur = NULL;
2337    while (1) {
2338      cur = hwloc__xml_v1export_object_next_numanode(obj, cur);
2339      if (!cur)
2340        break;
2341      nodes[nr++] = cur;
2342    }
2343    *first_p = nodes[0];
2344    *nodes_p = nodes;
2345    return nr;
2346  }
2347  static void
2348  hwloc__xml_v1export_object_with_memory(hwloc__xml_export_state_t parentstate, hwloc_topology_t topology, hwloc_obj_t obj, unsigned long flags)
2349  {
2350    struct hwloc__xml_export_state_s gstate, mstate, ostate, *state = parentstate;
2351    hwloc_obj_t child;
2352    unsigned nr_numanodes;
2353    hwloc_obj_t *numanodes, first_numanode;
2354    unsigned i;
2355    nr_numanodes = hwloc__xml_v1export_object_list_numanodes(obj, &first_numanode, &numanodes);
2356    if (obj->parent->arity > 1 && nr_numanodes > 1 && parentstate->global->v1_memory_group) {
2357      hwloc_obj_t group = parentstate->global->v1_memory_group;
2358      parentstate->new_child(parentstate, &gstate, "object");
2359      group->parent = obj->parent;
2360      group->cpuset = obj->cpuset;
2361      group->complete_cpuset = obj->complete_cpuset;
2362      group->nodeset = obj->nodeset;
2363      group->complete_nodeset = obj->complete_nodeset;
2364      hwloc__xml_export_object_contents (&gstate, topology, group, flags);
2365      group->cpuset = NULL;
2366      group->complete_cpuset = NULL;
2367      group->nodeset = NULL;
2368      group->complete_nodeset = NULL;
2369      state = &gstate;
2370    }
2371    state->new_child(state, &mstate, "object");
2372    hwloc__xml_export_object_contents (&mstate, topology, first_numanode, flags);
2373    mstate.new_child(&mstate, &ostate, "object");
2374    hwloc__xml_export_object_contents (&ostate, topology, obj, flags);
2375    for_each_child(child, obj)
2376      hwloc__xml_v1export_object (&ostate, topology, child, flags);
2377    for_each_io_child(child, obj)
2378      hwloc__xml_v1export_object (&ostate, topology, child, flags);
2379    for_each_misc_child(child, obj)
2380      hwloc__xml_v1export_object (&ostate, topology, child, flags);
2381    ostate.end_object(&ostate, "object");
2382    mstate.end_object(&mstate, "object");
2383    for(i=1; i<nr_numanodes; i++)
2384      hwloc__xml_v1export_object (state, topology, numanodes[i], flags);
2385    free(numanodes);
2386    if (state == &gstate) {
2387      gstate.end_object(&gstate, "object");
2388    }
2389  }
2390  static void
2391  hwloc__xml_v1export_object (hwloc__xml_export_state_t parentstate, hwloc_topology_t topology, hwloc_obj_t obj, unsigned long flags)
2392  {
2393    struct hwloc__xml_export_state_s state;
2394    hwloc_obj_t child;
2395    parentstate->new_child(parentstate, &state, "object");
2396    hwloc__xml_export_object_contents(&state, topology, obj, flags);
2397    for_each_child(child, obj) {
2398      if (!child->memory_arity) {
2399        hwloc__xml_v1export_object (&state, topology, child, flags);
2400      } else {
2401        hwloc__xml_v1export_object_with_memory(&state, topology, child, flags);
2402      }
2403    }
2404    for_each_io_child(child, obj)
2405      hwloc__xml_v1export_object (&state, topology, child, flags);
2406    for_each_misc_child(child, obj)
2407      hwloc__xml_v1export_object (&state, topology, child, flags);
2408    state.end_object(&state, "object");
2409  }
2410  #define EXPORT_ARRAY(state, type, nr, values, tagname, format, maxperline) do { \
2411    unsigned _i = 0; \
2412    while (_i<(nr)) { \
2413      char _tmp[255]; &bsol;* enough for (snprintf(format)+space) x maxperline */ \
2414      char _tmp2[16]; \
2415      size_t _len = 0; \
2416      unsigned _j; \
2417      struct hwloc__xml_export_state_s _childstate; \
2418      (state)->new_child(state, &_childstate, tagname); \
2419      for(_j=0; \
2420  	_i+_j<(nr) && _j<maxperline; \
2421  	_j++) \
2422        _len += sprintf(_tmp+_len, format " ", (type) (values)[_i+_j]); \
2423      _i += _j; \
2424      sprintf(_tmp2, "%lu", (unsigned long) _len); \
2425      _childstate.new_prop(&_childstate, "length", _tmp2); \
2426      _childstate.add_content(&_childstate, _tmp, _len); \
2427      _childstate.end_object(&_childstate, tagname); \
2428    } \
2429  } while (0)
2430  #define EXPORT_TYPE_GPINDEX_ARRAY(state, nr, objs, tagname, maxperline) do { \
2431    unsigned _i = 0; \
2432    while (_i<(nr)) { \
2433      char _tmp[255]; &bsol;* enough for (snprintf(type+index)+space) x maxperline */ \
2434      char _tmp2[16]; \
2435      size_t _len = 0; \
2436      unsigned _j; \
2437      struct hwloc__xml_export_state_s _childstate; \
2438      (state)->new_child(state, &_childstate, tagname); \
2439      for(_j=0; \
2440  	_i+_j<(nr) && _j<maxperline; \
2441  	_j++) \
2442        _len += sprintf(_tmp+_len, "%s:%llu ", hwloc_obj_type_string((objs)[_i+_j]->type), (unsigned long long) (objs)[_i+_j]->gp_index); \
2443      _i += _j; \
2444      sprintf(_tmp2, "%lu", (unsigned long) _len); \
2445      _childstate.new_prop(&_childstate, "length", _tmp2); \
2446      _childstate.add_content(&_childstate, _tmp, _len); \
2447      _childstate.end_object(&_childstate, tagname); \
2448    } \
2449  } while (0)
2450  static void
2451  hwloc___xml_v2export_distances(hwloc__xml_export_state_t parentstate, struct hwloc_internal_distances_s *dist)
2452  {
2453    char tmp[255];
2454    unsigned nbobjs = dist->nbobjs;
2455    struct hwloc__xml_export_state_s state;
2456    if (dist->different_types) {
2457      parentstate->new_child(parentstate, &state, "distances2hetero");
2458    } else {
2459      parentstate->new_child(parentstate, &state, "distances2");
2460      state.new_prop(&state, "type", hwloc_obj_type_string(dist->unique_type));
2461    }
2462    sprintf(tmp, "%u", nbobjs);
2463    state.new_prop(&state, "nbobjs", tmp);
2464    sprintf(tmp, "%lu", dist->kind);
2465    state.new_prop(&state, "kind", tmp);
2466    if (dist->name)
2467      state.new_prop(&state, "name", dist->name);
2468    if (!dist->different_types) {
2469      state.new_prop(&state, "indexing",
2470  		   HWLOC_DIST_TYPE_USE_OS_INDEX(dist->unique_type) ? "os" : "gp");
2471    }
2472    if (dist->different_types) {
2473      EXPORT_TYPE_GPINDEX_ARRAY(&state, nbobjs, dist->objs, "indexes", 10);
2474    } else {
2475      EXPORT_ARRAY(&state, unsigned long long, nbobjs, dist->indexes, "indexes", "%llu", 10);
2476    }
2477    EXPORT_ARRAY(&state, unsigned long long, nbobjs*nbobjs, dist->values, "u64values", "%llu", 10);
2478    state.end_object(&state, dist->different_types ? "distances2hetero" : "distances2");
2479  }
2480  static void
2481  hwloc__xml_v2export_distances(hwloc__xml_export_state_t parentstate, hwloc_topology_t topology)
2482  {
2483    struct hwloc_internal_distances_s *dist;
2484    for(dist = topology->first_dist; dist; dist = dist->next)
2485      if (!dist->different_types)
2486        hwloc___xml_v2export_distances(parentstate, dist);
2487    for(dist = topology->first_dist; dist; dist = dist->next)
2488      if (dist->different_types)
2489        hwloc___xml_v2export_distances(parentstate, dist);
2490  }
2491  static void
2492  hwloc__xml_v2export_support(hwloc__xml_export_state_t parentstate, hwloc_topology_t topology)
2493  {
2494    struct hwloc__xml_export_state_s state;
2495    char tmp[11];
2496  #ifdef HWLOC_DEBUG
2497    HWLOC_BUILD_ASSERT(sizeof(struct hwloc_topology_support) == 4*sizeof(void*));
2498    HWLOC_BUILD_ASSERT(sizeof(struct hwloc_topology_discovery_support) == 6);
2499    HWLOC_BUILD_ASSERT(sizeof(struct hwloc_topology_cpubind_support) == 11);
2500    HWLOC_BUILD_ASSERT(sizeof(struct hwloc_topology_membind_support) == 15);
2501    HWLOC_BUILD_ASSERT(sizeof(struct hwloc_topology_misc_support) == 1);
2502  #endif
2503  #define DO(_cat,_name) do {                                     \
2504      if (topology->support._cat->_name) {                        \
2505        parentstate->new_child(parentstate, &state, "support");   \
2506        state.new_prop(&state, "name", #_cat "." #_name);         \
2507        if (topology->support._cat->_name != 1) {                 \
2508          sprintf(tmp, "%u", topology->support._cat->_name); \
2509          state.new_prop(&state, "value", tmp);                   \
2510        }                                                         \
2511        state.end_object(&state, "support");                      \
2512      }                                                           \
2513    } while (0)
2514    DO(discovery,pu);
2515    DO(discovery,numa);
2516    DO(discovery,numa_memory);
2517    DO(discovery,disallowed_pu);
2518    DO(discovery,disallowed_numa);
2519    DO(discovery,cpukind_efficiency);
2520    DO(cpubind,set_thisproc_cpubind);
2521    DO(cpubind,get_thisproc_cpubind);
2522    DO(cpubind,set_proc_cpubind);
2523    DO(cpubind,get_proc_cpubind);
2524    DO(cpubind,set_thisthread_cpubind);
2525    DO(cpubind,get_thisthread_cpubind);
2526    DO(cpubind,set_thread_cpubind);
2527    DO(cpubind,get_thread_cpubind);
2528    DO(cpubind,get_thisproc_last_cpu_location);
2529    DO(cpubind,get_proc_last_cpu_location);
2530    DO(cpubind,get_thisthread_last_cpu_location);
2531    DO(membind,set_thisproc_membind);
2532    DO(membind,get_thisproc_membind);
2533    DO(membind,set_proc_membind);
2534    DO(membind,get_proc_membind);
2535    DO(membind,set_thisthread_membind);
2536    DO(membind,get_thisthread_membind);
2537    DO(membind,set_area_membind);
2538    DO(membind,get_area_membind);
2539    DO(membind,alloc_membind);
2540    DO(membind,firsttouch_membind);
2541    DO(membind,bind_membind);
2542    DO(membind,interleave_membind);
2543    DO(membind,nexttouch_membind);
2544    DO(membind,migrate_membind);
2545    DO(membind,get_area_memlocation);
2546    parentstate->new_child(parentstate, &state, "support");
2547    state.new_prop(&state, "name", "custom.exported_support");
2548    state.end_object(&state, "support");
2549  #undef DO
2550  }
2551  static void
2552  hwloc__xml_export_memattr_target(hwloc__xml_export_state_t state,
2553                                   struct hwloc_internal_memattr_s *imattr,
2554                                   struct hwloc_internal_memattr_target_s *imtg)
2555  {
2556    struct hwloc__xml_export_state_s vstate;
2557    char tmp[255];
2558    if (imattr->flags & HWLOC_MEMATTR_FLAG_NEED_INITIATOR) {
2559      unsigned k;
2560      for(k=0; k<imtg->nr_initiators; k++) {
2561        struct hwloc_internal_memattr_initiator_s *imi = &imtg->initiators[k];
2562        state->new_child(state, &vstate, "memattr_value");
2563        vstate.new_prop(&vstate, "target_obj_type", hwloc_obj_type_string(imtg->type));
2564        snprintf(tmp, sizeof(tmp), "%llu", (unsigned long long) imtg->gp_index);
2565        vstate.new_prop(&vstate, "target_obj_gp_index", tmp);
2566        snprintf(tmp, sizeof(tmp), "%llu", (unsigned long long) imi->value);
2567        vstate.new_prop(&vstate, "value", tmp);
2568        switch (imi->initiator.type) {
2569        case HWLOC_LOCATION_TYPE_OBJECT:
2570          snprintf(tmp, sizeof(tmp), "%llu", (unsigned long long) imi->initiator.location.object.gp_index);
2571          vstate.new_prop(&vstate, "initiator_obj_gp_index", tmp);
2572          vstate.new_prop(&vstate, "initiator_obj_type", hwloc_obj_type_string(imi->initiator.location.object.type));
2573          break;
2574        case HWLOC_LOCATION_TYPE_CPUSET: {
2575          char *setstring;
2576          hwloc_bitmap_asprintf(&setstring, imi->initiator.location.cpuset);
2577          if (setstring)
2578            vstate.new_prop(&vstate, "initiator_cpuset", setstring);
2579          free(setstring);
2580          break;
2581        }
2582        default:
2583          assert(0);
2584        }
2585        vstate.end_object(&vstate, "memattr_value");
2586      }
2587    } else {
2588      state->new_child(state, &vstate, "memattr_value");
2589      vstate.new_prop(&vstate, "target_obj_type", hwloc_obj_type_string(imtg->type));
2590      snprintf(tmp, sizeof(tmp), "%llu", (unsigned long long) imtg->gp_index);
2591      vstate.new_prop(&vstate, "target_obj_gp_index", tmp);
2592      snprintf(tmp, sizeof(tmp), "%llu", (unsigned long long) imtg->noinitiator_value);
2593      vstate.new_prop(&vstate, "value", tmp);
2594      vstate.end_object(&vstate, "memattr_value");
2595    }
2596  }
2597  static void
2598  hwloc__xml_export_memattrs(hwloc__xml_export_state_t state, hwloc_topology_t topology)
2599  {
2600    unsigned id;
2601    for(id=0; id<topology->nr_memattrs; id++) {
2602      struct hwloc_internal_memattr_s *imattr;
2603      struct hwloc__xml_export_state_s mstate;
2604      char tmp[255];
2605      unsigned j;
2606      if (id == HWLOC_MEMATTR_ID_CAPACITY || id == HWLOC_MEMATTR_ID_LOCALITY)
2607        continue;
2608      imattr = &topology->memattrs[id];
2609      if (id < HWLOC_MEMATTR_ID_MAX && !imattr->nr_targets)
2610        continue;
2611      state->new_child(state, &mstate, "memattr");
2612      mstate.new_prop(&mstate, "name", imattr->name);
2613      snprintf(tmp, sizeof(tmp), "%lu", imattr->flags);
2614      mstate.new_prop(&mstate, "flags", tmp);
2615      for(j=0; j<imattr->nr_targets; j++)
2616        hwloc__xml_export_memattr_target(&mstate, imattr, &imattr->targets[j]);
2617      mstate.end_object(&mstate, "memattr");
2618    }
2619  }
2620  static void
2621  hwloc__xml_export_cpukinds(hwloc__xml_export_state_t state, hwloc_topology_t topology)
2622  {
2623    unsigned i;
2624    for(i=0; i<topology->nr_cpukinds; i++) {
2625      struct hwloc_internal_cpukind_s *kind = &topology->cpukinds[i];
2626      struct hwloc__xml_export_state_s cstate;
2627      char *setstring;
2628      unsigned j;
2629      state->new_child(state, &cstate, "cpukind");
2630      hwloc_bitmap_asprintf(&setstring, kind->cpuset);
2631      cstate.new_prop(&cstate, "cpuset", setstring);
2632      free(setstring);
2633      if (kind->forced_efficiency != HWLOC_CPUKIND_EFFICIENCY_UNKNOWN) {
2634        char tmp[11];
2635        snprintf(tmp, sizeof(tmp), "%d", kind->forced_efficiency);
2636        cstate.new_prop(&cstate, "forced_efficiency", tmp);
2637      }
2638      for(j=0; j<kind->nr_infos; j++) {
2639        char *name = hwloc__xml_export_safestrdup(kind->infos[j].name);
2640        char *value = hwloc__xml_export_safestrdup(kind->infos[j].value);
2641        struct hwloc__xml_export_state_s istate;
2642        cstate.new_child(&cstate, &istate, "info");
2643        istate.new_prop(&istate, "name", name);
2644        istate.new_prop(&istate, "value", value);
2645        istate.end_object(&istate, "info");
2646        free(name);
2647        free(value);
2648      }
2649      cstate.end_object(&cstate, "cpukind");
2650    }
2651  }
2652  void
2653  hwloc__xml_export_topology(hwloc__xml_export_state_t state, hwloc_topology_t topology, unsigned long flags)
2654  {
2655    char *env;
2656    hwloc_obj_t root = hwloc_get_root_obj(topology);
2657    if (flags & HWLOC_TOPOLOGY_EXPORT_XML_FLAG_V1) {
2658      hwloc_obj_t *numanodes, first_numanode;
2659      unsigned nr_numanodes;
2660      nr_numanodes = hwloc__xml_v1export_object_list_numanodes(root, &first_numanode, &numanodes);
2661      if (nr_numanodes) {
2662        struct hwloc__xml_export_state_s rstate, mstate;
2663        hwloc_obj_t child;
2664        unsigned i;
2665        state->new_child(state, &rstate, "object");
2666        hwloc__xml_export_object_contents (&rstate, topology, root, flags);
2667        rstate.new_child(&rstate, &mstate, "object");
2668        hwloc__xml_export_object_contents (&mstate, topology, first_numanode, flags);
2669        for_each_child(child, root)
2670  	hwloc__xml_v1export_object (&mstate, topology, child, flags);
2671        for_each_io_child(child, root)
2672  	hwloc__xml_v1export_object (&mstate, topology, child, flags);
2673        for_each_misc_child(child, root)
2674  	hwloc__xml_v1export_object (&mstate, topology, child, flags);
2675        mstate.end_object(&mstate, "object");
2676        for(i=1; i<nr_numanodes; i++)
2677  	hwloc__xml_v1export_object (&rstate, topology, numanodes[i], flags);
2678        rstate.end_object(&rstate, "object");
2679      } else {
2680        hwloc__xml_v1export_object(state, topology, root, flags);
2681      }
2682      free(numanodes);
2683    } else {
2684      hwloc__xml_v2export_object (state, topology, root, flags);
2685      hwloc__xml_v2export_distances (state, topology);
2686      env = getenv("HWLOC_XML_EXPORT_SUPPORT");
2687      if (!env || atoi(env))
2688        hwloc__xml_v2export_support(state, topology);
2689      hwloc__xml_export_memattrs(state, topology);
2690      hwloc__xml_export_cpukinds(state, topology);
2691    }
2692  }
2693  void
2694  hwloc__xml_export_diff(hwloc__xml_export_state_t parentstate, hwloc_topology_diff_t diff)
2695  {
2696    while (diff) {
2697      struct hwloc__xml_export_state_s state;
2698      char tmp[255];
2699      parentstate->new_child(parentstate, &state, "diff");
2700      sprintf(tmp, "%d", (int) diff->generic.type);
2701      state.new_prop(&state, "type", tmp);
2702      switch (diff->generic.type) {
2703      case HWLOC_TOPOLOGY_DIFF_OBJ_ATTR:
2704        sprintf(tmp, "%d", diff->obj_attr.obj_depth);
2705        state.new_prop(&state, "obj_depth", tmp);
2706        sprintf(tmp, "%u", diff->obj_attr.obj_index);
2707        state.new_prop(&state, "obj_index", tmp);
2708        sprintf(tmp, "%d", (int) diff->obj_attr.diff.generic.type);
2709        state.new_prop(&state, "obj_attr_type", tmp);
2710        switch (diff->obj_attr.diff.generic.type) {
2711        case HWLOC_TOPOLOGY_DIFF_OBJ_ATTR_SIZE:
2712  	sprintf(tmp, "%llu", (unsigned long long) diff->obj_attr.diff.uint64.index);
2713  	state.new_prop(&state, "obj_attr_index", tmp);
2714  	sprintf(tmp, "%llu", (unsigned long long) diff->obj_attr.diff.uint64.oldvalue);
2715  	state.new_prop(&state, "obj_attr_oldvalue", tmp);
2716  	sprintf(tmp, "%llu", (unsigned long long) diff->obj_attr.diff.uint64.newvalue);
2717  	state.new_prop(&state, "obj_attr_newvalue", tmp);
2718  	break;
2719        case HWLOC_TOPOLOGY_DIFF_OBJ_ATTR_NAME:
2720        case HWLOC_TOPOLOGY_DIFF_OBJ_ATTR_INFO:
2721  	if (diff->obj_attr.diff.string.name)
2722  	  state.new_prop(&state, "obj_attr_name", diff->obj_attr.diff.string.name);
2723  	state.new_prop(&state, "obj_attr_oldvalue", diff->obj_attr.diff.string.oldvalue);
2724  	state.new_prop(&state, "obj_attr_newvalue", diff->obj_attr.diff.string.newvalue);
2725  	break;
2726        }
2727        break;
2728      default:
2729        assert(0);
2730      }
2731      state.end_object(&state, "diff");
2732      diff = diff->generic.next;
2733    }
2734  }
2735  int hwloc_topology_export_xml(hwloc_topology_t topology, const char *filename, unsigned long flags)
2736  {
2737    hwloc_localeswitch_declare;
2738    struct hwloc__xml_export_data_s edata;
2739    int force_nolibxml;
2740    int ret;
2741    if (!topology->is_loaded) {
2742      errno = EINVAL;
2743      return -1;
2744    }
2745    assert(hwloc_nolibxml_callbacks); &bsol;* the core called components_init() for the topology */
2746    if (flags & ~HWLOC_TOPOLOGY_EXPORT_XML_FLAG_V1) {
2747      errno = EINVAL;
2748      return -1;
2749    }
2750    hwloc_internal_distances_refresh(topology);
2751    hwloc_localeswitch_init();
2752    edata.v1_memory_group = NULL;
2753    if (flags & HWLOC_TOPOLOGY_EXPORT_XML_FLAG_V1)
2754      edata.v1_memory_group = hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
2755    force_nolibxml = hwloc_nolibxml_export();
2756  retry:
2757    if (!hwloc_libxml_callbacks || (hwloc_nolibxml_callbacks && force_nolibxml))
2758      ret = hwloc_nolibxml_callbacks->export_file(topology, &edata, filename, flags);
2759    else {
2760      ret = hwloc_libxml_callbacks->export_file(topology, &edata, filename, flags);
2761      if (ret < 0 && errno == ENOSYS) {
2762        hwloc_libxml_callbacks = NULL;
2763        goto retry;
2764      }
2765    }
2766    if (edata.v1_memory_group)
2767      hwloc_free_unlinked_object(edata.v1_memory_group);
2768    hwloc_localeswitch_fini();
2769    return ret;
2770  }
2771  int hwloc_topology_export_xmlbuffer(hwloc_topology_t topology, char **xmlbuffer, int *buflen, unsigned long flags)
2772  {
2773    hwloc_localeswitch_declare;
2774    struct hwloc__xml_export_data_s edata;
2775    int force_nolibxml;
2776    int ret;
2777    if (!topology->is_loaded) {
2778      errno = EINVAL;
2779      return -1;
2780    }
2781    assert(hwloc_nolibxml_callbacks); &bsol;* the core called components_init() for the topology */
2782    if (flags & ~HWLOC_TOPOLOGY_EXPORT_XML_FLAG_V1) {
2783      errno = EINVAL;
2784      return -1;
2785    }
2786    hwloc_internal_distances_refresh(topology);
2787    hwloc_localeswitch_init();
2788    edata.v1_memory_group = NULL;
2789    if (flags & HWLOC_TOPOLOGY_EXPORT_XML_FLAG_V1)
2790      edata.v1_memory_group = hwloc_alloc_setup_object(topology, HWLOC_OBJ_GROUP, HWLOC_UNKNOWN_INDEX);
2791    force_nolibxml = hwloc_nolibxml_export();
2792  retry:
2793    if (!hwloc_libxml_callbacks || (hwloc_nolibxml_callbacks && force_nolibxml))
2794      ret = hwloc_nolibxml_callbacks->export_buffer(topology, &edata, xmlbuffer, buflen, flags);
2795    else {
2796      ret = hwloc_libxml_callbacks->export_buffer(topology, &edata, xmlbuffer, buflen, flags);
2797      if (ret < 0 && errno == ENOSYS) {
2798        hwloc_libxml_callbacks = NULL;
2799        goto retry;
2800      }
2801    }
2802    if (edata.v1_memory_group)
2803      hwloc_free_unlinked_object(edata.v1_memory_group);
2804    hwloc_localeswitch_fini();
2805    return ret;
2806  }
2807  int
2808  hwloc_topology_diff_export_xml(hwloc_topology_diff_t diff, const char *refname,
2809  			       const char *filename)
2810  {
2811    hwloc_localeswitch_declare;
2812    hwloc_topology_diff_t tmpdiff;
2813    int force_nolibxml;
2814    int ret;
2815    tmpdiff = diff;
2816    while (tmpdiff) {
2817      if (tmpdiff->generic.type == HWLOC_TOPOLOGY_DIFF_TOO_COMPLEX) {
2818        errno = EINVAL;
2819        return -1;
2820      }
2821      tmpdiff = tmpdiff->generic.next;
2822    }
2823    hwloc_components_init();
<span onclick='openModal()' class='match'>2824    assert(hwloc_nolibxml_callbacks);
2825    hwloc_localeswitch_init();
2826    force_nolibxml = hwloc_nolibxml_export();
2827  retry:
</span>2828    if (!hwloc_libxml_callbacks || (hwloc_nolibxml_callbacks && force_nolibxml))
2829      ret = hwloc_nolibxml_callbacks->export_diff_file(diff, refname, filename);
2830    else {
2831      ret = hwloc_libxml_callbacks->export_diff_file(diff, refname, filename);
2832      if (ret < 0 && errno == ENOSYS) {
2833        hwloc_libxml_callbacks = NULL;
2834        goto retry;
2835      }
2836    }
2837    hwloc_localeswitch_fini();
2838    hwloc_components_fini();
2839    return ret;
2840  }
2841  int
2842  hwloc_topology_diff_export_xmlbuffer(hwloc_topology_diff_t diff, const char *refname,
2843  				     char **xmlbuffer, int *buflen)
2844  {
2845    hwloc_localeswitch_declare;
2846    hwloc_topology_diff_t tmpdiff;
2847    int force_nolibxml;
2848    int ret;
2849    tmpdiff = diff;
2850    while (tmpdiff) {
2851      if (tmpdiff->generic.type == HWLOC_TOPOLOGY_DIFF_TOO_COMPLEX) {
2852        errno = EINVAL;
2853        return -1;
2854      }
2855      tmpdiff = tmpdiff->generic.next;
2856    }
2857    hwloc_components_init();
2858    assert(hwloc_nolibxml_callbacks);
2859    hwloc_localeswitch_init();
2860    force_nolibxml = hwloc_nolibxml_export();
2861  retry:
2862    if (!hwloc_libxml_callbacks || (hwloc_nolibxml_callbacks && force_nolibxml))
2863      ret = hwloc_nolibxml_callbacks->export_diff_buffer(diff, refname, xmlbuffer, buflen);
2864    else {
2865      ret = hwloc_libxml_callbacks->export_diff_buffer(diff, refname, xmlbuffer, buflen);
2866      if (ret < 0 && errno == ENOSYS) {
2867        hwloc_libxml_callbacks = NULL;
2868        goto retry;
2869      }
2870    }
2871    hwloc_localeswitch_fini();
2872    hwloc_components_fini();
2873    return ret;
2874  }
2875  void hwloc_free_xmlbuffer(hwloc_topology_t topology __hwloc_attribute_unused, char *xmlbuffer)
2876  {
2877    int force_nolibxml;
2878    assert(hwloc_nolibxml_callbacks); &bsol;* the core called components_init() for the topology */
2879    force_nolibxml = hwloc_nolibxml_export();
2880    if (!hwloc_libxml_callbacks || (hwloc_nolibxml_callbacks && force_nolibxml))
2881      hwloc_nolibxml_callbacks->free_buffer(xmlbuffer);
2882    else
2883      hwloc_libxml_callbacks->free_buffer(xmlbuffer);
2884  }
2885  void
2886  hwloc_topology_set_userdata_export_callback(hwloc_topology_t topology,
2887  					    void (*export)(void *reserved, struct hwloc_topology *topology, struct hwloc_obj *obj))
2888  {
2889    topology->userdata_export_cb = export;
2890  }
2891  static void
2892  hwloc__export_obj_userdata(hwloc__xml_export_state_t parentstate, int encoded,
2893  			   const char *name, size_t length, const void *buffer, size_t encoded_length)
2894  {
2895    struct hwloc__xml_export_state_s state;
2896    char tmp[255];
2897    parentstate->new_child(parentstate, &state, "userdata");
2898    if (name)
2899      state.new_prop(&state, "name", name);
2900    sprintf(tmp, "%lu", (unsigned long) length);
2901    state.new_prop(&state, "length", tmp);
2902    if (encoded)
2903      state.new_prop(&state, "encoding", "base64");
2904    if (encoded_length)
2905      state.add_content(&state, buffer, encoded ? encoded_length : length);
2906    state.end_object(&state, "userdata");
2907  }
2908  int
2909  hwloc_export_obj_userdata(void *reserved,
2910  			  struct hwloc_topology *topology, struct hwloc_obj *obj __hwloc_attribute_unused,
2911  			  const char *name, const void *buffer, size_t length)
2912  {
2913    hwloc__xml_export_state_t state = reserved;
2914    if (!buffer) {
2915      errno = EINVAL;
2916      return -1;
2917    }
2918    if ((name && hwloc__xml_export_check_buffer(name, strlen(name)) < 0)
2919        || hwloc__xml_export_check_buffer(buffer, length) < 0) {
2920      errno = EINVAL;
2921      return -1;
2922    }
2923    if (topology->userdata_not_decoded) {
2924      int encoded;
2925      size_t encoded_length;
2926      const char *realname;
2927      assert(name);
2928      if (!strncmp(name, "base64", 6)) {
2929        encoded = 1;
2930        encoded_length = BASE64_ENCODED_LENGTH(length);
2931      } else {
2932        assert(!strncmp(name, "normal", 6));
2933        encoded = 0;
2934        encoded_length = length;
2935      }
2936      if (name[6] == ':')
2937        realname = name+7;
2938      else {
2939        assert(!strcmp(name+6, "-anon"));
2940        realname = NULL;
2941      }
2942      hwloc__export_obj_userdata(state, encoded, realname, length, buffer, encoded_length);
2943    } else
2944      hwloc__export_obj_userdata(state, 0, name, length, buffer, length);
2945    return 0;
2946  }
2947  int
2948  hwloc_export_obj_userdata_base64(void *reserved,
2949  				 struct hwloc_topology *topology __hwloc_attribute_unused, struct hwloc_obj *obj __hwloc_attribute_unused,
2950  				 const char *name, const void *buffer, size_t length)
2951  {
2952    hwloc__xml_export_state_t state = reserved;
2953    size_t encoded_length;
2954    char *encoded_buffer;
2955    int ret __hwloc_attribute_unused;
2956    if (!buffer) {
2957      errno = EINVAL;
2958      return -1;
2959    }
2960    assert(!topology->userdata_not_decoded);
2961    if (name && hwloc__xml_export_check_buffer(name, strlen(name)) < 0) {
2962      errno = EINVAL;
2963      return -1;
2964    }
2965    encoded_length = BASE64_ENCODED_LENGTH(length);
2966    encoded_buffer = malloc(encoded_length+1);
2967    if (!encoded_buffer) {
2968      errno = ENOMEM;
2969      return -1;
2970    }
2971    ret = hwloc_encode_to_base64(buffer, length, encoded_buffer, encoded_length+1);
2972    assert(ret == (int) encoded_length);
2973    hwloc__export_obj_userdata(state, 1, name, length, encoded_buffer, encoded_length);
2974    free(encoded_buffer);
2975    return 0;
2976  }
2977  void
2978  hwloc_topology_set_userdata_import_callback(hwloc_topology_t topology,
2979  					    void (*import)(struct hwloc_topology *topology, struct hwloc_obj *obj, const char *name, const void *buffer, size_t length))
2980  {
2981    topology->userdata_import_cb = import;
2982  }
2983  static void
2984  hwloc_xml_backend_disable(struct hwloc_backend *backend)
2985  {
2986    struct hwloc_xml_backend_data_s *data = backend->private_data;
2987    data->backend_exit(data);
2988    free(data->msgprefix);
2989    free(data);
2990  }
2991  static struct hwloc_backend *
2992  hwloc_xml_component_instantiate(struct hwloc_topology *topology,
2993  				struct hwloc_disc_component *component,
2994  				unsigned excluded_phases __hwloc_attribute_unused,
2995  				const void *_data1,
2996  				const void *_data2,
2997  				const void *_data3)
2998  {
2999    struct hwloc_xml_backend_data_s *data;
3000    struct hwloc_backend *backend;
3001    const char *env;
3002    int force_nolibxml;
3003    const char * xmlpath = (const char *) _data1;
3004    const char * xmlbuffer = (const char *) _data2;
3005    int xmlbuflen = (int)(uintptr_t) _data3;
3006    const char *local_basename;
3007    int err;
3008    assert(hwloc_nolibxml_callbacks); &bsol;* the core called components_init() for the component's topology */
3009    if (!xmlpath && !xmlbuffer) {
3010      env = getenv("HWLOC_XMLFILE");
3011      if (env) {
3012        xmlpath = env;
3013      } else {
3014        errno = EINVAL;
3015        goto out;
3016      }
3017    }
3018    backend = hwloc_backend_alloc(topology, component);
3019    if (!backend)
3020      goto out;
3021    data = malloc(sizeof(*data));
3022    if (!data) {
3023      errno = ENOMEM;
3024      goto out_with_backend;
3025    }
3026    backend->private_data = data;
3027    backend->discover = hwloc_look_xml;
3028    backend->disable = hwloc_xml_backend_disable;
3029    backend->is_thissystem = 0;
3030    if (xmlpath) {
3031      local_basename = strrchr(xmlpath, '/');
3032      if (local_basename)
3033        local_basename++;
3034      else
3035        local_basename = xmlpath;
3036    } else {
3037      local_basename = "xmlbuffer";
3038    }
3039    data->msgprefix = strdup(local_basename);
3040    force_nolibxml = hwloc_nolibxml_import();
3041  retry:
3042    if (!hwloc_libxml_callbacks || (hwloc_nolibxml_callbacks && force_nolibxml))
3043      err = hwloc_nolibxml_callbacks->backend_init(data, xmlpath, xmlbuffer, xmlbuflen);
3044    else {
3045      err = hwloc_libxml_callbacks->backend_init(data, xmlpath, xmlbuffer, xmlbuflen);
3046      if (err < 0 && errno == ENOSYS) {
3047        hwloc_libxml_callbacks = NULL;
3048        goto retry;
3049      }
3050    }
3051    if (err < 0)
3052      goto out_with_data;
3053    return backend;
3054   out_with_data:
3055    free(data->msgprefix);
3056    free(data);
3057   out_with_backend:
3058    free(backend);
3059   out:
3060    return NULL;
3061  }
3062  static struct hwloc_disc_component hwloc_xml_disc_component = {
3063    "xml",
3064    HWLOC_DISC_PHASE_GLOBAL,
3065    ~0,
3066    hwloc_xml_component_instantiate,
3067    30,
3068    1,
3069    NULL
3070  };
3071  const struct hwloc_component hwloc_xml_component = {
3072    HWLOC_COMPONENT_ABI,
3073    NULL, NULL,
3074    HWLOC_COMPONENT_TYPE_DISC,
3075    0,
3076    &hwloc_xml_disc_component
3077  };
</code></pre>
        </div>
        <div class="column">
            <h3>Adafruit_nRF52_Arduino-MDEwOlJlcG9zaXRvcnk3NDM1NDcyOQ==-flat-tasks.c</h3>
            <pre><code>1  #include <stdlib.h>
2  #include <string.h>
3  #define MPU_WRAPPERS_INCLUDED_FROM_API_FILE
4  #include "FreeRTOS.h"
5  #include "task.h"
6  #include "timers.h"
7  #include "stack_macros.h"
8  #undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE &bsol;*lint !e961 !e750. */
9  #if ( configUSE_STATS_FORMATTING_FUNCTIONS == 1 )
10  	#include <stdio.h>
11  #endif &bsol;* configUSE_STATS_FORMATTING_FUNCTIONS == 1 ) */
12  #if( configUSE_PREEMPTION == 0 )
13  	#define taskYIELD_IF_USING_PREEMPTION()
14  #else
15  	#define taskYIELD_IF_USING_PREEMPTION() portYIELD_WITHIN_API()
16  #endif
17  #define taskNOT_WAITING_NOTIFICATION	( ( uint8_t ) 0 )
18  #define taskWAITING_NOTIFICATION		( ( uint8_t ) 1 )
19  #define taskNOTIFICATION_RECEIVED		( ( uint8_t ) 2 )
20  #define tskSTACK_FILL_BYTE	( 0xa5U )
21  #define tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE	( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
22  #define tskDYNAMICALLY_ALLOCATED_STACK_AND_TCB 		( ( uint8_t ) 0 )
23  #define tskSTATICALLY_ALLOCATED_STACK_ONLY 			( ( uint8_t ) 1 )
24  #define tskSTATICALLY_ALLOCATED_STACK_AND_TCB		( ( uint8_t ) 2 )
25  #if( ( configCHECK_FOR_STACK_OVERFLOW > 1 ) || ( configUSE_TRACE_FACILITY == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark == 1 ) )
26  	#define tskSET_NEW_STACKS_TO_KNOWN_VALUE	1
27  #else
28  	#define tskSET_NEW_STACKS_TO_KNOWN_VALUE	0
29  #endif
30  #define tskRUNNING_CHAR		( 'X' )
31  #define tskBLOCKED_CHAR		( 'B' )
32  #define tskREADY_CHAR		( 'R' )
33  #define tskDELETED_CHAR		( 'D' )
34  #define tskSUSPENDED_CHAR	( 'S' )
35  #ifdef portREMOVE_STATIC_QUALIFIER
36  	#define static
37  #endif
38  #ifndef configIDLE_TASK_NAME
39  	#define configIDLE_TASK_NAME "IDLE"
40  #endif
41  #if ( configUSE_PORT_OPTIMISED_TASK_SELECTION == 0 )
42  	#define taskRECORD_READY_PRIORITY( uxPriority )														\
43  	{																									\
44  		if( ( uxPriority ) > uxTopReadyPriority )														\
45  		{																								\
46  			uxTopReadyPriority = ( uxPriority );														\
47  		}																								\
48  	} &bsol;* taskRECORD_READY_PRIORITY */
49  	#define taskSELECT_HIGHEST_PRIORITY_TASK()															\
50  	{																									\
51  	UBaseType_t uxTopPriority = uxTopReadyPriority;														\
52  																										\
53  										\
54  		while( listLIST_IS_EMPTY( &( pxReadyTasksLists[ uxTopPriority ] ) ) )							\
55  		{																								\
56  			configASSERT( uxTopPriority );																\
57  			--uxTopPriority;																			\
58  		}																								\
59  																										\
60  											\
61  		listGET_OWNER_OF_NEXT_ENTRY( pxCurrentTCB, &( pxReadyTasksLists[ uxTopPriority ] ) );			\
62  		uxTopReadyPriority = uxTopPriority;																\
63  	} &bsol;* taskSELECT_HIGHEST_PRIORITY_TASK */
64  	#define taskRESET_READY_PRIORITY( uxPriority )
65  	#define portRESET_READY_PRIORITY( uxPriority, uxTopReadyPriority )
66  #else &bsol;* configUSE_PORT_OPTIMISED_TASK_SELECTION */
67  	#define taskRECORD_READY_PRIORITY( uxPriority )	portRECORD_READY_PRIORITY( uxPriority, uxTopReadyPriority )
68  	#define taskSELECT_HIGHEST_PRIORITY_TASK()														\
69  	{																								\
70  	UBaseType_t uxTopPriority;																		\
71  																									\
72  										\
73  		portGET_HIGHEST_PRIORITY( uxTopPriority, uxTopReadyPriority );								\
74  		configASSERT( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ uxTopPriority ] ) ) > 0 );		\
75  		listGET_OWNER_OF_NEXT_ENTRY( pxCurrentTCB, &( pxReadyTasksLists[ uxTopPriority ] ) );		\
76  	} &bsol;* taskSELECT_HIGHEST_PRIORITY_TASK() */
77  	#define taskRESET_READY_PRIORITY( uxPriority )														\
78  	{																									\
79  		if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ ( uxPriority ) ] ) ) == ( UBaseType_t ) 0 )	\
80  		{																								\
81  			portRESET_READY_PRIORITY( ( uxPriority ), ( uxTopReadyPriority ) );							\
82  		}																								\
83  	}
84  #endif &bsol;* configUSE_PORT_OPTIMISED_TASK_SELECTION */
85  #define taskSWITCH_DELAYED_LISTS()																	\
86  {																									\
87  	List_t *pxTemp;																					\
88  																									\
89  							\
90  	configASSERT( ( listLIST_IS_EMPTY( pxDelayedTaskList ) ) );										\
91  																									\
92  	pxTemp = pxDelayedTaskList;																		\
93  	pxDelayedTaskList = pxOverflowDelayedTaskList;													\
94  	pxOverflowDelayedTaskList = pxTemp;																\
95  	xNumOfOverflows++;																				\
96  	prvResetNextTaskUnblockTime();																	\
97  }
98  #define prvAddTaskToReadyList( pxTCB )																\
99  	traceMOVED_TASK_TO_READY_STATE( pxTCB );														\
100  	taskRECORD_READY_PRIORITY( ( pxTCB )->uxPriority );												\
101  	vListInsertEnd( &( pxReadyTasksLists[ ( pxTCB )->uxPriority ] ), &( ( pxTCB )->xStateListItem ) ); \
102  	tracePOST_MOVED_TASK_TO_READY_STATE( pxTCB )
103  #define prvReaddTaskToReadyList( pxTCB )															\
104  	traceREADDED_TASK_TO_READY_STATE( pxTCB );														\
105  	taskRECORD_READY_PRIORITY( ( pxTCB )->uxPriority );												\
106  	vListInsertEnd( &( pxReadyTasksLists[ ( pxTCB )->uxPriority ] ), &( ( pxTCB )->xStateListItem ) ); \
107  	tracePOST_MOVED_TASK_TO_READY_STATE( pxTCB )
108  #define prvGetTCBFromHandle( pxHandle ) ( ( ( pxHandle ) == NULL ) ? ( TCB_t * ) pxCurrentTCB : ( TCB_t * ) ( pxHandle ) )
109  #if( configUSE_16_BIT_TICKS == 1 )
110  	#define taskEVENT_LIST_ITEM_VALUE_IN_USE	0x8000U
111  #else
112  	#define taskEVENT_LIST_ITEM_VALUE_IN_USE	0x80000000UL
113  #endif
114  typedef struct tskTaskControlBlock
115  {
116  	volatile StackType_t	*pxTopOfStack;	&bsol;*< Points to the location of the last item placed on the tasks stack.  THIS MUST BE THE FIRST MEMBER OF THE TCB STRUCT. */
117  	#if ( portUSING_MPU_WRAPPERS == 1 )
118  		xMPU_SETTINGS	xMPUSettings;		&bsol;*< The MPU settings are defined as part of the port layer.  THIS MUST BE THE SECOND MEMBER OF THE TCB STRUCT. */
119  	#endif
120  	ListItem_t			xStateListItem;	&bsol;*< The list that the state list item of a task is reference from denotes the state of that task (Ready, Blocked, Suspended ). */
121  	ListItem_t			xEventListItem;		&bsol;*< Used to reference a task from an event list. */
122  	UBaseType_t			uxPriority;			&bsol;*< The priority of the task.  0 is the lowest priority. */
123  	StackType_t			*pxStack;			&bsol;*< Points to the start of the stack. */
124  	char				pcTaskName[ configMAX_TASK_NAME_LEN ];&bsol;*< Descriptive name given to the task when created.  Facilitates debugging only. */ &bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
125  	#if ( ( portSTACK_GROWTH > 0 ) || ( configRECORD_STACK_HIGH_ADDRESS == 1 ) )
126  		StackType_t		*pxEndOfStack;		&bsol;*< Points to the highest valid address for the stack. */
127  	#endif
128  	#if ( portCRITICAL_NESTING_IN_TCB == 1 )
129  		UBaseType_t		uxCriticalNesting;	&bsol;*< Holds the critical section nesting depth for ports that do not maintain their own count in the port layer. */
130  	#endif
131  	#if ( configUSE_TRACE_FACILITY == 1 )
132  		UBaseType_t		uxTCBNumber;		&bsol;*< Stores a number that increments each time a TCB is created.  It allows debuggers to determine when a task has been deleted and then recreated. */
133  		UBaseType_t		uxTaskNumber;		&bsol;*< Stores a number specifically for use by third party trace code. */
134  	#endif
135  	#if ( configUSE_MUTEXES == 1 )
136  		UBaseType_t		uxBasePriority;		&bsol;*< The priority last assigned to the task - used by the priority inheritance mechanism. */
137  		UBaseType_t		uxMutexesHeld;
138  	#endif
139  	#if ( configUSE_APPLICATION_TASK_TAG == 1 )
140  		TaskHookFunction_t pxTaskTag;
141  	#endif
142  	#if( configNUM_THREAD_LOCAL_STORAGE_POINTERS > 0 )
143  		void			*pvThreadLocalStoragePointers[ configNUM_THREAD_LOCAL_STORAGE_POINTERS ];
144  	#endif
145  	#if( configGENERATE_RUN_TIME_STATS == 1 )
146  		uint32_t		ulRunTimeCounter;	&bsol;*< Stores the amount of time the task has spent in the Running state. */
147  	#endif
148  	#if ( configUSE_NEWLIB_REENTRANT == 1 )
149  		struct	_reent xNewLib_reent;
150  	#endif
151  	#if( configUSE_TASK_NOTIFICATIONS == 1 )
152  		volatile uint32_t ulNotifiedValue;
153  		volatile uint8_t ucNotifyState;
154  	#endif
155  	#if( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 ) &bsol;*lint !e731 Macro has been consolidated for readability reasons. */
156  		uint8_t	ucStaticallyAllocated; 		&bsol;*< Set to pdTRUE if the task is a statically allocated to ensure no attempt is made to free the memory. */
157  	#endif
158  	#if( INCLUDE_xTaskAbortDelay == 1 )
159  		uint8_t ucDelayAborted;
160  	#endif
161  } tskTCB;
162  typedef tskTCB TCB_t;
163  PRIVILEGED_DATA TCB_t * volatile pxCurrentTCB = NULL;
164  PRIVILEGED_DATA static List_t pxReadyTasksLists[ configMAX_PRIORITIES ];&bsol;*< Prioritised ready tasks. */
165  PRIVILEGED_DATA static List_t xDelayedTaskList1;						&bsol;*< Delayed tasks. */
166  PRIVILEGED_DATA static List_t xDelayedTaskList2;						&bsol;*< Delayed tasks (two lists are used - one for delays that have overflowed the current tick count. */
167  PRIVILEGED_DATA static List_t * volatile pxDelayedTaskList;				&bsol;*< Points to the delayed task list currently being used. */
168  PRIVILEGED_DATA static List_t * volatile pxOverflowDelayedTaskList;		&bsol;*< Points to the delayed task list currently being used to hold tasks that have overflowed the current tick count. */
169  PRIVILEGED_DATA static List_t xPendingReadyList;						&bsol;*< Tasks that have been readied while the scheduler was suspended.  They will be moved to the ready list when the scheduler is resumed. */
170  #if( INCLUDE_vTaskDelete == 1 )
171  	PRIVILEGED_DATA static List_t xTasksWaitingTermination;				&bsol;*< Tasks that have been deleted - but their memory not yet freed. */
172  	PRIVILEGED_DATA static volatile UBaseType_t uxDeletedTasksWaitingCleanUp = ( UBaseType_t ) 0U;
173  #endif
174  #if ( INCLUDE_vTaskSuspend == 1 )
175  	PRIVILEGED_DATA static List_t xSuspendedTaskList;					&bsol;*< Tasks that are currently suspended. */
176  #endif
177  PRIVILEGED_DATA static volatile UBaseType_t uxCurrentNumberOfTasks 	= ( UBaseType_t ) 0U;
178  PRIVILEGED_DATA static volatile TickType_t xTickCount 				= ( TickType_t ) configINITIAL_TICK_COUNT;
179  PRIVILEGED_DATA static volatile UBaseType_t uxTopReadyPriority 		= tskIDLE_PRIORITY;
180  PRIVILEGED_DATA static volatile BaseType_t xSchedulerRunning 		= pdFALSE;
181  PRIVILEGED_DATA static volatile UBaseType_t uxPendedTicks 			= ( UBaseType_t ) 0U;
182  PRIVILEGED_DATA static volatile BaseType_t xYieldPending 			= pdFALSE;
183  PRIVILEGED_DATA static volatile BaseType_t xNumOfOverflows 			= ( BaseType_t ) 0;
184  PRIVILEGED_DATA static UBaseType_t uxTaskNumber 					= ( UBaseType_t ) 0U;
185  PRIVILEGED_DATA static volatile TickType_t xNextTaskUnblockTime		= ( TickType_t ) 0U; &bsol;* Initialised to portMAX_DELAY before the scheduler starts. */
186  PRIVILEGED_DATA static TaskHandle_t xIdleTaskHandle					= NULL;			&bsol;*< Holds the handle of the idle task.  The idle task is created automatically when the scheduler is started. */
187  PRIVILEGED_DATA static volatile UBaseType_t uxSchedulerSuspended	= ( UBaseType_t ) pdFALSE;
188  #if ( configGENERATE_RUN_TIME_STATS == 1 )
189  	PRIVILEGED_DATA static uint32_t ulTaskSwitchedInTime = 0UL;	&bsol;*< Holds the value of a timer/counter the last time a task was switched in. */
190  	PRIVILEGED_DATA static uint32_t ulTotalRunTime = 0UL;		&bsol;*< Holds the total amount of execution time as defined by the run time counter clock. */
191  #endif
192  #if(  configCHECK_FOR_STACK_OVERFLOW > 0 )
193  	extern void vApplicationStackOverflowHook( TaskHandle_t xTask, char *pcTaskName );
194  #endif
195  #if( configUSE_TICK_HOOK > 0 )
196  	extern void vApplicationTickHook( void );
197  #endif
198  #if( configSUPPORT_STATIC_ALLOCATION == 1 )
199  	extern void vApplicationGetIdleTaskMemory( StaticTask_t **ppxIdleTaskTCBBuffer, StackType_t **ppxIdleTaskStackBuffer, uint32_t *pulIdleTaskStackSize );
200  #endif
201  #if ( INCLUDE_vTaskSuspend == 1 )
202  	static BaseType_t prvTaskIsTaskSuspended( const TaskHandle_t xTask ) PRIVILEGED_FUNCTION;
203  #endif &bsol;* INCLUDE_vTaskSuspend */
204  static void prvInitialiseTaskLists( void ) PRIVILEGED_FUNCTION;
205  static portTASK_FUNCTION_PROTO( prvIdleTask, pvParameters );
206  #if ( INCLUDE_vTaskDelete == 1 )
207  	static void prvDeleteTCB( TCB_t *pxTCB ) PRIVILEGED_FUNCTION;
208  #endif
209  static void prvCheckTasksWaitingTermination( void ) PRIVILEGED_FUNCTION;
210  static void prvAddCurrentTaskToDelayedList( TickType_t xTicksToWait, const BaseType_t xCanBlockIndefinitely ) PRIVILEGED_FUNCTION;
211  #if ( configUSE_TRACE_FACILITY == 1 )
212  	static UBaseType_t prvListTasksWithinSingleList( TaskStatus_t *pxTaskStatusArray, List_t *pxList, eTaskState eState ) PRIVILEGED_FUNCTION;
213  #endif
214  #if ( INCLUDE_xTaskGetHandle == 1 )
215  	static TCB_t *prvSearchForNameWithinSingleList( List_t *pxList, const char pcNameToQuery[] ) PRIVILEGED_FUNCTION;
216  #endif
217  #if ( ( configUSE_TRACE_FACILITY == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark == 1 ) )
218  	static uint16_t prvTaskCheckFreeStackSpace( const uint8_t * pucStackByte ) PRIVILEGED_FUNCTION;
219  #endif
220  #if ( configUSE_TICKLESS_IDLE != 0 )
221  	static TickType_t prvGetExpectedIdleTime( void ) PRIVILEGED_FUNCTION;
222  #endif
223  static void prvResetNextTaskUnblockTime( void );
224  #if ( ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) )
225  	static char *prvWriteNameToBuffer( char *pcBuffer, const char *pcTaskName ) PRIVILEGED_FUNCTION;
226  #endif
227  static void prvInitialiseNewTask( 	TaskFunction_t pxTaskCode,
228  									const char * const pcName, 		&bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
229  									const uint32_t ulStackDepth,
230  									void * const pvParameters,
231  									UBaseType_t uxPriority,
232  									TaskHandle_t * const pxCreatedTask,
233  									TCB_t *pxNewTCB,
234  									const MemoryRegion_t * const xRegions ) PRIVILEGED_FUNCTION;
235  static void prvAddNewTaskToReadyList( TCB_t *pxNewTCB ) PRIVILEGED_FUNCTION;
236  #ifdef FREERTOS_TASKS_C_ADDITIONS_INIT
237  	static void freertos_tasks_c_additions_init( void ) PRIVILEGED_FUNCTION;
238  #endif
239  #if( configSUPPORT_STATIC_ALLOCATION == 1 )
240  	TaskHandle_t xTaskCreateStatic(	TaskFunction_t pxTaskCode,
241  									const char * const pcName,		&bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
242  									const uint32_t ulStackDepth,
243  									void * const pvParameters,
244  									UBaseType_t uxPriority,
245  									StackType_t * const puxStackBuffer,
246  									StaticTask_t * const pxTaskBuffer )
247  	{
248  	TCB_t *pxNewTCB;
249  	TaskHandle_t xReturn;
250  		configASSERT( puxStackBuffer != NULL );
251  		configASSERT( pxTaskBuffer != NULL );
252  		#if( configASSERT_DEFINED == 1 )
253  		{
254  			volatile size_t xSize = sizeof( StaticTask_t );
255  			configASSERT( xSize == sizeof( TCB_t ) );
256  		}
257  		#endif &bsol;* configASSERT_DEFINED */
258  		if( ( pxTaskBuffer != NULL ) && ( puxStackBuffer != NULL ) )
259  		{
260  			pxNewTCB = ( TCB_t * ) pxTaskBuffer; &bsol;*lint !e740 Unusual cast is ok as the structures are designed to have the same alignment, and the size is checked by an assert. */
261  			pxNewTCB->pxStack = ( StackType_t * ) puxStackBuffer;
262  			#if( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 ) &bsol;*lint !e731 Macro has been consolidated for readability reasons. */
263  			{
264  				pxNewTCB->ucStaticallyAllocated = tskSTATICALLY_ALLOCATED_STACK_AND_TCB;
265  			}
266  			#endif &bsol;* configSUPPORT_DYNAMIC_ALLOCATION */
267  			prvInitialiseNewTask( pxTaskCode, pcName, ulStackDepth, pvParameters, uxPriority, &xReturn, pxNewTCB, NULL );
268  			prvAddNewTaskToReadyList( pxNewTCB );
269  		}
270  		else
271  		{
272  			xReturn = NULL;
273  		}
274  		return xReturn;
275  	}
276  #endif &bsol;* SUPPORT_STATIC_ALLOCATION */
277  #if( ( portUSING_MPU_WRAPPERS == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
278  	BaseType_t xTaskCreateRestrictedStatic( const TaskParameters_t * const pxTaskDefinition, TaskHandle_t *pxCreatedTask )
279  	{
280  	TCB_t *pxNewTCB;
281  	BaseType_t xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
282  		configASSERT( pxTaskDefinition->puxStackBuffer != NULL );
283  		configASSERT( pxTaskDefinition->pxTaskBuffer != NULL );
284  		if( ( pxTaskDefinition->puxStackBuffer != NULL ) && ( pxTaskDefinition->pxTaskBuffer != NULL ) )
285  		{
286  			pxNewTCB = ( TCB_t * ) pxTaskDefinition->pxTaskBuffer;
287  			pxNewTCB->pxStack = pxTaskDefinition->puxStackBuffer;
288  			#if( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 )
289  			{
290  				pxNewTCB->ucStaticallyAllocated = tskSTATICALLY_ALLOCATED_STACK_AND_TCB;
291  			}
292  			#endif &bsol;* configSUPPORT_DYNAMIC_ALLOCATION */
293  			prvInitialiseNewTask(	pxTaskDefinition->pvTaskCode,
294  									pxTaskDefinition->pcName,
295  									( uint32_t ) pxTaskDefinition->usStackDepth,
296  									pxTaskDefinition->pvParameters,
297  									pxTaskDefinition->uxPriority,
298  									pxCreatedTask, pxNewTCB,
299  									pxTaskDefinition->xRegions );
300  			prvAddNewTaskToReadyList( pxNewTCB );
301  			xReturn = pdPASS;
302  		}
303  		return xReturn;
304  	}
305  #endif &bsol;* ( portUSING_MPU_WRAPPERS == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) */
306  #if( ( portUSING_MPU_WRAPPERS == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
307  	BaseType_t xTaskCreateRestricted( const TaskParameters_t * const pxTaskDefinition, TaskHandle_t *pxCreatedTask )
308  	{
309  	TCB_t *pxNewTCB;
310  	BaseType_t xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
311  		configASSERT( pxTaskDefinition->puxStackBuffer );
312  		if( pxTaskDefinition->puxStackBuffer != NULL )
313  		{
314  			pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) );
315  			if( pxNewTCB != NULL )
316  			{
317  				pxNewTCB->pxStack = pxTaskDefinition->puxStackBuffer;
318  				#if( configSUPPORT_STATIC_ALLOCATION == 1 )
319  				{
320  					pxNewTCB->ucStaticallyAllocated = tskSTATICALLY_ALLOCATED_STACK_ONLY;
321  				}
322  				#endif
323  				prvInitialiseNewTask(	pxTaskDefinition->pvTaskCode,
324  										pxTaskDefinition->pcName,
325  										( uint32_t ) pxTaskDefinition->usStackDepth,
326  										pxTaskDefinition->pvParameters,
327  										pxTaskDefinition->uxPriority,
328  										pxCreatedTask, pxNewTCB,
329  										pxTaskDefinition->xRegions );
330  				prvAddNewTaskToReadyList( pxNewTCB );
331  				xReturn = pdPASS;
332  			}
333  		}
334  		return xReturn;
335  	}
336  #endif &bsol;* portUSING_MPU_WRAPPERS */
337  #if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
338  	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
339  							const char * const pcName,		&bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
340  							const configSTACK_DEPTH_TYPE usStackDepth,
341  							void * const pvParameters,
342  							UBaseType_t uxPriority,
343  							TaskHandle_t * const pxCreatedTask )
344  	{
345  	TCB_t *pxNewTCB;
346  	BaseType_t xReturn;
347  		#if( portSTACK_GROWTH > 0 )
348  		{
349  			pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) );
350  			if( pxNewTCB != NULL )
351  			{
352  				pxNewTCB->pxStack = ( StackType_t * ) pvPortMalloc( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ) ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
353  				if( pxNewTCB->pxStack == NULL )
354  				{
355  					vPortFree( pxNewTCB );
356  					pxNewTCB = NULL;
357  				}
358  			}
359  		}
360  		#else &bsol;* portSTACK_GROWTH */
361  		{
362  		StackType_t *pxStack;
363  			pxStack = ( StackType_t * ) pvPortMalloc( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ) ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
364  			if( pxStack != NULL )
365  			{
366  				pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some paths. */
367  				if( pxNewTCB != NULL )
368  				{
369  					pxNewTCB->pxStack = pxStack;
370  				}
371  				else
372  				{
373  					vPortFree( pxStack );
374  				}
375  			}
376  			else
377  			{
378  				pxNewTCB = NULL;
379  			}
380  		}
381  		#endif &bsol;* portSTACK_GROWTH */
382  		if( pxNewTCB != NULL )
383  		{
384  			#if( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 ) &bsol;*lint !e731 Macro has been consolidated for readability reasons. */
385  			{
386  				pxNewTCB->ucStaticallyAllocated = tskDYNAMICALLY_ALLOCATED_STACK_AND_TCB;
387  			}
388  			#endif &bsol;* configSUPPORT_STATIC_ALLOCATION */
389  			prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );
390  			prvAddNewTaskToReadyList( pxNewTCB );
391  			xReturn = pdPASS;
392  		}
393  		else
394  		{
395  			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
396  		}
397  		return xReturn;
398  	}
399  #endif &bsol;* configSUPPORT_DYNAMIC_ALLOCATION */
400  static void prvInitialiseNewTask( 	TaskFunction_t pxTaskCode,
401  									const char * const pcName,		&bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
402  									const uint32_t ulStackDepth,
403  									void * const pvParameters,
404  									UBaseType_t uxPriority,
405  									TaskHandle_t * const pxCreatedTask,
406  									TCB_t *pxNewTCB,
407  									const MemoryRegion_t * const xRegions )
408  {
409  StackType_t *pxTopOfStack;
410  UBaseType_t x;
411  	#if( portUSING_MPU_WRAPPERS == 1 )
412  		BaseType_t xRunPrivileged;
413  		if( ( uxPriority & portPRIVILEGE_BIT ) != 0U )
414  		{
415  			xRunPrivileged = pdTRUE;
416  		}
417  		else
418  		{
419  			xRunPrivileged = pdFALSE;
420  		}
421  		uxPriority &= ~portPRIVILEGE_BIT;
422  	#endif &bsol;* portUSING_MPU_WRAPPERS == 1 */
423  	#if( tskSET_NEW_STACKS_TO_KNOWN_VALUE == 1 )
424  	{
425  		( void ) memset( pxNewTCB->pxStack, ( int ) tskSTACK_FILL_BYTE, ( size_t ) ulStackDepth * sizeof( StackType_t ) );
426  	}
427  	#endif &bsol;* tskSET_NEW_STACKS_TO_KNOWN_VALUE */
428  	#if( portSTACK_GROWTH < 0 )
429  	{
430  		pxTopOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
431  		pxTopOfStack = ( StackType_t * ) ( ( ( portPOINTER_SIZE_TYPE ) pxTopOfStack ) & ( ~( ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) ) ); &bsol;*lint !e923 MISRA exception.  Avoiding casts between pointers and integers is not practical.  Size differences accounted for using portPOINTER_SIZE_TYPE type. */
432  		configASSERT( ( ( ( portPOINTER_SIZE_TYPE ) pxTopOfStack & ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) == 0UL ) );
433  		#if( configRECORD_STACK_HIGH_ADDRESS == 1 )
434  		{
435  			pxNewTCB->pxEndOfStack = pxTopOfStack;
436  		}
437  		#endif &bsol;* configRECORD_STACK_HIGH_ADDRESS */
438  	}
439  	#else &bsol;* portSTACK_GROWTH */
440  	{
441  		pxTopOfStack = pxNewTCB->pxStack;
442  		configASSERT( ( ( ( portPOINTER_SIZE_TYPE ) pxNewTCB->pxStack & ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) == 0UL ) );
443  		pxNewTCB->pxEndOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
444  	}
445  	#endif &bsol;* portSTACK_GROWTH */
446  	for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
447  	{
448  		pxNewTCB->pcTaskName[ x ] = pcName[ x ];
449  		if( pcName[ x ] == 0x00 )
450  		{
451  			break;
452  		}
453  		else
454  		{
455  			mtCOVERAGE_TEST_MARKER();
456  		}
457  	}
458  	pxNewTCB->pcTaskName[ configMAX_TASK_NAME_LEN - 1 ] = '\0';
459  	if( uxPriority >= ( UBaseType_t ) configMAX_PRIORITIES )
460  	{
461  		uxPriority = ( UBaseType_t ) configMAX_PRIORITIES - ( UBaseType_t ) 1U;
462  	}
463  	else
464  	{
465  		mtCOVERAGE_TEST_MARKER();
466  	}
467  	pxNewTCB->uxPriority = uxPriority;
468  	#if ( configUSE_MUTEXES == 1 )
469  	{
470  		pxNewTCB->uxBasePriority = uxPriority;
471  		pxNewTCB->uxMutexesHeld = 0;
472  	}
473  	#endif &bsol;* configUSE_MUTEXES */
474  	vListInitialiseItem( &( pxNewTCB->xStateListItem ) );
475  	vListInitialiseItem( &( pxNewTCB->xEventListItem ) );
476  	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xStateListItem ), pxNewTCB );
477  	listSET_LIST_ITEM_VALUE( &( pxNewTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriority ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
478  	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xEventListItem ), pxNewTCB );
479  	#if ( portCRITICAL_NESTING_IN_TCB == 1 )
480  	{
481  		pxNewTCB->uxCriticalNesting = ( UBaseType_t ) 0U;
482  	}
483  	#endif &bsol;* portCRITICAL_NESTING_IN_TCB */
484  	#if ( configUSE_APPLICATION_TASK_TAG == 1 )
485  	{
486  		pxNewTCB->pxTaskTag = NULL;
487  	}
488  	#endif &bsol;* configUSE_APPLICATION_TASK_TAG */
489  	#if ( configGENERATE_RUN_TIME_STATS == 1 )
490  	{
491  		pxNewTCB->ulRunTimeCounter = 0UL;
492  	}
493  	#endif &bsol;* configGENERATE_RUN_TIME_STATS */
494  	#if ( portUSING_MPU_WRAPPERS == 1 )
495  	{
496  		vPortStoreTaskMPUSettings( &( pxNewTCB->xMPUSettings ), xRegions, pxNewTCB->pxStack, ulStackDepth );
497  	}
498  	#else
499  	{
500  		( void ) xRegions;
501  	}
502  	#endif
503  	#if( configNUM_THREAD_LOCAL_STORAGE_POINTERS != 0 )
504  	{
505  		for( x = 0; x < ( UBaseType_t ) configNUM_THREAD_LOCAL_STORAGE_POINTERS; x++ )
506  		{
507  			pxNewTCB->pvThreadLocalStoragePointers[ x ] = NULL;
508  		}
509  	}
510  	#endif
511  	#if ( configUSE_TASK_NOTIFICATIONS == 1 )
512  	{
513  		pxNewTCB->ulNotifiedValue = 0;
514  		pxNewTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
515  	}
516  	#endif
517  	#if ( configUSE_NEWLIB_REENTRANT == 1 )
518  	{
519  		_REENT_INIT_PTR( ( &( pxNewTCB->xNewLib_reent ) ) );
520  	}
521  	#endif
522  	#if( INCLUDE_xTaskAbortDelay == 1 )
523  	{
524  		pxNewTCB->ucDelayAborted = pdFALSE;
525  	}
526  	#endif
527  	#if( portUSING_MPU_WRAPPERS == 1 )
528  	{
529  		pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters, xRunPrivileged );
530  	}
531  	#else &bsol;* portUSING_MPU_WRAPPERS */
532  	{
533  		pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters );
534  	}
535  	#endif &bsol;* portUSING_MPU_WRAPPERS */
536  	if( ( void * ) pxCreatedTask != NULL )
537  	{
538  		*pxCreatedTask = ( TaskHandle_t ) pxNewTCB;
539  	}
540  	else
541  	{
542  		mtCOVERAGE_TEST_MARKER();
543  	}
544  }
545  static void prvAddNewTaskToReadyList( TCB_t *pxNewTCB )
546  {
547  	taskENTER_CRITICAL();
548  	{
549  		uxCurrentNumberOfTasks++;
550  		if( pxCurrentTCB == NULL )
551  		{
552  			pxCurrentTCB = pxNewTCB;
553  			if( uxCurrentNumberOfTasks == ( UBaseType_t ) 1 )
554  			{
555  				prvInitialiseTaskLists();
556  			}
557  			else
558  			{
559  				mtCOVERAGE_TEST_MARKER();
560  			}
561  		}
562  		else
563  		{
564  			if( xSchedulerRunning == pdFALSE )
565  			{
566  				if( pxCurrentTCB->uxPriority <= pxNewTCB->uxPriority )
567  				{
568  					pxCurrentTCB = pxNewTCB;
569  				}
570  				else
571  				{
572  					mtCOVERAGE_TEST_MARKER();
573  				}
574  			}
575  			else
576  			{
577  				mtCOVERAGE_TEST_MARKER();
578  			}
579  		}
580  		uxTaskNumber++;
581  		#if ( configUSE_TRACE_FACILITY == 1 )
582  		{
583  			pxNewTCB->uxTCBNumber = uxTaskNumber;
584  		}
585  		#endif &bsol;* configUSE_TRACE_FACILITY */
586  		traceTASK_CREATE( pxNewTCB );
587  		prvAddTaskToReadyList( pxNewTCB );
588  		portSETUP_TCB( pxNewTCB );
589  	}
590  	taskEXIT_CRITICAL();
591  	if( xSchedulerRunning != pdFALSE )
592  	{
593  		if( pxCurrentTCB->uxPriority < pxNewTCB->uxPriority )
594  		{
595  			taskYIELD_IF_USING_PREEMPTION();
596  		}
597  		else
598  		{
599  			mtCOVERAGE_TEST_MARKER();
600  		}
601  	}
602  	else
603  	{
604  		mtCOVERAGE_TEST_MARKER();
605  	}
606  }
607  #if ( INCLUDE_vTaskDelete == 1 )
608  	void vTaskDelete( TaskHandle_t xTaskToDelete )
609  	{
610  	TCB_t *pxTCB;
611  		taskENTER_CRITICAL();
612  		{
613  			pxTCB = prvGetTCBFromHandle( xTaskToDelete );
614  			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
615  			{
616  				taskRESET_READY_PRIORITY( pxTCB->uxPriority );
617  			}
618  			else
619  			{
620  				mtCOVERAGE_TEST_MARKER();
621  			}
622  			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
623  			{
624  				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
625  			}
626  			else
627  			{
628  				mtCOVERAGE_TEST_MARKER();
629  			}
630  			uxTaskNumber++;
631  			if( pxTCB == pxCurrentTCB )
632  			{
633  				vListInsertEnd( &xTasksWaitingTermination, &( pxTCB->xStateListItem ) );
634  				++uxDeletedTasksWaitingCleanUp;
635  				portPRE_TASK_DELETE_HOOK( pxTCB, &xYieldPending );
636  			}
637  			else
638  			{
639  				--uxCurrentNumberOfTasks;
640  				prvDeleteTCB( pxTCB );
641  				prvResetNextTaskUnblockTime();
642  			}
643  			traceTASK_DELETE( pxTCB );
644  		}
645  		taskEXIT_CRITICAL();
646  		if( xSchedulerRunning != pdFALSE )
647  		{
648  			if( pxTCB == pxCurrentTCB )
649  			{
650  				configASSERT( uxSchedulerSuspended == 0 );
651  				portYIELD_WITHIN_API();
652  			}
653  			else
654  			{
655  				mtCOVERAGE_TEST_MARKER();
656  			}
657  		}
658  	}
659  #endif &bsol;* INCLUDE_vTaskDelete */
660  #if ( INCLUDE_vTaskDelayUntil == 1 )
661  	void vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement )
662  	{
663  	TickType_t xTimeToWake;
664  	BaseType_t xAlreadyYielded, xShouldDelay = pdFALSE;
665  		configASSERT( pxPreviousWakeTime );
666  		configASSERT( ( xTimeIncrement > 0U ) );
667  		configASSERT( uxSchedulerSuspended == 0 );
668  		vTaskSuspendAll();
669  		{
670  			const TickType_t xConstTickCount = xTickCount;
671  			xTimeToWake = *pxPreviousWakeTime + xTimeIncrement;
672  			if( xConstTickCount < *pxPreviousWakeTime )
673  			{
674  				if( ( xTimeToWake < *pxPreviousWakeTime ) && ( xTimeToWake > xConstTickCount ) )
675  				{
676  					xShouldDelay = pdTRUE;
677  				}
678  				else
679  				{
680  					mtCOVERAGE_TEST_MARKER();
681  				}
682  			}
683  			else
684  			{
685  				if( ( xTimeToWake < *pxPreviousWakeTime ) || ( xTimeToWake > xConstTickCount ) )
686  				{
687  					xShouldDelay = pdTRUE;
688  				}
689  				else
690  				{
691  					mtCOVERAGE_TEST_MARKER();
692  				}
693  			}
694  			*pxPreviousWakeTime = xTimeToWake;
695  			if( xShouldDelay != pdFALSE )
696  			{
697  				traceTASK_DELAY_UNTIL( xTimeToWake );
698  				prvAddCurrentTaskToDelayedList( xTimeToWake - xConstTickCount, pdFALSE );
699  			}
700  			else
701  			{
702  				mtCOVERAGE_TEST_MARKER();
703  			}
704  		}
705  		xAlreadyYielded = xTaskResumeAll();
706  		if( xAlreadyYielded == pdFALSE )
707  		{
708  			portYIELD_WITHIN_API();
709  		}
710  		else
711  		{
712  			mtCOVERAGE_TEST_MARKER();
713  		}
714  	}
715  #endif &bsol;* INCLUDE_vTaskDelayUntil */
716  #if ( INCLUDE_vTaskDelay == 1 )
717  	void vTaskDelay( const TickType_t xTicksToDelay )
718  	{
719  	BaseType_t xAlreadyYielded = pdFALSE;
720  		if( xTicksToDelay > ( TickType_t ) 0U )
721  		{
722  			configASSERT( uxSchedulerSuspended == 0 );
723  			vTaskSuspendAll();
724  			{
725  				traceTASK_DELAY();
726  				prvAddCurrentTaskToDelayedList( xTicksToDelay, pdFALSE );
727  			}
728  			xAlreadyYielded = xTaskResumeAll();
729  		}
730  		else
731  		{
732  			mtCOVERAGE_TEST_MARKER();
733  		}
734  		if( xAlreadyYielded == pdFALSE )
735  		{
736  			portYIELD_WITHIN_API();
737  		}
738  		else
739  		{
740  			mtCOVERAGE_TEST_MARKER();
741  		}
742  	}
743  #endif &bsol;* INCLUDE_vTaskDelay */
744  #if( ( INCLUDE_eTaskGetState == 1 ) || ( configUSE_TRACE_FACILITY == 1 ) )
745  	eTaskState eTaskGetState( TaskHandle_t xTask )
746  	{
747  	eTaskState eReturn;
748  	List_t *pxStateList;
749  	const TCB_t * const pxTCB = ( TCB_t * ) xTask;
750  		configASSERT( pxTCB );
751  		if( pxTCB == pxCurrentTCB )
752  		{
753  			eReturn = eRunning;
754  		}
755  		else
756  		{
757  			taskENTER_CRITICAL();
758  			{
759  				pxStateList = ( List_t * ) listLIST_ITEM_CONTAINER( &( pxTCB->xStateListItem ) );
760  			}
761  			taskEXIT_CRITICAL();
762  			if( ( pxStateList == pxDelayedTaskList ) || ( pxStateList == pxOverflowDelayedTaskList ) )
763  			{
764  				eReturn = eBlocked;
765  			}
766  			#if ( INCLUDE_vTaskSuspend == 1 )
767  				else if( pxStateList == &xSuspendedTaskList )
768  				{
769  					if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL )
770  					{
771  						eReturn = eSuspended;
772  					}
773  					else
774  					{
775  						eReturn = eBlocked;
776  					}
777  				}
778  			#endif
779  			#if ( INCLUDE_vTaskDelete == 1 )
780  				else if( ( pxStateList == &xTasksWaitingTermination ) || ( pxStateList == NULL ) )
781  				{
782  					eReturn = eDeleted;
783  				}
784  			#endif
785  			else &bsol;*lint !e525 Negative indentation is intended to make use of pre-processor clearer. */
786  			{
787  				eReturn = eReady;
788  			}
789  		}
790  		return eReturn;
791  	} &bsol;*lint !e818 xTask cannot be a pointer to const because it is a typedef. */
792  #endif &bsol;* INCLUDE_eTaskGetState */
793  #if ( INCLUDE_uxTaskPriorityGet == 1 )
794  	UBaseType_t uxTaskPriorityGet( TaskHandle_t xTask )
795  	{
796  	TCB_t *pxTCB;
797  	UBaseType_t uxReturn;
798  		taskENTER_CRITICAL();
799  		{
800  			pxTCB = prvGetTCBFromHandle( xTask );
801  			uxReturn = pxTCB->uxPriority;
802  		}
803  		taskEXIT_CRITICAL();
804  		return uxReturn;
805  	}
806  #endif &bsol;* INCLUDE_uxTaskPriorityGet */
807  #if ( INCLUDE_uxTaskPriorityGet == 1 )
808  	UBaseType_t uxTaskPriorityGetFromISR( TaskHandle_t xTask )
809  	{
810  	TCB_t *pxTCB;
811  	UBaseType_t uxReturn, uxSavedInterruptState;
812  		portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
813  		uxSavedInterruptState = portSET_INTERRUPT_MASK_FROM_ISR();
814  		{
815  			pxTCB = prvGetTCBFromHandle( xTask );
816  			uxReturn = pxTCB->uxPriority;
817  		}
818  		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptState );
819  		return uxReturn;
820  	}
821  #endif &bsol;* INCLUDE_uxTaskPriorityGet */
822  #if ( INCLUDE_vTaskPrioritySet == 1 )
823  	void vTaskPrioritySet( TaskHandle_t xTask, UBaseType_t uxNewPriority )
824  	{
825  	TCB_t *pxTCB;
826  	UBaseType_t uxCurrentBasePriority, uxPriorityUsedOnEntry;
827  	BaseType_t xYieldRequired = pdFALSE;
828  		configASSERT( ( uxNewPriority < configMAX_PRIORITIES ) );
829  		if( uxNewPriority >= ( UBaseType_t ) configMAX_PRIORITIES )
830  		{
831  			uxNewPriority = ( UBaseType_t ) configMAX_PRIORITIES - ( UBaseType_t ) 1U;
832  		}
833  		else
834  		{
835  			mtCOVERAGE_TEST_MARKER();
836  		}
837  		taskENTER_CRITICAL();
838  		{
839  			pxTCB = prvGetTCBFromHandle( xTask );
840  			traceTASK_PRIORITY_SET( pxTCB, uxNewPriority );
841  			#if ( configUSE_MUTEXES == 1 )
842  			{
843  				uxCurrentBasePriority = pxTCB->uxBasePriority;
844  			}
845  			#else
846  			{
847  				uxCurrentBasePriority = pxTCB->uxPriority;
848  			}
849  			#endif
850  			if( uxCurrentBasePriority != uxNewPriority )
851  			{
852  				if( uxNewPriority > uxCurrentBasePriority )
853  				{
854  					if( pxTCB != pxCurrentTCB )
855  					{
856  						if( uxNewPriority >= pxCurrentTCB->uxPriority )
857  						{
858  							xYieldRequired = pdTRUE;
859  						}
860  						else
861  						{
862  							mtCOVERAGE_TEST_MARKER();
863  						}
864  					}
865  					else
866  					{
867  					}
868  				}
869  				else if( pxTCB == pxCurrentTCB )
870  				{
871  					xYieldRequired = pdTRUE;
872  				}
873  				else
874  				{
875  				}
876  				uxPriorityUsedOnEntry = pxTCB->uxPriority;
877  				#if ( configUSE_MUTEXES == 1 )
878  				{
879  					if( pxTCB->uxBasePriority == pxTCB->uxPriority )
880  					{
881  						pxTCB->uxPriority = uxNewPriority;
882  					}
883  					else
884  					{
885  						mtCOVERAGE_TEST_MARKER();
886  					}
887  					pxTCB->uxBasePriority = uxNewPriority;
888  				}
889  				#else
890  				{
891  					pxTCB->uxPriority = uxNewPriority;
892  				}
893  				#endif
894  				if( ( listGET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == 0UL )
895  				{
896  					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxNewPriority ) ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
897  				}
898  				else
899  				{
900  					mtCOVERAGE_TEST_MARKER();
901  				}
902  				if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ uxPriorityUsedOnEntry ] ), &( pxTCB->xStateListItem ) ) != pdFALSE )
903  				{
904  					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
905  					{
906  						portRESET_READY_PRIORITY( uxPriorityUsedOnEntry, uxTopReadyPriority );
907  					}
908  					else
909  					{
910  						mtCOVERAGE_TEST_MARKER();
911  					}
912  					prvReaddTaskToReadyList( pxTCB );
913  				}
914  				else
915  				{
916  					mtCOVERAGE_TEST_MARKER();
917  				}
918  				if( xYieldRequired != pdFALSE )
919  				{
920  					taskYIELD_IF_USING_PREEMPTION();
921  				}
922  				else
923  				{
924  					mtCOVERAGE_TEST_MARKER();
925  				}
926  				( void ) uxPriorityUsedOnEntry;
927  			}
928  		}
929  		taskEXIT_CRITICAL();
930  	}
931  #endif &bsol;* INCLUDE_vTaskPrioritySet */
932  #if ( INCLUDE_vTaskSuspend == 1 )
933  	void vTaskSuspend( TaskHandle_t xTaskToSuspend )
934  	{
935  	TCB_t *pxTCB;
936  		taskENTER_CRITICAL();
937  		{
938  			pxTCB = prvGetTCBFromHandle( xTaskToSuspend );
939  			traceTASK_SUSPEND( pxTCB );
940  			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
941  			{
942  				taskRESET_READY_PRIORITY( pxTCB->uxPriority );
943  			}
944  			else
945  			{
946  				mtCOVERAGE_TEST_MARKER();
947  			}
948  			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
949  			{
950  				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
951  			}
952  			else
953  			{
954  				mtCOVERAGE_TEST_MARKER();
955  			}
956  			traceMOVED_TASK_TO_SUSPENDED_LIST(pxTCB);
957  			vListInsertEnd( &xSuspendedTaskList, &( pxTCB->xStateListItem ) );
958  			#if( configUSE_TASK_NOTIFICATIONS == 1 )
959  			{
960  				if( pxTCB->ucNotifyState == taskWAITING_NOTIFICATION )
961  				{
962  					pxTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
963  				}
964  			}
965  			#endif
966  		}
967  		taskEXIT_CRITICAL();
968  		if( xSchedulerRunning != pdFALSE )
969  		{
970  			taskENTER_CRITICAL();
971  			{
972  				prvResetNextTaskUnblockTime();
973  			}
974  			taskEXIT_CRITICAL();
975  		}
976  		else
977  		{
978  			mtCOVERAGE_TEST_MARKER();
979  		}
980  		if( pxTCB == pxCurrentTCB )
981  		{
982  			if( xSchedulerRunning != pdFALSE )
983  			{
984  				configASSERT( uxSchedulerSuspended == 0 );
985  				portYIELD_WITHIN_API();
986  			}
987  			else
988  			{
989  				if( listCURRENT_LIST_LENGTH( &xSuspendedTaskList ) == uxCurrentNumberOfTasks )
990  				{
991  					pxCurrentTCB = NULL;
992  				}
993  				else
994  				{
995  					vTaskSwitchContext();
996  				}
997  			}
998  		}
999  		else
1000  		{
1001  			mtCOVERAGE_TEST_MARKER();
1002  		}
1003  	}
1004  #endif &bsol;* INCLUDE_vTaskSuspend */
1005  #if ( INCLUDE_vTaskSuspend == 1 )
1006  	static BaseType_t prvTaskIsTaskSuspended( const TaskHandle_t xTask )
1007  	{
1008  	BaseType_t xReturn = pdFALSE;
1009  	const TCB_t * const pxTCB = ( TCB_t * ) xTask;
1010  		configASSERT( xTask );
1011  		if( listIS_CONTAINED_WITHIN( &xSuspendedTaskList, &( pxTCB->xStateListItem ) ) != pdFALSE )
1012  		{
1013  			if( listIS_CONTAINED_WITHIN( &xPendingReadyList, &( pxTCB->xEventListItem ) ) == pdFALSE )
1014  			{
1015  				if( listIS_CONTAINED_WITHIN( NULL, &( pxTCB->xEventListItem ) ) != pdFALSE ) &bsol;*lint !e961.  The cast is only redundant when NULL is used. */
1016  				{
1017  					xReturn = pdTRUE;
1018  				}
1019  				else
1020  				{
1021  					mtCOVERAGE_TEST_MARKER();
1022  				}
1023  			}
1024  			else
1025  			{
1026  				mtCOVERAGE_TEST_MARKER();
1027  			}
1028  		}
1029  		else
1030  		{
1031  			mtCOVERAGE_TEST_MARKER();
1032  		}
1033  		return xReturn;
1034  	} &bsol;*lint !e818 xTask cannot be a pointer to const because it is a typedef. */
1035  #endif &bsol;* INCLUDE_vTaskSuspend */
1036  #if ( INCLUDE_vTaskSuspend == 1 )
1037  	void vTaskResume( TaskHandle_t xTaskToResume )
1038  	{
1039  	TCB_t * const pxTCB = ( TCB_t * ) xTaskToResume;
1040  		configASSERT( xTaskToResume );
1041  		if( ( pxTCB != NULL ) && ( pxTCB != pxCurrentTCB ) )
1042  		{
1043  			taskENTER_CRITICAL();
1044  			{
1045  				if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )
1046  				{
1047  					traceTASK_RESUME( pxTCB );
1048  					( void ) uxListRemove(  &( pxTCB->xStateListItem ) );
1049  					prvAddTaskToReadyList( pxTCB );
1050  					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
1051  					{
1052  						taskYIELD_IF_USING_PREEMPTION();
1053  					}
1054  					else
1055  					{
1056  						mtCOVERAGE_TEST_MARKER();
1057  					}
1058  				}
1059  				else
1060  				{
1061  					mtCOVERAGE_TEST_MARKER();
1062  				}
1063  			}
1064  			taskEXIT_CRITICAL();
1065  		}
1066  		else
1067  		{
1068  			mtCOVERAGE_TEST_MARKER();
1069  		}
1070  	}
1071  #endif &bsol;* INCLUDE_vTaskSuspend */
1072  #if ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) )
1073  	BaseType_t xTaskResumeFromISR( TaskHandle_t xTaskToResume )
1074  	{
1075  	BaseType_t xYieldRequired = pdFALSE;
1076  	TCB_t * const pxTCB = ( TCB_t * ) xTaskToResume;
1077  	UBaseType_t uxSavedInterruptStatus;
<span onclick='openModal()' class='match'>1078  		configASSERT( xTaskToResume );
1079  		portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
1080  		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
1081  		{
</span>1082  			if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )
1083  			{
1084  				traceTASK_RESUME_FROM_ISR( pxTCB );
1085  				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
1086  				{
1087  					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
1088  					{
1089  						xYieldRequired = pdTRUE;
1090  					}
1091  					else
1092  					{
1093  						mtCOVERAGE_TEST_MARKER();
1094  					}
1095  					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
1096  					prvAddTaskToReadyList( pxTCB );
1097  				}
1098  				else
1099  				{
1100  					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
1101  				}
1102  			}
1103  			else
1104  			{
1105  				mtCOVERAGE_TEST_MARKER();
1106  			}
1107  		}
1108  		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
1109  		return xYieldRequired;
1110  	}
1111  #endif &bsol;* ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) ) */
1112  void vTaskStartScheduler( void )
1113  {
1114  BaseType_t xReturn;
1115  	#if( configSUPPORT_STATIC_ALLOCATION == 1 )
1116  	{
1117  		StaticTask_t *pxIdleTaskTCBBuffer = NULL;
1118  		StackType_t *pxIdleTaskStackBuffer = NULL;
1119  		uint32_t ulIdleTaskStackSize;
1120  		vApplicationGetIdleTaskMemory( &pxIdleTaskTCBBuffer, &pxIdleTaskStackBuffer, &ulIdleTaskStackSize );
1121  		xIdleTaskHandle = xTaskCreateStatic(	prvIdleTask,
1122  												configIDLE_TASK_NAME,
1123  												ulIdleTaskStackSize,
1124  												( void * ) NULL, &bsol;*lint !e961.  The cast is not redundant for all compilers. */
1125  												( tskIDLE_PRIORITY | portPRIVILEGE_BIT ),
1126  												pxIdleTaskStackBuffer,
1127  												pxIdleTaskTCBBuffer ); &bsol;*lint !e961 MISRA exception, justified as it is not a redundant explicit cast to all supported compilers. */
1128  		if( xIdleTaskHandle != NULL )
1129  		{
1130  			xReturn = pdPASS;
1131  		}
1132  		else
1133  		{
1134  			xReturn = pdFAIL;
1135  		}
1136  	}
1137  	#else
1138  	{
1139  		xReturn = xTaskCreate(	prvIdleTask,
1140  								configIDLE_TASK_NAME,
1141  								configMINIMAL_STACK_SIZE,
1142  								( void * ) NULL,
1143  								( tskIDLE_PRIORITY | portPRIVILEGE_BIT ),
1144  								&xIdleTaskHandle ); &bsol;*lint !e961 MISRA exception, justified as it is not a redundant explicit cast to all supported compilers. */
1145  	}
1146  	#endif &bsol;* configSUPPORT_STATIC_ALLOCATION */
1147  	#if ( configUSE_TIMERS == 1 )
1148  	{
1149  		if( xReturn == pdPASS )
1150  		{
1151  			xReturn = xTimerCreateTimerTask();
1152  		}
1153  		else
1154  		{
1155  			mtCOVERAGE_TEST_MARKER();
1156  		}
1157  	}
1158  	#endif &bsol;* configUSE_TIMERS */
1159  	if( xReturn == pdPASS )
1160  	{
1161  		#ifdef FREERTOS_TASKS_C_ADDITIONS_INIT
1162  		{
1163  			freertos_tasks_c_additions_init();
1164  		}
1165  		#endif
1166  		portDISABLE_INTERRUPTS();
1167  		#if ( configUSE_NEWLIB_REENTRANT == 1 )
1168  		{
1169  			_impure_ptr = &( pxCurrentTCB->xNewLib_reent );
1170  		}
1171  		#endif &bsol;* configUSE_NEWLIB_REENTRANT */
1172  		xNextTaskUnblockTime = portMAX_DELAY;
1173  		xSchedulerRunning = pdTRUE;
1174  		xTickCount = ( TickType_t ) 0U;
1175  		portCONFIGURE_TIMER_FOR_RUN_TIME_STATS();
1176  		if( xPortStartScheduler() != pdFALSE )
1177  		{
1178  		}
1179  		else
1180  		{
1181  		}
1182  	}
1183  	else
1184  	{
1185  		configASSERT( xReturn != errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY );
1186  	}
1187  	( void ) xIdleTaskHandle;
1188  }
1189  void vTaskEndScheduler( void )
1190  {
1191  	portDISABLE_INTERRUPTS();
1192  	xSchedulerRunning = pdFALSE;
1193  	vPortEndScheduler();
1194  }
1195  void vTaskSuspendAll( void )
1196  {
1197  	++uxSchedulerSuspended;
1198  }
1199  #if ( configUSE_TICKLESS_IDLE != 0 )
1200  	static TickType_t prvGetExpectedIdleTime( void )
1201  	{
1202  	TickType_t xReturn;
1203  	UBaseType_t uxHigherPriorityReadyTasks = pdFALSE;
1204  		#if( configUSE_PORT_OPTIMISED_TASK_SELECTION == 0 )
1205  		{
1206  			if( uxTopReadyPriority > tskIDLE_PRIORITY )
1207  			{
1208  				uxHigherPriorityReadyTasks = pdTRUE;
1209  			}
1210  		}
1211  		#else
1212  		{
1213  			const UBaseType_t uxLeastSignificantBit = ( UBaseType_t ) 0x01;
1214  			if( uxTopReadyPriority > uxLeastSignificantBit )
1215  			{
1216  				uxHigherPriorityReadyTasks = pdTRUE;
1217  			}
1218  		}
1219  		#endif
1220  		if( pxCurrentTCB->uxPriority > tskIDLE_PRIORITY )
1221  		{
1222  			xReturn = 0;
1223  		}
1224  		else if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > 1 )
1225  		{
1226  			xReturn = 0;
1227  		}
1228  		else if( uxHigherPriorityReadyTasks != pdFALSE )
1229  		{
1230  			xReturn = 0;
1231  		}
1232  		else
1233  		{
1234  			xReturn = xNextTaskUnblockTime - xTickCount;
1235  		}
1236  		return xReturn;
1237  	}
1238  #endif &bsol;* configUSE_TICKLESS_IDLE */
1239  BaseType_t xTaskResumeAll( void )
1240  {
1241  TCB_t *pxTCB = NULL;
1242  BaseType_t xAlreadyYielded = pdFALSE;
1243  	configASSERT( uxSchedulerSuspended );
1244  	taskENTER_CRITICAL();
1245  	{
1246  		--uxSchedulerSuspended;
1247  		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
1248  		{
1249  			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
1250  			{
1251  				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
1252  				{
1253  					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyList ) );
1254  					( void ) uxListRemove( &( pxTCB->xEventListItem ) );
1255  					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
1256  					prvAddTaskToReadyList( pxTCB );
1257  					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
1258  					{
1259  						xYieldPending = pdTRUE;
1260  					}
1261  					else
1262  					{
1263  						mtCOVERAGE_TEST_MARKER();
1264  					}
1265  				}
1266  				if( pxTCB != NULL )
1267  				{
1268  					prvResetNextTaskUnblockTime();
1269  				}
1270  				{
1271  					UBaseType_t uxPendedCounts = uxPendedTicks; &bsol;* Non-volatile copy. */
1272  					if( uxPendedCounts > ( UBaseType_t ) 0U )
1273  					{
1274  						do
1275  						{
1276  							if( xTaskIncrementTick() != pdFALSE )
1277  							{
1278  								xYieldPending = pdTRUE;
1279  							}
1280  							else
1281  							{
1282  								mtCOVERAGE_TEST_MARKER();
1283  							}
1284  							--uxPendedCounts;
1285  						} while( uxPendedCounts > ( UBaseType_t ) 0U );
1286  						uxPendedTicks = 0;
1287  					}
1288  					else
1289  					{
1290  						mtCOVERAGE_TEST_MARKER();
1291  					}
1292  				}
1293  				if( xYieldPending != pdFALSE )
1294  				{
1295  					#if( configUSE_PREEMPTION != 0 )
1296  					{
1297  						xAlreadyYielded = pdTRUE;
1298  					}
1299  					#endif
1300  					taskYIELD_IF_USING_PREEMPTION();
1301  				}
1302  				else
1303  				{
1304  					mtCOVERAGE_TEST_MARKER();
1305  				}
1306  			}
1307  		}
1308  		else
1309  		{
1310  			mtCOVERAGE_TEST_MARKER();
1311  		}
1312  	}
1313  	taskEXIT_CRITICAL();
1314  	return xAlreadyYielded;
1315  }
1316  TickType_t xTaskGetTickCount( void )
1317  {
1318  TickType_t xTicks;
1319  	portTICK_TYPE_ENTER_CRITICAL();
1320  	{
1321  		xTicks = xTickCount;
1322  	}
1323  	portTICK_TYPE_EXIT_CRITICAL();
1324  	return xTicks;
1325  }
1326  TickType_t xTaskGetTickCountFromISR( void )
1327  {
1328  TickType_t xReturn;
1329  UBaseType_t uxSavedInterruptStatus;
1330  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
1331  	uxSavedInterruptStatus = portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR();
1332  	{
1333  		xReturn = xTickCount;
1334  	}
1335  	portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
1336  	return xReturn;
1337  }
1338  UBaseType_t uxTaskGetNumberOfTasks( void )
1339  {
1340  	return uxCurrentNumberOfTasks;
1341  }
1342  char *pcTaskGetName( TaskHandle_t xTaskToQuery ) &bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1343  {
1344  TCB_t *pxTCB;
1345  	pxTCB = prvGetTCBFromHandle( xTaskToQuery );
1346  	configASSERT( pxTCB );
1347  	return &( pxTCB->pcTaskName[ 0 ] );
1348  }
1349  #if ( INCLUDE_xTaskGetHandle == 1 )
1350  	static TCB_t *prvSearchForNameWithinSingleList( List_t *pxList, const char pcNameToQuery[] )
1351  	{
1352  	TCB_t *pxNextTCB, *pxFirstTCB, *pxReturn = NULL;
1353  	UBaseType_t x;
1354  	char cNextChar;
1355  		if( listCURRENT_LIST_LENGTH( pxList ) > ( UBaseType_t ) 0 )
1356  		{
1357  			listGET_OWNER_OF_NEXT_ENTRY( pxFirstTCB, pxList );
1358  			do
1359  			{
1360  				listGET_OWNER_OF_NEXT_ENTRY( pxNextTCB, pxList );
1361  				for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
1362  				{
1363  					cNextChar = pxNextTCB->pcTaskName[ x ];
1364  					if( cNextChar != pcNameToQuery[ x ] )
1365  					{
1366  						break;
1367  					}
1368  					else if( cNextChar == 0x00 )
1369  					{
1370  						pxReturn = pxNextTCB;
1371  						break;
1372  					}
1373  					else
1374  					{
1375  						mtCOVERAGE_TEST_MARKER();
1376  					}
1377  				}
1378  				if( pxReturn != NULL )
1379  				{
1380  					break;
1381  				}
1382  			} while( pxNextTCB != pxFirstTCB );
1383  		}
1384  		else
1385  		{
1386  			mtCOVERAGE_TEST_MARKER();
1387  		}
1388  		return pxReturn;
1389  	}
1390  #endif &bsol;* INCLUDE_xTaskGetHandle */
1391  #if ( INCLUDE_xTaskGetHandle == 1 )
1392  	TaskHandle_t xTaskGetHandle( const char *pcNameToQuery ) &bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1393  	{
1394  	UBaseType_t uxQueue = configMAX_PRIORITIES;
1395  	TCB_t* pxTCB;
1396  		configASSERT( strlen( pcNameToQuery ) < configMAX_TASK_NAME_LEN );
1397  		vTaskSuspendAll();
1398  		{
1399  			do
1400  			{
1401  				uxQueue--;
1402  				pxTCB = prvSearchForNameWithinSingleList( ( List_t * ) &( pxReadyTasksLists[ uxQueue ] ), pcNameToQuery );
1403  				if( pxTCB != NULL )
1404  				{
1405  					break;
1406  				}
1407  			} while( uxQueue > ( UBaseType_t ) tskIDLE_PRIORITY ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
1408  			if( pxTCB == NULL )
1409  			{
1410  				pxTCB = prvSearchForNameWithinSingleList( ( List_t * ) pxDelayedTaskList, pcNameToQuery );
1411  			}
1412  			if( pxTCB == NULL )
1413  			{
1414  				pxTCB = prvSearchForNameWithinSingleList( ( List_t * ) pxOverflowDelayedTaskList, pcNameToQuery );
1415  			}
1416  			#if ( INCLUDE_vTaskSuspend == 1 )
1417  			{
1418  				if( pxTCB == NULL )
1419  				{
1420  					pxTCB = prvSearchForNameWithinSingleList( &xSuspendedTaskList, pcNameToQuery );
1421  				}
1422  			}
1423  			#endif
1424  			#if( INCLUDE_vTaskDelete == 1 )
1425  			{
1426  				if( pxTCB == NULL )
1427  				{
1428  					pxTCB = prvSearchForNameWithinSingleList( &xTasksWaitingTermination, pcNameToQuery );
1429  				}
1430  			}
1431  			#endif
1432  		}
1433  		( void ) xTaskResumeAll();
1434  		return ( TaskHandle_t ) pxTCB;
1435  	}
1436  #endif &bsol;* INCLUDE_xTaskGetHandle */
1437  #if ( configUSE_TRACE_FACILITY == 1 )
1438  	UBaseType_t uxTaskGetSystemState( TaskStatus_t * const pxTaskStatusArray, const UBaseType_t uxArraySize, uint32_t * const pulTotalRunTime )
1439  	{
1440  	UBaseType_t uxTask = 0, uxQueue = configMAX_PRIORITIES;
1441  		vTaskSuspendAll();
1442  		{
1443  			if( uxArraySize >= uxCurrentNumberOfTasks )
1444  			{
1445  				do
1446  				{
1447  					uxQueue--;
1448  					uxTask += prvListTasksWithinSingleList( &( pxTaskStatusArray[ uxTask ] ), &( pxReadyTasksLists[ uxQueue ] ), eReady );
1449  				} while( uxQueue > ( UBaseType_t ) tskIDLE_PRIORITY ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
1450  				uxTask += prvListTasksWithinSingleList( &( pxTaskStatusArray[ uxTask ] ), ( List_t * ) pxDelayedTaskList, eBlocked );
1451  				uxTask += prvListTasksWithinSingleList( &( pxTaskStatusArray[ uxTask ] ), ( List_t * ) pxOverflowDelayedTaskList, eBlocked );
1452  				#if( INCLUDE_vTaskDelete == 1 )
1453  				{
1454  					uxTask += prvListTasksWithinSingleList( &( pxTaskStatusArray[ uxTask ] ), &xTasksWaitingTermination, eDeleted );
1455  				}
1456  				#endif
1457  				#if ( INCLUDE_vTaskSuspend == 1 )
1458  				{
1459  					uxTask += prvListTasksWithinSingleList( &( pxTaskStatusArray[ uxTask ] ), &xSuspendedTaskList, eSuspended );
1460  				}
1461  				#endif
1462  				#if ( configGENERATE_RUN_TIME_STATS == 1)
1463  				{
1464  					if( pulTotalRunTime != NULL )
1465  					{
1466  						#ifdef portALT_GET_RUN_TIME_COUNTER_VALUE
1467  							portALT_GET_RUN_TIME_COUNTER_VALUE( ( *pulTotalRunTime ) );
1468  						#else
1469  							*pulTotalRunTime = portGET_RUN_TIME_COUNTER_VALUE();
1470  						#endif
1471  					}
1472  				}
1473  				#else
1474  				{
1475  					if( pulTotalRunTime != NULL )
1476  					{
1477  						*pulTotalRunTime = 0;
1478  					}
1479  				}
1480  				#endif
1481  			}
1482  			else
1483  			{
1484  				mtCOVERAGE_TEST_MARKER();
1485  			}
1486  		}
1487  		( void ) xTaskResumeAll();
1488  		return uxTask;
1489  	}
1490  #endif &bsol;* configUSE_TRACE_FACILITY */
1491  #if ( INCLUDE_xTaskGetIdleTaskHandle == 1 )
1492  	TaskHandle_t xTaskGetIdleTaskHandle( void )
1493  	{
1494  		configASSERT( ( xIdleTaskHandle != NULL ) );
1495  		return xIdleTaskHandle;
1496  	}
1497  #endif &bsol;* INCLUDE_xTaskGetIdleTaskHandle */
1498  #if ( configUSE_TICKLESS_IDLE != 0 )
1499  	void vTaskStepTick( const TickType_t xTicksToJump )
1500  	{
1501  		configASSERT( ( xTickCount + xTicksToJump ) <= xNextTaskUnblockTime );
1502  		xTickCount += xTicksToJump;
1503  		traceINCREASE_TICK_COUNT( xTicksToJump );
1504  	}
1505  #endif &bsol;* configUSE_TICKLESS_IDLE */
1506  #if ( INCLUDE_xTaskAbortDelay == 1 )
1507  	BaseType_t xTaskAbortDelay( TaskHandle_t xTask )
1508  	{
1509  	TCB_t *pxTCB = ( TCB_t * ) xTask;
1510  	BaseType_t xReturn;
1511  		configASSERT( pxTCB );
1512  		vTaskSuspendAll();
1513  		{
1514  			if( eTaskGetState( xTask ) == eBlocked )
1515  			{
1516  				xReturn = pdPASS;
1517  				( void ) uxListRemove( &( pxTCB->xStateListItem ) );
1518  				taskENTER_CRITICAL();
1519  				{
1520  					if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
1521  					{
1522  						( void ) uxListRemove( &( pxTCB->xEventListItem ) );
1523  						pxTCB->ucDelayAborted = pdTRUE;
1524  					}
1525  					else
1526  					{
1527  						mtCOVERAGE_TEST_MARKER();
1528  					}
1529  				}
1530  				taskEXIT_CRITICAL();
1531  				prvAddTaskToReadyList( pxTCB );
1532  				#if (  configUSE_PREEMPTION == 1 )
1533  				{
1534  					if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
1535  					{
1536  						xYieldPending = pdTRUE;
1537  					}
1538  					else
1539  					{
1540  						mtCOVERAGE_TEST_MARKER();
1541  					}
1542  				}
1543  				#endif &bsol;* configUSE_PREEMPTION */
1544  			}
1545  			else
1546  			{
1547  				xReturn = pdFAIL;
1548  			}
1549  		}
1550  		( void ) xTaskResumeAll();
1551  		return xReturn;
1552  	}
1553  #endif &bsol;* INCLUDE_xTaskAbortDelay */
1554  BaseType_t xTaskIncrementTick( void )
1555  {
1556  TCB_t * pxTCB;
1557  TickType_t xItemValue;
1558  BaseType_t xSwitchRequired = pdFALSE;
1559  	traceTASK_INCREMENT_TICK( xTickCount );
1560  	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
1561  	{
1562  		const TickType_t xConstTickCount = xTickCount + ( TickType_t ) 1;
1563  		xTickCount = xConstTickCount;
1564  		if( xConstTickCount == ( TickType_t ) 0U ) &bsol;*lint !e774 'if' does not always evaluate to false as it is looking for an overflow. */
1565  		{
1566  			taskSWITCH_DELAYED_LISTS();
1567  		}
1568  		else
1569  		{
1570  			mtCOVERAGE_TEST_MARKER();
1571  		}
1572  		if( xConstTickCount >= xNextTaskUnblockTime )
1573  		{
1574  			for( ;; )
1575  			{
1576  				if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
1577  				{
1578  					xNextTaskUnblockTime = portMAX_DELAY; &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
1579  					break;
1580  				}
1581  				else
1582  				{
1583  					pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
1584  					xItemValue = listGET_LIST_ITEM_VALUE( &( pxTCB->xStateListItem ) );
1585  					if( xConstTickCount < xItemValue )
1586  					{
1587  						xNextTaskUnblockTime = xItemValue;
1588  						break;
1589  					}
1590  					else
1591  					{
1592  						mtCOVERAGE_TEST_MARKER();
1593  					}
1594  					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
1595  					if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
1596  					{
1597  						( void ) uxListRemove( &( pxTCB->xEventListItem ) );
1598  					}
1599  					else
1600  					{
1601  						mtCOVERAGE_TEST_MARKER();
1602  					}
1603  					prvAddTaskToReadyList( pxTCB );
1604  					#if (  configUSE_PREEMPTION == 1 )
1605  					{
1606  						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
1607  						{
1608  							xSwitchRequired = pdTRUE;
1609  						}
1610  						else
1611  						{
1612  							mtCOVERAGE_TEST_MARKER();
1613  						}
1614  					}
1615  					#endif &bsol;* configUSE_PREEMPTION */
1616  				}
1617  			}
1618  		}
1619  		#if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) )
1620  		{
1621  			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCB->uxPriority ] ) ) > ( UBaseType_t ) 1 )
1622  			{
1623  				xSwitchRequired = pdTRUE;
1624  			}
1625  			else
1626  			{
1627  				mtCOVERAGE_TEST_MARKER();
1628  			}
1629  		}
1630  		#endif &bsol;* ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) ) */
1631  		#if ( configUSE_TICK_HOOK == 1 )
1632  		{
1633  			if( uxPendedTicks == ( UBaseType_t ) 0U )
1634  			{
1635  				vApplicationTickHook();
1636  			}
1637  			else
1638  			{
1639  				mtCOVERAGE_TEST_MARKER();
1640  			}
1641  		}
1642  		#endif &bsol;* configUSE_TICK_HOOK */
1643  	}
1644  	else
1645  	{
1646  		++uxPendedTicks;
1647  		#if ( configUSE_TICK_HOOK == 1 )
1648  		{
1649  			vApplicationTickHook();
1650  		}
1651  		#endif
1652  	}
1653  	#if ( configUSE_PREEMPTION == 1 )
1654  	{
1655  		if( xYieldPending != pdFALSE )
1656  		{
1657  			xSwitchRequired = pdTRUE;
1658  		}
1659  		else
1660  		{
1661  			mtCOVERAGE_TEST_MARKER();
1662  		}
1663  	}
1664  	#endif &bsol;* configUSE_PREEMPTION */
1665  	return xSwitchRequired;
1666  }
1667  #if ( configUSE_APPLICATION_TASK_TAG == 1 )
1668  	void vTaskSetApplicationTaskTag( TaskHandle_t xTask, TaskHookFunction_t pxHookFunction )
1669  	{
1670  	TCB_t *xTCB;
1671  		if( xTask == NULL )
1672  		{
1673  			xTCB = ( TCB_t * ) pxCurrentTCB;
1674  		}
1675  		else
1676  		{
1677  			xTCB = ( TCB_t * ) xTask;
1678  		}
1679  		taskENTER_CRITICAL();
1680  			xTCB->pxTaskTag = pxHookFunction;
1681  		taskEXIT_CRITICAL();
1682  	}
1683  #endif &bsol;* configUSE_APPLICATION_TASK_TAG */
1684  #if ( configUSE_APPLICATION_TASK_TAG == 1 )
1685  	TaskHookFunction_t xTaskGetApplicationTaskTag( TaskHandle_t xTask )
1686  	{
1687  	TCB_t *xTCB;
1688  	TaskHookFunction_t xReturn;
1689  		if( xTask == NULL )
1690  		{
1691  			xTCB = ( TCB_t * ) pxCurrentTCB;
1692  		}
1693  		else
1694  		{
1695  			xTCB = ( TCB_t * ) xTask;
1696  		}
1697  		taskENTER_CRITICAL();
1698  		{
1699  			xReturn = xTCB->pxTaskTag;
1700  		}
1701  		taskEXIT_CRITICAL();
1702  		return xReturn;
1703  	}
1704  #endif &bsol;* configUSE_APPLICATION_TASK_TAG */
1705  #if ( configUSE_APPLICATION_TASK_TAG == 1 )
1706  	BaseType_t xTaskCallApplicationTaskHook( TaskHandle_t xTask, void *pvParameter )
1707  	{
1708  	TCB_t *xTCB;
1709  	BaseType_t xReturn;
1710  		if( xTask == NULL )
1711  		{
1712  			xTCB = ( TCB_t * ) pxCurrentTCB;
1713  		}
1714  		else
1715  		{
1716  			xTCB = ( TCB_t * ) xTask;
1717  		}
1718  		if( xTCB->pxTaskTag != NULL )
1719  		{
1720  			xReturn = xTCB->pxTaskTag( pvParameter );
1721  		}
1722  		else
1723  		{
1724  			xReturn = pdFAIL;
1725  		}
1726  		return xReturn;
1727  	}
1728  #endif &bsol;* configUSE_APPLICATION_TASK_TAG */
1729  void vTaskSwitchContext( void )
1730  {
1731  	if( uxSchedulerSuspended != ( UBaseType_t ) pdFALSE )
1732  	{
1733  		xYieldPending = pdTRUE;
1734  	}
1735  	else
1736  	{
1737  		xYieldPending = pdFALSE;
1738  		traceTASK_SWITCHED_OUT();
1739  		#if ( configGENERATE_RUN_TIME_STATS == 1 )
1740  		{
1741  				#ifdef portALT_GET_RUN_TIME_COUNTER_VALUE
1742  					portALT_GET_RUN_TIME_COUNTER_VALUE( ulTotalRunTime );
1743  				#else
1744  					ulTotalRunTime = portGET_RUN_TIME_COUNTER_VALUE();
1745  				#endif
1746  				if( ulTotalRunTime > ulTaskSwitchedInTime )
1747  				{
1748  					pxCurrentTCB->ulRunTimeCounter += ( ulTotalRunTime - ulTaskSwitchedInTime );
1749  				}
1750  				else
1751  				{
1752  					mtCOVERAGE_TEST_MARKER();
1753  				}
1754  				ulTaskSwitchedInTime = ulTotalRunTime;
1755  		}
1756  		#endif &bsol;* configGENERATE_RUN_TIME_STATS */
1757  		taskCHECK_FOR_STACK_OVERFLOW();
1758  		taskSELECT_HIGHEST_PRIORITY_TASK();
1759  		traceTASK_SWITCHED_IN();
1760  		#if ( configUSE_NEWLIB_REENTRANT == 1 )
1761  		{
1762  			_impure_ptr = &( pxCurrentTCB->xNewLib_reent );
1763  		}
1764  		#endif &bsol;* configUSE_NEWLIB_REENTRANT */
1765  	}
1766  }
1767  void vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait )
1768  {
1769  	configASSERT( pxEventList );
1770  	vListInsert( pxEventList, &( pxCurrentTCB->xEventListItem ) );
1771  	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
1772  }
1773  void vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait )
1774  {
1775  	configASSERT( pxEventList );
1776  	configASSERT( uxSchedulerSuspended != 0 );
1777  	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
1778  	vListInsertEnd( pxEventList, &( pxCurrentTCB->xEventListItem ) );
1779  	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
1780  }
1781  #if( configUSE_TIMERS == 1 )
1782  	void vTaskPlaceOnEventListRestricted( List_t * const pxEventList, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely )
1783  	{
1784  		configASSERT( pxEventList );
1785  		vListInsertEnd( pxEventList, &( pxCurrentTCB->xEventListItem ) );
1786  		if( xWaitIndefinitely != pdFALSE )
1787  		{
1788  			xTicksToWait = portMAX_DELAY;
1789  		}
1790  		traceTASK_DELAY_UNTIL( ( xTickCount + xTicksToWait ) );
1791  		prvAddCurrentTaskToDelayedList( xTicksToWait, xWaitIndefinitely );
1792  	}
1793  #endif &bsol;* configUSE_TIMERS */
1794  BaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList )
1795  {
1796  TCB_t *pxUnblockedTCB;
1797  BaseType_t xReturn;
1798  	pxUnblockedTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxEventList );
1799  	configASSERT( pxUnblockedTCB );
1800  	( void ) uxListRemove( &( pxUnblockedTCB->xEventListItem ) );
1801  	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
1802  	{
1803  		( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
1804  		prvAddTaskToReadyList( pxUnblockedTCB );
1805  	}
1806  	else
1807  	{
1808  		vListInsertEnd( &( xPendingReadyList ), &( pxUnblockedTCB->xEventListItem ) );
1809  	}
1810  	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
1811  	{
1812  		xReturn = pdTRUE;
1813  		xYieldPending = pdTRUE;
1814  	}
1815  	else
1816  	{
1817  		xReturn = pdFALSE;
1818  	}
1819  	#if( configUSE_TICKLESS_IDLE != 0 )
1820  	{
1821  		prvResetNextTaskUnblockTime();
1822  	}
1823  	#endif
1824  	return xReturn;
1825  }
1826  void vTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue )
1827  {
1828  TCB_t *pxUnblockedTCB;
1829  	configASSERT( uxSchedulerSuspended != pdFALSE );
1830  	listSET_LIST_ITEM_VALUE( pxEventListItem, xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
1831  	pxUnblockedTCB = ( TCB_t * ) listGET_LIST_ITEM_OWNER( pxEventListItem );
1832  	configASSERT( pxUnblockedTCB );
1833  	( void ) uxListRemove( pxEventListItem );
1834  	( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
1835  	prvAddTaskToReadyList( pxUnblockedTCB );
1836  	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
1837  	{
1838  		xYieldPending = pdTRUE;
1839  	}
1840  }
1841  void vTaskSetTimeOutState( TimeOut_t * const pxTimeOut )
1842  {
1843  	configASSERT( pxTimeOut );
1844  	taskENTER_CRITICAL();
1845  	{
1846  		pxTimeOut->xOverflowCount = xNumOfOverflows;
1847  		pxTimeOut->xTimeOnEntering = xTickCount;
1848  	}
1849  	taskEXIT_CRITICAL();
1850  }
1851  void vTaskInternalSetTimeOutState( TimeOut_t * const pxTimeOut )
1852  {
1853  	pxTimeOut->xOverflowCount = xNumOfOverflows;
1854  	pxTimeOut->xTimeOnEntering = xTickCount;
1855  }
1856  BaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut, TickType_t * const pxTicksToWait )
1857  {
1858  BaseType_t xReturn;
1859  	configASSERT( pxTimeOut );
1860  	configASSERT( pxTicksToWait );
1861  	taskENTER_CRITICAL();
1862  	{
1863  		const TickType_t xConstTickCount = xTickCount;
1864  		const TickType_t xElapsedTime = xConstTickCount - pxTimeOut->xTimeOnEntering;
1865  		#if( INCLUDE_xTaskAbortDelay == 1 )
1866  			if( pxCurrentTCB->ucDelayAborted != pdFALSE )
1867  			{
1868  				pxCurrentTCB->ucDelayAborted = pdFALSE;
1869  				xReturn = pdTRUE;
1870  			}
1871  			else
1872  		#endif
1873  		#if ( INCLUDE_vTaskSuspend == 1 )
1874  			if( *pxTicksToWait == portMAX_DELAY )
1875  			{
1876  				xReturn = pdFALSE;
1877  			}
1878  			else
1879  		#endif
1880  		if( ( xNumOfOverflows != pxTimeOut->xOverflowCount ) && ( xConstTickCount >= pxTimeOut->xTimeOnEntering ) ) &bsol;*lint !e525 Indentation preferred as is to make code within pre-processor directives clearer. */
1881  		{
1882  			xReturn = pdTRUE;
1883  		}
1884  		else if( xElapsedTime < *pxTicksToWait ) &bsol;*lint !e961 Explicit casting is only redundant with some compilers, whereas others require it to prevent integer conversion errors. */
1885  		{
1886  			*pxTicksToWait -= xElapsedTime;
1887  			vTaskInternalSetTimeOutState( pxTimeOut );
1888  			xReturn = pdFALSE;
1889  		}
1890  		else
1891  		{
1892  			*pxTicksToWait = 0;
1893  			xReturn = pdTRUE;
1894  		}
1895  	}
1896  	taskEXIT_CRITICAL();
1897  	return xReturn;
1898  }
1899  void vTaskMissedYield( void )
1900  {
1901  	xYieldPending = pdTRUE;
1902  }
1903  #if ( configUSE_TRACE_FACILITY == 1 )
1904  	UBaseType_t uxTaskGetTaskNumber( TaskHandle_t xTask )
1905  	{
1906  	UBaseType_t uxReturn;
1907  	TCB_t *pxTCB;
1908  		if( xTask != NULL )
1909  		{
1910  			pxTCB = ( TCB_t * ) xTask;
1911  			uxReturn = pxTCB->uxTaskNumber;
1912  		}
1913  		else
1914  		{
1915  			uxReturn = 0U;
1916  		}
1917  		return uxReturn;
1918  	}
1919  #endif &bsol;* configUSE_TRACE_FACILITY */
1920  #if ( configUSE_TRACE_FACILITY == 1 )
1921  	void vTaskSetTaskNumber( TaskHandle_t xTask, const UBaseType_t uxHandle )
1922  	{
1923  	TCB_t *pxTCB;
1924  		if( xTask != NULL )
1925  		{
1926  			pxTCB = ( TCB_t * ) xTask;
1927  			pxTCB->uxTaskNumber = uxHandle;
1928  		}
1929  	}
1930  #endif &bsol;* configUSE_TRACE_FACILITY */
1931  static portTASK_FUNCTION( prvIdleTask, pvParameters )
1932  {
1933  	( void ) pvParameters;
1934  	portTASK_CALLS_SECURE_FUNCTIONS();
1935  	for( ;; )
1936  	{
1937  		prvCheckTasksWaitingTermination();
1938  		#if ( configUSE_PREEMPTION == 0 )
1939  		{
1940  			taskYIELD();
1941  		}
1942  		#endif &bsol;* configUSE_PREEMPTION */
1943  		#if ( ( configUSE_PREEMPTION == 1 ) && ( configIDLE_SHOULD_YIELD == 1 ) )
1944  		{
1945  			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
1946  			{
1947  				taskYIELD();
1948  			}
1949  			else
1950  			{
1951  				mtCOVERAGE_TEST_MARKER();
1952  			}
1953  		}
1954  		#endif &bsol;* ( ( configUSE_PREEMPTION == 1 ) && ( configIDLE_SHOULD_YIELD == 1 ) ) */
1955  		#if ( configUSE_IDLE_HOOK == 1 )
1956  		{
1957  			extern void vApplicationIdleHook( void );
1958  			vApplicationIdleHook();
1959  		}
1960  		#endif &bsol;* configUSE_IDLE_HOOK */
1961  		#if ( configUSE_TICKLESS_IDLE != 0 )
1962  		{
1963  		TickType_t xExpectedIdleTime;
1964  			xExpectedIdleTime = prvGetExpectedIdleTime();
1965  			if( xExpectedIdleTime >= configEXPECTED_IDLE_TIME_BEFORE_SLEEP )
1966  			{
1967  				vTaskSuspendAll();
1968  				{
1969  					configASSERT( xNextTaskUnblockTime >= xTickCount );
1970  					xExpectedIdleTime = prvGetExpectedIdleTime();
1971  					configPRE_SUPPRESS_TICKS_AND_SLEEP_PROCESSING( xExpectedIdleTime );
1972  					if( xExpectedIdleTime >= configEXPECTED_IDLE_TIME_BEFORE_SLEEP )
1973  					{
1974  						traceLOW_POWER_IDLE_BEGIN();
1975  						portSUPPRESS_TICKS_AND_SLEEP( xExpectedIdleTime );
1976  						traceLOW_POWER_IDLE_END();
1977  					}
1978  					else
1979  					{
1980  						mtCOVERAGE_TEST_MARKER();
1981  					}
1982  				}
1983  				( void ) xTaskResumeAll();
1984  			}
1985  			else
1986  			{
1987  				mtCOVERAGE_TEST_MARKER();
1988  			}
1989  		}
1990  		#endif &bsol;* configUSE_TICKLESS_IDLE */
1991  	}
1992  }
1993  #if( configUSE_TICKLESS_IDLE != 0 )
1994  	eSleepModeStatus eTaskConfirmSleepModeStatus( void )
1995  	{
1996  	const UBaseType_t uxNonApplicationTasks = 1;
1997  	eSleepModeStatus eReturn = eStandardSleep;
1998  		if( listCURRENT_LIST_LENGTH( &xPendingReadyList ) != 0 )
1999  		{
2000  			eReturn = eAbortSleep;
2001  		}
2002  		else if( xYieldPending != pdFALSE )
2003  		{
2004  			eReturn = eAbortSleep;
2005  		}
2006  		else
2007  		{
2008  			if( listCURRENT_LIST_LENGTH( &xSuspendedTaskList ) == ( uxCurrentNumberOfTasks - uxNonApplicationTasks ) )
2009  			{
2010  				eReturn = eNoTasksWaitingTimeout;
2011  			}
2012  			else
2013  			{
2014  				mtCOVERAGE_TEST_MARKER();
2015  			}
2016  		}
2017  		return eReturn;
2018  	}
2019  #endif &bsol;* configUSE_TICKLESS_IDLE */
2020  #if ( configNUM_THREAD_LOCAL_STORAGE_POINTERS != 0 )
2021  	void vTaskSetThreadLocalStoragePointer( TaskHandle_t xTaskToSet, BaseType_t xIndex, void *pvValue )
2022  	{
2023  	TCB_t *pxTCB;
2024  		if( xIndex < configNUM_THREAD_LOCAL_STORAGE_POINTERS )
2025  		{
2026  			pxTCB = prvGetTCBFromHandle( xTaskToSet );
2027  			pxTCB->pvThreadLocalStoragePointers[ xIndex ] = pvValue;
2028  		}
2029  	}
2030  #endif &bsol;* configNUM_THREAD_LOCAL_STORAGE_POINTERS */
2031  #if ( configNUM_THREAD_LOCAL_STORAGE_POINTERS != 0 )
2032  	void *pvTaskGetThreadLocalStoragePointer( TaskHandle_t xTaskToQuery, BaseType_t xIndex )
2033  	{
2034  	void *pvReturn = NULL;
2035  	TCB_t *pxTCB;
2036  		if( xIndex < configNUM_THREAD_LOCAL_STORAGE_POINTERS )
2037  		{
2038  			pxTCB = prvGetTCBFromHandle( xTaskToQuery );
2039  			pvReturn = pxTCB->pvThreadLocalStoragePointers[ xIndex ];
2040  		}
2041  		else
2042  		{
2043  			pvReturn = NULL;
2044  		}
2045  		return pvReturn;
2046  	}
2047  #endif &bsol;* configNUM_THREAD_LOCAL_STORAGE_POINTERS */
2048  #if ( portUSING_MPU_WRAPPERS == 1 )
2049  	void vTaskAllocateMPURegions( TaskHandle_t xTaskToModify, const MemoryRegion_t * const xRegions )
2050  	{
2051  	TCB_t *pxTCB;
2052  		pxTCB = prvGetTCBFromHandle( xTaskToModify );
2053  		vPortStoreTaskMPUSettings( &( pxTCB->xMPUSettings ), xRegions, NULL, 0 );
2054  	}
2055  #endif &bsol;* portUSING_MPU_WRAPPERS */
2056  static void prvInitialiseTaskLists( void )
2057  {
2058  UBaseType_t uxPriority;
2059  	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
2060  	{
2061  		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
2062  	}
2063  	vListInitialise( &xDelayedTaskList1 );
2064  	vListInitialise( &xDelayedTaskList2 );
2065  	vListInitialise( &xPendingReadyList );
2066  	#if ( INCLUDE_vTaskDelete == 1 )
2067  	{
2068  		vListInitialise( &xTasksWaitingTermination );
2069  	}
2070  	#endif &bsol;* INCLUDE_vTaskDelete */
2071  	#if ( INCLUDE_vTaskSuspend == 1 )
2072  	{
2073  		vListInitialise( &xSuspendedTaskList );
2074  	}
2075  	#endif &bsol;* INCLUDE_vTaskSuspend */
2076  	pxDelayedTaskList = &xDelayedTaskList1;
2077  	pxOverflowDelayedTaskList = &xDelayedTaskList2;
2078  }
2079  static void prvCheckTasksWaitingTermination( void )
2080  {
2081  	#if ( INCLUDE_vTaskDelete == 1 )
2082  	{
2083  		TCB_t *pxTCB;
2084  		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
2085  		{
2086  			taskENTER_CRITICAL();
2087  			{
2088  				pxTCB = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( ( &xTasksWaitingTermination ) );
2089  				( void ) uxListRemove( &( pxTCB->xStateListItem ) );
2090  				--uxCurrentNumberOfTasks;
2091  				--uxDeletedTasksWaitingCleanUp;
2092  			}
2093  			taskEXIT_CRITICAL();
2094  			prvDeleteTCB( pxTCB );
2095  		}
2096  	}
2097  	#endif &bsol;* INCLUDE_vTaskDelete */
2098  }
2099  #if( configUSE_TRACE_FACILITY == 1 )
2100  	void vTaskGetInfo( TaskHandle_t xTask, TaskStatus_t *pxTaskStatus, BaseType_t xGetFreeStackSpace, eTaskState eState )
2101  	{
2102  	TCB_t *pxTCB;
2103  		pxTCB = prvGetTCBFromHandle( xTask );
2104  		pxTaskStatus->xHandle = ( TaskHandle_t ) pxTCB;
2105  		pxTaskStatus->pcTaskName = ( const char * ) &( pxTCB->pcTaskName [ 0 ] );
2106  		pxTaskStatus->uxCurrentPriority = pxTCB->uxPriority;
2107  		pxTaskStatus->pxStackBase = pxTCB->pxStack;
2108  		pxTaskStatus->xTaskNumber = pxTCB->uxTCBNumber;
2109  		#if ( configUSE_MUTEXES == 1 )
2110  		{
2111  			pxTaskStatus->uxBasePriority = pxTCB->uxBasePriority;
2112  		}
2113  		#else
2114  		{
2115  			pxTaskStatus->uxBasePriority = 0;
2116  		}
2117  		#endif
2118  		#if ( configGENERATE_RUN_TIME_STATS == 1 )
2119  		{
2120  			pxTaskStatus->ulRunTimeCounter = pxTCB->ulRunTimeCounter;
2121  		}
2122  		#else
2123  		{
2124  			pxTaskStatus->ulRunTimeCounter = 0;
2125  		}
2126  		#endif
2127  		if( eState != eInvalid )
2128  		{
2129  			if( pxTCB == pxCurrentTCB )
2130  			{
2131  				pxTaskStatus->eCurrentState = eRunning;
2132  			}
2133  			else
2134  			{
2135  				pxTaskStatus->eCurrentState = eState;
2136  				#if ( INCLUDE_vTaskSuspend == 1 )
2137  				{
2138  					if( eState == eSuspended )
2139  					{
2140  						vTaskSuspendAll();
2141  						{
2142  							if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
2143  							{
2144  								pxTaskStatus->eCurrentState = eBlocked;
2145  							}
2146  						}
2147  						( void ) xTaskResumeAll();
2148  					}
2149  				}
2150  				#endif &bsol;* INCLUDE_vTaskSuspend */
2151  			}
2152  		}
2153  		else
2154  		{
2155  			pxTaskStatus->eCurrentState = eTaskGetState( pxTCB );
2156  		}
2157  		if( xGetFreeStackSpace != pdFALSE )
2158  		{
2159  			#if ( portSTACK_GROWTH > 0 )
2160  			{
2161  				pxTaskStatus->usStackHighWaterMark = prvTaskCheckFreeStackSpace( ( uint8_t * ) pxTCB->pxEndOfStack );
2162  			}
2163  			#else
2164  			{
2165  				pxTaskStatus->usStackHighWaterMark = prvTaskCheckFreeStackSpace( ( uint8_t * ) pxTCB->pxStack );
2166  			}
2167  			#endif
2168  		}
2169  		else
2170  		{
2171  			pxTaskStatus->usStackHighWaterMark = 0;
2172  		}
2173  	}
2174  #endif &bsol;* configUSE_TRACE_FACILITY */
2175  #if ( configUSE_TRACE_FACILITY == 1 )
2176  	static UBaseType_t prvListTasksWithinSingleList( TaskStatus_t *pxTaskStatusArray, List_t *pxList, eTaskState eState )
2177  	{
2178  	configLIST_VOLATILE TCB_t *pxNextTCB, *pxFirstTCB;
2179  	UBaseType_t uxTask = 0;
2180  		if( listCURRENT_LIST_LENGTH( pxList ) > ( UBaseType_t ) 0 )
2181  		{
2182  			listGET_OWNER_OF_NEXT_ENTRY( pxFirstTCB, pxList );
2183  			do
2184  			{
2185  				listGET_OWNER_OF_NEXT_ENTRY( pxNextTCB, pxList );
2186  				vTaskGetInfo( ( TaskHandle_t ) pxNextTCB, &( pxTaskStatusArray[ uxTask ] ), pdTRUE, eState );
2187  				uxTask++;
2188  			} while( pxNextTCB != pxFirstTCB );
2189  		}
2190  		else
2191  		{
2192  			mtCOVERAGE_TEST_MARKER();
2193  		}
2194  		return uxTask;
2195  	}
2196  #endif &bsol;* configUSE_TRACE_FACILITY */
2197  #if ( ( configUSE_TRACE_FACILITY == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark == 1 ) )
2198  	static uint16_t prvTaskCheckFreeStackSpace( const uint8_t * pucStackByte )
2199  	{
2200  	uint32_t ulCount = 0U;
2201  		while( *pucStackByte == ( uint8_t ) tskSTACK_FILL_BYTE )
2202  		{
2203  			pucStackByte -= portSTACK_GROWTH;
2204  			ulCount++;
2205  		}
2206  		ulCount /= ( uint32_t ) sizeof( StackType_t ); &bsol;*lint !e961 Casting is not redundant on smaller architectures. */
2207  		return ( uint16_t ) ulCount;
2208  	}
2209  #endif &bsol;* ( ( configUSE_TRACE_FACILITY == 1 ) || ( INCLUDE_uxTaskGetStackHighWaterMark == 1 ) ) */
2210  #if ( INCLUDE_uxTaskGetStackHighWaterMark == 1 )
2211  	UBaseType_t uxTaskGetStackHighWaterMark( TaskHandle_t xTask )
2212  	{
2213  	TCB_t *pxTCB;
2214  	uint8_t *pucEndOfStack;
2215  	UBaseType_t uxReturn;
2216  		pxTCB = prvGetTCBFromHandle( xTask );
2217  		#if portSTACK_GROWTH < 0
2218  		{
2219  			pucEndOfStack = ( uint8_t * ) pxTCB->pxStack;
2220  		}
2221  		#else
2222  		{
2223  			pucEndOfStack = ( uint8_t * ) pxTCB->pxEndOfStack;
2224  		}
2225  		#endif
2226  		uxReturn = ( UBaseType_t ) prvTaskCheckFreeStackSpace( pucEndOfStack );
2227  		return uxReturn;
2228  	}
2229  #endif &bsol;* INCLUDE_uxTaskGetStackHighWaterMark */
2230  #if (INCLUDE_pxTaskGetStackStart == 1)
2231  	uint8_t* pxTaskGetStackStart( TaskHandle_t xTask)
2232  	{
2233  	    TCB_t *pxTCB;
2234  	    UBaseType_t uxReturn;
2235          (void)uxReturn;
2236  		pxTCB = prvGetTCBFromHandle( xTask );
2237  		return ( uint8_t * ) pxTCB->pxStack;
2238  	}
2239  #endif &bsol;* INCLUDE_pxTaskGetStackStart */
2240  #if ( INCLUDE_vTaskDelete == 1 )
2241  	static void prvDeleteTCB( TCB_t *pxTCB )
2242  	{
2243  		portCLEAN_UP_TCB( pxTCB );
2244  		#if ( configUSE_NEWLIB_REENTRANT == 1 )
2245  		{
2246  			_reclaim_reent( &( pxTCB->xNewLib_reent ) );
2247  		}
2248  		#endif &bsol;* configUSE_NEWLIB_REENTRANT */
2249  		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) && ( portUSING_MPU_WRAPPERS == 0 ) )
2250  		{
2251  			vPortFree( pxTCB->pxStack );
2252  			vPortFree( pxTCB );
2253  		}
2254  		#elif( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 ) &bsol;*lint !e731 Macro has been consolidated for readability reasons. */
2255  		{
2256  			if( pxTCB->ucStaticallyAllocated == tskDYNAMICALLY_ALLOCATED_STACK_AND_TCB )
2257  			{
2258  				vPortFree( pxTCB->pxStack );
2259  				vPortFree( pxTCB );
2260  			}
2261  			else if( pxTCB->ucStaticallyAllocated == tskSTATICALLY_ALLOCATED_STACK_ONLY )
2262  			{
2263  				vPortFree( pxTCB );
2264  			}
2265  			else
2266  			{
2267  				configASSERT( pxTCB->ucStaticallyAllocated == tskSTATICALLY_ALLOCATED_STACK_AND_TCB	);
2268  				mtCOVERAGE_TEST_MARKER();
2269  			}
2270  		}
2271  		#endif &bsol;* configSUPPORT_DYNAMIC_ALLOCATION */
2272  	}
2273  #endif &bsol;* INCLUDE_vTaskDelete */
2274  static void prvResetNextTaskUnblockTime( void )
2275  {
2276  TCB_t *pxTCB;
2277  	if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
2278  	{
2279  		xNextTaskUnblockTime = portMAX_DELAY;
2280  	}
2281  	else
2282  	{
2283  		( pxTCB ) = ( TCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList );
2284  		xNextTaskUnblockTime = listGET_LIST_ITEM_VALUE( &( ( pxTCB )->xStateListItem ) );
2285  	}
2286  }
2287  #if ( ( INCLUDE_xTaskGetCurrentTaskHandle == 1 ) || ( configUSE_MUTEXES == 1 ) )
2288  	TaskHandle_t xTaskGetCurrentTaskHandle( void )
2289  	{
2290  	TaskHandle_t xReturn;
2291  		xReturn = pxCurrentTCB;
2292  		return xReturn;
2293  	}
2294  #endif &bsol;* ( ( INCLUDE_xTaskGetCurrentTaskHandle == 1 ) || ( configUSE_MUTEXES == 1 ) ) */
2295  #if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
2296  	BaseType_t xTaskGetSchedulerState( void )
2297  	{
2298  	BaseType_t xReturn;
2299  		if( xSchedulerRunning == pdFALSE )
2300  		{
2301  			xReturn = taskSCHEDULER_NOT_STARTED;
2302  		}
2303  		else
2304  		{
2305  			if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
2306  			{
2307  				xReturn = taskSCHEDULER_RUNNING;
2308  			}
2309  			else
2310  			{
2311  				xReturn = taskSCHEDULER_SUSPENDED;
2312  			}
2313  		}
2314  		return xReturn;
2315  	}
2316  #endif &bsol;* ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) ) */
2317  #if ( configUSE_MUTEXES == 1 )
2318  	BaseType_t xTaskPriorityInherit( TaskHandle_t const pxMutexHolder )
2319  	{
2320  	TCB_t * const pxMutexHolderTCB = ( TCB_t * ) pxMutexHolder;
2321  	BaseType_t xReturn = pdFALSE;
2322  		if( pxMutexHolder != NULL )
2323  		{
2324  			if( pxMutexHolderTCB->uxPriority < pxCurrentTCB->uxPriority )
2325  			{
2326  				if( ( listGET_LIST_ITEM_VALUE( &( pxMutexHolderTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == 0UL )
2327  				{
2328  					listSET_LIST_ITEM_VALUE( &( pxMutexHolderTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
2329  				}
2330  				else
2331  				{
2332  					mtCOVERAGE_TEST_MARKER();
2333  				}
2334  				if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ pxMutexHolderTCB->uxPriority ] ), &( pxMutexHolderTCB->xStateListItem ) ) != pdFALSE )
2335  				{
2336  					if( uxListRemove( &( pxMutexHolderTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
2337  					{
2338  						taskRESET_READY_PRIORITY( pxMutexHolderTCB->uxPriority );
2339  					}
2340  					else
2341  					{
2342  						mtCOVERAGE_TEST_MARKER();
2343  					}
2344  					pxMutexHolderTCB->uxPriority = pxCurrentTCB->uxPriority;
2345  					prvReaddTaskToReadyList( pxMutexHolderTCB );
2346  				}
2347  				else
2348  				{
2349  					pxMutexHolderTCB->uxPriority = pxCurrentTCB->uxPriority;
2350  				}
2351  				traceTASK_PRIORITY_INHERIT( pxMutexHolderTCB, pxCurrentTCB->uxPriority );
2352  				xReturn = pdTRUE;
2353  			}
2354  			else
2355  			{
2356  				if( pxMutexHolderTCB->uxBasePriority < pxCurrentTCB->uxPriority )
2357  				{
2358  					xReturn = pdTRUE;
2359  				}
2360  				else
2361  				{
2362  					mtCOVERAGE_TEST_MARKER();
2363  				}
2364  			}
2365  		}
2366  		else
2367  		{
2368  			mtCOVERAGE_TEST_MARKER();
2369  		}
2370  		return xReturn;
2371  	}
2372  #endif &bsol;* configUSE_MUTEXES */
2373  #if ( configUSE_MUTEXES == 1 )
2374  	BaseType_t xTaskPriorityDisinherit( TaskHandle_t const pxMutexHolder )
2375  	{
2376  	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;
2377  	BaseType_t xReturn = pdFALSE;
2378  		if( pxMutexHolder != NULL )
2379  		{
2380  			configASSERT( pxTCB == pxCurrentTCB );
2381  			configASSERT( pxTCB->uxMutexesHeld );
2382  			( pxTCB->uxMutexesHeld )--;
2383  			if( pxTCB->uxPriority != pxTCB->uxBasePriority )
2384  			{
2385  				if( pxTCB->uxMutexesHeld == ( UBaseType_t ) 0 )
2386  				{
2387  					if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
2388  					{
2389  						taskRESET_READY_PRIORITY( pxTCB->uxPriority );
2390  					}
2391  					else
2392  					{
2393  						mtCOVERAGE_TEST_MARKER();
2394  					}
2395  					traceTASK_PRIORITY_DISINHERIT( pxTCB, pxTCB->uxBasePriority );
2396  					pxTCB->uxPriority = pxTCB->uxBasePriority;
2397  					listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxTCB->uxPriority ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
2398  					prvReaddTaskToReadyList( pxTCB );
2399  					xReturn = pdTRUE;
2400  				}
2401  				else
2402  				{
2403  					mtCOVERAGE_TEST_MARKER();
2404  				}
2405  			}
2406  			else
2407  			{
2408  				mtCOVERAGE_TEST_MARKER();
2409  			}
2410  		}
2411  		else
2412  		{
2413  			mtCOVERAGE_TEST_MARKER();
2414  		}
2415  		return xReturn;
2416  	}
2417  #endif &bsol;* configUSE_MUTEXES */
2418  #if ( configUSE_MUTEXES == 1 )
2419  	void vTaskPriorityDisinheritAfterTimeout( TaskHandle_t const pxMutexHolder, UBaseType_t uxHighestPriorityWaitingTask )
2420  	{
2421  	TCB_t * const pxTCB = ( TCB_t * ) pxMutexHolder;
2422  	UBaseType_t uxPriorityUsedOnEntry, uxPriorityToUse;
2423  	const UBaseType_t uxOnlyOneMutexHeld = ( UBaseType_t ) 1;
2424  		if( pxMutexHolder != NULL )
2425  		{
2426  			configASSERT( pxTCB->uxMutexesHeld );
2427  			if( pxTCB->uxBasePriority < uxHighestPriorityWaitingTask )
2428  			{
2429  				uxPriorityToUse = uxHighestPriorityWaitingTask;
2430  			}
2431  			else
2432  			{
2433  				uxPriorityToUse = pxTCB->uxBasePriority;
2434  			}
2435  			if( pxTCB->uxPriority != uxPriorityToUse )
2436  			{
2437  				if( pxTCB->uxMutexesHeld == uxOnlyOneMutexHeld )
2438  				{
2439  					configASSERT( pxTCB != pxCurrentTCB );
2440  					traceTASK_PRIORITY_DISINHERIT( pxTCB, pxTCB->uxBasePriority );
2441  					uxPriorityUsedOnEntry = pxTCB->uxPriority;
2442  					pxTCB->uxPriority = uxPriorityToUse;
2443  					if( ( listGET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ) ) & taskEVENT_LIST_ITEM_VALUE_IN_USE ) == 0UL )
2444  					{
2445  						listSET_LIST_ITEM_VALUE( &( pxTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriorityToUse ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
2446  					}
2447  					else
2448  					{
2449  						mtCOVERAGE_TEST_MARKER();
2450  					}
2451  					if( listIS_CONTAINED_WITHIN( &( pxReadyTasksLists[ uxPriorityUsedOnEntry ] ), &( pxTCB->xStateListItem ) ) != pdFALSE )
2452  					{
2453  						if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
2454  						{
2455  							taskRESET_READY_PRIORITY( pxTCB->uxPriority );
2456  						}
2457  						else
2458  						{
2459  							mtCOVERAGE_TEST_MARKER();
2460  						}
2461  						prvAddTaskToReadyList( pxTCB );
2462  					}
2463  					else
2464  					{
2465  						mtCOVERAGE_TEST_MARKER();
2466  					}
2467  				}
2468  				else
2469  				{
2470  					mtCOVERAGE_TEST_MARKER();
2471  				}
2472  			}
2473  			else
2474  			{
2475  				mtCOVERAGE_TEST_MARKER();
2476  			}
2477  		}
2478  		else
2479  		{
2480  			mtCOVERAGE_TEST_MARKER();
2481  		}
2482  	}
2483  #endif &bsol;* configUSE_MUTEXES */
2484  #if ( portCRITICAL_NESTING_IN_TCB == 1 )
2485  	void vTaskEnterCritical( void )
2486  	{
2487  		portDISABLE_INTERRUPTS();
2488  		if( xSchedulerRunning != pdFALSE )
2489  		{
2490  			( pxCurrentTCB->uxCriticalNesting )++;
2491  			if( pxCurrentTCB->uxCriticalNesting == 1 )
2492  			{
2493  				portASSERT_IF_IN_ISR();
2494  			}
2495  		}
2496  		else
2497  		{
2498  			mtCOVERAGE_TEST_MARKER();
2499  		}
2500  	}
2501  #endif &bsol;* portCRITICAL_NESTING_IN_TCB */
2502  #if ( portCRITICAL_NESTING_IN_TCB == 1 )
2503  	void vTaskExitCritical( void )
2504  	{
2505  		if( xSchedulerRunning != pdFALSE )
2506  		{
2507  			if( pxCurrentTCB->uxCriticalNesting > 0U )
2508  			{
2509  				( pxCurrentTCB->uxCriticalNesting )--;
2510  				if( pxCurrentTCB->uxCriticalNesting == 0U )
2511  				{
2512  					portENABLE_INTERRUPTS();
2513  				}
2514  				else
2515  				{
2516  					mtCOVERAGE_TEST_MARKER();
2517  				}
2518  			}
2519  			else
2520  			{
2521  				mtCOVERAGE_TEST_MARKER();
2522  			}
2523  		}
2524  		else
2525  		{
2526  			mtCOVERAGE_TEST_MARKER();
2527  		}
2528  	}
2529  #endif &bsol;* portCRITICAL_NESTING_IN_TCB */
2530  #if ( ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) )
2531  	static char *prvWriteNameToBuffer( char *pcBuffer, const char *pcTaskName )
2532  	{
2533  	size_t x;
2534  		strcpy( pcBuffer, pcTaskName );
2535  		for( x = strlen( pcBuffer ); x < ( size_t ) ( configMAX_TASK_NAME_LEN - 1 ); x++ )
2536  		{
2537  			pcBuffer[ x ] = ' ';
2538  		}
2539  		pcBuffer[ x ] = 0x00;
2540  		return &( pcBuffer[ x ] );
2541  	}
2542  #endif &bsol;* ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) */
2543  #if ( ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
2544  	void vTaskList( char * pcWriteBuffer )
2545  	{
2546  	TaskStatus_t *pxTaskStatusArray;
2547  	volatile UBaseType_t uxArraySize, x;
2548  	char cStatus;
2549  		*pcWriteBuffer = 0x00;
2550  		uxArraySize = uxCurrentNumberOfTasks;
2551  		pxTaskStatusArray = pvPortMalloc( uxCurrentNumberOfTasks * sizeof( TaskStatus_t ) );
2552  		if( pxTaskStatusArray != NULL )
2553  		{
2554  			uxArraySize = uxTaskGetSystemState( pxTaskStatusArray, uxArraySize, NULL );
2555  			for( x = 0; x < uxArraySize; x++ )
2556  			{
2557  				switch( pxTaskStatusArray[ x ].eCurrentState )
2558  				{
2559  					case eRunning:		cStatus = tskRUNNING_CHAR;
2560  										break;
2561  					case eReady:		cStatus = tskREADY_CHAR;
2562  										break;
2563  					case eBlocked:		cStatus = tskBLOCKED_CHAR;
2564  										break;
2565  					case eSuspended:	cStatus = tskSUSPENDED_CHAR;
2566  										break;
2567  					case eDeleted:		cStatus = tskDELETED_CHAR;
2568  										break;
2569  					default:			&bsol;* Should not get here, but it is included
2570  										to prevent static checking errors. */
2571  										cStatus = 0x00;
2572  										break;
2573  				}
2574  				pcWriteBuffer = prvWriteNameToBuffer( pcWriteBuffer, pxTaskStatusArray[ x ].pcTaskName );
2575  				sprintf( pcWriteBuffer, "\t%c\t%u\t%u\t%u\r\n", cStatus, ( unsigned int ) pxTaskStatusArray[ x ].uxCurrentPriority, ( unsigned int ) pxTaskStatusArray[ x ].usStackHighWaterMark, ( unsigned int ) pxTaskStatusArray[ x ].xTaskNumber );
2576  				pcWriteBuffer += strlen( pcWriteBuffer );
2577  			}
2578  			vPortFree( pxTaskStatusArray );
2579  		}
2580  		else
2581  		{
2582  			mtCOVERAGE_TEST_MARKER();
2583  		}
2584  	}
2585  #endif &bsol;* ( ( configUSE_TRACE_FACILITY == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
2586  #if ( ( configGENERATE_RUN_TIME_STATS == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
2587  	void vTaskGetRunTimeStats( char *pcWriteBuffer )
2588  	{
2589  	TaskStatus_t *pxTaskStatusArray;
2590  	volatile UBaseType_t uxArraySize, x;
2591  	uint32_t ulTotalTime, ulStatsAsPercentage;
2592  		#if( configUSE_TRACE_FACILITY != 1 )
2593  		{
2594  			#error configUSE_TRACE_FACILITY must also be set to 1 in FreeRTOSConfig.h to use vTaskGetRunTimeStats().
2595  		}
2596  		#endif
2597  		*pcWriteBuffer = 0x00;
2598  		uxArraySize = uxCurrentNumberOfTasks;
2599  		pxTaskStatusArray = pvPortMalloc( uxCurrentNumberOfTasks * sizeof( TaskStatus_t ) );
2600  		if( pxTaskStatusArray != NULL )
2601  		{
2602  			uxArraySize = uxTaskGetSystemState( pxTaskStatusArray, uxArraySize, &ulTotalTime );
2603  			ulTotalTime /= 100UL;
2604  			if( ulTotalTime > 0 )
2605  			{
2606  				for( x = 0; x < uxArraySize; x++ )
2607  				{
2608  					ulStatsAsPercentage = pxTaskStatusArray[ x ].ulRunTimeCounter / ulTotalTime;
2609  					pcWriteBuffer = prvWriteNameToBuffer( pcWriteBuffer, pxTaskStatusArray[ x ].pcTaskName );
2610  					if( ulStatsAsPercentage > 0UL )
2611  					{
2612  						#ifdef portLU_PRINTF_SPECIFIER_REQUIRED
2613  						{
2614  							sprintf( pcWriteBuffer, "\t%lu\t\t%lu%%\r\n", pxTaskStatusArray[ x ].ulRunTimeCounter, ulStatsAsPercentage );
2615  						}
2616  						#else
2617  						{
2618  							sprintf( pcWriteBuffer, "\t%u\t\t%u%%\r\n", ( unsigned int ) pxTaskStatusArray[ x ].ulRunTimeCounter, ( unsigned int ) ulStatsAsPercentage );
2619  						}
2620  						#endif
2621  					}
2622  					else
2623  					{
2624  						#ifdef portLU_PRINTF_SPECIFIER_REQUIRED
2625  						{
2626  							sprintf( pcWriteBuffer, "\t%lu\t\t<1%%\r\n", pxTaskStatusArray[ x ].ulRunTimeCounter );
2627  						}
2628  						#else
2629  						{
2630  							sprintf( pcWriteBuffer, "\t%u\t\t<1%%\r\n", ( unsigned int ) pxTaskStatusArray[ x ].ulRunTimeCounter );
2631  						}
2632  						#endif
2633  					}
2634  					pcWriteBuffer += strlen( pcWriteBuffer );
2635  				}
2636  			}
2637  			else
2638  			{
2639  				mtCOVERAGE_TEST_MARKER();
2640  			}
2641  			vPortFree( pxTaskStatusArray );
2642  		}
2643  		else
2644  		{
2645  			mtCOVERAGE_TEST_MARKER();
2646  		}
2647  	}
2648  #endif &bsol;* ( ( configGENERATE_RUN_TIME_STATS == 1 ) && ( configUSE_STATS_FORMATTING_FUNCTIONS > 0 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) ) */
2649  TickType_t uxTaskResetEventItemValue( void )
2650  {
2651  TickType_t uxReturn;
2652  	uxReturn = listGET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ) );
2653  	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ) ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
2654  	return uxReturn;
2655  }
2656  #if ( configUSE_MUTEXES == 1 )
2657  	void *pvTaskIncrementMutexHeldCount( void )
2658  	{
2659  		if( pxCurrentTCB != NULL )
2660  		{
2661  			( pxCurrentTCB->uxMutexesHeld )++;
2662  		}
2663  		return pxCurrentTCB;
2664  	}
2665  #endif &bsol;* configUSE_MUTEXES */
2666  #if( configUSE_TASK_NOTIFICATIONS == 1 )
2667  	uint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait )
2668  	{
2669  	uint32_t ulReturn;
2670  		taskENTER_CRITICAL();
2671  		{
2672  			if( pxCurrentTCB->ulNotifiedValue == 0UL )
2673  			{
2674  				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
2675  				if( xTicksToWait > ( TickType_t ) 0 )
2676  				{
2677  					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
2678  					traceTASK_NOTIFY_TAKE_BLOCK();
2679  					portYIELD_WITHIN_API();
2680  				}
2681  				else
2682  				{
2683  					mtCOVERAGE_TEST_MARKER();
2684  				}
2685  			}
2686  			else
2687  			{
2688  				mtCOVERAGE_TEST_MARKER();
2689  			}
2690  		}
2691  		taskEXIT_CRITICAL();
2692  		taskENTER_CRITICAL();
2693  		{
2694  			traceTASK_NOTIFY_TAKE();
2695  			ulReturn = pxCurrentTCB->ulNotifiedValue;
2696  			if( ulReturn != 0UL )
2697  			{
2698  				if( xClearCountOnExit != pdFALSE )
2699  				{
2700  					pxCurrentTCB->ulNotifiedValue = 0UL;
2701  				}
2702  				else
2703  				{
2704  					pxCurrentTCB->ulNotifiedValue = ulReturn - ( uint32_t ) 1;
2705  				}
2706  			}
2707  			else
2708  			{
2709  				mtCOVERAGE_TEST_MARKER();
2710  			}
2711  			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
2712  		}
2713  		taskEXIT_CRITICAL();
2714  		return ulReturn;
2715  	}
2716  #endif &bsol;* configUSE_TASK_NOTIFICATIONS */
2717  #if( configUSE_TASK_NOTIFICATIONS == 1 )
2718  	BaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait )
2719  	{
2720  	BaseType_t xReturn;
2721  		taskENTER_CRITICAL();
2722  		{
2723  			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
2724  			{
2725  				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnEntry;
2726  				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
2727  				if( xTicksToWait > ( TickType_t ) 0 )
2728  				{
2729  					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
2730  					traceTASK_NOTIFY_WAIT_BLOCK();
2731  					portYIELD_WITHIN_API();
2732  				}
2733  				else
2734  				{
2735  					mtCOVERAGE_TEST_MARKER();
2736  				}
2737  			}
2738  			else
2739  			{
2740  				mtCOVERAGE_TEST_MARKER();
2741  			}
2742  		}
2743  		taskEXIT_CRITICAL();
2744  		taskENTER_CRITICAL();
2745  		{
2746  			traceTASK_NOTIFY_WAIT();
2747  			if( pulNotificationValue != NULL )
2748  			{
2749  				*pulNotificationValue = pxCurrentTCB->ulNotifiedValue;
2750  			}
2751  			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
2752  			{
2753  				xReturn = pdFALSE;
2754  			}
2755  			else
2756  			{
2757  				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
2758  				xReturn = pdTRUE;
2759  			}
2760  			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
2761  		}
2762  		taskEXIT_CRITICAL();
2763  		return xReturn;
2764  	}
2765  #endif &bsol;* configUSE_TASK_NOTIFICATIONS */
2766  #if( configUSE_TASK_NOTIFICATIONS == 1 )
2767  	BaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue )
2768  	{
2769  	TCB_t * pxTCB;
2770  	BaseType_t xReturn = pdPASS;
2771  	uint8_t ucOriginalNotifyState;
2772  		configASSERT( xTaskToNotify );
2773  		pxTCB = ( TCB_t * ) xTaskToNotify;
2774  		taskENTER_CRITICAL();
2775  		{
2776  			if( pulPreviousNotificationValue != NULL )
2777  			{
2778  				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
2779  			}
2780  			ucOriginalNotifyState = pxTCB->ucNotifyState;
2781  			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
2782  			switch( eAction )
2783  			{
2784  				case eSetBits	:
2785  					pxTCB->ulNotifiedValue |= ulValue;
2786  					break;
2787  				case eIncrement	:
2788  					( pxTCB->ulNotifiedValue )++;
2789  					break;
2790  				case eSetValueWithOverwrite	:
2791  					pxTCB->ulNotifiedValue = ulValue;
2792  					break;
2793  				case eSetValueWithoutOverwrite :
2794  					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
2795  					{
2796  						pxTCB->ulNotifiedValue = ulValue;
2797  					}
2798  					else
2799  					{
2800  						xReturn = pdFAIL;
2801  					}
2802  					break;
2803  				case eNoAction:
2804  					break;
2805  			}
2806  			traceTASK_NOTIFY();
2807  			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
2808  			{
2809  				( void ) uxListRemove( &( pxTCB->xStateListItem ) );
2810  				prvAddTaskToReadyList( pxTCB );
2811  				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );
2812  				#if( configUSE_TICKLESS_IDLE != 0 )
2813  				{
2814  					prvResetNextTaskUnblockTime();
2815  				}
2816  				#endif
2817  				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
2818  				{
2819  					taskYIELD_IF_USING_PREEMPTION();
2820  				}
2821  				else
2822  				{
2823  					mtCOVERAGE_TEST_MARKER();
2824  				}
2825  			}
2826  			else
2827  			{
2828  				mtCOVERAGE_TEST_MARKER();
2829  			}
2830  		}
2831  		taskEXIT_CRITICAL();
2832  		return xReturn;
2833  	}
2834  #endif &bsol;* configUSE_TASK_NOTIFICATIONS */
2835  #if( configUSE_TASK_NOTIFICATIONS == 1 )
2836  	BaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken )
2837  	{
2838  	TCB_t * pxTCB;
2839  	uint8_t ucOriginalNotifyState;
2840  	BaseType_t xReturn = pdPASS;
2841  	UBaseType_t uxSavedInterruptStatus;
2842  		configASSERT( xTaskToNotify );
2843  		portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
2844  		pxTCB = ( TCB_t * ) xTaskToNotify;
2845  		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
2846  		{
2847  			if( pulPreviousNotificationValue != NULL )
2848  			{
2849  				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
2850  			}
2851  			ucOriginalNotifyState = pxTCB->ucNotifyState;
2852  			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
2853  			switch( eAction )
2854  			{
2855  				case eSetBits	:
2856  					pxTCB->ulNotifiedValue |= ulValue;
2857  					break;
2858  				case eIncrement	:
2859  					( pxTCB->ulNotifiedValue )++;
2860  					break;
2861  				case eSetValueWithOverwrite	:
2862  					pxTCB->ulNotifiedValue = ulValue;
2863  					break;
2864  				case eSetValueWithoutOverwrite :
2865  					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
2866  					{
2867  						pxTCB->ulNotifiedValue = ulValue;
2868  					}
2869  					else
2870  					{
2871  						xReturn = pdFAIL;
2872  					}
2873  					break;
2874  				case eNoAction :
2875  					break;
2876  			}
2877  			traceTASK_NOTIFY_FROM_ISR();
2878  			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
2879  			{
2880  				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );
2881  				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
2882  				{
2883  					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
2884  					prvAddTaskToReadyList( pxTCB );
2885  				}
2886  				else
2887  				{
2888  					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
2889  				}
2890  				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
2891  				{
2892  					if( pxHigherPriorityTaskWoken != NULL )
2893  					{
2894  						*pxHigherPriorityTaskWoken = pdTRUE;
2895  					}
2896  					else
2897  					{
2898  						xYieldPending = pdTRUE;
2899  					}
2900  				}
2901  				else
2902  				{
2903  					mtCOVERAGE_TEST_MARKER();
2904  				}
2905  			}
2906  		}
2907  		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
2908  		return xReturn;
2909  	}
2910  #endif &bsol;* configUSE_TASK_NOTIFICATIONS */
2911  #if( configUSE_TASK_NOTIFICATIONS == 1 )
2912  	void vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken )
2913  	{
2914  	TCB_t * pxTCB;
2915  	uint8_t ucOriginalNotifyState;
2916  	UBaseType_t uxSavedInterruptStatus;
2917  		configASSERT( xTaskToNotify );
2918  		portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
2919  		pxTCB = ( TCB_t * ) xTaskToNotify;
2920  		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
2921  		{
2922  			ucOriginalNotifyState = pxTCB->ucNotifyState;
2923  			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
2924  			( pxTCB->ulNotifiedValue )++;
2925  			traceTASK_NOTIFY_GIVE_FROM_ISR();
2926  			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
2927  			{
2928  				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );
2929  				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
2930  				{
2931  					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
2932  					prvAddTaskToReadyList( pxTCB );
2933  				}
2934  				else
2935  				{
2936  					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
2937  				}
2938  				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
2939  				{
2940  					if( pxHigherPriorityTaskWoken != NULL )
2941  					{
2942  						*pxHigherPriorityTaskWoken = pdTRUE;
2943  					}
2944  					else
2945  					{
2946  						xYieldPending = pdTRUE;
2947  					}
2948  				}
2949  				else
2950  				{
2951  					mtCOVERAGE_TEST_MARKER();
2952  				}
2953  			}
2954  		}
2955  		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
2956  	}
2957  #endif &bsol;* configUSE_TASK_NOTIFICATIONS */
2958  #if( configUSE_TASK_NOTIFICATIONS == 1 )
2959  	BaseType_t xTaskNotifyStateClear( TaskHandle_t xTask )
2960  	{
2961  	TCB_t *pxTCB;
2962  	BaseType_t xReturn;
2963  		pxTCB = prvGetTCBFromHandle( xTask );
2964  		taskENTER_CRITICAL();
2965  		{
2966  			if( pxTCB->ucNotifyState == taskNOTIFICATION_RECEIVED )
2967  			{
2968  				pxTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
2969  				xReturn = pdPASS;
2970  			}
2971  			else
2972  			{
2973  				xReturn = pdFAIL;
2974  			}
2975  		}
2976  		taskEXIT_CRITICAL();
2977  		return xReturn;
2978  	}
2979  #endif &bsol;* configUSE_TASK_NOTIFICATIONS */
2980  static void prvAddCurrentTaskToDelayedList( TickType_t xTicksToWait, const BaseType_t xCanBlockIndefinitely )
2981  {
2982  TickType_t xTimeToWake;
2983  const TickType_t xConstTickCount = xTickCount;
2984  	#if( INCLUDE_xTaskAbortDelay == 1 )
2985  	{
2986  		pxCurrentTCB->ucDelayAborted = pdFALSE;
2987  	}
2988  	#endif
2989  	if( uxListRemove( &( pxCurrentTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
2990  	{
2991  		portRESET_READY_PRIORITY( pxCurrentTCB->uxPriority, uxTopReadyPriority );
2992  	}
2993  	else
2994  	{
2995  		mtCOVERAGE_TEST_MARKER();
2996  	}
2997  	#if ( INCLUDE_vTaskSuspend == 1 )
2998  	{
2999  		if( ( xTicksToWait == portMAX_DELAY ) && ( xCanBlockIndefinitely != pdFALSE ) )
3000  		{
3001  			traceMOVED_TASK_TO_SUSPENDED_LIST(pxCurrentTCB);
3002  			vListInsertEnd( &xSuspendedTaskList, &( pxCurrentTCB->xStateListItem ) );
3003  		}
3004  		else
3005  		{
3006  			xTimeToWake = xConstTickCount + xTicksToWait;
3007  			listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xStateListItem ), xTimeToWake );
3008  			if( xTimeToWake < xConstTickCount )
3009  			{
3010  				traceMOVED_TASK_TO_OVERFLOW_DELAYED_LIST();
3011  				vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
3012  			}
3013  			else
3014  			{
3015  				traceMOVED_TASK_TO_DELAYED_LIST();
3016  				vListInsert( pxDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
3017  				if( xTimeToWake < xNextTaskUnblockTime )
3018  				{
3019  					xNextTaskUnblockTime = xTimeToWake;
3020  				}
3021  				else
3022  				{
3023  					mtCOVERAGE_TEST_MARKER();
3024  				}
3025  			}
3026  		}
3027  	}
3028  	#else &bsol;* INCLUDE_vTaskSuspend */
3029  	{
3030  		xTimeToWake = xConstTickCount + xTicksToWait;
3031  		listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xStateListItem ), xTimeToWake );
3032  		if( xTimeToWake < xConstTickCount )
3033  		{
3034  			traceMOVED_TASK_TO_OVERFLOW_DELAYED_LIST();
3035  			vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
3036  		}
3037  		else
3038  		{
3039  			traceMOVED_TASK_TO_DELAYED_LIST();
3040  			vListInsert( pxDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
3041  			if( xTimeToWake < xNextTaskUnblockTime )
3042  			{
3043  				xNextTaskUnblockTime = xTimeToWake;
3044  			}
3045  			else
3046  			{
3047  				mtCOVERAGE_TEST_MARKER();
3048  			}
3049  		}
3050  		( void ) xCanBlockIndefinitely;
3051  	}
3052  	#endif &bsol;* INCLUDE_vTaskSuspend */
3053  }
3054  #ifdef FREERTOS_MODULE_TEST
3055  	#include "tasks_test_access_functions.h"
3056  #endif
3057  #if( configINCLUDE_FREERTOS_TASK_C_ADDITIONS_H == 1 )
3058  	#include "freertos_tasks_c_additions.h"
3059  	static void freertos_tasks_c_additions_init( void )
3060  	{
3061  		#ifdef FREERTOS_TASKS_C_ADDITIONS_INIT
3062  			FREERTOS_TASKS_C_ADDITIONS_INIT();
3063  		#endif
3064  	}
3065  #endif
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-topology-xml.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from Adafruit_nRF52_Arduino-MDEwOlJlcG9zaXRvcnk3NDM1NDcyOQ==-flat-tasks.c</div>
                </div>
                <div class="column column_space"><pre><code>2824    assert(hwloc_nolibxml_callbacks);
2825    hwloc_localeswitch_init();
2826    force_nolibxml = hwloc_nolibxml_export();
2827  retry:
</pre></code></div>
                <div class="column column_space"><pre><code>1078  		configASSERT( xTaskToResume );
1079  		portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
1080  		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
1081  		{
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    