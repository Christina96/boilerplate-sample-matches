
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 18, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>libpcap-MDEwOlJlcG9zaXRvcnk5NDM1ODg3-flat-pcap-linux.c</h3>
            <pre><code>1  #define _GNU_SOURCE
2  #ifdef HAVE_CONFIG_H
3  #include <config.h>
4  #endif
5  #include <errno.h>
6  #include <stdio.h>
7  #include <stdlib.h>
8  #include <unistd.h>
9  #include <fcntl.h>
10  #include <string.h>
11  #include <limits.h>
12  #include <sys/stat.h>
13  #include <sys/socket.h>
14  #include <sys/ioctl.h>
15  #include <sys/utsname.h>
16  #include <sys/mman.h>
17  #include <linux/if.h>
18  #include <linux/if_packet.h>
19  #include <linux/sockios.h>
20  #include <linux/ethtool.h>
21  #include <netinet/in.h>
22  #include <linux/if_ether.h>
23  #include <linux/if_arp.h>
24  #include <poll.h>
25  #include <dirent.h>
26  #include <sys/eventfd.h>
27  #include "pcap-int.h"
28  #include "pcap/sll.h"
29  #include "pcap/vlan.h"
30  #include "pcap/can_socketcan.h"
31  #include "diag-control.h"
32  #ifndef TPACKET2_HDRLEN
33  #error "Libpcap will only work if TPACKET_V2 is supported; you must build for a 2.6.27 or later kernel"
34  #endif
35  #ifdef TPACKET3_HDRLEN
36  # define HAVE_TPACKET3
37  #endif &bsol;* TPACKET3_HDRLEN */
38  #ifndef HAVE___ATOMIC_LOAD_N
39  #define __atomic_load_n(ptr, memory_model)		(*(ptr))
40  #endif
41  #ifndef HAVE___ATOMIC_STORE_N
42  #define __atomic_store_n(ptr, val, memory_model)	*(ptr) = (val)
43  #endif
44  #define packet_mmap_acquire(pkt) \
45  	(__atomic_load_n(&pkt->tp_status, __ATOMIC_ACQUIRE) != TP_STATUS_KERNEL)
46  #define packet_mmap_release(pkt) \
47  	(__atomic_store_n(&pkt->tp_status, TP_STATUS_KERNEL, __ATOMIC_RELEASE))
48  #define packet_mmap_v3_acquire(pkt) \
49  	(__atomic_load_n(&pkt->hdr.bh1.block_status, __ATOMIC_ACQUIRE) != TP_STATUS_KERNEL)
50  #define packet_mmap_v3_release(pkt) \
51  	(__atomic_store_n(&pkt->hdr.bh1.block_status, TP_STATUS_KERNEL, __ATOMIC_RELEASE))
52  #include <linux/types.h>
53  #include <linux/filter.h>
54  #ifdef HAVE_LINUX_NET_TSTAMP_H
55  #include <linux/net_tstamp.h>
56  #endif
57  #include <linux/if_bonding.h>
58  #ifdef HAVE_LIBNL
59  #include <linux/nl80211.h>
60  #include <netlink/genl/genl.h>
61  #include <netlink/genl/family.h>
62  #include <netlink/genl/ctrl.h>
63  #include <netlink/msg.h>
64  #include <netlink/attr.h>
65  #endif &bsol;* HAVE_LIBNL */
66  #ifndef HAVE_SOCKLEN_T
67  typedef int		socklen_t;
68  #endif
69  #define MAX_LINKHEADER_SIZE	256
70  #define BIGGER_THAN_ALL_MTUS	(64*1024)
71  struct pcap_linux {
72  	long long sysfs_dropped; &bsol;* packets reported dropped by /sys/class/net/{if_name}/statistics/rx_{missed,fifo}_errors */
73  	struct pcap_stat stat;
74  	char	*device;	&bsol;* device name */
75  	int	filter_in_userland; &bsol;* must filter in userland */
76  	int	blocks_to_filter_in_userland;
77  	int	must_do_on_close; &bsol;* stuff we must do when we close */
78  	int	timeout;	&bsol;* timeout for buffering */
79  	int	cooked;		&bsol;* using SOCK_DGRAM rather than SOCK_RAW */
80  	int	ifindex;	&bsol;* interface index of device we're bound to */
81  	int	lo_ifindex;	&bsol;* interface index of the loopback device */
82  	int	netdown;	&bsol;* we got an ENETDOWN and haven't resolved it */
83  	bpf_u_int32 oldmode;	&bsol;* mode to restore when turning monitor mode off */
84  	char	*mondevice;	&bsol;* mac80211 monitor device we created */
85  	u_char	*mmapbuf;	&bsol;* memory-mapped region pointer */
86  	size_t	mmapbuflen;	&bsol;* size of region */
87  	int	vlan_offset;	&bsol;* offset at which to insert vlan tags; if -1, don't insert */
88  	u_int	tp_version;	&bsol;* version of tpacket_hdr for mmaped ring */
89  	u_int	tp_hdrlen;	&bsol;* hdrlen of tpacket_hdr for mmaped ring */
90  	u_char	*oneshot_buffer; &bsol;* buffer for copy of packet */
91  	int	poll_timeout;	&bsol;* timeout to use in poll() */
92  #ifdef HAVE_TPACKET3
93  	unsigned char *current_packet; &bsol;* Current packet within the TPACKET_V3 block. Move to next block if NULL. */
94  	int packets_left; &bsol;* Unhandled packets left within the block from previous call to pcap_read_linux_mmap_v3 in case of TPACKET_V3. */
95  #endif
96  	int poll_breakloop_fd; &bsol;* fd to an eventfd to break from blocking operations */
97  };
98  #define MUST_CLEAR_RFMON	0x00000001	&bsol;* clear rfmon (monitor) mode */
99  #define MUST_DELETE_MONIF	0x00000002	&bsol;* delete monitor-mode interface */
100  static int get_if_flags(const char *, bpf_u_int32 *, char *);
101  static int is_wifi(const char *);
102  static int map_arphrd_to_dlt(pcap_t *, int, const char *, int);
103  static int pcap_activate_linux(pcap_t *);
104  static int setup_socket(pcap_t *, int);
105  static int setup_mmapped(pcap_t *);
106  static int pcap_can_set_rfmon_linux(pcap_t *);
107  static int pcap_inject_linux(pcap_t *, const void *, int);
108  static int pcap_stats_linux(pcap_t *, struct pcap_stat *);
109  static int pcap_setfilter_linux(pcap_t *, struct bpf_program *);
110  static int pcap_setdirection_linux(pcap_t *, pcap_direction_t);
111  static int pcap_set_datalink_linux(pcap_t *, int);
112  static void pcap_cleanup_linux(pcap_t *);
113  union thdr {
114  	struct tpacket2_hdr		*h2;
115  #ifdef HAVE_TPACKET3
116  	struct tpacket_block_desc	*h3;
117  #endif
118  	u_char				*raw;
119  };
120  #define RING_GET_FRAME_AT(h, offset) (((u_char **)h->buffer)[(offset)])
121  #define RING_GET_CURRENT_FRAME(h) RING_GET_FRAME_AT(h, h->offset)
122  static void destroy_ring(pcap_t *handle);
123  static int create_ring(pcap_t *handle);
124  static int prepare_tpacket_socket(pcap_t *handle);
125  static int pcap_read_linux_mmap_v2(pcap_t *, int, pcap_handler , u_char *);
126  #ifdef HAVE_TPACKET3
127  static int pcap_read_linux_mmap_v3(pcap_t *, int, pcap_handler , u_char *);
128  #endif
129  static int pcap_setnonblock_linux(pcap_t *p, int nonblock);
130  static int pcap_getnonblock_linux(pcap_t *p);
131  static void pcap_oneshot_linux(u_char *user, const struct pcap_pkthdr *h,
132      const u_char *bytes);
133  #ifdef TP_STATUS_VLAN_VALID
134    #define VLAN_VALID(hdr, hv)	((hv)->tp_vlan_tci != 0 || ((hdr)->tp_status & TP_STATUS_VLAN_VALID))
135  #else
136    #define VLAN_VALID(hdr, hv)	((hv)->tp_vlan_tci != 0 || ((hdr)->tp_status & 0x10))
137  #endif
138  #ifdef TP_STATUS_VLAN_TPID_VALID
139  # define VLAN_TPID(hdr, hv)	(((hv)->tp_vlan_tpid || ((hdr)->tp_status & TP_STATUS_VLAN_TPID_VALID)) ? (hv)->tp_vlan_tpid : ETH_P_8021Q)
140  #else
141  # define VLAN_TPID(hdr, hv)	ETH_P_8021Q
142  #endif
143  static const struct timeval netdown_timeout = {
144  	0, 1000		&bsol;* 1000 microseconds = 1 millisecond */
145  };
146  static int	iface_get_id(int fd, const char *device, char *ebuf);
147  static int	iface_get_mtu(int fd, const char *device, char *ebuf);
148  static int	iface_get_arptype(int fd, const char *device, char *ebuf);
149  static int	iface_bind(int fd, int ifindex, char *ebuf, int protocol);
150  static int	enter_rfmon_mode(pcap_t *handle, int sock_fd,
151      const char *device);
152  static int	iface_get_ts_types(const char *device, pcap_t *handle,
153      char *ebuf);
154  static int	iface_get_offload(pcap_t *handle);
155  static int	fix_program(pcap_t *handle, struct sock_fprog *fcode);
156  static int	fix_offset(pcap_t *handle, struct bpf_insn *p);
157  static int	set_kernel_filter(pcap_t *handle, struct sock_fprog *fcode);
158  static int	reset_kernel_filter(pcap_t *handle);
159  static struct sock_filter	total_insn
160  	= BPF_STMT(BPF_RET | BPF_K, 0);
161  static struct sock_fprog	total_fcode
162  	= { 1, &total_insn };
163  static int	iface_dsa_get_proto_info(const char *device, pcap_t *handle);
164  pcap_t *
165  pcap_create_interface(const char *device, char *ebuf)
166  {
167  	pcap_t *handle;
168  	handle = PCAP_CREATE_COMMON(ebuf, struct pcap_linux);
169  	if (handle == NULL)
170  		return NULL;
171  	handle->activate_op = pcap_activate_linux;
172  	handle->can_set_rfmon_op = pcap_can_set_rfmon_linux;
173  	if (iface_get_ts_types(device, handle, ebuf) == -1) {
174  		pcap_close(handle);
175  		return NULL;
176  	}
177  	handle->tstamp_precision_list = malloc(2 * sizeof(u_int));
178  	if (handle->tstamp_precision_list == NULL) {
179  		pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
180  		    errno, "malloc");
181  		pcap_close(handle);
182  		return NULL;
183  	}
184  	handle->tstamp_precision_list[0] = PCAP_TSTAMP_PRECISION_MICRO;
185  	handle->tstamp_precision_list[1] = PCAP_TSTAMP_PRECISION_NANO;
186  	handle->tstamp_precision_count = 2;
187  	struct pcap_linux *handlep = handle->priv;
188  	handlep->poll_breakloop_fd = eventfd(0, EFD_NONBLOCK);
189  	return handle;
190  }
191  #ifdef HAVE_LIBNL
192  static int
193  get_mac80211_phydev(pcap_t *handle, const char *device, char *phydev_path,
194      size_t phydev_max_pathlen)
195  {
196  	char *pathstr;
197  	ssize_t bytes_read;
198  	if (asprintf(&pathstr, "/sys/class/net/%s/phy80211", device) == -1) {
199  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
200  		    "%s: Can't generate path name string for /sys/class/net device",
201  		    device);
202  		return PCAP_ERROR;
203  	}
204  	bytes_read = readlink(pathstr, phydev_path, phydev_max_pathlen);
205  	if (bytes_read == -1) {
206  		if (errno == ENOENT || errno == EINVAL) {
207  			free(pathstr);
208  			return 0;
209  		}
210  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
211  		    errno, "%s: Can't readlink %s", device, pathstr);
212  		free(pathstr);
213  		return PCAP_ERROR;
214  	}
215  	free(pathstr);
216  	phydev_path[bytes_read] = '\0';
217  	return 1;
218  }
219  struct nl80211_state {
220  	struct nl_sock *nl_sock;
221  	struct nl_cache *nl_cache;
222  	struct genl_family *nl80211;
223  };
224  static int
225  nl80211_init(pcap_t *handle, struct nl80211_state *state, const char *device)
226  {
227  	int err;
228  	state->nl_sock = nl_socket_alloc();
229  	if (!state->nl_sock) {
230  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
231  		    "%s: failed to allocate netlink handle", device);
232  		return PCAP_ERROR;
233  	}
234  	if (genl_connect(state->nl_sock)) {
235  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
236  		    "%s: failed to connect to generic netlink", device);
237  		goto out_handle_destroy;
238  	}
239  	err = genl_ctrl_alloc_cache(state->nl_sock, &state->nl_cache);
240  	if (err < 0) {
241  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
242  		    "%s: failed to allocate generic netlink cache: %s",
243  		    device, nl_geterror(-err));
244  		goto out_handle_destroy;
245  	}
246  	state->nl80211 = genl_ctrl_search_by_name(state->nl_cache, "nl80211");
247  	if (!state->nl80211) {
248  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
249  		    "%s: nl80211 not found", device);
250  		goto out_cache_free;
251  	}
252  	return 0;
253  out_cache_free:
254  	nl_cache_free(state->nl_cache);
255  out_handle_destroy:
256  	nl_socket_free(state->nl_sock);
257  	return PCAP_ERROR;
258  }
259  static void
260  nl80211_cleanup(struct nl80211_state *state)
261  {
262  	genl_family_put(state->nl80211);
263  	nl_cache_free(state->nl_cache);
264  	nl_socket_free(state->nl_sock);
265  }
266  static int
267  del_mon_if(pcap_t *handle, int sock_fd, struct nl80211_state *state,
268      const char *device, const char *mondevice);
269  static int
270  add_mon_if(pcap_t *handle, int sock_fd, struct nl80211_state *state,
271      const char *device, const char *mondevice)
272  {
273  	struct pcap_linux *handlep = handle->priv;
274  	int ifindex;
275  	struct nl_msg *msg;
276  	int err;
277  	ifindex = iface_get_id(sock_fd, device, handle->errbuf);
278  	if (ifindex == -1)
279  		return PCAP_ERROR;
280  	msg = nlmsg_alloc();
281  	if (!msg) {
282  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
283  		    "%s: failed to allocate netlink msg", device);
284  		return PCAP_ERROR;
285  	}
286  	genlmsg_put(msg, 0, 0, genl_family_get_id(state->nl80211), 0,
287  		    0, NL80211_CMD_NEW_INTERFACE, 0);
288  	NLA_PUT_U32(msg, NL80211_ATTR_IFINDEX, ifindex);
289  DIAG_OFF_NARROWING
290  	NLA_PUT_STRING(msg, NL80211_ATTR_IFNAME, mondevice);
291  DIAG_ON_NARROWING
292  	NLA_PUT_U32(msg, NL80211_ATTR_IFTYPE, NL80211_IFTYPE_MONITOR);
293  	err = nl_send_auto_complete(state->nl_sock, msg);
294  	if (err < 0) {
295  		if (err == -NLE_FAILURE) {
296  			nlmsg_free(msg);
297  			return 0;
298  		} else {
299  			snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
300  			    "%s: nl_send_auto_complete failed adding %s interface: %s",
301  			    device, mondevice, nl_geterror(-err));
302  			nlmsg_free(msg);
303  			return PCAP_ERROR;
304  		}
305  	}
306  	err = nl_wait_for_ack(state->nl_sock);
307  	if (err < 0) {
308  		if (err == -NLE_FAILURE) {
309  			nlmsg_free(msg);
310  			return 0;
311  		} else {
312  			snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
313  			    "%s: nl_wait_for_ack failed adding %s interface: %s",
314  			    device, mondevice, nl_geterror(-err));
315  			nlmsg_free(msg);
316  			return PCAP_ERROR;
317  		}
318  	}
319  	nlmsg_free(msg);
320  	handlep->mondevice = strdup(mondevice);
321  	if (handlep->mondevice == NULL) {
322  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
323  		    errno, "strdup");
324  		del_mon_if(handle, sock_fd, state, device, mondevice);
325  		return PCAP_ERROR;
326  	}
327  	return 1;
328  nla_put_failure:
329  	snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
330  	    "%s: nl_put failed adding %s interface",
331  	    device, mondevice);
332  	nlmsg_free(msg);
333  	return PCAP_ERROR;
334  }
335  static int
336  del_mon_if(pcap_t *handle, int sock_fd, struct nl80211_state *state,
337      const char *device, const char *mondevice)
338  {
339  	int ifindex;
340  	struct nl_msg *msg;
341  	int err;
342  	ifindex = iface_get_id(sock_fd, mondevice, handle->errbuf);
343  	if (ifindex == -1)
344  		return PCAP_ERROR;
345  	msg = nlmsg_alloc();
346  	if (!msg) {
347  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
348  		    "%s: failed to allocate netlink msg", device);
349  		return PCAP_ERROR;
350  	}
351  	genlmsg_put(msg, 0, 0, genl_family_get_id(state->nl80211), 0,
352  		    0, NL80211_CMD_DEL_INTERFACE, 0);
353  	NLA_PUT_U32(msg, NL80211_ATTR_IFINDEX, ifindex);
354  	err = nl_send_auto_complete(state->nl_sock, msg);
355  	if (err < 0) {
356  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
357  		    "%s: nl_send_auto_complete failed deleting %s interface: %s",
358  		    device, mondevice, nl_geterror(-err));
359  		nlmsg_free(msg);
360  		return PCAP_ERROR;
361  	}
362  	err = nl_wait_for_ack(state->nl_sock);
363  	if (err < 0) {
364  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
365  		    "%s: nl_wait_for_ack failed adding %s interface: %s",
366  		    device, mondevice, nl_geterror(-err));
367  		nlmsg_free(msg);
368  		return PCAP_ERROR;
369  	}
370  	nlmsg_free(msg);
371  	return 1;
372  nla_put_failure:
373  	snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
374  	    "%s: nl_put failed deleting %s interface",
375  	    device, mondevice);
376  	nlmsg_free(msg);
377  	return PCAP_ERROR;
378  }
379  #endif &bsol;* HAVE_LIBNL */
380  static int pcap_protocol(pcap_t *handle)
381  {
382  	int protocol;
383  	protocol = handle->opt.protocol;
384  	if (protocol == 0)
385  		protocol = ETH_P_ALL;
386  	return htons(protocol);
387  }
388  static int
389  pcap_can_set_rfmon_linux(pcap_t *handle)
390  {
391  #ifdef HAVE_LIBNL
392  	char phydev_path[PATH_MAX+1];
393  	int ret;
394  #endif
395  	if (strcmp(handle->opt.device, "any") == 0) {
396  		return 0;
397  	}
398  #ifdef HAVE_LIBNL
399  	ret = get_mac80211_phydev(handle, handle->opt.device, phydev_path,
400  	    PATH_MAX);
401  	if (ret < 0)
402  		return ret;	&bsol;* error */
403  	if (ret == 1)
404  		return 1;	&bsol;* mac80211 device */
405  #endif
406  	return 0;
407  }
408  static long long int
409  linux_get_stat(const char * if_name, const char * stat) {
410  	ssize_t bytes_read;
411  	int fd;
412  	char buffer[PATH_MAX];
413  	snprintf(buffer, sizeof(buffer), "/sys/class/net/%s/statistics/%s", if_name, stat);
414  	fd = open(buffer, O_RDONLY);
415  	if (fd == -1)
416  		return 0;
417  	bytes_read = read(fd, buffer, sizeof(buffer) - 1);
418  	close(fd);
419  	if (bytes_read == -1)
420  		return 0;
421  	buffer[bytes_read] = '\0';
422  	return strtoll(buffer, NULL, 10);
423  }
424  static long long int
425  linux_if_drops(const char * if_name)
426  {
427  	long long int missed = linux_get_stat(if_name, "rx_missed_errors");
428  	long long int fifo = linux_get_stat(if_name, "rx_fifo_errors");
429  	return missed + fifo;
430  }
431  static void	pcap_cleanup_linux( pcap_t *handle )
432  {
433  	struct pcap_linux *handlep = handle->priv;
434  #ifdef HAVE_LIBNL
435  	struct nl80211_state nlstate;
436  	int ret;
437  #endif &bsol;* HAVE_LIBNL */
438  	if (handlep->must_do_on_close != 0) {
439  #ifdef HAVE_LIBNL
440  		if (handlep->must_do_on_close & MUST_DELETE_MONIF) {
441  			ret = nl80211_init(handle, &nlstate, handlep->device);
442  			if (ret >= 0) {
443  				ret = del_mon_if(handle, handle->fd, &nlstate,
444  				    handlep->device, handlep->mondevice);
445  				nl80211_cleanup(&nlstate);
446  			}
447  			if (ret < 0) {
448  				fprintf(stderr,
449  				    "Can't delete monitor interface %s (%s).\n"
450  				    "Please delete manually.\n",
451  				    handlep->mondevice, handle->errbuf);
452  			}
453  		}
454  #endif &bsol;* HAVE_LIBNL */
455  		pcap_remove_from_pcaps_to_close(handle);
456  	}
457  	if (handle->fd != -1) {
458  		destroy_ring(handle);
459  	}
460  	if (handlep->oneshot_buffer != NULL) {
461  		munmap(handlep->oneshot_buffer, handle->snapshot);
462  		handlep->oneshot_buffer = NULL;
463  	}
464  	if (handlep->mondevice != NULL) {
465  		free(handlep->mondevice);
466  		handlep->mondevice = NULL;
467  	}
468  	if (handlep->device != NULL) {
469  		free(handlep->device);
470  		handlep->device = NULL;
471  	}
472  	if (handlep->poll_breakloop_fd != -1) {
473  		close(handlep->poll_breakloop_fd);
474  		handlep->poll_breakloop_fd = -1;
475  	}
476  	pcap_cleanup_live_common(handle);
477  }
478  #ifdef HAVE_TPACKET3
479  static int has_broken_tpacket_v3(void)
480  {
481  	struct utsname utsname;
482  	const char *release;
483  	long major, minor;
484  	int matches, verlen;
485  	if (uname(&utsname) == -1)
486  		return 1;
487  	release = utsname.release;
488  	matches = sscanf(release, "%ld.%ld%n", &major, &minor, &verlen);
489  	if (matches != 2)
490  		return 1;
491  	if (release[verlen] != '.' && release[verlen] != '\0')
492  		return 1;
493  	if (major > 3 || (major == 3 && minor >= 19))
494  		return 0;
495  	return 1;
496  }
497  #endif
498  static void
499  set_poll_timeout(struct pcap_linux *handlep)
500  {
501  #ifdef HAVE_TPACKET3
502  	int broken_tpacket_v3 = has_broken_tpacket_v3();
503  #endif
504  	if (handlep->timeout == 0) {
505  #ifdef HAVE_TPACKET3
506  		if (handlep->tp_version == TPACKET_V3 && broken_tpacket_v3)
507  			handlep->poll_timeout = 1;	&bsol;* don't block for very long */
508  		else
509  #endif
510  			handlep->poll_timeout = -1;	&bsol;* block forever */
511  	} else if (handlep->timeout > 0) {
512  #ifdef HAVE_TPACKET3
513  		if (handlep->tp_version == TPACKET_V3 && !broken_tpacket_v3)
514  			handlep->poll_timeout = -1;	&bsol;* block forever, let TPACKET_V3 wake us up */
515  		else
516  #endif
517  			handlep->poll_timeout = handlep->timeout;	&bsol;* block for that amount of time */
518  	} else {
519  		handlep->poll_timeout = 0;
520  	}
521  }
522  static void pcap_breakloop_linux(pcap_t *handle)
523  {
524  	pcap_breakloop_common(handle);
525  	struct pcap_linux *handlep = handle->priv;
526  	uint64_t value = 1;
527  	if (handlep->poll_breakloop_fd != -1)
528  		(void)write(handlep->poll_breakloop_fd, &value, sizeof(value));
529  }
530  static void
531  set_vlan_offset(pcap_t *handle)
532  {
533  	struct pcap_linux *handlep = handle->priv;
534  	switch (handle->linktype) {
535  	case DLT_EN10MB:
536  		handlep->vlan_offset = 2 * ETH_ALEN;
537  		break;
538  	case DLT_LINUX_SLL:
539  		handlep->vlan_offset = SLL_HDR_LEN - 2;
540  		break;
541  	default:
542  		handlep->vlan_offset = -1; &bsol;* unknown */
543  		break;
544  	}
545  }
546  static int
547  pcap_activate_linux(pcap_t *handle)
548  {
549  	struct pcap_linux *handlep = handle->priv;
550  	const char	*device;
551  	int		is_any_device;
552  	struct ifreq	ifr;
553  	int		status;
554  	int		ret;
555  	device = handle->opt.device;
556  	status = 0;
557  	if (strlen(device) >= sizeof(ifr.ifr_name)) {
558  		handle->errbuf[0] = '\0';
559  		status = PCAP_ERROR_NO_SUCH_DEVICE;
560  		goto fail;
561  	}
562  	if (handle->snapshot <= 0 || handle->snapshot > MAXIMUM_SNAPLEN)
563  		handle->snapshot = MAXIMUM_SNAPLEN;
564  	handlep->device	= strdup(device);
565  	if (handlep->device == NULL) {
566  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
567  		    errno, "strdup");
568  		status = PCAP_ERROR;
569  		goto fail;
570  	}
571  	is_any_device = (strcmp(device, "any") == 0);
572  	if (is_any_device) {
573  		if (handle->opt.promisc) {
574  			handle->opt.promisc = 0;
575  			snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
576  			    "Promiscuous mode not supported on the \"any\" device");
577  			status = PCAP_WARNING_PROMISC_NOTSUP;
578  		}
579  	}
<span onclick='openModal()' class='match'>580  	handlep->timeout = handle->opt.timeout;
581  	if (handle->opt.promisc)
582  		handlep->sysfs_dropped = linux_if_drops(handlep->device);
</span>583  	ret = setup_socket(handle, is_any_device);
584  	if (ret < 0) {
585  		status = ret;
586  		goto fail;
587  	}
588  	if (ret > 0) {
589  		status = ret;
590  	}
591  	ret = setup_mmapped(handle);
592  	if (ret < 0) {
593  		status = ret;
594  		goto fail;
595  	}
596  	if (ret > 0) {
597  		status = ret;
598  	}
599  	if ((ret = iface_bind(handle->fd, handlep->ifindex,
600  	    handle->errbuf, pcap_protocol(handle))) != 0) {
601  		status = ret;
602  		goto fail;
603  	}
604  	handle->inject_op = pcap_inject_linux;
605  	handle->setfilter_op = pcap_setfilter_linux;
606  	handle->setdirection_op = pcap_setdirection_linux;
607  	handle->set_datalink_op = pcap_set_datalink_linux;
608  	handle->setnonblock_op = pcap_setnonblock_linux;
609  	handle->getnonblock_op = pcap_getnonblock_linux;
610  	handle->cleanup_op = pcap_cleanup_linux;
611  	handle->stats_op = pcap_stats_linux;
612  	handle->breakloop_op = pcap_breakloop_linux;
613  	switch (handlep->tp_version) {
614  	case TPACKET_V2:
615  		handle->read_op = pcap_read_linux_mmap_v2;
616  		break;
617  #ifdef HAVE_TPACKET3
618  	case TPACKET_V3:
619  		handle->read_op = pcap_read_linux_mmap_v3;
620  		break;
621  #endif
622  	}
623  	handle->oneshot_callback = pcap_oneshot_linux;
624  	handle->selectable_fd = handle->fd;
625  	return status;
626  fail:
627  	pcap_cleanup_linux(handle);
628  	return status;
629  }
630  static int
631  pcap_set_datalink_linux(pcap_t *handle, int dlt)
632  {
633  	handle->linktype = dlt;
634  	set_vlan_offset(handle);
635  	return 0;
636  }
637  static inline int
638  linux_check_direction(const pcap_t *handle, const struct sockaddr_ll *sll)
639  {
640  	struct pcap_linux	*handlep = handle->priv;
641  	if (sll->sll_pkttype == PACKET_OUTGOING) {
642  		if (sll->sll_ifindex == handlep->lo_ifindex)
643  			return 0;
644  		if (sll->sll_hatype == ARPHRD_CAN &&
645  		     handle->direction != PCAP_D_OUT)
646  			return 0;
647  		if (handle->direction == PCAP_D_IN)
648  			return 0;
649  	} else {
650  		if (handle->direction == PCAP_D_OUT)
651  			return 0;
652  	}
653  	return 1;
654  }
655  static int
656  device_still_exists(pcap_t *handle)
657  {
658  	struct pcap_linux *handlep = handle->priv;
659  	struct sockaddr_ll addr;
660  	socklen_t addr_len;
661  	if (handlep->ifindex == -1)
662  		return (1);	&bsol;* it's still here */
663  	addr_len = sizeof (addr);
664  	if (getsockname(handle->fd, (struct sockaddr *) &addr, &addr_len) == -1) {
665  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
666  		    errno, "getsockname failed");
667  		return (-1);
668  	}
669  	if (addr.sll_ifindex == -1) {
670  		return (0);
671  	}
672  	return (1);
673  }
674  static int
675  pcap_inject_linux(pcap_t *handle, const void *buf, int size)
676  {
677  	struct pcap_linux *handlep = handle->priv;
678  	int ret;
679  	if (handlep->ifindex == -1) {
680  		pcap_strlcpy(handle->errbuf,
681  		    "Sending packets isn't supported on the \"any\" device",
682  		    PCAP_ERRBUF_SIZE);
683  		return (-1);
684  	}
685  	if (handlep->cooked) {
686  		pcap_strlcpy(handle->errbuf,
687  		    "Sending packets isn't supported in cooked mode",
688  		    PCAP_ERRBUF_SIZE);
689  		return (-1);
690  	}
691  	ret = (int)send(handle->fd, buf, size, 0);
692  	if (ret == -1) {
693  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
694  		    errno, "send");
695  		return (-1);
696  	}
697  	return (ret);
698  }
699  static int
700  pcap_stats_linux(pcap_t *handle, struct pcap_stat *stats)
701  {
702  	struct pcap_linux *handlep = handle->priv;
703  #ifdef HAVE_TPACKET3
704  	struct tpacket_stats_v3 kstats;
705  #else &bsol;* HAVE_TPACKET3 */
706  	struct tpacket_stats kstats;
707  #endif &bsol;* HAVE_TPACKET3 */
708  	socklen_t len = sizeof (struct tpacket_stats);
709  	long long if_dropped = 0;
710  	if (handle->opt.promisc)
711  	{
712  		if_dropped = handlep->sysfs_dropped;
713  		handlep->sysfs_dropped = linux_if_drops(handlep->device);
714  		handlep->stat.ps_ifdrop += (u_int)(handlep->sysfs_dropped - if_dropped);
715  	}
716  	if (getsockopt(handle->fd, SOL_PACKET, PACKET_STATISTICS,
717  			&kstats, &len) > -1) {
718  		handlep->stat.ps_recv += kstats.tp_packets;
719  		handlep->stat.ps_drop += kstats.tp_drops;
720  		*stats = handlep->stat;
721  		return 0;
722  	}
723  	pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE, errno,
724  	    "failed to get statistics from socket");
725  	return -1;
726  }
727  static int
728  can_be_bound(const char *name _U_)
729  {
730  	return (1);
731  }
732  static int
733  get_if_ioctl_socket(void)
734  {
735  	int fd;
736  	fd = socket(AF_NETLINK, SOCK_RAW, NETLINK_GENERIC);
737  	if (fd != -1) {
738  		struct ifreq ifr;
739  		memset(&ifr, 0, sizeof(ifr));
740  		if (ioctl(fd, SIOCGIFNAME, &ifr) == 0 ||
741  		    errno != EOPNOTSUPP) {
742  			return (fd);
743  		}
744  		close(fd);
745  	}
746  	fd = socket(AF_UNIX, SOCK_RAW, 0);
747  	if (fd != -1) {
748  		return (fd);
749  	}
750  	fd = socket(AF_INET6, SOCK_DGRAM, 0);
751  	if (fd != -1) {
752  		return (fd);
753  	}
754  	return (socket(AF_INET, SOCK_DGRAM, 0));
755  }
756  static int
757  get_if_flags(const char *name, bpf_u_int32 *flags, char *errbuf)
758  {
759  	int sock;
760  	FILE *fh;
761  	unsigned int arptype;
762  	struct ifreq ifr;
763  	struct ethtool_value info;
764  	if (*flags & PCAP_IF_LOOPBACK) {
765  		*flags |= PCAP_IF_CONNECTION_STATUS_NOT_APPLICABLE;
766  		return 0;
767  	}
768  	sock = get_if_ioctl_socket();
769  	if (sock == -1) {
770  		pcap_fmt_errmsg_for_errno(errbuf, PCAP_ERRBUF_SIZE, errno,
771  		    "Can't create socket to get ethtool information for %s",
772  		    name);
773  		return -1;
774  	}
775  	if (is_wifi(name)) {
776  		*flags |= PCAP_IF_WIRELESS;
777  	} else {
778  		char *pathstr;
779  		if (asprintf(&pathstr, "/sys/class/net/%s/type", name) == -1) {
780  			snprintf(errbuf, PCAP_ERRBUF_SIZE,
781  			    "%s: Can't generate path name string for /sys/class/net device",
782  			    name);
783  			close(sock);
784  			return -1;
785  		}
786  		fh = fopen(pathstr, "r");
787  		if (fh != NULL) {
788  			if (fscanf(fh, "%u", &arptype) == 1) {
789  				switch (arptype) {
790  				case ARPHRD_LOOPBACK:
791  					close(sock);
792  					fclose(fh);
793  					free(pathstr);
794  					return 0;
795  				case ARPHRD_IRDA:
796  				case ARPHRD_IEEE80211:
797  				case ARPHRD_IEEE80211_PRISM:
798  				case ARPHRD_IEEE80211_RADIOTAP:
799  #ifdef ARPHRD_IEEE802154
800  				case ARPHRD_IEEE802154:
801  #endif
802  #ifdef ARPHRD_IEEE802154_MONITOR
803  				case ARPHRD_IEEE802154_MONITOR:
804  #endif
805  #ifdef ARPHRD_6LOWPAN
806  				case ARPHRD_6LOWPAN:
807  #endif
808  					*flags |= PCAP_IF_WIRELESS;
809  					break;
810  				}
811  			}
812  			fclose(fh);
813  		}
814  		free(pathstr);
815  	}
816  #ifdef ETHTOOL_GLINK
817  	memset(&ifr, 0, sizeof(ifr));
818  	pcap_strlcpy(ifr.ifr_name, name, sizeof(ifr.ifr_name));
819  	info.cmd = ETHTOOL_GLINK;
820  	info.data = 0;
821  	ifr.ifr_data = (caddr_t)&info;
822  	if (ioctl(sock, SIOCETHTOOL, &ifr) == -1) {
823  		int save_errno = errno;
824  		switch (save_errno) {
825  		case EOPNOTSUPP:
826  		case EINVAL:
827  			*flags |= PCAP_IF_CONNECTION_STATUS_NOT_APPLICABLE;
828  			close(sock);
829  			return 0;
830  		case ENODEV:
831  			close(sock);
832  			return 0;
833  		default:
834  			pcap_fmt_errmsg_for_errno(errbuf, PCAP_ERRBUF_SIZE,
835  			    save_errno,
836  			    "%s: SIOCETHTOOL(ETHTOOL_GLINK) ioctl failed",
837  			    name);
838  			close(sock);
839  			return -1;
840  		}
841  	}
842  	if (info.data) {
843  		*flags |= PCAP_IF_CONNECTION_STATUS_CONNECTED;
844  	} else {
845  		*flags |= PCAP_IF_CONNECTION_STATUS_DISCONNECTED;
846  	}
847  #endif
848  	close(sock);
849  	return 0;
850  }
851  int
852  pcap_platform_finddevs(pcap_if_list_t *devlistp, char *errbuf)
853  {
854  	if (pcap_findalldevs_interfaces(devlistp, errbuf, can_be_bound,
855  	    get_if_flags) == -1)
856  		return (-1);	&bsol;* failure */
857  	if (pcap_add_any_dev(devlistp, errbuf) == NULL)
858  		return (-1);
859  	return (0);
860  }
861  static int
862  pcap_setdirection_linux(pcap_t *handle, pcap_direction_t d)
863  {
864  	handle->direction = d;
865  	return 0;
866  }
867  static int
868  is_wifi(const char *device)
869  {
870  	char *pathstr;
871  	struct stat statb;
872  	if (asprintf(&pathstr, "/sys/class/net/%s/wireless", device) == -1) {
873  		return 0;
874  	}
875  	if (stat(pathstr, &statb) == 0) {
876  		free(pathstr);
877  		return 1;
878  	}
879  	free(pathstr);
880  	return 0;
881  }
882  static int map_arphrd_to_dlt(pcap_t *handle, int arptype,
883  			     const char *device, int cooked_ok)
884  {
885  	static const char cdma_rmnet[] = "cdma_rmnet";
886  	switch (arptype) {
887  	case ARPHRD_ETHER:
888  		if (strncmp(device, cdma_rmnet, sizeof cdma_rmnet - 1) == 0) {
889  			handle->linktype = DLT_RAW;
890  			return 0;
891  		}
892  		if (!is_wifi(device)) {
893  			int ret;
894  			ret = iface_dsa_get_proto_info(device, handle);
895  			if (ret < 0)
896  				return ret;
897  			if (ret == 1) {
898  				handle->offset = 2;
899  				break;
900  			}
901  			handle->dlt_list = (u_int *) malloc(sizeof(u_int) * 2);
902  			if (handle->dlt_list == NULL) {
903  				pcap_fmt_errmsg_for_errno(handle->errbuf,
904  				    PCAP_ERRBUF_SIZE, errno, "malloc");
905  				return (PCAP_ERROR);
906  			}
907  			handle->dlt_list[0] = DLT_EN10MB;
908  			handle->dlt_list[1] = DLT_DOCSIS;
909  			handle->dlt_count = 2;
910  		}
911  	case ARPHRD_METRICOM:
912  	case ARPHRD_LOOPBACK:
913  		handle->linktype = DLT_EN10MB;
914  		handle->offset = 2;
915  		break;
916  	case ARPHRD_EETHER:
917  		handle->linktype = DLT_EN3MB;
918  		break;
919  	case ARPHRD_AX25:
920  		handle->linktype = DLT_AX25_KISS;
921  		break;
922  	case ARPHRD_PRONET:
923  		handle->linktype = DLT_PRONET;
924  		break;
925  	case ARPHRD_CHAOS:
926  		handle->linktype = DLT_CHAOS;
927  		break;
928  #ifndef ARPHRD_CAN
929  #define ARPHRD_CAN 280
930  #endif
931  	case ARPHRD_CAN:
932  		handle->linktype = DLT_CAN_SOCKETCAN;
933  		break;
934  #ifndef ARPHRD_IEEE802_TR
935  #define ARPHRD_IEEE802_TR 800	&bsol;* From Linux 2.4 */
936  #endif
937  	case ARPHRD_IEEE802_TR:
938  	case ARPHRD_IEEE802:
939  		handle->linktype = DLT_IEEE802;
940  		handle->offset = 2;
941  		break;
942  	case ARPHRD_ARCNET:
943  		handle->linktype = DLT_ARCNET_LINUX;
944  		break;
945  #ifndef ARPHRD_FDDI	&bsol;* From Linux 2.2.13 */
946  #define ARPHRD_FDDI	774
947  #endif
948  	case ARPHRD_FDDI:
949  		handle->linktype = DLT_FDDI;
950  		handle->offset = 3;
951  		break;
952  #ifndef ARPHRD_ATM  &bsol;* FIXME: How to #include this? */
953  #define ARPHRD_ATM 19
954  #endif
955  	case ARPHRD_ATM:
956  		if (cooked_ok)
957  			handle->linktype = DLT_LINUX_SLL;
958  		else
959  			handle->linktype = -1;
960  		break;
961  #ifndef ARPHRD_IEEE80211  &bsol;* From Linux 2.4.6 */
962  #define ARPHRD_IEEE80211 801
963  #endif
964  	case ARPHRD_IEEE80211:
965  		handle->linktype = DLT_IEEE802_11;
966  		break;
967  #ifndef ARPHRD_IEEE80211_PRISM  &bsol;* From Linux 2.4.18 */
968  #define ARPHRD_IEEE80211_PRISM 802
969  #endif
970  	case ARPHRD_IEEE80211_PRISM:
971  		handle->linktype = DLT_PRISM_HEADER;
972  		break;
973  #ifndef ARPHRD_IEEE80211_RADIOTAP &bsol;* new */
974  #define ARPHRD_IEEE80211_RADIOTAP 803
975  #endif
976  	case ARPHRD_IEEE80211_RADIOTAP:
977  		handle->linktype = DLT_IEEE802_11_RADIO;
978  		break;
979  	case ARPHRD_PPP:
980  		if (cooked_ok)
981  			handle->linktype = DLT_LINUX_SLL;
982  		else {
983  			handle->linktype = DLT_RAW;
984  		}
985  		break;
986  #ifndef ARPHRD_CISCO
987  #define ARPHRD_CISCO 513 &bsol;* previously ARPHRD_HDLC */
988  #endif
989  	case ARPHRD_CISCO:
990  		handle->linktype = DLT_C_HDLC;
991  		break;
992  	case ARPHRD_TUNNEL:
993  #ifndef ARPHRD_SIT
994  #define ARPHRD_SIT 776	&bsol;* From Linux 2.2.13 */
995  #endif
996  	case ARPHRD_SIT:
997  	case ARPHRD_CSLIP:
998  	case ARPHRD_SLIP6:
999  	case ARPHRD_CSLIP6:
1000  	case ARPHRD_ADAPT:
1001  	case ARPHRD_SLIP:
1002  #ifndef ARPHRD_RAWHDLC
1003  #define ARPHRD_RAWHDLC 518
1004  #endif
1005  	case ARPHRD_RAWHDLC:
1006  #ifndef ARPHRD_DLCI
1007  #define ARPHRD_DLCI 15
1008  #endif
1009  	case ARPHRD_DLCI:
1010  		handle->linktype = DLT_RAW;
1011  		break;
1012  #ifndef ARPHRD_FRAD
1013  #define ARPHRD_FRAD 770
1014  #endif
1015  	case ARPHRD_FRAD:
1016  		handle->linktype = DLT_FRELAY;
1017  		break;
1018  	case ARPHRD_LOCALTLK:
1019  		handle->linktype = DLT_LTALK;
1020  		break;
1021  	case 18:
1022  		handle->linktype = DLT_IP_OVER_FC;
1023  		break;
1024  #ifndef ARPHRD_FCPP
1025  #define ARPHRD_FCPP	784
1026  #endif
1027  	case ARPHRD_FCPP:
1028  #ifndef ARPHRD_FCAL
1029  #define ARPHRD_FCAL	785
1030  #endif
1031  	case ARPHRD_FCAL:
1032  #ifndef ARPHRD_FCPL
1033  #define ARPHRD_FCPL	786
1034  #endif
1035  	case ARPHRD_FCPL:
1036  #ifndef ARPHRD_FCFABRIC
1037  #define ARPHRD_FCFABRIC	787
1038  #endif
1039  	case ARPHRD_FCFABRIC:
1040  		handle->linktype = DLT_FC_2;
1041  		handle->dlt_list = (u_int *) malloc(sizeof(u_int) * 3);
1042  		if (handle->dlt_list == NULL) {
1043  			pcap_fmt_errmsg_for_errno(handle->errbuf,
1044  			    PCAP_ERRBUF_SIZE, errno, "malloc");
1045  			return (PCAP_ERROR);
1046  		}
1047  		handle->dlt_list[0] = DLT_FC_2;
1048  		handle->dlt_list[1] = DLT_FC_2_WITH_FRAME_DELIMS;
1049  		handle->dlt_list[2] = DLT_IP_OVER_FC;
1050  		handle->dlt_count = 3;
1051  		break;
1052  #ifndef ARPHRD_IRDA
1053  #define ARPHRD_IRDA	783
1054  #endif
1055  	case ARPHRD_IRDA:
1056  		handle->linktype = DLT_LINUX_IRDA;
1057  		break;
1058  #ifndef ARPHRD_LAPD
1059  #define ARPHRD_LAPD	8445
1060  #endif
1061  	case ARPHRD_LAPD:
1062  		handle->linktype = DLT_LINUX_LAPD;
1063  		break;
1064  #ifndef ARPHRD_NONE
1065  #define ARPHRD_NONE	0xFFFE
1066  #endif
1067  	case ARPHRD_NONE:
1068  		handle->linktype = DLT_RAW;
1069  		break;
1070  #ifndef ARPHRD_IEEE802154
1071  #define ARPHRD_IEEE802154      804
1072  #endif
1073         case ARPHRD_IEEE802154:
1074                 handle->linktype =  DLT_IEEE802_15_4_NOFCS;
1075                 break;
1076  #ifndef ARPHRD_NETLINK
1077  #define ARPHRD_NETLINK	824
1078  #endif
1079  	case ARPHRD_NETLINK:
1080  		handle->linktype = DLT_NETLINK;
1081  		break;
1082  #ifndef ARPHRD_VSOCKMON
1083  #define ARPHRD_VSOCKMON	826
1084  #endif
1085  	case ARPHRD_VSOCKMON:
1086  		handle->linktype = DLT_VSOCK;
1087  		break;
1088  	default:
1089  		handle->linktype = -1;
1090  		break;
1091  	}
1092  	return (0);
1093  }
1094  static int
1095  setup_socket(pcap_t *handle, int is_any_device)
1096  {
1097  	struct pcap_linux *handlep = handle->priv;
1098  	const char		*device = handle->opt.device;
1099  	int			status = 0;
1100  	int			sock_fd, arptype;
1101  	int			val;
1102  	int			err = 0;
1103  	struct packet_mreq	mr;
1104  #if defined(SO_BPF_EXTENSIONS) && defined(SKF_AD_VLAN_TAG_PRESENT)
1105  	int			bpf_extensions;
1106  	socklen_t		len = sizeof(bpf_extensions);
1107  #endif
1108  	sock_fd = is_any_device ?
1109  		socket(PF_PACKET, SOCK_DGRAM, 0) :
1110  		socket(PF_PACKET, SOCK_RAW, 0);
1111  	if (sock_fd == -1) {
1112  		if (errno == EPERM || errno == EACCES) {
1113  			status = PCAP_ERROR_PERM_DENIED;
1114  			snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1115  			    "Attempt to create packet socket failed - CAP_NET_RAW may be required");
1116  		} else {
1117  			status = PCAP_ERROR;
1118  		}
1119  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
1120  		    errno, "socket");
1121  		return status;
1122  	}
1123  	handlep->lo_ifindex = iface_get_id(sock_fd, "lo", handle->errbuf);
1124  	handle->offset	 = 0;
1125  	if (!is_any_device) {
1126  		handlep->cooked = 0;
1127  		if (handle->opt.rfmon) {
1128  			err = enter_rfmon_mode(handle, sock_fd, device);
1129  			if (err < 0) {
1130  				close(sock_fd);
1131  				return err;
1132  			}
1133  			if (err == 0) {
1134  				close(sock_fd);
1135  				return PCAP_ERROR_RFMON_NOTSUP;
1136  			}
1137  			if (handlep->mondevice != NULL)
1138  				device = handlep->mondevice;
1139  		}
1140  		arptype	= iface_get_arptype(sock_fd, device, handle->errbuf);
1141  		if (arptype < 0) {
1142  			close(sock_fd);
1143  			return arptype;
1144  		}
1145  		status = map_arphrd_to_dlt(handle, arptype, device, 1);
1146  		if (status < 0)
1147  			return status;
1148  		if (handle->linktype == -1 ||
1149  		    handle->linktype == DLT_LINUX_SLL ||
1150  		    handle->linktype == DLT_LINUX_IRDA ||
1151  		    handle->linktype == DLT_LINUX_LAPD ||
1152  		    handle->linktype == DLT_NETLINK ||
1153  		    (handle->linktype == DLT_EN10MB &&
1154  		     (strncmp("isdn", device, 4) == 0 ||
1155  		      strncmp("isdY", device, 4) == 0))) {
1156  			if (close(sock_fd) == -1) {
1157  				pcap_fmt_errmsg_for_errno(handle->errbuf,
1158  				    PCAP_ERRBUF_SIZE, errno, "close");
1159  				return PCAP_ERROR;
1160  			}
1161  			sock_fd = socket(PF_PACKET, SOCK_DGRAM, 0);
1162  			if (sock_fd < 0) {
1163  				pcap_fmt_errmsg_for_errno(handle->errbuf,
1164  				    PCAP_ERRBUF_SIZE, errno, "socket");
1165  				return PCAP_ERROR;
1166  			}
1167  			handlep->cooked = 1;
1168  			if (handle->dlt_list != NULL) {
1169  				free(handle->dlt_list);
1170  				handle->dlt_list = NULL;
1171  				handle->dlt_count = 0;
1172  			}
1173  			if (handle->linktype == -1) {
1174  				snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1175  					"arptype %d not "
1176  					"supported by libpcap - "
1177  					"falling back to cooked "
1178  					"socket",
1179  					arptype);
1180  				status = PCAP_WARNING;
1181  			}
1182  			if (handle->linktype != DLT_LINUX_IRDA &&
1183  			    handle->linktype != DLT_LINUX_LAPD &&
1184  			    handle->linktype != DLT_NETLINK)
1185  				handle->linktype = DLT_LINUX_SLL;
1186  		}
1187  		handlep->ifindex = iface_get_id(sock_fd, device,
1188  		    handle->errbuf);
1189  		if (handlep->ifindex == -1) {
1190  			close(sock_fd);
1191  			return PCAP_ERROR;
1192  		}
1193  		if ((err = iface_bind(sock_fd, handlep->ifindex,
1194  		    handle->errbuf, 0)) != 0) {
1195  			close(sock_fd);
1196  			return err;
1197  		}
1198  	} else {
1199  		if (handle->opt.rfmon) {
1200  			close(sock_fd);
1201  			return PCAP_ERROR_RFMON_NOTSUP;
1202  		}
1203  		handlep->cooked = 1;
1204  		handle->linktype = DLT_LINUX_SLL;
1205  		handle->dlt_list = (u_int *) malloc(sizeof(u_int) * 2);
1206  		if (handle->dlt_list == NULL) {
1207  			pcap_fmt_errmsg_for_errno(handle->errbuf,
1208  			    PCAP_ERRBUF_SIZE, errno, "malloc");
1209  			return (PCAP_ERROR);
1210  		}
1211  		handle->dlt_list[0] = DLT_LINUX_SLL;
1212  		handle->dlt_list[1] = DLT_LINUX_SLL2;
1213  		handle->dlt_count = 2;
1214  		handlep->ifindex = -1;
1215  	}
1216  	if (!is_any_device && handle->opt.promisc) {
1217  		memset(&mr, 0, sizeof(mr));
1218  		mr.mr_ifindex = handlep->ifindex;
1219  		mr.mr_type    = PACKET_MR_PROMISC;
1220  		if (setsockopt(sock_fd, SOL_PACKET, PACKET_ADD_MEMBERSHIP,
1221  		    &mr, sizeof(mr)) == -1) {
1222  			pcap_fmt_errmsg_for_errno(handle->errbuf,
1223  			    PCAP_ERRBUF_SIZE, errno, "setsockopt (PACKET_ADD_MEMBERSHIP)");
1224  			close(sock_fd);
1225  			return PCAP_ERROR;
1226  		}
1227  	}
1228  	val = 1;
1229  	if (setsockopt(sock_fd, SOL_PACKET, PACKET_AUXDATA, &val,
1230  		       sizeof(val)) == -1 && errno != ENOPROTOOPT) {
1231  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
1232  		    errno, "setsockopt (PACKET_AUXDATA)");
1233  		close(sock_fd);
1234  		return PCAP_ERROR;
1235  	}
1236  	handle->offset += VLAN_TAG_LEN;
1237  	if (handlep->cooked) {
1238  		if (handle->snapshot < SLL2_HDR_LEN + 1)
1239  			handle->snapshot = SLL2_HDR_LEN + 1;
1240  	}
1241  	handle->bufsize = handle->snapshot;
1242  	set_vlan_offset(handle);
1243  	if (handle->opt.tstamp_precision == PCAP_TSTAMP_PRECISION_NANO) {
1244  		int nsec_tstamps = 1;
1245  		if (setsockopt(sock_fd, SOL_SOCKET, SO_TIMESTAMPNS, &nsec_tstamps, sizeof(nsec_tstamps)) < 0) {
1246  			snprintf(handle->errbuf, PCAP_ERRBUF_SIZE, "setsockopt: unable to set SO_TIMESTAMPNS");
1247  			close(sock_fd);
1248  			return PCAP_ERROR;
1249  		}
1250  	}
1251  	handle->fd = sock_fd;
1252  #if defined(SO_BPF_EXTENSIONS) && defined(SKF_AD_VLAN_TAG_PRESENT)
1253  	if (getsockopt(sock_fd, SOL_SOCKET, SO_BPF_EXTENSIONS,
1254  	    &bpf_extensions, &len) == 0) {
1255  		if (bpf_extensions >= SKF_AD_VLAN_TAG_PRESENT) {
1256  			handle->bpf_codegen_flags |= BPF_SPECIAL_VLAN_HANDLING;
1257  		}
1258  	}
1259  #endif &bsol;* defined(SO_BPF_EXTENSIONS) && defined(SKF_AD_VLAN_TAG_PRESENT) */
1260  	return status;
1261  }
1262  static int
1263  setup_mmapped(pcap_t *handle)
1264  {
1265  	struct pcap_linux *handlep = handle->priv;
1266  	int flags = MAP_ANONYMOUS | MAP_PRIVATE;
1267  	int status;
1268  #ifdef MAP_32BIT
1269  	if (pcap_mmap_32bit) flags |= MAP_32BIT;
1270  #endif
1271  	handlep->oneshot_buffer = mmap(0, handle->snapshot, PROT_READ | PROT_WRITE, flags, -1, 0);
1272  	if (handlep->oneshot_buffer == MAP_FAILED) {
1273  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
1274  		    errno, "can't allocate oneshot buffer");
1275  		return PCAP_ERROR;
1276  	}
1277  	if (handle->opt.buffer_size == 0) {
1278  		handle->opt.buffer_size = 2*1024*1024;
1279  	}
1280  	status = prepare_tpacket_socket(handle);
1281  	if (status == -1) {
1282  		munmap(handlep->oneshot_buffer, handle->snapshot);
1283  		handlep->oneshot_buffer = NULL;
1284  		return PCAP_ERROR;
1285  	}
1286  	status = create_ring(handle);
1287  	if (status < 0) {
1288  		munmap(handlep->oneshot_buffer, handle->snapshot);
1289  		handlep->oneshot_buffer = NULL;
1290  		return status;
1291  	}
1292  	set_poll_timeout(handlep);
1293  	return status;
1294  }
1295  static int
1296  init_tpacket(pcap_t *handle, int version, const char *version_str)
1297  {
1298  	struct pcap_linux *handlep = handle->priv;
1299  	int val = version;
1300  	socklen_t len = sizeof(val);
1301  	if (getsockopt(handle->fd, SOL_PACKET, PACKET_HDRLEN, &val, &len) < 0) {
1302  		if (errno == EINVAL) {
1303  			return 1;
1304  		}
1305  		if (errno == ENOPROTOOPT) {
1306  			snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1307  			    "Kernel doesn't support memory-mapped capture; a 2.6.27 or later 2.x kernel is required, with CONFIG_PACKET_MMAP specified for 2.x kernels");
1308  		} else {
1309  			pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
1310  			    errno, "can't get %s header len on packet socket",
1311  			    version_str);
1312  		}
1313  		return -1;
1314  	}
1315  	handlep->tp_hdrlen = val;
1316  	val = version;
1317  	if (setsockopt(handle->fd, SOL_PACKET, PACKET_VERSION, &val,
1318  			   sizeof(val)) < 0) {
1319  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
1320  		    errno, "can't activate %s on packet socket", version_str);
1321  		return -1;
1322  	}
1323  	handlep->tp_version = version;
1324  	return 0;
1325  }
1326  static int
1327  prepare_tpacket_socket(pcap_t *handle)
1328  {
1329  	int ret;
1330  #ifdef HAVE_TPACKET3
1331  	if (!handle->opt.immediate) {
1332  		ret = init_tpacket(handle, TPACKET_V3, "TPACKET_V3");
1333  		if (ret == 0) {
1334  			return 0;
1335  		}
1336  		if (ret == -1) {
1337  			return -1;
1338  		}
1339  	}
1340  #endif &bsol;* HAVE_TPACKET3 */
1341  	ret = init_tpacket(handle, TPACKET_V2, "TPACKET_V2");
1342  	if (ret == 0) {
1343  		return 0;
1344  	}
1345  	if (ret == 1) {
1346  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1347  		    "Kernel doesn't support TPACKET_V2; a 2.6.27 or later kernel is required");
1348  	}
1349  	return -1;
1350  }
1351  #define MAX(a,b) ((a)>(b)?(a):(b))
1352  static int
1353  create_ring(pcap_t *handle)
1354  {
1355  	struct pcap_linux *handlep = handle->priv;
1356  	unsigned i, j, frames_per_block;
1357  	int flags = MAP_SHARED;
1358  #ifdef HAVE_TPACKET3
1359  	struct tpacket_req3 req;
1360  #else
1361  	struct tpacket_req req;
1362  #endif
1363  	socklen_t len;
1364  	unsigned int sk_type, tp_reserve, maclen, tp_hdrlen, netoff, macoff;
1365  	unsigned int frame_size;
1366  	int status;
1367  	status = 0;
1368  	tp_reserve = VLAN_TAG_LEN;
1369  	if (handlep->cooked)
1370  		tp_reserve += SLL2_HDR_LEN - 16;
1371  	len = sizeof(tp_reserve);
1372  	if (setsockopt(handle->fd, SOL_PACKET, PACKET_RESERVE,
1373  	    &tp_reserve, len) < 0) {
1374  		pcap_fmt_errmsg_for_errno(handle->errbuf,
1375  		    PCAP_ERRBUF_SIZE, errno,
1376  		    "setsockopt (PACKET_RESERVE)");
1377  		return PCAP_ERROR;
1378  	}
1379  	switch (handlep->tp_version) {
1380  	case TPACKET_V2:
1381  		frame_size = handle->snapshot;
1382  		if (handle->linktype == DLT_EN10MB) {
1383  			unsigned int max_frame_len;
1384  			int mtu;
1385  			int offload;
1386  			mtu = iface_get_mtu(handle->fd, handle->opt.device,
1387  			    handle->errbuf);
1388  			if (mtu == -1)
1389  				return PCAP_ERROR;
1390  			offload = iface_get_offload(handle);
1391  			if (offload == -1)
1392  				return PCAP_ERROR;
1393  			if (offload)
1394  				max_frame_len = MAX(mtu, 65535);
1395  			else
1396  				max_frame_len = mtu;
1397  			max_frame_len += 18;
1398  			if (frame_size > max_frame_len)
1399  				frame_size = max_frame_len;
1400  		}
1401  		len = sizeof(sk_type);
1402  		if (getsockopt(handle->fd, SOL_SOCKET, SO_TYPE, &sk_type,
1403  		    &len) < 0) {
1404  			pcap_fmt_errmsg_for_errno(handle->errbuf,
1405  			    PCAP_ERRBUF_SIZE, errno, "getsockopt (SO_TYPE)");
1406  			return PCAP_ERROR;
1407  		}
1408  		maclen = (sk_type == SOCK_DGRAM) ? 0 : MAX_LINKHEADER_SIZE;
1409  		tp_hdrlen = TPACKET_ALIGN(handlep->tp_hdrlen) + sizeof(struct sockaddr_ll) ;
1410  		netoff = TPACKET_ALIGN(tp_hdrlen + (maclen < 16 ? 16 : maclen)) + tp_reserve;
1411  		macoff = netoff - maclen;
1412  		req.tp_frame_size = TPACKET_ALIGN(macoff + frame_size);
1413  		req.tp_frame_nr = (handle->opt.buffer_size + req.tp_frame_size - 1)/req.tp_frame_size;
1414  		break;
1415  #ifdef HAVE_TPACKET3
1416  	case TPACKET_V3:
1417  		req.tp_frame_size = MAXIMUM_SNAPLEN;
1418  		req.tp_frame_nr = (handle->opt.buffer_size + req.tp_frame_size - 1)/req.tp_frame_size;
1419  		break;
1420  #endif
1421  	default:
1422  		snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1423  		    "Internal error: unknown TPACKET_ value %u",
1424  		    handlep->tp_version);
1425  		return PCAP_ERROR;
1426  	}
1427  	req.tp_block_size = getpagesize();
1428  	while (req.tp_block_size < req.tp_frame_size)
1429  		req.tp_block_size <<= 1;
1430  	frames_per_block = req.tp_block_size/req.tp_frame_size;
1431  #if defined(HAVE_LINUX_NET_TSTAMP_H) && defined(PACKET_TIMESTAMP)
1432  	if (handle->opt.tstamp_type == PCAP_TSTAMP_ADAPTER ||
1433  	    handle->opt.tstamp_type == PCAP_TSTAMP_ADAPTER_UNSYNCED) {
1434  		struct hwtstamp_config hwconfig;
1435  		struct ifreq ifr;
1436  		int timesource;
1437  		memset(&hwconfig, 0, sizeof(hwconfig));
1438  		hwconfig.tx_type = HWTSTAMP_TX_ON;
1439  		hwconfig.rx_filter = HWTSTAMP_FILTER_ALL;
1440  		memset(&ifr, 0, sizeof(ifr));
1441  		pcap_strlcpy(ifr.ifr_name, handle->opt.device, sizeof(ifr.ifr_name));
1442  		ifr.ifr_data = (void *)&hwconfig;
1443  		if (ioctl(handle->fd, SIOCSHWTSTAMP, &ifr) < 0) {
1444  			switch (errno) {
1445  			case EPERM:
1446  				snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1447  				    "Attempt to set hardware timestamp failed - CAP_NET_ADMIN may be required");
1448  				return PCAP_ERROR_PERM_DENIED;
1449  			case EOPNOTSUPP:
1450  			case ERANGE:
1451  				status = PCAP_WARNING_TSTAMP_TYPE_NOTSUP;
1452  				break;
1453  			default:
1454  				pcap_fmt_errmsg_for_errno(handle->errbuf,
1455  				    PCAP_ERRBUF_SIZE, errno,
1456  				    "SIOCSHWTSTAMP failed");
1457  				return PCAP_ERROR;
1458  			}
1459  		} else {
1460  			if (handle->opt.tstamp_type == PCAP_TSTAMP_ADAPTER) {
1461  				timesource = SOF_TIMESTAMPING_SYS_HARDWARE;
1462  			} else {
1463  				timesource = SOF_TIMESTAMPING_RAW_HARDWARE;
1464  			}
1465  			if (setsockopt(handle->fd, SOL_PACKET, PACKET_TIMESTAMP,
1466  				(void *)&timesource, sizeof(timesource))) {
1467  				pcap_fmt_errmsg_for_errno(handle->errbuf,
1468  				    PCAP_ERRBUF_SIZE, errno,
1469  				    "can't set PACKET_TIMESTAMP");
1470  				return PCAP_ERROR;
1471  			}
1472  		}
1473  	}
1474  #endif &bsol;* HAVE_LINUX_NET_TSTAMP_H && PACKET_TIMESTAMP */
1475  retry:
1476  	req.tp_block_nr = req.tp_frame_nr / frames_per_block;
1477  	req.tp_frame_nr = req.tp_block_nr * frames_per_block;
1478  #ifdef HAVE_TPACKET3
1479  	if (handlep->timeout > 0) {
1480  		req.tp_retire_blk_tov = handlep->timeout;
1481  	} else if (handlep->timeout == 0) {
1482  		req.tp_retire_blk_tov = UINT_MAX;
1483  	} else {
1484  		req.tp_retire_blk_tov = 0;
1485  	}
1486  	req.tp_sizeof_priv = 0;
1487  	req.tp_feature_req_word = 0;
1488  #endif
1489  	if (setsockopt(handle->fd, SOL_PACKET, PACKET_RX_RING,
1490  					(void *) &req, sizeof(req))) {
1491  		if ((errno == ENOMEM) && (req.tp_block_nr > 1)) {
1492  			if (req.tp_frame_nr < 20)
1493  				req.tp_frame_nr -= 1;
1494  			else
1495  				req.tp_frame_nr -= req.tp_frame_nr/20;
1496  			goto retry;
1497  		}
1498  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
1499  		    errno, "can't create rx ring on packet socket");
1500  		return PCAP_ERROR;
1501  	}
1502  	handlep->mmapbuflen = req.tp_block_nr * req.tp_block_size;
1503  #ifdef MAP_32BIT
1504  	if (pcap_mmap_32bit) flags |= MAP_32BIT;
1505  #endif
1506  	handlep->mmapbuf = mmap(0, handlep->mmapbuflen, PROT_READ | PROT_WRITE, flags, handle->fd, 0);
1507  	if (handlep->mmapbuf == MAP_FAILED) {
1508  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
1509  		    errno, "can't mmap rx ring");
1510  		destroy_ring(handle);
1511  		return PCAP_ERROR;
1512  	}
1513  	handle->cc = req.tp_frame_nr;
1514  	handle->buffer = malloc(handle->cc * sizeof(union thdr *));
1515  	if (!handle->buffer) {
1516  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
1517  		    errno, "can't allocate ring of frame headers");
1518  		destroy_ring(handle);
1519  		return PCAP_ERROR;
1520  	}
1521  	handle->offset = 0;
1522  	for (i=0; i<req.tp_block_nr; ++i) {
1523  		u_char *base = &handlep->mmapbuf[i*req.tp_block_size];
1524  		for (j=0; j<frames_per_block; ++j, ++handle->offset) {
1525  			RING_GET_CURRENT_FRAME(handle) = base;
1526  			base += req.tp_frame_size;
1527  		}
1528  	}
1529  	handle->bufsize = req.tp_frame_size;
1530  	handle->offset = 0;
1531  	return status;
1532  }
1533  static void
1534  destroy_ring(pcap_t *handle)
1535  {
1536  	struct pcap_linux *handlep = handle->priv;
1537  	struct tpacket_req req;
1538  	memset(&req, 0, sizeof(req));
1539  	(void)setsockopt(handle->fd, SOL_PACKET, PACKET_RX_RING,
1540  				(void *) &req, sizeof(req));
1541  	if (handlep->mmapbuf) {
1542  		(void)munmap(handlep->mmapbuf, handlep->mmapbuflen);
1543  		handlep->mmapbuf = NULL;
1544  	}
1545  }
1546  static void
1547  pcap_oneshot_linux(u_char *user, const struct pcap_pkthdr *h,
1548      const u_char *bytes)
1549  {
1550  	struct oneshot_userdata *sp = (struct oneshot_userdata *)user;
1551  	pcap_t *handle = sp->pd;
1552  	struct pcap_linux *handlep = handle->priv;
1553  	*sp->hdr = *h;
1554  	memcpy(handlep->oneshot_buffer, bytes, h->caplen);
1555  	*sp->pkt = handlep->oneshot_buffer;
1556  }
1557  static int
1558  pcap_getnonblock_linux(pcap_t *handle)
1559  {
1560  	struct pcap_linux *handlep = handle->priv;
1561  	return (handlep->timeout<0);
1562  }
1563  static int
1564  pcap_setnonblock_linux(pcap_t *handle, int nonblock)
1565  {
1566  	struct pcap_linux *handlep = handle->priv;
1567  	if (pcap_setnonblock_fd(handle, nonblock) == -1)
1568  		return -1;
1569  	if (nonblock) {
1570  		if (handlep->timeout >= 0) {
1571  			handlep->timeout = ~handlep->timeout;
1572  		}
1573  		if (handlep->poll_breakloop_fd != -1) {
1574  			close(handlep->poll_breakloop_fd);
1575  			handlep->poll_breakloop_fd = -1;
1576  		}
1577  	} else {
1578  		if (handlep->poll_breakloop_fd == -1) {
1579  			if ( ( handlep->poll_breakloop_fd = eventfd(0, EFD_NONBLOCK) ) == -1 ) {
1580  				int save_errno = errno;
1581  				snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1582  						"Could not open eventfd: %s",
1583  						strerror(errno));
1584  				errno = save_errno;
1585  				return -1;
1586  			}
1587  		}
1588  		if (handlep->timeout < 0) {
1589  			handlep->timeout = ~handlep->timeout;
1590  		}
1591  	}
1592  	set_poll_timeout(handlep);
1593  	return 0;
1594  }
1595  static inline u_int
1596  pcap_get_ring_frame_status(pcap_t *handle, int offset)
1597  {
1598  	struct pcap_linux *handlep = handle->priv;
1599  	union thdr h;
1600  	h.raw = RING_GET_FRAME_AT(handle, offset);
1601  	switch (handlep->tp_version) {
1602  	case TPACKET_V2:
1603  		return __atomic_load_n(&h.h2->tp_status, __ATOMIC_ACQUIRE);
1604  		break;
1605  #ifdef HAVE_TPACKET3
1606  	case TPACKET_V3:
1607  		return __atomic_load_n(&h.h3->hdr.bh1.block_status, __ATOMIC_ACQUIRE);
1608  		break;
1609  #endif
1610  	}
1611  	return 0;
1612  }
1613  static int pcap_wait_for_frames_mmap(pcap_t *handle)
1614  {
1615  	struct pcap_linux *handlep = handle->priv;
1616  	int timeout;
1617  	struct ifreq ifr;
1618  	int ret;
1619  	struct pollfd pollinfo[2];
1620  	int numpollinfo;
1621  	pollinfo[0].fd = handle->fd;
1622  	pollinfo[0].events = POLLIN;
1623  	if ( handlep->poll_breakloop_fd == -1 ) {
1624  		numpollinfo = 1;
1625  		pollinfo[1].revents = 0;
1626  	} else {
1627  		pollinfo[1].fd = handlep->poll_breakloop_fd;
1628  		pollinfo[1].events = POLLIN;
1629  		numpollinfo = 2;
1630  	}
1631  	for (;;) {
1632  		timeout = handlep->poll_timeout;
1633  		if (handlep->netdown) {
1634  			if (timeout != 0)
1635  				timeout = 1;
1636  		}
1637  		ret = poll(pollinfo, numpollinfo, timeout);
1638  		if (ret < 0) {
1639  			if (errno != EINTR) {
1640  				pcap_fmt_errmsg_for_errno(handle->errbuf,
1641  				    PCAP_ERRBUF_SIZE, errno,
1642  				    "can't poll on packet socket");
1643  				return PCAP_ERROR;
1644  			}
1645  			if (handle->break_loop) {
1646  				handle->break_loop = 0;
1647  				return PCAP_ERROR_BREAK;
1648  			}
1649  		} else if (ret > 0) {
1650  			if (pollinfo[0].revents == POLLIN) {
1651  				break;
1652  			}
1653  			if (pollinfo[0].revents != 0) {
1654  				if (pollinfo[0].revents & POLLNVAL) {
1655  					snprintf(handle->errbuf,
1656  					    PCAP_ERRBUF_SIZE,
1657  					    "Invalid polling request on packet socket");
1658  					return PCAP_ERROR;
1659  				}
1660  				if (pollinfo[0].revents & (POLLHUP | POLLRDHUP)) {
1661  					snprintf(handle->errbuf,
1662  					    PCAP_ERRBUF_SIZE,
1663  					    "Hangup on packet socket");
1664  					return PCAP_ERROR;
1665  				}
1666  				if (pollinfo[0].revents & POLLERR) {
1667  					int err;
1668  					socklen_t errlen;
1669  					errlen = sizeof(err);
1670  					if (getsockopt(handle->fd, SOL_SOCKET,
1671  					    SO_ERROR, &err, &errlen) == -1) {
1672  						err = errno;
1673  					}
1674  					if (err == ENETDOWN) {
1675  						handlep->netdown = 1;
1676  						handle->required_select_timeout = &netdown_timeout;
1677  					} else if (err == 0) {
1678  						snprintf(handle->errbuf,
1679  						    PCAP_ERRBUF_SIZE,
1680  						    "Error condition on packet socket: Reported error was 0");
1681  						return PCAP_ERROR;
1682  					} else {
1683  						pcap_fmt_errmsg_for_errno(handle->errbuf,
1684  						    PCAP_ERRBUF_SIZE,
1685  						    err,
1686  						    "Error condition on packet socket");
1687  						return PCAP_ERROR;
1688  					}
1689  				}
1690  			}
1691  			if (pollinfo[1].revents & POLLIN) {
1692  				ssize_t nread;
1693  				uint64_t value;
1694  				nread = read(handlep->poll_breakloop_fd, &value,
1695  				    sizeof(value));
1696  				if (nread == -1) {
1697  					pcap_fmt_errmsg_for_errno(handle->errbuf,
1698  					    PCAP_ERRBUF_SIZE,
1699  					    errno,
1700  					    "Error reading from event FD");
1701  					return PCAP_ERROR;
1702  				}
1703  				if (nread != 0 &&
1704  				    (size_t)nread < sizeof(value)) {
1705  					snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1706  					    "Short read from event FD: expected %zu, got %zd",
1707  					    sizeof(value), nread);
1708  					return PCAP_ERROR;
1709  				}
1710  				if (handle->break_loop) {
1711  					handle->break_loop = 0;
1712  					return PCAP_ERROR_BREAK;
1713  				}
1714  			}
1715  		}
1716  		if (handlep->netdown) {
1717  			if (!device_still_exists(handle)) {
1718  				snprintf(handle->errbuf,  PCAP_ERRBUF_SIZE,
1719  				    "The interface disappeared");
1720  				return PCAP_ERROR;
1721  			}
1722  			memset(&ifr, 0, sizeof(ifr));
1723  			pcap_strlcpy(ifr.ifr_name, handlep->device,
1724  			    sizeof(ifr.ifr_name));
1725  			if (ioctl(handle->fd, SIOCGIFFLAGS, &ifr) == -1) {
1726  				if (errno == ENXIO || errno == ENODEV) {
1727  					snprintf(handle->errbuf,
1728  					    PCAP_ERRBUF_SIZE,
1729  					    "The interface disappeared");
1730  					return PCAP_ERROR;
1731  				} else {
1732  					pcap_fmt_errmsg_for_errno(handle->errbuf,
1733  					    PCAP_ERRBUF_SIZE, errno,
1734  					    "%s: Can't get flags",
1735  					    handlep->device);
1736  					return PCAP_ERROR;
1737  				}
1738  			}
1739  			if (ifr.ifr_flags & IFF_UP) {
1740  				handlep->netdown = 0;
1741  				handle->required_select_timeout = NULL;
1742  			}
1743  		}
1744  		if (handlep->poll_timeout == 0)
1745  			break;
1746  	}
1747  	return 0;
1748  }
1749  static int pcap_handle_packet_mmap(
1750  		pcap_t *handle,
1751  		pcap_handler callback,
1752  		u_char *user,
1753  		unsigned char *frame,
1754  		unsigned int tp_len,
1755  		unsigned int tp_mac,
1756  		unsigned int tp_snaplen,
1757  		unsigned int tp_sec,
1758  		unsigned int tp_usec,
1759  		int tp_vlan_tci_valid,
1760  		__u16 tp_vlan_tci,
1761  		__u16 tp_vlan_tpid)
1762  {
1763  	struct pcap_linux *handlep = handle->priv;
1764  	unsigned char *bp;
1765  	struct sockaddr_ll *sll;
1766  	struct pcap_pkthdr pcaphdr;
1767  	pcap_can_socketcan_hdr *canhdr;
1768  	unsigned int snaplen = tp_snaplen;
1769  	struct utsname utsname;
1770  	if (tp_mac + tp_snaplen > handle->bufsize) {
1771  		if (uname(&utsname) != -1) {
1772  			snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1773  				"corrupted frame on kernel ring mac "
1774  				"offset %u + caplen %u > frame len %d "
1775  				"(kernel %.32s version %s, machine %.16s)",
1776  				tp_mac, tp_snaplen, handle->bufsize,
1777  				utsname.release, utsname.version,
1778  				utsname.machine);
1779  		} else {
1780  			snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1781  				"corrupted frame on kernel ring mac "
1782  				"offset %u + caplen %u > frame len %d",
1783  				tp_mac, tp_snaplen, handle->bufsize);
1784  		}
1785  		return -1;
1786  	}
1787  	bp = frame + tp_mac;
1788  	sll = (void *)(frame + TPACKET_ALIGN(handlep->tp_hdrlen));
1789  	if (handlep->cooked) {
1790  		if (handle->linktype == DLT_LINUX_SLL2) {
1791  			struct sll2_header *hdrp;
1792  			bp -= SLL2_HDR_LEN;
1793  			if (bp < (u_char *)frame +
1794  					   TPACKET_ALIGN(handlep->tp_hdrlen) +
1795  					   sizeof(struct sockaddr_ll)) {
1796  				snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1797  					"cooked-mode frame doesn't have room for sll header");
1798  				return -1;
1799  			}
1800  			hdrp = (struct sll2_header *)bp;
1801  			hdrp->sll2_protocol = sll->sll_protocol;
1802  			hdrp->sll2_reserved_mbz = 0;
1803  			hdrp->sll2_if_index = htonl(sll->sll_ifindex);
1804  			hdrp->sll2_hatype = htons(sll->sll_hatype);
1805  			hdrp->sll2_pkttype = sll->sll_pkttype;
1806  			hdrp->sll2_halen = sll->sll_halen;
1807  			memcpy(hdrp->sll2_addr, sll->sll_addr, SLL_ADDRLEN);
1808  			snaplen += sizeof(struct sll2_header);
1809  		} else {
1810  			struct sll_header *hdrp;
1811  			bp -= SLL_HDR_LEN;
1812  			if (bp < (u_char *)frame +
1813  					   TPACKET_ALIGN(handlep->tp_hdrlen) +
1814  					   sizeof(struct sockaddr_ll)) {
1815  				snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
1816  					"cooked-mode frame doesn't have room for sll header");
1817  				return -1;
1818  			}
1819  			hdrp = (struct sll_header *)bp;
1820  			hdrp->sll_pkttype = htons(sll->sll_pkttype);
1821  			hdrp->sll_hatype = htons(sll->sll_hatype);
1822  			hdrp->sll_halen = htons(sll->sll_halen);
1823  			memcpy(hdrp->sll_addr, sll->sll_addr, SLL_ADDRLEN);
1824  			hdrp->sll_protocol = sll->sll_protocol;
1825  			snaplen += sizeof(struct sll_header);
1826  		}
1827  	} else {
1828  		if (sll->sll_hatype == ARPHRD_CAN) {
1829  			canhdr = (pcap_can_socketcan_hdr *)bp;
1830  			canhdr->can_id = htonl(canhdr->can_id);
1831  			uint16_t protocol = ntohs(sll->sll_protocol);
1832  			if (protocol == LINUX_SLL_P_CANFD) {
1833  				canhdr->fd_flags |= CANFD_FDF;
1834  				canhdr->fd_flags &= ~(CANFD_FDF|CANFD_ESI|CANFD_BRS);
1835  				canhdr->reserved1 = 0;
1836  				canhdr->reserved2 = 0;
1837  			} else {
1838  				canhdr->fd_flags &= ~CANFD_FDF;
1839  			}
1840  		}
1841  	}
1842  	if (handlep->filter_in_userland && handle->fcode.bf_insns) {
1843  		struct pcap_bpf_aux_data aux_data;
1844  		aux_data.vlan_tag_present = tp_vlan_tci_valid;
1845  		aux_data.vlan_tag = tp_vlan_tci & 0x0fff;
1846  		if (pcap_filter_with_aux_data(handle->fcode.bf_insns,
1847  					      bp,
1848  					      tp_len,
1849  					      snaplen,
1850  					      &aux_data) == 0)
1851  			return 0;
1852  	}
1853  	if (!linux_check_direction(handle, sll))
1854  		return 0;
1855  	pcaphdr.ts.tv_sec = tp_sec;
1856  	pcaphdr.ts.tv_usec = tp_usec;
1857  	pcaphdr.caplen = tp_snaplen;
1858  	pcaphdr.len = tp_len;
1859  	if (handlep->cooked) {
1860  		if (handle->linktype == DLT_LINUX_SLL2) {
1861  			pcaphdr.caplen += SLL2_HDR_LEN;
1862  			pcaphdr.len += SLL2_HDR_LEN;
1863  		} else {
1864  			pcaphdr.caplen += SLL_HDR_LEN;
1865  			pcaphdr.len += SLL_HDR_LEN;
1866  		}
1867  	}
1868  	if (tp_vlan_tci_valid &&
1869  		handlep->vlan_offset != -1 &&
1870  		tp_snaplen >= (unsigned int) handlep->vlan_offset)
1871  	{
1872  		struct vlan_tag *tag;
1873  		bp -= VLAN_TAG_LEN;
1874  		memmove(bp, bp + VLAN_TAG_LEN, handlep->vlan_offset);
1875  		tag = (struct vlan_tag *)(bp + handlep->vlan_offset);
1876  		tag->vlan_tpid = htons(tp_vlan_tpid);
1877  		tag->vlan_tci = htons(tp_vlan_tci);
1878  		pcaphdr.caplen += VLAN_TAG_LEN;
1879  		pcaphdr.len += VLAN_TAG_LEN;
1880  	}
1881  	if (pcaphdr.caplen > (bpf_u_int32)handle->snapshot)
1882  		pcaphdr.caplen = handle->snapshot;
1883  	callback(user, &pcaphdr, bp);
1884  	return 1;
1885  }
1886  static int
1887  pcap_read_linux_mmap_v2(pcap_t *handle, int max_packets, pcap_handler callback,
1888  		u_char *user)
1889  {
1890  	struct pcap_linux *handlep = handle->priv;
1891  	union thdr h;
1892  	int pkts = 0;
1893  	int ret;
1894  	h.raw = RING_GET_CURRENT_FRAME(handle);
1895  	if (!packet_mmap_acquire(h.h2)) {
1896  		ret = pcap_wait_for_frames_mmap(handle);
1897  		if (ret) {
1898  			return ret;
1899  		}
1900  	}
1901  	if (PACKET_COUNT_IS_UNLIMITED(max_packets))
1902  		max_packets = INT_MAX;
1903  	while (pkts < max_packets) {
1904  		h.raw = RING_GET_CURRENT_FRAME(handle);
1905  		if (!packet_mmap_acquire(h.h2))
1906  			break;
1907  		ret = pcap_handle_packet_mmap(
1908  				handle,
1909  				callback,
1910  				user,
1911  				h.raw,
1912  				h.h2->tp_len,
1913  				h.h2->tp_mac,
1914  				h.h2->tp_snaplen,
1915  				h.h2->tp_sec,
1916  				handle->opt.tstamp_precision == PCAP_TSTAMP_PRECISION_NANO ? h.h2->tp_nsec : h.h2->tp_nsec / 1000,
1917  				VLAN_VALID(h.h2, h.h2),
1918  				h.h2->tp_vlan_tci,
1919  				VLAN_TPID(h.h2, h.h2));
1920  		if (ret == 1) {
1921  			pkts++;
1922  		} else if (ret < 0) {
1923  			return ret;
1924  		}
1925  		packet_mmap_release(h.h2);
1926  		if (handlep->blocks_to_filter_in_userland > 0) {
1927  			handlep->blocks_to_filter_in_userland--;
1928  			if (handlep->blocks_to_filter_in_userland == 0) {
1929  				handlep->filter_in_userland = 0;
1930  			}
1931  		}
1932  		if (++handle->offset >= handle->cc)
1933  			handle->offset = 0;
1934  		if (handle->break_loop) {
1935  			handle->break_loop = 0;
1936  			return PCAP_ERROR_BREAK;
1937  		}
1938  	}
1939  	return pkts;
1940  }
1941  #ifdef HAVE_TPACKET3
1942  static int
1943  pcap_read_linux_mmap_v3(pcap_t *handle, int max_packets, pcap_handler callback,
1944  		u_char *user)
1945  {
1946  	struct pcap_linux *handlep = handle->priv;
1947  	union thdr h;
1948  	int pkts = 0;
1949  	int ret;
1950  again:
1951  	if (handlep->current_packet == NULL) {
1952  		h.raw = RING_GET_CURRENT_FRAME(handle);
1953  		if (!packet_mmap_v3_acquire(h.h3)) {
1954  			ret = pcap_wait_for_frames_mmap(handle);
1955  			if (ret) {
1956  				return ret;
1957  			}
1958  		}
1959  	}
1960  	h.raw = RING_GET_CURRENT_FRAME(handle);
1961  	if (!packet_mmap_v3_acquire(h.h3)) {
1962  		if (pkts == 0 && handlep->timeout == 0) {
1963  			goto again;
1964  		}
1965  		return pkts;
1966  	}
1967  	if (PACKET_COUNT_IS_UNLIMITED(max_packets))
1968  		max_packets = INT_MAX;
1969  	while (pkts < max_packets) {
1970  		int packets_to_read;
1971  		if (handlep->current_packet == NULL) {
1972  			h.raw = RING_GET_CURRENT_FRAME(handle);
1973  			if (!packet_mmap_v3_acquire(h.h3))
1974  				break;
1975  			handlep->current_packet = h.raw + h.h3->hdr.bh1.offset_to_first_pkt;
1976  			handlep->packets_left = h.h3->hdr.bh1.num_pkts;
1977  		}
1978  		packets_to_read = handlep->packets_left;
1979  		if (packets_to_read > (max_packets - pkts)) {
1980  			packets_to_read = max_packets - pkts;
1981  		}
1982  		while (packets_to_read-- && !handle->break_loop) {
1983  			struct tpacket3_hdr* tp3_hdr = (struct tpacket3_hdr*) handlep->current_packet;
1984  			ret = pcap_handle_packet_mmap(
1985  					handle,
1986  					callback,
1987  					user,
1988  					handlep->current_packet,
1989  					tp3_hdr->tp_len,
1990  					tp3_hdr->tp_mac,
1991  					tp3_hdr->tp_snaplen,
1992  					tp3_hdr->tp_sec,
1993  					handle->opt.tstamp_precision == PCAP_TSTAMP_PRECISION_NANO ? tp3_hdr->tp_nsec : tp3_hdr->tp_nsec / 1000,
1994  					VLAN_VALID(tp3_hdr, &tp3_hdr->hv1),
1995  					tp3_hdr->hv1.tp_vlan_tci,
1996  					VLAN_TPID(tp3_hdr, &tp3_hdr->hv1));
1997  			if (ret == 1) {
1998  				pkts++;
1999  			} else if (ret < 0) {
2000  				handlep->current_packet = NULL;
2001  				return ret;
2002  			}
2003  			handlep->current_packet += tp3_hdr->tp_next_offset;
2004  			handlep->packets_left--;
2005  		}
2006  		if (handlep->packets_left <= 0) {
2007  			packet_mmap_v3_release(h.h3);
2008  			if (handlep->blocks_to_filter_in_userland > 0) {
2009  				handlep->blocks_to_filter_in_userland--;
2010  				if (handlep->blocks_to_filter_in_userland == 0) {
2011  					handlep->filter_in_userland = 0;
2012  				}
2013  			}
2014  			if (++handle->offset >= handle->cc)
2015  				handle->offset = 0;
2016  			handlep->current_packet = NULL;
2017  		}
2018  		if (handle->break_loop) {
2019  			handle->break_loop = 0;
2020  			return PCAP_ERROR_BREAK;
2021  		}
2022  	}
2023  	if (pkts == 0 && handlep->timeout == 0) {
2024  		goto again;
2025  	}
2026  	return pkts;
2027  }
2028  #endif &bsol;* HAVE_TPACKET3 */
2029  static int
2030  pcap_setfilter_linux(pcap_t *handle, struct bpf_program *filter)
2031  {
2032  	struct pcap_linux *handlep;
2033  	struct sock_fprog	fcode;
2034  	int			can_filter_in_kernel;
2035  	int			err = 0;
2036  	int			n, offset;
2037  	if (!handle)
2038  		return -1;
2039  	if (!filter) {
2040  	        pcap_strlcpy(handle->errbuf, "setfilter: No filter specified",
2041  			PCAP_ERRBUF_SIZE);
2042  		return -1;
2043  	}
2044  	handlep = handle->priv;
2045  	if (pcap_install_bpf_program(handle, filter) < 0)
2046  		return -1;
2047  	handlep->filter_in_userland = 1;
2048  #ifdef USHRT_MAX
2049  	if (handle->fcode.bf_len > USHRT_MAX) {
2050  		fprintf(stderr, "Warning: Filter too complex for kernel\n");
2051  		fcode.len = 0;
2052  		fcode.filter = NULL;
2053  		can_filter_in_kernel = 0;
2054  	} else
2055  #endif &bsol;* USHRT_MAX */
2056  	{
2057  		switch (fix_program(handle, &fcode)) {
2058  		case -1:
2059  		default:
2060  			return -1;
2061  		case 0:
2062  			can_filter_in_kernel = 0;
2063  			break;
2064  		case 1:
2065  			can_filter_in_kernel = 1;
2066  			break;
2067  		}
2068  	}
2069  	if (can_filter_in_kernel) {
2070  		if ((err = set_kernel_filter(handle, &fcode)) == 0)
2071  		{
2072  			handlep->filter_in_userland = 0;
2073  		}
2074  		else if (err == -1)	&bsol;* Non-fatal error */
2075  		{
2076  			if (errno == ENOMEM) {
2077  				fprintf(stderr,
2078  				    "Warning: Couldn't allocate kernel memory for filter: try increasing net.core.optmem_max with sysctl\n");
2079  			} else if (errno != ENOPROTOOPT && errno != EOPNOTSUPP) {
2080  				fprintf(stderr,
2081  				    "Warning: Kernel filter failed: %s\n",
2082  					pcap_strerror(errno));
2083  			}
2084  		}
2085  	}
2086  	if (handlep->filter_in_userland) {
2087  		if (reset_kernel_filter(handle) == -1) {
2088  			pcap_fmt_errmsg_for_errno(handle->errbuf,
2089  			    PCAP_ERRBUF_SIZE, errno,
2090  			    "can't remove kernel filter");
2091  			err = -2;	&bsol;* fatal error */
2092  		}
2093  	}
2094  	if (fcode.filter != NULL)
2095  		free(fcode.filter);
2096  	if (err == -2)
2097  		return -1;
2098  	if (handlep->filter_in_userland)
2099  		return 0;
2100  	offset = handle->offset;
2101  	if (--offset < 0)
2102  		offset = handle->cc - 1;
2103  	for (n=0; n < handle->cc; ++n) {
2104  		if (--offset < 0)
2105  			offset = handle->cc - 1;
2106  		if (pcap_get_ring_frame_status(handle, offset) != TP_STATUS_KERNEL)
2107  			break;
2108  	}
2109  	if (n != 0)
2110  		n--;
2111  	handlep->blocks_to_filter_in_userland = handle->cc - n;
2112  	handlep->filter_in_userland = 1;
2113  	return 0;
2114  }
2115  static int
2116  iface_get_id(int fd, const char *device, char *ebuf)
2117  {
2118  	struct ifreq	ifr;
2119  	memset(&ifr, 0, sizeof(ifr));
2120  	pcap_strlcpy(ifr.ifr_name, device, sizeof(ifr.ifr_name));
2121  	if (ioctl(fd, SIOCGIFINDEX, &ifr) == -1) {
2122  		pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
2123  		    errno, "SIOCGIFINDEX");
2124  		return -1;
2125  	}
2126  	return ifr.ifr_ifindex;
2127  }
2128  static int
2129  iface_bind(int fd, int ifindex, char *ebuf, int protocol)
2130  {
2131  	struct sockaddr_ll	sll;
2132  	int			ret, err;
2133  	socklen_t		errlen = sizeof(err);
2134  	memset(&sll, 0, sizeof(sll));
2135  	sll.sll_family		= AF_PACKET;
2136  	sll.sll_ifindex		= ifindex < 0 ? 0 : ifindex;
2137  	sll.sll_protocol	= protocol;
2138  	if (bind(fd, (struct sockaddr *) &sll, sizeof(sll)) == -1) {
2139  		if (errno == ENETDOWN) {
2140  			return PCAP_ERROR_IFACE_NOT_UP;
2141  		}
2142  		if (errno == ENODEV) {
2143  			ebuf[0] = '\0';
2144  			ret = PCAP_ERROR_NO_SUCH_DEVICE;
2145  		} else {
2146  			ret = PCAP_ERROR;
2147  			pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
2148  			    errno, "bind");
2149  		}
2150  		return ret;
2151  	}
2152  	if (getsockopt(fd, SOL_SOCKET, SO_ERROR, &err, &errlen) == -1) {
2153  		pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
2154  		    errno, "getsockopt (SO_ERROR)");
2155  		return PCAP_ERROR;
2156  	}
2157  	if (err == ENETDOWN) {
2158  		return PCAP_ERROR_IFACE_NOT_UP;
2159  	} else if (err > 0) {
2160  		pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
2161  		    err, "bind");
2162  		return PCAP_ERROR;
2163  	}
2164  	return 0;
2165  }
2166  #ifdef HAVE_LIBNL
2167  static int
2168  enter_rfmon_mode(pcap_t *handle, int sock_fd, const char *device)
2169  {
2170  	struct pcap_linux *handlep = handle->priv;
2171  	int ret;
2172  	char phydev_path[PATH_MAX+1];
2173  	struct nl80211_state nlstate;
2174  	struct ifreq ifr;
2175  	u_int n;
2176  	ret = get_mac80211_phydev(handle, device, phydev_path, PATH_MAX);
2177  	if (ret < 0)
2178  		return ret;	&bsol;* error */
2179  	if (ret == 0)
2180  		return 0;	&bsol;* no error, but not mac80211 device */
2181  	ret = nl80211_init(handle, &nlstate, device);
2182  	if (ret != 0)
2183  		return ret;
2184  	for (n = 0; n < UINT_MAX; n++) {
2185  		char mondevice[3+10+1];	&bsol;* mon{UINT_MAX}\0 */
2186  		snprintf(mondevice, sizeof mondevice, "mon%u", n);
2187  		ret = add_mon_if(handle, sock_fd, &nlstate, device, mondevice);
2188  		if (ret == 1) {
2189  			goto added;
2190  		}
2191  		if (ret < 0) {
2192  			nl80211_cleanup(&nlstate);
2193  			return ret;
2194  		}
2195  	}
2196  	snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
2197  	    "%s: No free monN interfaces", device);
2198  	nl80211_cleanup(&nlstate);
2199  	return PCAP_ERROR;
2200  added:
2201  #if 0
2202  	delay.tv_sec = 0;
2203  	delay.tv_nsec = 500000000;
2204  	nanosleep(&delay, NULL);
2205  #endif
2206  	if (!pcap_do_addexit(handle)) {
2207  		del_mon_if(handle, sock_fd, &nlstate, device,
2208  		    handlep->mondevice);
2209  		nl80211_cleanup(&nlstate);
2210  		return PCAP_ERROR;
2211  	}
2212  	memset(&ifr, 0, sizeof(ifr));
2213  	pcap_strlcpy(ifr.ifr_name, handlep->mondevice, sizeof(ifr.ifr_name));
2214  	if (ioctl(sock_fd, SIOCGIFFLAGS, &ifr) == -1) {
2215  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
2216  		    errno, "%s: Can't get flags for %s", device,
2217  		    handlep->mondevice);
2218  		del_mon_if(handle, sock_fd, &nlstate, device,
2219  		    handlep->mondevice);
2220  		nl80211_cleanup(&nlstate);
2221  		return PCAP_ERROR;
2222  	}
2223  	ifr.ifr_flags |= IFF_UP|IFF_RUNNING;
2224  	if (ioctl(sock_fd, SIOCSIFFLAGS, &ifr) == -1) {
2225  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
2226  		    errno, "%s: Can't set flags for %s", device,
2227  		    handlep->mondevice);
2228  		del_mon_if(handle, sock_fd, &nlstate, device,
2229  		    handlep->mondevice);
2230  		nl80211_cleanup(&nlstate);
2231  		return PCAP_ERROR;
2232  	}
2233  	nl80211_cleanup(&nlstate);
2234  	handlep->must_do_on_close |= MUST_DELETE_MONIF;
2235  	pcap_add_to_pcaps_to_close(handle);
2236  	return 1;
2237  }
2238  #else &bsol;* HAVE_LIBNL */
2239  static int
2240  enter_rfmon_mode(pcap_t *handle _U_, int sock_fd _U_, const char *device _U_)
2241  {
2242  	return 0;
2243  }
2244  #endif &bsol;* HAVE_LIBNL */
2245  #if defined(HAVE_LINUX_NET_TSTAMP_H) && defined(PACKET_TIMESTAMP)
2246  static const struct {
2247  	int soft_timestamping_val;
2248  	int pcap_tstamp_val;
2249  } sof_ts_type_map[3] = {
2250  	{ SOF_TIMESTAMPING_SOFTWARE, PCAP_TSTAMP_HOST },
2251  	{ SOF_TIMESTAMPING_SYS_HARDWARE, PCAP_TSTAMP_ADAPTER },
2252  	{ SOF_TIMESTAMPING_RAW_HARDWARE, PCAP_TSTAMP_ADAPTER_UNSYNCED }
2253  };
2254  #define NUM_SOF_TIMESTAMPING_TYPES	(sizeof sof_ts_type_map / sizeof sof_ts_type_map[0])
2255  static int
2256  iface_set_all_ts_types(pcap_t *handle, char *ebuf)
2257  {
2258  	u_int i;
2259  	handle->tstamp_type_list = malloc(NUM_SOF_TIMESTAMPING_TYPES * sizeof(u_int));
2260  	if (handle->tstamp_type_list == NULL) {
2261  		pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
2262  		    errno, "malloc");
2263  		return -1;
2264  	}
2265  	for (i = 0; i < NUM_SOF_TIMESTAMPING_TYPES; i++)
2266  		handle->tstamp_type_list[i] = sof_ts_type_map[i].pcap_tstamp_val;
2267  	handle->tstamp_type_count = NUM_SOF_TIMESTAMPING_TYPES;
2268  	return 0;
2269  }
2270  #ifdef ETHTOOL_GET_TS_INFO
2271  static int
2272  iface_get_ts_types(const char *device, pcap_t *handle, char *ebuf)
2273  {
2274  	int fd;
2275  	struct ifreq ifr;
2276  	struct ethtool_ts_info info;
2277  	int num_ts_types;
2278  	u_int i, j;
2279  	if (strcmp(device, "any") == 0) {
2280  		handle->tstamp_type_list = NULL;
2281  		return 0;
2282  	}
2283  	fd = get_if_ioctl_socket();
2284  	if (fd < 0) {
2285  		pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
2286  		    errno, "socket for SIOCETHTOOL(ETHTOOL_GET_TS_INFO)");
2287  		return -1;
2288  	}
2289  	memset(&ifr, 0, sizeof(ifr));
2290  	pcap_strlcpy(ifr.ifr_name, device, sizeof(ifr.ifr_name));
2291  	memset(&info, 0, sizeof(info));
2292  	info.cmd = ETHTOOL_GET_TS_INFO;
2293  	ifr.ifr_data = (caddr_t)&info;
2294  	if (ioctl(fd, SIOCETHTOOL, &ifr) == -1) {
2295  		int save_errno = errno;
2296  		close(fd);
2297  		switch (save_errno) {
2298  		case EOPNOTSUPP:
2299  		case EINVAL:
2300  			if (iface_set_all_ts_types(handle, ebuf) == -1)
2301  				return -1;
2302  			return 0;
2303  		case ENODEV:
2304  			handle->tstamp_type_list = NULL;
2305  			return 0;
2306  		default:
2307  			pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
2308  			    save_errno,
2309  			    "%s: SIOCETHTOOL(ETHTOOL_GET_TS_INFO) ioctl failed",
2310  			    device);
2311  			return -1;
2312  		}
2313  	}
2314  	close(fd);
2315  	if (!(info.rx_filters & (1 << HWTSTAMP_FILTER_ALL))) {
2316  		handle->tstamp_type_list = NULL;
2317  		return 0;
2318  	}
2319  	num_ts_types = 0;
2320  	for (i = 0; i < NUM_SOF_TIMESTAMPING_TYPES; i++) {
2321  		if (info.so_timestamping & sof_ts_type_map[i].soft_timestamping_val)
2322  			num_ts_types++;
2323  	}
2324  	if (num_ts_types != 0) {
2325  		handle->tstamp_type_list = malloc(num_ts_types * sizeof(u_int));
2326  		if (handle->tstamp_type_list == NULL) {
2327  			pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
2328  			    errno, "malloc");
2329  			return -1;
2330  		}
2331  		for (i = 0, j = 0; i < NUM_SOF_TIMESTAMPING_TYPES; i++) {
2332  			if (info.so_timestamping & sof_ts_type_map[i].soft_timestamping_val) {
2333  				handle->tstamp_type_list[j] = sof_ts_type_map[i].pcap_tstamp_val;
2334  				j++;
2335  			}
2336  		}
2337  		handle->tstamp_type_count = num_ts_types;
2338  	} else
2339  		handle->tstamp_type_list = NULL;
2340  	return 0;
2341  }
2342  #else &bsol;* ETHTOOL_GET_TS_INFO */
2343  static int
2344  iface_get_ts_types(const char *device, pcap_t *handle, char *ebuf)
2345  {
2346  	if (strcmp(device, "any") == 0) {
2347  		handle->tstamp_type_list = NULL;
2348  		return 0;
2349  	}
2350  	if (iface_set_all_ts_types(handle, ebuf) == -1)
2351  		return -1;
2352  	return 0;
2353  }
2354  #endif &bsol;* ETHTOOL_GET_TS_INFO */
2355  #else  &bsol;* defined(HAVE_LINUX_NET_TSTAMP_H) && defined(PACKET_TIMESTAMP) */
2356  static int
2357  iface_get_ts_types(const char *device _U_, pcap_t *p _U_, char *ebuf _U_)
2358  {
2359  	return 0;
2360  }
2361  #endif &bsol;* defined(HAVE_LINUX_NET_TSTAMP_H) && defined(PACKET_TIMESTAMP) */
2362  #if defined(SIOCETHTOOL) && (defined(ETHTOOL_GTSO) || defined(ETHTOOL_GUFO) || defined(ETHTOOL_GGSO) || defined(ETHTOOL_GFLAGS) || defined(ETHTOOL_GGRO))
2363  static int
2364  iface_ethtool_flag_ioctl(pcap_t *handle, int cmd, const char *cmdname,
2365      int eperm_ok)
2366  {
2367  	struct ifreq	ifr;
2368  	struct ethtool_value eval;
2369  	memset(&ifr, 0, sizeof(ifr));
2370  	pcap_strlcpy(ifr.ifr_name, handle->opt.device, sizeof(ifr.ifr_name));
2371  	eval.cmd = cmd;
2372  	eval.data = 0;
2373  	ifr.ifr_data = (caddr_t)&eval;
2374  	if (ioctl(handle->fd, SIOCETHTOOL, &ifr) == -1) {
2375  		if (errno == EOPNOTSUPP || errno == EINVAL ||
2376  		    (errno == EPERM && eperm_ok)) {
2377  			return 0;
2378  		}
2379  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
2380  		    errno, "%s: SIOCETHTOOL(%s) ioctl failed",
2381  		    handle->opt.device, cmdname);
2382  		return -1;
2383  	}
2384  	return eval.data;
2385  }
2386  static int
2387  iface_get_offload(pcap_t *handle)
2388  {
2389  	int ret;
2390  #ifdef ETHTOOL_GTSO
2391  	ret = iface_ethtool_flag_ioctl(handle, ETHTOOL_GTSO, "ETHTOOL_GTSO", 0);
2392  	if (ret == -1)
2393  		return -1;
2394  	if (ret)
2395  		return 1;	&bsol;* TCP segmentation offloading on */
2396  #endif
2397  #ifdef ETHTOOL_GGSO
2398  	ret = iface_ethtool_flag_ioctl(handle, ETHTOOL_GGSO, "ETHTOOL_GGSO", 0);
2399  	if (ret == -1)
2400  		return -1;
2401  	if (ret)
2402  		return 1;	&bsol;* generic segmentation offloading on */
2403  #endif
2404  #ifdef ETHTOOL_GFLAGS
2405  	ret = iface_ethtool_flag_ioctl(handle, ETHTOOL_GFLAGS, "ETHTOOL_GFLAGS", 0);
2406  	if (ret == -1)
2407  		return -1;
2408  	if (ret & ETH_FLAG_LRO)
2409  		return 1;	&bsol;* large receive offloading on */
2410  #endif
2411  #ifdef ETHTOOL_GGRO
2412  	ret = iface_ethtool_flag_ioctl(handle, ETHTOOL_GGRO, "ETHTOOL_GGRO", 0);
2413  	if (ret == -1)
2414  		return -1;
2415  	if (ret)
2416  		return 1;	&bsol;* generic (large) receive offloading on */
2417  #endif
2418  #ifdef ETHTOOL_GUFO
2419  	ret = iface_ethtool_flag_ioctl(handle, ETHTOOL_GUFO, "ETHTOOL_GUFO", 1);
2420  	if (ret == -1)
2421  		return -1;
2422  	if (ret)
2423  		return 1;	&bsol;* UDP fragmentation offloading on */
2424  #endif
2425  	return 0;
2426  }
2427  #else &bsol;* SIOCETHTOOL */
2428  static int
2429  iface_get_offload(pcap_t *handle _U_)
2430  {
2431  	return 0;
2432  }
2433  #endif &bsol;* SIOCETHTOOL */
2434  static struct dsa_proto {
2435  	const char *name;
2436  	bpf_u_int32 linktype;
2437  } dsa_protos[] = {
2438  	{ "none", DLT_EN10MB },
2439  	{ "brcm", DLT_DSA_TAG_BRCM },
2440  	{ "brcm-prepend", DLT_DSA_TAG_BRCM_PREPEND },
2441  	{ "dsa", DLT_DSA_TAG_DSA },
2442  	{ "edsa", DLT_DSA_TAG_EDSA },
2443  };
2444  static int
2445  iface_dsa_get_proto_info(const char *device, pcap_t *handle)
2446  {
2447  	char *pathstr;
2448  	unsigned int i;
2449  	char buf[128];
2450  	ssize_t r;
2451  	int fd;
2452  	fd = asprintf(&pathstr, "/sys/class/net/%s/dsa/tagging", device);
2453  	if (fd < 0) {
2454  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
2455  					  fd, "asprintf");
2456  		return PCAP_ERROR;
2457  	}
2458  	fd = open(pathstr, O_RDONLY);
2459  	free(pathstr);
2460  	if (fd < 0)
2461  		return 0;
2462  	r = read(fd, buf, sizeof(buf) - 1);
2463  	if (r <= 0) {
2464  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
2465  					  errno, "read");
2466  		close(fd);
2467  		return PCAP_ERROR;
2468  	}
2469  	close(fd);
2470  	if (buf[r - 1] == '\n')
2471  		r--;
2472  	buf[r] = '\0';
2473  	for (i = 0; i < sizeof(dsa_protos) / sizeof(dsa_protos[0]); i++) {
2474  		if (strlen(dsa_protos[i].name) == (size_t)r &&
2475  		    strcmp(buf, dsa_protos[i].name) == 0) {
2476  			handle->linktype = dsa_protos[i].linktype;
2477  			switch (dsa_protos[i].linktype) {
2478  			case DLT_EN10MB:
2479  				return 0;
2480  			default:
2481  				return 1;
2482  			}
2483  		}
2484  	}
2485  	snprintf(handle->errbuf, PCAP_ERRBUF_SIZE,
2486  		      "unsupported DSA tag: %s", buf);
2487  	return PCAP_ERROR;
2488  }
2489  static int
2490  iface_get_mtu(int fd, const char *device, char *ebuf)
2491  {
2492  	struct ifreq	ifr;
2493  	if (!device)
2494  		return BIGGER_THAN_ALL_MTUS;
2495  	memset(&ifr, 0, sizeof(ifr));
2496  	pcap_strlcpy(ifr.ifr_name, device, sizeof(ifr.ifr_name));
2497  	if (ioctl(fd, SIOCGIFMTU, &ifr) == -1) {
2498  		pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
2499  		    errno, "SIOCGIFMTU");
2500  		return -1;
2501  	}
2502  	return ifr.ifr_mtu;
2503  }
2504  static int
2505  iface_get_arptype(int fd, const char *device, char *ebuf)
2506  {
2507  	struct ifreq	ifr;
2508  	int		ret;
2509  	memset(&ifr, 0, sizeof(ifr));
2510  	pcap_strlcpy(ifr.ifr_name, device, sizeof(ifr.ifr_name));
2511  	if (ioctl(fd, SIOCGIFHWADDR, &ifr) == -1) {
2512  		if (errno == ENODEV) {
2513  			ret = PCAP_ERROR_NO_SUCH_DEVICE;
2514  			ebuf[0] = '\0';
2515  		} else {
2516  			ret = PCAP_ERROR;
2517  			pcap_fmt_errmsg_for_errno(ebuf, PCAP_ERRBUF_SIZE,
2518  			    errno, "SIOCGIFHWADDR");
2519  		}
2520  		return ret;
2521  	}
2522  	return ifr.ifr_hwaddr.sa_family;
2523  }
2524  static int
2525  fix_program(pcap_t *handle, struct sock_fprog *fcode)
2526  {
2527  	struct pcap_linux *handlep = handle->priv;
2528  	size_t prog_size;
2529  	register int i;
2530  	register struct bpf_insn *p;
2531  	struct bpf_insn *f;
2532  	int len;
2533  	prog_size = sizeof(*handle->fcode.bf_insns) * handle->fcode.bf_len;
2534  	len = handle->fcode.bf_len;
2535  	f = (struct bpf_insn *)malloc(prog_size);
2536  	if (f == NULL) {
2537  		pcap_fmt_errmsg_for_errno(handle->errbuf, PCAP_ERRBUF_SIZE,
2538  		    errno, "malloc");
2539  		return -1;
2540  	}
2541  	memcpy(f, handle->fcode.bf_insns, prog_size);
2542  	fcode->len = len;
2543  	fcode->filter = (struct sock_filter *) f;
2544  	for (i = 0; i < len; ++i) {
2545  		p = &f[i];
2546  		switch (BPF_CLASS(p->code)) {
2547  		case BPF_LD:
2548  		case BPF_LDX:
2549  			switch (BPF_MODE(p->code)) {
2550  			case BPF_ABS:
2551  			case BPF_IND:
2552  			case BPF_MSH:
2553  				if (handlep->cooked) {
2554  					if (fix_offset(handle, p) < 0) {
2555  						return 0;
2556  					}
2557  				}
2558  				break;
2559  			}
2560  			break;
2561  		}
2562  	}
2563  	return 1;	&bsol;* we succeeded */
2564  }
2565  static int
2566  fix_offset(pcap_t *handle, struct bpf_insn *p)
2567  {
2568  	if (p->k >= (bpf_u_int32)SKF_AD_OFF)
2569  		return 0;
2570  	if (handle->linktype == DLT_LINUX_SLL2) {
2571  		if (p->k >= SLL2_HDR_LEN) {
2572  			p->k -= SLL2_HDR_LEN;
2573  		} else if (p->k == 0) {
2574  			p->k = SKF_AD_OFF + SKF_AD_PROTOCOL;
2575  		} else if (p->k == 4) {
2576  			p->k = SKF_AD_OFF + SKF_AD_IFINDEX;
2577  		} else if (p->k == 10) {
2578  			p->k = SKF_AD_OFF + SKF_AD_PKTTYPE;
2579  		} else if ((bpf_int32)(p->k) > 0) {
2580  			return -1;
2581  		}
2582  	} else {
2583  		if (p->k >= SLL_HDR_LEN) {
2584  			p->k -= SLL_HDR_LEN;
2585  		} else if (p->k == 0) {
2586  			p->k = SKF_AD_OFF + SKF_AD_PKTTYPE;
2587  		} else if (p->k == 14) {
2588  			p->k = SKF_AD_OFF + SKF_AD_PROTOCOL;
2589  		} else if ((bpf_int32)(p->k) > 0) {
2590  			return -1;
2591  		}
2592  	}
2593  	return 0;
2594  }
2595  static int
2596  set_kernel_filter(pcap_t *handle, struct sock_fprog *fcode)
2597  {
2598  	int total_filter_on = 0;
2599  	int save_mode;
2600  	int ret;
2601  	int save_errno;
2602  	if (setsockopt(handle->fd, SOL_SOCKET, SO_ATTACH_FILTER,
2603  		       &total_fcode, sizeof(total_fcode)) == 0) {
2604  		char drain[1];
2605  		total_filter_on = 1;
2606  		save_mode = fcntl(handle->fd, F_GETFL, 0);
2607  		if (save_mode == -1) {
2608  			pcap_fmt_errmsg_for_errno(handle->errbuf,
2609  			    PCAP_ERRBUF_SIZE, errno,
2610  			    "can't get FD flags when changing filter");
2611  			return -2;
2612  		}
2613  		if (fcntl(handle->fd, F_SETFL, save_mode | O_NONBLOCK) < 0) {
2614  			pcap_fmt_errmsg_for_errno(handle->errbuf,
2615  			    PCAP_ERRBUF_SIZE, errno,
2616  			    "can't set nonblocking mode when changing filter");
2617  			return -2;
2618  		}
2619  		while (recv(handle->fd, &drain, sizeof drain, MSG_TRUNC) >= 0)
2620  			;
2621  		save_errno = errno;
2622  		if (save_errno != EAGAIN) {
2623  			(void)fcntl(handle->fd, F_SETFL, save_mode);
2624  			(void)reset_kernel_filter(handle);
2625  			pcap_fmt_errmsg_for_errno(handle->errbuf,
2626  			    PCAP_ERRBUF_SIZE, save_errno,
2627  			    "recv failed when changing filter");
2628  			return -2;
2629  		}
2630  		if (fcntl(handle->fd, F_SETFL, save_mode) == -1) {
2631  			pcap_fmt_errmsg_for_errno(handle->errbuf,
2632  			    PCAP_ERRBUF_SIZE, errno,
2633  			    "can't restore FD flags when changing filter");
2634  			return -2;
2635  		}
2636  	}
2637  	ret = setsockopt(handle->fd, SOL_SOCKET, SO_ATTACH_FILTER,
2638  			 fcode, sizeof(*fcode));
2639  	if (ret == -1 && total_filter_on) {
2640  		save_errno = errno;
2641  		if (reset_kernel_filter(handle) == -1) {
2642  			pcap_fmt_errmsg_for_errno(handle->errbuf,
2643  			    PCAP_ERRBUF_SIZE, errno,
2644  			    "can't remove kernel total filter");
2645  			return -2;	&bsol;* fatal error */
2646  		}
2647  		errno = save_errno;
2648  	}
2649  	return ret;
2650  }
2651  static int
2652  reset_kernel_filter(pcap_t *handle)
2653  {
2654  	int ret;
2655  	int dummy = 0;
2656  	ret = setsockopt(handle->fd, SOL_SOCKET, SO_DETACH_FILTER,
2657  				   &dummy, sizeof(dummy));
2658  	if (ret == -1 && errno != ENOENT && errno != ENONET)
2659  		return -1;
2660  	return 0;
2661  }
2662  int
2663  pcap_set_protocol_linux(pcap_t *p, int protocol)
2664  {
2665  	if (pcap_check_activated(p))
2666  		return (PCAP_ERROR_ACTIVATED);
2667  	p->opt.protocol = protocol;
2668  	return (0);
2669  }
2670  const char *
2671  pcap_lib_version(void)
2672  {
2673  #if defined(HAVE_TPACKET3)
2674  	return (PCAP_VERSION_STRING " (with TPACKET_V3)");
2675  #else
2676  	return (PCAP_VERSION_STRING " (with TPACKET_V2)");
2677  #endif
2678  }
</code></pre>
        </div>
        <div class="column">
            <h3>libfuse-MDEwOlJlcG9zaXRvcnk0ODI5NjE3Nw==-flat-fuse.c</h3>
            <pre><code>1  #include "fuse_config.h"
2  #include "fuse_i.h"
3  #include "fuse_lowlevel.h"
4  #include "fuse_opt.h"
5  #include "fuse_misc.h"
6  #include "fuse_kernel.h"
7  #include <stdio.h>
8  #include <string.h>
9  #include <stdlib.h>
10  #include <stddef.h>
11  #include <stdbool.h>
12  #include <unistd.h>
13  #include <time.h>
14  #include <fcntl.h>
15  #include <limits.h>
16  #include <errno.h>
17  #include <signal.h>
18  #include <dlfcn.h>
19  #include <assert.h>
20  #include <poll.h>
21  #include <sys/param.h>
22  #include <sys/uio.h>
23  #include <sys/time.h>
24  #include <sys/mman.h>
25  #include <sys/file.h>
26  #define FUSE_NODE_SLAB 1
27  #ifndef MAP_ANONYMOUS
28  #undef FUSE_NODE_SLAB
29  #endif
30  #ifndef RENAME_EXCHANGE
31  #define RENAME_EXCHANGE		(1 << 1)	&bsol;* Exchange source and dest */
32  #endif
33  #define FUSE_DEFAULT_INTR_SIGNAL SIGUSR1
34  #define FUSE_UNKNOWN_INO 0xffffffff
35  #define OFFSET_MAX 0x7fffffffffffffffLL
36  #define NODE_TABLE_MIN_SIZE 8192
37  struct fuse_fs {
38  	struct fuse_operations op;
39  	void *user_data;
40  	int debug;
41  };
42  struct fusemod_so {
43  	void *handle;
44  	int ctr;
45  };
46  struct lock_queue_element {
47  	struct lock_queue_element *next;
48  	pthread_cond_t cond;
49  	fuse_ino_t nodeid1;
50  	const char *name1;
51  	char **path1;
52  	struct node **wnode1;
53  	fuse_ino_t nodeid2;
54  	const char *name2;
55  	char **path2;
56  	struct node **wnode2;
57  	int err;
58  	bool done : 1;
59  };
60  struct node_table {
61  	struct node **array;
62  	size_t use;
63  	size_t size;
64  	size_t split;
65  };
66  #define container_of(ptr, type, member) ({                              \
67  			const typeof( ((type *)0)->member ) *__mptr = (ptr); \
68  			(type *)( (char *)__mptr - offsetof(type,member) );})
69  #define list_entry(ptr, type, member)           \
70  	container_of(ptr, type, member)
71  struct list_head {
72  	struct list_head *next;
73  	struct list_head *prev;
74  };
75  struct node_slab {
76  	struct list_head list;  &bsol;* must be the first member */
77  	struct list_head freelist;
78  	int used;
79  };
80  struct fuse {
81  	struct fuse_session *se;
82  	struct node_table name_table;
83  	struct node_table id_table;
84  	struct list_head lru_table;
85  	fuse_ino_t ctr;
86  	unsigned int generation;
87  	unsigned int hidectr;
88  	pthread_mutex_t lock;
89  	struct fuse_config conf;
90  	int intr_installed;
91  	struct fuse_fs *fs;
92  	struct lock_queue_element *lockq;
93  	int pagesize;
94  	struct list_head partial_slabs;
95  	struct list_head full_slabs;
96  	pthread_t prune_thread;
97  };
98  struct lock {
99  	int type;
100  	off_t start;
101  	off_t end;
102  	pid_t pid;
103  	uint64_t owner;
104  	struct lock *next;
105  };
106  struct node {
107  	struct node *name_next;
108  	struct node *id_next;
109  	fuse_ino_t nodeid;
110  	unsigned int generation;
111  	int refctr;
112  	struct node *parent;
113  	char *name;
114  	uint64_t nlookup;
115  	int open_count;
116  	struct timespec stat_updated;
117  	struct timespec mtime;
118  	off_t size;
119  	struct lock *locks;
120  	unsigned int is_hidden : 1;
121  	unsigned int cache_valid : 1;
122  	int treelock;
123  	char inline_name[32];
124  };
125  #define TREELOCK_WRITE -1
126  #define TREELOCK_WAIT_OFFSET INT_MIN
127  struct node_lru {
128  	struct node node;
129  	struct list_head lru;
130  	struct timespec forget_time;
131  };
132  struct fuse_direntry {
133  	struct stat stat;
134  	char *name;
135  	struct fuse_direntry *next;
136  };
137  struct fuse_dh {
138  	pthread_mutex_t lock;
139  	struct fuse *fuse;
140  	fuse_req_t req;
141  	char *contents;
142  	struct fuse_direntry *first;
143  	struct fuse_direntry **last;
144  	unsigned len;
145  	unsigned size;
146  	unsigned needlen;
147  	int filled;
148  	uint64_t fh;
149  	int error;
150  	fuse_ino_t nodeid;
151  };
152  struct fuse_context_i {
153  	struct fuse_context ctx;
154  	fuse_req_t req;
155  };
156  extern fuse_module_factory_t fuse_module_subdir_factory;
157  #ifdef HAVE_ICONV
158  extern fuse_module_factory_t fuse_module_iconv_factory;
159  #endif
160  static pthread_key_t fuse_context_key;
161  static pthread_mutex_t fuse_context_lock = PTHREAD_MUTEX_INITIALIZER;
162  static int fuse_context_ref;
163  static struct fuse_module *fuse_modules = NULL;
164  static int fuse_register_module(const char *name,
165  				fuse_module_factory_t factory,
166  				struct fusemod_so *so)
167  {
168  	struct fuse_module *mod;
169  	mod = calloc(1, sizeof(struct fuse_module));
170  	if (!mod) {
171  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate module\n");
172  		return -1;
173  	}
174  	mod->name = strdup(name);
175  	if (!mod->name) {
176  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate module name\n");
177  		free(mod);
178  		return -1;
179  	}
180  	mod->factory = factory;
181  	mod->ctr = 0;
182  	mod->so = so;
183  	if (mod->so)
184  		mod->so->ctr++;
185  	mod->next = fuse_modules;
186  	fuse_modules = mod;
187  	return 0;
188  }
189  static void fuse_unregister_module(struct fuse_module *m)
190  {
191  	struct fuse_module **mp;
192  	for (mp = &fuse_modules; *mp; mp = &(*mp)->next) {
193  		if (*mp == m) {
194  			*mp = (*mp)->next;
195  			break;
196  		}
197  	}
198  	free(m->name);
199  	free(m);
200  }
201  static int fuse_load_so_module(const char *module)
202  {
203  	int ret = -1;
204  	char *tmp;
205  	struct fusemod_so *so;
206  	fuse_module_factory_t *factory;
207  	tmp = malloc(strlen(module) + 64);
208  	if (!tmp) {
209  		fuse_log(FUSE_LOG_ERR, "fuse: memory allocation failed\n");
210  		return -1;
211  	}
212  	sprintf(tmp, "libfusemod_%s.so", module);
213  	so = calloc(1, sizeof(struct fusemod_so));
214  	if (!so) {
215  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate module so\n");
216  		goto out;
217  	}
218  	so->handle = dlopen(tmp, RTLD_NOW);
219  	if (so->handle == NULL) {
220  		fuse_log(FUSE_LOG_ERR, "fuse: dlopen(%s) failed: %s\n",
221  			tmp, dlerror());
222  		goto out_free_so;
223  	}
224  	sprintf(tmp, "fuse_module_%s_factory", module);
225  	factory = (fuse_module_factory_t*)dlsym(so->handle, tmp);
226  	if (factory == NULL) {
227  		fuse_log(FUSE_LOG_ERR, "fuse: symbol <%s> not found in module: %s\n",
228  			tmp, dlerror());
229  		goto out_dlclose;
230  	}
231  	ret = fuse_register_module(module, *factory, so);
232  	if (ret)
233  		goto out_dlclose;
234  out:
235  	free(tmp);
236  	return ret;
237  out_dlclose:
238  	dlclose(so->handle);
239  out_free_so:
240  	free(so);
241  	goto out;
242  }
243  static struct fuse_module *fuse_find_module(const char *module)
244  {
245  	struct fuse_module *m;
246  	for (m = fuse_modules; m; m = m->next) {
247  		if (strcmp(module, m->name) == 0) {
248  			m->ctr++;
249  			break;
250  		}
251  	}
252  	return m;
253  }
254  static struct fuse_module *fuse_get_module(const char *module)
255  {
256  	struct fuse_module *m;
257  	pthread_mutex_lock(&fuse_context_lock);
258  	m = fuse_find_module(module);
259  	if (!m) {
260  		int err = fuse_load_so_module(module);
261  		if (!err)
262  			m = fuse_find_module(module);
263  	}
264  	pthread_mutex_unlock(&fuse_context_lock);
265  	return m;
266  }
267  static void fuse_put_module(struct fuse_module *m)
268  {
269  	pthread_mutex_lock(&fuse_context_lock);
270  	if (m->so)
271  		assert(m->ctr > 0);
272  	if (m->ctr > 0)
273  		m->ctr--;
274  	if (!m->ctr && m->so) {
275  		struct fusemod_so *so = m->so;
276  		assert(so->ctr > 0);
277  		so->ctr--;
278  		if (!so->ctr) {
279  			struct fuse_module **mp;
280  			for (mp = &fuse_modules; *mp;) {
281  				if ((*mp)->so == so)
282  					fuse_unregister_module(*mp);
283  				else
284  					mp = &(*mp)->next;
285  			}
286  			dlclose(so->handle);
287  			free(so);
288  		}
289  	} else if (!m->ctr) {
290  		fuse_unregister_module(m);
291  	}
292  	pthread_mutex_unlock(&fuse_context_lock);
293  }
294  static void init_list_head(struct list_head *list)
295  {
296  	list->next = list;
297  	list->prev = list;
298  }
299  static int list_empty(const struct list_head *head)
300  {
301  	return head->next == head;
302  }
303  static void list_add(struct list_head *new, struct list_head *prev,
304  		     struct list_head *next)
305  {
306  	next->prev = new;
307  	new->next = next;
308  	new->prev = prev;
309  	prev->next = new;
310  }
311  static inline void list_add_head(struct list_head *new, struct list_head *head)
312  {
313  	list_add(new, head, head->next);
314  }
315  static inline void list_add_tail(struct list_head *new, struct list_head *head)
316  {
317  	list_add(new, head->prev, head);
318  }
319  static inline void list_del(struct list_head *entry)
320  {
321  	struct list_head *prev = entry->prev;
322  	struct list_head *next = entry->next;
323  	next->prev = prev;
324  	prev->next = next;
325  }
326  static inline int lru_enabled(struct fuse *f)
327  {
328  	return f->conf.remember > 0;
329  }
330  static struct node_lru *node_lru(struct node *node)
331  {
332  	return (struct node_lru *) node;
333  }
334  static size_t get_node_size(struct fuse *f)
335  {
336  	if (lru_enabled(f))
337  		return sizeof(struct node_lru);
338  	else
339  		return sizeof(struct node);
340  }
341  #ifdef FUSE_NODE_SLAB
342  static struct node_slab *list_to_slab(struct list_head *head)
343  {
344  	return (struct node_slab *) head;
345  }
346  static struct node_slab *node_to_slab(struct fuse *f, struct node *node)
347  {
348  	return (struct node_slab *) (((uintptr_t) node) & ~((uintptr_t) f->pagesize - 1));
349  }
350  static int alloc_slab(struct fuse *f)
351  {
352  	void *mem;
353  	struct node_slab *slab;
354  	char *start;
355  	size_t num;
356  	size_t i;
357  	size_t node_size = get_node_size(f);
358  	mem = mmap(NULL, f->pagesize, PROT_READ | PROT_WRITE,
359  		   MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
360  	if (mem == MAP_FAILED)
361  		return -1;
362  	slab = mem;
363  	init_list_head(&slab->freelist);
364  	slab->used = 0;
365  	num = (f->pagesize - sizeof(struct node_slab)) / node_size;
366  	start = (char *) mem + f->pagesize - num * node_size;
367  	for (i = 0; i < num; i++) {
368  		struct list_head *n;
369  		n = (struct list_head *) (start + i * node_size);
370  		list_add_tail(n, &slab->freelist);
371  	}
372  	list_add_tail(&slab->list, &f->partial_slabs);
373  	return 0;
374  }
375  static struct node *alloc_node(struct fuse *f)
376  {
377  	struct node_slab *slab;
378  	struct list_head *node;
379  	if (list_empty(&f->partial_slabs)) {
380  		int res = alloc_slab(f);
381  		if (res != 0)
382  			return NULL;
383  	}
384  	slab = list_to_slab(f->partial_slabs.next);
385  	slab->used++;
386  	node = slab->freelist.next;
387  	list_del(node);
388  	if (list_empty(&slab->freelist)) {
389  		list_del(&slab->list);
390  		list_add_tail(&slab->list, &f->full_slabs);
391  	}
392  	memset(node, 0, sizeof(struct node));
393  	return (struct node *) node;
394  }
395  static void free_slab(struct fuse *f, struct node_slab *slab)
396  {
397  	int res;
398  	list_del(&slab->list);
399  	res = munmap(slab, f->pagesize);
400  	if (res == -1)
401  		fuse_log(FUSE_LOG_WARNING, "fuse warning: munmap(%p) failed\n",
402  			 slab);
403  }
404  static void free_node_mem(struct fuse *f, struct node *node)
405  {
406  	struct node_slab *slab = node_to_slab(f, node);
407  	struct list_head *n = (struct list_head *) node;
408  	slab->used--;
409  	if (slab->used) {
410  		if (list_empty(&slab->freelist)) {
411  			list_del(&slab->list);
412  			list_add_tail(&slab->list, &f->partial_slabs);
413  		}
414  		list_add_head(n, &slab->freelist);
415  	} else {
416  		free_slab(f, slab);
417  	}
418  }
419  #else
420  static struct node *alloc_node(struct fuse *f)
421  {
422  	return (struct node *) calloc(1, get_node_size(f));
423  }
424  static void free_node_mem(struct fuse *f, struct node *node)
425  {
426  	(void) f;
427  	free(node);
428  }
429  #endif
430  static size_t id_hash(struct fuse *f, fuse_ino_t ino)
431  {
432  	uint64_t hash = ((uint32_t) ino * 2654435761U) % f->id_table.size;
433  	uint64_t oldhash = hash % (f->id_table.size / 2);
434  	if (oldhash >= f->id_table.split)
435  		return oldhash;
436  	else
437  		return hash;
438  }
439  static struct node *get_node_nocheck(struct fuse *f, fuse_ino_t nodeid)
440  {
441  	size_t hash = id_hash(f, nodeid);
442  	struct node *node;
443  	for (node = f->id_table.array[hash]; node != NULL; node = node->id_next)
444  		if (node->nodeid == nodeid)
445  			return node;
446  	return NULL;
447  }
448  static struct node *get_node(struct fuse *f, fuse_ino_t nodeid)
449  {
450  	struct node *node = get_node_nocheck(f, nodeid);
451  	if (!node) {
452  		fuse_log(FUSE_LOG_ERR, "fuse internal error: node %llu not found\n",
453  			(unsigned long long) nodeid);
454  		abort();
455  	}
456  	return node;
457  }
458  static void curr_time(struct timespec *now);
459  static double diff_timespec(const struct timespec *t1,
460  			   const struct timespec *t2);
461  static void remove_node_lru(struct node *node)
462  {
463  	struct node_lru *lnode = node_lru(node);
464  	list_del(&lnode->lru);
465  	init_list_head(&lnode->lru);
466  }
467  static void set_forget_time(struct fuse *f, struct node *node)
468  {
469  	struct node_lru *lnode = node_lru(node);
470  	list_del(&lnode->lru);
471  	list_add_tail(&lnode->lru, &f->lru_table);
472  	curr_time(&lnode->forget_time);
473  }
474  static void free_node(struct fuse *f, struct node *node)
475  {
476  	if (node->name != node->inline_name)
477  		free(node->name);
478  	free_node_mem(f, node);
479  }
480  static void node_table_reduce(struct node_table *t)
481  {
482  	size_t newsize = t->size / 2;
483  	void *newarray;
484  	if (newsize < NODE_TABLE_MIN_SIZE)
485  		return;
486  	newarray = realloc(t->array, sizeof(struct node *) * newsize);
487  	if (newarray != NULL)
488  		t->array = newarray;
489  	t->size = newsize;
490  	t->split = t->size / 2;
491  }
492  static void remerge_id(struct fuse *f)
493  {
494  	struct node_table *t = &f->id_table;
495  	int iter;
496  	if (t->split == 0)
497  		node_table_reduce(t);
498  	for (iter = 8; t->split > 0 && iter; iter--) {
499  		struct node **upper;
500  		t->split--;
501  		upper = &t->array[t->split + t->size / 2];
502  		if (*upper) {
503  			struct node **nodep;
504  			for (nodep = &t->array[t->split]; *nodep;
505  			     nodep = &(*nodep)->id_next);
506  			*nodep = *upper;
507  			*upper = NULL;
508  			break;
509  		}
510  	}
511  }
512  static void unhash_id(struct fuse *f, struct node *node)
513  {
514  	struct node **nodep = &f->id_table.array[id_hash(f, node->nodeid)];
515  	for (; *nodep != NULL; nodep = &(*nodep)->id_next)
516  		if (*nodep == node) {
517  			*nodep = node->id_next;
518  			f->id_table.use--;
519  			if(f->id_table.use < f->id_table.size / 4)
520  				remerge_id(f);
521  			return;
522  		}
523  }
524  static int node_table_resize(struct node_table *t)
525  {
526  	size_t newsize = t->size * 2;
527  	void *newarray;
528  	newarray = realloc(t->array, sizeof(struct node *) * newsize);
529  	if (newarray == NULL)
530  		return -1;
531  	t->array = newarray;
532  	memset(t->array + t->size, 0, t->size * sizeof(struct node *));
533  	t->size = newsize;
534  	t->split = 0;
535  	return 0;
536  }
537  static void rehash_id(struct fuse *f)
538  {
539  	struct node_table *t = &f->id_table;
540  	struct node **nodep;
541  	struct node **next;
542  	size_t hash;
543  	if (t->split == t->size / 2)
544  		return;
545  	hash = t->split;
546  	t->split++;
547  	for (nodep = &t->array[hash]; *nodep != NULL; nodep = next) {
548  		struct node *node = *nodep;
549  		size_t newhash = id_hash(f, node->nodeid);
550  		if (newhash != hash) {
551  			next = nodep;
552  			*nodep = node->id_next;
553  			node->id_next = t->array[newhash];
554  			t->array[newhash] = node;
555  		} else {
556  			next = &node->id_next;
557  		}
558  	}
559  	if (t->split == t->size / 2)
560  		node_table_resize(t);
561  }
562  static void hash_id(struct fuse *f, struct node *node)
563  {
564  	size_t hash = id_hash(f, node->nodeid);
565  	node->id_next = f->id_table.array[hash];
566  	f->id_table.array[hash] = node;
567  	f->id_table.use++;
568  	if (f->id_table.use >= f->id_table.size / 2)
569  		rehash_id(f);
570  }
571  static size_t name_hash(struct fuse *f, fuse_ino_t parent,
572  			const char *name)
573  {
574  	uint64_t hash = parent;
575  	uint64_t oldhash;
576  	for (; *name; name++)
577  		hash = hash * 31 + (unsigned char) *name;
578  	hash %= f->name_table.size;
579  	oldhash = hash % (f->name_table.size / 2);
580  	if (oldhash >= f->name_table.split)
581  		return oldhash;
582  	else
583  		return hash;
584  }
585  static void unref_node(struct fuse *f, struct node *node);
586  static void remerge_name(struct fuse *f)
587  {
588  	struct node_table *t = &f->name_table;
589  	int iter;
590  	if (t->split == 0)
591  		node_table_reduce(t);
592  	for (iter = 8; t->split > 0 && iter; iter--) {
593  		struct node **upper;
594  		t->split--;
595  		upper = &t->array[t->split + t->size / 2];
596  		if (*upper) {
597  			struct node **nodep;
598  			for (nodep = &t->array[t->split]; *nodep;
599  			     nodep = &(*nodep)->name_next);
600  			*nodep = *upper;
601  			*upper = NULL;
602  			break;
603  		}
604  	}
605  }
606  static void unhash_name(struct fuse *f, struct node *node)
607  {
608  	if (node->name) {
609  		size_t hash = name_hash(f, node->parent->nodeid, node->name);
610  		struct node **nodep = &f->name_table.array[hash];
611  		for (; *nodep != NULL; nodep = &(*nodep)->name_next)
612  			if (*nodep == node) {
613  				*nodep = node->name_next;
614  				node->name_next = NULL;
615  				unref_node(f, node->parent);
616  				if (node->name != node->inline_name)
617  					free(node->name);
618  				node->name = NULL;
619  				node->parent = NULL;
620  				f->name_table.use--;
621  				if (f->name_table.use < f->name_table.size / 4)
622  					remerge_name(f);
623  				return;
624  			}
625  		fuse_log(FUSE_LOG_ERR,
626  			"fuse internal error: unable to unhash node: %llu\n",
627  			(unsigned long long) node->nodeid);
628  		abort();
629  	}
630  }
631  static void rehash_name(struct fuse *f)
632  {
633  	struct node_table *t = &f->name_table;
634  	struct node **nodep;
635  	struct node **next;
636  	size_t hash;
637  	if (t->split == t->size / 2)
638  		return;
639  	hash = t->split;
640  	t->split++;
641  	for (nodep = &t->array[hash]; *nodep != NULL; nodep = next) {
642  		struct node *node = *nodep;
643  		size_t newhash = name_hash(f, node->parent->nodeid, node->name);
644  		if (newhash != hash) {
645  			next = nodep;
646  			*nodep = node->name_next;
647  			node->name_next = t->array[newhash];
648  			t->array[newhash] = node;
649  		} else {
650  			next = &node->name_next;
651  		}
652  	}
653  	if (t->split == t->size / 2)
654  		node_table_resize(t);
655  }
656  static int hash_name(struct fuse *f, struct node *node, fuse_ino_t parentid,
657  		     const char *name)
658  {
659  	size_t hash = name_hash(f, parentid, name);
660  	struct node *parent = get_node(f, parentid);
661  	if (strlen(name) < sizeof(node->inline_name)) {
662  		strcpy(node->inline_name, name);
663  		node->name = node->inline_name;
664  	} else {
665  		node->name = strdup(name);
666  		if (node->name == NULL)
667  			return -1;
668  	}
669  	parent->refctr ++;
670  	node->parent = parent;
671  	node->name_next = f->name_table.array[hash];
672  	f->name_table.array[hash] = node;
673  	f->name_table.use++;
674  	if (f->name_table.use >= f->name_table.size / 2)
675  		rehash_name(f);
676  	return 0;
677  }
678  static void delete_node(struct fuse *f, struct node *node)
679  {
680  	if (f->conf.debug)
681  		fuse_log(FUSE_LOG_DEBUG, "DELETE: %llu\n",
682  			(unsigned long long) node->nodeid);
683  	assert(node->treelock == 0);
684  	unhash_name(f, node);
685  	if (lru_enabled(f))
686  		remove_node_lru(node);
687  	unhash_id(f, node);
688  	free_node(f, node);
689  }
690  static void unref_node(struct fuse *f, struct node *node)
691  {
692  	assert(node->refctr > 0);
693  	node->refctr --;
694  	if (!node->refctr)
695  		delete_node(f, node);
696  }
697  static fuse_ino_t next_id(struct fuse *f)
698  {
699  	do {
700  		f->ctr = (f->ctr + 1) & 0xffffffff;
701  		if (!f->ctr)
702  			f->generation ++;
703  	} while (f->ctr == 0 || f->ctr == FUSE_UNKNOWN_INO ||
704  		 get_node_nocheck(f, f->ctr) != NULL);
705  	return f->ctr;
706  }
707  static struct node *lookup_node(struct fuse *f, fuse_ino_t parent,
708  				const char *name)
709  {
710  	size_t hash = name_hash(f, parent, name);
711  	struct node *node;
712  	for (node = f->name_table.array[hash]; node != NULL; node = node->name_next)
713  		if (node->parent->nodeid == parent &&
714  		    strcmp(node->name, name) == 0)
715  			return node;
716  	return NULL;
717  }
718  static void inc_nlookup(struct node *node)
719  {
720  	if (!node->nlookup)
721  		node->refctr++;
722  	node->nlookup++;
723  }
724  static struct node *find_node(struct fuse *f, fuse_ino_t parent,
725  			      const char *name)
726  {
727  	struct node *node;
728  	pthread_mutex_lock(&f->lock);
729  	if (!name)
730  		node = get_node(f, parent);
731  	else
732  		node = lookup_node(f, parent, name);
733  	if (node == NULL) {
734  		node = alloc_node(f);
735  		if (node == NULL)
736  			goto out_err;
737  		node->nodeid = next_id(f);
738  		node->generation = f->generation;
739  		if (f->conf.remember)
740  			inc_nlookup(node);
741  		if (hash_name(f, node, parent, name) == -1) {
742  			free_node(f, node);
743  			node = NULL;
744  			goto out_err;
745  		}
746  		hash_id(f, node);
747  		if (lru_enabled(f)) {
748  			struct node_lru *lnode = node_lru(node);
749  			init_list_head(&lnode->lru);
750  		}
751  	} else if (lru_enabled(f) && node->nlookup == 1) {
752  		remove_node_lru(node);
753  	}
754  	inc_nlookup(node);
755  out_err:
756  	pthread_mutex_unlock(&f->lock);
757  	return node;
758  }
759  static int lookup_path_in_cache(struct fuse *f,
760  		const char *path, fuse_ino_t *inop)
761  {
762  	char *tmp = strdup(path);
763  	if (!tmp)
764  		return -ENOMEM;
765  	pthread_mutex_lock(&f->lock);
766  	fuse_ino_t ino = FUSE_ROOT_ID;
767  	int err = 0;
768  	char *save_ptr;
769  	char *path_element = strtok_r(tmp, "/", &save_ptr);
770  	while (path_element != NULL) {
771  		struct node *node = lookup_node(f, ino, path_element);
772  		if (node == NULL) {
773  			err = -ENOENT;
774  			break;
775  		}
776  		ino = node->nodeid;
777  		path_element = strtok_r(NULL, "/", &save_ptr);
778  	}
779  	pthread_mutex_unlock(&f->lock);
780  	free(tmp);
781  	if (!err)
782  		*inop = ino;
783  	return err;
784  }
785  static char *add_name(char **buf, unsigned *bufsize, char *s, const char *name)
786  {
787  	size_t len = strlen(name);
788  	if (s - len <= *buf) {
789  		unsigned pathlen = *bufsize - (s - *buf);
790  		unsigned newbufsize = *bufsize;
791  		char *newbuf;
792  		while (newbufsize < pathlen + len + 1) {
793  			if (newbufsize >= 0x80000000)
794  				newbufsize = 0xffffffff;
795  			else
796  				newbufsize *= 2;
797  		}
798  		newbuf = realloc(*buf, newbufsize);
799  		if (newbuf == NULL)
800  			return NULL;
801  		*buf = newbuf;
802  		s = newbuf + newbufsize - pathlen;
803  		memmove(s, newbuf + *bufsize - pathlen, pathlen);
804  		*bufsize = newbufsize;
805  	}
806  	s -= len;
807  	memcpy(s, name, len);
808  	s--;
809  	*s = '/';
810  	return s;
811  }
812  static void unlock_path(struct fuse *f, fuse_ino_t nodeid, struct node *wnode,
813  			struct node *end)
814  {
815  	struct node *node;
816  	if (wnode) {
817  		assert(wnode->treelock == TREELOCK_WRITE);
818  		wnode->treelock = 0;
819  	}
820  	for (node = get_node(f, nodeid);
821  	     node != end && node->nodeid != FUSE_ROOT_ID; node = node->parent) {
822  		assert(node->treelock != 0);
823  		assert(node->treelock != TREELOCK_WAIT_OFFSET);
824  		assert(node->treelock != TREELOCK_WRITE);
825  		node->treelock--;
826  		if (node->treelock == TREELOCK_WAIT_OFFSET)
827  			node->treelock = 0;
828  	}
829  }
830  static int try_get_path(struct fuse *f, fuse_ino_t nodeid, const char *name,
831  			char **path, struct node **wnodep, bool need_lock)
832  {
833  	unsigned bufsize = 256;
834  	char *buf;
835  	char *s;
836  	struct node *node;
837  	struct node *wnode = NULL;
838  	int err;
839  	*path = NULL;
840  	err = -ENOMEM;
841  	buf = malloc(bufsize);
842  	if (buf == NULL)
843  		goto out_err;
844  	s = buf + bufsize - 1;
845  	*s = '\0';
846  	if (name != NULL) {
847  		s = add_name(&buf, &bufsize, s, name);
848  		err = -ENOMEM;
849  		if (s == NULL)
850  			goto out_free;
851  	}
852  	if (wnodep) {
853  		assert(need_lock);
854  		wnode = lookup_node(f, nodeid, name);
855  		if (wnode) {
856  			if (wnode->treelock != 0) {
857  				if (wnode->treelock > 0)
858  					wnode->treelock += TREELOCK_WAIT_OFFSET;
859  				err = -EAGAIN;
860  				goto out_free;
861  			}
862  			wnode->treelock = TREELOCK_WRITE;
863  		}
864  	}
865  	for (node = get_node(f, nodeid); node->nodeid != FUSE_ROOT_ID;
866  	     node = node->parent) {
867  		err = -ESTALE;
868  		if (node->name == NULL || node->parent == NULL)
869  			goto out_unlock;
870  		err = -ENOMEM;
871  		s = add_name(&buf, &bufsize, s, node->name);
872  		if (s == NULL)
873  			goto out_unlock;
874  		if (need_lock) {
875  			err = -EAGAIN;
876  			if (node->treelock < 0)
877  				goto out_unlock;
878  			node->treelock++;
879  		}
880  	}
881  	if (s[0])
882  		memmove(buf, s, bufsize - (s - buf));
883  	else
884  		strcpy(buf, "/");
885  	*path = buf;
886  	if (wnodep)
887  		*wnodep = wnode;
888  	return 0;
889   out_unlock:
890  	if (need_lock)
891  		unlock_path(f, nodeid, wnode, node);
892   out_free:
893  	free(buf);
894   out_err:
895  	return err;
896  }
897  static int try_get_path2(struct fuse *f, fuse_ino_t nodeid1, const char *name1,
898  			 fuse_ino_t nodeid2, const char *name2,
899  			 char **path1, char **path2,
900  			 struct node **wnode1, struct node **wnode2)
901  {
902  	int err;
903  	err = try_get_path(f, nodeid1, name1, path1, wnode1, true);
904  	if (!err) {
905  		err = try_get_path(f, nodeid2, name2, path2, wnode2, true);
906  		if (err) {
907  			struct node *wn1 = wnode1 ? *wnode1 : NULL;
908  			unlock_path(f, nodeid1, wn1, NULL);
909  			free(*path1);
910  		}
911  	}
912  	return err;
913  }
914  static void queue_element_wakeup(struct fuse *f, struct lock_queue_element *qe)
915  {
916  	int err;
917  	if (!qe->path1) {
918  		if (get_node(f, qe->nodeid1)->treelock == 0)
919  			pthread_cond_signal(&qe->cond);
920  		return;
921  	}
922  	if (qe->done)
923  		return;  
924  	if (!qe->path2) {
925  		err = try_get_path(f, qe->nodeid1, qe->name1, qe->path1,
926  				   qe->wnode1, true);
927  	} else {
928  		err = try_get_path2(f, qe->nodeid1, qe->name1, qe->nodeid2,
929  				    qe->name2, qe->path1, qe->path2, qe->wnode1,
930  				    qe->wnode2);
931  	}
932  	if (err == -EAGAIN)
933  		return;  &bsol;* keep trying */
934  	qe->err = err;
935  	qe->done = true;
936  	pthread_cond_signal(&qe->cond);
937  }
938  static void wake_up_queued(struct fuse *f)
939  {
940  	struct lock_queue_element *qe;
941  	for (qe = f->lockq; qe != NULL; qe = qe->next)
942  		queue_element_wakeup(f, qe);
943  }
944  static void debug_path(struct fuse *f, const char *msg, fuse_ino_t nodeid,
945  		       const char *name, bool wr)
946  {
947  	if (f->conf.debug) {
948  		struct node *wnode = NULL;
949  		if (wr)
950  			wnode = lookup_node(f, nodeid, name);
951  		if (wnode) {
952  			fuse_log(FUSE_LOG_DEBUG, "%s %llu (w)\n",
953  				msg, (unsigned long long) wnode->nodeid);
954  		} else {
955  			fuse_log(FUSE_LOG_DEBUG, "%s %llu\n",
956  				msg, (unsigned long long) nodeid);
957  		}
958  	}
959  }
960  static void queue_path(struct fuse *f, struct lock_queue_element *qe)
961  {
962  	struct lock_queue_element **qp;
963  	qe->done = false;
964  	pthread_cond_init(&qe->cond, NULL);
965  	qe->next = NULL;
966  	for (qp = &f->lockq; *qp != NULL; qp = &(*qp)->next);
967  	*qp = qe;
968  }
969  static void dequeue_path(struct fuse *f, struct lock_queue_element *qe)
970  {
971  	struct lock_queue_element **qp;
972  	pthread_cond_destroy(&qe->cond);
973  	for (qp = &f->lockq; *qp != qe; qp = &(*qp)->next);
974  	*qp = qe->next;
975  }
976  static int wait_path(struct fuse *f, struct lock_queue_element *qe)
977  {
978  	queue_path(f, qe);
979  	do {
980  		pthread_cond_wait(&qe->cond, &f->lock);
981  	} while (!qe->done);
982  	dequeue_path(f, qe);
983  	return qe->err;
984  }
985  static int get_path_common(struct fuse *f, fuse_ino_t nodeid, const char *name,
986  			   char **path, struct node **wnode)
987  {
988  	int err;
989  	pthread_mutex_lock(&f->lock);
990  	err = try_get_path(f, nodeid, name, path, wnode, true);
991  	if (err == -EAGAIN) {
992  		struct lock_queue_element qe = {
993  			.nodeid1 = nodeid,
994  			.name1 = name,
995  			.path1 = path,
996  			.wnode1 = wnode,
997  		};
998  		debug_path(f, "QUEUE PATH", nodeid, name, !!wnode);
999  		err = wait_path(f, &qe);
1000  		debug_path(f, "DEQUEUE PATH", nodeid, name, !!wnode);
1001  	}
1002  	pthread_mutex_unlock(&f->lock);
1003  	return err;
1004  }
1005  static int get_path(struct fuse *f, fuse_ino_t nodeid, char **path)
1006  {
1007  	return get_path_common(f, nodeid, NULL, path, NULL);
1008  }
1009  static int get_path_nullok(struct fuse *f, fuse_ino_t nodeid, char **path)
1010  {
1011  	int err = 0;
1012  	if (f->conf.nullpath_ok) {
1013  		*path = NULL;
1014  	} else {
1015  		err = get_path_common(f, nodeid, NULL, path, NULL);
1016  		if (err == -ESTALE)
1017  			err = 0;
1018  	}
1019  	return err;
1020  }
1021  static int get_path_name(struct fuse *f, fuse_ino_t nodeid, const char *name,
1022  			 char **path)
1023  {
1024  	return get_path_common(f, nodeid, name, path, NULL);
1025  }
1026  static int get_path_wrlock(struct fuse *f, fuse_ino_t nodeid, const char *name,
1027  			   char **path, struct node **wnode)
1028  {
1029  	return get_path_common(f, nodeid, name, path, wnode);
1030  }
1031  #if defined(__FreeBSD__)
1032  #define CHECK_DIR_LOOP
1033  #endif
1034  #if defined(CHECK_DIR_LOOP)
1035  static int check_dir_loop(struct fuse *f,
1036  			  fuse_ino_t nodeid1, const char *name1,
1037  			  fuse_ino_t nodeid2, const char *name2)
1038  {
1039  	struct node *node, *node1, *node2;
1040  	fuse_ino_t id1, id2;
1041  	node1 = lookup_node(f, nodeid1, name1);
1042  	id1 = node1 ? node1->nodeid : nodeid1;
1043  	node2 = lookup_node(f, nodeid2, name2);
1044  	id2 = node2 ? node2->nodeid : nodeid2;
1045  	for (node = get_node(f, id2); node->nodeid != FUSE_ROOT_ID;
1046  	     node = node->parent) {
1047  		if (node->name == NULL || node->parent == NULL)
1048  			break;
1049  		if (node->nodeid != id2 && node->nodeid == id1)
1050  			return -EINVAL;
1051  	}
1052  	if (node2)
1053  	{
1054  		for (node = get_node(f, id1); node->nodeid != FUSE_ROOT_ID;
1055  		     node = node->parent) {
1056  			if (node->name == NULL || node->parent == NULL)
1057  				break;
1058  			if (node->nodeid != id1 && node->nodeid == id2)
1059  				return -ENOTEMPTY;
1060  		}
1061  	}
1062  	return 0;
1063  }
1064  #endif
1065  static int get_path2(struct fuse *f, fuse_ino_t nodeid1, const char *name1,
1066  		     fuse_ino_t nodeid2, const char *name2,
1067  		     char **path1, char **path2,
1068  		     struct node **wnode1, struct node **wnode2)
1069  {
1070  	int err;
1071  	pthread_mutex_lock(&f->lock);
1072  #if defined(CHECK_DIR_LOOP)
1073  	if (name1)
1074  	{
1075  		err = check_dir_loop(f, nodeid1, name1, nodeid2, name2);
1076  		if (err)
1077  			goto out_unlock;
1078  	}
1079  #endif
1080  	err = try_get_path2(f, nodeid1, name1, nodeid2, name2,
1081  			    path1, path2, wnode1, wnode2);
1082  	if (err == -EAGAIN) {
1083  		struct lock_queue_element qe = {
1084  			.nodeid1 = nodeid1,
1085  			.name1 = name1,
1086  			.path1 = path1,
1087  			.wnode1 = wnode1,
1088  			.nodeid2 = nodeid2,
1089  			.name2 = name2,
1090  			.path2 = path2,
1091  			.wnode2 = wnode2,
1092  		};
1093  		debug_path(f, "QUEUE PATH1", nodeid1, name1, !!wnode1);
1094  		debug_path(f, "      PATH2", nodeid2, name2, !!wnode2);
1095  		err = wait_path(f, &qe);
1096  		debug_path(f, "DEQUEUE PATH1", nodeid1, name1, !!wnode1);
1097  		debug_path(f, "        PATH2", nodeid2, name2, !!wnode2);
1098  	}
1099  #if defined(CHECK_DIR_LOOP)
1100  out_unlock:
1101  #endif
1102  	pthread_mutex_unlock(&f->lock);
1103  	return err;
1104  }
1105  static void free_path_wrlock(struct fuse *f, fuse_ino_t nodeid,
1106  			     struct node *wnode, char *path)
1107  {
1108  	pthread_mutex_lock(&f->lock);
1109  	unlock_path(f, nodeid, wnode, NULL);
1110  	if (f->lockq)
1111  		wake_up_queued(f);
1112  	pthread_mutex_unlock(&f->lock);
1113  	free(path);
1114  }
1115  static void free_path(struct fuse *f, fuse_ino_t nodeid, char *path)
1116  {
1117  	if (path)
1118  		free_path_wrlock(f, nodeid, NULL, path);
1119  }
1120  static void free_path2(struct fuse *f, fuse_ino_t nodeid1, fuse_ino_t nodeid2,
1121  		       struct node *wnode1, struct node *wnode2,
1122  		       char *path1, char *path2)
1123  {
1124  	pthread_mutex_lock(&f->lock);
1125  	unlock_path(f, nodeid1, wnode1, NULL);
1126  	unlock_path(f, nodeid2, wnode2, NULL);
1127  	wake_up_queued(f);
1128  	pthread_mutex_unlock(&f->lock);
1129  	free(path1);
1130  	free(path2);
1131  }
1132  static void forget_node(struct fuse *f, fuse_ino_t nodeid, uint64_t nlookup)
1133  {
1134  	struct node *node;
1135  	if (nodeid == FUSE_ROOT_ID)
1136  		return;
1137  	pthread_mutex_lock(&f->lock);
1138  	node = get_node(f, nodeid);
1139  	while (node->nlookup == nlookup && node->treelock) {
1140  		struct lock_queue_element qe = {
1141  			.nodeid1 = nodeid,
1142  		};
1143  		debug_path(f, "QUEUE PATH (forget)", nodeid, NULL, false);
1144  		queue_path(f, &qe);
1145  		do {
1146  			pthread_cond_wait(&qe.cond, &f->lock);
1147  		} while (node->nlookup == nlookup && node->treelock);
1148  		dequeue_path(f, &qe);
1149  		debug_path(f, "DEQUEUE_PATH (forget)", nodeid, NULL, false);
1150  	}
1151  	assert(node->nlookup >= nlookup);
1152  	node->nlookup -= nlookup;
1153  	if (!node->nlookup) {
1154  		unref_node(f, node);
1155  	} else if (lru_enabled(f) && node->nlookup == 1) {
1156  		set_forget_time(f, node);
1157  	}
1158  	pthread_mutex_unlock(&f->lock);
1159  }
1160  static void unlink_node(struct fuse *f, struct node *node)
1161  {
1162  	if (f->conf.remember) {
1163  		assert(node->nlookup > 1);
1164  		node->nlookup--;
1165  	}
1166  	unhash_name(f, node);
1167  }
1168  static void remove_node(struct fuse *f, fuse_ino_t dir, const char *name)
1169  {
1170  	struct node *node;
1171  	pthread_mutex_lock(&f->lock);
1172  	node = lookup_node(f, dir, name);
1173  	if (node != NULL)
1174  		unlink_node(f, node);
1175  	pthread_mutex_unlock(&f->lock);
1176  }
1177  static int rename_node(struct fuse *f, fuse_ino_t olddir, const char *oldname,
1178  		       fuse_ino_t newdir, const char *newname, int hide)
1179  {
1180  	struct node *node;
1181  	struct node *newnode;
1182  	int err = 0;
1183  	pthread_mutex_lock(&f->lock);
1184  	node  = lookup_node(f, olddir, oldname);
1185  	newnode	 = lookup_node(f, newdir, newname);
1186  	if (node == NULL)
1187  		goto out;
1188  	if (newnode != NULL) {
1189  		if (hide) {
1190  			fuse_log(FUSE_LOG_ERR, "fuse: hidden file got created during hiding\n");
1191  			err = -EBUSY;
1192  			goto out;
1193  		}
1194  		unlink_node(f, newnode);
1195  	}
1196  	unhash_name(f, node);
1197  	if (hash_name(f, node, newdir, newname) == -1) {
1198  		err = -ENOMEM;
1199  		goto out;
1200  	}
1201  	if (hide)
1202  		node->is_hidden = 1;
1203  out:
1204  	pthread_mutex_unlock(&f->lock);
1205  	return err;
1206  }
1207  static int exchange_node(struct fuse *f, fuse_ino_t olddir, const char *oldname,
1208  			 fuse_ino_t newdir, const char *newname)
1209  {
1210  	struct node *oldnode;
1211  	struct node *newnode;
1212  	int err;
1213  	pthread_mutex_lock(&f->lock);
1214  	oldnode  = lookup_node(f, olddir, oldname);
1215  	newnode	 = lookup_node(f, newdir, newname);
1216  	if (oldnode)
1217  		unhash_name(f, oldnode);
1218  	if (newnode)
1219  		unhash_name(f, newnode);
1220  	err = -ENOMEM;
1221  	if (oldnode) {
1222  		if (hash_name(f, oldnode, newdir, newname) == -1)
1223  			goto out;
1224  	}
1225  	if (newnode) {
1226  		if (hash_name(f, newnode, olddir, oldname) == -1)
1227  			goto out;
1228  	}
1229  	err = 0;
1230  out:
1231  	pthread_mutex_unlock(&f->lock);
1232  	return err;
1233  }
1234  static void set_stat(struct fuse *f, fuse_ino_t nodeid, struct stat *stbuf)
1235  {
1236  	if (!f->conf.use_ino)
1237  		stbuf->st_ino = nodeid;
1238  	if (f->conf.set_mode)
1239  		stbuf->st_mode = (stbuf->st_mode & S_IFMT) |
1240  				 (0777 & ~f->conf.umask);
1241  	if (f->conf.set_uid)
<span onclick='openModal()' class='match'>1242  		stbuf->st_uid = f->conf.uid;
1243  	if (f->conf.set_gid)
1244  		stbuf->st_gid = f->conf.gid;
</span>1245  }
1246  static struct fuse *req_fuse(fuse_req_t req)
1247  {
1248  	return (struct fuse *) fuse_req_userdata(req);
1249  }
1250  static void fuse_intr_sighandler(int sig)
1251  {
1252  	(void) sig;
1253  }
1254  struct fuse_intr_data {
1255  	pthread_t id;
1256  	pthread_cond_t cond;
1257  	int finished;
1258  };
1259  static void fuse_interrupt(fuse_req_t req, void *d_)
1260  {
1261  	struct fuse_intr_data *d = d_;
1262  	struct fuse *f = req_fuse(req);
1263  	if (d->id == pthread_self())
1264  		return;
1265  	pthread_mutex_lock(&f->lock);
1266  	while (!d->finished) {
1267  		struct timeval now;
1268  		struct timespec timeout;
1269  		pthread_kill(d->id, f->conf.intr_signal);
1270  		gettimeofday(&now, NULL);
1271  		timeout.tv_sec = now.tv_sec + 1;
1272  		timeout.tv_nsec = now.tv_usec * 1000;
1273  		pthread_cond_timedwait(&d->cond, &f->lock, &timeout);
1274  	}
1275  	pthread_mutex_unlock(&f->lock);
1276  }
1277  static void fuse_do_finish_interrupt(struct fuse *f, fuse_req_t req,
1278  				     struct fuse_intr_data *d)
1279  {
1280  	pthread_mutex_lock(&f->lock);
1281  	d->finished = 1;
1282  	pthread_cond_broadcast(&d->cond);
1283  	pthread_mutex_unlock(&f->lock);
1284  	fuse_req_interrupt_func(req, NULL, NULL);
1285  	pthread_cond_destroy(&d->cond);
1286  }
1287  static void fuse_do_prepare_interrupt(fuse_req_t req, struct fuse_intr_data *d)
1288  {
1289  	d->id = pthread_self();
1290  	pthread_cond_init(&d->cond, NULL);
1291  	d->finished = 0;
1292  	fuse_req_interrupt_func(req, fuse_interrupt, d);
1293  }
1294  static inline void fuse_finish_interrupt(struct fuse *f, fuse_req_t req,
1295  					 struct fuse_intr_data *d)
1296  {
1297  	if (f->conf.intr)
1298  		fuse_do_finish_interrupt(f, req, d);
1299  }
1300  static inline void fuse_prepare_interrupt(struct fuse *f, fuse_req_t req,
1301  					  struct fuse_intr_data *d)
1302  {
1303  	if (f->conf.intr)
1304  		fuse_do_prepare_interrupt(req, d);
1305  }
1306  static const char* file_info_string(struct fuse_file_info *fi,
1307  			      char* buf, size_t len)
1308  {
1309  	if(fi == NULL)
1310  		return "NULL";
1311  	snprintf(buf, len, "%llu", (unsigned long long) fi->fh);
1312  	return buf;
1313  }
1314  int fuse_fs_getattr(struct fuse_fs *fs, const char *path, struct stat *buf,
1315  		    struct fuse_file_info *fi)
1316  {
1317  	fuse_get_context()->private_data = fs->user_data;
1318  	if (fs->op.getattr) {
1319  		if (fs->debug) {
1320  			char buf[10];
1321  			fuse_log(FUSE_LOG_DEBUG, "getattr[%s] %s\n",
1322  				file_info_string(fi, buf, sizeof(buf)),
1323  				path);
1324  		}
1325  		return fs->op.getattr(path, buf, fi);
1326  	} else {
1327  		return -ENOSYS;
1328  	}
1329  }
1330  int fuse_fs_rename(struct fuse_fs *fs, const char *oldpath,
1331  		   const char *newpath, unsigned int flags)
1332  {
1333  	fuse_get_context()->private_data = fs->user_data;
1334  	if (fs->op.rename) {
1335  		if (fs->debug)
1336  			fuse_log(FUSE_LOG_DEBUG, "rename %s %s 0x%x\n", oldpath, newpath,
1337  				flags);
1338  		return fs->op.rename(oldpath, newpath, flags);
1339  	} else {
1340  		return -ENOSYS;
1341  	}
1342  }
1343  int fuse_fs_unlink(struct fuse_fs *fs, const char *path)
1344  {
1345  	fuse_get_context()->private_data = fs->user_data;
1346  	if (fs->op.unlink) {
1347  		if (fs->debug)
1348  			fuse_log(FUSE_LOG_DEBUG, "unlink %s\n", path);
1349  		return fs->op.unlink(path);
1350  	} else {
1351  		return -ENOSYS;
1352  	}
1353  }
1354  int fuse_fs_rmdir(struct fuse_fs *fs, const char *path)
1355  {
1356  	fuse_get_context()->private_data = fs->user_data;
1357  	if (fs->op.rmdir) {
1358  		if (fs->debug)
1359  			fuse_log(FUSE_LOG_DEBUG, "rmdir %s\n", path);
1360  		return fs->op.rmdir(path);
1361  	} else {
1362  		return -ENOSYS;
1363  	}
1364  }
1365  int fuse_fs_symlink(struct fuse_fs *fs, const char *linkname, const char *path)
1366  {
1367  	fuse_get_context()->private_data = fs->user_data;
1368  	if (fs->op.symlink) {
1369  		if (fs->debug)
1370  			fuse_log(FUSE_LOG_DEBUG, "symlink %s %s\n", linkname, path);
1371  		return fs->op.symlink(linkname, path);
1372  	} else {
1373  		return -ENOSYS;
1374  	}
1375  }
1376  int fuse_fs_link(struct fuse_fs *fs, const char *oldpath, const char *newpath)
1377  {
1378  	fuse_get_context()->private_data = fs->user_data;
1379  	if (fs->op.link) {
1380  		if (fs->debug)
1381  			fuse_log(FUSE_LOG_DEBUG, "link %s %s\n", oldpath, newpath);
1382  		return fs->op.link(oldpath, newpath);
1383  	} else {
1384  		return -ENOSYS;
1385  	}
1386  }
1387  int fuse_fs_release(struct fuse_fs *fs,	 const char *path,
1388  		    struct fuse_file_info *fi)
1389  {
1390  	fuse_get_context()->private_data = fs->user_data;
1391  	if (fs->op.release) {
1392  		if (fs->debug)
1393  			fuse_log(FUSE_LOG_DEBUG, "release%s[%llu] flags: 0x%x\n",
1394  				fi->flush ? "+flush" : "",
1395  				(unsigned long long) fi->fh, fi->flags);
1396  		return fs->op.release(path, fi);
1397  	} else {
1398  		return 0;
1399  	}
1400  }
1401  int fuse_fs_opendir(struct fuse_fs *fs, const char *path,
1402  		    struct fuse_file_info *fi)
1403  {
1404  	fuse_get_context()->private_data = fs->user_data;
1405  	if (fs->op.opendir) {
1406  		int err;
1407  		if (fs->debug)
1408  			fuse_log(FUSE_LOG_DEBUG, "opendir flags: 0x%x %s\n", fi->flags,
1409  				path);
1410  		err = fs->op.opendir(path, fi);
1411  		if (fs->debug && !err)
1412  			fuse_log(FUSE_LOG_DEBUG, "   opendir[%llu] flags: 0x%x %s\n",
1413  				(unsigned long long) fi->fh, fi->flags, path);
1414  		return err;
1415  	} else {
1416  		return 0;
1417  	}
1418  }
1419  int fuse_fs_open(struct fuse_fs *fs, const char *path,
1420  		 struct fuse_file_info *fi)
1421  {
1422  	fuse_get_context()->private_data = fs->user_data;
1423  	if (fs->op.open) {
1424  		int err;
1425  		if (fs->debug)
1426  			fuse_log(FUSE_LOG_DEBUG, "open flags: 0x%x %s\n", fi->flags,
1427  				path);
1428  		err = fs->op.open(path, fi);
1429  		if (fs->debug && !err)
1430  			fuse_log(FUSE_LOG_DEBUG, "   open[%llu] flags: 0x%x %s\n",
1431  				(unsigned long long) fi->fh, fi->flags, path);
1432  		return err;
1433  	} else {
1434  		return 0;
1435  	}
1436  }
1437  static void fuse_free_buf(struct fuse_bufvec *buf)
1438  {
1439  	if (buf != NULL) {
1440  		size_t i;
1441  		for (i = 0; i < buf->count; i++)
1442  			if (!(buf->buf[i].flags & FUSE_BUF_IS_FD))
1443  				free(buf->buf[i].mem);
1444  		free(buf);
1445  	}
1446  }
1447  int fuse_fs_read_buf(struct fuse_fs *fs, const char *path,
1448  		     struct fuse_bufvec **bufp, size_t size, off_t off,
1449  		     struct fuse_file_info *fi)
1450  {
1451  	fuse_get_context()->private_data = fs->user_data;
1452  	if (fs->op.read || fs->op.read_buf) {
1453  		int res;
1454  		if (fs->debug)
1455  			fuse_log(FUSE_LOG_DEBUG,
1456  				"read[%llu] %zu bytes from %llu flags: 0x%x\n",
1457  				(unsigned long long) fi->fh,
1458  				size, (unsigned long long) off, fi->flags);
1459  		if (fs->op.read_buf) {
1460  			res = fs->op.read_buf(path, bufp, size, off, fi);
1461  		} else {
1462  			struct fuse_bufvec *buf;
1463  			void *mem;
1464  			buf = malloc(sizeof(struct fuse_bufvec));
1465  			if (buf == NULL)
1466  				return -ENOMEM;
1467  			mem = malloc(size);
1468  			if (mem == NULL) {
1469  				free(buf);
1470  				return -ENOMEM;
1471  			}
1472  			*buf = FUSE_BUFVEC_INIT(size);
1473  			buf->buf[0].mem = mem;
1474  			*bufp = buf;
1475  			res = fs->op.read(path, mem, size, off, fi);
1476  			if (res >= 0)
1477  				buf->buf[0].size = res;
1478  		}
1479  		if (fs->debug && res >= 0)
1480  			fuse_log(FUSE_LOG_DEBUG, "   read[%llu] %zu bytes from %llu\n",
1481  				(unsigned long long) fi->fh,
1482  				fuse_buf_size(*bufp),
1483  				(unsigned long long) off);
1484  		if (res >= 0 && fuse_buf_size(*bufp) > size)
1485  			fuse_log(FUSE_LOG_ERR, "fuse: read too many bytes\n");
1486  		if (res < 0)
1487  			return res;
1488  		return 0;
1489  	} else {
1490  		return -ENOSYS;
1491  	}
1492  }
1493  int fuse_fs_read(struct fuse_fs *fs, const char *path, char *mem, size_t size,
1494  		 off_t off, struct fuse_file_info *fi)
1495  {
1496  	fuse_get_context()->private_data = fs->user_data;
1497  	if (fs->op.read || fs->op.read_buf) {
1498  		int res;
1499  		if (fs->debug)
1500  			fuse_log(FUSE_LOG_DEBUG,
1501  				"read[%llu] %zu bytes from %llu flags: 0x%x\n",
1502  				(unsigned long long) fi->fh,
1503  				size, (unsigned long long) off, fi->flags);
1504  		if (fs->op.read_buf) {
1505  			struct fuse_bufvec *buf = NULL;
1506  			res = fs->op.read_buf(path, &buf, size, off, fi);
1507  			if (res == 0) {
1508  				struct fuse_bufvec dst = FUSE_BUFVEC_INIT(size);
1509  				dst.buf[0].mem = mem;
1510  				res = fuse_buf_copy(&dst, buf, 0);
1511  			}
1512  			fuse_free_buf(buf);
1513  		} else {
1514  			res = fs->op.read(path, mem, size, off, fi);
1515  		}
1516  		if (fs->debug && res >= 0)
1517  			fuse_log(FUSE_LOG_DEBUG, "   read[%llu] %u bytes from %llu\n",
1518  				(unsigned long long) fi->fh,
1519  				res,
1520  				(unsigned long long) off);
1521  		if (res >= 0 && res > (int) size)
1522  			fuse_log(FUSE_LOG_ERR, "fuse: read too many bytes\n");
1523  		return res;
1524  	} else {
1525  		return -ENOSYS;
1526  	}
1527  }
1528  int fuse_fs_write_buf(struct fuse_fs *fs, const char *path,
1529  		      struct fuse_bufvec *buf, off_t off,
1530  		      struct fuse_file_info *fi)
1531  {
1532  	fuse_get_context()->private_data = fs->user_data;
1533  	if (fs->op.write_buf || fs->op.write) {
1534  		int res;
1535  		size_t size = fuse_buf_size(buf);
1536  		assert(buf->idx == 0 && buf->off == 0);
1537  		if (fs->debug)
1538  			fuse_log(FUSE_LOG_DEBUG,
1539  				"write%s[%llu] %zu bytes to %llu flags: 0x%x\n",
1540  				fi->writepage ? "page" : "",
1541  				(unsigned long long) fi->fh,
1542  				size,
1543  				(unsigned long long) off,
1544  				fi->flags);
1545  		if (fs->op.write_buf) {
1546  			res = fs->op.write_buf(path, buf, off, fi);
1547  		} else {
1548  			void *mem = NULL;
1549  			struct fuse_buf *flatbuf;
1550  			struct fuse_bufvec tmp = FUSE_BUFVEC_INIT(size);
1551  			if (buf->count == 1 &&
1552  			    !(buf->buf[0].flags & FUSE_BUF_IS_FD)) {
1553  				flatbuf = &buf->buf[0];
1554  			} else {
1555  				res = -ENOMEM;
1556  				mem = malloc(size);
1557  				if (mem == NULL)
1558  					goto out;
1559  				tmp.buf[0].mem = mem;
1560  				res = fuse_buf_copy(&tmp, buf, 0);
1561  				if (res <= 0)
1562  					goto out_free;
1563  				tmp.buf[0].size = res;
1564  				flatbuf = &tmp.buf[0];
1565  			}
1566  			res = fs->op.write(path, flatbuf->mem, flatbuf->size,
1567  					   off, fi);
1568  out_free:
1569  			free(mem);
1570  		}
1571  out:
1572  		if (fs->debug && res >= 0)
1573  			fuse_log(FUSE_LOG_DEBUG, "   write%s[%llu] %u bytes to %llu\n",
1574  				fi->writepage ? "page" : "",
1575  				(unsigned long long) fi->fh, res,
1576  				(unsigned long long) off);
1577  		if (res > (int) size)
1578  			fuse_log(FUSE_LOG_ERR, "fuse: wrote too many bytes\n");
1579  		return res;
1580  	} else {
1581  		return -ENOSYS;
1582  	}
1583  }
1584  int fuse_fs_write(struct fuse_fs *fs, const char *path, const char *mem,
1585  		  size_t size, off_t off, struct fuse_file_info *fi)
1586  {
1587  	struct fuse_bufvec bufv = FUSE_BUFVEC_INIT(size);
1588  	bufv.buf[0].mem = (void *) mem;
1589  	return fuse_fs_write_buf(fs, path, &bufv, off, fi);
1590  }
1591  int fuse_fs_fsync(struct fuse_fs *fs, const char *path, int datasync,
1592  		  struct fuse_file_info *fi)
1593  {
1594  	fuse_get_context()->private_data = fs->user_data;
1595  	if (fs->op.fsync) {
1596  		if (fs->debug)
1597  			fuse_log(FUSE_LOG_DEBUG, "fsync[%llu] datasync: %i\n",
1598  				(unsigned long long) fi->fh, datasync);
1599  		return fs->op.fsync(path, datasync, fi);
1600  	} else {
1601  		return -ENOSYS;
1602  	}
1603  }
1604  int fuse_fs_fsyncdir(struct fuse_fs *fs, const char *path, int datasync,
1605  		     struct fuse_file_info *fi)
1606  {
1607  	fuse_get_context()->private_data = fs->user_data;
1608  	if (fs->op.fsyncdir) {
1609  		if (fs->debug)
1610  			fuse_log(FUSE_LOG_DEBUG, "fsyncdir[%llu] datasync: %i\n",
1611  				(unsigned long long) fi->fh, datasync);
1612  		return fs->op.fsyncdir(path, datasync, fi);
1613  	} else {
1614  		return -ENOSYS;
1615  	}
1616  }
1617  int fuse_fs_flush(struct fuse_fs *fs, const char *path,
1618  		  struct fuse_file_info *fi)
1619  {
1620  	fuse_get_context()->private_data = fs->user_data;
1621  	if (fs->op.flush) {
1622  		if (fs->debug)
1623  			fuse_log(FUSE_LOG_DEBUG, "flush[%llu]\n",
1624  				(unsigned long long) fi->fh);
1625  		return fs->op.flush(path, fi);
1626  	} else {
1627  		return -ENOSYS;
1628  	}
1629  }
1630  int fuse_fs_statfs(struct fuse_fs *fs, const char *path, struct statvfs *buf)
1631  {
1632  	fuse_get_context()->private_data = fs->user_data;
1633  	if (fs->op.statfs) {
1634  		if (fs->debug)
1635  			fuse_log(FUSE_LOG_DEBUG, "statfs %s\n", path);
1636  		return fs->op.statfs(path, buf);
1637  	} else {
1638  		buf->f_namemax = 255;
1639  		buf->f_bsize = 512;
1640  		return 0;
1641  	}
1642  }
1643  int fuse_fs_releasedir(struct fuse_fs *fs, const char *path,
1644  		       struct fuse_file_info *fi)
1645  {
1646  	fuse_get_context()->private_data = fs->user_data;
1647  	if (fs->op.releasedir) {
1648  		if (fs->debug)
1649  			fuse_log(FUSE_LOG_DEBUG, "releasedir[%llu] flags: 0x%x\n",
1650  				(unsigned long long) fi->fh, fi->flags);
1651  		return fs->op.releasedir(path, fi);
1652  	} else {
1653  		return 0;
1654  	}
1655  }
1656  int fuse_fs_readdir(struct fuse_fs *fs, const char *path, void *buf,
1657  		    fuse_fill_dir_t filler, off_t off,
1658  		    struct fuse_file_info *fi,
1659  		    enum fuse_readdir_flags flags)
1660  {
1661  	fuse_get_context()->private_data = fs->user_data;
1662  	if (fs->op.readdir) {
1663  		if (fs->debug) {
1664  			fuse_log(FUSE_LOG_DEBUG, "readdir%s[%llu] from %llu\n",
1665  				(flags & FUSE_READDIR_PLUS) ? "plus" : "",
1666  				(unsigned long long) fi->fh,
1667  				(unsigned long long) off);
1668  		}
1669  		return fs->op.readdir(path, buf, filler, off, fi, flags);
1670  	} else {
1671  		return -ENOSYS;
1672  	}
1673  }
1674  int fuse_fs_create(struct fuse_fs *fs, const char *path, mode_t mode,
1675  		   struct fuse_file_info *fi)
1676  {
1677  	fuse_get_context()->private_data = fs->user_data;
1678  	if (fs->op.create) {
1679  		int err;
1680  		if (fs->debug)
1681  			fuse_log(FUSE_LOG_DEBUG,
1682  				"create flags: 0x%x %s 0%o umask=0%03o\n",
1683  				fi->flags, path, mode,
1684  				fuse_get_context()->umask);
1685  		err = fs->op.create(path, mode, fi);
1686  		if (fs->debug && !err)
1687  			fuse_log(FUSE_LOG_DEBUG, "   create[%llu] flags: 0x%x %s\n",
1688  				(unsigned long long) fi->fh, fi->flags, path);
1689  		return err;
1690  	} else {
1691  		return -ENOSYS;
1692  	}
1693  }
1694  int fuse_fs_lock(struct fuse_fs *fs, const char *path,
1695  		 struct fuse_file_info *fi, int cmd, struct flock *lock)
1696  {
1697  	fuse_get_context()->private_data = fs->user_data;
1698  	if (fs->op.lock) {
1699  		if (fs->debug)
1700  			fuse_log(FUSE_LOG_DEBUG, "lock[%llu] %s %s start: %llu len: %llu pid: %llu\n",
1701  				(unsigned long long) fi->fh,
1702  				(cmd == F_GETLK ? "F_GETLK" :
1703  				 (cmd == F_SETLK ? "F_SETLK" :
1704  				  (cmd == F_SETLKW ? "F_SETLKW" : "???"))),
1705  				(lock->l_type == F_RDLCK ? "F_RDLCK" :
1706  				 (lock->l_type == F_WRLCK ? "F_WRLCK" :
1707  				  (lock->l_type == F_UNLCK ? "F_UNLCK" :
1708  				   "???"))),
1709  				(unsigned long long) lock->l_start,
1710  				(unsigned long long) lock->l_len,
1711  				(unsigned long long) lock->l_pid);
1712  		return fs->op.lock(path, fi, cmd, lock);
1713  	} else {
1714  		return -ENOSYS;
1715  	}
1716  }
1717  int fuse_fs_flock(struct fuse_fs *fs, const char *path,
1718  		  struct fuse_file_info *fi, int op)
1719  {
1720  	fuse_get_context()->private_data = fs->user_data;
1721  	if (fs->op.flock) {
1722  		if (fs->debug) {
1723  			int xop = op & ~LOCK_NB;
1724  			fuse_log(FUSE_LOG_DEBUG, "lock[%llu] %s%s\n",
1725  				(unsigned long long) fi->fh,
1726  				xop == LOCK_SH ? "LOCK_SH" :
1727  				(xop == LOCK_EX ? "LOCK_EX" :
1728  				 (xop == LOCK_UN ? "LOCK_UN" : "???")),
1729  				(op & LOCK_NB) ? "|LOCK_NB" : "");
1730  		}
1731  		return fs->op.flock(path, fi, op);
1732  	} else {
1733  		return -ENOSYS;
1734  	}
1735  }
1736  int fuse_fs_chown(struct fuse_fs *fs, const char *path, uid_t uid,
1737  		  gid_t gid, struct fuse_file_info *fi)
1738  {
1739  	fuse_get_context()->private_data = fs->user_data;
1740  	if (fs->op.chown) {
1741  		if (fs->debug) {
1742  			char buf[10];
1743  			fuse_log(FUSE_LOG_DEBUG, "chown[%s] %s %lu %lu\n",
1744  				file_info_string(fi, buf, sizeof(buf)),
1745  				path, (unsigned long) uid, (unsigned long) gid);
1746  		}
1747  		return fs->op.chown(path, uid, gid, fi);
1748  	} else {
1749  		return -ENOSYS;
1750  	}
1751  }
1752  int fuse_fs_truncate(struct fuse_fs *fs, const char *path, off_t size,
1753  		      struct fuse_file_info *fi)
1754  {
1755  	fuse_get_context()->private_data = fs->user_data;
1756  	if (fs->op.truncate) {
1757  		if (fs->debug) {
1758  			char buf[10];
1759  			fuse_log(FUSE_LOG_DEBUG, "truncate[%s] %llu\n",
1760  				file_info_string(fi, buf, sizeof(buf)),
1761  				(unsigned long long) size);
1762  		}
1763  		return fs->op.truncate(path, size, fi);
1764  	} else {
1765  		return -ENOSYS;
1766  	}
1767  }
1768  int fuse_fs_utimens(struct fuse_fs *fs, const char *path,
1769  		    const struct timespec tv[2], struct fuse_file_info *fi)
1770  {
1771  	fuse_get_context()->private_data = fs->user_data;
1772  	if (fs->op.utimens) {
1773  		if (fs->debug) {
1774  			char buf[10];
1775  			fuse_log(FUSE_LOG_DEBUG, "utimens[%s] %s %li.%09lu %li.%09lu\n",
1776  				file_info_string(fi, buf, sizeof(buf)),
1777  				path, tv[0].tv_sec, tv[0].tv_nsec,
1778  				tv[1].tv_sec, tv[1].tv_nsec);
1779  		}
1780  		return fs->op.utimens(path, tv, fi);
1781  	} else {
1782  		return -ENOSYS;
1783  	}
1784  }
1785  int fuse_fs_access(struct fuse_fs *fs, const char *path, int mask)
1786  {
1787  	fuse_get_context()->private_data = fs->user_data;
1788  	if (fs->op.access) {
1789  		if (fs->debug)
1790  			fuse_log(FUSE_LOG_DEBUG, "access %s 0%o\n", path, mask);
1791  		return fs->op.access(path, mask);
1792  	} else {
1793  		return -ENOSYS;
1794  	}
1795  }
1796  int fuse_fs_readlink(struct fuse_fs *fs, const char *path, char *buf,
1797  		     size_t len)
1798  {
1799  	fuse_get_context()->private_data = fs->user_data;
1800  	if (fs->op.readlink) {
1801  		if (fs->debug)
1802  			fuse_log(FUSE_LOG_DEBUG, "readlink %s %lu\n", path,
1803  				(unsigned long) len);
1804  		return fs->op.readlink(path, buf, len);
1805  	} else {
1806  		return -ENOSYS;
1807  	}
1808  }
1809  int fuse_fs_mknod(struct fuse_fs *fs, const char *path, mode_t mode,
1810  		  dev_t rdev)
1811  {
1812  	fuse_get_context()->private_data = fs->user_data;
1813  	if (fs->op.mknod) {
1814  		if (fs->debug)
1815  			fuse_log(FUSE_LOG_DEBUG, "mknod %s 0%o 0x%llx umask=0%03o\n",
1816  				path, mode, (unsigned long long) rdev,
1817  				fuse_get_context()->umask);
1818  		return fs->op.mknod(path, mode, rdev);
1819  	} else {
1820  		return -ENOSYS;
1821  	}
1822  }
1823  int fuse_fs_mkdir(struct fuse_fs *fs, const char *path, mode_t mode)
1824  {
1825  	fuse_get_context()->private_data = fs->user_data;
1826  	if (fs->op.mkdir) {
1827  		if (fs->debug)
1828  			fuse_log(FUSE_LOG_DEBUG, "mkdir %s 0%o umask=0%03o\n",
1829  				path, mode, fuse_get_context()->umask);
1830  		return fs->op.mkdir(path, mode);
1831  	} else {
1832  		return -ENOSYS;
1833  	}
1834  }
1835  int fuse_fs_setxattr(struct fuse_fs *fs, const char *path, const char *name,
1836  		     const char *value, size_t size, int flags)
1837  {
1838  	fuse_get_context()->private_data = fs->user_data;
1839  	if (fs->op.setxattr) {
1840  		if (fs->debug)
1841  			fuse_log(FUSE_LOG_DEBUG, "setxattr %s %s %lu 0x%x\n",
1842  				path, name, (unsigned long) size, flags);
1843  		return fs->op.setxattr(path, name, value, size, flags);
1844  	} else {
1845  		return -ENOSYS;
1846  	}
1847  }
1848  int fuse_fs_getxattr(struct fuse_fs *fs, const char *path, const char *name,
1849  		     char *value, size_t size)
1850  {
1851  	fuse_get_context()->private_data = fs->user_data;
1852  	if (fs->op.getxattr) {
1853  		if (fs->debug)
1854  			fuse_log(FUSE_LOG_DEBUG, "getxattr %s %s %lu\n",
1855  				path, name, (unsigned long) size);
1856  		return fs->op.getxattr(path, name, value, size);
1857  	} else {
1858  		return -ENOSYS;
1859  	}
1860  }
1861  int fuse_fs_listxattr(struct fuse_fs *fs, const char *path, char *list,
1862  		      size_t size)
1863  {
1864  	fuse_get_context()->private_data = fs->user_data;
1865  	if (fs->op.listxattr) {
1866  		if (fs->debug)
1867  			fuse_log(FUSE_LOG_DEBUG, "listxattr %s %lu\n",
1868  				path, (unsigned long) size);
1869  		return fs->op.listxattr(path, list, size);
1870  	} else {
1871  		return -ENOSYS;
1872  	}
1873  }
1874  int fuse_fs_bmap(struct fuse_fs *fs, const char *path, size_t blocksize,
1875  		 uint64_t *idx)
1876  {
1877  	fuse_get_context()->private_data = fs->user_data;
1878  	if (fs->op.bmap) {
1879  		if (fs->debug)
1880  			fuse_log(FUSE_LOG_DEBUG, "bmap %s blocksize: %lu index: %llu\n",
1881  				path, (unsigned long) blocksize,
1882  				(unsigned long long) *idx);
1883  		return fs->op.bmap(path, blocksize, idx);
1884  	} else {
1885  		return -ENOSYS;
1886  	}
1887  }
1888  int fuse_fs_removexattr(struct fuse_fs *fs, const char *path, const char *name)
1889  {
1890  	fuse_get_context()->private_data = fs->user_data;
1891  	if (fs->op.removexattr) {
1892  		if (fs->debug)
1893  			fuse_log(FUSE_LOG_DEBUG, "removexattr %s %s\n", path, name);
1894  		return fs->op.removexattr(path, name);
1895  	} else {
1896  		return -ENOSYS;
1897  	}
1898  }
1899  int fuse_fs_ioctl(struct fuse_fs *fs, const char *path, unsigned int cmd,
1900  		  void *arg, struct fuse_file_info *fi, unsigned int flags,
1901  		  void *data)
1902  {
1903  	fuse_get_context()->private_data = fs->user_data;
1904  	if (fs->op.ioctl) {
1905  		if (fs->debug)
1906  			fuse_log(FUSE_LOG_DEBUG, "ioctl[%llu] 0x%x flags: 0x%x\n",
1907  				(unsigned long long) fi->fh, cmd, flags);
1908  		return fs->op.ioctl(path, cmd, arg, fi, flags, data);
1909  	} else
1910  		return -ENOSYS;
1911  }
1912  int fuse_fs_poll(struct fuse_fs *fs, const char *path,
1913  		 struct fuse_file_info *fi, struct fuse_pollhandle *ph,
1914  		 unsigned *reventsp)
1915  {
1916  	fuse_get_context()->private_data = fs->user_data;
1917  	if (fs->op.poll) {
1918  		int res;
1919  		if (fs->debug)
1920  			fuse_log(FUSE_LOG_DEBUG, "poll[%llu] ph: %p, events 0x%x\n",
1921  				(unsigned long long) fi->fh, ph,
1922  				fi->poll_events);
1923  		res = fs->op.poll(path, fi, ph, reventsp);
1924  		if (fs->debug && !res)
1925  			fuse_log(FUSE_LOG_DEBUG, "   poll[%llu] revents: 0x%x\n",
1926  				(unsigned long long) fi->fh, *reventsp);
1927  		return res;
1928  	} else
1929  		return -ENOSYS;
1930  }
1931  int fuse_fs_fallocate(struct fuse_fs *fs, const char *path, int mode,
1932  		off_t offset, off_t length, struct fuse_file_info *fi)
1933  {
1934  	fuse_get_context()->private_data = fs->user_data;
1935  	if (fs->op.fallocate) {
1936  		if (fs->debug)
1937  			fuse_log(FUSE_LOG_DEBUG, "fallocate %s mode %x, offset: %llu, length: %llu\n",
1938  				path,
1939  				mode,
1940  				(unsigned long long) offset,
1941  				(unsigned long long) length);
1942  		return fs->op.fallocate(path, mode, offset, length, fi);
1943  	} else
1944  		return -ENOSYS;
1945  }
1946  ssize_t fuse_fs_copy_file_range(struct fuse_fs *fs, const char *path_in,
1947  				struct fuse_file_info *fi_in, off_t off_in,
1948  				const char *path_out,
1949  				struct fuse_file_info *fi_out, off_t off_out,
1950  				size_t len, int flags)
1951  {
1952  	fuse_get_context()->private_data = fs->user_data;
1953  	if (fs->op.copy_file_range) {
1954  		if (fs->debug)
1955  			fuse_log(FUSE_LOG_DEBUG, "copy_file_range from %s:%llu to "
1956  			                "%s:%llu, length: %llu\n",
1957  				path_in,
1958  				(unsigned long long) off_in,
1959  				path_out,
1960  				(unsigned long long) off_out,
1961  				(unsigned long long) len);
1962  		return fs->op.copy_file_range(path_in, fi_in, off_in, path_out,
1963  					      fi_out, off_out, len, flags);
1964  	} else
1965  		return -ENOSYS;
1966  }
1967  off_t fuse_fs_lseek(struct fuse_fs *fs, const char *path, off_t off, int whence,
1968  		    struct fuse_file_info *fi)
1969  {
1970  	fuse_get_context()->private_data = fs->user_data;
1971  	if (fs->op.lseek) {
1972  		if (fs->debug) {
1973  			char buf[10];
1974  			fuse_log(FUSE_LOG_DEBUG, "lseek[%s] %llu %d\n",
1975  				file_info_string(fi, buf, sizeof(buf)),
1976  				(unsigned long long) off, whence);
1977  		}
1978  		return fs->op.lseek(path, off, whence, fi);
1979  	} else {
1980  		return -ENOSYS;
1981  	}
1982  }
1983  static int is_open(struct fuse *f, fuse_ino_t dir, const char *name)
1984  {
1985  	struct node *node;
1986  	int isopen = 0;
1987  	pthread_mutex_lock(&f->lock);
1988  	node = lookup_node(f, dir, name);
1989  	if (node && node->open_count > 0)
1990  		isopen = 1;
1991  	pthread_mutex_unlock(&f->lock);
1992  	return isopen;
1993  }
1994  static char *hidden_name(struct fuse *f, fuse_ino_t dir, const char *oldname,
1995  			 char *newname, size_t bufsize)
1996  {
1997  	struct stat buf;
1998  	struct node *node;
1999  	struct node *newnode;
2000  	char *newpath;
2001  	int res;
2002  	int failctr = 10;
2003  	do {
2004  		pthread_mutex_lock(&f->lock);
2005  		node = lookup_node(f, dir, oldname);
2006  		if (node == NULL) {
2007  			pthread_mutex_unlock(&f->lock);
2008  			return NULL;
2009  		}
2010  		do {
2011  			f->hidectr ++;
2012  			snprintf(newname, bufsize, ".fuse_hidden%08x%08x",
2013  				 (unsigned int) node->nodeid, f->hidectr);
2014  			newnode = lookup_node(f, dir, newname);
2015  		} while(newnode);
2016  		res = try_get_path(f, dir, newname, &newpath, NULL, false);
2017  		pthread_mutex_unlock(&f->lock);
2018  		if (res)
2019  			break;
2020  		memset(&buf, 0, sizeof(buf));
2021  		res = fuse_fs_getattr(f->fs, newpath, &buf, NULL);
2022  		if (res == -ENOENT)
2023  			break;
2024  		free(newpath);
2025  		newpath = NULL;
2026  	} while(res == 0 && --failctr);
2027  	return newpath;
2028  }
2029  static int hide_node(struct fuse *f, const char *oldpath,
2030  		     fuse_ino_t dir, const char *oldname)
2031  {
2032  	char newname[64];
2033  	char *newpath;
2034  	int err = -EBUSY;
2035  	newpath = hidden_name(f, dir, oldname, newname, sizeof(newname));
2036  	if (newpath) {
2037  		err = fuse_fs_rename(f->fs, oldpath, newpath, 0);
2038  		if (!err)
2039  			err = rename_node(f, dir, oldname, dir, newname, 1);
2040  		free(newpath);
2041  	}
2042  	return err;
2043  }
2044  static int mtime_eq(const struct stat *stbuf, const struct timespec *ts)
2045  {
2046  	return stbuf->st_mtime == ts->tv_sec &&
2047  		ST_MTIM_NSEC(stbuf) == ts->tv_nsec;
2048  }
2049  #ifndef CLOCK_MONOTONIC
2050  #define CLOCK_MONOTONIC CLOCK_REALTIME
2051  #endif
2052  static void curr_time(struct timespec *now)
2053  {
2054  	static clockid_t clockid = CLOCK_MONOTONIC;
2055  	int res = clock_gettime(clockid, now);
2056  	if (res == -1 && errno == EINVAL) {
2057  		clockid = CLOCK_REALTIME;
2058  		res = clock_gettime(clockid, now);
2059  	}
2060  	if (res == -1) {
2061  		perror("fuse: clock_gettime");
2062  		abort();
2063  	}
2064  }
2065  static void update_stat(struct node *node, const struct stat *stbuf)
2066  {
2067  	if (node->cache_valid && (!mtime_eq(stbuf, &node->mtime) ||
2068  				  stbuf->st_size != node->size))
2069  		node->cache_valid = 0;
2070  	node->mtime.tv_sec = stbuf->st_mtime;
2071  	node->mtime.tv_nsec = ST_MTIM_NSEC(stbuf);
2072  	node->size = stbuf->st_size;
2073  	curr_time(&node->stat_updated);
2074  }
2075  static int do_lookup(struct fuse *f, fuse_ino_t nodeid, const char *name,
2076  		     struct fuse_entry_param *e)
2077  {
2078  	struct node *node;
2079  	node = find_node(f, nodeid, name);
2080  	if (node == NULL)
2081  		return -ENOMEM;
2082  	e->ino = node->nodeid;
2083  	e->generation = node->generation;
2084  	e->entry_timeout = f->conf.entry_timeout;
2085  	e->attr_timeout = f->conf.attr_timeout;
2086  	if (f->conf.auto_cache) {
2087  		pthread_mutex_lock(&f->lock);
2088  		update_stat(node, &e->attr);
2089  		pthread_mutex_unlock(&f->lock);
2090  	}
2091  	set_stat(f, e->ino, &e->attr);
2092  	return 0;
2093  }
2094  static int lookup_path(struct fuse *f, fuse_ino_t nodeid,
2095  		       const char *name, const char *path,
2096  		       struct fuse_entry_param *e, struct fuse_file_info *fi)
2097  {
2098  	int res;
2099  	memset(e, 0, sizeof(struct fuse_entry_param));
2100  	res = fuse_fs_getattr(f->fs, path, &e->attr, fi);
2101  	if (res == 0) {
2102  		res = do_lookup(f, nodeid, name, e);
2103  		if (res == 0 && f->conf.debug) {
2104  			fuse_log(FUSE_LOG_DEBUG, "   NODEID: %llu\n",
2105  				(unsigned long long) e->ino);
2106  		}
2107  	}
2108  	return res;
2109  }
2110  static struct fuse_context_i *fuse_get_context_internal(void)
2111  {
2112  	return (struct fuse_context_i *) pthread_getspecific(fuse_context_key);
2113  }
2114  static struct fuse_context_i *fuse_create_context(struct fuse *f)
2115  {
2116  	struct fuse_context_i *c = fuse_get_context_internal();
2117  	if (c == NULL) {
2118  		c = (struct fuse_context_i *)
2119  			calloc(1, sizeof(struct fuse_context_i));
2120  		if (c == NULL) {
2121  			fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate thread specific data\n");
2122  			abort();
2123  		}
2124  		pthread_setspecific(fuse_context_key, c);
2125  	} else {
2126  		memset(c, 0, sizeof(*c));
2127  	}
2128  	c->ctx.fuse = f;
2129  	return c;
2130  }
2131  static void fuse_freecontext(void *data)
2132  {
2133  	free(data);
2134  }
2135  static int fuse_create_context_key(void)
2136  {
2137  	int err = 0;
2138  	pthread_mutex_lock(&fuse_context_lock);
2139  	if (!fuse_context_ref) {
2140  		err = pthread_key_create(&fuse_context_key, fuse_freecontext);
2141  		if (err) {
2142  			fuse_log(FUSE_LOG_ERR, "fuse: failed to create thread specific key: %s\n",
2143  				strerror(err));
2144  			pthread_mutex_unlock(&fuse_context_lock);
2145  			return -1;
2146  		}
2147  	}
2148  	fuse_context_ref++;
2149  	pthread_mutex_unlock(&fuse_context_lock);
2150  	return 0;
2151  }
2152  static void fuse_delete_context_key(void)
2153  {
2154  	pthread_mutex_lock(&fuse_context_lock);
2155  	fuse_context_ref--;
2156  	if (!fuse_context_ref) {
2157  		free(pthread_getspecific(fuse_context_key));
2158  		pthread_key_delete(fuse_context_key);
2159  	}
2160  	pthread_mutex_unlock(&fuse_context_lock);
2161  }
2162  static struct fuse *req_fuse_prepare(fuse_req_t req)
2163  {
2164  	struct fuse_context_i *c = fuse_create_context(req_fuse(req));
2165  	const struct fuse_ctx *ctx = fuse_req_ctx(req);
2166  	c->req = req;
2167  	c->ctx.uid = ctx->uid;
2168  	c->ctx.gid = ctx->gid;
2169  	c->ctx.pid = ctx->pid;
2170  	c->ctx.umask = ctx->umask;
2171  	return c->ctx.fuse;
2172  }
2173  static inline void reply_err(fuse_req_t req, int err)
2174  {
2175  	fuse_reply_err(req, -err);
2176  }
2177  static void reply_entry(fuse_req_t req, const struct fuse_entry_param *e,
2178  			int err)
2179  {
2180  	if (!err) {
2181  		struct fuse *f = req_fuse(req);
2182  		if (fuse_reply_entry(req, e) == -ENOENT) {
2183  			if  (e->ino != 0)
2184  				forget_node(f, e->ino, 1);
2185  		}
2186  	} else
2187  		reply_err(req, err);
2188  }
2189  void fuse_fs_init(struct fuse_fs *fs, struct fuse_conn_info *conn,
2190  		  struct fuse_config *cfg)
2191  {
2192  	fuse_get_context()->private_data = fs->user_data;
2193  	if (!fs->op.write_buf)
2194  		conn->want &= ~FUSE_CAP_SPLICE_READ;
2195  	if (!fs->op.lock)
2196  		conn->want &= ~FUSE_CAP_POSIX_LOCKS;
2197  	if (!fs->op.flock)
2198  		conn->want &= ~FUSE_CAP_FLOCK_LOCKS;
2199  	if (fs->op.init)
2200  		fs->user_data = fs->op.init(conn, cfg);
2201  }
2202  static void fuse_lib_init(void *data, struct fuse_conn_info *conn)
2203  {
2204  	struct fuse *f = (struct fuse *) data;
2205  	fuse_create_context(f);
2206  	if(conn->capable & FUSE_CAP_EXPORT_SUPPORT)
2207  		conn->want |= FUSE_CAP_EXPORT_SUPPORT;
2208  	fuse_fs_init(f->fs, conn, &f->conf);
2209  }
2210  void fuse_fs_destroy(struct fuse_fs *fs)
2211  {
2212  	fuse_get_context()->private_data = fs->user_data;
2213  	if (fs->op.destroy)
2214  		fs->op.destroy(fs->user_data);
2215  }
2216  static void fuse_lib_destroy(void *data)
2217  {
2218  	struct fuse *f = (struct fuse *) data;
2219  	fuse_create_context(f);
2220  	fuse_fs_destroy(f->fs);
2221  }
2222  static void fuse_lib_lookup(fuse_req_t req, fuse_ino_t parent,
2223  			    const char *name)
2224  {
2225  	struct fuse *f = req_fuse_prepare(req);
2226  	struct fuse_entry_param e;
2227  	char *path;
2228  	int err;
2229  	struct node *dot = NULL;
2230  	if (name[0] == '.') {
2231  		int len = strlen(name);
2232  		if (len == 1 || (name[1] == '.' && len == 2)) {
2233  			pthread_mutex_lock(&f->lock);
2234  			if (len == 1) {
2235  				if (f->conf.debug)
2236  					fuse_log(FUSE_LOG_DEBUG, "LOOKUP-DOT\n");
2237  				dot = get_node_nocheck(f, parent);
2238  				if (dot == NULL) {
2239  					pthread_mutex_unlock(&f->lock);
2240  					reply_entry(req, &e, -ESTALE);
2241  					return;
2242  				}
2243  				dot->refctr++;
2244  			} else {
2245  				if (f->conf.debug)
2246  					fuse_log(FUSE_LOG_DEBUG, "LOOKUP-DOTDOT\n");
2247  				parent = get_node(f, parent)->parent->nodeid;
2248  			}
2249  			pthread_mutex_unlock(&f->lock);
2250  			name = NULL;
2251  		}
2252  	}
2253  	err = get_path_name(f, parent, name, &path);
2254  	if (!err) {
2255  		struct fuse_intr_data d;
2256  		if (f->conf.debug)
2257  			fuse_log(FUSE_LOG_DEBUG, "LOOKUP %s\n", path);
2258  		fuse_prepare_interrupt(f, req, &d);
2259  		err = lookup_path(f, parent, name, path, &e, NULL);
2260  		if (err == -ENOENT && f->conf.negative_timeout != 0.0) {
2261  			e.ino = 0;
2262  			e.entry_timeout = f->conf.negative_timeout;
2263  			err = 0;
2264  		}
2265  		fuse_finish_interrupt(f, req, &d);
2266  		free_path(f, parent, path);
2267  	}
2268  	if (dot) {
2269  		pthread_mutex_lock(&f->lock);
2270  		unref_node(f, dot);
2271  		pthread_mutex_unlock(&f->lock);
2272  	}
2273  	reply_entry(req, &e, err);
2274  }
2275  static void do_forget(struct fuse *f, fuse_ino_t ino, uint64_t nlookup)
2276  {
2277  	if (f->conf.debug)
2278  		fuse_log(FUSE_LOG_DEBUG, "FORGET %llu/%llu\n", (unsigned long long)ino,
2279  			(unsigned long long) nlookup);
2280  	forget_node(f, ino, nlookup);
2281  }
2282  static void fuse_lib_forget(fuse_req_t req, fuse_ino_t ino, uint64_t nlookup)
2283  {
2284  	do_forget(req_fuse(req), ino, nlookup);
2285  	fuse_reply_none(req);
2286  }
2287  static void fuse_lib_forget_multi(fuse_req_t req, size_t count,
2288  				  struct fuse_forget_data *forgets)
2289  {
2290  	struct fuse *f = req_fuse(req);
2291  	size_t i;
2292  	for (i = 0; i < count; i++)
2293  		do_forget(f, forgets[i].ino, forgets[i].nlookup);
2294  	fuse_reply_none(req);
2295  }
2296  static void fuse_lib_getattr(fuse_req_t req, fuse_ino_t ino,
2297  			     struct fuse_file_info *fi)
2298  {
2299  	struct fuse *f = req_fuse_prepare(req);
2300  	struct stat buf;
2301  	char *path;
2302  	int err;
2303  	memset(&buf, 0, sizeof(buf));
2304  	if (fi != NULL)
2305  		err = get_path_nullok(f, ino, &path);
2306  	else
2307  		err = get_path(f, ino, &path);
2308  	if (!err) {
2309  		struct fuse_intr_data d;
2310  		fuse_prepare_interrupt(f, req, &d);
2311  		err = fuse_fs_getattr(f->fs, path, &buf, fi);
2312  		fuse_finish_interrupt(f, req, &d);
2313  		free_path(f, ino, path);
2314  	}
2315  	if (!err) {
2316  		struct node *node;
2317  		pthread_mutex_lock(&f->lock);
2318  		node = get_node(f, ino);
2319  		if (node->is_hidden && buf.st_nlink > 0)
2320  			buf.st_nlink--;
2321  		if (f->conf.auto_cache)
2322  			update_stat(node, &buf);
2323  		pthread_mutex_unlock(&f->lock);
2324  		set_stat(f, ino, &buf);
2325  		fuse_reply_attr(req, &buf, f->conf.attr_timeout);
2326  	} else
2327  		reply_err(req, err);
2328  }
2329  int fuse_fs_chmod(struct fuse_fs *fs, const char *path, mode_t mode,
2330  		  struct fuse_file_info *fi)
2331  {
2332  	fuse_get_context()->private_data = fs->user_data;
2333  	if (fs->op.chmod) {
2334  		if (fs->debug) {
2335  			char buf[10];
2336  			fuse_log(FUSE_LOG_DEBUG, "chmod[%s] %s %llo\n",
2337  				file_info_string(fi, buf, sizeof(buf)),
2338  				path, (unsigned long long) mode);
2339  		}
2340  		return fs->op.chmod(path, mode, fi);
2341  	}
2342  	else
2343  		return -ENOSYS;
2344  }
2345  static void fuse_lib_setattr(fuse_req_t req, fuse_ino_t ino, struct stat *attr,
2346  			     int valid, struct fuse_file_info *fi)
2347  {
2348  	struct fuse *f = req_fuse_prepare(req);
2349  	struct stat buf;
2350  	char *path;
2351  	int err;
2352  	memset(&buf, 0, sizeof(buf));
2353  	if (fi != NULL)
2354  		err = get_path_nullok(f, ino, &path);
2355  	else
2356  		err = get_path(f, ino, &path);
2357  	if (!err) {
2358  		struct fuse_intr_data d;
2359  		fuse_prepare_interrupt(f, req, &d);
2360  		err = 0;
2361  		if (!err && (valid & FUSE_SET_ATTR_MODE))
2362  			err = fuse_fs_chmod(f->fs, path, attr->st_mode, fi);
2363  		if (!err && (valid & (FUSE_SET_ATTR_UID | FUSE_SET_ATTR_GID))) {
2364  			uid_t uid = (valid & FUSE_SET_ATTR_UID) ?
2365  				attr->st_uid : (uid_t) -1;
2366  			gid_t gid = (valid & FUSE_SET_ATTR_GID) ?
2367  				attr->st_gid : (gid_t) -1;
2368  			err = fuse_fs_chown(f->fs, path, uid, gid, fi);
2369  		}
2370  		if (!err && (valid & FUSE_SET_ATTR_SIZE)) {
2371  			err = fuse_fs_truncate(f->fs, path,
2372  					       attr->st_size, fi);
2373  		}
2374  #ifdef HAVE_UTIMENSAT
2375  		if (!err &&
2376  		    (valid & (FUSE_SET_ATTR_ATIME | FUSE_SET_ATTR_MTIME))) {
2377  			struct timespec tv[2];
2378  			tv[0].tv_sec = 0;
2379  			tv[1].tv_sec = 0;
2380  			tv[0].tv_nsec = UTIME_OMIT;
2381  			tv[1].tv_nsec = UTIME_OMIT;
2382  			if (valid & FUSE_SET_ATTR_ATIME_NOW)
2383  				tv[0].tv_nsec = UTIME_NOW;
2384  			else if (valid & FUSE_SET_ATTR_ATIME)
2385  				tv[0] = attr->st_atim;
2386  			if (valid & FUSE_SET_ATTR_MTIME_NOW)
2387  				tv[1].tv_nsec = UTIME_NOW;
2388  			else if (valid & FUSE_SET_ATTR_MTIME)
2389  				tv[1] = attr->st_mtim;
2390  			err = fuse_fs_utimens(f->fs, path, tv, fi);
2391  		} else
2392  #endif
2393  		if (!err &&
2394  		    (valid & (FUSE_SET_ATTR_ATIME | FUSE_SET_ATTR_MTIME)) ==
2395  		    (FUSE_SET_ATTR_ATIME | FUSE_SET_ATTR_MTIME)) {
2396  			struct timespec tv[2];
2397  			tv[0].tv_sec = attr->st_atime;
2398  			tv[0].tv_nsec = ST_ATIM_NSEC(attr);
2399  			tv[1].tv_sec = attr->st_mtime;
2400  			tv[1].tv_nsec = ST_MTIM_NSEC(attr);
2401  			err = fuse_fs_utimens(f->fs, path, tv, fi);
2402  		}
2403  		if (!err) {
2404  			err = fuse_fs_getattr(f->fs, path, &buf, fi);
2405  		}
2406  		fuse_finish_interrupt(f, req, &d);
2407  		free_path(f, ino, path);
2408  	}
2409  	if (!err) {
2410  		if (f->conf.auto_cache) {
2411  			pthread_mutex_lock(&f->lock);
2412  			update_stat(get_node(f, ino), &buf);
2413  			pthread_mutex_unlock(&f->lock);
2414  		}
2415  		set_stat(f, ino, &buf);
2416  		fuse_reply_attr(req, &buf, f->conf.attr_timeout);
2417  	} else
2418  		reply_err(req, err);
2419  }
2420  static void fuse_lib_access(fuse_req_t req, fuse_ino_t ino, int mask)
2421  {
2422  	struct fuse *f = req_fuse_prepare(req);
2423  	char *path;
2424  	int err;
2425  	err = get_path(f, ino, &path);
2426  	if (!err) {
2427  		struct fuse_intr_data d;
2428  		fuse_prepare_interrupt(f, req, &d);
2429  		err = fuse_fs_access(f->fs, path, mask);
2430  		fuse_finish_interrupt(f, req, &d);
2431  		free_path(f, ino, path);
2432  	}
2433  	reply_err(req, err);
2434  }
2435  static void fuse_lib_readlink(fuse_req_t req, fuse_ino_t ino)
2436  {
2437  	struct fuse *f = req_fuse_prepare(req);
2438  	char linkname[PATH_MAX + 1];
2439  	char *path;
2440  	int err;
2441  	err = get_path(f, ino, &path);
2442  	if (!err) {
2443  		struct fuse_intr_data d;
2444  		fuse_prepare_interrupt(f, req, &d);
2445  		err = fuse_fs_readlink(f->fs, path, linkname, sizeof(linkname));
2446  		fuse_finish_interrupt(f, req, &d);
2447  		free_path(f, ino, path);
2448  	}
2449  	if (!err) {
2450  		linkname[PATH_MAX] = '\0';
2451  		fuse_reply_readlink(req, linkname);
2452  	} else
2453  		reply_err(req, err);
2454  }
2455  static void fuse_lib_mknod(fuse_req_t req, fuse_ino_t parent, const char *name,
2456  			   mode_t mode, dev_t rdev)
2457  {
2458  	struct fuse *f = req_fuse_prepare(req);
2459  	struct fuse_entry_param e;
2460  	char *path;
2461  	int err;
2462  	err = get_path_name(f, parent, name, &path);
2463  	if (!err) {
2464  		struct fuse_intr_data d;
2465  		fuse_prepare_interrupt(f, req, &d);
2466  		err = -ENOSYS;
2467  		if (S_ISREG(mode)) {
2468  			struct fuse_file_info fi;
2469  			memset(&fi, 0, sizeof(fi));
2470  			fi.flags = O_CREAT | O_EXCL | O_WRONLY;
2471  			err = fuse_fs_create(f->fs, path, mode, &fi);
2472  			if (!err) {
2473  				err = lookup_path(f, parent, name, path, &e,
2474  						  &fi);
2475  				fuse_fs_release(f->fs, path, &fi);
2476  			}
2477  		}
2478  		if (err == -ENOSYS) {
2479  			err = fuse_fs_mknod(f->fs, path, mode, rdev);
2480  			if (!err)
2481  				err = lookup_path(f, parent, name, path, &e,
2482  						  NULL);
2483  		}
2484  		fuse_finish_interrupt(f, req, &d);
2485  		free_path(f, parent, path);
2486  	}
2487  	reply_entry(req, &e, err);
2488  }
2489  static void fuse_lib_mkdir(fuse_req_t req, fuse_ino_t parent, const char *name,
2490  			   mode_t mode)
2491  {
2492  	struct fuse *f = req_fuse_prepare(req);
2493  	struct fuse_entry_param e;
2494  	char *path;
2495  	int err;
2496  	err = get_path_name(f, parent, name, &path);
2497  	if (!err) {
2498  		struct fuse_intr_data d;
2499  		fuse_prepare_interrupt(f, req, &d);
2500  		err = fuse_fs_mkdir(f->fs, path, mode);
2501  		if (!err)
2502  			err = lookup_path(f, parent, name, path, &e, NULL);
2503  		fuse_finish_interrupt(f, req, &d);
2504  		free_path(f, parent, path);
2505  	}
2506  	reply_entry(req, &e, err);
2507  }
2508  static void fuse_lib_unlink(fuse_req_t req, fuse_ino_t parent,
2509  			    const char *name)
2510  {
2511  	struct fuse *f = req_fuse_prepare(req);
2512  	struct node *wnode;
2513  	char *path;
2514  	int err;
2515  	err = get_path_wrlock(f, parent, name, &path, &wnode);
2516  	if (!err) {
2517  		struct fuse_intr_data d;
2518  		fuse_prepare_interrupt(f, req, &d);
2519  		if (!f->conf.hard_remove && is_open(f, parent, name)) {
2520  			err = hide_node(f, path, parent, name);
2521  			if (!err) {
2522  				if (!is_open(f, parent, wnode->name)) {
2523  					char *unlinkpath;
2524  					if (try_get_path(f, wnode->nodeid, NULL, &unlinkpath, NULL, false) == 0) {
2525  						err = fuse_fs_unlink(f->fs, unlinkpath);
2526  						if (!err)
2527  							remove_node(f, parent, wnode->name);
2528  						free(unlinkpath);
2529  					}
2530  				}
2531  			}
2532  		} else {
2533  			err = fuse_fs_unlink(f->fs, path);
2534  			if (!err)
2535  				remove_node(f, parent, name);
2536  		}
2537  		fuse_finish_interrupt(f, req, &d);
2538  		free_path_wrlock(f, parent, wnode, path);
2539  	}
2540  	reply_err(req, err);
2541  }
2542  static void fuse_lib_rmdir(fuse_req_t req, fuse_ino_t parent, const char *name)
2543  {
2544  	struct fuse *f = req_fuse_prepare(req);
2545  	struct node *wnode;
2546  	char *path;
2547  	int err;
2548  	err = get_path_wrlock(f, parent, name, &path, &wnode);
2549  	if (!err) {
2550  		struct fuse_intr_data d;
2551  		fuse_prepare_interrupt(f, req, &d);
2552  		err = fuse_fs_rmdir(f->fs, path);
2553  		fuse_finish_interrupt(f, req, &d);
2554  		if (!err)
2555  			remove_node(f, parent, name);
2556  		free_path_wrlock(f, parent, wnode, path);
2557  	}
2558  	reply_err(req, err);
2559  }
2560  static void fuse_lib_symlink(fuse_req_t req, const char *linkname,
2561  			     fuse_ino_t parent, const char *name)
2562  {
2563  	struct fuse *f = req_fuse_prepare(req);
2564  	struct fuse_entry_param e;
2565  	char *path;
2566  	int err;
2567  	err = get_path_name(f, parent, name, &path);
2568  	if (!err) {
2569  		struct fuse_intr_data d;
2570  		fuse_prepare_interrupt(f, req, &d);
2571  		err = fuse_fs_symlink(f->fs, linkname, path);
2572  		if (!err)
2573  			err = lookup_path(f, parent, name, path, &e, NULL);
2574  		fuse_finish_interrupt(f, req, &d);
2575  		free_path(f, parent, path);
2576  	}
2577  	reply_entry(req, &e, err);
2578  }
2579  static void fuse_lib_rename(fuse_req_t req, fuse_ino_t olddir,
2580  			    const char *oldname, fuse_ino_t newdir,
2581  			    const char *newname, unsigned int flags)
2582  {
2583  	struct fuse *f = req_fuse_prepare(req);
2584  	char *oldpath;
2585  	char *newpath;
2586  	struct node *wnode1;
2587  	struct node *wnode2;
2588  	int err;
2589  	err = get_path2(f, olddir, oldname, newdir, newname,
2590  			&oldpath, &newpath, &wnode1, &wnode2);
2591  	if (!err) {
2592  		struct fuse_intr_data d;
2593  		err = 0;
2594  		fuse_prepare_interrupt(f, req, &d);
2595  		if (!f->conf.hard_remove && !(flags & RENAME_EXCHANGE) &&
2596  		    is_open(f, newdir, newname))
2597  			err = hide_node(f, newpath, newdir, newname);
2598  		if (!err) {
2599  			err = fuse_fs_rename(f->fs, oldpath, newpath, flags);
2600  			if (!err) {
2601  				if (flags & RENAME_EXCHANGE) {
2602  					err = exchange_node(f, olddir, oldname,
2603  							    newdir, newname);
2604  				} else {
2605  					err = rename_node(f, olddir, oldname,
2606  							  newdir, newname, 0);
2607  				}
2608  			}
2609  		}
2610  		fuse_finish_interrupt(f, req, &d);
2611  		free_path2(f, olddir, newdir, wnode1, wnode2, oldpath, newpath);
2612  	}
2613  	reply_err(req, err);
2614  }
2615  static void fuse_lib_link(fuse_req_t req, fuse_ino_t ino, fuse_ino_t newparent,
2616  			  const char *newname)
2617  {
2618  	struct fuse *f = req_fuse_prepare(req);
2619  	struct fuse_entry_param e;
2620  	char *oldpath;
2621  	char *newpath;
2622  	int err;
2623  	err = get_path2(f, ino, NULL, newparent, newname,
2624  			&oldpath, &newpath, NULL, NULL);
2625  	if (!err) {
2626  		struct fuse_intr_data d;
2627  		fuse_prepare_interrupt(f, req, &d);
2628  		err = fuse_fs_link(f->fs, oldpath, newpath);
2629  		if (!err)
2630  			err = lookup_path(f, newparent, newname, newpath,
2631  					  &e, NULL);
2632  		fuse_finish_interrupt(f, req, &d);
2633  		free_path2(f, ino, newparent, NULL, NULL, oldpath, newpath);
2634  	}
2635  	reply_entry(req, &e, err);
2636  }
2637  static void fuse_do_release(struct fuse *f, fuse_ino_t ino, const char *path,
2638  			    struct fuse_file_info *fi)
2639  {
2640  	struct node *node;
2641  	int unlink_hidden = 0;
2642  	fuse_fs_release(f->fs, path, fi);
2643  	pthread_mutex_lock(&f->lock);
2644  	node = get_node(f, ino);
2645  	assert(node->open_count > 0);
2646  	--node->open_count;
2647  	if (node->is_hidden && !node->open_count) {
2648  		unlink_hidden = 1;
2649  		node->is_hidden = 0;
2650  	}
2651  	pthread_mutex_unlock(&f->lock);
2652  	if(unlink_hidden) {
2653  		if (path) {
2654  			fuse_fs_unlink(f->fs, path);
2655  		} else if (f->conf.nullpath_ok) {
2656  			char *unlinkpath;
2657  			if (get_path(f, ino, &unlinkpath) == 0)
2658  				fuse_fs_unlink(f->fs, unlinkpath);
2659  			free_path(f, ino, unlinkpath);
2660  		}
2661  	}
2662  }
2663  static void fuse_lib_create(fuse_req_t req, fuse_ino_t parent,
2664  			    const char *name, mode_t mode,
2665  			    struct fuse_file_info *fi)
2666  {
2667  	struct fuse *f = req_fuse_prepare(req);
2668  	struct fuse_intr_data d;
2669  	struct fuse_entry_param e;
2670  	char *path;
2671  	int err;
2672  	err = get_path_name(f, parent, name, &path);
2673  	if (!err) {
2674  		fuse_prepare_interrupt(f, req, &d);
2675  		err = fuse_fs_create(f->fs, path, mode, fi);
2676  		if (!err) {
2677  			err = lookup_path(f, parent, name, path, &e, fi);
2678  			if (err)
2679  				fuse_fs_release(f->fs, path, fi);
2680  			else if (!S_ISREG(e.attr.st_mode)) {
2681  				err = -EIO;
2682  				fuse_fs_release(f->fs, path, fi);
2683  				forget_node(f, e.ino, 1);
2684  			} else {
2685  				if (f->conf.direct_io)
2686  					fi->direct_io = 1;
2687  				if (f->conf.kernel_cache)
2688  					fi->keep_cache = 1;
2689  				if (fi->direct_io &&
2690  				    f->conf.parallel_direct_writes)
2691  					fi->parallel_direct_writes = 1;
2692  			}
2693  		}
2694  		fuse_finish_interrupt(f, req, &d);
2695  	}
2696  	if (!err) {
2697  		pthread_mutex_lock(&f->lock);
2698  		get_node(f, e.ino)->open_count++;
2699  		pthread_mutex_unlock(&f->lock);
2700  		if (fuse_reply_create(req, &e, fi) == -ENOENT) {
2701  			fuse_do_release(f, e.ino, path, fi);
2702  			forget_node(f, e.ino, 1);
2703  		}
2704  	} else {
2705  		reply_err(req, err);
2706  	}
2707  	free_path(f, parent, path);
2708  }
2709  static double diff_timespec(const struct timespec *t1,
2710  			    const struct timespec *t2)
2711  {
2712  	return (t1->tv_sec - t2->tv_sec) +
2713  		((double) t1->tv_nsec - (double) t2->tv_nsec) / 1000000000.0;
2714  }
2715  static void open_auto_cache(struct fuse *f, fuse_ino_t ino, const char *path,
2716  			    struct fuse_file_info *fi)
2717  {
2718  	struct node *node;
2719  	pthread_mutex_lock(&f->lock);
2720  	node = get_node(f, ino);
2721  	if (node->cache_valid) {
2722  		struct timespec now;
2723  		curr_time(&now);
2724  		if (diff_timespec(&now, &node->stat_updated) >
2725  		    f->conf.ac_attr_timeout) {
2726  			struct stat stbuf;
2727  			int err;
2728  			pthread_mutex_unlock(&f->lock);
2729  			err = fuse_fs_getattr(f->fs, path, &stbuf, fi);
2730  			pthread_mutex_lock(&f->lock);
2731  			if (!err)
2732  				update_stat(node, &stbuf);
2733  			else
2734  				node->cache_valid = 0;
2735  		}
2736  	}
2737  	if (node->cache_valid)
2738  		fi->keep_cache = 1;
2739  	node->cache_valid = 1;
2740  	pthread_mutex_unlock(&f->lock);
2741  }
2742  static void fuse_lib_open(fuse_req_t req, fuse_ino_t ino,
2743  			  struct fuse_file_info *fi)
2744  {
2745  	struct fuse *f = req_fuse_prepare(req);
2746  	struct fuse_intr_data d;
2747  	char *path;
2748  	int err;
2749  	err = get_path(f, ino, &path);
2750  	if (!err) {
2751  		fuse_prepare_interrupt(f, req, &d);
2752  		err = fuse_fs_open(f->fs, path, fi);
2753  		if (!err) {
2754  			if (f->conf.direct_io)
2755  				fi->direct_io = 1;
2756  			if (f->conf.kernel_cache)
2757  				fi->keep_cache = 1;
2758  			if (f->conf.auto_cache)
2759  				open_auto_cache(f, ino, path, fi);
2760  			if (f->conf.no_rofd_flush &&
2761  			    (fi->flags & O_ACCMODE) == O_RDONLY)
2762  				fi->noflush = 1;
2763  			if (fi->direct_io && f->conf.parallel_direct_writes)
2764  				fi->parallel_direct_writes = 1;
2765  		}
2766  		fuse_finish_interrupt(f, req, &d);
2767  	}
2768  	if (!err) {
2769  		pthread_mutex_lock(&f->lock);
2770  		get_node(f, ino)->open_count++;
2771  		pthread_mutex_unlock(&f->lock);
2772  		if (fuse_reply_open(req, fi) == -ENOENT) {
2773  			fuse_do_release(f, ino, path, fi);
2774  		}
2775  	} else
2776  		reply_err(req, err);
2777  	free_path(f, ino, path);
2778  }
2779  static void fuse_lib_read(fuse_req_t req, fuse_ino_t ino, size_t size,
2780  			  off_t off, struct fuse_file_info *fi)
2781  {
2782  	struct fuse *f = req_fuse_prepare(req);
2783  	struct fuse_bufvec *buf = NULL;
2784  	char *path;
2785  	int res;
2786  	res = get_path_nullok(f, ino, &path);
2787  	if (res == 0) {
2788  		struct fuse_intr_data d;
2789  		fuse_prepare_interrupt(f, req, &d);
2790  		res = fuse_fs_read_buf(f->fs, path, &buf, size, off, fi);
2791  		fuse_finish_interrupt(f, req, &d);
2792  		free_path(f, ino, path);
2793  	}
2794  	if (res == 0)
2795  		fuse_reply_data(req, buf, FUSE_BUF_SPLICE_MOVE);
2796  	else
2797  		reply_err(req, res);
2798  	fuse_free_buf(buf);
2799  }
2800  static void fuse_lib_write_buf(fuse_req_t req, fuse_ino_t ino,
2801  			       struct fuse_bufvec *buf, off_t off,
2802  			       struct fuse_file_info *fi)
2803  {
2804  	struct fuse *f = req_fuse_prepare(req);
2805  	char *path;
2806  	int res;
2807  	res = get_path_nullok(f, ino, &path);
2808  	if (res == 0) {
2809  		struct fuse_intr_data d;
2810  		fuse_prepare_interrupt(f, req, &d);
2811  		res = fuse_fs_write_buf(f->fs, path, buf, off, fi);
2812  		fuse_finish_interrupt(f, req, &d);
2813  		free_path(f, ino, path);
2814  	}
2815  	if (res >= 0)
2816  		fuse_reply_write(req, res);
2817  	else
2818  		reply_err(req, res);
2819  }
2820  static void fuse_lib_fsync(fuse_req_t req, fuse_ino_t ino, int datasync,
2821  			   struct fuse_file_info *fi)
2822  {
2823  	struct fuse *f = req_fuse_prepare(req);
2824  	char *path;
2825  	int err;
2826  	err = get_path_nullok(f, ino, &path);
2827  	if (!err) {
2828  		struct fuse_intr_data d;
2829  		fuse_prepare_interrupt(f, req, &d);
2830  		err = fuse_fs_fsync(f->fs, path, datasync, fi);
2831  		fuse_finish_interrupt(f, req, &d);
2832  		free_path(f, ino, path);
2833  	}
2834  	reply_err(req, err);
2835  }
2836  static struct fuse_dh *get_dirhandle(const struct fuse_file_info *llfi,
2837  				     struct fuse_file_info *fi)
2838  {
2839  	struct fuse_dh *dh = (struct fuse_dh *) (uintptr_t) llfi->fh;
2840  	memset(fi, 0, sizeof(struct fuse_file_info));
2841  	fi->fh = dh->fh;
2842  	return dh;
2843  }
2844  static void fuse_lib_opendir(fuse_req_t req, fuse_ino_t ino,
2845  			     struct fuse_file_info *llfi)
2846  {
2847  	struct fuse *f = req_fuse_prepare(req);
2848  	struct fuse_intr_data d;
2849  	struct fuse_dh *dh;
2850  	struct fuse_file_info fi;
2851  	char *path;
2852  	int err;
2853  	dh = (struct fuse_dh *) malloc(sizeof(struct fuse_dh));
2854  	if (dh == NULL) {
2855  		reply_err(req, -ENOMEM);
2856  		return;
2857  	}
2858  	memset(dh, 0, sizeof(struct fuse_dh));
2859  	dh->fuse = f;
2860  	dh->contents = NULL;
2861  	dh->first = NULL;
2862  	dh->len = 0;
2863  	dh->filled = 0;
2864  	dh->nodeid = ino;
2865  	pthread_mutex_init(&dh->lock, NULL);
2866  	llfi->fh = (uintptr_t) dh;
2867  	memset(&fi, 0, sizeof(fi));
2868  	fi.flags = llfi->flags;
2869  	err = get_path(f, ino, &path);
2870  	if (!err) {
2871  		fuse_prepare_interrupt(f, req, &d);
2872  		err = fuse_fs_opendir(f->fs, path, &fi);
2873  		fuse_finish_interrupt(f, req, &d);
2874  		dh->fh = fi.fh;
2875  	}
2876  	if (!err) {
2877  		if (fuse_reply_open(req, llfi) == -ENOENT) {
2878  			fuse_fs_releasedir(f->fs, path, &fi);
2879  			pthread_mutex_destroy(&dh->lock);
2880  			free(dh);
2881  		}
2882  	} else {
2883  		reply_err(req, err);
2884  		pthread_mutex_destroy(&dh->lock);
2885  		free(dh);
2886  	}
2887  	free_path(f, ino, path);
2888  }
2889  static int extend_contents(struct fuse_dh *dh, unsigned minsize)
2890  {
2891  	if (minsize > dh->size) {
2892  		char *newptr;
2893  		unsigned newsize = dh->size;
2894  		if (!newsize)
2895  			newsize = 1024;
2896  		while (newsize < minsize) {
2897  			if (newsize >= 0x80000000)
2898  				newsize = 0xffffffff;
2899  			else
2900  				newsize *= 2;
2901  		}
2902  		newptr = (char *) realloc(dh->contents, newsize);
2903  		if (!newptr) {
2904  			dh->error = -ENOMEM;
2905  			return -1;
2906  		}
2907  		dh->contents = newptr;
2908  		dh->size = newsize;
2909  	}
2910  	return 0;
2911  }
2912  static int fuse_add_direntry_to_dh(struct fuse_dh *dh, const char *name,
2913  				   struct stat *st)
2914  {
2915  	struct fuse_direntry *de;
2916  	de = malloc(sizeof(struct fuse_direntry));
2917  	if (!de) {
2918  		dh->error = -ENOMEM;
2919  		return -1;
2920  	}
2921  	de->name = strdup(name);
2922  	if (!de->name) {
2923  		dh->error = -ENOMEM;
2924  		free(de);
2925  		return -1;
2926  	}
2927  	de->stat = *st;
2928  	de->next = NULL;
2929  	*dh->last = de;
2930  	dh->last = &de->next;
2931  	return 0;
2932  }
2933  static fuse_ino_t lookup_nodeid(struct fuse *f, fuse_ino_t parent,
2934  				const char *name)
2935  {
2936  	struct node *node;
2937  	fuse_ino_t res = FUSE_UNKNOWN_INO;
2938  	pthread_mutex_lock(&f->lock);
2939  	node = lookup_node(f, parent, name);
2940  	if (node)
2941  		res = node->nodeid;
2942  	pthread_mutex_unlock(&f->lock);
2943  	return res;
2944  }
2945  static int fill_dir(void *dh_, const char *name, const struct stat *statp,
2946  		    off_t off, enum fuse_fill_dir_flags flags)
2947  {
2948  	struct fuse_dh *dh = (struct fuse_dh *) dh_;
2949  	struct stat stbuf;
2950  	if ((flags & ~FUSE_FILL_DIR_PLUS) != 0) {
2951  		dh->error = -EIO;
2952  		return 1;
2953  	}
2954  	if (statp)
2955  		stbuf = *statp;
2956  	else {
2957  		memset(&stbuf, 0, sizeof(stbuf));
2958  		stbuf.st_ino = FUSE_UNKNOWN_INO;
2959  	}
2960  	if (!dh->fuse->conf.use_ino) {
2961  		stbuf.st_ino = FUSE_UNKNOWN_INO;
2962  		if (dh->fuse->conf.readdir_ino) {
2963  			stbuf.st_ino = (ino_t)
2964  				lookup_nodeid(dh->fuse, dh->nodeid, name);
2965  		}
2966  	}
2967  	if (off) {
2968  		size_t newlen;
2969  		if (dh->filled) {
2970  			dh->error = -EIO;
2971  			return 1;
2972  		}
2973  		if (dh->first) {
2974  			dh->error = -EIO;
2975  			return 1;
2976  		}
2977  		if (extend_contents(dh, dh->needlen) == -1)
2978  			return 1;
2979  		newlen = dh->len +
2980  			fuse_add_direntry(dh->req, dh->contents + dh->len,
2981  					  dh->needlen - dh->len, name,
2982  					  &stbuf, off);
2983  		if (newlen > dh->needlen)
2984  			return 1;
2985  		dh->len = newlen;
2986  	} else {
2987  		dh->filled = 1;
2988  		if (fuse_add_direntry_to_dh(dh, name, &stbuf) == -1)
2989  			return 1;
2990  	}
2991  	return 0;
2992  }
2993  static int is_dot_or_dotdot(const char *name)
2994  {
2995  	return name[0] == '.' && (name[1] == '\0' ||
2996  				  (name[1] == '.' && name[2] == '\0'));
2997  }
2998  static int fill_dir_plus(void *dh_, const char *name, const struct stat *statp,
2999  			 off_t off, enum fuse_fill_dir_flags flags)
3000  {
3001  	struct fuse_dh *dh = (struct fuse_dh *) dh_;
3002  	struct fuse_entry_param e = {
3003  		.ino = 0,
3004  	};
3005  	struct fuse *f = dh->fuse;
3006  	int res;
3007  	if ((flags & ~FUSE_FILL_DIR_PLUS) != 0) {
3008  		dh->error = -EIO;
3009  		return 1;
3010  	}
3011  	if (statp && (flags & FUSE_FILL_DIR_PLUS)) {
3012  		e.attr = *statp;
3013  		if (!is_dot_or_dotdot(name)) {
3014  			res = do_lookup(f, dh->nodeid, name, &e);
3015  			if (res) {
3016  				dh->error = res;
3017  				return 1;
3018  			}
3019  		}
3020  	} else {
3021  		e.attr.st_ino = FUSE_UNKNOWN_INO;
3022  		if (statp) {
3023  			e.attr.st_mode = statp->st_mode;
3024  			if (f->conf.use_ino)
3025  				e.attr.st_ino = statp->st_ino;
3026  		}
3027  		if (!f->conf.use_ino && f->conf.readdir_ino) {
3028  			e.attr.st_ino = (ino_t)
3029  				lookup_nodeid(f, dh->nodeid, name);
3030  		}
3031  	}
3032  	if (off) {
3033  		size_t newlen;
3034  		if (dh->filled) {
3035  			dh->error = -EIO;
3036  			return 1;
3037  		}
3038  		if (dh->first) {
3039  			dh->error = -EIO;
3040  			return 1;
3041  		}
3042  		if (extend_contents(dh, dh->needlen) == -1)
3043  			return 1;
3044  		newlen = dh->len +
3045  			fuse_add_direntry_plus(dh->req, dh->contents + dh->len,
3046  					       dh->needlen - dh->len, name,
3047  					       &e, off);
3048  		if (newlen > dh->needlen)
3049  			return 1;
3050  		dh->len = newlen;
3051  	} else {
3052  		dh->filled = 1;
3053  		if (fuse_add_direntry_to_dh(dh, name, &e.attr) == -1)
3054  			return 1;
3055  	}
3056  	return 0;
3057  }
3058  static void free_direntries(struct fuse_direntry *de)
3059  {
3060  	while (de) {
3061  		struct fuse_direntry *next = de->next;
3062  		free(de->name);
3063  		free(de);
3064  		de = next;
3065  	}
3066  }
3067  static int readdir_fill(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3068  			size_t size, off_t off, struct fuse_dh *dh,
3069  			struct fuse_file_info *fi,
3070  			enum fuse_readdir_flags flags)
3071  {
3072  	char *path;
3073  	int err;
3074  	if (f->fs->op.readdir)
3075  		err = get_path_nullok(f, ino, &path);
3076  	else
3077  		err = get_path(f, ino, &path);
3078  	if (!err) {
3079  		struct fuse_intr_data d;
3080  		fuse_fill_dir_t filler = fill_dir;
3081  		if (flags & FUSE_READDIR_PLUS)
3082  			filler = fill_dir_plus;
3083  		free_direntries(dh->first);
3084  		dh->first = NULL;
3085  		dh->last = &dh->first;
3086  		dh->len = 0;
3087  		dh->error = 0;
3088  		dh->needlen = size;
3089  		dh->filled = 0;
3090  		dh->req = req;
3091  		fuse_prepare_interrupt(f, req, &d);
3092  		err = fuse_fs_readdir(f->fs, path, dh, filler, off, fi, flags);
3093  		fuse_finish_interrupt(f, req, &d);
3094  		dh->req = NULL;
3095  		if (!err)
3096  			err = dh->error;
3097  		if (err)
3098  			dh->filled = 0;
3099  		free_path(f, ino, path);
3100  	}
3101  	return err;
3102  }
3103  static int readdir_fill_from_list(fuse_req_t req, struct fuse_dh *dh,
3104  				  off_t off, enum fuse_readdir_flags flags)
3105  {
3106  	off_t pos;
3107  	struct fuse_direntry *de = dh->first;
3108  	dh->len = 0;
3109  	if (extend_contents(dh, dh->needlen) == -1)
3110  		return dh->error;
3111  	for (pos = 0; pos < off; pos++) {
3112  		if (!de)
3113  			break;
3114  		de = de->next;
3115  	}
3116  	while (de) {
3117  		char *p = dh->contents + dh->len;
3118  		unsigned rem = dh->needlen - dh->len;
3119  		unsigned thislen;
3120  		unsigned newlen;
3121  		pos++;
3122  		if (flags & FUSE_READDIR_PLUS) {
3123  			struct fuse_entry_param e = {
3124  				.ino = 0,
3125  				.attr = de->stat,
3126  			};
3127  			thislen = fuse_add_direntry_plus(req, p, rem,
3128  							 de->name, &e, pos);
3129  		} else {
3130  			thislen = fuse_add_direntry(req, p, rem,
3131  						    de->name, &de->stat, pos);
3132  		}
3133  		newlen = dh->len + thislen;
3134  		if (newlen > dh->needlen)
3135  			break;
3136  		dh->len = newlen;
3137  		de = de->next;
3138  	}
3139  	return 0;
3140  }
3141  static void fuse_readdir_common(fuse_req_t req, fuse_ino_t ino, size_t size,
3142  				off_t off, struct fuse_file_info *llfi,
3143  				enum fuse_readdir_flags flags)
3144  {
3145  	struct fuse *f = req_fuse_prepare(req);
3146  	struct fuse_file_info fi;
3147  	struct fuse_dh *dh = get_dirhandle(llfi, &fi);
3148  	int err;
3149  	pthread_mutex_lock(&dh->lock);
3150  	if (!off)
3151  		dh->filled = 0;
3152  	if (!dh->filled) {
3153  		err = readdir_fill(f, req, ino, size, off, dh, &fi, flags);
3154  		if (err) {
3155  			reply_err(req, err);
3156  			goto out;
3157  		}
3158  	}
3159  	if (dh->filled) {
3160  		dh->needlen = size;
3161  		err = readdir_fill_from_list(req, dh, off, flags);
3162  		if (err) {
3163  			reply_err(req, err);
3164  			goto out;
3165  		}
3166  	}
3167  	fuse_reply_buf(req, dh->contents, dh->len);
3168  out:
3169  	pthread_mutex_unlock(&dh->lock);
3170  }
3171  static void fuse_lib_readdir(fuse_req_t req, fuse_ino_t ino, size_t size,
3172  			     off_t off, struct fuse_file_info *llfi)
3173  {
3174  	fuse_readdir_common(req, ino, size, off, llfi, 0);
3175  }
3176  static void fuse_lib_readdirplus(fuse_req_t req, fuse_ino_t ino, size_t size,
3177  				  off_t off, struct fuse_file_info *llfi)
3178  {
3179  	fuse_readdir_common(req, ino, size, off, llfi, FUSE_READDIR_PLUS);
3180  }
3181  static void fuse_lib_releasedir(fuse_req_t req, fuse_ino_t ino,
3182  				struct fuse_file_info *llfi)
3183  {
3184  	struct fuse *f = req_fuse_prepare(req);
3185  	struct fuse_intr_data d;
3186  	struct fuse_file_info fi;
3187  	struct fuse_dh *dh = get_dirhandle(llfi, &fi);
3188  	char *path;
3189  	get_path_nullok(f, ino, &path);
3190  	fuse_prepare_interrupt(f, req, &d);
3191  	fuse_fs_releasedir(f->fs, path, &fi);
3192  	fuse_finish_interrupt(f, req, &d);
3193  	free_path(f, ino, path);
3194  	pthread_mutex_lock(&dh->lock);
3195  	pthread_mutex_unlock(&dh->lock);
3196  	pthread_mutex_destroy(&dh->lock);
3197  	free_direntries(dh->first);
3198  	free(dh->contents);
3199  	free(dh);
3200  	reply_err(req, 0);
3201  }
3202  static void fuse_lib_fsyncdir(fuse_req_t req, fuse_ino_t ino, int datasync,
3203  			      struct fuse_file_info *llfi)
3204  {
3205  	struct fuse *f = req_fuse_prepare(req);
3206  	struct fuse_file_info fi;
3207  	char *path;
3208  	int err;
3209  	get_dirhandle(llfi, &fi);
3210  	err = get_path_nullok(f, ino, &path);
3211  	if (!err) {
3212  		struct fuse_intr_data d;
3213  		fuse_prepare_interrupt(f, req, &d);
3214  		err = fuse_fs_fsyncdir(f->fs, path, datasync, &fi);
3215  		fuse_finish_interrupt(f, req, &d);
3216  		free_path(f, ino, path);
3217  	}
3218  	reply_err(req, err);
3219  }
3220  static void fuse_lib_statfs(fuse_req_t req, fuse_ino_t ino)
3221  {
3222  	struct fuse *f = req_fuse_prepare(req);
3223  	struct statvfs buf;
3224  	char *path = NULL;
3225  	int err = 0;
3226  	memset(&buf, 0, sizeof(buf));
3227  	if (ino)
3228  		err = get_path(f, ino, &path);
3229  	if (!err) {
3230  		struct fuse_intr_data d;
3231  		fuse_prepare_interrupt(f, req, &d);
3232  		err = fuse_fs_statfs(f->fs, path ? path : "/", &buf);
3233  		fuse_finish_interrupt(f, req, &d);
3234  		free_path(f, ino, path);
3235  	}
3236  	if (!err)
3237  		fuse_reply_statfs(req, &buf);
3238  	else
3239  		reply_err(req, err);
3240  }
3241  static void fuse_lib_setxattr(fuse_req_t req, fuse_ino_t ino, const char *name,
3242  			      const char *value, size_t size, int flags)
3243  {
3244  	struct fuse *f = req_fuse_prepare(req);
3245  	char *path;
3246  	int err;
3247  	err = get_path(f, ino, &path);
3248  	if (!err) {
3249  		struct fuse_intr_data d;
3250  		fuse_prepare_interrupt(f, req, &d);
3251  		err = fuse_fs_setxattr(f->fs, path, name, value, size, flags);
3252  		fuse_finish_interrupt(f, req, &d);
3253  		free_path(f, ino, path);
3254  	}
3255  	reply_err(req, err);
3256  }
3257  static int common_getxattr(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3258  			   const char *name, char *value, size_t size)
3259  {
3260  	int err;
3261  	char *path;
3262  	err = get_path(f, ino, &path);
3263  	if (!err) {
3264  		struct fuse_intr_data d;
3265  		fuse_prepare_interrupt(f, req, &d);
3266  		err = fuse_fs_getxattr(f->fs, path, name, value, size);
3267  		fuse_finish_interrupt(f, req, &d);
3268  		free_path(f, ino, path);
3269  	}
3270  	return err;
3271  }
3272  static void fuse_lib_getxattr(fuse_req_t req, fuse_ino_t ino, const char *name,
3273  			      size_t size)
3274  {
3275  	struct fuse *f = req_fuse_prepare(req);
3276  	int res;
3277  	if (size) {
3278  		char *value = (char *) malloc(size);
3279  		if (value == NULL) {
3280  			reply_err(req, -ENOMEM);
3281  			return;
3282  		}
3283  		res = common_getxattr(f, req, ino, name, value, size);
3284  		if (res > 0)
3285  			fuse_reply_buf(req, value, res);
3286  		else
3287  			reply_err(req, res);
3288  		free(value);
3289  	} else {
3290  		res = common_getxattr(f, req, ino, name, NULL, 0);
3291  		if (res >= 0)
3292  			fuse_reply_xattr(req, res);
3293  		else
3294  			reply_err(req, res);
3295  	}
3296  }
3297  static int common_listxattr(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3298  			    char *list, size_t size)
3299  {
3300  	char *path;
3301  	int err;
3302  	err = get_path(f, ino, &path);
3303  	if (!err) {
3304  		struct fuse_intr_data d;
3305  		fuse_prepare_interrupt(f, req, &d);
3306  		err = fuse_fs_listxattr(f->fs, path, list, size);
3307  		fuse_finish_interrupt(f, req, &d);
3308  		free_path(f, ino, path);
3309  	}
3310  	return err;
3311  }
3312  static void fuse_lib_listxattr(fuse_req_t req, fuse_ino_t ino, size_t size)
3313  {
3314  	struct fuse *f = req_fuse_prepare(req);
3315  	int res;
3316  	if (size) {
3317  		char *list = (char *) malloc(size);
3318  		if (list == NULL) {
3319  			reply_err(req, -ENOMEM);
3320  			return;
3321  		}
3322  		res = common_listxattr(f, req, ino, list, size);
3323  		if (res > 0)
3324  			fuse_reply_buf(req, list, res);
3325  		else
3326  			reply_err(req, res);
3327  		free(list);
3328  	} else {
3329  		res = common_listxattr(f, req, ino, NULL, 0);
3330  		if (res >= 0)
3331  			fuse_reply_xattr(req, res);
3332  		else
3333  			reply_err(req, res);
3334  	}
3335  }
3336  static void fuse_lib_removexattr(fuse_req_t req, fuse_ino_t ino,
3337  				 const char *name)
3338  {
3339  	struct fuse *f = req_fuse_prepare(req);
3340  	char *path;
3341  	int err;
3342  	err = get_path(f, ino, &path);
3343  	if (!err) {
3344  		struct fuse_intr_data d;
3345  		fuse_prepare_interrupt(f, req, &d);
3346  		err = fuse_fs_removexattr(f->fs, path, name);
3347  		fuse_finish_interrupt(f, req, &d);
3348  		free_path(f, ino, path);
3349  	}
3350  	reply_err(req, err);
3351  }
3352  static struct lock *locks_conflict(struct node *node, const struct lock *lock)
3353  {
3354  	struct lock *l;
3355  	for (l = node->locks; l; l = l->next)
3356  		if (l->owner != lock->owner &&
3357  		    lock->start <= l->end && l->start <= lock->end &&
3358  		    (l->type == F_WRLCK || lock->type == F_WRLCK))
3359  			break;
3360  	return l;
3361  }
3362  static void delete_lock(struct lock **lockp)
3363  {
3364  	struct lock *l = *lockp;
3365  	*lockp = l->next;
3366  	free(l);
3367  }
3368  static void insert_lock(struct lock **pos, struct lock *lock)
3369  {
3370  	lock->next = *pos;
3371  	*pos = lock;
3372  }
3373  static int locks_insert(struct node *node, struct lock *lock)
3374  {
3375  	struct lock **lp;
3376  	struct lock *newl1 = NULL;
3377  	struct lock *newl2 = NULL;
3378  	if (lock->type != F_UNLCK || lock->start != 0 ||
3379  	    lock->end != OFFSET_MAX) {
3380  		newl1 = malloc(sizeof(struct lock));
3381  		newl2 = malloc(sizeof(struct lock));
3382  		if (!newl1 || !newl2) {
3383  			free(newl1);
3384  			free(newl2);
3385  			return -ENOLCK;
3386  		}
3387  	}
3388  	for (lp = &node->locks; *lp;) {
3389  		struct lock *l = *lp;
3390  		if (l->owner != lock->owner)
3391  			goto skip;
3392  		if (lock->type == l->type) {
3393  			if (l->end < lock->start - 1)
3394  				goto skip;
3395  			if (lock->end < l->start - 1)
3396  				break;
3397  			if (l->start <= lock->start && lock->end <= l->end)
3398  				goto out;
3399  			if (l->start < lock->start)
3400  				lock->start = l->start;
3401  			if (lock->end < l->end)
3402  				lock->end = l->end;
3403  			goto delete;
3404  		} else {
3405  			if (l->end < lock->start)
3406  				goto skip;
3407  			if (lock->end < l->start)
3408  				break;
3409  			if (lock->start <= l->start && l->end <= lock->end)
3410  				goto delete;
3411  			if (l->end <= lock->end) {
3412  				l->end = lock->start - 1;
3413  				goto skip;
3414  			}
3415  			if (lock->start <= l->start) {
3416  				l->start = lock->end + 1;
3417  				break;
3418  			}
3419  			*newl2 = *l;
3420  			newl2->start = lock->end + 1;
3421  			l->end = lock->start - 1;
3422  			insert_lock(&l->next, newl2);
3423  			newl2 = NULL;
3424  		}
3425  	skip:
3426  		lp = &l->next;
3427  		continue;
3428  	delete:
3429  		delete_lock(lp);
3430  	}
3431  	if (lock->type != F_UNLCK) {
3432  		*newl1 = *lock;
3433  		insert_lock(lp, newl1);
3434  		newl1 = NULL;
3435  	}
3436  out:
3437  	free(newl1);
3438  	free(newl2);
3439  	return 0;
3440  }
3441  static void flock_to_lock(struct flock *flock, struct lock *lock)
3442  {
3443  	memset(lock, 0, sizeof(struct lock));
3444  	lock->type = flock->l_type;
3445  	lock->start = flock->l_start;
3446  	lock->end =
3447  		flock->l_len ? flock->l_start + flock->l_len - 1 : OFFSET_MAX;
3448  	lock->pid = flock->l_pid;
3449  }
3450  static void lock_to_flock(struct lock *lock, struct flock *flock)
3451  {
3452  	flock->l_type = lock->type;
3453  	flock->l_start = lock->start;
3454  	flock->l_len =
3455  		(lock->end == OFFSET_MAX) ? 0 : lock->end - lock->start + 1;
3456  	flock->l_pid = lock->pid;
3457  }
3458  static int fuse_flush_common(struct fuse *f, fuse_req_t req, fuse_ino_t ino,
3459  			     const char *path, struct fuse_file_info *fi)
3460  {
3461  	struct fuse_intr_data d;
3462  	struct flock lock;
3463  	struct lock l;
3464  	int err;
3465  	int errlock;
3466  	fuse_prepare_interrupt(f, req, &d);
3467  	memset(&lock, 0, sizeof(lock));
3468  	lock.l_type = F_UNLCK;
3469  	lock.l_whence = SEEK_SET;
3470  	err = fuse_fs_flush(f->fs, path, fi);
3471  	errlock = fuse_fs_lock(f->fs, path, fi, F_SETLK, &lock);
3472  	fuse_finish_interrupt(f, req, &d);
3473  	if (errlock != -ENOSYS) {
3474  		flock_to_lock(&lock, &l);
3475  		l.owner = fi->lock_owner;
3476  		pthread_mutex_lock(&f->lock);
3477  		locks_insert(get_node(f, ino), &l);
3478  		pthread_mutex_unlock(&f->lock);
3479  		if (err == -ENOSYS)
3480  			err = 0;
3481  	}
3482  	return err;
3483  }
3484  static void fuse_lib_release(fuse_req_t req, fuse_ino_t ino,
3485  			     struct fuse_file_info *fi)
3486  {
3487  	struct fuse *f = req_fuse_prepare(req);
3488  	struct fuse_intr_data d;
3489  	char *path;
3490  	int err = 0;
3491  	get_path_nullok(f, ino, &path);
3492  	if (fi->flush) {
3493  		err = fuse_flush_common(f, req, ino, path, fi);
3494  		if (err == -ENOSYS)
3495  			err = 0;
3496  	}
3497  	fuse_prepare_interrupt(f, req, &d);
3498  	fuse_do_release(f, ino, path, fi);
3499  	fuse_finish_interrupt(f, req, &d);
3500  	free_path(f, ino, path);
3501  	reply_err(req, err);
3502  }
3503  static void fuse_lib_flush(fuse_req_t req, fuse_ino_t ino,
3504  			   struct fuse_file_info *fi)
3505  {
3506  	struct fuse *f = req_fuse_prepare(req);
3507  	char *path;
3508  	int err;
3509  	get_path_nullok(f, ino, &path);
3510  	err = fuse_flush_common(f, req, ino, path, fi);
3511  	free_path(f, ino, path);
3512  	reply_err(req, err);
3513  }
3514  static int fuse_lock_common(fuse_req_t req, fuse_ino_t ino,
3515  			    struct fuse_file_info *fi, struct flock *lock,
3516  			    int cmd)
3517  {
3518  	struct fuse *f = req_fuse_prepare(req);
3519  	char *path;
3520  	int err;
3521  	err = get_path_nullok(f, ino, &path);
3522  	if (!err) {
3523  		struct fuse_intr_data d;
3524  		fuse_prepare_interrupt(f, req, &d);
3525  		err = fuse_fs_lock(f->fs, path, fi, cmd, lock);
3526  		fuse_finish_interrupt(f, req, &d);
3527  		free_path(f, ino, path);
3528  	}
3529  	return err;
3530  }
3531  static void fuse_lib_getlk(fuse_req_t req, fuse_ino_t ino,
3532  			   struct fuse_file_info *fi, struct flock *lock)
3533  {
3534  	int err;
3535  	struct lock l;
3536  	struct lock *conflict;
3537  	struct fuse *f = req_fuse(req);
3538  	flock_to_lock(lock, &l);
3539  	l.owner = fi->lock_owner;
3540  	pthread_mutex_lock(&f->lock);
3541  	conflict = locks_conflict(get_node(f, ino), &l);
3542  	if (conflict)
3543  		lock_to_flock(conflict, lock);
3544  	pthread_mutex_unlock(&f->lock);
3545  	if (!conflict)
3546  		err = fuse_lock_common(req, ino, fi, lock, F_GETLK);
3547  	else
3548  		err = 0;
3549  	if (!err)
3550  		fuse_reply_lock(req, lock);
3551  	else
3552  		reply_err(req, err);
3553  }
3554  static void fuse_lib_setlk(fuse_req_t req, fuse_ino_t ino,
3555  			   struct fuse_file_info *fi, struct flock *lock,
3556  			   int sleep)
3557  {
3558  	int err = fuse_lock_common(req, ino, fi, lock,
3559  				   sleep ? F_SETLKW : F_SETLK);
3560  	if (!err) {
3561  		struct fuse *f = req_fuse(req);
3562  		struct lock l;
3563  		flock_to_lock(lock, &l);
3564  		l.owner = fi->lock_owner;
3565  		pthread_mutex_lock(&f->lock);
3566  		locks_insert(get_node(f, ino), &l);
3567  		pthread_mutex_unlock(&f->lock);
3568  	}
3569  	reply_err(req, err);
3570  }
3571  static void fuse_lib_flock(fuse_req_t req, fuse_ino_t ino,
3572  			   struct fuse_file_info *fi, int op)
3573  {
3574  	struct fuse *f = req_fuse_prepare(req);
3575  	char *path;
3576  	int err;
3577  	err = get_path_nullok(f, ino, &path);
3578  	if (err == 0) {
3579  		struct fuse_intr_data d;
3580  		fuse_prepare_interrupt(f, req, &d);
3581  		err = fuse_fs_flock(f->fs, path, fi, op);
3582  		fuse_finish_interrupt(f, req, &d);
3583  		free_path(f, ino, path);
3584  	}
3585  	reply_err(req, err);
3586  }
3587  static void fuse_lib_bmap(fuse_req_t req, fuse_ino_t ino, size_t blocksize,
3588  			  uint64_t idx)
3589  {
3590  	struct fuse *f = req_fuse_prepare(req);
3591  	struct fuse_intr_data d;
3592  	char *path;
3593  	int err;
3594  	err = get_path(f, ino, &path);
3595  	if (!err) {
3596  		fuse_prepare_interrupt(f, req, &d);
3597  		err = fuse_fs_bmap(f->fs, path, blocksize, &idx);
3598  		fuse_finish_interrupt(f, req, &d);
3599  		free_path(f, ino, path);
3600  	}
3601  	if (!err)
3602  		fuse_reply_bmap(req, idx);
3603  	else
3604  		reply_err(req, err);
3605  }
3606  static void fuse_lib_ioctl(fuse_req_t req, fuse_ino_t ino, unsigned int cmd,
3607  			   void *arg, struct fuse_file_info *llfi,
3608  			   unsigned int flags, const void *in_buf,
3609  			   size_t in_bufsz, size_t out_bufsz)
3610  {
3611  	struct fuse *f = req_fuse_prepare(req);
3612  	struct fuse_intr_data d;
3613  	struct fuse_file_info fi;
3614  	char *path, *out_buf = NULL;
3615  	int err;
3616  	err = -EPERM;
3617  	if (flags & FUSE_IOCTL_UNRESTRICTED)
3618  		goto err;
3619  	if (flags & FUSE_IOCTL_DIR)
3620  		get_dirhandle(llfi, &fi);
3621  	else
3622  		fi = *llfi;
3623  	if (out_bufsz) {
3624  		err = -ENOMEM;
3625  		out_buf = malloc(out_bufsz);
3626  		if (!out_buf)
3627  			goto err;
3628  	}
3629  	assert(!in_bufsz || !out_bufsz || in_bufsz == out_bufsz);
3630  	if (out_buf && in_bufsz)
3631  		memcpy(out_buf, in_buf, in_bufsz);
3632  	err = get_path_nullok(f, ino, &path);
3633  	if (err)
3634  		goto err;
3635  	fuse_prepare_interrupt(f, req, &d);
3636  	err = fuse_fs_ioctl(f->fs, path, cmd, arg, &fi, flags,
3637  			    out_buf ? out_buf : (void *)in_buf);
3638  	fuse_finish_interrupt(f, req, &d);
3639  	free_path(f, ino, path);
3640  	if (err < 0)
3641  		goto err;
3642  	fuse_reply_ioctl(req, err, out_buf, out_bufsz);
3643  	goto out;
3644  err:
3645  	reply_err(req, err);
3646  out:
3647  	free(out_buf);
3648  }
3649  static void fuse_lib_poll(fuse_req_t req, fuse_ino_t ino,
3650  			  struct fuse_file_info *fi, struct fuse_pollhandle *ph)
3651  {
3652  	struct fuse *f = req_fuse_prepare(req);
3653  	struct fuse_intr_data d;
3654  	char *path;
3655  	int err;
3656  	unsigned revents = 0;
3657  	err = get_path_nullok(f, ino, &path);
3658  	if (!err) {
3659  		fuse_prepare_interrupt(f, req, &d);
3660  		err = fuse_fs_poll(f->fs, path, fi, ph, &revents);
3661  		fuse_finish_interrupt(f, req, &d);
3662  		free_path(f, ino, path);
3663  	}
3664  	if (!err)
3665  		fuse_reply_poll(req, revents);
3666  	else
3667  		reply_err(req, err);
3668  }
3669  static void fuse_lib_fallocate(fuse_req_t req, fuse_ino_t ino, int mode,
3670  		off_t offset, off_t length, struct fuse_file_info *fi)
3671  {
3672  	struct fuse *f = req_fuse_prepare(req);
3673  	struct fuse_intr_data d;
3674  	char *path;
3675  	int err;
3676  	err = get_path_nullok(f, ino, &path);
3677  	if (!err) {
3678  		fuse_prepare_interrupt(f, req, &d);
3679  		err = fuse_fs_fallocate(f->fs, path, mode, offset, length, fi);
3680  		fuse_finish_interrupt(f, req, &d);
3681  		free_path(f, ino, path);
3682  	}
3683  	reply_err(req, err);
3684  }
3685  static void fuse_lib_copy_file_range(fuse_req_t req, fuse_ino_t nodeid_in,
3686  				     off_t off_in, struct fuse_file_info *fi_in,
3687  				     fuse_ino_t nodeid_out, off_t off_out,
3688  				     struct fuse_file_info *fi_out, size_t len,
3689  				     int flags)
3690  {
3691  	struct fuse *f = req_fuse_prepare(req);
3692  	struct fuse_intr_data d;
3693  	char *path_in, *path_out;
3694  	int err;
3695  	ssize_t res;
3696  	err = get_path_nullok(f, nodeid_in, &path_in);
3697  	if (err) {
3698  		reply_err(req, err);
3699  		return;
3700  	}
3701  	err = get_path_nullok(f, nodeid_out, &path_out);
3702  	if (err) {
3703  		free_path(f, nodeid_in, path_in);
3704  		reply_err(req, err);
3705  		return;
3706  	}
3707  	fuse_prepare_interrupt(f, req, &d);
3708  	res = fuse_fs_copy_file_range(f->fs, path_in, fi_in, off_in, path_out,
3709  				      fi_out, off_out, len, flags);
3710  	fuse_finish_interrupt(f, req, &d);
3711  	if (res >= 0)
3712  		fuse_reply_write(req, res);
3713  	else
3714  		reply_err(req, res);
3715  	free_path(f, nodeid_in, path_in);
3716  	free_path(f, nodeid_out, path_out);
3717  }
3718  static void fuse_lib_lseek(fuse_req_t req, fuse_ino_t ino, off_t off, int whence,
3719  			   struct fuse_file_info *fi)
3720  {
3721  	struct fuse *f = req_fuse_prepare(req);
3722  	struct fuse_intr_data d;
3723  	char *path;
3724  	int err;
3725  	off_t res;
3726  	err = get_path(f, ino, &path);
3727  	if (err) {
3728  		reply_err(req, err);
3729  		return;
3730  	}
3731  	fuse_prepare_interrupt(f, req, &d);
3732  	res = fuse_fs_lseek(f->fs, path, off, whence, fi);
3733  	fuse_finish_interrupt(f, req, &d);
3734  	free_path(f, ino, path);
3735  	if (res >= 0)
3736  		fuse_reply_lseek(req, res);
3737  	else
3738  		reply_err(req, res);
3739  }
3740  static int clean_delay(struct fuse *f)
3741  {
3742  	int min_sleep = 60;
3743  	int max_sleep = 3600;
3744  	int sleep_time = f->conf.remember / 10;
3745  	if (sleep_time > max_sleep)
3746  		return max_sleep;
3747  	if (sleep_time < min_sleep)
3748  		return min_sleep;
3749  	return sleep_time;
3750  }
3751  int fuse_clean_cache(struct fuse *f)
3752  {
3753  	struct node_lru *lnode;
3754  	struct list_head *curr, *next;
3755  	struct node *node;
3756  	struct timespec now;
3757  	pthread_mutex_lock(&f->lock);
3758  	curr_time(&now);
3759  	for (curr = f->lru_table.next; curr != &f->lru_table; curr = next) {
3760  		double age;
3761  		next = curr->next;
3762  		lnode = list_entry(curr, struct node_lru, lru);
3763  		node = &lnode->node;
3764  		age = diff_timespec(&now, &lnode->forget_time);
3765  		if (age <= f->conf.remember)
3766  			break;
3767  		assert(node->nlookup == 1);
3768  		if (node->refctr > 1)
3769  			continue;
3770  		node->nlookup = 0;
3771  		unhash_name(f, node);
3772  		unref_node(f, node);
3773  	}
3774  	pthread_mutex_unlock(&f->lock);
3775  	return clean_delay(f);
3776  }
3777  static struct fuse_lowlevel_ops fuse_path_ops = {
3778  	.init = fuse_lib_init,
3779  	.destroy = fuse_lib_destroy,
3780  	.lookup = fuse_lib_lookup,
3781  	.forget = fuse_lib_forget,
3782  	.forget_multi = fuse_lib_forget_multi,
3783  	.getattr = fuse_lib_getattr,
3784  	.setattr = fuse_lib_setattr,
3785  	.access = fuse_lib_access,
3786  	.readlink = fuse_lib_readlink,
3787  	.mknod = fuse_lib_mknod,
3788  	.mkdir = fuse_lib_mkdir,
3789  	.unlink = fuse_lib_unlink,
3790  	.rmdir = fuse_lib_rmdir,
3791  	.symlink = fuse_lib_symlink,
3792  	.rename = fuse_lib_rename,
3793  	.link = fuse_lib_link,
3794  	.create = fuse_lib_create,
3795  	.open = fuse_lib_open,
3796  	.read = fuse_lib_read,
3797  	.write_buf = fuse_lib_write_buf,
3798  	.flush = fuse_lib_flush,
3799  	.release = fuse_lib_release,
3800  	.fsync = fuse_lib_fsync,
3801  	.opendir = fuse_lib_opendir,
3802  	.readdir = fuse_lib_readdir,
3803  	.readdirplus = fuse_lib_readdirplus,
3804  	.releasedir = fuse_lib_releasedir,
3805  	.fsyncdir = fuse_lib_fsyncdir,
3806  	.statfs = fuse_lib_statfs,
3807  	.setxattr = fuse_lib_setxattr,
3808  	.getxattr = fuse_lib_getxattr,
3809  	.listxattr = fuse_lib_listxattr,
3810  	.removexattr = fuse_lib_removexattr,
3811  	.getlk = fuse_lib_getlk,
3812  	.setlk = fuse_lib_setlk,
3813  	.flock = fuse_lib_flock,
3814  	.bmap = fuse_lib_bmap,
3815  	.ioctl = fuse_lib_ioctl,
3816  	.poll = fuse_lib_poll,
3817  	.fallocate = fuse_lib_fallocate,
3818  	.copy_file_range = fuse_lib_copy_file_range,
3819  	.lseek = fuse_lib_lseek,
3820  };
3821  int fuse_notify_poll(struct fuse_pollhandle *ph)
3822  {
3823  	return fuse_lowlevel_notify_poll(ph);
3824  }
3825  struct fuse_session *fuse_get_session(struct fuse *f)
3826  {
3827  	return f->se;
3828  }
3829  static int fuse_session_loop_remember(struct fuse *f)
3830  {
3831  	struct fuse_session *se = f->se;
3832  	int res = 0;
3833  	struct timespec now;
3834  	time_t next_clean;
3835  	struct pollfd fds = {
3836  		.fd = se->fd,
3837  		.events = POLLIN
3838  	};
3839  	struct fuse_buf fbuf = {
3840  		.mem = NULL,
3841  	};
3842  	curr_time(&now);
3843  	next_clean = now.tv_sec;
3844  	while (!fuse_session_exited(se)) {
3845  		unsigned timeout;
3846  		curr_time(&now);
3847  		if (now.tv_sec < next_clean)
3848  			timeout = next_clean - now.tv_sec;
3849  		else
3850  			timeout = 0;
3851  		res = poll(&fds, 1, timeout * 1000);
3852  		if (res == -1) {
3853  			if (errno == EINTR)
3854  				continue;
3855  			else
3856  				break;
3857  		} else if (res > 0) {
3858  			res = fuse_session_receive_buf_int(se, &fbuf, NULL);
3859  			if (res == -EINTR)
3860  				continue;
3861  			if (res <= 0)
3862  				break;
3863  			fuse_session_process_buf_int(se, &fbuf, NULL);
3864  		} else {
3865  			timeout = fuse_clean_cache(f);
3866  			curr_time(&now);
3867  			next_clean = now.tv_sec + timeout;
3868  		}
3869  	}
3870  	free(fbuf.mem);
3871  	fuse_session_reset(se);
3872  	return res < 0 ? -1 : 0;
3873  }
3874  int fuse_loop(struct fuse *f)
3875  {
3876  	if (!f)
3877  		return -1;
3878  	if (lru_enabled(f))
3879  		return fuse_session_loop_remember(f);
3880  	return fuse_session_loop(f->se);
3881  }
3882  FUSE_SYMVER("fuse_loop_mt_312", "fuse_loop_mt@@FUSE_3.12")
3883  int fuse_loop_mt_312(struct fuse *f, struct fuse_loop_config *config)
3884  {
3885  	if (f == NULL)
3886  		return -1;
3887  	int res = fuse_start_cleanup_thread(f);
3888  	if (res)
3889  		return -1;
3890  	res = fuse_session_loop_mt_312(fuse_get_session(f), config);
3891  	fuse_stop_cleanup_thread(f);
3892  	return res;
3893  }
3894  int fuse_loop_mt_32(struct fuse *f, struct fuse_loop_config_v1 *config_v1);
3895  FUSE_SYMVER("fuse_loop_mt_32", "fuse_loop_mt@FUSE_3.2")
3896  int fuse_loop_mt_32(struct fuse *f, struct fuse_loop_config_v1 *config_v1)
3897  {
3898  	struct fuse_loop_config *config = fuse_loop_cfg_create();
3899  	if (config == NULL)
3900  		return ENOMEM;
3901  	fuse_loop_cfg_convert(config, config_v1);
3902  	int res = fuse_loop_mt_312(f, config);
3903  	fuse_loop_cfg_destroy(config);
3904  	return res;
3905  }
3906  int fuse_loop_mt_31(struct fuse *f, int clone_fd);
3907  FUSE_SYMVER("fuse_loop_mt_31", "fuse_loop_mt@FUSE_3.0")
3908  int fuse_loop_mt_31(struct fuse *f, int clone_fd)
3909  {
3910  	int err;
3911  	struct fuse_loop_config *config = fuse_loop_cfg_create();
3912  	if (config == NULL)
3913  		return ENOMEM;
3914  	fuse_loop_cfg_set_clone_fd(config, clone_fd);
3915  	err = fuse_loop_mt_312(f, config);
3916  	fuse_loop_cfg_destroy(config);
3917  	return err;
3918  }
3919  void fuse_exit(struct fuse *f)
3920  {
3921  	fuse_session_exit(f->se);
3922  }
3923  struct fuse_context *fuse_get_context(void)
3924  {
3925  	struct fuse_context_i *c = fuse_get_context_internal();
3926  	if (c)
3927  		return &c->ctx;
3928  	else
3929  		return NULL;
3930  }
3931  int fuse_getgroups(int size, gid_t list[])
3932  {
3933  	struct fuse_context_i *c = fuse_get_context_internal();
3934  	if (!c)
3935  		return -EINVAL;
3936  	return fuse_req_getgroups(c->req, size, list);
3937  }
3938  int fuse_interrupted(void)
3939  {
3940  	struct fuse_context_i *c = fuse_get_context_internal();
3941  	if (c)
3942  		return fuse_req_interrupted(c->req);
3943  	else
3944  		return 0;
3945  }
3946  int fuse_invalidate_path(struct fuse *f, const char *path) {
3947  	fuse_ino_t ino;
3948  	int err = lookup_path_in_cache(f, path, &ino);
3949  	if (err) {
3950  		return err;
3951  	}
3952  	return fuse_lowlevel_notify_inval_inode(f->se, ino, 0, 0);
3953  }
3954  #define FUSE_LIB_OPT(t, p, v) { t, offsetof(struct fuse_config, p), v }
3955  static const struct fuse_opt fuse_lib_opts[] = {
3956  	FUSE_OPT_KEY("debug",		      FUSE_OPT_KEY_KEEP),
3957  	FUSE_OPT_KEY("-d",		      FUSE_OPT_KEY_KEEP),
3958  	FUSE_LIB_OPT("debug",		      debug, 1),
3959  	FUSE_LIB_OPT("-d",		      debug, 1),
3960  	FUSE_LIB_OPT("kernel_cache",	      kernel_cache, 1),
3961  	FUSE_LIB_OPT("auto_cache",	      auto_cache, 1),
3962  	FUSE_LIB_OPT("noauto_cache",	      auto_cache, 0),
3963  	FUSE_LIB_OPT("no_rofd_flush",	      no_rofd_flush, 1),
3964  	FUSE_LIB_OPT("umask=",		      set_mode, 1),
3965  	FUSE_LIB_OPT("umask=%o",	      umask, 0),
3966  	FUSE_LIB_OPT("uid=",		      set_uid, 1),
3967  	FUSE_LIB_OPT("uid=%d",		      uid, 0),
3968  	FUSE_LIB_OPT("gid=",		      set_gid, 1),
3969  	FUSE_LIB_OPT("gid=%d",		      gid, 0),
3970  	FUSE_LIB_OPT("entry_timeout=%lf",     entry_timeout, 0),
3971  	FUSE_LIB_OPT("attr_timeout=%lf",      attr_timeout, 0),
3972  	FUSE_LIB_OPT("ac_attr_timeout=%lf",   ac_attr_timeout, 0),
3973  	FUSE_LIB_OPT("ac_attr_timeout=",      ac_attr_timeout_set, 1),
3974  	FUSE_LIB_OPT("negative_timeout=%lf",  negative_timeout, 0),
3975  	FUSE_LIB_OPT("noforget",              remember, -1),
3976  	FUSE_LIB_OPT("remember=%u",           remember, 0),
3977  	FUSE_LIB_OPT("modules=%s",	      modules, 0),
3978  	FUSE_LIB_OPT("parallel_direct_write=%d", parallel_direct_writes, 0),
3979  	FUSE_OPT_END
3980  };
3981  static int fuse_lib_opt_proc(void *data, const char *arg, int key,
3982  			     struct fuse_args *outargs)
3983  {
3984  	(void) arg; (void) outargs; (void) data; (void) key;
3985  	return 1;
3986  }
3987  static const struct fuse_opt fuse_help_opts[] = {
3988  	FUSE_LIB_OPT("modules=%s", modules, 1),
3989  	FUSE_OPT_KEY("modules=%s", FUSE_OPT_KEY_KEEP),
3990  	FUSE_OPT_END
3991  };
3992  static void print_module_help(const char *name,
3993  			      fuse_module_factory_t *fac)
3994  {
3995  	struct fuse_args a = FUSE_ARGS_INIT(0, NULL);
3996  	if (fuse_opt_add_arg(&a, "") == -1 ||
3997  	    fuse_opt_add_arg(&a, "-h") == -1)
3998  		return;
3999  	printf("\nOptions for %s module:\n", name);
4000  	(*fac)(&a, NULL);
4001  	fuse_opt_free_args(&a);
4002  }
4003  void fuse_lib_help(struct fuse_args *args)
4004  {
4005  	printf(
4006  "    -o kernel_cache        cache files in kernel\n"
4007  "    -o [no]auto_cache      enable caching based on modification times (off)\n"
4008  "    -o no_rofd_flush       disable flushing of read-only fd on close (off)\n"
4009  "    -o umask=M             set file permissions (octal)\n"
4010  "    -o uid=N               set file owner\n"
4011  "    -o gid=N               set file group\n"
4012  "    -o entry_timeout=T     cache timeout for names (1.0s)\n"
4013  "    -o negative_timeout=T  cache timeout for deleted names (0.0s)\n"
4014  "    -o attr_timeout=T      cache timeout for attributes (1.0s)\n"
4015  "    -o ac_attr_timeout=T   auto cache timeout for attributes (attr_timeout)\n"
4016  "    -o noforget            never forget cached inodes\n"
4017  "    -o remember=T          remember cached inodes for T seconds (0s)\n"
4018  "    -o modules=M1[:M2...]  names of modules to push onto filesystem stack\n");
4019  	fuse_lowlevel_help();
4020  	print_module_help("subdir", &fuse_module_subdir_factory);
4021  #ifdef HAVE_ICONV
4022  	print_module_help("iconv", &fuse_module_iconv_factory);
4023  #endif
4024  	struct fuse_config conf = { .modules = NULL };
4025  	if (fuse_opt_parse(args, &conf, fuse_help_opts,
4026  			   fuse_lib_opt_proc) == -1
4027  	    || !conf.modules)
4028  		return;
4029  	char *module;
4030  	char *next;
4031  	struct fuse_module *m;
4032  	for (module = conf.modules; module; module = next) {
4033  		char *p;
4034  		for (p = module; *p && *p != ':'; p++);
4035  		next = *p ? p + 1 : NULL;
4036  		*p = '\0';
4037  		m = fuse_get_module(module);
4038  		if (m)
4039  			print_module_help(module, &m->factory);
4040  	}
4041  }
4042  static int fuse_init_intr_signal(int signum, int *installed)
4043  {
4044  	struct sigaction old_sa;
4045  	if (sigaction(signum, NULL, &old_sa) == -1) {
4046  		perror("fuse: cannot get old signal handler");
4047  		return -1;
4048  	}
4049  	if (old_sa.sa_handler == SIG_DFL) {
4050  		struct sigaction sa;
4051  		memset(&sa, 0, sizeof(struct sigaction));
4052  		sa.sa_handler = fuse_intr_sighandler;
4053  		sigemptyset(&sa.sa_mask);
4054  		if (sigaction(signum, &sa, NULL) == -1) {
4055  			perror("fuse: cannot set interrupt signal handler");
4056  			return -1;
4057  		}
4058  		*installed = 1;
4059  	}
4060  	return 0;
4061  }
4062  static void fuse_restore_intr_signal(int signum)
4063  {
4064  	struct sigaction sa;
4065  	memset(&sa, 0, sizeof(struct sigaction));
4066  	sa.sa_handler = SIG_DFL;
4067  	sigaction(signum, &sa, NULL);
4068  }
4069  static int fuse_push_module(struct fuse *f, const char *module,
4070  			    struct fuse_args *args)
4071  {
4072  	struct fuse_fs *fs[2] = { f->fs, NULL };
4073  	struct fuse_fs *newfs;
4074  	struct fuse_module *m = fuse_get_module(module);
4075  	if (!m)
4076  		return -1;
4077  	newfs = m->factory(args, fs);
4078  	if (!newfs) {
4079  		fuse_put_module(m);
4080  		return -1;
4081  	}
4082  	f->fs = newfs;
4083  	return 0;
4084  }
4085  struct fuse_fs *fuse_fs_new(const struct fuse_operations *op, size_t op_size,
4086  			    void *user_data)
4087  {
4088  	struct fuse_fs *fs;
4089  	if (sizeof(struct fuse_operations) < op_size) {
4090  		fuse_log(FUSE_LOG_ERR, "fuse: warning: library too old, some operations may not not work\n");
4091  		op_size = sizeof(struct fuse_operations);
4092  	}
4093  	fs = (struct fuse_fs *) calloc(1, sizeof(struct fuse_fs));
4094  	if (!fs) {
4095  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate fuse_fs object\n");
4096  		return NULL;
4097  	}
4098  	fs->user_data = user_data;
4099  	if (op)
4100  		memcpy(&fs->op, op, op_size);
4101  	return fs;
4102  }
4103  static int node_table_init(struct node_table *t)
4104  {
4105  	t->size = NODE_TABLE_MIN_SIZE;
4106  	t->array = (struct node **) calloc(1, sizeof(struct node *) * t->size);
4107  	if (t->array == NULL) {
4108  		fuse_log(FUSE_LOG_ERR, "fuse: memory allocation failed\n");
4109  		return -1;
4110  	}
4111  	t->use = 0;
4112  	t->split = 0;
4113  	return 0;
4114  }
4115  static void *fuse_prune_nodes(void *fuse)
4116  {
4117  	struct fuse *f = fuse;
4118  	int sleep_time;
4119  	while(1) {
4120  		sleep_time = fuse_clean_cache(f);
4121  		sleep(sleep_time);
4122  	}
4123  	return NULL;
4124  }
4125  int fuse_start_cleanup_thread(struct fuse *f)
4126  {
4127  	if (lru_enabled(f))
4128  		return fuse_start_thread(&f->prune_thread, fuse_prune_nodes, f);
4129  	return 0;
4130  }
4131  void fuse_stop_cleanup_thread(struct fuse *f)
4132  {
4133  	if (lru_enabled(f)) {
4134  		pthread_mutex_lock(&f->lock);
4135  		pthread_cancel(f->prune_thread);
4136  		pthread_mutex_unlock(&f->lock);
4137  		pthread_join(f->prune_thread, NULL);
4138  	}
4139  }
4140  FUSE_SYMVER("fuse_new_31", "fuse_new@@FUSE_3.1")
4141  struct fuse *fuse_new_31(struct fuse_args *args,
4142  		      const struct fuse_operations *op,
4143  		      size_t op_size, void *user_data)
4144  {
4145  	struct fuse *f;
4146  	struct node *root;
4147  	struct fuse_fs *fs;
4148  	struct fuse_lowlevel_ops llop = fuse_path_ops;
4149  	f = (struct fuse *) calloc(1, sizeof(struct fuse));
4150  	if (f == NULL) {
4151  		fuse_log(FUSE_LOG_ERR, "fuse: failed to allocate fuse object\n");
4152  		goto out;
4153  	}
4154  	f->conf.entry_timeout = 1.0;
4155  	f->conf.attr_timeout = 1.0;
4156  	f->conf.negative_timeout = 0.0;
4157  	f->conf.intr_signal = FUSE_DEFAULT_INTR_SIGNAL;
4158  	if (fuse_opt_parse(args, &f->conf, fuse_lib_opts,
4159  			   fuse_lib_opt_proc) == -1)
4160  		goto out_free;
4161  	pthread_mutex_lock(&fuse_context_lock);
4162  	static int builtin_modules_registered = 0;
4163  	if (builtin_modules_registered == 0) {
4164  		fuse_register_module("subdir", fuse_module_subdir_factory, NULL);
4165  #ifdef HAVE_ICONV
4166  		fuse_register_module("iconv", fuse_module_iconv_factory, NULL);
4167  #endif
4168  		builtin_modules_registered= 1;
4169  	}
4170  	pthread_mutex_unlock(&fuse_context_lock);
4171  	if (fuse_create_context_key() == -1)
4172  		goto out_free;
4173  	fs = fuse_fs_new(op, op_size, user_data);
4174  	if (!fs)
4175  		goto out_delete_context_key;
4176  	f->fs = fs;
4177  	if (!fs->op.lock) {
4178  		llop.getlk = NULL;
4179  		llop.setlk = NULL;
4180  	}
4181  	f->pagesize = getpagesize();
4182  	init_list_head(&f->partial_slabs);
4183  	init_list_head(&f->full_slabs);
4184  	init_list_head(&f->lru_table);
4185  	if (f->conf.modules) {
4186  		char *module;
4187  		char *next;
4188  		for (module = f->conf.modules; module; module = next) {
4189  			char *p;
4190  			for (p = module; *p && *p != ':'; p++);
4191  			next = *p ? p + 1 : NULL;
4192  			*p = '\0';
4193  			if (module[0] &&
4194  			    fuse_push_module(f, module, args) == -1)
4195  				goto out_free_fs;
4196  		}
4197  	}
4198  	if (!f->conf.ac_attr_timeout_set)
4199  		f->conf.ac_attr_timeout = f->conf.attr_timeout;
4200  #if defined(__FreeBSD__) || defined(__NetBSD__)
4201  	f->conf.readdir_ino = 1;
4202  #endif
4203  	f->se = fuse_session_new(args, &llop, sizeof(llop), f);
4204  	if (f->se == NULL)
4205  		goto out_free_fs;
4206  	if (f->conf.debug) {
4207  		fuse_log(FUSE_LOG_DEBUG, "nullpath_ok: %i\n", f->conf.nullpath_ok);
4208  	}
4209  	f->fs->debug = f->conf.debug;
4210  	f->ctr = 0;
4211  	f->generation = 0;
4212  	if (node_table_init(&f->name_table) == -1)
4213  		goto out_free_session;
4214  	if (node_table_init(&f->id_table) == -1)
4215  		goto out_free_name_table;
4216  	pthread_mutex_init(&f->lock, NULL);
4217  	root = alloc_node(f);
4218  	if (root == NULL) {
4219  		fuse_log(FUSE_LOG_ERR, "fuse: memory allocation failed\n");
4220  		goto out_free_id_table;
4221  	}
4222  	if (lru_enabled(f)) {
4223  		struct node_lru *lnode = node_lru(root);
4224  		init_list_head(&lnode->lru);
4225  	}
4226  	strcpy(root->inline_name, "/");
4227  	root->name = root->inline_name;
4228  	if (f->conf.intr &&
4229  	    fuse_init_intr_signal(f->conf.intr_signal,
4230  				  &f->intr_installed) == -1)
4231  		goto out_free_root;
4232  	root->parent = NULL;
4233  	root->nodeid = FUSE_ROOT_ID;
4234  	inc_nlookup(root);
4235  	hash_id(f, root);
4236  	return f;
4237  out_free_root:
4238  	free(root);
4239  out_free_id_table:
4240  	free(f->id_table.array);
4241  out_free_name_table:
4242  	free(f->name_table.array);
4243  out_free_session:
4244  	fuse_session_destroy(f->se);
4245  out_free_fs:
4246  	free(f->fs);
4247  	free(f->conf.modules);
4248  out_delete_context_key:
4249  	fuse_delete_context_key();
4250  out_free:
4251  	free(f);
4252  out:
4253  	return NULL;
4254  }
4255  struct fuse *fuse_new_30(struct fuse_args *args, const struct fuse_operations *op,
4256  			 size_t op_size, void *private_data);
4257  FUSE_SYMVER("fuse_new_30", "fuse_new@FUSE_3.0")
4258  struct fuse *fuse_new_30(struct fuse_args *args,
4259  			 const struct fuse_operations *op,
4260  			 size_t op_size, void *user_data)
4261  {
4262  	struct fuse_config conf;
4263  	memset(&conf, 0, sizeof(conf));
4264  	const struct fuse_opt opts[] = {
4265  		FUSE_LIB_OPT("-h", show_help, 1),
4266  		FUSE_LIB_OPT("--help", show_help, 1),
4267  		FUSE_OPT_END
4268  	};
4269  	if (fuse_opt_parse(args, &conf, opts,
4270  			   fuse_lib_opt_proc) == -1)
4271  		return NULL;
4272  	if (conf.show_help) {
4273  		fuse_lib_help(args);
4274  		return NULL;
4275  	} else
4276  		return fuse_new_31(args, op, op_size, user_data);
4277  }
4278  void fuse_destroy(struct fuse *f)
4279  {
4280  	size_t i;
4281  	if (f->conf.intr && f->intr_installed)
4282  		fuse_restore_intr_signal(f->conf.intr_signal);
4283  	if (f->fs) {
4284  		fuse_create_context(f);
4285  		for (i = 0; i < f->id_table.size; i++) {
4286  			struct node *node;
4287  			for (node = f->id_table.array[i]; node != NULL;
4288  			     node = node->id_next) {
4289  				if (node->is_hidden) {
4290  					char *path;
4291  					if (try_get_path(f, node->nodeid, NULL, &path, NULL, false) == 0) {
4292  						fuse_fs_unlink(f->fs, path);
4293  						free(path);
4294  					}
4295  				}
4296  			}
4297  		}
4298  	}
4299  	for (i = 0; i < f->id_table.size; i++) {
4300  		struct node *node;
4301  		struct node *next;
4302  		for (node = f->id_table.array[i]; node != NULL; node = next) {
4303  			next = node->id_next;
4304  			free_node(f, node);
4305  			f->id_table.use--;
4306  		}
4307  	}
4308  	assert(list_empty(&f->partial_slabs));
4309  	assert(list_empty(&f->full_slabs));
4310  	while (fuse_modules) {
4311  		fuse_put_module(fuse_modules);
4312  	}
4313  	free(f->id_table.array);
4314  	free(f->name_table.array);
4315  	pthread_mutex_destroy(&f->lock);
4316  	fuse_session_destroy(f->se);
4317  	free(f->fs);
4318  	free(f->conf.modules);
4319  	free(f);
4320  	fuse_delete_context_key();
4321  }
4322  int fuse_mount(struct fuse *f, const char *mountpoint) {
4323  	return fuse_session_mount(fuse_get_session(f), mountpoint);
4324  }
4325  void fuse_unmount(struct fuse *f) {
4326  	fuse_session_unmount(fuse_get_session(f));
4327  }
4328  int fuse_version(void)
4329  {
4330  	return FUSE_VERSION;
4331  }
4332  const char *fuse_pkgversion(void)
4333  {
4334  	return PACKAGE_VERSION;
4335  }
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from libpcap-MDEwOlJlcG9zaXRvcnk5NDM1ODg3-flat-pcap-linux.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from libfuse-MDEwOlJlcG9zaXRvcnk0ODI5NjE3Nw==-flat-fuse.c</div>
                </div>
                <div class="column column_space"><pre><code>580  	handlep->timeout = handle->opt.timeout;
581  	if (handle->opt.promisc)
582  		handlep->sysfs_dropped = linux_if_drops(handlep->device);
</pre></code></div>
                <div class="column column_space"><pre><code>1242  		stbuf->st_uid = f->conf.uid;
1243  	if (f->conf.set_gid)
1244  		stbuf->st_gid = f->conf.gid;
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    