
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 21, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-sph_shavite.c</h3>
            <pre><code>1  #include &lt;stddef.h&gt;
2  #include &lt;string.h&gt;
3  #include &quot;sph_shavite.h&quot;
4  #ifdef __cplusplus
5  extern &quot;C&quot;{
6  #endif
7  #if SPH_SMALL_FOOTPRINT &amp;&amp; !defined SPH_SMALL_FOOTPRINT_SHAVITE
8  #define SPH_SMALL_FOOTPRINT_SHAVITE   1
9  #endif
10  #ifdef _MSC_VER
11  #pragma warning (disable: 4146)
12  #endif
13  #define C32   SPH_C32
14  #define AES_BIG_ENDIAN   0
15  #include &quot;aes_helper.c&quot;
16  static const sph_u32 IV224[] = {
17  	C32(0x6774F31C), C32(0x990AE210), C32(0xC87D4274), C32(0xC9546371),
18  	C32(0x62B2AEA8), C32(0x4B5801D8), C32(0x1B702860), C32(0x842F3017)
19  };
20  static const sph_u32 IV256[] = {
21  	C32(0x49BB3E47), C32(0x2674860D), C32(0xA8B392AC), C32(0x021AC4E6),
22  	C32(0x409283CF), C32(0x620E5D86), C32(0x6D929DCB), C32(0x96CC2A8B)
23  };
24  static const sph_u32 IV384[] = {
25  	C32(0x83DF1545), C32(0xF9AAEC13), C32(0xF4803CB0), C32(0x11FE1F47),
26  	C32(0xDA6CD269), C32(0x4F53FCD7), C32(0x950529A2), C32(0x97908147),
27  	C32(0xB0A4D7AF), C32(0x2B9132BF), C32(0x226E607D), C32(0x3C0F8D7C),
28  	C32(0x487B3F0F), C32(0x04363E22), C32(0x0155C99C), C32(0xEC2E20D3)
29  };
30  static const sph_u32 IV512[] = {
31  	C32(0x72FCCDD8), C32(0x79CA4727), C32(0x128A077B), C32(0x40D55AEC),
32  	C32(0xD1901A06), C32(0x430AE307), C32(0xB29F5CD1), C32(0xDF07FBFC),
33  	C32(0x8E45D73D), C32(0x681AB538), C32(0xBDE86578), C32(0xDD577E47),
34  	C32(0xE275EADE), C32(0x502D9FCD), C32(0xB9357178), C32(0x022A4B9A)
35  };
36  #define AES_ROUND_NOKEY(x0, x1, x2, x3)   do { \
37  		sph_u32 t0 = (x0); \
38  		sph_u32 t1 = (x1); \
39  		sph_u32 t2 = (x2); \
40  		sph_u32 t3 = (x3); \
41  		AES_ROUND_NOKEY_LE(t0, t1, t2, t3, x0, x1, x2, x3); \
42  	} while (0)
43  #define KEY_EXPAND_ELT(k0, k1, k2, k3)   do { \
44  		sph_u32 kt; \
45  		AES_ROUND_NOKEY(k1, k2, k3, k0); \
46  		kt = (k0); \
47  		(k0) = (k1); \
48  		(k1) = (k2); \
49  		(k2) = (k3); \
50  		(k3) = kt; \
51  	} while (0)
52  #if SPH_SMALL_FOOTPRINT_SHAVITE
53  static void
54  c256(sph_shavite_small_context *sc, const void *msg)
55  {
56  	sph_u32 p0, p1, p2, p3, p4, p5, p6, p7;
57  	sph_u32 rk[144];
58  	size_t u;
59  	int r, s;
60  #if SPH_LITTLE_ENDIAN
61  	memcpy(rk, msg, 64);
62  #else
63  	for (u = 0; u &lt; 16; u += 4) {
64  		rk[u + 0] = sph_dec32le_aligned(
65  			(const unsigned char *)msg + (u &lt;&lt; 2) +  0);
66  		rk[u + 1] = sph_dec32le_aligned(
67  			(const unsigned char *)msg + (u &lt;&lt; 2) +  4);
68  		rk[u + 2] = sph_dec32le_aligned(
69  			(const unsigned char *)msg + (u &lt;&lt; 2) +  8);
70  		rk[u + 3] = sph_dec32le_aligned(
71  			(const unsigned char *)msg + (u &lt;&lt; 2) + 12);
72  	}
73  #endif
74  	u = 16;
75  	for (r = 0; r &lt; 4; r ++) {
76  		for (s = 0; s &lt; 2; s ++) {
77  			sph_u32 x0, x1, x2, x3;
78  			x0 = rk[u - 15];
79  			x1 = rk[u - 14];
80  			x2 = rk[u - 13];
81  			x3 = rk[u - 16];
82  			AES_ROUND_NOKEY(x0, x1, x2, x3);
83  			rk[u + 0] = x0 ^ rk[u - 4];
84  			rk[u + 1] = x1 ^ rk[u - 3];
85  			rk[u + 2] = x2 ^ rk[u - 2];
86  			rk[u + 3] = x3 ^ rk[u - 1];
87  			if (u == 16) {
88  				rk[ 16] ^= sc-&gt;count0;
89  				rk[ 17] ^= SPH_T32(~sc-&gt;count1);
90  			} else if (u == 56) {
91  				rk[ 57] ^= sc-&gt;count1;
92  				rk[ 58] ^= SPH_T32(~sc-&gt;count0);
93  			}
94  			u += 4;
95  			x0 = rk[u - 15];
96  			x1 = rk[u - 14];
97  			x2 = rk[u - 13];
98  			x3 = rk[u - 16];
99  			AES_ROUND_NOKEY(x0, x1, x2, x3);
100  			rk[u + 0] = x0 ^ rk[u - 4];
101  			rk[u + 1] = x1 ^ rk[u - 3];
102  			rk[u + 2] = x2 ^ rk[u - 2];
103  			rk[u + 3] = x3 ^ rk[u - 1];
104  			if (u == 84) {
105  				rk[ 86] ^= sc-&gt;count1;
106  				rk[ 87] ^= SPH_T32(~sc-&gt;count0);
107  			} else if (u == 124) {
108  				rk[124] ^= sc-&gt;count0;
109  				rk[127] ^= SPH_T32(~sc-&gt;count1);
110  			}
111  			u += 4;
112  		}
113  		for (s = 0; s &lt; 4; s ++) {
114  			rk[u + 0] = rk[u - 16] ^ rk[u - 3];
115  			rk[u + 1] = rk[u - 15] ^ rk[u - 2];
116  			rk[u + 2] = rk[u - 14] ^ rk[u - 1];
117  			rk[u + 3] = rk[u - 13] ^ rk[u - 0];
118  			u += 4;
119  		}
120  	}
121  	p0 = sc-&gt;h[0x0];
122  	p1 = sc-&gt;h[0x1];
123  	p2 = sc-&gt;h[0x2];
124  	p3 = sc-&gt;h[0x3];
125  	p4 = sc-&gt;h[0x4];
126  	p5 = sc-&gt;h[0x5];
127  	p6 = sc-&gt;h[0x6];
128  	p7 = sc-&gt;h[0x7];
129  	u = 0;
130  	for (r = 0; r &lt; 6; r ++) {
131  		sph_u32 x0, x1, x2, x3;
132  		x0 = p4 ^ rk[u ++];
133  		x1 = p5 ^ rk[u ++];
134  		x2 = p6 ^ rk[u ++];
135  		x3 = p7 ^ rk[u ++];
136  		AES_ROUND_NOKEY(x0, x1, x2, x3);
137  		x0 ^= rk[u ++];
138  		x1 ^= rk[u ++];
139  		x2 ^= rk[u ++];
140  		x3 ^= rk[u ++];
141  		AES_ROUND_NOKEY(x0, x1, x2, x3);
142  		x0 ^= rk[u ++];
143  		x1 ^= rk[u ++];
144  		x2 ^= rk[u ++];
145  		x3 ^= rk[u ++];
146  		AES_ROUND_NOKEY(x0, x1, x2, x3);
147  		p0 ^= x0;
148  		p1 ^= x1;
149  		p2 ^= x2;
150  		p3 ^= x3;
151  		x0 = p0 ^ rk[u ++];
152  		x1 = p1 ^ rk[u ++];
153  		x2 = p2 ^ rk[u ++];
154  		x3 = p3 ^ rk[u ++];
155  		AES_ROUND_NOKEY(x0, x1, x2, x3);
156  		x0 ^= rk[u ++];
157  		x1 ^= rk[u ++];
158  		x2 ^= rk[u ++];
159  		x3 ^= rk[u ++];
160  		AES_ROUND_NOKEY(x0, x1, x2, x3);
161  		x0 ^= rk[u ++];
162  		x1 ^= rk[u ++];
163  		x2 ^= rk[u ++];
164  		x3 ^= rk[u ++];
165  		AES_ROUND_NOKEY(x0, x1, x2, x3);
166  		p4 ^= x0;
167  		p5 ^= x1;
168  		p6 ^= x2;
169  		p7 ^= x3;
170  	}
171  	sc-&gt;h[0x0] ^= p0;
172  	sc-&gt;h[0x1] ^= p1;
173  	sc-&gt;h[0x2] ^= p2;
174  	sc-&gt;h[0x3] ^= p3;
175  	sc-&gt;h[0x4] ^= p4;
176  	sc-&gt;h[0x5] ^= p5;
177  	sc-&gt;h[0x6] ^= p6;
178  	sc-&gt;h[0x7] ^= p7;
179  }
180  #else
181  static void
182  c256(sph_shavite_small_context *sc, const void *msg)
183  {
184  	sph_u32 p0, p1, p2, p3, p4, p5, p6, p7;
185  	sph_u32 x0, x1, x2, x3;
186  	sph_u32 rk0, rk1, rk2, rk3, rk4, rk5, rk6, rk7;
187  	sph_u32 rk8, rk9, rkA, rkB, rkC, rkD, rkE, rkF;
188  	p0 = sc-&gt;h[0x0];
189  	p1 = sc-&gt;h[0x1];
190  	p2 = sc-&gt;h[0x2];
191  	p3 = sc-&gt;h[0x3];
192  	p4 = sc-&gt;h[0x4];
193  	p5 = sc-&gt;h[0x5];
194  	p6 = sc-&gt;h[0x6];
195  	p7 = sc-&gt;h[0x7];
196  	rk0 = sph_dec32le_aligned((const unsigned char *)msg +  0);
197  	x0 = p4 ^ rk0;
198  	rk1 = sph_dec32le_aligned((const unsigned char *)msg +  4);
199  	x1 = p5 ^ rk1;
200  	rk2 = sph_dec32le_aligned((const unsigned char *)msg +  8);
201  	x2 = p6 ^ rk2;
202  	rk3 = sph_dec32le_aligned((const unsigned char *)msg + 12);
203  	x3 = p7 ^ rk3;
204  	AES_ROUND_NOKEY(x0, x1, x2, x3);
205  	rk4 = sph_dec32le_aligned((const unsigned char *)msg + 16);
206  	x0 ^= rk4;
207  	rk5 = sph_dec32le_aligned((const unsigned char *)msg + 20);
208  	x1 ^= rk5;
209  	rk6 = sph_dec32le_aligned((const unsigned char *)msg + 24);
210  	x2 ^= rk6;
211  	rk7 = sph_dec32le_aligned((const unsigned char *)msg + 28);
212  	x3 ^= rk7;
213  	AES_ROUND_NOKEY(x0, x1, x2, x3);
214  	rk8 = sph_dec32le_aligned((const unsigned char *)msg + 32);
215  	x0 ^= rk8;
216  	rk9 = sph_dec32le_aligned((const unsigned char *)msg + 36);
217  	x1 ^= rk9;
218  	rkA = sph_dec32le_aligned((const unsigned char *)msg + 40);
219  	x2 ^= rkA;
220  	rkB = sph_dec32le_aligned((const unsigned char *)msg + 44);
221  	x3 ^= rkB;
222  	AES_ROUND_NOKEY(x0, x1, x2, x3);
223  	p0 ^= x0;
224  	p1 ^= x1;
225  	p2 ^= x2;
226  	p3 ^= x3;
227  	rkC = sph_dec32le_aligned((const unsigned char *)msg + 48);
228  	x0 = p0 ^ rkC;
229  	rkD = sph_dec32le_aligned((const unsigned char *)msg + 52);
230  	x1 = p1 ^ rkD;
231  	rkE = sph_dec32le_aligned((const unsigned char *)msg + 56);
232  	x2 = p2 ^ rkE;
233  	rkF = sph_dec32le_aligned((const unsigned char *)msg + 60);
234  	x3 = p3 ^ rkF;
235  	AES_ROUND_NOKEY(x0, x1, x2, x3);
236  	KEY_EXPAND_ELT(rk0, rk1, rk2, rk3);
237  	rk0 ^= rkC ^ sc-&gt;count0;
238  	rk1 ^= rkD ^ SPH_T32(~sc-&gt;count1);
239  	rk2 ^= rkE;
240  	rk3 ^= rkF;
241  	x0 ^= rk0;
242  	x1 ^= rk1;
243  	x2 ^= rk2;
244  	x3 ^= rk3;
245  	AES_ROUND_NOKEY(x0, x1, x2, x3);
246  	KEY_EXPAND_ELT(rk4, rk5, rk6, rk7);
247  	rk4 ^= rk0;
248  	rk5 ^= rk1;
249  	rk6 ^= rk2;
250  	rk7 ^= rk3;
251  	x0 ^= rk4;
252  	x1 ^= rk5;
253  	x2 ^= rk6;
254  	x3 ^= rk7;
255  	AES_ROUND_NOKEY(x0, x1, x2, x3);
256  	p4 ^= x0;
257  	p5 ^= x1;
258  	p6 ^= x2;
259  	p7 ^= x3;
260  	KEY_EXPAND_ELT(rk8, rk9, rkA, rkB);
261  	rk8 ^= rk4;
262  	rk9 ^= rk5;
263  	rkA ^= rk6;
264  	rkB ^= rk7;
265  	x0 = p4 ^ rk8;
266  	x1 = p5 ^ rk9;
267  	x2 = p6 ^ rkA;
268  	x3 = p7 ^ rkB;
269  	AES_ROUND_NOKEY(x0, x1, x2, x3);
270  	KEY_EXPAND_ELT(rkC, rkD, rkE, rkF);
271  	rkC ^= rk8;
272  	rkD ^= rk9;
273  	rkE ^= rkA;
274  	rkF ^= rkB;
275  	x0 ^= rkC;
276  	x1 ^= rkD;
277  	x2 ^= rkE;
278  	x3 ^= rkF;
279  	AES_ROUND_NOKEY(x0, x1, x2, x3);
280  	rk0 ^= rkD;
281  	x0 ^= rk0;
282  	rk1 ^= rkE;
283  	x1 ^= rk1;
284  	rk2 ^= rkF;
285  	x2 ^= rk2;
286  	rk3 ^= rk0;
287  	x3 ^= rk3;
288  	AES_ROUND_NOKEY(x0, x1, x2, x3);
289  	p0 ^= x0;
290  	p1 ^= x1;
291  	p2 ^= x2;
292  	p3 ^= x3;
293  	rk4 ^= rk1;
294  	x0 = p0 ^ rk4;
295  	rk5 ^= rk2;
296  	x1 = p1 ^ rk5;
297  	rk6 ^= rk3;
298  	x2 = p2 ^ rk6;
299  	rk7 ^= rk4;
300  	x3 = p3 ^ rk7;
301  	AES_ROUND_NOKEY(x0, x1, x2, x3);
302  	rk8 ^= rk5;
303  	x0 ^= rk8;
304  	rk9 ^= rk6;
305  	x1 ^= rk9;
306  	rkA ^= rk7;
307  	x2 ^= rkA;
308  	rkB ^= rk8;
309  	x3 ^= rkB;
310  	AES_ROUND_NOKEY(x0, x1, x2, x3);
311  	rkC ^= rk9;
312  	x0 ^= rkC;
313  	rkD ^= rkA;
314  	x1 ^= rkD;
315  	rkE ^= rkB;
316  	x2 ^= rkE;
317  	rkF ^= rkC;
318  	x3 ^= rkF;
319  	AES_ROUND_NOKEY(x0, x1, x2, x3);
320  	p4 ^= x0;
321  	p5 ^= x1;
322  	p6 ^= x2;
323  	p7 ^= x3;
324  	KEY_EXPAND_ELT(rk0, rk1, rk2, rk3);
325  	rk0 ^= rkC;
326  	rk1 ^= rkD;
327  	rk2 ^= rkE;
328  	rk3 ^= rkF;
329  	x0 = p4 ^ rk0;
330  	x1 = p5 ^ rk1;
331  	x2 = p6 ^ rk2;
332  	x3 = p7 ^ rk3;
333  	AES_ROUND_NOKEY(x0, x1, x2, x3);
334  	KEY_EXPAND_ELT(rk4, rk5, rk6, rk7);
335  	rk4 ^= rk0;
336  	rk5 ^= rk1;
337  	rk6 ^= rk2;
338  	rk7 ^= rk3;
339  	x0 ^= rk4;
340  	x1 ^= rk5;
341  	x2 ^= rk6;
342  	x3 ^= rk7;
343  	AES_ROUND_NOKEY(x0, x1, x2, x3);
344  	KEY_EXPAND_ELT(rk8, rk9, rkA, rkB);
345  	rk8 ^= rk4;
346  	rk9 ^= rk5 ^ sc-&gt;count1;
347  	rkA ^= rk6 ^ SPH_T32(~sc-&gt;count0);
348  	rkB ^= rk7;
349  	x0 ^= rk8;
350  	x1 ^= rk9;
351  	x2 ^= rkA;
352  	x3 ^= rkB;
353  	AES_ROUND_NOKEY(x0, x1, x2, x3);
354  	p0 ^= x0;
355  	p1 ^= x1;
356  	p2 ^= x2;
357  	p3 ^= x3;
358  	KEY_EXPAND_ELT(rkC, rkD, rkE, rkF);
359  	rkC ^= rk8;
360  	rkD ^= rk9;
361  	rkE ^= rkA;
362  	rkF ^= rkB;
363  	x0 = p0 ^ rkC;
364  	x1 = p1 ^ rkD;
365  	x2 = p2 ^ rkE;
366  	x3 = p3 ^ rkF;
367  	AES_ROUND_NOKEY(x0, x1, x2, x3);
368  	rk0 ^= rkD;
369  	x0 ^= rk0;
370  	rk1 ^= rkE;
371  	x1 ^= rk1;
372  	rk2 ^= rkF;
373  	x2 ^= rk2;
374  	rk3 ^= rk0;
375  	x3 ^= rk3;
376  	AES_ROUND_NOKEY(x0, x1, x2, x3);
377  	rk4 ^= rk1;
378  	x0 ^= rk4;
379  	rk5 ^= rk2;
380  	x1 ^= rk5;
381  	rk6 ^= rk3;
382  	x2 ^= rk6;
383  	rk7 ^= rk4;
384  	x3 ^= rk7;
385  	AES_ROUND_NOKEY(x0, x1, x2, x3);
386  	p4 ^= x0;
387  	p5 ^= x1;
388  	p6 ^= x2;
389  	p7 ^= x3;
390  	rk8 ^= rk5;
391  	x0 = p4 ^ rk8;
392  	rk9 ^= rk6;
393  	x1 = p5 ^ rk9;
394  	rkA ^= rk7;
395  	x2 = p6 ^ rkA;
396  	rkB ^= rk8;
397  	x3 = p7 ^ rkB;
398  	AES_ROUND_NOKEY(x0, x1, x2, x3);
399  	rkC ^= rk9;
400  	x0 ^= rkC;
401  	rkD ^= rkA;
402  	x1 ^= rkD;
403  	rkE ^= rkB;
404  	x2 ^= rkE;
405  	rkF ^= rkC;
406  	x3 ^= rkF;
407  	AES_ROUND_NOKEY(x0, x1, x2, x3);
408  	KEY_EXPAND_ELT(rk0, rk1, rk2, rk3);
409  	rk0 ^= rkC;
410  	rk1 ^= rkD;
411  	rk2 ^= rkE;
412  	rk3 ^= rkF;
413  	x0 ^= rk0;
414  	x1 ^= rk1;
415  	x2 ^= rk2;
416  	x3 ^= rk3;
417  	AES_ROUND_NOKEY(x0, x1, x2, x3);
418  	p0 ^= x0;
419  	p1 ^= x1;
420  	p2 ^= x2;
421  	p3 ^= x3;
422  	KEY_EXPAND_ELT(rk4, rk5, rk6, rk7);
423  	rk4 ^= rk0;
424  	rk5 ^= rk1;
425  	rk6 ^= rk2 ^ sc-&gt;count1;
426  	rk7 ^= rk3 ^ SPH_T32(~sc-&gt;count0);
427  	x0 = p0 ^ rk4;
428  	x1 = p1 ^ rk5;
429  	x2 = p2 ^ rk6;
430  	x3 = p3 ^ rk7;
431  	AES_ROUND_NOKEY(x0, x1, x2, x3);
432  	KEY_EXPAND_ELT(rk8, rk9, rkA, rkB);
433  	rk8 ^= rk4;
434  	rk9 ^= rk5;
435  	rkA ^= rk6;
436  	rkB ^= rk7;
437  	x0 ^= rk8;
438  	x1 ^= rk9;
439  	x2 ^= rkA;
440  	x3 ^= rkB;
441  	AES_ROUND_NOKEY(x0, x1, x2, x3);
442  	KEY_EXPAND_ELT(rkC, rkD, rkE, rkF);
443  	rkC ^= rk8;
444  	rkD ^= rk9;
445  	rkE ^= rkA;
446  	rkF ^= rkB;
447  	x0 ^= rkC;
448  	x1 ^= rkD;
449  	x2 ^= rkE;
450  	x3 ^= rkF;
451  	AES_ROUND_NOKEY(x0, x1, x2, x3);
452  	p4 ^= x0;
453  	p5 ^= x1;
454  	p6 ^= x2;
455  	p7 ^= x3;
456  	rk0 ^= rkD;
457  	x0 = p4 ^ rk0;
458  	rk1 ^= rkE;
459  	x1 = p5 ^ rk1;
460  	rk2 ^= rkF;
461  	x2 = p6 ^ rk2;
462  	rk3 ^= rk0;
463  	x3 = p7 ^ rk3;
464  	AES_ROUND_NOKEY(x0, x1, x2, x3);
465  	rk4 ^= rk1;
466  	x0 ^= rk4;
467  	rk5 ^= rk2;
468  	x1 ^= rk5;
469  	rk6 ^= rk3;
470  	x2 ^= rk6;
471  	rk7 ^= rk4;
472  	x3 ^= rk7;
473  	AES_ROUND_NOKEY(x0, x1, x2, x3);
474  	rk8 ^= rk5;
475  	x0 ^= rk8;
476  	rk9 ^= rk6;
477  	x1 ^= rk9;
478  	rkA ^= rk7;
479  	x2 ^= rkA;
480  	rkB ^= rk8;
481  	x3 ^= rkB;
482  	AES_ROUND_NOKEY(x0, x1, x2, x3);
483  	p0 ^= x0;
484  	p1 ^= x1;
485  	p2 ^= x2;
486  	p3 ^= x3;
487  	rkC ^= rk9;
488  	x0 = p0 ^ rkC;
489  	rkD ^= rkA;
490  	x1 = p1 ^ rkD;
491  	rkE ^= rkB;
492  	x2 = p2 ^ rkE;
493  	rkF ^= rkC;
494  	x3 = p3 ^ rkF;
495  	AES_ROUND_NOKEY(x0, x1, x2, x3);
496  	KEY_EXPAND_ELT(rk0, rk1, rk2, rk3);
497  	rk0 ^= rkC;
498  	rk1 ^= rkD;
499  	rk2 ^= rkE;
500  	rk3 ^= rkF;
501  	x0 ^= rk0;
502  	x1 ^= rk1;
503  	x2 ^= rk2;
504  	x3 ^= rk3;
505  	AES_ROUND_NOKEY(x0, x1, x2, x3);
506  	KEY_EXPAND_ELT(rk4, rk5, rk6, rk7);
507  	rk4 ^= rk0;
508  	rk5 ^= rk1;
509  	rk6 ^= rk2;
510  	rk7 ^= rk3;
511  	x0 ^= rk4;
512  	x1 ^= rk5;
513  	x2 ^= rk6;
514  	x3 ^= rk7;
515  	AES_ROUND_NOKEY(x0, x1, x2, x3);
516  	p4 ^= x0;
517  	p5 ^= x1;
518  	p6 ^= x2;
519  	p7 ^= x3;
520  	KEY_EXPAND_ELT(rk8, rk9, rkA, rkB);
521  	rk8 ^= rk4;
522  	rk9 ^= rk5;
523  	rkA ^= rk6;
524  	rkB ^= rk7;
525  	x0 = p4 ^ rk8;
526  	x1 = p5 ^ rk9;
527  	x2 = p6 ^ rkA;
528  	x3 = p7 ^ rkB;
529  	AES_ROUND_NOKEY(x0, x1, x2, x3);
530  	KEY_EXPAND_ELT(rkC, rkD, rkE, rkF);
531  	rkC ^= rk8 ^ sc-&gt;count0;
532  	rkD ^= rk9;
533  	rkE ^= rkA;
534  	rkF ^= rkB ^ SPH_T32(~sc-&gt;count1);
535  	x0 ^= rkC;
536  	x1 ^= rkD;
537  	x2 ^= rkE;
538  	x3 ^= rkF;
539  	AES_ROUND_NOKEY(x0, x1, x2, x3);
540  	rk0 ^= rkD;
541  	x0 ^= rk0;
542  	rk1 ^= rkE;
543  	x1 ^= rk1;
544  	rk2 ^= rkF;
545  	x2 ^= rk2;
546  	rk3 ^= rk0;
547  	x3 ^= rk3;
548  	AES_ROUND_NOKEY(x0, x1, x2, x3);
549  	p0 ^= x0;
550  	p1 ^= x1;
551  	p2 ^= x2;
552  	p3 ^= x3;
553  	rk4 ^= rk1;
554  	x0 = p0 ^ rk4;
555  	rk5 ^= rk2;
556  	x1 = p1 ^ rk5;
557  	rk6 ^= rk3;
558  	x2 = p2 ^ rk6;
559  	rk7 ^= rk4;
560  	x3 = p3 ^ rk7;
561  	AES_ROUND_NOKEY(x0, x1, x2, x3);
562  	rk8 ^= rk5;
563  	x0 ^= rk8;
564  	rk9 ^= rk6;
565  	x1 ^= rk9;
566  	rkA ^= rk7;
567  	x2 ^= rkA;
568  	rkB ^= rk8;
569  	x3 ^= rkB;
570  	AES_ROUND_NOKEY(x0, x1, x2, x3);
571  	rkC ^= rk9;
572  	x0 ^= rkC;
573  	rkD ^= rkA;
574  	x1 ^= rkD;
575  	rkE ^= rkB;
576  	x2 ^= rkE;
577  	rkF ^= rkC;
578  	x3 ^= rkF;
579  	AES_ROUND_NOKEY(x0, x1, x2, x3);
580  	p4 ^= x0;
581  	p5 ^= x1;
582  	p6 ^= x2;
583  	p7 ^= x3;
584  	sc-&gt;h[0x0] ^= p0;
585  	sc-&gt;h[0x1] ^= p1;
586  	sc-&gt;h[0x2] ^= p2;
587  	sc-&gt;h[0x3] ^= p3;
588  	sc-&gt;h[0x4] ^= p4;
589  	sc-&gt;h[0x5] ^= p5;
590  	sc-&gt;h[0x6] ^= p6;
591  	sc-&gt;h[0x7] ^= p7;
592  }
593  #endif
594  #if SPH_SMALL_FOOTPRINT_SHAVITE
595  static void
596  c512(sph_shavite_big_context *sc, const void *msg)
597  {
598  	sph_u32 p0, p1, p2, p3, p4, p5, p6, p7;
599  	sph_u32 p8, p9, pA, pB, pC, pD, pE, pF;
600  	sph_u32 rk[448];
601  	size_t u;
602  	int r, s;
603  #if SPH_LITTLE_ENDIAN
604  	memcpy(rk, msg, 128);
605  #else
606  	for (u = 0; u &lt; 32; u += 4) {
607  		rk[u + 0] = sph_dec32le_aligned(
608  			(const unsigned char *)msg + (u &lt;&lt; 2) +  0);
609  		rk[u + 1] = sph_dec32le_aligned(
610  			(const unsigned char *)msg + (u &lt;&lt; 2) +  4);
611  		rk[u + 2] = sph_dec32le_aligned(
612  			(const unsigned char *)msg + (u &lt;&lt; 2) +  8);
613  		rk[u + 3] = sph_dec32le_aligned(
614  			(const unsigned char *)msg + (u &lt;&lt; 2) + 12);
615  	}
616  #endif
617  	u = 32;
618  	for (;;) {
619  		for (s = 0; s &lt; 4; s ++) {
620  			sph_u32 x0, x1, x2, x3;
621  			x0 = rk[u - 31];
622  			x1 = rk[u - 30];
623  			x2 = rk[u - 29];
624  			x3 = rk[u - 32];
625  			AES_ROUND_NOKEY(x0, x1, x2, x3);
626  			rk[u + 0] = x0 ^ rk[u - 4];
627  			rk[u + 1] = x1 ^ rk[u - 3];
628  			rk[u + 2] = x2 ^ rk[u - 2];
629  			rk[u + 3] = x3 ^ rk[u - 1];
630  			if (u == 32) {
631  				rk[ 32] ^= sc-&gt;count0;
632  				rk[ 33] ^= sc-&gt;count1;
633  				rk[ 34] ^= sc-&gt;count2;
634  				rk[ 35] ^= SPH_T32(~sc-&gt;count3);
635  			} else if (u == 440) {
636  				rk[440] ^= sc-&gt;count1;
637  				rk[441] ^= sc-&gt;count0;
638  				rk[442] ^= sc-&gt;count3;
639  				rk[443] ^= SPH_T32(~sc-&gt;count2);
640  			}
641  			u += 4;
642  			x0 = rk[u - 31];
643  			x1 = rk[u - 30];
644  			x2 = rk[u - 29];
645  			x3 = rk[u - 32];
646  			AES_ROUND_NOKEY(x0, x1, x2, x3);
647  			rk[u + 0] = x0 ^ rk[u - 4];
648  			rk[u + 1] = x1 ^ rk[u - 3];
649  			rk[u + 2] = x2 ^ rk[u - 2];
650  			rk[u + 3] = x3 ^ rk[u - 1];
651  			if (u == 164) {
652  				rk[164] ^= sc-&gt;count3;
653  				rk[165] ^= sc-&gt;count2;
654  				rk[166] ^= sc-&gt;count1;
655  				rk[167] ^= SPH_T32(~sc-&gt;count0);
656  			} else if (u == 316) {
657  				rk[316] ^= sc-&gt;count2;
658  				rk[317] ^= sc-&gt;count3;
659  				rk[318] ^= sc-&gt;count0;
660  				rk[319] ^= SPH_T32(~sc-&gt;count1);
661  			}
662  			u += 4;
663  		}
664  		if (u == 448)
665  			break;
666  		for (s = 0; s &lt; 8; s ++) {
667  			rk[u + 0] = rk[u - 32] ^ rk[u - 7];
668  			rk[u + 1] = rk[u - 31] ^ rk[u - 6];
669  			rk[u + 2] = rk[u - 30] ^ rk[u - 5];
670  			rk[u + 3] = rk[u - 29] ^ rk[u - 4];
671  			u += 4;
672  		}
673  	}
674  	p0 = sc-&gt;h[0x0];
675  	p1 = sc-&gt;h[0x1];
676  	p2 = sc-&gt;h[0x2];
677  	p3 = sc-&gt;h[0x3];
678  	p4 = sc-&gt;h[0x4];
679  	p5 = sc-&gt;h[0x5];
680  	p6 = sc-&gt;h[0x6];
681  	p7 = sc-&gt;h[0x7];
682  	p8 = sc-&gt;h[0x8];
683  	p9 = sc-&gt;h[0x9];
684  	pA = sc-&gt;h[0xA];
685  	pB = sc-&gt;h[0xB];
686  	pC = sc-&gt;h[0xC];
687  	pD = sc-&gt;h[0xD];
688  	pE = sc-&gt;h[0xE];
689  	pF = sc-&gt;h[0xF];
690  	u = 0;
691  	for (r = 0; r &lt; 14; r ++) {
692  #define C512_ELT(l0, l1, l2, l3, r0, r1, r2, r3)   do { \
693  		sph_u32 x0, x1, x2, x3; \
694  		x0 = r0 ^ rk[u ++]; \
695  		x1 = r1 ^ rk[u ++]; \
696  		x2 = r2 ^ rk[u ++]; \
697  		x3 = r3 ^ rk[u ++]; \
698  		AES_ROUND_NOKEY(x0, x1, x2, x3); \
699  		x0 ^= rk[u ++]; \
700  		x1 ^= rk[u ++]; \
701  		x2 ^= rk[u ++]; \
702  		x3 ^= rk[u ++]; \
703  		AES_ROUND_NOKEY(x0, x1, x2, x3); \
704  		x0 ^= rk[u ++]; \
705  		x1 ^= rk[u ++]; \
706  		x2 ^= rk[u ++]; \
707  		x3 ^= rk[u ++]; \
708  		AES_ROUND_NOKEY(x0, x1, x2, x3); \
709  		x0 ^= rk[u ++]; \
710  		x1 ^= rk[u ++]; \
711  		x2 ^= rk[u ++]; \
712  		x3 ^= rk[u ++]; \
713  		AES_ROUND_NOKEY(x0, x1, x2, x3); \
714  		l0 ^= x0; \
715  		l1 ^= x1; \
716  		l2 ^= x2; \
717  		l3 ^= x3; \
718  	} while (0)
719  #define WROT(a, b, c, d)   do { \
720  		sph_u32 t = d; \
721  		d = c; \
722  		c = b; \
723  		b = a; \
724  		a = t; \
725  	} while (0)
726  		C512_ELT(p0, p1, p2, p3, p4, p5, p6, p7);
727  		C512_ELT(p8, p9, pA, pB, pC, pD, pE, pF);
728  		WROT(p0, p4, p8, pC);
729  		WROT(p1, p5, p9, pD);
730  		WROT(p2, p6, pA, pE);
731  		WROT(p3, p7, pB, pF);
732  #undef C512_ELT
733  #undef WROT
734  	}
735  	sc-&gt;h[0x0] ^= p0;
736  	sc-&gt;h[0x1] ^= p1;
737  	sc-&gt;h[0x2] ^= p2;
738  	sc-&gt;h[0x3] ^= p3;
739  	sc-&gt;h[0x4] ^= p4;
740  	sc-&gt;h[0x5] ^= p5;
741  	sc-&gt;h[0x6] ^= p6;
742  	sc-&gt;h[0x7] ^= p7;
743  	sc-&gt;h[0x8] ^= p8;
744  	sc-&gt;h[0x9] ^= p9;
745  	sc-&gt;h[0xA] ^= pA;
746  	sc-&gt;h[0xB] ^= pB;
747  	sc-&gt;h[0xC] ^= pC;
748  	sc-&gt;h[0xD] ^= pD;
749  	sc-&gt;h[0xE] ^= pE;
750  	sc-&gt;h[0xF] ^= pF;
751  }
752  #else
753  static void
754  c512(sph_shavite_big_context *sc, const void *msg)
755  {
756  	sph_u32 p0, p1, p2, p3, p4, p5, p6, p7;
757  	sph_u32 p8, p9, pA, pB, pC, pD, pE, pF;
758  	sph_u32 x0, x1, x2, x3;
759  	sph_u32 rk00, rk01, rk02, rk03, rk04, rk05, rk06, rk07;
760  	sph_u32 rk08, rk09, rk0A, rk0B, rk0C, rk0D, rk0E, rk0F;
761  	sph_u32 rk10, rk11, rk12, rk13, rk14, rk15, rk16, rk17;
762  	sph_u32 rk18, rk19, rk1A, rk1B, rk1C, rk1D, rk1E, rk1F;
763  	int r;
764  	p0 = sc-&gt;h[0x0];
765  	p1 = sc-&gt;h[0x1];
766  	p2 = sc-&gt;h[0x2];
767  	p3 = sc-&gt;h[0x3];
768  	p4 = sc-&gt;h[0x4];
769  	p5 = sc-&gt;h[0x5];
770  	p6 = sc-&gt;h[0x6];
771  	p7 = sc-&gt;h[0x7];
772  	p8 = sc-&gt;h[0x8];
773  	p9 = sc-&gt;h[0x9];
774  	pA = sc-&gt;h[0xA];
775  	pB = sc-&gt;h[0xB];
776  	pC = sc-&gt;h[0xC];
777  	pD = sc-&gt;h[0xD];
778  	pE = sc-&gt;h[0xE];
779  	pF = sc-&gt;h[0xF];
780  	rk00 = sph_dec32le_aligned((const unsigned char *)msg +   0);
781  	x0 = p4 ^ rk00;
782  	rk01 = sph_dec32le_aligned((const unsigned char *)msg +   4);
783  	x1 = p5 ^ rk01;
784  	rk02 = sph_dec32le_aligned((const unsigned char *)msg +   8);
785  	x2 = p6 ^ rk02;
786  	rk03 = sph_dec32le_aligned((const unsigned char *)msg +  12);
787  	x3 = p7 ^ rk03;
788  	AES_ROUND_NOKEY(x0, x1, x2, x3);
789  	rk04 = sph_dec32le_aligned((const unsigned char *)msg +  16);
790  	x0 ^= rk04;
791  	rk05 = sph_dec32le_aligned((const unsigned char *)msg +  20);
792  	x1 ^= rk05;
793  	rk06 = sph_dec32le_aligned((const unsigned char *)msg +  24);
794  	x2 ^= rk06;
795  	rk07 = sph_dec32le_aligned((const unsigned char *)msg +  28);
796  	x3 ^= rk07;
797  	AES_ROUND_NOKEY(x0, x1, x2, x3);
798  	rk08 = sph_dec32le_aligned((const unsigned char *)msg +  32);
799  	x0 ^= rk08;
800  	rk09 = sph_dec32le_aligned((const unsigned char *)msg +  36);
801  	x1 ^= rk09;
802  	rk0A = sph_dec32le_aligned((const unsigned char *)msg +  40);
803  	x2 ^= rk0A;
804  	rk0B = sph_dec32le_aligned((const unsigned char *)msg +  44);
805  	x3 ^= rk0B;
806  	AES_ROUND_NOKEY(x0, x1, x2, x3);
807  	rk0C = sph_dec32le_aligned((const unsigned char *)msg +  48);
808  	x0 ^= rk0C;
809  	rk0D = sph_dec32le_aligned((const unsigned char *)msg +  52);
810  	x1 ^= rk0D;
811  	rk0E = sph_dec32le_aligned((const unsigned char *)msg +  56);
812  	x2 ^= rk0E;
813  	rk0F = sph_dec32le_aligned((const unsigned char *)msg +  60);
814  	x3 ^= rk0F;
815  	AES_ROUND_NOKEY(x0, x1, x2, x3);
816  	p0 ^= x0;
817  	p1 ^= x1;
818  	p2 ^= x2;
819  	p3 ^= x3;
820  	rk10 = sph_dec32le_aligned((const unsigned char *)msg +  64);
821  	x0 = pC ^ rk10;
822  	rk11 = sph_dec32le_aligned((const unsigned char *)msg +  68);
823  	x1 = pD ^ rk11;
824  	rk12 = sph_dec32le_aligned((const unsigned char *)msg +  72);
825  	x2 = pE ^ rk12;
826  	rk13 = sph_dec32le_aligned((const unsigned char *)msg +  76);
827  	x3 = pF ^ rk13;
828  	AES_ROUND_NOKEY(x0, x1, x2, x3);
829  	rk14 = sph_dec32le_aligned((const unsigned char *)msg +  80);
830  	x0 ^= rk14;
831  	rk15 = sph_dec32le_aligned((const unsigned char *)msg +  84);
832  	x1 ^= rk15;
833  	rk16 = sph_dec32le_aligned((const unsigned char *)msg +  88);
834  	x2 ^= rk16;
835  	rk17 = sph_dec32le_aligned((const unsigned char *)msg +  92);
836  	x3 ^= rk17;
837  	AES_ROUND_NOKEY(x0, x1, x2, x3);
838  	rk18 = sph_dec32le_aligned((const unsigned char *)msg +  96);
839  	x0 ^= rk18;
840  	rk19 = sph_dec32le_aligned((const unsigned char *)msg + 100);
841  	x1 ^= rk19;
842  	rk1A = sph_dec32le_aligned((const unsigned char *)msg + 104);
843  	x2 ^= rk1A;
844  	rk1B = sph_dec32le_aligned((const unsigned char *)msg + 108);
845  	x3 ^= rk1B;
846  	AES_ROUND_NOKEY(x0, x1, x2, x3);
847  	rk1C = sph_dec32le_aligned((const unsigned char *)msg + 112);
848  	x0 ^= rk1C;
849  	rk1D = sph_dec32le_aligned((const unsigned char *)msg + 116);
850  	x1 ^= rk1D;
851  	rk1E = sph_dec32le_aligned((const unsigned char *)msg + 120);
852  	x2 ^= rk1E;
853  	rk1F = sph_dec32le_aligned((const unsigned char *)msg + 124);
854  	x3 ^= rk1F;
855  	AES_ROUND_NOKEY(x0, x1, x2, x3);
856  	p8 ^= x0;
857  	p9 ^= x1;
858  	pA ^= x2;
859  	pB ^= x3;
860  	for (r = 0; r &lt; 3; r ++) {
861  		KEY_EXPAND_ELT(rk00, rk01, rk02, rk03);
862  		rk00 ^= rk1C;
863  		rk01 ^= rk1D;
864  		rk02 ^= rk1E;
865  		rk03 ^= rk1F;
866  		if (r == 0) {
867  			rk00 ^= sc-&gt;count0;
868  			rk01 ^= sc-&gt;count1;
869  			rk02 ^= sc-&gt;count2;
870  			rk03 ^= SPH_T32(~sc-&gt;count3);
871  		}
872  		x0 = p0 ^ rk00;
873  		x1 = p1 ^ rk01;
874  		x2 = p2 ^ rk02;
875  		x3 = p3 ^ rk03;
876  		AES_ROUND_NOKEY(x0, x1, x2, x3);
877  		KEY_EXPAND_ELT(rk04, rk05, rk06, rk07);
878  		rk04 ^= rk00;
879  		rk05 ^= rk01;
880  		rk06 ^= rk02;
881  		rk07 ^= rk03;
882  		if (r == 1) {
883  			rk04 ^= sc-&gt;count3;
884  			rk05 ^= sc-&gt;count2;
885  			rk06 ^= sc-&gt;count1;
886  			rk07 ^= SPH_T32(~sc-&gt;count0);
887  		}
888  		x0 ^= rk04;
889  		x1 ^= rk05;
890  		x2 ^= rk06;
891  		x3 ^= rk07;
892  		AES_ROUND_NOKEY(x0, x1, x2, x3);
893  		KEY_EXPAND_ELT(rk08, rk09, rk0A, rk0B);
894  		rk08 ^= rk04;
895  		rk09 ^= rk05;
896  		rk0A ^= rk06;
897  		rk0B ^= rk07;
898  		x0 ^= rk08;
899  		x1 ^= rk09;
900  		x2 ^= rk0A;
901  		x3 ^= rk0B;
902  		AES_ROUND_NOKEY(x0, x1, x2, x3);
903  		KEY_EXPAND_ELT(rk0C, rk0D, rk0E, rk0F);
904  		rk0C ^= rk08;
905  		rk0D ^= rk09;
906  		rk0E ^= rk0A;
907  		rk0F ^= rk0B;
908  		x0 ^= rk0C;
909  		x1 ^= rk0D;
910  		x2 ^= rk0E;
911  		x3 ^= rk0F;
912  		AES_ROUND_NOKEY(x0, x1, x2, x3);
913  		pC ^= x0;
914  		pD ^= x1;
915  		pE ^= x2;
916  		pF ^= x3;
917  		KEY_EXPAND_ELT(rk10, rk11, rk12, rk13);
918  		rk10 ^= rk0C;
919  		rk11 ^= rk0D;
920  		rk12 ^= rk0E;
921  		rk13 ^= rk0F;
922  		x0 = p8 ^ rk10;
923  		x1 = p9 ^ rk11;
924  		x2 = pA ^ rk12;
925  		x3 = pB ^ rk13;
926  		AES_ROUND_NOKEY(x0, x1, x2, x3);
927  		KEY_EXPAND_ELT(rk14, rk15, rk16, rk17);
928  		rk14 ^= rk10;
929  		rk15 ^= rk11;
930  		rk16 ^= rk12;
931  		rk17 ^= rk13;
932  		x0 ^= rk14;
933  		x1 ^= rk15;
934  		x2 ^= rk16;
935  		x3 ^= rk17;
936  		AES_ROUND_NOKEY(x0, x1, x2, x3);
937  		KEY_EXPAND_ELT(rk18, rk19, rk1A, rk1B);
938  		rk18 ^= rk14;
939  		rk19 ^= rk15;
940  		rk1A ^= rk16;
941  		rk1B ^= rk17;
942  		x0 ^= rk18;
943  		x1 ^= rk19;
944  		x2 ^= rk1A;
945  		x3 ^= rk1B;
946  		AES_ROUND_NOKEY(x0, x1, x2, x3);
947  		KEY_EXPAND_ELT(rk1C, rk1D, rk1E, rk1F);
948  		rk1C ^= rk18;
949  		rk1D ^= rk19;
950  		rk1E ^= rk1A;
951  		rk1F ^= rk1B;
952  		if (r == 2) {
953  			rk1C ^= sc-&gt;count2;
954  			rk1D ^= sc-&gt;count3;
955  			rk1E ^= sc-&gt;count0;
956  			rk1F ^= SPH_T32(~sc-&gt;count1);
957  		}
958  		x0 ^= rk1C;
959  		x1 ^= rk1D;
960  		x2 ^= rk1E;
961  		x3 ^= rk1F;
962  		AES_ROUND_NOKEY(x0, x1, x2, x3);
963  		p4 ^= x0;
964  		p5 ^= x1;
965  		p6 ^= x2;
966  		p7 ^= x3;
967  		rk00 ^= rk19;
968  		x0 = pC ^ rk00;
969  		rk01 ^= rk1A;
970  		x1 = pD ^ rk01;
971  		rk02 ^= rk1B;
972  		x2 = pE ^ rk02;
973  		rk03 ^= rk1C;
974  		x3 = pF ^ rk03;
975  		AES_ROUND_NOKEY(x0, x1, x2, x3);
976  		rk04 ^= rk1D;
977  		x0 ^= rk04;
978  		rk05 ^= rk1E;
979  		x1 ^= rk05;
980  		rk06 ^= rk1F;
981  		x2 ^= rk06;
982  		rk07 ^= rk00;
983  		x3 ^= rk07;
984  		AES_ROUND_NOKEY(x0, x1, x2, x3);
985  		rk08 ^= rk01;
986  		x0 ^= rk08;
987  		rk09 ^= rk02;
988  		x1 ^= rk09;
989  		rk0A ^= rk03;
990  		x2 ^= rk0A;
991  		rk0B ^= rk04;
992  		x3 ^= rk0B;
993  		AES_ROUND_NOKEY(x0, x1, x2, x3);
994  		rk0C ^= rk05;
995  		x0 ^= rk0C;
996  		rk0D ^= rk06;
997  		x1 ^= rk0D;
998  		rk0E ^= rk07;
999  		x2 ^= rk0E;
1000  		rk0F ^= rk08;
1001  		x3 ^= rk0F;
1002  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1003  		p8 ^= x0;
1004  		p9 ^= x1;
1005  		pA ^= x2;
1006  		pB ^= x3;
1007  		rk10 ^= rk09;
1008  		x0 = p4 ^ rk10;
1009  		rk11 ^= rk0A;
1010  		x1 = p5 ^ rk11;
1011  		rk12 ^= rk0B;
1012  		x2 = p6 ^ rk12;
1013  		rk13 ^= rk0C;
1014  		x3 = p7 ^ rk13;
1015  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1016  		rk14 ^= rk0D;
1017  		x0 ^= rk14;
1018  		rk15 ^= rk0E;
1019  		x1 ^= rk15;
1020  		rk16 ^= rk0F;
1021  		x2 ^= rk16;
1022  		rk17 ^= rk10;
1023  		x3 ^= rk17;
1024  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1025  		rk18 ^= rk11;
1026  		x0 ^= rk18;
1027  		rk19 ^= rk12;
1028  		x1 ^= rk19;
1029  		rk1A ^= rk13;
1030  		x2 ^= rk1A;
1031  		rk1B ^= rk14;
1032  		x3 ^= rk1B;
1033  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1034  		rk1C ^= rk15;
1035  		x0 ^= rk1C;
1036  		rk1D ^= rk16;
1037  		x1 ^= rk1D;
1038  		rk1E ^= rk17;
1039  		x2 ^= rk1E;
1040  		rk1F ^= rk18;
1041  		x3 ^= rk1F;
1042  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1043  		p0 ^= x0;
1044  		p1 ^= x1;
1045  		p2 ^= x2;
1046  		p3 ^= x3;
1047  		KEY_EXPAND_ELT(rk00, rk01, rk02, rk03);
1048  		rk00 ^= rk1C;
1049  		rk01 ^= rk1D;
1050  		rk02 ^= rk1E;
1051  		rk03 ^= rk1F;
1052  		x0 = p8 ^ rk00;
1053  		x1 = p9 ^ rk01;
1054  		x2 = pA ^ rk02;
1055  		x3 = pB ^ rk03;
1056  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1057  		KEY_EXPAND_ELT(rk04, rk05, rk06, rk07);
1058  		rk04 ^= rk00;
1059  		rk05 ^= rk01;
1060  		rk06 ^= rk02;
1061  		rk07 ^= rk03;
1062  		x0 ^= rk04;
1063  		x1 ^= rk05;
1064  		x2 ^= rk06;
1065  		x3 ^= rk07;
1066  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1067  		KEY_EXPAND_ELT(rk08, rk09, rk0A, rk0B);
1068  		rk08 ^= rk04;
1069  		rk09 ^= rk05;
1070  		rk0A ^= rk06;
1071  		rk0B ^= rk07;
1072  		x0 ^= rk08;
1073  		x1 ^= rk09;
1074  		x2 ^= rk0A;
1075  		x3 ^= rk0B;
1076  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1077  		KEY_EXPAND_ELT(rk0C, rk0D, rk0E, rk0F);
1078  		rk0C ^= rk08;
1079  		rk0D ^= rk09;
1080  		rk0E ^= rk0A;
1081  		rk0F ^= rk0B;
1082  		x0 ^= rk0C;
1083  		x1 ^= rk0D;
1084  		x2 ^= rk0E;
1085  		x3 ^= rk0F;
1086  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1087  		p4 ^= x0;
1088  		p5 ^= x1;
1089  		p6 ^= x2;
1090  		p7 ^= x3;
1091  		KEY_EXPAND_ELT(rk10, rk11, rk12, rk13);
1092  		rk10 ^= rk0C;
1093  		rk11 ^= rk0D;
1094  		rk12 ^= rk0E;
1095  		rk13 ^= rk0F;
1096  		x0 = p0 ^ rk10;
1097  		x1 = p1 ^ rk11;
1098  		x2 = p2 ^ rk12;
1099  		x3 = p3 ^ rk13;
1100  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1101  		KEY_EXPAND_ELT(rk14, rk15, rk16, rk17);
1102  		rk14 ^= rk10;
1103  		rk15 ^= rk11;
1104  		rk16 ^= rk12;
1105  		rk17 ^= rk13;
1106  		x0 ^= rk14;
1107  		x1 ^= rk15;
1108  		x2 ^= rk16;
1109  		x3 ^= rk17;
1110  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1111  		KEY_EXPAND_ELT(rk18, rk19, rk1A, rk1B);
1112  		rk18 ^= rk14;
1113  		rk19 ^= rk15;
1114  		rk1A ^= rk16;
1115  		rk1B ^= rk17;
1116  		x0 ^= rk18;
1117  		x1 ^= rk19;
1118  		x2 ^= rk1A;
1119  		x3 ^= rk1B;
1120  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1121  		KEY_EXPAND_ELT(rk1C, rk1D, rk1E, rk1F);
1122  		rk1C ^= rk18;
1123  		rk1D ^= rk19;
1124  		rk1E ^= rk1A;
1125  		rk1F ^= rk1B;
1126  		x0 ^= rk1C;
1127  		x1 ^= rk1D;
1128  		x2 ^= rk1E;
1129  		x3 ^= rk1F;
1130  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1131  		pC ^= x0;
1132  		pD ^= x1;
1133  		pE ^= x2;
1134  		pF ^= x3;
1135  		rk00 ^= rk19;
1136  		x0 = p4 ^ rk00;
1137  		rk01 ^= rk1A;
1138  		x1 = p5 ^ rk01;
1139  		rk02 ^= rk1B;
1140  		x2 = p6 ^ rk02;
1141  		rk03 ^= rk1C;
1142  		x3 = p7 ^ rk03;
1143  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1144  		rk04 ^= rk1D;
1145  		x0 ^= rk04;
1146  		rk05 ^= rk1E;
1147  		x1 ^= rk05;
1148  		rk06 ^= rk1F;
1149  		x2 ^= rk06;
1150  		rk07 ^= rk00;
1151  		x3 ^= rk07;
1152  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1153  		rk08 ^= rk01;
1154  		x0 ^= rk08;
1155  		rk09 ^= rk02;
1156  		x1 ^= rk09;
1157  		rk0A ^= rk03;
1158  		x2 ^= rk0A;
1159  		rk0B ^= rk04;
1160  		x3 ^= rk0B;
1161  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1162  		rk0C ^= rk05;
1163  		x0 ^= rk0C;
1164  		rk0D ^= rk06;
1165  		x1 ^= rk0D;
1166  		rk0E ^= rk07;
1167  		x2 ^= rk0E;
1168  		rk0F ^= rk08;
1169  		x3 ^= rk0F;
1170  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1171  		p0 ^= x0;
1172  		p1 ^= x1;
1173  		p2 ^= x2;
1174  		p3 ^= x3;
1175  		rk10 ^= rk09;
1176  		x0 = pC ^ rk10;
1177  		rk11 ^= rk0A;
1178  		x1 = pD ^ rk11;
1179  		rk12 ^= rk0B;
1180  		x2 = pE ^ rk12;
1181  		rk13 ^= rk0C;
1182  		x3 = pF ^ rk13;
1183  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1184  		rk14 ^= rk0D;
1185  		x0 ^= rk14;
1186  		rk15 ^= rk0E;
1187  		x1 ^= rk15;
1188  		rk16 ^= rk0F;
1189  		x2 ^= rk16;
1190  		rk17 ^= rk10;
1191  		x3 ^= rk17;
1192  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1193  		rk18 ^= rk11;
1194  		x0 ^= rk18;
1195  		rk19 ^= rk12;
1196  		x1 ^= rk19;
1197  		rk1A ^= rk13;
1198  		x2 ^= rk1A;
1199  		rk1B ^= rk14;
1200  		x3 ^= rk1B;
1201  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1202  		rk1C ^= rk15;
1203  		x0 ^= rk1C;
1204  		rk1D ^= rk16;
1205  		x1 ^= rk1D;
1206  		rk1E ^= rk17;
1207  		x2 ^= rk1E;
1208  		rk1F ^= rk18;
1209  		x3 ^= rk1F;
1210  		AES_ROUND_NOKEY(x0, x1, x2, x3);
1211  		p8 ^= x0;
1212  		p9 ^= x1;
1213  		pA ^= x2;
1214  		pB ^= x3;
1215  	}
1216  	KEY_EXPAND_ELT(rk00, rk01, rk02, rk03);
1217  	rk00 ^= rk1C;
1218  	rk01 ^= rk1D;
1219  	rk02 ^= rk1E;
1220  	rk03 ^= rk1F;
1221  	x0 = p0 ^ rk00;
1222  	x1 = p1 ^ rk01;
1223  	x2 = p2 ^ rk02;
1224  	x3 = p3 ^ rk03;
1225  	AES_ROUND_NOKEY(x0, x1, x2, x3);
1226  	KEY_EXPAND_ELT(rk04, rk05, rk06, rk07);
1227  	rk04 ^= rk00;
1228  	rk05 ^= rk01;
1229  	rk06 ^= rk02;
1230  	rk07 ^= rk03;
1231  	x0 ^= rk04;
1232  	x1 ^= rk05;
1233  	x2 ^= rk06;
1234  	x3 ^= rk07;
1235  	AES_ROUND_NOKEY(x0, x1, x2, x3);
1236  	KEY_EXPAND_ELT(rk08, rk09, rk0A, rk0B);
1237  	rk08 ^= rk04;
1238  	rk09 ^= rk05;
1239  	rk0A ^= rk06;
1240  	rk0B ^= rk07;
1241  	x0 ^= rk08;
1242  	x1 ^= rk09;
1243  	x2 ^= rk0A;
1244  	x3 ^= rk0B;
1245  	AES_ROUND_NOKEY(x0, x1, x2, x3);
1246  	KEY_EXPAND_ELT(rk0C, rk0D, rk0E, rk0F);
1247  	rk0C ^= rk08;
1248  	rk0D ^= rk09;
1249  	rk0E ^= rk0A;
1250  	rk0F ^= rk0B;
1251  	x0 ^= rk0C;
1252  	x1 ^= rk0D;
1253  	x2 ^= rk0E;
1254  	x3 ^= rk0F;
1255  	AES_ROUND_NOKEY(x0, x1, x2, x3);
1256  	pC ^= x0;
1257  	pD ^= x1;
1258  	pE ^= x2;
1259  	pF ^= x3;
1260  	KEY_EXPAND_ELT(rk10, rk11, rk12, rk13);
1261  	rk10 ^= rk0C;
1262  	rk11 ^= rk0D;
1263  	rk12 ^= rk0E;
1264  	rk13 ^= rk0F;
1265  	x0 = p8 ^ rk10;
1266  	x1 = p9 ^ rk11;
1267  	x2 = pA ^ rk12;
1268  	x3 = pB ^ rk13;
1269  	AES_ROUND_NOKEY(x0, x1, x2, x3);
1270  	KEY_EXPAND_ELT(rk14, rk15, rk16, rk17);
1271  	rk14 ^= rk10;
1272  	rk15 ^= rk11;
1273  	rk16 ^= rk12;
1274  	rk17 ^= rk13;
1275  	x0 ^= rk14;
1276  	x1 ^= rk15;
1277  	x2 ^= rk16;
1278  	x3 ^= rk17;
1279  	AES_ROUND_NOKEY(x0, x1, x2, x3);
1280  	KEY_EXPAND_ELT(rk18, rk19, rk1A, rk1B);
1281  	rk18 ^= rk14 ^ sc-&gt;count1;
1282  	rk19 ^= rk15 ^ sc-&gt;count0;
1283  	rk1A ^= rk16 ^ sc-&gt;count3;
1284  	rk1B ^= rk17 ^ SPH_T32(~sc-&gt;count2);
1285  	x0 ^= rk18;
1286  	x1 ^= rk19;
1287  	x2 ^= rk1A;
1288  	x3 ^= rk1B;
1289  	AES_ROUND_NOKEY(x0, x1, x2, x3);
1290  	KEY_EXPAND_ELT(rk1C, rk1D, rk1E, rk1F);
1291  	rk1C ^= rk18;
1292  	rk1D ^= rk19;
1293  	rk1E ^= rk1A;
1294  	rk1F ^= rk1B;
1295  	x0 ^= rk1C;
1296  	x1 ^= rk1D;
1297  	x2 ^= rk1E;
1298  	x3 ^= rk1F;
1299  	AES_ROUND_NOKEY(x0, x1, x2, x3);
1300  	p4 ^= x0;
1301  	p5 ^= x1;
1302  	p6 ^= x2;
1303  	p7 ^= x3;
1304  	sc-&gt;h[0x0] ^= p8;
1305  	sc-&gt;h[0x1] ^= p9;
1306  	sc-&gt;h[0x2] ^= pA;
1307  	sc-&gt;h[0x3] ^= pB;
1308  	sc-&gt;h[0x4] ^= pC;
1309  	sc-&gt;h[0x5] ^= pD;
1310  	sc-&gt;h[0x6] ^= pE;
1311  	sc-&gt;h[0x7] ^= pF;
1312  	sc-&gt;h[0x8] ^= p0;
1313  	sc-&gt;h[0x9] ^= p1;
1314  	sc-&gt;h[0xA] ^= p2;
1315  	sc-&gt;h[0xB] ^= p3;
1316  	sc-&gt;h[0xC] ^= p4;
1317  	sc-&gt;h[0xD] ^= p5;
1318  	sc-&gt;h[0xE] ^= p6;
1319  	sc-&gt;h[0xF] ^= p7;
1320  }
1321  #endif
1322  static void
1323  shavite_small_init(sph_shavite_small_context *sc, const sph_u32 *iv)
1324  {
1325  	memcpy(sc-&gt;h, iv, sizeof sc-&gt;h);
1326  	sc-&gt;ptr = 0;
1327  	sc-&gt;count0 = 0;
1328  	sc-&gt;count1 = 0;
1329  }
1330  static void
1331  shavite_small_core(sph_shavite_small_context *sc, const void *data, size_t len)
1332  {
1333  	unsigned char *buf;
1334  	size_t ptr;
1335  	buf = sc-&gt;buf;
1336  	ptr = sc-&gt;ptr;
1337  	while (len &gt; 0) {
1338  		size_t clen;
1339  		clen = (sizeof sc-&gt;buf) - ptr;
1340  		if (clen &gt; len)
1341  			clen = len;
1342  		memcpy(buf + ptr, data, clen);
1343  		data = (const unsigned char *)data + clen;
1344  		ptr += clen;
1345  		len -= clen;
1346  		if (ptr == sizeof sc-&gt;buf) {
1347  			if ((sc-&gt;count0 = SPH_T32(sc-&gt;count0 + 512)) == 0)
1348  				sc-&gt;count1 = SPH_T32(sc-&gt;count1 + 1);
1349  			c256(sc, buf);
1350  			ptr = 0;
1351  		}
1352  	}
1353  	sc-&gt;ptr = ptr;
1354  }
1355  static void
1356  shavite_small_close(sph_shavite_small_context *sc,
1357  	unsigned ub, unsigned n, void *dst, size_t out_size_w32)
1358  {
1359  	unsigned char *buf;
1360  	size_t ptr, u;
1361  	unsigned z;
1362  	sph_u32 count0, count1;
1363  	buf = sc-&gt;buf;
1364  	ptr = sc-&gt;ptr;
1365  	count0 = (sc-&gt;count0 += (ptr &lt;&lt; 3) + n);
1366  	count1 = sc-&gt;count1;
1367  	z = 0x80 &gt;&gt; n;
1368  	z = ((ub &amp; -z) | z) &amp; 0xFF;
1369  	if (ptr == 0 &amp;&amp; n == 0) {
1370  		buf[0] = 0x80;
1371  		memset(buf + 1, 0, 53);
1372  		sc-&gt;count0 = sc-&gt;count1 = 0;
1373  	} else if (ptr &lt; 54) {
1374  		buf[ptr ++] = z;
1375  		memset(buf + ptr, 0, 54 - ptr);
1376  	} else {
1377  		buf[ptr ++] = z;
1378  		memset(buf + ptr, 0, 64 - ptr);
1379  		c256(sc, buf);
1380  		memset(buf, 0, 54);
1381  		sc-&gt;count0 = sc-&gt;count1 = 0;
1382  	}
1383  	sph_enc32le(buf + 54, count0);
1384  	sph_enc32le(buf + 58, count1);
1385  	buf[62] = out_size_w32 &lt;&lt; 5;
1386  	buf[63] = out_size_w32 &gt;&gt; 3;
1387  	c256(sc, buf);
1388  	for (u = 0; u &lt; out_size_w32; u ++)
1389  		sph_enc32le((unsigned char *)dst + (u &lt;&lt; 2), sc-&gt;h[u]);
1390  }
1391  static void
1392  shavite_big_init(sph_shavite_big_context *sc, const sph_u32 *iv)
1393  {
1394  	memcpy(sc-&gt;h, iv, sizeof sc-&gt;h);
1395  	sc-&gt;ptr = 0;
1396  	sc-&gt;count0 = 0;
1397  	sc-&gt;count1 = 0;
1398  	sc-&gt;count2 = 0;
1399  	sc-&gt;count3 = 0;
1400  }
1401  static void
1402  shavite_big_core(sph_shavite_big_context *sc, const void *data, size_t len)
1403  {
1404  	unsigned char *buf;
1405  	size_t ptr;
1406  	buf = sc-&gt;buf;
1407  	ptr = sc-&gt;ptr;
1408  	while (len &gt; 0) {
1409  		size_t clen;
1410  		clen = (sizeof sc-&gt;buf) - ptr;
1411  		if (clen &gt; len)
1412  			clen = len;
1413  		memcpy(buf + ptr, data, clen);
1414  		data = (const unsigned char *)data + clen;
1415  		ptr += clen;
1416  		len -= clen;
1417  		if (ptr == sizeof sc-&gt;buf) {
1418  			if ((sc-&gt;count0 = SPH_T32(sc-&gt;count0 + 1024)) == 0) {
1419  				sc-&gt;count1 = SPH_T32(sc-&gt;count1 + 1);
1420  				if (sc-&gt;count1 == 0) {
1421  					sc-&gt;count2 = SPH_T32(sc-&gt;count2 + 1);
1422  					if (sc-&gt;count2 == 0) {
1423  						sc-&gt;count3 = SPH_T32(
1424  							sc-&gt;count3 + 1);
1425  					}
1426  				}
1427  			}
1428  			c512(sc, buf);
<span onclick='openModal()' class='match'>1429  			ptr = 0;
1430  		}
1431  	}
1432  	sc-&gt;ptr = ptr;
1433  }
1434  static void
1435  shavite_big_close(sph_shavite_big_context *sc,
1436  	unsigned ub, unsigned n, void *dst, size_t out_size_w32)
</span>1437  {
1438  	unsigned char *buf;
1439  	size_t ptr, u;
1440  	unsigned z;
1441  	sph_u32 count0, count1, count2, count3;
1442  	buf = sc-&gt;buf;
1443  	ptr = sc-&gt;ptr;
1444  	count0 = (sc-&gt;count0 += (ptr &lt;&lt; 3) + n);
1445  	count1 = sc-&gt;count1;
1446  	count2 = sc-&gt;count2;
1447  	count3 = sc-&gt;count3;
1448  	z = 0x80 &gt;&gt; n;
1449  	z = ((ub &amp; -z) | z) &amp; 0xFF;
1450  	if (ptr == 0 &amp;&amp; n == 0) {
1451  		buf[0] = 0x80;
1452  		memset(buf + 1, 0, 109);
1453  		sc-&gt;count0 = sc-&gt;count1 = sc-&gt;count2 = sc-&gt;count3 = 0;
1454  	} else if (ptr &lt; 110) {
1455  		buf[ptr ++] = z;
1456  		memset(buf + ptr, 0, 110 - ptr);
1457  	} else {
1458  		buf[ptr ++] = z;
1459  		memset(buf + ptr, 0, 128 - ptr);
1460  		c512(sc, buf);
1461  		memset(buf, 0, 110);
1462  		sc-&gt;count0 = sc-&gt;count1 = sc-&gt;count2 = sc-&gt;count3 = 0;
1463  	}
1464  	sph_enc32le(buf + 110, count0);
1465  	sph_enc32le(buf + 114, count1);
1466  	sph_enc32le(buf + 118, count2);
1467  	sph_enc32le(buf + 122, count3);
1468  	buf[126] = out_size_w32 &lt;&lt; 5;
1469  	buf[127] = out_size_w32 &gt;&gt; 3;
1470  	c512(sc, buf);
1471  	for (u = 0; u &lt; out_size_w32; u ++)
1472  		sph_enc32le((unsigned char *)dst + (u &lt;&lt; 2), sc-&gt;h[u]);
1473  }
1474  void
1475  sph_shavite224_init(void *cc)
1476  {
1477  	shavite_small_init(cc, IV224);
1478  }
1479  void
1480  sph_shavite224(void *cc, const void *data, size_t len)
1481  {
1482  	shavite_small_core(cc, data, len);
1483  }
1484  void
1485  sph_shavite224_close(void *cc, void *dst)
1486  {
1487  	shavite_small_close(cc, 0, 0, dst, 7);
1488  	shavite_small_init(cc, IV224);
1489  }
1490  void
1491  sph_shavite224_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
1492  {
1493  	shavite_small_close(cc, ub, n, dst, 7);
1494  	shavite_small_init(cc, IV224);
1495  }
1496  void
1497  sph_shavite256_init(void *cc)
1498  {
1499  	shavite_small_init(cc, IV256);
1500  }
1501  void
1502  sph_shavite256(void *cc, const void *data, size_t len)
1503  {
1504  	shavite_small_core(cc, data, len);
1505  }
1506  void
1507  sph_shavite256_close(void *cc, void *dst)
1508  {
1509  	shavite_small_close(cc, 0, 0, dst, 8);
1510  	shavite_small_init(cc, IV256);
1511  }
1512  void
1513  sph_shavite256_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
1514  {
1515  	shavite_small_close(cc, ub, n, dst, 8);
1516  	shavite_small_init(cc, IV256);
1517  }
1518  void
1519  sph_shavite384_init(void *cc)
1520  {
1521  	shavite_big_init(cc, IV384);
1522  }
1523  void
1524  sph_shavite384(void *cc, const void *data, size_t len)
1525  {
1526  	shavite_big_core(cc, data, len);
1527  }
1528  void
1529  sph_shavite384_close(void *cc, void *dst)
1530  {
1531  	shavite_big_close(cc, 0, 0, dst, 12);
1532  	shavite_big_init(cc, IV384);
1533  }
1534  void
1535  sph_shavite384_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
1536  {
1537  	shavite_big_close(cc, ub, n, dst, 12);
1538  	shavite_big_init(cc, IV384);
1539  }
1540  void
1541  sph_shavite512_init(void *cc)
1542  {
1543  	shavite_big_init(cc, IV512);
1544  }
1545  void
1546  sph_shavite512(void *cc, const void *data, size_t len)
1547  {
1548  	shavite_big_core(cc, data, len);
1549  }
1550  void
1551  sph_shavite512_close(void *cc, void *dst)
1552  {
1553  	shavite_big_close(cc, 0, 0, dst, 16);
1554  	shavite_big_init(cc, IV512);
1555  }
1556  void
1557  sph_shavite512_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
1558  {
1559  	shavite_big_close(cc, ub, n, dst, 16);
1560  	shavite_big_init(cc, IV512);
1561  }
1562  #ifdef __cplusplus
1563  }
1564  #endif
</code></pre>
        </div>
        <div class="column">
            <h3>xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-sph_echo.c</h3>
            <pre><code>1  #include &lt;stddef.h&gt;
2  #include &lt;string.h&gt;
3  #include &lt;limits.h&gt;
4  #include &quot;sph_echo.h&quot;
5  #ifdef __cplusplus
6  extern &quot;C&quot;{
7  #endif
8  #if SPH_SMALL_FOOTPRINT &amp;&amp; !defined SPH_SMALL_FOOTPRINT_ECHO
9  #define SPH_SMALL_FOOTPRINT_ECHO   1
10  #endif
11  #if !defined SPH_ECHO_64 &amp;&amp; SPH_64_TRUE
12  #define SPH_ECHO_64   1
13  #endif
14  #if !SPH_64
15  #undef SPH_ECHO_64
16  #endif
17  #ifdef _MSC_VER
18  #pragma warning (disable: 4146)
19  #endif
20  #define T32   SPH_T32
21  #define C32   SPH_C32
22  #if SPH_64
23  #define C64   SPH_C64
24  #endif
25  #define AES_BIG_ENDIAN   0
26  #include &quot;aes_helper.c&quot;
27  #if SPH_ECHO_64
28  #define DECL_STATE_SMALL   \
29  	sph_u64 W[16][2];
30  #define DECL_STATE_BIG   \
31  	sph_u64 W[16][2];
32  #define INPUT_BLOCK_SMALL(sc)   do { \
33  		unsigned u; \
34  		memcpy(W, sc-&gt;u.Vb, 8 * sizeof(sph_u64)); \
35  		for (u = 0; u &lt; 12; u ++) { \
36  			W[u + 4][0] = sph_dec64le_aligned( \
37  				sc-&gt;buf + 16 * u); \
38  			W[u + 4][1] = sph_dec64le_aligned( \
39  				sc-&gt;buf + 16 * u + 8); \
40  		} \
41  	} while (0)
42  #define INPUT_BLOCK_BIG(sc)   do { \
43  		unsigned u; \
44  		memcpy(W, sc-&gt;u.Vb, 16 * sizeof(sph_u64)); \
45  		for (u = 0; u &lt; 8; u ++) { \
46  			W[u + 8][0] = sph_dec64le_aligned( \
47  				sc-&gt;buf + 16 * u); \
48  			W[u + 8][1] = sph_dec64le_aligned( \
49  				sc-&gt;buf + 16 * u + 8); \
50  		} \
51  	} while (0)
52  #if SPH_SMALL_FOOTPRINT_ECHO
53  static void
54  aes_2rounds_all(sph_u64 W[16][2],
55  	sph_u32 *pK0, sph_u32 *pK1, sph_u32 *pK2, sph_u32 *pK3)
56  {
57  	int n;
58  	sph_u32 K0 = *pK0;
59  	sph_u32 K1 = *pK1;
60  	sph_u32 K2 = *pK2;
61  	sph_u32 K3 = *pK3;
62  	for (n = 0; n &lt; 16; n ++) {
63  		sph_u64 Wl = W[n][0];
64  		sph_u64 Wh = W[n][1];
65  		sph_u32 X0 = (sph_u32)Wl;
66  		sph_u32 X1 = (sph_u32)(Wl &gt;&gt; 32);
67  		sph_u32 X2 = (sph_u32)Wh;
68  		sph_u32 X3 = (sph_u32)(Wh &gt;&gt; 32);
69  		sph_u32 Y0, Y1, Y2, Y3; \
70  		AES_ROUND_LE(X0, X1, X2, X3, K0, K1, K2, K3, Y0, Y1, Y2, Y3);
71  		AES_ROUND_NOKEY_LE(Y0, Y1, Y2, Y3, X0, X1, X2, X3);
72  		W[n][0] = (sph_u64)X0 | ((sph_u64)X1 &lt;&lt; 32);
73  		W[n][1] = (sph_u64)X2 | ((sph_u64)X3 &lt;&lt; 32);
74  		if ((K0 = T32(K0 + 1)) == 0) {
75  			if ((K1 = T32(K1 + 1)) == 0)
76  				if ((K2 = T32(K2 + 1)) == 0)
77  					K3 = T32(K3 + 1);
78  		}
79  	}
80  	*pK0 = K0;
81  	*pK1 = K1;
82  	*pK2 = K2;
83  	*pK3 = K3;
84  }
85  #define BIG_SUB_WORDS   do { \
86  		aes_2rounds_all(W, &amp;K0, &amp;K1, &amp;K2, &amp;K3); \
87  	} while (0)
88  #else
89  #define AES_2ROUNDS(X)   do { \
90  		sph_u32 X0 = (sph_u32)(X[0]); \
91  		sph_u32 X1 = (sph_u32)(X[0] &gt;&gt; 32); \
92  		sph_u32 X2 = (sph_u32)(X[1]); \
93  		sph_u32 X3 = (sph_u32)(X[1] &gt;&gt; 32); \
94  		sph_u32 Y0, Y1, Y2, Y3; \
95  		AES_ROUND_LE(X0, X1, X2, X3, K0, K1, K2, K3, Y0, Y1, Y2, Y3); \
96  		AES_ROUND_NOKEY_LE(Y0, Y1, Y2, Y3, X0, X1, X2, X3); \
97  		X[0] = (sph_u64)X0 | ((sph_u64)X1 &lt;&lt; 32); \
98  		X[1] = (sph_u64)X2 | ((sph_u64)X3 &lt;&lt; 32); \
99  		if ((K0 = T32(K0 + 1)) == 0) { \
100  			if ((K1 = T32(K1 + 1)) == 0) \
101  				if ((K2 = T32(K2 + 1)) == 0) \
102  					K3 = T32(K3 + 1); \
103  		} \
104  	} while (0)
105  #define BIG_SUB_WORDS   do { \
106  		AES_2ROUNDS(W[ 0]); \
107  		AES_2ROUNDS(W[ 1]); \
108  		AES_2ROUNDS(W[ 2]); \
109  		AES_2ROUNDS(W[ 3]); \
110  		AES_2ROUNDS(W[ 4]); \
111  		AES_2ROUNDS(W[ 5]); \
112  		AES_2ROUNDS(W[ 6]); \
113  		AES_2ROUNDS(W[ 7]); \
114  		AES_2ROUNDS(W[ 8]); \
115  		AES_2ROUNDS(W[ 9]); \
116  		AES_2ROUNDS(W[10]); \
117  		AES_2ROUNDS(W[11]); \
118  		AES_2ROUNDS(W[12]); \
119  		AES_2ROUNDS(W[13]); \
120  		AES_2ROUNDS(W[14]); \
121  		AES_2ROUNDS(W[15]); \
122  	} while (0)
123  #endif
124  #define SHIFT_ROW1(a, b, c, d)   do { \
125  		sph_u64 tmp; \
126  		tmp = W[a][0]; \
127  		W[a][0] = W[b][0]; \
128  		W[b][0] = W[c][0]; \
129  		W[c][0] = W[d][0]; \
130  		W[d][0] = tmp; \
131  		tmp = W[a][1]; \
132  		W[a][1] = W[b][1]; \
133  		W[b][1] = W[c][1]; \
134  		W[c][1] = W[d][1]; \
135  		W[d][1] = tmp; \
136  	} while (0)
137  #define SHIFT_ROW2(a, b, c, d)   do { \
138  		sph_u64 tmp; \
139  		tmp = W[a][0]; \
140  		W[a][0] = W[c][0]; \
141  		W[c][0] = tmp; \
142  		tmp = W[b][0]; \
143  		W[b][0] = W[d][0]; \
144  		W[d][0] = tmp; \
145  		tmp = W[a][1]; \
146  		W[a][1] = W[c][1]; \
147  		W[c][1] = tmp; \
148  		tmp = W[b][1]; \
149  		W[b][1] = W[d][1]; \
150  		W[d][1] = tmp; \
151  	} while (0)
152  #define SHIFT_ROW3(a, b, c, d)   SHIFT_ROW1(d, c, b, a)
153  #define BIG_SHIFT_ROWS   do { \
154  		SHIFT_ROW1(1, 5, 9, 13); \
155  		SHIFT_ROW2(2, 6, 10, 14); \
156  		SHIFT_ROW3(3, 7, 11, 15); \
157  	} while (0)
158  #if SPH_SMALL_FOOTPRINT_ECHO
159  static void
160  mix_column(sph_u64 W[16][2], int ia, int ib, int ic, int id)
161  {
162  	int n;
163  	for (n = 0; n &lt; 2; n ++) {
164  		sph_u64 a = W[ia][n];
165  		sph_u64 b = W[ib][n];
166  		sph_u64 c = W[ic][n];
167  		sph_u64 d = W[id][n];
168  		sph_u64 ab = a ^ b;
169  		sph_u64 bc = b ^ c;
170  		sph_u64 cd = c ^ d;
171  		sph_u64 abx = ((ab &amp; C64(0x8080808080808080)) &gt;&gt; 7) * 27U
172  			^ ((ab &amp; C64(0x7F7F7F7F7F7F7F7F)) &lt;&lt; 1);
173  		sph_u64 bcx = ((bc &amp; C64(0x8080808080808080)) &gt;&gt; 7) * 27U
174  			^ ((bc &amp; C64(0x7F7F7F7F7F7F7F7F)) &lt;&lt; 1);
175  		sph_u64 cdx = ((cd &amp; C64(0x8080808080808080)) &gt;&gt; 7) * 27U
176  			^ ((cd &amp; C64(0x7F7F7F7F7F7F7F7F)) &lt;&lt; 1);
177  		W[ia][n] = abx ^ bc ^ d;
178  		W[ib][n] = bcx ^ a ^ cd;
179  		W[ic][n] = cdx ^ ab ^ d;
180  		W[id][n] = abx ^ bcx ^ cdx ^ ab ^ c;
181  	}
182  }
183  #define MIX_COLUMN(a, b, c, d)   mix_column(W, a, b, c, d)
184  #else
185  #define MIX_COLUMN1(ia, ib, ic, id, n)   do { \
186  		sph_u64 a = W[ia][n]; \
187  		sph_u64 b = W[ib][n]; \
188  		sph_u64 c = W[ic][n]; \
189  		sph_u64 d = W[id][n]; \
190  		sph_u64 ab = a ^ b; \
191  		sph_u64 bc = b ^ c; \
192  		sph_u64 cd = c ^ d; \
193  		sph_u64 abx = ((ab &amp; C64(0x8080808080808080)) &gt;&gt; 7) * 27U \
194  			^ ((ab &amp; C64(0x7F7F7F7F7F7F7F7F)) &lt;&lt; 1); \
195  		sph_u64 bcx = ((bc &amp; C64(0x8080808080808080)) &gt;&gt; 7) * 27U \
196  			^ ((bc &amp; C64(0x7F7F7F7F7F7F7F7F)) &lt;&lt; 1); \
197  		sph_u64 cdx = ((cd &amp; C64(0x8080808080808080)) &gt;&gt; 7) * 27U \
198  			^ ((cd &amp; C64(0x7F7F7F7F7F7F7F7F)) &lt;&lt; 1); \
199  		W[ia][n] = abx ^ bc ^ d; \
200  		W[ib][n] = bcx ^ a ^ cd; \
201  		W[ic][n] = cdx ^ ab ^ d; \
202  		W[id][n] = abx ^ bcx ^ cdx ^ ab ^ c; \
203  	} while (0)
204  #define MIX_COLUMN(a, b, c, d)   do { \
205  		MIX_COLUMN1(a, b, c, d, 0); \
206  		MIX_COLUMN1(a, b, c, d, 1); \
207  	} while (0)
208  #endif
209  #define BIG_MIX_COLUMNS   do { \
210  		MIX_COLUMN(0, 1, 2, 3); \
211  		MIX_COLUMN(4, 5, 6, 7); \
212  		MIX_COLUMN(8, 9, 10, 11); \
213  		MIX_COLUMN(12, 13, 14, 15); \
214  	} while (0)
215  #define BIG_ROUND   do { \
216  		BIG_SUB_WORDS; \
217  		BIG_SHIFT_ROWS; \
218  		BIG_MIX_COLUMNS; \
219  	} while (0)
220  #define FINAL_SMALL   do { \
221  		unsigned u; \
222  		sph_u64 *VV = &amp;sc-&gt;u.Vb[0][0]; \
223  		sph_u64 *WW = &amp;W[0][0]; \
224  		for (u = 0; u &lt; 8; u ++) { \
225  			VV[u] ^= sph_dec64le_aligned(sc-&gt;buf + (u * 8)) \
226  				^ sph_dec64le_aligned(sc-&gt;buf + (u * 8) + 64) \
227  				^ sph_dec64le_aligned(sc-&gt;buf + (u * 8) + 128) \
228  				^ WW[u] ^ WW[u + 8] \
229  				^ WW[u + 16] ^ WW[u + 24]; \
230  		} \
231  	} while (0)
232  #define FINAL_BIG   do { \
233  		unsigned u; \
234  		sph_u64 *VV = &amp;sc-&gt;u.Vb[0][0]; \
235  		sph_u64 *WW = &amp;W[0][0]; \
236  		for (u = 0; u &lt; 16; u ++) { \
237  			VV[u] ^= sph_dec64le_aligned(sc-&gt;buf + (u * 8)) \
238  				^ WW[u] ^ WW[u + 16]; \
239  		} \
240  	} while (0)
241  #define COMPRESS_SMALL(sc)   do { \
242  		sph_u32 K0 = sc-&gt;C0; \
243  		sph_u32 K1 = sc-&gt;C1; \
244  		sph_u32 K2 = sc-&gt;C2; \
245  		sph_u32 K3 = sc-&gt;C3; \
246  		unsigned u; \
247  		INPUT_BLOCK_SMALL(sc); \
248  		for (u = 0; u &lt; 8; u ++) { \
249  			BIG_ROUND; \
250  		} \
251  		FINAL_SMALL; \
252  	} while (0)
253  #define COMPRESS_BIG(sc)   do { \
254  		sph_u32 K0 = sc-&gt;C0; \
255  		sph_u32 K1 = sc-&gt;C1; \
256  		sph_u32 K2 = sc-&gt;C2; \
257  		sph_u32 K3 = sc-&gt;C3; \
258  		unsigned u; \
259  		INPUT_BLOCK_BIG(sc); \
260  		for (u = 0; u &lt; 10; u ++) { \
261  			BIG_ROUND; \
262  		} \
263  		FINAL_BIG; \
264  	} while (0)
265  #else
266  #define DECL_STATE_SMALL   \
267  	sph_u32 W[16][4];
268  #define DECL_STATE_BIG   \
269  	sph_u32 W[16][4];
270  #define INPUT_BLOCK_SMALL(sc)   do { \
271  		unsigned u; \
272  		memcpy(W, sc-&gt;u.Vs, 16 * sizeof(sph_u32)); \
273  		for (u = 0; u &lt; 12; u ++) { \
274  			W[u + 4][0] = sph_dec32le_aligned( \
275  				sc-&gt;buf + 16 * u); \
276  			W[u + 4][1] = sph_dec32le_aligned( \
277  				sc-&gt;buf + 16 * u + 4); \
278  			W[u + 4][2] = sph_dec32le_aligned( \
279  				sc-&gt;buf + 16 * u + 8); \
280  			W[u + 4][3] = sph_dec32le_aligned( \
281  				sc-&gt;buf + 16 * u + 12); \
282  		} \
283  	} while (0)
284  #define INPUT_BLOCK_BIG(sc)   do { \
285  		unsigned u; \
286  		memcpy(W, sc-&gt;u.Vs, 32 * sizeof(sph_u32)); \
287  		for (u = 0; u &lt; 8; u ++) { \
288  			W[u + 8][0] = sph_dec32le_aligned( \
289  				sc-&gt;buf + 16 * u); \
290  			W[u + 8][1] = sph_dec32le_aligned( \
291  				sc-&gt;buf + 16 * u + 4); \
292  			W[u + 8][2] = sph_dec32le_aligned( \
293  				sc-&gt;buf + 16 * u + 8); \
294  			W[u + 8][3] = sph_dec32le_aligned( \
295  				sc-&gt;buf + 16 * u + 12); \
296  		} \
297  	} while (0)
298  #if SPH_SMALL_FOOTPRINT_ECHO
299  static void
300  aes_2rounds_all(sph_u32 W[16][4],
301  	sph_u32 *pK0, sph_u32 *pK1, sph_u32 *pK2, sph_u32 *pK3)
302  {
303  	int n;
304  	sph_u32 K0 = *pK0;
305  	sph_u32 K1 = *pK1;
306  	sph_u32 K2 = *pK2;
307  	sph_u32 K3 = *pK3;
308  	for (n = 0; n &lt; 16; n ++) {
309  		sph_u32 *X = W[n];
310  		sph_u32 Y0, Y1, Y2, Y3;
311  		AES_ROUND_LE(X[0], X[1], X[2], X[3],
312  			K0, K1, K2, K3, Y0, Y1, Y2, Y3);
313  		AES_ROUND_NOKEY_LE(Y0, Y1, Y2, Y3, X[0], X[1], X[2], X[3]);
314  		if ((K0 = T32(K0 + 1)) == 0) {
315  			if ((K1 = T32(K1 + 1)) == 0)
316  				if ((K2 = T32(K2 + 1)) == 0)
317  					K3 = T32(K3 + 1);
318  		}
319  	}
320  	*pK0 = K0;
321  	*pK1 = K1;
322  	*pK2 = K2;
323  	*pK3 = K3;
324  }
325  #define BIG_SUB_WORDS   do { \
326  		aes_2rounds_all(W, &amp;K0, &amp;K1, &amp;K2, &amp;K3); \
327  	} while (0)
328  #else
329  #define AES_2ROUNDS(X)   do { \
330  		sph_u32 Y0, Y1, Y2, Y3; \
331  		AES_ROUND_LE(X[0], X[1], X[2], X[3], \
332  			K0, K1, K2, K3, Y0, Y1, Y2, Y3); \
333  		AES_ROUND_NOKEY_LE(Y0, Y1, Y2, Y3, X[0], X[1], X[2], X[3]); \
334  		if ((K0 = T32(K0 + 1)) == 0) { \
335  			if ((K1 = T32(K1 + 1)) == 0) \
336  				if ((K2 = T32(K2 + 1)) == 0) \
337  					K3 = T32(K3 + 1); \
338  		} \
339  	} while (0)
340  #define BIG_SUB_WORDS   do { \
341  		AES_2ROUNDS(W[ 0]); \
342  		AES_2ROUNDS(W[ 1]); \
343  		AES_2ROUNDS(W[ 2]); \
344  		AES_2ROUNDS(W[ 3]); \
345  		AES_2ROUNDS(W[ 4]); \
346  		AES_2ROUNDS(W[ 5]); \
347  		AES_2ROUNDS(W[ 6]); \
348  		AES_2ROUNDS(W[ 7]); \
349  		AES_2ROUNDS(W[ 8]); \
350  		AES_2ROUNDS(W[ 9]); \
351  		AES_2ROUNDS(W[10]); \
352  		AES_2ROUNDS(W[11]); \
353  		AES_2ROUNDS(W[12]); \
354  		AES_2ROUNDS(W[13]); \
355  		AES_2ROUNDS(W[14]); \
356  		AES_2ROUNDS(W[15]); \
357  	} while (0)
358  #endif
359  #define SHIFT_ROW1(a, b, c, d)   do { \
360  		sph_u32 tmp; \
361  		tmp = W[a][0]; \
362  		W[a][0] = W[b][0]; \
363  		W[b][0] = W[c][0]; \
364  		W[c][0] = W[d][0]; \
365  		W[d][0] = tmp; \
366  		tmp = W[a][1]; \
367  		W[a][1] = W[b][1]; \
368  		W[b][1] = W[c][1]; \
369  		W[c][1] = W[d][1]; \
370  		W[d][1] = tmp; \
371  		tmp = W[a][2]; \
372  		W[a][2] = W[b][2]; \
373  		W[b][2] = W[c][2]; \
374  		W[c][2] = W[d][2]; \
375  		W[d][2] = tmp; \
376  		tmp = W[a][3]; \
377  		W[a][3] = W[b][3]; \
378  		W[b][3] = W[c][3]; \
379  		W[c][3] = W[d][3]; \
380  		W[d][3] = tmp; \
381  	} while (0)
382  #define SHIFT_ROW2(a, b, c, d)   do { \
383  		sph_u32 tmp; \
384  		tmp = W[a][0]; \
385  		W[a][0] = W[c][0]; \
386  		W[c][0] = tmp; \
387  		tmp = W[b][0]; \
388  		W[b][0] = W[d][0]; \
389  		W[d][0] = tmp; \
390  		tmp = W[a][1]; \
391  		W[a][1] = W[c][1]; \
392  		W[c][1] = tmp; \
393  		tmp = W[b][1]; \
394  		W[b][1] = W[d][1]; \
395  		W[d][1] = tmp; \
396  		tmp = W[a][2]; \
397  		W[a][2] = W[c][2]; \
398  		W[c][2] = tmp; \
399  		tmp = W[b][2]; \
400  		W[b][2] = W[d][2]; \
401  		W[d][2] = tmp; \
402  		tmp = W[a][3]; \
403  		W[a][3] = W[c][3]; \
404  		W[c][3] = tmp; \
405  		tmp = W[b][3]; \
406  		W[b][3] = W[d][3]; \
407  		W[d][3] = tmp; \
408  	} while (0)
409  #define SHIFT_ROW3(a, b, c, d)   SHIFT_ROW1(d, c, b, a)
410  #define BIG_SHIFT_ROWS   do { \
411  		SHIFT_ROW1(1, 5, 9, 13); \
412  		SHIFT_ROW2(2, 6, 10, 14); \
413  		SHIFT_ROW3(3, 7, 11, 15); \
414  	} while (0)
415  #if SPH_SMALL_FOOTPRINT_ECHO
416  static void
417  mix_column(sph_u32 W[16][4], int ia, int ib, int ic, int id)
418  {
419  	int n;
420  	for (n = 0; n &lt; 4; n ++) {
421  		sph_u32 a = W[ia][n];
422  		sph_u32 b = W[ib][n];
423  		sph_u32 c = W[ic][n];
424  		sph_u32 d = W[id][n];
425  		sph_u32 ab = a ^ b;
426  		sph_u32 bc = b ^ c;
427  		sph_u32 cd = c ^ d;
428  		sph_u32 abx = ((ab &amp; C32(0x80808080)) &gt;&gt; 7) * 27U
429  			^ ((ab &amp; C32(0x7F7F7F7F)) &lt;&lt; 1);
430  		sph_u32 bcx = ((bc &amp; C32(0x80808080)) &gt;&gt; 7) * 27U
431  			^ ((bc &amp; C32(0x7F7F7F7F)) &lt;&lt; 1);
432  		sph_u32 cdx = ((cd &amp; C32(0x80808080)) &gt;&gt; 7) * 27U
433  			^ ((cd &amp; C32(0x7F7F7F7F)) &lt;&lt; 1);
434  		W[ia][n] = abx ^ bc ^ d;
435  		W[ib][n] = bcx ^ a ^ cd;
436  		W[ic][n] = cdx ^ ab ^ d;
437  		W[id][n] = abx ^ bcx ^ cdx ^ ab ^ c;
438  	}
439  }
440  #define MIX_COLUMN(a, b, c, d)   mix_column(W, a, b, c, d)
441  #else
442  #define MIX_COLUMN1(ia, ib, ic, id, n)   do { \
443  		sph_u32 a = W[ia][n]; \
444  		sph_u32 b = W[ib][n]; \
445  		sph_u32 c = W[ic][n]; \
446  		sph_u32 d = W[id][n]; \
447  		sph_u32 ab = a ^ b; \
448  		sph_u32 bc = b ^ c; \
449  		sph_u32 cd = c ^ d; \
450  		sph_u32 abx = ((ab &amp; C32(0x80808080)) &gt;&gt; 7) * 27U \
451  			^ ((ab &amp; C32(0x7F7F7F7F)) &lt;&lt; 1); \
452  		sph_u32 bcx = ((bc &amp; C32(0x80808080)) &gt;&gt; 7) * 27U \
453  			^ ((bc &amp; C32(0x7F7F7F7F)) &lt;&lt; 1); \
454  		sph_u32 cdx = ((cd &amp; C32(0x80808080)) &gt;&gt; 7) * 27U \
455  			^ ((cd &amp; C32(0x7F7F7F7F)) &lt;&lt; 1); \
456  		W[ia][n] = abx ^ bc ^ d; \
457  		W[ib][n] = bcx ^ a ^ cd; \
458  		W[ic][n] = cdx ^ ab ^ d; \
459  		W[id][n] = abx ^ bcx ^ cdx ^ ab ^ c; \
460  	} while (0)
461  #define MIX_COLUMN(a, b, c, d)   do { \
462  		MIX_COLUMN1(a, b, c, d, 0); \
463  		MIX_COLUMN1(a, b, c, d, 1); \
464  		MIX_COLUMN1(a, b, c, d, 2); \
465  		MIX_COLUMN1(a, b, c, d, 3); \
466  	} while (0)
467  #endif
468  #define BIG_MIX_COLUMNS   do { \
469  		MIX_COLUMN(0, 1, 2, 3); \
470  		MIX_COLUMN(4, 5, 6, 7); \
471  		MIX_COLUMN(8, 9, 10, 11); \
472  		MIX_COLUMN(12, 13, 14, 15); \
473  	} while (0)
474  #define BIG_ROUND   do { \
475  		BIG_SUB_WORDS; \
476  		BIG_SHIFT_ROWS; \
477  		BIG_MIX_COLUMNS; \
478  	} while (0)
479  #define FINAL_SMALL   do { \
480  		unsigned u; \
481  		sph_u32 *VV = &amp;sc-&gt;u.Vs[0][0]; \
482  		sph_u32 *WW = &amp;W[0][0]; \
483  		for (u = 0; u &lt; 16; u ++) { \
484  			VV[u] ^= sph_dec32le_aligned(sc-&gt;buf + (u * 4)) \
485  				^ sph_dec32le_aligned(sc-&gt;buf + (u * 4) + 64) \
486  				^ sph_dec32le_aligned(sc-&gt;buf + (u * 4) + 128) \
487  				^ WW[u] ^ WW[u + 16] \
488  				^ WW[u + 32] ^ WW[u + 48]; \
489  		} \
490  	} while (0)
491  #define FINAL_BIG   do { \
492  		unsigned u; \
493  		sph_u32 *VV = &amp;sc-&gt;u.Vs[0][0]; \
494  		sph_u32 *WW = &amp;W[0][0]; \
495  		for (u = 0; u &lt; 32; u ++) { \
496  			VV[u] ^= sph_dec32le_aligned(sc-&gt;buf + (u * 4)) \
497  				^ WW[u] ^ WW[u + 32]; \
498  		} \
499  	} while (0)
500  #define COMPRESS_SMALL(sc)   do { \
501  		sph_u32 K0 = sc-&gt;C0; \
502  		sph_u32 K1 = sc-&gt;C1; \
503  		sph_u32 K2 = sc-&gt;C2; \
504  		sph_u32 K3 = sc-&gt;C3; \
505  		unsigned u; \
506  		INPUT_BLOCK_SMALL(sc); \
507  		for (u = 0; u &lt; 8; u ++) { \
508  			BIG_ROUND; \
509  		} \
510  		FINAL_SMALL; \
511  	} while (0)
512  #define COMPRESS_BIG(sc)   do { \
513  		sph_u32 K0 = sc-&gt;C0; \
514  		sph_u32 K1 = sc-&gt;C1; \
515  		sph_u32 K2 = sc-&gt;C2; \
516  		sph_u32 K3 = sc-&gt;C3; \
517  		unsigned u; \
518  		INPUT_BLOCK_BIG(sc); \
519  		for (u = 0; u &lt; 10; u ++) { \
520  			BIG_ROUND; \
521  		} \
522  		FINAL_BIG; \
523  	} while (0)
524  #endif
525  #define INCR_COUNTER(sc, val)   do { \
526  		sc-&gt;C0 = T32(sc-&gt;C0 + (sph_u32)(val)); \
527  		if (sc-&gt;C0 &lt; (sph_u32)(val)) { \
528  			if ((sc-&gt;C1 = T32(sc-&gt;C1 + 1)) == 0) \
529  				if ((sc-&gt;C2 = T32(sc-&gt;C2 + 1)) == 0) \
530  					sc-&gt;C3 = T32(sc-&gt;C3 + 1); \
531  		} \
532  	} while (0)
533  static void
534  echo_small_init(sph_echo_small_context *sc, unsigned out_len)
535  {
536  #if SPH_ECHO_64
537  	sc-&gt;u.Vb[0][0] = (sph_u64)out_len;
538  	sc-&gt;u.Vb[0][1] = 0;
539  	sc-&gt;u.Vb[1][0] = (sph_u64)out_len;
540  	sc-&gt;u.Vb[1][1] = 0;
541  	sc-&gt;u.Vb[2][0] = (sph_u64)out_len;
542  	sc-&gt;u.Vb[2][1] = 0;
543  	sc-&gt;u.Vb[3][0] = (sph_u64)out_len;
544  	sc-&gt;u.Vb[3][1] = 0;
545  #else
546  	sc-&gt;u.Vs[0][0] = (sph_u32)out_len;
547  	sc-&gt;u.Vs[0][1] = sc-&gt;u.Vs[0][2] = sc-&gt;u.Vs[0][3] = 0;
548  	sc-&gt;u.Vs[1][0] = (sph_u32)out_len;
549  	sc-&gt;u.Vs[1][1] = sc-&gt;u.Vs[1][2] = sc-&gt;u.Vs[1][3] = 0;
550  	sc-&gt;u.Vs[2][0] = (sph_u32)out_len;
551  	sc-&gt;u.Vs[2][1] = sc-&gt;u.Vs[2][2] = sc-&gt;u.Vs[2][3] = 0;
552  	sc-&gt;u.Vs[3][0] = (sph_u32)out_len;
553  	sc-&gt;u.Vs[3][1] = sc-&gt;u.Vs[3][2] = sc-&gt;u.Vs[3][3] = 0;
554  #endif
555  	sc-&gt;ptr = 0;
556  	sc-&gt;C0 = sc-&gt;C1 = sc-&gt;C2 = sc-&gt;C3 = 0;
557  }
558  static void
559  echo_big_init(sph_echo_big_context *sc, unsigned out_len)
560  {
561  #if SPH_ECHO_64
562  	sc-&gt;u.Vb[0][0] = (sph_u64)out_len;
563  	sc-&gt;u.Vb[0][1] = 0;
564  	sc-&gt;u.Vb[1][0] = (sph_u64)out_len;
565  	sc-&gt;u.Vb[1][1] = 0;
566  	sc-&gt;u.Vb[2][0] = (sph_u64)out_len;
567  	sc-&gt;u.Vb[2][1] = 0;
568  	sc-&gt;u.Vb[3][0] = (sph_u64)out_len;
569  	sc-&gt;u.Vb[3][1] = 0;
570  	sc-&gt;u.Vb[4][0] = (sph_u64)out_len;
571  	sc-&gt;u.Vb[4][1] = 0;
572  	sc-&gt;u.Vb[5][0] = (sph_u64)out_len;
573  	sc-&gt;u.Vb[5][1] = 0;
574  	sc-&gt;u.Vb[6][0] = (sph_u64)out_len;
575  	sc-&gt;u.Vb[6][1] = 0;
576  	sc-&gt;u.Vb[7][0] = (sph_u64)out_len;
577  	sc-&gt;u.Vb[7][1] = 0;
578  #else
579  	sc-&gt;u.Vs[0][0] = (sph_u32)out_len;
580  	sc-&gt;u.Vs[0][1] = sc-&gt;u.Vs[0][2] = sc-&gt;u.Vs[0][3] = 0;
581  	sc-&gt;u.Vs[1][0] = (sph_u32)out_len;
582  	sc-&gt;u.Vs[1][1] = sc-&gt;u.Vs[1][2] = sc-&gt;u.Vs[1][3] = 0;
583  	sc-&gt;u.Vs[2][0] = (sph_u32)out_len;
584  	sc-&gt;u.Vs[2][1] = sc-&gt;u.Vs[2][2] = sc-&gt;u.Vs[2][3] = 0;
585  	sc-&gt;u.Vs[3][0] = (sph_u32)out_len;
586  	sc-&gt;u.Vs[3][1] = sc-&gt;u.Vs[3][2] = sc-&gt;u.Vs[3][3] = 0;
587  	sc-&gt;u.Vs[4][0] = (sph_u32)out_len;
588  	sc-&gt;u.Vs[4][1] = sc-&gt;u.Vs[4][2] = sc-&gt;u.Vs[4][3] = 0;
589  	sc-&gt;u.Vs[5][0] = (sph_u32)out_len;
590  	sc-&gt;u.Vs[5][1] = sc-&gt;u.Vs[5][2] = sc-&gt;u.Vs[5][3] = 0;
591  	sc-&gt;u.Vs[6][0] = (sph_u32)out_len;
592  	sc-&gt;u.Vs[6][1] = sc-&gt;u.Vs[6][2] = sc-&gt;u.Vs[6][3] = 0;
593  	sc-&gt;u.Vs[7][0] = (sph_u32)out_len;
594  	sc-&gt;u.Vs[7][1] = sc-&gt;u.Vs[7][2] = sc-&gt;u.Vs[7][3] = 0;
595  #endif
596  	sc-&gt;ptr = 0;
597  	sc-&gt;C0 = sc-&gt;C1 = sc-&gt;C2 = sc-&gt;C3 = 0;
598  }
599  static void
600  echo_small_compress(sph_echo_small_context *sc)
601  {
602  	DECL_STATE_SMALL
603  	COMPRESS_SMALL(sc);
604  }
605  static void
606  echo_big_compress(sph_echo_big_context *sc)
607  {
608  	DECL_STATE_BIG
609  	COMPRESS_BIG(sc);
610  }
611  static void
612  echo_small_core(sph_echo_small_context *sc,
613  	const unsigned char *data, size_t len)
614  {
615  	unsigned char *buf;
616  	size_t ptr;
617  	buf = sc-&gt;buf;
618  	ptr = sc-&gt;ptr;
619  	if (len &lt; (sizeof sc-&gt;buf) - ptr) {
620  		memcpy(buf + ptr, data, len);
621  		ptr += len;
622  		sc-&gt;ptr = ptr;
623  		return;
624  	}
625  	while (len &gt; 0) {
626  		size_t clen;
627  		clen = (sizeof sc-&gt;buf) - ptr;
628  		if (clen &gt; len)
629  			clen = len;
630  		memcpy(buf + ptr, data, clen);
631  		ptr += clen;
632  		data += clen;
633  		len -= clen;
634  		if (ptr == sizeof sc-&gt;buf) {
635  			INCR_COUNTER(sc, 1536);
636  			echo_small_compress(sc);
637  			ptr = 0;
638  		}
639  	}
640  	sc-&gt;ptr = ptr;
641  }
642  static void
643  echo_big_core(sph_echo_big_context *sc,
644  	const unsigned char *data, size_t len)
645  {
646  	unsigned char *buf;
647  	size_t ptr;
648  	buf = sc-&gt;buf;
649  	ptr = sc-&gt;ptr;
650  	if (len &lt; (sizeof sc-&gt;buf) - ptr) {
651  		memcpy(buf + ptr, data, len);
652  		ptr += len;
653  		sc-&gt;ptr = ptr;
654  		return;
655  	}
656  	while (len &gt; 0) {
657  		size_t clen;
658  		clen = (sizeof sc-&gt;buf) - ptr;
659  		if (clen &gt; len)
660  			clen = len;
661  		memcpy(buf + ptr, data, clen);
662  		ptr += clen;
663  		data += clen;
664  		len -= clen;
665  		if (ptr == sizeof sc-&gt;buf) {
666  			INCR_COUNTER(sc, 1024);
667  			echo_big_compress(sc);
<span onclick='openModal()' class='match'>668  			ptr = 0;
669  		}
670  	}
671  	sc-&gt;ptr = ptr;
672  }
673  static void
674  echo_small_close(sph_echo_small_context *sc, unsigned ub, unsigned n,
</span>675  	void *dst, unsigned out_size_w32)
676  {
677  	unsigned char *buf;
678  	size_t ptr;
679  	unsigned z;
680  	unsigned elen;
681  	union {
682  		unsigned char tmp[32];
683  		sph_u32 dummy;
684  #if SPH_ECHO_64
685  		sph_u64 dummy2;
686  #endif
687  	} u;
688  #if SPH_ECHO_64
689  	sph_u64 *VV;
690  #else
691  	sph_u32 *VV;
692  #endif
693  	unsigned k;
694  	buf = sc-&gt;buf;
695  	ptr = sc-&gt;ptr;
696  	elen = ((unsigned)ptr &lt;&lt; 3) + n;
697  	INCR_COUNTER(sc, elen);
698  	sph_enc32le_aligned(u.tmp, sc-&gt;C0);
699  	sph_enc32le_aligned(u.tmp + 4, sc-&gt;C1);
700  	sph_enc32le_aligned(u.tmp + 8, sc-&gt;C2);
701  	sph_enc32le_aligned(u.tmp + 12, sc-&gt;C3);
702  	if (elen == 0) {
703  		sc-&gt;C0 = sc-&gt;C1 = sc-&gt;C2 = sc-&gt;C3 = 0;
704  	}
705  	z = 0x80 &gt;&gt; n;
706  	buf[ptr ++] = ((ub &amp; -z) | z) &amp; 0xFF;
707  	memset(buf + ptr, 0, (sizeof sc-&gt;buf) - ptr);
708  	if (ptr &gt; ((sizeof sc-&gt;buf) - 18)) {
709  		echo_small_compress(sc);
710  		sc-&gt;C0 = sc-&gt;C1 = sc-&gt;C2 = sc-&gt;C3 = 0;
711  		memset(buf, 0, sizeof sc-&gt;buf);
712  	}
713  	sph_enc16le(buf + (sizeof sc-&gt;buf) - 18, out_size_w32 &lt;&lt; 5);
714  	memcpy(buf + (sizeof sc-&gt;buf) - 16, u.tmp, 16);
715  	echo_small_compress(sc);
716  #if SPH_ECHO_64
717  	for (VV = &amp;sc-&gt;u.Vb[0][0], k = 0; k &lt; ((out_size_w32 + 1) &gt;&gt; 1); k ++)
718  		sph_enc64le_aligned(u.tmp + (k &lt;&lt; 3), VV[k]);
719  #else
720  	for (VV = &amp;sc-&gt;u.Vs[0][0], k = 0; k &lt; out_size_w32; k ++)
721  		sph_enc32le_aligned(u.tmp + (k &lt;&lt; 2), VV[k]);
722  #endif
723  	memcpy(dst, u.tmp, out_size_w32 &lt;&lt; 2);
724  	echo_small_init(sc, out_size_w32 &lt;&lt; 5);
725  }
726  static void
727  echo_big_close(sph_echo_big_context *sc, unsigned ub, unsigned n,
728  	void *dst, unsigned out_size_w32)
729  {
730  	unsigned char *buf;
731  	size_t ptr;
732  	unsigned z;
733  	unsigned elen;
734  	union {
735  		unsigned char tmp[64];
736  		sph_u32 dummy;
737  #if SPH_ECHO_64
738  		sph_u64 dummy2;
739  #endif
740  	} u;
741  #if SPH_ECHO_64
742  	sph_u64 *VV;
743  #else
744  	sph_u32 *VV;
745  #endif
746  	unsigned k;
747  	buf = sc-&gt;buf;
748  	ptr = sc-&gt;ptr;
749  	elen = ((unsigned)ptr &lt;&lt; 3) + n;
750  	INCR_COUNTER(sc, elen);
751  	sph_enc32le_aligned(u.tmp, sc-&gt;C0);
752  	sph_enc32le_aligned(u.tmp + 4, sc-&gt;C1);
753  	sph_enc32le_aligned(u.tmp + 8, sc-&gt;C2);
754  	sph_enc32le_aligned(u.tmp + 12, sc-&gt;C3);
755  	if (elen == 0) {
756  		sc-&gt;C0 = sc-&gt;C1 = sc-&gt;C2 = sc-&gt;C3 = 0;
757  	}
758  	z = 0x80 &gt;&gt; n;
759  	buf[ptr ++] = ((ub &amp; -z) | z) &amp; 0xFF;
760  	memset(buf + ptr, 0, (sizeof sc-&gt;buf) - ptr);
761  	if (ptr &gt; ((sizeof sc-&gt;buf) - 18)) {
762  		echo_big_compress(sc);
763  		sc-&gt;C0 = sc-&gt;C1 = sc-&gt;C2 = sc-&gt;C3 = 0;
764  		memset(buf, 0, sizeof sc-&gt;buf);
765  	}
766  	sph_enc16le(buf + (sizeof sc-&gt;buf) - 18, out_size_w32 &lt;&lt; 5);
767  	memcpy(buf + (sizeof sc-&gt;buf) - 16, u.tmp, 16);
768  	echo_big_compress(sc);
769  #if SPH_ECHO_64
770  	for (VV = &amp;sc-&gt;u.Vb[0][0], k = 0; k &lt; ((out_size_w32 + 1) &gt;&gt; 1); k ++)
771  		sph_enc64le_aligned(u.tmp + (k &lt;&lt; 3), VV[k]);
772  #else
773  	for (VV = &amp;sc-&gt;u.Vs[0][0], k = 0; k &lt; out_size_w32; k ++)
774  		sph_enc32le_aligned(u.tmp + (k &lt;&lt; 2), VV[k]);
775  #endif
776  	memcpy(dst, u.tmp, out_size_w32 &lt;&lt; 2);
777  	echo_big_init(sc, out_size_w32 &lt;&lt; 5);
778  }
779  void
780  sph_echo224_init(void *cc)
781  {
782  	echo_small_init(cc, 224);
783  }
784  void
785  sph_echo224(void *cc, const void *data, size_t len)
786  {
787  	echo_small_core(cc, data, len);
788  }
789  void
790  sph_echo224_close(void *cc, void *dst)
791  {
792  	echo_small_close(cc, 0, 0, dst, 7);
793  }
794  void
795  sph_echo224_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
796  {
797  	echo_small_close(cc, ub, n, dst, 7);
798  }
799  void
800  sph_echo256_init(void *cc)
801  {
802  	echo_small_init(cc, 256);
803  }
804  void
805  sph_echo256(void *cc, const void *data, size_t len)
806  {
807  	echo_small_core(cc, data, len);
808  }
809  void
810  sph_echo256_close(void *cc, void *dst)
811  {
812  	echo_small_close(cc, 0, 0, dst, 8);
813  }
814  void
815  sph_echo256_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
816  {
817  	echo_small_close(cc, ub, n, dst, 8);
818  }
819  void
820  sph_echo384_init(void *cc)
821  {
822  	echo_big_init(cc, 384);
823  }
824  void
825  sph_echo384(void *cc, const void *data, size_t len)
826  {
827  	echo_big_core(cc, data, len);
828  }
829  void
830  sph_echo384_close(void *cc, void *dst)
831  {
832  	echo_big_close(cc, 0, 0, dst, 12);
833  }
834  void
835  sph_echo384_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
836  {
837  	echo_big_close(cc, ub, n, dst, 12);
838  }
839  void
840  sph_echo512_init(void *cc)
841  {
842  	echo_big_init(cc, 512);
843  }
844  void
845  sph_echo512(void *cc, const void *data, size_t len)
846  {
847  	echo_big_core(cc, data, len);
848  }
849  void
850  sph_echo512_close(void *cc, void *dst)
851  {
852  	echo_big_close(cc, 0, 0, dst, 16);
853  }
854  void
855  sph_echo512_addbits_and_close(void *cc, unsigned ub, unsigned n, void *dst)
856  {
857  	echo_big_close(cc, ub, n, dst, 16);
858  }
859  #ifdef __cplusplus
860  }
861  #endif
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-sph_shavite.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-sph_echo.c</div>
                </div>
                <div class="column column_space"><pre><code>1429  			ptr = 0;
1430  		}
1431  	}
1432  	sc-&gt;ptr = ptr;
1433  }
1434  static void
1435  shavite_big_close(sph_shavite_big_context *sc,
1436  	unsigned ub, unsigned n, void *dst, size_t out_size_w32)
</pre></code></div>
                <div class="column column_space"><pre><code>668  			ptr = 0;
669  		}
670  	}
671  	sc-&gt;ptr = ptr;
672  }
673  static void
674  echo_small_close(sph_echo_small_context *sc, unsigned ub, unsigned n,
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    