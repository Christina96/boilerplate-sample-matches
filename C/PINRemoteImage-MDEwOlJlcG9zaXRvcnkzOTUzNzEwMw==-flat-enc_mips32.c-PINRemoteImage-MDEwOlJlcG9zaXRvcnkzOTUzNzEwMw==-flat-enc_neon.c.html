
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 15, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-enc_mips32.c</h3>
            <pre><code>1  #include "src/dsp/dsp.h"
2  #if defined(WEBP_USE_MIPS32)
3  #include "src/dsp/mips_macro.h"
4  #include "src/enc/vp8i_enc.h"
5  #include "src/enc/cost_enc.h"
6  static const int kC1 = 20091 + (1 << 16);
7  static const int kC2 = 35468;
8  #define VERTICAL_PASS(A, B, C, D, TEMP4, TEMP0, TEMP1, TEMP2, TEMP3)        \
9    "lh      %[temp16],      " #A "(%[temp20])                 \n\t"          \
10    "lh      %[temp18],      " #B "(%[temp20])                 \n\t"          \
11    "lh      %[temp17],      " #C "(%[temp20])                 \n\t"          \
12    "lh      %[temp19],      " #D "(%[temp20])                 \n\t"          \
13    "addu    %[" #TEMP4 "],    %[temp16],      %[temp18]       \n\t"          \
14    "subu    %[temp16],      %[temp16],      %[temp18]         \n\t"          \
15    "mul     %[" #TEMP0 "],    %[temp17],      %[kC2]          \n\t"          \
16    "mul     %[temp18],      %[temp19],      %[kC1]            \n\t"          \
17    "mul     %[temp17],      %[temp17],      %[kC1]            \n\t"          \
18    "mul     %[temp19],      %[temp19],      %[kC2]            \n\t"          \
19    "sra     %[" #TEMP0 "],    %[" #TEMP0 "],    16            \n\n"          \
20    "sra     %[temp18],      %[temp18],      16                \n\n"          \
21    "sra     %[temp17],      %[temp17],      16                \n\n"          \
22    "sra     %[temp19],      %[temp19],      16                \n\n"          \
23    "subu    %[" #TEMP2 "],    %[" #TEMP0 "],    %[temp18]     \n\t"          \
24    "addu    %[" #TEMP3 "],    %[temp17],      %[temp19]       \n\t"          \
25    "addu    %[" #TEMP0 "],    %[" #TEMP4 "],    %[" #TEMP3 "] \n\t"          \
26    "addu    %[" #TEMP1 "],    %[temp16],      %[" #TEMP2 "]   \n\t"          \
27    "subu    %[" #TEMP2 "],    %[temp16],      %[" #TEMP2 "]   \n\t"          \
28    "subu    %[" #TEMP3 "],    %[" #TEMP4 "],    %[" #TEMP3 "] \n\t"
29  #define HORIZONTAL_PASS(A, TEMP0, TEMP4, TEMP8, TEMP12)                       \
30    "addiu   %[" #TEMP0 "],    %[" #TEMP0 "],    4               \n\t"          \
31    "addu    %[temp16],      %[" #TEMP0 "],    %[" #TEMP8 "]     \n\t"          \
32    "subu    %[temp17],      %[" #TEMP0 "],    %[" #TEMP8 "]     \n\t"          \
33    "mul     %[" #TEMP0 "],    %[" #TEMP4 "],    %[kC2]          \n\t"          \
34    "mul     %[" #TEMP8 "],    %[" #TEMP12 "],   %[kC1]          \n\t"          \
35    "mul     %[" #TEMP4 "],    %[" #TEMP4 "],    %[kC1]          \n\t"          \
36    "mul     %[" #TEMP12 "],   %[" #TEMP12 "],   %[kC2]          \n\t"          \
37    "sra     %[" #TEMP0 "],    %[" #TEMP0 "],    16              \n\t"          \
38    "sra     %[" #TEMP8 "],    %[" #TEMP8 "],    16              \n\t"          \
39    "sra     %[" #TEMP4 "],    %[" #TEMP4 "],    16              \n\t"          \
40    "sra     %[" #TEMP12 "],   %[" #TEMP12 "],   16              \n\t"          \
41    "subu    %[temp18],      %[" #TEMP0 "],    %[" #TEMP8 "]     \n\t"          \
42    "addu    %[temp19],      %[" #TEMP4 "],    %[" #TEMP12 "]    \n\t"          \
43    "addu    %[" #TEMP0 "],    %[temp16],      %[temp19]         \n\t"          \
44    "addu    %[" #TEMP4 "],    %[temp17],      %[temp18]         \n\t"          \
45    "subu    %[" #TEMP8 "],    %[temp17],      %[temp18]         \n\t"          \
46    "subu    %[" #TEMP12 "],   %[temp16],      %[temp19]         \n\t"          \
47    "lw      %[temp20],      0(%[args])                          \n\t"          \
48    "sra     %[" #TEMP0 "],    %[" #TEMP0 "],    3               \n\t"          \
49    "sra     %[" #TEMP4 "],    %[" #TEMP4 "],    3               \n\t"          \
50    "sra     %[" #TEMP8 "],    %[" #TEMP8 "],    3               \n\t"          \
51    "sra     %[" #TEMP12 "],   %[" #TEMP12 "],   3               \n\t"          \
52    "lbu     %[temp16],      0+" XSTR(BPS) "*" #A "(%[temp20])   \n\t"          \
53    "lbu     %[temp17],      1+" XSTR(BPS) "*" #A "(%[temp20])   \n\t"          \
54    "lbu     %[temp18],      2+" XSTR(BPS) "*" #A "(%[temp20])   \n\t"          \
55    "lbu     %[temp19],      3+" XSTR(BPS) "*" #A "(%[temp20])   \n\t"          \
56    "addu    %[" #TEMP0 "],    %[temp16],      %[" #TEMP0 "]     \n\t"          \
57    "addu    %[" #TEMP4 "],    %[temp17],      %[" #TEMP4 "]     \n\t"          \
58    "addu    %[" #TEMP8 "],    %[temp18],      %[" #TEMP8 "]     \n\t"          \
59    "addu    %[" #TEMP12 "],   %[temp19],      %[" #TEMP12 "]    \n\t"          \
60    "slt     %[temp16],      %[" #TEMP0 "],    $zero             \n\t"          \
61    "slt     %[temp17],      %[" #TEMP4 "],    $zero             \n\t"          \
62    "slt     %[temp18],      %[" #TEMP8 "],    $zero             \n\t"          \
63    "slt     %[temp19],      %[" #TEMP12 "],   $zero             \n\t"          \
64    "movn    %[" #TEMP0 "],    $zero,          %[temp16]         \n\t"          \
65    "movn    %[" #TEMP4 "],    $zero,          %[temp17]         \n\t"          \
66    "movn    %[" #TEMP8 "],    $zero,          %[temp18]         \n\t"          \
67    "movn    %[" #TEMP12 "],   $zero,          %[temp19]         \n\t"          \
68    "addiu   %[temp20],      $zero,          255                 \n\t"          \
69    "slt     %[temp16],      %[" #TEMP0 "],    %[temp20]         \n\t"          \
70    "slt     %[temp17],      %[" #TEMP4 "],    %[temp20]         \n\t"          \
71    "slt     %[temp18],      %[" #TEMP8 "],    %[temp20]         \n\t"          \
72    "slt     %[temp19],      %[" #TEMP12 "],   %[temp20]         \n\t"          \
73    "movz    %[" #TEMP0 "],    %[temp20],      %[temp16]         \n\t"          \
74    "movz    %[" #TEMP4 "],    %[temp20],      %[temp17]         \n\t"          \
75    "lw      %[temp16],      8(%[args])                          \n\t"          \
76    "movz    %[" #TEMP8 "],    %[temp20],      %[temp18]         \n\t"          \
77    "movz    %[" #TEMP12 "],   %[temp20],      %[temp19]         \n\t"          \
78    "sb      %[" #TEMP0 "],    0+" XSTR(BPS) "*" #A "(%[temp16]) \n\t"          \
79    "sb      %[" #TEMP4 "],    1+" XSTR(BPS) "*" #A "(%[temp16]) \n\t"          \
80    "sb      %[" #TEMP8 "],    2+" XSTR(BPS) "*" #A "(%[temp16]) \n\t"          \
81    "sb      %[" #TEMP12 "],   3+" XSTR(BPS) "*" #A "(%[temp16]) \n\t"
82  static WEBP_INLINE void ITransformOne_MIPS32(const uint8_t* ref,
83                                               const int16_t* in,
84                                               uint8_t* dst) {
85    int temp0, temp1, temp2, temp3, temp4, temp5, temp6;
86    int temp7, temp8, temp9, temp10, temp11, temp12, temp13;
87    int temp14, temp15, temp16, temp17, temp18, temp19, temp20;
88    const int* args[3] = {(const int*)ref, (const int*)in, (const int*)dst};
89    __asm__ volatile(
90      "lw      %[temp20],      4(%[args])                      \n\t"
91      VERTICAL_PASS(0, 16,  8, 24, temp4,  temp0,  temp1,  temp2,  temp3)
92      VERTICAL_PASS(2, 18, 10, 26, temp8,  temp4,  temp5,  temp6,  temp7)
93      VERTICAL_PASS(4, 20, 12, 28, temp12, temp8,  temp9,  temp10, temp11)
94      VERTICAL_PASS(6, 22, 14, 30, temp20, temp12, temp13, temp14, temp15)
95      HORIZONTAL_PASS(0, temp0, temp4, temp8,  temp12)
96      HORIZONTAL_PASS(1, temp1, temp5, temp9,  temp13)
97      HORIZONTAL_PASS(2, temp2, temp6, temp10, temp14)
98      HORIZONTAL_PASS(3, temp3, temp7, temp11, temp15)
99      : [temp0]"=&r"(temp0), [temp1]"=&r"(temp1), [temp2]"=&r"(temp2),
100        [temp3]"=&r"(temp3), [temp4]"=&r"(temp4), [temp5]"=&r"(temp5),
101        [temp6]"=&r"(temp6), [temp7]"=&r"(temp7), [temp8]"=&r"(temp8),
102        [temp9]"=&r"(temp9), [temp10]"=&r"(temp10), [temp11]"=&r"(temp11),
103        [temp12]"=&r"(temp12), [temp13]"=&r"(temp13), [temp14]"=&r"(temp14),
104        [temp15]"=&r"(temp15), [temp16]"=&r"(temp16), [temp17]"=&r"(temp17),
105        [temp18]"=&r"(temp18), [temp19]"=&r"(temp19), [temp20]"=&r"(temp20)
106      : [args]"r"(args), [kC1]"r"(kC1), [kC2]"r"(kC2)
107      : "memory", "hi", "lo"
108    );
109  }
110  static void ITransform_MIPS32(const uint8_t* ref, const int16_t* in,
111                                uint8_t* dst, int do_two) {
112    ITransformOne_MIPS32(ref, in, dst);
113    if (do_two) {
114      ITransformOne_MIPS32(ref + 4, in + 16, dst + 4);
115    }
116  }
117  #undef VERTICAL_PASS
118  #undef HORIZONTAL_PASS
119  #define QUANTIZE_ONE(J, K, N)                                               \
120    "lh           %[temp0],       " #J "(%[ppin])                     \n\t"   \
121    "lhu          %[temp1],       " #J "(%[ppsharpen])                \n\t"   \
122    "lw           %[temp2],       " #K "(%[ppzthresh])                \n\t"   \
123    "sra          %[sign],        %[temp0],           15              \n\t"   \
124    "xor          %[coeff],       %[temp0],           %[sign]         \n\t"   \
125    "subu         %[coeff],       %[coeff],           %[sign]         \n\t"   \
126    "addu         %[coeff],       %[coeff],           %[temp1]        \n\t"   \
127    "slt          %[temp4],       %[temp2],           %[coeff]        \n\t"   \
128    "addiu        %[temp5],       $zero,              0               \n\t"   \
129    "addiu        %[level],       $zero,              0               \n\t"   \
130    "beqz         %[temp4],       2f                                  \n\t"   \
131    "lhu          %[temp1],       " #J "(%[ppiq])                     \n\t"   \
132    "lw           %[temp2],       " #K "(%[ppbias])                   \n\t"   \
133    "lhu          %[temp3],       " #J "(%[ppq])                      \n\t"   \
134    "mul          %[level],       %[coeff],           %[temp1]        \n\t"   \
135    "addu         %[level],       %[level],           %[temp2]        \n\t"   \
136    "sra          %[level],       %[level],           17              \n\t"   \
137    "slt          %[temp4],       %[max_level],       %[level]        \n\t"   \
138    "movn         %[level],       %[max_level],       %[temp4]        \n\t"   \
139    "xor          %[level],       %[level],           %[sign]         \n\t"   \
140    "subu         %[level],       %[level],           %[sign]         \n\t"   \
141    "mul          %[temp5],       %[level],           %[temp3]        \n\t"   \
142  "2:                                                                 \n\t"   \
143    "sh           %[temp5],       " #J "(%[ppin])                     \n\t"   \
144    "sh           %[level],       " #N "(%[pout])                     \n\t"
145  static int QuantizeBlock_MIPS32(int16_t in[16], int16_t out[16],
146                                  const VP8Matrix* const mtx) {
147    int temp0, temp1, temp2, temp3, temp4, temp5;
148    int sign, coeff, level, i;
149    int max_level = MAX_LEVEL;
150    int16_t* ppin             = &in[0];
151    int16_t* pout             = &out[0];
152    const uint16_t* ppsharpen = &mtx->sharpen_[0];
153    const uint32_t* ppzthresh = &mtx->zthresh_[0];
154    const uint16_t* ppq       = &mtx->q_[0];
155    const uint16_t* ppiq      = &mtx->iq_[0];
156    const uint32_t* ppbias    = &mtx->bias_[0];
157    __asm__ volatile(
158      QUANTIZE_ONE( 0,  0,  0)
159      QUANTIZE_ONE( 2,  4,  2)
160      QUANTIZE_ONE( 8, 16,  4)
161      QUANTIZE_ONE(16, 32,  6)
162      QUANTIZE_ONE(10, 20,  8)
163      QUANTIZE_ONE( 4,  8, 10)
164      QUANTIZE_ONE( 6, 12, 12)
165      QUANTIZE_ONE(12, 24, 14)
166      QUANTIZE_ONE(18, 36, 16)
167      QUANTIZE_ONE(24, 48, 18)
168      QUANTIZE_ONE(26, 52, 20)
169      QUANTIZE_ONE(20, 40, 22)
170      QUANTIZE_ONE(14, 28, 24)
171      QUANTIZE_ONE(22, 44, 26)
172      QUANTIZE_ONE(28, 56, 28)
173      QUANTIZE_ONE(30, 60, 30)
174      : [temp0]"=&r"(temp0), [temp1]"=&r"(temp1),
175        [temp2]"=&r"(temp2), [temp3]"=&r"(temp3),
176        [temp4]"=&r"(temp4), [temp5]"=&r"(temp5),
177        [sign]"=&r"(sign), [coeff]"=&r"(coeff),
178        [level]"=&r"(level)
179      : [pout]"r"(pout), [ppin]"r"(ppin),
180        [ppiq]"r"(ppiq), [max_level]"r"(max_level),
181        [ppbias]"r"(ppbias), [ppzthresh]"r"(ppzthresh),
182        [ppsharpen]"r"(ppsharpen), [ppq]"r"(ppq)
183      : "memory", "hi", "lo"
184    );
185    for (i = 15; i >= 0; i--) {
186      if (out[i]) return 1;
187    }
188    return 0;
189  }
190  static int Quantize2Blocks_MIPS32(int16_t in[32], int16_t out[32],
191                                    const VP8Matrix* const mtx) {
192    int nz;
193    nz  = QuantizeBlock_MIPS32(in + 0 * 16, out + 0 * 16, mtx) << 0;
194    nz |= QuantizeBlock_MIPS32(in + 1 * 16, out + 1 * 16, mtx) << 1;
195    return nz;
196  }
197  #undef QUANTIZE_ONE
198  #define HORIZONTAL_PASS(A, E, F, G, H, E1, F1, G1, H1)                  \
199    "lbu    %[temp0],  0+" XSTR(BPS) "*" #A "(%[a])  \n\t"                \
200    "lbu    %[temp1],  1+" XSTR(BPS) "*" #A "(%[a])  \n\t"                \
201    "lbu    %[temp2],  2+" XSTR(BPS) "*" #A "(%[a])  \n\t"                \
202    "lbu    %[temp3],  3+" XSTR(BPS) "*" #A "(%[a])  \n\t"                \
203    "lbu    %[temp4],  0+" XSTR(BPS) "*" #A "(%[b])  \n\t"                \
204    "lbu    %[temp5],  1+" XSTR(BPS) "*" #A "(%[b])  \n\t"                \
205    "lbu    %[temp6],  2+" XSTR(BPS) "*" #A "(%[b])  \n\t"                \
206    "lbu    %[temp7],  3+" XSTR(BPS) "*" #A "(%[b])  \n\t"                \
207    "addu   %[temp8],  %[temp0],    %[temp2]         \n\t"                \
208    "subu   %[temp0],  %[temp0],    %[temp2]         \n\t"                \
209    "addu   %[temp2],  %[temp1],    %[temp3]         \n\t"                \
210    "subu   %[temp1],  %[temp1],    %[temp3]         \n\t"                \
211    "addu   %[temp3],  %[temp4],    %[temp6]         \n\t"                \
212    "subu   %[temp4],  %[temp4],    %[temp6]         \n\t"                \
213    "addu   %[temp6],  %[temp5],    %[temp7]         \n\t"                \
214    "subu   %[temp5],  %[temp5],    %[temp7]         \n\t"                \
215    "addu   %[temp7],  %[temp8],    %[temp2]         \n\t"                \
216    "subu   %[temp2],  %[temp8],    %[temp2]         \n\t"                \
217    "addu   %[temp8],  %[temp0],    %[temp1]         \n\t"                \
218    "subu   %[temp0],  %[temp0],    %[temp1]         \n\t"                \
219    "addu   %[temp1],  %[temp3],    %[temp6]         \n\t"                \
220    "subu   %[temp3],  %[temp3],    %[temp6]         \n\t"                \
221    "addu   %[temp6],  %[temp4],    %[temp5]         \n\t"                \
222    "subu   %[temp4],  %[temp4],    %[temp5]         \n\t"                \
223    "sw     %[temp7],  " #E "(%[tmp])                \n\t"                \
224    "sw     %[temp2],  " #H "(%[tmp])                \n\t"                \
225    "sw     %[temp8],  " #F "(%[tmp])                \n\t"                \
226    "sw     %[temp0],  " #G "(%[tmp])                \n\t"                \
227    "sw     %[temp1],  " #E1 "(%[tmp])               \n\t"                \
228    "sw     %[temp3],  " #H1 "(%[tmp])               \n\t"                \
229    "sw     %[temp6],  " #F1 "(%[tmp])               \n\t"                \
230    "sw     %[temp4],  " #G1 "(%[tmp])               \n\t"
231  #define VERTICAL_PASS(A, B, C, D, A1, B1, C1, D1, E, F, G, H)     \
232    "lw     %[temp0],  " #A1 "(%[tmp])         \n\t"                \
233    "lw     %[temp1],  " #C1 "(%[tmp])         \n\t"                \
234    "lw     %[temp2],  " #B1 "(%[tmp])         \n\t"                \
235    "lw     %[temp3],  " #D1 "(%[tmp])         \n\t"                \
236    "addu   %[temp8],  %[temp0],    %[temp1]   \n\t"                \
237    "subu   %[temp0],  %[temp0],    %[temp1]   \n\t"                \
238    "addu   %[temp1],  %[temp2],    %[temp3]   \n\t"                \
239    "subu   %[temp2],  %[temp2],    %[temp3]   \n\t"                \
240    "addu   %[temp3],  %[temp8],    %[temp1]   \n\t"                \
241    "subu   %[temp8],  %[temp8],    %[temp1]   \n\t"                \
242    "addu   %[temp1],  %[temp0],    %[temp2]   \n\t"                \
243    "subu   %[temp0],  %[temp0],    %[temp2]   \n\t"                \
244    "sra    %[temp4],  %[temp3],    31         \n\t"                \
245    "sra    %[temp5],  %[temp1],    31         \n\t"                \
246    "sra    %[temp6],  %[temp0],    31         \n\t"                \
247    "sra    %[temp7],  %[temp8],    31         \n\t"                \
248    "xor    %[temp3],  %[temp3],    %[temp4]   \n\t"                \
249    "xor    %[temp1],  %[temp1],    %[temp5]   \n\t"                \
250    "xor    %[temp0],  %[temp0],    %[temp6]   \n\t"                \
251    "xor    %[temp8],  %[temp8],    %[temp7]   \n\t"                \
252    "subu   %[temp3],  %[temp3],    %[temp4]   \n\t"                \
253    "subu   %[temp1],  %[temp1],    %[temp5]   \n\t"                \
254    "subu   %[temp0],  %[temp0],    %[temp6]   \n\t"                \
255    "subu   %[temp8],  %[temp8],    %[temp7]   \n\t"                \
256    "lhu    %[temp4],  " #E "(%[w])            \n\t"                \
257    "lhu    %[temp5],  " #F "(%[w])            \n\t"                \
258    "lhu    %[temp6],  " #G "(%[w])            \n\t"                \
259    "lhu    %[temp7],  " #H "(%[w])            \n\t"                \
260    "madd   %[temp4],  %[temp3]                \n\t"                \
261    "madd   %[temp5],  %[temp1]                \n\t"                \
262    "madd   %[temp6],  %[temp0]                \n\t"                \
263    "madd   %[temp7],  %[temp8]                \n\t"                \
264    "lw     %[temp0],  " #A "(%[tmp])          \n\t"                \
265    "lw     %[temp1],  " #C "(%[tmp])          \n\t"                \
266    "lw     %[temp2],  " #B "(%[tmp])          \n\t"                \
267    "lw     %[temp3],  " #D "(%[tmp])          \n\t"                \
268    "addu   %[temp8],  %[temp0],    %[temp1]   \n\t"                \
269    "subu   %[temp0],  %[temp0],    %[temp1]   \n\t"                \
270    "addu   %[temp1],  %[temp2],    %[temp3]   \n\t"                \
271    "subu   %[temp2],  %[temp2],    %[temp3]   \n\t"                \
272    "addu   %[temp3],  %[temp8],    %[temp1]   \n\t"                \
273    "subu   %[temp1],  %[temp8],    %[temp1]   \n\t"                \
274    "addu   %[temp8],  %[temp0],    %[temp2]   \n\t"                \
275    "subu   %[temp0],  %[temp0],    %[temp2]   \n\t"                \
276    "sra    %[temp2],  %[temp3],    31         \n\t"                \
277    "xor    %[temp3],  %[temp3],    %[temp2]   \n\t"                \
278    "subu   %[temp3],  %[temp3],    %[temp2]   \n\t"                \
279    "msub   %[temp4],  %[temp3]                \n\t"                \
280    "sra    %[temp2],  %[temp8],    31         \n\t"                \
281    "sra    %[temp3],  %[temp0],    31         \n\t"                \
282    "sra    %[temp4],  %[temp1],    31         \n\t"                \
283    "xor    %[temp8],  %[temp8],    %[temp2]   \n\t"                \
284    "xor    %[temp0],  %[temp0],    %[temp3]   \n\t"                \
285    "xor    %[temp1],  %[temp1],    %[temp4]   \n\t"                \
286    "subu   %[temp8],  %[temp8],    %[temp2]   \n\t"                \
287    "subu   %[temp0],  %[temp0],    %[temp3]   \n\t"                \
288    "subu   %[temp1],  %[temp1],    %[temp4]   \n\t"                \
289    "msub   %[temp5],  %[temp8]                \n\t"                \
290    "msub   %[temp6],  %[temp0]                \n\t"                \
291    "msub   %[temp7],  %[temp1]                \n\t"
292  static int Disto4x4_MIPS32(const uint8_t* const a, const uint8_t* const b,
293                             const uint16_t* const w) {
294    int tmp[32];
295    int temp0, temp1, temp2, temp3, temp4, temp5, temp6, temp7, temp8;
296    __asm__ volatile(
297      HORIZONTAL_PASS(0,   0,  4,  8, 12,    64,  68,  72,  76)
298      HORIZONTAL_PASS(1,  16, 20, 24, 28,    80,  84,  88,  92)
299      HORIZONTAL_PASS(2,  32, 36, 40, 44,    96, 100, 104, 108)
300      HORIZONTAL_PASS(3,  48, 52, 56, 60,   112, 116, 120, 124)
301      "mthi   $zero                             \n\t"
302      "mtlo   $zero                             \n\t"
303      VERTICAL_PASS( 0, 16, 32, 48,     64, 80,  96, 112,   0,  8, 16, 24)
304      VERTICAL_PASS( 4, 20, 36, 52,     68, 84, 100, 116,   2, 10, 18, 26)
305      VERTICAL_PASS( 8, 24, 40, 56,     72, 88, 104, 120,   4, 12, 20, 28)
306      VERTICAL_PASS(12, 28, 44, 60,     76, 92, 108, 124,   6, 14, 22, 30)
307      "mflo   %[temp0]                          \n\t"
308      "sra    %[temp1],  %[temp0],  31          \n\t"
309      "xor    %[temp0],  %[temp0],  %[temp1]    \n\t"
310      "subu   %[temp0],  %[temp0],  %[temp1]    \n\t"
311      "sra    %[temp0],  %[temp0],  5           \n\t"
312      : [temp0]"=&r"(temp0), [temp1]"=&r"(temp1), [temp2]"=&r"(temp2),
313        [temp3]"=&r"(temp3), [temp4]"=&r"(temp4), [temp5]"=&r"(temp5),
314        [temp6]"=&r"(temp6), [temp7]"=&r"(temp7), [temp8]"=&r"(temp8)
315      : [a]"r"(a), [b]"r"(b), [w]"r"(w), [tmp]"r"(tmp)
316      : "memory", "hi", "lo"
317    );
318    return temp0;
319  }
320  #undef VERTICAL_PASS
321  #undef HORIZONTAL_PASS
322  static int Disto16x16_MIPS32(const uint8_t* const a, const uint8_t* const b,
323                               const uint16_t* const w) {
324    int D = 0;
325    int x, y;
326    for (y = 0; y < 16 * BPS; y += 4 * BPS) {
327      for (x = 0; x < 16; x += 4) {
328        D += Disto4x4_MIPS32(a + x + y, b + x + y, w);
329      }
330    }
331    return D;
332  }
333  #define HORIZONTAL_PASS(A, TEMP0, TEMP1, TEMP2, TEMP3)                  \
334    "lw     %[" #TEMP1 "],  0(%[args])                           \n\t"    \
335    "lw     %[" #TEMP2 "],  4(%[args])                           \n\t"    \
336    "lbu    %[temp16],    0+" XSTR(BPS) "*" #A "(%[" #TEMP1 "])  \n\t"    \
337    "lbu    %[temp17],    0+" XSTR(BPS) "*" #A "(%[" #TEMP2 "])  \n\t"    \
338    "lbu    %[temp18],    1+" XSTR(BPS) "*" #A "(%[" #TEMP1 "])  \n\t"    \
339    "lbu    %[temp19],    1+" XSTR(BPS) "*" #A "(%[" #TEMP2 "])  \n\t"    \
340    "subu   %[temp20],    %[temp16],    %[temp17]                \n\t"    \
341    "lbu    %[temp16],    2+" XSTR(BPS) "*" #A "(%[" #TEMP1 "])  \n\t"    \
342    "lbu    %[temp17],    2+" XSTR(BPS) "*" #A "(%[" #TEMP2 "])  \n\t"    \
343    "subu   %[" #TEMP0 "],  %[temp18],    %[temp19]              \n\t"    \
344    "lbu    %[temp18],    3+" XSTR(BPS) "*" #A "(%[" #TEMP1 "])  \n\t"    \
345    "lbu    %[temp19],    3+" XSTR(BPS) "*" #A "(%[" #TEMP2 "])  \n\t"    \
346    "subu   %[" #TEMP1 "],  %[temp16],    %[temp17]              \n\t"    \
347    "subu   %[" #TEMP2 "],  %[temp18],    %[temp19]              \n\t"    \
348    "addu   %[" #TEMP3 "],  %[temp20],    %[" #TEMP2 "]          \n\t"    \
349    "subu   %[" #TEMP2 "],  %[temp20],    %[" #TEMP2 "]          \n\t"    \
350    "addu   %[temp20],    %[" #TEMP0 "],  %[" #TEMP1 "]          \n\t"    \
351    "subu   %[" #TEMP0 "],  %[" #TEMP0 "],  %[" #TEMP1 "]        \n\t"    \
352    "mul    %[temp16],    %[" #TEMP2 "],  %[c5352]               \n\t"    \
353    "mul    %[temp17],    %[" #TEMP2 "],  %[c2217]               \n\t"    \
354    "mul    %[temp18],    %[" #TEMP0 "],  %[c5352]               \n\t"    \
355    "mul    %[temp19],    %[" #TEMP0 "],  %[c2217]               \n\t"    \
356    "addu   %[" #TEMP1 "],  %[" #TEMP3 "],  %[temp20]            \n\t"    \
357    "subu   %[temp20],    %[" #TEMP3 "],  %[temp20]              \n\t"    \
358    "sll    %[" #TEMP0 "],  %[" #TEMP1 "],  3                    \n\t"    \
359    "sll    %[" #TEMP2 "],  %[temp20],    3                      \n\t"    \
360    "addiu  %[temp16],    %[temp16],    1812                     \n\t"    \
361    "addiu  %[temp17],    %[temp17],    937                      \n\t"    \
362    "addu   %[temp16],    %[temp16],    %[temp19]                \n\t"    \
363    "subu   %[temp17],    %[temp17],    %[temp18]                \n\t"    \
364    "sra    %[" #TEMP1 "],  %[temp16],    9                      \n\t"    \
365    "sra    %[" #TEMP3 "],  %[temp17],    9                      \n\t"
366  #define VERTICAL_PASS(A, B, C, D, TEMP0, TEMP4, TEMP8, TEMP12)    \
367    "addu   %[temp16],    %[" #TEMP0 "],  %[" #TEMP12 "]   \n\t"    \
368    "subu   %[temp19],    %[" #TEMP0 "],  %[" #TEMP12 "]   \n\t"    \
369    "addu   %[temp17],    %[" #TEMP4 "],  %[" #TEMP8 "]    \n\t"    \
370    "subu   %[temp18],    %[" #TEMP4 "],  %[" #TEMP8 "]    \n\t"    \
371    "mul    %[" #TEMP8 "],  %[temp19],    %[c2217]         \n\t"    \
372    "mul    %[" #TEMP12 "], %[temp18],    %[c2217]         \n\t"    \
373    "mul    %[" #TEMP4 "],  %[temp19],    %[c5352]         \n\t"    \
374    "mul    %[temp18],    %[temp18],    %[c5352]           \n\t"    \
375    "addiu  %[temp16],    %[temp16],    7                  \n\t"    \
376    "addu   %[" #TEMP0 "],  %[temp16],    %[temp17]        \n\t"    \
377    "sra    %[" #TEMP0 "],  %[" #TEMP0 "],  4              \n\t"    \
378    "addu   %[" #TEMP12 "], %[" #TEMP12 "], %[" #TEMP4 "]  \n\t"    \
379    "subu   %[" #TEMP4 "],  %[temp16],    %[temp17]        \n\t"    \
380    "sra    %[" #TEMP4 "],  %[" #TEMP4 "],  4              \n\t"    \
381    "addiu  %[" #TEMP8 "],  %[" #TEMP8 "],  30000          \n\t"    \
382    "addiu  %[" #TEMP12 "], %[" #TEMP12 "], 12000          \n\t"    \
383    "addiu  %[" #TEMP8 "],  %[" #TEMP8 "],  21000          \n\t"    \
384    "subu   %[" #TEMP8 "],  %[" #TEMP8 "],  %[temp18]      \n\t"    \
385    "sra    %[" #TEMP12 "], %[" #TEMP12 "], 16             \n\t"    \
386    "sra    %[" #TEMP8 "],  %[" #TEMP8 "],  16             \n\t"    \
387    "addiu  %[temp16],    %[" #TEMP12 "], 1                \n\t"    \
388    "movn   %[" #TEMP12 "], %[temp16],    %[temp19]        \n\t"    \
389    "sh     %[" #TEMP0 "],  " #A "(%[temp20])              \n\t"    \
390    "sh     %[" #TEMP4 "],  " #C "(%[temp20])              \n\t"    \
391    "sh     %[" #TEMP8 "],  " #D "(%[temp20])              \n\t"    \
392    "sh     %[" #TEMP12 "], " #B "(%[temp20])              \n\t"
393  static void FTransform_MIPS32(const uint8_t* src, const uint8_t* ref,
394                                int16_t* out) {
395    int temp0, temp1, temp2, temp3, temp4, temp5, temp6, temp7, temp8;
396    int temp9, temp10, temp11, temp12, temp13, temp14, temp15, temp16;
397    int temp17, temp18, temp19, temp20;
398    const int c2217 = 2217;
399    const int c5352 = 5352;
400    const int* const args[3] =
401        { (const int*)src, (const int*)ref, (const int*)out };
402    __asm__ volatile(
403      HORIZONTAL_PASS(0, temp0,  temp1,  temp2,  temp3)
404      HORIZONTAL_PASS(1, temp4,  temp5,  temp6,  temp7)
405      HORIZONTAL_PASS(2, temp8,  temp9,  temp10, temp11)
406      HORIZONTAL_PASS(3, temp12, temp13, temp14, temp15)
407      "lw   %[temp20],    8(%[args])                     \n\t"
408      VERTICAL_PASS(0,  8, 16, 24, temp0, temp4, temp8,  temp12)
409      VERTICAL_PASS(2, 10, 18, 26, temp1, temp5, temp9,  temp13)
410      VERTICAL_PASS(4, 12, 20, 28, temp2, temp6, temp10, temp14)
411      VERTICAL_PASS(6, 14, 22, 30, temp3, temp7, temp11, temp15)
412      : [temp0]"=&r"(temp0), [temp1]"=&r"(temp1), [temp2]"=&r"(temp2),
413        [temp3]"=&r"(temp3), [temp4]"=&r"(temp4), [temp5]"=&r"(temp5),
414        [temp6]"=&r"(temp6), [temp7]"=&r"(temp7), [temp8]"=&r"(temp8),
415        [temp9]"=&r"(temp9), [temp10]"=&r"(temp10), [temp11]"=&r"(temp11),
416        [temp12]"=&r"(temp12), [temp13]"=&r"(temp13), [temp14]"=&r"(temp14),
417        [temp15]"=&r"(temp15), [temp16]"=&r"(temp16), [temp17]"=&r"(temp17),
418        [temp18]"=&r"(temp18), [temp19]"=&r"(temp19), [temp20]"=&r"(temp20)
419      : [args]"r"(args), [c2217]"r"(c2217), [c5352]"r"(c5352)
420      : "memory", "hi", "lo"
421    );
422  }
423  #undef VERTICAL_PASS
424  #undef HORIZONTAL_PASS
425  #if !defined(WORK_AROUND_GCC)
426  #define GET_SSE_INNER(A, B, C, D)                               \
427    "lbu     %[temp0],    " #A "(%[a])                 \n\t"      \
428    "lbu     %[temp1],    " #A "(%[b])                 \n\t"      \
429    "lbu     %[temp2],    " #B "(%[a])                 \n\t"      \
430    "lbu     %[temp3],    " #B "(%[b])                 \n\t"      \
431    "lbu     %[temp4],    " #C "(%[a])                 \n\t"      \
432    "lbu     %[temp5],    " #C "(%[b])                 \n\t"      \
433    "lbu     %[temp6],    " #D "(%[a])                 \n\t"      \
434    "lbu     %[temp7],    " #D "(%[b])                 \n\t"      \
435    "subu    %[temp0],    %[temp0],     %[temp1]       \n\t"      \
436    "subu    %[temp2],    %[temp2],     %[temp3]       \n\t"      \
437    "subu    %[temp4],    %[temp4],     %[temp5]       \n\t"      \
438    "subu    %[temp6],    %[temp6],     %[temp7]       \n\t"      \
439    "madd    %[temp0],    %[temp0]                     \n\t"      \
440    "madd    %[temp2],    %[temp2]                     \n\t"      \
441    "madd    %[temp4],    %[temp4]                     \n\t"      \
442    "madd    %[temp6],    %[temp6]                     \n\t"
443  #define GET_SSE(A, B, C, D)               \
444    GET_SSE_INNER(A, A + 1, A + 2, A + 3)   \
445    GET_SSE_INNER(B, B + 1, B + 2, B + 3)   \
446    GET_SSE_INNER(C, C + 1, C + 2, C + 3)   \
447    GET_SSE_INNER(D, D + 1, D + 2, D + 3)
448  static int SSE16x16_MIPS32(const uint8_t* a, const uint8_t* b) {
449    int count;
450    int temp0, temp1, temp2, temp3, temp4, temp5, temp6, temp7;
451    __asm__ volatile(
452       "mult   $zero,    $zero                            \n\t"
453       GET_SSE( 0 * BPS, 4 +  0 * BPS, 8 +  0 * BPS, 12 +  0 * BPS)
454       GET_SSE( 1 * BPS, 4 +  1 * BPS, 8 +  1 * BPS, 12 +  1 * BPS)
455       GET_SSE( 2 * BPS, 4 +  2 * BPS, 8 +  2 * BPS, 12 +  2 * BPS)
456       GET_SSE( 3 * BPS, 4 +  3 * BPS, 8 +  3 * BPS, 12 +  3 * BPS)
457       GET_SSE( 4 * BPS, 4 +  4 * BPS, 8 +  4 * BPS, 12 +  4 * BPS)
458       GET_SSE( 5 * BPS, 4 +  5 * BPS, 8 +  5 * BPS, 12 +  5 * BPS)
459       GET_SSE( 6 * BPS, 4 +  6 * BPS, 8 +  6 * BPS, 12 +  6 * BPS)
460       GET_SSE( 7 * BPS, 4 +  7 * BPS, 8 +  7 * BPS, 12 +  7 * BPS)
461       GET_SSE( 8 * BPS, 4 +  8 * BPS, 8 +  8 * BPS, 12 +  8 * BPS)
462       GET_SSE( 9 * BPS, 4 +  9 * BPS, 8 +  9 * BPS, 12 +  9 * BPS)
463       GET_SSE(10 * BPS, 4 + 10 * BPS, 8 + 10 * BPS, 12 + 10 * BPS)
464       GET_SSE(11 * BPS, 4 + 11 * BPS, 8 + 11 * BPS, 12 + 11 * BPS)
465       GET_SSE(12 * BPS, 4 + 12 * BPS, 8 + 12 * BPS, 12 + 12 * BPS)
466       GET_SSE(13 * BPS, 4 + 13 * BPS, 8 + 13 * BPS, 12 + 13 * BPS)
467       GET_SSE(14 * BPS, 4 + 14 * BPS, 8 + 14 * BPS, 12 + 14 * BPS)
468       GET_SSE(15 * BPS, 4 + 15 * BPS, 8 + 15 * BPS, 12 + 15 * BPS)
469      "mflo    %[count]                                   \n\t"
470      : [temp0]"=&r"(temp0), [temp1]"=&r"(temp1), [temp2]"=&r"(temp2),
471        [temp3]"=&r"(temp3), [temp4]"=&r"(temp4), [temp5]"=&r"(temp5),
472        [temp6]"=&r"(temp6), [temp7]"=&r"(temp7), [count]"=&r"(count)
473      : [a]"r"(a), [b]"r"(b)
474      : "memory", "hi", "lo"
475    );
476    return count;
477  }
478  static int SSE16x8_MIPS32(const uint8_t* a, const uint8_t* b) {
479    int count;
480    int temp0, temp1, temp2, temp3, temp4, temp5, temp6, temp7;
481    __asm__ volatile(
482       "mult   $zero,    $zero                            \n\t"
483       GET_SSE( 0 * BPS, 4 +  0 * BPS, 8 +  0 * BPS, 12 +  0 * BPS)
484       GET_SSE( 1 * BPS, 4 +  1 * BPS, 8 +  1 * BPS, 12 +  1 * BPS)
485       GET_SSE( 2 * BPS, 4 +  2 * BPS, 8 +  2 * BPS, 12 +  2 * BPS)
486       GET_SSE( 3 * BPS, 4 +  3 * BPS, 8 +  3 * BPS, 12 +  3 * BPS)
487       GET_SSE( 4 * BPS, 4 +  4 * BPS, 8 +  4 * BPS, 12 +  4 * BPS)
488       GET_SSE( 5 * BPS, 4 +  5 * BPS, 8 +  5 * BPS, 12 +  5 * BPS)
489       GET_SSE( 6 * BPS, 4 +  6 * BPS, 8 +  6 * BPS, 12 +  6 * BPS)
490       GET_SSE( 7 * BPS, 4 +  7 * BPS, 8 +  7 * BPS, 12 +  7 * BPS)
491      "mflo    %[count]                                   \n\t"
492      : [temp0]"=&r"(temp0), [temp1]"=&r"(temp1), [temp2]"=&r"(temp2),
493        [temp3]"=&r"(temp3), [temp4]"=&r"(temp4), [temp5]"=&r"(temp5),
494        [temp6]"=&r"(temp6), [temp7]"=&r"(temp7), [count]"=&r"(count)
495      : [a]"r"(a), [b]"r"(b)
496      : "memory", "hi", "lo"
497    );
498    return count;
499  }
500  static int SSE8x8_MIPS32(const uint8_t* a, const uint8_t* b) {
501    int count;
502    int temp0, temp1, temp2, temp3, temp4, temp5, temp6, temp7;
503    __asm__ volatile(
504       "mult   $zero,    $zero                            \n\t"
505       GET_SSE(0 * BPS, 4 + 0 * BPS, 1 * BPS, 4 + 1 * BPS)
506       GET_SSE(2 * BPS, 4 + 2 * BPS, 3 * BPS, 4 + 3 * BPS)
507       GET_SSE(4 * BPS, 4 + 4 * BPS, 5 * BPS, 4 + 5 * BPS)
508       GET_SSE(6 * BPS, 4 + 6 * BPS, 7 * BPS, 4 + 7 * BPS)
509      "mflo    %[count]                                   \n\t"
510      : [temp0]"=&r"(temp0), [temp1]"=&r"(temp1), [temp2]"=&r"(temp2),
511        [temp3]"=&r"(temp3), [temp4]"=&r"(temp4), [temp5]"=&r"(temp5),
512        [temp6]"=&r"(temp6), [temp7]"=&r"(temp7), [count]"=&r"(count)
513      : [a]"r"(a), [b]"r"(b)
514      : "memory", "hi", "lo"
515    );
516    return count;
517  }
518  static int SSE4x4_MIPS32(const uint8_t* a, const uint8_t* b) {
519    int count;
520    int temp0, temp1, temp2, temp3, temp4, temp5, temp6, temp7;
521    __asm__ volatile(
522       "mult   $zero,    $zero                            \n\t"
523       GET_SSE(0 * BPS, 1 * BPS, 2 * BPS, 3 * BPS)
524      "mflo    %[count]                                   \n\t"
525      : [temp0]"=&r"(temp0), [temp1]"=&r"(temp1), [temp2]"=&r"(temp2),
526        [temp3]"=&r"(temp3), [temp4]"=&r"(temp4), [temp5]"=&r"(temp5),
527        [temp6]"=&r"(temp6), [temp7]"=&r"(temp7), [count]"=&r"(count)
528      : [a]"r"(a), [b]"r"(b)
529      : "memory", "hi", "lo"
530    );
531    return count;
532  }
533  #undef GET_SSE
534  #undef GET_SSE_INNER
535  #endif  
536  extern void VP8EncDspInitMIPS32(void);
537  WEBP_TSAN_IGNORE_FUNCTION void VP8EncDspInitMIPS32(void) {
538    VP8ITransform = ITransform_MIPS32;
539    VP8FTransform = FTransform_MIPS32;
540    VP8EncQuantizeBlock = QuantizeBlock_MIPS32;
541    VP8EncQuantize2Blocks = Quantize2Blocks_MIPS32;
542    VP8TDisto4x4 = Disto4x4_MIPS32;
<span onclick='openModal()' class='match'>543    VP8TDisto16x16 = Disto16x16_MIPS32;
544  #if !defined(WORK_AROUND_GCC)
545    VP8SSE16x16 = SSE16x16_MIPS32;
546    VP8SSE8x8 = SSE8x8_MIPS32;
</span>547    VP8SSE16x8 = SSE16x8_MIPS32;
548    VP8SSE4x4 = SSE4x4_MIPS32;
549  #endif
550  }
551  #else  
552  WEBP_DSP_INIT_STUB(VP8EncDspInitMIPS32)
553  #endif  
</code></pre>
        </div>
        <div class="column">
            <h3>PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-enc_neon.c</h3>
            <pre><code>1  #include "src/dsp/dsp.h"
2  #if defined(WEBP_USE_NEON)
3  #include <assert.h>
4  #include "src/dsp/neon.h"
5  #include "src/enc/vp8i_enc.h"
6  static const int16_t kC1 = 20091;
7  static const int16_t kC2 = 17734;  
8  #if defined(WEBP_USE_INTRINSICS)
9  static WEBP_INLINE int16x8_t ConvertU8ToS16_NEON(uint32x2_t v) {
10    return vreinterpretq_s16_u16(vmovl_u8(vreinterpret_u8_u32(v)));
11  }
12  static WEBP_INLINE void SaturateAndStore4x4_NEON(uint8_t* const dst,
13                                                   const int16x8_t dst01,
14                                                   const int16x8_t dst23) {
15    const uint8x8_t dst01_u8 = vqmovun_s16(dst01);
16    const uint8x8_t dst23_u8 = vqmovun_s16(dst23);
17    vst1_lane_u32((uint32_t*)(dst + 0 * BPS), vreinterpret_u32_u8(dst01_u8), 0);
18    vst1_lane_u32((uint32_t*)(dst + 1 * BPS), vreinterpret_u32_u8(dst01_u8), 1);
19    vst1_lane_u32((uint32_t*)(dst + 2 * BPS), vreinterpret_u32_u8(dst23_u8), 0);
20    vst1_lane_u32((uint32_t*)(dst + 3 * BPS), vreinterpret_u32_u8(dst23_u8), 1);
21  }
22  static WEBP_INLINE void Add4x4_NEON(const int16x8_t row01,
23                                      const int16x8_t row23,
24                                      const uint8_t* const ref,
25                                      uint8_t* const dst) {
26    uint32x2_t dst01 = vdup_n_u32(0);
27    uint32x2_t dst23 = vdup_n_u32(0);
28    dst01 = vld1_lane_u32((uint32_t*)(ref + 0 * BPS), dst01, 0);
29    dst23 = vld1_lane_u32((uint32_t*)(ref + 2 * BPS), dst23, 0);
30    dst01 = vld1_lane_u32((uint32_t*)(ref + 1 * BPS), dst01, 1);
31    dst23 = vld1_lane_u32((uint32_t*)(ref + 3 * BPS), dst23, 1);
32    {
33      const int16x8_t dst01_s16 = ConvertU8ToS16_NEON(dst01);
34      const int16x8_t dst23_s16 = ConvertU8ToS16_NEON(dst23);
35      const int16x8_t out01 = vrsraq_n_s16(dst01_s16, row01, 3);
36      const int16x8_t out23 = vrsraq_n_s16(dst23_s16, row23, 3);
37      SaturateAndStore4x4_NEON(dst, out01, out23);
38    }
39  }
40  static WEBP_INLINE void Transpose8x2_NEON(const int16x8_t in0,
41                                            const int16x8_t in1,
42                                            int16x8x2_t* const out) {
43    const int16x8x2_t tmp0 = vzipq_s16(in0, in1);   
44    *out = vzipq_s16(tmp0.val[0], tmp0.val[1]);
45  }
46  static WEBP_INLINE void TransformPass_NEON(int16x8x2_t* const rows) {
47    const int16x8_t B1 =
48        vcombine_s16(vget_high_s16(rows->val[0]), vget_high_s16(rows->val[1]));
49    const int16x8_t C0 = vsraq_n_s16(B1, vqdmulhq_n_s16(B1, kC1), 1);
50    const int16x8_t C1 = vqdmulhq_n_s16(B1, kC2);
51    const int16x4_t a = vqadd_s16(vget_low_s16(rows->val[0]),
52                                  vget_low_s16(rows->val[1]));   
53    const int16x4_t b = vqsub_s16(vget_low_s16(rows->val[0]),
54                                  vget_low_s16(rows->val[1]));   
55    const int16x4_t c = vqsub_s16(vget_low_s16(C1), vget_high_s16(C0));
56    const int16x4_t d = vqadd_s16(vget_low_s16(C0), vget_high_s16(C1));
57    const int16x8_t D0 = vcombine_s16(a, b);      
58    const int16x8_t D1 = vcombine_s16(d, c);      
59    const int16x8_t E0 = vqaddq_s16(D0, D1);      
60    const int16x8_t E_tmp = vqsubq_s16(D0, D1);   
61    const int16x8_t E1 = vcombine_s16(vget_high_s16(E_tmp), vget_low_s16(E_tmp));
62    Transpose8x2_NEON(E0, E1, rows);
63  }
64  static void ITransformOne_NEON(const uint8_t* ref,
65                                 const int16_t* in, uint8_t* dst) {
66    int16x8x2_t rows;
67    INIT_VECTOR2(rows, vld1q_s16(in + 0), vld1q_s16(in + 8));
68    TransformPass_NEON(&rows);
69    TransformPass_NEON(&rows);
70    Add4x4_NEON(rows.val[0], rows.val[1], ref, dst);
71  }
72  #else
73  static void ITransformOne_NEON(const uint8_t* ref,
74                                 const int16_t* in, uint8_t* dst) {
75    const int kBPS = BPS;
76    const int16_t kC1C2[] = { kC1, kC2, 0, 0 };
77    __asm__ volatile (
78      "vld1.16         {q1, q2}, [%[in]]           \n"
79      "vld1.16         {d0}, [%[kC1C2]]            \n"
80      "vswp            d3, d4                      \n"
81      "vqdmulh.s16     q8, q2, d0[0]               \n"
82      "vqdmulh.s16     q9, q2, d0[1]               \n"
83      "vqadd.s16       d22, d2, d3                 \n"
84      "vqsub.s16       d23, d2, d3                 \n"
85      "vshr.s16        q8, q8, #1                  \n"
86      "vqadd.s16       q8, q2, q8                  \n"
87      "vqsub.s16       d20, d18, d17               \n"
88      "vqadd.s16       d21, d19, d16               \n"
89      "vqadd.s16       d2, d22, d21                \n"
90      "vqadd.s16       d3, d23, d20                \n"
91      "vqsub.s16       d4, d23, d20                \n"
92      "vqsub.s16       d5, d22, d21                \n"
93      "vzip.16         q1, q2                      \n"
94      "vzip.16         q1, q2                      \n"
95      "vswp            d3, d4                      \n"
96      "vqdmulh.s16     q8, q2, d0[0]               \n"
97      "vqdmulh.s16     q9, q2, d0[1]               \n"
98      "vqadd.s16       d22, d2, d3                 \n"
99      "vqsub.s16       d23, d2, d3                 \n"
100      "vshr.s16        q8, q8, #1                  \n"
101      "vqadd.s16       q8, q2, q8                  \n"
102      "vqsub.s16       d20, d18, d17               \n"
103      "vqadd.s16       d21, d19, d16               \n"
104      "vqadd.s16       d2, d22, d21                \n"
105      "vqadd.s16       d3, d23, d20                \n"
106      "vqsub.s16       d4, d23, d20                \n"
107      "vqsub.s16       d5, d22, d21                \n"
108      "vld1.32         d6[0], [%[ref]], %[kBPS]    \n"
109      "vld1.32         d6[1], [%[ref]], %[kBPS]    \n"
110      "vld1.32         d7[0], [%[ref]], %[kBPS]    \n"
111      "vld1.32         d7[1], [%[ref]], %[kBPS]    \n"
112      "sub         %[ref], %[ref], %[kBPS], lsl #2 \n"
113      "vrshr.s16       d2, d2, #3                  \n"
114      "vrshr.s16       d3, d3, #3                  \n"
115      "vrshr.s16       d4, d4, #3                  \n"
116      "vrshr.s16       d5, d5, #3                  \n"
117      "vzip.16         q1, q2                      \n"
118      "vzip.16         q1, q2                      \n"
119      "vmovl.u8        q8, d6                      \n"
120      "vmovl.u8        q9, d7                      \n"
121      "vqadd.s16       q1, q1, q8                  \n"
122      "vqadd.s16       q2, q2, q9                  \n"
123      "vqmovun.s16     d0, q1                      \n"
124      "vqmovun.s16     d1, q2                      \n"
125      "vst1.32         d0[0], [%[dst]], %[kBPS]    \n"
126      "vst1.32         d0[1], [%[dst]], %[kBPS]    \n"
127      "vst1.32         d1[0], [%[dst]], %[kBPS]    \n"
128      "vst1.32         d1[1], [%[dst]]             \n"
129      : [in] "+r"(in), [dst] "+r"(dst)               
130      : [kBPS] "r"(kBPS), [kC1C2] "r"(kC1C2), [ref] "r"(ref)  
131      : "memory", "q0", "q1", "q2", "q8", "q9", "q10", "q11"  
132    );
133  }
134  #endif    
135  static void ITransform_NEON(const uint8_t* ref,
136                              const int16_t* in, uint8_t* dst, int do_two) {
137    ITransformOne_NEON(ref, in, dst);
138    if (do_two) {
139      ITransformOne_NEON(ref + 4, in + 16, dst + 4);
140    }
141  }
142  static uint8x16_t Load4x4_NEON(const uint8_t* src) {
143    uint32x4_t out = vdupq_n_u32(0);
144    out = vld1q_lane_u32((const uint32_t*)(src + 0 * BPS), out, 0);
145    out = vld1q_lane_u32((const uint32_t*)(src + 1 * BPS), out, 1);
146    out = vld1q_lane_u32((const uint32_t*)(src + 2 * BPS), out, 2);
147    out = vld1q_lane_u32((const uint32_t*)(src + 3 * BPS), out, 3);
148    return vreinterpretq_u8_u32(out);
149  }
150  #if defined(WEBP_USE_INTRINSICS)
151  static WEBP_INLINE void Transpose4x4_S16_NEON(const int16x4_t A,
152                                                const int16x4_t B,
153                                                const int16x4_t C,
154                                                const int16x4_t D,
155                                                int16x8_t* const out01,
156                                                int16x8_t* const out32) {
157    const int16x4x2_t AB = vtrn_s16(A, B);
158    const int16x4x2_t CD = vtrn_s16(C, D);
159    const int32x2x2_t tmp02 = vtrn_s32(vreinterpret_s32_s16(AB.val[0]),
160                                       vreinterpret_s32_s16(CD.val[0]));
161    const int32x2x2_t tmp13 = vtrn_s32(vreinterpret_s32_s16(AB.val[1]),
162                                       vreinterpret_s32_s16(CD.val[1]));
163    *out01 = vreinterpretq_s16_s64(
164        vcombine_s64(vreinterpret_s64_s32(tmp02.val[0]),
165                     vreinterpret_s64_s32(tmp13.val[0])));
166    *out32 = vreinterpretq_s16_s64(
167        vcombine_s64(vreinterpret_s64_s32(tmp13.val[1]),
168                     vreinterpret_s64_s32(tmp02.val[1])));
169  }
170  static WEBP_INLINE int16x8_t DiffU8ToS16_NEON(const uint8x8_t a,
171                                                const uint8x8_t b) {
172    return vreinterpretq_s16_u16(vsubl_u8(a, b));
173  }
174  static void FTransform_NEON(const uint8_t* src, const uint8_t* ref,
175                              int16_t* out) {
176    int16x8_t d0d1, d3d2;   
177    {
178      const uint8x16_t S0 = Load4x4_NEON(src);
179      const uint8x16_t R0 = Load4x4_NEON(ref);
180      const int16x8_t D0D1 = DiffU8ToS16_NEON(vget_low_u8(S0), vget_low_u8(R0));
181      const int16x8_t D2D3 = DiffU8ToS16_NEON(vget_high_u8(S0), vget_high_u8(R0));
182      const int16x4_t D0 = vget_low_s16(D0D1);
183      const int16x4_t D1 = vget_high_s16(D0D1);
184      const int16x4_t D2 = vget_low_s16(D2D3);
185      const int16x4_t D3 = vget_high_s16(D2D3);
186      Transpose4x4_S16_NEON(D0, D1, D2, D3, &d0d1, &d3d2);
187    }
188    {    
189      const int32x4_t kCst937 = vdupq_n_s32(937);
190      const int32x4_t kCst1812 = vdupq_n_s32(1812);
191      const int16x8_t a0a1 = vaddq_s16(d0d1, d3d2);   
192      const int16x8_t a3a2 = vsubq_s16(d0d1, d3d2);   
193      const int16x8_t a0a1_2 = vshlq_n_s16(a0a1, 3);
194      const int16x4_t tmp0 = vadd_s16(vget_low_s16(a0a1_2),
195                                      vget_high_s16(a0a1_2));
196      const int16x4_t tmp2 = vsub_s16(vget_low_s16(a0a1_2),
197                                      vget_high_s16(a0a1_2));
198      const int32x4_t a3_2217 = vmull_n_s16(vget_low_s16(a3a2), 2217);
199      const int32x4_t a2_2217 = vmull_n_s16(vget_high_s16(a3a2), 2217);
200      const int32x4_t a2_p_a3 = vmlal_n_s16(a2_2217, vget_low_s16(a3a2), 5352);
201      const int32x4_t a3_m_a2 = vmlsl_n_s16(a3_2217, vget_high_s16(a3a2), 5352);
202      const int16x4_t tmp1 = vshrn_n_s32(vaddq_s32(a2_p_a3, kCst1812), 9);
203      const int16x4_t tmp3 = vshrn_n_s32(vaddq_s32(a3_m_a2, kCst937), 9);
204      Transpose4x4_S16_NEON(tmp0, tmp1, tmp2, tmp3, &d0d1, &d3d2);
205    }
206    {    
207      const int32x4_t kCst12000 = vdupq_n_s32(12000 + (1 << 16));
208      const int32x4_t kCst51000 = vdupq_n_s32(51000);
209      const int16x8_t a0a1 = vaddq_s16(d0d1, d3d2);   
210      const int16x8_t a3a2 = vsubq_s16(d0d1, d3d2);   
211      const int16x4_t a0_k7 = vadd_s16(vget_low_s16(a0a1), vdup_n_s16(7));
212      const int16x4_t out0 = vshr_n_s16(vadd_s16(a0_k7, vget_high_s16(a0a1)), 4);
213      const int16x4_t out2 = vshr_n_s16(vsub_s16(a0_k7, vget_high_s16(a0a1)), 4);
214      const int32x4_t a3_2217 = vmull_n_s16(vget_low_s16(a3a2), 2217);
215      const int32x4_t a2_2217 = vmull_n_s16(vget_high_s16(a3a2), 2217);
216      const int32x4_t a2_p_a3 = vmlal_n_s16(a2_2217, vget_low_s16(a3a2), 5352);
217      const int32x4_t a3_m_a2 = vmlsl_n_s16(a3_2217, vget_high_s16(a3a2), 5352);
218      const int16x4_t tmp1 = vaddhn_s32(a2_p_a3, kCst12000);
219      const int16x4_t out3 = vaddhn_s32(a3_m_a2, kCst51000);
220      const int16x4_t a3_eq_0 =
221          vreinterpret_s16_u16(vceq_s16(vget_low_s16(a3a2), vdup_n_s16(0)));
222      const int16x4_t out1 = vadd_s16(tmp1, a3_eq_0);
223      vst1_s16(out +  0, out0);
224      vst1_s16(out +  4, out1);
225      vst1_s16(out +  8, out2);
226      vst1_s16(out + 12, out3);
227    }
228  }
229  #else
230  static const int16_t kCoeff16[] = {
231    5352,  5352,  5352, 5352, 2217,  2217,  2217, 2217
232  };
233  static const int32_t kCoeff32[] = {
234     1812,  1812,  1812,  1812,
235      937,   937,   937,   937,
236    12000, 12000, 12000, 12000,
237    51000, 51000, 51000, 51000
238  };
239  static void FTransform_NEON(const uint8_t* src, const uint8_t* ref,
240                              int16_t* out) {
241    const int kBPS = BPS;
242    const uint8_t* src_ptr = src;
243    const uint8_t* ref_ptr = ref;
244    const int16_t* coeff16 = kCoeff16;
245    const int32_t* coeff32 = kCoeff32;
246    __asm__ volatile (
247      "vld1.8 {d8},  [%[src_ptr]], %[kBPS]      \n"
248      "vld1.8 {d10}, [%[src_ptr]], %[kBPS]      \n"
249      "vld1.8 {d9},  [%[src_ptr]], %[kBPS]      \n"
250      "vld1.8 {d11}, [%[src_ptr]]               \n"
251      "vld1.8 {d12}, [%[ref_ptr]], %[kBPS]      \n"
252      "vld1.8 {d14}, [%[ref_ptr]], %[kBPS]      \n"
253      "vld1.8 {d13}, [%[ref_ptr]], %[kBPS]      \n"
254      "vld1.8 {d15}, [%[ref_ptr]]               \n"
255      "vtrn.32     q4, q5                       \n"
256      "vtrn.32     q6, q7                       \n"
257      "vsubl.u8    q0, d8, d12                  \n"
258      "vsubl.u8    q1, d9, d13                  \n"
259      "vld1.16     {q8}, [%[coeff16]]           \n"
260      "vld1.32     {q9, q10}, [%[coeff32]]!     \n"
261      "vld1.32     {q11,q12}, [%[coeff32]]      \n"
262      "vtrn.32         d0, d2                   \n"
263      "vtrn.32         d1, d3                   \n"
264      "vtrn.16         d0, d1                   \n"
265      "vtrn.16         d2, d3                   \n"
266      "vadd.s16        d4, d0, d3               \n" 
267      "vadd.s16        d5, d1, d2               \n" 
268      "vsub.s16        d6, d1, d2               \n" 
269      "vsub.s16        d7, d0, d3               \n" 
270      "vadd.s16        d0, d4, d5               \n" 
271      "vshl.s16        d0, d0, #3               \n" 
272      "vsub.s16        d2, d4, d5               \n" 
273      "vshl.s16        d2, d2, #3               \n" 
274      "vmlal.s16       q9, d7, d16              \n" 
275      "vmlal.s16       q10, d7, d17             \n" 
276      "vmlal.s16       q9, d6, d17              \n" 
277      "vmlsl.s16       q10, d6, d16             \n" 
278      "vshrn.s32       d1, q9, #9               \n"
279      "vshrn.s32       d3, q10, #9              \n"
280      "vtrn.32         d0, d2                   \n"
281      "vtrn.32         d1, d3                   \n"
282      "vtrn.16         d0, d1                   \n"
283      "vtrn.16         d2, d3                   \n"
284      "vmov.s16        d26, #7                  \n"
285      "vadd.s16        d4, d0, d3               \n" 
286      "vadd.s16        d5, d1, d2               \n" 
287      "vsub.s16        d6, d1, d2               \n" 
288      "vadd.s16        d4, d4, d26              \n" 
289      "vsub.s16        d7, d0, d3               \n" 
290      "vadd.s16        d0, d4, d5               \n" 
291      "vsub.s16        d2, d4, d5               \n" 
292      "vmlal.s16       q11, d7, d16             \n" 
293      "vmlal.s16       q12, d7, d17             \n" 
294      "vceq.s16        d4, d7, #0               \n"
295      "vshr.s16        d0, d0, #4               \n"
296      "vshr.s16        d2, d2, #4               \n"
297      "vmlal.s16       q11, d6, d17             \n" 
298      "vmlsl.s16       q12, d6, d16             \n" 
299      "vmvn            d4, d4                   \n" 
300      "vshrn.s32       d1, q11, #16             \n"
301      "vsub.s16        d1, d1, d4               \n"
302      "vshrn.s32       d3, q12, #16             \n"
303      "vst1.16         {q0, q1}, [%[out]]   \n"
304      : [src_ptr] "+r"(src_ptr), [ref_ptr] "+r"(ref_ptr),
305        [coeff32] "+r"(coeff32)          
306      : [kBPS] "r"(kBPS), [coeff16] "r"(coeff16),
307        [out] "r"(out)                   
308      : "memory", "q0", "q1", "q2", "q3", "q4", "q5", "q6", "q7", "q8", "q9",
309        "q10", "q11", "q12", "q13"       
310    );
311  }
312  #endif
313  #define LOAD_LANE_16b(VALUE, LANE) do {             \
314    (VALUE) = vld1_lane_s16(src, (VALUE), (LANE));    \
315    src += stride;                                    \
316  } while (0)
317  static void FTransformWHT_NEON(const int16_t* src, int16_t* out) {
318    const int stride = 16;
319    const int16x4_t zero = vdup_n_s16(0);
320    int32x4x4_t tmp0;
321    int16x4x4_t in;
322    INIT_VECTOR4(in, zero, zero, zero, zero);
323    LOAD_LANE_16b(in.val[0], 0);
324    LOAD_LANE_16b(in.val[1], 0);
325    LOAD_LANE_16b(in.val[2], 0);
326    LOAD_LANE_16b(in.val[3], 0);
327    LOAD_LANE_16b(in.val[0], 1);
328    LOAD_LANE_16b(in.val[1], 1);
329    LOAD_LANE_16b(in.val[2], 1);
330    LOAD_LANE_16b(in.val[3], 1);
331    LOAD_LANE_16b(in.val[0], 2);
332    LOAD_LANE_16b(in.val[1], 2);
333    LOAD_LANE_16b(in.val[2], 2);
334    LOAD_LANE_16b(in.val[3], 2);
335    LOAD_LANE_16b(in.val[0], 3);
336    LOAD_LANE_16b(in.val[1], 3);
337    LOAD_LANE_16b(in.val[2], 3);
338    LOAD_LANE_16b(in.val[3], 3);
339    {
340      const int32x4_t a0 = vaddl_s16(in.val[0], in.val[2]);
341      const int32x4_t a1 = vaddl_s16(in.val[1], in.val[3]);
342      const int32x4_t a2 = vsubl_s16(in.val[1], in.val[3]);
343      const int32x4_t a3 = vsubl_s16(in.val[0], in.val[2]);
344      tmp0.val[0] = vaddq_s32(a0, a1);
345      tmp0.val[1] = vaddq_s32(a3, a2);
346      tmp0.val[2] = vsubq_s32(a3, a2);
347      tmp0.val[3] = vsubq_s32(a0, a1);
348    }
349    {
350      const int32x4x4_t tmp1 = Transpose4x4_NEON(tmp0);
351      const int32x4_t a0 = vaddq_s32(tmp1.val[0], tmp1.val[2]);
352      const int32x4_t a1 = vaddq_s32(tmp1.val[1], tmp1.val[3]);
353      const int32x4_t a2 = vsubq_s32(tmp1.val[1], tmp1.val[3]);
354      const int32x4_t a3 = vsubq_s32(tmp1.val[0], tmp1.val[2]);
355      const int32x4_t b0 = vhaddq_s32(a0, a1);  
356      const int32x4_t b1 = vhaddq_s32(a3, a2);  
357      const int32x4_t b2 = vhsubq_s32(a3, a2);  
358      const int32x4_t b3 = vhsubq_s32(a0, a1);  
359      const int16x4_t out0 = vmovn_s32(b0);
360      const int16x4_t out1 = vmovn_s32(b1);
361      const int16x4_t out2 = vmovn_s32(b2);
362      const int16x4_t out3 = vmovn_s32(b3);
363      vst1_s16(out +  0, out0);
364      vst1_s16(out +  4, out1);
365      vst1_s16(out +  8, out2);
366      vst1_s16(out + 12, out3);
367    }
368  }
369  #undef LOAD_LANE_16b
370  static WEBP_INLINE int16x8x4_t DistoTranspose4x4S16_NEON(int16x8x4_t q4_in) {
371    const int16x8x2_t q2_tmp0 = vtrnq_s16(q4_in.val[0], q4_in.val[1]);
372    const int16x8x2_t q2_tmp1 = vtrnq_s16(q4_in.val[2], q4_in.val[3]);
373    const int32x4x2_t q2_tmp2 = vtrnq_s32(vreinterpretq_s32_s16(q2_tmp0.val[0]),
374                                          vreinterpretq_s32_s16(q2_tmp1.val[0]));
375    const int32x4x2_t q2_tmp3 = vtrnq_s32(vreinterpretq_s32_s16(q2_tmp0.val[1]),
376                                          vreinterpretq_s32_s16(q2_tmp1.val[1]));
377    q4_in.val[0] = vreinterpretq_s16_s32(q2_tmp2.val[0]);
378    q4_in.val[2] = vreinterpretq_s16_s32(q2_tmp2.val[1]);
379    q4_in.val[1] = vreinterpretq_s16_s32(q2_tmp3.val[0]);
380    q4_in.val[3] = vreinterpretq_s16_s32(q2_tmp3.val[1]);
381    return q4_in;
382  }
383  static WEBP_INLINE int16x8x4_t DistoHorizontalPass_NEON(
384      const int16x8x4_t q4_in) {
385    const int16x8_t q_a0 = vaddq_s16(q4_in.val[0], q4_in.val[2]);
386    const int16x8_t q_a1 = vaddq_s16(q4_in.val[1], q4_in.val[3]);
387    const int16x8_t q_a3 = vsubq_s16(q4_in.val[0], q4_in.val[2]);
388    const int16x8_t q_a2 = vsubq_s16(q4_in.val[1], q4_in.val[3]);
389    int16x8x4_t q4_out;
390    INIT_VECTOR4(q4_out,
391                 vabsq_s16(vaddq_s16(q_a0, q_a1)),
392                 vabsq_s16(vaddq_s16(q_a3, q_a2)),
393                 vabdq_s16(q_a3, q_a2), vabdq_s16(q_a0, q_a1));
394    return q4_out;
395  }
396  static WEBP_INLINE int16x8x4_t DistoVerticalPass_NEON(const uint8x8x4_t q4_in) {
397    const int16x8_t q_a0 = vreinterpretq_s16_u16(vaddl_u8(q4_in.val[0],
398                                                          q4_in.val[2]));
399    const int16x8_t q_a1 = vreinterpretq_s16_u16(vaddl_u8(q4_in.val[1],
400                                                          q4_in.val[3]));
401    const int16x8_t q_a2 = vreinterpretq_s16_u16(vsubl_u8(q4_in.val[1],
402                                                          q4_in.val[3]));
403    const int16x8_t q_a3 = vreinterpretq_s16_u16(vsubl_u8(q4_in.val[0],
404                                                          q4_in.val[2]));
405    int16x8x4_t q4_out;
406    INIT_VECTOR4(q4_out,
407                 vaddq_s16(q_a0, q_a1), vaddq_s16(q_a3, q_a2),
408                 vsubq_s16(q_a3, q_a2), vsubq_s16(q_a0, q_a1));
409    return q4_out;
410  }
411  static WEBP_INLINE int16x4x4_t DistoLoadW_NEON(const uint16_t* w) {
412    const uint16x8_t q_w07 = vld1q_u16(&w[0]);
413    const uint16x8_t q_w8f = vld1q_u16(&w[8]);
414    int16x4x4_t d4_w;
415    INIT_VECTOR4(d4_w,
416                 vget_low_s16(vreinterpretq_s16_u16(q_w07)),
417                 vget_high_s16(vreinterpretq_s16_u16(q_w07)),
418                 vget_low_s16(vreinterpretq_s16_u16(q_w8f)),
419                 vget_high_s16(vreinterpretq_s16_u16(q_w8f)));
420    return d4_w;
421  }
422  static WEBP_INLINE int32x2_t DistoSum_NEON(const int16x8x4_t q4_in,
423                                             const int16x4x4_t d4_w) {
424    int32x2_t d_sum;
425    int32x4_t q_sum0 = vmull_s16(d4_w.val[0], vget_low_s16(q4_in.val[0]));
426    int32x4_t q_sum1 = vmull_s16(d4_w.val[1], vget_low_s16(q4_in.val[1]));
427    int32x4_t q_sum2 = vmull_s16(d4_w.val[2], vget_low_s16(q4_in.val[2]));
428    int32x4_t q_sum3 = vmull_s16(d4_w.val[3], vget_low_s16(q4_in.val[3]));
429    q_sum0 = vmlsl_s16(q_sum0, d4_w.val[0], vget_high_s16(q4_in.val[0]));
430    q_sum1 = vmlsl_s16(q_sum1, d4_w.val[1], vget_high_s16(q4_in.val[1]));
431    q_sum2 = vmlsl_s16(q_sum2, d4_w.val[2], vget_high_s16(q4_in.val[2]));
432    q_sum3 = vmlsl_s16(q_sum3, d4_w.val[3], vget_high_s16(q4_in.val[3]));
433    q_sum0 = vaddq_s32(q_sum0, q_sum1);
434    q_sum2 = vaddq_s32(q_sum2, q_sum3);
435    q_sum2 = vaddq_s32(q_sum0, q_sum2);
436    d_sum = vpadd_s32(vget_low_s32(q_sum2), vget_high_s32(q_sum2));
437    d_sum = vpadd_s32(d_sum, d_sum);
438    return d_sum;
439  }
440  #define LOAD_LANE_32b(src, VALUE, LANE) \
441      (VALUE) = vld1_lane_u32((const uint32_t*)(src), (VALUE), (LANE))
442  static int Disto4x4_NEON(const uint8_t* const a, const uint8_t* const b,
443                           const uint16_t* const w) {
444    uint32x2_t d_in_ab_0123 = vdup_n_u32(0);
445    uint32x2_t d_in_ab_4567 = vdup_n_u32(0);
446    uint32x2_t d_in_ab_89ab = vdup_n_u32(0);
447    uint32x2_t d_in_ab_cdef = vdup_n_u32(0);
448    uint8x8x4_t d4_in;
449    LOAD_LANE_32b(a + 0 * BPS, d_in_ab_0123, 0);
450    LOAD_LANE_32b(a + 1 * BPS, d_in_ab_4567, 0);
451    LOAD_LANE_32b(a + 2 * BPS, d_in_ab_89ab, 0);
452    LOAD_LANE_32b(a + 3 * BPS, d_in_ab_cdef, 0);
453    LOAD_LANE_32b(b + 0 * BPS, d_in_ab_0123, 1);
454    LOAD_LANE_32b(b + 1 * BPS, d_in_ab_4567, 1);
455    LOAD_LANE_32b(b + 2 * BPS, d_in_ab_89ab, 1);
456    LOAD_LANE_32b(b + 3 * BPS, d_in_ab_cdef, 1);
457    INIT_VECTOR4(d4_in,
458                 vreinterpret_u8_u32(d_in_ab_0123),
459                 vreinterpret_u8_u32(d_in_ab_4567),
460                 vreinterpret_u8_u32(d_in_ab_89ab),
461                 vreinterpret_u8_u32(d_in_ab_cdef));
462    {
463      const int16x8x4_t q4_v = DistoVerticalPass_NEON(d4_in);
464      const int16x4x4_t d4_w = DistoLoadW_NEON(w);
465      const int16x8x4_t q4_t = DistoTranspose4x4S16_NEON(q4_v);
466      const int16x8x4_t q4_h = DistoHorizontalPass_NEON(q4_t);
467      int32x2_t d_sum = DistoSum_NEON(q4_h, d4_w);
468      d_sum = vabs_s32(d_sum);
469      d_sum = vshr_n_s32(d_sum, 5);
470      return vget_lane_s32(d_sum, 0);
471    }
472  }
473  #undef LOAD_LANE_32b
474  static int Disto16x16_NEON(const uint8_t* const a, const uint8_t* const b,
475                             const uint16_t* const w) {
476    int D = 0;
477    int x, y;
478    for (y = 0; y < 16 * BPS; y += 4 * BPS) {
479      for (x = 0; x < 16; x += 4) {
480        D += Disto4x4_NEON(a + x + y, b + x + y, w);
481      }
482    }
483    return D;
484  }
485  static void CollectHistogram_NEON(const uint8_t* ref, const uint8_t* pred,
486                                    int start_block, int end_block,
487                                    VP8Histogram* const histo) {
488    const uint16x8_t max_coeff_thresh = vdupq_n_u16(MAX_COEFF_THRESH);
489    int j;
490    int distribution[MAX_COEFF_THRESH + 1] = { 0 };
491    for (j = start_block; j < end_block; ++j) {
492      int16_t out[16];
493      FTransform_NEON(ref + VP8DspScan[j], pred + VP8DspScan[j], out);
494      {
495        int k;
496        const int16x8_t a0 = vld1q_s16(out + 0);
497        const int16x8_t b0 = vld1q_s16(out + 8);
498        const uint16x8_t a1 = vreinterpretq_u16_s16(vabsq_s16(a0));
499        const uint16x8_t b1 = vreinterpretq_u16_s16(vabsq_s16(b0));
500        const uint16x8_t a2 = vshrq_n_u16(a1, 3);
501        const uint16x8_t b2 = vshrq_n_u16(b1, 3);
502        const uint16x8_t a3 = vminq_u16(a2, max_coeff_thresh);
503        const uint16x8_t b3 = vminq_u16(b2, max_coeff_thresh);
504        vst1q_s16(out + 0, vreinterpretq_s16_u16(a3));
505        vst1q_s16(out + 8, vreinterpretq_s16_u16(b3));
506        for (k = 0; k < 16; ++k) {
507          ++distribution[out[k]];
508        }
509      }
510    }
511    VP8SetHistogramData(distribution, histo);
512  }
513  static WEBP_INLINE void AccumulateSSE16_NEON(const uint8_t* const a,
514                                               const uint8_t* const b,
515                                               uint32x4_t* const sum) {
516    const uint8x16_t a0 = vld1q_u8(a);
517    const uint8x16_t b0 = vld1q_u8(b);
518    const uint8x16_t abs_diff = vabdq_u8(a0, b0);
519    const uint16x8_t prod1 = vmull_u8(vget_low_u8(abs_diff),
520                                      vget_low_u8(abs_diff));
521    const uint16x8_t prod2 = vmull_u8(vget_high_u8(abs_diff),
522                                      vget_high_u8(abs_diff));
523    const uint32x4_t sum1 = vpaddlq_u16(prod1);
524    const uint32x4_t sum2 = vpaddlq_u16(prod2);
525    *sum = vaddq_u32(*sum, vaddq_u32(sum1, sum2));
526  }
527  static int SumToInt_NEON(uint32x4_t sum) {
528    const uint64x2_t sum2 = vpaddlq_u32(sum);
529    const uint64_t sum3 = vgetq_lane_u64(sum2, 0) + vgetq_lane_u64(sum2, 1);
530    return (int)sum3;
531  }
532  static int SSE16x16_NEON(const uint8_t* a, const uint8_t* b) {
533    uint32x4_t sum = vdupq_n_u32(0);
534    int y;
535    for (y = 0; y < 16; ++y) {
536      AccumulateSSE16_NEON(a + y * BPS, b + y * BPS, &sum);
537    }
538    return SumToInt_NEON(sum);
539  }
540  static int SSE16x8_NEON(const uint8_t* a, const uint8_t* b) {
541    uint32x4_t sum = vdupq_n_u32(0);
542    int y;
543    for (y = 0; y < 8; ++y) {
544      AccumulateSSE16_NEON(a + y * BPS, b + y * BPS, &sum);
545    }
546    return SumToInt_NEON(sum);
547  }
548  static int SSE8x8_NEON(const uint8_t* a, const uint8_t* b) {
549    uint32x4_t sum = vdupq_n_u32(0);
550    int y;
551    for (y = 0; y < 8; ++y) {
552      const uint8x8_t a0 = vld1_u8(a + y * BPS);
553      const uint8x8_t b0 = vld1_u8(b + y * BPS);
554      const uint8x8_t abs_diff = vabd_u8(a0, b0);
555      const uint16x8_t prod = vmull_u8(abs_diff, abs_diff);
556      sum = vpadalq_u16(sum, prod);
557    }
558    return SumToInt_NEON(sum);
559  }
560  static int SSE4x4_NEON(const uint8_t* a, const uint8_t* b) {
561    const uint8x16_t a0 = Load4x4_NEON(a);
562    const uint8x16_t b0 = Load4x4_NEON(b);
563    const uint8x16_t abs_diff = vabdq_u8(a0, b0);
564    const uint16x8_t prod1 = vmull_u8(vget_low_u8(abs_diff),
565                                      vget_low_u8(abs_diff));
566    const uint16x8_t prod2 = vmull_u8(vget_high_u8(abs_diff),
567                                      vget_high_u8(abs_diff));
568    const uint32x4_t sum1 = vpaddlq_u16(prod1);
569    const uint32x4_t sum2 = vpaddlq_u16(prod2);
570    return SumToInt_NEON(vaddq_u32(sum1, sum2));
571  }
572  #if !defined(WORK_AROUND_GCC)
573  static int16x8_t Quantize_NEON(int16_t* const in,
574                                 const VP8Matrix* const mtx, int offset) {
575    const uint16x8_t sharp = vld1q_u16(&mtx->sharpen_[offset]);
576    const uint16x8_t q = vld1q_u16(&mtx->q_[offset]);
577    const uint16x8_t iq = vld1q_u16(&mtx->iq_[offset]);
578    const uint32x4_t bias0 = vld1q_u32(&mtx->bias_[offset + 0]);
579    const uint32x4_t bias1 = vld1q_u32(&mtx->bias_[offset + 4]);
580    const int16x8_t a = vld1q_s16(in + offset);                
581    const uint16x8_t b = vreinterpretq_u16_s16(vabsq_s16(a));  
582    const int16x8_t sign = vshrq_n_s16(a, 15);                 
583    const uint16x8_t c = vaddq_u16(b, sharp);                  
584    const uint32x4_t m0 = vmull_u16(vget_low_u16(c), vget_low_u16(iq));
585    const uint32x4_t m1 = vmull_u16(vget_high_u16(c), vget_high_u16(iq));
586    const uint32x4_t m2 = vhaddq_u32(m0, bias0);
587    const uint32x4_t m3 = vhaddq_u32(m1, bias1);     
588    const uint16x8_t c0 = vcombine_u16(vshrn_n_u32(m2, 16),
589                                       vshrn_n_u32(m3, 16));   
590    const uint16x8_t c1 = vminq_u16(c0, vdupq_n_u16(MAX_LEVEL));
591    const int16x8_t c2 = veorq_s16(vreinterpretq_s16_u16(c1), sign);
592    const int16x8_t c3 = vsubq_s16(c2, sign);                  
593    const int16x8_t c4 = vmulq_s16(c3, vreinterpretq_s16_u16(q));
594    vst1q_s16(in + offset, c4);
595    assert(QFIX == 17);  
596    return c3;
597  }
598  static const uint8_t kShuffles[4][8] = {
599    { 0,   1,  2,  3,  8,  9, 16, 17 },
600    { 10, 11,  4,  5,  6,  7, 12, 13 },
601    { 18, 19, 24, 25, 26, 27, 20, 21 },
602    { 14, 15, 22, 23, 28, 29, 30, 31 }
603  };
604  static int QuantizeBlock_NEON(int16_t in[16], int16_t out[16],
605                                const VP8Matrix* const mtx) {
606    const int16x8_t out0 = Quantize_NEON(in, mtx, 0);
607    const int16x8_t out1 = Quantize_NEON(in, mtx, 8);
608    uint8x8x4_t shuffles;
609  #if defined(__APPLE__) && defined(__aarch64__) && \
610      defined(__apple_build_version__) && (__apple_build_version__< 6020037)
611    uint8x16x2_t all_out;
612    INIT_VECTOR2(all_out, vreinterpretq_u8_s16(out0), vreinterpretq_u8_s16(out1));
613    INIT_VECTOR4(shuffles,
614                 vtbl2q_u8(all_out, vld1_u8(kShuffles[0])),
615                 vtbl2q_u8(all_out, vld1_u8(kShuffles[1])),
616                 vtbl2q_u8(all_out, vld1_u8(kShuffles[2])),
617                 vtbl2q_u8(all_out, vld1_u8(kShuffles[3])));
618  #else
619    uint8x8x4_t all_out;
620    INIT_VECTOR4(all_out,
621                 vreinterpret_u8_s16(vget_low_s16(out0)),
622                 vreinterpret_u8_s16(vget_high_s16(out0)),
623                 vreinterpret_u8_s16(vget_low_s16(out1)),
624                 vreinterpret_u8_s16(vget_high_s16(out1)));
625    INIT_VECTOR4(shuffles,
626                 vtbl4_u8(all_out, vld1_u8(kShuffles[0])),
627                 vtbl4_u8(all_out, vld1_u8(kShuffles[1])),
628                 vtbl4_u8(all_out, vld1_u8(kShuffles[2])),
629                 vtbl4_u8(all_out, vld1_u8(kShuffles[3])));
630  #endif
631    vst1_u8((uint8_t*)(out +  0), shuffles.val[0]);
632    vst1_u8((uint8_t*)(out +  4), shuffles.val[1]);
633    vst1_u8((uint8_t*)(out +  8), shuffles.val[2]);
634    vst1_u8((uint8_t*)(out + 12), shuffles.val[3]);
635    if (*(uint64_t*)(out +  0) != 0) return 1;
636    if (*(uint64_t*)(out +  4) != 0) return 1;
637    if (*(uint64_t*)(out +  8) != 0) return 1;
638    if (*(uint64_t*)(out + 12) != 0) return 1;
639    return 0;
640  }
641  static int Quantize2Blocks_NEON(int16_t in[32], int16_t out[32],
642                                  const VP8Matrix* const mtx) {
643    int nz;
644    nz  = QuantizeBlock_NEON(in + 0 * 16, out + 0 * 16, mtx) << 0;
645    nz |= QuantizeBlock_NEON(in + 1 * 16, out + 1 * 16, mtx) << 1;
646    return nz;
647  }
648  #endif   
649  extern void VP8EncDspInitNEON(void);
650  WEBP_TSAN_IGNORE_FUNCTION void VP8EncDspInitNEON(void) {
651    VP8ITransform = ITransform_NEON;
652    VP8FTransform = FTransform_NEON;
653    VP8FTransformWHT = FTransformWHT_NEON;
654    VP8TDisto4x4 = Disto4x4_NEON;
655    VP8TDisto16x16 = Disto16x16_NEON;
656    VP8CollectHistogram = CollectHistogram_NEON;
657    VP8SSE16x16 = SSE16x16_NEON;
658    VP8SSE16x8 = SSE16x8_NEON;
659    VP8SSE8x8 = SSE8x8_NEON;
<span onclick='openModal()' class='match'>660    VP8SSE4x4 = SSE4x4_NEON;
661  #if !defined(WORK_AROUND_GCC)
662    VP8EncQuantizeBlock = QuantizeBlock_NEON;
663    VP8EncQuantize2Blocks = Quantize2Blocks_NEON;
</span>664  #endif
665  }
666  #else  
667  WEBP_DSP_INIT_STUB(VP8EncDspInitNEON)
668  #endif  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-enc_mips32.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-enc_neon.c</div>
                </div>
                <div class="column column_space"><pre><code>543    VP8TDisto16x16 = Disto16x16_MIPS32;
544  #if !defined(WORK_AROUND_GCC)
545    VP8SSE16x16 = SSE16x16_MIPS32;
546    VP8SSE8x8 = SSE8x8_MIPS32;
</pre></code></div>
                <div class="column column_space"><pre><code>660    VP8SSE4x4 = SSE4x4_NEON;
661  #if !defined(WORK_AROUND_GCC)
662    VP8EncQuantizeBlock = QuantizeBlock_NEON;
663    VP8EncQuantize2Blocks = Quantize2Blocks_NEON;
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    