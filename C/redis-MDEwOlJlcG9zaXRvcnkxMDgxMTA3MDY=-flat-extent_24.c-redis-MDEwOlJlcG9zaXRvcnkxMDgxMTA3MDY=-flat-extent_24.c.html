
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 22, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-extent_24.c</h3>
            <pre><code>1  #define JEMALLOC_EXTENT_C_
2  #include "jemalloc/internal/jemalloc_preamble.h"
3  #include "jemalloc/internal/jemalloc_internal_includes.h"
4  #include "jemalloc/internal/assert.h"
5  #include "jemalloc/internal/extent_dss.h"
6  #include "jemalloc/internal/extent_mmap.h"
7  #include "jemalloc/internal/ph.h"
8  #include "jemalloc/internal/rtree.h"
9  #include "jemalloc/internal/mutex.h"
10  #include "jemalloc/internal/mutex_pool.h"
11  rtree_t		extents_rtree;
12  mutex_pool_t	extent_mutex_pool;
13  size_t opt_lg_extent_max_active_fit = LG_EXTENT_MAX_ACTIVE_FIT_DEFAULT;
14  static const bitmap_info_t extents_bitmap_info =
15      BITMAP_INFO_INITIALIZER(SC_NPSIZES+1);
16  static void *extent_alloc_default(extent_hooks_t *extent_hooks, void *new_addr,
17      size_t size, size_t alignment, bool *zero, bool *commit,
18      unsigned arena_ind);
19  static bool extent_dalloc_default(extent_hooks_t *extent_hooks, void *addr,
20      size_t size, bool committed, unsigned arena_ind);
21  static void extent_destroy_default(extent_hooks_t *extent_hooks, void *addr,
22      size_t size, bool committed, unsigned arena_ind);
23  static bool extent_commit_default(extent_hooks_t *extent_hooks, void *addr,
24      size_t size, size_t offset, size_t length, unsigned arena_ind);
25  static bool extent_commit_impl(tsdn_t *tsdn, arena_t *arena,
26      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
27      size_t length, bool growing_retained);
28  static bool extent_decommit_default(extent_hooks_t *extent_hooks,
29      void *addr, size_t size, size_t offset, size_t length, unsigned arena_ind);
30  #ifdef PAGES_CAN_PURGE_LAZY
31  static bool extent_purge_lazy_default(extent_hooks_t *extent_hooks, void *addr,
32      size_t size, size_t offset, size_t length, unsigned arena_ind);
33  #endif
34  static bool extent_purge_lazy_impl(tsdn_t *tsdn, arena_t *arena,
35      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
36      size_t length, bool growing_retained);
37  #ifdef PAGES_CAN_PURGE_FORCED
38  static bool extent_purge_forced_default(extent_hooks_t *extent_hooks,
39      void *addr, size_t size, size_t offset, size_t length, unsigned arena_ind);
40  #endif
41  static bool extent_purge_forced_impl(tsdn_t *tsdn, arena_t *arena,
42      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
43      size_t length, bool growing_retained);
44  static bool extent_split_default(extent_hooks_t *extent_hooks, void *addr,
45      size_t size, size_t size_a, size_t size_b, bool committed,
46      unsigned arena_ind);
47  static extent_t *extent_split_impl(tsdn_t *tsdn, arena_t *arena,
48      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t size_a,
49      szind_t szind_a, bool slab_a, size_t size_b, szind_t szind_b, bool slab_b,
50      bool growing_retained);
51  static bool extent_merge_default(extent_hooks_t *extent_hooks, void *addr_a,
52      size_t size_a, void *addr_b, size_t size_b, bool committed,
53      unsigned arena_ind);
54  static bool extent_merge_impl(tsdn_t *tsdn, arena_t *arena,
55      extent_hooks_t **r_extent_hooks, extent_t *a, extent_t *b,
56      bool growing_retained);
57  const extent_hooks_t	extent_hooks_default = {
58  	extent_alloc_default,
59  	extent_dalloc_default,
60  	extent_destroy_default,
61  	extent_commit_default,
62  	extent_decommit_default
63  #ifdef PAGES_CAN_PURGE_LAZY
64  	,
65  	extent_purge_lazy_default
66  #else
67  	,
68  	NULL
69  #endif
70  #ifdef PAGES_CAN_PURGE_FORCED
71  	,
72  	extent_purge_forced_default
73  #else
74  	,
75  	NULL
76  #endif
77  	,
78  	extent_split_default,
79  	extent_merge_default
80  };
81  static atomic_zu_t curpages;
82  static atomic_zu_t highpages;
83  static void extent_deregister(tsdn_t *tsdn, extent_t *extent);
84  static extent_t *extent_recycle(tsdn_t *tsdn, arena_t *arena,
85      extent_hooks_t **r_extent_hooks, extents_t *extents, void *new_addr,
86      size_t usize, size_t pad, size_t alignment, bool slab, szind_t szind,
87      bool *zero, bool *commit, bool growing_retained);
88  static extent_t *extent_try_coalesce(tsdn_t *tsdn, arena_t *arena,
89      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
90      extent_t *extent, bool *coalesced, bool growing_retained);
91  static void extent_record(tsdn_t *tsdn, arena_t *arena,
92      extent_hooks_t **r_extent_hooks, extents_t *extents, extent_t *extent,
93      bool growing_retained);
94  #define ATTR_NONE &bsol;* does nothing */
95  ph_gen(ATTR_NONE, extent_avail_, extent_tree_t, extent_t, ph_link,
96      extent_esnead_comp)
97  #undef ATTR_NONE
98  typedef enum {
99  	lock_result_success,
100  	lock_result_failure,
101  	lock_result_no_extent
102  } lock_result_t;
103  static lock_result_t
104  extent_rtree_leaf_elm_try_lock(tsdn_t *tsdn, rtree_leaf_elm_t *elm,
105      extent_t **result, bool inactive_only) {
106  	extent_t *extent1 = rtree_leaf_elm_extent_read(tsdn, &extents_rtree,
107  	    elm, true);
108  	if (extent1 == NULL || (inactive_only && rtree_leaf_elm_slab_read(tsdn,
109  	    &extents_rtree, elm, true))) {
110  		return lock_result_no_extent;
111  	}
112  	extent_lock(tsdn, extent1);
113  	extent_t *extent2 = rtree_leaf_elm_extent_read(tsdn,
114  	    &extents_rtree, elm, true);
115  	if (extent1 == extent2) {
116  		*result = extent1;
117  		return lock_result_success;
118  	} else {
119  		extent_unlock(tsdn, extent1);
120  		return lock_result_failure;
121  	}
122  }
123  static extent_t *
124  extent_lock_from_addr(tsdn_t *tsdn, rtree_ctx_t *rtree_ctx, void *addr,
125      bool inactive_only) {
126  	extent_t *ret = NULL;
127  	rtree_leaf_elm_t *elm = rtree_leaf_elm_lookup(tsdn, &extents_rtree,
128  	    rtree_ctx, (uintptr_t)addr, false, false);
129  	if (elm == NULL) {
130  		return NULL;
131  	}
132  	lock_result_t lock_result;
133  	do {
134  		lock_result = extent_rtree_leaf_elm_try_lock(tsdn, elm, &ret,
135  		    inactive_only);
136  	} while (lock_result == lock_result_failure);
137  	return ret;
138  }
139  extent_t *
140  extent_alloc(tsdn_t *tsdn, arena_t *arena) {
141  	malloc_mutex_lock(tsdn, &arena->extent_avail_mtx);
142  	extent_t *extent = extent_avail_first(&arena->extent_avail);
143  	if (extent == NULL) {
144  		malloc_mutex_unlock(tsdn, &arena->extent_avail_mtx);
145  		return base_alloc_extent(tsdn, arena->base);
146  	}
147  	extent_avail_remove(&arena->extent_avail, extent);
148  	atomic_fetch_sub_zu(&arena->extent_avail_cnt, 1, ATOMIC_RELAXED);
149  	malloc_mutex_unlock(tsdn, &arena->extent_avail_mtx);
150  	return extent;
151  }
152  void
153  extent_dalloc(tsdn_t *tsdn, arena_t *arena, extent_t *extent) {
154  	malloc_mutex_lock(tsdn, &arena->extent_avail_mtx);
155  	extent_avail_insert(&arena->extent_avail, extent);
156  	atomic_fetch_add_zu(&arena->extent_avail_cnt, 1, ATOMIC_RELAXED);
157  	malloc_mutex_unlock(tsdn, &arena->extent_avail_mtx);
158  }
159  extent_hooks_t *
160  extent_hooks_get(arena_t *arena) {
161  	return base_extent_hooks_get(arena->base);
162  }
163  extent_hooks_t *
164  extent_hooks_set(tsd_t *tsd, arena_t *arena, extent_hooks_t *extent_hooks) {
165  	background_thread_info_t *info;
166  	if (have_background_thread) {
167  		info = arena_background_thread_info_get(arena);
168  		malloc_mutex_lock(tsd_tsdn(tsd), &info->mtx);
169  	}
170  	extent_hooks_t *ret = base_extent_hooks_set(arena->base, extent_hooks);
171  	if (have_background_thread) {
172  		malloc_mutex_unlock(tsd_tsdn(tsd), &info->mtx);
173  	}
174  	return ret;
175  }
176  static void
177  extent_hooks_assure_initialized(arena_t *arena,
178      extent_hooks_t **r_extent_hooks) {
179  	if (*r_extent_hooks == EXTENT_HOOKS_INITIALIZER) {
180  		*r_extent_hooks = extent_hooks_get(arena);
181  	}
182  }
183  #ifndef JEMALLOC_JET
184  static
185  #endif
186  size_t
187  extent_size_quantize_floor(size_t size) {
188  	size_t ret;
189  	pszind_t pind;
190  	assert(size > 0);
191  	assert((size & PAGE_MASK) == 0);
192  	pind = sz_psz2ind(size - sz_large_pad + 1);
193  	if (pind == 0) {
194  		return size;
195  	}
196  	ret = sz_pind2sz(pind - 1) + sz_large_pad;
197  	assert(ret <= size);
198  	return ret;
199  }
200  #ifndef JEMALLOC_JET
201  static
202  #endif
203  size_t
204  extent_size_quantize_ceil(size_t size) {
205  	size_t ret;
206  	assert(size > 0);
207  	assert(size - sz_large_pad <= SC_LARGE_MAXCLASS);
208  	assert((size & PAGE_MASK) == 0);
209  	ret = extent_size_quantize_floor(size);
210  	if (ret < size) {
211  		ret = sz_pind2sz(sz_psz2ind(ret - sz_large_pad + 1)) +
212  		    sz_large_pad;
213  	}
214  	return ret;
215  }
216  ph_gen(, extent_heap_, extent_heap_t, extent_t, ph_link, extent_snad_comp)
217  bool
218  extents_init(tsdn_t *tsdn, extents_t *extents, extent_state_t state,
219      bool delay_coalesce) {
220  	if (malloc_mutex_init(&extents->mtx, "extents", WITNESS_RANK_EXTENTS,
221  	    malloc_mutex_rank_exclusive)) {
222  		return true;
223  	}
224  	for (unsigned i = 0; i < SC_NPSIZES + 1; i++) {
225  		extent_heap_new(&extents->heaps[i]);
226  	}
227  	bitmap_init(extents->bitmap, &extents_bitmap_info, true);
228  	extent_list_init(&extents->lru);
229  	atomic_store_zu(&extents->npages, 0, ATOMIC_RELAXED);
230  	extents->state = state;
231  	extents->delay_coalesce = delay_coalesce;
232  	return false;
233  }
234  extent_state_t
235  extents_state_get(const extents_t *extents) {
236  	return extents->state;
237  }
238  size_t
239  extents_npages_get(extents_t *extents) {
240  	return atomic_load_zu(&extents->npages, ATOMIC_RELAXED);
241  }
242  size_t
243  extents_nextents_get(extents_t *extents, pszind_t pind) {
244  	return atomic_load_zu(&extents->nextents[pind], ATOMIC_RELAXED);
245  }
246  size_t
247  extents_nbytes_get(extents_t *extents, pszind_t pind) {
248  	return atomic_load_zu(&extents->nbytes[pind], ATOMIC_RELAXED);
249  }
250  static void
251  extents_stats_add(extents_t *extent, pszind_t pind, size_t sz) {
252  	size_t cur = atomic_load_zu(&extent->nextents[pind], ATOMIC_RELAXED);
253  	atomic_store_zu(&extent->nextents[pind], cur + 1, ATOMIC_RELAXED);
254  	cur = atomic_load_zu(&extent->nbytes[pind], ATOMIC_RELAXED);
255  	atomic_store_zu(&extent->nbytes[pind], cur + sz, ATOMIC_RELAXED);
256  }
257  static void
258  extents_stats_sub(extents_t *extent, pszind_t pind, size_t sz) {
259  	size_t cur = atomic_load_zu(&extent->nextents[pind], ATOMIC_RELAXED);
260  	atomic_store_zu(&extent->nextents[pind], cur - 1, ATOMIC_RELAXED);
261  	cur = atomic_load_zu(&extent->nbytes[pind], ATOMIC_RELAXED);
262  	atomic_store_zu(&extent->nbytes[pind], cur - sz, ATOMIC_RELAXED);
263  }
264  static void
265  extents_insert_locked(tsdn_t *tsdn, extents_t *extents, extent_t *extent) {
266  	malloc_mutex_assert_owner(tsdn, &extents->mtx);
267  	assert(extent_state_get(extent) == extents->state);
268  	size_t size = extent_size_get(extent);
269  	size_t psz = extent_size_quantize_floor(size);
270  	pszind_t pind = sz_psz2ind(psz);
271  	if (extent_heap_empty(&extents->heaps[pind])) {
272  		bitmap_unset(extents->bitmap, &extents_bitmap_info,
273  		    (size_t)pind);
274  	}
275  	extent_heap_insert(&extents->heaps[pind], extent);
276  	if (config_stats) {
277  		extents_stats_add(extents, pind, size);
278  	}
279  	extent_list_append(&extents->lru, extent);
280  	size_t npages = size >> LG_PAGE;
281  	size_t cur_extents_npages =
282  	    atomic_load_zu(&extents->npages, ATOMIC_RELAXED);
283  	atomic_store_zu(&extents->npages, cur_extents_npages + npages,
284  	    ATOMIC_RELAXED);
285  }
286  static void
287  extents_remove_locked(tsdn_t *tsdn, extents_t *extents, extent_t *extent) {
288  	malloc_mutex_assert_owner(tsdn, &extents->mtx);
289  	assert(extent_state_get(extent) == extents->state);
290  	size_t size = extent_size_get(extent);
291  	size_t psz = extent_size_quantize_floor(size);
292  	pszind_t pind = sz_psz2ind(psz);
293  	extent_heap_remove(&extents->heaps[pind], extent);
294  	if (config_stats) {
295  		extents_stats_sub(extents, pind, size);
296  	}
297  	if (extent_heap_empty(&extents->heaps[pind])) {
298  		bitmap_set(extents->bitmap, &extents_bitmap_info,
299  		    (size_t)pind);
300  	}
301  	extent_list_remove(&extents->lru, extent);
302  	size_t npages = size >> LG_PAGE;
303  	size_t cur_extents_npages =
304  	    atomic_load_zu(&extents->npages, ATOMIC_RELAXED);
305  	assert(cur_extents_npages >= npages);
306  	atomic_store_zu(&extents->npages,
307  	    cur_extents_npages - (size >> LG_PAGE), ATOMIC_RELAXED);
308  }
309  static extent_t *
310  extents_fit_alignment(extents_t *extents, size_t min_size, size_t max_size,
311      size_t alignment) {
312          pszind_t pind = sz_psz2ind(extent_size_quantize_ceil(min_size));
313          pszind_t pind_max = sz_psz2ind(extent_size_quantize_ceil(max_size));
314  	for (pszind_t i = (pszind_t)bitmap_ffu(extents->bitmap,
315  	    &extents_bitmap_info, (size_t)pind); i < pind_max; i =
316  	    (pszind_t)bitmap_ffu(extents->bitmap, &extents_bitmap_info,
317  	    (size_t)i+1)) {
318  		assert(i < SC_NPSIZES);
319  		assert(!extent_heap_empty(&extents->heaps[i]));
320  		extent_t *extent = extent_heap_first(&extents->heaps[i]);
321  		uintptr_t base = (uintptr_t)extent_base_get(extent);
322  		size_t candidate_size = extent_size_get(extent);
323  		assert(candidate_size >= min_size);
324  		uintptr_t next_align = ALIGNMENT_CEILING((uintptr_t)base,
325  		    PAGE_CEILING(alignment));
326  		if (base > next_align || base + candidate_size <= next_align) {
327  			continue;
328  		}
329  		size_t leadsize = next_align - base;
330  		if (candidate_size - leadsize >= min_size) {
331  			return extent;
332  		}
333  	}
334  	return NULL;
335  }
336  static extent_t *
337  extents_first_fit_locked(tsdn_t *tsdn, arena_t *arena, extents_t *extents,
338      size_t size) {
339  	extent_t *ret = NULL;
340  	pszind_t pind = sz_psz2ind(extent_size_quantize_ceil(size));
341  	if (!maps_coalesce && !opt_retain) {
342  		return extent_heap_empty(&extents->heaps[pind]) ? NULL :
343  		    extent_heap_first(&extents->heaps[pind]);
344  	}
345  	for (pszind_t i = (pszind_t)bitmap_ffu(extents->bitmap,
346  	    &extents_bitmap_info, (size_t)pind);
347  	    i < SC_NPSIZES + 1;
348  	    i = (pszind_t)bitmap_ffu(extents->bitmap, &extents_bitmap_info,
349  	    (size_t)i+1)) {
350  		assert(!extent_heap_empty(&extents->heaps[i]));
351  		extent_t *extent = extent_heap_first(&extents->heaps[i]);
352  		assert(extent_size_get(extent) >= size);
353  		if (extents->delay_coalesce &&
354  		    (sz_pind2sz(i) >> opt_lg_extent_max_active_fit) > size) {
355  			break;
356  		}
357  		if (ret == NULL || extent_snad_comp(extent, ret) < 0) {
358  			ret = extent;
359  		}
360  		if (i == SC_NPSIZES) {
361  			break;
362  		}
363  		assert(i < SC_NPSIZES);
364  	}
365  	return ret;
366  }
367  static extent_t *
368  extents_fit_locked(tsdn_t *tsdn, arena_t *arena, extents_t *extents,
369      size_t esize, size_t alignment) {
370  	malloc_mutex_assert_owner(tsdn, &extents->mtx);
371  	size_t max_size = esize + PAGE_CEILING(alignment) - PAGE;
372  	if (max_size < esize) {
373  		return NULL;
374  	}
375  	extent_t *extent =
376  	    extents_first_fit_locked(tsdn, arena, extents, max_size);
377  	if (alignment > PAGE && extent == NULL) {
378  		extent = extents_fit_alignment(extents, esize, max_size,
379  		    alignment);
380  	}
381  	return extent;
382  }
383  static bool
384  extent_try_delayed_coalesce(tsdn_t *tsdn, arena_t *arena,
385      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
386      extent_t *extent) {
387  	extent_state_set(extent, extent_state_active);
388  	bool coalesced;
389  	extent = extent_try_coalesce(tsdn, arena, r_extent_hooks, rtree_ctx,
390  	    extents, extent, &coalesced, false);
391  	extent_state_set(extent, extents_state_get(extents));
392  	if (!coalesced) {
393  		return true;
394  	}
395  	extents_insert_locked(tsdn, extents, extent);
396  	return false;
397  }
398  extent_t *
399  extents_alloc(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
400      extents_t *extents, void *new_addr, size_t size, size_t pad,
401      size_t alignment, bool slab, szind_t szind, bool *zero, bool *commit) {
402  	assert(size + pad != 0);
403  	assert(alignment != 0);
404  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
405  	    WITNESS_RANK_CORE, 0);
406  	extent_t *extent = extent_recycle(tsdn, arena, r_extent_hooks, extents,
407  	    new_addr, size, pad, alignment, slab, szind, zero, commit, false);
408  	assert(extent == NULL || extent_dumpable_get(extent));
409  	return extent;
410  }
411  void
412  extents_dalloc(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
413      extents_t *extents, extent_t *extent) {
414  	assert(extent_base_get(extent) != NULL);
415  	assert(extent_size_get(extent) != 0);
416  	assert(extent_dumpable_get(extent));
417  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
<span onclick='openModal()' class='match'>418  	    WITNESS_RANK_CORE, 0);
419  	extent_addr_set(extent, extent_base_get(extent));
420  	extent_zeroed_set(extent, false);
421  	extent_record(tsdn, arena, r_extent_hooks, extents, extent, false);
</span>422  }
423  extent_t *
424  extents_evict(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
425      extents_t *extents, size_t npages_min) {
426  	rtree_ctx_t rtree_ctx_fallback;
427  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
428  	malloc_mutex_lock(tsdn, &extents->mtx);
429  	extent_t *extent;
430  	while (true) {
431  		extent = extent_list_first(&extents->lru);
432  		if (extent == NULL) {
433  			goto label_return;
434  		}
435  		size_t extents_npages = atomic_load_zu(&extents->npages,
436  		    ATOMIC_RELAXED);
437  		if (extents_npages <= npages_min) {
438  			extent = NULL;
439  			goto label_return;
440  		}
441  		extents_remove_locked(tsdn, extents, extent);
442  		if (!extents->delay_coalesce) {
443  			break;
444  		}
445  		if (extent_try_delayed_coalesce(tsdn, arena, r_extent_hooks,
446  		    rtree_ctx, extents, extent)) {
447  			break;
448  		}
449  	}
450  	switch (extents_state_get(extents)) {
451  	case extent_state_active:
452  		not_reached();
453  	case extent_state_dirty:
454  	case extent_state_muzzy:
455  		extent_state_set(extent, extent_state_active);
456  		break;
457  	case extent_state_retained:
458  		extent_deregister(tsdn, extent);
459  		break;
460  	default:
461  		not_reached();
462  	}
463  label_return:
464  	malloc_mutex_unlock(tsdn, &extents->mtx);
465  	return extent;
466  }
467  static void
468  extents_abandon_vm(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
469      extents_t *extents, extent_t *extent, bool growing_retained) {
470  	size_t sz = extent_size_get(extent);
471  	if (config_stats) {
472  		arena_stats_accum_zu(&arena->stats.abandoned_vm, sz);
473  	}
474  	if (extents_state_get(extents) == extent_state_dirty) {
475  		if (extent_purge_lazy_impl(tsdn, arena, r_extent_hooks,
476  		    extent, 0, sz, growing_retained)) {
477  			extent_purge_forced_impl(tsdn, arena, r_extent_hooks,
478  			    extent, 0, extent_size_get(extent),
479  			    growing_retained);
480  		}
481  	}
482  	extent_dalloc(tsdn, arena, extent);
483  }
484  void
485  extents_prefork(tsdn_t *tsdn, extents_t *extents) {
486  	malloc_mutex_prefork(tsdn, &extents->mtx);
487  }
488  void
489  extents_postfork_parent(tsdn_t *tsdn, extents_t *extents) {
490  	malloc_mutex_postfork_parent(tsdn, &extents->mtx);
491  }
492  void
493  extents_postfork_child(tsdn_t *tsdn, extents_t *extents) {
494  	malloc_mutex_postfork_child(tsdn, &extents->mtx);
495  }
496  static void
497  extent_deactivate_locked(tsdn_t *tsdn, arena_t *arena, extents_t *extents,
498      extent_t *extent) {
499  	assert(extent_arena_get(extent) == arena);
500  	assert(extent_state_get(extent) == extent_state_active);
501  	extent_state_set(extent, extents_state_get(extents));
502  	extents_insert_locked(tsdn, extents, extent);
503  }
504  static void
505  extent_deactivate(tsdn_t *tsdn, arena_t *arena, extents_t *extents,
506      extent_t *extent) {
507  	malloc_mutex_lock(tsdn, &extents->mtx);
508  	extent_deactivate_locked(tsdn, arena, extents, extent);
509  	malloc_mutex_unlock(tsdn, &extents->mtx);
510  }
511  static void
512  extent_activate_locked(tsdn_t *tsdn, arena_t *arena, extents_t *extents,
513      extent_t *extent) {
514  	assert(extent_arena_get(extent) == arena);
515  	assert(extent_state_get(extent) == extents_state_get(extents));
516  	extents_remove_locked(tsdn, extents, extent);
517  	extent_state_set(extent, extent_state_active);
518  }
519  static bool
520  extent_rtree_leaf_elms_lookup(tsdn_t *tsdn, rtree_ctx_t *rtree_ctx,
521      const extent_t *extent, bool dependent, bool init_missing,
522      rtree_leaf_elm_t **r_elm_a, rtree_leaf_elm_t **r_elm_b) {
523  	*r_elm_a = rtree_leaf_elm_lookup(tsdn, &extents_rtree, rtree_ctx,
524  	    (uintptr_t)extent_base_get(extent), dependent, init_missing);
525  	if (!dependent && *r_elm_a == NULL) {
526  		return true;
527  	}
528  	assert(*r_elm_a != NULL);
529  	*r_elm_b = rtree_leaf_elm_lookup(tsdn, &extents_rtree, rtree_ctx,
530  	    (uintptr_t)extent_last_get(extent), dependent, init_missing);
531  	if (!dependent && *r_elm_b == NULL) {
532  		return true;
533  	}
534  	assert(*r_elm_b != NULL);
535  	return false;
536  }
537  static void
538  extent_rtree_write_acquired(tsdn_t *tsdn, rtree_leaf_elm_t *elm_a,
539      rtree_leaf_elm_t *elm_b, extent_t *extent, szind_t szind, bool slab) {
540  	rtree_leaf_elm_write(tsdn, &extents_rtree, elm_a, extent, szind, slab);
541  	if (elm_b != NULL) {
542  		rtree_leaf_elm_write(tsdn, &extents_rtree, elm_b, extent, szind,
543  		    slab);
544  	}
545  }
546  static void
547  extent_interior_register(tsdn_t *tsdn, rtree_ctx_t *rtree_ctx, extent_t *extent,
548      szind_t szind) {
549  	assert(extent_slab_get(extent));
550  	for (size_t i = 1; i < (extent_size_get(extent) >> LG_PAGE) - 1; i++) {
551  		rtree_write(tsdn, &extents_rtree, rtree_ctx,
552  		    (uintptr_t)extent_base_get(extent) + (uintptr_t)(i <<
553  		    LG_PAGE), extent, szind, true);
554  	}
555  }
556  static void
557  extent_gdump_add(tsdn_t *tsdn, const extent_t *extent) {
558  	cassert(config_prof);
559  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
560  	    WITNESS_RANK_CORE, 0);
561  	if (opt_prof && extent_state_get(extent) == extent_state_active) {
562  		size_t nadd = extent_size_get(extent) >> LG_PAGE;
563  		size_t cur = atomic_fetch_add_zu(&curpages, nadd,
564  		    ATOMIC_RELAXED) + nadd;
565  		size_t high = atomic_load_zu(&highpages, ATOMIC_RELAXED);
566  		while (cur > high && !atomic_compare_exchange_weak_zu(
567  		    &highpages, &high, cur, ATOMIC_RELAXED, ATOMIC_RELAXED)) {
568  		}
569  		if (cur > high && prof_gdump_get_unlocked()) {
570  			prof_gdump(tsdn);
571  		}
572  	}
573  }
574  static void
575  extent_gdump_sub(tsdn_t *tsdn, const extent_t *extent) {
576  	cassert(config_prof);
577  	if (opt_prof && extent_state_get(extent) == extent_state_active) {
578  		size_t nsub = extent_size_get(extent) >> LG_PAGE;
579  		assert(atomic_load_zu(&curpages, ATOMIC_RELAXED) >= nsub);
580  		atomic_fetch_sub_zu(&curpages, nsub, ATOMIC_RELAXED);
581  	}
582  }
583  static bool
584  extent_register_impl(tsdn_t *tsdn, extent_t *extent, bool gdump_add) {
585  	rtree_ctx_t rtree_ctx_fallback;
586  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
587  	rtree_leaf_elm_t *elm_a, *elm_b;
588  	extent_lock(tsdn, extent);
589  	if (extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, extent, false, true,
590  	    &elm_a, &elm_b)) {
591  		extent_unlock(tsdn, extent);
592  		return true;
593  	}
594  	szind_t szind = extent_szind_get_maybe_invalid(extent);
595  	bool slab = extent_slab_get(extent);
596  	extent_rtree_write_acquired(tsdn, elm_a, elm_b, extent, szind, slab);
597  	if (slab) {
598  		extent_interior_register(tsdn, rtree_ctx, extent, szind);
599  	}
600  	extent_unlock(tsdn, extent);
601  	if (config_prof && gdump_add) {
602  		extent_gdump_add(tsdn, extent);
603  	}
604  	return false;
605  }
606  static bool
607  extent_register(tsdn_t *tsdn, extent_t *extent) {
608  	return extent_register_impl(tsdn, extent, true);
609  }
610  static bool
611  extent_register_no_gdump_add(tsdn_t *tsdn, extent_t *extent) {
612  	return extent_register_impl(tsdn, extent, false);
613  }
614  static void
615  extent_reregister(tsdn_t *tsdn, extent_t *extent) {
616  	bool err = extent_register(tsdn, extent);
617  	assert(!err);
618  }
619  static void
620  extent_interior_deregister(tsdn_t *tsdn, rtree_ctx_t *rtree_ctx,
621      extent_t *extent) {
622  	size_t i;
623  	assert(extent_slab_get(extent));
624  	for (i = 1; i < (extent_size_get(extent) >> LG_PAGE) - 1; i++) {
625  		rtree_clear(tsdn, &extents_rtree, rtree_ctx,
626  		    (uintptr_t)extent_base_get(extent) + (uintptr_t)(i <<
627  		    LG_PAGE));
628  	}
629  }
630  static void
631  extent_deregister_impl(tsdn_t *tsdn, extent_t *extent, bool gdump) {
632  	rtree_ctx_t rtree_ctx_fallback;
633  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
634  	rtree_leaf_elm_t *elm_a, *elm_b;
635  	extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, extent, true, false,
636  	    &elm_a, &elm_b);
637  	extent_lock(tsdn, extent);
638  	extent_rtree_write_acquired(tsdn, elm_a, elm_b, NULL, SC_NSIZES, false);
639  	if (extent_slab_get(extent)) {
640  		extent_interior_deregister(tsdn, rtree_ctx, extent);
641  		extent_slab_set(extent, false);
642  	}
643  	extent_unlock(tsdn, extent);
644  	if (config_prof && gdump) {
645  		extent_gdump_sub(tsdn, extent);
646  	}
647  }
648  static void
649  extent_deregister(tsdn_t *tsdn, extent_t *extent) {
650  	extent_deregister_impl(tsdn, extent, true);
651  }
652  static void
653  extent_deregister_no_gdump_sub(tsdn_t *tsdn, extent_t *extent) {
654  	extent_deregister_impl(tsdn, extent, false);
655  }
656  static extent_t *
657  extent_recycle_extract(tsdn_t *tsdn, arena_t *arena,
658      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
659      void *new_addr, size_t size, size_t pad, size_t alignment, bool slab,
660      bool growing_retained) {
661  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
662  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
663  	assert(alignment > 0);
664  	if (config_debug && new_addr != NULL) {
665  		assert(PAGE_ADDR2BASE(new_addr) == new_addr);
666  		assert(pad == 0);
667  		assert(alignment <= PAGE);
668  	}
669  	size_t esize = size + pad;
670  	malloc_mutex_lock(tsdn, &extents->mtx);
671  	extent_hooks_assure_initialized(arena, r_extent_hooks);
672  	extent_t *extent;
673  	if (new_addr != NULL) {
674  		extent = extent_lock_from_addr(tsdn, rtree_ctx, new_addr,
675  		    false);
676  		if (extent != NULL) {
677  			extent_t *unlock_extent = extent;
678  			assert(extent_base_get(extent) == new_addr);
679  			if (extent_arena_get(extent) != arena ||
680  			    extent_size_get(extent) < esize ||
681  			    extent_state_get(extent) !=
682  			    extents_state_get(extents)) {
683  				extent = NULL;
684  			}
685  			extent_unlock(tsdn, unlock_extent);
686  		}
687  	} else {
688  		extent = extents_fit_locked(tsdn, arena, extents, esize,
689  		    alignment);
690  	}
691  	if (extent == NULL) {
692  		malloc_mutex_unlock(tsdn, &extents->mtx);
693  		return NULL;
694  	}
695  	extent_activate_locked(tsdn, arena, extents, extent);
696  	malloc_mutex_unlock(tsdn, &extents->mtx);
697  	return extent;
698  }
699  typedef enum {
700  	extent_split_interior_ok,
701  	extent_split_interior_cant_alloc,
702  	extent_split_interior_error
703  } extent_split_interior_result_t;
704  static extent_split_interior_result_t
705  extent_split_interior(tsdn_t *tsdn, arena_t *arena,
706      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx,
707      extent_t **extent, extent_t **lead, extent_t **trail,
708      extent_t **to_leak, extent_t **to_salvage,
709      void *new_addr, size_t size, size_t pad, size_t alignment, bool slab,
710      szind_t szind, bool growing_retained) {
711  	size_t esize = size + pad;
712  	size_t leadsize = ALIGNMENT_CEILING((uintptr_t)extent_base_get(*extent),
713  	    PAGE_CEILING(alignment)) - (uintptr_t)extent_base_get(*extent);
714  	assert(new_addr == NULL || leadsize == 0);
715  	if (extent_size_get(*extent) < leadsize + esize) {
716  		return extent_split_interior_cant_alloc;
717  	}
718  	size_t trailsize = extent_size_get(*extent) - leadsize - esize;
719  	*lead = NULL;
720  	*trail = NULL;
721  	*to_leak = NULL;
722  	*to_salvage = NULL;
723  	if (leadsize != 0) {
724  		*lead = *extent;
725  		*extent = extent_split_impl(tsdn, arena, r_extent_hooks,
726  		    *lead, leadsize, SC_NSIZES, false, esize + trailsize, szind,
727  		    slab, growing_retained);
728  		if (*extent == NULL) {
729  			*to_leak = *lead;
730  			*lead = NULL;
731  			return extent_split_interior_error;
732  		}
733  	}
734  	if (trailsize != 0) {
735  		*trail = extent_split_impl(tsdn, arena, r_extent_hooks, *extent,
736  		    esize, szind, slab, trailsize, SC_NSIZES, false,
737  		    growing_retained);
738  		if (*trail == NULL) {
739  			*to_leak = *extent;
740  			*to_salvage = *lead;
741  			*lead = NULL;
742  			*extent = NULL;
743  			return extent_split_interior_error;
744  		}
745  	}
746  	if (leadsize == 0 && trailsize == 0) {
747  		extent_szind_set(*extent, szind);
748  		if (szind != SC_NSIZES) {
749  			rtree_szind_slab_update(tsdn, &extents_rtree, rtree_ctx,
750  			    (uintptr_t)extent_addr_get(*extent), szind, slab);
751  			if (slab && extent_size_get(*extent) > PAGE) {
752  				rtree_szind_slab_update(tsdn, &extents_rtree,
753  				    rtree_ctx,
754  				    (uintptr_t)extent_past_get(*extent) -
755  				    (uintptr_t)PAGE, szind, slab);
756  			}
757  		}
758  	}
759  	return extent_split_interior_ok;
760  }
761  static extent_t *
762  extent_recycle_split(tsdn_t *tsdn, arena_t *arena,
763      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
764      void *new_addr, size_t size, size_t pad, size_t alignment, bool slab,
765      szind_t szind, extent_t *extent, bool growing_retained) {
766  	extent_t *lead;
767  	extent_t *trail;
768  	extent_t *to_leak;
769  	extent_t *to_salvage;
770  	extent_split_interior_result_t result = extent_split_interior(
771  	    tsdn, arena, r_extent_hooks, rtree_ctx, &extent, &lead, &trail,
772  	    &to_leak, &to_salvage, new_addr, size, pad, alignment, slab, szind,
773  	    growing_retained);
774  	if (!maps_coalesce && result != extent_split_interior_ok
775  	    && !opt_retain) {
776  		assert(to_leak != NULL && lead == NULL && trail == NULL);
777  		extent_deactivate(tsdn, arena, extents, to_leak);
778  		return NULL;
779  	}
780  	if (result == extent_split_interior_ok) {
781  		if (lead != NULL) {
782  			extent_deactivate(tsdn, arena, extents, lead);
783  		}
784  		if (trail != NULL) {
785  			extent_deactivate(tsdn, arena, extents, trail);
786  		}
787  		return extent;
788  	} else {
789  		assert(result == extent_split_interior_error);
790  		if (to_salvage != NULL) {
791  			extent_deregister(tsdn, to_salvage);
792  		}
793  		if (to_leak != NULL) {
794  			void *leak = extent_base_get(to_leak);
795  			extent_deregister_no_gdump_sub(tsdn, to_leak);
796  			extents_abandon_vm(tsdn, arena, r_extent_hooks, extents,
797  			    to_leak, growing_retained);
798  			assert(extent_lock_from_addr(tsdn, rtree_ctx, leak,
799  			    false) == NULL);
800  		}
801  		return NULL;
802  	}
803  	unreachable();
804  }
805  static bool
806  extent_need_manual_zero(arena_t *arena) {
807  	return (!arena_has_default_hooks(arena) ||
808  		(opt_thp == thp_mode_always));
809  }
810  static extent_t *
811  extent_recycle(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
812      extents_t *extents, void *new_addr, size_t size, size_t pad,
813      size_t alignment, bool slab, szind_t szind, bool *zero, bool *commit,
814      bool growing_retained) {
815  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
816  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
817  	assert(new_addr == NULL || !slab);
818  	assert(pad == 0 || !slab);
819  	assert(!*zero || !slab);
820  	rtree_ctx_t rtree_ctx_fallback;
821  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
822  	extent_t *extent = extent_recycle_extract(tsdn, arena, r_extent_hooks,
823  	    rtree_ctx, extents, new_addr, size, pad, alignment, slab,
824  	    growing_retained);
825  	if (extent == NULL) {
826  		return NULL;
827  	}
828  	extent = extent_recycle_split(tsdn, arena, r_extent_hooks, rtree_ctx,
829  	    extents, new_addr, size, pad, alignment, slab, szind, extent,
830  	    growing_retained);
831  	if (extent == NULL) {
832  		return NULL;
833  	}
834  	if (*commit && !extent_committed_get(extent)) {
835  		if (extent_commit_impl(tsdn, arena, r_extent_hooks, extent,
836  		    0, extent_size_get(extent), growing_retained)) {
837  			extent_record(tsdn, arena, r_extent_hooks, extents,
838  			    extent, growing_retained);
839  			return NULL;
840  		}
841  		if (!extent_need_manual_zero(arena)) {
842  			extent_zeroed_set(extent, true);
843  		}
844  	}
845  	if (extent_committed_get(extent)) {
846  		*commit = true;
847  	}
848  	if (extent_zeroed_get(extent)) {
849  		*zero = true;
850  	}
851  	if (pad != 0) {
852  		extent_addr_randomize(tsdn, extent, alignment);
853  	}
854  	assert(extent_state_get(extent) == extent_state_active);
855  	if (slab) {
856  		extent_slab_set(extent, slab);
857  		extent_interior_register(tsdn, rtree_ctx, extent, szind);
858  	}
859  	if (*zero) {
860  		void *addr = extent_base_get(extent);
861  		if (!extent_zeroed_get(extent)) {
862  			size_t size = extent_size_get(extent);
863  			if (extent_need_manual_zero(arena) ||
864  			    pages_purge_forced(addr, size)) {
865  				memset(addr, 0, size);
866  			}
867  		} else if (config_debug) {
868  			size_t *p = (size_t *)(uintptr_t)addr;
869  			for (size_t i = 0; i < PAGE / sizeof(size_t); i++) {
870  				assert(p[i] == 0);
871  			}
872  		}
873  	}
874  	return extent;
875  }
876  static void *
877  extent_alloc_core(tsdn_t *tsdn, arena_t *arena, void *new_addr, size_t size,
878      size_t alignment, bool *zero, bool *commit, dss_prec_t dss_prec) {
879  	void *ret;
880  	assert(size != 0);
881  	assert(alignment != 0);
882  	if (have_dss && dss_prec == dss_prec_primary && (ret =
883  	    extent_alloc_dss(tsdn, arena, new_addr, size, alignment, zero,
884  	    commit)) != NULL) {
885  		return ret;
886  	}
887  	if ((ret = extent_alloc_mmap(new_addr, size, alignment, zero, commit))
888  	    != NULL) {
889  		return ret;
890  	}
891  	if (have_dss && dss_prec == dss_prec_secondary && (ret =
892  	    extent_alloc_dss(tsdn, arena, new_addr, size, alignment, zero,
893  	    commit)) != NULL) {
894  		return ret;
895  	}
896  	return NULL;
897  }
898  static void *
899  extent_alloc_default_impl(tsdn_t *tsdn, arena_t *arena, void *new_addr,
900      size_t size, size_t alignment, bool *zero, bool *commit) {
901  	void *ret = extent_alloc_core(tsdn, arena, new_addr, size, alignment, zero,
902  	    commit, (dss_prec_t)atomic_load_u(&arena->dss_prec,
903  	    ATOMIC_RELAXED));
904  	if (have_madvise_huge && ret) {
905  		pages_set_thp_state(ret, size);
906  	}
907  	return ret;
908  }
909  static void *
910  extent_alloc_default(extent_hooks_t *extent_hooks, void *new_addr, size_t size,
911      size_t alignment, bool *zero, bool *commit, unsigned arena_ind) {
912  	tsdn_t *tsdn;
913  	arena_t *arena;
914  	tsdn = tsdn_fetch();
915  	arena = arena_get(tsdn, arena_ind, false);
916  	assert(arena != NULL);
917  	return extent_alloc_default_impl(tsdn, arena, new_addr, size,
918  	    ALIGNMENT_CEILING(alignment, PAGE), zero, commit);
919  }
920  static void
921  extent_hook_pre_reentrancy(tsdn_t *tsdn, arena_t *arena) {
922  	tsd_t *tsd = tsdn_null(tsdn) ? tsd_fetch() : tsdn_tsd(tsdn);
923  	if (arena == arena_get(tsd_tsdn(tsd), 0, false)) {
924  		pre_reentrancy(tsd, NULL);
925  	} else {
926  		pre_reentrancy(tsd, arena);
927  	}
928  }
929  static void
930  extent_hook_post_reentrancy(tsdn_t *tsdn) {
931  	tsd_t *tsd = tsdn_null(tsdn) ? tsd_fetch() : tsdn_tsd(tsdn);
932  	post_reentrancy(tsd);
933  }
934  static extent_t *
935  extent_grow_retained(tsdn_t *tsdn, arena_t *arena,
936      extent_hooks_t **r_extent_hooks, size_t size, size_t pad, size_t alignment,
937      bool slab, szind_t szind, bool *zero, bool *commit) {
938  	malloc_mutex_assert_owner(tsdn, &arena->extent_grow_mtx);
939  	assert(pad == 0 || !slab);
940  	assert(!*zero || !slab);
941  	size_t esize = size + pad;
942  	size_t alloc_size_min = esize + PAGE_CEILING(alignment) - PAGE;
943  	if (alloc_size_min < esize) {
944  		goto label_err;
945  	}
946  	pszind_t egn_skip = 0;
947  	size_t alloc_size = sz_pind2sz(arena->extent_grow_next + egn_skip);
948  	while (alloc_size < alloc_size_min) {
949  		egn_skip++;
950  		if (arena->extent_grow_next + egn_skip >=
951  		    sz_psz2ind(SC_LARGE_MAXCLASS)) {
952  			goto label_err;
953  		}
954  		alloc_size = sz_pind2sz(arena->extent_grow_next + egn_skip);
955  	}
956  	extent_t *extent = extent_alloc(tsdn, arena);
957  	if (extent == NULL) {
958  		goto label_err;
959  	}
960  	bool zeroed = false;
961  	bool committed = false;
962  	void *ptr;
963  	if (*r_extent_hooks == &extent_hooks_default) {
964  		ptr = extent_alloc_default_impl(tsdn, arena, NULL,
965  		    alloc_size, PAGE, &zeroed, &committed);
966  	} else {
967  		extent_hook_pre_reentrancy(tsdn, arena);
968  		ptr = (*r_extent_hooks)->alloc(*r_extent_hooks, NULL,
969  		    alloc_size, PAGE, &zeroed, &committed,
970  		    arena_ind_get(arena));
971  		extent_hook_post_reentrancy(tsdn);
972  	}
973  	extent_init(extent, arena, ptr, alloc_size, false, SC_NSIZES,
974  	    arena_extent_sn_next(arena), extent_state_active, zeroed,
975  	    committed, true, EXTENT_IS_HEAD);
976  	if (ptr == NULL) {
977  		extent_dalloc(tsdn, arena, extent);
978  		goto label_err;
979  	}
980  	if (extent_register_no_gdump_add(tsdn, extent)) {
981  		extent_dalloc(tsdn, arena, extent);
982  		goto label_err;
983  	}
984  	if (extent_zeroed_get(extent) && extent_committed_get(extent)) {
985  		*zero = true;
986  	}
987  	if (extent_committed_get(extent)) {
988  		*commit = true;
989  	}
990  	rtree_ctx_t rtree_ctx_fallback;
991  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
992  	extent_t *lead;
993  	extent_t *trail;
994  	extent_t *to_leak;
995  	extent_t *to_salvage;
996  	extent_split_interior_result_t result = extent_split_interior(
997  	    tsdn, arena, r_extent_hooks, rtree_ctx, &extent, &lead, &trail,
998  	    &to_leak, &to_salvage, NULL, size, pad, alignment, slab, szind,
999  	    true);
1000  	if (result == extent_split_interior_ok) {
1001  		if (lead != NULL) {
1002  			extent_record(tsdn, arena, r_extent_hooks,
1003  			    &arena->extents_retained, lead, true);
1004  		}
1005  		if (trail != NULL) {
1006  			extent_record(tsdn, arena, r_extent_hooks,
1007  			    &arena->extents_retained, trail, true);
1008  		}
1009  	} else {
1010  		assert(result == extent_split_interior_error);
1011  		if (to_salvage != NULL) {
1012  			if (config_prof) {
1013  				extent_gdump_add(tsdn, to_salvage);
1014  			}
1015  			extent_record(tsdn, arena, r_extent_hooks,
1016  			    &arena->extents_retained, to_salvage, true);
1017  		}
1018  		if (to_leak != NULL) {
1019  			extent_deregister_no_gdump_sub(tsdn, to_leak);
1020  			extents_abandon_vm(tsdn, arena, r_extent_hooks,
1021  			    &arena->extents_retained, to_leak, true);
1022  		}
1023  		goto label_err;
1024  	}
1025  	if (*commit && !extent_committed_get(extent)) {
1026  		if (extent_commit_impl(tsdn, arena, r_extent_hooks, extent, 0,
1027  		    extent_size_get(extent), true)) {
1028  			extent_record(tsdn, arena, r_extent_hooks,
1029  			    &arena->extents_retained, extent, true);
1030  			goto label_err;
1031  		}
1032  		if (!extent_need_manual_zero(arena)) {
1033  			extent_zeroed_set(extent, true);
1034  		}
1035  	}
1036  	if (arena->extent_grow_next + egn_skip + 1 <=
1037  	    arena->retain_grow_limit) {
1038  		arena->extent_grow_next += egn_skip + 1;
1039  	} else {
1040  		arena->extent_grow_next = arena->retain_grow_limit;
1041  	}
1042  	malloc_mutex_unlock(tsdn, &arena->extent_grow_mtx);
1043  	if (config_prof) {
1044  		extent_gdump_add(tsdn, extent);
1045  	}
1046  	if (pad != 0) {
1047  		extent_addr_randomize(tsdn, extent, alignment);
1048  	}
1049  	if (slab) {
1050  		rtree_ctx_t rtree_ctx_fallback;
1051  		rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn,
1052  		    &rtree_ctx_fallback);
1053  		extent_slab_set(extent, true);
1054  		extent_interior_register(tsdn, rtree_ctx, extent, szind);
1055  	}
1056  	if (*zero && !extent_zeroed_get(extent)) {
1057  		void *addr = extent_base_get(extent);
1058  		size_t size = extent_size_get(extent);
1059  		if (extent_need_manual_zero(arena) ||
1060  		    pages_purge_forced(addr, size)) {
1061  			memset(addr, 0, size);
1062  		}
1063  	}
1064  	return extent;
1065  label_err:
1066  	malloc_mutex_unlock(tsdn, &arena->extent_grow_mtx);
1067  	return NULL;
1068  }
1069  static extent_t *
1070  extent_alloc_retained(tsdn_t *tsdn, arena_t *arena,
1071      extent_hooks_t **r_extent_hooks, void *new_addr, size_t size, size_t pad,
1072      size_t alignment, bool slab, szind_t szind, bool *zero, bool *commit) {
1073  	assert(size != 0);
1074  	assert(alignment != 0);
1075  	malloc_mutex_lock(tsdn, &arena->extent_grow_mtx);
1076  	extent_t *extent = extent_recycle(tsdn, arena, r_extent_hooks,
1077  	    &arena->extents_retained, new_addr, size, pad, alignment, slab,
1078  	    szind, zero, commit, true);
1079  	if (extent != NULL) {
1080  		malloc_mutex_unlock(tsdn, &arena->extent_grow_mtx);
1081  		if (config_prof) {
1082  			extent_gdump_add(tsdn, extent);
1083  		}
1084  	} else if (opt_retain && new_addr == NULL) {
1085  		extent = extent_grow_retained(tsdn, arena, r_extent_hooks, size,
1086  		    pad, alignment, slab, szind, zero, commit);
1087  	} else {
1088  		malloc_mutex_unlock(tsdn, &arena->extent_grow_mtx);
1089  	}
1090  	malloc_mutex_assert_not_owner(tsdn, &arena->extent_grow_mtx);
1091  	return extent;
1092  }
1093  static extent_t *
1094  extent_alloc_wrapper_hard(tsdn_t *tsdn, arena_t *arena,
1095      extent_hooks_t **r_extent_hooks, void *new_addr, size_t size, size_t pad,
1096      size_t alignment, bool slab, szind_t szind, bool *zero, bool *commit) {
1097  	size_t esize = size + pad;
1098  	extent_t *extent = extent_alloc(tsdn, arena);
1099  	if (extent == NULL) {
1100  		return NULL;
1101  	}
1102  	void *addr;
1103  	size_t palignment = ALIGNMENT_CEILING(alignment, PAGE);
1104  	if (*r_extent_hooks == &extent_hooks_default) {
1105  		addr = extent_alloc_default_impl(tsdn, arena, new_addr, esize,
1106  		    palignment, zero, commit);
1107  	} else {
1108  		extent_hook_pre_reentrancy(tsdn, arena);
1109  		addr = (*r_extent_hooks)->alloc(*r_extent_hooks, new_addr,
1110  		    esize, palignment, zero, commit, arena_ind_get(arena));
1111  		extent_hook_post_reentrancy(tsdn);
1112  	}
1113  	if (addr == NULL) {
1114  		extent_dalloc(tsdn, arena, extent);
1115  		return NULL;
1116  	}
1117  	extent_init(extent, arena, addr, esize, slab, szind,
1118  	    arena_extent_sn_next(arena), extent_state_active, *zero, *commit,
1119  	    true, EXTENT_NOT_HEAD);
1120  	if (pad != 0) {
1121  		extent_addr_randomize(tsdn, extent, alignment);
1122  	}
1123  	if (extent_register(tsdn, extent)) {
1124  		extent_dalloc(tsdn, arena, extent);
1125  		return NULL;
1126  	}
1127  	return extent;
1128  }
1129  extent_t *
1130  extent_alloc_wrapper(tsdn_t *tsdn, arena_t *arena,
1131      extent_hooks_t **r_extent_hooks, void *new_addr, size_t size, size_t pad,
1132      size_t alignment, bool slab, szind_t szind, bool *zero, bool *commit) {
1133  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1134  	    WITNESS_RANK_CORE, 0);
1135  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1136  	extent_t *extent = extent_alloc_retained(tsdn, arena, r_extent_hooks,
1137  	    new_addr, size, pad, alignment, slab, szind, zero, commit);
1138  	if (extent == NULL) {
1139  		if (opt_retain && new_addr != NULL) {
1140  			return NULL;
1141  		}
1142  		extent = extent_alloc_wrapper_hard(tsdn, arena, r_extent_hooks,
1143  		    new_addr, size, pad, alignment, slab, szind, zero, commit);
1144  	}
1145  	assert(extent == NULL || extent_dumpable_get(extent));
1146  	return extent;
1147  }
1148  static bool
1149  extent_can_coalesce(arena_t *arena, extents_t *extents, const extent_t *inner,
1150      const extent_t *outer) {
1151  	assert(extent_arena_get(inner) == arena);
1152  	if (extent_arena_get(outer) != arena) {
1153  		return false;
1154  	}
1155  	assert(extent_state_get(inner) == extent_state_active);
1156  	if (extent_state_get(outer) != extents->state) {
1157  		return false;
1158  	}
1159  	if (extent_committed_get(inner) != extent_committed_get(outer)) {
1160  		return false;
1161  	}
1162  	return true;
1163  }
1164  static bool
1165  extent_coalesce(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
1166      extents_t *extents, extent_t *inner, extent_t *outer, bool forward,
1167      bool growing_retained) {
1168  	assert(extent_can_coalesce(arena, extents, inner, outer));
1169  	extent_activate_locked(tsdn, arena, extents, outer);
1170  	malloc_mutex_unlock(tsdn, &extents->mtx);
1171  	bool err = extent_merge_impl(tsdn, arena, r_extent_hooks,
1172  	    forward ? inner : outer, forward ? outer : inner, growing_retained);
1173  	malloc_mutex_lock(tsdn, &extents->mtx);
1174  	if (err) {
1175  		extent_deactivate_locked(tsdn, arena, extents, outer);
1176  	}
1177  	return err;
1178  }
1179  static extent_t *
1180  extent_try_coalesce_impl(tsdn_t *tsdn, arena_t *arena,
1181      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
1182      extent_t *extent, bool *coalesced, bool growing_retained,
1183      bool inactive_only) {
1184  	bool again;
1185  	do {
1186  		again = false;
1187  		extent_t *next = extent_lock_from_addr(tsdn, rtree_ctx,
1188  		    extent_past_get(extent), inactive_only);
1189  		if (next != NULL) {
1190  			bool can_coalesce = extent_can_coalesce(arena, extents,
1191  			    extent, next);
1192  			extent_unlock(tsdn, next);
1193  			if (can_coalesce && !extent_coalesce(tsdn, arena,
1194  			    r_extent_hooks, extents, extent, next, true,
1195  			    growing_retained)) {
1196  				if (extents->delay_coalesce) {
1197  					*coalesced = true;
1198  					return extent;
1199  				}
1200  				again = true;
1201  			}
1202  		}
1203  		extent_t *prev = extent_lock_from_addr(tsdn, rtree_ctx,
1204  		    extent_before_get(extent), inactive_only);
1205  		if (prev != NULL) {
1206  			bool can_coalesce = extent_can_coalesce(arena, extents,
1207  			    extent, prev);
1208  			extent_unlock(tsdn, prev);
1209  			if (can_coalesce && !extent_coalesce(tsdn, arena,
1210  			    r_extent_hooks, extents, extent, prev, false,
1211  			    growing_retained)) {
1212  				extent = prev;
1213  				if (extents->delay_coalesce) {
1214  					*coalesced = true;
1215  					return extent;
1216  				}
1217  				again = true;
1218  			}
1219  		}
1220  	} while (again);
1221  	if (extents->delay_coalesce) {
1222  		*coalesced = false;
1223  	}
1224  	return extent;
1225  }
1226  static extent_t *
1227  extent_try_coalesce(tsdn_t *tsdn, arena_t *arena,
1228      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
1229      extent_t *extent, bool *coalesced, bool growing_retained) {
1230  	return extent_try_coalesce_impl(tsdn, arena, r_extent_hooks, rtree_ctx,
1231  	    extents, extent, coalesced, growing_retained, false);
1232  }
1233  static extent_t *
1234  extent_try_coalesce_large(tsdn_t *tsdn, arena_t *arena,
1235      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
1236      extent_t *extent, bool *coalesced, bool growing_retained) {
1237  	return extent_try_coalesce_impl(tsdn, arena, r_extent_hooks, rtree_ctx,
1238  	    extents, extent, coalesced, growing_retained, true);
1239  }
1240  static void
1241  extent_record(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
1242      extents_t *extents, extent_t *extent, bool growing_retained) {
1243  	rtree_ctx_t rtree_ctx_fallback;
1244  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
1245  	assert((extents_state_get(extents) != extent_state_dirty &&
1246  	    extents_state_get(extents) != extent_state_muzzy) ||
1247  	    !extent_zeroed_get(extent));
1248  	malloc_mutex_lock(tsdn, &extents->mtx);
1249  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1250  	extent_szind_set(extent, SC_NSIZES);
1251  	if (extent_slab_get(extent)) {
1252  		extent_interior_deregister(tsdn, rtree_ctx, extent);
1253  		extent_slab_set(extent, false);
1254  	}
1255  	assert(rtree_extent_read(tsdn, &extents_rtree, rtree_ctx,
1256  	    (uintptr_t)extent_base_get(extent), true) == extent);
1257  	if (!extents->delay_coalesce) {
1258  		extent = extent_try_coalesce(tsdn, arena, r_extent_hooks,
1259  		    rtree_ctx, extents, extent, NULL, growing_retained);
1260  	} else if (extent_size_get(extent) >= SC_LARGE_MINCLASS) {
1261  		assert(extents == &arena->extents_dirty);
1262  		bool coalesced;
1263  		do {
1264  			assert(extent_state_get(extent) == extent_state_active);
1265  			extent = extent_try_coalesce_large(tsdn, arena,
1266  			    r_extent_hooks, rtree_ctx, extents, extent,
1267  			    &coalesced, growing_retained);
1268  		} while (coalesced);
1269  		if (extent_size_get(extent) >= oversize_threshold) {
1270  			malloc_mutex_unlock(tsdn, &extents->mtx);
1271  			arena_decay_extent(tsdn, arena, r_extent_hooks, extent);
1272  			return;
1273  		}
1274  	}
1275  	extent_deactivate_locked(tsdn, arena, extents, extent);
1276  	malloc_mutex_unlock(tsdn, &extents->mtx);
1277  }
1278  void
1279  extent_dalloc_gap(tsdn_t *tsdn, arena_t *arena, extent_t *extent) {
1280  	extent_hooks_t *extent_hooks = EXTENT_HOOKS_INITIALIZER;
1281  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1282  	    WITNESS_RANK_CORE, 0);
1283  	if (extent_register(tsdn, extent)) {
1284  		extent_dalloc(tsdn, arena, extent);
1285  		return;
1286  	}
1287  	extent_dalloc_wrapper(tsdn, arena, &extent_hooks, extent);
1288  }
1289  static bool
1290  extent_may_dalloc(void) {
1291  	return !opt_retain;
1292  }
1293  static bool
1294  extent_dalloc_default_impl(void *addr, size_t size) {
1295  	if (!have_dss || !extent_in_dss(addr)) {
1296  		return extent_dalloc_mmap(addr, size);
1297  	}
1298  	return true;
1299  }
1300  static bool
1301  extent_dalloc_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1302      bool committed, unsigned arena_ind) {
1303  	return extent_dalloc_default_impl(addr, size);
1304  }
1305  static bool
1306  extent_dalloc_wrapper_try(tsdn_t *tsdn, arena_t *arena,
1307      extent_hooks_t **r_extent_hooks, extent_t *extent) {
1308  	bool err;
1309  	assert(extent_base_get(extent) != NULL);
1310  	assert(extent_size_get(extent) != 0);
1311  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1312  	    WITNESS_RANK_CORE, 0);
1313  	extent_addr_set(extent, extent_base_get(extent));
1314  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1315  	if (*r_extent_hooks == &extent_hooks_default) {
1316  		err = extent_dalloc_default_impl(extent_base_get(extent),
1317  		    extent_size_get(extent));
1318  	} else {
1319  		extent_hook_pre_reentrancy(tsdn, arena);
1320  		err = ((*r_extent_hooks)->dalloc == NULL ||
1321  		    (*r_extent_hooks)->dalloc(*r_extent_hooks,
1322  		    extent_base_get(extent), extent_size_get(extent),
1323  		    extent_committed_get(extent), arena_ind_get(arena)));
1324  		extent_hook_post_reentrancy(tsdn);
1325  	}
1326  	if (!err) {
1327  		extent_dalloc(tsdn, arena, extent);
1328  	}
1329  	return err;
1330  }
1331  void
1332  extent_dalloc_wrapper(tsdn_t *tsdn, arena_t *arena,
1333      extent_hooks_t **r_extent_hooks, extent_t *extent) {
1334  	assert(extent_dumpable_get(extent));
1335  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1336  	    WITNESS_RANK_CORE, 0);
1337  	if (*r_extent_hooks != &extent_hooks_default || extent_may_dalloc()) {
1338  		extent_deregister(tsdn, extent);
1339  		if (!extent_dalloc_wrapper_try(tsdn, arena, r_extent_hooks,
1340  		    extent)) {
1341  			return;
1342  		}
1343  		extent_reregister(tsdn, extent);
1344  	}
1345  	if (*r_extent_hooks != &extent_hooks_default) {
1346  		extent_hook_pre_reentrancy(tsdn, arena);
1347  	}
1348  	bool zeroed;
1349  	if (!extent_committed_get(extent)) {
1350  		zeroed = true;
1351  	} else if (!extent_decommit_wrapper(tsdn, arena, r_extent_hooks, extent,
1352  	    0, extent_size_get(extent))) {
1353  		zeroed = true;
1354  	} else if ((*r_extent_hooks)->purge_forced != NULL &&
1355  	    !(*r_extent_hooks)->purge_forced(*r_extent_hooks,
1356  	    extent_base_get(extent), extent_size_get(extent), 0,
1357  	    extent_size_get(extent), arena_ind_get(arena))) {
1358  		zeroed = true;
1359  	} else if (extent_state_get(extent) == extent_state_muzzy ||
1360  	    ((*r_extent_hooks)->purge_lazy != NULL &&
1361  	    !(*r_extent_hooks)->purge_lazy(*r_extent_hooks,
1362  	    extent_base_get(extent), extent_size_get(extent), 0,
1363  	    extent_size_get(extent), arena_ind_get(arena)))) {
1364  		zeroed = false;
1365  	} else {
1366  		zeroed = false;
1367  	}
1368  	if (*r_extent_hooks != &extent_hooks_default) {
1369  		extent_hook_post_reentrancy(tsdn);
1370  	}
1371  	extent_zeroed_set(extent, zeroed);
1372  	if (config_prof) {
1373  		extent_gdump_sub(tsdn, extent);
1374  	}
1375  	extent_record(tsdn, arena, r_extent_hooks, &arena->extents_retained,
1376  	    extent, false);
1377  }
1378  static void
1379  extent_destroy_default_impl(void *addr, size_t size) {
1380  	if (!have_dss || !extent_in_dss(addr)) {
1381  		pages_unmap(addr, size);
1382  	}
1383  }
1384  static void
1385  extent_destroy_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1386      bool committed, unsigned arena_ind) {
1387  	extent_destroy_default_impl(addr, size);
1388  }
1389  void
1390  extent_destroy_wrapper(tsdn_t *tsdn, arena_t *arena,
1391      extent_hooks_t **r_extent_hooks, extent_t *extent) {
1392  	assert(extent_base_get(extent) != NULL);
1393  	assert(extent_size_get(extent) != 0);
1394  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1395  	    WITNESS_RANK_CORE, 0);
1396  	extent_deregister(tsdn, extent);
1397  	extent_addr_set(extent, extent_base_get(extent));
1398  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1399  	if (*r_extent_hooks == &extent_hooks_default) {
1400  		extent_destroy_default_impl(extent_base_get(extent),
1401  		    extent_size_get(extent));
1402  	} else if ((*r_extent_hooks)->destroy != NULL) {
1403  		extent_hook_pre_reentrancy(tsdn, arena);
1404  		(*r_extent_hooks)->destroy(*r_extent_hooks,
1405  		    extent_base_get(extent), extent_size_get(extent),
1406  		    extent_committed_get(extent), arena_ind_get(arena));
1407  		extent_hook_post_reentrancy(tsdn);
1408  	}
1409  	extent_dalloc(tsdn, arena, extent);
1410  }
1411  static bool
1412  extent_commit_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1413      size_t offset, size_t length, unsigned arena_ind) {
1414  	return pages_commit((void *)((uintptr_t)addr + (uintptr_t)offset),
1415  	    length);
1416  }
1417  static bool
1418  extent_commit_impl(tsdn_t *tsdn, arena_t *arena,
1419      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1420      size_t length, bool growing_retained) {
1421  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1422  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
1423  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1424  	if (*r_extent_hooks != &extent_hooks_default) {
1425  		extent_hook_pre_reentrancy(tsdn, arena);
1426  	}
1427  	bool err = ((*r_extent_hooks)->commit == NULL ||
1428  	    (*r_extent_hooks)->commit(*r_extent_hooks, extent_base_get(extent),
1429  	    extent_size_get(extent), offset, length, arena_ind_get(arena)));
1430  	if (*r_extent_hooks != &extent_hooks_default) {
1431  		extent_hook_post_reentrancy(tsdn);
1432  	}
1433  	extent_committed_set(extent, extent_committed_get(extent) || !err);
1434  	return err;
1435  }
1436  bool
1437  extent_commit_wrapper(tsdn_t *tsdn, arena_t *arena,
1438      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1439      size_t length) {
1440  	return extent_commit_impl(tsdn, arena, r_extent_hooks, extent, offset,
1441  	    length, false);
1442  }
1443  static bool
1444  extent_decommit_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1445      size_t offset, size_t length, unsigned arena_ind) {
1446  	return pages_decommit((void *)((uintptr_t)addr + (uintptr_t)offset),
1447  	    length);
1448  }
1449  bool
1450  extent_decommit_wrapper(tsdn_t *tsdn, arena_t *arena,
1451      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1452      size_t length) {
1453  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1454  	    WITNESS_RANK_CORE, 0);
1455  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1456  	if (*r_extent_hooks != &extent_hooks_default) {
1457  		extent_hook_pre_reentrancy(tsdn, arena);
1458  	}
1459  	bool err = ((*r_extent_hooks)->decommit == NULL ||
1460  	    (*r_extent_hooks)->decommit(*r_extent_hooks,
1461  	    extent_base_get(extent), extent_size_get(extent), offset, length,
1462  	    arena_ind_get(arena)));
1463  	if (*r_extent_hooks != &extent_hooks_default) {
1464  		extent_hook_post_reentrancy(tsdn);
1465  	}
1466  	extent_committed_set(extent, extent_committed_get(extent) && err);
1467  	return err;
1468  }
1469  #ifdef PAGES_CAN_PURGE_LAZY
1470  static bool
1471  extent_purge_lazy_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1472      size_t offset, size_t length, unsigned arena_ind) {
1473  	assert(addr != NULL);
1474  	assert((offset & PAGE_MASK) == 0);
1475  	assert(length != 0);
1476  	assert((length & PAGE_MASK) == 0);
1477  	return pages_purge_lazy((void *)((uintptr_t)addr + (uintptr_t)offset),
1478  	    length);
1479  }
1480  #endif
1481  static bool
1482  extent_purge_lazy_impl(tsdn_t *tsdn, arena_t *arena,
1483      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1484      size_t length, bool growing_retained) {
1485  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1486  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
1487  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1488  	if ((*r_extent_hooks)->purge_lazy == NULL) {
1489  		return true;
1490  	}
1491  	if (*r_extent_hooks != &extent_hooks_default) {
1492  		extent_hook_pre_reentrancy(tsdn, arena);
1493  	}
1494  	bool err = (*r_extent_hooks)->purge_lazy(*r_extent_hooks,
1495  	    extent_base_get(extent), extent_size_get(extent), offset, length,
1496  	    arena_ind_get(arena));
1497  	if (*r_extent_hooks != &extent_hooks_default) {
1498  		extent_hook_post_reentrancy(tsdn);
1499  	}
1500  	return err;
1501  }
1502  bool
1503  extent_purge_lazy_wrapper(tsdn_t *tsdn, arena_t *arena,
1504      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1505      size_t length) {
1506  	return extent_purge_lazy_impl(tsdn, arena, r_extent_hooks, extent,
1507  	    offset, length, false);
1508  }
1509  #ifdef PAGES_CAN_PURGE_FORCED
1510  static bool
1511  extent_purge_forced_default(extent_hooks_t *extent_hooks, void *addr,
1512      size_t size, size_t offset, size_t length, unsigned arena_ind) {
1513  	assert(addr != NULL);
1514  	assert((offset & PAGE_MASK) == 0);
1515  	assert(length != 0);
1516  	assert((length & PAGE_MASK) == 0);
1517  	return pages_purge_forced((void *)((uintptr_t)addr +
1518  	    (uintptr_t)offset), length);
1519  }
1520  #endif
1521  static bool
1522  extent_purge_forced_impl(tsdn_t *tsdn, arena_t *arena,
1523      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1524      size_t length, bool growing_retained) {
1525  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1526  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
1527  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1528  	if ((*r_extent_hooks)->purge_forced == NULL) {
1529  		return true;
1530  	}
1531  	if (*r_extent_hooks != &extent_hooks_default) {
1532  		extent_hook_pre_reentrancy(tsdn, arena);
1533  	}
1534  	bool err = (*r_extent_hooks)->purge_forced(*r_extent_hooks,
1535  	    extent_base_get(extent), extent_size_get(extent), offset, length,
1536  	    arena_ind_get(arena));
1537  	if (*r_extent_hooks != &extent_hooks_default) {
1538  		extent_hook_post_reentrancy(tsdn);
1539  	}
1540  	return err;
1541  }
1542  bool
1543  extent_purge_forced_wrapper(tsdn_t *tsdn, arena_t *arena,
1544      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1545      size_t length) {
1546  	return extent_purge_forced_impl(tsdn, arena, r_extent_hooks, extent,
1547  	    offset, length, false);
1548  }
1549  static bool
1550  extent_split_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1551      size_t size_a, size_t size_b, bool committed, unsigned arena_ind) {
1552  	if (!maps_coalesce) {
1553  		return !opt_retain;
1554  	}
1555  	return false;
1556  }
1557  static extent_t *
1558  extent_split_impl(tsdn_t *tsdn, arena_t *arena,
1559      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t size_a,
1560      szind_t szind_a, bool slab_a, size_t size_b, szind_t szind_b, bool slab_b,
1561      bool growing_retained) {
1562  	assert(extent_size_get(extent) == size_a + size_b);
1563  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1564  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
1565  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1566  	if ((*r_extent_hooks)->split == NULL) {
1567  		return NULL;
1568  	}
1569  	extent_t *trail = extent_alloc(tsdn, arena);
1570  	if (trail == NULL) {
1571  		goto label_error_a;
1572  	}
1573  	extent_init(trail, arena, (void *)((uintptr_t)extent_base_get(extent) +
1574  	    size_a), size_b, slab_b, szind_b, extent_sn_get(extent),
1575  	    extent_state_get(extent), extent_zeroed_get(extent),
1576  	    extent_committed_get(extent), extent_dumpable_get(extent),
1577  	    EXTENT_NOT_HEAD);
1578  	rtree_ctx_t rtree_ctx_fallback;
1579  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
1580  	rtree_leaf_elm_t *lead_elm_a, *lead_elm_b;
1581  	{
1582  		extent_t lead;
1583  		extent_init(&lead, arena, extent_addr_get(extent), size_a,
1584  		    slab_a, szind_a, extent_sn_get(extent),
1585  		    extent_state_get(extent), extent_zeroed_get(extent),
1586  		    extent_committed_get(extent), extent_dumpable_get(extent),
1587  		    EXTENT_NOT_HEAD);
1588  		extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, &lead, false,
1589  		    true, &lead_elm_a, &lead_elm_b);
1590  	}
1591  	rtree_leaf_elm_t *trail_elm_a, *trail_elm_b;
1592  	extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, trail, false, true,
1593  	    &trail_elm_a, &trail_elm_b);
1594  	if (lead_elm_a == NULL || lead_elm_b == NULL || trail_elm_a == NULL
1595  	    || trail_elm_b == NULL) {
1596  		goto label_error_b;
1597  	}
1598  	extent_lock2(tsdn, extent, trail);
1599  	if (*r_extent_hooks != &extent_hooks_default) {
1600  		extent_hook_pre_reentrancy(tsdn, arena);
1601  	}
1602  	bool err = (*r_extent_hooks)->split(*r_extent_hooks, extent_base_get(extent),
1603  	    size_a + size_b, size_a, size_b, extent_committed_get(extent),
1604  	    arena_ind_get(arena));
1605  	if (*r_extent_hooks != &extent_hooks_default) {
1606  		extent_hook_post_reentrancy(tsdn);
1607  	}
1608  	if (err) {
1609  		goto label_error_c;
1610  	}
1611  	extent_size_set(extent, size_a);
1612  	extent_szind_set(extent, szind_a);
1613  	extent_rtree_write_acquired(tsdn, lead_elm_a, lead_elm_b, extent,
1614  	    szind_a, slab_a);
1615  	extent_rtree_write_acquired(tsdn, trail_elm_a, trail_elm_b, trail,
1616  	    szind_b, slab_b);
1617  	extent_unlock2(tsdn, extent, trail);
1618  	return trail;
1619  label_error_c:
1620  	extent_unlock2(tsdn, extent, trail);
1621  label_error_b:
1622  	extent_dalloc(tsdn, arena, trail);
1623  label_error_a:
1624  	return NULL;
1625  }
1626  extent_t *
1627  extent_split_wrapper(tsdn_t *tsdn, arena_t *arena,
1628      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t size_a,
1629      szind_t szind_a, bool slab_a, size_t size_b, szind_t szind_b, bool slab_b) {
1630  	return extent_split_impl(tsdn, arena, r_extent_hooks, extent, size_a,
1631  	    szind_a, slab_a, size_b, szind_b, slab_b, false);
1632  }
1633  static bool
1634  extent_merge_default_impl(void *addr_a, void *addr_b) {
1635  	if (!maps_coalesce && !opt_retain) {
1636  		return true;
1637  	}
1638  	if (have_dss && !extent_dss_mergeable(addr_a, addr_b)) {
1639  		return true;
1640  	}
1641  	return false;
1642  }
1643  static bool
1644  extent_head_no_merge(extent_t *a, extent_t *b) {
1645  	assert(extent_base_get(a) < extent_base_get(b));
1646  	if (maps_coalesce) {
1647  		return false;
1648  	}
1649  	if (!opt_retain) {
1650  		return true;
1651  	}
1652  	if (extent_is_head_get(b)) {
1653  		assert(extent_sn_comp(a, b) != 0);
1654  		return true;
1655  	}
1656  	assert(extent_sn_comp(a, b) == 0);
1657  	return false;
1658  }
1659  static bool
1660  extent_merge_default(extent_hooks_t *extent_hooks, void *addr_a, size_t size_a,
1661      void *addr_b, size_t size_b, bool committed, unsigned arena_ind) {
1662  	if (!maps_coalesce) {
1663  		tsdn_t *tsdn = tsdn_fetch();
1664  		extent_t *a = iealloc(tsdn, addr_a);
1665  		extent_t *b = iealloc(tsdn, addr_b);
1666  		if (extent_head_no_merge(a, b)) {
1667  			return true;
1668  		}
1669  	}
1670  	return extent_merge_default_impl(addr_a, addr_b);
1671  }
1672  static bool
1673  extent_merge_impl(tsdn_t *tsdn, arena_t *arena,
1674      extent_hooks_t **r_extent_hooks, extent_t *a, extent_t *b,
1675      bool growing_retained) {
1676  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1677  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
1678  	assert(extent_base_get(a) < extent_base_get(b));
1679  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1680  	if ((*r_extent_hooks)->merge == NULL || extent_head_no_merge(a, b)) {
1681  		return true;
1682  	}
1683  	bool err;
1684  	if (*r_extent_hooks == &extent_hooks_default) {
1685  		err = extent_merge_default_impl(extent_base_get(a),
1686  		    extent_base_get(b));
1687  	} else {
1688  		extent_hook_pre_reentrancy(tsdn, arena);
1689  		err = (*r_extent_hooks)->merge(*r_extent_hooks,
1690  		    extent_base_get(a), extent_size_get(a), extent_base_get(b),
1691  		    extent_size_get(b), extent_committed_get(a),
1692  		    arena_ind_get(arena));
1693  		extent_hook_post_reentrancy(tsdn);
1694  	}
1695  	if (err) {
1696  		return true;
1697  	}
1698  	rtree_ctx_t rtree_ctx_fallback;
1699  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
1700  	rtree_leaf_elm_t *a_elm_a, *a_elm_b, *b_elm_a, *b_elm_b;
1701  	extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, a, true, false, &a_elm_a,
1702  	    &a_elm_b);
1703  	extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, b, true, false, &b_elm_a,
1704  	    &b_elm_b);
1705  	extent_lock2(tsdn, a, b);
1706  	if (a_elm_b != NULL) {
1707  		rtree_leaf_elm_write(tsdn, &extents_rtree, a_elm_b, NULL,
1708  		    SC_NSIZES, false);
1709  	}
1710  	if (b_elm_b != NULL) {
1711  		rtree_leaf_elm_write(tsdn, &extents_rtree, b_elm_a, NULL,
1712  		    SC_NSIZES, false);
1713  	} else {
1714  		b_elm_b = b_elm_a;
1715  	}
1716  	extent_size_set(a, extent_size_get(a) + extent_size_get(b));
1717  	extent_szind_set(a, SC_NSIZES);
1718  	extent_sn_set(a, (extent_sn_get(a) < extent_sn_get(b)) ?
1719  	    extent_sn_get(a) : extent_sn_get(b));
1720  	extent_zeroed_set(a, extent_zeroed_get(a) && extent_zeroed_get(b));
1721  	extent_rtree_write_acquired(tsdn, a_elm_a, b_elm_b, a, SC_NSIZES,
1722  	    false);
1723  	extent_unlock2(tsdn, a, b);
1724  	extent_dalloc(tsdn, extent_arena_get(b), b);
1725  	return false;
1726  }
1727  bool
1728  extent_merge_wrapper(tsdn_t *tsdn, arena_t *arena,
1729      extent_hooks_t **r_extent_hooks, extent_t *a, extent_t *b) {
1730  	return extent_merge_impl(tsdn, arena, r_extent_hooks, a, b, false);
1731  }
1732  bool
1733  extent_boot(void) {
1734  	if (rtree_new(&extents_rtree, true)) {
1735  		return true;
1736  	}
1737  	if (mutex_pool_init(&extent_mutex_pool, "extent_mutex_pool",
1738  	    WITNESS_RANK_EXTENT_POOL)) {
1739  		return true;
1740  	}
1741  	if (have_dss) {
1742  		extent_dss_boot();
1743  	}
1744  	return false;
1745  }
1746  void
1747  extent_util_stats_get(tsdn_t *tsdn, const void *ptr,
1748      size_t *nfree, size_t *nregs, size_t *size) {
1749  	assert(ptr != NULL && nfree != NULL && nregs != NULL && size != NULL);
1750  	const extent_t *extent = iealloc(tsdn, ptr);
1751  	if (unlikely(extent == NULL)) {
1752  		*nfree = *nregs = *size = 0;
1753  		return;
1754  	}
1755  	*size = extent_size_get(extent);
1756  	if (!extent_slab_get(extent)) {
1757  		*nfree = 0;
1758  		*nregs = 1;
1759  	} else {
1760  		*nfree = extent_nfree_get(extent);
1761  		*nregs = bin_infos[extent_szind_get(extent)].nregs;
1762  		assert(*nfree <= *nregs);
1763  		assert(*nfree * extent_usize_get(extent) <= *size);
1764  	}
1765  }
1766  void
1767  extent_util_stats_verbose_get(tsdn_t *tsdn, const void *ptr,
1768      size_t *nfree, size_t *nregs, size_t *size,
1769      size_t *bin_nfree, size_t *bin_nregs, void **slabcur_addr) {
1770  	assert(ptr != NULL && nfree != NULL && nregs != NULL && size != NULL
1771  	    && bin_nfree != NULL && bin_nregs != NULL && slabcur_addr != NULL);
1772  	const extent_t *extent = iealloc(tsdn, ptr);
1773  	if (unlikely(extent == NULL)) {
1774  		*nfree = *nregs = *size = *bin_nfree = *bin_nregs = 0;
1775  		*slabcur_addr = NULL;
1776  		return;
1777  	}
1778  	*size = extent_size_get(extent);
1779  	if (!extent_slab_get(extent)) {
1780  		*nfree = *bin_nfree = *bin_nregs = 0;
1781  		*nregs = 1;
1782  		*slabcur_addr = NULL;
1783  		return;
1784  	}
1785  	*nfree = extent_nfree_get(extent);
1786  	const szind_t szind = extent_szind_get(extent);
1787  	*nregs = bin_infos[szind].nregs;
1788  	assert(*nfree <= *nregs);
1789  	assert(*nfree * extent_usize_get(extent) <= *size);
1790  	const arena_t *arena = extent_arena_get(extent);
1791  	assert(arena != NULL);
1792  	const unsigned binshard = extent_binshard_get(extent);
1793  	bin_t *bin = &arena->bins[szind].bin_shards[binshard];
1794  	malloc_mutex_lock(tsdn, &bin->lock);
1795  	if (config_stats) {
1796  		*bin_nregs = *nregs * bin->stats.curslabs;
1797  		assert(*bin_nregs >= bin->stats.curregs);
1798  		*bin_nfree = *bin_nregs - bin->stats.curregs;
1799  	} else {
1800  		*bin_nfree = *bin_nregs = 0;
1801  	}
1802  	*slabcur_addr = extent_addr_get(bin->slabcur);
1803  	assert(*slabcur_addr != NULL);
1804  	malloc_mutex_unlock(tsdn, &bin->lock);
1805  }
</code></pre>
        </div>
        <div class="column">
            <h3>redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-extent_24.c</h3>
            <pre><code>1  #define JEMALLOC_EXTENT_C_
2  #include "jemalloc/internal/jemalloc_preamble.h"
3  #include "jemalloc/internal/jemalloc_internal_includes.h"
4  #include "jemalloc/internal/assert.h"
5  #include "jemalloc/internal/extent_dss.h"
6  #include "jemalloc/internal/extent_mmap.h"
7  #include "jemalloc/internal/ph.h"
8  #include "jemalloc/internal/rtree.h"
9  #include "jemalloc/internal/mutex.h"
10  #include "jemalloc/internal/mutex_pool.h"
11  rtree_t		extents_rtree;
12  mutex_pool_t	extent_mutex_pool;
13  size_t opt_lg_extent_max_active_fit = LG_EXTENT_MAX_ACTIVE_FIT_DEFAULT;
14  static const bitmap_info_t extents_bitmap_info =
15      BITMAP_INFO_INITIALIZER(SC_NPSIZES+1);
16  static void *extent_alloc_default(extent_hooks_t *extent_hooks, void *new_addr,
17      size_t size, size_t alignment, bool *zero, bool *commit,
18      unsigned arena_ind);
19  static bool extent_dalloc_default(extent_hooks_t *extent_hooks, void *addr,
20      size_t size, bool committed, unsigned arena_ind);
21  static void extent_destroy_default(extent_hooks_t *extent_hooks, void *addr,
22      size_t size, bool committed, unsigned arena_ind);
23  static bool extent_commit_default(extent_hooks_t *extent_hooks, void *addr,
24      size_t size, size_t offset, size_t length, unsigned arena_ind);
25  static bool extent_commit_impl(tsdn_t *tsdn, arena_t *arena,
26      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
27      size_t length, bool growing_retained);
28  static bool extent_decommit_default(extent_hooks_t *extent_hooks,
29      void *addr, size_t size, size_t offset, size_t length, unsigned arena_ind);
30  #ifdef PAGES_CAN_PURGE_LAZY
31  static bool extent_purge_lazy_default(extent_hooks_t *extent_hooks, void *addr,
32      size_t size, size_t offset, size_t length, unsigned arena_ind);
33  #endif
34  static bool extent_purge_lazy_impl(tsdn_t *tsdn, arena_t *arena,
35      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
36      size_t length, bool growing_retained);
37  #ifdef PAGES_CAN_PURGE_FORCED
38  static bool extent_purge_forced_default(extent_hooks_t *extent_hooks,
39      void *addr, size_t size, size_t offset, size_t length, unsigned arena_ind);
40  #endif
41  static bool extent_purge_forced_impl(tsdn_t *tsdn, arena_t *arena,
42      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
43      size_t length, bool growing_retained);
44  static bool extent_split_default(extent_hooks_t *extent_hooks, void *addr,
45      size_t size, size_t size_a, size_t size_b, bool committed,
46      unsigned arena_ind);
47  static extent_t *extent_split_impl(tsdn_t *tsdn, arena_t *arena,
48      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t size_a,
49      szind_t szind_a, bool slab_a, size_t size_b, szind_t szind_b, bool slab_b,
50      bool growing_retained);
51  static bool extent_merge_default(extent_hooks_t *extent_hooks, void *addr_a,
52      size_t size_a, void *addr_b, size_t size_b, bool committed,
53      unsigned arena_ind);
54  static bool extent_merge_impl(tsdn_t *tsdn, arena_t *arena,
55      extent_hooks_t **r_extent_hooks, extent_t *a, extent_t *b,
56      bool growing_retained);
57  const extent_hooks_t	extent_hooks_default = {
58  	extent_alloc_default,
59  	extent_dalloc_default,
60  	extent_destroy_default,
61  	extent_commit_default,
62  	extent_decommit_default
63  #ifdef PAGES_CAN_PURGE_LAZY
64  	,
65  	extent_purge_lazy_default
66  #else
67  	,
68  	NULL
69  #endif
70  #ifdef PAGES_CAN_PURGE_FORCED
71  	,
72  	extent_purge_forced_default
73  #else
74  	,
75  	NULL
76  #endif
77  	,
78  	extent_split_default,
79  	extent_merge_default
80  };
81  static atomic_zu_t curpages;
82  static atomic_zu_t highpages;
83  static void extent_deregister(tsdn_t *tsdn, extent_t *extent);
84  static extent_t *extent_recycle(tsdn_t *tsdn, arena_t *arena,
85      extent_hooks_t **r_extent_hooks, extents_t *extents, void *new_addr,
86      size_t usize, size_t pad, size_t alignment, bool slab, szind_t szind,
87      bool *zero, bool *commit, bool growing_retained);
88  static extent_t *extent_try_coalesce(tsdn_t *tsdn, arena_t *arena,
89      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
90      extent_t *extent, bool *coalesced, bool growing_retained);
91  static void extent_record(tsdn_t *tsdn, arena_t *arena,
92      extent_hooks_t **r_extent_hooks, extents_t *extents, extent_t *extent,
93      bool growing_retained);
94  #define ATTR_NONE &bsol;* does nothing */
95  ph_gen(ATTR_NONE, extent_avail_, extent_tree_t, extent_t, ph_link,
96      extent_esnead_comp)
97  #undef ATTR_NONE
98  typedef enum {
99  	lock_result_success,
100  	lock_result_failure,
101  	lock_result_no_extent
102  } lock_result_t;
103  static lock_result_t
104  extent_rtree_leaf_elm_try_lock(tsdn_t *tsdn, rtree_leaf_elm_t *elm,
105      extent_t **result, bool inactive_only) {
106  	extent_t *extent1 = rtree_leaf_elm_extent_read(tsdn, &extents_rtree,
107  	    elm, true);
108  	if (extent1 == NULL || (inactive_only && rtree_leaf_elm_slab_read(tsdn,
109  	    &extents_rtree, elm, true))) {
110  		return lock_result_no_extent;
111  	}
112  	extent_lock(tsdn, extent1);
113  	extent_t *extent2 = rtree_leaf_elm_extent_read(tsdn,
114  	    &extents_rtree, elm, true);
115  	if (extent1 == extent2) {
116  		*result = extent1;
117  		return lock_result_success;
118  	} else {
119  		extent_unlock(tsdn, extent1);
120  		return lock_result_failure;
121  	}
122  }
123  static extent_t *
124  extent_lock_from_addr(tsdn_t *tsdn, rtree_ctx_t *rtree_ctx, void *addr,
125      bool inactive_only) {
126  	extent_t *ret = NULL;
127  	rtree_leaf_elm_t *elm = rtree_leaf_elm_lookup(tsdn, &extents_rtree,
128  	    rtree_ctx, (uintptr_t)addr, false, false);
129  	if (elm == NULL) {
130  		return NULL;
131  	}
132  	lock_result_t lock_result;
133  	do {
134  		lock_result = extent_rtree_leaf_elm_try_lock(tsdn, elm, &ret,
135  		    inactive_only);
136  	} while (lock_result == lock_result_failure);
137  	return ret;
138  }
139  extent_t *
140  extent_alloc(tsdn_t *tsdn, arena_t *arena) {
141  	malloc_mutex_lock(tsdn, &arena->extent_avail_mtx);
142  	extent_t *extent = extent_avail_first(&arena->extent_avail);
143  	if (extent == NULL) {
144  		malloc_mutex_unlock(tsdn, &arena->extent_avail_mtx);
145  		return base_alloc_extent(tsdn, arena->base);
146  	}
147  	extent_avail_remove(&arena->extent_avail, extent);
148  	atomic_fetch_sub_zu(&arena->extent_avail_cnt, 1, ATOMIC_RELAXED);
149  	malloc_mutex_unlock(tsdn, &arena->extent_avail_mtx);
150  	return extent;
151  }
152  void
153  extent_dalloc(tsdn_t *tsdn, arena_t *arena, extent_t *extent) {
154  	malloc_mutex_lock(tsdn, &arena->extent_avail_mtx);
155  	extent_avail_insert(&arena->extent_avail, extent);
156  	atomic_fetch_add_zu(&arena->extent_avail_cnt, 1, ATOMIC_RELAXED);
157  	malloc_mutex_unlock(tsdn, &arena->extent_avail_mtx);
158  }
159  extent_hooks_t *
160  extent_hooks_get(arena_t *arena) {
161  	return base_extent_hooks_get(arena->base);
162  }
163  extent_hooks_t *
164  extent_hooks_set(tsd_t *tsd, arena_t *arena, extent_hooks_t *extent_hooks) {
165  	background_thread_info_t *info;
166  	if (have_background_thread) {
167  		info = arena_background_thread_info_get(arena);
168  		malloc_mutex_lock(tsd_tsdn(tsd), &info->mtx);
169  	}
170  	extent_hooks_t *ret = base_extent_hooks_set(arena->base, extent_hooks);
171  	if (have_background_thread) {
172  		malloc_mutex_unlock(tsd_tsdn(tsd), &info->mtx);
173  	}
174  	return ret;
175  }
176  static void
177  extent_hooks_assure_initialized(arena_t *arena,
178      extent_hooks_t **r_extent_hooks) {
179  	if (*r_extent_hooks == EXTENT_HOOKS_INITIALIZER) {
180  		*r_extent_hooks = extent_hooks_get(arena);
181  	}
182  }
183  #ifndef JEMALLOC_JET
184  static
185  #endif
186  size_t
187  extent_size_quantize_floor(size_t size) {
188  	size_t ret;
189  	pszind_t pind;
190  	assert(size > 0);
191  	assert((size & PAGE_MASK) == 0);
192  	pind = sz_psz2ind(size - sz_large_pad + 1);
193  	if (pind == 0) {
194  		return size;
195  	}
196  	ret = sz_pind2sz(pind - 1) + sz_large_pad;
197  	assert(ret <= size);
198  	return ret;
199  }
200  #ifndef JEMALLOC_JET
201  static
202  #endif
203  size_t
204  extent_size_quantize_ceil(size_t size) {
205  	size_t ret;
206  	assert(size > 0);
207  	assert(size - sz_large_pad <= SC_LARGE_MAXCLASS);
208  	assert((size & PAGE_MASK) == 0);
209  	ret = extent_size_quantize_floor(size);
210  	if (ret < size) {
211  		ret = sz_pind2sz(sz_psz2ind(ret - sz_large_pad + 1)) +
212  		    sz_large_pad;
213  	}
214  	return ret;
215  }
216  ph_gen(, extent_heap_, extent_heap_t, extent_t, ph_link, extent_snad_comp)
217  bool
218  extents_init(tsdn_t *tsdn, extents_t *extents, extent_state_t state,
219      bool delay_coalesce) {
220  	if (malloc_mutex_init(&extents->mtx, "extents", WITNESS_RANK_EXTENTS,
221  	    malloc_mutex_rank_exclusive)) {
222  		return true;
223  	}
224  	for (unsigned i = 0; i < SC_NPSIZES + 1; i++) {
225  		extent_heap_new(&extents->heaps[i]);
226  	}
227  	bitmap_init(extents->bitmap, &extents_bitmap_info, true);
228  	extent_list_init(&extents->lru);
229  	atomic_store_zu(&extents->npages, 0, ATOMIC_RELAXED);
230  	extents->state = state;
231  	extents->delay_coalesce = delay_coalesce;
232  	return false;
233  }
234  extent_state_t
235  extents_state_get(const extents_t *extents) {
236  	return extents->state;
237  }
238  size_t
239  extents_npages_get(extents_t *extents) {
240  	return atomic_load_zu(&extents->npages, ATOMIC_RELAXED);
241  }
242  size_t
243  extents_nextents_get(extents_t *extents, pszind_t pind) {
244  	return atomic_load_zu(&extents->nextents[pind], ATOMIC_RELAXED);
245  }
246  size_t
247  extents_nbytes_get(extents_t *extents, pszind_t pind) {
248  	return atomic_load_zu(&extents->nbytes[pind], ATOMIC_RELAXED);
249  }
250  static void
251  extents_stats_add(extents_t *extent, pszind_t pind, size_t sz) {
252  	size_t cur = atomic_load_zu(&extent->nextents[pind], ATOMIC_RELAXED);
253  	atomic_store_zu(&extent->nextents[pind], cur + 1, ATOMIC_RELAXED);
254  	cur = atomic_load_zu(&extent->nbytes[pind], ATOMIC_RELAXED);
255  	atomic_store_zu(&extent->nbytes[pind], cur + sz, ATOMIC_RELAXED);
256  }
257  static void
258  extents_stats_sub(extents_t *extent, pszind_t pind, size_t sz) {
259  	size_t cur = atomic_load_zu(&extent->nextents[pind], ATOMIC_RELAXED);
260  	atomic_store_zu(&extent->nextents[pind], cur - 1, ATOMIC_RELAXED);
261  	cur = atomic_load_zu(&extent->nbytes[pind], ATOMIC_RELAXED);
262  	atomic_store_zu(&extent->nbytes[pind], cur - sz, ATOMIC_RELAXED);
263  }
264  static void
265  extents_insert_locked(tsdn_t *tsdn, extents_t *extents, extent_t *extent) {
266  	malloc_mutex_assert_owner(tsdn, &extents->mtx);
267  	assert(extent_state_get(extent) == extents->state);
268  	size_t size = extent_size_get(extent);
269  	size_t psz = extent_size_quantize_floor(size);
270  	pszind_t pind = sz_psz2ind(psz);
271  	if (extent_heap_empty(&extents->heaps[pind])) {
272  		bitmap_unset(extents->bitmap, &extents_bitmap_info,
273  		    (size_t)pind);
274  	}
275  	extent_heap_insert(&extents->heaps[pind], extent);
276  	if (config_stats) {
277  		extents_stats_add(extents, pind, size);
278  	}
279  	extent_list_append(&extents->lru, extent);
280  	size_t npages = size >> LG_PAGE;
281  	size_t cur_extents_npages =
282  	    atomic_load_zu(&extents->npages, ATOMIC_RELAXED);
283  	atomic_store_zu(&extents->npages, cur_extents_npages + npages,
284  	    ATOMIC_RELAXED);
285  }
286  static void
287  extents_remove_locked(tsdn_t *tsdn, extents_t *extents, extent_t *extent) {
288  	malloc_mutex_assert_owner(tsdn, &extents->mtx);
289  	assert(extent_state_get(extent) == extents->state);
290  	size_t size = extent_size_get(extent);
291  	size_t psz = extent_size_quantize_floor(size);
292  	pszind_t pind = sz_psz2ind(psz);
293  	extent_heap_remove(&extents->heaps[pind], extent);
294  	if (config_stats) {
295  		extents_stats_sub(extents, pind, size);
296  	}
297  	if (extent_heap_empty(&extents->heaps[pind])) {
298  		bitmap_set(extents->bitmap, &extents_bitmap_info,
299  		    (size_t)pind);
300  	}
301  	extent_list_remove(&extents->lru, extent);
302  	size_t npages = size >> LG_PAGE;
303  	size_t cur_extents_npages =
304  	    atomic_load_zu(&extents->npages, ATOMIC_RELAXED);
305  	assert(cur_extents_npages >= npages);
306  	atomic_store_zu(&extents->npages,
307  	    cur_extents_npages - (size >> LG_PAGE), ATOMIC_RELAXED);
308  }
309  static extent_t *
310  extents_fit_alignment(extents_t *extents, size_t min_size, size_t max_size,
311      size_t alignment) {
312          pszind_t pind = sz_psz2ind(extent_size_quantize_ceil(min_size));
313          pszind_t pind_max = sz_psz2ind(extent_size_quantize_ceil(max_size));
314  	for (pszind_t i = (pszind_t)bitmap_ffu(extents->bitmap,
315  	    &extents_bitmap_info, (size_t)pind); i < pind_max; i =
316  	    (pszind_t)bitmap_ffu(extents->bitmap, &extents_bitmap_info,
317  	    (size_t)i+1)) {
318  		assert(i < SC_NPSIZES);
319  		assert(!extent_heap_empty(&extents->heaps[i]));
320  		extent_t *extent = extent_heap_first(&extents->heaps[i]);
321  		uintptr_t base = (uintptr_t)extent_base_get(extent);
322  		size_t candidate_size = extent_size_get(extent);
323  		assert(candidate_size >= min_size);
324  		uintptr_t next_align = ALIGNMENT_CEILING((uintptr_t)base,
325  		    PAGE_CEILING(alignment));
326  		if (base > next_align || base + candidate_size <= next_align) {
327  			continue;
328  		}
329  		size_t leadsize = next_align - base;
330  		if (candidate_size - leadsize >= min_size) {
331  			return extent;
332  		}
333  	}
334  	return NULL;
335  }
336  static extent_t *
337  extents_first_fit_locked(tsdn_t *tsdn, arena_t *arena, extents_t *extents,
338      size_t size) {
339  	extent_t *ret = NULL;
340  	pszind_t pind = sz_psz2ind(extent_size_quantize_ceil(size));
341  	if (!maps_coalesce && !opt_retain) {
342  		return extent_heap_empty(&extents->heaps[pind]) ? NULL :
343  		    extent_heap_first(&extents->heaps[pind]);
344  	}
345  	for (pszind_t i = (pszind_t)bitmap_ffu(extents->bitmap,
346  	    &extents_bitmap_info, (size_t)pind);
347  	    i < SC_NPSIZES + 1;
348  	    i = (pszind_t)bitmap_ffu(extents->bitmap, &extents_bitmap_info,
349  	    (size_t)i+1)) {
350  		assert(!extent_heap_empty(&extents->heaps[i]));
351  		extent_t *extent = extent_heap_first(&extents->heaps[i]);
352  		assert(extent_size_get(extent) >= size);
353  		if (extents->delay_coalesce &&
354  		    (sz_pind2sz(i) >> opt_lg_extent_max_active_fit) > size) {
355  			break;
356  		}
357  		if (ret == NULL || extent_snad_comp(extent, ret) < 0) {
358  			ret = extent;
359  		}
360  		if (i == SC_NPSIZES) {
361  			break;
362  		}
363  		assert(i < SC_NPSIZES);
364  	}
365  	return ret;
366  }
367  static extent_t *
368  extents_fit_locked(tsdn_t *tsdn, arena_t *arena, extents_t *extents,
369      size_t esize, size_t alignment) {
370  	malloc_mutex_assert_owner(tsdn, &extents->mtx);
371  	size_t max_size = esize + PAGE_CEILING(alignment) - PAGE;
372  	if (max_size < esize) {
373  		return NULL;
374  	}
375  	extent_t *extent =
376  	    extents_first_fit_locked(tsdn, arena, extents, max_size);
377  	if (alignment > PAGE && extent == NULL) {
378  		extent = extents_fit_alignment(extents, esize, max_size,
379  		    alignment);
380  	}
381  	return extent;
382  }
383  static bool
384  extent_try_delayed_coalesce(tsdn_t *tsdn, arena_t *arena,
385      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
386      extent_t *extent) {
387  	extent_state_set(extent, extent_state_active);
388  	bool coalesced;
389  	extent = extent_try_coalesce(tsdn, arena, r_extent_hooks, rtree_ctx,
390  	    extents, extent, &coalesced, false);
391  	extent_state_set(extent, extents_state_get(extents));
392  	if (!coalesced) {
393  		return true;
394  	}
395  	extents_insert_locked(tsdn, extents, extent);
396  	return false;
397  }
398  extent_t *
399  extents_alloc(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
400      extents_t *extents, void *new_addr, size_t size, size_t pad,
401      size_t alignment, bool slab, szind_t szind, bool *zero, bool *commit) {
402  	assert(size + pad != 0);
403  	assert(alignment != 0);
404  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
405  	    WITNESS_RANK_CORE, 0);
406  	extent_t *extent = extent_recycle(tsdn, arena, r_extent_hooks, extents,
407  	    new_addr, size, pad, alignment, slab, szind, zero, commit, false);
408  	assert(extent == NULL || extent_dumpable_get(extent));
409  	return extent;
410  }
411  void
412  extents_dalloc(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
413      extents_t *extents, extent_t *extent) {
414  	assert(extent_base_get(extent) != NULL);
415  	assert(extent_size_get(extent) != 0);
416  	assert(extent_dumpable_get(extent));
417  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
<span onclick='openModal()' class='match'>418  	    WITNESS_RANK_CORE, 0);
419  	extent_addr_set(extent, extent_base_get(extent));
420  	extent_zeroed_set(extent, false);
421  	extent_record(tsdn, arena, r_extent_hooks, extents, extent, false);
</span>422  }
423  extent_t *
424  extents_evict(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
425      extents_t *extents, size_t npages_min) {
426  	rtree_ctx_t rtree_ctx_fallback;
427  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
428  	malloc_mutex_lock(tsdn, &extents->mtx);
429  	extent_t *extent;
430  	while (true) {
431  		extent = extent_list_first(&extents->lru);
432  		if (extent == NULL) {
433  			goto label_return;
434  		}
435  		size_t extents_npages = atomic_load_zu(&extents->npages,
436  		    ATOMIC_RELAXED);
437  		if (extents_npages <= npages_min) {
438  			extent = NULL;
439  			goto label_return;
440  		}
441  		extents_remove_locked(tsdn, extents, extent);
442  		if (!extents->delay_coalesce) {
443  			break;
444  		}
445  		if (extent_try_delayed_coalesce(tsdn, arena, r_extent_hooks,
446  		    rtree_ctx, extents, extent)) {
447  			break;
448  		}
449  	}
450  	switch (extents_state_get(extents)) {
451  	case extent_state_active:
452  		not_reached();
453  	case extent_state_dirty:
454  	case extent_state_muzzy:
455  		extent_state_set(extent, extent_state_active);
456  		break;
457  	case extent_state_retained:
458  		extent_deregister(tsdn, extent);
459  		break;
460  	default:
461  		not_reached();
462  	}
463  label_return:
464  	malloc_mutex_unlock(tsdn, &extents->mtx);
465  	return extent;
466  }
467  static void
468  extents_abandon_vm(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
469      extents_t *extents, extent_t *extent, bool growing_retained) {
470  	size_t sz = extent_size_get(extent);
471  	if (config_stats) {
472  		arena_stats_accum_zu(&arena->stats.abandoned_vm, sz);
473  	}
474  	if (extents_state_get(extents) == extent_state_dirty) {
475  		if (extent_purge_lazy_impl(tsdn, arena, r_extent_hooks,
476  		    extent, 0, sz, growing_retained)) {
477  			extent_purge_forced_impl(tsdn, arena, r_extent_hooks,
478  			    extent, 0, extent_size_get(extent),
479  			    growing_retained);
480  		}
481  	}
482  	extent_dalloc(tsdn, arena, extent);
483  }
484  void
485  extents_prefork(tsdn_t *tsdn, extents_t *extents) {
486  	malloc_mutex_prefork(tsdn, &extents->mtx);
487  }
488  void
489  extents_postfork_parent(tsdn_t *tsdn, extents_t *extents) {
490  	malloc_mutex_postfork_parent(tsdn, &extents->mtx);
491  }
492  void
493  extents_postfork_child(tsdn_t *tsdn, extents_t *extents) {
494  	malloc_mutex_postfork_child(tsdn, &extents->mtx);
495  }
496  static void
497  extent_deactivate_locked(tsdn_t *tsdn, arena_t *arena, extents_t *extents,
498      extent_t *extent) {
499  	assert(extent_arena_get(extent) == arena);
500  	assert(extent_state_get(extent) == extent_state_active);
501  	extent_state_set(extent, extents_state_get(extents));
502  	extents_insert_locked(tsdn, extents, extent);
503  }
504  static void
505  extent_deactivate(tsdn_t *tsdn, arena_t *arena, extents_t *extents,
506      extent_t *extent) {
507  	malloc_mutex_lock(tsdn, &extents->mtx);
508  	extent_deactivate_locked(tsdn, arena, extents, extent);
509  	malloc_mutex_unlock(tsdn, &extents->mtx);
510  }
511  static void
512  extent_activate_locked(tsdn_t *tsdn, arena_t *arena, extents_t *extents,
513      extent_t *extent) {
514  	assert(extent_arena_get(extent) == arena);
515  	assert(extent_state_get(extent) == extents_state_get(extents));
516  	extents_remove_locked(tsdn, extents, extent);
517  	extent_state_set(extent, extent_state_active);
518  }
519  static bool
520  extent_rtree_leaf_elms_lookup(tsdn_t *tsdn, rtree_ctx_t *rtree_ctx,
521      const extent_t *extent, bool dependent, bool init_missing,
522      rtree_leaf_elm_t **r_elm_a, rtree_leaf_elm_t **r_elm_b) {
523  	*r_elm_a = rtree_leaf_elm_lookup(tsdn, &extents_rtree, rtree_ctx,
524  	    (uintptr_t)extent_base_get(extent), dependent, init_missing);
525  	if (!dependent && *r_elm_a == NULL) {
526  		return true;
527  	}
528  	assert(*r_elm_a != NULL);
529  	*r_elm_b = rtree_leaf_elm_lookup(tsdn, &extents_rtree, rtree_ctx,
530  	    (uintptr_t)extent_last_get(extent), dependent, init_missing);
531  	if (!dependent && *r_elm_b == NULL) {
532  		return true;
533  	}
534  	assert(*r_elm_b != NULL);
535  	return false;
536  }
537  static void
538  extent_rtree_write_acquired(tsdn_t *tsdn, rtree_leaf_elm_t *elm_a,
539      rtree_leaf_elm_t *elm_b, extent_t *extent, szind_t szind, bool slab) {
540  	rtree_leaf_elm_write(tsdn, &extents_rtree, elm_a, extent, szind, slab);
541  	if (elm_b != NULL) {
542  		rtree_leaf_elm_write(tsdn, &extents_rtree, elm_b, extent, szind,
543  		    slab);
544  	}
545  }
546  static void
547  extent_interior_register(tsdn_t *tsdn, rtree_ctx_t *rtree_ctx, extent_t *extent,
548      szind_t szind) {
549  	assert(extent_slab_get(extent));
550  	for (size_t i = 1; i < (extent_size_get(extent) >> LG_PAGE) - 1; i++) {
551  		rtree_write(tsdn, &extents_rtree, rtree_ctx,
552  		    (uintptr_t)extent_base_get(extent) + (uintptr_t)(i <<
553  		    LG_PAGE), extent, szind, true);
554  	}
555  }
556  static void
557  extent_gdump_add(tsdn_t *tsdn, const extent_t *extent) {
558  	cassert(config_prof);
559  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
560  	    WITNESS_RANK_CORE, 0);
561  	if (opt_prof && extent_state_get(extent) == extent_state_active) {
562  		size_t nadd = extent_size_get(extent) >> LG_PAGE;
563  		size_t cur = atomic_fetch_add_zu(&curpages, nadd,
564  		    ATOMIC_RELAXED) + nadd;
565  		size_t high = atomic_load_zu(&highpages, ATOMIC_RELAXED);
566  		while (cur > high && !atomic_compare_exchange_weak_zu(
567  		    &highpages, &high, cur, ATOMIC_RELAXED, ATOMIC_RELAXED)) {
568  		}
569  		if (cur > high && prof_gdump_get_unlocked()) {
570  			prof_gdump(tsdn);
571  		}
572  	}
573  }
574  static void
575  extent_gdump_sub(tsdn_t *tsdn, const extent_t *extent) {
576  	cassert(config_prof);
577  	if (opt_prof && extent_state_get(extent) == extent_state_active) {
578  		size_t nsub = extent_size_get(extent) >> LG_PAGE;
579  		assert(atomic_load_zu(&curpages, ATOMIC_RELAXED) >= nsub);
580  		atomic_fetch_sub_zu(&curpages, nsub, ATOMIC_RELAXED);
581  	}
582  }
583  static bool
584  extent_register_impl(tsdn_t *tsdn, extent_t *extent, bool gdump_add) {
585  	rtree_ctx_t rtree_ctx_fallback;
586  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
587  	rtree_leaf_elm_t *elm_a, *elm_b;
588  	extent_lock(tsdn, extent);
589  	if (extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, extent, false, true,
590  	    &elm_a, &elm_b)) {
591  		extent_unlock(tsdn, extent);
592  		return true;
593  	}
594  	szind_t szind = extent_szind_get_maybe_invalid(extent);
595  	bool slab = extent_slab_get(extent);
596  	extent_rtree_write_acquired(tsdn, elm_a, elm_b, extent, szind, slab);
597  	if (slab) {
598  		extent_interior_register(tsdn, rtree_ctx, extent, szind);
599  	}
600  	extent_unlock(tsdn, extent);
601  	if (config_prof && gdump_add) {
602  		extent_gdump_add(tsdn, extent);
603  	}
604  	return false;
605  }
606  static bool
607  extent_register(tsdn_t *tsdn, extent_t *extent) {
608  	return extent_register_impl(tsdn, extent, true);
609  }
610  static bool
611  extent_register_no_gdump_add(tsdn_t *tsdn, extent_t *extent) {
612  	return extent_register_impl(tsdn, extent, false);
613  }
614  static void
615  extent_reregister(tsdn_t *tsdn, extent_t *extent) {
616  	bool err = extent_register(tsdn, extent);
617  	assert(!err);
618  }
619  static void
620  extent_interior_deregister(tsdn_t *tsdn, rtree_ctx_t *rtree_ctx,
621      extent_t *extent) {
622  	size_t i;
623  	assert(extent_slab_get(extent));
624  	for (i = 1; i < (extent_size_get(extent) >> LG_PAGE) - 1; i++) {
625  		rtree_clear(tsdn, &extents_rtree, rtree_ctx,
626  		    (uintptr_t)extent_base_get(extent) + (uintptr_t)(i <<
627  		    LG_PAGE));
628  	}
629  }
630  static void
631  extent_deregister_impl(tsdn_t *tsdn, extent_t *extent, bool gdump) {
632  	rtree_ctx_t rtree_ctx_fallback;
633  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
634  	rtree_leaf_elm_t *elm_a, *elm_b;
635  	extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, extent, true, false,
636  	    &elm_a, &elm_b);
637  	extent_lock(tsdn, extent);
638  	extent_rtree_write_acquired(tsdn, elm_a, elm_b, NULL, SC_NSIZES, false);
639  	if (extent_slab_get(extent)) {
640  		extent_interior_deregister(tsdn, rtree_ctx, extent);
641  		extent_slab_set(extent, false);
642  	}
643  	extent_unlock(tsdn, extent);
644  	if (config_prof && gdump) {
645  		extent_gdump_sub(tsdn, extent);
646  	}
647  }
648  static void
649  extent_deregister(tsdn_t *tsdn, extent_t *extent) {
650  	extent_deregister_impl(tsdn, extent, true);
651  }
652  static void
653  extent_deregister_no_gdump_sub(tsdn_t *tsdn, extent_t *extent) {
654  	extent_deregister_impl(tsdn, extent, false);
655  }
656  static extent_t *
657  extent_recycle_extract(tsdn_t *tsdn, arena_t *arena,
658      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
659      void *new_addr, size_t size, size_t pad, size_t alignment, bool slab,
660      bool growing_retained) {
661  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
662  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
663  	assert(alignment > 0);
664  	if (config_debug && new_addr != NULL) {
665  		assert(PAGE_ADDR2BASE(new_addr) == new_addr);
666  		assert(pad == 0);
667  		assert(alignment <= PAGE);
668  	}
669  	size_t esize = size + pad;
670  	malloc_mutex_lock(tsdn, &extents->mtx);
671  	extent_hooks_assure_initialized(arena, r_extent_hooks);
672  	extent_t *extent;
673  	if (new_addr != NULL) {
674  		extent = extent_lock_from_addr(tsdn, rtree_ctx, new_addr,
675  		    false);
676  		if (extent != NULL) {
677  			extent_t *unlock_extent = extent;
678  			assert(extent_base_get(extent) == new_addr);
679  			if (extent_arena_get(extent) != arena ||
680  			    extent_size_get(extent) < esize ||
681  			    extent_state_get(extent) !=
682  			    extents_state_get(extents)) {
683  				extent = NULL;
684  			}
685  			extent_unlock(tsdn, unlock_extent);
686  		}
687  	} else {
688  		extent = extents_fit_locked(tsdn, arena, extents, esize,
689  		    alignment);
690  	}
691  	if (extent == NULL) {
692  		malloc_mutex_unlock(tsdn, &extents->mtx);
693  		return NULL;
694  	}
695  	extent_activate_locked(tsdn, arena, extents, extent);
696  	malloc_mutex_unlock(tsdn, &extents->mtx);
697  	return extent;
698  }
699  typedef enum {
700  	extent_split_interior_ok,
701  	extent_split_interior_cant_alloc,
702  	extent_split_interior_error
703  } extent_split_interior_result_t;
704  static extent_split_interior_result_t
705  extent_split_interior(tsdn_t *tsdn, arena_t *arena,
706      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx,
707      extent_t **extent, extent_t **lead, extent_t **trail,
708      extent_t **to_leak, extent_t **to_salvage,
709      void *new_addr, size_t size, size_t pad, size_t alignment, bool slab,
710      szind_t szind, bool growing_retained) {
711  	size_t esize = size + pad;
712  	size_t leadsize = ALIGNMENT_CEILING((uintptr_t)extent_base_get(*extent),
713  	    PAGE_CEILING(alignment)) - (uintptr_t)extent_base_get(*extent);
714  	assert(new_addr == NULL || leadsize == 0);
715  	if (extent_size_get(*extent) < leadsize + esize) {
716  		return extent_split_interior_cant_alloc;
717  	}
718  	size_t trailsize = extent_size_get(*extent) - leadsize - esize;
719  	*lead = NULL;
720  	*trail = NULL;
721  	*to_leak = NULL;
722  	*to_salvage = NULL;
723  	if (leadsize != 0) {
724  		*lead = *extent;
725  		*extent = extent_split_impl(tsdn, arena, r_extent_hooks,
726  		    *lead, leadsize, SC_NSIZES, false, esize + trailsize, szind,
727  		    slab, growing_retained);
728  		if (*extent == NULL) {
729  			*to_leak = *lead;
730  			*lead = NULL;
731  			return extent_split_interior_error;
732  		}
733  	}
734  	if (trailsize != 0) {
735  		*trail = extent_split_impl(tsdn, arena, r_extent_hooks, *extent,
736  		    esize, szind, slab, trailsize, SC_NSIZES, false,
737  		    growing_retained);
738  		if (*trail == NULL) {
739  			*to_leak = *extent;
740  			*to_salvage = *lead;
741  			*lead = NULL;
742  			*extent = NULL;
743  			return extent_split_interior_error;
744  		}
745  	}
746  	if (leadsize == 0 && trailsize == 0) {
747  		extent_szind_set(*extent, szind);
748  		if (szind != SC_NSIZES) {
749  			rtree_szind_slab_update(tsdn, &extents_rtree, rtree_ctx,
750  			    (uintptr_t)extent_addr_get(*extent), szind, slab);
751  			if (slab && extent_size_get(*extent) > PAGE) {
752  				rtree_szind_slab_update(tsdn, &extents_rtree,
753  				    rtree_ctx,
754  				    (uintptr_t)extent_past_get(*extent) -
755  				    (uintptr_t)PAGE, szind, slab);
756  			}
757  		}
758  	}
759  	return extent_split_interior_ok;
760  }
761  static extent_t *
762  extent_recycle_split(tsdn_t *tsdn, arena_t *arena,
763      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
764      void *new_addr, size_t size, size_t pad, size_t alignment, bool slab,
765      szind_t szind, extent_t *extent, bool growing_retained) {
766  	extent_t *lead;
767  	extent_t *trail;
768  	extent_t *to_leak;
769  	extent_t *to_salvage;
770  	extent_split_interior_result_t result = extent_split_interior(
771  	    tsdn, arena, r_extent_hooks, rtree_ctx, &extent, &lead, &trail,
772  	    &to_leak, &to_salvage, new_addr, size, pad, alignment, slab, szind,
773  	    growing_retained);
774  	if (!maps_coalesce && result != extent_split_interior_ok
775  	    && !opt_retain) {
776  		assert(to_leak != NULL && lead == NULL && trail == NULL);
777  		extent_deactivate(tsdn, arena, extents, to_leak);
778  		return NULL;
779  	}
780  	if (result == extent_split_interior_ok) {
781  		if (lead != NULL) {
782  			extent_deactivate(tsdn, arena, extents, lead);
783  		}
784  		if (trail != NULL) {
785  			extent_deactivate(tsdn, arena, extents, trail);
786  		}
787  		return extent;
788  	} else {
789  		assert(result == extent_split_interior_error);
790  		if (to_salvage != NULL) {
791  			extent_deregister(tsdn, to_salvage);
792  		}
793  		if (to_leak != NULL) {
794  			void *leak = extent_base_get(to_leak);
795  			extent_deregister_no_gdump_sub(tsdn, to_leak);
796  			extents_abandon_vm(tsdn, arena, r_extent_hooks, extents,
797  			    to_leak, growing_retained);
798  			assert(extent_lock_from_addr(tsdn, rtree_ctx, leak,
799  			    false) == NULL);
800  		}
801  		return NULL;
802  	}
803  	unreachable();
804  }
805  static bool
806  extent_need_manual_zero(arena_t *arena) {
807  	return (!arena_has_default_hooks(arena) ||
808  		(opt_thp == thp_mode_always));
809  }
810  static extent_t *
811  extent_recycle(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
812      extents_t *extents, void *new_addr, size_t size, size_t pad,
813      size_t alignment, bool slab, szind_t szind, bool *zero, bool *commit,
814      bool growing_retained) {
815  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
816  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
817  	assert(new_addr == NULL || !slab);
818  	assert(pad == 0 || !slab);
819  	assert(!*zero || !slab);
820  	rtree_ctx_t rtree_ctx_fallback;
821  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
822  	extent_t *extent = extent_recycle_extract(tsdn, arena, r_extent_hooks,
823  	    rtree_ctx, extents, new_addr, size, pad, alignment, slab,
824  	    growing_retained);
825  	if (extent == NULL) {
826  		return NULL;
827  	}
828  	extent = extent_recycle_split(tsdn, arena, r_extent_hooks, rtree_ctx,
829  	    extents, new_addr, size, pad, alignment, slab, szind, extent,
830  	    growing_retained);
831  	if (extent == NULL) {
832  		return NULL;
833  	}
834  	if (*commit && !extent_committed_get(extent)) {
835  		if (extent_commit_impl(tsdn, arena, r_extent_hooks, extent,
836  		    0, extent_size_get(extent), growing_retained)) {
837  			extent_record(tsdn, arena, r_extent_hooks, extents,
838  			    extent, growing_retained);
839  			return NULL;
840  		}
841  		if (!extent_need_manual_zero(arena)) {
842  			extent_zeroed_set(extent, true);
843  		}
844  	}
845  	if (extent_committed_get(extent)) {
846  		*commit = true;
847  	}
848  	if (extent_zeroed_get(extent)) {
849  		*zero = true;
850  	}
851  	if (pad != 0) {
852  		extent_addr_randomize(tsdn, extent, alignment);
853  	}
854  	assert(extent_state_get(extent) == extent_state_active);
855  	if (slab) {
856  		extent_slab_set(extent, slab);
857  		extent_interior_register(tsdn, rtree_ctx, extent, szind);
858  	}
859  	if (*zero) {
860  		void *addr = extent_base_get(extent);
861  		if (!extent_zeroed_get(extent)) {
862  			size_t size = extent_size_get(extent);
863  			if (extent_need_manual_zero(arena) ||
864  			    pages_purge_forced(addr, size)) {
865  				memset(addr, 0, size);
866  			}
867  		} else if (config_debug) {
868  			size_t *p = (size_t *)(uintptr_t)addr;
869  			for (size_t i = 0; i < PAGE / sizeof(size_t); i++) {
870  				assert(p[i] == 0);
871  			}
872  		}
873  	}
874  	return extent;
875  }
876  static void *
877  extent_alloc_core(tsdn_t *tsdn, arena_t *arena, void *new_addr, size_t size,
878      size_t alignment, bool *zero, bool *commit, dss_prec_t dss_prec) {
879  	void *ret;
880  	assert(size != 0);
881  	assert(alignment != 0);
882  	if (have_dss && dss_prec == dss_prec_primary && (ret =
883  	    extent_alloc_dss(tsdn, arena, new_addr, size, alignment, zero,
884  	    commit)) != NULL) {
885  		return ret;
886  	}
887  	if ((ret = extent_alloc_mmap(new_addr, size, alignment, zero, commit))
888  	    != NULL) {
889  		return ret;
890  	}
891  	if (have_dss && dss_prec == dss_prec_secondary && (ret =
892  	    extent_alloc_dss(tsdn, arena, new_addr, size, alignment, zero,
893  	    commit)) != NULL) {
894  		return ret;
895  	}
896  	return NULL;
897  }
898  static void *
899  extent_alloc_default_impl(tsdn_t *tsdn, arena_t *arena, void *new_addr,
900      size_t size, size_t alignment, bool *zero, bool *commit) {
901  	void *ret = extent_alloc_core(tsdn, arena, new_addr, size, alignment, zero,
902  	    commit, (dss_prec_t)atomic_load_u(&arena->dss_prec,
903  	    ATOMIC_RELAXED));
904  	if (have_madvise_huge && ret) {
905  		pages_set_thp_state(ret, size);
906  	}
907  	return ret;
908  }
909  static void *
910  extent_alloc_default(extent_hooks_t *extent_hooks, void *new_addr, size_t size,
911      size_t alignment, bool *zero, bool *commit, unsigned arena_ind) {
912  	tsdn_t *tsdn;
913  	arena_t *arena;
914  	tsdn = tsdn_fetch();
915  	arena = arena_get(tsdn, arena_ind, false);
916  	assert(arena != NULL);
917  	return extent_alloc_default_impl(tsdn, arena, new_addr, size,
918  	    ALIGNMENT_CEILING(alignment, PAGE), zero, commit);
919  }
920  static void
921  extent_hook_pre_reentrancy(tsdn_t *tsdn, arena_t *arena) {
922  	tsd_t *tsd = tsdn_null(tsdn) ? tsd_fetch() : tsdn_tsd(tsdn);
923  	if (arena == arena_get(tsd_tsdn(tsd), 0, false)) {
924  		pre_reentrancy(tsd, NULL);
925  	} else {
926  		pre_reentrancy(tsd, arena);
927  	}
928  }
929  static void
930  extent_hook_post_reentrancy(tsdn_t *tsdn) {
931  	tsd_t *tsd = tsdn_null(tsdn) ? tsd_fetch() : tsdn_tsd(tsdn);
932  	post_reentrancy(tsd);
933  }
934  static extent_t *
935  extent_grow_retained(tsdn_t *tsdn, arena_t *arena,
936      extent_hooks_t **r_extent_hooks, size_t size, size_t pad, size_t alignment,
937      bool slab, szind_t szind, bool *zero, bool *commit) {
938  	malloc_mutex_assert_owner(tsdn, &arena->extent_grow_mtx);
939  	assert(pad == 0 || !slab);
940  	assert(!*zero || !slab);
941  	size_t esize = size + pad;
942  	size_t alloc_size_min = esize + PAGE_CEILING(alignment) - PAGE;
943  	if (alloc_size_min < esize) {
944  		goto label_err;
945  	}
946  	pszind_t egn_skip = 0;
947  	size_t alloc_size = sz_pind2sz(arena->extent_grow_next + egn_skip);
948  	while (alloc_size < alloc_size_min) {
949  		egn_skip++;
950  		if (arena->extent_grow_next + egn_skip >=
951  		    sz_psz2ind(SC_LARGE_MAXCLASS)) {
952  			goto label_err;
953  		}
954  		alloc_size = sz_pind2sz(arena->extent_grow_next + egn_skip);
955  	}
956  	extent_t *extent = extent_alloc(tsdn, arena);
957  	if (extent == NULL) {
958  		goto label_err;
959  	}
960  	bool zeroed = false;
961  	bool committed = false;
962  	void *ptr;
963  	if (*r_extent_hooks == &extent_hooks_default) {
964  		ptr = extent_alloc_default_impl(tsdn, arena, NULL,
965  		    alloc_size, PAGE, &zeroed, &committed);
966  	} else {
967  		extent_hook_pre_reentrancy(tsdn, arena);
968  		ptr = (*r_extent_hooks)->alloc(*r_extent_hooks, NULL,
969  		    alloc_size, PAGE, &zeroed, &committed,
970  		    arena_ind_get(arena));
971  		extent_hook_post_reentrancy(tsdn);
972  	}
973  	extent_init(extent, arena, ptr, alloc_size, false, SC_NSIZES,
974  	    arena_extent_sn_next(arena), extent_state_active, zeroed,
975  	    committed, true, EXTENT_IS_HEAD);
976  	if (ptr == NULL) {
977  		extent_dalloc(tsdn, arena, extent);
978  		goto label_err;
979  	}
980  	if (extent_register_no_gdump_add(tsdn, extent)) {
981  		extent_dalloc(tsdn, arena, extent);
982  		goto label_err;
983  	}
984  	if (extent_zeroed_get(extent) && extent_committed_get(extent)) {
985  		*zero = true;
986  	}
987  	if (extent_committed_get(extent)) {
988  		*commit = true;
989  	}
990  	rtree_ctx_t rtree_ctx_fallback;
991  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
992  	extent_t *lead;
993  	extent_t *trail;
994  	extent_t *to_leak;
995  	extent_t *to_salvage;
996  	extent_split_interior_result_t result = extent_split_interior(
997  	    tsdn, arena, r_extent_hooks, rtree_ctx, &extent, &lead, &trail,
998  	    &to_leak, &to_salvage, NULL, size, pad, alignment, slab, szind,
999  	    true);
1000  	if (result == extent_split_interior_ok) {
1001  		if (lead != NULL) {
1002  			extent_record(tsdn, arena, r_extent_hooks,
1003  			    &arena->extents_retained, lead, true);
1004  		}
1005  		if (trail != NULL) {
1006  			extent_record(tsdn, arena, r_extent_hooks,
1007  			    &arena->extents_retained, trail, true);
1008  		}
1009  	} else {
1010  		assert(result == extent_split_interior_error);
1011  		if (to_salvage != NULL) {
1012  			if (config_prof) {
1013  				extent_gdump_add(tsdn, to_salvage);
1014  			}
1015  			extent_record(tsdn, arena, r_extent_hooks,
1016  			    &arena->extents_retained, to_salvage, true);
1017  		}
1018  		if (to_leak != NULL) {
1019  			extent_deregister_no_gdump_sub(tsdn, to_leak);
1020  			extents_abandon_vm(tsdn, arena, r_extent_hooks,
1021  			    &arena->extents_retained, to_leak, true);
1022  		}
1023  		goto label_err;
1024  	}
1025  	if (*commit && !extent_committed_get(extent)) {
1026  		if (extent_commit_impl(tsdn, arena, r_extent_hooks, extent, 0,
1027  		    extent_size_get(extent), true)) {
1028  			extent_record(tsdn, arena, r_extent_hooks,
1029  			    &arena->extents_retained, extent, true);
1030  			goto label_err;
1031  		}
1032  		if (!extent_need_manual_zero(arena)) {
1033  			extent_zeroed_set(extent, true);
1034  		}
1035  	}
1036  	if (arena->extent_grow_next + egn_skip + 1 <=
1037  	    arena->retain_grow_limit) {
1038  		arena->extent_grow_next += egn_skip + 1;
1039  	} else {
1040  		arena->extent_grow_next = arena->retain_grow_limit;
1041  	}
1042  	malloc_mutex_unlock(tsdn, &arena->extent_grow_mtx);
1043  	if (config_prof) {
1044  		extent_gdump_add(tsdn, extent);
1045  	}
1046  	if (pad != 0) {
1047  		extent_addr_randomize(tsdn, extent, alignment);
1048  	}
1049  	if (slab) {
1050  		rtree_ctx_t rtree_ctx_fallback;
1051  		rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn,
1052  		    &rtree_ctx_fallback);
1053  		extent_slab_set(extent, true);
1054  		extent_interior_register(tsdn, rtree_ctx, extent, szind);
1055  	}
1056  	if (*zero && !extent_zeroed_get(extent)) {
1057  		void *addr = extent_base_get(extent);
1058  		size_t size = extent_size_get(extent);
1059  		if (extent_need_manual_zero(arena) ||
1060  		    pages_purge_forced(addr, size)) {
1061  			memset(addr, 0, size);
1062  		}
1063  	}
1064  	return extent;
1065  label_err:
1066  	malloc_mutex_unlock(tsdn, &arena->extent_grow_mtx);
1067  	return NULL;
1068  }
1069  static extent_t *
1070  extent_alloc_retained(tsdn_t *tsdn, arena_t *arena,
1071      extent_hooks_t **r_extent_hooks, void *new_addr, size_t size, size_t pad,
1072      size_t alignment, bool slab, szind_t szind, bool *zero, bool *commit) {
1073  	assert(size != 0);
1074  	assert(alignment != 0);
1075  	malloc_mutex_lock(tsdn, &arena->extent_grow_mtx);
1076  	extent_t *extent = extent_recycle(tsdn, arena, r_extent_hooks,
1077  	    &arena->extents_retained, new_addr, size, pad, alignment, slab,
1078  	    szind, zero, commit, true);
1079  	if (extent != NULL) {
1080  		malloc_mutex_unlock(tsdn, &arena->extent_grow_mtx);
1081  		if (config_prof) {
1082  			extent_gdump_add(tsdn, extent);
1083  		}
1084  	} else if (opt_retain && new_addr == NULL) {
1085  		extent = extent_grow_retained(tsdn, arena, r_extent_hooks, size,
1086  		    pad, alignment, slab, szind, zero, commit);
1087  	} else {
1088  		malloc_mutex_unlock(tsdn, &arena->extent_grow_mtx);
1089  	}
1090  	malloc_mutex_assert_not_owner(tsdn, &arena->extent_grow_mtx);
1091  	return extent;
1092  }
1093  static extent_t *
1094  extent_alloc_wrapper_hard(tsdn_t *tsdn, arena_t *arena,
1095      extent_hooks_t **r_extent_hooks, void *new_addr, size_t size, size_t pad,
1096      size_t alignment, bool slab, szind_t szind, bool *zero, bool *commit) {
1097  	size_t esize = size + pad;
1098  	extent_t *extent = extent_alloc(tsdn, arena);
1099  	if (extent == NULL) {
1100  		return NULL;
1101  	}
1102  	void *addr;
1103  	size_t palignment = ALIGNMENT_CEILING(alignment, PAGE);
1104  	if (*r_extent_hooks == &extent_hooks_default) {
1105  		addr = extent_alloc_default_impl(tsdn, arena, new_addr, esize,
1106  		    palignment, zero, commit);
1107  	} else {
1108  		extent_hook_pre_reentrancy(tsdn, arena);
1109  		addr = (*r_extent_hooks)->alloc(*r_extent_hooks, new_addr,
1110  		    esize, palignment, zero, commit, arena_ind_get(arena));
1111  		extent_hook_post_reentrancy(tsdn);
1112  	}
1113  	if (addr == NULL) {
1114  		extent_dalloc(tsdn, arena, extent);
1115  		return NULL;
1116  	}
1117  	extent_init(extent, arena, addr, esize, slab, szind,
1118  	    arena_extent_sn_next(arena), extent_state_active, *zero, *commit,
1119  	    true, EXTENT_NOT_HEAD);
1120  	if (pad != 0) {
1121  		extent_addr_randomize(tsdn, extent, alignment);
1122  	}
1123  	if (extent_register(tsdn, extent)) {
1124  		extent_dalloc(tsdn, arena, extent);
1125  		return NULL;
1126  	}
1127  	return extent;
1128  }
1129  extent_t *
1130  extent_alloc_wrapper(tsdn_t *tsdn, arena_t *arena,
1131      extent_hooks_t **r_extent_hooks, void *new_addr, size_t size, size_t pad,
1132      size_t alignment, bool slab, szind_t szind, bool *zero, bool *commit) {
1133  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1134  	    WITNESS_RANK_CORE, 0);
1135  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1136  	extent_t *extent = extent_alloc_retained(tsdn, arena, r_extent_hooks,
1137  	    new_addr, size, pad, alignment, slab, szind, zero, commit);
1138  	if (extent == NULL) {
1139  		if (opt_retain && new_addr != NULL) {
1140  			return NULL;
1141  		}
1142  		extent = extent_alloc_wrapper_hard(tsdn, arena, r_extent_hooks,
1143  		    new_addr, size, pad, alignment, slab, szind, zero, commit);
1144  	}
1145  	assert(extent == NULL || extent_dumpable_get(extent));
1146  	return extent;
1147  }
1148  static bool
1149  extent_can_coalesce(arena_t *arena, extents_t *extents, const extent_t *inner,
1150      const extent_t *outer) {
1151  	assert(extent_arena_get(inner) == arena);
1152  	if (extent_arena_get(outer) != arena) {
1153  		return false;
1154  	}
1155  	assert(extent_state_get(inner) == extent_state_active);
1156  	if (extent_state_get(outer) != extents->state) {
1157  		return false;
1158  	}
1159  	if (extent_committed_get(inner) != extent_committed_get(outer)) {
1160  		return false;
1161  	}
1162  	return true;
1163  }
1164  static bool
1165  extent_coalesce(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
1166      extents_t *extents, extent_t *inner, extent_t *outer, bool forward,
1167      bool growing_retained) {
1168  	assert(extent_can_coalesce(arena, extents, inner, outer));
1169  	extent_activate_locked(tsdn, arena, extents, outer);
1170  	malloc_mutex_unlock(tsdn, &extents->mtx);
1171  	bool err = extent_merge_impl(tsdn, arena, r_extent_hooks,
1172  	    forward ? inner : outer, forward ? outer : inner, growing_retained);
1173  	malloc_mutex_lock(tsdn, &extents->mtx);
1174  	if (err) {
1175  		extent_deactivate_locked(tsdn, arena, extents, outer);
1176  	}
1177  	return err;
1178  }
1179  static extent_t *
1180  extent_try_coalesce_impl(tsdn_t *tsdn, arena_t *arena,
1181      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
1182      extent_t *extent, bool *coalesced, bool growing_retained,
1183      bool inactive_only) {
1184  	bool again;
1185  	do {
1186  		again = false;
1187  		extent_t *next = extent_lock_from_addr(tsdn, rtree_ctx,
1188  		    extent_past_get(extent), inactive_only);
1189  		if (next != NULL) {
1190  			bool can_coalesce = extent_can_coalesce(arena, extents,
1191  			    extent, next);
1192  			extent_unlock(tsdn, next);
1193  			if (can_coalesce && !extent_coalesce(tsdn, arena,
1194  			    r_extent_hooks, extents, extent, next, true,
1195  			    growing_retained)) {
1196  				if (extents->delay_coalesce) {
1197  					*coalesced = true;
1198  					return extent;
1199  				}
1200  				again = true;
1201  			}
1202  		}
1203  		extent_t *prev = extent_lock_from_addr(tsdn, rtree_ctx,
1204  		    extent_before_get(extent), inactive_only);
1205  		if (prev != NULL) {
1206  			bool can_coalesce = extent_can_coalesce(arena, extents,
1207  			    extent, prev);
1208  			extent_unlock(tsdn, prev);
1209  			if (can_coalesce && !extent_coalesce(tsdn, arena,
1210  			    r_extent_hooks, extents, extent, prev, false,
1211  			    growing_retained)) {
1212  				extent = prev;
1213  				if (extents->delay_coalesce) {
1214  					*coalesced = true;
1215  					return extent;
1216  				}
1217  				again = true;
1218  			}
1219  		}
1220  	} while (again);
1221  	if (extents->delay_coalesce) {
1222  		*coalesced = false;
1223  	}
1224  	return extent;
1225  }
1226  static extent_t *
1227  extent_try_coalesce(tsdn_t *tsdn, arena_t *arena,
1228      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
1229      extent_t *extent, bool *coalesced, bool growing_retained) {
1230  	return extent_try_coalesce_impl(tsdn, arena, r_extent_hooks, rtree_ctx,
1231  	    extents, extent, coalesced, growing_retained, false);
1232  }
1233  static extent_t *
1234  extent_try_coalesce_large(tsdn_t *tsdn, arena_t *arena,
1235      extent_hooks_t **r_extent_hooks, rtree_ctx_t *rtree_ctx, extents_t *extents,
1236      extent_t *extent, bool *coalesced, bool growing_retained) {
1237  	return extent_try_coalesce_impl(tsdn, arena, r_extent_hooks, rtree_ctx,
1238  	    extents, extent, coalesced, growing_retained, true);
1239  }
1240  static void
1241  extent_record(tsdn_t *tsdn, arena_t *arena, extent_hooks_t **r_extent_hooks,
1242      extents_t *extents, extent_t *extent, bool growing_retained) {
1243  	rtree_ctx_t rtree_ctx_fallback;
1244  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
1245  	assert((extents_state_get(extents) != extent_state_dirty &&
1246  	    extents_state_get(extents) != extent_state_muzzy) ||
1247  	    !extent_zeroed_get(extent));
1248  	malloc_mutex_lock(tsdn, &extents->mtx);
1249  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1250  	extent_szind_set(extent, SC_NSIZES);
1251  	if (extent_slab_get(extent)) {
1252  		extent_interior_deregister(tsdn, rtree_ctx, extent);
1253  		extent_slab_set(extent, false);
1254  	}
1255  	assert(rtree_extent_read(tsdn, &extents_rtree, rtree_ctx,
1256  	    (uintptr_t)extent_base_get(extent), true) == extent);
1257  	if (!extents->delay_coalesce) {
1258  		extent = extent_try_coalesce(tsdn, arena, r_extent_hooks,
1259  		    rtree_ctx, extents, extent, NULL, growing_retained);
1260  	} else if (extent_size_get(extent) >= SC_LARGE_MINCLASS) {
1261  		assert(extents == &arena->extents_dirty);
1262  		bool coalesced;
1263  		do {
1264  			assert(extent_state_get(extent) == extent_state_active);
1265  			extent = extent_try_coalesce_large(tsdn, arena,
1266  			    r_extent_hooks, rtree_ctx, extents, extent,
1267  			    &coalesced, growing_retained);
1268  		} while (coalesced);
1269  		if (extent_size_get(extent) >= oversize_threshold) {
1270  			malloc_mutex_unlock(tsdn, &extents->mtx);
1271  			arena_decay_extent(tsdn, arena, r_extent_hooks, extent);
1272  			return;
1273  		}
1274  	}
1275  	extent_deactivate_locked(tsdn, arena, extents, extent);
1276  	malloc_mutex_unlock(tsdn, &extents->mtx);
1277  }
1278  void
1279  extent_dalloc_gap(tsdn_t *tsdn, arena_t *arena, extent_t *extent) {
1280  	extent_hooks_t *extent_hooks = EXTENT_HOOKS_INITIALIZER;
1281  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1282  	    WITNESS_RANK_CORE, 0);
1283  	if (extent_register(tsdn, extent)) {
1284  		extent_dalloc(tsdn, arena, extent);
1285  		return;
1286  	}
1287  	extent_dalloc_wrapper(tsdn, arena, &extent_hooks, extent);
1288  }
1289  static bool
1290  extent_may_dalloc(void) {
1291  	return !opt_retain;
1292  }
1293  static bool
1294  extent_dalloc_default_impl(void *addr, size_t size) {
1295  	if (!have_dss || !extent_in_dss(addr)) {
1296  		return extent_dalloc_mmap(addr, size);
1297  	}
1298  	return true;
1299  }
1300  static bool
1301  extent_dalloc_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1302      bool committed, unsigned arena_ind) {
1303  	return extent_dalloc_default_impl(addr, size);
1304  }
1305  static bool
1306  extent_dalloc_wrapper_try(tsdn_t *tsdn, arena_t *arena,
1307      extent_hooks_t **r_extent_hooks, extent_t *extent) {
1308  	bool err;
1309  	assert(extent_base_get(extent) != NULL);
1310  	assert(extent_size_get(extent) != 0);
1311  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1312  	    WITNESS_RANK_CORE, 0);
1313  	extent_addr_set(extent, extent_base_get(extent));
1314  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1315  	if (*r_extent_hooks == &extent_hooks_default) {
1316  		err = extent_dalloc_default_impl(extent_base_get(extent),
1317  		    extent_size_get(extent));
1318  	} else {
1319  		extent_hook_pre_reentrancy(tsdn, arena);
1320  		err = ((*r_extent_hooks)->dalloc == NULL ||
1321  		    (*r_extent_hooks)->dalloc(*r_extent_hooks,
1322  		    extent_base_get(extent), extent_size_get(extent),
1323  		    extent_committed_get(extent), arena_ind_get(arena)));
1324  		extent_hook_post_reentrancy(tsdn);
1325  	}
1326  	if (!err) {
1327  		extent_dalloc(tsdn, arena, extent);
1328  	}
1329  	return err;
1330  }
1331  void
1332  extent_dalloc_wrapper(tsdn_t *tsdn, arena_t *arena,
1333      extent_hooks_t **r_extent_hooks, extent_t *extent) {
1334  	assert(extent_dumpable_get(extent));
1335  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1336  	    WITNESS_RANK_CORE, 0);
1337  	if (*r_extent_hooks != &extent_hooks_default || extent_may_dalloc()) {
1338  		extent_deregister(tsdn, extent);
1339  		if (!extent_dalloc_wrapper_try(tsdn, arena, r_extent_hooks,
1340  		    extent)) {
1341  			return;
1342  		}
1343  		extent_reregister(tsdn, extent);
1344  	}
1345  	if (*r_extent_hooks != &extent_hooks_default) {
1346  		extent_hook_pre_reentrancy(tsdn, arena);
1347  	}
1348  	bool zeroed;
1349  	if (!extent_committed_get(extent)) {
1350  		zeroed = true;
1351  	} else if (!extent_decommit_wrapper(tsdn, arena, r_extent_hooks, extent,
1352  	    0, extent_size_get(extent))) {
1353  		zeroed = true;
1354  	} else if ((*r_extent_hooks)->purge_forced != NULL &&
1355  	    !(*r_extent_hooks)->purge_forced(*r_extent_hooks,
1356  	    extent_base_get(extent), extent_size_get(extent), 0,
1357  	    extent_size_get(extent), arena_ind_get(arena))) {
1358  		zeroed = true;
1359  	} else if (extent_state_get(extent) == extent_state_muzzy ||
1360  	    ((*r_extent_hooks)->purge_lazy != NULL &&
1361  	    !(*r_extent_hooks)->purge_lazy(*r_extent_hooks,
1362  	    extent_base_get(extent), extent_size_get(extent), 0,
1363  	    extent_size_get(extent), arena_ind_get(arena)))) {
1364  		zeroed = false;
1365  	} else {
1366  		zeroed = false;
1367  	}
1368  	if (*r_extent_hooks != &extent_hooks_default) {
1369  		extent_hook_post_reentrancy(tsdn);
1370  	}
1371  	extent_zeroed_set(extent, zeroed);
1372  	if (config_prof) {
1373  		extent_gdump_sub(tsdn, extent);
1374  	}
1375  	extent_record(tsdn, arena, r_extent_hooks, &arena->extents_retained,
1376  	    extent, false);
1377  }
1378  static void
1379  extent_destroy_default_impl(void *addr, size_t size) {
1380  	if (!have_dss || !extent_in_dss(addr)) {
1381  		pages_unmap(addr, size);
1382  	}
1383  }
1384  static void
1385  extent_destroy_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1386      bool committed, unsigned arena_ind) {
1387  	extent_destroy_default_impl(addr, size);
1388  }
1389  void
1390  extent_destroy_wrapper(tsdn_t *tsdn, arena_t *arena,
1391      extent_hooks_t **r_extent_hooks, extent_t *extent) {
1392  	assert(extent_base_get(extent) != NULL);
1393  	assert(extent_size_get(extent) != 0);
1394  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1395  	    WITNESS_RANK_CORE, 0);
1396  	extent_deregister(tsdn, extent);
1397  	extent_addr_set(extent, extent_base_get(extent));
1398  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1399  	if (*r_extent_hooks == &extent_hooks_default) {
1400  		extent_destroy_default_impl(extent_base_get(extent),
1401  		    extent_size_get(extent));
1402  	} else if ((*r_extent_hooks)->destroy != NULL) {
1403  		extent_hook_pre_reentrancy(tsdn, arena);
1404  		(*r_extent_hooks)->destroy(*r_extent_hooks,
1405  		    extent_base_get(extent), extent_size_get(extent),
1406  		    extent_committed_get(extent), arena_ind_get(arena));
1407  		extent_hook_post_reentrancy(tsdn);
1408  	}
1409  	extent_dalloc(tsdn, arena, extent);
1410  }
1411  static bool
1412  extent_commit_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1413      size_t offset, size_t length, unsigned arena_ind) {
1414  	return pages_commit((void *)((uintptr_t)addr + (uintptr_t)offset),
1415  	    length);
1416  }
1417  static bool
1418  extent_commit_impl(tsdn_t *tsdn, arena_t *arena,
1419      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1420      size_t length, bool growing_retained) {
1421  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1422  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
1423  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1424  	if (*r_extent_hooks != &extent_hooks_default) {
1425  		extent_hook_pre_reentrancy(tsdn, arena);
1426  	}
1427  	bool err = ((*r_extent_hooks)->commit == NULL ||
1428  	    (*r_extent_hooks)->commit(*r_extent_hooks, extent_base_get(extent),
1429  	    extent_size_get(extent), offset, length, arena_ind_get(arena)));
1430  	if (*r_extent_hooks != &extent_hooks_default) {
1431  		extent_hook_post_reentrancy(tsdn);
1432  	}
1433  	extent_committed_set(extent, extent_committed_get(extent) || !err);
1434  	return err;
1435  }
1436  bool
1437  extent_commit_wrapper(tsdn_t *tsdn, arena_t *arena,
1438      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1439      size_t length) {
1440  	return extent_commit_impl(tsdn, arena, r_extent_hooks, extent, offset,
1441  	    length, false);
1442  }
1443  static bool
1444  extent_decommit_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1445      size_t offset, size_t length, unsigned arena_ind) {
1446  	return pages_decommit((void *)((uintptr_t)addr + (uintptr_t)offset),
1447  	    length);
1448  }
1449  bool
1450  extent_decommit_wrapper(tsdn_t *tsdn, arena_t *arena,
1451      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1452      size_t length) {
1453  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1454  	    WITNESS_RANK_CORE, 0);
1455  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1456  	if (*r_extent_hooks != &extent_hooks_default) {
1457  		extent_hook_pre_reentrancy(tsdn, arena);
1458  	}
1459  	bool err = ((*r_extent_hooks)->decommit == NULL ||
1460  	    (*r_extent_hooks)->decommit(*r_extent_hooks,
1461  	    extent_base_get(extent), extent_size_get(extent), offset, length,
1462  	    arena_ind_get(arena)));
1463  	if (*r_extent_hooks != &extent_hooks_default) {
1464  		extent_hook_post_reentrancy(tsdn);
1465  	}
1466  	extent_committed_set(extent, extent_committed_get(extent) && err);
1467  	return err;
1468  }
1469  #ifdef PAGES_CAN_PURGE_LAZY
1470  static bool
1471  extent_purge_lazy_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1472      size_t offset, size_t length, unsigned arena_ind) {
1473  	assert(addr != NULL);
1474  	assert((offset & PAGE_MASK) == 0);
1475  	assert(length != 0);
1476  	assert((length & PAGE_MASK) == 0);
1477  	return pages_purge_lazy((void *)((uintptr_t)addr + (uintptr_t)offset),
1478  	    length);
1479  }
1480  #endif
1481  static bool
1482  extent_purge_lazy_impl(tsdn_t *tsdn, arena_t *arena,
1483      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1484      size_t length, bool growing_retained) {
1485  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1486  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
1487  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1488  	if ((*r_extent_hooks)->purge_lazy == NULL) {
1489  		return true;
1490  	}
1491  	if (*r_extent_hooks != &extent_hooks_default) {
1492  		extent_hook_pre_reentrancy(tsdn, arena);
1493  	}
1494  	bool err = (*r_extent_hooks)->purge_lazy(*r_extent_hooks,
1495  	    extent_base_get(extent), extent_size_get(extent), offset, length,
1496  	    arena_ind_get(arena));
1497  	if (*r_extent_hooks != &extent_hooks_default) {
1498  		extent_hook_post_reentrancy(tsdn);
1499  	}
1500  	return err;
1501  }
1502  bool
1503  extent_purge_lazy_wrapper(tsdn_t *tsdn, arena_t *arena,
1504      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1505      size_t length) {
1506  	return extent_purge_lazy_impl(tsdn, arena, r_extent_hooks, extent,
1507  	    offset, length, false);
1508  }
1509  #ifdef PAGES_CAN_PURGE_FORCED
1510  static bool
1511  extent_purge_forced_default(extent_hooks_t *extent_hooks, void *addr,
1512      size_t size, size_t offset, size_t length, unsigned arena_ind) {
1513  	assert(addr != NULL);
1514  	assert((offset & PAGE_MASK) == 0);
1515  	assert(length != 0);
1516  	assert((length & PAGE_MASK) == 0);
1517  	return pages_purge_forced((void *)((uintptr_t)addr +
1518  	    (uintptr_t)offset), length);
1519  }
1520  #endif
1521  static bool
1522  extent_purge_forced_impl(tsdn_t *tsdn, arena_t *arena,
1523      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1524      size_t length, bool growing_retained) {
1525  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1526  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
1527  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1528  	if ((*r_extent_hooks)->purge_forced == NULL) {
1529  		return true;
1530  	}
1531  	if (*r_extent_hooks != &extent_hooks_default) {
1532  		extent_hook_pre_reentrancy(tsdn, arena);
1533  	}
1534  	bool err = (*r_extent_hooks)->purge_forced(*r_extent_hooks,
1535  	    extent_base_get(extent), extent_size_get(extent), offset, length,
1536  	    arena_ind_get(arena));
1537  	if (*r_extent_hooks != &extent_hooks_default) {
1538  		extent_hook_post_reentrancy(tsdn);
1539  	}
1540  	return err;
1541  }
1542  bool
1543  extent_purge_forced_wrapper(tsdn_t *tsdn, arena_t *arena,
1544      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t offset,
1545      size_t length) {
1546  	return extent_purge_forced_impl(tsdn, arena, r_extent_hooks, extent,
1547  	    offset, length, false);
1548  }
1549  static bool
1550  extent_split_default(extent_hooks_t *extent_hooks, void *addr, size_t size,
1551      size_t size_a, size_t size_b, bool committed, unsigned arena_ind) {
1552  	if (!maps_coalesce) {
1553  		return !opt_retain;
1554  	}
1555  	return false;
1556  }
1557  static extent_t *
1558  extent_split_impl(tsdn_t *tsdn, arena_t *arena,
1559      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t size_a,
1560      szind_t szind_a, bool slab_a, size_t size_b, szind_t szind_b, bool slab_b,
1561      bool growing_retained) {
1562  	assert(extent_size_get(extent) == size_a + size_b);
1563  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1564  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
1565  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1566  	if ((*r_extent_hooks)->split == NULL) {
1567  		return NULL;
1568  	}
1569  	extent_t *trail = extent_alloc(tsdn, arena);
1570  	if (trail == NULL) {
1571  		goto label_error_a;
1572  	}
1573  	extent_init(trail, arena, (void *)((uintptr_t)extent_base_get(extent) +
1574  	    size_a), size_b, slab_b, szind_b, extent_sn_get(extent),
1575  	    extent_state_get(extent), extent_zeroed_get(extent),
1576  	    extent_committed_get(extent), extent_dumpable_get(extent),
1577  	    EXTENT_NOT_HEAD);
1578  	rtree_ctx_t rtree_ctx_fallback;
1579  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
1580  	rtree_leaf_elm_t *lead_elm_a, *lead_elm_b;
1581  	{
1582  		extent_t lead;
1583  		extent_init(&lead, arena, extent_addr_get(extent), size_a,
1584  		    slab_a, szind_a, extent_sn_get(extent),
1585  		    extent_state_get(extent), extent_zeroed_get(extent),
1586  		    extent_committed_get(extent), extent_dumpable_get(extent),
1587  		    EXTENT_NOT_HEAD);
1588  		extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, &lead, false,
1589  		    true, &lead_elm_a, &lead_elm_b);
1590  	}
1591  	rtree_leaf_elm_t *trail_elm_a, *trail_elm_b;
1592  	extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, trail, false, true,
1593  	    &trail_elm_a, &trail_elm_b);
1594  	if (lead_elm_a == NULL || lead_elm_b == NULL || trail_elm_a == NULL
1595  	    || trail_elm_b == NULL) {
1596  		goto label_error_b;
1597  	}
1598  	extent_lock2(tsdn, extent, trail);
1599  	if (*r_extent_hooks != &extent_hooks_default) {
1600  		extent_hook_pre_reentrancy(tsdn, arena);
1601  	}
1602  	bool err = (*r_extent_hooks)->split(*r_extent_hooks, extent_base_get(extent),
1603  	    size_a + size_b, size_a, size_b, extent_committed_get(extent),
1604  	    arena_ind_get(arena));
1605  	if (*r_extent_hooks != &extent_hooks_default) {
1606  		extent_hook_post_reentrancy(tsdn);
1607  	}
1608  	if (err) {
1609  		goto label_error_c;
1610  	}
1611  	extent_size_set(extent, size_a);
1612  	extent_szind_set(extent, szind_a);
1613  	extent_rtree_write_acquired(tsdn, lead_elm_a, lead_elm_b, extent,
1614  	    szind_a, slab_a);
1615  	extent_rtree_write_acquired(tsdn, trail_elm_a, trail_elm_b, trail,
1616  	    szind_b, slab_b);
1617  	extent_unlock2(tsdn, extent, trail);
1618  	return trail;
1619  label_error_c:
1620  	extent_unlock2(tsdn, extent, trail);
1621  label_error_b:
1622  	extent_dalloc(tsdn, arena, trail);
1623  label_error_a:
1624  	return NULL;
1625  }
1626  extent_t *
1627  extent_split_wrapper(tsdn_t *tsdn, arena_t *arena,
1628      extent_hooks_t **r_extent_hooks, extent_t *extent, size_t size_a,
1629      szind_t szind_a, bool slab_a, size_t size_b, szind_t szind_b, bool slab_b) {
1630  	return extent_split_impl(tsdn, arena, r_extent_hooks, extent, size_a,
1631  	    szind_a, slab_a, size_b, szind_b, slab_b, false);
1632  }
1633  static bool
1634  extent_merge_default_impl(void *addr_a, void *addr_b) {
1635  	if (!maps_coalesce && !opt_retain) {
1636  		return true;
1637  	}
1638  	if (have_dss && !extent_dss_mergeable(addr_a, addr_b)) {
1639  		return true;
1640  	}
1641  	return false;
1642  }
1643  static bool
1644  extent_head_no_merge(extent_t *a, extent_t *b) {
1645  	assert(extent_base_get(a) < extent_base_get(b));
1646  	if (maps_coalesce) {
1647  		return false;
1648  	}
1649  	if (!opt_retain) {
1650  		return true;
1651  	}
1652  	if (extent_is_head_get(b)) {
1653  		assert(extent_sn_comp(a, b) != 0);
1654  		return true;
1655  	}
1656  	assert(extent_sn_comp(a, b) == 0);
1657  	return false;
1658  }
1659  static bool
1660  extent_merge_default(extent_hooks_t *extent_hooks, void *addr_a, size_t size_a,
1661      void *addr_b, size_t size_b, bool committed, unsigned arena_ind) {
1662  	if (!maps_coalesce) {
1663  		tsdn_t *tsdn = tsdn_fetch();
1664  		extent_t *a = iealloc(tsdn, addr_a);
1665  		extent_t *b = iealloc(tsdn, addr_b);
1666  		if (extent_head_no_merge(a, b)) {
1667  			return true;
1668  		}
1669  	}
1670  	return extent_merge_default_impl(addr_a, addr_b);
1671  }
1672  static bool
1673  extent_merge_impl(tsdn_t *tsdn, arena_t *arena,
1674      extent_hooks_t **r_extent_hooks, extent_t *a, extent_t *b,
1675      bool growing_retained) {
1676  	witness_assert_depth_to_rank(tsdn_witness_tsdp_get(tsdn),
1677  	    WITNESS_RANK_CORE, growing_retained ? 1 : 0);
1678  	assert(extent_base_get(a) < extent_base_get(b));
1679  	extent_hooks_assure_initialized(arena, r_extent_hooks);
1680  	if ((*r_extent_hooks)->merge == NULL || extent_head_no_merge(a, b)) {
1681  		return true;
1682  	}
1683  	bool err;
1684  	if (*r_extent_hooks == &extent_hooks_default) {
1685  		err = extent_merge_default_impl(extent_base_get(a),
1686  		    extent_base_get(b));
1687  	} else {
1688  		extent_hook_pre_reentrancy(tsdn, arena);
1689  		err = (*r_extent_hooks)->merge(*r_extent_hooks,
1690  		    extent_base_get(a), extent_size_get(a), extent_base_get(b),
1691  		    extent_size_get(b), extent_committed_get(a),
1692  		    arena_ind_get(arena));
1693  		extent_hook_post_reentrancy(tsdn);
1694  	}
1695  	if (err) {
1696  		return true;
1697  	}
1698  	rtree_ctx_t rtree_ctx_fallback;
1699  	rtree_ctx_t *rtree_ctx = tsdn_rtree_ctx(tsdn, &rtree_ctx_fallback);
1700  	rtree_leaf_elm_t *a_elm_a, *a_elm_b, *b_elm_a, *b_elm_b;
1701  	extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, a, true, false, &a_elm_a,
1702  	    &a_elm_b);
1703  	extent_rtree_leaf_elms_lookup(tsdn, rtree_ctx, b, true, false, &b_elm_a,
1704  	    &b_elm_b);
1705  	extent_lock2(tsdn, a, b);
1706  	if (a_elm_b != NULL) {
1707  		rtree_leaf_elm_write(tsdn, &extents_rtree, a_elm_b, NULL,
1708  		    SC_NSIZES, false);
1709  	}
1710  	if (b_elm_b != NULL) {
1711  		rtree_leaf_elm_write(tsdn, &extents_rtree, b_elm_a, NULL,
1712  		    SC_NSIZES, false);
1713  	} else {
1714  		b_elm_b = b_elm_a;
1715  	}
1716  	extent_size_set(a, extent_size_get(a) + extent_size_get(b));
1717  	extent_szind_set(a, SC_NSIZES);
1718  	extent_sn_set(a, (extent_sn_get(a) < extent_sn_get(b)) ?
1719  	    extent_sn_get(a) : extent_sn_get(b));
1720  	extent_zeroed_set(a, extent_zeroed_get(a) && extent_zeroed_get(b));
1721  	extent_rtree_write_acquired(tsdn, a_elm_a, b_elm_b, a, SC_NSIZES,
1722  	    false);
1723  	extent_unlock2(tsdn, a, b);
1724  	extent_dalloc(tsdn, extent_arena_get(b), b);
1725  	return false;
1726  }
1727  bool
1728  extent_merge_wrapper(tsdn_t *tsdn, arena_t *arena,
1729      extent_hooks_t **r_extent_hooks, extent_t *a, extent_t *b) {
1730  	return extent_merge_impl(tsdn, arena, r_extent_hooks, a, b, false);
1731  }
1732  bool
1733  extent_boot(void) {
1734  	if (rtree_new(&extents_rtree, true)) {
1735  		return true;
1736  	}
1737  	if (mutex_pool_init(&extent_mutex_pool, "extent_mutex_pool",
1738  	    WITNESS_RANK_EXTENT_POOL)) {
1739  		return true;
1740  	}
1741  	if (have_dss) {
1742  		extent_dss_boot();
1743  	}
1744  	return false;
1745  }
1746  void
1747  extent_util_stats_get(tsdn_t *tsdn, const void *ptr,
1748      size_t *nfree, size_t *nregs, size_t *size) {
1749  	assert(ptr != NULL && nfree != NULL && nregs != NULL && size != NULL);
1750  	const extent_t *extent = iealloc(tsdn, ptr);
1751  	if (unlikely(extent == NULL)) {
1752  		*nfree = *nregs = *size = 0;
1753  		return;
1754  	}
1755  	*size = extent_size_get(extent);
1756  	if (!extent_slab_get(extent)) {
1757  		*nfree = 0;
1758  		*nregs = 1;
1759  	} else {
1760  		*nfree = extent_nfree_get(extent);
1761  		*nregs = bin_infos[extent_szind_get(extent)].nregs;
1762  		assert(*nfree <= *nregs);
1763  		assert(*nfree * extent_usize_get(extent) <= *size);
1764  	}
1765  }
1766  void
1767  extent_util_stats_verbose_get(tsdn_t *tsdn, const void *ptr,
1768      size_t *nfree, size_t *nregs, size_t *size,
1769      size_t *bin_nfree, size_t *bin_nregs, void **slabcur_addr) {
1770  	assert(ptr != NULL && nfree != NULL && nregs != NULL && size != NULL
1771  	    && bin_nfree != NULL && bin_nregs != NULL && slabcur_addr != NULL);
1772  	const extent_t *extent = iealloc(tsdn, ptr);
1773  	if (unlikely(extent == NULL)) {
1774  		*nfree = *nregs = *size = *bin_nfree = *bin_nregs = 0;
1775  		*slabcur_addr = NULL;
1776  		return;
1777  	}
1778  	*size = extent_size_get(extent);
1779  	if (!extent_slab_get(extent)) {
1780  		*nfree = *bin_nfree = *bin_nregs = 0;
1781  		*nregs = 1;
1782  		*slabcur_addr = NULL;
1783  		return;
1784  	}
1785  	*nfree = extent_nfree_get(extent);
1786  	const szind_t szind = extent_szind_get(extent);
1787  	*nregs = bin_infos[szind].nregs;
1788  	assert(*nfree <= *nregs);
1789  	assert(*nfree * extent_usize_get(extent) <= *size);
1790  	const arena_t *arena = extent_arena_get(extent);
1791  	assert(arena != NULL);
1792  	const unsigned binshard = extent_binshard_get(extent);
1793  	bin_t *bin = &arena->bins[szind].bin_shards[binshard];
1794  	malloc_mutex_lock(tsdn, &bin->lock);
1795  	if (config_stats) {
1796  		*bin_nregs = *nregs * bin->stats.curslabs;
1797  		assert(*bin_nregs >= bin->stats.curregs);
1798  		*bin_nfree = *bin_nregs - bin->stats.curregs;
1799  	} else {
1800  		*bin_nfree = *bin_nregs = 0;
1801  	}
1802  	*slabcur_addr = extent_addr_get(bin->slabcur);
1803  	assert(*slabcur_addr != NULL);
1804  	malloc_mutex_unlock(tsdn, &bin->lock);
1805  }
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-extent_24.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-extent_24.c</div>
                </div>
                <div class="column column_space"><pre><code>418  	    WITNESS_RANK_CORE, 0);
419  	extent_addr_set(extent, extent_base_get(extent));
420  	extent_zeroed_set(extent, false);
421  	extent_record(tsdn, arena, r_extent_hooks, extents, extent, false);
</pre></code></div>
                <div class="column column_space"><pre><code>418  	    WITNESS_RANK_CORE, 0);
419  	extent_addr_set(extent, extent_base_get(extent));
420  	extent_zeroed_set(extent, false);
421  	extent_record(tsdn, arena, r_extent_hooks, extents, extent, false);
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    