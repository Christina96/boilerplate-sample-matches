
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 3.007518796992481%, Tokens: 10</h2>
        <div class="column">
            <h3>xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-strtod.h</h3>
            <pre><code>1  #ifndef RAPIDJSON_STRTOD_
2  #define RAPIDJSON_STRTOD_
3  #include "ieee754.h"
4  #include "biginteger.h"
5  #include "diyfp.h"
6  #include "pow10.h"
7  #include <climits>
8  #include <limits>
9  RAPIDJSON_NAMESPACE_BEGIN
10  namespace internal {
11  inline double FastPath(double significand, int exp) {
12      if (exp < -308)
13          return 0.0;
14      else if (exp >= 0)
15          return significand * internal::Pow10(exp);
16      else
17          return significand / internal::Pow10(-exp);
18  }
<span onclick='openModal()' class='match'>19  inline double StrtodNormalPrecision(double d, int p) {
20      if (p < -308) {
21          d = FastPath(d, -308);
22          d = FastPath(d, p + 308);
23      }
24      else
25          d = FastPath(d, p);
26      return d;
27  }
</span>28  template <typename T>
29  inline T Min3(T a, T b, T c) {
30      T m = a;
31      if (m > b) m = b;
32      if (m > c) m = c;
33      return m;
34  }
35  inline int CheckWithinHalfULP(double b, const BigInteger& d, int dExp) {
36      const Double db(b);
37      const uint64_t bInt = db.IntegerSignificand();
38      const int bExp = db.IntegerExponent();
39      const int hExp = bExp - 1;
40      int dS_Exp2 = 0, dS_Exp5 = 0, bS_Exp2 = 0, bS_Exp5 = 0, hS_Exp2 = 0, hS_Exp5 = 0;
41      if (dExp >= 0) {
42          dS_Exp2 += dExp;
43          dS_Exp5 += dExp;
44      }
45      else {
46          bS_Exp2 -= dExp;
47          bS_Exp5 -= dExp;
48          hS_Exp2 -= dExp;
49          hS_Exp5 -= dExp;
50      }
51      if (bExp >= 0)
52          bS_Exp2 += bExp;
53      else {
54          dS_Exp2 -= bExp;
55          hS_Exp2 -= bExp;
56      }
57      if (hExp >= 0)
58          hS_Exp2 += hExp;
59      else {
60          dS_Exp2 -= hExp;
61          bS_Exp2 -= hExp;
62      }
63      int common_Exp2 = Min3(dS_Exp2, bS_Exp2, hS_Exp2);
64      dS_Exp2 -= common_Exp2;
65      bS_Exp2 -= common_Exp2;
66      hS_Exp2 -= common_Exp2;
67      BigInteger dS = d;
68      dS.MultiplyPow5(static_cast<unsigned>(dS_Exp5)) <<= static_cast<unsigned>(dS_Exp2);
69      BigInteger bS(bInt);
70      bS.MultiplyPow5(static_cast<unsigned>(bS_Exp5)) <<= static_cast<unsigned>(bS_Exp2);
71      BigInteger hS(1);
72      hS.MultiplyPow5(static_cast<unsigned>(hS_Exp5)) <<= static_cast<unsigned>(hS_Exp2);
73      BigInteger delta(0);
74      dS.Difference(bS, &delta);
75      return delta.Compare(hS);
76  }
77  inline bool StrtodFast(double d, int p, double* result) {
78      if (p > 22  && p < 22 + 16) {
79          d *= internal::Pow10(p - 22);
80          p = 22;
81      }
82      if (p >= -22 && p <= 22 && d <= 9007199254740991.0) { 
83          *result = FastPath(d, p);
84          return true;
85      }
86      else
87          return false;
88  }
89  template<typename Ch>
90  inline bool StrtodDiyFp(const Ch* decimals, int dLen, int dExp, double* result) {
91      uint64_t significand = 0;
92      int i = 0;   
93      for (; i < dLen; i++) {
94          if (significand  >  RAPIDJSON_UINT64_C2(0x19999999, 0x99999999) ||
95              (significand == RAPIDJSON_UINT64_C2(0x19999999, 0x99999999) && decimals[i] > Ch('5')))
96              break;
97          significand = significand * 10u + static_cast<unsigned>(decimals[i] - Ch('0'));
98      }
99      if (i < dLen && decimals[i] >= Ch('5')) 
100          significand++;
101      int remaining = dLen - i;
102      const int kUlpShift = 3;
103      const int kUlp = 1 << kUlpShift;
104      int64_t error = (remaining == 0) ? 0 : kUlp / 2;
105      DiyFp v(significand, 0);
106      v = v.Normalize();
107      error <<= -v.e;
108      dExp += remaining;
109      int actualExp;
110      DiyFp cachedPower = GetCachedPower10(dExp, &actualExp);
111      if (actualExp != dExp) {
112          static const DiyFp kPow10[] = {
113              DiyFp(RAPIDJSON_UINT64_C2(0xa0000000, 0x00000000), -60),  
114              DiyFp(RAPIDJSON_UINT64_C2(0xc8000000, 0x00000000), -57),  
115              DiyFp(RAPIDJSON_UINT64_C2(0xfa000000, 0x00000000), -54),  
116              DiyFp(RAPIDJSON_UINT64_C2(0x9c400000, 0x00000000), -50),  
117              DiyFp(RAPIDJSON_UINT64_C2(0xc3500000, 0x00000000), -47),  
118              DiyFp(RAPIDJSON_UINT64_C2(0xf4240000, 0x00000000), -44),  
119              DiyFp(RAPIDJSON_UINT64_C2(0x98968000, 0x00000000), -40)   
120          };
121          int adjustment = dExp - actualExp;
122          RAPIDJSON_ASSERT(adjustment >= 1 && adjustment < 8);
123          v = v * kPow10[adjustment - 1];
124          if (dLen + adjustment > 19) 
125              error += kUlp / 2;
126      }
127      v = v * cachedPower;
128      error += kUlp + (error == 0 ? 0 : 1);
129      const int oldExp = v.e;
130      v = v.Normalize();
131      error <<= oldExp - v.e;
132      const int effectiveSignificandSize = Double::EffectiveSignificandSize(64 + v.e);
133      int precisionSize = 64 - effectiveSignificandSize;
134      if (precisionSize + kUlpShift >= 64) {
135          int scaleExp = (precisionSize + kUlpShift) - 63;
136          v.f >>= scaleExp;
137          v.e += scaleExp;
138          error = (error >> scaleExp) + 1 + kUlp;
139          precisionSize -= scaleExp;
140      }
141      DiyFp rounded(v.f >> precisionSize, v.e + precisionSize);
142      const uint64_t precisionBits = (v.f & ((uint64_t(1) << precisionSize) - 1)) * kUlp;
143      const uint64_t halfWay = (uint64_t(1) << (precisionSize - 1)) * kUlp;
144      if (precisionBits >= halfWay + static_cast<unsigned>(error)) {
145          rounded.f++;
146          if (rounded.f & (DiyFp::kDpHiddenBit << 1)) { 
147              rounded.f >>= 1;
148              rounded.e++;
149          }
150      }
151      *result = rounded.ToDouble();
152      return halfWay - static_cast<unsigned>(error) >= precisionBits || precisionBits >= halfWay + static_cast<unsigned>(error);
153  }
154  template<typename Ch>
155  inline double StrtodBigInteger(double approx, const Ch* decimals, int dLen, int dExp) {
156      RAPIDJSON_ASSERT(dLen >= 0);
157      const BigInteger dInt(decimals, static_cast<unsigned>(dLen));
158      Double a(approx);
159      int cmp = CheckWithinHalfULP(a.Value(), dInt, dExp);
160      if (cmp < 0)
161          return a.Value();  
162      else if (cmp == 0) {
163          if (a.Significand() & 1)
164              return a.NextPositiveDouble();
165          else
166              return a.Value();
167      }
168      else 
169          return a.NextPositiveDouble();
170  }
171  template<typename Ch>
172  inline double StrtodFullPrecision(double d, int p, const Ch* decimals, size_t length, size_t decimalPosition, int exp) {
173      RAPIDJSON_ASSERT(d >= 0.0);
174      RAPIDJSON_ASSERT(length >= 1);
175      double result = 0.0;
176      if (StrtodFast(d, p, &result))
177          return result;
178      RAPIDJSON_ASSERT(length <= INT_MAX);
179      int dLen = static_cast<int>(length);
180      RAPIDJSON_ASSERT(length >= decimalPosition);
181      RAPIDJSON_ASSERT(length - decimalPosition <= INT_MAX);
182      int dExpAdjust = static_cast<int>(length - decimalPosition);
183      RAPIDJSON_ASSERT(exp >= INT_MIN + dExpAdjust);
184      int dExp = exp - dExpAdjust;
185      RAPIDJSON_ASSERT(dExp <= INT_MAX - dLen);
186      while (dLen > 0 && *decimals == '0') {
187          dLen--;
188          decimals++;
189      }
190      while (dLen > 0 && decimals[dLen - 1] == '0') {
191          dLen--;
192          dExp++;
193      }
194      if (dLen == 0) { 
195          return 0.0;
196      }
197      const int kMaxDecimalDigit = 767 + 1;
198      if (dLen > kMaxDecimalDigit) {
199          dExp += dLen - kMaxDecimalDigit;
200          dLen = kMaxDecimalDigit;
201      }
202      if (dLen + dExp <= -324)
203          return 0.0;
204      if (dLen + dExp > 309)
205          return std::numeric_limits<double>::infinity();
206      if (StrtodDiyFp(decimals, dLen, dExp, &result))
207          return result;
208      return StrtodBigInteger(result, decimals, dLen, dExp);
209  }
210  } 
211  RAPIDJSON_NAMESPACE_END
212  #endif 
</code></pre>
        </div>
        <div class="column">
            <h3>redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-jemalloc_internal.h</h3>
            <pre><code>1  #ifndef JEMALLOC_INTERNAL_H
2  #define	JEMALLOC_INTERNAL_H
3  #include "jemalloc_internal_defs.h"
4  #include "jemalloc/internal/jemalloc_internal_decls.h"
5  #ifdef JEMALLOC_UTRACE
6  #include <sys/ktrace.h>
7  #endif
8  #define	JEMALLOC_NO_DEMANGLE
9  #ifdef JEMALLOC_JET
10  #  define JEMALLOC_N(n) jet_##n
11  #  include "jemalloc/internal/public_namespace.h"
12  #  define JEMALLOC_NO_RENAME
13  #  include "../jemalloc.h"
14  #  undef JEMALLOC_NO_RENAME
15  #else
16  #  define JEMALLOC_N(n) je_##n
17  #  include "../jemalloc.h"
18  #endif
19  #include "jemalloc/internal/private_namespace.h"
20  static const bool config_debug =
21  #ifdef JEMALLOC_DEBUG
22      true
23  #else
24      false
25  #endif
26      ;
27  static const bool have_dss =
28  #ifdef JEMALLOC_DSS
29      true
30  #else
31      false
32  #endif
33      ;
34  static const bool config_fill =
35  #ifdef JEMALLOC_FILL
36      true
37  #else
38      false
39  #endif
40      ;
41  static const bool config_lazy_lock =
42  #ifdef JEMALLOC_LAZY_LOCK
43      true
44  #else
45      false
46  #endif
47      ;
48  static const bool config_prof =
49  #ifdef JEMALLOC_PROF
50      true
51  #else
52      false
53  #endif
54      ;
55  static const bool config_prof_libgcc =
56  #ifdef JEMALLOC_PROF_LIBGCC
57      true
58  #else
59      false
60  #endif
61      ;
62  static const bool config_prof_libunwind =
63  #ifdef JEMALLOC_PROF_LIBUNWIND
64      true
65  #else
66      false
67  #endif
68      ;
69  static const bool maps_coalesce =
70  #ifdef JEMALLOC_MAPS_COALESCE
71      true
72  #else
73      false
74  #endif
75      ;
76  static const bool config_munmap =
77  #ifdef JEMALLOC_MUNMAP
78      true
79  #else
80      false
81  #endif
82      ;
83  static const bool config_stats =
84  #ifdef JEMALLOC_STATS
85      true
86  #else
87      false
88  #endif
89      ;
90  static const bool config_tcache =
91  #ifdef JEMALLOC_TCACHE
92      true
93  #else
94      false
95  #endif
96      ;
97  static const bool config_tls =
98  #ifdef JEMALLOC_TLS
99      true
100  #else
101      false
102  #endif
103      ;
104  static const bool config_utrace =
105  #ifdef JEMALLOC_UTRACE
106      true
107  #else
108      false
109  #endif
110      ;
111  static const bool config_valgrind =
112  #ifdef JEMALLOC_VALGRIND
113      true
114  #else
115      false
116  #endif
117      ;
118  static const bool config_xmalloc =
119  #ifdef JEMALLOC_XMALLOC
120      true
121  #else
122      false
123  #endif
124      ;
125  static const bool config_ivsalloc =
126  #ifdef JEMALLOC_IVSALLOC
127      true
128  #else
129      false
130  #endif
131      ;
132  static const bool config_cache_oblivious =
133  #ifdef JEMALLOC_CACHE_OBLIVIOUS
134      true
135  #else
136      false
137  #endif
138      ;
139  #ifdef JEMALLOC_C11ATOMICS
140  #include <stdatomic.h>
141  #endif
142  #ifdef JEMALLOC_ATOMIC9
143  #include <machine/atomic.h>
144  #endif
145  #if (defined(JEMALLOC_OSATOMIC) || defined(JEMALLOC_OSSPIN))
146  #include <libkern/OSAtomic.h>
147  #endif
148  #ifdef JEMALLOC_ZONE
149  #include <mach/mach_error.h>
150  #include <mach/mach_init.h>
151  #include <mach/vm_map.h>
152  #include <malloc/malloc.h>
153  #endif
154  #define	RB_COMPACT
155  #include "jemalloc/internal/rb.h"
156  #include "jemalloc/internal/qr.h"
157  #include "jemalloc/internal/ql.h"
158  #define	JEMALLOC_H_TYPES
159  #include "jemalloc/internal/jemalloc_internal_macros.h"
160  typedef unsigned szind_t;
161  #define	MALLOCX_ARENA_MASK	((int)~0xfffff)
162  #define	MALLOCX_ARENA_MAX	0xffe
163  #define	MALLOCX_TCACHE_MASK	((int)~0xfff000ffU)
164  #define	MALLOCX_TCACHE_MAX	0xffd
165  #define	MALLOCX_LG_ALIGN_MASK	((int)0x3f)
166  #define	MALLOCX_ALIGN_GET_SPECIFIED(flags)				\
167      (ZU(1) << (flags & MALLOCX_LG_ALIGN_MASK))
168  #define	MALLOCX_ALIGN_GET(flags)					\
169      (MALLOCX_ALIGN_GET_SPECIFIED(flags) & (SIZE_T_MAX-1))
170  #define	MALLOCX_ZERO_GET(flags)						\
171      ((bool)(flags & MALLOCX_ZERO))
172  #define	MALLOCX_TCACHE_GET(flags)					\
173      (((unsigned)((flags & MALLOCX_TCACHE_MASK) >> 8)) - 2)
174  #define	MALLOCX_ARENA_GET(flags)					\
175      (((unsigned)(((unsigned)flags) >> 20)) - 1)
176  #define	TINY_MIN		(1U << LG_TINY_MIN)
177  #ifndef LG_QUANTUM
178  #  if (defined(__i386__) || defined(_M_IX86))
179  #    define LG_QUANTUM		4
180  #  endif
181  #  ifdef __ia64__
182  #    define LG_QUANTUM		4
183  #  endif
184  #  ifdef __alpha__
185  #    define LG_QUANTUM		4
186  #  endif
187  #  if (defined(__sparc64__) || defined(__sparcv9))
188  #    define LG_QUANTUM		4
189  #  endif
190  #  if (defined(__amd64__) || defined(__x86_64__) || defined(_M_X64))
191  #    define LG_QUANTUM		4
192  #  endif
193  #  ifdef __arm__
194  #    define LG_QUANTUM		3
195  #  endif
196  #  ifdef __aarch64__
197  #    define LG_QUANTUM		4
198  #  endif
199  #  ifdef __hppa__
200  #    define LG_QUANTUM		4
201  #  endif
202  #  ifdef __mips__
203  #    define LG_QUANTUM		3
204  #  endif
205  #  ifdef __or1k__
206  #    define LG_QUANTUM		3
207  #  endif
208  #  ifdef __powerpc__
209  #    define LG_QUANTUM		4
210  #  endif
211  #  ifdef __s390__
212  #    define LG_QUANTUM		4
213  #  endif
214  #  ifdef __SH4__
215  #    define LG_QUANTUM		4
216  #  endif
217  #  ifdef __tile__
218  #    define LG_QUANTUM		4
219  #  endif
220  #  ifdef __le32__
221  #    define LG_QUANTUM		4
222  #  endif
223  #  ifndef LG_QUANTUM
224  #    error "Unknown minimum alignment for architecture; specify via "
225  	 "--with-lg-quantum"
226  #  endif
227  #endif
228  #define	QUANTUM			((size_t)(1U << LG_QUANTUM))
229  #define	QUANTUM_MASK		(QUANTUM - 1)
230  #define	QUANTUM_CEILING(a)						\
231  	(((a) + QUANTUM_MASK) & ~QUANTUM_MASK)
232  #define	LONG			((size_t)(1U << LG_SIZEOF_LONG))
233  #define	LONG_MASK		(LONG - 1)
234  #define	LONG_CEILING(a)							\
235  	(((a) + LONG_MASK) & ~LONG_MASK)
236  #define	SIZEOF_PTR		(1U << LG_SIZEOF_PTR)
237  #define	PTR_MASK		(SIZEOF_PTR - 1)
238  #define	PTR_CEILING(a)							\
239  	(((a) + PTR_MASK) & ~PTR_MASK)
240  #define	LG_CACHELINE		6
241  #define	CACHELINE		64
242  #define	CACHELINE_MASK		(CACHELINE - 1)
243  #define	CACHELINE_CEILING(s)						\
244  	(((s) + CACHELINE_MASK) & ~CACHELINE_MASK)
245  #ifdef PAGE_MASK
246  #  undef PAGE_MASK
247  #endif
248  #define	PAGE		((size_t)(1U << LG_PAGE))
249  #define	PAGE_MASK	((size_t)(PAGE - 1))
250  #define	PAGE_CEILING(s)							\
251  	(((s) + PAGE_MASK) & ~PAGE_MASK)
252  #define	ALIGNMENT_ADDR2BASE(a, alignment)				\
253  	((void *)((uintptr_t)(a) & (-(alignment))))
254  #define	ALIGNMENT_ADDR2OFFSET(a, alignment)				\
255  	((size_t)((uintptr_t)(a) & (alignment - 1)))
256  #define	ALIGNMENT_CEILING(s, alignment)					\
257  	(((s) + (alignment - 1)) & (-(alignment)))
258  #if __STDC_VERSION__ < 199901L
259  #  ifdef _MSC_VER
260  #    include <malloc.h>
261  #    define alloca _alloca
262  #  else
263  #    ifdef JEMALLOC_HAS_ALLOCA_H
264  #      include <alloca.h>
265  #    else
266  #      include <stdlib.h>
267  #    endif
268  #  endif
269  #  define VARIABLE_ARRAY(type, name, count) \
270  	type *name = alloca(sizeof(type) * (count))
271  #else
272  #  define VARIABLE_ARRAY(type, name, count) type name[(count)]
273  #endif
274  #include "jemalloc/internal/valgrind.h"
275  #include "jemalloc/internal/util.h"
276  #include "jemalloc/internal/atomic.h"
277  #include "jemalloc/internal/prng.h"
278  #include "jemalloc/internal/ckh.h"
279  #include "jemalloc/internal/size_classes.h"
280  #include "jemalloc/internal/stats.h"
281  #include "jemalloc/internal/ctl.h"
282  #include "jemalloc/internal/mutex.h"
283  #include "jemalloc/internal/tsd.h"
284  #include "jemalloc/internal/mb.h"
285  #include "jemalloc/internal/extent.h"
286  #include "jemalloc/internal/arena.h"
287  #include "jemalloc/internal/bitmap.h"
288  #include "jemalloc/internal/base.h"
289  #include "jemalloc/internal/rtree.h"
290  #include "jemalloc/internal/pages.h"
291  #include "jemalloc/internal/chunk.h"
292  #include "jemalloc/internal/huge.h"
293  #include "jemalloc/internal/tcache.h"
294  #include "jemalloc/internal/hash.h"
295  #include "jemalloc/internal/quarantine.h"
296  #include "jemalloc/internal/prof.h"
297  #undef JEMALLOC_H_TYPES
298  #define	JEMALLOC_H_STRUCTS
299  #include "jemalloc/internal/valgrind.h"
300  #include "jemalloc/internal/util.h"
301  #include "jemalloc/internal/atomic.h"
302  #include "jemalloc/internal/prng.h"
303  #include "jemalloc/internal/ckh.h"
304  #include "jemalloc/internal/size_classes.h"
305  #include "jemalloc/internal/stats.h"
306  #include "jemalloc/internal/ctl.h"
307  #include "jemalloc/internal/mutex.h"
308  #include "jemalloc/internal/mb.h"
309  #include "jemalloc/internal/bitmap.h"
310  #define	JEMALLOC_ARENA_STRUCTS_A
311  #include "jemalloc/internal/arena.h"
312  #undef JEMALLOC_ARENA_STRUCTS_A
313  #include "jemalloc/internal/extent.h"
314  #define	JEMALLOC_ARENA_STRUCTS_B
315  #include "jemalloc/internal/arena.h"
316  #undef JEMALLOC_ARENA_STRUCTS_B
317  #include "jemalloc/internal/base.h"
318  #include "jemalloc/internal/rtree.h"
319  #include "jemalloc/internal/pages.h"
320  #include "jemalloc/internal/chunk.h"
321  #include "jemalloc/internal/huge.h"
322  #include "jemalloc/internal/tcache.h"
323  #include "jemalloc/internal/hash.h"
324  #include "jemalloc/internal/quarantine.h"
325  #include "jemalloc/internal/prof.h"
326  #include "jemalloc/internal/tsd.h"
327  #undef JEMALLOC_H_STRUCTS
328  #define	JEMALLOC_H_EXTERNS
329  extern bool	opt_abort;
330  extern const char	*opt_junk;
331  extern bool	opt_junk_alloc;
332  extern bool	opt_junk_free;
333  extern size_t	opt_quarantine;
334  extern bool	opt_redzone;
335  extern bool	opt_utrace;
336  extern bool	opt_xmalloc;
337  extern bool	opt_zero;
338  extern size_t	opt_narenas;
339  extern bool	in_valgrind;
340  extern unsigned		ncpus;
341  extern size_t const	index2size_tab[NSIZES];
342  extern uint8_t const	size2index_tab[];
343  arena_t	*a0get(void);
344  void	*a0malloc(size_t size);
345  void	a0dalloc(void *ptr);
346  void	*bootstrap_malloc(size_t size);
347  void	*bootstrap_calloc(size_t num, size_t size);
348  void	bootstrap_free(void *ptr);
349  arena_t	*arenas_extend(unsigned ind);
350  arena_t	*arena_init(unsigned ind);
351  unsigned	narenas_total_get(void);
352  arena_t	*arena_get_hard(tsd_t *tsd, unsigned ind, bool init_if_missing);
353  arena_t	*arena_choose_hard(tsd_t *tsd);
354  void	arena_migrate(tsd_t *tsd, unsigned oldind, unsigned newind);
355  unsigned	arena_nbound(unsigned ind);
356  void	thread_allocated_cleanup(tsd_t *tsd);
357  void	thread_deallocated_cleanup(tsd_t *tsd);
358  void	arena_cleanup(tsd_t *tsd);
359  void	arenas_cache_cleanup(tsd_t *tsd);
360  void	narenas_cache_cleanup(tsd_t *tsd);
361  void	arenas_cache_bypass_cleanup(tsd_t *tsd);
362  void	jemalloc_prefork(void);
363  void	jemalloc_postfork_parent(void);
364  void	jemalloc_postfork_child(void);
365  #include "jemalloc/internal/valgrind.h"
366  #include "jemalloc/internal/util.h"
367  #include "jemalloc/internal/atomic.h"
368  #include "jemalloc/internal/prng.h"
369  #include "jemalloc/internal/ckh.h"
370  #include "jemalloc/internal/size_classes.h"
371  #include "jemalloc/internal/stats.h"
372  #include "jemalloc/internal/ctl.h"
373  #include "jemalloc/internal/mutex.h"
374  #include "jemalloc/internal/mb.h"
375  #include "jemalloc/internal/bitmap.h"
376  #include "jemalloc/internal/extent.h"
377  #include "jemalloc/internal/arena.h"
378  #include "jemalloc/internal/base.h"
379  #include "jemalloc/internal/rtree.h"
380  #include "jemalloc/internal/pages.h"
381  #include "jemalloc/internal/chunk.h"
382  #include "jemalloc/internal/huge.h"
383  #include "jemalloc/internal/tcache.h"
384  #include "jemalloc/internal/hash.h"
385  #include "jemalloc/internal/quarantine.h"
386  #include "jemalloc/internal/prof.h"
387  #include "jemalloc/internal/tsd.h"
388  #undef JEMALLOC_H_EXTERNS
389  #define	JEMALLOC_H_INLINES
390  #include "jemalloc/internal/valgrind.h"
391  #include "jemalloc/internal/util.h"
392  #include "jemalloc/internal/atomic.h"
393  #include "jemalloc/internal/prng.h"
394  #include "jemalloc/internal/ckh.h"
395  #include "jemalloc/internal/size_classes.h"
396  #include "jemalloc/internal/stats.h"
397  #include "jemalloc/internal/ctl.h"
398  #include "jemalloc/internal/mutex.h"
399  #include "jemalloc/internal/tsd.h"
400  #include "jemalloc/internal/mb.h"
401  #include "jemalloc/internal/extent.h"
402  #include "jemalloc/internal/base.h"
403  #include "jemalloc/internal/rtree.h"
404  #include "jemalloc/internal/pages.h"
405  #include "jemalloc/internal/chunk.h"
406  #include "jemalloc/internal/huge.h"
407  #ifndef JEMALLOC_ENABLE_INLINE
408  szind_t	size2index_compute(size_t size);
409  szind_t	size2index_lookup(size_t size);
410  szind_t	size2index(size_t size);
411  size_t	index2size_compute(szind_t index);
412  size_t	index2size_lookup(szind_t index);
413  size_t	index2size(szind_t index);
414  size_t	s2u_compute(size_t size);
415  size_t	s2u_lookup(size_t size);
416  size_t	s2u(size_t size);
417  size_t	sa2u(size_t size, size_t alignment);
418  arena_t	*arena_choose(tsd_t *tsd, arena_t *arena);
419  arena_t	*arena_get(tsd_t *tsd, unsigned ind, bool init_if_missing,
420      bool refresh_if_missing);
421  #endif
422  #if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_C_))
423  JEMALLOC_INLINE szind_t
424  size2index_compute(size_t size)
425  {
426  #if (NTBINS != 0)
427  	if (size <= (ZU(1) << LG_TINY_MAXCLASS)) {
428  		size_t lg_tmin = LG_TINY_MAXCLASS - NTBINS + 1;
429  		size_t lg_ceil = lg_floor(pow2_ceil(size));
430  		return (lg_ceil < lg_tmin ? 0 : lg_ceil - lg_tmin);
431  	}
432  #endif
433  	{
434  		size_t x = unlikely(ZI(size) < 0) ? ((size<<1) ?
435  		    (ZU(1)<<(LG_SIZEOF_PTR+3)) : ((ZU(1)<<(LG_SIZEOF_PTR+3))-1))
436  		    : lg_floor((size<<1)-1);
437  		size_t shift = (x < LG_SIZE_CLASS_GROUP + LG_QUANTUM) ? 0 :
438  		    x - (LG_SIZE_CLASS_GROUP + LG_QUANTUM);
439  		size_t grp = shift << LG_SIZE_CLASS_GROUP;
440  		size_t lg_delta = (x < LG_SIZE_CLASS_GROUP + LG_QUANTUM + 1)
441  		    ? LG_QUANTUM : x - LG_SIZE_CLASS_GROUP - 1;
442  		size_t delta_inverse_mask = ZI(-1) << lg_delta;
443  		size_t mod = ((((size-1) & delta_inverse_mask) >> lg_delta)) &
444  		    ((ZU(1) << LG_SIZE_CLASS_GROUP) - 1);
445  		size_t index = NTBINS + grp + mod;
446  		return (index);
447  	}
448  }
449  JEMALLOC_ALWAYS_INLINE szind_t
450  size2index_lookup(size_t size)
451  {
452  	assert(size <= LOOKUP_MAXCLASS);
453  	{
454  		size_t ret = ((size_t)(size2index_tab[(size-1) >>
455  		    LG_TINY_MIN]));
456  		assert(ret == size2index_compute(size));
457  		return (ret);
458  	}
459  }
460  JEMALLOC_ALWAYS_INLINE szind_t
461  size2index(size_t size)
462  {
463  	assert(size > 0);
464  	if (likely(size <= LOOKUP_MAXCLASS))
465  		return (size2index_lookup(size));
466  	return (size2index_compute(size));
467  }
468  JEMALLOC_INLINE size_t
469  index2size_compute(szind_t index)
470  {
471  #if (NTBINS > 0)
472  	if (index < NTBINS)
473  		return (ZU(1) << (LG_TINY_MAXCLASS - NTBINS + 1 + index));
474  #endif
475  	{
476  		size_t reduced_index = index - NTBINS;
477  		size_t grp = reduced_index >> LG_SIZE_CLASS_GROUP;
478  		size_t mod = reduced_index & ((ZU(1) << LG_SIZE_CLASS_GROUP) -
479  		    1);
480  		size_t grp_size_mask = ~((!!grp)-1);
481  		size_t grp_size = ((ZU(1) << (LG_QUANTUM +
482  		    (LG_SIZE_CLASS_GROUP-1))) << grp) & grp_size_mask;
483  		size_t shift = (grp == 0) ? 1 : grp;
484  		size_t lg_delta = shift + (LG_QUANTUM-1);
485  		size_t mod_size = (mod+1) << lg_delta;
486  		size_t usize = grp_size + mod_size;
487  		return (usize);
488  	}
489  }
490  JEMALLOC_ALWAYS_INLINE size_t
491  index2size_lookup(szind_t index)
492  {
493  	size_t ret = (size_t)index2size_tab[index];
494  	assert(ret == index2size_compute(index));
495  	return (ret);
496  }
497  JEMALLOC_ALWAYS_INLINE size_t
498  index2size(szind_t index)
499  {
500  	assert(index < NSIZES);
501  	return (index2size_lookup(index));
502  }
503  JEMALLOC_ALWAYS_INLINE size_t
504  s2u_compute(size_t size)
505  {
506  #if (NTBINS > 0)
507  	if (size <= (ZU(1) << LG_TINY_MAXCLASS)) {
508  		size_t lg_tmin = LG_TINY_MAXCLASS - NTBINS + 1;
509  		size_t lg_ceil = lg_floor(pow2_ceil(size));
510  		return (lg_ceil < lg_tmin ? (ZU(1) << lg_tmin) :
511  		    (ZU(1) << lg_ceil));
512  	}
513  #endif
514  	{
515  		size_t x = unlikely(ZI(size) < 0) ? ((size<<1) ?
516  		    (ZU(1)<<(LG_SIZEOF_PTR+3)) : ((ZU(1)<<(LG_SIZEOF_PTR+3))-1))
517  		    : lg_floor((size<<1)-1);
518  		size_t lg_delta = (x < LG_SIZE_CLASS_GROUP + LG_QUANTUM + 1)
519  		    ?  LG_QUANTUM : x - LG_SIZE_CLASS_GROUP - 1;
520  		size_t delta = ZU(1) << lg_delta;
521  		size_t delta_mask = delta - 1;
522  		size_t usize = (size + delta_mask) & ~delta_mask;
523  		return (usize);
524  	}
525  }
526  JEMALLOC_ALWAYS_INLINE size_t
527  s2u_lookup(size_t size)
528  {
529  	size_t ret = index2size_lookup(size2index_lookup(size));
530  	assert(ret == s2u_compute(size));
531  	return (ret);
532  }
533  JEMALLOC_ALWAYS_INLINE size_t
534  s2u(size_t size)
535  {
536  	assert(size > 0);
537  	if (likely(size <= LOOKUP_MAXCLASS))
538  		return (s2u_lookup(size));
539  	return (s2u_compute(size));
540  }
541  JEMALLOC_ALWAYS_INLINE size_t
542  sa2u(size_t size, size_t alignment)
543  {
544  	size_t usize;
545  	assert(alignment != 0 && ((alignment - 1) & alignment) == 0);
546  	if (size <= SMALL_MAXCLASS && alignment < PAGE) {
547  		usize = s2u(ALIGNMENT_CEILING(size, alignment));
548  		if (usize < LARGE_MINCLASS)
549  			return (usize);
550  	}
551  	if (likely(size <= large_maxclass) && likely(alignment < chunksize)) {
552  		alignment = PAGE_CEILING(alignment);
553  		usize = (size <= LARGE_MINCLASS) ? LARGE_MINCLASS : s2u(size);
554  		if (usize + large_pad + alignment - PAGE <= arena_maxrun)
555  			return (usize);
556  	}
557  	alignment = CHUNK_CEILING(alignment);
558  	if (alignment == 0) {
559  		return (0);
560  	}
561  	if (size <= chunksize)
562  		usize = chunksize;
563  	else {
564  		usize = s2u(size);
565  		if (usize < size) {
566  			return (0);
567  		}
568  	}
569  	if (usize + alignment - PAGE < usize) {
570  		return (0);
571  	}
572  	return (usize);
573  }
574  JEMALLOC_INLINE arena_t *
575  arena_choose(tsd_t *tsd, arena_t *arena)
576  {
577  	arena_t *ret;
578  	if (arena != NULL)
579  		return (arena);
580  	if (unlikely((ret = tsd_arena_get(tsd)) == NULL))
581  		ret = arena_choose_hard(tsd);
582  	return (ret);
583  }
584  JEMALLOC_INLINE arena_t *
585  arena_get(tsd_t *tsd, unsigned ind, bool init_if_missing,
586      bool refresh_if_missing)
587  {
588  	arena_t *arena;
589  	arena_t **arenas_cache = tsd_arenas_cache_get(tsd);
590  	assert(!init_if_missing || refresh_if_missing);
591  	if (unlikely(arenas_cache == NULL)) {
592  		return (arena_get_hard(tsd, ind, init_if_missing));
593  	}
594  	if (unlikely(ind >= tsd_narenas_cache_get(tsd))) {
595  		return (refresh_if_missing ? arena_get_hard(tsd, ind,
596  		    init_if_missing) : NULL);
597  	}
598  	arena = arenas_cache[ind];
599  	if (likely(arena != NULL) || !refresh_if_missing)
600  		return (arena);
601  	return (arena_get_hard(tsd, ind, init_if_missing));
602  }
603  #endif
604  #include "jemalloc/internal/bitmap.h"
605  #define	JEMALLOC_ARENA_INLINE_A
606  #include "jemalloc/internal/arena.h"
607  #undef JEMALLOC_ARENA_INLINE_A
608  #include "jemalloc/internal/tcache.h"
609  #define	JEMALLOC_ARENA_INLINE_B
610  #include "jemalloc/internal/arena.h"
611  #undef JEMALLOC_ARENA_INLINE_B
612  #include "jemalloc/internal/hash.h"
613  #include "jemalloc/internal/quarantine.h"
614  #ifndef JEMALLOC_ENABLE_INLINE
615  arena_t	*iaalloc(const void *ptr);
616  size_t	isalloc(const void *ptr, bool demote);
617  void	*iallocztm(tsd_t *tsd, size_t size, bool zero, tcache_t *tcache,
618      bool is_metadata, arena_t *arena);
619  void	*imalloct(tsd_t *tsd, size_t size, tcache_t *tcache, arena_t *arena);
620  void	*imalloc(tsd_t *tsd, size_t size);
621  void	*icalloct(tsd_t *tsd, size_t size, tcache_t *tcache, arena_t *arena);
622  void	*icalloc(tsd_t *tsd, size_t size);
623  void	*ipallocztm(tsd_t *tsd, size_t usize, size_t alignment, bool zero,
624      tcache_t *tcache, bool is_metadata, arena_t *arena);
625  void	*ipalloct(tsd_t *tsd, size_t usize, size_t alignment, bool zero,
626      tcache_t *tcache, arena_t *arena);
627  void	*ipalloc(tsd_t *tsd, size_t usize, size_t alignment, bool zero);
628  size_t	ivsalloc(const void *ptr, bool demote);
629  size_t	u2rz(size_t usize);
630  size_t	p2rz(const void *ptr);
631  void	idalloctm(tsd_t *tsd, void *ptr, tcache_t *tcache, bool is_metadata);
632  void	idalloct(tsd_t *tsd, void *ptr, tcache_t *tcache);
633  void	idalloc(tsd_t *tsd, void *ptr);
634  void	iqalloc(tsd_t *tsd, void *ptr, tcache_t *tcache);
635  void	isdalloct(tsd_t *tsd, void *ptr, size_t size, tcache_t *tcache);
636  void	isqalloc(tsd_t *tsd, void *ptr, size_t size, tcache_t *tcache);
637  void	*iralloct_realign(tsd_t *tsd, void *ptr, size_t oldsize, size_t size,
638      size_t extra, size_t alignment, bool zero, tcache_t *tcache,
639      arena_t *arena);
640  void	*iralloct(tsd_t *tsd, void *ptr, size_t oldsize, size_t size,
641      size_t alignment, bool zero, tcache_t *tcache, arena_t *arena);
642  void	*iralloc(tsd_t *tsd, void *ptr, size_t oldsize, size_t size,
643      size_t alignment, bool zero);
644  bool	ixalloc(void *ptr, size_t oldsize, size_t size, size_t extra,
645      size_t alignment, bool zero);
646  #endif
647  #if (defined(JEMALLOC_ENABLE_INLINE) || defined(JEMALLOC_C_))
648  JEMALLOC_ALWAYS_INLINE arena_t *
649  iaalloc(const void *ptr)
650  {
651  	assert(ptr != NULL);
652  	return (arena_aalloc(ptr));
653  }
654  JEMALLOC_ALWAYS_INLINE size_t
655  isalloc(const void *ptr, bool demote)
656  {
657  	assert(ptr != NULL);
658  	assert(config_prof || !demote);
659  	return (arena_salloc(ptr, demote));
660  }
661  JEMALLOC_ALWAYS_INLINE void *
662  iallocztm(tsd_t *tsd, size_t size, bool zero, tcache_t *tcache, bool is_metadata,
663      arena_t *arena)
664  {
665  	void *ret;
666  	assert(size != 0);
667  	ret = arena_malloc(tsd, arena, size, zero, tcache);
668  	if (config_stats && is_metadata && likely(ret != NULL)) {
669  		arena_metadata_allocated_add(iaalloc(ret), isalloc(ret,
670  		    config_prof));
671  	}
672  	return (ret);
673  }
674  JEMALLOC_ALWAYS_INLINE void *
675  imalloct(tsd_t *tsd, size_t size, tcache_t *tcache, arena_t *arena)
676  {
677  	return (iallocztm(tsd, size, false, tcache, false, arena));
678  }
679  JEMALLOC_ALWAYS_INLINE void *
680  imalloc(tsd_t *tsd, size_t size)
681  {
682  	return (iallocztm(tsd, size, false, tcache_get(tsd, true), false, NULL));
683  }
684  JEMALLOC_ALWAYS_INLINE void *
685  icalloct(tsd_t *tsd, size_t size, tcache_t *tcache, arena_t *arena)
686  {
687  	return (iallocztm(tsd, size, true, tcache, false, arena));
688  }
689  JEMALLOC_ALWAYS_INLINE void *
690  icalloc(tsd_t *tsd, size_t size)
691  {
692  	return (iallocztm(tsd, size, true, tcache_get(tsd, true), false, NULL));
693  }
694  JEMALLOC_ALWAYS_INLINE void *
695  ipallocztm(tsd_t *tsd, size_t usize, size_t alignment, bool zero,
696      tcache_t *tcache, bool is_metadata, arena_t *arena)
697  {
698  	void *ret;
699  	assert(usize != 0);
700  	assert(usize == sa2u(usize, alignment));
701  	ret = arena_palloc(tsd, arena, usize, alignment, zero, tcache);
702  	assert(ALIGNMENT_ADDR2BASE(ret, alignment) == ret);
703  	if (config_stats && is_metadata && likely(ret != NULL)) {
704  		arena_metadata_allocated_add(iaalloc(ret), isalloc(ret,
705  		    config_prof));
706  	}
707  	return (ret);
708  }
709  JEMALLOC_ALWAYS_INLINE void *
710  ipalloct(tsd_t *tsd, size_t usize, size_t alignment, bool zero,
711      tcache_t *tcache, arena_t *arena)
712  {
713  	return (ipallocztm(tsd, usize, alignment, zero, tcache, false, arena));
714  }
715  JEMALLOC_ALWAYS_INLINE void *
716  ipalloc(tsd_t *tsd, size_t usize, size_t alignment, bool zero)
717  {
718  	return (ipallocztm(tsd, usize, alignment, zero, tcache_get(tsd,
719  	    NULL), false, NULL));
720  }
721  JEMALLOC_ALWAYS_INLINE size_t
722  ivsalloc(const void *ptr, bool demote)
723  {
724  	extent_node_t *node;
725  	node = chunk_lookup(ptr, false);
726  	if (node == NULL)
727  		return (0);
728  	assert(extent_node_addr_get(node) == ptr ||
729  	    extent_node_achunk_get(node));
730  	return (isalloc(ptr, demote));
731  }
732  JEMALLOC_INLINE size_t
733  u2rz(size_t usize)
<span onclick='openModal()' class='match'>734  {
735  	size_t ret;
736  	if (usize <= SMALL_MAXCLASS) {
737  		szind_t binind = size2index(usize);
738  		ret = arena_bin_info[binind].redzone_size;
739  	} else
740  		ret = 0;
741  	return (ret);
742  }
</span>743  JEMALLOC_INLINE size_t
744  p2rz(const void *ptr)
745  {
746  	size_t usize = isalloc(ptr, false);
747  	return (u2rz(usize));
748  }
749  JEMALLOC_ALWAYS_INLINE void
750  idalloctm(tsd_t *tsd, void *ptr, tcache_t *tcache, bool is_metadata)
751  {
752  	assert(ptr != NULL);
753  	if (config_stats && is_metadata) {
754  		arena_metadata_allocated_sub(iaalloc(ptr), isalloc(ptr,
755  		    config_prof));
756  	}
757  	arena_dalloc(tsd, ptr, tcache);
758  }
759  JEMALLOC_ALWAYS_INLINE void
760  idalloct(tsd_t *tsd, void *ptr, tcache_t *tcache)
761  {
762  	idalloctm(tsd, ptr, tcache, false);
763  }
764  JEMALLOC_ALWAYS_INLINE void
765  idalloc(tsd_t *tsd, void *ptr)
766  {
767  	idalloctm(tsd, ptr, tcache_get(tsd, false), false);
768  }
769  JEMALLOC_ALWAYS_INLINE void
770  iqalloc(tsd_t *tsd, void *ptr, tcache_t *tcache)
771  {
772  	if (config_fill && unlikely(opt_quarantine))
773  		quarantine(tsd, ptr);
774  	else
775  		idalloctm(tsd, ptr, tcache, false);
776  }
777  JEMALLOC_ALWAYS_INLINE void
778  isdalloct(tsd_t *tsd, void *ptr, size_t size, tcache_t *tcache)
779  {
780  	arena_sdalloc(tsd, ptr, size, tcache);
781  }
782  JEMALLOC_ALWAYS_INLINE void
783  isqalloc(tsd_t *tsd, void *ptr, size_t size, tcache_t *tcache)
784  {
785  	if (config_fill && unlikely(opt_quarantine))
786  		quarantine(tsd, ptr);
787  	else
788  		isdalloct(tsd, ptr, size, tcache);
789  }
790  JEMALLOC_ALWAYS_INLINE void *
791  iralloct_realign(tsd_t *tsd, void *ptr, size_t oldsize, size_t size,
792      size_t extra, size_t alignment, bool zero, tcache_t *tcache, arena_t *arena)
793  {
794  	void *p;
795  	size_t usize, copysize;
796  	usize = sa2u(size + extra, alignment);
797  	if (usize == 0)
798  		return (NULL);
799  	p = ipalloct(tsd, usize, alignment, zero, tcache, arena);
800  	if (p == NULL) {
801  		if (extra == 0)
802  			return (NULL);
803  		usize = sa2u(size, alignment);
804  		if (usize == 0)
805  			return (NULL);
806  		p = ipalloct(tsd, usize, alignment, zero, tcache, arena);
807  		if (p == NULL)
808  			return (NULL);
809  	}
810  	copysize = (size < oldsize) ? size : oldsize;
811  	memcpy(p, ptr, copysize);
812  	isqalloc(tsd, ptr, oldsize, tcache);
813  	return (p);
814  }
815  JEMALLOC_ALWAYS_INLINE void *
816  iralloct(tsd_t *tsd, void *ptr, size_t oldsize, size_t size, size_t alignment,
817      bool zero, tcache_t *tcache, arena_t *arena)
818  {
819  	assert(ptr != NULL);
820  	assert(size != 0);
821  	if (alignment != 0 && ((uintptr_t)ptr & ((uintptr_t)alignment-1))
822  	    != 0) {
823  		return (iralloct_realign(tsd, ptr, oldsize, size, 0, alignment,
824  		    zero, tcache, arena));
825  	}
826  	return (arena_ralloc(tsd, arena, ptr, oldsize, size, alignment, zero,
827  	    tcache));
828  }
829  JEMALLOC_ALWAYS_INLINE void *
830  iralloc(tsd_t *tsd, void *ptr, size_t oldsize, size_t size, size_t alignment,
831      bool zero)
832  {
833  	return (iralloct(tsd, ptr, oldsize, size, alignment, zero,
834  	    tcache_get(tsd, true), NULL));
835  }
836  JEMALLOC_ALWAYS_INLINE bool
837  ixalloc(void *ptr, size_t oldsize, size_t size, size_t extra, size_t alignment,
838      bool zero)
839  {
840  	assert(ptr != NULL);
841  	assert(size != 0);
842  	if (alignment != 0 && ((uintptr_t)ptr & ((uintptr_t)alignment-1))
843  	    != 0) {
844  		return (true);
845  	}
846  	return (arena_ralloc_no_move(ptr, oldsize, size, extra, zero));
847  }
848  #endif
849  #include "jemalloc/internal/prof.h"
850  #undef JEMALLOC_H_INLINES
851  #endif &bsol;* JEMALLOC_INTERNAL_H */
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from xmrig-MDEwOlJlcG9zaXRvcnk4ODMyNzQwNg==-flat-strtod.h</div>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from redis-MDEwOlJlcG9zaXRvcnkxMDgxMTA3MDY=-flat-jemalloc_internal.h</div>
                <div class="column column_space"><pre><code>19  inline double StrtodNormalPrecision(double d, int p) {
20      if (p < -308) {
21          d = FastPath(d, -308);
22          d = FastPath(d, p + 308);
23      }
24      else
25          d = FastPath(d, p);
26      return d;
27  }
</pre></code></div>
                <div class="column column_space"><pre><code>734  {
735  	size_t ret;
736  	if (usize <= SMALL_MAXCLASS) {
737  		szind_t binind = size2index(usize);
738  		ret = arena_bin_info[binind].redzone_size;
739  	} else
740  		ret = 0;
741  	return (ret);
742  }
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    