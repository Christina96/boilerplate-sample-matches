
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 20, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>Adafruit_nRF52_Arduino-MDEwOlJlcG9zaXRvcnk3NDM1NDcyOQ==-flat-queue.c</h3>
            <pre><code>1  #include &lt;stdlib.h&gt;
2  #include &lt;string.h&gt;
3  #define MPU_WRAPPERS_INCLUDED_FROM_API_FILE
4  #include &quot;FreeRTOS.h&quot;
5  #include &quot;task.h&quot;
6  #include &quot;queue.h&quot;
7  #if ( configUSE_CO_ROUTINES == 1 )
8  	#include &quot;croutine.h&quot;
9  #endif
10  #undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE &amp;bsol;*lint !e961 !e750. */
11  #define queueUNLOCKED					( ( int8_t ) -1 )
12  #define queueLOCKED_UNMODIFIED			( ( int8_t ) 0 )
13  #define pxMutexHolder					pcTail
14  #define uxQueueType						pcHead
15  #define queueQUEUE_IS_MUTEX				NULL
16  #define queueSEMAPHORE_QUEUE_ITEM_LENGTH ( ( UBaseType_t ) 0 )
17  #define queueMUTEX_GIVE_BLOCK_TIME		 ( ( TickType_t ) 0U )
18  #if( configUSE_PREEMPTION == 0 )
19  	#define queueYIELD_IF_USING_PREEMPTION()
20  #else
21  	#define queueYIELD_IF_USING_PREEMPTION() portYIELD_WITHIN_API()
22  #endif
23  typedef struct QueueDefinition
24  {
25  	int8_t *pcHead;					&amp;bsol;*&lt; Points to the beginning of the queue storage area. */
26  	int8_t *pcTail;					&amp;bsol;*&lt; Points to the byte at the end of the queue storage area.  Once more byte is allocated than necessary to store the queue items, this is used as a marker. */
27  	int8_t *pcWriteTo;				&amp;bsol;*&lt; Points to the free next place in the storage area. */
28  	union							&amp;bsol;* Use of a union is an exception to the coding standard to ensure two mutually exclusive structure members don&#x27;t appear simultaneously (wasting RAM). */
29  	{
30  		int8_t *pcReadFrom;			&amp;bsol;*&lt; Points to the last place that a queued item was read from when the structure is used as a queue. */
31  		UBaseType_t uxRecursiveCallCount;&amp;bsol;*&lt; Maintains a count of the number of times a recursive mutex has been recursively &#x27;taken&#x27; when the structure is used as a mutex. */
32  	} u;
33  	List_t xTasksWaitingToSend;		&amp;bsol;*&lt; List of tasks that are blocked waiting to post onto this queue.  Stored in priority order. */
34  	List_t xTasksWaitingToReceive;	&amp;bsol;*&lt; List of tasks that are blocked waiting to read from this queue.  Stored in priority order. */
35  	volatile UBaseType_t uxMessagesWaiting;&amp;bsol;*&lt; The number of items currently in the queue. */
36  	UBaseType_t uxLength;			&amp;bsol;*&lt; The length of the queue defined as the number of items it will hold, not the number of bytes. */
37  	UBaseType_t uxItemSize;			&amp;bsol;*&lt; The size of each items that the queue will hold. */
38  	volatile int8_t cRxLock;		&amp;bsol;*&lt; Stores the number of items received from the queue (removed from the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */
39  	volatile int8_t cTxLock;		&amp;bsol;*&lt; Stores the number of items transmitted to the queue (added to the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */
40  	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
41  		uint8_t ucStaticallyAllocated;	&amp;bsol;*&lt; Set to pdTRUE if the memory used by the queue was statically allocated to ensure no attempt is made to free the memory. */
42  	#endif
43  	#if ( configUSE_QUEUE_SETS == 1 )
44  		struct QueueDefinition *pxQueueSetContainer;
45  	#endif
46  	#if ( configUSE_TRACE_FACILITY == 1 )
47  		UBaseType_t uxQueueNumber;
48  		uint8_t ucQueueType;
49  	#endif
50  } xQUEUE;
51  typedef xQUEUE Queue_t;
52  #if ( configQUEUE_REGISTRY_SIZE &gt; 0 )
53  	typedef struct QUEUE_REGISTRY_ITEM
54  	{
55  		const char *pcQueueName; &amp;bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
56  		QueueHandle_t xHandle;
57  	} xQueueRegistryItem;
58  	typedef xQueueRegistryItem QueueRegistryItem_t;
59  	PRIVILEGED_DATA QueueRegistryItem_t xQueueRegistry[ configQUEUE_REGISTRY_SIZE ];
60  #endif &amp;bsol;* configQUEUE_REGISTRY_SIZE */
61  static void prvUnlockQueue( Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;
62  static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue ) PRIVILEGED_FUNCTION;
63  static BaseType_t prvIsQueueFull( const Queue_t *pxQueue ) PRIVILEGED_FUNCTION;
64  static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition ) PRIVILEGED_FUNCTION;
65  static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer ) PRIVILEGED_FUNCTION;
66  #if ( configUSE_QUEUE_SETS == 1 )
67  	static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue, const BaseType_t xCopyPosition ) PRIVILEGED_FUNCTION;
68  #endif
69  static void prvInitialiseNewQueue( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, const uint8_t ucQueueType, Queue_t *pxNewQueue ) PRIVILEGED_FUNCTION;
70  #if( configUSE_MUTEXES == 1 )
71  	static void prvInitialiseMutex( Queue_t *pxNewQueue ) PRIVILEGED_FUNCTION;
72  #endif
73  #if( configUSE_MUTEXES == 1 )
74  	static UBaseType_t prvGetDisinheritPriorityAfterTimeout( const Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;
75  #endif
76  #define prvLockQueue( pxQueue )								\
77  	taskENTER_CRITICAL();									\
78  	{														\
79  		if( ( pxQueue )-&gt;cRxLock == queueUNLOCKED )			\
80  		{													\
81  			( pxQueue )-&gt;cRxLock = queueLOCKED_UNMODIFIED;	\
82  		}													\
83  		if( ( pxQueue )-&gt;cTxLock == queueUNLOCKED )			\
84  		{													\
85  			( pxQueue )-&gt;cTxLock = queueLOCKED_UNMODIFIED;	\
86  		}													\
87  	}														\
88  	taskEXIT_CRITICAL()
89  BaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue )
90  {
91  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
92  	configASSERT( pxQueue );
93  	taskENTER_CRITICAL();
94  	{
95  		pxQueue-&gt;pcTail = pxQueue-&gt;pcHead + ( pxQueue-&gt;uxLength * pxQueue-&gt;uxItemSize );
96  		pxQueue-&gt;uxMessagesWaiting = ( UBaseType_t ) 0U;
97  		pxQueue-&gt;pcWriteTo = pxQueue-&gt;pcHead;
98  		pxQueue-&gt;u.pcReadFrom = pxQueue-&gt;pcHead + ( ( pxQueue-&gt;uxLength - ( UBaseType_t ) 1U ) * pxQueue-&gt;uxItemSize );
99  		pxQueue-&gt;cRxLock = queueUNLOCKED;
100  		pxQueue-&gt;cTxLock = queueUNLOCKED;
101  		if( xNewQueue == pdFALSE )
102  		{
103  			if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
104  			{
105  				if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
106  				{
107  					queueYIELD_IF_USING_PREEMPTION();
108  				}
109  				else
110  				{
111  					mtCOVERAGE_TEST_MARKER();
112  				}
113  			}
114  			else
115  			{
116  				mtCOVERAGE_TEST_MARKER();
117  			}
118  		}
119  		else
120  		{
121  			vListInitialise( &amp;( pxQueue-&gt;xTasksWaitingToSend ) );
122  			vListInitialise( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) );
123  		}
124  	}
125  	taskEXIT_CRITICAL();
126  	return pdPASS;
127  }
128  #if( configSUPPORT_STATIC_ALLOCATION == 1 )
129  	QueueHandle_t xQueueGenericCreateStatic( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, StaticQueue_t *pxStaticQueue, const uint8_t ucQueueType )
130  	{
131  	Queue_t *pxNewQueue;
132  		configASSERT( uxQueueLength &gt; ( UBaseType_t ) 0 );
133  		configASSERT( pxStaticQueue != NULL );
134  		configASSERT( !( ( pucQueueStorage != NULL ) &amp;&amp; ( uxItemSize == 0 ) ) );
135  		configASSERT( !( ( pucQueueStorage == NULL ) &amp;&amp; ( uxItemSize != 0 ) ) );
136  		#if( configASSERT_DEFINED == 1 )
137  		{
138  			volatile size_t xSize = sizeof( StaticQueue_t );
139  			configASSERT( xSize == sizeof( Queue_t ) );
140  		}
141  		#endif &amp;bsol;* configASSERT_DEFINED */
142  		pxNewQueue = ( Queue_t * ) pxStaticQueue; &amp;bsol;*lint !e740 Unusual cast is ok as the structures are designed to have the same alignment, and the size is checked by an assert. */
143  		if( pxNewQueue != NULL )
144  		{
145  			#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
146  			{
147  				pxNewQueue-&gt;ucStaticallyAllocated = pdTRUE;
148  			}
149  			#endif &amp;bsol;* configSUPPORT_DYNAMIC_ALLOCATION */
150  			prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );
151  		}
152  		else
153  		{
154  			traceQUEUE_CREATE_FAILED( ucQueueType );
155  		}
156  		return pxNewQueue;
157  	}
158  #endif &amp;bsol;* configSUPPORT_STATIC_ALLOCATION */
159  #if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
160  	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType )
161  	{
162  	Queue_t *pxNewQueue;
163  	size_t xQueueSizeInBytes;
164  	uint8_t *pucQueueStorage;
165  		configASSERT( uxQueueLength &gt; ( UBaseType_t ) 0 );
166  		if( uxItemSize == ( UBaseType_t ) 0 )
167  		{
168  			xQueueSizeInBytes = ( size_t ) 0;
169  		}
170  		else
171  		{
172  			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); &amp;bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
173  		}
174  		pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );
175  		if( pxNewQueue != NULL )
176  		{
177  			pucQueueStorage = ( ( uint8_t * ) pxNewQueue ) + sizeof( Queue_t );
178  			#if( configSUPPORT_STATIC_ALLOCATION == 1 )
179  			{
180  				pxNewQueue-&gt;ucStaticallyAllocated = pdFALSE;
181  			}
182  			#endif &amp;bsol;* configSUPPORT_STATIC_ALLOCATION */
183  			prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );
184  		}
185  		else
186  		{
187  			traceQUEUE_CREATE_FAILED( ucQueueType );
188  		}
189  		return pxNewQueue;
190  	}
191  #endif &amp;bsol;* configSUPPORT_STATIC_ALLOCATION */
192  static void prvInitialiseNewQueue( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, const uint8_t ucQueueType, Queue_t *pxNewQueue )
193  {
194  	( void ) ucQueueType;
195  	if( uxItemSize == ( UBaseType_t ) 0 )
196  	{
197  		pxNewQueue-&gt;pcHead = ( int8_t * ) pxNewQueue;
198  	}
199  	else
200  	{
201  		pxNewQueue-&gt;pcHead = ( int8_t * ) pucQueueStorage;
202  	}
203  	pxNewQueue-&gt;uxLength = uxQueueLength;
204  	pxNewQueue-&gt;uxItemSize = uxItemSize;
205  	( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
206  	#if ( configUSE_TRACE_FACILITY == 1 )
207  	{
208  		pxNewQueue-&gt;ucQueueType = ucQueueType;
209  	}
210  	#endif &amp;bsol;* configUSE_TRACE_FACILITY */
211  	#if( configUSE_QUEUE_SETS == 1 )
212  	{
213  		pxNewQueue-&gt;pxQueueSetContainer = NULL;
214  	}
215  	#endif &amp;bsol;* configUSE_QUEUE_SETS */
216  	traceQUEUE_CREATE( pxNewQueue );
217  }
218  #if( configUSE_MUTEXES == 1 )
219  	static void prvInitialiseMutex( Queue_t *pxNewQueue )
220  	{
221  		if( pxNewQueue != NULL )
222  		{
223  			pxNewQueue-&gt;pxMutexHolder = NULL;
224  			pxNewQueue-&gt;uxQueueType = queueQUEUE_IS_MUTEX;
225  			pxNewQueue-&gt;u.uxRecursiveCallCount = 0;
226  			traceCREATE_MUTEX( pxNewQueue );
227  			( void ) xQueueGenericSend( pxNewQueue, NULL, ( TickType_t ) 0U, queueSEND_TO_BACK );
228  		}
229  		else
230  		{
231  			traceCREATE_MUTEX_FAILED();
232  		}
233  	}
234  #endif &amp;bsol;* configUSE_MUTEXES */
235  #if( ( configUSE_MUTEXES == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
236  	QueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType )
237  	{
238  	Queue_t *pxNewQueue;
239  	const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;
240  		pxNewQueue = ( Queue_t * ) xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );
241  		prvInitialiseMutex( pxNewQueue );
242  		return pxNewQueue;
243  	}
244  #endif &amp;bsol;* configUSE_MUTEXES */
245  #if( ( configUSE_MUTEXES == 1 ) &amp;&amp; ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
246  	QueueHandle_t xQueueCreateMutexStatic( const uint8_t ucQueueType, StaticQueue_t *pxStaticQueue )
247  	{
248  	Queue_t *pxNewQueue;
249  	const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;
250  		( void ) ucQueueType;
251  		pxNewQueue = ( Queue_t * ) xQueueGenericCreateStatic( uxMutexLength, uxMutexSize, NULL, pxStaticQueue, ucQueueType );
252  		prvInitialiseMutex( pxNewQueue );
253  		return pxNewQueue;
254  	}
255  #endif &amp;bsol;* configUSE_MUTEXES */
256  #if ( ( configUSE_MUTEXES == 1 ) &amp;&amp; ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) )
257  	void* xQueueGetMutexHolder( QueueHandle_t xSemaphore )
258  	{
259  	void *pxReturn;
260  		taskENTER_CRITICAL();
261  		{
262  			if( ( ( Queue_t * ) xSemaphore )-&gt;uxQueueType == queueQUEUE_IS_MUTEX )
263  			{
264  				pxReturn = ( void * ) ( ( Queue_t * ) xSemaphore )-&gt;pxMutexHolder;
265  			}
266  			else
267  			{
268  				pxReturn = NULL;
269  			}
270  		}
271  		taskEXIT_CRITICAL();
272  		return pxReturn;
273  	} &amp;bsol;*lint !e818 xSemaphore cannot be a pointer to const because it is a typedef. */
274  #endif
275  #if ( ( configUSE_MUTEXES == 1 ) &amp;&amp; ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) )
276  	void* xQueueGetMutexHolderFromISR( QueueHandle_t xSemaphore )
277  	{
278  	void *pxReturn;
279  		configASSERT( xSemaphore );
280  		if( ( ( Queue_t * ) xSemaphore )-&gt;uxQueueType == queueQUEUE_IS_MUTEX )
281  		{
282  			pxReturn = ( void * ) ( ( Queue_t * ) xSemaphore )-&gt;pxMutexHolder;
283  		}
284  		else
285  		{
286  			pxReturn = NULL;
287  		}
288  		return pxReturn;
289  	} &amp;bsol;*lint !e818 xSemaphore cannot be a pointer to const because it is a typedef. */
290  #endif
291  #if ( configUSE_RECURSIVE_MUTEXES == 1 )
292  	BaseType_t xQueueGiveMutexRecursive( QueueHandle_t xMutex )
293  	{
294  	BaseType_t xReturn;
295  	Queue_t * const pxMutex = ( Queue_t * ) xMutex;
296  		configASSERT( pxMutex );
297  		if( pxMutex-&gt;pxMutexHolder == ( void * ) xTaskGetCurrentTaskHandle() ) &amp;bsol;*lint !e961 Not a redundant cast as TaskHandle_t is a typedef. */
298  		{
299  			traceGIVE_MUTEX_RECURSIVE( pxMutex );
300  			( pxMutex-&gt;u.uxRecursiveCallCount )--;
301  			if( pxMutex-&gt;u.uxRecursiveCallCount == ( UBaseType_t ) 0 )
302  			{
303  				( void ) xQueueGenericSend( pxMutex, NULL, queueMUTEX_GIVE_BLOCK_TIME, queueSEND_TO_BACK );
304  			}
305  			else
306  			{
307  				mtCOVERAGE_TEST_MARKER();
308  			}
309  			xReturn = pdPASS;
310  		}
311  		else
312  		{
313  			xReturn = pdFAIL;
314  			traceGIVE_MUTEX_RECURSIVE_FAILED( pxMutex );
315  		}
316  		return xReturn;
317  	}
318  #endif &amp;bsol;* configUSE_RECURSIVE_MUTEXES */
319  #if ( configUSE_RECURSIVE_MUTEXES == 1 )
320  	BaseType_t xQueueTakeMutexRecursive( QueueHandle_t xMutex, TickType_t xTicksToWait )
321  	{
322  	BaseType_t xReturn;
323  	Queue_t * const pxMutex = ( Queue_t * ) xMutex;
324  		configASSERT( pxMutex );
325  		traceTAKE_MUTEX_RECURSIVE( pxMutex );
326  		if( pxMutex-&gt;pxMutexHolder == ( void * ) xTaskGetCurrentTaskHandle() ) &amp;bsol;*lint !e961 Cast is not redundant as TaskHandle_t is a typedef. */
327  		{
328  			( pxMutex-&gt;u.uxRecursiveCallCount )++;
329  			xReturn = pdPASS;
330  		}
331  		else
332  		{
333  			xReturn = xQueueSemaphoreTake( pxMutex, xTicksToWait );
334  			if( xReturn != pdFAIL )
335  			{
336  				( pxMutex-&gt;u.uxRecursiveCallCount )++;
337  			}
338  			else
339  			{
340  				traceTAKE_MUTEX_RECURSIVE_FAILED( pxMutex );
341  			}
342  		}
343  		return xReturn;
344  	}
345  #endif &amp;bsol;* configUSE_RECURSIVE_MUTEXES */
346  #if( ( configUSE_COUNTING_SEMAPHORES == 1 ) &amp;&amp; ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
347  	QueueHandle_t xQueueCreateCountingSemaphoreStatic( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount, StaticQueue_t *pxStaticQueue )
348  	{
349  	QueueHandle_t xHandle;
350  		configASSERT( uxMaxCount != 0 );
351  		configASSERT( uxInitialCount &lt;= uxMaxCount );
352  		xHandle = xQueueGenericCreateStatic( uxMaxCount, queueSEMAPHORE_QUEUE_ITEM_LENGTH, NULL, pxStaticQueue, queueQUEUE_TYPE_COUNTING_SEMAPHORE );
353  		if( xHandle != NULL )
354  		{
355  			( ( Queue_t * ) xHandle )-&gt;uxMessagesWaiting = uxInitialCount;
356  			traceCREATE_COUNTING_SEMAPHORE();
357  		}
358  		else
359  		{
360  			traceCREATE_COUNTING_SEMAPHORE_FAILED();
361  		}
362  		return xHandle;
363  	}
364  #endif &amp;bsol;* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
365  #if( ( configUSE_COUNTING_SEMAPHORES == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
366  	QueueHandle_t xQueueCreateCountingSemaphore( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount )
367  	{
368  	QueueHandle_t xHandle;
369  		configASSERT( uxMaxCount != 0 );
370  		configASSERT( uxInitialCount &lt;= uxMaxCount );
371  		xHandle = xQueueGenericCreate( uxMaxCount, queueSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_COUNTING_SEMAPHORE );
372  		if( xHandle != NULL )
373  		{
374  			( ( Queue_t * ) xHandle )-&gt;uxMessagesWaiting = uxInitialCount;
375  			traceCREATE_COUNTING_SEMAPHORE();
376  		}
377  		else
378  		{
379  			traceCREATE_COUNTING_SEMAPHORE_FAILED();
380  		}
381  		return xHandle;
382  	}
383  #endif &amp;bsol;* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
384  BaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition )
385  {
386  BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
387  TimeOut_t xTimeOut;
388  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
389  	configASSERT( pxQueue );
390  	configASSERT( !( ( pvItemToQueue == NULL ) &amp;&amp; ( pxQueue-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
391  	configASSERT( !( ( xCopyPosition == queueOVERWRITE ) &amp;&amp; ( pxQueue-&gt;uxLength != 1 ) ) );
392  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
393  	{
394  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) &amp;&amp; ( xTicksToWait != 0 ) ) );
395  	}
396  	#endif
397  	for( ;; )
398  	{
399  		taskENTER_CRITICAL();
400  		{
401  			if( ( pxQueue-&gt;uxMessagesWaiting &lt; pxQueue-&gt;uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
402  			{
403  				traceQUEUE_SEND( pxQueue );
404  				xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
405  				#if ( configUSE_QUEUE_SETS == 1 )
406  				{
407  					if( pxQueue-&gt;pxQueueSetContainer != NULL )
408  					{
409  						if( prvNotifyQueueSetContainer( pxQueue, xCopyPosition ) != pdFALSE )
410  						{
411  							queueYIELD_IF_USING_PREEMPTION();
412  						}
413  						else
414  						{
415  							mtCOVERAGE_TEST_MARKER();
416  						}
417  					}
418  					else
419  					{
420  						if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
421  						{
422  							if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
423  							{
424  								queueYIELD_IF_USING_PREEMPTION();
425  							}
426  							else
427  							{
428  								mtCOVERAGE_TEST_MARKER();
429  							}
430  						}
431  						else if( xYieldRequired != pdFALSE )
432  						{
433  							queueYIELD_IF_USING_PREEMPTION();
434  						}
435  						else
436  						{
437  							mtCOVERAGE_TEST_MARKER();
438  						}
439  					}
440  				}
441  				#else &amp;bsol;* configUSE_QUEUE_SETS */
442  				{
443  					if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
444  					{
445  						if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
446  						{
447  							queueYIELD_IF_USING_PREEMPTION();
448  						}
449  						else
450  						{
451  							mtCOVERAGE_TEST_MARKER();
452  						}
453  					}
454  					else if( xYieldRequired != pdFALSE )
455  					{
456  						queueYIELD_IF_USING_PREEMPTION();
457  					}
458  					else
459  					{
460  						mtCOVERAGE_TEST_MARKER();
461  					}
462  				}
463  				#endif &amp;bsol;* configUSE_QUEUE_SETS */
464  				taskEXIT_CRITICAL();
465  				return pdPASS;
466  			}
467  			else
468  			{
469  				if( xTicksToWait == ( TickType_t ) 0 )
470  				{
471  					taskEXIT_CRITICAL();
472  					traceQUEUE_SEND_FAILED( pxQueue );
473  					return errQUEUE_FULL;
474  				}
475  				else if( xEntryTimeSet == pdFALSE )
476  				{
477  					vTaskInternalSetTimeOutState( &amp;xTimeOut );
478  					xEntryTimeSet = pdTRUE;
479  				}
480  				else
481  				{
482  					mtCOVERAGE_TEST_MARKER();
483  				}
484  			}
485  		}
486  		taskEXIT_CRITICAL();
487  		vTaskSuspendAll();
488  		prvLockQueue( pxQueue );
489  		if( xTaskCheckForTimeOut( &amp;xTimeOut, &amp;xTicksToWait ) == pdFALSE )
490  		{
491  			if( prvIsQueueFull( pxQueue ) != pdFALSE )
492  			{
493  				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
494  				vTaskPlaceOnEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ), xTicksToWait );
495  				prvUnlockQueue( pxQueue );
496  				if( xTaskResumeAll() == pdFALSE )
497  				{
498  					portYIELD_WITHIN_API();
499  				}
500  			}
501  			else
502  			{
503  				prvUnlockQueue( pxQueue );
504  				( void ) xTaskResumeAll();
505  			}
506  		}
507  		else
508  		{
509  			prvUnlockQueue( pxQueue );
510  			( void ) xTaskResumeAll();
511  			traceQUEUE_SEND_FAILED( pxQueue );
512  			return errQUEUE_FULL;
513  		}
514  	}
515  }
516  BaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition )
517  {
518  BaseType_t xReturn;
519  UBaseType_t uxSavedInterruptStatus;
520  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
521  	configASSERT( pxQueue );
522  	configASSERT( !( ( pvItemToQueue == NULL ) &amp;&amp; ( pxQueue-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
523  	configASSERT( !( ( xCopyPosition == queueOVERWRITE ) &amp;&amp; ( pxQueue-&gt;uxLength != 1 ) ) );
524  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
525  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
526  	{
527  		if( ( pxQueue-&gt;uxMessagesWaiting &lt; pxQueue-&gt;uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
528  		{
529  			const int8_t cTxLock = pxQueue-&gt;cTxLock;
530  			traceQUEUE_SEND_FROM_ISR( pxQueue );
531  			( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
532  			if( cTxLock == queueUNLOCKED )
533  			{
534  				#if ( configUSE_QUEUE_SETS == 1 )
535  				{
536  					if( pxQueue-&gt;pxQueueSetContainer != NULL )
537  					{
538  						if( prvNotifyQueueSetContainer( pxQueue, xCopyPosition ) != pdFALSE )
539  						{
540  							if( pxHigherPriorityTaskWoken != NULL )
541  							{
542  								*pxHigherPriorityTaskWoken = pdTRUE;
543  							}
544  							else
545  							{
546  								mtCOVERAGE_TEST_MARKER();
547  							}
548  						}
549  						else
550  						{
551  							mtCOVERAGE_TEST_MARKER();
552  						}
553  					}
554  					else
555  					{
556  						if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
557  						{
558  							if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
559  							{
560  								if( pxHigherPriorityTaskWoken != NULL )
561  								{
562  									*pxHigherPriorityTaskWoken = pdTRUE;
563  								}
564  								else
565  								{
566  									mtCOVERAGE_TEST_MARKER();
567  								}
568  							}
569  							else
570  							{
571  								mtCOVERAGE_TEST_MARKER();
572  							}
573  						}
574  						else
575  						{
576  							mtCOVERAGE_TEST_MARKER();
577  						}
578  					}
579  				}
580  				#else &amp;bsol;* configUSE_QUEUE_SETS */
581  				{
582  					if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
583  					{
584  						if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
585  						{
586  							if( pxHigherPriorityTaskWoken != NULL )
587  							{
588  								*pxHigherPriorityTaskWoken = pdTRUE;
589  							}
590  							else
591  							{
592  								mtCOVERAGE_TEST_MARKER();
593  							}
594  						}
595  						else
596  						{
597  							mtCOVERAGE_TEST_MARKER();
598  						}
599  					}
600  					else
601  					{
602  						mtCOVERAGE_TEST_MARKER();
603  					}
604  				}
605  				#endif &amp;bsol;* configUSE_QUEUE_SETS */
606  			}
607  			else
608  			{
609  				pxQueue-&gt;cTxLock = ( int8_t ) ( cTxLock + 1 );
610  			}
611  			xReturn = pdPASS;
612  		}
613  		else
614  		{
615  			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
616  			xReturn = errQUEUE_FULL;
617  		}
618  	}
619  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
620  	return xReturn;
621  }
622  BaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken )
623  {
624  BaseType_t xReturn;
625  UBaseType_t uxSavedInterruptStatus;
626  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
627  	configASSERT( pxQueue );
628  	configASSERT( pxQueue-&gt;uxItemSize == 0 );
629  	configASSERT( !( ( pxQueue-&gt;uxQueueType == queueQUEUE_IS_MUTEX ) &amp;&amp; ( pxQueue-&gt;pxMutexHolder != NULL ) ) );
630  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
631  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
632  	{
633  		const UBaseType_t uxMessagesWaiting = pxQueue-&gt;uxMessagesWaiting;
634  		if( uxMessagesWaiting &lt; pxQueue-&gt;uxLength )
635  		{
636  			const int8_t cTxLock = pxQueue-&gt;cTxLock;
637  			traceQUEUE_SEND_FROM_ISR( pxQueue );
638  			pxQueue-&gt;uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
639  			if( cTxLock == queueUNLOCKED )
640  			{
641  				#if ( configUSE_QUEUE_SETS == 1 )
642  				{
643  					if( pxQueue-&gt;pxQueueSetContainer != NULL )
644  					{
645  						if( prvNotifyQueueSetContainer( pxQueue, queueSEND_TO_BACK ) != pdFALSE )
646  						{
647  							if( pxHigherPriorityTaskWoken != NULL )
648  							{
649  								*pxHigherPriorityTaskWoken = pdTRUE;
650  							}
651  							else
652  							{
653  								mtCOVERAGE_TEST_MARKER();
654  							}
655  						}
656  						else
657  						{
658  							mtCOVERAGE_TEST_MARKER();
659  						}
660  					}
661  					else
662  					{
663  						if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
664  						{
665  							if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
666  							{
667  								if( pxHigherPriorityTaskWoken != NULL )
668  								{
669  									*pxHigherPriorityTaskWoken = pdTRUE;
670  								}
671  								else
672  								{
673  									mtCOVERAGE_TEST_MARKER();
674  								}
675  							}
676  							else
677  							{
678  								mtCOVERAGE_TEST_MARKER();
679  							}
680  						}
681  						else
682  						{
683  							mtCOVERAGE_TEST_MARKER();
684  						}
685  					}
686  				}
687  				#else &amp;bsol;* configUSE_QUEUE_SETS */
688  				{
689  					if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
690  					{
691  						if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
692  						{
693  							if( pxHigherPriorityTaskWoken != NULL )
694  							{
695  								*pxHigherPriorityTaskWoken = pdTRUE;
696  							}
697  							else
698  							{
699  								mtCOVERAGE_TEST_MARKER();
700  							}
701  						}
702  						else
703  						{
704  							mtCOVERAGE_TEST_MARKER();
705  						}
706  					}
707  					else
708  					{
709  						mtCOVERAGE_TEST_MARKER();
710  					}
711  				}
712  				#endif &amp;bsol;* configUSE_QUEUE_SETS */
713  			}
714  			else
715  			{
716  				pxQueue-&gt;cTxLock = ( int8_t ) ( cTxLock + 1 );
717  			}
718  			xReturn = pdPASS;
719  		}
720  		else
721  		{
722  			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
723  			xReturn = errQUEUE_FULL;
724  		}
725  	}
726  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
727  	return xReturn;
728  }
729  BaseType_t xQueueReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait )
730  {
731  BaseType_t xEntryTimeSet = pdFALSE;
732  TimeOut_t xTimeOut;
733  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
734  	configASSERT( ( pxQueue ) );
735  	configASSERT( !( ( ( pvBuffer ) == NULL ) &amp;&amp; ( ( pxQueue )-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
736  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
737  	{
738  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) &amp;&amp; ( xTicksToWait != 0 ) ) );
739  	}
740  	#endif
741  	for( ;; )
742  	{
743  		taskENTER_CRITICAL();
744  		{
745  			const UBaseType_t uxMessagesWaiting = pxQueue-&gt;uxMessagesWaiting;
746  			if( uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
747  			{
748  				prvCopyDataFromQueue( pxQueue, pvBuffer );
749  				traceQUEUE_RECEIVE( pxQueue );
750  				pxQueue-&gt;uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
751  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
752  				{
753  					if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
754  					{
755  						queueYIELD_IF_USING_PREEMPTION();
756  					}
757  					else
758  					{
759  						mtCOVERAGE_TEST_MARKER();
760  					}
761  				}
762  				else
763  				{
764  					mtCOVERAGE_TEST_MARKER();
765  				}
766  				taskEXIT_CRITICAL();
767  				return pdPASS;
768  			}
769  			else
770  			{
771  				if( xTicksToWait == ( TickType_t ) 0 )
772  				{
773  					taskEXIT_CRITICAL();
774  					traceQUEUE_RECEIVE_FAILED( pxQueue );
775  					return errQUEUE_EMPTY;
776  				}
777  				else if( xEntryTimeSet == pdFALSE )
778  				{
779  					vTaskInternalSetTimeOutState( &amp;xTimeOut );
780  					xEntryTimeSet = pdTRUE;
781  				}
782  				else
783  				{
784  					mtCOVERAGE_TEST_MARKER();
785  				}
786  			}
787  		}
788  		taskEXIT_CRITICAL();
789  		vTaskSuspendAll();
790  		prvLockQueue( pxQueue );
791  		if( xTaskCheckForTimeOut( &amp;xTimeOut, &amp;xTicksToWait ) == pdFALSE )
792  		{
793  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
794  			{
795  				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
796  				vTaskPlaceOnEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ), xTicksToWait );
797  				prvUnlockQueue( pxQueue );
798  				if( xTaskResumeAll() == pdFALSE )
799  				{
800  					portYIELD_WITHIN_API();
801  				}
802  				else
803  				{
804  					mtCOVERAGE_TEST_MARKER();
805  				}
806  			}
807  			else
808  			{
809  				prvUnlockQueue( pxQueue );
810  				( void ) xTaskResumeAll();
811  			}
812  		}
813  		else
814  		{
815  			prvUnlockQueue( pxQueue );
816  			( void ) xTaskResumeAll();
817  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
818  			{
819  				traceQUEUE_RECEIVE_FAILED( pxQueue );
820  				return errQUEUE_EMPTY;
821  			}
822  			else
823  			{
824  				mtCOVERAGE_TEST_MARKER();
825  			}
826  		}
827  	}
828  }
829  BaseType_t xQueueSemaphoreTake( QueueHandle_t xQueue, TickType_t xTicksToWait )
830  {
831  BaseType_t xEntryTimeSet = pdFALSE;
832  TimeOut_t xTimeOut;
833  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
834  #if( configUSE_MUTEXES == 1 )
835  	BaseType_t xInheritanceOccurred = pdFALSE;
836  #endif
837  	configASSERT( ( pxQueue ) );
838  	configASSERT( pxQueue-&gt;uxItemSize == 0 );
839  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
840  	{
841  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) &amp;&amp; ( xTicksToWait != 0 ) ) );
842  	}
843  	#endif
844  	for( ;; )
845  	{
846  		taskENTER_CRITICAL();
847  		{
848  			const UBaseType_t uxSemaphoreCount = pxQueue-&gt;uxMessagesWaiting;
849  			if( uxSemaphoreCount &gt; ( UBaseType_t ) 0 )
850  			{
851  				traceQUEUE_RECEIVE( pxQueue );
852  				pxQueue-&gt;uxMessagesWaiting = uxSemaphoreCount - ( UBaseType_t ) 1;
853  				#if ( configUSE_MUTEXES == 1 )
854  				{
855  					if( pxQueue-&gt;uxQueueType == queueQUEUE_IS_MUTEX )
856  					{
857  						pxQueue-&gt;pxMutexHolder = ( int8_t * ) pvTaskIncrementMutexHeldCount(); &amp;bsol;*lint !e961 Cast is not redundant as TaskHandle_t is a typedef. */
858  					}
859  					else
860  					{
861  						mtCOVERAGE_TEST_MARKER();
862  					}
863  				}
864  				#endif &amp;bsol;* configUSE_MUTEXES */
865  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
866  				{
867  					if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
868  					{
869  						queueYIELD_IF_USING_PREEMPTION();
870  					}
871  					else
872  					{
873  						mtCOVERAGE_TEST_MARKER();
874  					}
875  				}
876  				else
877  				{
878  					mtCOVERAGE_TEST_MARKER();
879  				}
880  				taskEXIT_CRITICAL();
881  				return pdPASS;
882  			}
883  			else
884  			{
885  				if( xTicksToWait == ( TickType_t ) 0 )
886  				{
887  					#if( configUSE_MUTEXES == 1 )
888  					{
889  						configASSERT( xInheritanceOccurred == pdFALSE );
890  					}
891  					#endif &amp;bsol;* configUSE_MUTEXES */
892  					taskEXIT_CRITICAL();
893  					traceQUEUE_RECEIVE_FAILED( pxQueue );
894  					return errQUEUE_EMPTY;
895  				}
896  				else if( xEntryTimeSet == pdFALSE )
897  				{
898  					vTaskInternalSetTimeOutState( &amp;xTimeOut );
899  					xEntryTimeSet = pdTRUE;
900  				}
901  				else
902  				{
903  					mtCOVERAGE_TEST_MARKER();
904  				}
905  			}
906  		}
907  		taskEXIT_CRITICAL();
908  		vTaskSuspendAll();
909  		prvLockQueue( pxQueue );
910  		if( xTaskCheckForTimeOut( &amp;xTimeOut, &amp;xTicksToWait ) == pdFALSE )
911  		{
912  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
913  			{
914  				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
915  				#if ( configUSE_MUTEXES == 1 )
916  				{
917  					if( pxQueue-&gt;uxQueueType == queueQUEUE_IS_MUTEX )
918  					{
919  						taskENTER_CRITICAL();
920  						{
921  							xInheritanceOccurred = xTaskPriorityInherit( ( void * ) pxQueue-&gt;pxMutexHolder );
922  						}
923  						taskEXIT_CRITICAL();
924  					}
925  					else
926  					{
927  						mtCOVERAGE_TEST_MARKER();
928  					}
929  				}
930  				#endif
931  				vTaskPlaceOnEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ), xTicksToWait );
932  				prvUnlockQueue( pxQueue );
933  				if( xTaskResumeAll() == pdFALSE )
934  				{
935  					portYIELD_WITHIN_API();
936  				}
937  				else
938  				{
939  					mtCOVERAGE_TEST_MARKER();
940  				}
941  			}
942  			else
943  			{
944  				prvUnlockQueue( pxQueue );
945  				( void ) xTaskResumeAll();
946  			}
947  		}
948  		else
949  		{
950  			prvUnlockQueue( pxQueue );
951  			( void ) xTaskResumeAll();
952  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
953  			{
954  				#if ( configUSE_MUTEXES == 1 )
955  				{
956  					if( xInheritanceOccurred != pdFALSE )
957  					{
958  						taskENTER_CRITICAL();
959  						{
960  							UBaseType_t uxHighestWaitingPriority;
961  							uxHighestWaitingPriority = prvGetDisinheritPriorityAfterTimeout( pxQueue );
962  							vTaskPriorityDisinheritAfterTimeout( ( void * ) pxQueue-&gt;pxMutexHolder, uxHighestWaitingPriority );
963  						}
964  						taskEXIT_CRITICAL();
965  					}
966  				}
967  				#endif &amp;bsol;* configUSE_MUTEXES */
968  				traceQUEUE_RECEIVE_FAILED( pxQueue );
969  				return errQUEUE_EMPTY;
970  			}
971  			else
972  			{
973  				mtCOVERAGE_TEST_MARKER();
974  			}
975  		}
976  	}
977  }
978  BaseType_t xQueuePeek( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait )
979  {
980  BaseType_t xEntryTimeSet = pdFALSE;
981  TimeOut_t xTimeOut;
982  int8_t *pcOriginalReadPosition;
983  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
984  	configASSERT( ( pxQueue ) );
985  	configASSERT( !( ( ( pvBuffer ) == NULL ) &amp;&amp; ( ( pxQueue )-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
986  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
987  	{
988  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) &amp;&amp; ( xTicksToWait != 0 ) ) );
989  	}
990  	#endif
991  	for( ;; )
992  	{
993  		taskENTER_CRITICAL();
994  		{
995  			const UBaseType_t uxMessagesWaiting = pxQueue-&gt;uxMessagesWaiting;
996  			if( uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
997  			{
998  				pcOriginalReadPosition = pxQueue-&gt;u.pcReadFrom;
999  				prvCopyDataFromQueue( pxQueue, pvBuffer );
1000  				traceQUEUE_PEEK( pxQueue );
1001  				pxQueue-&gt;u.pcReadFrom = pcOriginalReadPosition;
1002  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1003  				{
1004  					if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1005  					{
1006  						queueYIELD_IF_USING_PREEMPTION();
1007  					}
1008  					else
1009  					{
1010  						mtCOVERAGE_TEST_MARKER();
1011  					}
1012  				}
1013  				else
1014  				{
1015  					mtCOVERAGE_TEST_MARKER();
1016  				}
1017  				taskEXIT_CRITICAL();
1018  				return pdPASS;
1019  			}
1020  			else
1021  			{
1022  				if( xTicksToWait == ( TickType_t ) 0 )
1023  				{
1024  					taskEXIT_CRITICAL();
1025  					traceQUEUE_PEEK_FAILED( pxQueue );
1026  					return errQUEUE_EMPTY;
1027  				}
1028  				else if( xEntryTimeSet == pdFALSE )
1029  				{
1030  					vTaskInternalSetTimeOutState( &amp;xTimeOut );
1031  					xEntryTimeSet = pdTRUE;
1032  				}
1033  				else
1034  				{
1035  					mtCOVERAGE_TEST_MARKER();
1036  				}
1037  			}
1038  		}
1039  		taskEXIT_CRITICAL();
1040  		vTaskSuspendAll();
1041  		prvLockQueue( pxQueue );
1042  		if( xTaskCheckForTimeOut( &amp;xTimeOut, &amp;xTicksToWait ) == pdFALSE )
1043  		{
1044  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
1045  			{
1046  				traceBLOCKING_ON_QUEUE_PEEK( pxQueue );
1047  				vTaskPlaceOnEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ), xTicksToWait );
1048  				prvUnlockQueue( pxQueue );
1049  				if( xTaskResumeAll() == pdFALSE )
1050  				{
1051  					portYIELD_WITHIN_API();
1052  				}
1053  				else
1054  				{
1055  					mtCOVERAGE_TEST_MARKER();
1056  				}
1057  			}
1058  			else
1059  			{
1060  				prvUnlockQueue( pxQueue );
1061  				( void ) xTaskResumeAll();
1062  			}
1063  		}
1064  		else
1065  		{
1066  			prvUnlockQueue( pxQueue );
1067  			( void ) xTaskResumeAll();
1068  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
1069  			{
1070  				traceQUEUE_PEEK_FAILED( pxQueue );
1071  				return errQUEUE_EMPTY;
1072  			}
1073  			else
1074  			{
1075  				mtCOVERAGE_TEST_MARKER();
1076  			}
1077  		}
1078  	}
1079  }
1080  BaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken )
1081  {
1082  BaseType_t xReturn;
1083  UBaseType_t uxSavedInterruptStatus;
1084  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1085  	configASSERT( pxQueue );
1086  	configASSERT( !( ( pvBuffer == NULL ) &amp;&amp; ( pxQueue-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
1087  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
1088  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
1089  	{
1090  		const UBaseType_t uxMessagesWaiting = pxQueue-&gt;uxMessagesWaiting;
1091  		if( uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
1092  		{
1093  			const int8_t cRxLock = pxQueue-&gt;cRxLock;
1094  			traceQUEUE_RECEIVE_FROM_ISR( pxQueue );
1095  			prvCopyDataFromQueue( pxQueue, pvBuffer );
1096  			pxQueue-&gt;uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
1097  			if( cRxLock == queueUNLOCKED )
1098  			{
1099  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
1100  				{
1101  					if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
1102  					{
1103  						if( pxHigherPriorityTaskWoken != NULL )
1104  						{
1105  							*pxHigherPriorityTaskWoken = pdTRUE;
1106  						}
1107  						else
1108  						{
1109  							mtCOVERAGE_TEST_MARKER();
1110  						}
1111  					}
1112  					else
1113  					{
1114  						mtCOVERAGE_TEST_MARKER();
1115  					}
1116  				}
1117  				else
1118  				{
1119  					mtCOVERAGE_TEST_MARKER();
1120  				}
1121  			}
1122  			else
1123  			{
1124  				pxQueue-&gt;cRxLock = ( int8_t ) ( cRxLock + 1 );
1125  			}
1126  			xReturn = pdPASS;
1127  		}
1128  		else
1129  		{
1130  			xReturn = pdFAIL;
1131  			traceQUEUE_RECEIVE_FROM_ISR_FAILED( pxQueue );
1132  		}
1133  	}
1134  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
1135  	return xReturn;
1136  }
1137  BaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,  void * const pvBuffer )
1138  {
1139  BaseType_t xReturn;
1140  UBaseType_t uxSavedInterruptStatus;
1141  int8_t *pcOriginalReadPosition;
1142  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1143  	configASSERT( pxQueue );
1144  	configASSERT( !( ( pvBuffer == NULL ) &amp;&amp; ( pxQueue-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
1145  	configASSERT( pxQueue-&gt;uxItemSize != 0 ); &amp;bsol;* Can&#x27;t peek a semaphore. */
1146  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
1147  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
1148  	{
1149  		if( pxQueue-&gt;uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
1150  		{
1151  			traceQUEUE_PEEK_FROM_ISR( pxQueue );
1152  			pcOriginalReadPosition = pxQueue-&gt;u.pcReadFrom;
1153  			prvCopyDataFromQueue( pxQueue, pvBuffer );
1154  			pxQueue-&gt;u.pcReadFrom = pcOriginalReadPosition;
1155  			xReturn = pdPASS;
1156  		}
1157  		else
1158  		{
1159  			xReturn = pdFAIL;
1160  			traceQUEUE_PEEK_FROM_ISR_FAILED( pxQueue );
1161  		}
1162  	}
1163  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
1164  	return xReturn;
1165  }
1166  UBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue )
1167  {
1168  UBaseType_t uxReturn;
1169  	configASSERT( xQueue );
1170  	taskENTER_CRITICAL();
1171  	{
1172  		uxReturn = ( ( Queue_t * ) xQueue )-&gt;uxMessagesWaiting;
1173  	}
1174  	taskEXIT_CRITICAL();
1175  	return uxReturn;
1176  } &amp;bsol;*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
1177  UBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue )
1178  {
1179  UBaseType_t uxReturn;
1180  Queue_t *pxQueue;
1181  	pxQueue = ( Queue_t * ) xQueue;
1182  	configASSERT( pxQueue );
1183  	taskENTER_CRITICAL();
1184  	{
1185  		uxReturn = pxQueue-&gt;uxLength - pxQueue-&gt;uxMessagesWaiting;
1186  	}
1187  	taskEXIT_CRITICAL();
1188  	return uxReturn;
1189  } &amp;bsol;*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
1190  UBaseType_t uxQueueMessagesWaitingFromISR( const QueueHandle_t xQueue )
1191  {
1192  UBaseType_t uxReturn;
1193  	configASSERT( xQueue );
1194  	uxReturn = ( ( Queue_t * ) xQueue )-&gt;uxMessagesWaiting;
1195  	return uxReturn;
1196  } &amp;bsol;*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
1197  void vQueueDelete( QueueHandle_t xQueue )
1198  {
1199  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1200  	configASSERT( pxQueue );
1201  	traceQUEUE_DELETE( pxQueue );
1202  	#if ( configQUEUE_REGISTRY_SIZE &gt; 0 )
1203  	{
1204  		vQueueUnregisterQueue( pxQueue );
1205  	}
1206  	#endif
1207  	#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) &amp;&amp; ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
1208  	{
1209  		vPortFree( pxQueue );
1210  	}
1211  	#elif( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) &amp;&amp; ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
1212  	{
1213  		if( pxQueue-&gt;ucStaticallyAllocated == ( uint8_t ) pdFALSE )
1214  		{
1215  			vPortFree( pxQueue );
1216  		}
1217  		else
1218  		{
1219  			mtCOVERAGE_TEST_MARKER();
1220  		}
1221  	}
1222  	#else
1223  	{
1224  		( void ) pxQueue;
1225  	}
1226  	#endif &amp;bsol;* configSUPPORT_DYNAMIC_ALLOCATION */
1227  }
1228  #if ( configUSE_TRACE_FACILITY == 1 )
1229  	UBaseType_t uxQueueGetQueueNumber( QueueHandle_t xQueue )
1230  	{
1231  		return ( ( Queue_t * ) xQueue )-&gt;uxQueueNumber;
1232  	}
1233  #endif &amp;bsol;* configUSE_TRACE_FACILITY */
1234  #if ( configUSE_TRACE_FACILITY == 1 )
1235  	void vQueueSetQueueNumber( QueueHandle_t xQueue, UBaseType_t uxQueueNumber )
1236  	{
1237  		( ( Queue_t * ) xQueue )-&gt;uxQueueNumber = uxQueueNumber;
1238  	}
1239  #endif &amp;bsol;* configUSE_TRACE_FACILITY */
1240  #if ( configUSE_TRACE_FACILITY == 1 )
1241  	uint8_t ucQueueGetQueueType( QueueHandle_t xQueue )
1242  	{
1243  		return ( ( Queue_t * ) xQueue )-&gt;ucQueueType;
1244  	}
1245  #endif &amp;bsol;* configUSE_TRACE_FACILITY */
1246  #if( configUSE_MUTEXES == 1 )
1247  	static UBaseType_t prvGetDisinheritPriorityAfterTimeout( const Queue_t * const pxQueue )
1248  	{
1249  	UBaseType_t uxHighestPriorityOfWaitingTasks;
1250  		if( listCURRENT_LIST_LENGTH( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) &gt; 0 )
1251  		{
1252  			uxHighestPriorityOfWaitingTasks = configMAX_PRIORITIES - listGET_ITEM_VALUE_OF_HEAD_ENTRY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) );
1253  		}
1254  		else
1255  		{
1256  			uxHighestPriorityOfWaitingTasks = tskIDLE_PRIORITY;
1257  		}
1258  		return uxHighestPriorityOfWaitingTasks;
1259  	}
1260  #endif &amp;bsol;* configUSE_MUTEXES */
1261  static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
1262  {
1263  BaseType_t xReturn = pdFALSE;
1264  UBaseType_t uxMessagesWaiting;
1265  	uxMessagesWaiting = pxQueue-&gt;uxMessagesWaiting;
1266  	if( pxQueue-&gt;uxItemSize == ( UBaseType_t ) 0 )
1267  	{
1268  		#if ( configUSE_MUTEXES == 1 )
1269  		{
1270  			if( pxQueue-&gt;uxQueueType == queueQUEUE_IS_MUTEX )
1271  			{
1272  				xReturn = xTaskPriorityDisinherit( ( void * ) pxQueue-&gt;pxMutexHolder );
1273  				pxQueue-&gt;pxMutexHolder = NULL;
1274  			}
1275  			else
1276  			{
1277  				mtCOVERAGE_TEST_MARKER();
1278  			}
1279  		}
1280  		#endif &amp;bsol;* configUSE_MUTEXES */
1281  	}
1282  	else if( xPosition == queueSEND_TO_BACK )
1283  	{
1284  		( void ) memcpy( ( void * ) pxQueue-&gt;pcWriteTo, pvItemToQueue, ( size_t ) pxQueue-&gt;uxItemSize ); &amp;bsol;*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a null pointer can only be passed to memcpy() if the copy size is 0. */
1285  		pxQueue-&gt;pcWriteTo += pxQueue-&gt;uxItemSize;
1286  		if( pxQueue-&gt;pcWriteTo &gt;= pxQueue-&gt;pcTail ) &amp;bsol;*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
1287  		{
1288  			pxQueue-&gt;pcWriteTo = pxQueue-&gt;pcHead;
1289  		}
1290  		else
1291  		{
1292  			mtCOVERAGE_TEST_MARKER();
1293  		}
1294  	}
1295  	else
1296  	{
1297  		( void ) memcpy( ( void * ) pxQueue-&gt;u.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue-&gt;uxItemSize ); &amp;bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
1298  		pxQueue-&gt;u.pcReadFrom -= pxQueue-&gt;uxItemSize;
1299  		if( pxQueue-&gt;u.pcReadFrom &lt; pxQueue-&gt;pcHead ) &amp;bsol;*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
1300  		{
1301  			pxQueue-&gt;u.pcReadFrom = ( pxQueue-&gt;pcTail - pxQueue-&gt;uxItemSize );
1302  		}
1303  		else
1304  		{
1305  			mtCOVERAGE_TEST_MARKER();
1306  		}
1307  		if( xPosition == queueOVERWRITE )
1308  		{
1309  			if( uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
1310  			{
1311  				--uxMessagesWaiting;
1312  			}
1313  			else
1314  			{
1315  				mtCOVERAGE_TEST_MARKER();
1316  			}
1317  		}
1318  		else
1319  		{
1320  			mtCOVERAGE_TEST_MARKER();
1321  		}
1322  	}
1323  	pxQueue-&gt;uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
1324  	return xReturn;
1325  }
1326  static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer )
1327  {
1328  	if( pxQueue-&gt;uxItemSize != ( UBaseType_t ) 0 )
1329  	{
1330  		pxQueue-&gt;u.pcReadFrom += pxQueue-&gt;uxItemSize;
1331  		if( pxQueue-&gt;u.pcReadFrom &gt;= pxQueue-&gt;pcTail ) &amp;bsol;*lint !e946 MISRA exception justified as use of the relational operator is the cleanest solutions. */
1332  		{
1333  			pxQueue-&gt;u.pcReadFrom = pxQueue-&gt;pcHead;
1334  		}
1335  		else
1336  		{
1337  			mtCOVERAGE_TEST_MARKER();
1338  		}
1339  		( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue-&gt;u.pcReadFrom, ( size_t ) pxQueue-&gt;uxItemSize ); &amp;bsol;*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports.  Also previous logic ensures a null pointer can only be passed to memcpy() when the count is 0. */
1340  	}
1341  }
1342  static void prvUnlockQueue( Queue_t * const pxQueue )
1343  {
1344  	taskENTER_CRITICAL();
1345  	{
1346  		int8_t cTxLock = pxQueue-&gt;cTxLock;
1347  		while( cTxLock &gt; queueLOCKED_UNMODIFIED )
1348  		{
1349  			#if ( configUSE_QUEUE_SETS == 1 )
1350  			{
1351  				if( pxQueue-&gt;pxQueueSetContainer != NULL )
1352  				{
1353  					if( prvNotifyQueueSetContainer( pxQueue, queueSEND_TO_BACK ) != pdFALSE )
1354  					{
1355  						vTaskMissedYield();
1356  					}
1357  					else
1358  					{
1359  						mtCOVERAGE_TEST_MARKER();
1360  					}
1361  				}
1362  				else
1363  				{
1364  					if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1365  					{
1366  						if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1367  						{
1368  							vTaskMissedYield();
1369  						}
1370  						else
1371  						{
1372  							mtCOVERAGE_TEST_MARKER();
1373  						}
1374  					}
1375  					else
1376  					{
1377  						break;
1378  					}
1379  				}
1380  			}
1381  			#else &amp;bsol;* configUSE_QUEUE_SETS */
1382  			{
1383  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1384  				{
1385  					if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1386  					{
1387  						vTaskMissedYield();
1388  					}
1389  					else
1390  					{
1391  						mtCOVERAGE_TEST_MARKER();
1392  					}
1393  				}
1394  				else
1395  				{
1396  					break;
1397  				}
1398  			}
1399  			#endif &amp;bsol;* configUSE_QUEUE_SETS */
1400  			--cTxLock;
1401  		}
1402  		pxQueue-&gt;cTxLock = queueUNLOCKED;
1403  	}
1404  	taskEXIT_CRITICAL();
1405  	taskENTER_CRITICAL();
1406  	{
1407  		int8_t cRxLock = pxQueue-&gt;cRxLock;
1408  		while( cRxLock &gt; queueLOCKED_UNMODIFIED )
1409  		{
1410  			if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
1411  			{
1412  				if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
1413  				{
1414  					vTaskMissedYield();
1415  				}
1416  				else
1417  				{
1418  					mtCOVERAGE_TEST_MARKER();
1419  				}
1420  				--cRxLock;
1421  			}
1422  			else
1423  			{
1424  				break;
1425  			}
1426  		}
1427  		pxQueue-&gt;cRxLock = queueUNLOCKED;
1428  	}
1429  	taskEXIT_CRITICAL();
1430  }
1431  static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue )
1432  {
1433  BaseType_t xReturn;
1434  	taskENTER_CRITICAL();
1435  	{
1436  		if( pxQueue-&gt;uxMessagesWaiting == ( UBaseType_t )  0 )
1437  		{
1438  			xReturn = pdTRUE;
1439  		}
1440  		else
1441  		{
1442  			xReturn = pdFALSE;
1443  		}
1444  	}
1445  	taskEXIT_CRITICAL();
1446  	return xReturn;
1447  }
1448  BaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue )
1449  {
1450  BaseType_t xReturn;
1451  	configASSERT( xQueue );
1452  	if( ( ( Queue_t * ) xQueue )-&gt;uxMessagesWaiting == ( UBaseType_t ) 0 )
1453  	{
1454  		xReturn = pdTRUE;
1455  	}
1456  	else
1457  	{
1458  		xReturn = pdFALSE;
1459  	}
1460  	return xReturn;
1461  } &amp;bsol;*lint !e818 xQueue could not be pointer to const because it is a typedef. */
1462  static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
1463  {
1464  BaseType_t xReturn;
1465  	taskENTER_CRITICAL();
1466  	{
1467  		if( pxQueue-&gt;uxMessagesWaiting == pxQueue-&gt;uxLength )
1468  		{
1469  			xReturn = pdTRUE;
1470  		}
1471  		else
1472  		{
1473  			xReturn = pdFALSE;
1474  		}
1475  	}
1476  	taskEXIT_CRITICAL();
1477  	return xReturn;
1478  }
1479  BaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )
1480  {
1481  BaseType_t xReturn;
1482  	configASSERT( xQueue );
1483  	if( ( ( Queue_t * ) xQueue )-&gt;uxMessagesWaiting == ( ( Queue_t * ) xQueue )-&gt;uxLength )
1484  	{
1485  		xReturn = pdTRUE;
1486  	}
1487  	else
1488  	{
1489  		xReturn = pdFALSE;
1490  	}
1491  	return xReturn;
1492  } &amp;bsol;*lint !e818 xQueue could not be pointer to const because it is a typedef. */
1493  #if ( configUSE_CO_ROUTINES == 1 )
1494  	BaseType_t xQueueCRSend( QueueHandle_t xQueue, const void *pvItemToQueue, TickType_t xTicksToWait )
1495  	{
1496  	BaseType_t xReturn;
1497  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1498  		portDISABLE_INTERRUPTS();
1499  		{
1500  			if( prvIsQueueFull( pxQueue ) != pdFALSE )
1501  			{
1502  				if( xTicksToWait &gt; ( TickType_t ) 0 )
1503  				{
1504  					vCoRoutineAddToDelayedList( xTicksToWait, &amp;( pxQueue-&gt;xTasksWaitingToSend ) );
1505  					portENABLE_INTERRUPTS();
1506  					return errQUEUE_BLOCKED;
1507  				}
1508  				else
1509  				{
1510  					portENABLE_INTERRUPTS();
1511  					return errQUEUE_FULL;
1512  				}
1513  			}
1514  		}
1515  		portENABLE_INTERRUPTS();
1516  		portDISABLE_INTERRUPTS();
1517  		{
<span onclick='openModal()' class='match'>1518  			if( pxQueue-&gt;uxMessagesWaiting &lt; pxQueue-&gt;uxLength )
1519  			{
1520  				prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
1521  				xReturn = pdPASS;
</span>1522  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1523  				{
1524  					if( xCoRoutineRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1525  					{
1526  						xReturn = errQUEUE_YIELD;
1527  					}
1528  					else
1529  					{
1530  						mtCOVERAGE_TEST_MARKER();
1531  					}
1532  				}
1533  				else
1534  				{
1535  					mtCOVERAGE_TEST_MARKER();
1536  				}
1537  			}
1538  			else
1539  			{
1540  				xReturn = errQUEUE_FULL;
1541  			}
1542  		}
1543  		portENABLE_INTERRUPTS();
1544  		return xReturn;
1545  	}
1546  #endif &amp;bsol;* configUSE_CO_ROUTINES */
1547  #if ( configUSE_CO_ROUTINES == 1 )
1548  	BaseType_t xQueueCRReceive( QueueHandle_t xQueue, void *pvBuffer, TickType_t xTicksToWait )
1549  	{
1550  	BaseType_t xReturn;
1551  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1552  		portDISABLE_INTERRUPTS();
1553  		{
1554  			if( pxQueue-&gt;uxMessagesWaiting == ( UBaseType_t ) 0 )
1555  			{
1556  				if( xTicksToWait &gt; ( TickType_t ) 0 )
1557  				{
1558  					vCoRoutineAddToDelayedList( xTicksToWait, &amp;( pxQueue-&gt;xTasksWaitingToReceive ) );
1559  					portENABLE_INTERRUPTS();
1560  					return errQUEUE_BLOCKED;
1561  				}
1562  				else
1563  				{
1564  					portENABLE_INTERRUPTS();
1565  					return errQUEUE_FULL;
1566  				}
1567  			}
1568  			else
1569  			{
1570  				mtCOVERAGE_TEST_MARKER();
1571  			}
1572  		}
1573  		portENABLE_INTERRUPTS();
1574  		portDISABLE_INTERRUPTS();
1575  		{
1576  			if( pxQueue-&gt;uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
1577  			{
1578  				pxQueue-&gt;u.pcReadFrom += pxQueue-&gt;uxItemSize;
1579  				if( pxQueue-&gt;u.pcReadFrom &gt;= pxQueue-&gt;pcTail )
1580  				{
1581  					pxQueue-&gt;u.pcReadFrom = pxQueue-&gt;pcHead;
1582  				}
1583  				else
1584  				{
1585  					mtCOVERAGE_TEST_MARKER();
1586  				}
1587  				--( pxQueue-&gt;uxMessagesWaiting );
1588  				( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue-&gt;u.pcReadFrom, ( unsigned ) pxQueue-&gt;uxItemSize );
1589  				xReturn = pdPASS;
1590  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
1591  				{
1592  					if( xCoRoutineRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
1593  					{
1594  						xReturn = errQUEUE_YIELD;
1595  					}
1596  					else
1597  					{
1598  						mtCOVERAGE_TEST_MARKER();
1599  					}
1600  				}
1601  				else
1602  				{
1603  					mtCOVERAGE_TEST_MARKER();
1604  				}
1605  			}
1606  			else
1607  			{
1608  				xReturn = pdFAIL;
1609  			}
1610  		}
1611  		portENABLE_INTERRUPTS();
1612  		return xReturn;
1613  	}
1614  #endif &amp;bsol;* configUSE_CO_ROUTINES */
1615  #if ( configUSE_CO_ROUTINES == 1 )
1616  	BaseType_t xQueueCRSendFromISR( QueueHandle_t xQueue, const void *pvItemToQueue, BaseType_t xCoRoutinePreviouslyWoken )
1617  	{
1618  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1619  		if( pxQueue-&gt;uxMessagesWaiting &lt; pxQueue-&gt;uxLength )
1620  		{
1621  			prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
1622  			if( xCoRoutinePreviouslyWoken == pdFALSE )
1623  			{
1624  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1625  				{
1626  					if( xCoRoutineRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1627  					{
1628  						return pdTRUE;
1629  					}
1630  					else
1631  					{
1632  						mtCOVERAGE_TEST_MARKER();
1633  					}
1634  				}
1635  				else
1636  				{
1637  					mtCOVERAGE_TEST_MARKER();
1638  				}
1639  			}
1640  			else
1641  			{
1642  				mtCOVERAGE_TEST_MARKER();
1643  			}
1644  		}
1645  		else
1646  		{
1647  			mtCOVERAGE_TEST_MARKER();
1648  		}
1649  		return xCoRoutinePreviouslyWoken;
1650  	}
1651  #endif &amp;bsol;* configUSE_CO_ROUTINES */
1652  #if ( configUSE_CO_ROUTINES == 1 )
1653  	BaseType_t xQueueCRReceiveFromISR( QueueHandle_t xQueue, void *pvBuffer, BaseType_t *pxCoRoutineWoken )
1654  	{
1655  	BaseType_t xReturn;
1656  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1657  		if( pxQueue-&gt;uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
1658  		{
1659  			pxQueue-&gt;u.pcReadFrom += pxQueue-&gt;uxItemSize;
1660  			if( pxQueue-&gt;u.pcReadFrom &gt;= pxQueue-&gt;pcTail )
1661  			{
1662  				pxQueue-&gt;u.pcReadFrom = pxQueue-&gt;pcHead;
1663  			}
1664  			else
1665  			{
1666  				mtCOVERAGE_TEST_MARKER();
1667  			}
1668  			--( pxQueue-&gt;uxMessagesWaiting );
1669  			( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue-&gt;u.pcReadFrom, ( unsigned ) pxQueue-&gt;uxItemSize );
1670  			if( ( *pxCoRoutineWoken ) == pdFALSE )
1671  			{
1672  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
1673  				{
1674  					if( xCoRoutineRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
1675  					{
1676  						*pxCoRoutineWoken = pdTRUE;
1677  					}
1678  					else
1679  					{
1680  						mtCOVERAGE_TEST_MARKER();
1681  					}
1682  				}
1683  				else
1684  				{
1685  					mtCOVERAGE_TEST_MARKER();
1686  				}
1687  			}
1688  			else
1689  			{
1690  				mtCOVERAGE_TEST_MARKER();
1691  			}
1692  			xReturn = pdPASS;
1693  		}
1694  		else
1695  		{
1696  			xReturn = pdFAIL;
1697  		}
1698  		return xReturn;
1699  	}
1700  #endif &amp;bsol;* configUSE_CO_ROUTINES */
1701  #if ( configQUEUE_REGISTRY_SIZE &gt; 0 )
1702  	void vQueueAddToRegistry( QueueHandle_t xQueue, const char *pcQueueName ) &amp;bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1703  	{
1704  	UBaseType_t ux;
1705  		for( ux = ( UBaseType_t ) 0U; ux &lt; ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
1706  		{
1707  			if( xQueueRegistry[ ux ].pcQueueName == NULL )
1708  			{
1709  				xQueueRegistry[ ux ].pcQueueName = pcQueueName;
1710  				xQueueRegistry[ ux ].xHandle = xQueue;
1711  				traceQUEUE_REGISTRY_ADD( xQueue, pcQueueName );
1712  				break;
1713  			}
1714  			else
1715  			{
1716  				mtCOVERAGE_TEST_MARKER();
1717  			}
1718  		}
1719  	}
1720  #endif &amp;bsol;* configQUEUE_REGISTRY_SIZE */
1721  #if ( configQUEUE_REGISTRY_SIZE &gt; 0 )
1722  	const char *pcQueueGetName( QueueHandle_t xQueue ) &amp;bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1723  	{
1724  	UBaseType_t ux;
1725  	const char *pcReturn = NULL; &amp;bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1726  		for( ux = ( UBaseType_t ) 0U; ux &lt; ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
1727  		{
1728  			if( xQueueRegistry[ ux ].xHandle == xQueue )
1729  			{
1730  				pcReturn = xQueueRegistry[ ux ].pcQueueName;
1731  				break;
1732  			}
1733  			else
1734  			{
1735  				mtCOVERAGE_TEST_MARKER();
1736  			}
1737  		}
1738  		return pcReturn;
1739  	} &amp;bsol;*lint !e818 xQueue cannot be a pointer to const because it is a typedef. */
1740  #endif &amp;bsol;* configQUEUE_REGISTRY_SIZE */
1741  #if ( configQUEUE_REGISTRY_SIZE &gt; 0 )
1742  	void vQueueUnregisterQueue( QueueHandle_t xQueue )
1743  	{
1744  	UBaseType_t ux;
1745  		for( ux = ( UBaseType_t ) 0U; ux &lt; ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
1746  		{
1747  			if( xQueueRegistry[ ux ].xHandle == xQueue )
1748  			{
1749  				xQueueRegistry[ ux ].pcQueueName = NULL;
1750  				xQueueRegistry[ ux ].xHandle = ( QueueHandle_t ) 0;
1751  				break;
1752  			}
1753  			else
1754  			{
1755  				mtCOVERAGE_TEST_MARKER();
1756  			}
1757  		}
1758  	} &amp;bsol;*lint !e818 xQueue could not be pointer to const because it is a typedef. */
1759  #endif &amp;bsol;* configQUEUE_REGISTRY_SIZE */
1760  #if ( configUSE_TIMERS == 1 )
1761  	void vQueueWaitForMessageRestricted( QueueHandle_t xQueue, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely )
1762  	{
1763  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1764  		prvLockQueue( pxQueue );
1765  		if( pxQueue-&gt;uxMessagesWaiting == ( UBaseType_t ) 0U )
1766  		{
1767  			vTaskPlaceOnEventListRestricted( &amp;( pxQueue-&gt;xTasksWaitingToReceive ), xTicksToWait, xWaitIndefinitely );
1768  		}
1769  		else
1770  		{
1771  			mtCOVERAGE_TEST_MARKER();
1772  		}
1773  		prvUnlockQueue( pxQueue );
1774  	}
1775  #endif &amp;bsol;* configUSE_TIMERS */
1776  #if( ( configUSE_QUEUE_SETS == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
1777  	QueueSetHandle_t xQueueCreateSet( const UBaseType_t uxEventQueueLength )
1778  	{
1779  	QueueSetHandle_t pxQueue;
1780  		pxQueue = xQueueGenericCreate( uxEventQueueLength, ( UBaseType_t ) sizeof( Queue_t * ), queueQUEUE_TYPE_SET );
1781  		return pxQueue;
1782  	}
1783  #endif &amp;bsol;* configUSE_QUEUE_SETS */
1784  #if ( configUSE_QUEUE_SETS == 1 )
1785  	BaseType_t xQueueAddToSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet )
1786  	{
1787  	BaseType_t xReturn;
1788  		taskENTER_CRITICAL();
1789  		{
1790  			if( ( ( Queue_t * ) xQueueOrSemaphore )-&gt;pxQueueSetContainer != NULL )
1791  			{
1792  				xReturn = pdFAIL;
1793  			}
1794  			else if( ( ( Queue_t * ) xQueueOrSemaphore )-&gt;uxMessagesWaiting != ( UBaseType_t ) 0 )
1795  			{
1796  				xReturn = pdFAIL;
1797  			}
1798  			else
1799  			{
1800  				( ( Queue_t * ) xQueueOrSemaphore )-&gt;pxQueueSetContainer = xQueueSet;
1801  				xReturn = pdPASS;
1802  			}
1803  		}
1804  		taskEXIT_CRITICAL();
1805  		return xReturn;
1806  	}
1807  #endif &amp;bsol;* configUSE_QUEUE_SETS */
1808  #if ( configUSE_QUEUE_SETS == 1 )
1809  	BaseType_t xQueueRemoveFromSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet )
1810  	{
1811  	BaseType_t xReturn;
1812  	Queue_t * const pxQueueOrSemaphore = ( Queue_t * ) xQueueOrSemaphore;
1813  		if( pxQueueOrSemaphore-&gt;pxQueueSetContainer != xQueueSet )
1814  		{
1815  			xReturn = pdFAIL;
1816  		}
1817  		else if( pxQueueOrSemaphore-&gt;uxMessagesWaiting != ( UBaseType_t ) 0 )
1818  		{
1819  			xReturn = pdFAIL;
1820  		}
1821  		else
1822  		{
1823  			taskENTER_CRITICAL();
1824  			{
1825  				pxQueueOrSemaphore-&gt;pxQueueSetContainer = NULL;
1826  			}
1827  			taskEXIT_CRITICAL();
1828  			xReturn = pdPASS;
1829  		}
1830  		return xReturn;
1831  	} &amp;bsol;*lint !e818 xQueueSet could not be declared as pointing to const as it is a typedef. */
1832  #endif &amp;bsol;* configUSE_QUEUE_SETS */
1833  #if ( configUSE_QUEUE_SETS == 1 )
1834  	QueueSetMemberHandle_t xQueueSelectFromSet( QueueSetHandle_t xQueueSet, TickType_t const xTicksToWait )
1835  	{
1836  	QueueSetMemberHandle_t xReturn = NULL;
1837  		( void ) xQueueReceive( ( QueueHandle_t ) xQueueSet, &amp;xReturn, xTicksToWait ); &amp;bsol;*lint !e961 Casting from one typedef to another is not redundant. */
1838  		return xReturn;
1839  	}
1840  #endif &amp;bsol;* configUSE_QUEUE_SETS */
1841  #if ( configUSE_QUEUE_SETS == 1 )
1842  	QueueSetMemberHandle_t xQueueSelectFromSetFromISR( QueueSetHandle_t xQueueSet )
1843  	{
1844  	QueueSetMemberHandle_t xReturn = NULL;
1845  		( void ) xQueueReceiveFromISR( ( QueueHandle_t ) xQueueSet, &amp;xReturn, NULL ); &amp;bsol;*lint !e961 Casting from one typedef to another is not redundant. */
1846  		return xReturn;
1847  	}
1848  #endif &amp;bsol;* configUSE_QUEUE_SETS */
1849  #if ( configUSE_QUEUE_SETS == 1 )
1850  	static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue, const BaseType_t xCopyPosition )
1851  	{
1852  	Queue_t *pxQueueSetContainer = pxQueue-&gt;pxQueueSetContainer;
1853  	BaseType_t xReturn = pdFALSE;
1854  		configASSERT( pxQueueSetContainer );
1855  		configASSERT( pxQueueSetContainer-&gt;uxMessagesWaiting &lt; pxQueueSetContainer-&gt;uxLength );
1856  		if( pxQueueSetContainer-&gt;uxMessagesWaiting &lt; pxQueueSetContainer-&gt;uxLength )
1857  		{
1858  			const int8_t cTxLock = pxQueueSetContainer-&gt;cTxLock;
1859  			traceQUEUE_SEND( pxQueueSetContainer );
1860  			xReturn = prvCopyDataToQueue( pxQueueSetContainer, &amp;pxQueue, xCopyPosition );
1861  			if( cTxLock == queueUNLOCKED )
1862  			{
1863  				if( listLIST_IS_EMPTY( &amp;( pxQueueSetContainer-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1864  				{
1865  					if( xTaskRemoveFromEventList( &amp;( pxQueueSetContainer-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1866  					{
1867  						xReturn = pdTRUE;
1868  					}
1869  					else
1870  					{
1871  						mtCOVERAGE_TEST_MARKER();
1872  					}
1873  				}
1874  				else
1875  				{
1876  					mtCOVERAGE_TEST_MARKER();
1877  				}
1878  			}
1879  			else
1880  			{
1881  				pxQueueSetContainer-&gt;cTxLock = ( int8_t ) ( cTxLock + 1 );
1882  			}
1883  		}
1884  		else
1885  		{
1886  			mtCOVERAGE_TEST_MARKER();
1887  		}
1888  		return xReturn;
1889  	}
1890  #endif &amp;bsol;* configUSE_QUEUE_SETS */
</code></pre>
        </div>
        <div class="column">
            <h3>Adafruit_nRF52_Arduino-MDEwOlJlcG9zaXRvcnk3NDM1NDcyOQ==-flat-queue.c</h3>
            <pre><code>1  #include &lt;stdlib.h&gt;
2  #include &lt;string.h&gt;
3  #define MPU_WRAPPERS_INCLUDED_FROM_API_FILE
4  #include &quot;FreeRTOS.h&quot;
5  #include &quot;task.h&quot;
6  #include &quot;queue.h&quot;
7  #if ( configUSE_CO_ROUTINES == 1 )
8  	#include &quot;croutine.h&quot;
9  #endif
10  #undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE &amp;bsol;*lint !e961 !e750. */
11  #define queueUNLOCKED					( ( int8_t ) -1 )
12  #define queueLOCKED_UNMODIFIED			( ( int8_t ) 0 )
13  #define pxMutexHolder					pcTail
14  #define uxQueueType						pcHead
15  #define queueQUEUE_IS_MUTEX				NULL
16  #define queueSEMAPHORE_QUEUE_ITEM_LENGTH ( ( UBaseType_t ) 0 )
17  #define queueMUTEX_GIVE_BLOCK_TIME		 ( ( TickType_t ) 0U )
18  #if( configUSE_PREEMPTION == 0 )
19  	#define queueYIELD_IF_USING_PREEMPTION()
20  #else
21  	#define queueYIELD_IF_USING_PREEMPTION() portYIELD_WITHIN_API()
22  #endif
23  typedef struct QueueDefinition
24  {
25  	int8_t *pcHead;					&amp;bsol;*&lt; Points to the beginning of the queue storage area. */
26  	int8_t *pcTail;					&amp;bsol;*&lt; Points to the byte at the end of the queue storage area.  Once more byte is allocated than necessary to store the queue items, this is used as a marker. */
27  	int8_t *pcWriteTo;				&amp;bsol;*&lt; Points to the free next place in the storage area. */
28  	union							&amp;bsol;* Use of a union is an exception to the coding standard to ensure two mutually exclusive structure members don&#x27;t appear simultaneously (wasting RAM). */
29  	{
30  		int8_t *pcReadFrom;			&amp;bsol;*&lt; Points to the last place that a queued item was read from when the structure is used as a queue. */
31  		UBaseType_t uxRecursiveCallCount;&amp;bsol;*&lt; Maintains a count of the number of times a recursive mutex has been recursively &#x27;taken&#x27; when the structure is used as a mutex. */
32  	} u;
33  	List_t xTasksWaitingToSend;		&amp;bsol;*&lt; List of tasks that are blocked waiting to post onto this queue.  Stored in priority order. */
34  	List_t xTasksWaitingToReceive;	&amp;bsol;*&lt; List of tasks that are blocked waiting to read from this queue.  Stored in priority order. */
35  	volatile UBaseType_t uxMessagesWaiting;&amp;bsol;*&lt; The number of items currently in the queue. */
36  	UBaseType_t uxLength;			&amp;bsol;*&lt; The length of the queue defined as the number of items it will hold, not the number of bytes. */
37  	UBaseType_t uxItemSize;			&amp;bsol;*&lt; The size of each items that the queue will hold. */
38  	volatile int8_t cRxLock;		&amp;bsol;*&lt; Stores the number of items received from the queue (removed from the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */
39  	volatile int8_t cTxLock;		&amp;bsol;*&lt; Stores the number of items transmitted to the queue (added to the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */
40  	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
41  		uint8_t ucStaticallyAllocated;	&amp;bsol;*&lt; Set to pdTRUE if the memory used by the queue was statically allocated to ensure no attempt is made to free the memory. */
42  	#endif
43  	#if ( configUSE_QUEUE_SETS == 1 )
44  		struct QueueDefinition *pxQueueSetContainer;
45  	#endif
46  	#if ( configUSE_TRACE_FACILITY == 1 )
47  		UBaseType_t uxQueueNumber;
48  		uint8_t ucQueueType;
49  	#endif
50  } xQUEUE;
51  typedef xQUEUE Queue_t;
52  #if ( configQUEUE_REGISTRY_SIZE &gt; 0 )
53  	typedef struct QUEUE_REGISTRY_ITEM
54  	{
55  		const char *pcQueueName; &amp;bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
56  		QueueHandle_t xHandle;
57  	} xQueueRegistryItem;
58  	typedef xQueueRegistryItem QueueRegistryItem_t;
59  	PRIVILEGED_DATA QueueRegistryItem_t xQueueRegistry[ configQUEUE_REGISTRY_SIZE ];
60  #endif &amp;bsol;* configQUEUE_REGISTRY_SIZE */
61  static void prvUnlockQueue( Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;
62  static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue ) PRIVILEGED_FUNCTION;
63  static BaseType_t prvIsQueueFull( const Queue_t *pxQueue ) PRIVILEGED_FUNCTION;
64  static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition ) PRIVILEGED_FUNCTION;
65  static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer ) PRIVILEGED_FUNCTION;
66  #if ( configUSE_QUEUE_SETS == 1 )
67  	static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue, const BaseType_t xCopyPosition ) PRIVILEGED_FUNCTION;
68  #endif
69  static void prvInitialiseNewQueue( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, const uint8_t ucQueueType, Queue_t *pxNewQueue ) PRIVILEGED_FUNCTION;
70  #if( configUSE_MUTEXES == 1 )
71  	static void prvInitialiseMutex( Queue_t *pxNewQueue ) PRIVILEGED_FUNCTION;
72  #endif
73  #if( configUSE_MUTEXES == 1 )
74  	static UBaseType_t prvGetDisinheritPriorityAfterTimeout( const Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;
75  #endif
76  #define prvLockQueue( pxQueue )								\
77  	taskENTER_CRITICAL();									\
78  	{														\
79  		if( ( pxQueue )-&gt;cRxLock == queueUNLOCKED )			\
80  		{													\
81  			( pxQueue )-&gt;cRxLock = queueLOCKED_UNMODIFIED;	\
82  		}													\
83  		if( ( pxQueue )-&gt;cTxLock == queueUNLOCKED )			\
84  		{													\
85  			( pxQueue )-&gt;cTxLock = queueLOCKED_UNMODIFIED;	\
86  		}													\
87  	}														\
88  	taskEXIT_CRITICAL()
89  BaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue )
90  {
91  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
92  	configASSERT( pxQueue );
93  	taskENTER_CRITICAL();
94  	{
95  		pxQueue-&gt;pcTail = pxQueue-&gt;pcHead + ( pxQueue-&gt;uxLength * pxQueue-&gt;uxItemSize );
96  		pxQueue-&gt;uxMessagesWaiting = ( UBaseType_t ) 0U;
97  		pxQueue-&gt;pcWriteTo = pxQueue-&gt;pcHead;
98  		pxQueue-&gt;u.pcReadFrom = pxQueue-&gt;pcHead + ( ( pxQueue-&gt;uxLength - ( UBaseType_t ) 1U ) * pxQueue-&gt;uxItemSize );
99  		pxQueue-&gt;cRxLock = queueUNLOCKED;
100  		pxQueue-&gt;cTxLock = queueUNLOCKED;
101  		if( xNewQueue == pdFALSE )
102  		{
103  			if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
104  			{
105  				if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
106  				{
107  					queueYIELD_IF_USING_PREEMPTION();
108  				}
109  				else
110  				{
111  					mtCOVERAGE_TEST_MARKER();
112  				}
113  			}
114  			else
115  			{
116  				mtCOVERAGE_TEST_MARKER();
117  			}
118  		}
119  		else
120  		{
121  			vListInitialise( &amp;( pxQueue-&gt;xTasksWaitingToSend ) );
122  			vListInitialise( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) );
123  		}
124  	}
125  	taskEXIT_CRITICAL();
126  	return pdPASS;
127  }
128  #if( configSUPPORT_STATIC_ALLOCATION == 1 )
129  	QueueHandle_t xQueueGenericCreateStatic( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, StaticQueue_t *pxStaticQueue, const uint8_t ucQueueType )
130  	{
131  	Queue_t *pxNewQueue;
132  		configASSERT( uxQueueLength &gt; ( UBaseType_t ) 0 );
133  		configASSERT( pxStaticQueue != NULL );
134  		configASSERT( !( ( pucQueueStorage != NULL ) &amp;&amp; ( uxItemSize == 0 ) ) );
135  		configASSERT( !( ( pucQueueStorage == NULL ) &amp;&amp; ( uxItemSize != 0 ) ) );
136  		#if( configASSERT_DEFINED == 1 )
137  		{
138  			volatile size_t xSize = sizeof( StaticQueue_t );
139  			configASSERT( xSize == sizeof( Queue_t ) );
140  		}
141  		#endif &amp;bsol;* configASSERT_DEFINED */
142  		pxNewQueue = ( Queue_t * ) pxStaticQueue; &amp;bsol;*lint !e740 Unusual cast is ok as the structures are designed to have the same alignment, and the size is checked by an assert. */
143  		if( pxNewQueue != NULL )
144  		{
145  			#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
146  			{
147  				pxNewQueue-&gt;ucStaticallyAllocated = pdTRUE;
148  			}
149  			#endif &amp;bsol;* configSUPPORT_DYNAMIC_ALLOCATION */
150  			prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );
151  		}
152  		else
153  		{
154  			traceQUEUE_CREATE_FAILED( ucQueueType );
155  		}
156  		return pxNewQueue;
157  	}
158  #endif &amp;bsol;* configSUPPORT_STATIC_ALLOCATION */
159  #if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
160  	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType )
161  	{
162  	Queue_t *pxNewQueue;
163  	size_t xQueueSizeInBytes;
164  	uint8_t *pucQueueStorage;
165  		configASSERT( uxQueueLength &gt; ( UBaseType_t ) 0 );
166  		if( uxItemSize == ( UBaseType_t ) 0 )
167  		{
168  			xQueueSizeInBytes = ( size_t ) 0;
169  		}
170  		else
171  		{
172  			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); &amp;bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
173  		}
174  		pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );
175  		if( pxNewQueue != NULL )
176  		{
177  			pucQueueStorage = ( ( uint8_t * ) pxNewQueue ) + sizeof( Queue_t );
178  			#if( configSUPPORT_STATIC_ALLOCATION == 1 )
179  			{
180  				pxNewQueue-&gt;ucStaticallyAllocated = pdFALSE;
181  			}
182  			#endif &amp;bsol;* configSUPPORT_STATIC_ALLOCATION */
183  			prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );
184  		}
185  		else
186  		{
187  			traceQUEUE_CREATE_FAILED( ucQueueType );
188  		}
189  		return pxNewQueue;
190  	}
191  #endif &amp;bsol;* configSUPPORT_STATIC_ALLOCATION */
192  static void prvInitialiseNewQueue( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, const uint8_t ucQueueType, Queue_t *pxNewQueue )
193  {
194  	( void ) ucQueueType;
195  	if( uxItemSize == ( UBaseType_t ) 0 )
196  	{
197  		pxNewQueue-&gt;pcHead = ( int8_t * ) pxNewQueue;
198  	}
199  	else
200  	{
201  		pxNewQueue-&gt;pcHead = ( int8_t * ) pucQueueStorage;
202  	}
203  	pxNewQueue-&gt;uxLength = uxQueueLength;
204  	pxNewQueue-&gt;uxItemSize = uxItemSize;
205  	( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
206  	#if ( configUSE_TRACE_FACILITY == 1 )
207  	{
208  		pxNewQueue-&gt;ucQueueType = ucQueueType;
209  	}
210  	#endif &amp;bsol;* configUSE_TRACE_FACILITY */
211  	#if( configUSE_QUEUE_SETS == 1 )
212  	{
213  		pxNewQueue-&gt;pxQueueSetContainer = NULL;
214  	}
215  	#endif &amp;bsol;* configUSE_QUEUE_SETS */
216  	traceQUEUE_CREATE( pxNewQueue );
217  }
218  #if( configUSE_MUTEXES == 1 )
219  	static void prvInitialiseMutex( Queue_t *pxNewQueue )
220  	{
221  		if( pxNewQueue != NULL )
222  		{
223  			pxNewQueue-&gt;pxMutexHolder = NULL;
224  			pxNewQueue-&gt;uxQueueType = queueQUEUE_IS_MUTEX;
225  			pxNewQueue-&gt;u.uxRecursiveCallCount = 0;
226  			traceCREATE_MUTEX( pxNewQueue );
227  			( void ) xQueueGenericSend( pxNewQueue, NULL, ( TickType_t ) 0U, queueSEND_TO_BACK );
228  		}
229  		else
230  		{
231  			traceCREATE_MUTEX_FAILED();
232  		}
233  	}
234  #endif &amp;bsol;* configUSE_MUTEXES */
235  #if( ( configUSE_MUTEXES == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
236  	QueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType )
237  	{
238  	Queue_t *pxNewQueue;
239  	const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;
240  		pxNewQueue = ( Queue_t * ) xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );
241  		prvInitialiseMutex( pxNewQueue );
242  		return pxNewQueue;
243  	}
244  #endif &amp;bsol;* configUSE_MUTEXES */
245  #if( ( configUSE_MUTEXES == 1 ) &amp;&amp; ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
246  	QueueHandle_t xQueueCreateMutexStatic( const uint8_t ucQueueType, StaticQueue_t *pxStaticQueue )
247  	{
248  	Queue_t *pxNewQueue;
249  	const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;
250  		( void ) ucQueueType;
251  		pxNewQueue = ( Queue_t * ) xQueueGenericCreateStatic( uxMutexLength, uxMutexSize, NULL, pxStaticQueue, ucQueueType );
252  		prvInitialiseMutex( pxNewQueue );
253  		return pxNewQueue;
254  	}
255  #endif &amp;bsol;* configUSE_MUTEXES */
256  #if ( ( configUSE_MUTEXES == 1 ) &amp;&amp; ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) )
257  	void* xQueueGetMutexHolder( QueueHandle_t xSemaphore )
258  	{
259  	void *pxReturn;
260  		taskENTER_CRITICAL();
261  		{
262  			if( ( ( Queue_t * ) xSemaphore )-&gt;uxQueueType == queueQUEUE_IS_MUTEX )
263  			{
264  				pxReturn = ( void * ) ( ( Queue_t * ) xSemaphore )-&gt;pxMutexHolder;
265  			}
266  			else
267  			{
268  				pxReturn = NULL;
269  			}
270  		}
271  		taskEXIT_CRITICAL();
272  		return pxReturn;
273  	} &amp;bsol;*lint !e818 xSemaphore cannot be a pointer to const because it is a typedef. */
274  #endif
275  #if ( ( configUSE_MUTEXES == 1 ) &amp;&amp; ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) )
276  	void* xQueueGetMutexHolderFromISR( QueueHandle_t xSemaphore )
277  	{
278  	void *pxReturn;
279  		configASSERT( xSemaphore );
280  		if( ( ( Queue_t * ) xSemaphore )-&gt;uxQueueType == queueQUEUE_IS_MUTEX )
281  		{
282  			pxReturn = ( void * ) ( ( Queue_t * ) xSemaphore )-&gt;pxMutexHolder;
283  		}
284  		else
285  		{
286  			pxReturn = NULL;
287  		}
288  		return pxReturn;
289  	} &amp;bsol;*lint !e818 xSemaphore cannot be a pointer to const because it is a typedef. */
290  #endif
291  #if ( configUSE_RECURSIVE_MUTEXES == 1 )
292  	BaseType_t xQueueGiveMutexRecursive( QueueHandle_t xMutex )
293  	{
294  	BaseType_t xReturn;
295  	Queue_t * const pxMutex = ( Queue_t * ) xMutex;
296  		configASSERT( pxMutex );
297  		if( pxMutex-&gt;pxMutexHolder == ( void * ) xTaskGetCurrentTaskHandle() ) &amp;bsol;*lint !e961 Not a redundant cast as TaskHandle_t is a typedef. */
298  		{
299  			traceGIVE_MUTEX_RECURSIVE( pxMutex );
300  			( pxMutex-&gt;u.uxRecursiveCallCount )--;
301  			if( pxMutex-&gt;u.uxRecursiveCallCount == ( UBaseType_t ) 0 )
302  			{
303  				( void ) xQueueGenericSend( pxMutex, NULL, queueMUTEX_GIVE_BLOCK_TIME, queueSEND_TO_BACK );
304  			}
305  			else
306  			{
307  				mtCOVERAGE_TEST_MARKER();
308  			}
309  			xReturn = pdPASS;
310  		}
311  		else
312  		{
313  			xReturn = pdFAIL;
314  			traceGIVE_MUTEX_RECURSIVE_FAILED( pxMutex );
315  		}
316  		return xReturn;
317  	}
318  #endif &amp;bsol;* configUSE_RECURSIVE_MUTEXES */
319  #if ( configUSE_RECURSIVE_MUTEXES == 1 )
320  	BaseType_t xQueueTakeMutexRecursive( QueueHandle_t xMutex, TickType_t xTicksToWait )
321  	{
322  	BaseType_t xReturn;
323  	Queue_t * const pxMutex = ( Queue_t * ) xMutex;
324  		configASSERT( pxMutex );
325  		traceTAKE_MUTEX_RECURSIVE( pxMutex );
326  		if( pxMutex-&gt;pxMutexHolder == ( void * ) xTaskGetCurrentTaskHandle() ) &amp;bsol;*lint !e961 Cast is not redundant as TaskHandle_t is a typedef. */
327  		{
328  			( pxMutex-&gt;u.uxRecursiveCallCount )++;
329  			xReturn = pdPASS;
330  		}
331  		else
332  		{
333  			xReturn = xQueueSemaphoreTake( pxMutex, xTicksToWait );
334  			if( xReturn != pdFAIL )
335  			{
336  				( pxMutex-&gt;u.uxRecursiveCallCount )++;
337  			}
338  			else
339  			{
340  				traceTAKE_MUTEX_RECURSIVE_FAILED( pxMutex );
341  			}
342  		}
343  		return xReturn;
344  	}
345  #endif &amp;bsol;* configUSE_RECURSIVE_MUTEXES */
346  #if( ( configUSE_COUNTING_SEMAPHORES == 1 ) &amp;&amp; ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
347  	QueueHandle_t xQueueCreateCountingSemaphoreStatic( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount, StaticQueue_t *pxStaticQueue )
348  	{
349  	QueueHandle_t xHandle;
350  		configASSERT( uxMaxCount != 0 );
351  		configASSERT( uxInitialCount &lt;= uxMaxCount );
352  		xHandle = xQueueGenericCreateStatic( uxMaxCount, queueSEMAPHORE_QUEUE_ITEM_LENGTH, NULL, pxStaticQueue, queueQUEUE_TYPE_COUNTING_SEMAPHORE );
353  		if( xHandle != NULL )
354  		{
355  			( ( Queue_t * ) xHandle )-&gt;uxMessagesWaiting = uxInitialCount;
356  			traceCREATE_COUNTING_SEMAPHORE();
357  		}
358  		else
359  		{
360  			traceCREATE_COUNTING_SEMAPHORE_FAILED();
361  		}
362  		return xHandle;
363  	}
364  #endif &amp;bsol;* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
365  #if( ( configUSE_COUNTING_SEMAPHORES == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
366  	QueueHandle_t xQueueCreateCountingSemaphore( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount )
367  	{
368  	QueueHandle_t xHandle;
369  		configASSERT( uxMaxCount != 0 );
370  		configASSERT( uxInitialCount &lt;= uxMaxCount );
371  		xHandle = xQueueGenericCreate( uxMaxCount, queueSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_COUNTING_SEMAPHORE );
372  		if( xHandle != NULL )
373  		{
374  			( ( Queue_t * ) xHandle )-&gt;uxMessagesWaiting = uxInitialCount;
375  			traceCREATE_COUNTING_SEMAPHORE();
376  		}
377  		else
378  		{
379  			traceCREATE_COUNTING_SEMAPHORE_FAILED();
380  		}
381  		return xHandle;
382  	}
383  #endif &amp;bsol;* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
384  BaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition )
385  {
386  BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
387  TimeOut_t xTimeOut;
388  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
389  	configASSERT( pxQueue );
390  	configASSERT( !( ( pvItemToQueue == NULL ) &amp;&amp; ( pxQueue-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
391  	configASSERT( !( ( xCopyPosition == queueOVERWRITE ) &amp;&amp; ( pxQueue-&gt;uxLength != 1 ) ) );
392  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
393  	{
394  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) &amp;&amp; ( xTicksToWait != 0 ) ) );
395  	}
396  	#endif
397  	for( ;; )
398  	{
399  		taskENTER_CRITICAL();
400  		{
401  			if( ( pxQueue-&gt;uxMessagesWaiting &lt; pxQueue-&gt;uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
402  			{
403  				traceQUEUE_SEND( pxQueue );
404  				xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
405  				#if ( configUSE_QUEUE_SETS == 1 )
406  				{
407  					if( pxQueue-&gt;pxQueueSetContainer != NULL )
408  					{
409  						if( prvNotifyQueueSetContainer( pxQueue, xCopyPosition ) != pdFALSE )
410  						{
411  							queueYIELD_IF_USING_PREEMPTION();
412  						}
413  						else
414  						{
415  							mtCOVERAGE_TEST_MARKER();
416  						}
417  					}
418  					else
419  					{
420  						if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
421  						{
422  							if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
423  							{
424  								queueYIELD_IF_USING_PREEMPTION();
425  							}
426  							else
427  							{
428  								mtCOVERAGE_TEST_MARKER();
429  							}
430  						}
431  						else if( xYieldRequired != pdFALSE )
432  						{
433  							queueYIELD_IF_USING_PREEMPTION();
434  						}
435  						else
436  						{
437  							mtCOVERAGE_TEST_MARKER();
438  						}
439  					}
440  				}
441  				#else &amp;bsol;* configUSE_QUEUE_SETS */
442  				{
443  					if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
444  					{
445  						if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
446  						{
447  							queueYIELD_IF_USING_PREEMPTION();
448  						}
449  						else
450  						{
451  							mtCOVERAGE_TEST_MARKER();
452  						}
453  					}
454  					else if( xYieldRequired != pdFALSE )
455  					{
456  						queueYIELD_IF_USING_PREEMPTION();
457  					}
458  					else
459  					{
460  						mtCOVERAGE_TEST_MARKER();
461  					}
462  				}
463  				#endif &amp;bsol;* configUSE_QUEUE_SETS */
464  				taskEXIT_CRITICAL();
465  				return pdPASS;
466  			}
467  			else
468  			{
469  				if( xTicksToWait == ( TickType_t ) 0 )
470  				{
471  					taskEXIT_CRITICAL();
472  					traceQUEUE_SEND_FAILED( pxQueue );
473  					return errQUEUE_FULL;
474  				}
475  				else if( xEntryTimeSet == pdFALSE )
476  				{
477  					vTaskInternalSetTimeOutState( &amp;xTimeOut );
478  					xEntryTimeSet = pdTRUE;
479  				}
480  				else
481  				{
482  					mtCOVERAGE_TEST_MARKER();
483  				}
484  			}
485  		}
486  		taskEXIT_CRITICAL();
487  		vTaskSuspendAll();
488  		prvLockQueue( pxQueue );
489  		if( xTaskCheckForTimeOut( &amp;xTimeOut, &amp;xTicksToWait ) == pdFALSE )
490  		{
491  			if( prvIsQueueFull( pxQueue ) != pdFALSE )
492  			{
493  				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
494  				vTaskPlaceOnEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ), xTicksToWait );
495  				prvUnlockQueue( pxQueue );
496  				if( xTaskResumeAll() == pdFALSE )
497  				{
498  					portYIELD_WITHIN_API();
499  				}
500  			}
501  			else
502  			{
503  				prvUnlockQueue( pxQueue );
504  				( void ) xTaskResumeAll();
505  			}
506  		}
507  		else
508  		{
509  			prvUnlockQueue( pxQueue );
510  			( void ) xTaskResumeAll();
511  			traceQUEUE_SEND_FAILED( pxQueue );
512  			return errQUEUE_FULL;
513  		}
514  	}
515  }
516  BaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition )
517  {
518  BaseType_t xReturn;
519  UBaseType_t uxSavedInterruptStatus;
520  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
521  	configASSERT( pxQueue );
522  	configASSERT( !( ( pvItemToQueue == NULL ) &amp;&amp; ( pxQueue-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
523  	configASSERT( !( ( xCopyPosition == queueOVERWRITE ) &amp;&amp; ( pxQueue-&gt;uxLength != 1 ) ) );
524  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
525  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
526  	{
527  		if( ( pxQueue-&gt;uxMessagesWaiting &lt; pxQueue-&gt;uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
528  		{
529  			const int8_t cTxLock = pxQueue-&gt;cTxLock;
530  			traceQUEUE_SEND_FROM_ISR( pxQueue );
531  			( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
532  			if( cTxLock == queueUNLOCKED )
533  			{
534  				#if ( configUSE_QUEUE_SETS == 1 )
535  				{
536  					if( pxQueue-&gt;pxQueueSetContainer != NULL )
537  					{
538  						if( prvNotifyQueueSetContainer( pxQueue, xCopyPosition ) != pdFALSE )
539  						{
540  							if( pxHigherPriorityTaskWoken != NULL )
541  							{
542  								*pxHigherPriorityTaskWoken = pdTRUE;
543  							}
544  							else
545  							{
546  								mtCOVERAGE_TEST_MARKER();
547  							}
548  						}
549  						else
550  						{
551  							mtCOVERAGE_TEST_MARKER();
552  						}
553  					}
554  					else
555  					{
556  						if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
557  						{
558  							if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
559  							{
560  								if( pxHigherPriorityTaskWoken != NULL )
561  								{
562  									*pxHigherPriorityTaskWoken = pdTRUE;
563  								}
564  								else
565  								{
566  									mtCOVERAGE_TEST_MARKER();
567  								}
568  							}
569  							else
570  							{
571  								mtCOVERAGE_TEST_MARKER();
572  							}
573  						}
574  						else
575  						{
576  							mtCOVERAGE_TEST_MARKER();
577  						}
578  					}
579  				}
580  				#else &amp;bsol;* configUSE_QUEUE_SETS */
581  				{
582  					if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
583  					{
584  						if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
585  						{
586  							if( pxHigherPriorityTaskWoken != NULL )
587  							{
588  								*pxHigherPriorityTaskWoken = pdTRUE;
589  							}
590  							else
591  							{
592  								mtCOVERAGE_TEST_MARKER();
593  							}
594  						}
595  						else
596  						{
597  							mtCOVERAGE_TEST_MARKER();
598  						}
599  					}
600  					else
601  					{
602  						mtCOVERAGE_TEST_MARKER();
603  					}
604  				}
605  				#endif &amp;bsol;* configUSE_QUEUE_SETS */
606  			}
607  			else
608  			{
609  				pxQueue-&gt;cTxLock = ( int8_t ) ( cTxLock + 1 );
610  			}
611  			xReturn = pdPASS;
612  		}
613  		else
614  		{
615  			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
616  			xReturn = errQUEUE_FULL;
617  		}
618  	}
619  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
620  	return xReturn;
621  }
622  BaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken )
623  {
624  BaseType_t xReturn;
625  UBaseType_t uxSavedInterruptStatus;
626  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
627  	configASSERT( pxQueue );
628  	configASSERT( pxQueue-&gt;uxItemSize == 0 );
629  	configASSERT( !( ( pxQueue-&gt;uxQueueType == queueQUEUE_IS_MUTEX ) &amp;&amp; ( pxQueue-&gt;pxMutexHolder != NULL ) ) );
630  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
631  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
632  	{
633  		const UBaseType_t uxMessagesWaiting = pxQueue-&gt;uxMessagesWaiting;
634  		if( uxMessagesWaiting &lt; pxQueue-&gt;uxLength )
635  		{
636  			const int8_t cTxLock = pxQueue-&gt;cTxLock;
637  			traceQUEUE_SEND_FROM_ISR( pxQueue );
638  			pxQueue-&gt;uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
639  			if( cTxLock == queueUNLOCKED )
640  			{
641  				#if ( configUSE_QUEUE_SETS == 1 )
642  				{
643  					if( pxQueue-&gt;pxQueueSetContainer != NULL )
644  					{
645  						if( prvNotifyQueueSetContainer( pxQueue, queueSEND_TO_BACK ) != pdFALSE )
646  						{
647  							if( pxHigherPriorityTaskWoken != NULL )
648  							{
649  								*pxHigherPriorityTaskWoken = pdTRUE;
650  							}
651  							else
652  							{
653  								mtCOVERAGE_TEST_MARKER();
654  							}
655  						}
656  						else
657  						{
658  							mtCOVERAGE_TEST_MARKER();
659  						}
660  					}
661  					else
662  					{
663  						if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
664  						{
665  							if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
666  							{
667  								if( pxHigherPriorityTaskWoken != NULL )
668  								{
669  									*pxHigherPriorityTaskWoken = pdTRUE;
670  								}
671  								else
672  								{
673  									mtCOVERAGE_TEST_MARKER();
674  								}
675  							}
676  							else
677  							{
678  								mtCOVERAGE_TEST_MARKER();
679  							}
680  						}
681  						else
682  						{
683  							mtCOVERAGE_TEST_MARKER();
684  						}
685  					}
686  				}
687  				#else &amp;bsol;* configUSE_QUEUE_SETS */
688  				{
689  					if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
690  					{
691  						if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
692  						{
693  							if( pxHigherPriorityTaskWoken != NULL )
694  							{
695  								*pxHigherPriorityTaskWoken = pdTRUE;
696  							}
697  							else
698  							{
699  								mtCOVERAGE_TEST_MARKER();
700  							}
701  						}
702  						else
703  						{
704  							mtCOVERAGE_TEST_MARKER();
705  						}
706  					}
707  					else
708  					{
709  						mtCOVERAGE_TEST_MARKER();
710  					}
711  				}
712  				#endif &amp;bsol;* configUSE_QUEUE_SETS */
713  			}
714  			else
715  			{
716  				pxQueue-&gt;cTxLock = ( int8_t ) ( cTxLock + 1 );
717  			}
718  			xReturn = pdPASS;
719  		}
720  		else
721  		{
722  			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
723  			xReturn = errQUEUE_FULL;
724  		}
725  	}
726  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
727  	return xReturn;
728  }
729  BaseType_t xQueueReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait )
730  {
731  BaseType_t xEntryTimeSet = pdFALSE;
732  TimeOut_t xTimeOut;
733  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
734  	configASSERT( ( pxQueue ) );
735  	configASSERT( !( ( ( pvBuffer ) == NULL ) &amp;&amp; ( ( pxQueue )-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
736  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
737  	{
738  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) &amp;&amp; ( xTicksToWait != 0 ) ) );
739  	}
740  	#endif
741  	for( ;; )
742  	{
743  		taskENTER_CRITICAL();
744  		{
745  			const UBaseType_t uxMessagesWaiting = pxQueue-&gt;uxMessagesWaiting;
746  			if( uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
747  			{
748  				prvCopyDataFromQueue( pxQueue, pvBuffer );
749  				traceQUEUE_RECEIVE( pxQueue );
750  				pxQueue-&gt;uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
751  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
752  				{
753  					if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
754  					{
755  						queueYIELD_IF_USING_PREEMPTION();
756  					}
757  					else
758  					{
759  						mtCOVERAGE_TEST_MARKER();
760  					}
761  				}
762  				else
763  				{
764  					mtCOVERAGE_TEST_MARKER();
765  				}
766  				taskEXIT_CRITICAL();
767  				return pdPASS;
768  			}
769  			else
770  			{
771  				if( xTicksToWait == ( TickType_t ) 0 )
772  				{
773  					taskEXIT_CRITICAL();
774  					traceQUEUE_RECEIVE_FAILED( pxQueue );
775  					return errQUEUE_EMPTY;
776  				}
777  				else if( xEntryTimeSet == pdFALSE )
778  				{
779  					vTaskInternalSetTimeOutState( &amp;xTimeOut );
780  					xEntryTimeSet = pdTRUE;
781  				}
782  				else
783  				{
784  					mtCOVERAGE_TEST_MARKER();
785  				}
786  			}
787  		}
788  		taskEXIT_CRITICAL();
789  		vTaskSuspendAll();
790  		prvLockQueue( pxQueue );
791  		if( xTaskCheckForTimeOut( &amp;xTimeOut, &amp;xTicksToWait ) == pdFALSE )
792  		{
793  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
794  			{
795  				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
796  				vTaskPlaceOnEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ), xTicksToWait );
797  				prvUnlockQueue( pxQueue );
798  				if( xTaskResumeAll() == pdFALSE )
799  				{
800  					portYIELD_WITHIN_API();
801  				}
802  				else
803  				{
804  					mtCOVERAGE_TEST_MARKER();
805  				}
806  			}
807  			else
808  			{
809  				prvUnlockQueue( pxQueue );
810  				( void ) xTaskResumeAll();
811  			}
812  		}
813  		else
814  		{
815  			prvUnlockQueue( pxQueue );
816  			( void ) xTaskResumeAll();
817  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
818  			{
819  				traceQUEUE_RECEIVE_FAILED( pxQueue );
820  				return errQUEUE_EMPTY;
821  			}
822  			else
823  			{
824  				mtCOVERAGE_TEST_MARKER();
825  			}
826  		}
827  	}
828  }
829  BaseType_t xQueueSemaphoreTake( QueueHandle_t xQueue, TickType_t xTicksToWait )
830  {
831  BaseType_t xEntryTimeSet = pdFALSE;
832  TimeOut_t xTimeOut;
833  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
834  #if( configUSE_MUTEXES == 1 )
835  	BaseType_t xInheritanceOccurred = pdFALSE;
836  #endif
837  	configASSERT( ( pxQueue ) );
838  	configASSERT( pxQueue-&gt;uxItemSize == 0 );
839  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
840  	{
841  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) &amp;&amp; ( xTicksToWait != 0 ) ) );
842  	}
843  	#endif
844  	for( ;; )
845  	{
846  		taskENTER_CRITICAL();
847  		{
848  			const UBaseType_t uxSemaphoreCount = pxQueue-&gt;uxMessagesWaiting;
849  			if( uxSemaphoreCount &gt; ( UBaseType_t ) 0 )
850  			{
851  				traceQUEUE_RECEIVE( pxQueue );
852  				pxQueue-&gt;uxMessagesWaiting = uxSemaphoreCount - ( UBaseType_t ) 1;
853  				#if ( configUSE_MUTEXES == 1 )
854  				{
855  					if( pxQueue-&gt;uxQueueType == queueQUEUE_IS_MUTEX )
856  					{
857  						pxQueue-&gt;pxMutexHolder = ( int8_t * ) pvTaskIncrementMutexHeldCount(); &amp;bsol;*lint !e961 Cast is not redundant as TaskHandle_t is a typedef. */
858  					}
859  					else
860  					{
861  						mtCOVERAGE_TEST_MARKER();
862  					}
863  				}
864  				#endif &amp;bsol;* configUSE_MUTEXES */
865  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
866  				{
867  					if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
868  					{
869  						queueYIELD_IF_USING_PREEMPTION();
870  					}
871  					else
872  					{
873  						mtCOVERAGE_TEST_MARKER();
874  					}
875  				}
876  				else
877  				{
878  					mtCOVERAGE_TEST_MARKER();
879  				}
880  				taskEXIT_CRITICAL();
881  				return pdPASS;
882  			}
883  			else
884  			{
885  				if( xTicksToWait == ( TickType_t ) 0 )
886  				{
887  					#if( configUSE_MUTEXES == 1 )
888  					{
889  						configASSERT( xInheritanceOccurred == pdFALSE );
890  					}
891  					#endif &amp;bsol;* configUSE_MUTEXES */
892  					taskEXIT_CRITICAL();
893  					traceQUEUE_RECEIVE_FAILED( pxQueue );
894  					return errQUEUE_EMPTY;
895  				}
896  				else if( xEntryTimeSet == pdFALSE )
897  				{
898  					vTaskInternalSetTimeOutState( &amp;xTimeOut );
899  					xEntryTimeSet = pdTRUE;
900  				}
901  				else
902  				{
903  					mtCOVERAGE_TEST_MARKER();
904  				}
905  			}
906  		}
907  		taskEXIT_CRITICAL();
908  		vTaskSuspendAll();
909  		prvLockQueue( pxQueue );
910  		if( xTaskCheckForTimeOut( &amp;xTimeOut, &amp;xTicksToWait ) == pdFALSE )
911  		{
912  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
913  			{
914  				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
915  				#if ( configUSE_MUTEXES == 1 )
916  				{
917  					if( pxQueue-&gt;uxQueueType == queueQUEUE_IS_MUTEX )
918  					{
919  						taskENTER_CRITICAL();
920  						{
921  							xInheritanceOccurred = xTaskPriorityInherit( ( void * ) pxQueue-&gt;pxMutexHolder );
922  						}
923  						taskEXIT_CRITICAL();
924  					}
925  					else
926  					{
927  						mtCOVERAGE_TEST_MARKER();
928  					}
929  				}
930  				#endif
931  				vTaskPlaceOnEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ), xTicksToWait );
932  				prvUnlockQueue( pxQueue );
933  				if( xTaskResumeAll() == pdFALSE )
934  				{
935  					portYIELD_WITHIN_API();
936  				}
937  				else
938  				{
939  					mtCOVERAGE_TEST_MARKER();
940  				}
941  			}
942  			else
943  			{
944  				prvUnlockQueue( pxQueue );
945  				( void ) xTaskResumeAll();
946  			}
947  		}
948  		else
949  		{
950  			prvUnlockQueue( pxQueue );
951  			( void ) xTaskResumeAll();
952  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
953  			{
954  				#if ( configUSE_MUTEXES == 1 )
955  				{
956  					if( xInheritanceOccurred != pdFALSE )
957  					{
958  						taskENTER_CRITICAL();
959  						{
960  							UBaseType_t uxHighestWaitingPriority;
961  							uxHighestWaitingPriority = prvGetDisinheritPriorityAfterTimeout( pxQueue );
962  							vTaskPriorityDisinheritAfterTimeout( ( void * ) pxQueue-&gt;pxMutexHolder, uxHighestWaitingPriority );
963  						}
964  						taskEXIT_CRITICAL();
965  					}
966  				}
967  				#endif &amp;bsol;* configUSE_MUTEXES */
968  				traceQUEUE_RECEIVE_FAILED( pxQueue );
969  				return errQUEUE_EMPTY;
970  			}
971  			else
972  			{
973  				mtCOVERAGE_TEST_MARKER();
974  			}
975  		}
976  	}
977  }
978  BaseType_t xQueuePeek( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait )
979  {
980  BaseType_t xEntryTimeSet = pdFALSE;
981  TimeOut_t xTimeOut;
982  int8_t *pcOriginalReadPosition;
983  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
984  	configASSERT( ( pxQueue ) );
985  	configASSERT( !( ( ( pvBuffer ) == NULL ) &amp;&amp; ( ( pxQueue )-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
986  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
987  	{
988  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) &amp;&amp; ( xTicksToWait != 0 ) ) );
989  	}
990  	#endif
991  	for( ;; )
992  	{
993  		taskENTER_CRITICAL();
994  		{
995  			const UBaseType_t uxMessagesWaiting = pxQueue-&gt;uxMessagesWaiting;
996  			if( uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
997  			{
998  				pcOriginalReadPosition = pxQueue-&gt;u.pcReadFrom;
999  				prvCopyDataFromQueue( pxQueue, pvBuffer );
1000  				traceQUEUE_PEEK( pxQueue );
1001  				pxQueue-&gt;u.pcReadFrom = pcOriginalReadPosition;
1002  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1003  				{
1004  					if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1005  					{
1006  						queueYIELD_IF_USING_PREEMPTION();
1007  					}
1008  					else
1009  					{
1010  						mtCOVERAGE_TEST_MARKER();
1011  					}
1012  				}
1013  				else
1014  				{
1015  					mtCOVERAGE_TEST_MARKER();
1016  				}
1017  				taskEXIT_CRITICAL();
1018  				return pdPASS;
1019  			}
1020  			else
1021  			{
1022  				if( xTicksToWait == ( TickType_t ) 0 )
1023  				{
1024  					taskEXIT_CRITICAL();
1025  					traceQUEUE_PEEK_FAILED( pxQueue );
1026  					return errQUEUE_EMPTY;
1027  				}
1028  				else if( xEntryTimeSet == pdFALSE )
1029  				{
1030  					vTaskInternalSetTimeOutState( &amp;xTimeOut );
1031  					xEntryTimeSet = pdTRUE;
1032  				}
1033  				else
1034  				{
1035  					mtCOVERAGE_TEST_MARKER();
1036  				}
1037  			}
1038  		}
1039  		taskEXIT_CRITICAL();
1040  		vTaskSuspendAll();
1041  		prvLockQueue( pxQueue );
1042  		if( xTaskCheckForTimeOut( &amp;xTimeOut, &amp;xTicksToWait ) == pdFALSE )
1043  		{
1044  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
1045  			{
1046  				traceBLOCKING_ON_QUEUE_PEEK( pxQueue );
1047  				vTaskPlaceOnEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ), xTicksToWait );
1048  				prvUnlockQueue( pxQueue );
1049  				if( xTaskResumeAll() == pdFALSE )
1050  				{
1051  					portYIELD_WITHIN_API();
1052  				}
1053  				else
1054  				{
1055  					mtCOVERAGE_TEST_MARKER();
1056  				}
1057  			}
1058  			else
1059  			{
1060  				prvUnlockQueue( pxQueue );
1061  				( void ) xTaskResumeAll();
1062  			}
1063  		}
1064  		else
1065  		{
1066  			prvUnlockQueue( pxQueue );
1067  			( void ) xTaskResumeAll();
1068  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
1069  			{
1070  				traceQUEUE_PEEK_FAILED( pxQueue );
1071  				return errQUEUE_EMPTY;
1072  			}
1073  			else
1074  			{
1075  				mtCOVERAGE_TEST_MARKER();
1076  			}
1077  		}
1078  	}
1079  }
1080  BaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken )
1081  {
1082  BaseType_t xReturn;
1083  UBaseType_t uxSavedInterruptStatus;
1084  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1085  	configASSERT( pxQueue );
1086  	configASSERT( !( ( pvBuffer == NULL ) &amp;&amp; ( pxQueue-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
1087  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
1088  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
1089  	{
1090  		const UBaseType_t uxMessagesWaiting = pxQueue-&gt;uxMessagesWaiting;
1091  		if( uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
1092  		{
1093  			const int8_t cRxLock = pxQueue-&gt;cRxLock;
1094  			traceQUEUE_RECEIVE_FROM_ISR( pxQueue );
1095  			prvCopyDataFromQueue( pxQueue, pvBuffer );
1096  			pxQueue-&gt;uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
1097  			if( cRxLock == queueUNLOCKED )
1098  			{
1099  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
1100  				{
1101  					if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
1102  					{
1103  						if( pxHigherPriorityTaskWoken != NULL )
1104  						{
1105  							*pxHigherPriorityTaskWoken = pdTRUE;
1106  						}
1107  						else
1108  						{
1109  							mtCOVERAGE_TEST_MARKER();
1110  						}
1111  					}
1112  					else
1113  					{
1114  						mtCOVERAGE_TEST_MARKER();
1115  					}
1116  				}
1117  				else
1118  				{
1119  					mtCOVERAGE_TEST_MARKER();
1120  				}
1121  			}
1122  			else
1123  			{
1124  				pxQueue-&gt;cRxLock = ( int8_t ) ( cRxLock + 1 );
1125  			}
1126  			xReturn = pdPASS;
1127  		}
1128  		else
1129  		{
1130  			xReturn = pdFAIL;
1131  			traceQUEUE_RECEIVE_FROM_ISR_FAILED( pxQueue );
1132  		}
1133  	}
1134  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
1135  	return xReturn;
1136  }
1137  BaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,  void * const pvBuffer )
1138  {
1139  BaseType_t xReturn;
1140  UBaseType_t uxSavedInterruptStatus;
1141  int8_t *pcOriginalReadPosition;
1142  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1143  	configASSERT( pxQueue );
1144  	configASSERT( !( ( pvBuffer == NULL ) &amp;&amp; ( pxQueue-&gt;uxItemSize != ( UBaseType_t ) 0U ) ) );
1145  	configASSERT( pxQueue-&gt;uxItemSize != 0 ); &amp;bsol;* Can&#x27;t peek a semaphore. */
1146  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
1147  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
1148  	{
1149  		if( pxQueue-&gt;uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
1150  		{
1151  			traceQUEUE_PEEK_FROM_ISR( pxQueue );
1152  			pcOriginalReadPosition = pxQueue-&gt;u.pcReadFrom;
1153  			prvCopyDataFromQueue( pxQueue, pvBuffer );
1154  			pxQueue-&gt;u.pcReadFrom = pcOriginalReadPosition;
1155  			xReturn = pdPASS;
1156  		}
1157  		else
1158  		{
1159  			xReturn = pdFAIL;
1160  			traceQUEUE_PEEK_FROM_ISR_FAILED( pxQueue );
1161  		}
1162  	}
1163  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
1164  	return xReturn;
1165  }
1166  UBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue )
1167  {
1168  UBaseType_t uxReturn;
1169  	configASSERT( xQueue );
1170  	taskENTER_CRITICAL();
1171  	{
1172  		uxReturn = ( ( Queue_t * ) xQueue )-&gt;uxMessagesWaiting;
1173  	}
1174  	taskEXIT_CRITICAL();
1175  	return uxReturn;
1176  } &amp;bsol;*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
1177  UBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue )
1178  {
1179  UBaseType_t uxReturn;
1180  Queue_t *pxQueue;
1181  	pxQueue = ( Queue_t * ) xQueue;
1182  	configASSERT( pxQueue );
1183  	taskENTER_CRITICAL();
1184  	{
1185  		uxReturn = pxQueue-&gt;uxLength - pxQueue-&gt;uxMessagesWaiting;
1186  	}
1187  	taskEXIT_CRITICAL();
1188  	return uxReturn;
1189  } &amp;bsol;*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
1190  UBaseType_t uxQueueMessagesWaitingFromISR( const QueueHandle_t xQueue )
1191  {
1192  UBaseType_t uxReturn;
1193  	configASSERT( xQueue );
1194  	uxReturn = ( ( Queue_t * ) xQueue )-&gt;uxMessagesWaiting;
1195  	return uxReturn;
1196  } &amp;bsol;*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
1197  void vQueueDelete( QueueHandle_t xQueue )
1198  {
1199  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1200  	configASSERT( pxQueue );
1201  	traceQUEUE_DELETE( pxQueue );
1202  	#if ( configQUEUE_REGISTRY_SIZE &gt; 0 )
1203  	{
1204  		vQueueUnregisterQueue( pxQueue );
1205  	}
1206  	#endif
1207  	#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) &amp;&amp; ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
1208  	{
1209  		vPortFree( pxQueue );
1210  	}
1211  	#elif( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) &amp;&amp; ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
1212  	{
1213  		if( pxQueue-&gt;ucStaticallyAllocated == ( uint8_t ) pdFALSE )
1214  		{
1215  			vPortFree( pxQueue );
1216  		}
1217  		else
1218  		{
1219  			mtCOVERAGE_TEST_MARKER();
1220  		}
1221  	}
1222  	#else
1223  	{
1224  		( void ) pxQueue;
1225  	}
1226  	#endif &amp;bsol;* configSUPPORT_DYNAMIC_ALLOCATION */
1227  }
1228  #if ( configUSE_TRACE_FACILITY == 1 )
1229  	UBaseType_t uxQueueGetQueueNumber( QueueHandle_t xQueue )
1230  	{
1231  		return ( ( Queue_t * ) xQueue )-&gt;uxQueueNumber;
1232  	}
1233  #endif &amp;bsol;* configUSE_TRACE_FACILITY */
1234  #if ( configUSE_TRACE_FACILITY == 1 )
1235  	void vQueueSetQueueNumber( QueueHandle_t xQueue, UBaseType_t uxQueueNumber )
1236  	{
1237  		( ( Queue_t * ) xQueue )-&gt;uxQueueNumber = uxQueueNumber;
1238  	}
1239  #endif &amp;bsol;* configUSE_TRACE_FACILITY */
1240  #if ( configUSE_TRACE_FACILITY == 1 )
1241  	uint8_t ucQueueGetQueueType( QueueHandle_t xQueue )
1242  	{
1243  		return ( ( Queue_t * ) xQueue )-&gt;ucQueueType;
1244  	}
1245  #endif &amp;bsol;* configUSE_TRACE_FACILITY */
1246  #if( configUSE_MUTEXES == 1 )
1247  	static UBaseType_t prvGetDisinheritPriorityAfterTimeout( const Queue_t * const pxQueue )
1248  	{
1249  	UBaseType_t uxHighestPriorityOfWaitingTasks;
1250  		if( listCURRENT_LIST_LENGTH( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) &gt; 0 )
1251  		{
1252  			uxHighestPriorityOfWaitingTasks = configMAX_PRIORITIES - listGET_ITEM_VALUE_OF_HEAD_ENTRY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) );
1253  		}
1254  		else
1255  		{
1256  			uxHighestPriorityOfWaitingTasks = tskIDLE_PRIORITY;
1257  		}
1258  		return uxHighestPriorityOfWaitingTasks;
1259  	}
1260  #endif &amp;bsol;* configUSE_MUTEXES */
1261  static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
1262  {
1263  BaseType_t xReturn = pdFALSE;
1264  UBaseType_t uxMessagesWaiting;
1265  	uxMessagesWaiting = pxQueue-&gt;uxMessagesWaiting;
1266  	if( pxQueue-&gt;uxItemSize == ( UBaseType_t ) 0 )
1267  	{
1268  		#if ( configUSE_MUTEXES == 1 )
1269  		{
1270  			if( pxQueue-&gt;uxQueueType == queueQUEUE_IS_MUTEX )
1271  			{
1272  				xReturn = xTaskPriorityDisinherit( ( void * ) pxQueue-&gt;pxMutexHolder );
1273  				pxQueue-&gt;pxMutexHolder = NULL;
1274  			}
1275  			else
1276  			{
1277  				mtCOVERAGE_TEST_MARKER();
1278  			}
1279  		}
1280  		#endif &amp;bsol;* configUSE_MUTEXES */
1281  	}
1282  	else if( xPosition == queueSEND_TO_BACK )
1283  	{
1284  		( void ) memcpy( ( void * ) pxQueue-&gt;pcWriteTo, pvItemToQueue, ( size_t ) pxQueue-&gt;uxItemSize ); &amp;bsol;*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a null pointer can only be passed to memcpy() if the copy size is 0. */
1285  		pxQueue-&gt;pcWriteTo += pxQueue-&gt;uxItemSize;
1286  		if( pxQueue-&gt;pcWriteTo &gt;= pxQueue-&gt;pcTail ) &amp;bsol;*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
1287  		{
1288  			pxQueue-&gt;pcWriteTo = pxQueue-&gt;pcHead;
1289  		}
1290  		else
1291  		{
1292  			mtCOVERAGE_TEST_MARKER();
1293  		}
1294  	}
1295  	else
1296  	{
1297  		( void ) memcpy( ( void * ) pxQueue-&gt;u.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue-&gt;uxItemSize ); &amp;bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
1298  		pxQueue-&gt;u.pcReadFrom -= pxQueue-&gt;uxItemSize;
1299  		if( pxQueue-&gt;u.pcReadFrom &lt; pxQueue-&gt;pcHead ) &amp;bsol;*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
1300  		{
1301  			pxQueue-&gt;u.pcReadFrom = ( pxQueue-&gt;pcTail - pxQueue-&gt;uxItemSize );
1302  		}
1303  		else
1304  		{
1305  			mtCOVERAGE_TEST_MARKER();
1306  		}
1307  		if( xPosition == queueOVERWRITE )
1308  		{
1309  			if( uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
1310  			{
1311  				--uxMessagesWaiting;
1312  			}
1313  			else
1314  			{
1315  				mtCOVERAGE_TEST_MARKER();
1316  			}
1317  		}
1318  		else
1319  		{
1320  			mtCOVERAGE_TEST_MARKER();
1321  		}
1322  	}
1323  	pxQueue-&gt;uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
1324  	return xReturn;
1325  }
1326  static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer )
1327  {
1328  	if( pxQueue-&gt;uxItemSize != ( UBaseType_t ) 0 )
1329  	{
1330  		pxQueue-&gt;u.pcReadFrom += pxQueue-&gt;uxItemSize;
1331  		if( pxQueue-&gt;u.pcReadFrom &gt;= pxQueue-&gt;pcTail ) &amp;bsol;*lint !e946 MISRA exception justified as use of the relational operator is the cleanest solutions. */
1332  		{
1333  			pxQueue-&gt;u.pcReadFrom = pxQueue-&gt;pcHead;
1334  		}
1335  		else
1336  		{
1337  			mtCOVERAGE_TEST_MARKER();
1338  		}
1339  		( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue-&gt;u.pcReadFrom, ( size_t ) pxQueue-&gt;uxItemSize ); &amp;bsol;*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports.  Also previous logic ensures a null pointer can only be passed to memcpy() when the count is 0. */
1340  	}
1341  }
1342  static void prvUnlockQueue( Queue_t * const pxQueue )
1343  {
1344  	taskENTER_CRITICAL();
1345  	{
1346  		int8_t cTxLock = pxQueue-&gt;cTxLock;
1347  		while( cTxLock &gt; queueLOCKED_UNMODIFIED )
1348  		{
1349  			#if ( configUSE_QUEUE_SETS == 1 )
1350  			{
1351  				if( pxQueue-&gt;pxQueueSetContainer != NULL )
1352  				{
1353  					if( prvNotifyQueueSetContainer( pxQueue, queueSEND_TO_BACK ) != pdFALSE )
1354  					{
1355  						vTaskMissedYield();
1356  					}
1357  					else
1358  					{
1359  						mtCOVERAGE_TEST_MARKER();
1360  					}
1361  				}
1362  				else
1363  				{
1364  					if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1365  					{
1366  						if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1367  						{
1368  							vTaskMissedYield();
1369  						}
1370  						else
1371  						{
1372  							mtCOVERAGE_TEST_MARKER();
1373  						}
1374  					}
1375  					else
1376  					{
1377  						break;
1378  					}
1379  				}
1380  			}
1381  			#else &amp;bsol;* configUSE_QUEUE_SETS */
1382  			{
1383  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1384  				{
1385  					if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1386  					{
1387  						vTaskMissedYield();
1388  					}
1389  					else
1390  					{
1391  						mtCOVERAGE_TEST_MARKER();
1392  					}
1393  				}
1394  				else
1395  				{
1396  					break;
1397  				}
1398  			}
1399  			#endif &amp;bsol;* configUSE_QUEUE_SETS */
1400  			--cTxLock;
1401  		}
1402  		pxQueue-&gt;cTxLock = queueUNLOCKED;
1403  	}
1404  	taskEXIT_CRITICAL();
1405  	taskENTER_CRITICAL();
1406  	{
1407  		int8_t cRxLock = pxQueue-&gt;cRxLock;
1408  		while( cRxLock &gt; queueLOCKED_UNMODIFIED )
1409  		{
1410  			if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
1411  			{
1412  				if( xTaskRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
1413  				{
1414  					vTaskMissedYield();
1415  				}
1416  				else
1417  				{
1418  					mtCOVERAGE_TEST_MARKER();
1419  				}
1420  				--cRxLock;
1421  			}
1422  			else
1423  			{
1424  				break;
1425  			}
1426  		}
1427  		pxQueue-&gt;cRxLock = queueUNLOCKED;
1428  	}
1429  	taskEXIT_CRITICAL();
1430  }
1431  static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue )
1432  {
1433  BaseType_t xReturn;
1434  	taskENTER_CRITICAL();
1435  	{
1436  		if( pxQueue-&gt;uxMessagesWaiting == ( UBaseType_t )  0 )
1437  		{
1438  			xReturn = pdTRUE;
1439  		}
1440  		else
1441  		{
1442  			xReturn = pdFALSE;
1443  		}
1444  	}
1445  	taskEXIT_CRITICAL();
1446  	return xReturn;
1447  }
1448  BaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue )
1449  {
1450  BaseType_t xReturn;
1451  	configASSERT( xQueue );
1452  	if( ( ( Queue_t * ) xQueue )-&gt;uxMessagesWaiting == ( UBaseType_t ) 0 )
1453  	{
1454  		xReturn = pdTRUE;
1455  	}
1456  	else
1457  	{
1458  		xReturn = pdFALSE;
1459  	}
1460  	return xReturn;
1461  } &amp;bsol;*lint !e818 xQueue could not be pointer to const because it is a typedef. */
1462  static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
1463  {
1464  BaseType_t xReturn;
1465  	taskENTER_CRITICAL();
1466  	{
1467  		if( pxQueue-&gt;uxMessagesWaiting == pxQueue-&gt;uxLength )
1468  		{
1469  			xReturn = pdTRUE;
1470  		}
1471  		else
1472  		{
1473  			xReturn = pdFALSE;
1474  		}
1475  	}
1476  	taskEXIT_CRITICAL();
1477  	return xReturn;
1478  }
1479  BaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )
1480  {
1481  BaseType_t xReturn;
1482  	configASSERT( xQueue );
1483  	if( ( ( Queue_t * ) xQueue )-&gt;uxMessagesWaiting == ( ( Queue_t * ) xQueue )-&gt;uxLength )
1484  	{
1485  		xReturn = pdTRUE;
1486  	}
1487  	else
1488  	{
1489  		xReturn = pdFALSE;
1490  	}
1491  	return xReturn;
1492  } &amp;bsol;*lint !e818 xQueue could not be pointer to const because it is a typedef. */
1493  #if ( configUSE_CO_ROUTINES == 1 )
1494  	BaseType_t xQueueCRSend( QueueHandle_t xQueue, const void *pvItemToQueue, TickType_t xTicksToWait )
1495  	{
1496  	BaseType_t xReturn;
1497  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1498  		portDISABLE_INTERRUPTS();
1499  		{
1500  			if( prvIsQueueFull( pxQueue ) != pdFALSE )
1501  			{
1502  				if( xTicksToWait &gt; ( TickType_t ) 0 )
1503  				{
1504  					vCoRoutineAddToDelayedList( xTicksToWait, &amp;( pxQueue-&gt;xTasksWaitingToSend ) );
1505  					portENABLE_INTERRUPTS();
1506  					return errQUEUE_BLOCKED;
1507  				}
1508  				else
1509  				{
1510  					portENABLE_INTERRUPTS();
1511  					return errQUEUE_FULL;
1512  				}
1513  			}
1514  		}
1515  		portENABLE_INTERRUPTS();
1516  		portDISABLE_INTERRUPTS();
1517  		{
1518  			if( pxQueue-&gt;uxMessagesWaiting &lt; pxQueue-&gt;uxLength )
1519  			{
1520  				prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
1521  				xReturn = pdPASS;
1522  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1523  				{
1524  					if( xCoRoutineRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1525  					{
1526  						xReturn = errQUEUE_YIELD;
1527  					}
1528  					else
1529  					{
1530  						mtCOVERAGE_TEST_MARKER();
1531  					}
1532  				}
1533  				else
1534  				{
1535  					mtCOVERAGE_TEST_MARKER();
1536  				}
1537  			}
1538  			else
1539  			{
1540  				xReturn = errQUEUE_FULL;
1541  			}
1542  		}
1543  		portENABLE_INTERRUPTS();
1544  		return xReturn;
1545  	}
1546  #endif &amp;bsol;* configUSE_CO_ROUTINES */
1547  #if ( configUSE_CO_ROUTINES == 1 )
1548  	BaseType_t xQueueCRReceive( QueueHandle_t xQueue, void *pvBuffer, TickType_t xTicksToWait )
1549  	{
1550  	BaseType_t xReturn;
1551  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1552  		portDISABLE_INTERRUPTS();
1553  		{
1554  			if( pxQueue-&gt;uxMessagesWaiting == ( UBaseType_t ) 0 )
1555  			{
1556  				if( xTicksToWait &gt; ( TickType_t ) 0 )
1557  				{
1558  					vCoRoutineAddToDelayedList( xTicksToWait, &amp;( pxQueue-&gt;xTasksWaitingToReceive ) );
1559  					portENABLE_INTERRUPTS();
1560  					return errQUEUE_BLOCKED;
1561  				}
1562  				else
1563  				{
1564  					portENABLE_INTERRUPTS();
1565  					return errQUEUE_FULL;
1566  				}
1567  			}
1568  			else
1569  			{
1570  				mtCOVERAGE_TEST_MARKER();
1571  			}
1572  		}
1573  		portENABLE_INTERRUPTS();
1574  		portDISABLE_INTERRUPTS();
1575  		{
1576  			if( pxQueue-&gt;uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
1577  			{
1578  				pxQueue-&gt;u.pcReadFrom += pxQueue-&gt;uxItemSize;
1579  				if( pxQueue-&gt;u.pcReadFrom &gt;= pxQueue-&gt;pcTail )
1580  				{
1581  					pxQueue-&gt;u.pcReadFrom = pxQueue-&gt;pcHead;
1582  				}
1583  				else
1584  				{
1585  					mtCOVERAGE_TEST_MARKER();
1586  				}
1587  				--( pxQueue-&gt;uxMessagesWaiting );
1588  				( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue-&gt;u.pcReadFrom, ( unsigned ) pxQueue-&gt;uxItemSize );
1589  				xReturn = pdPASS;
1590  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
1591  				{
1592  					if( xCoRoutineRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
1593  					{
1594  						xReturn = errQUEUE_YIELD;
1595  					}
1596  					else
1597  					{
1598  						mtCOVERAGE_TEST_MARKER();
1599  					}
1600  				}
1601  				else
1602  				{
1603  					mtCOVERAGE_TEST_MARKER();
1604  				}
1605  			}
1606  			else
1607  			{
1608  				xReturn = pdFAIL;
1609  			}
1610  		}
1611  		portENABLE_INTERRUPTS();
1612  		return xReturn;
1613  	}
1614  #endif &amp;bsol;* configUSE_CO_ROUTINES */
1615  #if ( configUSE_CO_ROUTINES == 1 )
1616  	BaseType_t xQueueCRSendFromISR( QueueHandle_t xQueue, const void *pvItemToQueue, BaseType_t xCoRoutinePreviouslyWoken )
1617  	{
1618  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
<span onclick='openModal()' class='match'>1619  		if( pxQueue-&gt;uxMessagesWaiting &lt; pxQueue-&gt;uxLength )
1620  		{
1621  			prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
1622  			if( xCoRoutinePreviouslyWoken == pdFALSE )
</span>1623  			{
1624  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1625  				{
1626  					if( xCoRoutineRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1627  					{
1628  						return pdTRUE;
1629  					}
1630  					else
1631  					{
1632  						mtCOVERAGE_TEST_MARKER();
1633  					}
1634  				}
1635  				else
1636  				{
1637  					mtCOVERAGE_TEST_MARKER();
1638  				}
1639  			}
1640  			else
1641  			{
1642  				mtCOVERAGE_TEST_MARKER();
1643  			}
1644  		}
1645  		else
1646  		{
1647  			mtCOVERAGE_TEST_MARKER();
1648  		}
1649  		return xCoRoutinePreviouslyWoken;
1650  	}
1651  #endif &amp;bsol;* configUSE_CO_ROUTINES */
1652  #if ( configUSE_CO_ROUTINES == 1 )
1653  	BaseType_t xQueueCRReceiveFromISR( QueueHandle_t xQueue, void *pvBuffer, BaseType_t *pxCoRoutineWoken )
1654  	{
1655  	BaseType_t xReturn;
1656  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1657  		if( pxQueue-&gt;uxMessagesWaiting &gt; ( UBaseType_t ) 0 )
1658  		{
1659  			pxQueue-&gt;u.pcReadFrom += pxQueue-&gt;uxItemSize;
1660  			if( pxQueue-&gt;u.pcReadFrom &gt;= pxQueue-&gt;pcTail )
1661  			{
1662  				pxQueue-&gt;u.pcReadFrom = pxQueue-&gt;pcHead;
1663  			}
1664  			else
1665  			{
1666  				mtCOVERAGE_TEST_MARKER();
1667  			}
1668  			--( pxQueue-&gt;uxMessagesWaiting );
1669  			( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue-&gt;u.pcReadFrom, ( unsigned ) pxQueue-&gt;uxItemSize );
1670  			if( ( *pxCoRoutineWoken ) == pdFALSE )
1671  			{
1672  				if( listLIST_IS_EMPTY( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) == pdFALSE )
1673  				{
1674  					if( xCoRoutineRemoveFromEventList( &amp;( pxQueue-&gt;xTasksWaitingToSend ) ) != pdFALSE )
1675  					{
1676  						*pxCoRoutineWoken = pdTRUE;
1677  					}
1678  					else
1679  					{
1680  						mtCOVERAGE_TEST_MARKER();
1681  					}
1682  				}
1683  				else
1684  				{
1685  					mtCOVERAGE_TEST_MARKER();
1686  				}
1687  			}
1688  			else
1689  			{
1690  				mtCOVERAGE_TEST_MARKER();
1691  			}
1692  			xReturn = pdPASS;
1693  		}
1694  		else
1695  		{
1696  			xReturn = pdFAIL;
1697  		}
1698  		return xReturn;
1699  	}
1700  #endif &amp;bsol;* configUSE_CO_ROUTINES */
1701  #if ( configQUEUE_REGISTRY_SIZE &gt; 0 )
1702  	void vQueueAddToRegistry( QueueHandle_t xQueue, const char *pcQueueName ) &amp;bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1703  	{
1704  	UBaseType_t ux;
1705  		for( ux = ( UBaseType_t ) 0U; ux &lt; ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
1706  		{
1707  			if( xQueueRegistry[ ux ].pcQueueName == NULL )
1708  			{
1709  				xQueueRegistry[ ux ].pcQueueName = pcQueueName;
1710  				xQueueRegistry[ ux ].xHandle = xQueue;
1711  				traceQUEUE_REGISTRY_ADD( xQueue, pcQueueName );
1712  				break;
1713  			}
1714  			else
1715  			{
1716  				mtCOVERAGE_TEST_MARKER();
1717  			}
1718  		}
1719  	}
1720  #endif &amp;bsol;* configQUEUE_REGISTRY_SIZE */
1721  #if ( configQUEUE_REGISTRY_SIZE &gt; 0 )
1722  	const char *pcQueueGetName( QueueHandle_t xQueue ) &amp;bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1723  	{
1724  	UBaseType_t ux;
1725  	const char *pcReturn = NULL; &amp;bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1726  		for( ux = ( UBaseType_t ) 0U; ux &lt; ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
1727  		{
1728  			if( xQueueRegistry[ ux ].xHandle == xQueue )
1729  			{
1730  				pcReturn = xQueueRegistry[ ux ].pcQueueName;
1731  				break;
1732  			}
1733  			else
1734  			{
1735  				mtCOVERAGE_TEST_MARKER();
1736  			}
1737  		}
1738  		return pcReturn;
1739  	} &amp;bsol;*lint !e818 xQueue cannot be a pointer to const because it is a typedef. */
1740  #endif &amp;bsol;* configQUEUE_REGISTRY_SIZE */
1741  #if ( configQUEUE_REGISTRY_SIZE &gt; 0 )
1742  	void vQueueUnregisterQueue( QueueHandle_t xQueue )
1743  	{
1744  	UBaseType_t ux;
1745  		for( ux = ( UBaseType_t ) 0U; ux &lt; ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
1746  		{
1747  			if( xQueueRegistry[ ux ].xHandle == xQueue )
1748  			{
1749  				xQueueRegistry[ ux ].pcQueueName = NULL;
1750  				xQueueRegistry[ ux ].xHandle = ( QueueHandle_t ) 0;
1751  				break;
1752  			}
1753  			else
1754  			{
1755  				mtCOVERAGE_TEST_MARKER();
1756  			}
1757  		}
1758  	} &amp;bsol;*lint !e818 xQueue could not be pointer to const because it is a typedef. */
1759  #endif &amp;bsol;* configQUEUE_REGISTRY_SIZE */
1760  #if ( configUSE_TIMERS == 1 )
1761  	void vQueueWaitForMessageRestricted( QueueHandle_t xQueue, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely )
1762  	{
1763  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1764  		prvLockQueue( pxQueue );
1765  		if( pxQueue-&gt;uxMessagesWaiting == ( UBaseType_t ) 0U )
1766  		{
1767  			vTaskPlaceOnEventListRestricted( &amp;( pxQueue-&gt;xTasksWaitingToReceive ), xTicksToWait, xWaitIndefinitely );
1768  		}
1769  		else
1770  		{
1771  			mtCOVERAGE_TEST_MARKER();
1772  		}
1773  		prvUnlockQueue( pxQueue );
1774  	}
1775  #endif &amp;bsol;* configUSE_TIMERS */
1776  #if( ( configUSE_QUEUE_SETS == 1 ) &amp;&amp; ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
1777  	QueueSetHandle_t xQueueCreateSet( const UBaseType_t uxEventQueueLength )
1778  	{
1779  	QueueSetHandle_t pxQueue;
1780  		pxQueue = xQueueGenericCreate( uxEventQueueLength, ( UBaseType_t ) sizeof( Queue_t * ), queueQUEUE_TYPE_SET );
1781  		return pxQueue;
1782  	}
1783  #endif &amp;bsol;* configUSE_QUEUE_SETS */
1784  #if ( configUSE_QUEUE_SETS == 1 )
1785  	BaseType_t xQueueAddToSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet )
1786  	{
1787  	BaseType_t xReturn;
1788  		taskENTER_CRITICAL();
1789  		{
1790  			if( ( ( Queue_t * ) xQueueOrSemaphore )-&gt;pxQueueSetContainer != NULL )
1791  			{
1792  				xReturn = pdFAIL;
1793  			}
1794  			else if( ( ( Queue_t * ) xQueueOrSemaphore )-&gt;uxMessagesWaiting != ( UBaseType_t ) 0 )
1795  			{
1796  				xReturn = pdFAIL;
1797  			}
1798  			else
1799  			{
1800  				( ( Queue_t * ) xQueueOrSemaphore )-&gt;pxQueueSetContainer = xQueueSet;
1801  				xReturn = pdPASS;
1802  			}
1803  		}
1804  		taskEXIT_CRITICAL();
1805  		return xReturn;
1806  	}
1807  #endif &amp;bsol;* configUSE_QUEUE_SETS */
1808  #if ( configUSE_QUEUE_SETS == 1 )
1809  	BaseType_t xQueueRemoveFromSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet )
1810  	{
1811  	BaseType_t xReturn;
1812  	Queue_t * const pxQueueOrSemaphore = ( Queue_t * ) xQueueOrSemaphore;
1813  		if( pxQueueOrSemaphore-&gt;pxQueueSetContainer != xQueueSet )
1814  		{
1815  			xReturn = pdFAIL;
1816  		}
1817  		else if( pxQueueOrSemaphore-&gt;uxMessagesWaiting != ( UBaseType_t ) 0 )
1818  		{
1819  			xReturn = pdFAIL;
1820  		}
1821  		else
1822  		{
1823  			taskENTER_CRITICAL();
1824  			{
1825  				pxQueueOrSemaphore-&gt;pxQueueSetContainer = NULL;
1826  			}
1827  			taskEXIT_CRITICAL();
1828  			xReturn = pdPASS;
1829  		}
1830  		return xReturn;
1831  	} &amp;bsol;*lint !e818 xQueueSet could not be declared as pointing to const as it is a typedef. */
1832  #endif &amp;bsol;* configUSE_QUEUE_SETS */
1833  #if ( configUSE_QUEUE_SETS == 1 )
1834  	QueueSetMemberHandle_t xQueueSelectFromSet( QueueSetHandle_t xQueueSet, TickType_t const xTicksToWait )
1835  	{
1836  	QueueSetMemberHandle_t xReturn = NULL;
1837  		( void ) xQueueReceive( ( QueueHandle_t ) xQueueSet, &amp;xReturn, xTicksToWait ); &amp;bsol;*lint !e961 Casting from one typedef to another is not redundant. */
1838  		return xReturn;
1839  	}
1840  #endif &amp;bsol;* configUSE_QUEUE_SETS */
1841  #if ( configUSE_QUEUE_SETS == 1 )
1842  	QueueSetMemberHandle_t xQueueSelectFromSetFromISR( QueueSetHandle_t xQueueSet )
1843  	{
1844  	QueueSetMemberHandle_t xReturn = NULL;
1845  		( void ) xQueueReceiveFromISR( ( QueueHandle_t ) xQueueSet, &amp;xReturn, NULL ); &amp;bsol;*lint !e961 Casting from one typedef to another is not redundant. */
1846  		return xReturn;
1847  	}
1848  #endif &amp;bsol;* configUSE_QUEUE_SETS */
1849  #if ( configUSE_QUEUE_SETS == 1 )
1850  	static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue, const BaseType_t xCopyPosition )
1851  	{
1852  	Queue_t *pxQueueSetContainer = pxQueue-&gt;pxQueueSetContainer;
1853  	BaseType_t xReturn = pdFALSE;
1854  		configASSERT( pxQueueSetContainer );
1855  		configASSERT( pxQueueSetContainer-&gt;uxMessagesWaiting &lt; pxQueueSetContainer-&gt;uxLength );
1856  		if( pxQueueSetContainer-&gt;uxMessagesWaiting &lt; pxQueueSetContainer-&gt;uxLength )
1857  		{
1858  			const int8_t cTxLock = pxQueueSetContainer-&gt;cTxLock;
1859  			traceQUEUE_SEND( pxQueueSetContainer );
1860  			xReturn = prvCopyDataToQueue( pxQueueSetContainer, &amp;pxQueue, xCopyPosition );
1861  			if( cTxLock == queueUNLOCKED )
1862  			{
1863  				if( listLIST_IS_EMPTY( &amp;( pxQueueSetContainer-&gt;xTasksWaitingToReceive ) ) == pdFALSE )
1864  				{
1865  					if( xTaskRemoveFromEventList( &amp;( pxQueueSetContainer-&gt;xTasksWaitingToReceive ) ) != pdFALSE )
1866  					{
1867  						xReturn = pdTRUE;
1868  					}
1869  					else
1870  					{
1871  						mtCOVERAGE_TEST_MARKER();
1872  					}
1873  				}
1874  				else
1875  				{
1876  					mtCOVERAGE_TEST_MARKER();
1877  				}
1878  			}
1879  			else
1880  			{
1881  				pxQueueSetContainer-&gt;cTxLock = ( int8_t ) ( cTxLock + 1 );
1882  			}
1883  		}
1884  		else
1885  		{
1886  			mtCOVERAGE_TEST_MARKER();
1887  		}
1888  		return xReturn;
1889  	}
1890  #endif &amp;bsol;* configUSE_QUEUE_SETS */
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from Adafruit_nRF52_Arduino-MDEwOlJlcG9zaXRvcnk3NDM1NDcyOQ==-flat-queue.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from Adafruit_nRF52_Arduino-MDEwOlJlcG9zaXRvcnk3NDM1NDcyOQ==-flat-queue.c</div>
                </div>
                <div class="column column_space"><pre><code>1518  			if( pxQueue-&gt;uxMessagesWaiting &lt; pxQueue-&gt;uxLength )
1519  			{
1520  				prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
1521  				xReturn = pdPASS;
</pre></code></div>
                <div class="column column_space"><pre><code>1619  		if( pxQueue-&gt;uxMessagesWaiting &lt; pxQueue-&gt;uxLength )
1620  		{
1621  			prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
1622  			if( xCoRoutinePreviouslyWoken == pdFALSE )
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    