<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for imkafka.c & mmdarwin.c</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for imkafka.c & mmdarwin.c
      </h3>
      <h1 align="center">
        11.0%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>imkafka.c (11.147012%)<TH>mmdarwin.c (10.900474%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match754-0.html#0',2,'match754-1.html#0',3)" NAME="0">(128-150)<TD><A HREF="javascript:ZweiFrames('match754-0.html#0',2,'match754-1.html#0',3)" NAME="0">(105-126)</A><TD ALIGN=center><FONT COLOR="#ff0000">37</FONT>
<TR><TD BGCOLOR="#f63526"><FONT COLOR="#f63526">-</FONT><TD><A HREF="javascript:ZweiFrames('match754-0.html#1',2,'match754-1.html#1',3)" NAME="1">(615-631)<TD><A HREF="javascript:ZweiFrames('match754-0.html#1',2,'match754-1.html#1',3)" NAME="1">(590-609)</A><TD ALIGN=center><FONT COLOR="#820000">19</FONT>
<TR><TD BGCOLOR="#980517"><FONT COLOR="#980517">-</FONT><TD><A HREF="javascript:ZweiFrames('match754-0.html#2',2,'match754-1.html#2',3)" NAME="2">(521-538)<TD><A HREF="javascript:ZweiFrames('match754-0.html#2',2,'match754-1.html#2',3)" NAME="2">(641-655)</A><TD ALIGN=center><FONT COLOR="#590000">13</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>imkafka.c</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/* imkafka.c
 *
 * This input plugin is a consumer for Apache Kafka.
 *
 * File begun on 2017-04-25 by alorbach
 *
 * Copyright 2008-2017 Adiscon GmbH.
 *
 * This file is part of rsyslog.
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *       http://www.apache.org/licenses/LICENSE-2.0
 *       -or-
 *       see COPYING.ASL20 in the source distribution
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#include &quot;config.h&quot;
#include &lt;stdio.h&gt;
#include &lt;stdarg.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;assert.h&gt;
#include &lt;errno.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;pthread.h&gt;
#include &lt;sys/uio.h&gt;
#include &lt;librdkafka/rdkafka.h&gt;

#include &quot;rsyslog.h&quot;
#include &quot;conf.h&quot;
#include &quot;syslogd-types.h&quot;
#include &quot;srUtils.h&quot;
#include &quot;template.h&quot;
#include &quot;module-template.h&quot;
#include &quot;errmsg.h&quot;
#include &quot;atomic.h&quot;
#include &quot;statsobj.h&quot;
#include &quot;unicode-helper.h&quot;
#include &quot;prop.h&quot;
#include &quot;ruleset.h&quot;
#include &quot;glbl.h&quot;
#include &quot;cfsysline.h&quot;
#include &quot;msg.h&quot;
#include &quot;dirty.h&quot;

MODULE_TYPE_INPUT
MODULE_TYPE_NOKEEP
MODULE_CNFNAME(&quot;imkafka&quot;)

/* static data */
DEF_IMOD_STATIC_DATA
DEFobjCurrIf(prop)
DEFobjCurrIf(ruleset)
DEFobjCurrIf(glbl)
DEFobjCurrIf(statsobj)

/* forward references */
static void * imkafkawrkr(void *myself);


struct kafka_params {
	const char *name;
	const char *val;
};

/* Module static data */
static struct configSettings_s {
	uchar *topic;
	uchar *consumergroup;
	char *brokers;
	uchar *pszBindRuleset;
	int nConfParams;
	struct kafka_params *confParams;
} cs;

struct instanceConf_s {
	uchar *topic;
	uchar *consumergroup;
	char *brokers;
	int64_t offset;
	ruleset_t *pBindRuleset;	/* ruleset to bind listener to (use system default if unspecified) */
	uchar *pszBindRuleset;		/* default name of Ruleset to bind to */
	int bReportErrs;
	int nConfParams;
	struct kafka_params *confParams;
	int bIsConnected;
	rd_kafka_conf_t *conf;
	rd_kafka_t *rk;
	rd_kafka_topic_conf_t *topic_conf;
	int partition;
	int bIsSubscribed;
	int nMsgParsingFlags;

	struct instanceConf_s *next;
};


struct modConfData_s {
	rsconf_t *pConf;		/* our overall config object */
	uchar *topic;
	uchar *consumergroup;
	char *brokers;
	instanceConf_t *root, *tail;
	ruleset_t *pBindRuleset;	/* ruleset to bind listener to (use system default if unspecified) */
	uchar *pszBindRuleset;		/* default name of Ruleset to bind to */
};

/* global data */
pthread_attr_t wrkrThrdAttr;	/* Attribute for worker threads ; read only after startup */
static int activeKafkaworkers = 0;
/* The following structure controls the worker threads. Global data is
 * needed for their access.
 */
static struct kafkaWrkrInfo_s {
	pthread_t tid;		/* the worker's thread ID */
	instanceConf_t *inst;	/* Pointer to imkafka instance */
<A NAME="0"></A>} *kafkaWrkrInfo;

static modConfData_t *loadModConf = NULL;/* modConf ptr to use for the current load process */
<FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match754-1.html#0',3,'match754-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>static modConfData_t *runModConf = NULL;/* modConf ptr to use for the current load process */

static prop_t *pInputName = NULL;
/* there is only one global inputName for all messages generated by this input */

/* module-global parameters */
static struct cnfparamdescr modpdescr[] = {
	{ &quot;ruleset&quot;, eCmdHdlrGetWord, 0 },
};
static struct cnfparamblk modpblk =
	{ CNFPARAMBLK_VERSION,
	  sizeof(modpdescr)/sizeof(struct cnfparamdescr),
	  modpdescr
	};

/* input instance parameters */
static struct cnfparamdescr inppdescr[] = {
	{ &quot;topic&quot;, eCmdHdlrString, CNFPARAM_REQUIRED },
	{ &quot;broker&quot;, eCmdHdlrArray, 0 },
	{ &quot;confparam&quot;, eCmdHdlrArray, 0 },
	{ &quot;consumergroup&quot;, eCmdHdlrString, 0},
	{ &quot;ruleset&quot;, eCmdHdlrString, 0 },
	{ &quot;parsehostname&quot;, eCmdHdlrBinary, 0 },</B></FONT>
};
static struct cnfparamblk inppblk =
	{ CNFPARAMBLK_VERSION,
	  sizeof(inppdescr)/sizeof(struct cnfparamdescr),
	  inppdescr
	};

#include &quot;im-helper.h&quot; /* must be included AFTER the type definitions! */

/* ------------------------------ callbacks ------------------------------ */




/* ------------------------------ end callbacks ------------------------------ */

static void
kafkaLogger(const rd_kafka_t __attribute__((unused)) *rk, int level,
	    const char *fac, const char *buf)
{
	DBGPRINTF(&quot;imkafka: kafka log message [%d,%s]: %s\n&quot;,
		  level, fac, buf);
}


/* enqueue the kafka message. The provided string is
 * not freed - thuis must be done by the caller.
 */
static rsRetVal enqMsg(instanceConf_t *const __restrict__ inst,
			rd_kafka_message_t *const __restrict__ rkmessage)
{
	DEFiRet;
	smsg_t *pMsg;

	if((int)rkmessage-&gt;len == 0) {
		/* we do not process empty lines */
		FINALIZE;
	}

DBGPRINTF(&quot;imkafka: enqMsg: Msg: %.*s\n&quot;, (int)rkmessage-&gt;len, (char *)rkmessage-&gt;payload);

	CHKiRet(msgConstruct(&amp;pMsg));
	MsgSetInputName(pMsg, pInputName);
	MsgSetRawMsg(pMsg, (char*)rkmessage-&gt;payload, (int)rkmessage-&gt;len);
	MsgSetFlowControlType(pMsg, eFLOWCTL_LIGHT_DELAY);
	MsgSetRuleset(pMsg, inst-&gt;pBindRuleset);
	pMsg-&gt;msgFlags  = inst-&gt;nMsgParsingFlags;
	/* Optional Fields */
	if (rkmessage-&gt;key_len) {
		DBGPRINTF(&quot;imkafka: enqMsg: Key: %.*s\n&quot;, (int)rkmessage-&gt;key_len, (char *)rkmessage-&gt;key);
		MsgSetTAG(pMsg, (const uchar *)rkmessage-&gt;key, (int)rkmessage-&gt;key_len);
	}
	MsgSetMSGoffs(pMsg, 0);	/* we do not have a header... */

	CHKiRet(submitMsg2(pMsg));

finalize_it:
	RETiRet;
}

/**
 * Handle Kafka Consumer Loop until all msgs are processed
 */
static void msgConsume (instanceConf_t *inst) {
	rd_kafka_message_t *rkmessage = NULL;

	do { /* Consume messages */
		rkmessage = rd_kafka_consumer_poll(inst-&gt;rk, 1000); /* Block for 1000 ms max */
		if(rkmessage == NULL) {
			DBGPRINTF(&quot;imkafka: msgConsume EMPTY Loop on %s/%s/%s\n&quot;,
				inst-&gt;topic, inst-&gt;consumergroup, inst-&gt;brokers);
			goto done;
		}

		if (rkmessage-&gt;err) {
			if (rkmessage-&gt;err == RD_KAFKA_RESP_ERR__PARTITION_EOF) {
				/* not an error, just a regular status! */
				DBGPRINTF(&quot;imkafka: Consumer &quot;
					&quot;reached end of topic \&quot;%s\&quot; [%&quot;PRId32&quot;]&quot;
					&quot;message queue offset %&quot;PRId64&quot;\n&quot;,
					rd_kafka_topic_name(rkmessage-&gt;rkt),
					rkmessage-&gt;partition,
					rkmessage-&gt;offset);
				goto done;
			}
			if (rkmessage-&gt;rkt) {
				LogError(0, RS_RET_KAFKA_ERROR,
				&quot;imkafka: Consumer error for topic \&quot;%s\&quot; [%&quot;PRId32&quot;]&quot;
				&quot;message queue offset %&quot;PRId64&quot;: %s\n&quot;,
					rd_kafka_topic_name(rkmessage-&gt;rkt),
					rkmessage-&gt;partition,
					rkmessage-&gt;offset,
					rd_kafka_message_errstr(rkmessage));
			} else {
				LogError(0, RS_RET_KAFKA_ERROR,
					&quot;imkafka: Consumer error for topic \&quot;%s\&quot;: \&quot;%s\&quot;\n&quot;,
					rd_kafka_err2str(rkmessage-&gt;err),
					rd_kafka_message_errstr(rkmessage));
			}
			goto done;
		}

		DBGPRINTF(&quot;imkafka: msgConsume Loop on %s/%s/%s: [%&quot;PRId32&quot;], &quot;
					&quot;offset %&quot;PRId64&quot;, %zd bytes):\n&quot;,
					rd_kafka_topic_name(rkmessage-&gt;rkt) /*inst-&gt;topic*/,
					inst-&gt;consumergroup,
					inst-&gt;brokers,
					rkmessage-&gt;partition,
					rkmessage-&gt;offset,
					rkmessage-&gt;len);
		enqMsg(inst, rkmessage);
		/* Destroy message and continue */
		rd_kafka_message_destroy(rkmessage);
		rkmessage = NULL;
	} while(1); /* loop broken inside */
done:
	/* Destroy message in case rkmessage-&gt;err was set */
	if(rkmessage != NULL) {
		rd_kafka_message_destroy(rkmessage);
	}
	return;
}



/* create input instance, set default parameters, and
 * add it to the list of instances.
 */
static rsRetVal
createInstance(instanceConf_t **pinst)
{
	instanceConf_t *inst;
	DEFiRet;
	CHKmalloc(inst = malloc(sizeof(instanceConf_t)));
	inst-&gt;next = NULL;

	inst-&gt;brokers = NULL;
	inst-&gt;topic = NULL;
	inst-&gt;consumergroup = NULL;
	inst-&gt;pszBindRuleset = NULL;
	inst-&gt;nConfParams = 0;
	inst-&gt;confParams = NULL;
	inst-&gt;pBindRuleset = NULL;
	inst-&gt;bReportErrs = 1; /* Fixed for now */
	inst-&gt;nMsgParsingFlags = NEEDS_PARSING;
	inst-&gt;bIsConnected = 0;
	inst-&gt;bIsSubscribed = 0;
	/* Kafka objects */
	inst-&gt;conf = NULL;
	inst-&gt;rk = NULL;
	inst-&gt;topic_conf = NULL;
	inst-&gt;partition = RD_KAFKA_PARTITION_UA;

	/* node created, let's add to config */
	if(loadModConf-&gt;tail == NULL) {
		loadModConf-&gt;tail = loadModConf-&gt;root = inst;
	} else {
		loadModConf-&gt;tail-&gt;next = inst;
		loadModConf-&gt;tail = inst;
	}

	*pinst = inst;
finalize_it:
	RETiRet;
}

/* this function checks instance parameters and does some required pre-processing
 */
static rsRetVal ATTR_NONNULL()
checkInstance(instanceConf_t *const inst)
{
	DEFiRet;
	char kafkaErrMsg[1024];

	/* main kafka conf */
	inst-&gt;conf = rd_kafka_conf_new();
	if(inst-&gt;conf == NULL) {
		if(inst-&gt;bReportErrs) {
			LogError(0, RS_RET_KAFKA_ERROR,
				&quot;imkafka: error creating kafka conf obj: %s\n&quot;,
				rd_kafka_err2str(rd_kafka_last_error()));
		}
		ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
	}

#	ifdef DEBUG
	/* enable kafka debug output */
	if(rd_kafka_conf_set(inst-&gt;conf, &quot;debug&quot;, RD_KAFKA_DEBUG_CONTEXTS,
		kafkaErrMsg, sizeof(kafkaErrMsg)) != RD_KAFKA_CONF_OK) {
		LogError(0, RS_RET_KAFKA_ERROR, &quot;imkafka: error setting kafka debug option: %s\n&quot;, kafkaErrMsg);
		/* DO NOT ABORT IN THIS CASE! */
	}
#	endif

	/* Set custom configuration parameters */
	for(int i = 0 ; i &lt; inst-&gt;nConfParams ; ++i) {
		assert(inst-&gt;confParams+i != NULL); /* invariant: nConfParams MUST exist! */
		DBGPRINTF(&quot;imkafka: setting custom configuration parameter: %s:%s\n&quot;,
			inst-&gt;confParams[i].name,
			inst-&gt;confParams[i].val);
		if(rd_kafka_conf_set(inst-&gt;conf,
			inst-&gt;confParams[i].name,
			inst-&gt;confParams[i].val,
			kafkaErrMsg, sizeof(kafkaErrMsg)) != RD_KAFKA_CONF_OK) {
			if(inst-&gt;bReportErrs) {
				LogError(0, RS_RET_PARAM_ERROR, &quot;error setting custom configuration &quot;
					&quot;parameter '%s=%s': %s&quot;,
					inst-&gt;confParams[i].name,
					inst-&gt;confParams[i].val, kafkaErrMsg);
			} else {
				DBGPRINTF(&quot;imkafka: error setting custom configuration parameter '%s=%s': %s&quot;,
					inst-&gt;confParams[i].name,
					inst-&gt;confParams[i].val, kafkaErrMsg);
			}
			ABORT_FINALIZE(RS_RET_PARAM_ERROR);
		}
	}

	/* Topic configuration */
	inst-&gt;topic_conf = rd_kafka_topic_conf_new();

	/* Assign kafka group id */
	if (inst-&gt;consumergroup != NULL) {
		DBGPRINTF(&quot;imkafka: setting consumergroup: '%s'\n&quot;, inst-&gt;consumergroup);
		if (rd_kafka_conf_set(inst-&gt;conf, &quot;group.id&quot;, (char*) inst-&gt;consumergroup,
			kafkaErrMsg, sizeof(kafkaErrMsg)) != RD_KAFKA_CONF_OK) {
			if(inst-&gt;bReportErrs) {
				LogError(0, RS_RET_KAFKA_ERROR,
					&quot;imkafka: error assigning consumergroup %s to &quot;
					&quot;kafka config: %s\n&quot;, inst-&gt;consumergroup,
					kafkaErrMsg);
			}
			ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
		}


		/* Set default for auto offset reset */
		if (rd_kafka_topic_conf_set(inst-&gt;topic_conf, &quot;auto.offset.reset&quot;,
			&quot;smallest&quot;, kafkaErrMsg, sizeof(kafkaErrMsg)) != RD_KAFKA_CONF_OK) {
			if(inst-&gt;bReportErrs) {
				LogError(0, RS_RET_KAFKA_ERROR,
					&quot;imkafka: error setting kafka auto.offset.reset on %s: %s\n&quot;,
					inst-&gt;consumergroup,
					kafkaErrMsg);
			}
			ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
		}
		/* Consumer groups always use broker based offset storage */
		if (rd_kafka_topic_conf_set(inst-&gt;topic_conf, &quot;offset.store.method&quot;,
			&quot;broker&quot;, kafkaErrMsg, sizeof(kafkaErrMsg)) != RD_KAFKA_CONF_OK) {
			if(inst-&gt;bReportErrs) {
				LogError(0, RS_RET_KAFKA_ERROR,
					&quot;imkafka: error setting kafka offset.store.method on %s: %s\n&quot;,
					inst-&gt;consumergroup,
					kafkaErrMsg);
			}
			ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
		}

		/* Set default topic config for pattern-matched topics. */
		rd_kafka_conf_set_default_topic_conf(inst-&gt;conf, inst-&gt;topic_conf);
	}

	#if RD_KAFKA_VERSION &gt;= 0x00090001
		rd_kafka_conf_set_log_cb(inst-&gt;conf, kafkaLogger);
	#endif

	/* Create Kafka Consumer */
	inst-&gt;rk = rd_kafka_new(RD_KAFKA_CONSUMER, inst-&gt;conf,
				     kafkaErrMsg, sizeof(kafkaErrMsg));
	if(inst-&gt;rk == NULL) {
		if(inst-&gt;bReportErrs) {
			LogError(0, RS_RET_KAFKA_ERROR,
				&quot;imkafka: error creating kafka handle: %s\n&quot;, kafkaErrMsg);
		}
		ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
	}
	#if RD_KAFKA_VERSION &lt; 0x00090001
		rd_kafka_set_logger(inst-&gt;rk, kafkaLogger);
	#endif

	DBGPRINTF(&quot;imkafka: setting brokers: '%s'\n&quot;, inst-&gt;brokers);
	if(rd_kafka_brokers_add(inst-&gt;rk, (char*)inst-&gt;brokers) == 0) {
		if(inst-&gt;bReportErrs) {
			LogError(0, RS_RET_KAFKA_NO_VALID_BROKERS,
				&quot;imkafka: no valid brokers specified: %s&quot;, inst-&gt;brokers);
		}
		ABORT_FINALIZE(RS_RET_KAFKA_NO_VALID_BROKERS);
	}

	/* Kafka Consumer is opened */
	inst-&gt;bIsConnected = 1;

finalize_it:
	if(iRet != RS_RET_OK) {
		if(inst-&gt;rk == NULL) {
			if(inst-&gt;conf != NULL) {
				rd_kafka_conf_destroy(inst-&gt;conf);
				inst-&gt;conf = NULL;
			}
		} else { /* inst-&gt;rk != NULL ! */
			rd_kafka_destroy(inst-&gt;rk);
			inst-&gt;rk = NULL;
		}
	}

	RETiRet;
}

/* function to generate an error message if the ruleset cannot be found */
static inline void
std_checkRuleset_genErrMsg(__attribute__((unused)) modConfData_t *modConf, instanceConf_t *inst)
{
	if(inst-&gt;bReportErrs) {
		LogError(0, NO_ERRCODE, &quot;imkafka: ruleset '%s' not found - &quot;
			&quot;using default ruleset instead&quot;,
			inst-&gt;pszBindRuleset);
	}
}


static rsRetVal ATTR_NONNULL(2)
addConsumer(modConfData_t __attribute__((unused)) *modConf, instanceConf_t *inst)
{
	DEFiRet;
	rd_kafka_resp_err_t err;

	assert(inst != NULL);

	rd_kafka_topic_partition_list_t *topics = NULL;
	DBGPRINTF(&quot;imkafka: creating kafka consumer on %s/%s/%s\n&quot;,
		inst-&gt;topic, inst-&gt;consumergroup, inst-&gt;brokers);

	/* Redirect rd_kafka_poll() to consumer_poll() */
	rd_kafka_poll_set_consumer(inst-&gt;rk);

	topics = rd_kafka_topic_partition_list_new(1);
	rd_kafka_topic_partition_list_add(topics, (const char*)inst-&gt;topic, inst-&gt;partition);
	DBGPRINTF(&quot;imkafka: Created topics(%d) for %s)\n&quot;,
		topics-&gt;cnt, inst-&gt;topic);
	if ((err = rd_kafka_subscribe(inst-&gt;rk, topics))) {
		/* Subscription failed */
		inst-&gt;bIsSubscribed = 0;
		LogError(0, RS_RET_KAFKA_ERROR, &quot;imkafka: Failed to start consuming &quot;
			&quot;topics: %s\n&quot;, rd_kafka_err2str(err));
		ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
	} else {
		DBGPRINTF(&quot;imkafka: Successfully subscribed to %s/%s/%s\n&quot;,
			inst-&gt;topic, inst-&gt;consumergroup, inst-&gt;brokers);
		/* Subscription is working */
		inst-&gt;bIsSubscribed = 1;
	}
finalize_it:
	if(topics != NULL)
		rd_kafka_topic_partition_list_destroy(topics);
	RETiRet;
}

static rsRetVal ATTR_NONNULL()
processKafkaParam(char *const param,
	const char **const name,
	const char **const paramval)
{
	DEFiRet;
	char *val = strstr(param, &quot;=&quot;);
	if(val == NULL) {
		LogError(0, RS_RET_PARAM_ERROR, &quot;missing equal sign in &quot;
<A NAME="2"></A>				&quot;parameter '%s'&quot;, param);
		ABORT_FINALIZE(RS_RET_PARAM_ERROR);
	}
<FONT color="#980517"><A HREF="javascript:ZweiFrames('match754-1.html#2',3,'match754-top.html#2',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>	*val = '\0'; /* terminates name */
	++val; /* now points to begin of value */
	CHKmalloc(*name = strdup(param));
	CHKmalloc(*paramval = strdup(val));
finalize_it:
	RETiRet;
}

BEGINnewInpInst
	struct cnfparamvals *pvals;
	instanceConf_t *inst;
	int i;
CODESTARTnewInpInst
	DBGPRINTF(&quot;newInpInst (imkafka)\n&quot;);

	if((pvals = nvlstGetParams(lst, &amp;inppblk, NULL)) == NULL) {
		ABORT_FINALIZE(RS_RET_MISSING_CNFPARAMS);
	}</B></FONT>

	if(Debug) {
		dbgprintf(&quot;input param blk in imkafka:\n&quot;);
		cnfparamsPrint(&amp;inppblk, pvals);
	}

	CHKiRet(createInstance(&amp;inst));

	for(i = 0 ; i &lt; inppblk.nParams ; ++i) {
		if(!pvals[i].bUsed)
			continue;
		if(!strcmp(inppblk.descr[i].name, &quot;broker&quot;)) {
			es_str_t *es = es_newStr(128);
			int bNeedComma = 0;
			for(int j = 0 ; j &lt;  pvals[i].val.d.ar-&gt;nmemb ; ++j) {
				if(bNeedComma)
					es_addChar(&amp;es, ',');
				es_addStr(&amp;es, pvals[i].val.d.ar-&gt;arr[j]);
				bNeedComma = 1;
			}
			inst-&gt;brokers = es_str2cstr(es, NULL);
			es_deleteStr(es);
		} else if(!strcmp(inppblk.descr[i].name, &quot;confparam&quot;)) {
			inst-&gt;nConfParams = pvals[i].val.d.ar-&gt;nmemb;
			CHKmalloc(inst-&gt;confParams = malloc(sizeof(struct kafka_params)*inst-&gt;nConfParams));
			for(int j = 0; j &lt; inst-&gt;nConfParams; j++) {
				char *cstr = es_str2cstr(pvals[i].val.d.ar-&gt;arr[j], NULL);
				CHKiRet(processKafkaParam(cstr, &amp;inst-&gt;confParams[j].name,
								&amp;inst-&gt;confParams[j].val));
				free(cstr);
			}
		} else if(!strcmp(inppblk.descr[i].name, &quot;topic&quot;)) {
			inst-&gt;topic = (uchar*)es_str2cstr(pvals[i].val.d.estr, NULL);
		} else if(!strcmp(inppblk.descr[i].name, &quot;consumergroup&quot;)) {
			inst-&gt;consumergroup = (uchar*)es_str2cstr(pvals[i].val.d.estr, NULL);
		} else if(!strcmp(inppblk.descr[i].name, &quot;ruleset&quot;)) {
			inst-&gt;pszBindRuleset = (uchar*)es_str2cstr(pvals[i].val.d.estr, NULL);
		} else if(!strcmp(inppblk.descr[i].name, &quot;parsehostname&quot;)) {
			if (pvals[i].val.d.n) {
				inst-&gt;nMsgParsingFlags = NEEDS_PARSING | PARSE_HOSTNAME;
			} else {
				inst-&gt;nMsgParsingFlags = NEEDS_PARSING;
			}
		} else {
			dbgprintf(&quot;imkafka: program error, non-handled &quot;
			  &quot;param '%s'\n&quot;, inppblk.descr[i].name);
		}
	}

	if(inst-&gt;brokers == NULL) {
		CHKmalloc(inst-&gt;brokers = strdup(&quot;localhost:9092&quot;));
		LogMsg(0, NO_ERRCODE, LOG_INFO, &quot;imkafka: \&quot;broker\&quot; parameter not specified &quot;
			&quot;using default of localhost:9092 -- this may not be what you want!&quot;);
	}

	DBGPRINTF(&quot;imkafka: newInpIns brokers=%s, topic=%s, consumergroup=%s\n&quot;,
		inst-&gt;brokers, inst-&gt;topic, inst-&gt;consumergroup);

finalize_it:
CODE_STD_FINALIZERnewInpInst
	cnfparamvalsDestruct(pvals, &amp;inppblk);
ENDnewInpInst


BEGINbeginCnfLoad
CODESTARTbeginCnfLoad
	loadModConf = pModConf;
	pModConf-&gt;pConf = pConf;
	pModConf-&gt;pszBindRuleset = NULL;
ENDbeginCnfLoad


BEGINsetModCnf
<A NAME="1"></A>	struct cnfparamvals *pvals = NULL;
	int i;
CODESTARTsetModCnf
<FONT color="#f63526"><A HREF="javascript:ZweiFrames('match754-1.html#1',3,'match754-top.html#1',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>	pvals = nvlstGetParams(lst, &amp;modpblk, NULL);
	if(pvals == NULL) {
		LogError(0, RS_RET_MISSING_CNFPARAMS, &quot;imkafka: error processing module &quot;
			&quot;config parameters [module(...)]&quot;);
		ABORT_FINALIZE(RS_RET_MISSING_CNFPARAMS);
	}

	if(Debug) {
		dbgprintf(&quot;module (global) param blk for imkafka:\n&quot;);
		cnfparamsPrint(&amp;modpblk, pvals);
	}

	for(i = 0 ; i &lt; modpblk.nParams ; ++i) {
		if(!pvals[i].bUsed)
			continue;
		if(!strcmp(modpblk.descr[i].name, &quot;ruleset&quot;)) {
			loadModConf-&gt;pszBindRuleset = (uchar*)es_str2cstr(pvals[i].val.d.estr, NULL);</B></FONT>
		} else {
			dbgprintf(&quot;imkafka: program error, non-handled &quot;
			  &quot;param '%s' in beginCnfLoad\n&quot;, modpblk.descr[i].name);
		}
	}
finalize_it:
	if(pvals != NULL)
		cnfparamvalsDestruct(pvals, &amp;modpblk);
ENDsetModCnf

BEGINendCnfLoad
CODESTARTendCnfLoad
	if(loadModConf-&gt;pszBindRuleset == NULL) {
		if((cs.pszBindRuleset == NULL) || (cs.pszBindRuleset[0] == '\0')) {
			loadModConf-&gt;pszBindRuleset = NULL;
		} else {
			CHKmalloc(loadModConf-&gt;pszBindRuleset = ustrdup(cs.pszBindRuleset));
		}
	}
finalize_it:
	free(cs.pszBindRuleset);
	cs.pszBindRuleset = NULL;
	loadModConf = NULL; /* done loading */
ENDendCnfLoad

BEGINcheckCnf
	instanceConf_t *inst;
CODESTARTcheckCnf
	for(inst = pModConf-&gt;root ; inst != NULL ; inst = inst-&gt;next) {
		if(inst-&gt;pszBindRuleset == NULL &amp;&amp; pModConf-&gt;pszBindRuleset != NULL) {
			CHKmalloc(inst-&gt;pszBindRuleset = ustrdup(pModConf-&gt;pszBindRuleset));
		}
		std_checkRuleset(pModConf, inst);
	}
finalize_it:
ENDcheckCnf


BEGINactivateCnfPrePrivDrop
CODESTARTactivateCnfPrePrivDrop
	runModConf = pModConf;
ENDactivateCnfPrePrivDrop

BEGINactivateCnf
CODESTARTactivateCnf
	for(instanceConf_t *inst = pModConf-&gt;root ; inst != NULL ; inst = inst-&gt;next) {
		iRet = checkInstance(inst);
	}
ENDactivateCnf


BEGINfreeCnf
	instanceConf_t *inst, *del;
CODESTARTfreeCnf
	for(inst = pModConf-&gt;root ; inst != NULL ; ) {
		free(inst-&gt;topic);
		free(inst-&gt;consumergroup);
		free(inst-&gt;brokers);
		free(inst-&gt;pszBindRuleset);
		for(int i = 0; i &lt; inst-&gt;nConfParams; i++) {
			free((void*)inst-&gt;confParams[i].name);
			free((void*)inst-&gt;confParams[i].val);
		}
		free((void*)inst-&gt;confParams);
		del = inst;
		inst = inst-&gt;next;
		free(del);
	}
	free(pModConf-&gt;pszBindRuleset);
ENDfreeCnf


/* Cleanup imkafka worker threads */
static void
shutdownKafkaWorkers(void)
{
	int i;
	instanceConf_t *inst;

	assert(kafkaWrkrInfo != NULL);

	DBGPRINTF(&quot;imkafka: waiting on imkafka workerthread termination\n&quot;);
	for(i = 0 ; i &lt; activeKafkaworkers ; ++i) {
		pthread_join(kafkaWrkrInfo[i].tid, NULL);
		DBGPRINTF(&quot;imkafka: Stopped worker %d\n&quot;, i);
	}
	free(kafkaWrkrInfo);
	kafkaWrkrInfo = NULL;

	for(inst = runModConf-&gt;root ; inst != NULL ; inst = inst-&gt;next) {
		DBGPRINTF(&quot;imkafka: stop consuming %s/%s/%s\n&quot;,
			inst-&gt;topic, inst-&gt;consumergroup, inst-&gt;brokers);
		rd_kafka_consumer_close(inst-&gt;rk); /* Close the consumer, committing final offsets, etc. */
		rd_kafka_destroy(inst-&gt;rk); /* Destroy handle object */
		DBGPRINTF(&quot;imkafka: stopped consuming %s/%s/%s\n&quot;,
			inst-&gt;topic, inst-&gt;consumergroup, inst-&gt;brokers);

		#if RD_KAFKA_VERSION &lt; 0x00090001
		/* Wait for kafka being destroyed in old API */
		if (rd_kafka_wait_destroyed(10000) &lt; 0)	{
			DBGPRINTF(&quot;imkafka: error, rd_kafka_destroy did not finish after grace &quot;
				&quot;timeout (10s)!\n&quot;);
		} else {
			DBGPRINTF(&quot;imkafka: rd_kafka_destroy successfully finished\n&quot;);
		}
		#endif
	}
}


/* This function is called to gather input.  */
BEGINrunInput
	int i;
	instanceConf_t *inst;
CODESTARTrunInput
	DBGPRINTF(&quot;imkafka: runInput loop started ...\n&quot;);
	activeKafkaworkers = 0;
	for(inst = runModConf-&gt;root ; inst != NULL ; inst = inst-&gt;next) {
		if(inst-&gt;rk != NULL) {
			++activeKafkaworkers;
		}
	}

	if(activeKafkaworkers == 0) {
		LogError(0, RS_RET_ERR, &quot;imkafka: no active inputs, input does &quot;
			&quot;not run - there should have been additional error &quot;
			&quot;messages given previously&quot;);
		ABORT_FINALIZE(RS_RET_ERR);
	}


	DBGPRINTF(&quot;imkafka: Starting %d imkafka workerthreads\n&quot;, activeKafkaworkers);
	kafkaWrkrInfo = calloc(activeKafkaworkers, sizeof(struct kafkaWrkrInfo_s));
	if (kafkaWrkrInfo == NULL) {
		LogError(errno, RS_RET_OUT_OF_MEMORY, &quot;imkafka: worker-info array allocation failed.&quot;);
		ABORT_FINALIZE(RS_RET_OUT_OF_MEMORY);
	}

	/* Start worker threads for each imkafka input source
	*/
	i = 0;
	for(inst = runModConf-&gt;root ; inst != NULL ; inst = inst-&gt;next) {
		/* init worker info structure! */
		kafkaWrkrInfo[i].inst = inst; /* Set reference pointer */
		pthread_create(&amp;kafkaWrkrInfo[i].tid, &amp;wrkrThrdAttr, imkafkawrkr, &amp;(kafkaWrkrInfo[i]));
		i++;
	}

	while(glbl.GetGlobalInputTermState() == 0) {

		/* Note: the additional 10000ns wait is vitally important. It guards rsyslog
		 * against totally hogging the CPU if the users selects a polling interval
		 * of 0 seconds. It doesn't hurt any other valid scenario. So do not remove.
		 */
		if(glbl.GetGlobalInputTermState() == 0)
			srSleep(0, 100000);
	}
	DBGPRINTF(&quot;imkafka: terminating upon request of rsyslog core\n&quot;);

	/* we need to shutdown kafak worker threads here because this operation can
	 * potentially block (e.g. when no kafka broker is available!). If this
	 * happens in runInput, the rsyslog core can cancel our thread. However,
	 * in afterRun this is not possible, because the core does not assume it
	 * can block there. -- rgerhards, 2018-10-23
	 */
	shutdownKafkaWorkers();
finalize_it:
ENDrunInput


BEGINwillRun
CODESTARTwillRun
	/* we need to create the inputName property (only once during our lifetime) */
	CHKiRet(prop.Construct(&amp;pInputName));
	CHKiRet(prop.SetString(pInputName, UCHAR_CONSTANT(&quot;imkafka&quot;), sizeof(&quot;imkafka&quot;) - 1));
	CHKiRet(prop.ConstructFinalize(pInputName));
finalize_it:
ENDwillRun


BEGINafterRun
CODESTARTafterRun
	if(pInputName != NULL)
		prop.Destruct(&amp;pInputName);

ENDafterRun


BEGINmodExit
CODESTARTmodExit
	pthread_attr_destroy(&amp;wrkrThrdAttr);
	/* release objects we used */
	objRelease(statsobj, CORE_COMPONENT);
	objRelease(ruleset, CORE_COMPONENT);
	objRelease(glbl, CORE_COMPONENT);
	objRelease(prop, CORE_COMPONENT);
ENDmodExit


BEGINisCompatibleWithFeature
CODESTARTisCompatibleWithFeature
	if(eFeat == sFEATURENonCancelInputTermination)
		iRet = RS_RET_OK;
ENDisCompatibleWithFeature


BEGINqueryEtryPt
CODESTARTqueryEtryPt
CODEqueryEtryPt_STD_IMOD_QUERIES
CODEqueryEtryPt_STD_CONF2_QUERIES
CODEqueryEtryPt_STD_CONF2_PREPRIVDROP_QUERIES
CODEqueryEtryPt_STD_CONF2_IMOD_QUERIES
CODEqueryEtryPt_STD_CONF2_setModCnf_QUERIES
CODEqueryEtryPt_IsCompatibleWithFeature_IF_OMOD_QUERIES
ENDqueryEtryPt


BEGINmodInit()
CODESTARTmodInit
	*ipIFVersProvided = CURR_MOD_IF_VERSION;
CODEmodInit_QueryRegCFSLineHdlr
	/* request objects we use */
	CHKiRet(objUse(glbl, CORE_COMPONENT));
	CHKiRet(objUse(prop, CORE_COMPONENT));
	CHKiRet(objUse(ruleset, CORE_COMPONENT));
	CHKiRet(objUse(statsobj, CORE_COMPONENT));

	/* initialize &quot;read-only&quot; thread attributes */
	pthread_attr_init(&amp;wrkrThrdAttr);
	pthread_attr_setstacksize(&amp;wrkrThrdAttr, 4096*1024);

	DBGPRINTF(&quot;imkafka %s using librdkafka version %s, 0x%x\n&quot;,
		VERSION, rd_kafka_version_str(), rd_kafka_version());
ENDmodInit

/*
*	Workerthread function for a single kafka consomer
 */
static void *
imkafkawrkr(void *myself)
{
	struct kafkaWrkrInfo_s *me = (struct kafkaWrkrInfo_s*) myself;
	DBGPRINTF(&quot;imkafka: started kafka consumer workerthread on %s/%s/%s\n&quot;,
		me-&gt;inst-&gt;topic, me-&gt;inst-&gt;consumergroup, me-&gt;inst-&gt;brokers);

	do {
		if(glbl.GetGlobalInputTermState() == 1)
			break; /* terminate input! */

		if(me-&gt;inst-&gt;rk == NULL) {
			continue;
		}

		// Try to add consumer only if connected! */
		if(me-&gt;inst-&gt;bIsConnected == 1 &amp;&amp; me-&gt;inst-&gt;bIsSubscribed == 0 ) {
			addConsumer(runModConf, me-&gt;inst);
		}
		if(me-&gt;inst-&gt;bIsSubscribed == 1 ) {
			msgConsume(me-&gt;inst);
		}
		/* Note: the additional 10000ns wait is vitally important. It guards rsyslog
		 * against totally hogging the CPU if the users selects a polling interval
		 * of 0 seconds. It doesn't hurt any other valid scenario. So do not remove.
		 * rgerhards, 2008-02-14
		 */
		if(glbl.GetGlobalInputTermState() == 0)
			srSleep(0, 100000);
	} while(glbl.GetGlobalInputTermState() == 0);

	DBGPRINTF(&quot;imkafka: stopped kafka consumer workerthread on %s/%s/%s\n&quot;,
		me-&gt;inst-&gt;topic, me-&gt;inst-&gt;consumergroup, me-&gt;inst-&gt;brokers);
	return NULL;
}
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>mmdarwin.c</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/* Copyright 2019 Advens
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include &quot;config.h&quot;
#include &quot;rsyslog.h&quot;
#include &lt;stdio.h&gt;
#include &lt;stdarg.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;assert.h&gt;
#include &lt;signal.h&gt;
#include &lt;errno.h&gt;
#include &lt;unistd.h&gt;
#include &lt;stdint.h&gt;
#include &lt;pthread.h&gt;
#include &quot;conf.h&quot;
#include &quot;syslogd-types.h&quot;
#include &quot;srUtils.h&quot;
#include &quot;template.h&quot;
#include &quot;module-template.h&quot;
#include &quot;errmsg.h&quot;
#include &quot;parserif.h&quot;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/un.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;uuid/uuid.h&gt;
#include &lt;json.h&gt;

#include &quot;protocol.h&quot; /* custom file written for Darwin */

#define JSON_DEFAULT_CONTAINER &quot;!mmdarwin&quot;
#define JSON_DARWIN_ID &quot;darwin_id&quot;
#define INVLD_SOCK -1
#define INITIAL_BUFFER_SIZE 32
#define BUFFER_DEFAULT_MAX_SIZE 65536

MODULE_TYPE_OUTPUT
MODULE_TYPE_NOKEEP
MODULE_CNFNAME(&quot;mmdarwin&quot;)

DEFobjCurrIf(glbl)
DEF_OMOD_STATIC_DATA

typedef struct dyn_buffer_t
{
	char *buffer;
	size_t bufferAllocSize;
	size_t bufferMsgSize;
	size_t bufferMaxSize;
} dyn_buffer;

/* config variables */
typedef struct _instanceData
{
	char *pUUIDKey;					/* the key to the UUID generated by an mmdarwin instance */
	char *pCertitudeKey;				/* the key name to save in the enriched log
							   line the certitude obtained from Darwin */
	uchar *pSockName;				/* the socket path of the filter which will be used by
							   Darwin */
	unsigned long long int filterCode;		/* the filter code associated to the filter which will be used
							   by Darwin */
	enum darwin_filter_response_type response;	/* the type of response for Darwin: no / back / darwin / both */
	struct
	{
		int nmemb;
		char **name;
		char **varname;
	} fieldList; /* our keys (fields) to be extracted from the JSON-parsed log line */
	unsigned int socketMaxUse;
	sbool sendPartial;
} instanceData;

typedef struct wrkrInstanceData
{
	instanceData *pData;
	int sock;				 /* the socket of the filter which will be used by Darwin */
	struct sockaddr_un addr; /* the sockaddr_un used to connect to the Darwin filter */
	uint8_t pktSentSocket;
	dyn_buffer darwinBody; /* the body object used (and reused) to hold data to send to Darwin */
	dyn_buffer fieldBuffer;
} wrkrInstanceData_t;

struct modConfData_s
{
	/* our overall config object */
	rsconf_t *pConf;
	const char *container;
<A NAME="0"></A>};

/* modConf ptr to use for the current load process */
<FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match754-0.html#0',2,'match754-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>static modConfData_t *loadModConf = NULL;
/* modConf ptr to use for the current exec process */
static modConfData_t *runModConf = NULL;

/* module-global parameters */
static struct cnfparamdescr modpdescr[] = {
	{&quot;container&quot;, eCmdHdlrGetWord, 0},
};
static struct cnfparamblk modpblk =
	{CNFPARAMBLK_VERSION,
	 sizeof(modpdescr) / sizeof(struct cnfparamdescr),
	 modpdescr};

/* tables for interfacing with the v6 config system
 * action (instance) parameters */
static struct cnfparamdescr actpdescr[] = {
	{&quot;key&quot;, eCmdHdlrGetWord, CNFPARAM_REQUIRED},
	{&quot;socketpath&quot;, eCmdHdlrGetWord, CNFPARAM_REQUIRED},
	{&quot;fields&quot;, eCmdHdlrArray, CNFPARAM_REQUIRED},
	{&quot;filtercode&quot;, eCmdHdlrGetWord, 0},			/* optional parameter */
	{&quot;response&quot;, eCmdHdlrGetWord, 0},			/* optional parameter */
	{&quot;send_partial&quot;, eCmdHdlrBinary, 0},		/* optional parameter */</B></FONT>
	{&quot;socket_max_use&quot;, eCmdHdlrNonNegInt, 0}, /* optional parameter - will disappear in future updates */
};
static struct cnfparamblk actpblk = {
	CNFPARAMBLK_VERSION,
	sizeof(actpdescr) / sizeof(struct cnfparamdescr),
	actpdescr};

/* custom functions */
#define min(a, b) \
	({ __typeof__ (a) _a = (a); \
	__typeof__ (b) _b = (b); \
	_a &lt; _b ? _a : _b; })

static rsRetVal openSocket(wrkrInstanceData_t *pWrkrData);
static rsRetVal closeSocket(wrkrInstanceData_t *pWrkrData);
static rsRetVal doTryResume(wrkrInstanceData_t *pWrkrData);

static rsRetVal sendMsg(wrkrInstanceData_t *pWrkrData, void *msg, size_t len);
static rsRetVal receiveMsg(wrkrInstanceData_t *pWrkrData, void *response, size_t len);

const char* get_uuid_object(smsg_t *const pMsg);
int get_field(smsg_t *const pMsg, const char *pFieldName, char **ppRetString);
int expand_buffer(dyn_buffer *pBody, size_t new_size);
int add_field_to_body(dyn_buffer *pBody, const char *field, size_t size);
int start_new_line(dyn_buffer *pBody);
int end_body(dyn_buffer *pBody);

/* open socket to remote system
 */
static rsRetVal openSocket(wrkrInstanceData_t *pWrkrData)
{
	DEFiRet;
	assert(pWrkrData-&gt;sock == INVLD_SOCK);

	if ((pWrkrData-&gt;sock = socket(AF_UNIX, SOCK_STREAM, 0)) == -1)
	{
		char errStr[1024];
		int eno = errno;
		DBGPRINTF(&quot;mmdarwin::openSocket:: error %d creating AF_UNIX/SOCK_STREAM: %s.\n&quot;,
				  eno, rs_strerror_r(eno, errStr, sizeof(errStr)));
		pWrkrData-&gt;sock = INVLD_SOCK;
		ABORT_FINALIZE(RS_RET_NO_SOCKET);
	}

	memset(&amp;pWrkrData-&gt;addr, 0, sizeof(struct sockaddr_un));
	pWrkrData-&gt;addr.sun_family = AF_UNIX;
	strncpy(pWrkrData-&gt;addr.sun_path, (char *)pWrkrData-&gt;pData-&gt;pSockName, sizeof(pWrkrData-&gt;addr.sun_path) - 1);

	DBGPRINTF(&quot;mmdarwin::openSocket:: connecting to Darwin...\n&quot;);

	if (connect(pWrkrData-&gt;sock, (struct sockaddr *)&amp;pWrkrData-&gt;addr, sizeof(struct sockaddr_un)) == -1)
	{
		LogError(errno, RS_RET_NO_SOCKET, &quot;mmdarwin::openSocket:: error connecting to Darwin &quot;
										  &quot;via socket '%s'&quot;,
				 pWrkrData-&gt;pData-&gt;pSockName);

		pWrkrData-&gt;sock = INVLD_SOCK;
		ABORT_FINALIZE(RS_RET_NO_SOCKET);
	}

	DBGPRINTF(&quot;mmdarwin::openSocket:: connected !\n&quot;);
finalize_it:
	if (iRet != RS_RET_OK)
	{
		closeSocket(pWrkrData);
	}
	RETiRet;
}

/* close socket to remote system
 */
static rsRetVal closeSocket(wrkrInstanceData_t *pWrkrData)
{
	DEFiRet;
	if (pWrkrData-&gt;sock != INVLD_SOCK)
	{
		if (close(pWrkrData-&gt;sock) != 0)
		{
			char errStr[1024];
			int eno = errno;
			DBGPRINTF(&quot;mmdarwin::closeSocket:: error %d closing the socket: %s.\n&quot;,
					  eno, rs_strerror_r(eno, errStr, sizeof(errStr)));
		}
		pWrkrData-&gt;sock = INVLD_SOCK;
	}
	RETiRet;
}

/* try to resume connection if it is not ready
 */
static rsRetVal doTryResume(wrkrInstanceData_t *pWrkrData)
{
	DEFiRet;

	DBGPRINTF(&quot;mmdarwin::doTryResume:: trying to resume\n&quot;);
	closeSocket(pWrkrData);
	iRet = openSocket(pWrkrData);

	if (iRet != RS_RET_OK)
	{
		iRet = RS_RET_SUSPENDED;
	}

	RETiRet;
}

/* send a message via TCP
 * inspired by rgehards, 2007-12-20
 */
static rsRetVal sendMsg(wrkrInstanceData_t *pWrkrData, void *msg, size_t len)
{
	DEFiRet;

	DBGPRINTF(&quot;mmdarwin::sendMsg:: sending message to Darwin...\n&quot;);

	if (pWrkrData-&gt;sock == INVLD_SOCK)
	{
		CHKiRet(doTryResume(pWrkrData));
	}

	if (pWrkrData-&gt;sock != INVLD_SOCK)
	{
		if (send(pWrkrData-&gt;sock, msg, len, 0) == -1)
		{
			char errStr[1024];
			DBGPRINTF(&quot;mmdarwin::sendData:: error while sending data: error[%d] -&gt; %s\n&quot;,
					  errno, rs_strerror_r(errno, errStr, sizeof(errStr)));
			iRet = RS_RET_SUSPENDED;
		}
	}

finalize_it:
	RETiRet;
}

/* receive a message via TCP
 * inspired by rgehards, 2007-12-20
 */
static rsRetVal receiveMsg(wrkrInstanceData_t *pWrkrData, void *response, size_t len)
{
	DEFiRet;

	DBGPRINTF(&quot;mmdarwin::receiveMsg:: receiving message from Darwin...\n&quot;);

	if (pWrkrData-&gt;sock == INVLD_SOCK)
	{
		CHKiRet(doTryResume(pWrkrData));
	}

	if (pWrkrData-&gt;sock != INVLD_SOCK)
	{
		if (recv(pWrkrData-&gt;sock, response, len, MSG_WAITALL) &lt;= 0)
		{
			char errStr[1024];
			DBGPRINTF(&quot;mmdarwin::receiveMsg:: error while receiving data: error[%d] -&gt; %s\n&quot;,
					  errno, rs_strerror_r(errno, errStr, sizeof(errStr)));
			iRet = RS_RET_NONE;
		}
	}

finalize_it:
	RETiRet;
}

/**
 * Get the string corresponding to a field supposedly present in the provided message
 *
 * params:
 *  - pMsg: a pointer to the rsyslog message where the field should be
 *  - pFieldName: a nul-terminated pointer to string representing the name of the field to search for
 *  - ppRetString: the pointer to contain the potential return string
 *
 * return: 1 if a string was put in ppRetString, 0 otherwise
 *
 * note: the string placed in ppRetString should be freed by the caller
 */
int get_field(smsg_t *const pMsg, const char *pFieldName, char **ppRetString)
{
	DBGPRINTF(&quot;mmdarwin::get_field:: getting key '%s' in msg\n&quot;, pFieldName);
	struct json_object *pJson = NULL;
	char *pFieldString = NULL;
	int retVal = 0;

	msgPropDescr_t propDesc;
	msgPropDescrFill(&amp;propDesc, (uchar *)pFieldName, strlen(pFieldName));
	msgGetJSONPropJSONorString(pMsg, &amp;propDesc, &amp;pJson, (uchar **)&amp;pFieldString);

	if (pFieldString)
	{
		*ppRetString = pFieldString;
		DBGPRINTF(&quot;mmdarwin::get_field:: got string\n&quot;);
		retVal = 1;
	}
	else if (pJson)
	{
		pFieldString = (char *)json_object_get_string(pJson);
		if (pFieldString)
		{
			*ppRetString = strdup(pFieldString);
			retVal = 1;
			DBGPRINTF(&quot;mmdarwin::get_field:: got string from json\n&quot;);
			json_object_put(pJson);
		}
	}

	msgPropDescrDestruct(&amp;propDesc);
	return retVal;
}

/**
 * expands the buffer object in the dyn_buffer object
 *
 * params:
 *  - pBody: a pointer to the concerned structure to expand
 *  - new_size: the new size to give to the underlying buffer
 *
 * return: 0 if the expansion was successful, -1 otherwise
 */
int expand_buffer(dyn_buffer *pBody, size_t new_size)
{
	/* return error if new_size tries to exceed max defined size */
	if (new_size &gt; pBody-&gt;bufferMaxSize)
		return -1;
	while (pBody-&gt;bufferAllocSize &lt; new_size)
		pBody-&gt;bufferAllocSize += INITIAL_BUFFER_SIZE;

	DBGPRINTF(&quot;mmdarwin::expand_buffer:: expanding buffer to %zu\n&quot;, pBody-&gt;bufferAllocSize);

	char *tmp = realloc(pBody-&gt;buffer, pBody-&gt;bufferAllocSize * sizeof(char));

	if (!tmp)
	{
		DBGPRINTF(&quot;mmdarwin::expand_buffer:: could not resize buffer\n&quot;);
		return -1;
	}

	pBody-&gt;buffer = tmp;
	return 0;
}

/**
 * adds a field to the dyn_buffer buffer
 *
 * params:
 *  - pBody: the pointer on the dyn_buffer structure
 *  - field: the potentially not null-terminated string to add as a field to the dyn_buffer
 *  - size: the size of the string (without the '\0' character)
 *
 * return: 0 if the field was indeed added to the dyn_buffer, -1 otherwise
 */
int add_field_to_body(dyn_buffer *pBody, const char *field, size_t size)
{
	/* get required additional size for field, quotes, colon, and \0
	and potentially also for the beginning of the message structure */
	int beginning = (pBody-&gt;bufferMsgSize == 0) ? 2 : 0;
	size_t requiredBodySize = pBody-&gt;bufferMsgSize + size + 4 + beginning;

	/* resize body buffer if necessary */
	if (requiredBodySize &gt; pBody-&gt;bufferAllocSize)
	{
		if (expand_buffer(pBody, requiredBodySize) != 0)
		{
			return -1;
		}
	}

	/* add message structure beginning if current message is empty */
	if (!pBody-&gt;bufferMsgSize)
	{
		pBody-&gt;buffer[0] = '[';
		pBody-&gt;buffer[1] = '[';
		pBody-&gt;bufferMsgSize += 2;
	}

	/* add field with quotes and colon */
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = '\&quot;';
	memcpy((void *)&amp;pBody-&gt;buffer[pBody-&gt;bufferMsgSize], (const void *)field, size);
	pBody-&gt;bufferMsgSize += size;
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = '\&quot;';
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = ',';

	return 0;
}

/**
 * small helper function to start a new input line (used for bulk-calls) in the dyn_buffer.
 * will close current line with a ']' and start the next with a '['.
 * will also remove leading ',' in fields list.
 *
 * params:
 *  - pBody: the pointer on the dyn_buffer on which to start a new input line
 *
 * return: 0 if successful, -1 otherwise
 */
int start_new_line(dyn_buffer *pBody)
{
	/* don't if the message is empty */
	if (!pBody-&gt;bufferMsgSize)
	{
		return -1;
	}

	DBGPRINTF(&quot;mmdarwin::start_new_line:: starting new line entry in body\n&quot;);

	if (pBody-&gt;bufferAllocSize &lt; pBody-&gt;bufferMsgSize + 2)
	{
		if (expand_buffer(pBody, pBody-&gt;bufferAllocSize + 2) != 0)
		{
			return -1;
		}
	}

	pBody-&gt;buffer[pBody-&gt;bufferMsgSize - 1] = ']';
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = ',';
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = '[';
	return 0;
}

/**
 * small helper function to close the dyn_buffer structure.
 * will close the line list with two ']' and will remove the leading ',' in the fields list
 *
 * params:
 *  - pBody: the pointer on the dyn_buffer on which to start a new input line
 *
 * return: 0 if successful, -1 otherwise
 */
int end_body(dyn_buffer *pBody)
{
	/* don't if the message is empty */
	if (!pBody-&gt;bufferMsgSize)
	{
		return -1;
	}

	DBGPRINTF(&quot;mmdarwin::end_body:: finishing body structure\n&quot;);

	if (pBody-&gt;bufferAllocSize &lt; pBody-&gt;bufferMsgSize + 2)
	{
		if (expand_buffer(pBody, pBody-&gt;bufferAllocSize + 2) != 0)
		{
			return -1;
		}
	}

	pBody-&gt;buffer[pBody-&gt;bufferMsgSize - 1] = ']';
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = ']';
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = '\0';
	return 0;
}

/**
 * Get the potential existing uuid put by previous mmdarwin call in a json
 *
 * params:
 *  - pJson: the pointer on the json
 *
 * return: a valid json_object pointer if found, NULL otherwise
 */
const char* get_uuid_object(smsg_t *const pMsg) {
	struct json_object *mmdarwin_object = NULL;
	const char *result = NULL, *key = NULL;

	msgPropDescr_t propDesc;
	msgPropDescrFill(&amp;propDesc, (uchar *)runModConf-&gt;container, strlen(runModConf-&gt;container));
	msgGetJSONPropJSON(pMsg, &amp;propDesc, &amp;mmdarwin_object);

	if(mmdarwin_object) {
		struct json_object_iterator it = json_object_iter_begin(mmdarwin_object);
		struct json_object_iterator itEnd = json_object_iter_end(mmdarwin_object);

		while(!json_object_iter_equal(&amp;it, &amp;itEnd)) {
			key = json_object_iter_peek_name(&amp;it);

			if(!strcmp(key, JSON_DARWIN_ID)) {
				// should always be a (non-empty) null-terminated string, safe to use with strdup()
				result = strdup(json_object_get_string(json_object_iter_peek_value(&amp;it)));
				break;
			}

			json_object_iter_next(&amp;it);
		}
		json_object_put(mmdarwin_object);
	}

	msgPropDescrDestruct(&amp;propDesc);
	return result;
}

BEGINbeginCnfLoad
CODESTARTbeginCnfLoad
	loadModConf = pModConf;
pModConf-&gt;pConf = pConf;
ENDbeginCnfLoad

BEGINendCnfLoad
CODESTARTendCnfLoad
ENDendCnfLoad

BEGINcheckCnf
CODESTARTcheckCnf
ENDcheckCnf

BEGINactivateCnf
CODESTARTactivateCnf
	runModConf = pModConf;
ENDactivateCnf

BEGINfreeCnf
CODESTARTfreeCnf
	free((void *)pModConf-&gt;container);
ENDfreeCnf

BEGINdbgPrintInstInfo
CODESTARTdbgPrintInstInfo
	DBGPRINTF(&quot;%s\n&quot;, pData-&gt;pSockName);
ENDdbgPrintInstInfo

BEGINcreateInstance
CODESTARTcreateInstance
ENDcreateInstance

BEGINcreateWrkrInstance
CODESTARTcreateWrkrInstance
	pWrkrData-&gt;pktSentSocket = 0;
	pWrkrData-&gt;darwinBody.bufferAllocSize = 0;
	pWrkrData-&gt;darwinBody.bufferMaxSize = BUFFER_DEFAULT_MAX_SIZE;
	pWrkrData-&gt;darwinBody.bufferMsgSize = 0;
	pWrkrData-&gt;sock = INVLD_SOCK;
ENDcreateWrkrInstance

BEGINisCompatibleWithFeature
CODESTARTisCompatibleWithFeature
ENDisCompatibleWithFeature

BEGINfreeInstance
CODESTARTfreeInstance
	if (pData-&gt;fieldList.name != NULL)
	{
		for (int i = 0; i &lt; pData-&gt;fieldList.nmemb; ++i)
		{
			free(pData-&gt;fieldList.name[i]);
			free(pData-&gt;fieldList.varname[i]);
		}
		free(pData-&gt;fieldList.name);
		free(pData-&gt;fieldList.varname);
	}
	free(pData-&gt;pUUIDKey);
	free(pData-&gt;pCertitudeKey);
	free(pData-&gt;pSockName);
ENDfreeInstance

BEGINfreeWrkrInstance
CODESTARTfreeWrkrInstance
	closeSocket(pWrkrData);
	free(pWrkrData-&gt;darwinBody.buffer);
ENDfreeWrkrInstance

BEGINsetModCnf
struct cnfparamvals *pvals = NULL;
<A NAME="1"></A>int i;
CODESTARTsetModCnf
	loadModConf-&gt;container = NULL;
<FONT color="#f63526"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match754-0.html#1',2,'match754-top.html#1',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>	pvals = nvlstGetParams(lst, &amp;modpblk, NULL);
	if (pvals == NULL)
	{
		LogError(0, RS_RET_MISSING_CNFPARAMS,
				&quot;mmdarwin: error processing module config parameters missing [module(...)]&quot;);
		ABORT_FINALIZE(RS_RET_MISSING_CNFPARAMS);
	}
	if (Debug)
	{
		DBGPRINTF(&quot;mmdarwin::setModCnf:: module (global) param blk for mmdarwin:\n&quot;);
		cnfparamsPrint(&amp;modpblk, pvals);
	}

	for (i = 0; i &lt; modpblk.nParams; ++i)
	{
		if (!pvals[i].bUsed)
			continue;
		if (!strcmp(modpblk.descr[i].name, &quot;container&quot;))
		{
			loadModConf-&gt;container = es_str2cstr(pvals[i].val.d.estr, NULL);</B></FONT>
			if(loadModConf-&gt;container[0] != '!' &amp;&amp; loadModConf-&gt;container[0] != '.') {
				LogError(0, RS_RET_INVALID_PARAMS, &quot;mmdarwin: container should either&quot;
					&quot; begin with '!' or '.'\n&quot;);
				ABORT_FINALIZE(RS_RET_INVALID_PARAMS);
			}
		}
		else
		{
			DBGPRINTF(&quot;mmdarwin::setModCnf:: program error, non-handled &quot;
					&quot;param '%s'\n&quot;,
					modpblk.descr[i].name);
		}
	}

	if (loadModConf-&gt;container == NULL)
	{
		CHKmalloc(loadModConf-&gt;container = strdup(JSON_DEFAULT_CONTAINER));
	}

finalize_it :
	if (pvals != NULL)
		cnfparamvalsDestruct(pvals, &amp;modpblk);
ENDsetModCnf

static inline void setInstParamDefaults(instanceData *pData)
{
	DBGPRINTF(&quot;mmdarwin::setInstParamDefaults::\n&quot;);
	pData-&gt;pUUIDKey = NULL;
<A NAME="2"></A>	pData-&gt;pCertitudeKey = NULL;
	pData-&gt;pSockName = NULL;
	pData-&gt;fieldList.nmemb = 0;
<FONT color="#980517"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match754-0.html#2',2,'match754-top.html#2',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>	pData-&gt;filterCode = DARWIN_FILTER_CODE_NO;
	pData-&gt;response = DARWIN_RESPONSE_SEND_NO;
	pData-&gt;socketMaxUse = 0;
	pData-&gt;sendPartial = 0;
}

BEGINnewActInst
	struct cnfparamvals *pvals;
	int i;
CODESTARTnewActInst
	DBGPRINTF(&quot;mmdarwin::newActInst::\n&quot;);
	if ((pvals = nvlstGetParams(lst, &amp;actpblk, NULL)) == NULL)
	{
		ABORT_FINALIZE(RS_RET_MISSING_CNFPARAMS);
	}</B></FONT>

	CODE_STD_STRING_REQUESTnewActInst(1)
	CHKiRet(OMSRsetEntry(*ppOMSR, 0, NULL, OMSR_TPL_AS_MSG));
	CHKiRet(createInstance(&amp;pData));
	setInstParamDefaults(pData);

	for (i = 0; i &lt; actpblk.nParams; ++i)
	{
		if (!pvals[i].bUsed)
			continue;

		if (!strcmp(actpblk.descr[i].name, &quot;key&quot;))
		{
			char *key = es_str2cstr(pvals[i].val.d.estr, NULL);
			char vnamebuf[1024];
			snprintf(vnamebuf, sizeof(vnamebuf), &quot;%s!%s&quot;, loadModConf-&gt;container, key);
			CHKmalloc(pData-&gt;pCertitudeKey = strdup(vnamebuf));
			free(key);
			DBGPRINTF(&quot;mmdarwin::newActInst:: certitudeKey is %s\n&quot;, pData-&gt;pCertitudeKey);
		}
		else if (!strcmp(actpblk.descr[i].name, &quot;socketpath&quot;))
		{
			pData-&gt;pSockName = (uchar *)es_str2cstr(pvals[i].val.d.estr, NULL);
			DBGPRINTF(&quot;mmdarwin::newActInst:: sockName is %s\n&quot;, pData-&gt;pSockName);
		}
		else if (!strcmp(actpblk.descr[i].name, &quot;socket_max_use&quot;))
		{
			pData-&gt;socketMaxUse = (uint32_t)pvals[i].val.d.n;
			DBGPRINTF(&quot;mmdarwin::newActInst:: socketMaxUse is %d\n&quot;, pData-&gt;socketMaxUse);
		}
		else if (!strcmp(actpblk.descr[i].name, &quot;send_partial&quot;))
		{
			pData-&gt;sendPartial = (sbool)pvals[i].val.d.n;
			if (pData-&gt;sendPartial)
			{
				DBGPRINTF(&quot;mmdarwin::newActInst:: sending bodies even if fields are missing\n&quot;);
			}
			else
			{
				DBGPRINTF(&quot;mmdarwin::newActInst:: only sending complete bodies\n&quot;);
			}
		}
		else if (!strcmp(actpblk.descr[i].name, &quot;response&quot;))
		{
			char *response = es_str2cstr(pvals[i].val.d.estr, NULL);

			if (!strcmp(response, &quot;no&quot;))
			{
				pData-&gt;response = DARWIN_RESPONSE_SEND_NO;
				DBGPRINTF(&quot;mmdarwin::newActInst:: response type is 'no'\n&quot;);
			}
			else if (!strcmp(response, &quot;back&quot;))
			{
				pData-&gt;response = DARWIN_RESPONSE_SEND_BACK;
				DBGPRINTF(&quot;mmdarwin::newActInst:: response type is 'back'\n&quot;);
			}
			else if (!strcmp(response, &quot;darwin&quot;))
			{
				pData-&gt;response = DARWIN_RESPONSE_SEND_DARWIN;
				DBGPRINTF(&quot;mmdarwin::newActInst:: response type is 'darwin'\n&quot;);
			}
			else if (!strcmp(response, &quot;both&quot;))
			{
				pData-&gt;response = DARWIN_RESPONSE_SEND_BOTH;
				DBGPRINTF(&quot;mmdarwin::newActInst:: response type is 'both'\n&quot;);
			}
			else
			{
				DBGPRINTF(
					&quot;mmdarwin::newActInst:: invalid 'response' value: %s. 'No response' set.\n&quot;,
					response);

				pData-&gt;response = DARWIN_RESPONSE_SEND_NO;
				DBGPRINTF(&quot;mmdarwin::newActInst:: response type is 'no'\n&quot;);
			}

			free(response);
		}
		else if (!strcmp(actpblk.descr[i].name, &quot;filtercode&quot;))
		{
			char *filterCode = es_str2cstr(pvals[i].val.d.estr, NULL);
			pData-&gt;filterCode = strtoull(filterCode, NULL, 16);
			free(filterCode);
		}
		else if (!strcmp(actpblk.descr[i].name, &quot;fields&quot;))
		{
			pData-&gt;fieldList.nmemb = pvals[i].val.d.ar-&gt;nmemb;
			CHKmalloc(pData-&gt;fieldList.name = calloc(pData-&gt;fieldList.nmemb, sizeof(char *)));
			CHKmalloc(pData-&gt;fieldList.varname = calloc(pData-&gt;fieldList.nmemb, sizeof(char *)));

			for (int j = 0; j &lt; pData-&gt;fieldList.nmemb; ++j)
			{
				char *const param = es_str2cstr(pvals[i].val.d.ar-&gt;arr[j], NULL);
				char *varname = NULL;
				char *name;
				if (*param == ':')
				{
					char *b = strchr(param + 1, ':');
					if (b == NULL)
					{
						parser_errmsg(
							&quot;mmdarwin::newActInst:: missing closing colon: '%s'&quot;, param);
						ABORT_FINALIZE(RS_RET_ERR);
					}

					*b = '\0'; /* split name &amp; varname */
					varname = param + 1;
					name = b + 1;
				}
				else
				{
					name = param;
				}
				CHKmalloc(pData-&gt;fieldList.name[j] = strdup(name));
				char vnamebuf[1024];
				snprintf(vnamebuf, sizeof(vnamebuf),
						&quot;%s!%s&quot;, loadModConf-&gt;container,
						(varname == NULL) ? name : varname);
				CHKmalloc(pData-&gt;fieldList.varname[j] = strdup(vnamebuf));
				free(param);
				DBGPRINTF(&quot;mmdarwin::newActInst:: will look for field %s\n&quot;, pData-&gt;fieldList.name[j]);
			}
		}
		else
		{
			DBGPRINTF(
			&quot;mmdarwin::newActInst:: program error, non-handled param '%s'\n&quot;, actpblk.descr[i].name);
		}
	}

	// reserve space for 'container!key\0'
	size_t sizeKey = strlen(loadModConf-&gt;container) + strlen(JSON_DARWIN_ID) + 2;
	pData-&gt;pUUIDKey = malloc(sizeKey);
	snprintf(pData-&gt;pUUIDKey, sizeKey, &quot;%s!%s&quot;, loadModConf-&gt;container, JSON_DARWIN_ID);
	DBGPRINTF(&quot;mmdarwin:: uuid key is %s\n&quot;, pData-&gt;pUUIDKey);

CODE_STD_FINALIZERnewActInst
	cnfparamvalsDestruct(pvals, &amp;actpblk);
ENDnewActInst

BEGINtryResume
CODESTARTtryResume
	iRet = doTryResume(pWrkrData);
ENDtryResume

BEGINdoAction_NoStrings
	smsg_t **ppMsg = (smsg_t **)pMsgData; /* the raw data */
	smsg_t *pMsg = ppMsg[0]; /* the raw log line */
	instanceData *pData = pWrkrData-&gt;pData; /* the parameters given for the plugin */
	char *pFieldValue = NULL; /* ponter to the found field value */
	int fieldsNum = 0; /* number of fields retrieved */

CODESTARTdoAction
	DBGPRINTF(&quot;mmdarwin::doAction:: beggining action\n&quot;);
	pWrkrData-&gt;darwinBody.bufferMsgSize = 0;
	fieldsNum = 0;

	for (int i = 0; i &lt; pData-&gt;fieldList.nmemb; i++)
	{
		DBGPRINTF(&quot;mmdarwin::doAction:: processing field '%s'\n&quot;, pData-&gt;fieldList.name[i]);
		pFieldValue = NULL;

		/* case 1: static field. We simply forward it to Darwin */
		if (pData-&gt;fieldList.name[i][0] != '!' &amp;&amp; pData-&gt;fieldList.name[i][0] != '.')
		{
			pFieldValue = strdup(pData-&gt;fieldList.name[i]);
		}
		/* case 2: dynamic field. We retrieve its value from the JSON logline and forward it to
		 * Darwin */
		else
		{
			if (!get_field(pMsg, pData-&gt;fieldList.name[i], &amp;pFieldValue))
			{
				DBGPRINTF(&quot;mmdarwin::doAction:: \
could not extract field '%s' from message\n&quot;, pData-&gt;fieldList.name[i]);
				continue;
			}
		}

		DBGPRINTF(
			&quot;mmdarwin::doAction:: got value of field '%s': '%s'\n&quot;, pData-&gt;fieldList.name[i], pFieldValue);

		if (add_field_to_body(&amp;(pWrkrData-&gt;darwinBody), pFieldValue, strlen(pFieldValue)) != 0)
		{
			DBGPRINTF(&quot;mmdarwin::doAction:: could not add field to body, aborting\n&quot;);
			free(pFieldValue);
			ABORT_FINALIZE(RS_RET_ERR);
		}

		fieldsNum++;
		free(pFieldValue);
	}

	if (fieldsNum)
	{
		if (!pData-&gt;sendPartial &amp;&amp; fieldsNum != pData-&gt;fieldList.nmemb)
		{
			DBGPRINTF(&quot;mmdarwin::doAction:: not all fields could be retrieved, not sending partial message.&quot;
	&quot; (if you wish to send partial messages anyway, set 'send_partial' to 'on' in instance parameters)\n&quot;);
			FINALIZE;
		}
		if (end_body(&amp;(pWrkrData-&gt;darwinBody)) != 0)
			ABORT_FINALIZE(RS_RET_ERR);
	}
	else
	{
		DBGPRINTF(&quot;mmdarwin::doAction:: no fields retrieved, finalizing\n&quot;);
		FINALIZE;
	}

	DBGPRINTF(&quot;mmdarwin::doAction:: body to send: '%s'\n&quot;, pWrkrData-&gt;darwinBody.buffer);

	if (pData-&gt;socketMaxUse)
	{
		/* need to rotate socket connections */
		if (!pWrkrData-&gt;pktSentSocket)
		{
			DBGPRINTF(&quot;mmdarwin::doAction:: opening a new connection\n&quot;);
			CHKiRet(doTryResume(pWrkrData));
		}
		pWrkrData-&gt;pktSentSocket = (pWrkrData-&gt;pktSentSocket + 1) % pData-&gt;socketMaxUse;
	}

	/* the Darwin header to be sent to the filter */
	darwin_filter_packet_t header = {
		.type = DARWIN_PACKET_OTHER,
		.response = pData-&gt;response,
		.filter_code = pData-&gt;filterCode,
		.body_size = pWrkrData-&gt;darwinBody.bufferMsgSize};

	const char *uuid = get_uuid_object(pMsg);
	if(uuid) {
		DBGPRINTF(&quot;mmdarwin: using existing UUID = %s\n&quot;, uuid);
		if(uuid_parse(uuid, header.evt_id))
			LogError(0, RS_RET_ERR, &quot;mmdarwin:: failed to parse existing UUID: %s\n&quot;, uuid);
		free((void*)uuid);
	}
	else {
		uuid_generate(header.evt_id);
		char uuidStr[40];
		uuid_unparse(header.evt_id, uuidStr);
		DBGPRINTF(&quot;mmdarwin: generated new UUID = %s\n&quot;, uuidStr);
		msgAddJSON(pMsg, (uchar *)pData-&gt;pUUIDKey, json_object_new_string(uuidStr), 0, 0);
	}

	DBGPRINTF(&quot;mmdarwin::doAction:: sending header to Darwin\n&quot;);
	CHKiRet(sendMsg(pWrkrData, &amp;header, sizeof(darwin_filter_packet_t)));

	DBGPRINTF(&quot;mmdarwin::doAction:: sending body to Darwin\n&quot;);
	CHKiRet(sendMsg(pWrkrData, (void *)(pWrkrData-&gt;darwinBody.buffer), pWrkrData-&gt;darwinBody.bufferMsgSize));

	/* there is no need to wait for a response that will never come */
	if (pData-&gt;response == DARWIN_RESPONSE_SEND_NO || pData-&gt;response == DARWIN_RESPONSE_SEND_DARWIN)
	{
		DBGPRINTF(&quot;mmdarwin::doAction:: no response will be sent back &quot;
				&quot;(darwin response type is set to 'no' or 'darwin')\n&quot;);
		goto finalize_it;
	}

	darwin_filter_packet_t response;
	memset(&amp;response, 0, sizeof(response));
	DBGPRINTF(&quot;mmdarwin::doAction:: receiving from Darwin\n&quot;);
	CHKiRet(receiveMsg(pWrkrData, &amp;response, sizeof(response)));

	unsigned int certitude = response.certitude_list[0];
	DBGPRINTF(&quot;mmdarwin::doAction:: end of the transaction, certitude is %d\n&quot;, certitude);

	msgAddJSON(pMsg, (uchar *)pData-&gt;pCertitudeKey, json_object_new_int(certitude), 0, 0);

finalize_it :
	DBGPRINTF(&quot;mmdarwin::doAction:: finished processing log line\n&quot;);

ENDdoAction

NO_LEGACY_CONF_parseSelectorAct

BEGINmodExit
CODESTARTmodExit
	objRelease(glbl, CORE_COMPONENT);
ENDmodExit

BEGINqueryEtryPt
CODESTARTqueryEtryPt
CODEqueryEtryPt_STD_OMOD_QUERIES
CODEqueryEtryPt_STD_OMOD8_QUERIES
CODEqueryEtryPt_STD_CONF2_setModCnf_QUERIES
CODEqueryEtryPt_STD_CONF2_OMOD_QUERIES
CODEqueryEtryPt_STD_CONF2_QUERIES
ENDqueryEtryPt

BEGINmodInit()
CODESTARTmodInit
	/* we only support the current interface specification */
	*ipIFVersProvided = CURR_MOD_IF_VERSION;
CODEmodInit_QueryRegCFSLineHdlr
	DBGPRINTF(&quot;mmdarwin::modInit:: module compiled with rsyslog version %s.\n&quot;, VERSION);
	CHKiRet(objUse(glbl, CORE_COMPONENT));
ENDmodInit
</PRE>
</div>
  </div>
</body>
</html>
