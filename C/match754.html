<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html><head><title>Matches for imkafka.c &amp; mmdarwin.c</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for imkafka.c &amp; mmdarwin.c
      </h3>
<h1 align="center">
        11.0%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>imkafka.c (11.147012%)<th>mmdarwin.c (10.900474%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(128-150)<td><a href="#" name="0">(105-126)</a><td align="center"><font color="#ff0000">37</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(615-631)<td><a href="#" name="1">(590-609)</a><td align="center"><font color="#820000">19</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(521-538)<td><a href="#" name="2">(641-655)</a><td align="center"><font color="#590000">13</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>imkafka.c</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
/* imkafka.c
 *
 * This input plugin is a consumer for Apache Kafka.
 *
 * File begun on 2017-04-25 by alorbach
 *
 * Copyright 2008-2017 Adiscon GmbH.
 *
 * This file is part of rsyslog.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *       http://www.apache.org/licenses/LICENSE-2.0
 *       -or-
 *       see COPYING.ASL20 in the source distribution
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#include "config.h"
#include &lt;stdio.h&gt;
#include &lt;stdarg.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;assert.h&gt;
#include &lt;errno.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;pthread.h&gt;
#include &lt;sys/uio.h&gt;
#include &lt;librdkafka/rdkafka.h&gt;

#include "rsyslog.h"
#include "conf.h"
#include "syslogd-types.h"
#include "srUtils.h"
#include "template.h"
#include "module-template.h"
#include "errmsg.h"
#include "atomic.h"
#include "statsobj.h"
#include "unicode-helper.h"
#include "prop.h"
#include "ruleset.h"
#include "glbl.h"
#include "cfsysline.h"
#include "msg.h"
#include "dirty.h"

MODULE_TYPE_INPUT
MODULE_TYPE_NOKEEP
MODULE_CNFNAME("imkafka")

/* static data */
DEF_IMOD_STATIC_DATA
DEFobjCurrIf(prop)
DEFobjCurrIf(ruleset)
DEFobjCurrIf(glbl)
DEFobjCurrIf(statsobj)

/* forward references */
static void * imkafkawrkr(void *myself);


struct kafka_params {
	const char *name;
	const char *val;
};

/* Module static data */
static struct configSettings_s {
	uchar *topic;
	uchar *consumergroup;
	char *brokers;
	uchar *pszBindRuleset;
	int nConfParams;
	struct kafka_params *confParams;
} cs;

struct instanceConf_s {
	uchar *topic;
	uchar *consumergroup;
	char *brokers;
	int64_t offset;
	ruleset_t *pBindRuleset;	/* ruleset to bind listener to (use system default if unspecified) */
	uchar *pszBindRuleset;		/* default name of Ruleset to bind to */
	int bReportErrs;
	int nConfParams;
	struct kafka_params *confParams;
	int bIsConnected;
	rd_kafka_conf_t *conf;
	rd_kafka_t *rk;
	rd_kafka_topic_conf_t *topic_conf;
	int partition;
	int bIsSubscribed;
	int nMsgParsingFlags;

	struct instanceConf_s *next;
};


struct modConfData_s {
	rsconf_t *pConf;		/* our overall config object */
	uchar *topic;
	uchar *consumergroup;
	char *brokers;
	instanceConf_t *root, *tail;
	ruleset_t *pBindRuleset;	/* ruleset to bind listener to (use system default if unspecified) */
	uchar *pszBindRuleset;		/* default name of Ruleset to bind to */
};

/* global data */
pthread_attr_t wrkrThrdAttr;	/* Attribute for worker threads ; read only after startup */
static int activeKafkaworkers = 0;
/* The following structure controls the worker threads. Global data is
 * needed for their access.
 */
static struct kafkaWrkrInfo_s {
	pthread_t tid;		/* the worker's thread ID */
	instanceConf_t *inst;	/* Pointer to imkafka instance */
<a name="0"></a>} *kafkaWrkrInfo;

static modConfData_t *loadModConf = NULL;/* modConf ptr to use for the current load process */
<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>static modConfData_t *runModConf = NULL;/* modConf ptr to use for the current load process */

static prop_t *pInputName = NULL;
/* there is only one global inputName for all messages generated by this input */

/* module-global parameters */
static struct cnfparamdescr modpdescr[] = {
	{ "ruleset", eCmdHdlrGetWord, 0 },
};
static struct cnfparamblk modpblk =
	{ CNFPARAMBLK_VERSION,
	  sizeof(modpdescr)/sizeof(struct cnfparamdescr),
	  modpdescr
	};

/* input instance parameters */
static struct cnfparamdescr inppdescr[] = {
	{ "topic", eCmdHdlrString, CNFPARAM_REQUIRED },
	{ "broker", eCmdHdlrArray, 0 },
	{ "confparam", eCmdHdlrArray, 0 },
	{ "consumergroup", eCmdHdlrString, 0},
	{ "ruleset", eCmdHdlrString, 0 },
	{ "parsehostname", eCmdHdlrBinary, 0 },</b></font>
};
static struct cnfparamblk inppblk =
	{ CNFPARAMBLK_VERSION,
	  sizeof(inppdescr)/sizeof(struct cnfparamdescr),
	  inppdescr
	};

#include "im-helper.h" /* must be included AFTER the type definitions! */

/* ------------------------------ callbacks ------------------------------ */




/* ------------------------------ end callbacks ------------------------------ */

static void
kafkaLogger(const rd_kafka_t __attribute__((unused)) *rk, int level,
	    const char *fac, const char *buf)
{
	DBGPRINTF("imkafka: kafka log message [%d,%s]: %s\n",
		  level, fac, buf);
}


/* enqueue the kafka message. The provided string is
 * not freed - thuis must be done by the caller.
 */
static rsRetVal enqMsg(instanceConf_t *const __restrict__ inst,
			rd_kafka_message_t *const __restrict__ rkmessage)
{
	DEFiRet;
	smsg_t *pMsg;

	if((int)rkmessage-&gt;len == 0) {
		/* we do not process empty lines */
		FINALIZE;
	}

DBGPRINTF("imkafka: enqMsg: Msg: %.*s\n", (int)rkmessage-&gt;len, (char *)rkmessage-&gt;payload);

	CHKiRet(msgConstruct(&amp;pMsg));
	MsgSetInputName(pMsg, pInputName);
	MsgSetRawMsg(pMsg, (char*)rkmessage-&gt;payload, (int)rkmessage-&gt;len);
	MsgSetFlowControlType(pMsg, eFLOWCTL_LIGHT_DELAY);
	MsgSetRuleset(pMsg, inst-&gt;pBindRuleset);
	pMsg-&gt;msgFlags  = inst-&gt;nMsgParsingFlags;
	/* Optional Fields */
	if (rkmessage-&gt;key_len) {
		DBGPRINTF("imkafka: enqMsg: Key: %.*s\n", (int)rkmessage-&gt;key_len, (char *)rkmessage-&gt;key);
		MsgSetTAG(pMsg, (const uchar *)rkmessage-&gt;key, (int)rkmessage-&gt;key_len);
	}
	MsgSetMSGoffs(pMsg, 0);	/* we do not have a header... */

	CHKiRet(submitMsg2(pMsg));

finalize_it:
	RETiRet;
}

/**
 * Handle Kafka Consumer Loop until all msgs are processed
 */
static void msgConsume (instanceConf_t *inst) {
	rd_kafka_message_t *rkmessage = NULL;

	do { /* Consume messages */
		rkmessage = rd_kafka_consumer_poll(inst-&gt;rk, 1000); /* Block for 1000 ms max */
		if(rkmessage == NULL) {
			DBGPRINTF("imkafka: msgConsume EMPTY Loop on %s/%s/%s\n",
				inst-&gt;topic, inst-&gt;consumergroup, inst-&gt;brokers);
			goto done;
		}

		if (rkmessage-&gt;err) {
			if (rkmessage-&gt;err == RD_KAFKA_RESP_ERR__PARTITION_EOF) {
				/* not an error, just a regular status! */
				DBGPRINTF("imkafka: Consumer "
					"reached end of topic \"%s\" [%"PRId32"]"
					"message queue offset %"PRId64"\n",
					rd_kafka_topic_name(rkmessage-&gt;rkt),
					rkmessage-&gt;partition,
					rkmessage-&gt;offset);
				goto done;
			}
			if (rkmessage-&gt;rkt) {
				LogError(0, RS_RET_KAFKA_ERROR,
				"imkafka: Consumer error for topic \"%s\" [%"PRId32"]"
				"message queue offset %"PRId64": %s\n",
					rd_kafka_topic_name(rkmessage-&gt;rkt),
					rkmessage-&gt;partition,
					rkmessage-&gt;offset,
					rd_kafka_message_errstr(rkmessage));
			} else {
				LogError(0, RS_RET_KAFKA_ERROR,
					"imkafka: Consumer error for topic \"%s\": \"%s\"\n",
					rd_kafka_err2str(rkmessage-&gt;err),
					rd_kafka_message_errstr(rkmessage));
			}
			goto done;
		}

		DBGPRINTF("imkafka: msgConsume Loop on %s/%s/%s: [%"PRId32"], "
					"offset %"PRId64", %zd bytes):\n",
					rd_kafka_topic_name(rkmessage-&gt;rkt) /*inst-&gt;topic*/,
					inst-&gt;consumergroup,
					inst-&gt;brokers,
					rkmessage-&gt;partition,
					rkmessage-&gt;offset,
					rkmessage-&gt;len);
		enqMsg(inst, rkmessage);
		/* Destroy message and continue */
		rd_kafka_message_destroy(rkmessage);
		rkmessage = NULL;
	} while(1); /* loop broken inside */
done:
	/* Destroy message in case rkmessage-&gt;err was set */
	if(rkmessage != NULL) {
		rd_kafka_message_destroy(rkmessage);
	}
	return;
}



/* create input instance, set default parameters, and
 * add it to the list of instances.
 */
static rsRetVal
createInstance(instanceConf_t **pinst)
{
	instanceConf_t *inst;
	DEFiRet;
	CHKmalloc(inst = malloc(sizeof(instanceConf_t)));
	inst-&gt;next = NULL;

	inst-&gt;brokers = NULL;
	inst-&gt;topic = NULL;
	inst-&gt;consumergroup = NULL;
	inst-&gt;pszBindRuleset = NULL;
	inst-&gt;nConfParams = 0;
	inst-&gt;confParams = NULL;
	inst-&gt;pBindRuleset = NULL;
	inst-&gt;bReportErrs = 1; /* Fixed for now */
	inst-&gt;nMsgParsingFlags = NEEDS_PARSING;
	inst-&gt;bIsConnected = 0;
	inst-&gt;bIsSubscribed = 0;
	/* Kafka objects */
	inst-&gt;conf = NULL;
	inst-&gt;rk = NULL;
	inst-&gt;topic_conf = NULL;
	inst-&gt;partition = RD_KAFKA_PARTITION_UA;

	/* node created, let's add to config */
	if(loadModConf-&gt;tail == NULL) {
		loadModConf-&gt;tail = loadModConf-&gt;root = inst;
	} else {
		loadModConf-&gt;tail-&gt;next = inst;
		loadModConf-&gt;tail = inst;
	}

	*pinst = inst;
finalize_it:
	RETiRet;
}

/* this function checks instance parameters and does some required pre-processing
 */
static rsRetVal ATTR_NONNULL()
checkInstance(instanceConf_t *const inst)
{
	DEFiRet;
	char kafkaErrMsg[1024];

	/* main kafka conf */
	inst-&gt;conf = rd_kafka_conf_new();
	if(inst-&gt;conf == NULL) {
		if(inst-&gt;bReportErrs) {
			LogError(0, RS_RET_KAFKA_ERROR,
				"imkafka: error creating kafka conf obj: %s\n",
				rd_kafka_err2str(rd_kafka_last_error()));
		}
		ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
	}

#	ifdef DEBUG
	/* enable kafka debug output */
	if(rd_kafka_conf_set(inst-&gt;conf, "debug", RD_KAFKA_DEBUG_CONTEXTS,
		kafkaErrMsg, sizeof(kafkaErrMsg)) != RD_KAFKA_CONF_OK) {
		LogError(0, RS_RET_KAFKA_ERROR, "imkafka: error setting kafka debug option: %s\n", kafkaErrMsg);
		/* DO NOT ABORT IN THIS CASE! */
	}
#	endif

	/* Set custom configuration parameters */
	for(int i = 0 ; i &lt; inst-&gt;nConfParams ; ++i) {
		assert(inst-&gt;confParams+i != NULL); /* invariant: nConfParams MUST exist! */
		DBGPRINTF("imkafka: setting custom configuration parameter: %s:%s\n",
			inst-&gt;confParams[i].name,
			inst-&gt;confParams[i].val);
		if(rd_kafka_conf_set(inst-&gt;conf,
			inst-&gt;confParams[i].name,
			inst-&gt;confParams[i].val,
			kafkaErrMsg, sizeof(kafkaErrMsg)) != RD_KAFKA_CONF_OK) {
			if(inst-&gt;bReportErrs) {
				LogError(0, RS_RET_PARAM_ERROR, "error setting custom configuration "
					"parameter '%s=%s': %s",
					inst-&gt;confParams[i].name,
					inst-&gt;confParams[i].val, kafkaErrMsg);
			} else {
				DBGPRINTF("imkafka: error setting custom configuration parameter '%s=%s': %s",
					inst-&gt;confParams[i].name,
					inst-&gt;confParams[i].val, kafkaErrMsg);
			}
			ABORT_FINALIZE(RS_RET_PARAM_ERROR);
		}
	}

	/* Topic configuration */
	inst-&gt;topic_conf = rd_kafka_topic_conf_new();

	/* Assign kafka group id */
	if (inst-&gt;consumergroup != NULL) {
		DBGPRINTF("imkafka: setting consumergroup: '%s'\n", inst-&gt;consumergroup);
		if (rd_kafka_conf_set(inst-&gt;conf, "group.id", (char*) inst-&gt;consumergroup,
			kafkaErrMsg, sizeof(kafkaErrMsg)) != RD_KAFKA_CONF_OK) {
			if(inst-&gt;bReportErrs) {
				LogError(0, RS_RET_KAFKA_ERROR,
					"imkafka: error assigning consumergroup %s to "
					"kafka config: %s\n", inst-&gt;consumergroup,
					kafkaErrMsg);
			}
			ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
		}


		/* Set default for auto offset reset */
		if (rd_kafka_topic_conf_set(inst-&gt;topic_conf, "auto.offset.reset",
			"smallest", kafkaErrMsg, sizeof(kafkaErrMsg)) != RD_KAFKA_CONF_OK) {
			if(inst-&gt;bReportErrs) {
				LogError(0, RS_RET_KAFKA_ERROR,
					"imkafka: error setting kafka auto.offset.reset on %s: %s\n",
					inst-&gt;consumergroup,
					kafkaErrMsg);
			}
			ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
		}
		/* Consumer groups always use broker based offset storage */
		if (rd_kafka_topic_conf_set(inst-&gt;topic_conf, "offset.store.method",
			"broker", kafkaErrMsg, sizeof(kafkaErrMsg)) != RD_KAFKA_CONF_OK) {
			if(inst-&gt;bReportErrs) {
				LogError(0, RS_RET_KAFKA_ERROR,
					"imkafka: error setting kafka offset.store.method on %s: %s\n",
					inst-&gt;consumergroup,
					kafkaErrMsg);
			}
			ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
		}

		/* Set default topic config for pattern-matched topics. */
		rd_kafka_conf_set_default_topic_conf(inst-&gt;conf, inst-&gt;topic_conf);
	}

	#if RD_KAFKA_VERSION &gt;= 0x00090001
		rd_kafka_conf_set_log_cb(inst-&gt;conf, kafkaLogger);
	#endif

	/* Create Kafka Consumer */
	inst-&gt;rk = rd_kafka_new(RD_KAFKA_CONSUMER, inst-&gt;conf,
				     kafkaErrMsg, sizeof(kafkaErrMsg));
	if(inst-&gt;rk == NULL) {
		if(inst-&gt;bReportErrs) {
			LogError(0, RS_RET_KAFKA_ERROR,
				"imkafka: error creating kafka handle: %s\n", kafkaErrMsg);
		}
		ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
	}
	#if RD_KAFKA_VERSION &lt; 0x00090001
		rd_kafka_set_logger(inst-&gt;rk, kafkaLogger);
	#endif

	DBGPRINTF("imkafka: setting brokers: '%s'\n", inst-&gt;brokers);
	if(rd_kafka_brokers_add(inst-&gt;rk, (char*)inst-&gt;brokers) == 0) {
		if(inst-&gt;bReportErrs) {
			LogError(0, RS_RET_KAFKA_NO_VALID_BROKERS,
				"imkafka: no valid brokers specified: %s", inst-&gt;brokers);
		}
		ABORT_FINALIZE(RS_RET_KAFKA_NO_VALID_BROKERS);
	}

	/* Kafka Consumer is opened */
	inst-&gt;bIsConnected = 1;

finalize_it:
	if(iRet != RS_RET_OK) {
		if(inst-&gt;rk == NULL) {
			if(inst-&gt;conf != NULL) {
				rd_kafka_conf_destroy(inst-&gt;conf);
				inst-&gt;conf = NULL;
			}
		} else { /* inst-&gt;rk != NULL ! */
			rd_kafka_destroy(inst-&gt;rk);
			inst-&gt;rk = NULL;
		}
	}

	RETiRet;
}

/* function to generate an error message if the ruleset cannot be found */
static inline void
std_checkRuleset_genErrMsg(__attribute__((unused)) modConfData_t *modConf, instanceConf_t *inst)
{
	if(inst-&gt;bReportErrs) {
		LogError(0, NO_ERRCODE, "imkafka: ruleset '%s' not found - "
			"using default ruleset instead",
			inst-&gt;pszBindRuleset);
	}
}


static rsRetVal ATTR_NONNULL(2)
addConsumer(modConfData_t __attribute__((unused)) *modConf, instanceConf_t *inst)
{
	DEFiRet;
	rd_kafka_resp_err_t err;

	assert(inst != NULL);

	rd_kafka_topic_partition_list_t *topics = NULL;
	DBGPRINTF("imkafka: creating kafka consumer on %s/%s/%s\n",
		inst-&gt;topic, inst-&gt;consumergroup, inst-&gt;brokers);

	/* Redirect rd_kafka_poll() to consumer_poll() */
	rd_kafka_poll_set_consumer(inst-&gt;rk);

	topics = rd_kafka_topic_partition_list_new(1);
	rd_kafka_topic_partition_list_add(topics, (const char*)inst-&gt;topic, inst-&gt;partition);
	DBGPRINTF("imkafka: Created topics(%d) for %s)\n",
		topics-&gt;cnt, inst-&gt;topic);
	if ((err = rd_kafka_subscribe(inst-&gt;rk, topics))) {
		/* Subscription failed */
		inst-&gt;bIsSubscribed = 0;
		LogError(0, RS_RET_KAFKA_ERROR, "imkafka: Failed to start consuming "
			"topics: %s\n", rd_kafka_err2str(err));
		ABORT_FINALIZE(RS_RET_KAFKA_ERROR);
	} else {
		DBGPRINTF("imkafka: Successfully subscribed to %s/%s/%s\n",
			inst-&gt;topic, inst-&gt;consumergroup, inst-&gt;brokers);
		/* Subscription is working */
		inst-&gt;bIsSubscribed = 1;
	}
finalize_it:
	if(topics != NULL)
		rd_kafka_topic_partition_list_destroy(topics);
	RETiRet;
}

static rsRetVal ATTR_NONNULL()
processKafkaParam(char *const param,
	const char **const name,
	const char **const paramval)
{
	DEFiRet;
	char *val = strstr(param, "=");
	if(val == NULL) {
		LogError(0, RS_RET_PARAM_ERROR, "missing equal sign in "
<a name="2"></a>				"parameter '%s'", param);
		ABORT_FINALIZE(RS_RET_PARAM_ERROR);
	}
<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>	*val = '\0'; /* terminates name */
	++val; /* now points to begin of value */
	CHKmalloc(*name = strdup(param));
	CHKmalloc(*paramval = strdup(val));
finalize_it:
	RETiRet;
}

BEGINnewInpInst
	struct cnfparamvals *pvals;
	instanceConf_t *inst;
	int i;
CODESTARTnewInpInst
	DBGPRINTF("newInpInst (imkafka)\n");

	if((pvals = nvlstGetParams(lst, &amp;inppblk, NULL)) == NULL) {
		ABORT_FINALIZE(RS_RET_MISSING_CNFPARAMS);
	}</b></font>

	if(Debug) {
		dbgprintf("input param blk in imkafka:\n");
		cnfparamsPrint(&amp;inppblk, pvals);
	}

	CHKiRet(createInstance(&amp;inst));

	for(i = 0 ; i &lt; inppblk.nParams ; ++i) {
		if(!pvals[i].bUsed)
			continue;
		if(!strcmp(inppblk.descr[i].name, "broker")) {
			es_str_t *es = es_newStr(128);
			int bNeedComma = 0;
			for(int j = 0 ; j &lt;  pvals[i].val.d.ar-&gt;nmemb ; ++j) {
				if(bNeedComma)
					es_addChar(&amp;es, ',');
				es_addStr(&amp;es, pvals[i].val.d.ar-&gt;arr[j]);
				bNeedComma = 1;
			}
			inst-&gt;brokers = es_str2cstr(es, NULL);
			es_deleteStr(es);
		} else if(!strcmp(inppblk.descr[i].name, "confparam")) {
			inst-&gt;nConfParams = pvals[i].val.d.ar-&gt;nmemb;
			CHKmalloc(inst-&gt;confParams = malloc(sizeof(struct kafka_params)*inst-&gt;nConfParams));
			for(int j = 0; j &lt; inst-&gt;nConfParams; j++) {
				char *cstr = es_str2cstr(pvals[i].val.d.ar-&gt;arr[j], NULL);
				CHKiRet(processKafkaParam(cstr, &amp;inst-&gt;confParams[j].name,
								&amp;inst-&gt;confParams[j].val));
				free(cstr);
			}
		} else if(!strcmp(inppblk.descr[i].name, "topic")) {
			inst-&gt;topic = (uchar*)es_str2cstr(pvals[i].val.d.estr, NULL);
		} else if(!strcmp(inppblk.descr[i].name, "consumergroup")) {
			inst-&gt;consumergroup = (uchar*)es_str2cstr(pvals[i].val.d.estr, NULL);
		} else if(!strcmp(inppblk.descr[i].name, "ruleset")) {
			inst-&gt;pszBindRuleset = (uchar*)es_str2cstr(pvals[i].val.d.estr, NULL);
		} else if(!strcmp(inppblk.descr[i].name, "parsehostname")) {
			if (pvals[i].val.d.n) {
				inst-&gt;nMsgParsingFlags = NEEDS_PARSING | PARSE_HOSTNAME;
			} else {
				inst-&gt;nMsgParsingFlags = NEEDS_PARSING;
			}
		} else {
			dbgprintf("imkafka: program error, non-handled "
			  "param '%s'\n", inppblk.descr[i].name);
		}
	}

	if(inst-&gt;brokers == NULL) {
		CHKmalloc(inst-&gt;brokers = strdup("localhost:9092"));
		LogMsg(0, NO_ERRCODE, LOG_INFO, "imkafka: \"broker\" parameter not specified "
			"using default of localhost:9092 -- this may not be what you want!");
	}

	DBGPRINTF("imkafka: newInpIns brokers=%s, topic=%s, consumergroup=%s\n",
		inst-&gt;brokers, inst-&gt;topic, inst-&gt;consumergroup);

finalize_it:
CODE_STD_FINALIZERnewInpInst
	cnfparamvalsDestruct(pvals, &amp;inppblk);
ENDnewInpInst


BEGINbeginCnfLoad
CODESTARTbeginCnfLoad
	loadModConf = pModConf;
	pModConf-&gt;pConf = pConf;
	pModConf-&gt;pszBindRuleset = NULL;
ENDbeginCnfLoad


BEGINsetModCnf
<a name="1"></a>	struct cnfparamvals *pvals = NULL;
	int i;
CODESTARTsetModCnf
<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>	pvals = nvlstGetParams(lst, &amp;modpblk, NULL);
	if(pvals == NULL) {
		LogError(0, RS_RET_MISSING_CNFPARAMS, "imkafka: error processing module "
			"config parameters [module(...)]");
		ABORT_FINALIZE(RS_RET_MISSING_CNFPARAMS);
	}

	if(Debug) {
		dbgprintf("module (global) param blk for imkafka:\n");
		cnfparamsPrint(&amp;modpblk, pvals);
	}

	for(i = 0 ; i &lt; modpblk.nParams ; ++i) {
		if(!pvals[i].bUsed)
			continue;
		if(!strcmp(modpblk.descr[i].name, "ruleset")) {
			loadModConf-&gt;pszBindRuleset = (uchar*)es_str2cstr(pvals[i].val.d.estr, NULL);</b></font>
		} else {
			dbgprintf("imkafka: program error, non-handled "
			  "param '%s' in beginCnfLoad\n", modpblk.descr[i].name);
		}
	}
finalize_it:
	if(pvals != NULL)
		cnfparamvalsDestruct(pvals, &amp;modpblk);
ENDsetModCnf

BEGINendCnfLoad
CODESTARTendCnfLoad
	if(loadModConf-&gt;pszBindRuleset == NULL) {
		if((cs.pszBindRuleset == NULL) || (cs.pszBindRuleset[0] == '\0')) {
			loadModConf-&gt;pszBindRuleset = NULL;
		} else {
			CHKmalloc(loadModConf-&gt;pszBindRuleset = ustrdup(cs.pszBindRuleset));
		}
	}
finalize_it:
	free(cs.pszBindRuleset);
	cs.pszBindRuleset = NULL;
	loadModConf = NULL; /* done loading */
ENDendCnfLoad

BEGINcheckCnf
	instanceConf_t *inst;
CODESTARTcheckCnf
	for(inst = pModConf-&gt;root ; inst != NULL ; inst = inst-&gt;next) {
		if(inst-&gt;pszBindRuleset == NULL &amp;&amp; pModConf-&gt;pszBindRuleset != NULL) {
			CHKmalloc(inst-&gt;pszBindRuleset = ustrdup(pModConf-&gt;pszBindRuleset));
		}
		std_checkRuleset(pModConf, inst);
	}
finalize_it:
ENDcheckCnf


BEGINactivateCnfPrePrivDrop
CODESTARTactivateCnfPrePrivDrop
	runModConf = pModConf;
ENDactivateCnfPrePrivDrop

BEGINactivateCnf
CODESTARTactivateCnf
	for(instanceConf_t *inst = pModConf-&gt;root ; inst != NULL ; inst = inst-&gt;next) {
		iRet = checkInstance(inst);
	}
ENDactivateCnf


BEGINfreeCnf
	instanceConf_t *inst, *del;
CODESTARTfreeCnf
	for(inst = pModConf-&gt;root ; inst != NULL ; ) {
		free(inst-&gt;topic);
		free(inst-&gt;consumergroup);
		free(inst-&gt;brokers);
		free(inst-&gt;pszBindRuleset);
		for(int i = 0; i &lt; inst-&gt;nConfParams; i++) {
			free((void*)inst-&gt;confParams[i].name);
			free((void*)inst-&gt;confParams[i].val);
		}
		free((void*)inst-&gt;confParams);
		del = inst;
		inst = inst-&gt;next;
		free(del);
	}
	free(pModConf-&gt;pszBindRuleset);
ENDfreeCnf


/* Cleanup imkafka worker threads */
static void
shutdownKafkaWorkers(void)
{
	int i;
	instanceConf_t *inst;

	assert(kafkaWrkrInfo != NULL);

	DBGPRINTF("imkafka: waiting on imkafka workerthread termination\n");
	for(i = 0 ; i &lt; activeKafkaworkers ; ++i) {
		pthread_join(kafkaWrkrInfo[i].tid, NULL);
		DBGPRINTF("imkafka: Stopped worker %d\n", i);
	}
	free(kafkaWrkrInfo);
	kafkaWrkrInfo = NULL;

	for(inst = runModConf-&gt;root ; inst != NULL ; inst = inst-&gt;next) {
		DBGPRINTF("imkafka: stop consuming %s/%s/%s\n",
			inst-&gt;topic, inst-&gt;consumergroup, inst-&gt;brokers);
		rd_kafka_consumer_close(inst-&gt;rk); /* Close the consumer, committing final offsets, etc. */
		rd_kafka_destroy(inst-&gt;rk); /* Destroy handle object */
		DBGPRINTF("imkafka: stopped consuming %s/%s/%s\n",
			inst-&gt;topic, inst-&gt;consumergroup, inst-&gt;brokers);

		#if RD_KAFKA_VERSION &lt; 0x00090001
		/* Wait for kafka being destroyed in old API */
		if (rd_kafka_wait_destroyed(10000) &lt; 0)	{
			DBGPRINTF("imkafka: error, rd_kafka_destroy did not finish after grace "
				"timeout (10s)!\n");
		} else {
			DBGPRINTF("imkafka: rd_kafka_destroy successfully finished\n");
		}
		#endif
	}
}


/* This function is called to gather input.  */
BEGINrunInput
	int i;
	instanceConf_t *inst;
CODESTARTrunInput
	DBGPRINTF("imkafka: runInput loop started ...\n");
	activeKafkaworkers = 0;
	for(inst = runModConf-&gt;root ; inst != NULL ; inst = inst-&gt;next) {
		if(inst-&gt;rk != NULL) {
			++activeKafkaworkers;
		}
	}

	if(activeKafkaworkers == 0) {
		LogError(0, RS_RET_ERR, "imkafka: no active inputs, input does "
			"not run - there should have been additional error "
			"messages given previously");
		ABORT_FINALIZE(RS_RET_ERR);
	}


	DBGPRINTF("imkafka: Starting %d imkafka workerthreads\n", activeKafkaworkers);
	kafkaWrkrInfo = calloc(activeKafkaworkers, sizeof(struct kafkaWrkrInfo_s));
	if (kafkaWrkrInfo == NULL) {
		LogError(errno, RS_RET_OUT_OF_MEMORY, "imkafka: worker-info array allocation failed.");
		ABORT_FINALIZE(RS_RET_OUT_OF_MEMORY);
	}

	/* Start worker threads for each imkafka input source
	*/
	i = 0;
	for(inst = runModConf-&gt;root ; inst != NULL ; inst = inst-&gt;next) {
		/* init worker info structure! */
		kafkaWrkrInfo[i].inst = inst; /* Set reference pointer */
		pthread_create(&amp;kafkaWrkrInfo[i].tid, &amp;wrkrThrdAttr, imkafkawrkr, &amp;(kafkaWrkrInfo[i]));
		i++;
	}

	while(glbl.GetGlobalInputTermState() == 0) {

		/* Note: the additional 10000ns wait is vitally important. It guards rsyslog
		 * against totally hogging the CPU if the users selects a polling interval
		 * of 0 seconds. It doesn't hurt any other valid scenario. So do not remove.
		 */
		if(glbl.GetGlobalInputTermState() == 0)
			srSleep(0, 100000);
	}
	DBGPRINTF("imkafka: terminating upon request of rsyslog core\n");

	/* we need to shutdown kafak worker threads here because this operation can
	 * potentially block (e.g. when no kafka broker is available!). If this
	 * happens in runInput, the rsyslog core can cancel our thread. However,
	 * in afterRun this is not possible, because the core does not assume it
	 * can block there. -- rgerhards, 2018-10-23
	 */
	shutdownKafkaWorkers();
finalize_it:
ENDrunInput


BEGINwillRun
CODESTARTwillRun
	/* we need to create the inputName property (only once during our lifetime) */
	CHKiRet(prop.Construct(&amp;pInputName));
	CHKiRet(prop.SetString(pInputName, UCHAR_CONSTANT("imkafka"), sizeof("imkafka") - 1));
	CHKiRet(prop.ConstructFinalize(pInputName));
finalize_it:
ENDwillRun


BEGINafterRun
CODESTARTafterRun
	if(pInputName != NULL)
		prop.Destruct(&amp;pInputName);

ENDafterRun


BEGINmodExit
CODESTARTmodExit
	pthread_attr_destroy(&amp;wrkrThrdAttr);
	/* release objects we used */
	objRelease(statsobj, CORE_COMPONENT);
	objRelease(ruleset, CORE_COMPONENT);
	objRelease(glbl, CORE_COMPONENT);
	objRelease(prop, CORE_COMPONENT);
ENDmodExit


BEGINisCompatibleWithFeature
CODESTARTisCompatibleWithFeature
	if(eFeat == sFEATURENonCancelInputTermination)
		iRet = RS_RET_OK;
ENDisCompatibleWithFeature


BEGINqueryEtryPt
CODESTARTqueryEtryPt
CODEqueryEtryPt_STD_IMOD_QUERIES
CODEqueryEtryPt_STD_CONF2_QUERIES
CODEqueryEtryPt_STD_CONF2_PREPRIVDROP_QUERIES
CODEqueryEtryPt_STD_CONF2_IMOD_QUERIES
CODEqueryEtryPt_STD_CONF2_setModCnf_QUERIES
CODEqueryEtryPt_IsCompatibleWithFeature_IF_OMOD_QUERIES
ENDqueryEtryPt


BEGINmodInit()
CODESTARTmodInit
	*ipIFVersProvided = CURR_MOD_IF_VERSION;
CODEmodInit_QueryRegCFSLineHdlr
	/* request objects we use */
	CHKiRet(objUse(glbl, CORE_COMPONENT));
	CHKiRet(objUse(prop, CORE_COMPONENT));
	CHKiRet(objUse(ruleset, CORE_COMPONENT));
	CHKiRet(objUse(statsobj, CORE_COMPONENT));

	/* initialize "read-only" thread attributes */
	pthread_attr_init(&amp;wrkrThrdAttr);
	pthread_attr_setstacksize(&amp;wrkrThrdAttr, 4096*1024);

	DBGPRINTF("imkafka %s using librdkafka version %s, 0x%x\n",
		VERSION, rd_kafka_version_str(), rd_kafka_version());
ENDmodInit

/*
*	Workerthread function for a single kafka consomer
 */
static void *
imkafkawrkr(void *myself)
{
	struct kafkaWrkrInfo_s *me = (struct kafkaWrkrInfo_s*) myself;
	DBGPRINTF("imkafka: started kafka consumer workerthread on %s/%s/%s\n",
		me-&gt;inst-&gt;topic, me-&gt;inst-&gt;consumergroup, me-&gt;inst-&gt;brokers);

	do {
		if(glbl.GetGlobalInputTermState() == 1)
			break; /* terminate input! */

		if(me-&gt;inst-&gt;rk == NULL) {
			continue;
		}

		// Try to add consumer only if connected! */
		if(me-&gt;inst-&gt;bIsConnected == 1 &amp;&amp; me-&gt;inst-&gt;bIsSubscribed == 0 ) {
			addConsumer(runModConf, me-&gt;inst);
		}
		if(me-&gt;inst-&gt;bIsSubscribed == 1 ) {
			msgConsume(me-&gt;inst);
		}
		/* Note: the additional 10000ns wait is vitally important. It guards rsyslog
		 * against totally hogging the CPU if the users selects a polling interval
		 * of 0 seconds. It doesn't hurt any other valid scenario. So do not remove.
		 * rgerhards, 2008-02-14
		 */
		if(glbl.GetGlobalInputTermState() == 0)
			srSleep(0, 100000);
	} while(glbl.GetGlobalInputTermState() == 0);

	DBGPRINTF("imkafka: stopped kafka consumer workerthread on %s/%s/%s\n",
		me-&gt;inst-&gt;topic, me-&gt;inst-&gt;consumergroup, me-&gt;inst-&gt;brokers);
	return NULL;
}
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>mmdarwin.c</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
/* Copyright 2019 Advens
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "config.h"
#include "rsyslog.h"
#include &lt;stdio.h&gt;
#include &lt;stdarg.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;assert.h&gt;
#include &lt;signal.h&gt;
#include &lt;errno.h&gt;
#include &lt;unistd.h&gt;
#include &lt;stdint.h&gt;
#include &lt;pthread.h&gt;
#include "conf.h"
#include "syslogd-types.h"
#include "srUtils.h"
#include "template.h"
#include "module-template.h"
#include "errmsg.h"
#include "parserif.h"
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/un.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;uuid/uuid.h&gt;
#include &lt;json.h&gt;

#include "protocol.h" /* custom file written for Darwin */

#define JSON_DEFAULT_CONTAINER "!mmdarwin"
#define JSON_DARWIN_ID "darwin_id"
#define INVLD_SOCK -1
#define INITIAL_BUFFER_SIZE 32
#define BUFFER_DEFAULT_MAX_SIZE 65536

MODULE_TYPE_OUTPUT
MODULE_TYPE_NOKEEP
MODULE_CNFNAME("mmdarwin")

DEFobjCurrIf(glbl)
DEF_OMOD_STATIC_DATA

typedef struct dyn_buffer_t
{
	char *buffer;
	size_t bufferAllocSize;
	size_t bufferMsgSize;
	size_t bufferMaxSize;
} dyn_buffer;

/* config variables */
typedef struct _instanceData
{
	char *pUUIDKey;					/* the key to the UUID generated by an mmdarwin instance */
	char *pCertitudeKey;				/* the key name to save in the enriched log
							   line the certitude obtained from Darwin */
	uchar *pSockName;				/* the socket path of the filter which will be used by
							   Darwin */
	unsigned long long int filterCode;		/* the filter code associated to the filter which will be used
							   by Darwin */
	enum darwin_filter_response_type response;	/* the type of response for Darwin: no / back / darwin / both */
	struct
	{
		int nmemb;
		char **name;
		char **varname;
	} fieldList; /* our keys (fields) to be extracted from the JSON-parsed log line */
	unsigned int socketMaxUse;
	sbool sendPartial;
} instanceData;

typedef struct wrkrInstanceData
{
	instanceData *pData;
	int sock;				 /* the socket of the filter which will be used by Darwin */
	struct sockaddr_un addr; /* the sockaddr_un used to connect to the Darwin filter */
	uint8_t pktSentSocket;
	dyn_buffer darwinBody; /* the body object used (and reused) to hold data to send to Darwin */
	dyn_buffer fieldBuffer;
} wrkrInstanceData_t;

struct modConfData_s
{
	/* our overall config object */
	rsconf_t *pConf;
	const char *container;
<a name="0"></a>};

/* modConf ptr to use for the current load process */
<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>static modConfData_t *loadModConf = NULL;
/* modConf ptr to use for the current exec process */
static modConfData_t *runModConf = NULL;

/* module-global parameters */
static struct cnfparamdescr modpdescr[] = {
	{"container", eCmdHdlrGetWord, 0},
};
static struct cnfparamblk modpblk =
	{CNFPARAMBLK_VERSION,
	 sizeof(modpdescr) / sizeof(struct cnfparamdescr),
	 modpdescr};

/* tables for interfacing with the v6 config system
 * action (instance) parameters */
static struct cnfparamdescr actpdescr[] = {
	{"key", eCmdHdlrGetWord, CNFPARAM_REQUIRED},
	{"socketpath", eCmdHdlrGetWord, CNFPARAM_REQUIRED},
	{"fields", eCmdHdlrArray, CNFPARAM_REQUIRED},
	{"filtercode", eCmdHdlrGetWord, 0},			/* optional parameter */
	{"response", eCmdHdlrGetWord, 0},			/* optional parameter */
	{"send_partial", eCmdHdlrBinary, 0},		/* optional parameter */</b></font>
	{"socket_max_use", eCmdHdlrNonNegInt, 0}, /* optional parameter - will disappear in future updates */
};
static struct cnfparamblk actpblk = {
	CNFPARAMBLK_VERSION,
	sizeof(actpdescr) / sizeof(struct cnfparamdescr),
	actpdescr};

/* custom functions */
#define min(a, b) \
	({ __typeof__ (a) _a = (a); \
	__typeof__ (b) _b = (b); \
	_a &lt; _b ? _a : _b; })

static rsRetVal openSocket(wrkrInstanceData_t *pWrkrData);
static rsRetVal closeSocket(wrkrInstanceData_t *pWrkrData);
static rsRetVal doTryResume(wrkrInstanceData_t *pWrkrData);

static rsRetVal sendMsg(wrkrInstanceData_t *pWrkrData, void *msg, size_t len);
static rsRetVal receiveMsg(wrkrInstanceData_t *pWrkrData, void *response, size_t len);

const char* get_uuid_object(smsg_t *const pMsg);
int get_field(smsg_t *const pMsg, const char *pFieldName, char **ppRetString);
int expand_buffer(dyn_buffer *pBody, size_t new_size);
int add_field_to_body(dyn_buffer *pBody, const char *field, size_t size);
int start_new_line(dyn_buffer *pBody);
int end_body(dyn_buffer *pBody);

/* open socket to remote system
 */
static rsRetVal openSocket(wrkrInstanceData_t *pWrkrData)
{
	DEFiRet;
	assert(pWrkrData-&gt;sock == INVLD_SOCK);

	if ((pWrkrData-&gt;sock = socket(AF_UNIX, SOCK_STREAM, 0)) == -1)
	{
		char errStr[1024];
		int eno = errno;
		DBGPRINTF("mmdarwin::openSocket:: error %d creating AF_UNIX/SOCK_STREAM: %s.\n",
				  eno, rs_strerror_r(eno, errStr, sizeof(errStr)));
		pWrkrData-&gt;sock = INVLD_SOCK;
		ABORT_FINALIZE(RS_RET_NO_SOCKET);
	}

	memset(&amp;pWrkrData-&gt;addr, 0, sizeof(struct sockaddr_un));
	pWrkrData-&gt;addr.sun_family = AF_UNIX;
	strncpy(pWrkrData-&gt;addr.sun_path, (char *)pWrkrData-&gt;pData-&gt;pSockName, sizeof(pWrkrData-&gt;addr.sun_path) - 1);

	DBGPRINTF("mmdarwin::openSocket:: connecting to Darwin...\n");

	if (connect(pWrkrData-&gt;sock, (struct sockaddr *)&amp;pWrkrData-&gt;addr, sizeof(struct sockaddr_un)) == -1)
	{
		LogError(errno, RS_RET_NO_SOCKET, "mmdarwin::openSocket:: error connecting to Darwin "
										  "via socket '%s'",
				 pWrkrData-&gt;pData-&gt;pSockName);

		pWrkrData-&gt;sock = INVLD_SOCK;
		ABORT_FINALIZE(RS_RET_NO_SOCKET);
	}

	DBGPRINTF("mmdarwin::openSocket:: connected !\n");
finalize_it:
	if (iRet != RS_RET_OK)
	{
		closeSocket(pWrkrData);
	}
	RETiRet;
}

/* close socket to remote system
 */
static rsRetVal closeSocket(wrkrInstanceData_t *pWrkrData)
{
	DEFiRet;
	if (pWrkrData-&gt;sock != INVLD_SOCK)
	{
		if (close(pWrkrData-&gt;sock) != 0)
		{
			char errStr[1024];
			int eno = errno;
			DBGPRINTF("mmdarwin::closeSocket:: error %d closing the socket: %s.\n",
					  eno, rs_strerror_r(eno, errStr, sizeof(errStr)));
		}
		pWrkrData-&gt;sock = INVLD_SOCK;
	}
	RETiRet;
}

/* try to resume connection if it is not ready
 */
static rsRetVal doTryResume(wrkrInstanceData_t *pWrkrData)
{
	DEFiRet;

	DBGPRINTF("mmdarwin::doTryResume:: trying to resume\n");
	closeSocket(pWrkrData);
	iRet = openSocket(pWrkrData);

	if (iRet != RS_RET_OK)
	{
		iRet = RS_RET_SUSPENDED;
	}

	RETiRet;
}

/* send a message via TCP
 * inspired by rgehards, 2007-12-20
 */
static rsRetVal sendMsg(wrkrInstanceData_t *pWrkrData, void *msg, size_t len)
{
	DEFiRet;

	DBGPRINTF("mmdarwin::sendMsg:: sending message to Darwin...\n");

	if (pWrkrData-&gt;sock == INVLD_SOCK)
	{
		CHKiRet(doTryResume(pWrkrData));
	}

	if (pWrkrData-&gt;sock != INVLD_SOCK)
	{
		if (send(pWrkrData-&gt;sock, msg, len, 0) == -1)
		{
			char errStr[1024];
			DBGPRINTF("mmdarwin::sendData:: error while sending data: error[%d] -&gt; %s\n",
					  errno, rs_strerror_r(errno, errStr, sizeof(errStr)));
			iRet = RS_RET_SUSPENDED;
		}
	}

finalize_it:
	RETiRet;
}

/* receive a message via TCP
 * inspired by rgehards, 2007-12-20
 */
static rsRetVal receiveMsg(wrkrInstanceData_t *pWrkrData, void *response, size_t len)
{
	DEFiRet;

	DBGPRINTF("mmdarwin::receiveMsg:: receiving message from Darwin...\n");

	if (pWrkrData-&gt;sock == INVLD_SOCK)
	{
		CHKiRet(doTryResume(pWrkrData));
	}

	if (pWrkrData-&gt;sock != INVLD_SOCK)
	{
		if (recv(pWrkrData-&gt;sock, response, len, MSG_WAITALL) &lt;= 0)
		{
			char errStr[1024];
			DBGPRINTF("mmdarwin::receiveMsg:: error while receiving data: error[%d] -&gt; %s\n",
					  errno, rs_strerror_r(errno, errStr, sizeof(errStr)));
			iRet = RS_RET_NONE;
		}
	}

finalize_it:
	RETiRet;
}

/**
 * Get the string corresponding to a field supposedly present in the provided message
 *
 * params:
 *  - pMsg: a pointer to the rsyslog message where the field should be
 *  - pFieldName: a nul-terminated pointer to string representing the name of the field to search for
 *  - ppRetString: the pointer to contain the potential return string
 *
 * return: 1 if a string was put in ppRetString, 0 otherwise
 *
 * note: the string placed in ppRetString should be freed by the caller
 */
int get_field(smsg_t *const pMsg, const char *pFieldName, char **ppRetString)
{
	DBGPRINTF("mmdarwin::get_field:: getting key '%s' in msg\n", pFieldName);
	struct json_object *pJson = NULL;
	char *pFieldString = NULL;
	int retVal = 0;

	msgPropDescr_t propDesc;
	msgPropDescrFill(&amp;propDesc, (uchar *)pFieldName, strlen(pFieldName));
	msgGetJSONPropJSONorString(pMsg, &amp;propDesc, &amp;pJson, (uchar **)&amp;pFieldString);

	if (pFieldString)
	{
		*ppRetString = pFieldString;
		DBGPRINTF("mmdarwin::get_field:: got string\n");
		retVal = 1;
	}
	else if (pJson)
	{
		pFieldString = (char *)json_object_get_string(pJson);
		if (pFieldString)
		{
			*ppRetString = strdup(pFieldString);
			retVal = 1;
			DBGPRINTF("mmdarwin::get_field:: got string from json\n");
			json_object_put(pJson);
		}
	}

	msgPropDescrDestruct(&amp;propDesc);
	return retVal;
}

/**
 * expands the buffer object in the dyn_buffer object
 *
 * params:
 *  - pBody: a pointer to the concerned structure to expand
 *  - new_size: the new size to give to the underlying buffer
 *
 * return: 0 if the expansion was successful, -1 otherwise
 */
int expand_buffer(dyn_buffer *pBody, size_t new_size)
{
	/* return error if new_size tries to exceed max defined size */
	if (new_size &gt; pBody-&gt;bufferMaxSize)
		return -1;
	while (pBody-&gt;bufferAllocSize &lt; new_size)
		pBody-&gt;bufferAllocSize += INITIAL_BUFFER_SIZE;

	DBGPRINTF("mmdarwin::expand_buffer:: expanding buffer to %zu\n", pBody-&gt;bufferAllocSize);

	char *tmp = realloc(pBody-&gt;buffer, pBody-&gt;bufferAllocSize * sizeof(char));

	if (!tmp)
	{
		DBGPRINTF("mmdarwin::expand_buffer:: could not resize buffer\n");
		return -1;
	}

	pBody-&gt;buffer = tmp;
	return 0;
}

/**
 * adds a field to the dyn_buffer buffer
 *
 * params:
 *  - pBody: the pointer on the dyn_buffer structure
 *  - field: the potentially not null-terminated string to add as a field to the dyn_buffer
 *  - size: the size of the string (without the '\0' character)
 *
 * return: 0 if the field was indeed added to the dyn_buffer, -1 otherwise
 */
int add_field_to_body(dyn_buffer *pBody, const char *field, size_t size)
{
	/* get required additional size for field, quotes, colon, and \0
	and potentially also for the beginning of the message structure */
	int beginning = (pBody-&gt;bufferMsgSize == 0) ? 2 : 0;
	size_t requiredBodySize = pBody-&gt;bufferMsgSize + size + 4 + beginning;

	/* resize body buffer if necessary */
	if (requiredBodySize &gt; pBody-&gt;bufferAllocSize)
	{
		if (expand_buffer(pBody, requiredBodySize) != 0)
		{
			return -1;
		}
	}

	/* add message structure beginning if current message is empty */
	if (!pBody-&gt;bufferMsgSize)
	{
		pBody-&gt;buffer[0] = '[';
		pBody-&gt;buffer[1] = '[';
		pBody-&gt;bufferMsgSize += 2;
	}

	/* add field with quotes and colon */
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = '\"';
	memcpy((void *)&amp;pBody-&gt;buffer[pBody-&gt;bufferMsgSize], (const void *)field, size);
	pBody-&gt;bufferMsgSize += size;
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = '\"';
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = ',';

	return 0;
}

/**
 * small helper function to start a new input line (used for bulk-calls) in the dyn_buffer.
 * will close current line with a ']' and start the next with a '['.
 * will also remove leading ',' in fields list.
 *
 * params:
 *  - pBody: the pointer on the dyn_buffer on which to start a new input line
 *
 * return: 0 if successful, -1 otherwise
 */
int start_new_line(dyn_buffer *pBody)
{
	/* don't if the message is empty */
	if (!pBody-&gt;bufferMsgSize)
	{
		return -1;
	}

	DBGPRINTF("mmdarwin::start_new_line:: starting new line entry in body\n");

	if (pBody-&gt;bufferAllocSize &lt; pBody-&gt;bufferMsgSize + 2)
	{
		if (expand_buffer(pBody, pBody-&gt;bufferAllocSize + 2) != 0)
		{
			return -1;
		}
	}

	pBody-&gt;buffer[pBody-&gt;bufferMsgSize - 1] = ']';
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = ',';
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = '[';
	return 0;
}

/**
 * small helper function to close the dyn_buffer structure.
 * will close the line list with two ']' and will remove the leading ',' in the fields list
 *
 * params:
 *  - pBody: the pointer on the dyn_buffer on which to start a new input line
 *
 * return: 0 if successful, -1 otherwise
 */
int end_body(dyn_buffer *pBody)
{
	/* don't if the message is empty */
	if (!pBody-&gt;bufferMsgSize)
	{
		return -1;
	}

	DBGPRINTF("mmdarwin::end_body:: finishing body structure\n");

	if (pBody-&gt;bufferAllocSize &lt; pBody-&gt;bufferMsgSize + 2)
	{
		if (expand_buffer(pBody, pBody-&gt;bufferAllocSize + 2) != 0)
		{
			return -1;
		}
	}

	pBody-&gt;buffer[pBody-&gt;bufferMsgSize - 1] = ']';
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = ']';
	pBody-&gt;buffer[pBody-&gt;bufferMsgSize++] = '\0';
	return 0;
}

/**
 * Get the potential existing uuid put by previous mmdarwin call in a json
 *
 * params:
 *  - pJson: the pointer on the json
 *
 * return: a valid json_object pointer if found, NULL otherwise
 */
const char* get_uuid_object(smsg_t *const pMsg) {
	struct json_object *mmdarwin_object = NULL;
	const char *result = NULL, *key = NULL;

	msgPropDescr_t propDesc;
	msgPropDescrFill(&amp;propDesc, (uchar *)runModConf-&gt;container, strlen(runModConf-&gt;container));
	msgGetJSONPropJSON(pMsg, &amp;propDesc, &amp;mmdarwin_object);

	if(mmdarwin_object) {
		struct json_object_iterator it = json_object_iter_begin(mmdarwin_object);
		struct json_object_iterator itEnd = json_object_iter_end(mmdarwin_object);

		while(!json_object_iter_equal(&amp;it, &amp;itEnd)) {
			key = json_object_iter_peek_name(&amp;it);

			if(!strcmp(key, JSON_DARWIN_ID)) {
				// should always be a (non-empty) null-terminated string, safe to use with strdup()
				result = strdup(json_object_get_string(json_object_iter_peek_value(&amp;it)));
				break;
			}

			json_object_iter_next(&amp;it);
		}
		json_object_put(mmdarwin_object);
	}

	msgPropDescrDestruct(&amp;propDesc);
	return result;
}

BEGINbeginCnfLoad
CODESTARTbeginCnfLoad
	loadModConf = pModConf;
pModConf-&gt;pConf = pConf;
ENDbeginCnfLoad

BEGINendCnfLoad
CODESTARTendCnfLoad
ENDendCnfLoad

BEGINcheckCnf
CODESTARTcheckCnf
ENDcheckCnf

BEGINactivateCnf
CODESTARTactivateCnf
	runModConf = pModConf;
ENDactivateCnf

BEGINfreeCnf
CODESTARTfreeCnf
	free((void *)pModConf-&gt;container);
ENDfreeCnf

BEGINdbgPrintInstInfo
CODESTARTdbgPrintInstInfo
	DBGPRINTF("%s\n", pData-&gt;pSockName);
ENDdbgPrintInstInfo

BEGINcreateInstance
CODESTARTcreateInstance
ENDcreateInstance

BEGINcreateWrkrInstance
CODESTARTcreateWrkrInstance
	pWrkrData-&gt;pktSentSocket = 0;
	pWrkrData-&gt;darwinBody.bufferAllocSize = 0;
	pWrkrData-&gt;darwinBody.bufferMaxSize = BUFFER_DEFAULT_MAX_SIZE;
	pWrkrData-&gt;darwinBody.bufferMsgSize = 0;
	pWrkrData-&gt;sock = INVLD_SOCK;
ENDcreateWrkrInstance

BEGINisCompatibleWithFeature
CODESTARTisCompatibleWithFeature
ENDisCompatibleWithFeature

BEGINfreeInstance
CODESTARTfreeInstance
	if (pData-&gt;fieldList.name != NULL)
	{
		for (int i = 0; i &lt; pData-&gt;fieldList.nmemb; ++i)
		{
			free(pData-&gt;fieldList.name[i]);
			free(pData-&gt;fieldList.varname[i]);
		}
		free(pData-&gt;fieldList.name);
		free(pData-&gt;fieldList.varname);
	}
	free(pData-&gt;pUUIDKey);
	free(pData-&gt;pCertitudeKey);
	free(pData-&gt;pSockName);
ENDfreeInstance

BEGINfreeWrkrInstance
CODESTARTfreeWrkrInstance
	closeSocket(pWrkrData);
	free(pWrkrData-&gt;darwinBody.buffer);
ENDfreeWrkrInstance

BEGINsetModCnf
struct cnfparamvals *pvals = NULL;
<a name="1"></a>int i;
CODESTARTsetModCnf
	loadModConf-&gt;container = NULL;
<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>	pvals = nvlstGetParams(lst, &amp;modpblk, NULL);
	if (pvals == NULL)
	{
		LogError(0, RS_RET_MISSING_CNFPARAMS,
				"mmdarwin: error processing module config parameters missing [module(...)]");
		ABORT_FINALIZE(RS_RET_MISSING_CNFPARAMS);
	}
	if (Debug)
	{
		DBGPRINTF("mmdarwin::setModCnf:: module (global) param blk for mmdarwin:\n");
		cnfparamsPrint(&amp;modpblk, pvals);
	}

	for (i = 0; i &lt; modpblk.nParams; ++i)
	{
		if (!pvals[i].bUsed)
			continue;
		if (!strcmp(modpblk.descr[i].name, "container"))
		{
			loadModConf-&gt;container = es_str2cstr(pvals[i].val.d.estr, NULL);</b></font>
			if(loadModConf-&gt;container[0] != '!' &amp;&amp; loadModConf-&gt;container[0] != '.') {
				LogError(0, RS_RET_INVALID_PARAMS, "mmdarwin: container should either"
					" begin with '!' or '.'\n");
				ABORT_FINALIZE(RS_RET_INVALID_PARAMS);
			}
		}
		else
		{
			DBGPRINTF("mmdarwin::setModCnf:: program error, non-handled "
					"param '%s'\n",
					modpblk.descr[i].name);
		}
	}

	if (loadModConf-&gt;container == NULL)
	{
		CHKmalloc(loadModConf-&gt;container = strdup(JSON_DEFAULT_CONTAINER));
	}

finalize_it :
	if (pvals != NULL)
		cnfparamvalsDestruct(pvals, &amp;modpblk);
ENDsetModCnf

static inline void setInstParamDefaults(instanceData *pData)
{
	DBGPRINTF("mmdarwin::setInstParamDefaults::\n");
	pData-&gt;pUUIDKey = NULL;
<a name="2"></a>	pData-&gt;pCertitudeKey = NULL;
	pData-&gt;pSockName = NULL;
	pData-&gt;fieldList.nmemb = 0;
<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>	pData-&gt;filterCode = DARWIN_FILTER_CODE_NO;
	pData-&gt;response = DARWIN_RESPONSE_SEND_NO;
	pData-&gt;socketMaxUse = 0;
	pData-&gt;sendPartial = 0;
}

BEGINnewActInst
	struct cnfparamvals *pvals;
	int i;
CODESTARTnewActInst
	DBGPRINTF("mmdarwin::newActInst::\n");
	if ((pvals = nvlstGetParams(lst, &amp;actpblk, NULL)) == NULL)
	{
		ABORT_FINALIZE(RS_RET_MISSING_CNFPARAMS);
	}</b></font>

	CODE_STD_STRING_REQUESTnewActInst(1)
	CHKiRet(OMSRsetEntry(*ppOMSR, 0, NULL, OMSR_TPL_AS_MSG));
	CHKiRet(createInstance(&amp;pData));
	setInstParamDefaults(pData);

	for (i = 0; i &lt; actpblk.nParams; ++i)
	{
		if (!pvals[i].bUsed)
			continue;

		if (!strcmp(actpblk.descr[i].name, "key"))
		{
			char *key = es_str2cstr(pvals[i].val.d.estr, NULL);
			char vnamebuf[1024];
			snprintf(vnamebuf, sizeof(vnamebuf), "%s!%s", loadModConf-&gt;container, key);
			CHKmalloc(pData-&gt;pCertitudeKey = strdup(vnamebuf));
			free(key);
			DBGPRINTF("mmdarwin::newActInst:: certitudeKey is %s\n", pData-&gt;pCertitudeKey);
		}
		else if (!strcmp(actpblk.descr[i].name, "socketpath"))
		{
			pData-&gt;pSockName = (uchar *)es_str2cstr(pvals[i].val.d.estr, NULL);
			DBGPRINTF("mmdarwin::newActInst:: sockName is %s\n", pData-&gt;pSockName);
		}
		else if (!strcmp(actpblk.descr[i].name, "socket_max_use"))
		{
			pData-&gt;socketMaxUse = (uint32_t)pvals[i].val.d.n;
			DBGPRINTF("mmdarwin::newActInst:: socketMaxUse is %d\n", pData-&gt;socketMaxUse);
		}
		else if (!strcmp(actpblk.descr[i].name, "send_partial"))
		{
			pData-&gt;sendPartial = (sbool)pvals[i].val.d.n;
			if (pData-&gt;sendPartial)
			{
				DBGPRINTF("mmdarwin::newActInst:: sending bodies even if fields are missing\n");
			}
			else
			{
				DBGPRINTF("mmdarwin::newActInst:: only sending complete bodies\n");
			}
		}
		else if (!strcmp(actpblk.descr[i].name, "response"))
		{
			char *response = es_str2cstr(pvals[i].val.d.estr, NULL);

			if (!strcmp(response, "no"))
			{
				pData-&gt;response = DARWIN_RESPONSE_SEND_NO;
				DBGPRINTF("mmdarwin::newActInst:: response type is 'no'\n");
			}
			else if (!strcmp(response, "back"))
			{
				pData-&gt;response = DARWIN_RESPONSE_SEND_BACK;
				DBGPRINTF("mmdarwin::newActInst:: response type is 'back'\n");
			}
			else if (!strcmp(response, "darwin"))
			{
				pData-&gt;response = DARWIN_RESPONSE_SEND_DARWIN;
				DBGPRINTF("mmdarwin::newActInst:: response type is 'darwin'\n");
			}
			else if (!strcmp(response, "both"))
			{
				pData-&gt;response = DARWIN_RESPONSE_SEND_BOTH;
				DBGPRINTF("mmdarwin::newActInst:: response type is 'both'\n");
			}
			else
			{
				DBGPRINTF(
					"mmdarwin::newActInst:: invalid 'response' value: %s. 'No response' set.\n",
					response);

				pData-&gt;response = DARWIN_RESPONSE_SEND_NO;
				DBGPRINTF("mmdarwin::newActInst:: response type is 'no'\n");
			}

			free(response);
		}
		else if (!strcmp(actpblk.descr[i].name, "filtercode"))
		{
			char *filterCode = es_str2cstr(pvals[i].val.d.estr, NULL);
			pData-&gt;filterCode = strtoull(filterCode, NULL, 16);
			free(filterCode);
		}
		else if (!strcmp(actpblk.descr[i].name, "fields"))
		{
			pData-&gt;fieldList.nmemb = pvals[i].val.d.ar-&gt;nmemb;
			CHKmalloc(pData-&gt;fieldList.name = calloc(pData-&gt;fieldList.nmemb, sizeof(char *)));
			CHKmalloc(pData-&gt;fieldList.varname = calloc(pData-&gt;fieldList.nmemb, sizeof(char *)));

			for (int j = 0; j &lt; pData-&gt;fieldList.nmemb; ++j)
			{
				char *const param = es_str2cstr(pvals[i].val.d.ar-&gt;arr[j], NULL);
				char *varname = NULL;
				char *name;
				if (*param == ':')
				{
					char *b = strchr(param + 1, ':');
					if (b == NULL)
					{
						parser_errmsg(
							"mmdarwin::newActInst:: missing closing colon: '%s'", param);
						ABORT_FINALIZE(RS_RET_ERR);
					}

					*b = '\0'; /* split name &amp; varname */
					varname = param + 1;
					name = b + 1;
				}
				else
				{
					name = param;
				}
				CHKmalloc(pData-&gt;fieldList.name[j] = strdup(name));
				char vnamebuf[1024];
				snprintf(vnamebuf, sizeof(vnamebuf),
						"%s!%s", loadModConf-&gt;container,
						(varname == NULL) ? name : varname);
				CHKmalloc(pData-&gt;fieldList.varname[j] = strdup(vnamebuf));
				free(param);
				DBGPRINTF("mmdarwin::newActInst:: will look for field %s\n", pData-&gt;fieldList.name[j]);
			}
		}
		else
		{
			DBGPRINTF(
			"mmdarwin::newActInst:: program error, non-handled param '%s'\n", actpblk.descr[i].name);
		}
	}

	// reserve space for 'container!key\0'
	size_t sizeKey = strlen(loadModConf-&gt;container) + strlen(JSON_DARWIN_ID) + 2;
	pData-&gt;pUUIDKey = malloc(sizeKey);
	snprintf(pData-&gt;pUUIDKey, sizeKey, "%s!%s", loadModConf-&gt;container, JSON_DARWIN_ID);
	DBGPRINTF("mmdarwin:: uuid key is %s\n", pData-&gt;pUUIDKey);

CODE_STD_FINALIZERnewActInst
	cnfparamvalsDestruct(pvals, &amp;actpblk);
ENDnewActInst

BEGINtryResume
CODESTARTtryResume
	iRet = doTryResume(pWrkrData);
ENDtryResume

BEGINdoAction_NoStrings
	smsg_t **ppMsg = (smsg_t **)pMsgData; /* the raw data */
	smsg_t *pMsg = ppMsg[0]; /* the raw log line */
	instanceData *pData = pWrkrData-&gt;pData; /* the parameters given for the plugin */
	char *pFieldValue = NULL; /* ponter to the found field value */
	int fieldsNum = 0; /* number of fields retrieved */

CODESTARTdoAction
	DBGPRINTF("mmdarwin::doAction:: beggining action\n");
	pWrkrData-&gt;darwinBody.bufferMsgSize = 0;
	fieldsNum = 0;

	for (int i = 0; i &lt; pData-&gt;fieldList.nmemb; i++)
	{
		DBGPRINTF("mmdarwin::doAction:: processing field '%s'\n", pData-&gt;fieldList.name[i]);
		pFieldValue = NULL;

		/* case 1: static field. We simply forward it to Darwin */
		if (pData-&gt;fieldList.name[i][0] != '!' &amp;&amp; pData-&gt;fieldList.name[i][0] != '.')
		{
			pFieldValue = strdup(pData-&gt;fieldList.name[i]);
		}
		/* case 2: dynamic field. We retrieve its value from the JSON logline and forward it to
		 * Darwin */
		else
		{
			if (!get_field(pMsg, pData-&gt;fieldList.name[i], &amp;pFieldValue))
			{
				DBGPRINTF("mmdarwin::doAction:: \
could not extract field '%s' from message\n", pData-&gt;fieldList.name[i]);
				continue;
			}
		}

		DBGPRINTF(
			"mmdarwin::doAction:: got value of field '%s': '%s'\n", pData-&gt;fieldList.name[i], pFieldValue);

		if (add_field_to_body(&amp;(pWrkrData-&gt;darwinBody), pFieldValue, strlen(pFieldValue)) != 0)
		{
			DBGPRINTF("mmdarwin::doAction:: could not add field to body, aborting\n");
			free(pFieldValue);
			ABORT_FINALIZE(RS_RET_ERR);
		}

		fieldsNum++;
		free(pFieldValue);
	}

	if (fieldsNum)
	{
		if (!pData-&gt;sendPartial &amp;&amp; fieldsNum != pData-&gt;fieldList.nmemb)
		{
			DBGPRINTF("mmdarwin::doAction:: not all fields could be retrieved, not sending partial message."
	" (if you wish to send partial messages anyway, set 'send_partial' to 'on' in instance parameters)\n");
			FINALIZE;
		}
		if (end_body(&amp;(pWrkrData-&gt;darwinBody)) != 0)
			ABORT_FINALIZE(RS_RET_ERR);
	}
	else
	{
		DBGPRINTF("mmdarwin::doAction:: no fields retrieved, finalizing\n");
		FINALIZE;
	}

	DBGPRINTF("mmdarwin::doAction:: body to send: '%s'\n", pWrkrData-&gt;darwinBody.buffer);

	if (pData-&gt;socketMaxUse)
	{
		/* need to rotate socket connections */
		if (!pWrkrData-&gt;pktSentSocket)
		{
			DBGPRINTF("mmdarwin::doAction:: opening a new connection\n");
			CHKiRet(doTryResume(pWrkrData));
		}
		pWrkrData-&gt;pktSentSocket = (pWrkrData-&gt;pktSentSocket + 1) % pData-&gt;socketMaxUse;
	}

	/* the Darwin header to be sent to the filter */
	darwin_filter_packet_t header = {
		.type = DARWIN_PACKET_OTHER,
		.response = pData-&gt;response,
		.filter_code = pData-&gt;filterCode,
		.body_size = pWrkrData-&gt;darwinBody.bufferMsgSize};

	const char *uuid = get_uuid_object(pMsg);
	if(uuid) {
		DBGPRINTF("mmdarwin: using existing UUID = %s\n", uuid);
		if(uuid_parse(uuid, header.evt_id))
			LogError(0, RS_RET_ERR, "mmdarwin:: failed to parse existing UUID: %s\n", uuid);
		free((void*)uuid);
	}
	else {
		uuid_generate(header.evt_id);
		char uuidStr[40];
		uuid_unparse(header.evt_id, uuidStr);
		DBGPRINTF("mmdarwin: generated new UUID = %s\n", uuidStr);
		msgAddJSON(pMsg, (uchar *)pData-&gt;pUUIDKey, json_object_new_string(uuidStr), 0, 0);
	}

	DBGPRINTF("mmdarwin::doAction:: sending header to Darwin\n");
	CHKiRet(sendMsg(pWrkrData, &amp;header, sizeof(darwin_filter_packet_t)));

	DBGPRINTF("mmdarwin::doAction:: sending body to Darwin\n");
	CHKiRet(sendMsg(pWrkrData, (void *)(pWrkrData-&gt;darwinBody.buffer), pWrkrData-&gt;darwinBody.bufferMsgSize));

	/* there is no need to wait for a response that will never come */
	if (pData-&gt;response == DARWIN_RESPONSE_SEND_NO || pData-&gt;response == DARWIN_RESPONSE_SEND_DARWIN)
	{
		DBGPRINTF("mmdarwin::doAction:: no response will be sent back "
				"(darwin response type is set to 'no' or 'darwin')\n");
		goto finalize_it;
	}

	darwin_filter_packet_t response;
	memset(&amp;response, 0, sizeof(response));
	DBGPRINTF("mmdarwin::doAction:: receiving from Darwin\n");
	CHKiRet(receiveMsg(pWrkrData, &amp;response, sizeof(response)));

	unsigned int certitude = response.certitude_list[0];
	DBGPRINTF("mmdarwin::doAction:: end of the transaction, certitude is %d\n", certitude);

	msgAddJSON(pMsg, (uchar *)pData-&gt;pCertitudeKey, json_object_new_int(certitude), 0, 0);

finalize_it :
	DBGPRINTF("mmdarwin::doAction:: finished processing log line\n");

ENDdoAction

NO_LEGACY_CONF_parseSelectorAct

BEGINmodExit
CODESTARTmodExit
	objRelease(glbl, CORE_COMPONENT);
ENDmodExit

BEGINqueryEtryPt
CODESTARTqueryEtryPt
CODEqueryEtryPt_STD_OMOD_QUERIES
CODEqueryEtryPt_STD_OMOD8_QUERIES
CODEqueryEtryPt_STD_CONF2_setModCnf_QUERIES
CODEqueryEtryPt_STD_CONF2_OMOD_QUERIES
CODEqueryEtryPt_STD_CONF2_QUERIES
ENDqueryEtryPt

BEGINmodInit()
CODESTARTmodInit
	/* we only support the current interface specification */
	*ipIFVersProvided = CURR_MOD_IF_VERSION;
CODEmodInit_QueryRegCFSLineHdlr
	DBGPRINTF("mmdarwin::modInit:: module compiled with rsyslog version %s.\n", VERSION);
	CHKiRet(objUse(glbl, CORE_COMPONENT));
ENDmodInit
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerHTML.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
