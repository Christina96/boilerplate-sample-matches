
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 14, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>runner-MDEwOlJlcG9zaXRvcnkxODQyODY4NzU=-flat-JobDispatcher.cs</h3>
            <pre><code>1  using System;
2  using System.Collections.Concurrent;
3  using System.Collections.Generic;
4  using System.IO;
5  using System.Linq;
6  using System.Text;
7  using System.Text.RegularExpressions;
8  using System.Threading;
9  using System.Threading.Tasks;
10  using GitHub.DistributedTask.Pipelines;
11  using GitHub.DistributedTask.WebApi;
12  using GitHub.Runner.Common;
13  using GitHub.Runner.Common.Util;
14  using GitHub.Runner.Sdk;
15  using GitHub.Services.Common;
16  using GitHub.Services.WebApi;
17  using GitHub.Services.WebApi.Jwt;
18  using Sdk.RSWebApi.Contracts;
19  using Pipelines = GitHub.DistributedTask.Pipelines;
20  namespace GitHub.Runner.Listener
21  {
22      [ServiceLocator(Default = typeof(JobDispatcher))]
23      public interface IJobDispatcher : IRunnerService
24      {
25          bool Busy { get; }
26          TaskCompletionSource<bool> RunOnceJobCompleted { get; }
27          void Run(Pipelines.AgentJobRequestMessage message, bool runOnce = false);
28          bool Cancel(JobCancelMessage message);
29          Task WaitAsync(CancellationToken token);
30          Task ShutdownAsync();
31          event EventHandler<JobStatusEventArgs> JobStatus;
32      }
33      public sealed class JobDispatcher : RunnerService, IJobDispatcher
34      {
35          private static Regex _invalidJsonRegex = new(@"invalid\ Json\ at\ position\ '(\d+)':", RegexOptions.Compiled | RegexOptions.IgnoreCase);
36          private readonly Lazy<Dictionary<long, TaskResult>> _localRunJobResult = new();
37          private int _poolId;
38          IConfigurationStore _configurationStore;
39          RunnerSettings _runnerSettings;
40          private static readonly string _workerProcessName = $"Runner.Worker{IOUtil.ExeExtension}";
41          private readonly Queue<Guid> _jobDispatchedQueue = new();
42          private readonly ConcurrentDictionary<Guid, WorkerDispatcher> _jobInfos = new();
43          private TimeSpan _channelTimeout;
44          private TaskCompletionSource<bool> _runOnceJobCompleted = new();
45          public event EventHandler<JobStatusEventArgs> JobStatus;
46          private bool _isRunServiceJob;
47          public override void Initialize(IHostContext hostContext)
48          {
49              base.Initialize(hostContext);
50              _configurationStore = hostContext.GetService<IConfigurationStore>();
51              _runnerSettings = _configurationStore.GetSettings();
52              _poolId = _runnerSettings.PoolId;
53              int channelTimeoutSeconds;
54              if (!int.TryParse(Environment.GetEnvironmentVariable("GITHUB_ACTIONS_RUNNER_CHANNEL_TIMEOUT") ?? string.Empty, out channelTimeoutSeconds))
55              {
56                  channelTimeoutSeconds = 30;
57              }
58              _channelTimeout = TimeSpan.FromSeconds(Math.Min(Math.Max(channelTimeoutSeconds, 30), 300));
59              Trace.Info($"Set runner/worker IPC timeout to {_channelTimeout.TotalSeconds} seconds.");
60          }
61          public TaskCompletionSource<bool> RunOnceJobCompleted => _runOnceJobCompleted;
62          public bool Busy { get; private set; }
63          public void Run(Pipelines.AgentJobRequestMessage jobRequestMessage, bool runOnce = false)
64          {
65              Trace.Info($"Job request {jobRequestMessage.RequestId} for plan {jobRequestMessage.Plan.PlanId} job {jobRequestMessage.JobId} received.");
66              _isRunServiceJob = MessageUtil.IsRunServiceJob(jobRequestMessage.MessageType);
67              WorkerDispatcher currentDispatch = null;
68              if (_jobDispatchedQueue.Count > 0)
69              {
70                  Guid dispatchedJobId = _jobDispatchedQueue.Dequeue();
71                  if (_jobInfos.TryGetValue(dispatchedJobId, out currentDispatch))
72                  {
73                      Trace.Verbose($"Retrive previous WorkerDispather for job {currentDispatch.JobId}.");
74                  }
75              }
76              var orchestrationId = string.Empty;
77              var systemConnection = jobRequestMessage.Resources.Endpoints.SingleOrDefault(x => string.Equals(x.Name, WellKnownServiceEndpointNames.SystemVssConnection, StringComparison.OrdinalIgnoreCase));
78              if (systemConnection?.Authorization != null &&
79                  systemConnection.Authorization.Parameters.TryGetValue("AccessToken", out var accessToken) &&
80                  !string.IsNullOrEmpty(accessToken))
81              {
82                  var jwt = JsonWebToken.Create(accessToken);
83                  var claims = jwt.ExtractClaims();
84                  orchestrationId = claims.FirstOrDefault(x => string.Equals(x.Type, "orchid", StringComparison.OrdinalIgnoreCase))?.Value;
85                  if (!string.IsNullOrEmpty(orchestrationId))
86                  {
87                      Trace.Info($"Pull OrchestrationId {orchestrationId} from JWT claims");
88                  }
89              }
90              WorkerDispatcher newDispatch = new(jobRequestMessage.JobId, jobRequestMessage.RequestId);
91              if (runOnce)
92              {
93                  Trace.Info("Start dispatcher for one time used runner.");
94                  newDispatch.WorkerDispatch = RunOnceAsync(jobRequestMessage, orchestrationId, currentDispatch, newDispatch.WorkerCancellationTokenSource.Token, newDispatch.WorkerCancelTimeoutKillTokenSource.Token);
95              }
96              else
97              {
98                  newDispatch.WorkerDispatch = RunAsync(jobRequestMessage, orchestrationId, currentDispatch, newDispatch.WorkerCancellationTokenSource.Token, newDispatch.WorkerCancelTimeoutKillTokenSource.Token);
99              }
100              _jobInfos.TryAdd(newDispatch.JobId, newDispatch);
101              _jobDispatchedQueue.Enqueue(newDispatch.JobId);
102          }
103          public bool Cancel(JobCancelMessage jobCancelMessage)
104          {
105              Trace.Info($"Job cancellation request {jobCancelMessage.JobId} received, cancellation timeout {jobCancelMessage.Timeout.TotalMinutes} minutes.");
106              WorkerDispatcher workerDispatcher;
107              if (!_jobInfos.TryGetValue(jobCancelMessage.JobId, out workerDispatcher))
108              {
109                  Trace.Verbose($"Job request {jobCancelMessage.JobId} is not a current running job, ignore cancllation request.");
110                  return false;
111              }
112              else
113              {
114                  if (workerDispatcher.Cancel(jobCancelMessage.Timeout))
115                  {
116                      Trace.Verbose($"Fired cancellation token for job request {workerDispatcher.JobId}.");
117                  }
118                  return true;
119              }
120          }
121          public async Task WaitAsync(CancellationToken token)
122          {
123              WorkerDispatcher currentDispatch = null;
124              Guid dispatchedJobId;
125              if (_jobDispatchedQueue.Count > 0)
126              {
127                  dispatchedJobId = _jobDispatchedQueue.Dequeue();
128                  if (_jobInfos.TryGetValue(dispatchedJobId, out currentDispatch))
129                  {
130                      Trace.Verbose($"Retrive previous WorkerDispather for job {currentDispatch.JobId}.");
131                  }
132              }
133              else
134              {
135                  Trace.Verbose($"There is no running WorkerDispather needs to await.");
136              }
137              if (currentDispatch != null)
138              {
139                  using (var registration = token.Register(() => { if (currentDispatch.Cancel(TimeSpan.FromSeconds(60))) { Trace.Verbose($"Fired cancellation token for job request {currentDispatch.JobId}."); } }))
140                  {
141                      try
142                      {
143                          Trace.Info($"Waiting WorkerDispather for job {currentDispatch.JobId} run to finish.");
<span onclick='openModal()' class='match'>144                          await currentDispatch.WorkerDispatch;
145                          Trace.Info($"Job request {currentDispatch.JobId} processed succeed.");
146                      }
147                      catch (Exception ex)
</span>148                      {
149                          Trace.Error($"Worker Dispatch failed with an exception for job request {currentDispatch.JobId}.");
150                          Trace.Error(ex);
151                      }
152                      finally
153                      {
154                          WorkerDispatcher workerDispatcher;
155                          if (_jobInfos.TryRemove(currentDispatch.JobId, out workerDispatcher))
156                          {
157                              Trace.Verbose($"Remove WorkerDispather from {nameof(_jobInfos)} dictionary for job {currentDispatch.JobId}.");
158                              workerDispatcher.Dispose();
159                          }
160                      }
161                  }
162              }
163          }
164          public async Task ShutdownAsync()
165          {
166              Trace.Info($"Shutting down JobDispatcher. Make sure all WorkerDispatcher has finished.");
167              WorkerDispatcher currentDispatch = null;
168              if (_jobDispatchedQueue.Count > 0)
169              {
170                  Guid dispatchedJobId = _jobDispatchedQueue.Dequeue();
171                  if (_jobInfos.TryGetValue(dispatchedJobId, out currentDispatch))
172                  {
173                      try
174                      {
175                          Trace.Info($"Ensure WorkerDispather for job {currentDispatch.JobId} run to finish, cancel any running job.");
176                          await EnsureDispatchFinished(currentDispatch, cancelRunningJob: true);
177                      }
178                      catch (Exception ex)
179                      {
180                          Trace.Error($"Catching worker dispatch exception for job request {currentDispatch.JobId} durning job dispatcher shut down.");
181                          Trace.Error(ex);
182                      }
183                      finally
184                      {
185                          WorkerDispatcher workerDispatcher;
186                          if (_jobInfos.TryRemove(currentDispatch.JobId, out workerDispatcher))
187                          {
188                              Trace.Verbose($"Remove WorkerDispather from {nameof(_jobInfos)} dictionary for job {currentDispatch.JobId}.");
189                              workerDispatcher.Dispose();
190                          }
191                      }
192                  }
193              }
194          }
195          private async Task EnsureDispatchFinished(WorkerDispatcher jobDispatch, bool cancelRunningJob = false)
196          {
197              if (!jobDispatch.WorkerDispatch.IsCompleted)
198              {
199                  if (cancelRunningJob)
200                  {
201                      jobDispatch.WorkerCancellationTokenSource.Cancel();
202                      await jobDispatch.WorkerDispatch;
203                      return;
204                  }
205                  if (this._isRunServiceJob)
206                  {
207                      Trace.Error($"We are not yet checking the state of jobrequest {jobDispatch.JobId} status. Cancel running worker right away.");
208                      jobDispatch.WorkerCancellationTokenSource.Cancel();
209                      return;
210                  }
211                  var runnerServer = HostContext.GetService<IRunnerServer>();
212                  TaskAgentJobRequest request = null;
213                  try
214                  {
215                      request = await runnerServer.GetAgentRequestAsync(_poolId, jobDispatch.RequestId, CancellationToken.None);
216                  }
217                  catch (TaskAgentJobNotFoundException ex)
218                  {
219                      Trace.Error($"Catch job-not-found exception while checking jobrequest {jobDispatch.JobId} status. Cancel running worker right away.");
220                      Trace.Error(ex);
221                      jobDispatch.WorkerCancellationTokenSource.Cancel();
222                      await jobDispatch.WorkerDispatch;
223                      return;
224                  }
225                  catch (Exception ex)
226                  {
227                      Trace.Error($"Catch exception while checking jobrequest {jobDispatch.JobId} status. Cancel running worker right away.");
228                      Trace.Error(ex);
229                      jobDispatch.WorkerCancellationTokenSource.Cancel();
230                      await jobDispatch.WorkerDispatch;
231                      throw;
232                  }
233                  if (request.Result != null)
234                  {
235                      Trace.Error($"Received job request while previous job {jobDispatch.JobId} still running on worker. Cancel the previous job since the job request have been finished on server side with result: {request.Result.Value}.");
236                      jobDispatch.WorkerCancellationTokenSource.Cancel();
237                      Task completedTask = await Task.WhenAny(jobDispatch.WorkerDispatch, Task.Delay(TimeSpan.FromSeconds(45)));
238                      if (completedTask != jobDispatch.WorkerDispatch)
239                      {
240                          throw new InvalidOperationException($"Job dispatch process for {jobDispatch.JobId} has encountered unexpected error, the dispatch task is not able to be cancelled within 45 seconds.");
241                      }
242                  }
243                  else
244                  {
245                      throw new InvalidOperationException($"Server send a new job request while the previous job request {jobDispatch.JobId} haven't finished.");
246                  }
247              }
248              try
249              {
250                  await jobDispatch.WorkerDispatch;
251                  Trace.Info($"Job request {jobDispatch.JobId} processed succeed.");
252              }
253              catch (Exception ex)
254              {
255                  Trace.Error($"Worker Dispatch failed with an exception for job request {jobDispatch.JobId}.");
256                  Trace.Error(ex);
257              }
258              finally
259              {
260                  WorkerDispatcher workerDispatcher;
261                  if (_jobInfos.TryRemove(jobDispatch.JobId, out workerDispatcher))
262                  {
263                      Trace.Verbose($"Remove WorkerDispather from {nameof(_jobInfos)} dictionary for job {jobDispatch.JobId}.");
264                      workerDispatcher.Dispose();
265                  }
266              }
267          }
268          private async Task RunOnceAsync(Pipelines.AgentJobRequestMessage message, string orchestrationId, WorkerDispatcher previousJobDispatch, CancellationToken jobRequestCancellationToken, CancellationToken workerCancelTimeoutKillToken)
269          {
270              try
271              {
272                  await RunAsync(message, orchestrationId, previousJobDispatch, jobRequestCancellationToken, workerCancelTimeoutKillToken);
273              }
274              finally
275              {
276                  Trace.Info("Fire signal for one time used runner.");
277                  _runOnceJobCompleted.TrySetResult(true);
278              }
279          }
280          private async Task RunAsync(Pipelines.AgentJobRequestMessage message, string orchestrationId, WorkerDispatcher previousJobDispatch, CancellationToken jobRequestCancellationToken, CancellationToken workerCancelTimeoutKillToken)
281          {
282              Busy = true;
283              try
284              {
285                  if (JobStatus != null)
286                  {
287                      JobStatus(this, new JobStatusEventArgs(TaskAgentStatus.Busy));
288                  }
289                  if (previousJobDispatch != null)
290                  {
291                      Trace.Verbose($"Make sure the previous job request {previousJobDispatch.JobId} has successfully finished on worker.");
292                      await EnsureDispatchFinished(previousJobDispatch);
293                  }
294                  else
295                  {
296                      Trace.Verbose($"This is the first job request.");
297                  }
298                  var term = HostContext.GetService<ITerminal>();
299                  term.WriteLine($"{DateTime.UtcNow:u}: Running job: {message.JobDisplayName}");
300                  TaskCompletionSource<int> firstJobRequestRenewed = new();
301                  var notification = HostContext.GetService<IJobNotification>();
302                  var systemConnection = message.Resources.Endpoints.SingleOrDefault(x => string.Equals(x.Name, WellKnownServiceEndpointNames.SystemVssConnection, StringComparison.OrdinalIgnoreCase));
303                  using (var lockRenewalTokenSource = new CancellationTokenSource())
304                  using (var workerProcessCancelTokenSource = new CancellationTokenSource())
305                  {
306                      long requestId = message.RequestId;
307                      Guid lockToken = Guid.Empty; 
308                      Trace.Info($"Start renew job request {requestId} for job {message.JobId}.");
309                      Task renewJobRequest = RenewJobRequestAsync(message, systemConnection, _poolId, requestId, lockToken, orchestrationId, firstJobRequestRenewed, lockRenewalTokenSource.Token);
310                      await Task.WhenAny(firstJobRequestRenewed.Task, renewJobRequest, Task.Delay(-1, jobRequestCancellationToken));
311                      if (renewJobRequest.IsCompleted)
312                      {
313                          Trace.Info($"Unable to renew job request for job {message.JobId} for the first time, stop dispatching job to worker.");
314                          return;
315                      }
316                      if (jobRequestCancellationToken.IsCancellationRequested)
317                      {
318                          Trace.Info($"Stop renew job request for job {message.JobId}.");
319                          lockRenewalTokenSource.Cancel();
320                          await renewJobRequest;
321                          await CompleteJobRequestAsync(_poolId, message, systemConnection, lockToken, TaskResult.Canceled);
322                          return;
323                      }
324                      HostContext.WritePerfCounter($"JobRequestRenewed_{requestId.ToString()}");
325                      Task<int> workerProcessTask = null;
326                      object _outputLock = new();
327                      List<string> workerOutput = new();
328                      bool printToStdout = StringUtil.ConvertToBoolean(Environment.GetEnvironmentVariable(Constants.Variables.Agent.PrintLogToStdout));
329                      using (var processChannel = HostContext.CreateService<IProcessChannel>())
330                      using (var processInvoker = HostContext.CreateService<IProcessInvoker>())
331                      {
332                          processChannel.StartServer(
333                              startProcess: (string pipeHandleOut, string pipeHandleIn) =>
334                              {
335                                  ArgUtil.NotNullOrEmpty(pipeHandleOut, nameof(pipeHandleOut));
336                                  ArgUtil.NotNullOrEmpty(pipeHandleIn, nameof(pipeHandleIn));
337                                  processInvoker.OutputDataReceived += delegate (object sender, ProcessDataReceivedEventArgs stdout)
338                                      {
339                                          if (!string.IsNullOrEmpty(stdout.Data))
340                                          {
341                                              lock (_outputLock)
342                                              {
343                                                  if (!stdout.Data.StartsWith("[WORKER"))
344                                                  {
345                                                      workerOutput.Add(stdout.Data);
346                                                  }
347                                                  if (printToStdout)
348                                                  {
349                                                      term.WriteLine(stdout.Data, skipTracing: true);
350                                                  }
351                                              }
352                                          }
353                                      };
354                                  processInvoker.ErrorDataReceived += delegate (object sender, ProcessDataReceivedEventArgs stderr)
355                                      {
356                                          if (!string.IsNullOrEmpty(stderr.Data))
357                                          {
358                                              lock (_outputLock)
359                                              {
360                                                  workerOutput.Add(stderr.Data);
361                                              }
362                                          }
363                                      };
364                                  HostContext.WritePerfCounter("StartingWorkerProcess");
365                                  var assemblyDirectory = HostContext.GetDirectory(WellKnownDirectory.Bin);
366                                  string workerFileName = Path.Combine(assemblyDirectory, _workerProcessName);
367                                  workerProcessTask = processInvoker.ExecuteAsync(
368                                      workingDirectory: assemblyDirectory,
369                                      fileName: workerFileName,
370                                      arguments: "spawnclient " + pipeHandleOut + " " + pipeHandleIn,
371                                      environment: null,
372                                      requireExitCodeZero: false,
373                                      outputEncoding: null,
374                                      killProcessOnCancel: true,
375                                      redirectStandardIn: null,
376                                      inheritConsoleHandler: false,
377                                      keepStandardInOpen: false,
378                                      highPriorityProcess: true,
379                                      cancellationToken: workerProcessCancelTokenSource.Token);
380                              });
381                          try
382                          {
383                              Trace.Info($"Send job request message to worker for job {message.JobId}.");
384                              HostContext.WritePerfCounter($"RunnerSendingJobToWorker_{message.JobId}");
385                              using (var csSendJobRequest = new CancellationTokenSource(_channelTimeout))
386                              {
387                                  await processChannel.SendAsync(
388                                      messageType: MessageType.NewJobRequest,
389                                      body: JsonUtility.ToString(message),
390                                      cancellationToken: csSendJobRequest.Token);
391                              }
392                          }
393                          catch (OperationCanceledException)
394                          {
395                              Trace.Info($"Job request message sending for job {message.JobId} been cancelled, kill running worker.");
396                              workerProcessCancelTokenSource.Cancel();
397                              try
398                              {
399                                  await workerProcessTask;
400                              }
401                              catch (OperationCanceledException)
402                              {
403                                  Trace.Info("worker process has been killed.");
404                              }
405                              Trace.Info($"Stop renew job request for job {message.JobId}.");
406                              lockRenewalTokenSource.Cancel();
407                              await renewJobRequest;
408                              return;
409                          }
410                          var accessToken = systemConnection?.Authorization?.Parameters["AccessToken"];
411                          notification.JobStarted(message.JobId, accessToken, systemConnection.Url);
412                          HostContext.WritePerfCounter($"SentJobToWorker_{requestId.ToString()}");
413                          try
414                          {
415                              TaskResult resultOnAbandonOrCancel = TaskResult.Succeeded;
416                              var completedTask = await Task.WhenAny(renewJobRequest, workerProcessTask, Task.Delay(-1, jobRequestCancellationToken));
417                              if (completedTask == workerProcessTask)
418                              {
419                                  int returnCode = await workerProcessTask;
420                                  Trace.Info($"Worker finished for job {message.JobId}. Code: " + returnCode);
421                                  string detailInfo = null;
422                                  if (!TaskResultUtil.IsValidReturnCode(returnCode))
423                                  {
424                                      detailInfo = string.Join(Environment.NewLine, workerOutput);
425                                      Trace.Info($"Return code {returnCode} indicate worker encounter an unhandled exception or app crash, attach worker stdout/stderr to JobRequest result.");
426                                      var jobServer = await InitializeJobServerAsync(systemConnection);
427                                      await LogWorkerProcessUnhandledException(jobServer, message, detailInfo);
428                                      if (detailInfo.Contains(typeof(System.IO.IOException).ToString(), StringComparison.OrdinalIgnoreCase))
429                                      {
430                                          Trace.Info($"Finish job with result 'Failed' due to IOException.");
431                                          await ForceFailJob(jobServer, message, detailInfo);
432                                      }
433                                  }
434                                  TaskResult result = TaskResultUtil.TranslateFromReturnCode(returnCode);
435                                  Trace.Info($"finish job request for job {message.JobId} with result: {result}");
436                                  term.WriteLine($"{DateTime.UtcNow:u}: Job {message.JobDisplayName} completed with result: {result}");
437                                  Trace.Info($"Stop renew job request for job {message.JobId}.");
438                                  lockRenewalTokenSource.Cancel();
439                                  await renewJobRequest;
440                                  await CompleteJobRequestAsync(_poolId, message, systemConnection, lockToken, result, detailInfo);
441                                  if (!string.IsNullOrEmpty(detailInfo))
442                                  {
443                                      Trace.Error("Unhandled exception happened in worker:");
444                                      Trace.Error(detailInfo);
445                                  }
446                                  return;
447                              }
448                              else if (completedTask == renewJobRequest)
449                              {
450                                  resultOnAbandonOrCancel = TaskResult.Abandoned;
451                              }
452                              else
453                              {
454                                  resultOnAbandonOrCancel = TaskResult.Canceled;
455                              }
456                              try
457                              {
458                                  Trace.Info($"Send job cancellation message to worker for job {message.JobId}.");
459                                  using (var csSendCancel = new CancellationTokenSource(_channelTimeout))
460                                  {
461                                      var messageType = MessageType.CancelRequest;
462                                      if (HostContext.RunnerShutdownToken.IsCancellationRequested)
463                                      {
464                                          switch (HostContext.RunnerShutdownReason)
465                                          {
466                                              case ShutdownReason.UserCancelled:
467                                                  messageType = MessageType.RunnerShutdown;
468                                                  break;
469                                              case ShutdownReason.OperatingSystemShutdown:
470                                                  messageType = MessageType.OperatingSystemShutdown;
471                                                  break;
472                                          }
473                                      }
474                                      await processChannel.SendAsync(
475                                          messageType: messageType,
476                                          body: string.Empty,
477                                          cancellationToken: csSendCancel.Token);
478                                  }
479                              }
480                              catch (OperationCanceledException)
481                              {
482                                  Trace.Info($"Job cancel message sending for job {message.JobId} been cancelled, kill running worker.");
483                                  workerProcessCancelTokenSource.Cancel();
484                                  try
485                                  {
486                                      await workerProcessTask;
487                                  }
488                                  catch (OperationCanceledException)
489                                  {
490                                      Trace.Info("worker process has been killed.");
491                                  }
492                              }
493                              completedTask = await Task.WhenAny(workerProcessTask, Task.Delay(-1, workerCancelTimeoutKillToken));
494                              if (completedTask != workerProcessTask)
495                              {
496                                  Trace.Info($"worker process for job {message.JobId} haven't exit within cancellation timout, kill running worker.");
497                                  workerProcessCancelTokenSource.Cancel();
498                                  try
499                                  {
500                                      await workerProcessTask;
501                                  }
502                                  catch (OperationCanceledException)
503                                  {
504                                      Trace.Info("worker process has been killed.");
505                                  }
506                                  await TryUploadUnfinishedLogs(message);
507                              }
508                              Trace.Info($"finish job request for job {message.JobId} with result: {resultOnAbandonOrCancel}");
509                              term.WriteLine($"{DateTime.UtcNow:u}: Job {message.JobDisplayName} completed with result: {resultOnAbandonOrCancel}");
510                              Trace.Info($"Stop renew job request for job {message.JobId}.");
511                              lockRenewalTokenSource.Cancel();
512                              await renewJobRequest;
513                              await CompleteJobRequestAsync(_poolId, message, systemConnection, lockToken, resultOnAbandonOrCancel);
514                          }
515                          finally
516                          {
517                              await notification.JobCompleted(message.JobId);
518                          }
519                      }
520                  }
521              }
522              finally
523              {
524                  Busy = false;
525                  if (JobStatus != null)
526                  {
527                      JobStatus(this, new JobStatusEventArgs(TaskAgentStatus.Online));
528                  }
529              }
530          }
531          internal async Task RenewJobRequestAsync(Pipelines.AgentJobRequestMessage message, ServiceEndpoint systemConnection, int poolId, long requestId, Guid lockToken, string orchestrationId, TaskCompletionSource<int> firstJobRequestRenewed, CancellationToken token)
532          {
533              if (this._isRunServiceJob)
534              {
535                  var runServer = await GetRunServerAsync(systemConnection);
536                  await RenewJobRequestAsync(runServer, message.Plan.PlanId, message.JobId, firstJobRequestRenewed, token);
537              }
538              else
539              {
540                  var runnerServer = HostContext.GetService<IRunnerServer>();
541                  await RenewJobRequestAsync(runnerServer, poolId, requestId, lockToken, orchestrationId, firstJobRequestRenewed, token);
542              }
543          }
544          private async Task RenewJobRequestAsync(IRunServer runServer, Guid planId, Guid jobId, TaskCompletionSource<int> firstJobRequestRenewed, CancellationToken token)
545          {
546              TaskAgentJobRequest request = null;
547              int firstRenewRetryLimit = 5;
548              int encounteringError = 0;
549              while (!token.IsCancellationRequested)
550              {
551                  try
552                  {
553                      var renewResponse = await runServer.RenewJobAsync(planId, jobId, token);
554                      Trace.Info($"Successfully renew job {jobId}, job is valid till {renewResponse.LockedUntil}");
555                      if (!firstJobRequestRenewed.Task.IsCompleted)
556                      {
557                          firstJobRequestRenewed.TrySetResult(0);
558                      }
559                      if (encounteringError > 0)
560                      {
561                          encounteringError = 0;
562                          HostContext.WritePerfCounter("JobRenewRecovered");
563                      }
564                      await HostContext.Delay(TimeSpan.FromSeconds(60), token);
565                  }
566                  catch (TaskOrchestrationJobNotFoundException)
567                  {
568                      Trace.Info($"TaskAgentJobNotFoundException received when renew job {jobId}, job is no longer valid, stop renew job request.");
569                      return;
570                  }
571                  catch (OperationCanceledException) when (token.IsCancellationRequested)
572                  {
573                      Trace.Info($"job renew has been cancelled, stop renew job {jobId}.");
574                      return;
575                  }
576                  catch (Exception ex)
577                  {
578                      Trace.Error($"Catch exception during renew runner job {jobId}.");
579                      Trace.Error(ex);
580                      encounteringError++;
581                      TimeSpan remainingTime = TimeSpan.Zero;
582                      if (!firstJobRequestRenewed.Task.IsCompleted)
583                      {
584                          if (firstRenewRetryLimit-- > 0)
585                          {
586                              remainingTime = TimeSpan.FromSeconds(10);
587                          }
588                      }
589                      else
590                      {
591                          remainingTime = request.LockedUntil.Value + TimeSpan.FromMinutes(5) - DateTime.UtcNow;
592                      }
593                      if (remainingTime > TimeSpan.Zero)
594                      {
595                          TimeSpan delayTime;
596                          if (!firstJobRequestRenewed.Task.IsCompleted)
597                          {
598                              Trace.Info($"Retrying lock renewal for job {jobId}. The first job renew request has failed.");
599                              delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(10));
600                          }
601                          else
602                          {
603                              Trace.Info($"Retrying lock renewal for job {jobId}. Job is valid until {request.LockedUntil.Value}.");
604                              if (encounteringError > 5)
605                              {
606                                  delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(15), TimeSpan.FromSeconds(30));
607                              }
608                              else
609                              {
610                                  delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(15));
611                              }
612                          }
613                          try
614                          {
615                              await HostContext.Delay(delayTime, token);
616                          }
617                          catch (OperationCanceledException) when (token.IsCancellationRequested)
618                          {
619                              Trace.Info($"job renew has been cancelled, stop renew job {jobId}.");
620                          }
621                      }
622                      else
623                      {
624                          Trace.Info($"Lock renewal has run out of retry, stop renew lock for job {jobId}.");
625                          HostContext.WritePerfCounter("JobRenewReachLimit");
626                          return;
627                      }
628                  }
629              }
630          }
631          private async Task RenewJobRequestAsync(IRunnerServer runnerServer, int poolId, long requestId, Guid lockToken, string orchestrationId, TaskCompletionSource<int> firstJobRequestRenewed, CancellationToken token)
632          {
633              TaskAgentJobRequest request = null;
634              int firstRenewRetryLimit = 5;
635              int encounteringError = 0;
636              while (!token.IsCancellationRequested)
637              {
638                  try
639                  {
640                      request = await runnerServer.RenewAgentRequestAsync(poolId, requestId, lockToken, orchestrationId, token);
641                      Trace.Info($"Successfully renew job request {requestId}, job is valid till {request.LockedUntil.Value}");
642                      if (!firstJobRequestRenewed.Task.IsCompleted)
643                      {
644                          firstJobRequestRenewed.TrySetResult(0);
645                          UpdateAgentNameIfNeeded(request.ReservedAgent?.Name);
646                      }
647                      if (encounteringError > 0)
648                      {
649                          encounteringError = 0;
650                          runnerServer.SetConnectionTimeout(RunnerConnectionType.JobRequest, TimeSpan.FromSeconds(60));
651                          HostContext.WritePerfCounter("JobRenewRecovered");
652                      }
653                      await HostContext.Delay(TimeSpan.FromSeconds(60), token);
654                  }
655                  catch (TaskAgentJobNotFoundException)
656                  {
657                      Trace.Info($"TaskAgentJobNotFoundException received when renew job request {requestId}, job is no longer valid, stop renew job request.");
658                      return;
659                  }
660                  catch (TaskAgentJobTokenExpiredException)
661                  {
662                      Trace.Info($"TaskAgentJobTokenExpiredException received renew job request {requestId}, job is no longer valid, stop renew job request.");
663                      return;
664                  }
665                  catch (OperationCanceledException) when (token.IsCancellationRequested)
666                  {
667                      Trace.Info($"job renew has been cancelled, stop renew job request {requestId}.");
668                      return;
669                  }
670                  catch (Exception ex)
671                  {
672                      Trace.Error($"Catch exception during renew runner jobrequest {requestId}.");
673                      Trace.Error(ex);
674                      encounteringError++;
675                      TimeSpan remainingTime = TimeSpan.Zero;
676                      if (!firstJobRequestRenewed.Task.IsCompleted)
677                      {
678                          if (firstRenewRetryLimit-- > 0)
679                          {
680                              remainingTime = TimeSpan.FromSeconds(10);
681                          }
682                      }
683                      else
684                      {
685                          remainingTime = request.LockedUntil.Value + TimeSpan.FromMinutes(5) - DateTime.UtcNow;
686                      }
687                      if (remainingTime > TimeSpan.Zero)
688                      {
689                          TimeSpan delayTime;
690                          if (!firstJobRequestRenewed.Task.IsCompleted)
691                          {
692                              Trace.Info($"Retrying lock renewal for jobrequest {requestId}. The first job renew request has failed.");
693                              delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(10));
694                          }
695                          else
696                          {
697                              Trace.Info($"Retrying lock renewal for jobrequest {requestId}. Job is valid until {request.LockedUntil.Value}.");
698                              if (encounteringError > 5)
699                              {
700                                  delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(15), TimeSpan.FromSeconds(30));
701                              }
702                              else
703                              {
704                                  delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(15));
705                              }
706                          }
707                          HostContext.WritePerfCounter("ResetJobRenewConnection");
708                          await runnerServer.RefreshConnectionAsync(RunnerConnectionType.JobRequest, TimeSpan.FromSeconds(30));
709                          try
710                          {
711                              await HostContext.Delay(delayTime, token);
712                          }
713                          catch (OperationCanceledException) when (token.IsCancellationRequested)
714                          {
715                              Trace.Info($"job renew has been cancelled, stop renew job request {requestId}.");
716                          }
717                      }
718                      else
719                      {
720                          Trace.Info($"Lock renewal has run out of retry, stop renew lock for jobrequest {requestId}.");
721                          HostContext.WritePerfCounter("JobRenewReachLimit");
722                          return;
723                      }
724                  }
725              }
726          }
727          private void UpdateAgentNameIfNeeded(string agentName)
728          {
729              var isNewAgentName = !string.Equals(_runnerSettings.AgentName, agentName, StringComparison.Ordinal);
730              if (!isNewAgentName || string.IsNullOrEmpty(agentName))
731              {
732                  return;
733              }
734              _runnerSettings.AgentName = agentName;
735              try
736              {
737                  _configurationStore.SaveSettings(_runnerSettings);
738              }
739              catch (Exception ex)
740              {
741                  Trace.Error("Cannot update the settings file:");
742                  Trace.Error(ex);
743              }
744          }
745          private async Task TryUploadUnfinishedLogs(Pipelines.AgentJobRequestMessage message)
746          {
747              Trace.Entering();
748              var logFolder = Path.Combine(HostContext.GetDirectory(WellKnownDirectory.Diag), PagingLogger.PagingFolder);
749              if (!Directory.Exists(logFolder))
750              {
751                  return;
752              }
753              var logs = Directory.GetFiles(logFolder);
754              if (logs.Length == 0)
755              {
756                  return;
757              }
758              try
759              {
760                  var systemConnection = message.Resources.Endpoints.SingleOrDefault(x => string.Equals(x.Name, WellKnownServiceEndpointNames.SystemVssConnection));
761                  ArgUtil.NotNull(systemConnection, nameof(systemConnection));
762                  var server = await InitializeJobServerAsync(systemConnection);
763                  if (server is IJobServer jobServer)
764                  {
765                      var timeline = await jobServer.GetTimelineAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, message.Timeline.Id, CancellationToken.None);
766                      var updatedRecords = new List<TimelineRecord>();
767                      var logPages = new Dictionary<Guid, Dictionary<int, string>>();
768                      var logRecords = new Dictionary<Guid, TimelineRecord>();
769                      foreach (var log in logs)
770                      {
771                          var logName = Path.GetFileNameWithoutExtension(log);
772                          var logNameParts = logName.Split('_', StringSplitOptions.RemoveEmptyEntries);
773                          if (logNameParts.Length != 3)
774                          {
775                              Trace.Warning($"log file '{log}' doesn't follow naming convension 'GUID_GUID_INT'.");
776                              continue;
777                          }
778                          var logPageSeperator = logName.IndexOf('_');
779                          var logRecordId = Guid.Empty;
780                          var pageNumber = 0;
781                          if (!Guid.TryParse(logNameParts[0], out Guid timelineId) || timelineId != timeline.Id)
782                          {
783                              Trace.Warning($"log file '{log}' is not belongs to current job");
784                              continue;
785                          }
786                          if (!Guid.TryParse(logNameParts[1], out logRecordId))
787                          {
788                              Trace.Warning($"log file '{log}' doesn't follow naming convension 'GUID_GUID_INT'.");
789                              continue;
790                          }
791                          if (!int.TryParse(logNameParts[2], out pageNumber))
792                          {
793                              Trace.Warning($"log file '{log}' doesn't follow naming convension 'GUID_GUID_INT'.");
794                              continue;
795                          }
796                          var record = timeline.Records.FirstOrDefault(x => x.Id == logRecordId);
797                          if (record != null)
798                          {
799                              if (!logPages.ContainsKey(record.Id))
800                              {
801                                  logPages[record.Id] = new Dictionary<int, string>();
802                                  logRecords[record.Id] = record;
803                              }
804                              logPages[record.Id][pageNumber] = log;
805                          }
806                      }
807                      foreach (var pages in logPages)
808                      {
809                          var record = logRecords[pages.Key];
810                          if (record.Log == null)
811                          {
812                              record.Log = await jobServer.CreateLogAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, new TaskLog(String.Format(@"logs\{0:D}", record.Id)), default(CancellationToken));
813                              updatedRecords.Add(record.Clone());
814                          }
815                          for (var i = 1; i <= pages.Value.Count; i++)
816                          {
817                              var logFile = pages.Value[i];
818                              using (FileStream fs = File.Open(logFile, FileMode.Open, FileAccess.Read, FileShare.ReadWrite))
819                              {
820                                  var logUploaded = await jobServer.AppendLogContentAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, record.Log.Id, fs, default(CancellationToken));
821                              }
822                              Trace.Info($"Uploaded unfinished log '{logFile}' for current job.");
823                              IOUtil.DeleteFile(logFile);
824                          }
825                      }
826                      if (updatedRecords.Count > 0)
827                      {
828                          await jobServer.UpdateTimelineRecordsAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, message.Timeline.Id, updatedRecords, CancellationToken.None);
829                      }
830                  }
831                  else
832                  {
833                      Trace.Info("Job server does not support log upload yet.");
834                  }
835              }
836              catch (Exception ex)
837              {
838                  Trace.Error(ex);
839              }
840          }
841          private async Task CompleteJobRequestAsync(int poolId, Pipelines.AgentJobRequestMessage message, ServiceEndpoint systemConnection, Guid lockToken, TaskResult result, string detailInfo = null)
842          {
843              Trace.Entering();
844              if (PlanUtil.GetFeatures(message.Plan).HasFlag(PlanFeatures.JobCompletedPlanEvent))
845              {
846                  Trace.Verbose($"Skip FinishAgentRequest call from Listener because Plan version is {message.Plan.Version}");
847                  return;
848              }
849              if (this._isRunServiceJob)
850              {
851                  Trace.Verbose($"Skip CompleteJobRequestAsync call from Listener because it's RunService job");
852                  return;
853              }
854              var runnerServer = HostContext.GetService<IRunnerServer>();
855              int completeJobRequestRetryLimit = 5;
856              List<Exception> exceptions = new();
857              while (completeJobRequestRetryLimit-- > 0)
858              {
859                  try
860                  {
861                      await runnerServer.FinishAgentRequestAsync(poolId, message.RequestId, lockToken, DateTime.UtcNow, result, CancellationToken.None);
862                      return;
863                  }
864                  catch (TaskAgentJobNotFoundException)
865                  {
866                      Trace.Info($"TaskAgentJobNotFoundException received, job {message.JobId} is no longer valid.");
867                      return;
868                  }
869                  catch (TaskAgentJobTokenExpiredException)
870                  {
871                      Trace.Info($"TaskAgentJobTokenExpiredException received, job {message.JobId} is no longer valid.");
872                      return;
873                  }
874                  catch (Exception ex)
875                  {
876                      Trace.Error($"Catch exception during complete runner jobrequest {message.RequestId}.");
877                      Trace.Error(ex);
878                      exceptions.Add(ex);
879                  }
880                  await Task.Delay(TimeSpan.FromSeconds(5));
881              }
882              throw new AggregateException(exceptions);
883          }
884          private async Task LogWorkerProcessUnhandledException(IRunnerService server, Pipelines.AgentJobRequestMessage message, string detailInfo)
885          {
886              if (server is IJobServer jobServer)
887              {
888                  try
889                  {
890                      var timeline = await jobServer.GetTimelineAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, message.Timeline.Id, CancellationToken.None);
891                      ArgUtil.NotNull(timeline, nameof(timeline));
892                      TimelineRecord jobRecord = timeline.Records.FirstOrDefault(x => x.Id == message.JobId && x.RecordType == "Job");
893                      ArgUtil.NotNull(jobRecord, nameof(jobRecord));
894                      var unhandledExceptionIssue = new Issue() { Type = IssueType.Error, Message = detailInfo };
895                      unhandledExceptionIssue.Data[Constants.Runner.InternalTelemetryIssueDataKey] = Constants.Runner.WorkerCrash;
896                      jobRecord.ErrorCount++;
897                      jobRecord.Issues.Add(unhandledExceptionIssue);
898                      await jobServer.UpdateTimelineRecordsAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, message.Timeline.Id, new TimelineRecord[] { jobRecord }, CancellationToken.None);
899                  }
900                  catch (Exception ex)
901                  {
902                      Trace.Error("Fail to report unhandled exception from Runner.Worker process");
903                      Trace.Error(ex);
904                  }
905              }
906              else
907              {
908                  Trace.Info("Job server does not support handling unhandled exception yet, error message: {0}", detailInfo);
909                  return;
910              }
911          }
912          private async Task ForceFailJob(IRunnerService server, Pipelines.AgentJobRequestMessage message, string detailInfo)
913          {
914              if (server is IJobServer jobServer)
915              {
916                  try
917                  {
918                      var jobCompletedEvent = new JobCompletedEvent(message.RequestId, message.JobId, TaskResult.Failed);
919                      await jobServer.RaisePlanEventAsync<JobCompletedEvent>(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, jobCompletedEvent, CancellationToken.None);
920                  }
921                  catch (Exception ex)
922                  {
923                      Trace.Error("Fail to raise JobCompletedEvent back to service.");
924                      Trace.Error(ex);
925                  }
926              }
927              else if (server is IRunServer runServer)
928              {
929                  try
930                  {
931                      var unhandledExceptionIssue = new Issue() { Type = IssueType.Error, Message = detailInfo };
932                      var unhandledAnnotation = unhandledExceptionIssue.ToAnnotation();
933                      var jobAnnotations = new List<Annotation>();
934                      if (unhandledAnnotation.HasValue)
935                      {
936                          jobAnnotations.Add(unhandledAnnotation.Value);
937                      }
938                      await runServer.CompleteJobAsync(message.Plan.PlanId, message.JobId, TaskResult.Failed, outputs: null, stepResults: null, jobAnnotations: jobAnnotations, environmentUrl: null, CancellationToken.None);
939                  }
940                  catch (Exception ex)
941                  {
942                      Trace.Error("Fail to raise job completion back to service.");
943                      Trace.Error(ex);
944                  }
945              }
946              else
947              {
948                  throw new NotSupportedException($"Server type {server.GetType().FullName} is not supported.");
949              }
950          }
951          private async Task<IRunnerService> InitializeJobServerAsync(ServiceEndpoint systemConnection)
952          {
953              if (this._isRunServiceJob)
954              {
955                  return await GetRunServerAsync(systemConnection);
956              }
957              else
958              {
959                  var jobServer = HostContext.GetService<IJobServer>();
960                  VssCredentials jobServerCredential = VssUtil.GetVssCredential(systemConnection);
961                  VssConnection jobConnection = VssUtil.CreateConnection(systemConnection.Url, jobServerCredential);
962                  await jobServer.ConnectAsync(jobConnection);
963                  return jobServer;
964              }
965          }
966          private async Task<IRunServer> GetRunServerAsync(ServiceEndpoint systemConnection)
967          {
968              var runServer = HostContext.GetService<IRunServer>();
969              VssCredentials jobServerCredential = VssUtil.GetVssCredential(systemConnection);
970              await runServer.ConnectAsync(systemConnection.Url, jobServerCredential);
971              return runServer;
972          }
973          private class WorkerDispatcher : IDisposable
974          {
975              public long RequestId { get; }
976              public Guid JobId { get; }
977              public Task WorkerDispatch { get; set; }
978              public CancellationTokenSource WorkerCancellationTokenSource { get; private set; }
979              public CancellationTokenSource WorkerCancelTimeoutKillTokenSource { get; private set; }
980              private readonly object _lock = new();
981              public WorkerDispatcher(Guid jobId, long requestId)
982              {
983                  JobId = jobId;
984                  RequestId = requestId;
985                  WorkerCancelTimeoutKillTokenSource = new CancellationTokenSource();
986                  WorkerCancellationTokenSource = new CancellationTokenSource();
987              }
988              public bool Cancel(TimeSpan timeout)
989              {
990                  if (WorkerCancellationTokenSource != null && WorkerCancelTimeoutKillTokenSource != null)
991                  {
992                      lock (_lock)
993                      {
994                          if (WorkerCancellationTokenSource != null && WorkerCancelTimeoutKillTokenSource != null)
995                          {
996                              WorkerCancellationTokenSource.Cancel();
997                              if (timeout.TotalSeconds < 60)
998                              {
999                                  timeout = TimeSpan.FromSeconds(60);
1000                              }
1001                              WorkerCancelTimeoutKillTokenSource.CancelAfter(timeout.Subtract(TimeSpan.FromSeconds(15)));
1002                              return true;
1003                          }
1004                      }
1005                  }
1006                  return false;
1007              }
1008              public void Dispose()
1009              {
1010                  Dispose(true);
1011                  GC.SuppressFinalize(this);
1012              }
1013              private void Dispose(bool disposing)
1014              {
1015                  if (disposing)
1016                  {
1017                      if (WorkerCancellationTokenSource != null || WorkerCancelTimeoutKillTokenSource != null)
1018                      {
1019                          lock (_lock)
1020                          {
1021                              if (WorkerCancellationTokenSource != null)
1022                              {
1023                                  WorkerCancellationTokenSource.Dispose();
1024                                  WorkerCancellationTokenSource = null;
1025                              }
1026                              if (WorkerCancelTimeoutKillTokenSource != null)
1027                              {
1028                                  WorkerCancelTimeoutKillTokenSource.Dispose();
1029                                  WorkerCancelTimeoutKillTokenSource = null;
1030                              }
1031                          }
1032                      }
1033                  }
1034              }
1035          }
1036      }
1037  }
</code></pre>
        </div>
        <div class="column">
            <h3>runner-MDEwOlJlcG9zaXRvcnkxODQyODY4NzU=-flat-JobDispatcher.cs</h3>
            <pre><code>1  using System;
2  using System.Collections.Concurrent;
3  using System.Collections.Generic;
4  using System.IO;
5  using System.Linq;
6  using System.Text;
7  using System.Text.RegularExpressions;
8  using System.Threading;
9  using System.Threading.Tasks;
10  using GitHub.DistributedTask.Pipelines;
11  using GitHub.DistributedTask.WebApi;
12  using GitHub.Runner.Common;
13  using GitHub.Runner.Common.Util;
14  using GitHub.Runner.Sdk;
15  using GitHub.Services.Common;
16  using GitHub.Services.WebApi;
17  using GitHub.Services.WebApi.Jwt;
18  using Sdk.RSWebApi.Contracts;
19  using Pipelines = GitHub.DistributedTask.Pipelines;
20  namespace GitHub.Runner.Listener
21  {
22      [ServiceLocator(Default = typeof(JobDispatcher))]
23      public interface IJobDispatcher : IRunnerService
24      {
25          bool Busy { get; }
26          TaskCompletionSource<bool> RunOnceJobCompleted { get; }
27          void Run(Pipelines.AgentJobRequestMessage message, bool runOnce = false);
28          bool Cancel(JobCancelMessage message);
29          Task WaitAsync(CancellationToken token);
30          Task ShutdownAsync();
31          event EventHandler<JobStatusEventArgs> JobStatus;
32      }
33      public sealed class JobDispatcher : RunnerService, IJobDispatcher
34      {
35          private static Regex _invalidJsonRegex = new(@"invalid\ Json\ at\ position\ '(\d+)':", RegexOptions.Compiled | RegexOptions.IgnoreCase);
36          private readonly Lazy<Dictionary<long, TaskResult>> _localRunJobResult = new();
37          private int _poolId;
38          IConfigurationStore _configurationStore;
39          RunnerSettings _runnerSettings;
40          private static readonly string _workerProcessName = $"Runner.Worker{IOUtil.ExeExtension}";
41          private readonly Queue<Guid> _jobDispatchedQueue = new();
42          private readonly ConcurrentDictionary<Guid, WorkerDispatcher> _jobInfos = new();
43          private TimeSpan _channelTimeout;
44          private TaskCompletionSource<bool> _runOnceJobCompleted = new();
45          public event EventHandler<JobStatusEventArgs> JobStatus;
46          private bool _isRunServiceJob;
47          public override void Initialize(IHostContext hostContext)
48          {
49              base.Initialize(hostContext);
50              _configurationStore = hostContext.GetService<IConfigurationStore>();
51              _runnerSettings = _configurationStore.GetSettings();
52              _poolId = _runnerSettings.PoolId;
53              int channelTimeoutSeconds;
54              if (!int.TryParse(Environment.GetEnvironmentVariable("GITHUB_ACTIONS_RUNNER_CHANNEL_TIMEOUT") ?? string.Empty, out channelTimeoutSeconds))
55              {
56                  channelTimeoutSeconds = 30;
57              }
58              _channelTimeout = TimeSpan.FromSeconds(Math.Min(Math.Max(channelTimeoutSeconds, 30), 300));
59              Trace.Info($"Set runner/worker IPC timeout to {_channelTimeout.TotalSeconds} seconds.");
60          }
61          public TaskCompletionSource<bool> RunOnceJobCompleted => _runOnceJobCompleted;
62          public bool Busy { get; private set; }
63          public void Run(Pipelines.AgentJobRequestMessage jobRequestMessage, bool runOnce = false)
64          {
65              Trace.Info($"Job request {jobRequestMessage.RequestId} for plan {jobRequestMessage.Plan.PlanId} job {jobRequestMessage.JobId} received.");
66              _isRunServiceJob = MessageUtil.IsRunServiceJob(jobRequestMessage.MessageType);
67              WorkerDispatcher currentDispatch = null;
68              if (_jobDispatchedQueue.Count > 0)
69              {
70                  Guid dispatchedJobId = _jobDispatchedQueue.Dequeue();
71                  if (_jobInfos.TryGetValue(dispatchedJobId, out currentDispatch))
72                  {
73                      Trace.Verbose($"Retrive previous WorkerDispather for job {currentDispatch.JobId}.");
74                  }
75              }
76              var orchestrationId = string.Empty;
77              var systemConnection = jobRequestMessage.Resources.Endpoints.SingleOrDefault(x => string.Equals(x.Name, WellKnownServiceEndpointNames.SystemVssConnection, StringComparison.OrdinalIgnoreCase));
78              if (systemConnection?.Authorization != null &&
79                  systemConnection.Authorization.Parameters.TryGetValue("AccessToken", out var accessToken) &&
80                  !string.IsNullOrEmpty(accessToken))
81              {
82                  var jwt = JsonWebToken.Create(accessToken);
83                  var claims = jwt.ExtractClaims();
84                  orchestrationId = claims.FirstOrDefault(x => string.Equals(x.Type, "orchid", StringComparison.OrdinalIgnoreCase))?.Value;
85                  if (!string.IsNullOrEmpty(orchestrationId))
86                  {
87                      Trace.Info($"Pull OrchestrationId {orchestrationId} from JWT claims");
88                  }
89              }
90              WorkerDispatcher newDispatch = new(jobRequestMessage.JobId, jobRequestMessage.RequestId);
91              if (runOnce)
92              {
93                  Trace.Info("Start dispatcher for one time used runner.");
94                  newDispatch.WorkerDispatch = RunOnceAsync(jobRequestMessage, orchestrationId, currentDispatch, newDispatch.WorkerCancellationTokenSource.Token, newDispatch.WorkerCancelTimeoutKillTokenSource.Token);
95              }
96              else
97              {
98                  newDispatch.WorkerDispatch = RunAsync(jobRequestMessage, orchestrationId, currentDispatch, newDispatch.WorkerCancellationTokenSource.Token, newDispatch.WorkerCancelTimeoutKillTokenSource.Token);
99              }
100              _jobInfos.TryAdd(newDispatch.JobId, newDispatch);
101              _jobDispatchedQueue.Enqueue(newDispatch.JobId);
102          }
103          public bool Cancel(JobCancelMessage jobCancelMessage)
104          {
105              Trace.Info($"Job cancellation request {jobCancelMessage.JobId} received, cancellation timeout {jobCancelMessage.Timeout.TotalMinutes} minutes.");
106              WorkerDispatcher workerDispatcher;
107              if (!_jobInfos.TryGetValue(jobCancelMessage.JobId, out workerDispatcher))
108              {
109                  Trace.Verbose($"Job request {jobCancelMessage.JobId} is not a current running job, ignore cancllation request.");
110                  return false;
111              }
112              else
113              {
114                  if (workerDispatcher.Cancel(jobCancelMessage.Timeout))
115                  {
116                      Trace.Verbose($"Fired cancellation token for job request {workerDispatcher.JobId}.");
117                  }
118                  return true;
119              }
120          }
121          public async Task WaitAsync(CancellationToken token)
122          {
123              WorkerDispatcher currentDispatch = null;
124              Guid dispatchedJobId;
125              if (_jobDispatchedQueue.Count > 0)
126              {
127                  dispatchedJobId = _jobDispatchedQueue.Dequeue();
128                  if (_jobInfos.TryGetValue(dispatchedJobId, out currentDispatch))
129                  {
130                      Trace.Verbose($"Retrive previous WorkerDispather for job {currentDispatch.JobId}.");
131                  }
132              }
133              else
134              {
135                  Trace.Verbose($"There is no running WorkerDispather needs to await.");
136              }
137              if (currentDispatch != null)
138              {
139                  using (var registration = token.Register(() => { if (currentDispatch.Cancel(TimeSpan.FromSeconds(60))) { Trace.Verbose($"Fired cancellation token for job request {currentDispatch.JobId}."); } }))
140                  {
141                      try
142                      {
143                          Trace.Info($"Waiting WorkerDispather for job {currentDispatch.JobId} run to finish.");
<span onclick='openModal()' class='match'>144                          await currentDispatch.WorkerDispatch;
145                          Trace.Info($"Job request {currentDispatch.JobId} processed succeed.");
146                      }
147                      catch (Exception ex)
</span>148                      {
149                          Trace.Error($"Worker Dispatch failed with an exception for job request {currentDispatch.JobId}.");
150                          Trace.Error(ex);
151                      }
152                      finally
153                      {
154                          WorkerDispatcher workerDispatcher;
155                          if (_jobInfos.TryRemove(currentDispatch.JobId, out workerDispatcher))
156                          {
157                              Trace.Verbose($"Remove WorkerDispather from {nameof(_jobInfos)} dictionary for job {currentDispatch.JobId}.");
158                              workerDispatcher.Dispose();
159                          }
160                      }
161                  }
162              }
163          }
164          public async Task ShutdownAsync()
165          {
166              Trace.Info($"Shutting down JobDispatcher. Make sure all WorkerDispatcher has finished.");
167              WorkerDispatcher currentDispatch = null;
168              if (_jobDispatchedQueue.Count > 0)
169              {
170                  Guid dispatchedJobId = _jobDispatchedQueue.Dequeue();
171                  if (_jobInfos.TryGetValue(dispatchedJobId, out currentDispatch))
172                  {
173                      try
174                      {
175                          Trace.Info($"Ensure WorkerDispather for job {currentDispatch.JobId} run to finish, cancel any running job.");
176                          await EnsureDispatchFinished(currentDispatch, cancelRunningJob: true);
177                      }
178                      catch (Exception ex)
179                      {
180                          Trace.Error($"Catching worker dispatch exception for job request {currentDispatch.JobId} durning job dispatcher shut down.");
181                          Trace.Error(ex);
182                      }
183                      finally
184                      {
185                          WorkerDispatcher workerDispatcher;
186                          if (_jobInfos.TryRemove(currentDispatch.JobId, out workerDispatcher))
187                          {
188                              Trace.Verbose($"Remove WorkerDispather from {nameof(_jobInfos)} dictionary for job {currentDispatch.JobId}.");
189                              workerDispatcher.Dispose();
190                          }
191                      }
192                  }
193              }
194          }
195          private async Task EnsureDispatchFinished(WorkerDispatcher jobDispatch, bool cancelRunningJob = false)
196          {
197              if (!jobDispatch.WorkerDispatch.IsCompleted)
198              {
199                  if (cancelRunningJob)
200                  {
201                      jobDispatch.WorkerCancellationTokenSource.Cancel();
202                      await jobDispatch.WorkerDispatch;
203                      return;
204                  }
205                  if (this._isRunServiceJob)
206                  {
207                      Trace.Error($"We are not yet checking the state of jobrequest {jobDispatch.JobId} status. Cancel running worker right away.");
208                      jobDispatch.WorkerCancellationTokenSource.Cancel();
209                      return;
210                  }
211                  var runnerServer = HostContext.GetService<IRunnerServer>();
212                  TaskAgentJobRequest request = null;
213                  try
214                  {
215                      request = await runnerServer.GetAgentRequestAsync(_poolId, jobDispatch.RequestId, CancellationToken.None);
216                  }
217                  catch (TaskAgentJobNotFoundException ex)
218                  {
219                      Trace.Error($"Catch job-not-found exception while checking jobrequest {jobDispatch.JobId} status. Cancel running worker right away.");
220                      Trace.Error(ex);
221                      jobDispatch.WorkerCancellationTokenSource.Cancel();
222                      await jobDispatch.WorkerDispatch;
223                      return;
224                  }
225                  catch (Exception ex)
226                  {
227                      Trace.Error($"Catch exception while checking jobrequest {jobDispatch.JobId} status. Cancel running worker right away.");
228                      Trace.Error(ex);
229                      jobDispatch.WorkerCancellationTokenSource.Cancel();
230                      await jobDispatch.WorkerDispatch;
231                      throw;
232                  }
233                  if (request.Result != null)
234                  {
235                      Trace.Error($"Received job request while previous job {jobDispatch.JobId} still running on worker. Cancel the previous job since the job request have been finished on server side with result: {request.Result.Value}.");
236                      jobDispatch.WorkerCancellationTokenSource.Cancel();
237                      Task completedTask = await Task.WhenAny(jobDispatch.WorkerDispatch, Task.Delay(TimeSpan.FromSeconds(45)));
238                      if (completedTask != jobDispatch.WorkerDispatch)
239                      {
240                          throw new InvalidOperationException($"Job dispatch process for {jobDispatch.JobId} has encountered unexpected error, the dispatch task is not able to be cancelled within 45 seconds.");
241                      }
242                  }
243                  else
244                  {
245                      throw new InvalidOperationException($"Server send a new job request while the previous job request {jobDispatch.JobId} haven't finished.");
246                  }
247              }
248              try
249              {
250                  await jobDispatch.WorkerDispatch;
251                  Trace.Info($"Job request {jobDispatch.JobId} processed succeed.");
252              }
253              catch (Exception ex)
254              {
255                  Trace.Error($"Worker Dispatch failed with an exception for job request {jobDispatch.JobId}.");
256                  Trace.Error(ex);
257              }
258              finally
259              {
260                  WorkerDispatcher workerDispatcher;
261                  if (_jobInfos.TryRemove(jobDispatch.JobId, out workerDispatcher))
262                  {
263                      Trace.Verbose($"Remove WorkerDispather from {nameof(_jobInfos)} dictionary for job {jobDispatch.JobId}.");
264                      workerDispatcher.Dispose();
265                  }
266              }
267          }
268          private async Task RunOnceAsync(Pipelines.AgentJobRequestMessage message, string orchestrationId, WorkerDispatcher previousJobDispatch, CancellationToken jobRequestCancellationToken, CancellationToken workerCancelTimeoutKillToken)
269          {
270              try
271              {
272                  await RunAsync(message, orchestrationId, previousJobDispatch, jobRequestCancellationToken, workerCancelTimeoutKillToken);
273              }
274              finally
275              {
276                  Trace.Info("Fire signal for one time used runner.");
277                  _runOnceJobCompleted.TrySetResult(true);
278              }
279          }
280          private async Task RunAsync(Pipelines.AgentJobRequestMessage message, string orchestrationId, WorkerDispatcher previousJobDispatch, CancellationToken jobRequestCancellationToken, CancellationToken workerCancelTimeoutKillToken)
281          {
282              Busy = true;
283              try
284              {
285                  if (JobStatus != null)
286                  {
287                      JobStatus(this, new JobStatusEventArgs(TaskAgentStatus.Busy));
288                  }
289                  if (previousJobDispatch != null)
290                  {
291                      Trace.Verbose($"Make sure the previous job request {previousJobDispatch.JobId} has successfully finished on worker.");
292                      await EnsureDispatchFinished(previousJobDispatch);
293                  }
294                  else
295                  {
296                      Trace.Verbose($"This is the first job request.");
297                  }
298                  var term = HostContext.GetService<ITerminal>();
299                  term.WriteLine($"{DateTime.UtcNow:u}: Running job: {message.JobDisplayName}");
300                  TaskCompletionSource<int> firstJobRequestRenewed = new();
301                  var notification = HostContext.GetService<IJobNotification>();
302                  var systemConnection = message.Resources.Endpoints.SingleOrDefault(x => string.Equals(x.Name, WellKnownServiceEndpointNames.SystemVssConnection, StringComparison.OrdinalIgnoreCase));
303                  using (var lockRenewalTokenSource = new CancellationTokenSource())
304                  using (var workerProcessCancelTokenSource = new CancellationTokenSource())
305                  {
306                      long requestId = message.RequestId;
307                      Guid lockToken = Guid.Empty; 
308                      Trace.Info($"Start renew job request {requestId} for job {message.JobId}.");
309                      Task renewJobRequest = RenewJobRequestAsync(message, systemConnection, _poolId, requestId, lockToken, orchestrationId, firstJobRequestRenewed, lockRenewalTokenSource.Token);
310                      await Task.WhenAny(firstJobRequestRenewed.Task, renewJobRequest, Task.Delay(-1, jobRequestCancellationToken));
311                      if (renewJobRequest.IsCompleted)
312                      {
313                          Trace.Info($"Unable to renew job request for job {message.JobId} for the first time, stop dispatching job to worker.");
314                          return;
315                      }
316                      if (jobRequestCancellationToken.IsCancellationRequested)
317                      {
318                          Trace.Info($"Stop renew job request for job {message.JobId}.");
319                          lockRenewalTokenSource.Cancel();
320                          await renewJobRequest;
321                          await CompleteJobRequestAsync(_poolId, message, systemConnection, lockToken, TaskResult.Canceled);
322                          return;
323                      }
324                      HostContext.WritePerfCounter($"JobRequestRenewed_{requestId.ToString()}");
325                      Task<int> workerProcessTask = null;
326                      object _outputLock = new();
327                      List<string> workerOutput = new();
328                      bool printToStdout = StringUtil.ConvertToBoolean(Environment.GetEnvironmentVariable(Constants.Variables.Agent.PrintLogToStdout));
329                      using (var processChannel = HostContext.CreateService<IProcessChannel>())
330                      using (var processInvoker = HostContext.CreateService<IProcessInvoker>())
331                      {
332                          processChannel.StartServer(
333                              startProcess: (string pipeHandleOut, string pipeHandleIn) =>
334                              {
335                                  ArgUtil.NotNullOrEmpty(pipeHandleOut, nameof(pipeHandleOut));
336                                  ArgUtil.NotNullOrEmpty(pipeHandleIn, nameof(pipeHandleIn));
337                                  processInvoker.OutputDataReceived += delegate (object sender, ProcessDataReceivedEventArgs stdout)
338                                      {
339                                          if (!string.IsNullOrEmpty(stdout.Data))
340                                          {
341                                              lock (_outputLock)
342                                              {
343                                                  if (!stdout.Data.StartsWith("[WORKER"))
344                                                  {
345                                                      workerOutput.Add(stdout.Data);
346                                                  }
347                                                  if (printToStdout)
348                                                  {
349                                                      term.WriteLine(stdout.Data, skipTracing: true);
350                                                  }
351                                              }
352                                          }
353                                      };
354                                  processInvoker.ErrorDataReceived += delegate (object sender, ProcessDataReceivedEventArgs stderr)
355                                      {
356                                          if (!string.IsNullOrEmpty(stderr.Data))
357                                          {
358                                              lock (_outputLock)
359                                              {
360                                                  workerOutput.Add(stderr.Data);
361                                              }
362                                          }
363                                      };
364                                  HostContext.WritePerfCounter("StartingWorkerProcess");
365                                  var assemblyDirectory = HostContext.GetDirectory(WellKnownDirectory.Bin);
366                                  string workerFileName = Path.Combine(assemblyDirectory, _workerProcessName);
367                                  workerProcessTask = processInvoker.ExecuteAsync(
368                                      workingDirectory: assemblyDirectory,
369                                      fileName: workerFileName,
370                                      arguments: "spawnclient " + pipeHandleOut + " " + pipeHandleIn,
371                                      environment: null,
372                                      requireExitCodeZero: false,
373                                      outputEncoding: null,
374                                      killProcessOnCancel: true,
375                                      redirectStandardIn: null,
376                                      inheritConsoleHandler: false,
377                                      keepStandardInOpen: false,
378                                      highPriorityProcess: true,
379                                      cancellationToken: workerProcessCancelTokenSource.Token);
380                              });
381                          try
382                          {
383                              Trace.Info($"Send job request message to worker for job {message.JobId}.");
384                              HostContext.WritePerfCounter($"RunnerSendingJobToWorker_{message.JobId}");
385                              using (var csSendJobRequest = new CancellationTokenSource(_channelTimeout))
386                              {
387                                  await processChannel.SendAsync(
388                                      messageType: MessageType.NewJobRequest,
389                                      body: JsonUtility.ToString(message),
390                                      cancellationToken: csSendJobRequest.Token);
391                              }
392                          }
393                          catch (OperationCanceledException)
394                          {
395                              Trace.Info($"Job request message sending for job {message.JobId} been cancelled, kill running worker.");
396                              workerProcessCancelTokenSource.Cancel();
397                              try
398                              {
399                                  await workerProcessTask;
400                              }
401                              catch (OperationCanceledException)
402                              {
403                                  Trace.Info("worker process has been killed.");
404                              }
405                              Trace.Info($"Stop renew job request for job {message.JobId}.");
406                              lockRenewalTokenSource.Cancel();
407                              await renewJobRequest;
408                              return;
409                          }
410                          var accessToken = systemConnection?.Authorization?.Parameters["AccessToken"];
411                          notification.JobStarted(message.JobId, accessToken, systemConnection.Url);
412                          HostContext.WritePerfCounter($"SentJobToWorker_{requestId.ToString()}");
413                          try
414                          {
415                              TaskResult resultOnAbandonOrCancel = TaskResult.Succeeded;
416                              var completedTask = await Task.WhenAny(renewJobRequest, workerProcessTask, Task.Delay(-1, jobRequestCancellationToken));
417                              if (completedTask == workerProcessTask)
418                              {
419                                  int returnCode = await workerProcessTask;
420                                  Trace.Info($"Worker finished for job {message.JobId}. Code: " + returnCode);
421                                  string detailInfo = null;
422                                  if (!TaskResultUtil.IsValidReturnCode(returnCode))
423                                  {
424                                      detailInfo = string.Join(Environment.NewLine, workerOutput);
425                                      Trace.Info($"Return code {returnCode} indicate worker encounter an unhandled exception or app crash, attach worker stdout/stderr to JobRequest result.");
426                                      var jobServer = await InitializeJobServerAsync(systemConnection);
427                                      await LogWorkerProcessUnhandledException(jobServer, message, detailInfo);
428                                      if (detailInfo.Contains(typeof(System.IO.IOException).ToString(), StringComparison.OrdinalIgnoreCase))
429                                      {
430                                          Trace.Info($"Finish job with result 'Failed' due to IOException.");
431                                          await ForceFailJob(jobServer, message, detailInfo);
432                                      }
433                                  }
434                                  TaskResult result = TaskResultUtil.TranslateFromReturnCode(returnCode);
435                                  Trace.Info($"finish job request for job {message.JobId} with result: {result}");
436                                  term.WriteLine($"{DateTime.UtcNow:u}: Job {message.JobDisplayName} completed with result: {result}");
437                                  Trace.Info($"Stop renew job request for job {message.JobId}.");
438                                  lockRenewalTokenSource.Cancel();
439                                  await renewJobRequest;
440                                  await CompleteJobRequestAsync(_poolId, message, systemConnection, lockToken, result, detailInfo);
441                                  if (!string.IsNullOrEmpty(detailInfo))
442                                  {
443                                      Trace.Error("Unhandled exception happened in worker:");
444                                      Trace.Error(detailInfo);
445                                  }
446                                  return;
447                              }
448                              else if (completedTask == renewJobRequest)
449                              {
450                                  resultOnAbandonOrCancel = TaskResult.Abandoned;
451                              }
452                              else
453                              {
454                                  resultOnAbandonOrCancel = TaskResult.Canceled;
455                              }
456                              try
457                              {
458                                  Trace.Info($"Send job cancellation message to worker for job {message.JobId}.");
459                                  using (var csSendCancel = new CancellationTokenSource(_channelTimeout))
460                                  {
461                                      var messageType = MessageType.CancelRequest;
462                                      if (HostContext.RunnerShutdownToken.IsCancellationRequested)
463                                      {
464                                          switch (HostContext.RunnerShutdownReason)
465                                          {
466                                              case ShutdownReason.UserCancelled:
467                                                  messageType = MessageType.RunnerShutdown;
468                                                  break;
469                                              case ShutdownReason.OperatingSystemShutdown:
470                                                  messageType = MessageType.OperatingSystemShutdown;
471                                                  break;
472                                          }
473                                      }
474                                      await processChannel.SendAsync(
475                                          messageType: messageType,
476                                          body: string.Empty,
477                                          cancellationToken: csSendCancel.Token);
478                                  }
479                              }
480                              catch (OperationCanceledException)
481                              {
482                                  Trace.Info($"Job cancel message sending for job {message.JobId} been cancelled, kill running worker.");
483                                  workerProcessCancelTokenSource.Cancel();
484                                  try
485                                  {
486                                      await workerProcessTask;
487                                  }
488                                  catch (OperationCanceledException)
489                                  {
490                                      Trace.Info("worker process has been killed.");
491                                  }
492                              }
493                              completedTask = await Task.WhenAny(workerProcessTask, Task.Delay(-1, workerCancelTimeoutKillToken));
494                              if (completedTask != workerProcessTask)
495                              {
496                                  Trace.Info($"worker process for job {message.JobId} haven't exit within cancellation timout, kill running worker.");
497                                  workerProcessCancelTokenSource.Cancel();
498                                  try
499                                  {
500                                      await workerProcessTask;
501                                  }
502                                  catch (OperationCanceledException)
503                                  {
504                                      Trace.Info("worker process has been killed.");
505                                  }
506                                  await TryUploadUnfinishedLogs(message);
507                              }
508                              Trace.Info($"finish job request for job {message.JobId} with result: {resultOnAbandonOrCancel}");
509                              term.WriteLine($"{DateTime.UtcNow:u}: Job {message.JobDisplayName} completed with result: {resultOnAbandonOrCancel}");
510                              Trace.Info($"Stop renew job request for job {message.JobId}.");
511                              lockRenewalTokenSource.Cancel();
512                              await renewJobRequest;
513                              await CompleteJobRequestAsync(_poolId, message, systemConnection, lockToken, resultOnAbandonOrCancel);
514                          }
515                          finally
516                          {
517                              await notification.JobCompleted(message.JobId);
518                          }
519                      }
520                  }
521              }
522              finally
523              {
524                  Busy = false;
525                  if (JobStatus != null)
526                  {
527                      JobStatus(this, new JobStatusEventArgs(TaskAgentStatus.Online));
528                  }
529              }
530          }
531          internal async Task RenewJobRequestAsync(Pipelines.AgentJobRequestMessage message, ServiceEndpoint systemConnection, int poolId, long requestId, Guid lockToken, string orchestrationId, TaskCompletionSource<int> firstJobRequestRenewed, CancellationToken token)
532          {
533              if (this._isRunServiceJob)
534              {
535                  var runServer = await GetRunServerAsync(systemConnection);
536                  await RenewJobRequestAsync(runServer, message.Plan.PlanId, message.JobId, firstJobRequestRenewed, token);
537              }
538              else
539              {
540                  var runnerServer = HostContext.GetService<IRunnerServer>();
541                  await RenewJobRequestAsync(runnerServer, poolId, requestId, lockToken, orchestrationId, firstJobRequestRenewed, token);
542              }
543          }
544          private async Task RenewJobRequestAsync(IRunServer runServer, Guid planId, Guid jobId, TaskCompletionSource<int> firstJobRequestRenewed, CancellationToken token)
545          {
546              TaskAgentJobRequest request = null;
547              int firstRenewRetryLimit = 5;
548              int encounteringError = 0;
549              while (!token.IsCancellationRequested)
550              {
551                  try
552                  {
553                      var renewResponse = await runServer.RenewJobAsync(planId, jobId, token);
554                      Trace.Info($"Successfully renew job {jobId}, job is valid till {renewResponse.LockedUntil}");
555                      if (!firstJobRequestRenewed.Task.IsCompleted)
556                      {
557                          firstJobRequestRenewed.TrySetResult(0);
558                      }
559                      if (encounteringError > 0)
560                      {
561                          encounteringError = 0;
562                          HostContext.WritePerfCounter("JobRenewRecovered");
563                      }
564                      await HostContext.Delay(TimeSpan.FromSeconds(60), token);
565                  }
566                  catch (TaskOrchestrationJobNotFoundException)
567                  {
568                      Trace.Info($"TaskAgentJobNotFoundException received when renew job {jobId}, job is no longer valid, stop renew job request.");
569                      return;
570                  }
571                  catch (OperationCanceledException) when (token.IsCancellationRequested)
572                  {
573                      Trace.Info($"job renew has been cancelled, stop renew job {jobId}.");
574                      return;
575                  }
576                  catch (Exception ex)
577                  {
578                      Trace.Error($"Catch exception during renew runner job {jobId}.");
579                      Trace.Error(ex);
580                      encounteringError++;
581                      TimeSpan remainingTime = TimeSpan.Zero;
582                      if (!firstJobRequestRenewed.Task.IsCompleted)
583                      {
584                          if (firstRenewRetryLimit-- > 0)
585                          {
586                              remainingTime = TimeSpan.FromSeconds(10);
587                          }
588                      }
589                      else
590                      {
591                          remainingTime = request.LockedUntil.Value + TimeSpan.FromMinutes(5) - DateTime.UtcNow;
592                      }
593                      if (remainingTime > TimeSpan.Zero)
594                      {
595                          TimeSpan delayTime;
596                          if (!firstJobRequestRenewed.Task.IsCompleted)
597                          {
598                              Trace.Info($"Retrying lock renewal for job {jobId}. The first job renew request has failed.");
599                              delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(10));
600                          }
601                          else
602                          {
603                              Trace.Info($"Retrying lock renewal for job {jobId}. Job is valid until {request.LockedUntil.Value}.");
604                              if (encounteringError > 5)
605                              {
606                                  delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(15), TimeSpan.FromSeconds(30));
607                              }
608                              else
609                              {
610                                  delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(15));
611                              }
612                          }
613                          try
614                          {
615                              await HostContext.Delay(delayTime, token);
616                          }
617                          catch (OperationCanceledException) when (token.IsCancellationRequested)
618                          {
619                              Trace.Info($"job renew has been cancelled, stop renew job {jobId}.");
620                          }
621                      }
622                      else
623                      {
624                          Trace.Info($"Lock renewal has run out of retry, stop renew lock for job {jobId}.");
625                          HostContext.WritePerfCounter("JobRenewReachLimit");
626                          return;
627                      }
628                  }
629              }
630          }
631          private async Task RenewJobRequestAsync(IRunnerServer runnerServer, int poolId, long requestId, Guid lockToken, string orchestrationId, TaskCompletionSource<int> firstJobRequestRenewed, CancellationToken token)
632          {
633              TaskAgentJobRequest request = null;
634              int firstRenewRetryLimit = 5;
635              int encounteringError = 0;
636              while (!token.IsCancellationRequested)
637              {
638                  try
639                  {
640                      request = await runnerServer.RenewAgentRequestAsync(poolId, requestId, lockToken, orchestrationId, token);
641                      Trace.Info($"Successfully renew job request {requestId}, job is valid till {request.LockedUntil.Value}");
642                      if (!firstJobRequestRenewed.Task.IsCompleted)
643                      {
644                          firstJobRequestRenewed.TrySetResult(0);
645                          UpdateAgentNameIfNeeded(request.ReservedAgent?.Name);
646                      }
647                      if (encounteringError > 0)
648                      {
649                          encounteringError = 0;
650                          runnerServer.SetConnectionTimeout(RunnerConnectionType.JobRequest, TimeSpan.FromSeconds(60));
651                          HostContext.WritePerfCounter("JobRenewRecovered");
652                      }
653                      await HostContext.Delay(TimeSpan.FromSeconds(60), token);
654                  }
655                  catch (TaskAgentJobNotFoundException)
656                  {
657                      Trace.Info($"TaskAgentJobNotFoundException received when renew job request {requestId}, job is no longer valid, stop renew job request.");
658                      return;
659                  }
660                  catch (TaskAgentJobTokenExpiredException)
661                  {
662                      Trace.Info($"TaskAgentJobTokenExpiredException received renew job request {requestId}, job is no longer valid, stop renew job request.");
663                      return;
664                  }
665                  catch (OperationCanceledException) when (token.IsCancellationRequested)
666                  {
667                      Trace.Info($"job renew has been cancelled, stop renew job request {requestId}.");
668                      return;
669                  }
670                  catch (Exception ex)
671                  {
672                      Trace.Error($"Catch exception during renew runner jobrequest {requestId}.");
673                      Trace.Error(ex);
674                      encounteringError++;
675                      TimeSpan remainingTime = TimeSpan.Zero;
676                      if (!firstJobRequestRenewed.Task.IsCompleted)
677                      {
678                          if (firstRenewRetryLimit-- > 0)
679                          {
680                              remainingTime = TimeSpan.FromSeconds(10);
681                          }
682                      }
683                      else
684                      {
685                          remainingTime = request.LockedUntil.Value + TimeSpan.FromMinutes(5) - DateTime.UtcNow;
686                      }
687                      if (remainingTime > TimeSpan.Zero)
688                      {
689                          TimeSpan delayTime;
690                          if (!firstJobRequestRenewed.Task.IsCompleted)
691                          {
692                              Trace.Info($"Retrying lock renewal for jobrequest {requestId}. The first job renew request has failed.");
693                              delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(10));
694                          }
695                          else
696                          {
697                              Trace.Info($"Retrying lock renewal for jobrequest {requestId}. Job is valid until {request.LockedUntil.Value}.");
698                              if (encounteringError > 5)
699                              {
700                                  delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(15), TimeSpan.FromSeconds(30));
701                              }
702                              else
703                              {
704                                  delayTime = BackoffTimerHelper.GetRandomBackoff(TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(15));
705                              }
706                          }
707                          HostContext.WritePerfCounter("ResetJobRenewConnection");
708                          await runnerServer.RefreshConnectionAsync(RunnerConnectionType.JobRequest, TimeSpan.FromSeconds(30));
709                          try
710                          {
711                              await HostContext.Delay(delayTime, token);
712                          }
713                          catch (OperationCanceledException) when (token.IsCancellationRequested)
714                          {
715                              Trace.Info($"job renew has been cancelled, stop renew job request {requestId}.");
716                          }
717                      }
718                      else
719                      {
720                          Trace.Info($"Lock renewal has run out of retry, stop renew lock for jobrequest {requestId}.");
721                          HostContext.WritePerfCounter("JobRenewReachLimit");
722                          return;
723                      }
724                  }
725              }
726          }
727          private void UpdateAgentNameIfNeeded(string agentName)
728          {
729              var isNewAgentName = !string.Equals(_runnerSettings.AgentName, agentName, StringComparison.Ordinal);
730              if (!isNewAgentName || string.IsNullOrEmpty(agentName))
731              {
732                  return;
733              }
734              _runnerSettings.AgentName = agentName;
735              try
736              {
737                  _configurationStore.SaveSettings(_runnerSettings);
738              }
739              catch (Exception ex)
740              {
741                  Trace.Error("Cannot update the settings file:");
742                  Trace.Error(ex);
743              }
744          }
745          private async Task TryUploadUnfinishedLogs(Pipelines.AgentJobRequestMessage message)
746          {
747              Trace.Entering();
748              var logFolder = Path.Combine(HostContext.GetDirectory(WellKnownDirectory.Diag), PagingLogger.PagingFolder);
749              if (!Directory.Exists(logFolder))
750              {
751                  return;
752              }
753              var logs = Directory.GetFiles(logFolder);
754              if (logs.Length == 0)
755              {
756                  return;
757              }
758              try
759              {
760                  var systemConnection = message.Resources.Endpoints.SingleOrDefault(x => string.Equals(x.Name, WellKnownServiceEndpointNames.SystemVssConnection));
761                  ArgUtil.NotNull(systemConnection, nameof(systemConnection));
762                  var server = await InitializeJobServerAsync(systemConnection);
763                  if (server is IJobServer jobServer)
764                  {
765                      var timeline = await jobServer.GetTimelineAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, message.Timeline.Id, CancellationToken.None);
766                      var updatedRecords = new List<TimelineRecord>();
767                      var logPages = new Dictionary<Guid, Dictionary<int, string>>();
768                      var logRecords = new Dictionary<Guid, TimelineRecord>();
769                      foreach (var log in logs)
770                      {
771                          var logName = Path.GetFileNameWithoutExtension(log);
772                          var logNameParts = logName.Split('_', StringSplitOptions.RemoveEmptyEntries);
773                          if (logNameParts.Length != 3)
774                          {
775                              Trace.Warning($"log file '{log}' doesn't follow naming convension 'GUID_GUID_INT'.");
776                              continue;
777                          }
778                          var logPageSeperator = logName.IndexOf('_');
779                          var logRecordId = Guid.Empty;
780                          var pageNumber = 0;
781                          if (!Guid.TryParse(logNameParts[0], out Guid timelineId) || timelineId != timeline.Id)
782                          {
783                              Trace.Warning($"log file '{log}' is not belongs to current job");
784                              continue;
785                          }
786                          if (!Guid.TryParse(logNameParts[1], out logRecordId))
787                          {
788                              Trace.Warning($"log file '{log}' doesn't follow naming convension 'GUID_GUID_INT'.");
789                              continue;
790                          }
791                          if (!int.TryParse(logNameParts[2], out pageNumber))
792                          {
793                              Trace.Warning($"log file '{log}' doesn't follow naming convension 'GUID_GUID_INT'.");
794                              continue;
795                          }
796                          var record = timeline.Records.FirstOrDefault(x => x.Id == logRecordId);
797                          if (record != null)
798                          {
799                              if (!logPages.ContainsKey(record.Id))
800                              {
801                                  logPages[record.Id] = new Dictionary<int, string>();
802                                  logRecords[record.Id] = record;
803                              }
804                              logPages[record.Id][pageNumber] = log;
805                          }
806                      }
807                      foreach (var pages in logPages)
808                      {
809                          var record = logRecords[pages.Key];
810                          if (record.Log == null)
811                          {
812                              record.Log = await jobServer.CreateLogAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, new TaskLog(String.Format(@"logs\{0:D}", record.Id)), default(CancellationToken));
813                              updatedRecords.Add(record.Clone());
814                          }
815                          for (var i = 1; i <= pages.Value.Count; i++)
816                          {
817                              var logFile = pages.Value[i];
818                              using (FileStream fs = File.Open(logFile, FileMode.Open, FileAccess.Read, FileShare.ReadWrite))
819                              {
820                                  var logUploaded = await jobServer.AppendLogContentAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, record.Log.Id, fs, default(CancellationToken));
821                              }
822                              Trace.Info($"Uploaded unfinished log '{logFile}' for current job.");
823                              IOUtil.DeleteFile(logFile);
824                          }
825                      }
826                      if (updatedRecords.Count > 0)
827                      {
828                          await jobServer.UpdateTimelineRecordsAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, message.Timeline.Id, updatedRecords, CancellationToken.None);
829                      }
830                  }
831                  else
832                  {
833                      Trace.Info("Job server does not support log upload yet.");
834                  }
835              }
836              catch (Exception ex)
837              {
838                  Trace.Error(ex);
839              }
840          }
841          private async Task CompleteJobRequestAsync(int poolId, Pipelines.AgentJobRequestMessage message, ServiceEndpoint systemConnection, Guid lockToken, TaskResult result, string detailInfo = null)
842          {
843              Trace.Entering();
844              if (PlanUtil.GetFeatures(message.Plan).HasFlag(PlanFeatures.JobCompletedPlanEvent))
845              {
846                  Trace.Verbose($"Skip FinishAgentRequest call from Listener because Plan version is {message.Plan.Version}");
847                  return;
848              }
849              if (this._isRunServiceJob)
850              {
851                  Trace.Verbose($"Skip CompleteJobRequestAsync call from Listener because it's RunService job");
852                  return;
853              }
854              var runnerServer = HostContext.GetService<IRunnerServer>();
855              int completeJobRequestRetryLimit = 5;
856              List<Exception> exceptions = new();
857              while (completeJobRequestRetryLimit-- > 0)
858              {
859                  try
860                  {
861                      await runnerServer.FinishAgentRequestAsync(poolId, message.RequestId, lockToken, DateTime.UtcNow, result, CancellationToken.None);
862                      return;
863                  }
864                  catch (TaskAgentJobNotFoundException)
865                  {
866                      Trace.Info($"TaskAgentJobNotFoundException received, job {message.JobId} is no longer valid.");
867                      return;
868                  }
869                  catch (TaskAgentJobTokenExpiredException)
870                  {
871                      Trace.Info($"TaskAgentJobTokenExpiredException received, job {message.JobId} is no longer valid.");
872                      return;
873                  }
874                  catch (Exception ex)
875                  {
876                      Trace.Error($"Catch exception during complete runner jobrequest {message.RequestId}.");
877                      Trace.Error(ex);
878                      exceptions.Add(ex);
879                  }
880                  await Task.Delay(TimeSpan.FromSeconds(5));
881              }
882              throw new AggregateException(exceptions);
883          }
884          private async Task LogWorkerProcessUnhandledException(IRunnerService server, Pipelines.AgentJobRequestMessage message, string detailInfo)
885          {
886              if (server is IJobServer jobServer)
887              {
888                  try
889                  {
890                      var timeline = await jobServer.GetTimelineAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, message.Timeline.Id, CancellationToken.None);
891                      ArgUtil.NotNull(timeline, nameof(timeline));
892                      TimelineRecord jobRecord = timeline.Records.FirstOrDefault(x => x.Id == message.JobId && x.RecordType == "Job");
893                      ArgUtil.NotNull(jobRecord, nameof(jobRecord));
894                      var unhandledExceptionIssue = new Issue() { Type = IssueType.Error, Message = detailInfo };
895                      unhandledExceptionIssue.Data[Constants.Runner.InternalTelemetryIssueDataKey] = Constants.Runner.WorkerCrash;
896                      jobRecord.ErrorCount++;
897                      jobRecord.Issues.Add(unhandledExceptionIssue);
898                      await jobServer.UpdateTimelineRecordsAsync(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, message.Timeline.Id, new TimelineRecord[] { jobRecord }, CancellationToken.None);
899                  }
900                  catch (Exception ex)
901                  {
902                      Trace.Error("Fail to report unhandled exception from Runner.Worker process");
903                      Trace.Error(ex);
904                  }
905              }
906              else
907              {
908                  Trace.Info("Job server does not support handling unhandled exception yet, error message: {0}", detailInfo);
909                  return;
910              }
911          }
912          private async Task ForceFailJob(IRunnerService server, Pipelines.AgentJobRequestMessage message, string detailInfo)
913          {
914              if (server is IJobServer jobServer)
915              {
916                  try
917                  {
918                      var jobCompletedEvent = new JobCompletedEvent(message.RequestId, message.JobId, TaskResult.Failed);
919                      await jobServer.RaisePlanEventAsync<JobCompletedEvent>(message.Plan.ScopeIdentifier, message.Plan.PlanType, message.Plan.PlanId, jobCompletedEvent, CancellationToken.None);
920                  }
921                  catch (Exception ex)
922                  {
923                      Trace.Error("Fail to raise JobCompletedEvent back to service.");
924                      Trace.Error(ex);
925                  }
926              }
927              else if (server is IRunServer runServer)
928              {
929                  try
930                  {
931                      var unhandledExceptionIssue = new Issue() { Type = IssueType.Error, Message = detailInfo };
932                      var unhandledAnnotation = unhandledExceptionIssue.ToAnnotation();
933                      var jobAnnotations = new List<Annotation>();
934                      if (unhandledAnnotation.HasValue)
935                      {
936                          jobAnnotations.Add(unhandledAnnotation.Value);
937                      }
938                      await runServer.CompleteJobAsync(message.Plan.PlanId, message.JobId, TaskResult.Failed, outputs: null, stepResults: null, jobAnnotations: jobAnnotations, environmentUrl: null, CancellationToken.None);
939                  }
940                  catch (Exception ex)
941                  {
942                      Trace.Error("Fail to raise job completion back to service.");
943                      Trace.Error(ex);
944                  }
945              }
946              else
947              {
948                  throw new NotSupportedException($"Server type {server.GetType().FullName} is not supported.");
949              }
950          }
951          private async Task<IRunnerService> InitializeJobServerAsync(ServiceEndpoint systemConnection)
952          {
953              if (this._isRunServiceJob)
954              {
955                  return await GetRunServerAsync(systemConnection);
956              }
957              else
958              {
959                  var jobServer = HostContext.GetService<IJobServer>();
960                  VssCredentials jobServerCredential = VssUtil.GetVssCredential(systemConnection);
961                  VssConnection jobConnection = VssUtil.CreateConnection(systemConnection.Url, jobServerCredential);
962                  await jobServer.ConnectAsync(jobConnection);
963                  return jobServer;
964              }
965          }
966          private async Task<IRunServer> GetRunServerAsync(ServiceEndpoint systemConnection)
967          {
968              var runServer = HostContext.GetService<IRunServer>();
969              VssCredentials jobServerCredential = VssUtil.GetVssCredential(systemConnection);
970              await runServer.ConnectAsync(systemConnection.Url, jobServerCredential);
971              return runServer;
972          }
973          private class WorkerDispatcher : IDisposable
974          {
975              public long RequestId { get; }
976              public Guid JobId { get; }
977              public Task WorkerDispatch { get; set; }
978              public CancellationTokenSource WorkerCancellationTokenSource { get; private set; }
979              public CancellationTokenSource WorkerCancelTimeoutKillTokenSource { get; private set; }
980              private readonly object _lock = new();
981              public WorkerDispatcher(Guid jobId, long requestId)
982              {
983                  JobId = jobId;
984                  RequestId = requestId;
985                  WorkerCancelTimeoutKillTokenSource = new CancellationTokenSource();
986                  WorkerCancellationTokenSource = new CancellationTokenSource();
987              }
988              public bool Cancel(TimeSpan timeout)
989              {
990                  if (WorkerCancellationTokenSource != null && WorkerCancelTimeoutKillTokenSource != null)
991                  {
992                      lock (_lock)
993                      {
994                          if (WorkerCancellationTokenSource != null && WorkerCancelTimeoutKillTokenSource != null)
995                          {
996                              WorkerCancellationTokenSource.Cancel();
997                              if (timeout.TotalSeconds < 60)
998                              {
999                                  timeout = TimeSpan.FromSeconds(60);
1000                              }
1001                              WorkerCancelTimeoutKillTokenSource.CancelAfter(timeout.Subtract(TimeSpan.FromSeconds(15)));
1002                              return true;
1003                          }
1004                      }
1005                  }
1006                  return false;
1007              }
1008              public void Dispose()
1009              {
1010                  Dispose(true);
1011                  GC.SuppressFinalize(this);
1012              }
1013              private void Dispose(bool disposing)
1014              {
1015                  if (disposing)
1016                  {
1017                      if (WorkerCancellationTokenSource != null || WorkerCancelTimeoutKillTokenSource != null)
1018                      {
1019                          lock (_lock)
1020                          {
1021                              if (WorkerCancellationTokenSource != null)
1022                              {
1023                                  WorkerCancellationTokenSource.Dispose();
1024                                  WorkerCancellationTokenSource = null;
1025                              }
1026                              if (WorkerCancelTimeoutKillTokenSource != null)
1027                              {
1028                                  WorkerCancelTimeoutKillTokenSource.Dispose();
1029                                  WorkerCancelTimeoutKillTokenSource = null;
1030                              }
1031                          }
1032                      }
1033                  }
1034              }
1035          }
1036      }
1037  }
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from runner-MDEwOlJlcG9zaXRvcnkxODQyODY4NzU=-flat-JobDispatcher.cs</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from runner-MDEwOlJlcG9zaXRvcnkxODQyODY4NzU=-flat-JobDispatcher.cs</div>
                </div>
                <div class="column column_space"><pre><code>144                          await currentDispatch.WorkerDispatch;
145                          Trace.Info($"Job request {currentDispatch.JobId} processed succeed.");
146                      }
147                      catch (Exception ex)
</pre></code></div>
                <div class="column column_space"><pre><code>144                          await currentDispatch.WorkerDispatch;
145                          Trace.Info($"Job request {currentDispatch.JobId} processed succeed.");
146                      }
147                      catch (Exception ex)
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    