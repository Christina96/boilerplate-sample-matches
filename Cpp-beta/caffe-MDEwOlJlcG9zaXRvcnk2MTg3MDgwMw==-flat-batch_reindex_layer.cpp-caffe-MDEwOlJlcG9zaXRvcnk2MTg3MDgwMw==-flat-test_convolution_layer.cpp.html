
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 3.117206982543641%, Tokens: 16, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-batch_reindex_layer.cpp</h3>
            <pre><code>1  #include <vector>
2  #include "caffe/layers/batch_reindex_layer.hpp"
3  #include "caffe/util/math_functions.hpp"
4  namespace caffe {
5  template<typename Dtype>
6  void BatchReindexLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
7                                         const vector<Blob<Dtype>*>& top) {
8    CHECK_EQ(1, bottom[1]->num_axes());
9    vector<int> newshape;
10    newshape.push_back(bottom[1]->shape(0));
11    for (int i = 1; i < bottom[0]->shape().size(); ++i) {
12      newshape.push_back(bottom[0]->shape()[i]);
13    }
14    top[0]->Reshape(newshape);
15  }
16  template<typename Dtype>
17  void BatchReindexLayer<Dtype>::check_batch_reindex(int initial_num,
18                                                     int final_num,
19                                                     const Dtype* ridx_data) {
20    for (int i = 0; i < final_num; ++i) {
21      CHECK_GE(ridx_data[i], 0)
22          << "Index specified for reindex layer was negative.";
23      CHECK_LT(ridx_data[i], initial_num)
24          << "Index specified for reindex layer was greater than batch size.";
25    }
26  }
27  template<typename Dtype>
28  void BatchReindexLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
29                                             const vector<Blob<Dtype>*>& top) {
30    check_batch_reindex(bottom[0]->shape(0), bottom[1]->count(),
31                        bottom[1]->cpu_data());
32    if (top[0]->count() == 0) {
33      return;
34    }
<span onclick='openModal()' class='match'>35    int inner_dim = bottom[0]->count() / bottom[0]->shape(0);
36    const Dtype* in = bottom[0]->cpu_data();
37    const Dtype* permut = bottom[1]->cpu_data();
38    Dtype* out = top[0]->mutable_cpu_data();
39    for (int index = 0; index < top[0]->count(); ++index) {
</span>40      int n = index / (inner_dim);
41      int in_n = static_cast<int>(permut[n]);
42      out[index] = in[in_n * (inner_dim) + index % (inner_dim)];
43    }
44  }
45  template<typename Dtype>
46  void BatchReindexLayer<Dtype>::Backward_cpu(
47      const vector<Blob<Dtype>*>& top, const vector<bool>& propagate_down,
48      const vector<Blob<Dtype>*>& bottom) {
49    CHECK(!propagate_down[1]) << "Cannot backprop to index.";
50    if (!propagate_down[0]) {
51      return;
52    }
53    int inner_dim = bottom[0]->count() / bottom[0]->shape(0);
54    Dtype* bot_diff = bottom[0]->mutable_cpu_diff();
55    const Dtype* permut = bottom[1]->cpu_data();
56    const Dtype* top_diff = top[0]->cpu_diff();
57    caffe_set(bottom[0]->count(), Dtype(0), bot_diff);
58    for (int index = 0; index < top[0]->count(); ++index) {
59      int n = index / (inner_dim);
60      int in_n = static_cast<int>(permut[n]);
61      bot_diff[in_n * (inner_dim) + index % (inner_dim)] += top_diff[index];
62    }
63  }
64  #ifdef CPU_ONLY
65  STUB_GPU(BatchReindexLayer);
66  #endif
67  INSTANTIATE_CLASS(BatchReindexLayer);
68  REGISTER_LAYER_CLASS(BatchReindex);
69  }  
</code></pre>
        </div>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-test_convolution_layer.cpp</h3>
            <pre><code>1  #include <vector>
2  #include "gtest/gtest.h"
3  #include "caffe/blob.hpp"
4  #include "caffe/common.hpp"
5  #include "caffe/filler.hpp"
6  #include "caffe/layers/conv_layer.hpp"
7  #ifdef USE_CUDNN
8  #include "caffe/layers/cudnn_conv_layer.hpp"
9  #endif
10  #include "caffe/test/test_caffe_main.hpp"
11  #include "caffe/test/test_gradient_check_util.hpp"
12  namespace caffe {
13  template <typename Dtype>
14  void caffe_conv(const Blob<Dtype>* in, ConvolutionParameter* conv_param,
15      const vector<shared_ptr<Blob<Dtype> > >& weights,
16      Blob<Dtype>* out) {
17    const bool has_depth = (out->num_axes() == 5);
18    if (!has_depth) { CHECK_EQ(4, out->num_axes()); }
19    int kernel_h, kernel_w;
20    if (conv_param->has_kernel_h() || conv_param->has_kernel_w()) {
21      kernel_h = conv_param->kernel_h();
22      kernel_w = conv_param->kernel_w();
23    } else {
24      kernel_h = kernel_w = conv_param->kernel_size(0);
25    }
26    int pad_h, pad_w;
27    if (conv_param->has_pad_h() || conv_param->has_pad_w()) {
28      pad_h = conv_param->pad_h();
29      pad_w = conv_param->pad_w();
30    } else {
31      pad_h = pad_w = conv_param->pad_size() ? conv_param->pad(0) : 0;
32    }
33    int stride_h, stride_w;
34    if (conv_param->has_stride_h() || conv_param->has_stride_w()) {
35      stride_h = conv_param->stride_h();
36      stride_w = conv_param->stride_w();
37    } else {
38      stride_h = stride_w = conv_param->stride_size() ? conv_param->stride(0) : 1;
39    }
40    int dilation_h, dilation_w;
41    dilation_h = dilation_w = conv_param->dilation_size() ?
42                              conv_param->dilation(0) : 1;
43    int kernel_d, pad_d, stride_d, dilation_d;
44    if (has_depth) {
45      kernel_d = kernel_h;
46      stride_d = stride_h;
47      pad_d = pad_h;
48      dilation_d = dilation_h;
49    } else {
50      kernel_d = stride_d = dilation_d = 1;
51      pad_d = 0;
52    }
53    int groups = conv_param->group();
54    int o_g = out->shape(1) / groups;
55    int k_g = in->shape(1) / groups;
56    int o_head, k_head;
57    vector<int> weight_offset(4 + has_depth);
58    vector<int> in_offset(4 + has_depth);
59    vector<int> out_offset(4 + has_depth);
60    Dtype* out_data = out->mutable_cpu_data();
61    for (int n = 0; n < out->shape(0); n++) {
62      for (int g = 0; g < groups; g++) {
63        o_head = o_g * g;
64        k_head = k_g * g;
65        for (int o = 0; o < o_g; o++) {
66          for (int k = 0; k < k_g; k++) {
67            for (int z = 0; z < (has_depth ? out->shape(2) : 1); z++) {
68              for (int y = 0; y < out->shape(2 + has_depth); y++) {
69                for (int x = 0; x < out->shape(3 + has_depth); x++) {
70                  for (int r = 0; r < kernel_d; r++) {
71                    for (int p = 0; p < kernel_h; p++) {
72                      for (int q = 0; q < kernel_w; q++) {
73                        int in_z = z * stride_d - pad_d + r * dilation_d;
74                        int in_y = y * stride_h - pad_h + p * dilation_h;
75                        int in_x = x * stride_w - pad_w + q * dilation_w;
76                        if (in_z >= 0 && in_z < (has_depth ? in->shape(2) : 1)
77                            && in_y >= 0 && in_y < in->shape(2 + has_depth)
78                            && in_x >= 0 && in_x < in->shape(3 + has_depth)) {
79                          weight_offset[0] = o + o_head;
80                          weight_offset[1] = k;
81                          if (has_depth) { weight_offset[2] = r; }
82                          weight_offset[2 + has_depth] = p;
83                          weight_offset[3 + has_depth] = q;
84                          in_offset[0] = n;
85                          in_offset[1] = k + k_head;
86                          if (has_depth) { in_offset[2] = in_z; }
87                          in_offset[2 + has_depth] = in_y;
88                          in_offset[3 + has_depth] = in_x;
89                          out_offset[0] = n;
90                          out_offset[1] = o + o_head;
91                          if (has_depth) { out_offset[2] = z; }
92                          out_offset[2 + has_depth] = y;
93                          out_offset[3 + has_depth] = x;
94                          out_data[out->offset(out_offset)] +=
95                              in->data_at(in_offset)
96                              * weights[0]->data_at(weight_offset);
97                        }
98                      }
99                    }
100                  }
101                }
102              }
103            }
104          }
105        }
106      }
107    }
108    if (conv_param->bias_term()) {
109      const Dtype* bias_data = weights[1]->cpu_data();
110      for (int n = 0; n < out->shape(0); n++) {
111        for (int o = 0; o < out->shape(1); o++) {
112          for (int z = 0; z < (has_depth ? out->shape(2) : 1); z++) {
113            for (int y = 0; y < out->shape(2 + has_depth); y++) {
114              for (int x = 0; x < out->shape(3 + has_depth); x++) {
115                out_offset[0] = n;
116                out_offset[1] = o;
117                if (has_depth) { out_offset[2] = z; }
118                out_offset[2 + has_depth] = y;
119                out_offset[3 + has_depth] = x;
120                out_data[out->offset(out_offset)] += bias_data[o];
121              }
122            }
123          }
124        }
125      }
126    }
127    if (conv_param->relu()){
128      for (int n = 0; n < out->shape(0); n++) {
129        for (int o = 0; o < out->shape(1); o++) {
130          for (int z = 0; z < (has_depth ? out->shape(2) : 1); z++) {
131            for (int y = 0; y < out->shape(2 + has_depth); y++) {
132              for (int x = 0; x < out->shape(3 + has_depth); x++) {
133                out_offset[0] = n;
134                out_offset[1] = o;
135                if (has_depth) { out_offset[2] = z; }
136                out_offset[2 + has_depth] = y;
137                out_offset[3 + has_depth] = x;
138                if(out_data[out->offset(out_offset)] < 0) out_data[out->offset(out_offset)] = 0;
139              }
140            }
141          }
142        }
143      }
144    }
145  }
146  template void caffe_conv(const Blob<float>* in,
147      ConvolutionParameter* conv_param,
148      const vector<shared_ptr<Blob<float> > >& weights,
149      Blob<float>* out);
150  template void caffe_conv(const Blob<double>* in,
151      ConvolutionParameter* conv_param,
152      const vector<shared_ptr<Blob<double> > >& weights,
153      Blob<double>* out);
154  template <typename TypeParam>
155  class ConvolutionLayerTest : public MultiDeviceTest<TypeParam> {
156    typedef typename TypeParam::Dtype Dtype;
157   protected:
158    ConvolutionLayerTest()
159        : blob_bottom_(new Blob<Dtype>(2, 3, 6, 4)),
160          blob_bottom_2_(new Blob<Dtype>(2, 3, 6, 4)),
161          blob_top_(new Blob<Dtype>()),
162          blob_top_2_(new Blob<Dtype>()) {}
163    virtual void SetUp() {
164      FillerParameter filler_param;
165      filler_param.set_value(1.);
166      GaussianFiller<Dtype> filler(filler_param);
167      filler.Fill(this->blob_bottom_);
168      filler.Fill(this->blob_bottom_2_);
169      blob_bottom_vec_.push_back(blob_bottom_);
170      blob_top_vec_.push_back(blob_top_);
171    }
172    virtual ~ConvolutionLayerTest() {
173      delete blob_bottom_;
174      delete blob_bottom_2_;
175      delete blob_top_;
176      delete blob_top_2_;
177    }
178    virtual Blob<Dtype>* MakeReferenceTop(Blob<Dtype>* top) {
179      this->ref_blob_top_.reset(new Blob<Dtype>());
180      this->ref_blob_top_->ReshapeLike(*top);
181      return this->ref_blob_top_.get();
182    }
183    Blob<Dtype>* const blob_bottom_;
184    Blob<Dtype>* const blob_bottom_2_;
185    Blob<Dtype>* const blob_top_;
186    Blob<Dtype>* const blob_top_2_;
187    shared_ptr<Blob<Dtype> > ref_blob_top_;
188    vector<Blob<Dtype>*> blob_bottom_vec_;
189    vector<Blob<Dtype>*> blob_top_vec_;
190  };
191  TYPED_TEST_CASE(ConvolutionLayerTest, TestDtypesAndDevices);
192  TYPED_TEST(ConvolutionLayerTest, TestSetup) {
193    typedef typename TypeParam::Dtype Dtype;
194    LayerParameter layer_param;
195    ConvolutionParameter* convolution_param =
196        layer_param.mutable_convolution_param();
197    convolution_param->add_kernel_size(3);
198    convolution_param->add_stride(2);
199    convolution_param->set_num_output(4);
200    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
201    this->blob_top_vec_.push_back(this->blob_top_2_);
202    shared_ptr<Layer<Dtype> > layer(
203        new ConvolutionLayer<Dtype>(layer_param));
204    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
205    EXPECT_EQ(this->blob_top_->num(), 2);
206    EXPECT_EQ(this->blob_top_->channels(), 4);
207    EXPECT_EQ(this->blob_top_->height(), 2);
208    EXPECT_EQ(this->blob_top_->width(), 1);
209    EXPECT_EQ(this->blob_top_2_->num(), 2);
210    EXPECT_EQ(this->blob_top_2_->channels(), 4);
211    EXPECT_EQ(this->blob_top_2_->height(), 2);
212    EXPECT_EQ(this->blob_top_2_->width(), 1);
213    convolution_param->set_num_output(3);
214    convolution_param->set_group(3);
215    layer.reset(new ConvolutionLayer<Dtype>(layer_param));
216    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
217    EXPECT_EQ(this->blob_top_->num(), 2);
218    EXPECT_EQ(this->blob_top_->channels(), 3);
219    EXPECT_EQ(this->blob_top_->height(), 2);
220    EXPECT_EQ(this->blob_top_->width(), 1);
221    EXPECT_EQ(this->blob_top_2_->num(), 2);
222    EXPECT_EQ(this->blob_top_2_->channels(), 3);
223    EXPECT_EQ(this->blob_top_2_->height(), 2);
224    EXPECT_EQ(this->blob_top_2_->width(), 1);
225  }
226  TYPED_TEST(ConvolutionLayerTest, TestSimpleConvolution) {
227    typedef typename TypeParam::Dtype Dtype;
228    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
229    this->blob_top_vec_.push_back(this->blob_top_2_);
230    LayerParameter layer_param;
231    ConvolutionParameter* convolution_param =
232        layer_param.mutable_convolution_param();
233    convolution_param->add_kernel_size(3);
234    convolution_param->add_stride(2);
235    convolution_param->set_num_output(4);
236    convolution_param->mutable_weight_filler()->set_type("gaussian");
237    convolution_param->mutable_bias_filler()->set_type("constant");
238    convolution_param->mutable_bias_filler()->set_value(0.1);
239    shared_ptr<Layer<Dtype> > layer(
240        new ConvolutionLayer<Dtype>(layer_param));
241    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
242    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
243    const Dtype* top_data;
244    const Dtype* ref_top_data;
245    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
246        this->MakeReferenceTop(this->blob_top_));
247    top_data = this->blob_top_->cpu_data();
248    ref_top_data = this->ref_blob_top_->cpu_data();
249    for (int i = 0; i < this->blob_top_->count(); ++i) {
250      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
251    }
252    caffe_conv(this->blob_bottom_2_, convolution_param, layer->blobs(),
253        this->MakeReferenceTop(this->blob_top_2_));
254    top_data = this->blob_top_2_->cpu_data();
255    ref_top_data = this->ref_blob_top_->cpu_data();
256    for (int i = 0; i < this->blob_top_->count(); ++i) {
257      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
258    }
259  }
260  TYPED_TEST(ConvolutionLayerTest, TestDilatedConvolution) {
261    typedef typename TypeParam::Dtype Dtype;
262    vector<int> bottom_shape;
263    bottom_shape.push_back(2);
264    bottom_shape.push_back(3);
265    bottom_shape.push_back(8);
266    bottom_shape.push_back(7);
267    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
268    this->blob_top_vec_.push_back(this->blob_top_2_);
269    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
270      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
271    }
272    LayerParameter layer_param;
273    ConvolutionParameter* convolution_param =
274        layer_param.mutable_convolution_param();
275    convolution_param->add_kernel_size(3);
276    convolution_param->add_dilation(2);
277    convolution_param->set_num_output(4);
278    convolution_param->mutable_weight_filler()->set_type("gaussian");
279    convolution_param->mutable_bias_filler()->set_type("constant");
280    convolution_param->mutable_bias_filler()->set_value(0.1);
281    shared_ptr<Layer<Dtype> > layer(
282        new ConvolutionLayer<Dtype>(layer_param));
283    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
284    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
285    const Dtype* top_data;
286    const Dtype* ref_top_data;
287    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
288               this->MakeReferenceTop(this->blob_top_));
289    top_data = this->blob_top_->cpu_data();
290    ref_top_data = this->ref_blob_top_->cpu_data();
291    for (int i = 0; i < this->blob_top_->count(); ++i) {
292      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
293    }
294    caffe_conv(this->blob_bottom_2_, convolution_param, layer->blobs(),
295               this->MakeReferenceTop(this->blob_top_2_));
296    top_data = this->blob_top_2_->cpu_data();
297    ref_top_data = this->ref_blob_top_->cpu_data();
298    for (int i = 0; i < this->blob_top_->count(); ++i) {
299      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
300    }
301  }
302  TYPED_TEST(ConvolutionLayerTest, Test0DConvolution) {
303    typedef typename TypeParam::Dtype Dtype;
304    LayerParameter layer_param;
305    ConvolutionParameter* convolution_param =
306        layer_param.mutable_convolution_param();
307    const int kNumOutput = 3;
308    convolution_param->set_num_output(kNumOutput);
309    convolution_param->set_axis(3);
310    convolution_param->mutable_weight_filler()->set_type("gaussian");
311    convolution_param->mutable_bias_filler()->set_type("gaussian");
312    shared_ptr<Layer<Dtype> > layer(
313        new ConvolutionLayer<Dtype>(layer_param));
314    vector<int> top_shape = this->blob_bottom_->shape();
315    top_shape[3] = kNumOutput;
316    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
317    EXPECT_EQ(top_shape, this->blob_top_->shape());
318    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
319    vector<int> weight_offset(2);
320    const Blob<Dtype>* weight = layer->blobs()[0].get();
<span onclick='openModal()' class='match'>321    const Blob<Dtype>* bias = layer->blobs()[1].get();
322    const int num = this->blob_top_->count(3);
323    const int dim = this->blob_top_->shape(3);
324    const int bottom_dim = this->blob_bottom_->shape(3);
325    for (int n = 0; n < num; ++n) {
</span>326      for (int d = 0; d < dim; ++d) {
327        weight_offset[0] = d;
328        Dtype value = bias->cpu_data()[d];
329        for (int bottom_d = 0; bottom_d < bottom_dim; ++bottom_d) {
330          weight_offset[1] = bottom_d;
331          value += weight->data_at(weight_offset) *
332                   this->blob_bottom_->cpu_data()[n * bottom_dim + bottom_d];
333        }
334        EXPECT_NEAR(value, this->blob_top_->cpu_data()[n * dim + d], 1e-4);
335      }
336    }
337  }
338  TYPED_TEST(ConvolutionLayerTest, TestSimple3DConvolution) {
339    typedef typename TypeParam::Dtype Dtype;
340    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
341    this->blob_top_vec_.push_back(this->blob_top_2_);
342    vector<int> bottom_shape(5);
343    bottom_shape[0] = this->blob_bottom_vec_[0]->shape(0);
344    bottom_shape[1] = this->blob_bottom_vec_[0]->shape(1);
345    bottom_shape[2] = 5;
346    bottom_shape[3] = this->blob_bottom_vec_[0]->shape(2);
347    bottom_shape[4] = this->blob_bottom_vec_[0]->shape(3);
348    FillerParameter filler_param;
349    GaussianFiller<Dtype> filler(filler_param);
350    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
351      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
352      filler.Fill(this->blob_bottom_vec_[i]);
353    }
354    LayerParameter layer_param;
355    ConvolutionParameter* convolution_param =
356        layer_param.mutable_convolution_param();
357    convolution_param->add_kernel_size(3);
358    convolution_param->add_stride(2);
359    convolution_param->set_num_output(4);
360    convolution_param->mutable_weight_filler()->set_type("gaussian");
361    convolution_param->mutable_bias_filler()->set_type("gaussian");
362    shared_ptr<Layer<Dtype> > layer(
363        new ConvolutionLayer<Dtype>(layer_param));
364    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
365    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
366    const Dtype* top_data;
367    const Dtype* ref_top_data;
368    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
369        this->MakeReferenceTop(this->blob_top_));
370    top_data = this->blob_top_->cpu_data();
371    ref_top_data = this->ref_blob_top_->cpu_data();
372    for (int i = 0; i < this->blob_top_->count(); ++i) {
373      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
374    }
375    caffe_conv(this->blob_bottom_2_, convolution_param, layer->blobs(),
376        this->MakeReferenceTop(this->blob_top_2_));
377    top_data = this->blob_top_2_->cpu_data();
378    ref_top_data = this->ref_blob_top_->cpu_data();
379    for (int i = 0; i < this->blob_top_->count(); ++i) {
380      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
381    }
382  }
383  TYPED_TEST(ConvolutionLayerTest, TestDilated3DConvolution) {
384    typedef typename TypeParam::Dtype Dtype;
385    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
386    this->blob_top_vec_.push_back(this->blob_top_2_);
387    vector<int> bottom_shape(5);
388    bottom_shape[0] = this->blob_bottom_vec_[0]->shape(0);
389    bottom_shape[1] = this->blob_bottom_vec_[0]->shape(1);
390    bottom_shape[2] = 6;
391    bottom_shape[3] = 7;
392    bottom_shape[4] = 8;
393    FillerParameter filler_param;
394    GaussianFiller<Dtype> filler(filler_param);
395    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
396      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
397      filler.Fill(this->blob_bottom_vec_[i]);
398    }
399    LayerParameter layer_param;
400    ConvolutionParameter* convolution_param =
401        layer_param.mutable_convolution_param();
402    convolution_param->add_kernel_size(3);
403    convolution_param->add_dilation(2);
404    convolution_param->set_num_output(4);
405    convolution_param->mutable_weight_filler()->set_type("gaussian");
406    convolution_param->mutable_bias_filler()->set_type("gaussian");
407    shared_ptr<Layer<Dtype> > layer(
408        new ConvolutionLayer<Dtype>(layer_param));
409    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
410    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
411    const Dtype* top_data;
412    const Dtype* ref_top_data;
413    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
414               this->MakeReferenceTop(this->blob_top_));
415    top_data = this->blob_top_->cpu_data();
416    ref_top_data = this->ref_blob_top_->cpu_data();
417    for (int i = 0; i < this->blob_top_->count(); ++i) {
418      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
419    }
420    caffe_conv(this->blob_bottom_2_, convolution_param, layer->blobs(),
421               this->MakeReferenceTop(this->blob_top_2_));
422    top_data = this->blob_top_2_->cpu_data();
423    ref_top_data = this->ref_blob_top_->cpu_data();
424    for (int i = 0; i < this->blob_top_->count(); ++i) {
425      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
426    }
427  }
428  TYPED_TEST(ConvolutionLayerTest, Test1x1Convolution) {
429    typedef typename TypeParam::Dtype Dtype;
430    LayerParameter layer_param;
431    ConvolutionParameter* convolution_param =
432        layer_param.mutable_convolution_param();
433    convolution_param->add_kernel_size(1);
434    convolution_param->add_stride(1);
435    convolution_param->set_num_output(4);
436    convolution_param->mutable_weight_filler()->set_type("gaussian");
437    convolution_param->mutable_bias_filler()->set_type("constant");
438    convolution_param->mutable_bias_filler()->set_value(0.1);
439    shared_ptr<Layer<Dtype> > layer(
440        new ConvolutionLayer<Dtype>(layer_param));
441    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
442    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
443    const Dtype* top_data;
444    const Dtype* ref_top_data;
445    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
446        this->MakeReferenceTop(this->blob_top_));
447    top_data = this->blob_top_->cpu_data();
448    ref_top_data = this->ref_blob_top_->cpu_data();
449    for (int i = 0; i < this->blob_top_->count(); ++i) {
450      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
451    }
452  }
453  TYPED_TEST(ConvolutionLayerTest, TestSimpleConvolutionGroup) {
454    typedef typename TypeParam::Dtype Dtype;
455    LayerParameter layer_param;
456    ConvolutionParameter* convolution_param =
457        layer_param.mutable_convolution_param();
458    convolution_param->add_kernel_size(3);
459    convolution_param->add_stride(2);
460    convolution_param->set_num_output(3);
461    convolution_param->set_group(3);
462    convolution_param->mutable_weight_filler()->set_type("gaussian");
463    convolution_param->mutable_bias_filler()->set_type("constant");
464    convolution_param->mutable_bias_filler()->set_value(0.1);
465    shared_ptr<Layer<Dtype> > layer(
466        new ConvolutionLayer<Dtype>(layer_param));
467    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
468    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
469    const Dtype* top_data;
470    const Dtype* ref_top_data;
471    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
472        this->MakeReferenceTop(this->blob_top_));
473    top_data = this->blob_top_->cpu_data();
474    ref_top_data = this->ref_blob_top_->cpu_data();
475    for (int i = 0; i < this->blob_top_->count(); ++i) {
476      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
477    }
478  }
479  TYPED_TEST(ConvolutionLayerTest, TestSobelConvolution) {
480    typedef typename TypeParam::Dtype Dtype;
481    shared_ptr<GaussianFiller<Dtype> > filler;
482    FillerParameter filler_param;
483    filler_param.set_value(1.);
484    filler.reset(new GaussianFiller<Dtype>(filler_param));
485    filler->Fill(this->blob_bottom_);
486    this->blob_bottom_2_->CopyFrom(*this->blob_bottom_);
487    LayerParameter layer_param;
488    ConvolutionParameter* convolution_param =
489        layer_param.mutable_convolution_param();
490    convolution_param->add_kernel_size(3);
491    convolution_param->add_stride(2);
492    convolution_param->set_num_output(1);
493    convolution_param->set_bias_term(false);
494    shared_ptr<Layer<Dtype> > layer(
495        new ConvolutionLayer<Dtype>(layer_param));
496    layer->blobs().resize(1);
497    layer->blobs()[0].reset(new Blob<Dtype>(1, 3, 3, 3));
498    Dtype* weights = layer->blobs()[0]->mutable_cpu_data();
499    for (int c = 0; c < 3; ++c) {
500      int i = c * 9;  
501      weights[i +  0] = -1;
502      weights[i +  1] =  0;
503      weights[i +  2] =  1;
504      weights[i +  3] = -2;
505      weights[i +  4] =  0;
506      weights[i +  5] =  2;
507      weights[i +  6] = -1;
508      weights[i +  7] =  0;
509      weights[i +  8] =  1;
510    }
511    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
512    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
513    vector<Blob<Dtype>*> sep_blob_bottom_vec;
514    vector<Blob<Dtype>*> sep_blob_top_vec;
515    shared_ptr<Blob<Dtype> > blob_sep(new Blob<Dtype>());
516    sep_blob_bottom_vec.push_back(this->blob_bottom_2_);
517    sep_blob_top_vec.push_back(this->blob_top_2_);
518    convolution_param->clear_kernel_size();
519    convolution_param->clear_stride();
520    convolution_param->set_kernel_h(3);
521    convolution_param->set_kernel_w(1);
522    convolution_param->set_stride_h(2);
523    convolution_param->set_stride_w(1);
524    convolution_param->set_num_output(1);
525    convolution_param->set_bias_term(false);
526    layer.reset(new ConvolutionLayer<Dtype>(layer_param));
527    layer->blobs().resize(1);
528    layer->blobs()[0].reset(new Blob<Dtype>(1, 3, 3, 1));
529    Dtype* weights_1 = layer->blobs()[0]->mutable_cpu_data();
530    for (int c = 0; c < 3; ++c) {
531      int i = c * 3;  
532      weights_1[i +  0] = 1;
533      weights_1[i +  1] = 2;
534      weights_1[i +  2] = 1;
535    }
536    layer->SetUp(sep_blob_bottom_vec, sep_blob_top_vec);
537    layer->Forward(sep_blob_bottom_vec, sep_blob_top_vec);
538    blob_sep->CopyFrom(*this->blob_top_2_, false, true);
539    sep_blob_bottom_vec.clear();
540    sep_blob_bottom_vec.push_back(blob_sep.get());
541    convolution_param->set_kernel_h(1);
542    convolution_param->set_kernel_w(3);
543    convolution_param->set_stride_h(1);
544    convolution_param->set_stride_w(2);
545    convolution_param->set_num_output(1);
546    convolution_param->set_bias_term(false);
547    layer.reset(new ConvolutionLayer<Dtype>(layer_param));
548    layer->blobs().resize(1);
549    layer->blobs()[0].reset(new Blob<Dtype>(1, 1, 1, 3));
550    Dtype* weights_2 = layer->blobs()[0]->mutable_cpu_data();
551    weights_2[0] = -1;
552    weights_2[1] =  0;
553    weights_2[2] =  1;
554    layer->SetUp(sep_blob_bottom_vec, sep_blob_top_vec);
555    layer->Forward(sep_blob_bottom_vec, sep_blob_top_vec);
556    const Dtype* top_data = this->blob_top_->cpu_data();
557    const Dtype* sep_top_data = this->blob_top_2_->cpu_data();
558    for (int i = 0; i < this->blob_top_->count(); ++i) {
559      EXPECT_NEAR(top_data[i], sep_top_data[i], 1e-4);
560    }
561  }
562  TYPED_TEST(ConvolutionLayerTest, TestNDAgainst2D) {
563    typedef typename TypeParam::Dtype Dtype;
564    const int kernel_h = 11;
565    const int kernel_w = 13;
566    vector<int> bottom_shape(4);
567    bottom_shape[0] = 15;
568    bottom_shape[1] = 18;
569    bottom_shape[2] = kernel_h * 2;
570    bottom_shape[3] = kernel_w * 2;
571    FillerParameter filler_param;
572    GaussianFiller<Dtype> filler(filler_param);
573    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
574      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
575      filler.Fill(this->blob_bottom_vec_[i]);
576    }
577    LayerParameter layer_param;
578    ConvolutionParameter* convolution_param =
579        layer_param.mutable_convolution_param();
580    convolution_param->set_num_output(12);
581    convolution_param->set_bias_term(false);
582    convolution_param->set_group(6);
583    convolution_param->set_kernel_h(kernel_h);
584    convolution_param->set_kernel_w(kernel_w);
585    convolution_param->mutable_weight_filler()->set_type("gaussian");
586    Blob<Dtype> weights;
587    Blob<Dtype> top_diff;
588    bool copy_diff;
589    bool reshape;
590    {
591      ConvolutionLayer<Dtype> layer(layer_param);
592      layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
593      top_diff.ReshapeLike(*this->blob_top_);
594      filler.Fill(&top_diff);
595      ASSERT_EQ(1, layer.blobs().size());
596      copy_diff = false; reshape = true;
597      weights.CopyFrom(*layer.blobs()[0], copy_diff, reshape);
598    }
599    vector<bool> propagate_down(1, true);
600    Blob<Dtype> result_2d;
601    Blob<Dtype> backward_result_2d;
602    Blob<Dtype> backward_weight_result_2d;
603    {
604      caffe_set(this->blob_top_->count(), Dtype(0),
605                this->blob_top_->mutable_cpu_data());
606      caffe_set(this->blob_bottom_->count(), Dtype(0),
607                this->blob_bottom_->mutable_cpu_diff());
608      caffe_set(weights.count(), Dtype(0), weights.mutable_cpu_diff());
609      convolution_param->set_force_nd_im2col(false);
610      ConvolutionLayer<Dtype> layer_2d(layer_param);
611      layer_2d.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
612      ASSERT_EQ(1, layer_2d.blobs().size());
613      copy_diff = false; reshape = false;
614      layer_2d.blobs()[0]->CopyFrom(weights, copy_diff, reshape);
615      layer_2d.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
616      copy_diff = false; reshape = true;
617      result_2d.CopyFrom(*this->blob_top_, copy_diff, reshape);
618      ASSERT_EQ(this->blob_top_->shape(), top_diff.shape());
619      caffe_copy(top_diff.count(), top_diff.cpu_data(),
620                 this->blob_top_->mutable_cpu_diff());
621      layer_2d.Backward(this->blob_top_vec_, propagate_down,
622                        this->blob_bottom_vec_);
623      copy_diff = true; reshape = true;
624      backward_result_2d.CopyFrom(*this->blob_bottom_, copy_diff, reshape);
625      backward_weight_result_2d.CopyFrom(weights, copy_diff, reshape);
626    }
627    Blob<Dtype> result_nd;
628    Blob<Dtype> backward_result_nd;
629    Blob<Dtype> backward_weight_result_nd;
630    {
631      caffe_set(this->blob_top_->count(), Dtype(0),
632                this->blob_top_->mutable_cpu_data());
633      caffe_set(this->blob_bottom_->count(), Dtype(0),
634                this->blob_bottom_->mutable_cpu_diff());
635      caffe_set(weights.count(), Dtype(0), weights.mutable_cpu_diff());
636      convolution_param->set_force_nd_im2col(true);
637      ConvolutionLayer<Dtype> layer_nd(layer_param);
638      layer_nd.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
639      ASSERT_EQ(1, layer_nd.blobs().size());
640      copy_diff = false; reshape = false;
641      layer_nd.blobs()[0]->CopyFrom(weights, copy_diff, reshape);
642      layer_nd.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
643      copy_diff = false; reshape = true;
644      result_nd.CopyFrom(*this->blob_top_, copy_diff, reshape);
645      ASSERT_EQ(this->blob_top_->shape(), top_diff.shape());
646      caffe_copy(top_diff.count(), top_diff.cpu_data(),
647                 this->blob_top_->mutable_cpu_diff());
648      layer_nd.Backward(this->blob_top_vec_, propagate_down,
649                        this->blob_bottom_vec_);
650      copy_diff = true; reshape = true;
651      backward_result_nd.CopyFrom(*this->blob_bottom_, copy_diff, reshape);
652      backward_weight_result_nd.CopyFrom(weights, copy_diff, reshape);
653    }
654    ASSERT_EQ(result_nd.count(), result_2d.count());
655    for (int i = 0; i < result_2d.count(); ++i)  {
656      EXPECT_EQ(result_2d.cpu_data()[i], result_nd.cpu_data()[i]);
657    }
658    ASSERT_EQ(backward_result_nd.count(), backward_result_2d.count());
659    for (int i = 0; i < backward_result_2d.count(); ++i) {
660      EXPECT_EQ(backward_result_2d.cpu_diff()[i],
661                backward_result_nd.cpu_diff()[i]);
662    }
663    ASSERT_EQ(backward_weight_result_nd.count(),
664              backward_weight_result_2d.count());
665    for (int i = 0; i < backward_weight_result_2d.count(); ++i) {
666      EXPECT_EQ(backward_weight_result_2d.cpu_diff()[i],
667                backward_weight_result_nd.cpu_diff()[i]);
668    }
669  }
670  TYPED_TEST(ConvolutionLayerTest, TestGradient) {
671    typedef typename TypeParam::Dtype Dtype;
672    LayerParameter layer_param;
673    ConvolutionParameter* convolution_param =
674        layer_param.mutable_convolution_param();
675    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
676    this->blob_top_vec_.push_back(this->blob_top_2_);
677    convolution_param->add_kernel_size(3);
678    convolution_param->add_stride(2);
679    convolution_param->set_num_output(2);
680    convolution_param->mutable_weight_filler()->set_type("gaussian");
681    convolution_param->mutable_bias_filler()->set_type("gaussian");
682    ConvolutionLayer<Dtype> layer(layer_param);
683    GradientChecker<Dtype> checker(1e-2, 1e-3);
684    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
685        this->blob_top_vec_);
686  }
687  TYPED_TEST(ConvolutionLayerTest, TestDilatedGradient) {
688    typedef typename TypeParam::Dtype Dtype;
689    LayerParameter layer_param;
690    ConvolutionParameter* convolution_param =
691        layer_param.mutable_convolution_param();
692    vector<int> bottom_shape;
693    bottom_shape.push_back(2);
694    bottom_shape.push_back(3);
695    bottom_shape.push_back(5);
696    bottom_shape.push_back(6);
697    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
698      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
699    }
700    convolution_param->add_kernel_size(3);
701    convolution_param->add_dilation(2);
702    convolution_param->set_num_output(2);
703    convolution_param->mutable_weight_filler()->set_type("gaussian");
704    convolution_param->mutable_bias_filler()->set_type("gaussian");
705    ConvolutionLayer<Dtype> layer(layer_param);
706    GradientChecker<Dtype> checker(1e-2, 1e-3);
707    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
708                                    this->blob_top_vec_);
709  }
710  TYPED_TEST(ConvolutionLayerTest, TestGradient3D) {
711    typedef typename TypeParam::Dtype Dtype;
712    LayerParameter layer_param;
713    ConvolutionParameter* convolution_param =
714        layer_param.mutable_convolution_param();
715    vector<int> bottom_shape(5);
716    bottom_shape[0] = this->blob_bottom_vec_[0]->shape(0);
717    bottom_shape[1] = this->blob_bottom_vec_[0]->shape(1);
718    bottom_shape[2] = 5;
719    bottom_shape[3] = this->blob_bottom_vec_[0]->shape(2);
720    bottom_shape[4] = this->blob_bottom_vec_[0]->shape(3);
721    FillerParameter filler_param;
722    GaussianFiller<Dtype> filler(filler_param);
723    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
724      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
725      filler.Fill(this->blob_bottom_vec_[i]);
726    }
727    convolution_param->add_kernel_size(3);
728    convolution_param->add_stride(2);
729    convolution_param->set_num_output(2);
730    convolution_param->mutable_weight_filler()->set_type("gaussian");
731    convolution_param->mutable_bias_filler()->set_type("gaussian");
732    ConvolutionLayer<Dtype> layer(layer_param);
733    GradientChecker<Dtype> checker(1e-2, 1e-3);
734    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
735        this->blob_top_vec_);
736  }
737  TYPED_TEST(ConvolutionLayerTest, Test1x1Gradient) {
738    typedef typename TypeParam::Dtype Dtype;
739    LayerParameter layer_param;
740    ConvolutionParameter* convolution_param =
741        layer_param.mutable_convolution_param();
742    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
743    this->blob_top_vec_.push_back(this->blob_top_2_);
744    convolution_param->add_kernel_size(1);
745    convolution_param->add_stride(1);
746    convolution_param->set_num_output(2);
747    convolution_param->mutable_weight_filler()->set_type("gaussian");
748    convolution_param->mutable_bias_filler()->set_type("gaussian");
749    ConvolutionLayer<Dtype> layer(layer_param);
750    GradientChecker<Dtype> checker(1e-2, 1e-3);
751    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
752        this->blob_top_vec_);
753  }
754  TYPED_TEST(ConvolutionLayerTest, TestGradientGroup) {
755    typedef typename TypeParam::Dtype Dtype;
756    LayerParameter layer_param;
757    ConvolutionParameter* convolution_param =
758        layer_param.mutable_convolution_param();
759    convolution_param->add_kernel_size(3);
760    convolution_param->add_stride(2);
761    convolution_param->set_num_output(3);
762    convolution_param->set_group(3);
763    convolution_param->mutable_weight_filler()->set_type("gaussian");
764    convolution_param->mutable_bias_filler()->set_type("gaussian");
765    ConvolutionLayer<Dtype> layer(layer_param);
766    GradientChecker<Dtype> checker(1e-2, 1e-3);
767    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
768        this->blob_top_vec_);
769  }
770  #ifdef USE_CUDNN
771  template <typename Dtype>
772  class CuDNNConvolutionLayerTest : public GPUDeviceTest<Dtype> {
773   protected:
774    CuDNNConvolutionLayerTest()
775        : blob_bottom_(new Blob<Dtype>(2, 3, 6, 4)),
776          blob_bottom_2_(new Blob<Dtype>(2, 3, 6, 4)),
777          blob_top_(new Blob<Dtype>()),
778          blob_top_2_(new Blob<Dtype>()) {}
779    virtual void SetUp() {
780      FillerParameter filler_param;
781      filler_param.set_value(1.);
782      GaussianFiller<Dtype> filler(filler_param);
783      filler.Fill(this->blob_bottom_);
784      filler.Fill(this->blob_bottom_2_);
785      blob_bottom_vec_.push_back(blob_bottom_);
786      blob_top_vec_.push_back(blob_top_);
787    }
788    virtual ~CuDNNConvolutionLayerTest() {
789      delete blob_bottom_;
790      delete blob_bottom_2_;
791      delete blob_top_;
792      delete blob_top_2_;
793    }
794    virtual Blob<Dtype>* MakeReferenceTop(Blob<Dtype>* top) {
795      this->ref_blob_top_.reset(new Blob<Dtype>());
796      this->ref_blob_top_->ReshapeLike(*top);
797      return this->ref_blob_top_.get();
798    }
799    Blob<Dtype>* const blob_bottom_;
800    Blob<Dtype>* const blob_bottom_2_;
801    Blob<Dtype>* const blob_top_;
802    Blob<Dtype>* const blob_top_2_;
803    shared_ptr<Blob<Dtype> > ref_blob_top_;
804    vector<Blob<Dtype>*> blob_bottom_vec_;
805    vector<Blob<Dtype>*> blob_top_vec_;
806  };
807  TYPED_TEST_CASE(CuDNNConvolutionLayerTest, TestDtypes);
808  TYPED_TEST(CuDNNConvolutionLayerTest, TestSetupCuDNN) {
809    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
810    this->blob_top_vec_.push_back(this->blob_top_2_);
811    LayerParameter layer_param;
812    ConvolutionParameter* convolution_param =
813        layer_param.mutable_convolution_param();
814    convolution_param->add_kernel_size(3);
815    convolution_param->add_stride(2);
816    convolution_param->set_num_output(4);
817    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
818    this->blob_top_vec_.push_back(this->blob_top_2_);
819    shared_ptr<Layer<TypeParam> > layer(
820        new CuDNNConvolutionLayer<TypeParam>(layer_param));
821    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
822    EXPECT_EQ(this->blob_top_->num(), 2);
823    EXPECT_EQ(this->blob_top_->channels(), 4);
824    EXPECT_EQ(this->blob_top_->height(), 2);
825    EXPECT_EQ(this->blob_top_->width(), 1);
826    EXPECT_EQ(this->blob_top_2_->num(), 2);
827    EXPECT_EQ(this->blob_top_2_->channels(), 4);
828    EXPECT_EQ(this->blob_top_2_->height(), 2);
829    EXPECT_EQ(this->blob_top_2_->width(), 1);
830    convolution_param->set_num_output(3);
831    convolution_param->set_group(3);
832    layer.reset(new CuDNNConvolutionLayer<TypeParam>(layer_param));
833    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
834    EXPECT_EQ(this->blob_top_->num(), 2);
835    EXPECT_EQ(this->blob_top_->channels(), 3);
836    EXPECT_EQ(this->blob_top_->height(), 2);
837    EXPECT_EQ(this->blob_top_->width(), 1);
838    EXPECT_EQ(this->blob_top_2_->num(), 2);
839    EXPECT_EQ(this->blob_top_2_->channels(), 3);
840    EXPECT_EQ(this->blob_top_2_->height(), 2);
841    EXPECT_EQ(this->blob_top_2_->width(), 1);
842  }
843  TYPED_TEST(CuDNNConvolutionLayerTest, TestSimpleConvolutionCuDNN) {
844    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
845    this->blob_top_vec_.push_back(this->blob_top_2_);
846    LayerParameter layer_param;
847    ConvolutionParameter* convolution_param =
848        layer_param.mutable_convolution_param();
849    convolution_param->add_kernel_size(3);
850    convolution_param->add_stride(2);
851    convolution_param->set_num_output(4);
852    convolution_param->mutable_weight_filler()->set_type("gaussian");
853    convolution_param->mutable_bias_filler()->set_type("constant");
854    convolution_param->mutable_bias_filler()->set_value(0.1);
855    shared_ptr<Layer<TypeParam> > layer(
856        new CuDNNConvolutionLayer<TypeParam>(layer_param));
857    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
858    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
859    const TypeParam* top_data;
860    const TypeParam* ref_top_data;
861    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
862        this->MakeReferenceTop(this->blob_top_));
863    top_data = this->blob_top_->cpu_data();
864    ref_top_data = this->ref_blob_top_->cpu_data();
865    for (int i = 0; i < this->blob_top_->count(); ++i) {
866      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
867    }
868    caffe_conv(this->blob_bottom_2_, convolution_param, layer->blobs(),
869        this->MakeReferenceTop(this->blob_top_2_));
870    top_data = this->blob_top_2_->cpu_data();
871    ref_top_data = this->ref_blob_top_->cpu_data();
872    for (int i = 0; i < this->blob_top_->count(); ++i) {
873      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
874    }
875  }
876  TYPED_TEST(CuDNNConvolutionLayerTest, TestSimpleConvolutionGroupCuDNN) {
877    LayerParameter layer_param;
878    ConvolutionParameter* convolution_param =
879        layer_param.mutable_convolution_param();
880    convolution_param->add_kernel_size(3);
881    convolution_param->add_stride(2);
882    convolution_param->set_num_output(3);
883    convolution_param->set_group(3);
884    convolution_param->mutable_weight_filler()->set_type("gaussian");
885    convolution_param->mutable_bias_filler()->set_type("constant");
886    convolution_param->mutable_bias_filler()->set_value(0.1);
887    shared_ptr<Layer<TypeParam> > layer(
888        new CuDNNConvolutionLayer<TypeParam>(layer_param));
889    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
890    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
891    const TypeParam* top_data;
892    const TypeParam* ref_top_data;
893    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
894        this->MakeReferenceTop(this->blob_top_));
895    top_data = this->blob_top_->cpu_data();
896    ref_top_data = this->ref_blob_top_->cpu_data();
897    for (int i = 0; i < this->blob_top_->count(); ++i) {
898      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
899    }
900  }
901  TYPED_TEST(CuDNNConvolutionLayerTest, TestSobelConvolutionCuDNN) {
902    shared_ptr<GaussianFiller<TypeParam> > filler;
903    FillerParameter filler_param;
904    filler_param.set_value(1.);
905    filler.reset(new GaussianFiller<TypeParam>(filler_param));
906    filler->Fill(this->blob_bottom_);
907    this->blob_bottom_2_->CopyFrom(*this->blob_bottom_);
908    LayerParameter layer_param;
909    ConvolutionParameter* convolution_param =
910        layer_param.mutable_convolution_param();
911    convolution_param->add_kernel_size(3);
912    convolution_param->add_stride(2);
913    convolution_param->set_num_output(1);
914    convolution_param->set_bias_term(false);
915    shared_ptr<Layer<TypeParam> > layer(
916        new CuDNNConvolutionLayer<TypeParam>(layer_param));
917    layer->blobs().resize(1);
918    layer->blobs()[0].reset(new Blob<TypeParam>(1, 3, 3, 3));
919    TypeParam* weights = layer->blobs()[0]->mutable_cpu_data();
920    for (int c = 0; c < 3; ++c) {
921      int i = c * 9;  
922      weights[i +  0] = -1;
923      weights[i +  1] =  0;
924      weights[i +  2] =  1;
925      weights[i +  3] = -2;
926      weights[i +  4] =  0;
927      weights[i +  5] =  2;
928      weights[i +  6] = -1;
929      weights[i +  7] =  0;
930      weights[i +  8] =  1;
931    }
932    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
933    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
934    vector<Blob<TypeParam>*> sep_blob_bottom_vec;
935    vector<Blob<TypeParam>*> sep_blob_top_vec;
936    shared_ptr<Blob<TypeParam> > blob_sep(new Blob<TypeParam>());
937    sep_blob_bottom_vec.push_back(this->blob_bottom_2_);
938    sep_blob_top_vec.push_back(this->blob_top_2_);
939    convolution_param->clear_kernel_size();
940    convolution_param->clear_stride();
941    convolution_param->set_kernel_h(3);
942    convolution_param->set_kernel_w(1);
943    convolution_param->set_stride_h(2);
944    convolution_param->set_stride_w(1);
945    convolution_param->set_num_output(1);
946    convolution_param->set_bias_term(false);
947    layer.reset(new CuDNNConvolutionLayer<TypeParam>(layer_param));
948    layer->blobs().resize(1);
949    layer->blobs()[0].reset(new Blob<TypeParam>(1, 3, 3, 1));
950    TypeParam* weights_1 = layer->blobs()[0]->mutable_cpu_data();
951    for (int c = 0; c < 3; ++c) {
952      int i = c * 3;  
953      weights_1[i +  0] = 1;
954      weights_1[i +  1] = 2;
955      weights_1[i +  2] = 1;
956    }
957    layer->SetUp(sep_blob_bottom_vec, sep_blob_top_vec);
958    layer->Forward(sep_blob_bottom_vec, sep_blob_top_vec);
959    blob_sep->CopyFrom(*this->blob_top_2_, false, true);
960    sep_blob_bottom_vec.clear();
961    sep_blob_bottom_vec.push_back(blob_sep.get());
962    convolution_param->set_kernel_h(1);
963    convolution_param->set_kernel_w(3);
964    convolution_param->set_stride_h(1);
965    convolution_param->set_stride_w(2);
966    convolution_param->set_num_output(1);
967    convolution_param->set_bias_term(false);
968    layer.reset(new CuDNNConvolutionLayer<TypeParam>(layer_param));
969    layer->blobs().resize(1);
970    layer->blobs()[0].reset(new Blob<TypeParam>(1, 1, 1, 3));
971    TypeParam* weights_2 = layer->blobs()[0]->mutable_cpu_data();
972    weights_2[0] = -1;
973    weights_2[1] =  0;
974    weights_2[2] =  1;
975    layer->SetUp(sep_blob_bottom_vec, sep_blob_top_vec);
976    layer->Forward(sep_blob_bottom_vec, sep_blob_top_vec);
977    const TypeParam* top_data = this->blob_top_->cpu_data();
978    const TypeParam* sep_top_data = this->blob_top_2_->cpu_data();
979    for (int i = 0; i < this->blob_top_->count(); ++i) {
980      EXPECT_NEAR(top_data[i], sep_top_data[i], 1e-4);
981    }
982  }
983  TYPED_TEST(CuDNNConvolutionLayerTest, TestGradientCuDNN) {
984    LayerParameter layer_param;
985    ConvolutionParameter* convolution_param =
986        layer_param.mutable_convolution_param();
987    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
988    this->blob_top_vec_.push_back(this->blob_top_2_);
989    convolution_param->add_kernel_size(3);
990    convolution_param->add_stride(2);
991    convolution_param->set_num_output(2);
992    convolution_param->mutable_weight_filler()->set_type("gaussian");
993    convolution_param->mutable_bias_filler()->set_type("gaussian");
994    CuDNNConvolutionLayer<TypeParam> layer(layer_param);
995    GradientChecker<TypeParam> checker(1e-2, 1e-3);
996    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
997        this->blob_top_vec_);
998  }
999  TYPED_TEST(CuDNNConvolutionLayerTest, TestGradientGroupCuDNN) {
1000    LayerParameter layer_param;
1001    ConvolutionParameter* convolution_param =
1002        layer_param.mutable_convolution_param();
1003    convolution_param->add_kernel_size(3);
1004    convolution_param->add_stride(2);
1005    convolution_param->set_num_output(3);
1006    convolution_param->set_group(3);
1007    convolution_param->mutable_weight_filler()->set_type("gaussian");
1008    convolution_param->mutable_bias_filler()->set_type("gaussian");
1009    CuDNNConvolutionLayer<TypeParam> layer(layer_param);
1010    GradientChecker<TypeParam> checker(1e-2, 1e-3);
1011    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
1012        this->blob_top_vec_);
1013  }
1014  #endif
1015  }  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-batch_reindex_layer.cpp</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-test_convolution_layer.cpp</div>
                </div>
                <div class="column column_space"><pre><code>35    int inner_dim = bottom[0]->count() / bottom[0]->shape(0);
36    const Dtype* in = bottom[0]->cpu_data();
37    const Dtype* permut = bottom[1]->cpu_data();
38    Dtype* out = top[0]->mutable_cpu_data();
39    for (int index = 0; index < top[0]->count(); ++index) {
</pre></code></div>
                <div class="column column_space"><pre><code>321    const Blob<Dtype>* bias = layer->blobs()[1].get();
322    const int num = this->blob_top_->count(3);
323    const int dim = this->blob_top_->shape(3);
324    const int bottom_dim = this->blob_bottom_->shape(3);
325    for (int n = 0; n < num; ++n) {
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    