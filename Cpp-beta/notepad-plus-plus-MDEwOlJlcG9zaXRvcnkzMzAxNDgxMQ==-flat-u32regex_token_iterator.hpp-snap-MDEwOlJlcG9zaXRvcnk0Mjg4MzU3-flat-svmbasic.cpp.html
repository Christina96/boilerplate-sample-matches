
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 2.9468786351298952%, Tokens: 9, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>notepad-plus-plus-MDEwOlJlcG9zaXRvcnkzMzAxNDgxMQ==-flat-u32regex_token_iterator.hpp</h3>
            <pre><code>1  #ifndef BOOST_REGEX_V5_U32REGEX_TOKEN_ITERATOR_HPP
2  #define BOOST_REGEX_V5_U32REGEX_TOKEN_ITERATOR_HPP
3  namespace boost{
4  #ifdef BOOST_REGEX_MSVC
5  #  pragma warning(push)
6  #  pragma warning(disable:4700)
7  #endif
8  template <class BidirectionalIterator>
9  class u32regex_token_iterator_implementation 
10  {
11     typedef u32regex                              regex_type;
12     typedef sub_match<BidirectionalIterator>      value_type;
13     match_results<BidirectionalIterator> what;   
14     BidirectionalIterator                end;    
15     BidirectionalIterator                base;   
16     const regex_type                     re;     
17     match_flag_type                      flags;  
18     value_type                           result; 
19     int                                  N;      
20     std::vector<int>                     subs;   
21  public:
22     u32regex_token_iterator_implementation(const regex_type* p, BidirectionalIterator last, int sub, match_flag_type f)
23        : end(last), re(*p), flags(f){ subs.push_back(sub); }
24     u32regex_token_iterator_implementation(const regex_type* p, BidirectionalIterator last, const std::vector<int>& v, match_flag_type f)
25        : end(last), re(*p), flags(f), subs(v){}
26     template <std::size_t CN>
27     u32regex_token_iterator_implementation(const regex_type* p, BidirectionalIterator last, const int (&submatches)[CN], match_flag_type f)
28        : end(last), re(*p), flags(f)
29     {
30        for(std::size_t i = 0; i < CN; ++i)
31        {
32           subs.push_back(submatches[i]);
33        }
34     }
35     bool init(BidirectionalIterator first)
36     {
37        base = first;
38        N = 0;
39        if(u32regex_search(first, end, what, re, flags, base) == true)
40        {
41           N = 0;
42           result = ((subs[N] == -1) ? what.prefix() : what[(int)subs[N]]);
43           return true;
44        }
45        else if((subs[N] == -1) && (first != end))
46        {
47           result.first = first;
48           result.second = end;
49           result.matched = (first != end);
50           N = -1;
51           return true;
52        }
53        return false;
54     }
55     bool compare(const u32regex_token_iterator_implementation& that)
56     {
57        if(this == &that) return true;
58        return (&re.get_data() == &that.re.get_data()) 
59           && (end == that.end) 
60           && (flags == that.flags) 
61           && (N == that.N) 
62           && (what[0].first == that.what[0].first) 
63           && (what[0].second == that.what[0].second);
64     }
65     const value_type& get()
66     { return result; }
67     bool next()
68     {
69        if(N == -1)
70           return false;
71        if(N+1 < (int)subs.size())
72        {
73           ++N;
74           result =((subs[N] == -1) ? what.prefix() : what[subs[N]]);
75           return true;
76        }
77        BidirectionalIterator last_end(what[0].second);
78        if(u32regex_search(last_end, end, what, re, ((what[0].first == what[0].second) ? flags | regex_constants::match_not_initial_null : flags), base))
79        {
80           N =0;
81           result =((subs[N] == -1) ? what.prefix() : what[subs[N]]);
82           return true;
83        }
84        else if((last_end != end) && (subs[0] == -1))
85        {
86           N =-1;
87           result.first = last_end;
88           result.second = end;
89           result.matched = (last_end != end);
90           return true;
91        }
92        return false;
93     }
94  private:
95     u32regex_token_iterator_implementation& operator=(const u32regex_token_iterator_implementation&);
96  };
97  template <class BidirectionalIterator>
98  class u32regex_token_iterator 
99  {
100  private:
101     typedef u32regex_token_iterator_implementation<BidirectionalIterator> impl;
102     typedef std::shared_ptr<impl> pimpl;
103  public:
104     typedef          u32regex                                                regex_type;
105     typedef          sub_match<BidirectionalIterator>                        value_type;
106     typedef typename std::iterator_traits<BidirectionalIterator>::difference_type 
107                                                                              difference_type;
108     typedef          const value_type*                                       pointer;
109     typedef          const value_type&                                       reference; 
110     typedef          std::forward_iterator_tag                               iterator_category;
111     u32regex_token_iterator(){}
112     u32regex_token_iterator(BidirectionalIterator a, BidirectionalIterator b, const regex_type& re, 
113                          int submatch = 0, match_flag_type m = match_default)
114                          : pdata(new impl(&re, b, submatch, m))
115     {
116        if(!pdata->init(a))
<span onclick='openModal()' class='match'>117           pdata.reset();
118     }
119     u32regex_token_iterator(BidirectionalIterator a, BidirectionalIterator b, const regex_type& re, 
120                          const std::vector<int>& submatches, match_flag_type m = match_default)
</span>121                          : pdata(new impl(&re, b, submatches, m))
122     {
123        if(!pdata->init(a))
124           pdata.reset();
125     }
126     template <std::size_t N>
127     u32regex_token_iterator(BidirectionalIterator a, BidirectionalIterator b, const regex_type& re,
128                          const int (&submatches)[N], match_flag_type m = match_default)
129                          : pdata(new impl(&re, b, submatches, m))
130     {
131        if(!pdata->init(a))
132           pdata.reset();
133     }
134     u32regex_token_iterator(const u32regex_token_iterator& that)
135        : pdata(that.pdata) {}
136     u32regex_token_iterator& operator=(const u32regex_token_iterator& that)
137     {
138        pdata = that.pdata;
139        return *this;
140     }
141     bool operator==(const u32regex_token_iterator& that)const
142     { 
143        if((pdata.get() == 0) || (that.pdata.get() == 0))
144           return pdata.get() == that.pdata.get();
145        return pdata->compare(*(that.pdata.get())); 
146     }
147     bool operator!=(const u32regex_token_iterator& that)const
148     { return !(*this == that); }
149     const value_type& operator*()const
150     { return pdata->get(); }
151     const value_type* operator->()const
152     { return &(pdata->get()); }
153     u32regex_token_iterator& operator++()
154     {
155        cow();
156        if(0 == pdata->next())
157        {
158           pdata.reset();
159        }
160        return *this;
161     }
162     u32regex_token_iterator operator++(int)
163     {
164        u32regex_token_iterator result(*this);
165        ++(*this);
166        return result;
167     }
168  private:
169     pimpl pdata;
170     void cow()
171     {
172        if(pdata.get() && (pdata.use_count() > 1))
173        {
174           pdata.reset(new impl(*(pdata.get())));
175        }
176     }
177  };
178  typedef u32regex_token_iterator<const char*> utf8regex_token_iterator;
179  typedef u32regex_token_iterator<const UChar*> utf16regex_token_iterator;
180  typedef u32regex_token_iterator<const UChar32*> utf32regex_token_iterator;
181  inline u32regex_token_iterator<const char*> make_u32regex_token_iterator(const char* p, const u32regex& e, int submatch = 0, regex_constants::match_flag_type m = regex_constants::match_default)
182  {
183     return u32regex_token_iterator<const char*>(p, p+std::strlen(p), e, submatch, m);
184  }
185  #ifndef BOOST_NO_WREGEX
186  inline u32regex_token_iterator<const wchar_t*> make_u32regex_token_iterator(const wchar_t* p, const u32regex& e, int submatch = 0, regex_constants::match_flag_type m = regex_constants::match_default)
187  {
188     return u32regex_token_iterator<const wchar_t*>(p, p+std::wcslen(p), e, submatch, m);
189  }
190  #endif
191  #if !defined(BOOST_REGEX_UCHAR_IS_WCHAR_T)
192  inline u32regex_token_iterator<const UChar*> make_u32regex_token_iterator(const UChar* p, const u32regex& e, int submatch = 0, regex_constants::match_flag_type m = regex_constants::match_default)
193  {
194     return u32regex_token_iterator<const UChar*>(p, p+u_strlen(p), e, submatch, m);
195  }
196  #endif
197  template <class charT, class Traits, class Alloc>
198  inline u32regex_token_iterator<typename std::basic_string<charT, Traits, Alloc>::const_iterator> make_u32regex_token_iterator(const std::basic_string<charT, Traits, Alloc>& p, const u32regex& e, int submatch = 0, regex_constants::match_flag_type m = regex_constants::match_default)
199  {
200     typedef typename std::basic_string<charT, Traits, Alloc>::const_iterator iter_type;
201     return u32regex_token_iterator<iter_type>(p.begin(), p.end(), e, submatch, m);
202  }
203  inline u32regex_token_iterator<const UChar*> make_u32regex_token_iterator(const U_NAMESPACE_QUALIFIER UnicodeString& s, const u32regex& e, int submatch = 0, regex_constants::match_flag_type m = regex_constants::match_default)
204  {
205     return u32regex_token_iterator<const UChar*>(s.getBuffer(), s.getBuffer() + s.length(), e, submatch, m);
206  }
207  template <std::size_t N>
208  inline u32regex_token_iterator<const char*> make_u32regex_token_iterator(const char* p, const u32regex& e, const int (&submatch)[N], regex_constants::match_flag_type m = regex_constants::match_default)
209  {
210     return u32regex_token_iterator<const char*>(p, p+std::strlen(p), e, submatch, m);
211  }
212  #ifndef BOOST_NO_WREGEX
213  template <std::size_t N>
214  inline u32regex_token_iterator<const wchar_t*> make_u32regex_token_iterator(const wchar_t* p, const u32regex& e, const int (&submatch)[N], regex_constants::match_flag_type m = regex_constants::match_default)
215  {
216     return u32regex_token_iterator<const wchar_t*>(p, p+std::wcslen(p), e, submatch, m);
217  }
218  #endif
219  #if !defined(BOOST_REGEX_UCHAR_IS_WCHAR_T)
220  template <std::size_t N>
221  inline u32regex_token_iterator<const UChar*> make_u32regex_token_iterator(const UChar* p, const u32regex& e, const int (&submatch)[N], regex_constants::match_flag_type m = regex_constants::match_default)
222  {
223     return u32regex_token_iterator<const UChar*>(p, p+u_strlen(p), e, submatch, m);
224  }
225  #endif
226  template <class charT, class Traits, class Alloc, std::size_t N>
227  inline u32regex_token_iterator<typename std::basic_string<charT, Traits, Alloc>::const_iterator> make_u32regex_token_iterator(const std::basic_string<charT, Traits, Alloc>& p, const u32regex& e, const int (&submatch)[N], regex_constants::match_flag_type m = regex_constants::match_default)
228  {
229     typedef typename std::basic_string<charT, Traits, Alloc>::const_iterator iter_type;
230     return u32regex_token_iterator<iter_type>(p.begin(), p.end(), e, submatch, m);
231  }
232  template <std::size_t N>
233  inline u32regex_token_iterator<const UChar*> make_u32regex_token_iterator(const U_NAMESPACE_QUALIFIER UnicodeString& s, const u32regex& e, const int (&submatch)[N], regex_constants::match_flag_type m = regex_constants::match_default)
234  {
235     return u32regex_token_iterator<const UChar*>(s.getBuffer(), s.getBuffer() + s.length(), e, submatch, m);
236  }
237  inline u32regex_token_iterator<const char*> make_u32regex_token_iterator(const char* p, const u32regex& e, const std::vector<int>& submatch, regex_constants::match_flag_type m = regex_constants::match_default)
238  {
239     return u32regex_token_iterator<const char*>(p, p+std::strlen(p), e, submatch, m);
240  }
241  #ifndef BOOST_NO_WREGEX
242  inline u32regex_token_iterator<const wchar_t*> make_u32regex_token_iterator(const wchar_t* p, const u32regex& e, const std::vector<int>& submatch, regex_constants::match_flag_type m = regex_constants::match_default)
243  {
244     return u32regex_token_iterator<const wchar_t*>(p, p+std::wcslen(p), e, submatch, m);
245  }
246  #endif
247  #if !defined(U_WCHAR_IS_UTF16) && (U_SIZEOF_WCHAR_T != 2)
248  inline u32regex_token_iterator<const UChar*> make_u32regex_token_iterator(const UChar* p, const u32regex& e, const std::vector<int>& submatch, regex_constants::match_flag_type m = regex_constants::match_default)
249  {
250     return u32regex_token_iterator<const UChar*>(p, p+u_strlen(p), e, submatch, m);
251  }
252  #endif
253  template <class charT, class Traits, class Alloc>
254  inline u32regex_token_iterator<typename std::basic_string<charT, Traits, Alloc>::const_iterator> make_u32regex_token_iterator(const std::basic_string<charT, Traits, Alloc>& p, const u32regex& e, const std::vector<int>& submatch, regex_constants::match_flag_type m = regex_constants::match_default)
255  {
256     typedef typename std::basic_string<charT, Traits, Alloc>::const_iterator iter_type;
257     return u32regex_token_iterator<iter_type>(p.begin(), p.end(), e, submatch, m);
258  }
259  inline u32regex_token_iterator<const UChar*> make_u32regex_token_iterator(const U_NAMESPACE_QUALIFIER UnicodeString& s, const u32regex& e, const std::vector<int>& submatch, regex_constants::match_flag_type m = regex_constants::match_default)
260  {
261     return u32regex_token_iterator<const UChar*>(s.getBuffer(), s.getBuffer() + s.length(), e, submatch, m);
262  }
263  #ifdef BOOST_REGEX_MSVC
264  #  pragma warning(pop)
265  #endif
266  } 
267  #endif 
</code></pre>
        </div>
        <div class="column">
            <h3>snap-MDEwOlJlcG9zaXRvcnk0Mjg4MzU3-flat-svmbasic.cpp</h3>
            <pre><code>1  void TSVMCache::Reset(const int& memory_size, const int& d) {
2      IAssert(memory_size > 0 && d > 0);
3      top = bottom = NULL;
4      size = 0; dim = numRows = d;
5      int vecsize = (sizeof(TFltType) + sizeof(bool)) * dim;
6      int aviable_memory = memory_size*1024*1024
7                           - dim * sizeof(int)    
8                           - dim * sizeof(bool)   
9                           - dim * sizeof(int);   
10      maxsize = aviable_memory / vecsize;
11      maxsize = maxsize < dim ? maxsize : dim;
12      if (verbosity > 0) {
13          printf("cache size = %d (%.3f MB)\n",
14                 maxsize, maxsize * vecsize / (1024.0 * 1024.0));
15      }
16      cache = (maxsize > 0) ? new TFltType[maxsize * dim] : NULL;
17      valid = (maxsize > 0) ? new bool[maxsize * dim] : NULL;
18      idsT = (maxsize > 0) ? new int[dim] : NULL;
19      vecShrink.Reserve(maxsize+1, maxsize+1);
20      int i;
21      saved.Reserve(dim, dim);
22      vecPt.Reserve(dim, dim);
23      for (i = 0; i < dim; i++) {
24          saved[i] = false;
25          idsT[i] = i;
26      }
27      for (i = 0; i < maxsize+1; i++) {
28          vecShrink[i] = NULL;
29      }
30  }
31  void TSVMCache::Clear() {
32      if (cache != NULL) delete[] cache;
33      if (valid != NULL) delete[] valid;
34      if (idsT != NULL) delete[] idsT;
35      cache = NULL; valid = NULL; idsT = NULL;
36      TListNode *node = bottom, *tmp;
37      while (node != NULL) {
38          tmp = node;
39          node = node->next;
40          delete tmp;
41      }
42      bottom = top = NULL;
43      vecPt.Clr(); saved.Clr();
44      numRows = size = maxsize = dim = 0;
45  }
46  void TSVMCache::toTop(TListNode *node) {
47      if (node->prev != NULL && node->next != NULL) {
48          node->prev->next = node->next;
49          node->next->prev = node->prev;
50          node->next = NULL;
51          node->prev = top;
52          top->next = node;
53          top = node;
54      } else if (node == bottom && node->next != NULL) {
55          bottom = bottom->next;
56          bottom->prev = NULL;
57          node->next = NULL;
58          node->prev = top;
59          top->next = node;
60          top = node;
61      } 
62  }
63  TSVMCacheVec TSVMCache::Get(const int& i) {
64      Assert(0 <= i && i < dim && saved[i]);
65      toTop(vecPt[i]);
66      return TSVMCacheVec(vecPt[i]->addr, vecPt[i]->vaddr, idsT, numRows);
67  }
68  TFltType TSVMCache::GetVal(const int& i, const int& j) const {
69      Assert(0 <= i && i < dim && saved[i] && 0 <= j && j < dim && idsT[j] >= 0);
70      return vecPt[i]->addr[idsT[j]];
71  }
72  TSVMCacheVec TSVMCache::Add(const int& i) {
73      Assert(0 <= i && i < dim && cache != NULL);
74      if (saved[i]) {
75          toTop(vecPt[i]);
76          return TSVMCacheVec(vecPt[i]->addr, vecPt[i]->vaddr, idsT, numRows);
77      }
78      TFltType *vecAddr; bool *vecVAddr;
79      TListNode *node = new TListNode();
80      Assert(size >= 0 && size <= maxsize);
81      if (size == 0) {
82          vecAddr = cache;
83          vecVAddr = valid;
84          node->position = 0;
85          node->next = node->prev = NULL;
86          top = bottom = node;
87          size++;
88      } else if (size < maxsize) {
89          vecAddr = &cache[size * numRows];
90          vecVAddr = &valid[size * numRows];
91          node->position = size;
92          node->next = NULL;
93          node->prev = top;
94          top->next = node;
95          top = node;
96          size++;
97      } else {
98          vecAddr = bottom->addr;
99          vecVAddr = bottom->vaddr;
100          node->position = bottom->position;
101          saved[bottom->ID] = false;
102          bottom = bottom->next;
103          delete bottom->prev;
104          bottom->prev = NULL;
105          node->next = NULL;
106          node->prev = top;
107          top->next = node;
108          top = node;
109      }
110      node->ID = i;
111      node->addr = vecAddr;
112      node->vaddr = vecVAddr;
113      saved[i] = true;
114      vecPt[i] = node;
115      vecShrink[node->position] = node;
116      return TSVMCacheVec(vecAddr, vecVAddr, idsT, numRows);
117  }
118  void TSVMCache::Shrink(const int& n, int *ids) {
119      if (n < numRows) {
120          int newMaxSize = (maxsize * numRows) / n;
121          int pos = 0; 
122          int i = 0;   
123          while (vecShrink[i] != NULL) { 
124              TListNode *node = vecShrink[i];
125              Assert(i == node->position);
126              TFltType *newAddr = &cache[pos];
127              int jNew, jOld;
128              for (jNew = 0; jNew < n; jNew++) {
129                  jOld = idsT[ids[jNew]];
130                  Assert(jOld >= 0); 
131                  cache[pos] = node->addr[jOld];
132                  valid[pos] = node->vaddr[jOld];
133                  pos++;
134              }
135              node->addr = newAddr;   
136              i++;                    
137          }
138          numRows = n;
139          for (i = 0; i < dim; i++) idsT[i] = -1;
140          for (i = 0; i < numRows; i++) idsT[ids[i]] = i;
141          vecShrink.Reserve(newMaxSize + 1, newMaxSize + 1);
142          for (i = size; i < newMaxSize+1; i++)
143              vecShrink[i] = NULL;
144          maxsize = newMaxSize;
145          if (verbosity > 1) printf("<%d>", maxsize);
146      }
147  }
148  THash<TStr, TSVMTrainSet::TSVMTrainSetLoadF> TSVMTrainSet::TypeToLoadFH;
149  bool TSVMTrainSet::Reg(const TStr& TypeNm, const TSVMTrainSetLoadF& LoadF){
150    IAssert(!TypeToLoadFH.IsKey(TypeNm));
151    TypeToLoadFH.AddDat(TypeNm, LoadF);
152    return true;
153  }
154  PSVMTrainSet TSVMTrainSet::Load(TSIn& SIn){
155      TStr TypeNm(SIn);
156      int TypeKeyId=-1;
157      if (TypeToLoadFH.IsKey(TypeNm, TypeKeyId)){
158          TSVMTrainSetLoadF LoadF=TypeToLoadFH[TypeKeyId];
159          return (*LoadF())(SIn);
160      } else {
161          return NULL;
162      }
163  }
164  void TSVMTrainSet::LinComb(const TFltV& AlphV, TFltV& Result) {
165      IAssert(AlphV.Len() == Len());
166      int d = Dim(); Result.Gen(d); Result.PutAll(0.0);
167      for (int VecC = 0, VecN = AlphV.Len(); VecC < VecN; VecC++)
168          AddVec(VecC, Result, AlphV[VecC]);
169  }
170  void TSVMTrainSet::LinComb(const TIntV& VecIdV, const TFltV& AlphV, TFltV& Result) {
171      IAssert(VecIdV.Len() == AlphV.Len());
172      Result.Gen(Dim()); Result.PutAll(0.0);
173      for (int VecC = 0, VecN = VecIdV.Len(); VecC < VecN; VecC++)
174          AddVec(VecIdV[VecC], Result, AlphV[VecC]);
175  }
176  void TSVMTrainSet::GetKeywords(const TFltV& NormalV, TIntFltKdV& WIdWgtV,
177          const TIntV& VecIdV, const int& WdN,  const double& VecSign,
178          const double& WgtSign, const bool& AvgOverSet) {
179      TFltV WgtV(NormalV.Len());
180      if (AvgOverSet) {
181          WgtV.PutAll(0.0);
182          if (VecIdV.Empty()) {
183              const int Docs = Len();
184              for (int DId = 0; DId < Docs; DId++) {
185                  if (VecSign*GetVecParam(DId) > 0)
186                      AddVec(DId, WgtV, 1.0);
187              }
188          } else {
189              for (int DocN = 0; DocN < VecIdV.Len(); DocN++) {
190                  const int DId = VecIdV[DocN];
191                  if (VecSign*GetVecParam(DId) > 0)
192                      AddVec(DId, WgtV, 1.0);
193              }
194          }
195      } else {
196          WgtV.PutAll(1.0);
197      }
198      TFltIntKdV WdWgtV(NormalV.Len(), 0);
199      for (int AttrC = 0; AttrC < NormalV.Len(); AttrC++) {
200          WdWgtV.Add(TFltIntKd(WgtSign*NormalV[AttrC]*WgtV[AttrC], AttrC));
201      }
202      if (WdN > 0) {
203          WdWgtV.Sort(false);
204          WIdWgtV.Gen(WdN, 0);
205          IAssert(WdN <= NormalV.Len());
206          for (int WdC = 0; WdC < WdN; WdC++) {
207              const double WdWgt = WdWgtV[WdC].Key;
208              const int WdId = WdWgtV[WdC].Dat;
209              if (WdWgt > 0) {
210                  WIdWgtV.Add(TIntFltKd(WdId, WdWgt));
211              }
212          }
213      } else {
214          WIdWgtV.Clr();
215          for (int WdC = 0; WdC < WdWgtV.Len(); WdC++) {
216              const double WdWgt = WdWgtV[WdC].Key;
217              const int WdId = WdWgtV[WdC].Dat;
218              if (WdWgt > 0.0) {
219                  WIdWgtV.Add(TIntFltKd(WdId, WdWgt));
220              }
221          }
222      }
223  }
224  double TSVMTrainSet::CalcSvmUnblParam(const double& MxVal, const double& MnVal) {
225      int PosVecs = 0;
226      int NegVecs = 0;
227      for (int VecN = 0; VecN < Len(); VecN++) {
228          const double VecParam = GetVecParam(VecN);
229          if (VecParam > 0.0) {
230              PosVecs++;
231          } else if (VecParam < 0.0) {
232              NegVecs++;
233          }
234      }
235      if (PosVecs > 0 && NegVecs > 0) {
236          const double CalcVal = double(NegVecs)/double(PosVecs);
237          return TMath::Median(MnVal, CalcVal, MxVal);
238      } else {
239          return 1.0;
240      }
241  }
242  int TSVMTrainSet::GetSignVecs(const double& Sign) {
243      int SignVecs = 0;
244      for (int VecN = 0; VecN < Len(); VecN++) {
245          if ((Sign*GetVecParam(VecN)) > 0.0) SignVecs++;
246      }
247      return SignVecs;
248  }
249  bool TSVMTrainSet::HasPosNegVecs(const int& MnVec) {
250      int PosVecs = GetSignVecs(1.0);
251      int NegVecs = GetSignVecs(-1.0);
252      return (PosVecs >= MnVec) && (NegVecs >= MnVec);
253  }
254  bool TSVMTrainSet::HasPosVecs(const int& MnPosVec) {
255      int PosVecs = GetSignVecs(1.0);
256      return (PosVecs >= MnPosVec);
257  }
258  bool TSVMTrainSet::HasNegVecs(const int& MnNegVec) {
259      int NegVecs = GetSignVecs(-1.0);
260      return (NegVecs >= MnNegVec);
261  }
262  TSTSetMatrix::TSTSetMatrix(PSVMTrainSet Set, TFltV& ClsV): TMatrix(), ColVV(Set) {
263      IAssert(Set->Type() == ststSparse);
264      ClsV.Gen(Set->Len(), 0);
265      for (int i = 0; i < Set->Len(); i++)
266          ClsV.Add(Set->GetVecParam(i) * 0.99);
267  }
268  void TSTSetMatrix::PMultiply(const TFltVV& B, int ColId, TFltV& Result) const {
269      IAssert(B.GetXDim() >= PGetCols() && Result.Len() >= PGetRows());
270      int RowN = PGetRows(), ColN = PGetCols();
271      int i, j; TFlt *ResV = Result.BegI();
272      for (i = 0; i < RowN; i++) ResV[i] = 0.0;
273      for (j = 0; j < ColN; j++) {
274          const TIntFltKdV& ColV = ColVV->GetAttrSparseV(j); int len = ColV.Len();
275          for (i = 0; i < len; i++) {
276              if (ColV[i].Key < Result.Len())
277                  ResV[ColV[i].Key] += ColV[i].Dat * B(j,ColId);
278          }
279      }
280  }
281  void TSTSetMatrix::PMultiply(const TFltV& Vec, TFltV& Result) const {
282      IAssert(Vec.Len() >= PGetCols() && Result.Len() >= PGetRows());
283      int RowN = PGetRows(), ColN = PGetCols();
284      int i, j; TFlt *ResV = Result.BegI();
285      for (i = 0; i < RowN; i++) ResV[i] = 0.0;
286      for (j = 0; j < ColN; j++) {
287          const TIntFltKdV& ColV = ColVV->GetAttrSparseV(j); int len = ColV.Len();
288          for (i = 0; i < len; i++) {
289              if (ColV[i].Key < Result.Len())
290                  ResV[ColV[i].Key] += ColV[i].Dat * Vec[j];
291          }
292      }
293  }
294  void TSTSetMatrix::PMultiplyT(const TFltVV& B, int ColId, TFltV& Result) const {
295      IAssert(B.GetXDim() >= PGetRows() && Result.Len() >= PGetCols());
296      int ColN = PGetCols();
297      int i, j, len; TFlt *ResV = Result.BegI();
298      for (j = 0; j < ColN; j++) {
299          const TIntFltKdV& ColV = ColVV->GetAttrSparseV(j);
300          len = ColV.Len(); ResV[j] = 0.0;
301          for (i = 0; i < len; i++) {
302              if (ColV[i].Key < B.GetXDim())
303                  ResV[j] += ColV[i].Dat * B(ColV[i].Key, ColId);
304          }
305      }
306  }
307  void TSTSetMatrix::PMultiplyT(const TFltV& Vec, TFltV& Result) const {
308      IAssert(Vec.Len() >= PGetRows() && Result.Len() >= PGetCols());
309      int ColN = PGetCols();
310      int i, j, len; TFlt *VecV = Vec.BegI(), *ResV = Result.BegI();
311      for (j = 0; j < ColN; j++) {
312          const TIntFltKdV& ColV = ColVV->GetAttrSparseV(j);
313          len = ColV.Len(); ResV[j] = 0.0;
314          for (i = 0; i < len; i++) {
315              if (ColV[i].Key < Vec.Len())
316                  ResV[j] += ColV[i].Dat * VecV[ColV[i].Key];
317          }
318      }
319  }
320  void TSTSetMatrix::Load(TSparseColMatrix& Matrix, TFltV& y,
321          PSVMTrainSet TrainSet, const double& PWgt, const double& NWgt) {
322      IAssert(TrainSet->Type() == ststSparse);
323      Matrix.ColN = TrainSet->Len();
324      Matrix.RowN = TrainSet->Dim();
325      for (int i = 0; i < Matrix.ColN; i++) {
326          Matrix.DocSpVV.Add(TrainSet->GetAttrSparseV(i));
327          y.Add(TrainSet->GetVecParam(i) > 0.0 ? PWgt : NWgt);
328      }
329      Matrix.DocSpVV.Pack();
330  }
331  THash<TStr, TKernel::TKernelLoadF> TKernel::TypeToLoadFH;
332  bool TKernel::Reg(const TStr& TypeNm, const TKernelLoadF& LoadF){
333    IAssert(!TypeToLoadFH.IsKey(TypeNm));
334    TypeToLoadFH.AddDat(TypeNm, LoadF);
335    return true;
336  }
337  PKernel TKernel::Load(TSIn& SIn){
338      TStr TypeNm(SIn);
339      int TypeKeyId=-1;
340      if (TypeToLoadFH.IsKey(TypeNm, TypeKeyId)){
341          TKernelLoadF LoadF=TypeToLoadFH[TypeKeyId];
342          return (*LoadF())(SIn);
343      } else {
344          return NULL;
345      }
346  }
347  bool TPolynomialKernel::IsReg = TPolynomialKernel::MkReg();
348  bool TRadialKernel::IsReg = TRadialKernel::MkReg();
349  bool TSigmoidKernel::IsReg = TSigmoidKernel::MkReg();
350  TSVMQP::TSVMQP(const int& nn, const int& mm, const double& ll):
351    n(nn), m(mm) {
352      pl = new double[n];
353      for (int i = 0; i < n; i++)
354          pl[i] = ll;
355      primal = new double[3*n];
356      dual = new double[m + 2*n];
357  }
358  TSVMQP::~TSVMQP() {
359      delete[] pl; delete[] primal; delete[] dual;
360  }
361  bool TSVMQP::solve(const int& size, const double& bb, double *u, double *Q,
362                     double *A, double *c, double *resultV, const int& verbosity) {
363      IAssert(size <= n);
364      int i;
365      double b = bb;
366      int verb = 0;
367      double init_margin = 0.15;
368      long init_iter = 500;
369      double sigdig = 8;
370      int result = TPrLoqo::pr_loqo(size, m, c, Q, A, &b, pl, u,
371                           primal, dual, verb, sigdig,
372                           init_iter, init_margin,
373                           u[0] / 4.0, 0);
374      if (!TFlt::IsNum(dual[0]) && verbosity > 0) printf("ERR[nan]");
375      if (result == OPTIMAL_SOLUTION) {
376          for (i = 0; i < size; i++) resultV[i] = primal[i];
377          return true;
378      };
379      if (verbosity > 0) printf("ERR[%d]", result);
380      return false;
381  }
382  inline double TSVMQPSolver::kernel(const int& i1, const int& i2) const {
383      if (is_linear) {
384          return docs->DotProduct(i1, i2);
385      } else {
<span onclick='openModal()' class='match'>386          return nonlin_kernel->CalcSet(docs, i1, i2);
387      }
388  }
389  void TSVMQPSolver::readColumnRows(const int& i, const int& len, int *ids,
390                          double *result, const bool& store, const bool& sync) {
</span>391      int j,k;
392      if (cache.Exists(i))  {
393          cache_yes++;
394          TSVMCacheVec vec = cache.Get(i);
395          TFltType *vecVals = vec.valT;
396          bool *vecValid = vec.validT;
397          int *vecIds = vec.idsT;
398          int vecLen = vec.dim;
399          if (sync) {
400              if (len == vecLen) {
401                  for (j = 0; j < len; j++) {
402                      Assert(vecIds[ids[j]] == j);
403                      result[j] = vecVals[j];
404                  }
405              } else {
406                  for (j = 0; j < len; j++)  {
407                      k = vecIds[ids[j]];
408                      Assert(0 <= k && k <= vecLen && vecValid[k]);
409                      result[j] = vecVals[k];
410                  }
411              }
412          } else {
413              for (j = 0; j < len; j++) {
414                  k = vecIds[ids[j]];
415                  if (k >= 0) {
416                      if (vecValid[k]) {
417                          Assert(k <= vecLen);
418                          result[j] = vecVals[k];
419                      } else {
420                          if (cache.IsRowValid(ids[j], i)) {
421                              result[j] = cache.GetVal(ids[j], i);
422                          } else {
423                              result[j] = kernel(i, ids[j]);
424                              kernel_count++;
425                          }
426                          vecVals[k] = (TFltType)result[j];
427                          vecValid[k] = true;
428                      }
429                  } else {
430                      result[j] = kernel(i, ids[j]);
431                      kernel_count++;
432                  }
433              } 
434          } 
435      } else {
436          cache_no++;
437          for (j = 0; j < len; j++) {
438              k = ids[j];
439              if (cache.IsRowValid(ids[j], i)) {
440                  result[j] = cache.GetVal(k, i);
441              } else {
442                  result[j] = kernel(i, ids[j]);
443                  kernel_count++;
444              }
445          }
446          if (store) {
447              TSVMCacheVec vec = cache.Add(i);
448              TFltType *vecVals = vec.valT;
449              bool *vecValid = vec.validT;
450              int *vecIds = vec.idsT;
451              int vecLen = vec.dim;
452              if (sync) {
453                  if (len == vecLen) {
454                      for (j = 0; j < len; j++) {
455                          Assert(vecIds[ids[j]] != -1);
456                          vecVals[j] = (TFltType)result[j];
457                          vecValid[j] = true;
458                      }
459                  } else {
460                      for (j = 0; j < vecLen; j++) vecValid[j] = false;
461                      for (j = 0; j < len; j++) {
462                          k = vecIds[ids[j]];
463                          Assert(0 <= k && k <= vecLen);
464                          vecVals[k] = (TFltType)result[j];
465                          vecValid[k] = true; 
466                      }
467                  }
468              } else {
469                  int l = docs->Len();
470                  for (j = 0; j < vecLen; j++) vecValid[j] = false;
471                  for (j = k = 0; j < l; j++) {
472                      if (j < ids[k]) {
473                          if (vecIds[j] >= 0) {
474                              Assert(vecIds[j] <= vecLen);
475                              if (cache.IsRowValid(j, i)) {
476                                  vecVals[vecIds[j]] = cache.GetVal(j, i);
477                              } else {
478                                  vecVals[vecIds[j]] = (TFltType)kernel(i, j);
479                                  kernel_count++;
480                              }
481                              vecValid[vecIds[j]] = true;
482                          }
483                      } else {
484                          Assert(j == ids[k]);
485                          if (vecIds[j] >= 0) {
486                              vecVals[vecIds[j]] = (TFltType)result[k];
487                              vecValid[vecIds[j]] = true;
488                          }
489                          k++;
490                      }
491                  }
492              } 
493          } 
494      } 
495  }
496  inline void TSVMQPSolver::column(const int& i, double *result) {
497      readColumnRows(i, numUSV, USV, result, true, shrinking);
498  }
499  void TSVMQPSolver::calcColumns(const int& n) {
500      for (int i = 0; i < n; i++)
501          column(USV[workingSet[i]], cols[i]);
502  }
503  void TSVMQPSolver::optimize(TFltV& alphas, double& _base, const PSVMTrainSet& _docs,
504         const TFltV& _pV, const TFltV& _yV, const double& _D, const TFltV& _CV,
505         const int& sub_size, const int& memory_size, const int& time) {
506      IAssert(_docs->Len() > 0 && _docs->Dim() > 0);
507      IAssert(_pV.Len() == _yV.Len() && _yV.Len() == _CV.Len());
508      docs = _docs;
509      int i, ii, j, jj;       
510      int len = docs->Len();  
511      int size = sub_size + sub_size % 2;
512      size = size < len ? size : len;
513      IAssert(size >= 2);
514      double *QQ = new double[size*size];
515      double *Q = new double[size * size]; 
516      double *A = new double[size]; 
517      double *cc = new double[size]; 
518      double *u = new double[size]; 
519      TSVMQP qp(size);
520      if (!is_linear) initializeCache(memory_size, size);
521      bool old_shrinking = shrinking;
522      shrink = new TShrinkState;
523      shrinkInitialize();
524      initialize(_pV, _yV, _D, _CV, size);
525      int n; 
526      initRelearning(alphas);
527      initNonzeroD(size);
528      TSVMTime time_tmp, time_workingset = 0, time_kernel = 0, time_prepare = 0,
529               time_solve = 0, time_s = 0, time_analize = 0, time_shrink = 0;
530      double leq, res; 
531      double old_violation = 0.0;
532      double absChange = 1.0; 
533      int noChangeCount = 0; 
534      int numUnbnd;   
535      TSVMTime trainingTime = GetCurrentTime();
536      bool overTime = false; iter = 0;
537      do {
538          if (verbosity > 0 && (verbosity > 1 || iter % 100 == 0)) printf(".");
539          iter++;
540          time_tmp = GetCurrentTime();
541          bool DoingRandomStep = false;
542              n = selectWorkingSet(size, false);
543          IAssert(n >= 2 && n <= size);
544          time_workingset += GetCurrentTime() - time_tmp;
545          time_tmp= GetCurrentTime();
546          if (!is_linear) {
547              calcColumns(n);
548          }
549          time_kernel += GetCurrentTime() - time_tmp;
550          time_tmp = GetCurrentTime();
551          double b = 0.0;
552          for (i = 0; i < numUSV; i++) b -= alphaV[USV[i]] * y[USV[i]];
553          for (i = 0; i < numBSV; i++) b -= alphaV[BSV[i]] * y[BSV[i]]; 
554          for (i = 0; i < n; i++) {
555              ii = USV[workingSet[i]];
556              Assert(0 <= ii && ii < len);
557              b += alphaV[ii] * y[ii];  
558              A[i] = y[ii];
559              cc[i] = gradV[ii];
560              u[i] = C[ii];
561              for (j = 0; j < n; j++) {
562                  jj = USV[workingSet[j]];
563                  Assert(0 <= jj && jj < len);
564                  if (is_linear) {
565                      kernel_count++;
566                      if (j >= i) {
567                          QQ[i*n + j] = res = kernel(ii,jj);
568                      } else {
569                          res = QQ[j*n + i];
570                      }
571                  } else {
572                      res = cols[i][workingSet[j]];
573                  }
574                  cc[i] -= alphaV[jj]*y[jj]*res;
575                  Q[i*n + j] = y[ii]*y[jj]*res;
576              }
577              cc[i] = y[ii]*cc[i] + p[ii];
578          }
579          b = D + b;
580          time_prepare += GetCurrentTime() - time_tmp;
581          time_tmp= GetCurrentTime();
582          double *newAlphaV = new double[n];   
583          if (!qp.solve(n, b, u, Q, A, cc, newAlphaV, verbosity)) {
584              for(int i = 0; i < n; i++)
585                  newAlphaV[i] = alphaV[USV[workingSet[i]]];
586          }
587          for (i = 0; i < n; i++) {
588              if (C[USV[workingSet[i]]] - newAlphaV[i] < EPSILON)
589                  newAlphaV[i] = C[USV[workingSet[i]]];
590              else if (newAlphaV[i] < EPSILON)
591                  newAlphaV[i] = 0.0;
592          }
593          time_solve += GetCurrentTime() - time_tmp;
594          time_tmp = GetCurrentTime();
595          adjustS(n, newAlphaV);
596          time_s += GetCurrentTime() - time_tmp;
597          time_tmp= GetCurrentTime();
598          absChange = 0.0;
599          for (i = 0; i < n; i++) {
600              ii = USV[workingSet[i]];
601              used[ii] = false;
602              absChange += fabs(alphaV[ii] - newAlphaV[i]);
603              alphaV[ii] = newAlphaV[i];
604          }
605          delete[] newAlphaV;
606          if (DoingRandomStep) {
607              absChange = 1.0; noChangeCount = 0;
608          } else if (absChange < EPSILON) {
609              noChangeCount++;
610          } else {
611              noChangeCount = 0;
612          }
613          leq = 0.0;
614          numUnbnd = 0;
615          for (i = numUnbnd = 0; i < numUSV; i++) {
616              ii = USV[i];
617              res = gradV[ii] + y[ii] * p[ii];
618              listV[ii] = res;
619              if (EPSILON < alphaV[ii] && alphaV[ii] < C[ii] - EPSILON) {
620                  leq += -res;
621                  numUnbnd++;
622              }
623          }
624          if (numUnbnd > 0) {  
625              base = leq = leq / numUnbnd;
626              old_violation = max_violation;
627              max_violation = shrinking ? shrinkCheckOptimality(1, leq) :
628                                          checkOptimality(leq);
629              if (shrinking) {
630                  if (is_linear && iter > 30 && iter % 3 == 0 && numUSV < len &&
631                      max_violation - old_violation > 0.1) {
632                      if (verbosity > 1) printf("#");
633                      shrinkReactivate();
634                      shrinkCheckOptimality(h, leq);
635                      if (shrink->count >= minNumElts)
636                          shrinkReduce();
637                  } else if (max_violation > epsilon_ter) {
638                      if ((shrink->count >= minNumElts) && (iter % h == 0) &&
639                          (is_linear || shrink->hcount < shrink->aHist.Reserved())) {
640                            shrinkReduce();
641                      }
642                  } else  {
643                      time_analize += GetCurrentTime() - time_tmp;
644                      time_tmp= GetCurrentTime();
645                      if (verbosity > 0) printf("\nchecking unactive variables...");
646                      shrinkReactivate();
647                      time_shrink += GetCurrentTime() - time_tmp;
648                      time_tmp= GetCurrentTime();
649                      old_violation = max_violation;
650                      max_violation = checkOptimality(leq);
651                      if (verbosity > 0 && max_violation > epsilon_ter) printf("\n");
652                      if (!is_linear) shrinking = false;
653                  }
654              }
655              if (verbosity > 2) printf("<%.5f,%.5f>", max_violation, absChange);
656          }
657          time_analize += GetCurrentTime() - time_tmp;
658          if (time != -1) overTime = ToSeconds(GetCurrentTime() - trainingTime) > time;
659      } while ((max_violation > epsilon_ter || numUnbnd == 0) && (!overTime) && (noChangeCount < 30));
660      shrinking = old_shrinking;
661      alphas.Reserve(len,len);
662      for (i = 0; i < len; i++)
663          alphas[i] = alphaV[i];
664      _base = base;
665      if (verbosity > 0) {
666          printf("\n");
667          if (verbosity == 1) {
668              printf("Max-Violation = %.6f\n", max_violation);
669              double time_all = ToSeconds(time_workingset + time_kernel +
670                  time_prepare + time_solve + time_s + time_analize + time_shrink);
671              printf("Iterations = %d, Time=%.3f\n", iter, time_all);
672          } else {
673              printf("Max-Violation = %.6f\n", max_violation);
674              printf("Iterations = %d, Kernel-Count=%d\n", iter, kernel_count);
675              if (verbosity > 1) {
676                  printf("Time: workset=%.3f, kernel=%.3f, prepare=%.3f, solve=%.3f,\n"
677                         "      s=%.3f, analize=%.3f, shrink=%.3f\n",
678                      ToSeconds(time_workingset), ToSeconds(time_kernel), ToSeconds(time_prepare),
679                      ToSeconds(time_solve), ToSeconds(time_s), ToSeconds(time_analize),
680                      ToSeconds(time_shrink));
681              }
682              if (!is_linear)
683                  printf("Cache: yes = %d, no = %d\n", cache_yes, cache_no);
684          }
685      }
686      dealocate();
687      delete[] QQ; delete[] Q; delete[] A; delete[] cc; delete[] u;
688      delete shrink;
689  }
690  void TSVMQPSolver::initializeCache(const int& memory_size, int& size) {
691      cache.Reset(memory_size, docs->Len());
692      if (cache.MaxSize() < size) {
693          if (cache.MaxSize() < 2) {
694              printf("cache size is to small, can't even store two columns!\n");
695          } else {
696              size = cache.MaxSize() - cache.MaxSize() % 2;
697              if (verbosity > 0)
698                  printf("cache size is to small, size of subQP = %d", size);
699          }
700      }
701      cache_yes = cache_no = 0;
702  }
703  void TSVMQPSolver::initialize(const TFltV& _pV, const TFltV& _yV,
704             const double& _D, const TFltV& _CV, const int& size) {
705      int len = docs->Len();
706      int dim = docs->Dim();
707      max_violation = 0.0;       
708      kernel_count = 0;          
709      D = _D;
710      p = new double[len];
711      y = new double[len];
712      C = new double[len];
713      gradV = new double[len];   
714      listV = new double[len];
715      alphaV = new double[len];  
716      used = new bool[len];       
717      workingSet = new int[size]; 
718      for (int i = 0; i < len; i++) {
719          alphaV[i] = gradV[i] = 0.0;
720          used[i] = false;
721          p[i] = _pV[i];
722          y[i] = _yV[i];
723          listV[i] = y[i] * p[i];
724          IAssert(_CV[i] > 0); C[i] = _CV[i];
725      }
726      if (is_linear) {
727          weightV = new double[dim];
728          for (int j = 0; j < dim; j++) weightV[j] = 0.0;
729      }
730      if (!is_linear) {
731          cols.Reserve(size, size);
732          for (int i = 0; i < size; i++) cols[i] = new double[len];
733      }
734  }
735  void TSVMQPSolver::initRelearning(TFltV& alphas) {
736      int len = docs->Len();  
737      int dim = docs->Dim();  
738      int i, ii;
739      if (alphas.Len() != 0 && alphas.Len() == len) {
740          printf("relearning...\n");
741          double res;
742          if (is_linear) {
743              for (i = 0; i < dim; i++) weightV[i] = 0.0;
744              for (i = 0; i < len; i++) {
745                  res = (alphas[i] - alphaV[i]) * y[i];
746                  docs->AddVec(i, weightV, dim, res);
747              }
748              for (i = 0; i < numUSV; i++) {
749                  ii = USV[i];
750                  gradV[ii] += docs->DotProduct(ii, weightV, dim);
751                  listV[ii] += gradV[ii];
752              }
753          } else {
754              printf("relearning not implemented for non-linear svm!\n"); Fail;
755          }
756      }
757  }
758  void TSVMQPSolver::initNonzeroD(const int& size) {
759      int len = docs->Len();  
760      int dim = docs->Dim();  
761      int i, j;
762      if (D > 0.0) {
763          if (is_linear)
764              for (i = 0; i < dim; i++) weightV[i] = 0.0;
765          double minC = C[0];
766          for (i = 0; i < len; i++)
767              minC = TFlt::GetMn(minC, C[i]);
768          int M1 = (int)(2*D/minC) + size, M2 = 0;
769          for (i = 0; i < len; i++) if (y[i] > 0.0) M2++;
770          int M = M1 < M2 ? M1 : M2;
771          double beginningAlpha = D/M;
772          double res;
773          i = 0;
774          while (i < len) {
775              if (y[i] > 0.0) {
776                  alphaV[i] = beginningAlpha;
777                  M--;
778                  if (is_linear) {
779                      docs->AddVec(i, weightV, dim, alphaV[i] * y[i]);
780                  } else {
781                      double *ker = new double[len];
782                      column(i, ker);
783                      res = alphaV[i] * y[i];
784                      for (j = 0; j < len; j++) {
785                          gradV[j] += res * ker[j];
786                      }
787                      delete[] ker;
788                  }
789                  if (M == 0) break;
790              }
791              i++;
792          }
793          IAssert(M == 0);
794          if (is_linear) {
795              for (i = 0; i < len; i++) {
796                  gradV[i] += docs->DotProduct(i, weightV, dim);
797              }
798          }
799          for (i = 0; i < len; i++)
800              listV[i] += gradV[i];
801      }
802  }
803  void TSVMQPSolver::dealocate() {
804      if (!is_linear) {
805          cache.Clear();
806          int size = cols.Len();
807          for (int i = 0; i < size; i++) delete cols[i];
808      }
809      delete[] p, delete[] y; delete[] C;
810      delete[] gradV; delete[] listV;
811      delete[] alphaV;
812      if (is_linear) delete[] weightV;
813      delete[] used; delete[] workingSet;
814      delete[] USV; delete[] BSV; delete[] NSV;
815  }
816  int TSVMQPSolver::selectWorkingSet(const int& n, const bool& random) {
817      int i, j, jj;   
818      int q = n / 2;
819      if (random) {
820          TIntV WorkSetTmpV(numUSV, 0);
821          for (i = 0; i < numUSV; i++) {
822              if (!used[USV[i]])
823                  WorkSetTmpV.Add(i);
824          }
825          WorkSetTmpV.Shuffle(rnd);
826          const int Len = TInt::GetMn(numUSV, n);
827          for (int i = 0; i < Len; i++) {
828              j = WorkSetTmpV[i];
829              jj = USV[j];
830              workingSet[i] = j;
831              used[jj] = true;
832          }
833          return n;
834      }
835      TMaxHeap maxHeap(q); TMaxHeapVal maxElt;
836      TMinHeap minHeap(q); TMinHeapVal minElt; 
837      for (j = 0; j < numUSV; j++) {
838          jj = USV[j];
839          if (EPSILON < alphaV[jj] && alphaV[jj] < C[jj] - EPSILON) {
840              minElt.id = maxElt.id = j;
841              minElt.val = maxElt.val = listV[jj];
842              if (!maxHeap.Full()) { maxHeap.Add(maxElt); }
843              else if (maxElt > maxHeap.Top()) { maxHeap.ChangeTop(maxElt); }
844              if (!minHeap.Full()) { minHeap.Add(minElt);}
845              else if (minElt > minHeap.Top()) { minHeap.ChangeTop(minElt); }
846          } else {
847              if ((alphaV[jj] < EPSILON && y[jj] < 0) ||
848                  (alphaV[jj] > C[jj] - EPSILON && y[jj] > 0)) {
849                      maxElt.id = j; maxElt.val = listV[jj];
850                      if (!maxHeap.Full()) { maxHeap.Add(maxElt); }
851                      else if (maxElt > maxHeap.Top()) { maxHeap.ChangeTop(maxElt); }
852              }
853              if ((alphaV[jj] < EPSILON && y[jj] > 0) ||
854                  (alphaV[jj] > C[jj] - EPSILON && y[jj] < 0)) {
855                      minElt.id = j; minElt.val = listV[jj];
856                      if (!minHeap.Full()) { minHeap.Add(minElt); }
857                      else if (minElt > minHeap.Top()) { minHeap.ChangeTop(minElt); }
858              }
859          }
860      } 
861      int cs = 0;
862      int heapSize = maxHeap.Size();
863      TMaxHeapVal *maxArray = maxHeap.Array();
864      for (i = 1; i <= heapSize; i++) {
865          Assert(0 <= maxArray[i].id && maxArray[i].id < numUSV);
866          workingSet[cs++] = maxArray[i].id;
867          used[USV[maxArray[i].id]] = true;
868      }
869      heapSize = minHeap.Size();
870      TMinHeapVal *minArray = minHeap.Array();
871      for (i = 1; i <= heapSize; i++) {  
872          if (!used[USV[minArray[i].id]]) {
873              Assert(0 <= minArray[i].id && minArray[i].id < numUSV);
874              workingSet[cs++] = minArray[i].id;
875              used[USV[minArray[i].id]] = true;
876          } else {
877          }
878      }
879      return cs;
880  }
881  void TSVMQPSolver::adjustS(const int& n, double *newAlphaV) {
882      int dim = docs->Dim();
883      int i, ii, j ,jj;
884      double res;
885      if (is_linear) {
886          for (i = 0; i < dim; i++) weightV[i] = 0.0;
887          for (i = 0; i < n; i++) {
888              ii = USV[workingSet[i]];
889              res = (newAlphaV[i] - alphaV[ii]) * y[ii];
890              docs->AddVec(ii, weightV, dim, res);
891          }
892          for (i = 0; i < numUSV; i++) {
893              ii = USV[i];
894              gradV[ii] += docs->DotProduct(ii, weightV, dim);
895          }
896      } else {
897          double *ker;
898          for (i = 0; i < n; i++) {
899              ii = USV[workingSet[i]];
900              res = (newAlphaV[i] - alphaV[ii]) * y[ii];
901              ker = cols[i];
902              for (j = 0; j < numUSV; j++) {
903                  jj = USV[j];
904                  gradV[jj] += res * ker[j];
905              }
906          }
907      }
908  }
909  double TSVMQPSolver::checkOptimality(double leq) {
910      int i, ii;
911      double res, max = 0.0;
912      for (i = 0; i < numUSV; i++) {
913          ii = USV[i];
914          if (EPSILON < alphaV[ii] && alphaV[ii] < C[ii] - EPSILON) {
915              res = fabs(leq + listV[ii]);
916              max = TFlt::GetMx(max, res);
917          } else if (alphaV[ii] < EPSILON) {
918              res = y[ii]*(gradV[ii] + leq) + p[ii];  
919              max = TFlt::GetMx(max, -res);
920          } else {
921              Assert(alphaV[ii] > C[ii] - EPSILON);
922              res = y[ii]*(gradV[ii] + leq) + p[ii];
923              max = TFlt::GetMx(max, res);
924          }
925      }
926      return max;
927  }
928  void TSVMQPSolver::shrinkInitialize() {
929      int len = docs->Len();
930      int i;
931      USV = new int[len];     
932      BSV = new int[len];     
933      NSV = new int[len];     
934      numUSV = len;
935      numBSV = numNSV = 0;
936      shrink->BSVcount = new int[len];
937      shrink->NSVcount = new int[len];
938      if (is_linear) {
939          shrink->epsilon = 0.01; 
940          shrink->aOld = new double[len];
941          shrink->sOld = new double[len];
942          for (i = 0; i < len; i++) {
943              USV[i] = i;
944              shrink->BSVcount[i] = shrink->NSVcount[i] = 0;
945              shrink->aOld[i] = shrink->sOld[i] = 0.0;
946          }
947      } else {
948          shrink->epsilon = 2.0;
949          shrink->aHist.Reserve(100,0);
950          shrink->histID = new int[len];
951          shrink->hcount = 0;
952          for (i = 0; i < len; i++) {
953              USV[i] = i;
954              shrink->BSVcount[i] = shrink->NSVcount[i] = 0;
955              shrink->histID[i] = -1;
956          }
957      }
958  }
959  double TSVMQPSolver::shrinkCheckOptimality(int step, const double& leq) {
960      int i, ii; 
961      double res, max = 0.0;
962      if (!is_linear)
963          shrink->epsilon = 0.7*shrink->epsilon + 0.3*max_violation;
964      shrink->count = 0;
965      for (i = 0; i < numUSV; i++) {
966          ii = USV[i];
967          if (EPSILON < alphaV[ii] && alphaV[ii] < C[ii] - EPSILON) {
968              res = fabs(leq + listV[ii]);
969              max = TFlt::GetMx(max, res);
970          } else if (alphaV[ii] < EPSILON) {
971              res = y[ii]*(gradV[ii] + leq) + p[ii];
972              if (res > shrink->epsilon) {
973                  shrink->NSVcount[ii] += step;
974                  if (shrink->NSVcount[ii] >= h) shrink->count++;
975              } else {
976                  shrink->NSVcount[ii] = 0;
977              }
978              max = TFlt::GetMx(max, -res);
979          } else if (alphaV[ii] > C[ii] - EPSILON) {
980              res = y[ii]*(gradV[ii] + leq) + p[ii];
981              if (res < -shrink->epsilon) {
982                  shrink->BSVcount[ii] += step;
983                  if (shrink->BSVcount[ii] >= h) shrink->count++;
984              } else {
985                  shrink->BSVcount[ii] = 0;
986              }
987              max = TFlt::GetMx(max, res);
988          } else {
989              printf("we shouldn't be here... %d\n", __LINE__); Fail;
990          }
991      }
992      return max;
993  }
994  void TSVMQPSolver::shrinkReduce() {
995      int len = docs->Len();
996      int i, ii, j = 0;
997      int newnumUSV = 0;
998      if (!is_linear) {
999          TFltV ha(len);
1000          for (i = 0; i < len; i++) ha[i] = alphaV[i];
1001          shrink->aHist.Add(TFltVP::New(ha));
1002      } else {
1003      }
1004      for (i = 0; i < numUSV; i++) {
1005          ii = USV[i];
1006          if (shrink->NSVcount[ii] >= h) {
1007              NSV[numNSV] = ii;
1008              if (!is_linear) {
1009                  shrink->histID[ii] = shrink->hcount;
1010              }
1011              numNSV++;
1012          } else if (shrink->BSVcount[ii] >= h) {
1013              BSV[numBSV] = ii;
1014              if (!is_linear) {
1015                  shrink->histID[ii] = shrink->hcount;
1016              }
1017              numBSV++;
1018          } else {
1019              USV[j] = ii;
1020              j++; newnumUSV++;
1021          }
1022      }
1023      if (!is_linear) {
1024          if (cache.Full())
1025              cache.Shrink(newnumUSV, USV);
1026          if (verbosity > 1) printf("[%d:%d]", shrink->hcount, len - newnumUSV);
1027          shrink->hcount++;
1028      } else {
1029          if (verbosity > 1) printf("[%d]", len - newnumUSV);
1030      }
1031      numUSV = newnumUSV;
1032  }
1033  void TSVMQPSolver::shrinkReactivate() {
1034      int i, j;
1035      int len = docs->Len();
1036      int dim = docs->Dim();
1037      if (is_linear) {
1038          double res;
1039          for (i = 0; i < dim; i++) weightV[i] = 0.0;
1040          for (i = 0; i < len; i++) {
1041              if (shrink->aOld[i] != alphaV[i]) {
1042                  res = (alphaV[i] - shrink->aOld[i]) * y[i];
1043                  docs->AddVec(i, weightV, dim, res);
1044              }
1045              shrink->aOld[i] = alphaV[i];
1046          }
1047          for (i = 0, j = 0; i < len; i++) {
1048              if (USV[j] > i)
1049                  gradV[i] = shrink->sOld[i] + docs->DotProduct(i, weightV, dim);
1050              else
1051                  j++;
1052              shrink->sOld[i] = gradV[i];
1053          }
1054      } else {
1055          int k, kk;
1056          PFltV a_old;
1057          double res;
1058          int numInactive;    
1059          int *inactiveIds = new int[len];    
1060          double *col = new double[len];      
1061          for (i = shrink->hcount - 1; i >= 0; i--) {
1062              if (verbosity > 1) printf("..%d", i);
1063              a_old = shrink->aHist[i];
1064              numInactive = 0;
1065              for (j = 0; j < len; j++) {
1066                  if (shrink->histID[j] == i) {
1067                      inactiveIds[numInactive] = j;
1068                      numInactive++;
1069                      shrink->histID[j] = -1;
1070                  }
1071              }
1072              for (j = 0; j < len; j++) {
1073                  a_old->Len();
1074                  if (a_old->GetVal(j) != alphaV[j]) {
1075                      readColumnRows(j, numInactive, inactiveIds, col, false, false);
1076                      res = (alphaV[j] - a_old->GetVal(j)) * y[j];
1077                      for (k = 0; k < numInactive; k++) {
1078                          kk = inactiveIds[k];
1079                          gradV[kk] += res * col[k];
1080                      }
1081                  }
1082              }
1083          }
1084          delete[] col;
1085          delete[] inactiveIds;
1086          shrink->hcount = 0;
1087          shrink->aHist.Reserve(100,0);
1088      }
1089      numUSV = len; numBSV = numNSV = 0;
1090      for (i = 0; i < len; i++) {
1091          USV[i] = i;
1092          shrink->BSVcount[i] = shrink->NSVcount[i] = 0;
1093          listV[i] = gradV[i] + y[i] * p[i];;
1094      }
1095  }
1096  TSVMQPSolver::TSVMTime TSVMQPSolver::GetCurrentTime() {
1097  #ifdef GLib_WIN32
1098      FILETIME lpCreationTime; 
1099      FILETIME lpExitTime;     
1100      FILETIME lpKernelTime;   
1101      FILETIME lpUserTime;     
1102      GetProcessTimes(GetCurrentProcess(), &lpCreationTime, &lpExitTime,
1103                                           &lpKernelTime, &lpUserTime);
1104      return lpUserTime.dwLowDateTime +
1105             ((unsigned __int64)lpUserTime.dwHighDateTime << 32);
1106  #elif defined(GLib_UNIX)
1107      return TSysTm::GetCurUniMSecs();            
1108  #endif
1109  }
1110  inline double TSVMQPSolver::ToSeconds(TSVMTime time) {
1111      return time / 1e7;
1112  }
1113  template <class TVal>
1114  void TSVMQPSolver::THeap<TVal>::Add(const TVal& elt) {
1115      n++; int i = n;
1116      while (i > 1 && array[i/2] > elt) {
1117          array[i] = array[i/2]; i = i/2;
1118      }
1119      array[i] = elt;
1120  }
1121  template <class TVal>
1122  void TSVMQPSolver::THeap<TVal>::ChangeTop(const TVal& elt) {
1123      int left, right, smallest, i = 1; TVal tmp; array[1] = elt;
1124      forever {
1125          left = 2*i; right = 2*i + 1;
1126          if (left <= n && elt > array[left])
1127              smallest = left;
1128          else
1129              smallest = i;
1130          if (right <= n && array[smallest] > array[right])
1131              smallest = right;
1132          if (smallest != i) {
1133              tmp = array[i];
1134              array[i] = array[smallest];
1135              array[smallest] = tmp;
1136              i = smallest;
1137          } else break;
1138      }
1139  }
1140  void TSVMLargeScale::Solve(PSVMTrainSet TrainSet, const double& SvmCost,
1141          const double& AccuracyEps, const int& MxTime, const bool& TillMxIter,
1142          const int& ProcN, TFltV& WgtV, PNotify Notify) {
1143      EAssertR(TrainSet->Len() > 0, "Empty training set!");
1144      EAssertR(SvmCost > 0.0, "Cost parameter must be nonzero!");
1145      EAssertR(AccuracyEps > 0.0, "Accuaryc epsilon must be nonzero!");
1146      const int Dims = TrainSet->Dim(); 
1147      const int Vecs = TrainSet->Len(); 
1148      const double InvVecs = 1.0 / double(Vecs); 
1149      WgtV.Gen(Dims); WgtV.PutAll(0.0); 
1150      double Slack = 0.0; 
1151      TIntV ConstrLenV; 
1152      TVec<TFltV> ConstrVecsVV; 
1153      TVVec<double> QPQuad; TVec<double> QPLin, QPConstr;
1154      double MxVecNorm2 = 0.0;
1155      for (int VecId = 0; VecId < Vecs; VecId++) {
1156          MxVecNorm2 = TMath::Mx(MxVecNorm2, TrainSet->GetNorm2(VecId)); }
1157      int MxIters = TFlt::Round(TMath::Mx(2/AccuracyEps, (8*SvmCost*MxVecNorm2)/TMath::Sqr(AccuracyEps)));
1158      Notify->OnStatus(TInt::GetStr(MxIters, "Maximal number of iterations: %d"));
1159      int IterN = 0; TExeTm Timer;
1160      forever {
1161          ConstrVecsVV.Add(TFltV()); TFltV& ConstrVecsV = ConstrVecsVV.Last();
1162          ConstrVecsV.Gen(Vecs); ConstrVecsV.PutAll(0.0);
1163          int ConstrLen = 0; double ConstrSum = 0.0;
1164          for (int VecId = 0; VecId < Vecs; VecId++) {
1165              const double VecParam = TrainSet->GetVecParam(VecId);
1166              const double Val = VecParam * TrainSet->DotProduct(VecId, WgtV);
1167              if (Val < 1.0) {
1168                  TrainSet->AddVec(VecId, ConstrVecsV, VecParam);
1169                  ConstrLen++; ConstrSum += Val;
1170              }
1171          }
1172          ConstrLenV.Add(ConstrLen);
1173          for (int DimN = 0; DimN < Dims; DimN++) {
1174              ConstrVecsV[DimN] = InvVecs * ConstrVecsV[DimN]; }
1175          QPLin.Add(-  InvVecs * double(ConstrLen));
1176          TVVec<double> NewQPQuad(IterN+1, IterN+1);
1177          for (int i = 0; i < IterN; i++) {
1178              for (int j = 0; j < IterN; j++) {
1179                  NewQPQuad(i,j) = QPQuad(i,j); }
1180          }
1181          for (int i = 0; i < IterN; i++) {
1182              const double EltVal = TLinAlg::DotProduct(ConstrVecsVV[i], ConstrVecsV);
1183              NewQPQuad(IterN, i) = EltVal; NewQPQuad(i, IterN) = EltVal;
1184          }
1185          NewQPQuad(IterN, IterN) = TLinAlg::DotProduct(ConstrVecsV, ConstrVecsV);
1186          QPQuad = NewQPQuad;
1187          QPConstr.Add(1.0);
1188          const double StopCrit = InvVecs*ConstrLen - InvVecs*ConstrSum;
1189          if (StopCrit > (Slack + AccuracyEps)) { break; } 
1190          if ((MxTime != -1) && (Timer.GetSecs() > MxTime)) { break; } 
1191          IterN++; if (TillMxIter && (IterN > MxIters)) { break; } 
1192          Notify->OnStatus(TStr::Fmt("[IterN:%5d, Accr:%8.5f, Time:%5d s]\r",
1193              IterN, (StopCrit - Slack), Timer.GetSecs()));
1194      };
1195  }
1196  void TSVMFactory::trainClassifier(TFltV& alphas, double& threshold,
1197          const bool& is_linear, const PKernel& ker, const PSVMTrainSet& docs,
1198          const double& C, const double& j, const TSVMLearnParam& LearnParam) {
1199      IAssert(C > 0.0 && j > 0.0);
1200      int len = docs->Len();
1201      TFltV p(len), y(len), CV(len);
1202      for (int i = 0; i < len; i++) {
1203          p[i] = -1;
1204          y[i] = docs->GetVecParam(i);
1205          CV[i] = (y[i] > 0) ? C*j : C;
1206      }
1207      int h = 10, minNumElts = is_linear ? 10 : 100;
1208      TSVMQPSolver solver(is_linear, ker, LearnParam.Verbosity,
1209          LearnParam.EpsTer, LearnParam.Shrink, h, minNumElts);
1210      solver.optimize(alphas, threshold, docs, p, y, 0, CV,
1211          LearnParam.SubSize, LearnParam.MemSize, LearnParam.Time);
1212  }
1213  void TSVMFactory::trainOneClass(TFltV& alphas, double& threshold,
1214          const bool& is_linear, const PKernel& ker, const PSVMTrainSet& docs,
1215          const double& nu, const TSVMLearnParam& LearnParam) {
1216      IAssert(0.0 < nu && nu < 1.0);
1217      int len = docs->Len();
1218      double D = nu*len;
1219      TFltV p(len), y(len), C(len);
1220      for (int i = 0; i < len; i++) {
1221          p[i] = 0;
1222          y[i] = 1;
1223          C[i] = 1.0;
1224      }
1225      int h = 10, minNumElts = is_linear ? 10 : 100;
1226      TSVMQPSolver solver(is_linear, ker, LearnParam.Verbosity,
1227          LearnParam.EpsTer, LearnParam.Shrink, h, minNumElts);
1228      solver.optimize(alphas, threshold, docs, p, y, D, C,
1229          LearnParam.SubSize, LearnParam.MemSize, LearnParam.Time);
1230  }
1231  void TSVMFactory::trainRegression(TFltV& alphas, double& threshold,
1232          const bool& is_linear, const PKernel& ker, const PSVMTrainSet& docs,
1233          const double& E, const double& C, const TSVMLearnParam& LearnParam) {
1234      IAssert(E > 0.0 && C > 0.0);
1235      int len = docs->Len();
1236      TIntV IdV(2*len, 0);
1237      TFltV p(2*len), y(2*len), CV(2*len);
1238      for (int i = 0; i < len; i++) {
1239          p[i] = E + docs->GetVecParam(i);
1240          y[i] = 1; CV[i] = C; IdV.Add(i);
1241      }
1242      for (int i = len; i < 2*len; i++) {
1243          p[i] = E - docs->GetVecParam(i-len);
1244          y[i] = -1; CV[i] = C; IdV.Add(i-len);
1245      }
1246      PSVMTrainSet docs2 = TSVMTrainSubSet::New(docs, IdV);
1247      int h = 10, minNumElts = is_linear ? 10 : 100;
1248      TSVMQPSolver solver(is_linear, ker, LearnParam.Verbosity,
1249          LearnParam.EpsTer, LearnParam.Shrink, h, minNumElts);
1250      solver.optimize(alphas, threshold, docs2, p, y, 0, CV,
1251          LearnParam.SubSize, LearnParam.MemSize, LearnParam.Time);
1252  }
1253  void TSVMFactory::train(TFltV& alphas, double& threshold,
1254          const bool& is_linear, const PKernel& ker, const PSVMTrainSet& docs,
1255          const TSVMModelParam& ModelParam, const TSVMLearnParam& LearnParam) {
1256      if (ModelParam.ModelType == smtClassifier) {
1257          trainClassifier(alphas, threshold, is_linear, ker, docs, ModelParam.C, ModelParam.j, LearnParam);
1258      } else if (ModelParam.ModelType == smtRegression) {
1259          trainRegression(alphas, threshold, is_linear, ker, docs, ModelParam.E, ModelParam.C, LearnParam);
1260      } else if (ModelParam.ModelType == smtOneClass) {
1261          trainOneClass(alphas, threshold, is_linear, ker, docs, ModelParam.nu, LearnParam);
1262      }
1263  }
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from notepad-plus-plus-MDEwOlJlcG9zaXRvcnkzMzAxNDgxMQ==-flat-u32regex_token_iterator.hpp</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from snap-MDEwOlJlcG9zaXRvcnk0Mjg4MzU3-flat-svmbasic.cpp</div>
                </div>
                <div class="column column_space"><pre><code>117           pdata.reset();
118     }
119     u32regex_token_iterator(BidirectionalIterator a, BidirectionalIterator b, const regex_type& re, 
120                          const std::vector<int>& submatches, match_flag_type m = match_default)
</pre></code></div>
                <div class="column column_space"><pre><code>386          return nonlin_kernel->CalcSet(docs, i1, i2);
387      }
388  }
389  void TSVMQPSolver::readColumnRows(const int& i, const int& len, int *ids,
390                          double *result, const bool& store, const bool& sync) {
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    