
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 3.8379530916844353%, Tokens: 9, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>tesseract-MDEwOlJlcG9zaXRvcnkyMjg4NzA5NA==-flat-validate_khmer_test.cc</h3>
            <pre><code>1  #include "include_gunit.h"
2  #include "normstrngs.h"
3  #include "normstrngs_test.h"
4  namespace tesseract {
5  TEST(ValidateKhmerTest, GoodKhmerWords) {
6    std::string str = "ព័ត៏មានប្លែកៗ";
7    ExpectGraphemeModeResults(str, UnicodeNormMode::kNFC, 13, 12, 7, str);
8    str = "ទំនុកច្រៀង";
9    ExpectGraphemeModeResults(str, UnicodeNormMode::kNFC, 10, 9, 5, str);
10    str = "កាលីហ្វូញ៉ា";
11    ExpectGraphemeModeResults(str, UnicodeNormMode::kNFC, 11, 10, 4, str);
12    str = "ចាប់ពីផ្លូវ";
13    ExpectGraphemeModeResults(str, UnicodeNormMode::kNFC, 11, 10, 5, str);
14  }
15  TEST(ValidateKhmerTest, BadKhmerWords) {
16    std::string result;
<span onclick='openModal()' class='match'>17    std::string str = "\u1796\u17b6\u17b7";
18    EXPECT_FALSE(NormalizeUTF8String(UnicodeNormMode::kNFC, OCRNorm::kNone, GraphemeNorm::kNormalize,
19                                     str.c_str(), &result));
20    str = "\u1798\u17c9\u17ca";
21    EXPECT_FALSE(NormalizeUTF8String(UnicodeNormMode::kNFC, OCRNorm::kNone, GraphemeNorm::kNormalize,
22                                     str.c_str(), &result));
23    str = "\u1780\u17b6\u17cb\u17cd";
24    EXPECT_FALSE(NormalizeUTF8String(UnicodeNormMode::kNFC, OCRNorm::kNone, GraphemeNorm::kNormalize,
25                                     str.c_str(), &result));
</span>26  }
27  } 
</code></pre>
        </div>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-mkldnn_lrn_layer.cpp</h3>
            <pre><code>1  #ifdef MKLDNN_SUPPORTED
2  #include <vector>
3  #include "caffe/layer.hpp"
4  #include "caffe/layers/mkldnn_layers.hpp"
5  #include "caffe/util/math_functions.hpp"
6  namespace caffe {
7  template <typename Dtype>
8  MKLDNNLRNLayer<Dtype>::MKLDNNLRNLayer(const LayerParameter& param)
9          : MKLDNNLayer<Dtype>(param), Layer<Dtype>(param)
10          , fwd_top_data(NULL), fwd_bottom_data(NULL)
11          , bwd_top_diff(NULL), bwd_bottom_diff(NULL)
12          , lrnFwd_pd(NULL), lrnBwd_pd(NULL)
13  		, fwd_top_data_memory(NULL), bwd_bottom_diff_memory(NULL)
14  		, scratch_memory(NULL)
15  		, fwd_bottom_data_primitive(NULL), bwd_top_diff_primitive(NULL)
16  		, alpha_(0), beta_(0), k_(0)
17  		, size_(0), num_(0), width_(0), height_(0), channels_(0)
18  {
19    PERFORMANCE_EVENT_ID_RESET(perf_id_fw_);
20    PERFORMANCE_EVENT_ID_RESET(perf_id_bw_);
21  }
22  template <typename Dtype>
23  void MKLDNNLRNLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
24                                         const vector<Blob<Dtype>*>& top)
25  {
26      VLOG(1) << "MKLDNNLRNLayer<Dtype>::LayerSetUp: " << this->layer_param_.name();
27      Layer<Dtype>::LayerSetUp(bottom, top);
28      size_ = this->layer_param_.lrn_param().local_size();
29      CHECK_EQ(size_ % 2, 1) << "LRN only supports odd values for local_size";
30  }
31  template <typename Dtype>
32  void MKLDNNLRNLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom
33                                      ,const vector<Blob<Dtype>*>& top)
34  {
35      VLOG(1) << "MKLDNNLRNLayer<Dtype>::Reshape: " << this->layer_param_.name();
<span onclick='openModal()' class='match'>36      alpha_ = this->layer_param_.lrn_param().alpha();
37      beta_ = this->layer_param_.lrn_param().beta();
38      k_ = this->layer_param_.lrn_param().k();
</span>39      this->reshape = (this->width_ == bottom[0]->width() &&
40                       this->height_ == bottom[0]->height() &&
41                       this->channels_ == bottom[0]->channels() &&
42                       this->num_ == bottom[0]->num()) ? false : true;
43      this->width_ = bottom[0]->width();
44      this->height_ = bottom[0]->height();
45      this->num_ = bottom[0]->num();
46      this->channels_ = bottom[0]->channels();
47      CHECK_EQ(4, bottom[0]->num_axes())
48              << "Input must have 4 axes, corresponding to (num, channels, height, width)";
49      switch (this->layer_param_.lrn_param().norm_region()) {
50      case LRNParameter_NormRegion_ACROSS_CHANNELS:
51          top[0]->Reshape(num_, channels_, height_, width_);
52          break;
53      case LRNParameter_NormRegion_WITHIN_CHANNEL:
54          top[0]->Reshape(num_, channels_, height_, width_);
55          break;
56      default:
57          LOG(FATAL) << "Unknown normalization region.";
58      }
59  }
60  template <typename Dtype>
61  void MKLDNNLRNLayer<Dtype>::InitLRNFwd(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top)
62  {
63      if (std::is_same<Dtype, double>::value)  NOT_IMPLEMENTED;
64      auto propagation = this->phase_ == TEST ? prop_kind::forward_scoring : prop_kind::forward_training;
65      algorithm  lrn_algorithm;
66      switch (this->layer_param_.lrn_param().norm_region()) {
67      case LRNParameter_NormRegion_ACROSS_CHANNELS:
68          lrn_algorithm = algorithm::lrn_across_channels;
69          break;
70      case LRNParameter_NormRegion_WITHIN_CHANNEL:
71          if (this->phase_ == TEST)
72              lrn_algorithm = algorithm::lrn_within_channel;
73          else
74              NOT_IMPLEMENTED;
75          break;
76      default:
77          LOG(FATAL) << "Unknown normalization region.";
78      }
79      int32_t n  = this->num_;
80      int32_t iw = this->width_;
81      int32_t ih = this->height_;
82      int32_t ic = this->channels_;
83      bool bottom_data_is_prv = (const_cast<Dtype*>(bottom[0]->prv_data()) != NULL);
84      engine cpu_engine = CpuEngine::Instance().get_engine();
85      memory::data_type mpcsn = memory::data_type::f32;
86      memory::dims tz = {n, ic, ih, iw};
87      memory::format mfmt_nchw = memory::format::nchw;
88      memory::format cmfmt = mfmt_nchw;
89      typedef typename memory::primitive_desc MemPD; 
90      shared_ptr<MemPD> usr_data_memory_pd(new MemPD({{tz}, mpcsn, mfmt_nchw}, cpu_engine));
91      if (bottom_data_is_prv) {
92          shared_ptr<MKLDNNMemoryDescriptor<Dtype, false> > mem_descr
93              = get_mkldnn_prv_descriptor<Dtype, false>(bottom[0]);
94          cmfmt = static_cast<memory::format>(mem_descr->prv_memory_pd()->desc().data.format);
95      }
96      bottom_md.reset(new memory::desc({tz}, mpcsn, cmfmt));
97      lrn_forward::desc lrnFwd_desc(propagation, lrn_algorithm, *bottom_md,
98                          size_, alpha_, beta_);
99      std::string subengines = this->layer_param_.engine();
100      if (subengines.find("MKLDNN") == std::string::npos || subengines == "MKLDNN")
101        subengines = "MKLDNN:CPU";
102      EngineParser ep(subengines);
103      unsigned subEngineIndex = 0;
104      lrnFwd_pd = NULL;
105      for(; subEngineIndex < ep.getNumberOfSubEngines(); subEngineIndex++) {
106        try {
107          lrnFwd_pd.reset(new lrn_forward::primitive_desc(lrnFwd_desc,
108                  ep.getMKLDNNSubEngine(subEngineIndex)));
109        }
110        catch(...) {
111          continue;
112        }
113        break;
114      }
115      CHECK(lrnFwd_pd);
116      shared_ptr<MemPD> prv_fwd_bottom_data_memory_pd(new MemPD(lrnFwd_pd->src_primitive_desc()));
117      shared_ptr<MemPD> prv_fwd_top_data_memory_pd(new MemPD(lrnFwd_pd->dst_primitive_desc()));
118      shared_ptr<MemPD> prv_memory_pd(new MemPD(lrnFwd_pd->dst_primitive_desc()));
119      fwd_bottom_data.reset(new MKLDNNData<Dtype>(usr_data_memory_pd, prv_fwd_bottom_data_memory_pd, bottom[0], this));
120      fwd_bottom_data->name = "fwd_bottom_data   @ " + this->layer_param_.name();
121      fwd_bottom_data_primitive = fwd_bottom_data->create_input(false);
122      fwd_top_data.reset(new MKLDNNData<Dtype>(usr_data_memory_pd, prv_fwd_top_data_memory_pd, top[0], this));
123      fwd_top_data->name = "fwd_top_data   @ " + this->layer_param_.name();
124      fwd_top_data_memory = fwd_top_data->create_output_memory();
125      if ( propagation == prop_kind::forward_training ) {
126          memory::primitive_desc scratch_mpd(lrnFwd_pd->workspace_primitive_desc());
127          scratch_memory.reset(new memory(scratch_mpd));
128          lrnFwd.reset(new lrn_forward(*lrnFwd_pd, *fwd_bottom_data_primitive, *scratch_memory, *fwd_top_data_memory));
129      } else {
130          lrnFwd.reset(new lrn_forward(*lrnFwd_pd, *fwd_bottom_data_primitive, *fwd_top_data_memory));
131      }
132      MKLDNNPrimitive<Dtype> fwd_bottom_data_primitive_transfer(fwd_bottom_data_primitive);
133      fwd_bottom_data->set_mkldnn_primitive(fwd_bottom_data_primitive_transfer);
134      MKLDNNPrimitive<Dtype> fwd_top_data_memory_transfer(fwd_top_data_memory);
135      fwd_top_data->set_mkldnn_primitive(fwd_top_data_memory_transfer);
136  }
137  template <typename Dtype>
138  void MKLDNNLRNLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom
139                                          ,const vector<Blob<Dtype>*>& top)
140  {
141      VLOG(1) << "MKLDNNLRNLayer<Dtype>::Forward_cpu: " << this->layer_param_.name();
142      bool _mkldnn_primitive = false;
143      if( lrnFwd_pd == NULL || this->reshape) {
144          InitLRNFwd(bottom, top);
145          _mkldnn_primitive = true;
146      }
147      fwd_bottom_data->sync_before_read();
148      fwd_top_data->sync_before_write();
149      PERFORMANCE_EVENT_ID_INIT(perf_id_fw_, PERFORMANCE_MKLDNN_NAME("FW"));
150      PERFORMANCE_MEASUREMENT_BEGIN();
151      lrnFwd.submit();
152      if(_mkldnn_primitive) {
153        CircleBuf::Instance()->DecRefCnt(bottom[0]->prv_data());
154      }  
155      PERFORMANCE_MEASUREMENT_END_ID(perf_id_fw_);
156  }
157  template <typename Dtype>
158  void MKLDNNLRNLayer<Dtype>::InitLRNBwd(const vector<Blob<Dtype>*>& top
159                                              ,const vector<bool>& propagate_down
160                                              ,const vector<Blob<Dtype>*>& bottom)
161  {
162      if (std::is_same<Dtype, double>::value)  NOT_IMPLEMENTED;
163      algorithm  lrn_algorithm;
164      switch (this->layer_param_.lrn_param().norm_region()) {
165      case LRNParameter_NormRegion_ACROSS_CHANNELS:
166          lrn_algorithm = algorithm::lrn_across_channels;
167          break;
168      case LRNParameter_NormRegion_WITHIN_CHANNEL:
169          NOT_IMPLEMENTED;
170          break;
171      default:
172          LOG(FATAL) << "Unknown normalization region.";
173      }
174      int32_t n  = this->num_;
175      int32_t iw = this->width_;
176      int32_t ih = this->height_;
177      int32_t ic = this->channels_;
178      bool top_diff_is_prv = (const_cast<Dtype*>(top[0]->prv_diff()) != NULL);
179      engine cpu_engine = CpuEngine::Instance().get_engine();
180      memory::data_type mpcsn = memory::data_type::f32;
181      memory::dims tz = {n, ic, ih, iw};
182      shared_ptr<memory::desc> bottom_diff_md, top_diff_md;
183      shared_ptr<memory::primitive_desc> usr_diff_mpd, prv_diff_mpd;
184      if (top_diff_is_prv) {
185          shared_ptr<MKLDNNMemoryDescriptor<Dtype, true> > mem_descr
186              = get_mkldnn_prv_descriptor<Dtype, true>(top[0]);
187          memory::format bwd_prv_top_diff_mfmt = static_cast<memory::format>(mem_descr->prv_memory_pd()->desc().data.format);
188  #ifdef DEBUG
189          LOG(INFO) << "MKLDNNLRNLayer<Dtype>::InitLRNBwd: memory format of prv top diff is: " << bwd_prv_top_diff_mfmt;
190  #endif        
191          top_diff_md.reset(new memory::desc(mem_descr->prv_memory_pd()->desc()));
192          usr_diff_mpd = mem_descr->usr_memory_pd();
193          prv_diff_mpd = mem_descr->prv_memory_pd();
194          bool bottom_data_is_prv = (const_cast<Dtype*>(bottom[0]->prv_data()) != NULL);
195          if (bottom_data_is_prv) {
196              shared_ptr<MKLDNNMemoryDescriptor<Dtype, false> > mem_descr
197                  = get_mkldnn_prv_descriptor<Dtype, false>(bottom[0]);
198              memory::format fwd_prv_bottom_data_mfmt = static_cast<memory::format>(mem_descr->prv_memory_pd()->desc().data.format);
199  #ifdef DEBUG
200              LOG(INFO) << "MKLDNNLRNLayer<Dtype>::InitLRNBwd: memory format of prv bottom data is: " << fwd_prv_bottom_data_mfmt;
201  #endif
202              if (bwd_prv_top_diff_mfmt != fwd_prv_bottom_data_mfmt)
203              {
204  #ifdef DEBUG
205                  LOG(INFO) << "MKLDNNLRNLayer<Dtype>::InitLRNBwd: Reorder the prv top/bottom diff to the format of prv bottom data! (Performance consideration)";
206  #endif
207                  top_diff_md.reset(new memory::desc({tz}, mpcsn, fwd_prv_bottom_data_mfmt));
208              }
209          }
210      } else {
211          memory::format bwd_cmfmt = memory::format::nchw;
212          bool bottom_data_is_prv = (const_cast<Dtype*>(bottom[0]->prv_data()) != NULL);
213          if (bottom_data_is_prv) {
214              shared_ptr<MKLDNNMemoryDescriptor<Dtype, false> > mem_descr
215                  = get_mkldnn_prv_descriptor<Dtype, false>(bottom[0]);
216              memory::format fwd_prv_bottom_data_mfmt = static_cast<memory::format>(mem_descr->prv_memory_pd()->desc().data.format);
217  #ifdef DEBUG
218              LOG(INFO) << "MKLDNNLRNLayer<Dtype>::InitLRNBwd: memory format of prv bottom data is: " << fwd_prv_bottom_data_mfmt;
219              LOG(INFO) << "MKLDNNLRNLayer<Dtype>::InitLRNBwd: Reorder the usr top/bottom diff to the format of prv bottom data! (Performance consideration)";
220  #endif
221              bwd_cmfmt = fwd_prv_bottom_data_mfmt;
222          }
223          top_diff_md.reset(new memory::desc({tz}, mpcsn, bwd_cmfmt));
224          usr_diff_mpd.reset(new memory::primitive_desc(*top_diff_md, cpu_engine));
225      }
226      bottom_diff_md = top_diff_md;
227      lrn_backward::desc lrnBwd_desc(lrn_algorithm, *bottom_md, *top_diff_md,
228                          size_, alpha_, beta_);
229      std::string subengines = this->layer_param_.engine();
230      if (subengines.find("MKLDNN") == std::string::npos || subengines == "MKLDNN")
231        subengines = "MKLDNN:CPU";
232      EngineParser ep(subengines);
233      unsigned subEngineIndex = 0;
234      lrnBwd_pd = NULL;
235      for(; subEngineIndex < ep.getNumberOfSubEngines(); subEngineIndex++) {
236        try {
237          lrnBwd_pd.reset(new lrn_backward::primitive_desc(lrnBwd_desc,
238              ep.getMKLDNNSubEngine(subEngineIndex), *lrnFwd_pd));
239        }
240        catch(...) {
241          continue;
242        }
243        break;
244      }
245      CHECK(lrnBwd_pd);
246      typedef typename memory::primitive_desc MemPD; 
247      shared_ptr<MemPD> prv_bwd_bottom_diff_memory_pd(new MemPD(lrnBwd_pd->diff_src_primitive_desc()));
248      shared_ptr<MemPD> prv_bwd_top_diff_memory_pd(new MemPD(lrnBwd_pd->diff_dst_primitive_desc()));
249      memory::format mfmt_nchw = memory::format::nchw;
250      shared_ptr<MemPD> usr_data_memory_pd(new MemPD({{tz}, mpcsn, mfmt_nchw}, cpu_engine));
251      bwd_bottom_diff.reset(new MKLDNNDiff<Dtype>(usr_data_memory_pd, prv_bwd_bottom_diff_memory_pd, bottom[0], this));
252      bwd_bottom_diff->name = "bwd_bottom_diff_data   @ " + this->layer_param_.name();
253      bwd_bottom_diff_memory = bwd_bottom_diff->create_output_memory();
254      bwd_top_diff.reset(new MKLDNNDiff<Dtype>(usr_diff_mpd, prv_bwd_top_diff_memory_pd, top[0], this));
255      bwd_top_diff->name = "bwd_top_diff_data   @ " + this->layer_param_.name();
256      bwd_top_diff_primitive = bwd_top_diff->create_input(false);
257      lrnBwd.reset(new lrn_backward(*lrnBwd_pd, *fwd_bottom_data_primitive, *bwd_top_diff_primitive, *scratch_memory, *bwd_bottom_diff_memory));
258      MKLDNNPrimitive<Dtype> bwd_bottom_diff_memory_transfer(bwd_bottom_diff_memory);
259      bwd_bottom_diff->set_mkldnn_primitive(bwd_bottom_diff_memory_transfer);
260      MKLDNNPrimitive<Dtype> bwd_top_diff_primitive_transfer(bwd_top_diff_primitive);
261      bwd_top_diff->set_mkldnn_primitive(bwd_top_diff_primitive_transfer);
262  }
263  template <typename Dtype>
264  void MKLDNNLRNLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top
265                                          ,const vector<bool>& propagate_down
266                                          ,const vector<Blob<Dtype>*>& bottom)
267  {
268      VLOG(1) << "MKLDNNLRNLayer<Dtype>::Backward_cpu: " << this->layer_param_.name();
269      if (!propagate_down[0]) {
270          return;
271      }
272      if( lrnBwd_pd == NULL || this->reshape)
273          InitLRNBwd(top, propagate_down, bottom);
274      bwd_top_diff->sync_before_read();
275      bwd_bottom_diff->sync_before_write();
276      PERFORMANCE_EVENT_ID_INIT(perf_id_bw_, PERFORMANCE_MKLDNN_NAME("BW"));
277      PERFORMANCE_MEASUREMENT_BEGIN();
278      lrnBwd.submit();
279      PERFORMANCE_MEASUREMENT_END_ID(perf_id_bw_);
280  }
281  #ifdef CPU_ONLY
282  STUB_GPU(MKLDNNLRNLayer);
283  #else
284  template <typename Dtype>
285  void MKLDNNLRNLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
286                                          const vector<Blob<Dtype>*>& top)
287  {NOT_IMPLEMENTED;}
288  template <typename Dtype>
289  void MKLDNNLRNLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
290                                          const vector<bool>& propagate_down
291                                          ,const vector<Blob<Dtype>*>& bottom)
292  {NOT_IMPLEMENTED;}
293  #endif
294  INSTANTIATE_CLASS(MKLDNNLRNLayer);
295  }  
296  #endif  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from tesseract-MDEwOlJlcG9zaXRvcnkyMjg4NzA5NA==-flat-validate_khmer_test.cc</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-mkldnn_lrn_layer.cpp</div>
                </div>
                <div class="column column_space"><pre><code>17    std::string str = "\u1796\u17b6\u17b7";
18    EXPECT_FALSE(NormalizeUTF8String(UnicodeNormMode::kNFC, OCRNorm::kNone, GraphemeNorm::kNormalize,
19                                     str.c_str(), &result));
20    str = "\u1798\u17c9\u17ca";
21    EXPECT_FALSE(NormalizeUTF8String(UnicodeNormMode::kNFC, OCRNorm::kNone, GraphemeNorm::kNormalize,
22                                     str.c_str(), &result));
23    str = "\u1780\u17b6\u17cb\u17cd";
24    EXPECT_FALSE(NormalizeUTF8String(UnicodeNormMode::kNFC, OCRNorm::kNone, GraphemeNorm::kNormalize,
25                                     str.c_str(), &result));
</pre></code></div>
                <div class="column column_space"><pre><code>36      alpha_ = this->layer_param_.lrn_param().alpha();
37      beta_ = this->layer_param_.lrn_param().beta();
38      k_ = this->layer_param_.lrn_param().k();
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    