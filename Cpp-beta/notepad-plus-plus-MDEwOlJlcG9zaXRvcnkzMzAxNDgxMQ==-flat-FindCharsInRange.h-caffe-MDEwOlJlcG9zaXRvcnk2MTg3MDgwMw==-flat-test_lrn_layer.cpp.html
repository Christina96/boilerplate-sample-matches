
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 8.469945355191257%, Tokens: 21, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>notepad-plus-plus-MDEwOlJlcG9zaXRvcnkzMzAxNDgxMQ==-flat-FindCharsInRange.h</h3>
            <pre><code>1  #pragma once
2  #include "findCharsInRange_rc.h"
3  #include "ScintillaEditView.h"
4  class FindCharsInRangeDlg : public StaticDialog
5  {
6  public :
7  	FindCharsInRangeDlg() = default;
8  	void init(HINSTANCE hInst, HWND hPere, ScintillaEditView **ppEditView) {
9  		Window::init(hInst, hPere);
10  		if (!ppEditView)
11  			throw std::runtime_error("FindCharsInRangeDlg::init : ppEditView is null.");
12  		_ppEditView = ppEditView;
13  	};
14  	void doDialog(bool isRTL = false) {
15  		if (!isCreated())
16  			create(IDD_FINDCHARACTERS, isRTL);
17  		display();
18  	};
19  	void display(bool toShow = true) const override {
20  		Window::display(toShow);
21  	};
22  protected :
23  	intptr_t CALLBACK run_dlgProc(UINT message, WPARAM wParam, LPARAM lParam) override;
24  private :
25  	ScintillaEditView **_ppEditView = nullptr;
<span onclick='openModal()' class='match'>26  	bool findCharInRange(unsigned char beginRange, unsigned char endRange, intptr_t startPos, bool direction, bool wrap);
27  	bool getRangeFromUI(unsigned char & startRange, unsigned char & endRange);
28  	void getDirectionFromUI(bool & whichDirection, bool & isWrap);
29  };
</span></code></pre>
        </div>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-test_lrn_layer.cpp</h3>
            <pre><code>1  #include <algorithm>
2  #include <vector>
3  #include "gtest/gtest.h"
4  #include "caffe/blob.hpp"
5  #include "caffe/common.hpp"
6  #include "caffe/filler.hpp"
7  #include "caffe/layers/lrn_layer.hpp"
8  #ifdef USE_CUDNN
9  #include "caffe/layers/cudnn_lcn_layer.hpp"
10  #include "caffe/layers/cudnn_lrn_layer.hpp"
11  #endif
12  #include "caffe/test/test_caffe_main.hpp"
13  #include "caffe/test/test_gradient_check_util.hpp"
14  using std::min;
15  using std::max;
16  namespace caffe {
17  template <typename TypeParam>
18  class LRNLayerTest : public MultiDeviceTest<TypeParam> {
19    typedef typename TypeParam::Dtype Dtype;
20   protected:
21    LRNLayerTest()
22        : epsilon_(Dtype(1e-5)),
23          blob_bottom_(new Blob<Dtype>()),
24          blob_top_(new Blob<Dtype>()) {}
25    virtual void SetUp() {
26      Caffe::set_random_seed(1701);
27      blob_bottom_->Reshape(2, 7, 3, 3);
28      FillerParameter filler_param;
29      GaussianFiller<Dtype> filler(filler_param);
30      filler.Fill(this->blob_bottom_);
31      blob_bottom_vec_.push_back(blob_bottom_);
32      blob_top_vec_.push_back(blob_top_);
33    }
34    virtual ~LRNLayerTest() { delete blob_bottom_; delete blob_top_; }
<span onclick='openModal()' class='match'>35    void ReferenceLRNForward(const Blob<Dtype>& blob_bottom,
36        const LayerParameter& layer_param, Blob<Dtype>* blob_top);
37    Dtype epsilon_;
38    Blob<Dtype>* const blob_bottom_;
39    Blob<Dtype>* const blob_top_;
40    vector<Blob<Dtype>*> blob_bottom_vec_;
41    vector<Blob<Dtype>*> blob_top_vec_;
42  };
</span>43  template <typename TypeParam>
44  void LRNLayerTest<TypeParam>::ReferenceLRNForward(
45      const Blob<Dtype>& blob_bottom, const LayerParameter& layer_param,
46      Blob<Dtype>* blob_top) {
47    typedef typename TypeParam::Dtype Dtype;
48    blob_top->Reshape(blob_bottom.num(), blob_bottom.channels(),
49        blob_bottom.height(), blob_bottom.width());
50    Dtype* top_data = blob_top->mutable_cpu_data();
51    LRNParameter lrn_param = layer_param.lrn_param();
52    Dtype alpha = lrn_param.alpha();
53    Dtype beta = lrn_param.beta();
54    int size = lrn_param.local_size();
55    switch (lrn_param.norm_region()) {
56    case LRNParameter_NormRegion_ACROSS_CHANNELS:
57      for (int n = 0; n < blob_bottom.num(); ++n) {
58        for (int c = 0; c < blob_bottom.channels(); ++c) {
59          for (int h = 0; h < blob_bottom.height(); ++h) {
60            for (int w = 0; w < blob_bottom.width(); ++w) {
61              int c_start = c - (size - 1) / 2;
62              int c_end = min(c_start + size, blob_bottom.channels());
63              c_start = max(c_start, 0);
64              Dtype scale = 1.;
65              for (int i = c_start; i < c_end; ++i) {
66                Dtype value = blob_bottom.data_at(n, i, h, w);
67                scale += value * value * alpha / size;
68              }
69              *(top_data + blob_top->offset(n, c, h, w)) =
70                blob_bottom.data_at(n, c, h, w) / pow(scale, beta);
71            }
72          }
73        }
74      }
75      break;
76    case LRNParameter_NormRegion_WITHIN_CHANNEL:
77      for (int n = 0; n < blob_bottom.num(); ++n) {
78        for (int c = 0; c < blob_bottom.channels(); ++c) {
79          for (int h = 0; h < blob_bottom.height(); ++h) {
80            int h_start = h - (size - 1) / 2;
81            int h_end = min(h_start + size, blob_bottom.height());
82            h_start = max(h_start, 0);
83            for (int w = 0; w < blob_bottom.width(); ++w) {
84              Dtype scale = 1.;
85              int w_start = w - (size - 1) / 2;
86              int w_end = min(w_start + size, blob_bottom.width());
87              w_start = max(w_start, 0);
88              for (int nh = h_start; nh < h_end; ++nh) {
89                for (int nw = w_start; nw < w_end; ++nw) {
90                  Dtype value = blob_bottom.data_at(n, c, nh, nw);
91                  scale += value * value * alpha / (size * size);
92                }
93              }
94              *(top_data + blob_top->offset(n, c, h, w)) =
95                blob_bottom.data_at(n, c, h, w) / pow(scale, beta);
96            }
97          }
98        }
99      }
100      break;
101    default:
102      LOG(FATAL) << "Unknown normalization region.";
103    }
104  }
105  TYPED_TEST_CASE(LRNLayerTest, TestDtypesAndDevices);
106  TYPED_TEST(LRNLayerTest, TestSetupAcrossChannels) {
107    typedef typename TypeParam::Dtype Dtype;
108    LayerParameter layer_param;
109    LRNLayer<Dtype> layer(layer_param);
110    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
111    EXPECT_EQ(this->blob_top_->num(), 2);
112    EXPECT_EQ(this->blob_top_->channels(), 7);
113    EXPECT_EQ(this->blob_top_->height(), 3);
114    EXPECT_EQ(this->blob_top_->width(), 3);
115  }
116  TYPED_TEST(LRNLayerTest, TestForwardAcrossChannels) {
117    typedef typename TypeParam::Dtype Dtype;
118    LayerParameter layer_param;
119    LRNLayer<Dtype> layer(layer_param);
120    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
121    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
122    Blob<Dtype> top_reference;
123    this->ReferenceLRNForward(*(this->blob_bottom_), layer_param,
124        &top_reference);
125    for (int i = 0; i < this->blob_bottom_->count(); ++i) {
126      EXPECT_NEAR(this->blob_top_->cpu_data()[i], top_reference.cpu_data()[i],
127                  this->epsilon_);
128    }
129  }
130  TYPED_TEST(LRNLayerTest, TestForwardAcrossChannelsLargeRegion) {
131    typedef typename TypeParam::Dtype Dtype;
132    LayerParameter layer_param;
133    layer_param.mutable_lrn_param()->set_local_size(15);
134    LRNLayer<Dtype> layer(layer_param);
135    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
136    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
137    Blob<Dtype> top_reference;
138    this->ReferenceLRNForward(*(this->blob_bottom_), layer_param,
139        &top_reference);
140    for (int i = 0; i < this->blob_bottom_->count(); ++i) {
141      EXPECT_NEAR(this->blob_top_->cpu_data()[i], top_reference.cpu_data()[i],
142                  this->epsilon_);
143    }
144  }
145  TYPED_TEST(LRNLayerTest, TestGradientAcrossChannels) {
146    typedef typename TypeParam::Dtype Dtype;
147    LayerParameter layer_param;
148    LRNLayer<Dtype> layer(layer_param);
149    GradientChecker<Dtype> checker(1e-2, 1e-2);
150    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
151    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
152    for (int i = 0; i < this->blob_top_->count(); ++i) {
153      this->blob_top_->mutable_cpu_diff()[i] = 1.;
154    }
155    vector<bool> propagate_down(this->blob_bottom_vec_.size(), true);
156    layer.Backward(this->blob_top_vec_, propagate_down,
157                   this->blob_bottom_vec_);
158    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
159        this->blob_top_vec_);
160  }
161  TYPED_TEST(LRNLayerTest, TestGradientAcrossChannelsLargeRegion) {
162    typedef typename TypeParam::Dtype Dtype;
163    LayerParameter layer_param;
164    layer_param.mutable_lrn_param()->set_local_size(15);
165    LRNLayer<Dtype> layer(layer_param);
166    GradientChecker<Dtype> checker(1e-2, 1e-2);
167    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
168    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
169    for (int i = 0; i < this->blob_top_->count(); ++i) {
170      this->blob_top_->mutable_cpu_diff()[i] = 1.;
171    }
172    vector<bool> propagate_down(this->blob_bottom_vec_.size(), true);
173    layer.Backward(this->blob_top_vec_, propagate_down,
174                   this->blob_bottom_vec_);
175    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
176        this->blob_top_vec_);
177  }
178  TYPED_TEST(LRNLayerTest, TestSetupWithinChannel) {
179    typedef typename TypeParam::Dtype Dtype;
180    LayerParameter layer_param;
181    layer_param.mutable_lrn_param()->set_norm_region(
182        LRNParameter_NormRegion_WITHIN_CHANNEL);
183    layer_param.mutable_lrn_param()->set_local_size(3);
184    LRNLayer<Dtype> layer(layer_param);
185    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
186    EXPECT_EQ(this->blob_top_->num(), 2);
187    EXPECT_EQ(this->blob_top_->channels(), 7);
188    EXPECT_EQ(this->blob_top_->height(), 3);
189    EXPECT_EQ(this->blob_top_->width(), 3);
190  }
191  TYPED_TEST(LRNLayerTest, TestForwardWithinChannel) {
192    typedef typename TypeParam::Dtype Dtype;
193    LayerParameter layer_param;
194    layer_param.mutable_lrn_param()->set_norm_region(
195        LRNParameter_NormRegion_WITHIN_CHANNEL);
196    layer_param.mutable_lrn_param()->set_local_size(3);
197    LRNLayer<Dtype> layer(layer_param);
198    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
199    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
200    Blob<Dtype> top_reference;
201    this->ReferenceLRNForward(*(this->blob_bottom_), layer_param,
202        &top_reference);
203    for (int i = 0; i < this->blob_bottom_->count(); ++i) {
204      EXPECT_NEAR(this->blob_top_->cpu_data()[i], top_reference.cpu_data()[i],
205                  this->epsilon_);
206    }
207  }
208  TYPED_TEST(LRNLayerTest, TestGradientWithinChannel) {
209    typedef typename TypeParam::Dtype Dtype;
210    LayerParameter layer_param;
211    layer_param.mutable_lrn_param()->set_norm_region(
212        LRNParameter_NormRegion_WITHIN_CHANNEL);
213    layer_param.mutable_lrn_param()->set_local_size(3);
214    LRNLayer<Dtype> layer(layer_param);
215    GradientChecker<Dtype> checker(1e-2, 1e-2);
216    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
217    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
218    for (int i = 0; i < this->blob_top_->count(); ++i) {
219      this->blob_top_->mutable_cpu_diff()[i] = 1.;
220    }
221    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
222        this->blob_top_vec_);
223  }
224  #ifdef USE_CUDNN
225  template <typename Dtype>
226  class CuDNNLRNLayerTest : public GPUDeviceTest<Dtype> {
227   protected:
228    CuDNNLRNLayerTest()
229        : epsilon_(Dtype(1e-5)),
230          blob_bottom_(new Blob<Dtype>()),
231          blob_top_(new Blob<Dtype>()) {}
232    virtual void SetUp() {
233      Caffe::set_random_seed(1701);
234      blob_bottom_->Reshape(2, 7, 3, 3);
235      FillerParameter filler_param;
236      GaussianFiller<Dtype> filler(filler_param);
237      filler.Fill(this->blob_bottom_);
238      blob_bottom_vec_.push_back(blob_bottom_);
239      blob_top_vec_.push_back(blob_top_);
240    }
241    virtual ~CuDNNLRNLayerTest() { delete blob_bottom_; delete blob_top_; }
242    void ReferenceLRNForward(const Blob<Dtype>& blob_bottom,
243        const LayerParameter& layer_param, Blob<Dtype>* blob_top);
244    Dtype epsilon_;
245    Blob<Dtype>* const blob_bottom_;
246    Blob<Dtype>* const blob_top_;
247    vector<Blob<Dtype>*> blob_bottom_vec_;
248    vector<Blob<Dtype>*> blob_top_vec_;
249  };
250  template <typename TypeParam>
251  void CuDNNLRNLayerTest<TypeParam>::ReferenceLRNForward(
252      const Blob<TypeParam>& blob_bottom, const LayerParameter& layer_param,
253      Blob<TypeParam>* blob_top) {
254    typedef TypeParam Dtype;
255    blob_top->Reshape(blob_bottom.num(), blob_bottom.channels(),
256        blob_bottom.height(), blob_bottom.width());
257    Dtype* top_data = blob_top->mutable_cpu_data();
258    LRNParameter lrn_param = layer_param.lrn_param();
259    Dtype alpha = lrn_param.alpha();
260    Dtype beta = lrn_param.beta();
261    int size = lrn_param.local_size();
262    switch (lrn_param.norm_region()) {
263    case LRNParameter_NormRegion_ACROSS_CHANNELS:
264      for (int n = 0; n < blob_bottom.num(); ++n) {
265        for (int c = 0; c < blob_bottom.channels(); ++c) {
266          for (int h = 0; h < blob_bottom.height(); ++h) {
267            for (int w = 0; w < blob_bottom.width(); ++w) {
268              int c_start = c - (size - 1) / 2;
269              int c_end = min(c_start + size, blob_bottom.channels());
270              c_start = max(c_start, 0);
271              Dtype scale = 1.;
272              for (int i = c_start; i < c_end; ++i) {
273                Dtype value = blob_bottom.data_at(n, i, h, w);
274                scale += value * value * alpha / size;
275              }
276              *(top_data + blob_top->offset(n, c, h, w)) =
277                blob_bottom.data_at(n, c, h, w) / pow(scale, beta);
278            }
279          }
280        }
281      }
282      break;
283    case LRNParameter_NormRegion_WITHIN_CHANNEL:
284      for (int n = 0; n < blob_bottom.num(); ++n) {
285        for (int c = 0; c < blob_bottom.channels(); ++c) {
286          for (int h = 0; h < blob_bottom.height(); ++h) {
287            int h_start = h - (size - 1) / 2;
288            int h_end = min(h_start + size, blob_bottom.height());
289            h_start = max(h_start, 0);
290            for (int w = 0; w < blob_bottom.width(); ++w) {
291              Dtype scale = 1.;
292              int w_start = w - (size - 1) / 2;
293              int w_end = min(w_start + size, blob_bottom.width());
294              w_start = max(w_start, 0);
295              for (int nh = h_start; nh < h_end; ++nh) {
296                for (int nw = w_start; nw < w_end; ++nw) {
297                  Dtype value = blob_bottom.data_at(n, c, nh, nw);
298                  scale += value * value * alpha / (size * size);
299                }
300              }
301              *(top_data + blob_top->offset(n, c, h, w)) =
302                blob_bottom.data_at(n, c, h, w) / pow(scale, beta);
303            }
304          }
305        }
306      }
307      break;
308    default:
309      LOG(FATAL) << "Unknown normalization region.";
310    }
311  }
312  TYPED_TEST_CASE(CuDNNLRNLayerTest, TestDtypes);
313  TYPED_TEST(CuDNNLRNLayerTest, TestForwardAcrossChannelsCuDNN) {
314    LayerParameter layer_param;
315    CuDNNLRNLayer<TypeParam> layer(layer_param);
316    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
317    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
318    Blob<TypeParam> top_reference;
319    this->ReferenceLRNForward(*(this->blob_bottom_), layer_param,
320        &top_reference);
321    for (int i = 0; i < this->blob_bottom_->count(); ++i) {
322      EXPECT_NEAR(this->blob_top_->cpu_data()[i], top_reference.cpu_data()[i],
323                  this->epsilon_);
324    }
325  }
326  TYPED_TEST(CuDNNLRNLayerTest, TestForwardAcrossChannelsLargeRegionCuDNN) {
327    typedef TypeParam Dtype;
328    LayerParameter layer_param;
329    layer_param.mutable_lrn_param()->set_local_size(15);
330    CuDNNLRNLayer<Dtype> layer(layer_param);
331    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
332    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
333    Blob<Dtype> top_reference;
334    this->ReferenceLRNForward(*(this->blob_bottom_), layer_param,
335        &top_reference);
336    for (int i = 0; i < this->blob_bottom_->count(); ++i) {
337      EXPECT_NEAR(this->blob_top_->cpu_data()[i], top_reference.cpu_data()[i],
338                  this->epsilon_);
339    }
340  }
341  TYPED_TEST(CuDNNLRNLayerTest, TestGradientAcrossChannelsCuDNN) {
342    typedef TypeParam Dtype;
343    LayerParameter layer_param;
344    CuDNNLRNLayer<Dtype> layer(layer_param);
345    GradientChecker<Dtype> checker(1e-2, 1e-2);
346    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
347    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
348    for (int i = 0; i < this->blob_top_->count(); ++i) {
349      this->blob_top_->mutable_cpu_diff()[i] = 1.;
350    }
351    vector<bool> propagate_down(this->blob_bottom_vec_.size(), true);
352    layer.Backward(this->blob_top_vec_, propagate_down,
353                   this->blob_bottom_vec_);
354    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
355        this->blob_top_vec_);
356  }
357  TYPED_TEST(CuDNNLRNLayerTest, TestForwardWithinChannel) {
358    typedef TypeParam Dtype;
359    LayerParameter layer_param;
360    layer_param.mutable_lrn_param()->set_norm_region(
361        LRNParameter_NormRegion_WITHIN_CHANNEL);
362    layer_param.mutable_lrn_param()->set_local_size(3);
363    CuDNNLCNLayer<Dtype> layer(layer_param);
364    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
365    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
366    Blob<Dtype> top_reference;
367    this->ReferenceLRNForward(*(this->blob_bottom_), layer_param,
368        &top_reference);
369    for (int i = 0; i < this->blob_bottom_->count(); ++i) {
370      EXPECT_NEAR(this->blob_top_->cpu_data()[i], top_reference.cpu_data()[i],
371                  this->epsilon_);
372    }
373  }
374  TYPED_TEST(CuDNNLRNLayerTest, TestGradientWithinChannel) {
375    typedef TypeParam Dtype;
376    LayerParameter layer_param;
377    layer_param.mutable_lrn_param()->set_norm_region(
378        LRNParameter_NormRegion_WITHIN_CHANNEL);
379    layer_param.mutable_lrn_param()->set_local_size(3);
380    CuDNNLCNLayer<Dtype> layer(layer_param);
381    GradientChecker<Dtype> checker(1e-2, 1e-2);
382    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
383    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
384    for (int i = 0; i < this->blob_top_->count(); ++i) {
385      this->blob_top_->mutable_cpu_diff()[i] = 1.;
386    }
387    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
388        this->blob_top_vec_);
389  }
390  TYPED_TEST(CuDNNLRNLayerTest, TestGradientAcrossChannelsLargeRegionCuDNN) {
391    typedef TypeParam Dtype;
392    LayerParameter layer_param;
393    layer_param.mutable_lrn_param()->set_local_size(15);
394    CuDNNLRNLayer<Dtype> layer(layer_param);
395    GradientChecker<Dtype> checker(1e-2, 1e-2);
396    layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
397    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
398    for (int i = 0; i < this->blob_top_->count(); ++i) {
399      this->blob_top_->mutable_cpu_diff()[i] = 1.;
400    }
401    vector<bool> propagate_down(this->blob_bottom_vec_.size(), true);
402    layer.Backward(this->blob_top_vec_, propagate_down,
403                   this->blob_bottom_vec_);
404    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
405        this->blob_top_vec_);
406  }
407  #endif
408  }  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from notepad-plus-plus-MDEwOlJlcG9zaXRvcnkzMzAxNDgxMQ==-flat-FindCharsInRange.h</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-test_lrn_layer.cpp</div>
                </div>
                <div class="column column_space"><pre><code>26  	bool findCharInRange(unsigned char beginRange, unsigned char endRange, intptr_t startPos, bool direction, bool wrap);
27  	bool getRangeFromUI(unsigned char & startRange, unsigned char & endRange);
28  	void getDirectionFromUI(bool & whichDirection, bool & isWrap);
29  };
</pre></code></div>
                <div class="column column_space"><pre><code>35    void ReferenceLRNForward(const Blob<Dtype>& blob_bottom,
36        const LayerParameter& layer_param, Blob<Dtype>* blob_top);
37    Dtype epsilon_;
38    Blob<Dtype>* const blob_bottom_;
39    Blob<Dtype>* const blob_top_;
40    vector<Blob<Dtype>*> blob_bottom_vec_;
41    vector<Blob<Dtype>*> blob_top_vec_;
42  };
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    