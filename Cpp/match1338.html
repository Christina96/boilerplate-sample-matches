<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for sigmoid_layer.hpp & reduction_layer.hpp</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for sigmoid_layer.hpp & reduction_layer.hpp
      </h3>
      <h1 align="center">
        45.5%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>sigmoid_layer.hpp (60.526318%)<TH>reduction_layer.hpp (36.50794%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match1338-0.html#0',2,'match1338-1.html#0',3)" NAME="0">(28-66)<TD><A HREF="javascript:ZweiFrames('match1338-0.html#0',2,'match1338-1.html#0',3)" NAME="0">(31-41)</A><TD ALIGN=center><FONT COLOR="#ff0000">23</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>sigmoid_layer.hpp</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
#ifndef CAFFE_SIGMOID_LAYER_HPP_
#define CAFFE_SIGMOID_LAYER_HPP_

#include &lt;vector&gt;

#include &quot;caffe/blob.hpp&quot;
#include &quot;caffe/layer.hpp&quot;
#include &quot;caffe/proto/caffe.pb.h&quot;

#include &quot;caffe/layers/neuron_layer.hpp&quot;

namespace caffe {

/**
 * @brief Sigmoid function non-linearity @f$
 *         y = (1 + \exp(-x))^{-1}
 *     @f$, a classic choice in neural networks.
 *
 * Note that the gradient vanishes as the values move away from 0.
 * The ReLULayer is often a better choice for this reason.
 */
template &lt;typename Dtype&gt;
class SigmoidLayer : public NeuronLayer&lt;Dtype&gt; {
 public:
<A NAME="0"></A>  explicit SigmoidLayer(const LayerParameter&amp; param)
      : NeuronLayer&lt;Dtype&gt;(param) {}

<FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match1338-1.html#0',3,'match1338-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>  virtual inline const char* type() const { return &quot;Sigmoid&quot;; }

 protected:
  /**
   * @param bottom input Blob vector (length 1)
   *   -# @f$ (N \times C \times H \times W) @f$
   *      the inputs @f$ x @f$
   * @param top output Blob vector (length 1)
   *   -# @f$ (N \times C \times H \times W) @f$
   *      the computed outputs @f$
   *        y = (1 + \exp(-x))^{-1}
   *      @f$
   */
  virtual void Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  virtual void Forward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);

  /**
   * @brief Computes the error gradient w.r.t. the sigmoid inputs.
   *
   * @param top output Blob vector (length 1), providing the error gradient with
   *      respect to the outputs
   *   -# @f$ (N \times C \times H \times W) @f$
   *      containing error gradients @f$ \frac{\partial E}{\partial y} @f$
   *      with respect to computed outputs @f$ y @f$
   * @param propagate_down see Layer::Backward.
   * @param bottom input Blob vector (length 1)
   *   -# @f$ (N \times C \times H \times W) @f$
   *      the inputs @f$ x @f$; Backward fills their diff with
   *      gradients @f$
   *        \frac{\partial E}{\partial x}
   *            = \frac{\partial E}{\partial y} y (1 - y)
   *      @f$ if propagate_down[0]
   */
  virtual void Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);
  virtual void Backward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</B></FONT>
};

}  // namespace caffe

#endif  // CAFFE_SIGMOID_LAYER_HPP_
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>reduction_layer.hpp</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
#ifndef CAFFE_REDUCTION_LAYER_HPP_
#define CAFFE_REDUCTION_LAYER_HPP_

#include &lt;vector&gt;

#include &quot;caffe/blob.hpp&quot;
#include &quot;caffe/layer.hpp&quot;
#include &quot;caffe/proto/caffe.pb.h&quot;

namespace caffe {

/**
 * @brief Compute &quot;reductions&quot; -- operations that return a scalar output Blob
 *        for an input Blob of arbitrary size, such as the sum, absolute sum,
 *        and sum of squares.
 *
 * TODO(dox): thorough documentation for Forward, Backward, and proto params.
 */
template &lt;typename Dtype&gt;
class ReductionLayer : public Layer&lt;Dtype&gt; {
 public:
  explicit ReductionLayer(const LayerParameter&amp; param)
      : Layer&lt;Dtype&gt;(param) {}
  virtual void LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  virtual void Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
<A NAME="0"></A>
  virtual inline const char* type() const { return &quot;Reduction&quot;; }
  virtual inline int ExactNumBottomBlobs() const { return 1; }
<FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match1338-0.html#0',2,'match1338-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>  virtual inline int ExactNumTopBlobs() const { return 1; }

 protected:
  virtual void Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  virtual void Forward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);
  virtual void Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);
  virtual void Backward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</B></FONT>

  /// @brief the reduction operation performed by the layer
  ReductionParameter_ReductionOp op_;
  /// @brief a scalar coefficient applied to all outputs
  Dtype coeff_;
  /// @brief the index of the first input axis to reduce
  int axis_;
  /// @brief the number of reductions performed
  int num_;
  /// @brief the input size of each reduction
  int dim_;
  /// @brief a helper Blob used for summation (op_ == SUM)
  Blob&lt;Dtype&gt; sum_multiplier_;
};

}  // namespace caffe

#endif  // CAFFE_REDUCTION_LAYER_HPP_
</PRE>
</div>
  </div>
</body>
</html>
