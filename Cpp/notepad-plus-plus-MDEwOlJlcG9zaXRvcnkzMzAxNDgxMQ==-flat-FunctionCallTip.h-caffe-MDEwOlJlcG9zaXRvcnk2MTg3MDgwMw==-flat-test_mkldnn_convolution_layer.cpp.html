
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 1.9267822736030826%, Tokens: 10</h2>
        <div class="column">
            <h3>notepad-plus-plus-MDEwOlJlcG9zaXRvcnkzMzAxNDgxMQ==-flat-FunctionCallTip.h</h3>
            <pre><code>1  #pragma once
2  #include "ScintillaEditView.h"
3  typedef std::vector<const TCHAR *> stringVec;
4  class FunctionCallTip {
5  	 friend class AutoCompletion;
6  public:
7  	explicit FunctionCallTip(ScintillaEditView * pEditView) : _pEditView(pEditView) {};
8  	~FunctionCallTip() {&bsol;* cleanup(); */};
9  	void setLanguageXML(TiXmlElement * pXmlKeyword);	
10  	bool updateCalltip(int ch, bool needShown = false);	
11  	void showNextOverload();							
12  	void showPrevOverload();							
13  	bool isVisible() { return _pEditView?_pEditView->execute(SCI_CALLTIPACTIVE) == TRUE:false; };	
14  	void close();					
15  private:
<span onclick='openModal()' class='match'>16  	ScintillaEditView * _pEditView = nullptr;	
17  	TiXmlElement * _pXmlKeyword = nullptr;	
18  	intptr_t _curPos = 0;					
19  	intptr_t _startPos = 0;					
20  	TiXmlElement * _curFunction = nullptr;	
21  	TCHAR * _funcName = nullptr;				
22  	stringVec _retVals;				
23  	std::vector<stringVec> _overloads;	
24  	stringVec _descriptions;		
25  	size_t _currentNbOverloads = 0;		
26  	size_t _currentOverload = 0;			
27  	size_t _currentParam = 0;				
28  	TCHAR _start = '(';
</span>29  	TCHAR _stop = ')';
30  	TCHAR _param = ',';
31  	TCHAR _terminal = ';';
32      generic_string _additionalWordChar = TEXT("");
33  	bool _ignoreCase = true;
34  	bool _selfActivated = false;
35  	bool getCursorFunction();		
36  	bool loadFunction();			
37  	void showCalltip();				
38  	void reset();					
39  	void cleanup();					
40      bool isBasicWordChar(TCHAR ch) const {
41          return ((ch >= 'A' && ch <= 'Z') || (ch >= 'a' && ch <= 'z') || (ch >= '0' && ch <= '9') || ch == '_');
42      };
43      bool isAdditionalWordChar(TCHAR ch) const {
44          const TCHAR *addChars = _additionalWordChar.c_str();
45          size_t len = _additionalWordChar.length();
46          for (size_t i = 0 ; i < len ; ++i)
47              if (ch == addChars[i])
48                  return true;
49          return false;
50      };
51  };
</code></pre>
        </div>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-test_mkldnn_convolution_layer.cpp</h3>
            <pre><code>1  #ifdef MKLDNN_SUPPORTED
2  #include <vector>
3  #include "gtest/gtest.h"
4  #include "caffe/blob.hpp"
5  #include "caffe/common.hpp"
6  #include "caffe/filler.hpp"
7  #include "caffe/layers/mkldnn_layers.hpp"
8  #include "caffe/test/test_caffe_main.hpp"
9  #include "caffe/test/test_gradient_check_util.hpp"
10  namespace caffe {
11  template <typename Dtype>
12  void caffe_conv(const Blob<Dtype>* in, ConvolutionParameter* conv_param,
13      const vector<shared_ptr<Blob<Dtype> > >& weights,
14      Blob<Dtype>* out) {
15    const bool has_depth = (out->num_axes() == 5);
16    if (!has_depth) { CHECK_EQ(4, out->num_axes()); }
17    int kernel_h, kernel_w;
18    if (conv_param->has_kernel_h() || conv_param->has_kernel_w()) {
19      kernel_h = conv_param->kernel_h();
20      kernel_w = conv_param->kernel_w();
21    } else {
22      kernel_h = kernel_w = conv_param->kernel_size(0);
23    }
24    int pad_h, pad_w;
25    if (conv_param->has_pad_h() || conv_param->has_pad_w()) {
26      pad_h = conv_param->pad_h();
27      pad_w = conv_param->pad_w();
28    } else {
29      pad_h = pad_w = conv_param->pad_size() ? conv_param->pad(0) : 0;
30    }
31    int stride_h, stride_w;
32    if (conv_param->has_stride_h() || conv_param->has_stride_w()) {
33      stride_h = conv_param->stride_h();
34      stride_w = conv_param->stride_w();
35    } else {
36      stride_h = stride_w = conv_param->stride_size() ? conv_param->stride(0) : 1;
37    }
38    int dilation_h, dilation_w;
39    dilation_h = dilation_w = conv_param->dilation_size() ?
40                              conv_param->dilation(0) : 1;
41    int kernel_d, pad_d, stride_d, dilation_d;
42    if (has_depth) {
43      kernel_d = kernel_h;
44      stride_d = stride_h;
45      pad_d = pad_h;
46      dilation_d = dilation_h;
47    } else {
48      kernel_d = stride_d = dilation_d = 1;
49      pad_d = 0;
50    }
51    int groups = conv_param->group();
52    int o_g = out->shape(1) / groups;
53    int k_g = in->shape(1) / groups;
54    int o_head, k_head;
55    vector<int> weight_offset(4 + has_depth);
56    vector<int> in_offset(4 + has_depth);
57    vector<int> out_offset(4 + has_depth);
58    Dtype* out_data = out->mutable_cpu_data();
59    for (int n = 0; n < out->shape(0); n++) {
60      for (int g = 0; g < groups; g++) {
61        o_head = o_g * g;
62        k_head = k_g * g;
63        for (int o = 0; o < o_g; o++) {
64          for (int k = 0; k < k_g; k++) {
65            for (int z = 0; z < (has_depth ? out->shape(2) : 1); z++) {
66              for (int y = 0; y < out->shape(2 + has_depth); y++) {
67                for (int x = 0; x < out->shape(3 + has_depth); x++) {
68                  for (int r = 0; r < kernel_d; r++) {
69                    for (int p = 0; p < kernel_h; p++) {
70                      for (int q = 0; q < kernel_w; q++) {
71                        int in_z = z * stride_d - pad_d + r * dilation_d;
72                        int in_y = y * stride_h - pad_h + p * dilation_h;
73                        int in_x = x * stride_w - pad_w + q * dilation_w;
74                        if (in_z >= 0 && in_z < (has_depth ? in->shape(2) : 1)
75                            && in_y >= 0 && in_y < in->shape(2 + has_depth)
76                            && in_x >= 0 && in_x < in->shape(3 + has_depth)) {
77                          weight_offset[0] = o + o_head;
78                          weight_offset[1] = k;
79                          if (has_depth) { weight_offset[2] = r; }
80                          weight_offset[2 + has_depth] = p;
81                          weight_offset[3 + has_depth] = q;
82                          in_offset[0] = n;
83                          in_offset[1] = k + k_head;
84                          if (has_depth) { in_offset[2] = in_z; }
85                          in_offset[2 + has_depth] = in_y;
86                          in_offset[3 + has_depth] = in_x;
87                          out_offset[0] = n;
88                          out_offset[1] = o + o_head;
89                          if (has_depth) { out_offset[2] = z; }
90                          out_offset[2 + has_depth] = y;
91                          out_offset[3 + has_depth] = x;
92                          out_data[out->offset(out_offset)] +=
93                              in->data_at(in_offset)
94                              * weights[0]->data_at(weight_offset);
95                        }
96                      }
97                    }
98                  }
99                }
100              }
101            }
102          }
103        }
104      }
105    }
106    if (conv_param->bias_term()) {
107      const Dtype* bias_data = weights[1]->cpu_data();
108      for (int n = 0; n < out->shape(0); n++) {
109        for (int o = 0; o < out->shape(1); o++) {
110          for (int z = 0; z < (has_depth ? out->shape(2) : 1); z++) {
111            for (int y = 0; y < out->shape(2 + has_depth); y++) {
112              for (int x = 0; x < out->shape(3 + has_depth); x++) {
113                out_offset[0] = n;
114                out_offset[1] = o;
115                if (has_depth) { out_offset[2] = z; }
116                out_offset[2 + has_depth] = y;
117                out_offset[3 + has_depth] = x;
118                out_data[out->offset(out_offset)] += bias_data[o];
119              }
120            }
121          }
122        }
123      }
124    }
125    if (conv_param->relu()){
126      for (int n = 0; n < out->shape(0); n++) {
127        for (int o = 0; o < out->shape(1); o++) {
128          for (int z = 0; z < (has_depth ? out->shape(2) : 1); z++) {
129            for (int y = 0; y < out->shape(2 + has_depth); y++) {
130              for (int x = 0; x < out->shape(3 + has_depth); x++) {
131                out_offset[0] = n;
132                out_offset[1] = o;
133                if (has_depth) { out_offset[2] = z; }
134                out_offset[2 + has_depth] = y;
135                out_offset[3 + has_depth] = x;
136                if(out_data[out->offset(out_offset)] < 0) out_data[out->offset(out_offset)] = 0;
137              }
138            }
139          }
140        }
141      }
142    }
143  }
144  template void caffe_conv(const Blob<float>* in,
145      ConvolutionParameter* conv_param,
146      const vector<shared_ptr<Blob<float> > >& weights,
147      Blob<float>* out);
148  template void caffe_conv(const Blob<double>* in,
149      ConvolutionParameter* conv_param,
150      const vector<shared_ptr<Blob<double> > >& weights,
151      Blob<double>* out);
152  template <typename TypeParam>
153  class MKLDNNConvolutionLayerTest : public MultiDeviceTest<TypeParam> {
154    typedef typename TypeParam::Dtype Dtype;
155  #define MB 2
156  #define IC 8
157  #define OC 8
158  #define IH 5
159  #define IW 5
160  #define OH 5
161  #define OW 5
162  #define KH 3
163  #define KW 3
164  #define CS 1
165  #define GR 2
166  #define PD 1
167   protected:
168    MKLDNNConvolutionLayerTest()
169        : blob_bottom_(new Blob<Dtype>(MB, IC, IH, IW)),
170          blob_bottom_2_(new Blob<Dtype>(MB, IC, IH, IW)),
171          blob_top_(new Blob<Dtype>()),
172          blob_top_2_(new Blob<Dtype>()) {}
173    virtual void SetUp() {
174      FillerParameter filler_param;
175      filler_param.set_value(1.);
176      GaussianFiller<Dtype> filler(filler_param);
177      filler.Fill(this->blob_bottom_);
178      filler.Fill(this->blob_bottom_2_);
179      blob_bottom_vec_.push_back(blob_bottom_);
180      blob_top_vec_.push_back(blob_top_);
181    }
182    virtual ~MKLDNNConvolutionLayerTest() {
183      delete blob_bottom_;
184      delete blob_bottom_2_;
185      delete blob_top_;
186      delete blob_top_2_;
187    }
188    virtual Blob<Dtype>* MakeReferenceTop(Blob<Dtype>* top) {
189      this->ref_blob_top_.reset(new Blob<Dtype>());
190      this->ref_blob_top_->ReshapeLike(*top);
191      return this->ref_blob_top_.get();
192    }
193    Blob<Dtype>* const blob_bottom_;
194    Blob<Dtype>* const blob_bottom_2_;
195    Blob<Dtype>* const blob_top_;
196    Blob<Dtype>* const blob_top_2_;
197    shared_ptr<Blob<Dtype> > ref_blob_top_;
198    vector<Blob<Dtype>*> blob_bottom_vec_;
199    vector<Blob<Dtype>*> blob_top_vec_;
200  };
201  typedef ::testing::Types<CPUDevice<float>
202                          > TestDtypesCPU;
203  TYPED_TEST_CASE(MKLDNNConvolutionLayerTest, TestDtypesCPU);
204  TYPED_TEST(MKLDNNConvolutionLayerTest, TestSetupMKLDNN) {
205    typedef typename TypeParam::Dtype Dtype;
206    LayerParameter layer_param;
207    ConvolutionParameter* convolution_param =
208        layer_param.mutable_convolution_param();
209    convolution_param->add_kernel_size(KH);
210    convolution_param->add_stride(CS);
211    convolution_param->set_num_output(OC);
212    convolution_param->add_pad(PD);
213    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
214    this->blob_top_vec_.push_back(this->blob_top_2_);
215    shared_ptr<Layer<Dtype> > layer(
216        new MKLDNNConvolutionLayer<Dtype>(layer_param));
217    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
218    EXPECT_EQ(this->blob_top_->num(), MB);
219    EXPECT_EQ(this->blob_top_->channels(), OC);
220    EXPECT_EQ(this->blob_top_->height(), OH);
221    EXPECT_EQ(this->blob_top_->width(), OW);
222    EXPECT_EQ(this->blob_top_2_->num(), MB);
223    EXPECT_EQ(this->blob_top_2_->channels(), OC );
224    EXPECT_EQ(this->blob_top_2_->height(), OH);
225    EXPECT_EQ(this->blob_top_2_->width(), OW);
226    convolution_param->set_num_output(OC);
227    convolution_param->set_group(GR);
228    layer.reset(new MKLDNNConvolutionLayer<Dtype>(layer_param));
229    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
230    EXPECT_EQ(this->blob_top_->num(), MB);
231    EXPECT_EQ(this->blob_top_->channels(), OC);
232    EXPECT_EQ(this->blob_top_->height(), OH);
233    EXPECT_EQ(this->blob_top_->width(), OW);
234    EXPECT_EQ(this->blob_top_2_->num(), MB);
235    EXPECT_EQ(this->blob_top_2_->channels(), OC);
236    EXPECT_EQ(this->blob_top_2_->height(), OH);
237    EXPECT_EQ(this->blob_top_2_->width(), OW);
238  }
239  #if 0
240  TYPED_TEST(MKLDNNConvolutionLayerTest, TestSetupMKLDNNWithRectangeKernelStridePad) {
241    typedef typename TypeParam::Dtype Dtype;
242    LayerParameter layer_param;
243    ConvolutionParameter* convolution_param =
244        layer_param.mutable_convolution_param();
245    convolution_param->set_kernel_h(4);
246    convolution_param->set_kernel_w(1);
247    convolution_param->set_stride_h(3);
248    convolution_param->set_stride_w(1);
249    convolution_param->set_num_output(OC);
250    convolution_param->set_pad_h(2);
251    convolution_param->set_pad_w(1);
252    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
253    this->blob_top_vec_.push_back(this->blob_top_2_);
254    shared_ptr<MKLDNNConvolutionLayer<Dtype> > layer(
255        new MKLDNNConvolutionLayer<Dtype>(layer_param));
256    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
257    EXPECT_EQ(convolution_param->kernel_h(), 4);
258    EXPECT_EQ(layer->GetKernelHeight(), 4);
259    EXPECT_EQ(convolution_param->kernel_w(), 1);
260    EXPECT_EQ(layer->GetKernelWidth(), 1);
261    EXPECT_EQ(convolution_param->stride_h(), 3);
262    EXPECT_EQ(layer->GetStrideHeight(), 3);
263    EXPECT_EQ(convolution_param->stride_w(), 1);
264    EXPECT_EQ(layer->GetStrideWidth(), 1);
265    EXPECT_EQ(convolution_param->pad_h(), 2);
266    EXPECT_EQ(layer->GetPadHeight(), 2);
267    EXPECT_EQ(convolution_param->pad_w(), 1);
268    EXPECT_EQ(layer->GetPadWidth(), 1);
269    convolution_param->set_num_output(OC);
270    convolution_param->set_group(GR);
271    layer.reset(new MKLDNNConvolutionLayer<Dtype>(layer_param));
272    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
273    EXPECT_EQ(convolution_param->kernel_h(), 4);
274    EXPECT_EQ(layer->GetKernelHeight(), 4);
275    EXPECT_EQ(convolution_param->kernel_w(), 1);
276    EXPECT_EQ(layer->GetKernelWidth(), 1);
277    EXPECT_EQ(convolution_param->stride_h(), 3);
278    EXPECT_EQ(layer->GetStrideHeight(), 3);
279    EXPECT_EQ(convolution_param->stride_w(), 1);
280    EXPECT_EQ(layer->GetStrideWidth(), 1);
281    EXPECT_EQ(convolution_param->pad_h(), 2);
282    EXPECT_EQ(layer->GetPadHeight(), 2);
283    EXPECT_EQ(convolution_param->pad_w(), 1);
284    EXPECT_EQ(layer->GetPadWidth(), 1);
285  }
286  TYPED_TEST(MKLDNNConvolutionLayerTest, TestSimpleConvolutionMKLDNN) {
287    typedef typename TypeParam::Dtype Dtype;
288    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
289    this->blob_top_vec_.push_back(this->blob_top_2_);
290    LayerParameter layer_param;
291    ConvolutionParameter* convolution_param =
292        layer_param.mutable_convolution_param();
293    convolution_param->add_kernel_size(KH);
294    convolution_param->add_stride(CS);
295    convolution_param->set_num_output(OC);
296    convolution_param->add_pad(PD);
297    convolution_param->mutable_weight_filler()->set_type("gaussian");
298    convolution_param->mutable_bias_filler()->set_type("constant");
299    convolution_param->mutable_bias_filler()->set_value(0.1);
300    shared_ptr<Layer<Dtype> > layer(
301        new MKLDNNConvolutionLayer<Dtype>(layer_param));
302    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
303    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
304    const Dtype* top_data;
305    const Dtype* ref_top_data;
306    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
307        this->MakeReferenceTop(this->blob_top_));
308    top_data = this->blob_top_->cpu_data();
309    ref_top_data = this->ref_blob_top_->cpu_data();
310    for (int i = 0; i < this->blob_top_->count(); ++i) {
311      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
312    }
313  #if 0   
314    caffe_conv(this->blob_bottom_2_, convolution_param, layer->blobs(),
315        this->MakeReferenceTop(this->blob_top_2_));
316    top_data = this->blob_top_2_->cpu_data();
317    ref_top_data = this->ref_blob_top_->cpu_data();
318    for (int i = 0; i < this->blob_top_->count(); ++i) {
319      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
320    }
321  #endif
322  }
323  TYPED_TEST(MKLDNNConvolutionLayerTest, TestSimpleConvolutionReLUMKLDNN) {
324    typedef typename TypeParam::Dtype Dtype;
325    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
326    this->blob_top_vec_.push_back(this->blob_top_2_);
327    LayerParameter layer_param;
328    ConvolutionParameter* convolution_param =
329        layer_param.mutable_convolution_param();
330    convolution_param->add_kernel_size(3);
331    convolution_param->add_stride(2);
332    convolution_param->set_num_output(OC);
333    convolution_param->set_relu(true);
334    convolution_param->mutable_weight_filler()->set_type("gaussian");
335    convolution_param->mutable_bias_filler()->set_type("constant");
336    convolution_param->mutable_bias_filler()->set_value(0.1);
337    shared_ptr<Layer<Dtype> > layer(
338        new MKLDNNConvolutionLayer<Dtype>(layer_param));
339    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
340    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
341    const Dtype* top_data;
342    const Dtype* ref_top_data;
343    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
344        this->MakeReferenceTop(this->blob_top_));
345    top_data = this->blob_top_->cpu_data();
346    ref_top_data = this->ref_blob_top_->cpu_data();
347    for (int i = 0; i < this->blob_top_->count(); ++i) {
348      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
349    }
350  }
351  TYPED_TEST(MKLDNNConvolutionLayerTest, TestDilatedConvolutionMKLDNN) {
352    typedef typename TypeParam::Dtype Dtype;
353    vector<int> bottom_shape;
354    bottom_shape.push_back(2);
355    bottom_shape.push_back(3);
356    bottom_shape.push_back(8);
357    bottom_shape.push_back(7);
358    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
359    this->blob_top_vec_.push_back(this->blob_top_2_);
360    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
361      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
362    }
363    LayerParameter layer_param;
364    ConvolutionParameter* convolution_param =
365        layer_param.mutable_convolution_param();
366    convolution_param->add_kernel_size(3);
367    convolution_param->add_dilation(2);
368    convolution_param->set_num_output(4);
369    convolution_param->mutable_weight_filler()->set_type("gaussian");
370    convolution_param->mutable_bias_filler()->set_type("constant");
371    convolution_param->mutable_bias_filler()->set_value(0.1);
372    shared_ptr<Layer<Dtype> > layer(
373        new MKLDNNConvolutionLayer<Dtype>(layer_param));
374    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
375    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
376    const Dtype* top_data;
377    const Dtype* ref_top_data;
378    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
379               this->MakeReferenceTop(this->blob_top_));
380    top_data = this->blob_top_->cpu_data();
381    ref_top_data = this->ref_blob_top_->cpu_data();
382    for (int i = 0; i < this->blob_top_->count(); ++i) {
383      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
384    }
385  #if 0   
386    caffe_conv(this->blob_bottom_2_, convolution_param, layer->blobs(),
387               this->MakeReferenceTop(this->blob_top_2_));
388    top_data = this->blob_top_2_->cpu_data();
389    ref_top_data = this->ref_blob_top_->cpu_data();
390    for (int i = 0; i < this->blob_top_->count(); ++i) {
391      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
392    }
393  #endif
394  }
395  #endif
396  #if 0
397  TYPED_TEST(MKLDNNConvolutionLayerTest, Test0DConvolutionMKLDNN) {
398    typedef typename TypeParam::Dtype Dtype;
399    LayerParameter layer_param;
400    ConvolutionParameter* convolution_param =
401        layer_param.mutable_convolution_param();
402    const int kNumOutput = 3;
403    convolution_param->set_num_output(kNumOutput);
404    convolution_param->set_axis(3);
405    convolution_param->mutable_weight_filler()->set_type("gaussian");
406    convolution_param->mutable_bias_filler()->set_type("gaussian");
407    shared_ptr<Layer<Dtype> > layer(
408        new MKLDNNConvolutionLayer<Dtype>(layer_param));
409    vector<int> top_shape = this->blob_bottom_->shape();
410    top_shape[3] = kNumOutput;
411    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
412    EXPECT_EQ(top_shape, this->blob_top_->shape());
413    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
414    vector<int> weight_offset(2);
415    const Blob<Dtype>* weight = layer->blobs()[0].get();
416    const Blob<Dtype>* bias = layer->blobs()[1].get();
417    const int num = this->blob_top_->count(3);
418    const int dim = this->blob_top_->shape(3);
419    const int bottom_dim = this->blob_bottom_->shape(3);
420    for (int n = 0; n < num; ++n) {
421      for (int d = 0; d < dim; ++d) {
422        weight_offset[0] = d;
423        Dtype value = bias->cpu_data()[d];
424        for (int bottom_d = 0; bottom_d < bottom_dim; ++bottom_d) {
425          weight_offset[1] = bottom_d;
426          value += weight->data_at(weight_offset) *
427                   this->blob_bottom_->cpu_data()[n * bottom_dim + bottom_d];
428        }
429        EXPECT_NEAR(value, this->blob_top_->cpu_data()[n * dim + d], 1e-4);
430      }
431    }
432  }
433  #endif
434  #if 0
435  TYPED_TEST(MKLDNNConvolutionLayerTest, TestSimple3DConvolution) {
436    typedef typename TypeParam::Dtype Dtype;
437    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
438    this->blob_top_vec_.push_back(this->blob_top_2_);
439    vector<int> bottom_shape(5);
440    bottom_shape[0] = this->blob_bottom_vec_[0]->shape(0);
441    bottom_shape[1] = this->blob_bottom_vec_[0]->shape(1);
442    bottom_shape[2] = 5;
443    bottom_shape[3] = this->blob_bottom_vec_[0]->shape(2);
444    bottom_shape[4] = this->blob_bottom_vec_[0]->shape(3);
445    FillerParameter filler_param;
446    GaussianFiller<Dtype> filler(filler_param);
447    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
448      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
449      filler.Fill(this->blob_bottom_vec_[i]);
450    }
451    LayerParameter layer_param;
452    ConvolutionParameter* convolution_param =
453        layer_param.mutable_convolution_param();
454    convolution_param->add_kernel_size(3);
455    convolution_param->add_stride(2);
456    convolution_param->set_num_output(4);
457    convolution_param->mutable_weight_filler()->set_type("gaussian");
458    convolution_param->mutable_bias_filler()->set_type("gaussian");
459    shared_ptr<Layer<Dtype> > layer(
460        new MKLDNNConvolutionLayer<Dtype>(layer_param));
461    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
462    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
463    const Dtype* top_data;
464    const Dtype* ref_top_data;
465    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
466        this->MakeReferenceTop(this->blob_top_));
467    top_data = this->blob_top_->cpu_data();
468    ref_top_data = this->ref_blob_top_->cpu_data();
469    for (int i = 0; i < this->blob_top_->count(); ++i) {
470      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
471    }
472  #if 0   
473    caffe_conv(this->blob_bottom_2_, convolution_param, layer->blobs(),
474        this->MakeReferenceTop(this->blob_top_2_));
475    top_data = this->blob_top_2_->cpu_data();
476    ref_top_data = this->ref_blob_top_->cpu_data();
477    for (int i = 0; i < this->blob_top_->count(); ++i) {
478      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
479    }
480  #endif
481  }
482  #endif
483  #if 0
484  TYPED_TEST(MKLDNNConvolutionLayerTest, TestDilated3DConvolution) {
485    typedef typename TypeParam::Dtype Dtype;
486    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
487    this->blob_top_vec_.push_back(this->blob_top_2_);
488    vector<int> bottom_shape(5);
489    bottom_shape[0] = this->blob_bottom_vec_[0]->shape(0);
490    bottom_shape[1] = this->blob_bottom_vec_[0]->shape(1);
491    bottom_shape[2] = 6;
492    bottom_shape[3] = 7;
493    bottom_shape[4] = 8;
494    FillerParameter filler_param;
495    GaussianFiller<Dtype> filler(filler_param);
496    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
497      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
498      filler.Fill(this->blob_bottom_vec_[i]);
499    }
500    LayerParameter layer_param;
501    ConvolutionParameter* convolution_param =
502        layer_param.mutable_convolution_param();
503    convolution_param->add_kernel_size(3);
504    convolution_param->add_dilation(2);
505    convolution_param->set_num_output(4);
506    convolution_param->mutable_weight_filler()->set_type("gaussian");
507    convolution_param->mutable_bias_filler()->set_type("gaussian");
508    shared_ptr<Layer<Dtype> > layer(
509        new MKLDNNConvolutionLayer<Dtype>(layer_param));
510    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
511    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
512    const Dtype* top_data;
513    const Dtype* ref_top_data;
514    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
515               this->MakeReferenceTop(this->blob_top_));
516    top_data = this->blob_top_->cpu_data();
517    ref_top_data = this->ref_blob_top_->cpu_data();
518    for (int i = 0; i < this->blob_top_->count(); ++i) {
519      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
520    }
521    caffe_conv(this->blob_bottom_2_, convolution_param, layer->blobs(),
522               this->MakeReferenceTop(this->blob_top_2_));
523    top_data = this->blob_top_2_->cpu_data();
524    ref_top_data = this->ref_blob_top_->cpu_data();
525    for (int i = 0; i < this->blob_top_->count(); ++i) {
526      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
527    }
528  }
529  #endif
530  TYPED_TEST(MKLDNNConvolutionLayerTest, Test1x1Convolution) {
531    typedef typename TypeParam::Dtype Dtype;
532    LayerParameter layer_param;
533    ConvolutionParameter* convolution_param =
534        layer_param.mutable_convolution_param();
535    convolution_param->add_kernel_size(1);
536    convolution_param->add_stride(1);
537    convolution_param->set_num_output(OC);
538    convolution_param->mutable_weight_filler()->set_type("gaussian");
539    convolution_param->mutable_bias_filler()->set_type("constant");
540    convolution_param->mutable_bias_filler()->set_value(0.1);
541    shared_ptr<Layer<Dtype> > layer(
542        new MKLDNNConvolutionLayer<Dtype>(layer_param));
543    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
544    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
545    const Dtype* top_data;
546    const Dtype* ref_top_data;
547    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
548        this->MakeReferenceTop(this->blob_top_));
549    top_data = this->blob_top_->cpu_data();
550    ref_top_data = this->ref_blob_top_->cpu_data();
551    for (int i = 0; i < this->blob_top_->count(); ++i) {
552      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
553    }
554  }
555  TYPED_TEST(MKLDNNConvolutionLayerTest, Test1x1ConvolutionReLU) {
556    typedef typename TypeParam::Dtype Dtype;
557    LayerParameter layer_param;
558    ConvolutionParameter* convolution_param =
559        layer_param.mutable_convolution_param();
560    convolution_param->add_kernel_size(1);
561    convolution_param->add_stride(1);
562    convolution_param->set_num_output(OC);
563    convolution_param->set_relu(true);
564    convolution_param->mutable_weight_filler()->set_type("gaussian");
565    convolution_param->mutable_bias_filler()->set_type("constant");
566    convolution_param->mutable_bias_filler()->set_value(0.1);
567    shared_ptr<Layer<Dtype> > layer(
568        new MKLDNNConvolutionLayer<Dtype>(layer_param));
569    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
570    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
571    const Dtype* top_data;
572    const Dtype* ref_top_data;
573    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
574        this->MakeReferenceTop(this->blob_top_));
575    top_data = this->blob_top_->cpu_data();
576    ref_top_data = this->ref_blob_top_->cpu_data();
577    for (int i = 0; i < this->blob_top_->count(); ++i) {
578      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
579    }
580  }
581  TYPED_TEST(MKLDNNConvolutionLayerTest, TestSimpleConvolutionGroup) {
582    typedef typename TypeParam::Dtype Dtype;
583    LayerParameter layer_param;
584    ConvolutionParameter* convolution_param =
585        layer_param.mutable_convolution_param();
586    convolution_param->add_kernel_size(KH);
587    convolution_param->add_stride(CS);
588    convolution_param->set_num_output(OC);
589    convolution_param->set_group(GR);
590    convolution_param->add_pad(PD);
591    convolution_param->mutable_weight_filler()->set_type("gaussian");
592    convolution_param->mutable_bias_filler()->set_type("constant");
593    convolution_param->mutable_bias_filler()->set_value(0.1);
594    shared_ptr<Layer<Dtype> > layer(
595        new MKLDNNConvolutionLayer<Dtype>(layer_param));
596    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
597    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
598    const Dtype* top_data;
599    const Dtype* ref_top_data;
600    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
601        this->MakeReferenceTop(this->blob_top_));
602    top_data = this->blob_top_->cpu_data();
603    ref_top_data = this->ref_blob_top_->cpu_data();
604    for (int i = 0; i < this->blob_top_->count(); ++i) {
605      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
606    }
607  }
608  #if 0
609  TYPED_TEST(MKLDNNConvolutionLayerTest, TestSimpleConvolutionReLUGroup) {
610    typedef typename TypeParam::Dtype Dtype;
611    LayerParameter layer_param;
612    ConvolutionParameter* convolution_param =
613        layer_param.mutable_convolution_param();
614    convolution_param->add_kernel_size(3);
615    convolution_param->add_stride(2);
616    convolution_param->set_num_output(OC);
617    convolution_param->set_relu(true);
618    convolution_param->set_group(GR);
619    convolution_param->mutable_weight_filler()->set_type("gaussian");
620    convolution_param->mutable_bias_filler()->set_type("constant");
621    convolution_param->mutable_bias_filler()->set_value(0.1);
622    shared_ptr<Layer<Dtype> > layer(
623        new MKLDNNConvolutionLayer<Dtype>(layer_param));
624    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
625    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
626    const Dtype* top_data;
627    const Dtype* ref_top_data;
628    caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
629        this->MakeReferenceTop(this->blob_top_));
630    top_data = this->blob_top_->cpu_data();
631    ref_top_data = this->ref_blob_top_->cpu_data();
632    for (int i = 0; i < this->blob_top_->count(); ++i) {
633      EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
634    }
635  }
636  TYPED_TEST(MKLDNNConvolutionLayerTest, TestSobelConvolution) {
637    typedef typename TypeParam::Dtype Dtype;
638    shared_ptr<GaussianFiller<Dtype> > filler;
639    FillerParameter filler_param;
640    filler_param.set_value(1.);
641    filler.reset(new GaussianFiller<Dtype>(filler_param));
642    filler->Fill(this->blob_bottom_);
643    this->blob_bottom_2_->CopyFrom(*this->blob_bottom_);
644    LayerParameter layer_param;
645    ConvolutionParameter* convolution_param =
646        layer_param.mutable_convolution_param();
647    convolution_param->add_kernel_size(3);
648    convolution_param->add_stride(2);
649    convolution_param->set_num_output(1);
650    convolution_param->set_bias_term(false);
651    shared_ptr<Layer<Dtype> > layer(
652        new MKLDNNConvolutionLayer<Dtype>(layer_param));
653    layer->blobs().resize(1);
654    layer->blobs()[0].reset(new Blob<Dtype>(1, 3, 3, 3));
655    Dtype* weights = layer->blobs()[0]->mutable_cpu_data();
656    for (int c = 0; c < 3; ++c) {
<span onclick='openModal()' class='match'>657      int i = c * 9;  
658      weights[i +  0] = -1;
659      weights[i +  1] =  0;
660      weights[i +  2] =  1;
661      weights[i +  3] = -2;
662      weights[i +  4] =  0;
663      weights[i +  5] =  2;
664      weights[i +  6] = -1;
665      weights[i +  7] =  0;
666      weights[i +  8] =  1;
</span>667    }
668    layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
669    layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
670    vector<Blob<Dtype>*> sep_blob_bottom_vec;
671    vector<Blob<Dtype>*> sep_blob_top_vec;
672    shared_ptr<Blob<Dtype> > blob_sep(new Blob<Dtype>());
673    sep_blob_bottom_vec.push_back(this->blob_bottom_2_);
674    sep_blob_top_vec.push_back(this->blob_top_2_);
675    convolution_param->clear_kernel_size();
676    convolution_param->clear_stride();
677    convolution_param->set_kernel_h(3);
678    convolution_param->set_kernel_w(1);
679    convolution_param->set_stride_h(2);
680    convolution_param->set_stride_w(1);
681    convolution_param->set_num_output(1);
682    convolution_param->set_bias_term(false);
683    layer.reset(new MKLDNNConvolutionLayer<Dtype>(layer_param));
684    layer->blobs().resize(1);
685    layer->blobs()[0].reset(new Blob<Dtype>(1, 3, 3, 1));
686    Dtype* weights_1 = layer->blobs()[0]->mutable_cpu_data();
687    for (int c = 0; c < 3; ++c) {
688      int i = c * 3;  
689      weights_1[i +  0] = 1;
690      weights_1[i +  1] = 2;
691      weights_1[i +  2] = 1;
692    }
693    layer->SetUp(sep_blob_bottom_vec, sep_blob_top_vec);
694    layer->Forward(sep_blob_bottom_vec, sep_blob_top_vec);
695    blob_sep->CopyFrom(*this->blob_top_2_, false, true);
696    sep_blob_bottom_vec.clear();
697    sep_blob_bottom_vec.push_back(blob_sep.get());
698    convolution_param->set_kernel_h(1);
699    convolution_param->set_kernel_w(3);
700    convolution_param->set_stride_h(1);
701    convolution_param->set_stride_w(2);
702    convolution_param->set_num_output(1);
703    convolution_param->set_bias_term(false);
704    layer.reset(new MKLDNNConvolutionLayer<Dtype>(layer_param));
705    layer->blobs().resize(1);
706    layer->blobs()[0].reset(new Blob<Dtype>(1, 1, 1, 3));
707    Dtype* weights_2 = layer->blobs()[0]->mutable_cpu_data();
708    weights_2[0] = -1;
709    weights_2[1] =  0;
710    weights_2[2] =  1;
711    layer->SetUp(sep_blob_bottom_vec, sep_blob_top_vec);
712    layer->Forward(sep_blob_bottom_vec, sep_blob_top_vec);
713    const Dtype* top_data = this->blob_top_->cpu_data();
714    const Dtype* sep_top_data = this->blob_top_2_->cpu_data();
715    for (int i = 0; i < this->blob_top_->count(); ++i) {
716      EXPECT_NEAR(top_data[i], sep_top_data[i], 1e-4);
717    }
718  }
719  #endif
720  #if 0
721  TYPED_TEST(MKLDNNConvolutionLayerTest, TestNDAgainst2D) {
722    typedef typename TypeParam::Dtype Dtype;
723    const int kernel_h = 11;
724    const int kernel_w = 13;
725    vector<int> bottom_shape(4);
726    bottom_shape[0] = 15;
727    bottom_shape[1] = 18;
728    bottom_shape[2] = kernel_h * 2;
729    bottom_shape[3] = kernel_w * 2;
730    FillerParameter filler_param;
731    GaussianFiller<Dtype> filler(filler_param);
732    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
733      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
734      filler.Fill(this->blob_bottom_vec_[i]);
735    }
736    LayerParameter layer_param;
737    ConvolutionParameter* convolution_param =
738        layer_param.mutable_convolution_param();
739    convolution_param->set_num_output(12);
740    convolution_param->set_bias_term(false);
741    convolution_param->set_group(6);
742    convolution_param->set_kernel_h(kernel_h);
743    convolution_param->set_kernel_w(kernel_w);
744    convolution_param->mutable_weight_filler()->set_type("gaussian");
745    Blob<Dtype> weights;
746    Blob<Dtype> top_diff;
747    bool copy_diff;
748    bool reshape;
749    {
750      MKLDNNConvolutionLayer<Dtype> layer(layer_param);
751      layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
752      top_diff.ReshapeLike(*this->blob_top_);
753      filler.Fill(&top_diff);
754      ASSERT_EQ(1, layer.blobs().size());
755      copy_diff = false; reshape = true;
756      weights.CopyFrom(*layer.blobs()[0], copy_diff, reshape);
757    }
758    vector<bool> propagate_down(1, true);
759    Blob<Dtype> result_2d;
760    Blob<Dtype> backward_result_2d;
761    Blob<Dtype> backward_weight_result_2d;
762    {
763      caffe_set(this->blob_top_->count(), Dtype(0),
764                this->blob_top_->mutable_cpu_data());
765      caffe_set(this->blob_bottom_->count(), Dtype(0),
766                this->blob_bottom_->mutable_cpu_diff());
767      caffe_set(weights.count(), Dtype(0), weights.mutable_cpu_diff());
768      convolution_param->set_force_nd_im2col(false);
769      MKLDNNConvolutionLayer<Dtype> layer_2d(layer_param);
770      layer_2d.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
771      ASSERT_EQ(1, layer_2d.blobs().size());
772      copy_diff = false; reshape = false;
773      layer_2d.blobs()[0]->CopyFrom(weights, copy_diff, reshape);
774      layer_2d.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
775      copy_diff = false; reshape = true;
776      result_2d.CopyFrom(*this->blob_top_, copy_diff, reshape);
777      ASSERT_EQ(this->blob_top_->shape(), top_diff.shape());
778      caffe_copy(top_diff.count(), top_diff.cpu_data(),
779                 this->blob_top_->mutable_cpu_diff());
780      layer_2d.Backward(this->blob_top_vec_, propagate_down,
781                        this->blob_bottom_vec_);
782      copy_diff = true; reshape = true;
783      backward_result_2d.CopyFrom(*this->blob_bottom_, copy_diff, reshape);
784      backward_weight_result_2d.CopyFrom(weights, copy_diff, reshape);
785    }
786    Blob<Dtype> result_nd;
787    Blob<Dtype> backward_result_nd;
788    Blob<Dtype> backward_weight_result_nd;
789    {
790      caffe_set(this->blob_top_->count(), Dtype(0),
791                this->blob_top_->mutable_cpu_data());
792      caffe_set(this->blob_bottom_->count(), Dtype(0),
793                this->blob_bottom_->mutable_cpu_diff());
794      caffe_set(weights.count(), Dtype(0), weights.mutable_cpu_diff());
795      convolution_param->set_force_nd_im2col(true);
796      MKLDNNConvolutionLayer<Dtype> layer_nd(layer_param);
797      layer_nd.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
798      ASSERT_EQ(1, layer_nd.blobs().size());
799      copy_diff = false; reshape = false;
800      layer_nd.blobs()[0]->CopyFrom(weights, copy_diff, reshape);
801      layer_nd.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
802      copy_diff = false; reshape = true;
803      result_nd.CopyFrom(*this->blob_top_, copy_diff, reshape);
804      ASSERT_EQ(this->blob_top_->shape(), top_diff.shape());
805      caffe_copy(top_diff.count(), top_diff.cpu_data(),
806                 this->blob_top_->mutable_cpu_diff());
807      layer_nd.Backward(this->blob_top_vec_, propagate_down,
808                        this->blob_bottom_vec_);
809      copy_diff = true; reshape = true;
810      backward_result_nd.CopyFrom(*this->blob_bottom_, copy_diff, reshape);
811      backward_weight_result_nd.CopyFrom(weights, copy_diff, reshape);
812    }
813    ASSERT_EQ(result_nd.count(), result_2d.count());
814    for (int i = 0; i < result_2d.count(); ++i)  {
815      EXPECT_EQ(result_2d.cpu_data()[i], result_nd.cpu_data()[i]);
816    }
817    ASSERT_EQ(backward_result_nd.count(), backward_result_2d.count());
818    for (int i = 0; i < backward_result_2d.count(); ++i) {
819      EXPECT_EQ(backward_result_2d.cpu_diff()[i],
820                backward_result_nd.cpu_diff()[i]);
821    }
822    ASSERT_EQ(backward_weight_result_nd.count(),
823              backward_weight_result_2d.count());
824    for (int i = 0; i < backward_weight_result_2d.count(); ++i) {
825      EXPECT_EQ(backward_weight_result_2d.cpu_diff()[i],
826                backward_weight_result_nd.cpu_diff()[i]);
827    }
828  }
829  #endif
830  TYPED_TEST(MKLDNNConvolutionLayerTest, DISABLED_TestGradient) {
831    typedef typename TypeParam::Dtype Dtype;
832    LayerParameter layer_param;
833    ConvolutionParameter* convolution_param =
834        layer_param.mutable_convolution_param();
835    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
836    this->blob_top_vec_.push_back(this->blob_top_2_);
837    convolution_param->add_kernel_size(KH);
838    convolution_param->add_stride(CS);
839    convolution_param->set_num_output(OC);
840    convolution_param->add_pad(PD);
841    convolution_param->mutable_weight_filler()->set_type("gaussian");
842    convolution_param->mutable_bias_filler()->set_type("gaussian");
843    MKLDNNConvolutionLayer<Dtype> layer(layer_param);
844    GradientChecker<Dtype> checker(1e-2, 1e-3);
845    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
846        this->blob_top_vec_);
847  }
848  #if 0
849  TYPED_TEST(MKLDNNConvolutionLayerTest, TestDilatedGradient) {
850    typedef typename TypeParam::Dtype Dtype;
851    LayerParameter layer_param;
852    ConvolutionParameter* convolution_param =
853        layer_param.mutable_convolution_param();
854    vector<int> bottom_shape;
855    bottom_shape.push_back(2);
856    bottom_shape.push_back(3);
857    bottom_shape.push_back(5);
858    bottom_shape.push_back(6);
859    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
860      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
861    }
862    convolution_param->add_kernel_size(3);
863    convolution_param->add_dilation(2);
864    convolution_param->set_num_output(2);
865    convolution_param->mutable_weight_filler()->set_type("gaussian");
866    convolution_param->mutable_bias_filler()->set_type("gaussian");
867    MKLDNNConvolutionLayer<Dtype> layer(layer_param);
868    GradientChecker<Dtype> checker(1e-2, 1e-3);
869    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
870                                    this->blob_top_vec_);
871  }
872  #endif
873  #if 0
874  TYPED_TEST(MKLDNNConvolutionLayerTest, TestGradient3D) {
875    typedef typename TypeParam::Dtype Dtype;
876    LayerParameter layer_param;
877    ConvolutionParameter* convolution_param =
878        layer_param.mutable_convolution_param();
879    vector<int> bottom_shape(5);
880    bottom_shape[0] = this->blob_bottom_vec_[0]->shape(0);
881    bottom_shape[1] = this->blob_bottom_vec_[0]->shape(1);
882    bottom_shape[2] = 5;
883    bottom_shape[3] = this->blob_bottom_vec_[0]->shape(2);
884    bottom_shape[4] = this->blob_bottom_vec_[0]->shape(3);
885    FillerParameter filler_param;
886    GaussianFiller<Dtype> filler(filler_param);
887    for (int i = 0; i < this->blob_bottom_vec_.size(); ++i) {
888      this->blob_bottom_vec_[i]->Reshape(bottom_shape);
889      filler.Fill(this->blob_bottom_vec_[i]);
890    }
891    convolution_param->add_kernel_size(3);
892    convolution_param->add_stride(2);
893    convolution_param->set_num_output(2);
894    convolution_param->mutable_weight_filler()->set_type("gaussian");
895    convolution_param->mutable_bias_filler()->set_type("gaussian");
896    MKLDNNConvolutionLayer<Dtype> layer(layer_param);
897    GradientChecker<Dtype> checker(1e-2, 1e-3);
898    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
899        this->blob_top_vec_);
900  }
901  TYPED_TEST(MKLDNNConvolutionLayerTest, Test1x1Gradient) {
902    typedef typename TypeParam::Dtype Dtype;
903    LayerParameter layer_param;
904    ConvolutionParameter* convolution_param =
905        layer_param.mutable_convolution_param();
906    this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
907    this->blob_top_vec_.push_back(this->blob_top_2_);
908    convolution_param->add_kernel_size(1);
909    convolution_param->add_stride(1);
910    convolution_param->set_num_output(2);
911    convolution_param->mutable_weight_filler()->set_type("gaussian");
912    convolution_param->mutable_bias_filler()->set_type("gaussian");
913    MKLDNNConvolutionLayer<Dtype> layer(layer_param);
914    GradientChecker<Dtype> checker(1e-2, 1e-3);
915    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
916        this->blob_top_vec_);
917  }
918  #endif
919  TYPED_TEST(MKLDNNConvolutionLayerTest, TestGradientGroup) {
920    typedef typename TypeParam::Dtype Dtype;
921    LayerParameter layer_param;
922    ConvolutionParameter* convolution_param =
923        layer_param.mutable_convolution_param();
924    convolution_param->add_kernel_size(3);
925    convolution_param->add_stride(2);
926    convolution_param->set_num_output(2);
927    convolution_param->set_group(GR);
928    convolution_param->mutable_weight_filler()->set_type("gaussian");
929    convolution_param->mutable_bias_filler()->set_type("gaussian");
930    MKLDNNConvolutionLayer<Dtype> layer(layer_param);
931    GradientChecker<Dtype> checker(1e-2, 1e-3);
932    checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
933        this->blob_top_vec_);
934  }
935  }  
936  #endif  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from notepad-plus-plus-MDEwOlJlcG9zaXRvcnkzMzAxNDgxMQ==-flat-FunctionCallTip.h</div>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-test_mkldnn_convolution_layer.cpp</div>
                <div class="column column_space"><pre><code>16  	ScintillaEditView * _pEditView = nullptr;	
17  	TiXmlElement * _pXmlKeyword = nullptr;	
18  	intptr_t _curPos = 0;					
19  	intptr_t _startPos = 0;					
20  	TiXmlElement * _curFunction = nullptr;	
21  	TCHAR * _funcName = nullptr;				
22  	stringVec _retVals;				
23  	std::vector<stringVec> _overloads;	
24  	stringVec _descriptions;		
25  	size_t _currentNbOverloads = 0;		
26  	size_t _currentOverload = 0;			
27  	size_t _currentParam = 0;				
28  	TCHAR _start = '(';
</pre></code></div>
                <div class="column column_space"><pre><code>657      int i = c * 9;  
658      weights[i +  0] = -1;
659      weights[i +  1] =  0;
660      weights[i +  2] =  1;
661      weights[i +  3] = -2;
662      weights[i +  4] =  0;
663      weights[i +  5] =  2;
664      weights[i +  6] = -1;
665      weights[i +  7] =  0;
666      weights[i +  8] =  1;
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    