
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 15.706806282722512%, Tokens: 9</h2>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-eval_detection_layer.cpp</h3>
            <pre><code>1  #include <algorithm>
2  #include <cfloat>
3  #include <vector>
4  #include <cmath>
5  #include "caffe/layers/region_loss_layer.hpp"
6  #include "caffe/layers/eval_detection_layer.hpp"
7  #include "caffe/util/math_functions.hpp"
8  #include "caffe/util/benchmark.hpp"
9  #ifdef ENABLE_NMS_OPTIMIZATION
10  #include "caffe/util/bbox_util.hpp"
11  #include <immintrin.h>
12  #include "omp.h"
13  #endif
14  namespace caffe {
15      class BoxData {
16      public:
17          int label_;
18          float score_;
19          vector<float> box_;
20      };
21      inline float sigmoid(float x)
22      {
23          return 1. / (1. + exp(-x));
24      }
25      template <typename Dtype>
26      Dtype softmax_region(Dtype* input, int classes)
27      {
28          Dtype sum = 0;
29          Dtype large = input[0];
30          for (int i = 0; i < classes; ++i) {
31              if (input[i] > large)
32                  large = input[i];
33          }
34          for (int i = 0; i < classes; ++i) {
35              Dtype e = exp(input[i] - large);
36              sum += e;
37              input[i] = e;
38          }
39          for (int i = 0; i < classes; ++i) {
40              input[i] = input[i] / sum;
41          }
42          return 0;
43      }
44      bool BoxSortDecendScore(const BoxData& box1, const BoxData& box2) {
45          return box1.score_ > box2.score_;
46      }
47      void ApplyNms(const vector<BoxData>& boxes, vector<int>* idxes, float threshold) {
48          map<int, int> idx_map;
49          for (int i = 0; i < boxes.size() - 1; ++i) {
50              if (idx_map.find(i) != idx_map.end()) {
51                  continue;
52              }
53              vector<float> box1 = boxes[i].box_;
54              for (int j = i + 1; j < boxes.size(); ++j) {
55                  if (idx_map.find(j) != idx_map.end()) {
56                      continue;
57                  }
58                  vector<float> box2 = boxes[j].box_;
59                  float iou = Calc_iou(box1, box2);
60                  if (iou >= threshold) {
61                      idx_map[j] = 1;
62                  }
63              }
64          }
65          for (int i = 0; i < boxes.size(); ++i) {
66              if (idx_map.find(i) == idx_map.end()) {
67                  idxes->push_back(i);
68              }
69          }
70      }
71      template <typename Dtype>
72      void GetGTBox(int side, vector<vector<Dtype> > boxes, map<int, vector<BoxData> >* gt_boxes) {
73          for (int i = 0; i < boxes.size(); ++i) {
74              vector<Dtype> box = boxes[i];
75              BoxData gt_box;
76              int label = box[0];
77              gt_box.label_ = label;
78              gt_box.score_ = i; 
79              gt_box.box_.push_back(box[1]);
80              gt_box.box_.push_back(box[2]);
81              gt_box.box_.push_back(box[3]);
82              gt_box.box_.push_back(box[4]);
83              if (gt_boxes->find(label) == gt_boxes->end()) {
84                  (*gt_boxes)[label] = vector<BoxData>(1, gt_box);
85              }
86              else {
87                  (*gt_boxes)[label].push_back(gt_box);
88              }
89          }
90      }
91      template <typename Dtype>
92      void GetPredBox(int side, int num_object, int num_class, Dtype* input_data, map<int, vector<BoxData> >* pred_boxes, int score_type, float nms_threshold, vector<Dtype> biases) {
93          vector<BoxData> tmp_boxes;
94          for (int j = 0; j < side; ++j) {
95              for (int i = 0; i < side; ++i) {
96                  for (int n = 0; n < 5; ++n)
97                  {
98                      int index = (j * side + i) * num_object * (num_class + 1 + 4) + n * (num_class + 1 + 4);
99                      float x = (i + sigmoid(input_data[index + 0])) / side;
100                      float y = (j + sigmoid(input_data[index + 1])) / side;
101                      float w = (exp(input_data[index + 2]) * biases[2 * n]) / side;
102                      float h = (exp(input_data[index + 3]) * biases[2 * n + 1]) / side;
103                      softmax_region(input_data + index + 5, num_class);
104                      int pred_label = 0;
105                      float max_prob = input_data[index + 5];
106                      for (int c = 0; c < num_class; ++c)
107                      {
108                          if (max_prob < input_data[index + 5 + c])
109                          {
110                              max_prob = input_data[index + 5 + c];
111                              pred_label = c; 
112                          }
113                      }
114                      BoxData pred_box;
115                      pred_box.label_ = pred_label;
116                      float obj_score = sigmoid(input_data[index + 4]);
117                      if (score_type == 0) {
118                          pred_box.score_ = obj_score;
119                      }
120                      else if (score_type == 1) {
121                          pred_box.score_ = max_prob;
122                      }
123                      else {
124                          pred_box.score_ = obj_score * max_prob;
125                      }
126                      pred_box.box_.push_back(x);
127                      pred_box.box_.push_back(y);
128                      pred_box.box_.push_back(w);
129                      pred_box.box_.push_back(h);
130                      tmp_boxes.push_back(pred_box);
131                  }
132              }
133          }
134          if (nms_threshold >= 0) {
135              std::sort(tmp_boxes.begin(), tmp_boxes.end(), BoxSortDecendScore);
136              vector<int> idxes;
137  #ifdef ENABLE_NMS_OPTIMIZATION
138              if (_may_i_use_cpu_feature(_FEATURE_AVX512CD | _FEATURE_AVX512F)) {
139                  uint64_t boxes_num = tmp_boxes.size();
140                  float* x1 = (float*)aligned_alloc(64, boxes_num * sizeof(float));
141                  float* y1 = (float*)aligned_alloc(64, boxes_num * sizeof(float));
142                  float* x2 = (float*)aligned_alloc(64, boxes_num * sizeof(float));
143                  float* y2 = (float*)aligned_alloc(64, boxes_num * sizeof(float));
144                  uint64_t i = 0;
145  #pragma omp parallel for
146                  for (i = 0; i < boxes_num; ++i) {
147                      x1[i] = tmp_boxes[i].box_[0] - tmp_boxes[i].box_[2] / 2.0;       
148                      y1[i] = tmp_boxes[i].box_[1] - tmp_boxes[i].box_[3] / 2.0;       
149                      x2[i] = tmp_boxes[i].box_[0] + tmp_boxes[i].box_[2] / 2.0;       
150                      y2[i] = tmp_boxes[i].box_[1] + tmp_boxes[i].box_[3] / 2.0;       
151                  }
152                  int* keep_out = (int*)malloc(sizeof(int) * tmp_boxes.size());
153                  int num_out = 0;
154                  cpu_nms_avx512_parallize_inner(keep_out, &num_out, x1, y1, x2, y2, boxes_num, nms_threshold);
155                  for (int i = 0; i < num_out; i++) {
156                      idxes.push_back(keep_out[i]);
157                  }
158                  if (x1)
159                      free(x1);
160                  if (x2)
161                      free(x2);
162                  if (y1)
163                      free(y1);
164                  if (y2)
165                      free(y2);
166                  if (keep_out)
167                      free(keep_out);
168              }
169              else {
170  #endif
171              ApplyNms(tmp_boxes, &idxes, nms_threshold);
172  #ifdef ENABLE_NMS_OPTIMIZATION
173          }
174  #endif
175              for (int i = 0; i < idxes.size(); ++i) {
176                  BoxData box_data = tmp_boxes[idxes[i]];
177                  /&bsol;**************************************************************************************
178                  if (box_data.score_ < 0.005) 
179                      continue;
180                  if (pred_boxes->find(box_data.label_) == pred_boxes->end()) {
181                      (*pred_boxes)[box_data.label_] = vector<BoxData>();
182                  }
183                  (*pred_boxes)[box_data.label_].push_back(box_data);
<span onclick='openModal()' class='match'>184              }
185          }
186          else {
187              for (std::map<int, vector<BoxData> >::iterator it = pred_boxes->begin(); it != pred_boxes->end(); ++it) {
</span>188                  std::sort(it->second.begin(), it->second.end(), BoxSortDecendScore);
189              }
190          }
191      }
192      template <typename Dtype>
193      void EvalDetectionLayer<Dtype>::LayerSetUp(
194          const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
195          EvalDetectionParameter param = this->layer_param_.eval_detection_param();
196          side_ = param.side();
197          num_class_ = param.num_class();
198          num_object_ = param.num_object();
199          threshold_ = param.threshold();
200          nms_ = param.nms();
201          for (int c = 0; c < param.biases_size(); ++c) {
202              biases_.push_back(param.biases(c));
203          }
204          switch (param.score_type()) {
205          case EvalDetectionParameter_ScoreType_OBJ:
206              score_type_ = 0;
207              break;
208          case EvalDetectionParameter_ScoreType_PROB:
209              score_type_ = 1;
210              break;
211          case EvalDetectionParameter_ScoreType_MULTIPLY:
212              score_type_ = 2;
213              break;
214          default:
215              LOG(FATAL) << "Unknow score type.";
216          }
217      }
218      template <typename Dtype>
219      void EvalDetectionLayer<Dtype>::Reshape(
220          const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
221          int input_count = bottom[0]->count(1); 
222          int tmp_input_count = side_ * side_ * num_object_ *(num_class_ + 4 + 1); 
223          CHECK_EQ(input_count, tmp_input_count);
224          vector<int> top_shape(2, 1);
225          top_shape[0] = bottom[0]->num();
226          top_shape[1] = num_class_ + side_ * side_ * num_object_ * 4; 
227          top[0]->Reshape(top_shape);
228      }
229      template <typename Dtype>
230      void EvalDetectionLayer<Dtype>::Forward_cpu(
231          const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
232          const Dtype* label_data = bottom[1]->cpu_data();
233          Blob<Dtype> swap;
234          swap.Reshape(bottom[0]->num(), bottom[0]->height()*bottom[0]->width(), num_object_, bottom[0]->channels() / num_object_);
235          Dtype* swap_data = swap.mutable_cpu_data();
236          int index = 0;
237          int n_value = bottom[0]->num();
238          int h_value = bottom[0]->height();
239          int w_value = bottom[0]->width();
240          int c_value = bottom[0]->channels();
241          const Dtype* input_data = bottom[0]->cpu_data();
242          for (int b = 0; b < n_value; ++b) {
243              for (int h = 0; h < h_value; ++h) {
244                  for (int w = 0; w < w_value; ++w) {
245                      for (int c = 0; c < c_value; ++c) {
246                          swap_data[index++] = input_data[((b * c_value + c) * h_value + h) * w_value + w];
247                      }
248                  }
249              }
250          }
251          /&bsol;******************************************************** Label ********************************************************
252          vector<vector<vector<Dtype> > > labels;
253          labels.resize(bottom[0]->num() + 1); 
254          int num_boxes = bottom[1]->height();
255          for (int i = 0; i < num_boxes; ++i) {
256              vector<Dtype> box;
257              int item_id = label_data[i * 8 + 0]; 
258              if (item_id == -1) continue;
259              Dtype xmin = label_data[i * 8 + 3];
260              Dtype ymin = label_data[i * 8 + 4];
261              Dtype xmax = label_data[i * 8 + 5];
262              Dtype ymax = label_data[i * 8 + 6];
263              Dtype cx = (xmin + xmax) / 2.0;
264              Dtype cy = (ymin + ymax) / 2.0;
265              Dtype w = xmax - xmin;
266              Dtype h = ymax - ymin;
267              box.push_back(label_data[i * 8 + 1] - 1); 
268              box.push_back(cx); 
269              box.push_back(cy); 
270              box.push_back(w); 
271              box.push_back(h); 
272              labels[item_id].push_back(box);
273          }
274          /&bsol;*********************************************************Diff********************************************************
275          Dtype* top_data = top[0]->mutable_cpu_data();
276          caffe_set(top[0]->count(), Dtype(0), top_data);
277          for (int i = 0; i < bottom[0]->num(); ++i) {
278              int input_index = i * bottom[0]->count(1);
279              int top_index = i * top[0]->count(1);
280              map<int, vector<BoxData> > gt_boxes;
281              GetGTBox(side_, labels[i], &gt_boxes);
282              for (std::map<int, vector<BoxData > >::iterator it = gt_boxes.begin(); it != gt_boxes.end(); ++it) {
283                  int label = it->first;
284                  vector<BoxData>& g_boxes = it->second;
285                  for (int j = 0; j < g_boxes.size(); ++j) {
286                      top_data[top_index + label] += 1; 
287                  }
288              }
289              map<int, vector<BoxData> > pred_boxes;
290              GetPredBox(side_, num_object_, num_class_, swap_data + input_index, &pred_boxes, score_type_, nms_, biases_);
291              int index = top_index + num_class_;
292              int pred_count(0);
293              for (std::map<int, vector<BoxData> >::iterator it = pred_boxes.begin(); it != pred_boxes.end(); ++it) {
294                  int label = it->first;
295                  vector<BoxData>& p_boxes = it->second;
296                  if (gt_boxes.find(label) == gt_boxes.end()) {
297                      for (int b = 0; b < p_boxes.size(); ++b) {
298                          top_data[index + pred_count * 4 + 0] = p_boxes[b].label_;
299                          top_data[index + pred_count * 4 + 1] = p_boxes[b].score_;
300                          top_data[index + pred_count * 4 + 2] = 0; 
301                          top_data[index + pred_count * 4 + 3] = 1; 
302                          ++pred_count;
303                      }
304                      continue;
305                  }
306                  vector<BoxData>& g_boxes = gt_boxes[label];
307                  vector<bool> records(g_boxes.size(), false);
308                  for (int k = 0; k < p_boxes.size(); ++k) {
309                      top_data[index + pred_count * 4 + 0] = p_boxes[k].label_;
310                      top_data[index + pred_count * 4 + 1] = p_boxes[k].score_;
311                      float max_iou(-1);
312                      int idx(-1);
313                      for (int g = 0; g < g_boxes.size(); ++g) {
314                          float iou = Calc_iou(p_boxes[k].box_, g_boxes[g].box_);
315                          if (iou > max_iou) {
316                              max_iou = iou;
317                              idx = g;
318                          }
319                      }
320                      if (max_iou >= threshold_) {
321                          if (!records[idx]) {
322                              records[idx] = true;
323                              top_data[index + pred_count * 4 + 2] = 1;
324                              top_data[index + pred_count * 4 + 3] = 0;
325                          }
326                          else {
327                              top_data[index + pred_count * 4 + 2] = 0;
328                              top_data[index + pred_count * 4 + 3] = 1;
329                          }
330                      }
331                      ++pred_count;
332                  }
333              }
334          }
335      }
336      INSTANTIATE_CLASS(EvalDetectionLayer);
337      REGISTER_LAYER_CLASS(EvalDetection);
338  }  
</code></pre>
        </div>
        <div class="column">
            <h3>snap-MDEwOlJlcG9zaXRvcnk0Mjg4MzU3-flat-agmdirected.cpp</h3>
            <pre><code>1  #include "stdafx.h"
2  #include "agmfast.h"
3  #include "agmdirected.h"
4  #include "Snap.h"
5  #include "agm.h"
6  void TCoda::Save(TSOut& SOut) {
7    G->Save(SOut);
8    F.Save(SOut);
9    H.Save(SOut);
10    NIDV.Save(SOut);
11    RegCoef.Save(SOut);
12    SumFV.Save(SOut);
13    SumHV.Save(SOut);
14    NodesOk.Save(SOut);
15    MinVal.Save(SOut);
16    MaxVal.Save(SOut);
17    NegWgt.Save(SOut);
18    NumComs.Save(SOut);
19    HOVIDSV.Save(SOut);
20    PNoCom.Save(SOut);
21  }
22  void TCoda::Load(TSIn& SIn, const int& RndSeed) {
23    G->Load(SIn);
24    F.Load(SIn);
25    H.Load(SIn);
26    NIDV.Load(SIn);
27    RegCoef.Load(SIn);
28    SumFV.Load(SIn);
29    SumHV.Load(SIn);
30    NodesOk.Load(SIn);
31    MinVal.Load(SIn);
32    MaxVal.Load(SIn);
33    NegWgt.Load(SIn);
34    NumComs.Load(SIn);
35    HOVIDSV.Load(SIn);
36    PNoCom.Load(SIn);
37    Rnd.PutSeed(RndSeed);
38  }
39  void TCoda::RandomInit(const int InitComs) {
40    F.Gen(G->GetNodes());
41    H.Gen(G->GetNodes());
42    SumFV.Gen(InitComs);
43    SumHV.Gen(InitComs);
44    NumComs = InitComs;
45    for (int u = 0; u < F.Len(); u++) {
46      int Mem = G->GetNI(u).GetOutDeg();
47      if (Mem > 10) { Mem = 10; }
48      for (int c = 0; c < Mem; c++) {
49        int CID = Rnd.GetUniDevInt(InitComs);
50        AddComOut(u, CID, Rnd.GetUniDev());
51      }
52    }
53    for (int u = 0; u < H.Len(); u++) {
54      int Mem = G->GetNI(u).GetInDeg();
55      if (Mem > 10) { Mem = 10; }
56      for (int c = 0; c < Mem; c++) {
57        int CID = Rnd.GetUniDevInt(InitComs);
58        AddComIn(u, CID, Rnd.GetUniDev());
59      }
60    }
61    for (int c = 0; c < SumFV.Len(); c++) {
62      if (SumFV[c] == 0.0) {
63        int UID = Rnd.GetUniDevInt(G->GetNodes());
64        AddComOut(UID, c, Rnd.GetUniDev());
65      }
66    }
67    for (int c = 0; c < SumHV.Len(); c++) {
68      if (SumHV[c] == 0.0) {
69        int UID = Rnd.GetUniDevInt(G->GetNodes());
70        AddComIn(UID, c, Rnd.GetUniDev());
71      }
72    }
73  }
74  void TCoda::NeighborComInit(const int InitComs) {
75    TExeTm RunTm;
76    TFltIntPrV NIdPhiV(F.Len(), 0);
77    TAGMFastUtil::GetNIdPhiV<PNGraph>(G, NIdPhiV);
78    NeighborComInit(NIdPhiV, InitComs);
79  }
80  void TCoda::NeighborComInit(TFltIntPrV& NIdPhiV, const int InitComs) {
81    NIdPhiV.Sort(true);
82    F.Gen(G->GetNodes());
83    H.Gen(G->GetNodes());
84    SumFV.Gen(InitComs);
85    SumHV.Gen(InitComs);
86    NumComs = InitComs;
87    TIntSet InvalidNIDS(F.Len());
88    TIntV ChosenNIDV(InitComs, 0); 
89    int CurCID = 0;
90    for (int ui = 0; ui < NIdPhiV.Len(); ui++) {
91      int UID = NIdPhiV[ui].Val2;
92      fflush(stdout);
93      if (InvalidNIDS.IsKey(UID)) { continue; }
94      ChosenNIDV.Add(UID); 
95      TNGraph::TNodeI NI = G->GetNI(UID);
96      if (NI.GetOutDeg() > 0) { AddComOut(UID, CurCID, 1.0); }
97      if (NI.GetInDeg() > 0) { AddComIn(UID, CurCID, 1.0); }
98      fflush(stdout);
99      for (int e = 0; e < NI.GetDeg(); e++) {
100        int VID = NI.GetNbrNId(e);
101        TNGraph::TNodeI VI = G->GetNI(VID);
102        if (VI.GetOutDeg() > 0) { AddComOut(VID, CurCID, 1.0); }
103        if (VI.GetInDeg() > 0) { AddComIn(VID, CurCID, 1.0); }
104      }
105      for (int e = 0; e < NI.GetDeg(); e++) {
106        InvalidNIDS.AddKey(NI.GetNbrNId(e));
107      }
108      CurCID++;
109      fflush(stdout);
110      if (CurCID >= NumComs) { break;  }
111    }
112    if (NumComs > CurCID) {
113      printf("%d communities needed to fill randomly\n", NumComs - CurCID);
114    }
115    for (int c = 0; c < SumFV.Len(); c++) {
116      if (SumFV[c] == 0.0) {
117        int ComSz = 10;
118        for (int u = 0; u < ComSz; u++) {
119          int UID = Rnd.GetUniDevInt(G->GetNodes());
120          AddComOut(UID, c, Rnd.GetUniDev());
121        }
122      }
123    }
124    for (int c = 0; c < SumHV.Len(); c++) {
125      if (SumHV[c] == 0.0) {
126        int ComSz = 10;
127        for (int u = 0; u < ComSz; u++) {
128          int UID = Rnd.GetUniDevInt(G->GetNodes());
129          AddComIn(UID, c, Rnd.GetUniDev());
130        }
131      }
132    }
133  }
134  void TCoda::GetNonEdgePairScores(TFltIntIntTrV& ScoreV) {
135    ScoreV.Gen(G->GetNodes() * G->GetNodes(), 0);
136    TIntV NIDV;
137    G->GetNIdV(NIDV);
138    TIntSet Cuv;
139    for (int u = 0; u < NIDV.Len(); u++) {
140      int UID = NIDV[u];
141      for (int v = 0; v < NIDV.Len(); v++) {
142        int VID = NIDV[v];
143        if (UID == VID) { continue; }
144        if (! G->IsEdge(UID, VID)) {
145          double Val = 1.0 - Prediction(UID, VID);
146          ScoreV.Add(TFltIntIntTr(Val, UID, VID));
147        }
148      }
149    }
150  }
151  void TCoda::SetCmtyVV(const TVec<TIntV>& CmtyVVOut, const TVec<TIntV>& CmtyVVIn) {
152    IAssert(CmtyVVOut.Len() == CmtyVVIn.Len());
153    F.Gen(G->GetNodes());
154    H.Gen(G->GetNodes());
155    SumFV.Gen(CmtyVVOut.Len());
156    SumHV.Gen(CmtyVVIn.Len());
157    NumComs = CmtyVVOut.Len();
158    TIntH NIDIdxH(NIDV.Len());
159    if (! NodesOk) {
160      for (int u = 0; u < NIDV.Len(); u++) {
161        NIDIdxH.AddDat(NIDV[u], u);
162      }
163    }
164    for (int c = 0; c < CmtyVVOut.Len(); c++) {
165      for (int u = 0; u < CmtyVVOut[c].Len(); u++) {
166        int UID = CmtyVVOut[c][u];
167        if (! NodesOk) { UID = NIDIdxH.GetDat(UID); }
168        if (G->IsNode(UID)) { 
169          AddComOut(UID, c, 1.0);
170        }
171      }
172    }
173    for (int c = 0; c < CmtyVVIn.Len(); c++) {
174      for (int u = 0; u < CmtyVVIn[c].Len(); u++) {
175        int UID = CmtyVVIn[c][u];
176        if (! NodesOk) { UID = NIDIdxH.GetDat(UID); }
177        if (G->IsNode(UID)) { 
178          AddComIn(UID, c, 1.0);
179        }
180      }
181    }
182  }
183  void TCoda::SetGraph(const PNGraph& GraphPt) {
184    G = GraphPt;
185    HOVIDSV.Gen(G->GetNodes());  
186    NodesOk = true;
187    GraphPt->GetNIdV(NIDV);
188    for (int nid = 0; nid < GraphPt->GetNodes(); nid++) {
189      if (! GraphPt->IsNode(nid)) { 
190        NodesOk = false; 
191        break; 
192      } 
193    }
194    if (! NodesOk) {
195      printf("rearrage nodes\n");
196      G = TSnap::GetSubGraph(GraphPt, NIDV, true);
197      for (int nid = 0; nid < G->GetNodes(); nid++) {
198        IAssert(G->IsNode(nid)); 
199      }
200    }
201    TSnap::DelSelfEdges(G);
202    PNoCom = 1.0 / (double) G->GetNodes();
203    DoParallel = false;
204    if (1.0 / PNoCom > sqrt(TFlt::Mx)) { PNoCom = 0.99 / sqrt(TFlt::Mx); } 
205    NegWgt = 1.0;
206  }
207  double TCoda::Likelihood(const bool _DoParallel) { 
208    TExeTm ExeTm;
209    double L = 0.0;
210    if (_DoParallel) {
211    #pragma omp parallel for 
212      for (int u = 0; u < F.Len(); u++) {
213        double LU = LikelihoodForNode(true, u);
214        #pragma omp atomic
215          L += LU;
<span onclick='openModal()' class='match'>216      }
217    }
218    else {
219      for (int u = 0; u < F.Len(); u++) {
</span>220        double LU = LikelihoodForNode(true, u);
221          L += LU;
222      }
223    }
224    return L;
225  }
226  double TCoda::LikelihoodForNode(const bool IsRow, const int UID) {
227    if (IsRow) {
228      return LikelihoodForNode(IsRow, UID, F[UID]);
229    } else {
230      return LikelihoodForNode(IsRow, UID, H[UID]);
231    }
232  }
233  double TCoda::LikelihoodForNode(const bool IsRow, const int UID, const TIntFltH& FU) {
234    double L = 0.0;
235    TFltV HOSumHV; 
236    if (HOVIDSV[UID].Len() > 0) {
237      HOSumHV.Gen(NumComs);
238      for (int e = 0; e < HOVIDSV[UID].Len(); e++) {
239        for (int c = 0; c < SumHV.Len(); c++) {
240          HOSumHV[c] += GetCom(! IsRow, HOVIDSV[UID][e], c);
241        }
242      }
243    }
244    TNGraph::TNodeI NI = G->GetNI(UID);
245    const int Deg = IsRow ? NI.GetOutDeg(): NI.GetInDeg();
246    for (int e = 0; e < Deg; e++) {
247      const int v = IsRow ? NI.GetOutNId(e): NI.GetInNId(e);
248      if (v == UID) { continue; }
249      if (HOVIDSV[UID].IsKey(v)) { continue; }
250      if (IsRow) {
251        L += log (1.0 - Prediction(FU, H[v])) + NegWgt * DotProduct(FU, H[v]);
252      } else {
253        L += log (1.0 - Prediction(F[v], FU)) + NegWgt * DotProduct(F[v], FU);
254      }
255    }
256    for (TIntFltH::TIter HI = FU.BegI(); HI < FU.EndI(); HI++) {
257      double HOSum = HOVIDSV[UID].Len() > 0?  HOSumHV[HI.GetKey()].Val: 0.0;
258      L -= NegWgt * (GetSumVal(! IsRow, HI.GetKey()) - HOSum - GetCom(! IsRow, UID, HI.GetKey())) * HI.GetDat();
259    }
260    if (RegCoef > 0.0) { 
261      L -= RegCoef * Sum(FU);
262    }
263    if (RegCoef < 0.0) { 
264      L += RegCoef * Norm2(FU);
265    }
266    return L;
267  }
268  void TCoda::GradientForNode(const bool IsRow, const int UID, TIntFltH& GradU, const TIntSet& CIDSet) {
269    GradU.Gen(CIDSet.Len());
270    TFltV HOSumHV; 
271    if (HOVIDSV[UID].Len() > 0) {
272      HOSumHV.Gen(NumComs);
273      for (int e = 0; e < HOVIDSV[UID].Len(); e++) {
274        for (int c = 0; c < SumHV.Len(); c++) {
275          HOSumHV[c] += GetCom(! IsRow, HOVIDSV[UID][e], c);
276        }
277      }
278    }
279    TNGraph::TNodeI NI = G->GetNI(UID);
280    int Deg = IsRow ? NI.GetOutDeg(): NI.GetInDeg();
281    TFltV PredV(Deg), GradV(CIDSet.Len());
282    TIntV CIDV(CIDSet.Len());
283    for (int e = 0; e < Deg; e++) {
284      int VID = IsRow? NI.GetOutNId(e): NI.GetInNId(e);
285      if (VID == UID) { continue; }
286      if (HOVIDSV[UID].IsKey(VID)) { continue; }
287      PredV[e] = IsRow? Prediction(UID, VID): Prediction(VID, UID);
288    }
289    for (int c = 0; c < CIDSet.Len(); c++) {
290      int CID = CIDSet.GetKey(c);
291      double Val = 0.0;
292      for (int e = 0; e < Deg; e++) {
293        int VID = IsRow? NI.GetOutNId(e): NI.GetInNId(e);
294        if (VID == UID) { continue; }
295        if (HOVIDSV[UID].IsKey(VID)) { continue; }
296        Val += PredV[e] * GetCom(! IsRow, VID, CID) / (1.0 - PredV[e]) + NegWgt * GetCom(! IsRow, VID, CID);
297      }
298      double HOSum = HOVIDSV[UID].Len() > 0?  HOSumHV[CID].Val: 0.0;
299      Val -= NegWgt * (GetSumVal(! IsRow, CID) - HOSum - GetCom(! IsRow, UID, CID));
300      CIDV[c] = CID;
301      GradV[c] = Val;
302    }
303    if (RegCoef > 0.0) { 
304      for (int c = 0; c < GradV.Len(); c++) {
305        GradV[c] -= RegCoef; 
306      }
307    }
308    if (RegCoef < 0.0) { 
309      for (int c = 0; c < GradV.Len(); c++) {
310        GradV[c] += 2 * RegCoef * GetCom(IsRow, UID, CIDV[c]); 
311      }
312    }
313    for (int c = 0; c < GradV.Len(); c++) {
314      if (GetCom(IsRow, UID, CIDV[c]) == 0.0 && GradV[c] < 0.0) { continue; }
315      if (fabs(GradV[c]) < 0.0001) { continue; }
316      GradU.AddDat(CIDV[c], GradV[c]);
317    }
318    for (int c = 0; c < GradU.Len(); c++) {
319      if (GradU[c] >= 10) { GradU[c] = 10; }
320      if (GradU[c] <= -10) { GradU[c] = -10; }
321      IAssert(GradU[c] >= -10);
322    }
323  }
324  void TCoda::GetCmtyVV(const bool IsOut, TVec<TIntV>& CmtyVV) {
325    GetCmtyVV(IsOut, CmtyVV, sqrt(1.0 / G->GetNodes()), 3);
326  }
327  void TCoda::GetCommunity(TIntV& CmtyVIn, TIntV& CmtyVOut, const int CID, const double Thres) {
328    TIntFltH NIDFucH(F.Len() / 10), NIDHucH(F.Len() / 10);
329    for (int u = 0; u < NIDV.Len(); u++) {
330      int NID = u;
331      if (! NodesOk) { NID = NIDV[u]; }
332      if (GetCom(true, u, CID) >= Thres) { NIDFucH.AddDat(NID, GetCom(true, u, CID)); }
333      if (GetCom(false, u, CID) >= Thres) { NIDHucH.AddDat(NID, GetCom(false, u, CID)); }
334    }
335    NIDFucH.SortByDat(false);
336    NIDHucH.SortByDat(false);
337    NIDFucH.GetKeyV(CmtyVOut);
338    NIDHucH.GetKeyV(CmtyVIn);
339  }
340  void TCoda::GetTopCIDs(TIntV& CIdV, const int TopK, const int IsAverage, const int MinSz) {
341    TIntFltH CIdFHH;
342    for (int c = 0; c < GetNumComs(); c++) {
343      if (IsAverage == 1) {
344        TIntV CmtyVIn, CmtyVOut;
345        GetCommunity(CmtyVIn, CmtyVOut, c);
346        if (CmtyVIn.Len() == 0 || CmtyVOut.Len() == 0) { continue; }
347        if (CmtyVIn.Len() < MinSz || CmtyVOut.Len() < MinSz) { continue; }
348        CIdFHH.AddDat(c, GetSumVal(true, c) * GetSumVal(false, c) / (double) CmtyVIn.Len() / (double) CmtyVOut.Len());
349      } else {
350        CIdFHH.AddDat(c, GetSumVal(true, c) * GetSumVal(false, c));
351      }
352    }
353    CIdFHH.SortByDat(false);
354    CIdFHH.GetKeyV(CIdV);
355    if (TopK < CIdFHH.Len()) { CIdV.Trunc(TopK); }
356  }
357  void TCoda::GetCmtyVV(const bool IsOut, TVec<TIntV>& CmtyVV, const double Thres, const int MinSz) {
358    CmtyVV.Gen(NumComs, 0);
359    TIntFltH CIDSumFH(NumComs);
360    for (int c = 0; c < NumComs; c++) {
361      CIDSumFH.AddDat(c, GetSumVal(IsOut, c));
362    }
363    CIDSumFH.SortByDat(false);
364    for (int c = 0; c < NumComs; c++) {
365      int CID = CIDSumFH.GetKey(c);
366      TIntFltH NIDFucH, NIDHucH, NIDInOutH;
367      TIntV CmtyV;
368      GetNIDValH(NIDInOutH, NIDFucH, NIDHucH, CID, Thres);
369      if (IsOut) {
370        NIDFucH.GetKeyV(CmtyV);
371      } else {
372        NIDHucH.GetKeyV(CmtyV);
373      }
374      if (CmtyV.Len() >= MinSz) { CmtyVV.Add(CmtyV); }
375    }
376    if ( NumComs != CmtyVV.Len()) {
377      printf("Community vector generated. %d communities are ommitted\n", NumComs.Val - CmtyVV.Len());
378    }
379  }
380  void TCoda::GetCmtyVVUnSorted(const bool IsOut, TVec<TIntV>& CmtyVV, const double Thres, const int MinSz) {
381    CmtyVV.Gen(NumComs, 0);
382    for (int c = 0; c < NumComs; c++) {
383      TIntV CmtyV((int) (GetSumVal(IsOut, c) * 10), 0);
384      for (int u = 0; u < G->GetNodes(); u++) {
385        if (GetCom(IsOut, u, c) > Thres) { CmtyV.Add(NIDV[u]); }
386      }
387      if (CmtyV.Len() >= MinSz) { CmtyVV.Add(CmtyV); }
388    }
389    if ( NumComs != CmtyVV.Len()) {
390      printf("Community vector generated. %d communities are ommitted\n", NumComs.Val - CmtyVV.Len());
391    }
392  }
393  PNGraph TCoda::GetGraphRawNID() {
394    PNGraph NewG = TNGraph::New(G->GetNodes(), -1);
395    for (TNGraph::TNodeI NI = G->BegNI(); NI < G->EndNI(); NI++) {
396      int NIdx = NI.GetId();
397      int NID = NIDV[NIdx];
398      if (! NewG->IsNode(NID)) { NewG->AddNode(NID); }
399      for (int e = 0; e < NI.GetOutDeg(); e++) {
400        int OutNID = NIDV[NI.GetOutNId(e)];
401        if (! NewG->IsNode(OutNID)) { NewG->AddNode(OutNID); }
402        NewG->AddEdge(NID, OutNID);
403      }
404    }
405    IAssert(G->GetNodes() == NewG->GetNodes());
406    IAssert(G->GetEdges() == NewG->GetEdges());
407    return NewG;
408  }
409  void TCoda::GetNIDValH(TIntFltH& NIdValInOutH, TIntFltH& NIdValOutH, TIntFltH& NIdValInH, const int CID, const double Thres) {
410    NIdValOutH.Gen((int) GetSumVal(true, CID) + 1);
411    NIdValInH.Gen((int) GetSumVal(false, CID) + 1);
412    NIdValInOutH.Gen((int) GetSumVal(false, CID) + 1);
413    if (GetSumVal(true, CID) < Thres && GetSumVal(false, CID) < Thres) { return; }
414    for (int u = 0; u < NIDV.Len(); u++) {
415      if (GetCom(true, u, CID) >= Thres && GetCom(false, u, CID) >= Thres) {
416        NIdValInOutH.AddDat(NIDV[u], GetCom(true, u, CID) + GetCom(false, u, CID));
417      }
418      if (GetCom(true, u, CID) >= Thres) {
419        NIdValOutH.AddDat(NIDV[u], GetCom(true, u, CID));
420      }
421      if (GetCom(false, u, CID) >= Thres) {
422        NIdValInH.AddDat(NIDV[u], GetCom(false, u, CID));
423      }
424    }
425    NIdValInH.SortByDat(false);
426    NIdValOutH.SortByDat(false);
427    NIdValInOutH.SortByDat(false);
428  }
429  void TCoda::DumpMemberships(const TStr& OutFNm, const TStrHash<TInt>& NodeNameH, const double Thres) {
430    if (NodeNameH.Len() > 0) { IAssert(NodeNameH.Len() == G->GetNodes()); }
431    FILE* FId = fopen(OutFNm.CStr(), "wt");
432    TIntFltH CIDSumFH(NumComs);
433    for (int c = 0; c < NumComs; c++) {
434      CIDSumFH.AddDat(c, GetSumVal(true, c) * GetSumVal(false, c));
435    }
436    CIDSumFH.SortByDat(false);
437    for (int c = 0; c < NumComs; c++) {
438      int CID = CIDSumFH.GetKey(c);
439      TIntFltH NIDOutFH, NIDInFH, NIDInOutFH;
440      GetNIDValH(NIDInOutFH, NIDOutFH, NIDInFH, CID, Thres);
441      if (NIDOutFH.Len() == 0 || NIDInFH.Len() == 0) { continue; }
442      fprintf(FId, "%d\t%d\t%d\t%f\t%f\t%f\t", NIDInOutFH.Len(), NIDInFH.Len() - NIDInOutFH.Len(), NIDOutFH.Len() - NIDInOutFH.Len(), CIDSumFH.GetDat(CID).Val, GetSumVal(false, CID).Val, GetSumVal(true, CID).Val);
443      fprintf(FId, "InOut:\t");
444      for (int u = 0; u < NIDInOutFH.Len(); u++) {
445        int NIdx = NIDInOutFH.GetKey(u);
446        fprintf(FId, "%s (%f)\t", NodeNameH.GetKey(NIdx), NIDInOutFH[u].Val);
447      }
448      fprintf(FId, "In:\t");
449      for (int u = 0; u < NIDInFH.Len(); u++) {
450        int NIdx = NIDInFH.GetKey(u);
451        fprintf(FId, "%s (%f)\t", NodeNameH.GetKey(NIdx), NIDInFH[u].Val);
452      }
453      fprintf(FId, "Out:\t");
454      for (int u = 0; u < NIDOutFH.Len(); u++) {
455        int NIdx = NIDOutFH.GetKey(u);
456        fprintf(FId, "%s (%f)\t", NodeNameH.GetKey(NIdx), NIDOutFH[u].Val);
457      }
458      fprintf(FId, "\n");
459    }
460    fclose(FId);
461  }
462  void TCoda::DumpMemberships(const TStr& OutFNm, const double Thres) {
463    TStrHash<TInt> NodeNameH(G->GetNodes(), false);
464    for (int u = 0; u < NIDV.Len(); u++) { NodeNameH.AddKey(TStr::Fmt("%d", NIDV[u].Val)); }
465    DumpMemberships(OutFNm, NodeNameH, Thres);
466  }
467  void TCoda::GetCmtyS(TIntSet& CmtySOut, TIntSet& CmtySIn, const int CID, const double Thres) {
468    CmtySOut.Gen(G->GetNodes() / 10);
469    CmtySIn.Gen(G->GetNodes() / 10);
470    for (int u = 0; u < NIDV.Len(); u++) {
471      if (GetCom(true, u, CID) > Thres) {
472      }
473    }
474  }
475  void TCoda::GetCmtyVV(TVec<TIntV>& CmtyVVOut, TVec<TIntV>& CmtyVVIn, const int MinSz) {
476    GetCmtyVV(false, CmtyVVIn, sqrt(1.0 / G->GetNodes()), MinSz);
477    GetCmtyVV(true, CmtyVVOut, sqrt(1.0 / G->GetNodes()), MinSz);
478  }
479  void TCoda::GetCmtyVVUnSorted(TVec<TIntV>& CmtyVVOut, TVec<TIntV>& CmtyVVIn) {
480    GetCmtyVVUnSorted(false, CmtyVVIn, sqrt(1.0 / G->GetNodes()));
481    GetCmtyVVUnSorted(true, CmtyVVOut, sqrt(1.0 / G->GetNodes()));
482  }
483  void TCoda::GetCmtyVV(TVec<TIntV>& CmtyVVOut, TVec<TIntV>& CmtyVVIn, const double ThresOut, const double ThresIn, const int MinSz) {
484    GetCmtyVV(false, CmtyVVIn, ThresIn, MinSz);
485    GetCmtyVV(true, CmtyVVOut, ThresOut, MinSz);
486  }
487  int TCoda::FindComsByCV(const int NumThreads, const int MaxComs, const int MinComs, const int DivComs, const TStr OutFNm, const int EdgesForCV, const double StepAlpha, const double StepBeta) {
488      double ComsGap = exp(TMath::Log((double) MaxComs / (double) MinComs) / (double) DivComs);
489      TIntV ComsV;
490      ComsV.Add(MinComs);
491      while (ComsV.Len() < DivComs) {
492        int NewComs = int(ComsV.Last() * ComsGap);
493        if (NewComs == ComsV.Last().Val) { NewComs++; }
494        ComsV.Add(NewComs);
495      }
496      if (ComsV.Last() < MaxComs) { ComsV.Add(MaxComs); }
497      return FindComsByCV(ComsV, 0.1, NumThreads, OutFNm, EdgesForCV, StepAlpha, StepBeta);
498  }
499  int TCoda::FindComsByCV(TIntV& ComsV, const double HOFrac, const int NumThreads, const TStr PlotLFNm, const int EdgesForCV, const double StepAlpha, const double StepBeta) {
500    if (ComsV.Len() == 0) {
501      int MaxComs = G->GetNodes() / 5;
502      ComsV.Add(2);
503      while(ComsV.Last() < MaxComs) { ComsV.Add(ComsV.Last() * 2); }
504    }
505    int MaxIterCV = 3;
506    TVec<TVec<TIntSet> > HoldOutSets(MaxIterCV);
507    TFltIntPrV NIdPhiV;
508    TAGMFastUtil::GetNIdPhiV<PNGraph>(G, NIdPhiV);
509    if (G->GetEdges() > EdgesForCV) { 
510      printf("generating hold out set\n");
511      TIntV NIdV1, NIdV2;
512      G->GetNIdV(NIdV1);
513      G->GetNIdV(NIdV2);
514      for (int IterCV = 0; IterCV < MaxIterCV; IterCV++) {
515        TAGMFastUtil::GenHoldOutPairs(G, HoldOutSets[IterCV], HOFrac, Rnd);
516      }
517      printf("hold out set generated\n");
518    }
519    TFltV HOLV(ComsV.Len());
520    TIntFltPrV ComsLV;
521    for (int c = 0; c < ComsV.Len(); c++) {
522      const int Coms = ComsV[c];
523      printf("Try number of Coms:%d\n", Coms);
524      if (G->GetEdges() > EdgesForCV) { 
525        for (int IterCV = 0; IterCV < MaxIterCV; IterCV++) {
526          HOVIDSV = HoldOutSets[IterCV];
527          NeighborComInit(NIdPhiV, Coms);
528          printf("Initialized\n");
529          if (NumThreads == 1) {
530            printf("MLE without parallelization begins\n");
531            MLEGradAscent(0.05, 10 * G->GetNodes(), "", StepAlpha, StepBeta);
532          } else {
533            printf("MLE with parallelization begins\n");
534            MLEGradAscentParallel(0.05, 100, NumThreads, "", StepAlpha, StepBeta);
535          }
536          double HOL = LikelihoodHoldOut();
537          HOL = HOL < 0? HOL: TFlt::Mn;
538          HOLV[c] += HOL;
539        }
540      }
541      else {
542        HOVIDSV.Gen(G->GetNodes());
543        MLEGradAscent(0.0001, 100 * G->GetNodes(), "");
544        double BIC = 2 * Likelihood() - (double) G->GetNodes() * Coms * 2.0 * log ( (double) G->GetNodes());
545        HOLV[c] = BIC;
546      }
547    }
548    int EstComs = 2;
549    double MaxL = TFlt::Mn;
550    printf("\n");
551    for (int c = 0; c < ComsV.Len(); c++) {
552      ComsLV.Add(TIntFltPr(ComsV[c].Val, HOLV[c].Val));
553      printf("%d(%f)\t", ComsV[c].Val, HOLV[c].Val);
554      if (MaxL < HOLV[c]) {
555        MaxL = HOLV[c];
556        EstComs = ComsV[c];
557      }
558    }
559    printf("\n");
560    RandomInit(EstComs);
561    HOVIDSV.Gen(G->GetNodes());
562    if (! PlotLFNm.Empty()) {
563      TGnuPlot::PlotValV(ComsLV, PlotLFNm, "hold-out likelihood", "communities", "likelihood");
564    }
565    return EstComs;
566  }
567  double TCoda::LikelihoodHoldOut(const bool DoParallel) { 
568    double L = 0.0;
569    for (int u = 0; u < HOVIDSV.Len(); u++) {
570      for (int e = 0; e < HOVIDSV[u].Len(); e++) {
571        int VID = HOVIDSV[u][e];
572        if (VID == u) { continue; } 
573        double Pred = Prediction(u, VID);
574        if (G->IsEdge(u, VID)) {
575          L += log(1.0 - Pred);
576        }
577        else {
578          L += NegWgt * log(Pred);
579        }
580      }
581    }
582    return L;
583  }
584  double TCoda::GetStepSizeByLineSearch(const bool IsRow, const int UID, const TIntFltH& DeltaV, const TIntFltH& GradV, const double& Alpha, const double& Beta, const int MaxIter) {
585    double StepSize = 1.0;
586    double InitLikelihood = LikelihoodForNode(IsRow, UID);
587    TIntFltH NewVarV(DeltaV.Len());
588    for(int iter = 0; iter < MaxIter; iter++) {
589      for (int i = 0; i < DeltaV.Len(); i++){
590        int CID = DeltaV.GetKey(i);
591        double NewVal;
592        NewVal = GetCom(IsRow, UID, CID) + StepSize * DeltaV.GetDat(CID);
593        if (NewVal < MinVal) { NewVal = MinVal; }
594        if (NewVal > MaxVal) { NewVal = MaxVal; }
595        NewVarV.AddDat(CID, NewVal);
596      }
597      if (LikelihoodForNode(IsRow, UID, NewVarV) < InitLikelihood + Alpha * StepSize * DotProduct(GradV, DeltaV)) {
598        StepSize *= Beta;
599      } else {
600        break;
601      }
602      if (iter == MaxIter - 1) { 
603        StepSize = 0.0;
604        break;
605      }
606    }
607    return StepSize;
608  }
609  int TCoda::MLEGradAscent(const double& Thres, const int& MaxIter, const TStr PlotNm, const double StepAlpha, const double StepBeta) {
610    time_t InitTime = time(NULL);
611    TExeTm ExeTm, CheckTm;
612    int iter = 0, PrevIter = 0;
613    TIntFltPrV IterLV;
614    TNGraph::TNodeI UI;
615    double PrevL = TFlt::Mn, CurL = 0.0;
616    TIntV NIdxV(F.Len(), 0);
617    for (int i = 0; i < F.Len(); i++) { NIdxV.Add(i); }
618    IAssert(NIdxV.Len() == F.Len());
619    TIntFltH GradV;
620    while(iter < MaxIter) {
621      NIdxV.Shuffle(Rnd);
622      for (int ui = 0; ui < F.Len(); ui++, iter++) {
623        const bool IsRow = (ui % 2 == 0);
624        int u = NIdxV[ui]; 
625        UI = G->GetNI(u);
626        const int Deg = IsRow? UI.GetOutDeg(): UI.GetInDeg();
627        TIntSet CIDSet(5 * Deg);
628        for (int e = 0; e < Deg; e++) {
629          int VID = IsRow? UI.GetOutNId(e): UI.GetInNId(e);
630          if (HOVIDSV[u].IsKey(VID)) { continue; }
631          TIntFltH NbhCIDH = IsRow? H[VID]: F[VID];
632          for (TIntFltH::TIter CI = NbhCIDH.BegI(); CI < NbhCIDH.EndI(); CI++) {
633            CIDSet.AddKey(CI.GetKey());
634            IAssert(CI.GetKey() <= NumComs);
635          }
636        }
637        TIntFltH& CurMem = IsRow? F[u]: H[u];
638        for (TIntFltH::TIter CI = CurMem.BegI(); CI < CurMem.EndI(); CI++) { 
639          if (! CIDSet.IsKey(CI.GetKey())) {
640            DelCom(IsRow, u, CI.GetKey());
641          }
642        }
643        if (CIDSet.Empty()) { continue; }
644        GradientForNode(IsRow, u, GradV, CIDSet);
645        if (Norm2(GradV) < 1e-4) { continue; }
646        double LearnRate = GetStepSizeByLineSearch(IsRow, u, GradV, GradV, StepAlpha, StepBeta);
647        if (LearnRate == 0.0) { continue; }
648        for (int ci = 0; ci < GradV.Len(); ci++) {
649          int CID = GradV.GetKey(ci);
650          double Change = LearnRate * GradV.GetDat(CID);
651          double NewFuc = GetCom(IsRow, u, CID) + Change;
652          if (NewFuc <= 0.0) {
653            DelCom(IsRow, u, CID);
654          } else {
655            AddCom(IsRow, u, CID, NewFuc);
656          }
657        }
658        if (! PlotNm.Empty() && (iter + 1) % G->GetNodes() == 0) {
659          IterLV.Add(TIntFltPr(iter, Likelihood(false)));
660        }
661      }
662      printf("\r%d iterations (%f) [%lu sec]", iter, CurL, time(NULL) - InitTime);
663      fflush(stdout);
664      if (iter - PrevIter >= 2 * G->GetNodes() && iter > 10000) {
665        PrevIter = iter;
666        CurL = Likelihood();
667        if (PrevL > TFlt::Mn && ! PlotNm.Empty()) {
668          printf("\r%d iterations, Likelihood: %f, Diff: %f", iter, CurL,  CurL - PrevL);
669        }
670        fflush(stdout);
671        if (CurL - PrevL <= Thres * fabs(PrevL)) { break; }
672        else { PrevL = CurL; }
673      }
674    }
675    printf("\n");
676    printf("MLE for Lambda completed with %d iterations(%s)\n", iter, ExeTm.GetTmStr());
677    if (! PlotNm.Empty()) {
678      TGnuPlot::PlotValV(IterLV, PlotNm + ".likelihood_Q");
679    }
680    return iter;
681  }
682  int TCoda::MLEGradAscentParallel(const double& Thres, const int& MaxIter, const int ChunkNum, const int ChunkSize, const TStr PlotNm, const double StepAlpha, const double StepBeta) {
683    time_t InitTime = time(NULL);
684    TExeTm ExeTm, CheckTm;
685    double PrevL = Likelihood(true);
686    TIntFltPrV IterLV;
687    int PrevIter = 0;
688    int iter = 0;
689    TIntV NIdxV(F.Len(), 0);
690    for (int i = 0; i < F.Len(); i++) { NIdxV.Add(i); }
691    TIntV NIDOPTV(F.Len()); 
692    NIDOPTV.PutAll(0);
693    TVec<TIntFltH> NewF(ChunkNum * ChunkSize);
694    TIntV NewNIDV(ChunkNum * ChunkSize);
695    TBoolV IsRowV(ChunkNum * ChunkSize);
696    for (iter = 0; iter < MaxIter; iter++) {
697      NIdxV.Clr(false);
698      for (int i = 0; i < F.Len(); i++) { 
699        NIdxV.Add(i);
700      }
701      IAssert (NIdxV.Len() <= F.Len());
702      NIdxV.Shuffle(Rnd);
703  #pragma omp parallel for schedule(static, 1)
704      for (int TIdx = 0; TIdx < ChunkNum; TIdx++) {
705        TIntFltH GradV;
706        for (int ui = TIdx * ChunkSize; ui < (TIdx + 1) * ChunkSize; ui++) {
707          const bool IsRow = (ui % 2 == 0);
708          NewNIDV[ui] = -1;
709          if (ui > NIdxV.Len()) { continue; }
710          const int u = NIdxV[ui]; 
711          TNGraph::TNodeI UI = G->GetNI(u);
712          const int Deg = IsRow? UI.GetOutDeg(): UI.GetInDeg();
713          TIntSet CIDSet(5 * Deg);
714          TIntFltH CurFU = IsRow? F[u]: H[u];
715          for (int e = 0; e < Deg; e++) {
716            int VID = IsRow? UI.GetOutNId(e): UI.GetInNId(e);
717            if (HOVIDSV[u].IsKey(VID)) { continue; }
718            TIntFltH& NbhCIDH = IsRow? H[VID]: F[VID];
719            for (TIntFltH::TIter CI = NbhCIDH.BegI(); CI < NbhCIDH.EndI(); CI++) {
720              CIDSet.AddKey(CI.GetKey());
721            }
722          }
723          if (CIDSet.Empty()) { 
724            CurFU.Clr();
725          }
726          else {
727            for (TIntFltH::TIter CI = CurFU.BegI(); CI < CurFU.EndI(); CI++) { 
728              if (! CIDSet.IsKey(CI.GetKey())) {
729                CurFU.DelIfKey(CI.GetKey());
730              }
731            }
732            GradientForNode(IsRow, u, GradV, CIDSet);
733            if (Norm2(GradV) < 1e-4) { NIDOPTV[u] = 1; continue; }
734            double LearnRate = GetStepSizeByLineSearch(IsRow, u, GradV, GradV, StepAlpha, StepBeta);
735            if (LearnRate == 0.0) { NewNIDV[ui] = -2; continue; }
736            for (int ci = 0; ci < GradV.Len(); ci++) {
737              int CID = GradV.GetKey(ci);
738              double Change = LearnRate * GradV.GetDat(CID);
739              double NewFuc = CurFU.IsKey(CID)? CurFU.GetDat(CID) + Change : Change;
740              if (NewFuc <= 0.0) {
741                CurFU.DelIfKey(CID);
742              } else {
743                CurFU.AddDat(CID) = NewFuc;
744              }
745            }
746            CurFU.Defrag();
747          }
748          NewF[ui] = CurFU;
749          NewNIDV[ui] = u;
750          IsRowV[ui] = IsRow;
751        }
752      }
753      int NumNoChangeGrad = 0;
754      int NumNoChangeStepSize = 0;
755      for (int ui = 0; ui < NewNIDV.Len(); ui++) {
756        int NewNID = NewNIDV[ui];
757        if (NewNID == -1) { NumNoChangeGrad++; continue; }
758        if (NewNID == -2) { NumNoChangeStepSize++; continue; }
759        if (IsRowV[ui]) {
760          for (TIntFltH::TIter CI = F[NewNID].BegI(); CI < F[NewNID].EndI(); CI++) {
761            SumFV[CI.GetKey()] -= CI.GetDat();
762          }
763        } else {
764          for (TIntFltH::TIter CI = H[NewNID].BegI(); CI < H[NewNID].EndI(); CI++) {
765            SumHV[CI.GetKey()] -= CI.GetDat();
766          }
767        }
768      }
769  #pragma omp parallel for
770      for (int ui = 0; ui < NewNIDV.Len(); ui++) {
771        int NewNID = NewNIDV[ui];
772        if (NewNID < 0) { continue; }
773        if (IsRowV[ui]) {
774          F[NewNID] = NewF[ui];
775        } else {
776          H[NewNID] = NewF[ui];
777        }
778      }
779      for (int ui = 0; ui < NewNIDV.Len(); ui++) {
780        int NewNID = NewNIDV[ui];
781        if (NewNID < 0) { continue; }
782        if (IsRowV[ui]) {
783          for (TIntFltH::TIter CI = F[NewNID].BegI(); CI < F[NewNID].EndI(); CI++) {
784            SumFV[CI.GetKey()] += CI.GetDat();
785          }
786        } else {
787          for (TIntFltH::TIter CI = H[NewNID].BegI(); CI < H[NewNID].EndI(); CI++) {
788            SumHV[CI.GetKey()] += CI.GetDat();
789          }
790        }
791      }
792      for (int ui = 0; ui < NewNIDV.Len(); ui++) {
793        int NewNID = NewNIDV[ui];
794        if (NewNID < 0) { continue; }
795        TNGraph::TNodeI UI = G->GetNI(NewNID);
796        NIDOPTV[NewNID] = 0;
797        for (int e = 0; e < UI.GetDeg(); e++) {
798          NIDOPTV[UI.GetNbrNId(e)] = 0;
799        }
800      }
801      int OPTCnt = 0;
802      for (int i = 0; i < NIDOPTV.Len(); i++) { if (NIDOPTV[i] == 1) { OPTCnt++; } }
803      if ((iter - PrevIter) * ChunkSize * ChunkNum >= G->GetNodes()) {
804        PrevIter = iter;
805        double CurL = Likelihood(true);
806        IterLV.Add(TIntFltPr(iter * ChunkSize * ChunkNum, CurL));
807        printf("\r%d iterations, Likelihood: %f, Diff: %f [%lu secs]", iter, CurL,  CurL - PrevL, time(NULL) - InitTime);
808         fflush(stdout);
809        if (CurL - PrevL <= Thres * fabs(PrevL)) { 
810          break;
811        }
812        else {
813          PrevL = CurL;
814        }
815      }
816    }
817    if (! PlotNm.Empty()) {
818      printf("\nMLE completed with %d iterations(%lu secs)\n", iter, time(NULL) - InitTime);
819      TGnuPlot::PlotValV(IterLV, PlotNm + ".likelihood_Q");
820    } else {
821      printf("\rMLE completed with %d iterations(%lu secs)\n", iter, time(NULL) - InitTime);
822      fflush(stdout);
823    }
824    return iter;
825  }
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-eval_detection_layer.cpp</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from snap-MDEwOlJlcG9zaXRvcnk0Mjg4MzU3-flat-agmdirected.cpp</div>
                </div>
                <div class="column column_space"><pre><code>184              }
185          }
186          else {
187              for (std::map<int, vector<BoxData> >::iterator it = pred_boxes->begin(); it != pred_boxes->end(); ++it) {
</pre></code></div>
                <div class="column column_space"><pre><code>216      }
217    }
218    else {
219      for (int u = 0; u < F.Len(); u++) {
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    