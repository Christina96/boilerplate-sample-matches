
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 36, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-mkl_batch_norm_layer.cpp</h3>
            <pre><code>1  #if defined(MKL2017_SUPPORTED)
2  #include <vector>
3  #include "caffe/filler.hpp"
4  #include "caffe/layer.hpp"
5  #include "caffe/layers/mkl_layers.hpp"
6  #include "caffe/util/math_functions.hpp"
7  #include "caffe/util/performance.hpp"
8  namespace caffe {
9  template <typename Dtype>
10  MKLBatchNormLayer<Dtype>::~MKLBatchNormLayer() {
11    dnnDelete<Dtype>(batchNormFwd);
12    dnnDelete<Dtype>(batchNormFwdInference);
13    dnnDelete<Dtype>(batchNormBwd);
14    dnnLayoutDelete<Dtype>(layout_usr_);
15    for (int i = 0; i < mean_buffers_.size(); i++) {
16      dnnReleaseBuffer<Dtype>(mean_buffers_[i]);
17    }
18    for (int i = 0; i < variance_buffers_.size(); i++) {
19      dnnReleaseBuffer<Dtype>(variance_buffers_[i]);
20    }
21    dnnReleaseBuffer<Dtype>(scaleShift_buffer_);
22    dnnReleaseBuffer<Dtype>(diffScaleShift_buffer_);
23  }
24  template <typename Dtype>
25  void MKLBatchNormLayer<Dtype>::Init(const vector<Blob<Dtype>*>& bottom,
26        const vector<Blob<Dtype>*>& top) {
27    moving_average_fraction_ =
28                  this->layer_param_.batch_norm_param().moving_average_fraction();
29    eps_ = this->layer_param_.batch_norm_param().eps();
30    use_weight_bias_ = this->layer_param_.batch_norm_param().use_weight_bias();
31    bias_term_ = this->layer_param_.batch_norm_param().bias_term();
<span onclick='openModal()' class='match'>32    use_global_stats_ = this->phase_ == TEST;
33    if (this->layer_param_.batch_norm_param().has_use_global_stats())
34      use_global_stats_ = this->layer_param_.batch_norm_param().use_global_stats();
35    num_stats_batches_ = 1;
</span>36    stats_batch_size_ = bottom[0]->shape(0);
37    BatchNormParameter param = this->layer_param_.batch_norm_param();
38    if (!use_global_stats_ && param.stats_batch_size() > 0) {
39      CHECK_EQ(bottom[0]->shape(0) % param.stats_batch_size(), 0);
40      num_stats_batches_ = bottom[0]->shape(0) / param.stats_batch_size();
41      stats_batch_size_ = param.stats_batch_size();
42    }
43    CHECK(use_weight_bias_) << "BatchNorm without scaling have not supported yet";
44    size_t dim = 4, sizes[4], strides[4];
45    channels_ = bottom[0]->channels();
46    height_   = bottom[0]->height();
47    width_    = bottom[0]->width();
48    num_      = bottom[0]->num();
49    sizes[0] = width_;
50    sizes[1] = height_;
51    sizes[2] = channels_;
52    sizes[3] = num_;
53    strides[0] = 1;
54    strides[1] = sizes[0];
55    strides[2] = sizes[0]*sizes[1];
56    strides[3] = sizes[0]*sizes[1]*sizes[2];
57    fwd_bottom_data->name = "fwd_bottom_data   @ " + this->layer_param_.name();
58    fwd_top_data->name =    "fwd_top_data      @ " + this->layer_param_.name();
59    bwd_bottom_diff->name = "bwd_bottom_diff   @ " + this->layer_param_.name();
60    bwd_top_diff->name =    "bwd_top_diff      @ " + this->layer_param_.name();
61    fwd_bottom_data->create_user_layout(dim, sizes, strides, false);
62    fwd_top_data   ->create_user_layout(dim, sizes, strides, false);
63    bwd_bottom_diff->create_user_layout(dim, sizes, strides, false);
64    bwd_top_diff   ->create_user_layout(dim, sizes, strides, false);
65    sizes[3] /= num_stats_batches_;
66    dnnError_t e;
67    dnnLayoutDelete<Dtype>(layout_usr_);
68    e = dnnLayoutCreate<Dtype>(&layout_usr_, dim, sizes, strides);
69    CHECK_EQ(e, E_SUCCESS);
70    for (int i = 0; i < mean_buffers_.size(); i++) {
71      dnnReleaseBuffer<Dtype>(mean_buffers_[i]);
72    }
73    for (int i = 0; i < variance_buffers_.size(); i++) {
74      dnnReleaseBuffer<Dtype>(variance_buffers_[i]);
75    }
76    mean_buffers_.resize(num_stats_batches_, NULL);
77    variance_buffers_.resize(num_stats_batches_, NULL);
78    dnnReleaseBuffer<Dtype>(scaleShift_buffer_);
79    dnnReleaseBuffer<Dtype>(diffScaleShift_buffer_);
80    dnnDelete<Dtype>(batchNormFwd);
81    dnnDelete<Dtype>(batchNormFwdInference);
82    dnnDelete<Dtype>(batchNormBwd);
83    this->blobs_.resize(3);
84    if (use_weight_bias_) {
85      if ( bias_term_ ) {
86          this->blobs_.resize(5);
87      } else {
88          this->blobs_.resize(4);
89      }
90      vector<int> scaleshift_shape(1);
91      scaleshift_shape[0] = channels_;
92      this->blobs_[3].reset(new Blob<Dtype>(scaleshift_shape));
93      FillerParameter filler_param(
94        this->layer_param_.batch_norm_param().filler());
95      if (!this->layer_param_.batch_norm_param().has_filler()) {
96        filler_param.set_type("constant");
97        filler_param.set_value(1);
98      }
99      shared_ptr<Filler<Dtype> > filler(GetFiller<Dtype>(filler_param));
100      filler->Fill(this->blobs_[3].get());
101      if ( bias_term_ ) {
102        this->blobs_[4].reset(new Blob<Dtype>(scaleshift_shape));
103        FillerParameter bias_filler_param(
104          this->layer_param_.batch_norm_param().bias_filler());
105        if (!this->layer_param_.batch_norm_param().has_bias_filler()) {
106          bias_filler_param.set_type("constant");
107          bias_filler_param.set_value(0);
108        }
109        shared_ptr<Filler<Dtype> > bias_filler(
110          GetFiller<Dtype>(bias_filler_param));
111        bias_filler->Fill(this->blobs_[4].get());
112      }
113    }
114    vector<int> sz;
115    sz.push_back(channels_);
116    this->blobs_[0].reset(new Blob<Dtype>(sz));
117    this->blobs_[1].reset(new Blob<Dtype>(sz));
118    sz[0]=1;
119    this->blobs_[2].reset(new Blob<Dtype>(sz));
120    for (int i = 0; i < 3; ++i) {
121      caffe_set(this->blobs_[i]->count(), Dtype(0),
122                this->blobs_[i]->mutable_cpu_data());
123    }
124    for (int i = 0; i < 3; ++i) {
125      if (this->layer_param_.param_size() == i) {
126        ParamSpec* fixed_param_spec = this->layer_param_.add_param();
127        fixed_param_spec->set_lr_mult(0.f);
128      } else {
129        CHECK_EQ(this->layer_param_.param(i).lr_mult(), 0.f)
130            << "Cannot configure batch normalization statistics as layer "
131            << "parameters.";
132      }
133    }
134  }
135  template <typename Dtype>
136  void MKLBatchNormLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
137        const vector<Blob<Dtype>*>& top) {
138    Init(bottom, top);
139  }
140  template <typename Dtype>
141  void MKLBatchNormLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
142        const vector<Blob<Dtype>*>& top) {
143    bool re_init = true;
144    if (channels_ == bottom[0]->channels() &&
145        height_ == bottom[0]->height() &&
146        width_ == bottom[0]->width()) {
147      re_init = false;
148    }
149    if (bottom[0] == top[0]) {  
150      temp_.ReshapeLike(*bottom[0]);
151    } else {
152      channels_ = bottom[0]->channels();
153      height_ = bottom[0]->height();
154      width_ = bottom[0]->width();
155      num_ = bottom[0]->num();
156      top[0]->Reshape(num_, channels_, height_, width_);
157    }
158    if (re_init == true) {
159      Init(bottom, top);
160    } else if (num_ != bottom[0]->num()) { 
161      size_t dim = 4, sizes[4], strides[4];
162      sizes[0] = width_;
163      sizes[1] = height_;
164      sizes[2] = channels_;
165      sizes[3] = num_;
166      strides[0] = 1;
167      strides[1] = sizes[0];
168      strides[2] = sizes[0]*sizes[1];
169      strides[3] = sizes[0]*sizes[1]*sizes[2];
170      fwd_bottom_data->create_user_layout(dim, sizes, strides, false);
171      fwd_top_data   ->create_user_layout(dim, sizes, strides, false);
172      bwd_bottom_diff->create_user_layout(dim, sizes, strides, false);
173      bwd_top_diff   ->create_user_layout(dim, sizes, strides, false);
174      sizes[3] /= num_stats_batches_;
175      dnnError_t e;
176      dnnLayoutDelete<Dtype>(layout_usr_);
177      e = dnnLayoutCreate<Dtype>(&layout_usr_, dim, sizes, strides);
178      CHECK_EQ(e, E_SUCCESS);
179    }
180  }
181  template <typename Dtype>
182  void MKLBatchNormLayer<Dtype>::ForwardStatsBatch_cpu(const vector<Blob<Dtype>*>& bottom,
183      const vector<Blob<Dtype>*>& top, int stats_batch_idx) {
184    long data_offset = stats_batch_idx * stats_batch_size_ * bottom[0]->count(1);
185    void* bottom_data =
186      reinterpret_cast<void *>(const_cast<Dtype*>(bottom[0]->prv_data()));
187    int is_first_pass = 0;
188    long amount_to_copy =0;
189    if (NULL != bottom_data && num_stats_batches_ == 1) {
190      amount_to_copy = bottom[0]->prv_data_count();
191      if (batchNormFwd == NULL) {
192        is_first_pass = 1;
193        CHECK((bottom[0]->get_prv_data_descriptor())->get_descr_type() ==
194          PrvMemDescr::PRV_DESCR_MKL2017);
195        shared_ptr<MKLData<Dtype> > mem_descr
196          =  boost::static_pointer_cast<MKLData<Dtype> >(
197             bottom[0]->get_prv_data_descriptor());
198        CHECK(mem_descr != NULL);
199        DLOG(INFO) << "Using layout of " << mem_descr->name
200                << " as input layout for " << this->layer_param_.name();
201        fwd_bottom_data = mem_descr;
202        dnnError_t e;
203        e = dnnBatchNormalizationCreateForward<Dtype>(
204          &batchNormFwd, NULL, mem_descr->layout_int, eps_, dnnUseScaleShift);
205        CHECK_EQ(e, E_SUCCESS);
206        e = dnnBatchNormalizationCreateForward<Dtype>(
207          &batchNormFwdInference, NULL, mem_descr->layout_int, eps_,
208                                      dnnUseScaleShift | dnnUseInputMeanVariance);
209        CHECK_EQ(e, E_SUCCESS);
210        fwd_top_data   ->create_internal_layout(batchNormFwd, dnnResourceDst);
211        bwd_top_diff   ->create_internal_layout(batchNormFwd, dnnResourceDst);
212        bwd_bottom_diff->create_internal_layout(batchNormFwd, dnnResourceSrc);
213         if (!use_global_stats_) {
214           e = dnnBatchNormalizationCreateBackward<Dtype>(
215              &batchNormBwd, NULL, mem_descr->layout_int, eps_, dnnUseScaleShift);
216           CHECK_EQ(e, E_SUCCESS);
217         } else {
218           e = dnnBatchNormalizationCreateBackward<Dtype>(
219              &batchNormBwd, NULL, mem_descr->layout_int, eps_, dnnUseScaleShift | dnnUseInputMeanVariance);
220           CHECK_EQ(e, E_SUCCESS);
221         }
222      }
223    } else {
224      DLOG(INFO) << "Using cpu_data in MKLBatchNormLayer.";
225      if (batchNormFwd == NULL) {
226        is_first_pass = 1;
227        dnnError_t e;
228        e = dnnBatchNormalizationCreateForward<Dtype>(
229          &batchNormFwd, NULL, layout_usr_, eps_, dnnUseScaleShift);
230        CHECK_EQ(e, E_SUCCESS);
231        e = dnnBatchNormalizationCreateForward<Dtype>(
232          &batchNormFwdInference, NULL, layout_usr_, eps_,
233                                      dnnUseScaleShift | dnnUseInputMeanVariance);
234        CHECK_EQ(e, E_SUCCESS);
235        if (!use_global_stats_) {
236          e = dnnBatchNormalizationCreateBackward<Dtype>(
237            &batchNormBwd, NULL, layout_usr_, eps_, dnnUseScaleShift);
238          CHECK_EQ(e, E_SUCCESS);
239        } else {
240          e = dnnBatchNormalizationCreateBackward<Dtype>(
241            &batchNormBwd, NULL, layout_usr_, eps_, dnnUseScaleShift | dnnUseInputMeanVariance);
242          CHECK_EQ(e, E_SUCCESS);
243        }
244      }
245      bottom_data =
246        reinterpret_cast<void *>(const_cast<Dtype*>(bottom[0]->cpu_data()));
247      amount_to_copy = bottom[0]->count() / num_stats_batches_;
248    }
249    if (is_first_pass == 1) {
250        dnnError_t e;
251        dnnLayout_t mean_buffer_l = NULL;
252        e = dnnLayoutCreateFromPrimitive<Dtype>(
253          &mean_buffer_l, batchNormFwd, dnnResourceMean);
254        CHECK_EQ(e, E_SUCCESS);
255        for (int i = 0; i < num_stats_batches_; i++) {
256          e = dnnAllocateBuffer<Dtype>(
257            reinterpret_cast<void**>(&mean_buffers_[i]), mean_buffer_l);
258          CHECK_EQ(e, E_SUCCESS);
259        }
260        dnnLayoutDelete<Dtype>(mean_buffer_l);
261        dnnLayout_t variance_buffer_l = NULL;
262        e = dnnLayoutCreateFromPrimitive<Dtype>(
263          &variance_buffer_l, batchNormFwd, dnnResourceVariance);
264        CHECK_EQ(e, E_SUCCESS);
265        for (int i = 0; i < num_stats_batches_; i++) {
266          e = dnnAllocateBuffer<Dtype>(
267            reinterpret_cast<void**>(&variance_buffers_[i]), variance_buffer_l);
268          CHECK_EQ(e, E_SUCCESS);
269        }
270        dnnLayoutDelete<Dtype>(variance_buffer_l);
271         dnnLayout_t diffScaleShift_buffer_l = NULL;
272        e = dnnLayoutCreateFromPrimitive<Dtype>(
273          &diffScaleShift_buffer_l, batchNormBwd, dnnResourceDiffScaleShift);
274        CHECK_EQ(e, E_SUCCESS);
275        e = dnnAllocateBuffer<Dtype>(
276          reinterpret_cast<void**>(&diffScaleShift_buffer_), diffScaleShift_buffer_l);
277        CHECK_EQ(e, E_SUCCESS);
278        dnnLayoutDelete<Dtype>(diffScaleShift_buffer_l);
279        dnnLayout_t scaleShift_buffer_l = NULL;
280        e = dnnLayoutCreateFromPrimitive<Dtype>(
281          &scaleShift_buffer_l, batchNormFwd, dnnResourceScaleShift);
282        CHECK_EQ(e, E_SUCCESS);
283        e = dnnAllocateBuffer<Dtype>(
284          reinterpret_cast<void**>(&scaleShift_buffer_), scaleShift_buffer_l);
285        CHECK_EQ(e, E_SUCCESS);
286        dnnLayoutDelete<Dtype>(scaleShift_buffer_l);
287        if (!use_weight_bias_) {
288           for (int i = 0; i < channels_; i++) {
289              scaleShift_buffer_[i] = 1.0;
290              scaleShift_buffer_[channels_ + i] = 0;
291           }
292        }
293    }
294    if (use_weight_bias_) {
295      for (int i = 0; i < channels_; i++) {
296        scaleShift_buffer_[i] = this->blobs_[3]->cpu_data()[i];
297        scaleShift_buffer_[channels_ + i] = 0;
298        if (bias_term_) {
299           scaleShift_buffer_[channels_ + i] = this->blobs_[4]->cpu_data()[i];
300        }
301      }
302    }
303    if (bottom[0] == top[0] && this->phase_ == TRAIN) {
304      caffe_copy(amount_to_copy, static_cast<Dtype*>(bottom_data) + data_offset,
305                 temp_.mutable_cpu_data() + data_offset);
306    }
307    if (use_global_stats_) {
308      const Dtype scale_factor = this->blobs_[2]->cpu_data()[0] == 0 ?
309                                 0 : 1 / this->blobs_[2]->cpu_data()[0];
310      caffe_cpu_scale(this->blobs_[0]->count(), scale_factor,
311                      this->blobs_[0]->cpu_data(), mean_buffers_[stats_batch_idx]);
312      caffe_cpu_scale(this->blobs_[1]->count(), scale_factor,
313                      this->blobs_[1]->cpu_data(), variance_buffers_[stats_batch_idx]);
314    }
315    dnnError_t e;
316    void* BatchNorm_res[dnnResourceNumber];
317    BatchNorm_res[dnnResourceMean] = mean_buffers_[stats_batch_idx];
318    BatchNorm_res[dnnResourceVariance] = variance_buffers_[stats_batch_idx];
319    BatchNorm_res[dnnResourceSrc] = (Dtype*)bottom_data + data_offset;
320    BatchNorm_res[dnnResourceScaleShift] = scaleShift_buffer_;
321    if (fwd_top_data->conversion_needed()) {
322      top[0]->set_prv_data_descriptor(fwd_top_data);
323      data_offset = stats_batch_idx * (top[0]->prv_data_count() / num_stats_batches_);
324      BatchNorm_res[dnnResourceDst] =
325              reinterpret_cast<void *>(top[0]->mutable_prv_data() + data_offset);
326    } else {
327      BatchNorm_res[dnnResourceDst] =
328              reinterpret_cast<void *>(top[0]->mutable_cpu_data() + data_offset);
329      DLOG(INFO) << "Using cpu_data for top in DnnBatchNorm.";
330    }
331    PERFORMANCE_EVENT_ID_INIT(perf_id_fw_, PERFORMANCE_MKL_NAME("FW"));
332    PERFORMANCE_MEASUREMENT_BEGIN();
333    e = dnnExecute<Dtype>(use_global_stats_? batchNormFwdInference : batchNormFwd,
334                                                                   BatchNorm_res);
335    PERFORMANCE_MEASUREMENT_END_ID(perf_id_fw_);
336    CHECK_EQ(e, E_SUCCESS);
337    if (!use_global_stats_) {
338      this->blobs_[2]->mutable_cpu_data()[0] *= moving_average_fraction_;
339      this->blobs_[2]->mutable_cpu_data()[0] += 1;
340      caffe_cpu_axpby(this->blobs_[0]->count(), Dtype(1), mean_buffers_[stats_batch_idx],
341          moving_average_fraction_, this->blobs_[0]->mutable_cpu_data());
342      int m = bottom[0]->count()/num_stats_batches_/channels_;
343      Dtype bias_correction_factor = m > 1 ? Dtype(m)/(m-1) : 1;
344      caffe_cpu_axpby(this->blobs_[1]->count(), bias_correction_factor,
345          variance_buffers_[stats_batch_idx], moving_average_fraction_,
346          this->blobs_[1]->mutable_cpu_data());
347    }
348  }
349  template <typename Dtype>
350  void MKLBatchNormLayer<Dtype>::BackwardStatsBatch_cpu(const vector<Blob<Dtype>*>& top,
351      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom,
352      int stats_batch_idx) {
353    long data_offset = stats_batch_idx * stats_batch_size_ * bottom[0]->count(1);
354    void *bottom_data = NULL;
355    if (bottom[0] == top[0]) {
356      bottom_data = reinterpret_cast<void *>(
357                          const_cast<Dtype*>(temp_.cpu_data()));
358    } else {
359      bottom_data =
360              reinterpret_cast<void *>(
361                          const_cast<Dtype*>(bottom[0]->prv_data()));
362      if (NULL == bottom_data || num_stats_batches_ > 1)
363        bottom_data =
364              reinterpret_cast<void *>(
365                          const_cast<Dtype*>(bottom[0]->cpu_data()));
366    }
367    dnnError_t e;
368    void* BatchNorm_res[dnnResourceNumber];
369    BatchNorm_res[dnnResourceMean] = mean_buffers_[stats_batch_idx];
370    BatchNorm_res[dnnResourceVariance] = variance_buffers_[stats_batch_idx];
371    BatchNorm_res[dnnResourceSrc] = (Dtype*)bottom_data + data_offset;
372    BatchNorm_res[dnnResourceScaleShift] = scaleShift_buffer_;
373    BatchNorm_res[dnnResourceDiffScaleShift] = diffScaleShift_buffer_;
374    BatchNorm_res[dnnResourceDiffDst] =
375      bwd_top_diff->get_converted_prv(top[0], true) + data_offset;
376    if (bwd_bottom_diff->conversion_needed()) {
377      bottom[0]->set_prv_diff_descriptor(bwd_bottom_diff);
378      data_offset = stats_batch_idx * (bottom[0]->prv_diff_count() / num_stats_batches_);
379      BatchNorm_res[dnnResourceDiffSrc] = bottom[0]->mutable_prv_diff() + data_offset;
380    } else {
381      BatchNorm_res[dnnResourceDiffSrc] = bottom[0]->mutable_cpu_diff() + data_offset;
382    }
383    PERFORMANCE_EVENT_ID_INIT(perf_id_bw_, PERFORMANCE_MKL_NAME("BW"));
384    PERFORMANCE_MEASUREMENT_BEGIN();
385    e = dnnExecute<Dtype>(batchNormBwd, BatchNorm_res);
386    PERFORMANCE_MEASUREMENT_END_ID(perf_id_bw_);
387    CHECK_EQ(e, E_SUCCESS);
388    if (use_weight_bias_) {
389      caffe_cpu_axpby(this->blobs_[3]->count(), (Dtype)1.,
390                      diffScaleShift_buffer_, (Dtype)1., this->blobs_[3]->mutable_cpu_diff());
391      if (bias_term_)
392        caffe_cpu_axpby(this->blobs_[4]->count(), (Dtype)1.,
393                        diffScaleShift_buffer_ + channels_,
394                        (Dtype)1., this->blobs_[4]->mutable_cpu_diff());
395      else
396        caffe_set(this->blobs_[4]->count(),
397                      static_cast<Dtype>(0), this->blobs_[4]->mutable_cpu_diff());
398    }
399  }
400  template <typename Dtype>
401  void MKLBatchNormLayer<Dtype>::Forward_cpu(
402      const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
403    for (int i = 0; i < num_stats_batches_; i++) {
404      ForwardStatsBatch_cpu(bottom, top, i);
405    }
406  }
407  template <typename Dtype>
408  void MKLBatchNormLayer<Dtype>::Backward_cpu(
409      const vector<Blob<Dtype>*>& top, const vector<bool>& propagate_down,
410      const vector<Blob<Dtype>*>& bottom) {
411    for (int i = 0; i < num_stats_batches_; i++) {
412      BackwardStatsBatch_cpu(top, propagate_down, bottom, i);
413    }
414  }
415  #ifdef CPU_ONLY
416  STUB_GPU(MKLBatchNormLayer);
417  #else
418  template <typename Dtype>
419  void MKLBatchNormLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
420      const vector<Blob<Dtype>*>& top) {NOT_IMPLEMENTED;}
421  template <typename Dtype>
422  void MKLBatchNormLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
423      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom)
424    {NOT_IMPLEMENTED;}
425  #endif
426  INSTANTIATE_CLASS(MKLBatchNormLayer);
427  }  
428  #endif  
</code></pre>
        </div>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-mkldnn_batch_norm_layer.cpp</h3>
            <pre><code>1  #ifdef MKLDNN_SUPPORTED
2  #include <algorithm>
3  #include <vector>
4  #include "caffe/filler.hpp"
5  #include "caffe/layers/mkldnn_layers.hpp"
6  namespace caffe {
7  template <typename Dtype>
8  void MKLDNNBatchNormLayer<Dtype>::InitStatsBatchVars(int batch_size) {
9      num_stats_batches_ = 1;
10      stats_batch_size_ = batch_size;
11      BatchNormParameter param = this->layer_param_.batch_norm_param();
12      if (!use_global_stats_ && param.stats_batch_size() > 0) {
13        CHECK_EQ(batch_size % param.stats_batch_size(), 0);
14        num_stats_batches_ = batch_size / param.stats_batch_size();
15        stats_batch_size_ = param.stats_batch_size();
16      }
17  }
18  template <typename Dtype>
19  void MKLDNNBatchNormLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom
20                                          ,const vector<Blob<Dtype>*>& top)
21  {
22      VLOG(1) << "MKLDNNBatchNormLayer<Dtype>::LayerSetUp: " << this->layer_param_.name();
23      Layer<Dtype>::LayerSetUp(bottom, top);
24      shape_ = bottom[0]->shape();
25      const int channels = shape_[1];
26      eps_ = this->layer_param_.batch_norm_param().eps();
27      use_weight_bias_ = this->layer_param_.batch_norm_param().use_weight_bias();
28      bias_term_ = this->layer_param_.batch_norm_param().bias_term();
29      moving_average_fraction_ = this->layer_param_.batch_norm_param().moving_average_fraction();
<span onclick='openModal()' class='match'>30      use_global_stats_ = this->phase_ == TEST;
31      if (this->layer_param_.batch_norm_param().has_use_global_stats())
32        use_global_stats_ = this->layer_param_.batch_norm_param().use_global_stats();
33      InitStatsBatchVars(shape_[0]);
</span>34      this->blobs_.resize(3 + (use_weight_bias_ ? 1:0) + (use_weight_bias_ && bias_term_ ? 1:0));
35      vector<int> sz;
36      sz.push_back(channels);
37      this->blobs_[0].reset(new Blob<Dtype>(sz));
38      this->blobs_[1].reset(new Blob<Dtype>(sz));
39      sz[0]=1;
40      this->blobs_[2].reset(new Blob<Dtype>(sz));
41      for (int i = 0; i < 3; ++i) {
42          caffe_set(this->blobs_[i]->count(), Dtype(0),
43              this->blobs_[i]->mutable_cpu_data());
44      }
45      vector<int> scaleshift_blob_shape(1);
46      scaleshift_blob_shape[0] = 2*channels;
47      scaleshift_blob_.reset(new Blob<Dtype>(scaleshift_blob_shape));
48      caffe_set(scaleshift_blob_shape[0], static_cast<Dtype>(0),
49                scaleshift_blob_->mutable_cpu_data());
50      shared_ptr<Blob<Dtype> > scaleshift_diff_blob = scaleshift_blob_;
51      scaleshift_acc_ = scaleshift_blob_;
52      if (num_stats_batches_ > 1) {
53        this->scaleshift_acc_.reset(new Blob<Dtype>(scaleshift_blob_shape));
54        scaleshift_diff_blob = scaleshift_acc_;
55      }
56      if (use_weight_bias_) {
57          vector<int> scaleshift_shape(1);
58          scaleshift_shape[0] = channels;
59          VLOG(1) << "MKLDNNBatchNormLayer<Dtype>::LayerSetUp: channels_  = " << channels;
60          this->blobs_[3].reset(new Blob<Dtype>(scaleshift_shape));
61          this->blobs_[3]->set_cpu_data(scaleshift_blob_->mutable_cpu_data());
62          this->blobs_[3]->set_cpu_diff(scaleshift_diff_blob->mutable_cpu_diff());
63          FillerParameter filler_param(this->layer_param_.batch_norm_param().filler());
64          if (!this->layer_param_.batch_norm_param().has_filler()) {
65              filler_param.set_type("constant");
66              filler_param.set_value(1);
67          }
68          shared_ptr<Filler<Dtype> > filler(GetFiller<Dtype>(filler_param));
69          VLOG(1) << "MKLDNNBatchNormLayer<Dtype>::LayerSetUp: scaleshift " << __LINE__ << ":" << this->layer_param_.name();
70          filler->Fill(this->blobs_[3].get());
71          if (bias_term_) {
72              this->blobs_[4].reset(new Blob<Dtype>(scaleshift_shape));
73              this->blobs_[4]->set_cpu_data(scaleshift_blob_->mutable_cpu_data() + scaleshift_blob_->offset(channels));
74              this->blobs_[4]->set_cpu_diff(scaleshift_diff_blob->mutable_cpu_diff() + scaleshift_blob_->offset(channels));
75              FillerParameter bias_filler_param(this->layer_param_.batch_norm_param().bias_filler());
76              if (!this->layer_param_.batch_norm_param().has_bias_filler()) {
77                  bias_filler_param.set_type("constant");
78                  bias_filler_param.set_value(0);
79              }
80              shared_ptr<Filler<Dtype> > bias_filler(GetFiller<Dtype>(bias_filler_param));
81              VLOG(1) << "MKLDNNBatchNormLayer<Dtype>::LayerSetUp: bias " << __LINE__ << ":" << this->layer_param_.name();
82              bias_filler->Fill(this->blobs_[4].get());
83          }
84      }
85      for (int i = 0; i < 3; ++i) {
86        if (this->layer_param_.param_size() == i) {
87          ParamSpec* fixed_param_spec = this->layer_param_.add_param();
88          fixed_param_spec->set_lr_mult(0.f);
89        } else {
90          CHECK_EQ(this->layer_param_.param(i).lr_mult(), 0.f)
91              << "Cannot configure batch normalization statistics as layer "
92              << "parameters.";
93        }
94      }
95  }
96  template <typename Dtype>
97  void MKLDNNBatchNormLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom
98                                      ,const vector<Blob<Dtype>*>& top)
99  {
100      VLOG(1) << "MKLDNNBatchNormLayer<Dtype>::Reshape: " << this->layer_param_.name();
101      this->reshape = (this->shape_ == bottom[0]->shape()) ? false : true;
102      this->shape_ = bottom[0]->shape();
103      InitStatsBatchVars(this->shape_[0]);
104  #ifdef DEBUG
105      LOG(INFO) << "size of bottom blob: " << bottom[0]->shape().size();
106  #endif
107      top[0]->ReshapeLike(*bottom[0]);
108      if(bottom[0] == top[0] && this->phase_ == TRAIN)
109          inplace_buffer.ReshapeLike(*bottom[0]);
110  }
111  template <typename Dtype>
112  void MKLDNNBatchNormLayer<Dtype>::InitBatchNorm(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top)
113  {
114      if (std::is_same<Dtype, double>::value) NOT_IMPLEMENTED;
115      auto propagation = this->phase_ == TEST ? prop_kind::forward_scoring : prop_kind::forward_training;
116      unsigned flags = 0;
117      if (use_weight_bias_) flags |= use_scale_shift;
118      if (use_global_stats_) flags |= use_global_stats;
119      memory::format src_mfmt;
120      auto tensor_size = this->shape_.size();
121      memory::dims dim = this->shape_;
122      if(tensor_size == 5) {
123          src_mfmt = memory::format::ncdhw;
124      } else {
125          CHECK_LE(tensor_size, 4)
126              << "mkldnn batch normalization layer only supports dim size <= 5!";
127          if (tensor_size < 4) dim.resize(4, 1); 
128          src_mfmt = memory::format::nchw;
129      }
130      const int channels = this->shape_[1];
131      bool bottom_data_is_prv = (const_cast<Dtype*>(bottom[0]->prv_data()) != NULL);
132      bool inplace = (bottom[0] == top[0]);
133      engine cpu_engine = CpuEngine::Instance().get_engine();
134      memory::data_type mpcsn = memory::data_type::f32;
135      shared_ptr<memory::desc> input_md, input_stats_md, output_md, scaleshift_md;
136      shared_ptr<memory::primitive_desc> usr_mpd, prv_mpd;
137      shared_ptr<memory::primitive_desc> scaleshift_mpd;
138      if (bottom_data_is_prv) {
139          shared_ptr<MKLDNNMemoryDescriptor<Dtype, false> > mem_descr
140              = get_mkldnn_prv_descriptor<Dtype, false>(bottom[0]);
141          input_md.reset(new memory::desc(mem_descr->prv_memory_pd()->desc()));
142          usr_mpd = mem_descr->usr_memory_pd();
143          prv_mpd = mem_descr->prv_memory_pd();
144      } else {
145          input_md.reset(new memory::desc({dim}, mpcsn, src_mfmt));
146          usr_mpd.reset(new memory::primitive_desc(*input_md, cpu_engine));
147      }
148      output_md = input_md;
149      input_stats_md.reset(new memory::desc(*input_md));
150      CHECK(input_stats_md->data.ndims > 0 &&
151            input_stats_md->data.dims[0] == this->shape_[0]);
152      input_stats_md->data.dims[0] = stats_batch_size_;
153      batch_normalization_forward::desc BatchNormFwd_desc(propagation, *input_stats_md, eps_, flags);
154      std::string subengines = this->layer_param_.engine();
155      if (subengines.find("MKLDNN") == std::string::npos || subengines == "MKLDNN")
156        subengines = "MKLDNN:CPU";
157      EngineParser ep(subengines);
158      unsigned subEngineIndex = 0;
159      BatchNormFwd_pd = NULL;
160      bool relu = this->layer_param_.batch_norm_param().relu();
161      mkldnn::primitive_attr attr;
162      mkldnn::post_ops ops;
163      if (relu) {
164          ops.append_eltwise(1.f, eltwise_relu, 0.f, 0.f);
165          attr.set_post_ops(ops);
166      }
167      for(; subEngineIndex < ep.getNumberOfSubEngines(); subEngineIndex++) {
168        try {
169          if (relu)
170              BatchNormFwd_pd.reset(new batch_normalization_forward::primitive_desc(BatchNormFwd_desc, attr,
171                  ep.getMKLDNNSubEngine(subEngineIndex)));
172          else
173              BatchNormFwd_pd.reset(new batch_normalization_forward::primitive_desc(BatchNormFwd_desc,
174                  ep.getMKLDNNSubEngine(subEngineIndex)));
175        }
176        catch(...) {
177          continue;
178        }
179        break;
180      }
181      CHECK(BatchNormFwd_pd);
182      if (use_weight_bias_) {
183          if((this->blobs_[3]->mutable_cpu_data() + this->blobs_[3]->offset(channels)) == this->blobs_[4]->mutable_cpu_data()){
184              scaleshift_memory.reset(new memory(BatchNormFwd_pd->weights_primitive_desc(), this->blobs_[3]->mutable_cpu_data()));
185          }else {
186              scaleshift_memory.reset(new memory(BatchNormFwd_pd->weights_primitive_desc(), this->scaleshift_blob_->mutable_cpu_data()));
187          }
188      }
189      fwd_bottom_data.reset(new MKLDNNData<Dtype>(usr_mpd, prv_mpd, bottom[0], this));
190      input_primitive = fwd_bottom_data->create_input(false);
191      if(inplace && this->phase_ == TRAIN) {
192          fwd_top_data.reset(new MKLDNNData<Dtype>(usr_mpd, prv_mpd, &inplace_buffer, this));
193      } else {
194          fwd_top_data.reset(new MKLDNNData<Dtype>(usr_mpd, prv_mpd, top[0], this));
195      }
196      output_memory = fwd_top_data->create_output_memory();
197      mean_memory.resize(num_stats_batches_);
198      variance_memory.resize(num_stats_batches_);
199      input_stats.resize(num_stats_batches_);
200      output_stats.resize(num_stats_batches_);
201      BatchNormFwd.resize(num_stats_batches_);
202      for (int i = 0; i < num_stats_batches_; i++) {
203        InitBatchNormFwdPrimitive(i);
204      }
205      MKLDNNPrimitive<Dtype> fwd_bottom_data_primitive_transfer(input_primitive);
206      fwd_bottom_data->set_mkldnn_primitive(fwd_bottom_data_primitive_transfer);
207      MKLDNNPrimitive<Dtype> fwd_top_data_memory_transfer(output_memory);
208      fwd_top_data->set_mkldnn_primitive(fwd_top_data_memory_transfer);
209      bool has_spatial = (bottom[0]->shape().size() != 2);
210  #ifdef DEBUG
211      LOG(INFO) << "has_spatial flag value: " << has_spatial;
212  #endif
213      if (has_spatial == false)
214      {
215  #ifdef DEBUG
216          LOG(INFO) << "size of bottom blob: " << bottom[0]->shape().size();
217          LOG(INFO) << "MKLDNN batch norm only support 4D memory descriptor! Use 4D for calculation and reshape to 2D for output!";
218  #endif
219          vector<int> top_shape;
220          top_shape.push_back(bottom[0]->shape(0));
221          top_shape.push_back(bottom[0]->shape(1));
222          top[0]->Reshape(top_shape);
223      }
224  }
225  template <typename Dtype>
226  template <bool diff>
227  shared_ptr<memory> MKLDNNBatchNormLayer<Dtype>::GetStatsBatchMemory(
228    shared_ptr<MKLDNNMemoryDescriptor<Dtype, diff> > mkldnn_mem, int idx) {
229      int length = this->shape_[1];
230      for(int i=2;i<this->shape_.size();i++)
231          length *= this->shape_[i];
232      long data_offset =  idx * stats_batch_size_ * length;
233      engine cpu_engine = CpuEngine::Instance().get_engine();
234      shared_ptr<memory::desc> stats_md = mkldnn_mem->get_memory_desc();
235      CHECK(stats_md->data.ndims > 0 &&
236            stats_md->data.dims[0] == this->shape_[0]);
237      stats_md->data.dims[0] = stats_batch_size_;
238      shared_ptr<memory::primitive_desc> stats_mpd(
239        new memory::primitive_desc(*stats_md, cpu_engine));
240      shared_ptr<memory> stats(
241        new memory(*stats_mpd, mkldnn_mem->get_memory_ptr(data_offset)));
242      return stats;
243  }
244  template <typename Dtype>
245  void MKLDNNBatchNormLayer<Dtype>::InitBatchNormFwdPrimitive(int idx) {
246      input_stats[idx] = GetStatsBatchMemory<false>(fwd_bottom_data, idx);
247      output_stats[idx] = GetStatsBatchMemory<false>(fwd_top_data, idx);
248      const int channels = this->shape_[1];
249      if (this->phase_ == TEST && !use_global_stats_) {
250          if (use_weight_bias_) {
251              BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
252                      *input_stats[idx], *scaleshift_memory,
253                      *output_stats[idx]));
254          } else {
255              BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
256                      *input_stats[idx], *output_stats[idx]));
257          }
258      } else {
259          mean_memory[idx].reset(new memory(BatchNormFwd_pd->mean_primitive_desc()));
260          variance_memory[idx].reset(new memory(BatchNormFwd_pd->variance_primitive_desc()));
261          if (use_global_stats_) {
262              caffe_copy<Dtype>(channels, this->blobs_[0]->cpu_data(),
263                  static_cast<Dtype *>(mean_memory[idx]->get_data_handle()));
264              caffe_copy<Dtype>(channels, this->blobs_[1]->cpu_data(),
265                 static_cast<Dtype *>(variance_memory[idx]->get_data_handle()));
266              if (use_weight_bias_) {
267                  BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
268                          *input_stats[idx], (const primitive::at)*mean_memory[idx],
269                          (const primitive::at)*variance_memory[idx], *scaleshift_memory,
270                          *output_stats[idx]));
271              } else {
272                  BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
273                          *input_stats[idx], (const primitive::at)*mean_memory[idx],
274                          (const primitive::at)*variance_memory[idx], *output_stats[idx]));
275              }
276          } else {
277              if (use_weight_bias_) {
278                  BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
279                          *input_stats[idx], *scaleshift_memory, *output_stats[idx],
280                          *mean_memory[idx], *variance_memory[idx]));
281              } else {
282                  BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
283                          *input_stats[idx], *output_stats[idx], *mean_memory[idx], *variance_memory[idx]));
284              }
285          }
286      }
287  }
288  template <typename Dtype>
289  void MKLDNNBatchNormLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom
290                                          ,const vector<Blob<Dtype>*>& top)
291  {
292      VLOG(1) << "MKLDNNBatchNormLayer<Dtype>::Forward_cpu: " << this->layer_param_.name();
293  #ifdef DEBUG
294      LOG(INFO) << "MKLDNNBatchNormLayer<Dtype>::Forward_cpu: " << this->layer_param_.name();
295  #endif
296      if(BatchNormFwd_pd == NULL || this->reshape)
297          InitBatchNorm(bottom, top);
298      bool inplace = (bottom[0] == top[0]);
299      fwd_bottom_data->sync_before_read();
300      fwd_top_data->sync_before_write();
301      const int channels = this->shape_[1];
302      if((this->blobs_[3]->mutable_cpu_data() + this->blobs_[3]->offset(channels)) != this->blobs_[4]->mutable_cpu_data()){
303          caffe_copy(channels, this->blobs_[3]->cpu_data(), this->scaleshift_blob_->mutable_cpu_data());
304          caffe_copy(channels, this->blobs_[4]->cpu_data(), this->scaleshift_blob_->mutable_cpu_data() + scaleshift_blob_->offset(channels));
305      }
306      for (int stats_batch_idx = 0; stats_batch_idx < num_stats_batches_; stats_batch_idx++) {
307        if (use_global_stats_) {
308          const Dtype scale_factor = this->blobs_[2]->cpu_data()[0] == 0 ?
309              0 : 1 / this->blobs_[2]->cpu_data()[0];
310          Dtype *mean_buffer_ = (Dtype *)(mean_memory[stats_batch_idx]->get_data_handle());
311          Dtype *variance_buffer_ = (Dtype *)(variance_memory[stats_batch_idx]->get_data_handle());
312          caffe_cpu_scale(this->blobs_[0]->count(), scale_factor,
313                      this->blobs_[0]->cpu_data(), mean_buffer_);
314          caffe_cpu_scale(this->blobs_[1]->count(), scale_factor,
315                      this->blobs_[1]->cpu_data(), variance_buffer_);
316        }
317        PERFORMANCE_EVENT_ID_INIT(perf_id_fw_, PERFORMANCE_MKLDNN_NAME("FW"));
318        PERFORMANCE_MEASUREMENT_BEGIN();
319        BatchNormFwd[stats_batch_idx].submit();
320        PERFORMANCE_MEASUREMENT_END_ID(perf_id_fw_);
321        if (this->phase_ == TRAIN && !use_global_stats_) {
322          Dtype *mean_buffer_ = (Dtype *)(mean_memory[stats_batch_idx]->get_data_handle());
323          Dtype *variance_buffer_ = (Dtype *)(variance_memory[stats_batch_idx]->get_data_handle());
324          this->blobs_[2]->mutable_cpu_data()[0] *= moving_average_fraction_;
325          this->blobs_[2]->mutable_cpu_data()[0] += 1;
326          caffe_cpu_axpby<Dtype>(channels, Dtype(1), mean_buffer_,
327              moving_average_fraction_, this->blobs_[0]->mutable_cpu_data());
328          int m = bottom[0]->count()/num_stats_batches_/channels;
329          Dtype bias_correction_factor = m > 1 ? Dtype(m)/(m-1) : 1;
330          caffe_cpu_axpby<Dtype>(channels, bias_correction_factor,
331              variance_buffer_, moving_average_fraction_,
332              this->blobs_[1]->mutable_cpu_data());
333        }
334      }
335      if(inplace && this->phase_ == TRAIN)
336          bottom[0]->data()->swap((inplace_buffer.data()));
337  }
338  template <typename Dtype>
339  void MKLDNNBatchNormLayer<Dtype>::InitBatchNormBwd(
340          const vector<Blob<Dtype>*>& top, const vector<bool>& propagate_down,
341          const vector<Blob<Dtype>*>& bottom)
342  {
343      if (std::is_same<Dtype, double>::value) NOT_IMPLEMENTED;
344      memory::format src_mfmt;
345      auto tensor_size = this->shape_.size();
346      memory::dims dim = this->shape_;
347      if(tensor_size == 5) {
348          src_mfmt = memory::format::ncdhw;
349      } else {
350          CHECK_LE(tensor_size, 4)
351              << "mkldnn batch normalization layer only supports dim size <= 5!";
352          if (tensor_size < 4) dim.resize(4, 1); 
353          src_mfmt = memory::format::nchw;
354      }
355      unsigned flags = 0;
356      if (use_weight_bias_) flags |= use_scale_shift;
357      if (use_global_stats_) flags |= use_global_stats;
358      bool top_diff_is_prv = (const_cast<Dtype*>(top[0]->prv_diff()) != NULL);
359      bool inplace = (bottom[0] == top[0]);
360      engine cpu_engine = CpuEngine::Instance().get_engine();
361      memory::data_type mpcsn = memory::data_type::f32;
362      shared_ptr<memory::desc> top_diff_md, top_diff_stats_md, top_data_md, output_stats_md;
363      shared_ptr<memory::primitive_desc> usr_diff_mpd(NULL), prv_diff_mpd(NULL);
364      if (top_diff_is_prv) {
365          shared_ptr<MKLDNNMemoryDescriptor<Dtype, true> > mem_descr
366              = get_mkldnn_prv_descriptor<Dtype, true>(top[0]);
367          top_diff_md.reset(new memory::desc(mem_descr->prv_memory_pd()->desc()));
368          usr_diff_mpd = mem_descr->usr_memory_pd();
369          prv_diff_mpd = mem_descr->prv_memory_pd();
370      } else {
371          top_diff_md.reset(new memory::desc({dim}, mpcsn, src_mfmt));   
372          usr_diff_mpd.reset(new memory::primitive_desc(*top_diff_md, cpu_engine));
373      }
374      top_diff_stats_md.reset(new memory::desc(*top_diff_md));
375      CHECK(top_diff_stats_md->data.ndims > 0 &&
376            top_diff_stats_md->data.dims[0] == this->shape_[0]);
377      top_diff_stats_md->data.dims[0] = stats_batch_size_;
378      output_stats_md.reset(new memory::desc(output_memory->get_primitive_desc().desc()));
379      CHECK(output_stats_md->data.ndims > 0 &&
380            output_stats_md->data.dims[0] == this->shape_[0]);
381      output_stats_md->data.dims[0] = stats_batch_size_;
382      batch_normalization_backward::desc BatchNormBwd_desc(prop_kind::backward,
383              *top_diff_stats_md, *output_stats_md, eps_,
384              flags);
385      std::string subengines = this->layer_param_.engine();
386      if (subengines.find("MKLDNN") == std::string::npos || subengines == "MKLDNN")
387        subengines = "MKLDNN:CPU";
388      EngineParser ep(subengines);
389      unsigned subEngineIndex = 0;
390      BatchNormBwd_pd = NULL;
391      for(; subEngineIndex < ep.getNumberOfSubEngines(); subEngineIndex++) {
392        try {
393          BatchNormBwd_pd.reset(new batch_normalization_backward::primitive_desc(
394                      BatchNormBwd_desc, ep.getMKLDNNSubEngine(subEngineIndex),
395                      *BatchNormFwd_pd));
396        }
397        catch(...) {
398          continue;
399        }
400        break;
401      }
402      CHECK(BatchNormBwd_pd);
403      if (use_weight_bias_) {
404          bwd_scaleshift_diff_memory.reset(new memory(
405                      BatchNormFwd_pd->weights_primitive_desc(), this->scaleshift_blob_->mutable_cpu_diff()));
406      }
407      bwd_top_diff.reset(new MKLDNNDiff<Dtype>(usr_diff_mpd, prv_diff_mpd, top[0], this));
408      bwd_top_diff->name = "bwd_top_diff_data   @ " + this->layer_param_.name();
409      bwd_top_diff_primitive = bwd_top_diff->create_input(false);
410      bwd_bottom_diff.reset(new MKLDNNDiff<Dtype>(usr_diff_mpd, prv_diff_mpd, bottom[0], this));
411      bwd_bottom_diff->name = "bwd_bottom_diff_data   @ " + this->layer_param_.name();
412      bwd_bottom_diff_memory = bwd_bottom_diff->create_output_memory(inplace);
413      top_diff_stats.resize(num_stats_batches_);
414      bottom_diff_stats.resize(num_stats_batches_);
415      BatchNormBwd.resize(num_stats_batches_);
416      for (int i = 0; i < num_stats_batches_; i++) {
417        InitBatchNormBwdPrimitive(i);
418      }
419      MKLDNNPrimitive<Dtype> bwd_top_diff_primitive_transfer(bwd_top_diff_primitive);
420      bwd_top_diff->set_mkldnn_primitive(bwd_top_diff_primitive_transfer);
421      MKLDNNPrimitive<Dtype> bwd_bottom_diff_memory_transfer(bwd_bottom_diff_memory);
422      bwd_bottom_diff->set_mkldnn_primitive(bwd_bottom_diff_memory_transfer);
423  }
424  template <typename Dtype>
425  void MKLDNNBatchNormLayer<Dtype>::InitBatchNormBwdPrimitive(int idx) {
426      top_diff_stats[idx] = GetStatsBatchMemory<true>(bwd_top_diff, idx);
427      bottom_diff_stats[idx] = GetStatsBatchMemory<true>(bwd_bottom_diff, idx);
428      if (use_weight_bias_) {
429          BatchNormBwd[idx].reset(new batch_normalization_backward(*BatchNormBwd_pd,
430                      *input_stats[idx], *mean_memory[idx], *variance_memory[idx],
431                      *top_diff_stats[idx], *scaleshift_memory,
432                      *bottom_diff_stats[idx], *bwd_scaleshift_diff_memory));
433      } else {
434          BatchNormBwd[idx].reset(new batch_normalization_backward(*BatchNormBwd_pd,
435                      *input_stats[idx], *mean_memory[idx], *variance_memory[idx],
436                      *top_diff_stats[idx], *bottom_diff_stats[idx]));
437      }
438  }
439  template <typename Dtype>
440  void MKLDNNBatchNormLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
441          const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom)
442  {
443      VLOG(1) << "MKLDNNBatchNormLayer<Dtype>::Backward_cpu: " << this->layer_param_.name();
444  #ifdef DEBUG
445      LOG(INFO) << "MKLDNNBatchNormLayer<Dtype>::Backward_cpu: " << this->layer_param_.name();
446  #endif
447      if (BatchNormBwd_pd == NULL || this->reshape)
448          InitBatchNormBwd(top, propagate_down, bottom);
449      bwd_top_diff->sync_before_read();
450      bwd_bottom_diff->sync_before_write();
451      for (int stats_batch_idx = 0; stats_batch_idx < num_stats_batches_; stats_batch_idx++) {
452        PERFORMANCE_EVENT_ID_INIT(perf_id_bw_, PERFORMANCE_MKLDNN_NAME("BW"));
453        PERFORMANCE_MEASUREMENT_BEGIN();
454  #ifdef DEBUG
455        if (bottom[0]->prv_data() != NULL)
456        {
457          LOG(INFO) << "Debug: Bottom prv data: " << *bottom[0]->prv_data();
458        }
459        else
460        {
461          LOG(INFO) << "Debug: Bottom prv data is NULL!";
462        }
463        if (top[0]->prv_diff() != NULL)
464        {
465          LOG(INFO) << "Debug: Top prv diff: " << *top[0]->prv_diff();
466        }
467        else
468        {
469          LOG(INFO) << "Debug: Top prv diff is NULL!";
470          LOG(INFO) << "Debug: Top cpu diff: " << *top[0]->cpu_diff();
471        }
472  #endif
473        BatchNormBwd[stats_batch_idx].submit();
474  #ifdef DEBUG
475        if (bottom[0]->prv_diff() != NULL)
476        {
477          LOG(INFO) << "Debug: Bottom prv diff: " << *bottom[0]->prv_diff();
478        }
479        else
480        {
481          LOG(INFO) << "Debug: Bottom prv diff is NULL!";
482          LOG(INFO) << "Debug: Bottom cpu diff: " << *bottom[0]->cpu_diff();
483        }
484  #endif
485        PERFORMANCE_MEASUREMENT_END_ID(perf_id_bw_);
486        if (num_stats_batches_ > 1) {
487          CHECK(scaleshift_blob_ != scaleshift_acc_);
488          CHECK(scaleshift_blob_->count() == scaleshift_acc_->count());
489          caffe_cpu_axpby(scaleshift_acc_->count(), Dtype(1),
490                          scaleshift_blob_->mutable_cpu_diff(),
491                          Dtype(1), scaleshift_acc_->mutable_cpu_diff());
492        }
493      }
494  }
495  #ifdef CPU_ONLY
496  STUB_GPU(MKLDNNBatchNormLayer);
497  #else
498  template <typename Dtype>
499  void MKLDNNBatchNormLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom
500                                          ,const vector<Blob<Dtype>*>& top)
501  { NOT_IMPLEMENTED; }
502  template <typename Dtype>
503  void MKLDNNBatchNormLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top
504                                              ,const vector<bool>& propagate_down
505                                              ,const vector<Blob<Dtype>*>& bottom)
506  { NOT_IMPLEMENTED; }
507  #endif
508  INSTANTIATE_CLASS(MKLDNNBatchNormLayer);
509  }  
510  #endif  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-mkl_batch_norm_layer.cpp</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-mkldnn_batch_norm_layer.cpp</div>
                </div>
                <div class="column column_space"><pre><code>32    use_global_stats_ = this->phase_ == TEST;
33    if (this->layer_param_.batch_norm_param().has_use_global_stats())
34      use_global_stats_ = this->layer_param_.batch_norm_param().use_global_stats();
35    num_stats_batches_ = 1;
</pre></code></div>
                <div class="column column_space"><pre><code>30      use_global_stats_ = this->phase_ == TEST;
31      if (this->layer_param_.batch_norm_param().has_use_global_stats())
32        use_global_stats_ = this->layer_param_.batch_norm_param().use_global_stats();
33      InitStatsBatchVars(shape_[0]);
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    