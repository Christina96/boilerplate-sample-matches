
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 14, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-softmax_layer.cpp</h3>
            <pre><code>1  #include &lt;algorithm&gt;
2  #include &lt;vector&gt;
3  #include &quot;caffe/layers/softmax_layer.hpp&quot;
4  #include &quot;caffe/util/math_functions.hpp&quot;
5  namespace caffe {
6  template &lt;typename Dtype&gt;
7  void SoftmaxLayer&lt;Dtype&gt;::Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
8        const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
9    softmax_axis_ =
10        bottom[0]-&gt;CanonicalAxisIndex(this-&gt;layer_param_.softmax_param().axis());
11    top[0]-&gt;ReshapeLike(*bottom[0]);
12    vector&lt;int&gt; mult_dims(1, bottom[0]-&gt;shape(softmax_axis_));
13    sum_multiplier_.Reshape(mult_dims);
14    Dtype* multiplier_data = sum_multiplier_.mutable_cpu_data();
15    caffe_set(sum_multiplier_.count(), Dtype(1), multiplier_data);
16    outer_num_ = bottom[0]-&gt;count(0, softmax_axis_);
17    inner_num_ = bottom[0]-&gt;count(softmax_axis_ + 1);
18    vector&lt;int&gt; scale_dims = bottom[0]-&gt;shape();
19    scale_dims[softmax_axis_] = 1;
20    scale_.Reshape(scale_dims);
21  }
22  template &lt;typename Dtype&gt;
23  void SoftmaxLayer&lt;Dtype&gt;::Forward_cpu_fast_case(
24      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
25      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
26    int channels = bottom[0]-&gt;shape(softmax_axis_);
27    int dim = bottom[0]-&gt;count() / outer_num_;
28  #if defined(_MSC_EXTENSIONS)
29    const Dtype* __restrict bottom_ = bottom[0]-&gt;cpu_data();
<span onclick='openModal()' class='match'>30    Dtype* __restrict top_ = top[0]-&gt;mutable_cpu_data();
31  #else
</span>32    const Dtype* __restrict__ bottom_ = bottom[0]-&gt;cpu_data();
33    Dtype* __restrict__ top_ = top[0]-&gt;mutable_cpu_data();
34  #endif
35    #ifdef _OPENMP
36    #pragma omp parallel for
37    #endif
38    for (int i = 0; i &lt; outer_num_; ++i) {
39      const Dtype* bottom_data = bottom_ + i*dim;
40      Dtype *top_data = top_ + channels*i;
41      Dtype scale_data = bottom_data[0];
42      for (int j = 1; j &lt; channels; ++j) {
43        scale_data = std::max(scale_data, bottom_data[j]);
44      }
45      for (int j = 0; j &lt; channels; j++) {
46        top_data[j] = bottom_data[j] - scale_data;
47      }
48      caffe_exp&lt;Dtype&gt;(dim, top_data, top_data);
49      scale_data = top_data[0];
50      for (int j = 1; j &lt; channels; j++) {
51        scale_data += top_data[j];
52      }
53      scale_data = Dtype(1.0) / scale_data;
54      for (int j = 0; j &lt; channels; j++) {
55        top_data[j] *= scale_data;
56      }
57    }
58  }
59  template &lt;typename Dtype&gt;
60  void SoftmaxLayer&lt;Dtype&gt;::Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
61      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
62    const Dtype* bottom_data = bottom[0]-&gt;cpu_data();
63    Dtype* top_data = top[0]-&gt;mutable_cpu_data();
64    Dtype* scale_data = scale_.mutable_cpu_data();
65    int channels = bottom[0]-&gt;shape(softmax_axis_);
66    int dim = bottom[0]-&gt;count() / outer_num_;
67    if (inner_num_ == 1 &amp;&amp; channels == dim) {
68        Forward_cpu_fast_case(bottom, top);
69        return;
70    }
71    caffe_copy(bottom[0]-&gt;count(), bottom_data, top_data);
72    for (int i = 0; i &lt; outer_num_; ++i) {
73  #ifdef _OPENMP
74  #pragma omp parallel for
75  #endif
76      for (int k = 0; k &lt; inner_num_; k++) {
77        Dtype max_val = bottom_data[i * dim + k];
78        for (int j = 1; j &lt; channels; j++) {
79          Dtype value = bottom_data[i * dim + k + j * inner_num_];
80          if (max_val &lt; value) max_val = value;
81        }
82        scale_data[k] = max_val;
83      }
84      caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels, inner_num_,
85          1, -1., sum_multiplier_.cpu_data(), scale_data, 1., top_data);
86      caffe_exp&lt;Dtype&gt;(dim, top_data, top_data);
87      caffe_cpu_gemv&lt;Dtype&gt;(CblasTrans, channels, inner_num_, 1.,
88          top_data, sum_multiplier_.cpu_data(), 0., scale_data);
89  #ifdef _OPENMP
90  #pragma omp parallel for
91  #endif
92      for (int j = 0; j &lt; channels; j++) {
93        caffe_div(inner_num_, top_data + j*inner_num_, scale_data,
94                top_data + j*inner_num_);
95      }
96      top_data += channels*inner_num_;
97    }
98  }
99  template &lt;typename Dtype&gt;
100  void SoftmaxLayer&lt;Dtype&gt;::Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
101      const vector&lt;bool&gt;&amp; propagate_down,
102      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {
103    const Dtype* top_diff = top[0]-&gt;cpu_diff();
104    const Dtype* top_data = top[0]-&gt;cpu_data();
105    Dtype* bottom_diff = bottom[0]-&gt;mutable_cpu_diff();
106    Dtype* scale_data = scale_.mutable_cpu_data();
107    int channels = top[0]-&gt;shape(softmax_axis_);
108    int dim = top[0]-&gt;count() / outer_num_;
109    caffe_copy(top[0]-&gt;count(), top_diff, bottom_diff);
110    for (int i = 0; i &lt; outer_num_; ++i) {
111  #ifdef _OPENMP
112  #pragma omp parallel for
113  #endif
114      for (int k = 0; k &lt; inner_num_; ++k) {
115        scale_data[k] = caffe_cpu_strided_dot&lt;Dtype&gt;(channels,
116            bottom_diff + i * dim + k, inner_num_,
117            top_data + i * dim + k, inner_num_);
118      }
119      caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels, inner_num_, 1,
120          -1., sum_multiplier_.cpu_data(), scale_data, 1., bottom_diff + i * dim);
121    }
122    caffe_mul(top[0]-&gt;count(), bottom_diff, top_data, bottom_diff);
123  }
124  #ifdef CPU_ONLY
125  STUB_GPU(SoftmaxLayer);
126  #endif
127  INSTANTIATE_CLASS(SoftmaxLayer);
128  }  
</code></pre>
        </div>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-softmax_layer.cpp</h3>
            <pre><code>1  #include &lt;algorithm&gt;
2  #include &lt;vector&gt;
3  #include &quot;caffe/layers/softmax_layer.hpp&quot;
4  #include &quot;caffe/util/math_functions.hpp&quot;
5  namespace caffe {
6  template &lt;typename Dtype&gt;
7  void SoftmaxLayer&lt;Dtype&gt;::Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
8        const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
9    softmax_axis_ =
10        bottom[0]-&gt;CanonicalAxisIndex(this-&gt;layer_param_.softmax_param().axis());
11    top[0]-&gt;ReshapeLike(*bottom[0]);
12    vector&lt;int&gt; mult_dims(1, bottom[0]-&gt;shape(softmax_axis_));
13    sum_multiplier_.Reshape(mult_dims);
14    Dtype* multiplier_data = sum_multiplier_.mutable_cpu_data();
15    caffe_set(sum_multiplier_.count(), Dtype(1), multiplier_data);
16    outer_num_ = bottom[0]-&gt;count(0, softmax_axis_);
17    inner_num_ = bottom[0]-&gt;count(softmax_axis_ + 1);
18    vector&lt;int&gt; scale_dims = bottom[0]-&gt;shape();
19    scale_dims[softmax_axis_] = 1;
20    scale_.Reshape(scale_dims);
21  }
22  template &lt;typename Dtype&gt;
23  void SoftmaxLayer&lt;Dtype&gt;::Forward_cpu_fast_case(
24      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
25      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
26    int channels = bottom[0]-&gt;shape(softmax_axis_);
27    int dim = bottom[0]-&gt;count() / outer_num_;
28  #if defined(_MSC_EXTENSIONS)
29    const Dtype* __restrict bottom_ = bottom[0]-&gt;cpu_data();
30    Dtype* __restrict top_ = top[0]-&gt;mutable_cpu_data();
31  #else
32    const Dtype* __restrict__ bottom_ = bottom[0]-&gt;cpu_data();
<span onclick='openModal()' class='match'>33    Dtype* __restrict__ top_ = top[0]-&gt;mutable_cpu_data();
34  #endif
</span>35    #ifdef _OPENMP
36    #pragma omp parallel for
37    #endif
38    for (int i = 0; i &lt; outer_num_; ++i) {
39      const Dtype* bottom_data = bottom_ + i*dim;
40      Dtype *top_data = top_ + channels*i;
41      Dtype scale_data = bottom_data[0];
42      for (int j = 1; j &lt; channels; ++j) {
43        scale_data = std::max(scale_data, bottom_data[j]);
44      }
45      for (int j = 0; j &lt; channels; j++) {
46        top_data[j] = bottom_data[j] - scale_data;
47      }
48      caffe_exp&lt;Dtype&gt;(dim, top_data, top_data);
49      scale_data = top_data[0];
50      for (int j = 1; j &lt; channels; j++) {
51        scale_data += top_data[j];
52      }
53      scale_data = Dtype(1.0) / scale_data;
54      for (int j = 0; j &lt; channels; j++) {
55        top_data[j] *= scale_data;
56      }
57    }
58  }
59  template &lt;typename Dtype&gt;
60  void SoftmaxLayer&lt;Dtype&gt;::Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
61      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
62    const Dtype* bottom_data = bottom[0]-&gt;cpu_data();
63    Dtype* top_data = top[0]-&gt;mutable_cpu_data();
64    Dtype* scale_data = scale_.mutable_cpu_data();
65    int channels = bottom[0]-&gt;shape(softmax_axis_);
66    int dim = bottom[0]-&gt;count() / outer_num_;
67    if (inner_num_ == 1 &amp;&amp; channels == dim) {
68        Forward_cpu_fast_case(bottom, top);
69        return;
70    }
71    caffe_copy(bottom[0]-&gt;count(), bottom_data, top_data);
72    for (int i = 0; i &lt; outer_num_; ++i) {
73  #ifdef _OPENMP
74  #pragma omp parallel for
75  #endif
76      for (int k = 0; k &lt; inner_num_; k++) {
77        Dtype max_val = bottom_data[i * dim + k];
78        for (int j = 1; j &lt; channels; j++) {
79          Dtype value = bottom_data[i * dim + k + j * inner_num_];
80          if (max_val &lt; value) max_val = value;
81        }
82        scale_data[k] = max_val;
83      }
84      caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels, inner_num_,
85          1, -1., sum_multiplier_.cpu_data(), scale_data, 1., top_data);
86      caffe_exp&lt;Dtype&gt;(dim, top_data, top_data);
87      caffe_cpu_gemv&lt;Dtype&gt;(CblasTrans, channels, inner_num_, 1.,
88          top_data, sum_multiplier_.cpu_data(), 0., scale_data);
89  #ifdef _OPENMP
90  #pragma omp parallel for
91  #endif
92      for (int j = 0; j &lt; channels; j++) {
93        caffe_div(inner_num_, top_data + j*inner_num_, scale_data,
94                top_data + j*inner_num_);
95      }
96      top_data += channels*inner_num_;
97    }
98  }
99  template &lt;typename Dtype&gt;
100  void SoftmaxLayer&lt;Dtype&gt;::Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
101      const vector&lt;bool&gt;&amp; propagate_down,
102      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {
103    const Dtype* top_diff = top[0]-&gt;cpu_diff();
104    const Dtype* top_data = top[0]-&gt;cpu_data();
105    Dtype* bottom_diff = bottom[0]-&gt;mutable_cpu_diff();
106    Dtype* scale_data = scale_.mutable_cpu_data();
107    int channels = top[0]-&gt;shape(softmax_axis_);
108    int dim = top[0]-&gt;count() / outer_num_;
109    caffe_copy(top[0]-&gt;count(), top_diff, bottom_diff);
110    for (int i = 0; i &lt; outer_num_; ++i) {
111  #ifdef _OPENMP
112  #pragma omp parallel for
113  #endif
114      for (int k = 0; k &lt; inner_num_; ++k) {
115        scale_data[k] = caffe_cpu_strided_dot&lt;Dtype&gt;(channels,
116            bottom_diff + i * dim + k, inner_num_,
117            top_data + i * dim + k, inner_num_);
118      }
119      caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels, inner_num_, 1,
120          -1., sum_multiplier_.cpu_data(), scale_data, 1., bottom_diff + i * dim);
121    }
122    caffe_mul(top[0]-&gt;count(), bottom_diff, top_data, bottom_diff);
123  }
124  #ifdef CPU_ONLY
125  STUB_GPU(SoftmaxLayer);
126  #endif
127  INSTANTIATE_CLASS(SoftmaxLayer);
128  }  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-softmax_layer.cpp</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-softmax_layer.cpp</div>
                </div>
                <div class="column column_space"><pre><code>30    Dtype* __restrict top_ = top[0]-&gt;mutable_cpu_data();
31  #else
</pre></code></div>
                <div class="column column_space"><pre><code>33    Dtype* __restrict__ top_ = top[0]-&gt;mutable_cpu_data();
34  #endif
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    