
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 100, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-normalize_layer.cpp</h3>
            <pre><code>1  #include <vector>
2  #include "caffe/filler.hpp"
3  #include "caffe/layers/normalize_layer.hpp"
4  namespace caffe {
5  template <typename Dtype>
6  void NormalizeLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
7        const vector<Blob<Dtype>*>& top) {
8    CHECK_GE(bottom[0]->num_axes(), 2)
9        << "Number of axes of bottom blob must be >=2.";
10    buffer_.Reshape(1, bottom[0]->channels(),
11                     bottom[0]->height(), bottom[0]->width());
12    buffer_channel_.Reshape(1, bottom[0]->channels(), 1, 1);
13    buffer_spatial_.Reshape(1, 1, bottom[0]->height(), bottom[0]->width());
14    NormalizeParameter norm_param = this->layer_param().norm_param();
15    across_spatial_ = norm_param.across_spatial();
16    if (across_spatial_) {
17      norm_.Reshape(bottom[0]->num(), 1, 1, 1);
18    } else {
19      norm_.Reshape(bottom[0]->num(), 1, bottom[0]->height(), bottom[0]->width());
20    }
21    eps_ = norm_param.eps();
22    int channels = bottom[0]->channels();
23    int spatial_dim = bottom[0]->width() * bottom[0]->height();
24    sum_channel_multiplier_.Reshape(1, channels, 1, 1);
25    caffe_set(channels, Dtype(1), sum_channel_multiplier_.mutable_cpu_data());
26    sum_spatial_multiplier_.Reshape(
27        1, 1, bottom[0]->height(), bottom[0]->width());
28    caffe_set(spatial_dim, Dtype(1), sum_spatial_multiplier_.mutable_cpu_data());
29    channel_shared_ = norm_param.channel_shared();
30    if (this->blobs_.size() > 0) {
31      LOG(INFO) << "Skipping parameter initialization";
32    } else {
33      this->blobs_.resize(1);
34      if (channel_shared_) {
35        this->blobs_[0].reset(new Blob<Dtype>(vector<int>(0)));
36      } else {
37        this->blobs_[0].reset(new Blob<Dtype>(vector<int>(1, channels)));
38      }
39      shared_ptr<Filler<Dtype> > scale_filler;
40      if (norm_param.has_scale_filler()) {
41        scale_filler.reset(GetFiller<Dtype>(norm_param.scale_filler()));
42      } else {
43        FillerParameter filler_param;
44        filler_param.set_type("constant");
<span onclick='openModal()' class='match'>45        filler_param.set_value(1.0);
46        scale_filler.reset(GetFiller<Dtype>(filler_param));
47      }
48      scale_filler->Fill(this->blobs_[0].get());
49    }
50    if (channel_shared_) {
51      CHECK_EQ(this->blobs_[0]->count(), 1)
52          << "Scale size is inconsistent with prototxt config";
53    } else {
54      CHECK_EQ(this->blobs_[0]->count(), channels)
55          << "Scale size is inconsistent with prototxt config";
56    }
57    this->param_propagate_down_.resize(this->blobs_.size(), true);
58  }
</span>59  template <typename Dtype>
60  void NormalizeLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
61        const vector<Blob<Dtype>*>& top) {
62    CHECK_GE(bottom[0]->num_axes(), 2)
63        << "Number of axes of bottom blob must be >=2.";
64    top[0]->ReshapeLike(*bottom[0]);
65    buffer_.Reshape(1, bottom[0]->channels(),
66                     bottom[0]->height(), bottom[0]->width());
67    if (!across_spatial_) {
68      norm_.Reshape(bottom[0]->num(), 1, bottom[0]->height(), bottom[0]->width());
69    }
70    int spatial_dim = bottom[0]->height() * bottom[0]->width();
71    if (spatial_dim != sum_spatial_multiplier_.count()) {
72      sum_spatial_multiplier_.Reshape(
73          1, 1, bottom[0]->height(), bottom[0]->width());
74      caffe_set(spatial_dim, Dtype(1),
75                sum_spatial_multiplier_.mutable_cpu_data());
76      buffer_spatial_.Reshape(1, 1, bottom[0]->height(), bottom[0]->width());
77    }
78  }
79  template <typename Dtype>
80  void NormalizeLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
81      const vector<Blob<Dtype>*>& top) {
82    const Dtype* bottom_data = bottom[0]->cpu_data();
83    Dtype* top_data = top[0]->mutable_cpu_data();
84    const Dtype* scale = this->blobs_[0]->cpu_data();
85    Dtype* buffer_data = buffer_.mutable_cpu_data();
86    Dtype* norm_data = norm_.mutable_cpu_data();
87    caffe_set<Dtype>(norm_.count(), Dtype(eps_), norm_data);
88    const Dtype* sum_channel_multiplier = sum_channel_multiplier_.cpu_data();
89    const Dtype* sum_spatial_multiplier = sum_spatial_multiplier_.cpu_data();
90    int num = bottom[0]->num();
91    int dim = bottom[0]->count() / num;
92    int spatial_dim = bottom[0]->height() * bottom[0]->width();
93    int channels = bottom[0]->channels();
94    for (int n = 0; n < num; ++n) {
95      caffe_sqr<Dtype>(dim, bottom_data, buffer_data);
96      if (across_spatial_) {
97        norm_data[n] = pow(caffe_cpu_asum<Dtype>(dim, buffer_data)+eps_,
98                           Dtype(0.5));
99        caffe_cpu_scale<Dtype>(dim, Dtype(1.0 / norm_data[n]), bottom_data,
100                               top_data);
101      } else {
102        caffe_cpu_gemv<Dtype>(CblasTrans, channels, spatial_dim, Dtype(1),
103                              buffer_data, sum_channel_multiplier, Dtype(1),
104                              norm_data);
105        caffe_powx<Dtype>(spatial_dim, norm_data, Dtype(0.5), norm_data);
106        caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
107                              1, Dtype(1), sum_channel_multiplier, norm_data,
108                              Dtype(0), buffer_data);
109        caffe_div<Dtype>(dim, bottom_data, buffer_data, top_data);
110        norm_data += spatial_dim;
111      }
112      if (channel_shared_) {
113        caffe_scal<Dtype>(dim, scale[0], top_data);
114      } else {
115        caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
116                              1, Dtype(1), scale, sum_spatial_multiplier,
117                              Dtype(0),
118                              buffer_data);
119        caffe_mul<Dtype>(dim, top_data, buffer_data, top_data);
120      }
121      bottom_data += dim;
122      top_data += dim;
123    }
124  }
125  template <typename Dtype>
126  void NormalizeLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
127      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
128    const Dtype* top_diff = top[0]->cpu_diff();
129    const Dtype* top_data = top[0]->cpu_data();
130    const Dtype* bottom_data = bottom[0]->cpu_data();
131    Dtype* bottom_diff = bottom[0]->mutable_cpu_diff();
132    const Dtype* scale = this->blobs_[0]->cpu_data();
133    const Dtype* norm_data = norm_.cpu_data();
134    Dtype* buffer_data = buffer_.mutable_cpu_data();
135    Dtype* buffer_channel = buffer_channel_.mutable_cpu_data();
136    Dtype* buffer_spatial = buffer_spatial_.mutable_cpu_data();
137    const Dtype* sum_channel_multiplier = sum_channel_multiplier_.cpu_data();
138    const Dtype* sum_spatial_multiplier = sum_spatial_multiplier_.cpu_data();
139    int count = top[0]->count();
140    int num = top[0]->num();
141    int dim = count / num;
142    int spatial_dim = top[0]->height() * top[0]->width();
143    int channels = top[0]->channels();
144    if (this->param_propagate_down_[0]) {
145      Dtype* scale_diff = this->blobs_[0]->mutable_cpu_diff();
146      if (channel_shared_) {
147        scale_diff[0] +=
148            caffe_cpu_dot<Dtype>(count, top_data, top_diff) / scale[0];
149      } else {
150        for (int n = 0; n < num; ++n) {
151          caffe_mul<Dtype>(dim, top_data+n*dim, top_diff+n*dim, buffer_data);
152          caffe_cpu_gemv<Dtype>(CblasNoTrans, channels, spatial_dim, Dtype(1),
153                                buffer_data, sum_spatial_multiplier, Dtype(0),
154                                buffer_channel);
155          caffe_div<Dtype>(channels, buffer_channel, scale, buffer_channel);
156          caffe_add<Dtype>(channels, buffer_channel, scale_diff, scale_diff);
157        }
158      }
159    }
160    if (propagate_down[0]) {
161      for (int n = 0; n < num; ++n) {
162        if (across_spatial_) {
163          Dtype a = caffe_cpu_dot<Dtype>(dim, bottom_data, top_diff);
164          caffe_cpu_scale<Dtype>(dim, a / norm_data[n] / norm_data[n],
165                                 bottom_data, bottom_diff);
166          caffe_sub<Dtype>(dim, top_diff, bottom_diff, bottom_diff);
167          caffe_scal<Dtype>(dim, Dtype(1.0 / norm_data[n]), bottom_diff);
168        } else {
169          caffe_mul<Dtype>(dim, bottom_data, top_diff, buffer_data);
170          caffe_cpu_gemv<Dtype>(CblasTrans, channels, spatial_dim, Dtype(1),
171                                buffer_data, sum_channel_multiplier, Dtype(0),
172                                buffer_spatial);
173          caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
174                                1, Dtype(1), sum_channel_multiplier,
175                                buffer_spatial, Dtype(0), buffer_data);
176          caffe_mul<Dtype>(dim, bottom_data, buffer_data, bottom_diff);
177          caffe_powx<Dtype>(spatial_dim, norm_data, Dtype(2), buffer_spatial);
178          caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
179                                1, Dtype(1), sum_channel_multiplier,
180                                buffer_spatial, Dtype(0), buffer_data);
181          caffe_div<Dtype>(dim, bottom_diff, buffer_data, bottom_diff);
182          caffe_sub<Dtype>(dim, top_diff, bottom_diff, bottom_diff);
183          caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
184                                1, Dtype(1), sum_channel_multiplier, norm_data,
185                                Dtype(0), buffer_data);
186          caffe_div<Dtype>(dim, bottom_diff, buffer_data, bottom_diff);
187          norm_data += spatial_dim;
188        }
189        if (channel_shared_) {
190          caffe_scal<Dtype>(dim, scale[0], bottom_diff);
191        } else {
192          caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
193                                1, Dtype(1), scale, sum_spatial_multiplier,
194                                Dtype(0), buffer_data);
195          caffe_mul<Dtype>(dim, bottom_diff, buffer_data, bottom_diff);
196        }
197        bottom_data += dim;
198        top_diff += dim;
199        bottom_diff += dim;
200      }
201    }
202  }
203  #ifdef CPU_ONLY
204  STUB_GPU(NormalizeLayer);
205  #endif
206  INSTANTIATE_CLASS(NormalizeLayer);
207  REGISTER_LAYER_CLASS(Normalize);
208  }  
</code></pre>
        </div>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-normalize_layer.cpp</h3>
            <pre><code>1  #include <vector>
2  #include "caffe/filler.hpp"
3  #include "caffe/layers/normalize_layer.hpp"
4  namespace caffe {
5  template <typename Dtype>
6  void NormalizeLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
7        const vector<Blob<Dtype>*>& top) {
8    CHECK_GE(bottom[0]->num_axes(), 2)
9        << "Number of axes of bottom blob must be >=2.";
10    buffer_.Reshape(1, bottom[0]->channels(),
11                     bottom[0]->height(), bottom[0]->width());
12    buffer_channel_.Reshape(1, bottom[0]->channels(), 1, 1);
13    buffer_spatial_.Reshape(1, 1, bottom[0]->height(), bottom[0]->width());
14    NormalizeParameter norm_param = this->layer_param().norm_param();
15    across_spatial_ = norm_param.across_spatial();
16    if (across_spatial_) {
17      norm_.Reshape(bottom[0]->num(), 1, 1, 1);
18    } else {
19      norm_.Reshape(bottom[0]->num(), 1, bottom[0]->height(), bottom[0]->width());
20    }
21    eps_ = norm_param.eps();
22    int channels = bottom[0]->channels();
23    int spatial_dim = bottom[0]->width() * bottom[0]->height();
24    sum_channel_multiplier_.Reshape(1, channels, 1, 1);
25    caffe_set(channels, Dtype(1), sum_channel_multiplier_.mutable_cpu_data());
26    sum_spatial_multiplier_.Reshape(
27        1, 1, bottom[0]->height(), bottom[0]->width());
28    caffe_set(spatial_dim, Dtype(1), sum_spatial_multiplier_.mutable_cpu_data());
29    channel_shared_ = norm_param.channel_shared();
30    if (this->blobs_.size() > 0) {
31      LOG(INFO) << "Skipping parameter initialization";
32    } else {
33      this->blobs_.resize(1);
34      if (channel_shared_) {
35        this->blobs_[0].reset(new Blob<Dtype>(vector<int>(0)));
36      } else {
37        this->blobs_[0].reset(new Blob<Dtype>(vector<int>(1, channels)));
38      }
39      shared_ptr<Filler<Dtype> > scale_filler;
40      if (norm_param.has_scale_filler()) {
41        scale_filler.reset(GetFiller<Dtype>(norm_param.scale_filler()));
42      } else {
43        FillerParameter filler_param;
44        filler_param.set_type("constant");
<span onclick='openModal()' class='match'>45        filler_param.set_value(1.0);
46        scale_filler.reset(GetFiller<Dtype>(filler_param));
47      }
48      scale_filler->Fill(this->blobs_[0].get());
49    }
50    if (channel_shared_) {
51      CHECK_EQ(this->blobs_[0]->count(), 1)
52          << "Scale size is inconsistent with prototxt config";
53    } else {
54      CHECK_EQ(this->blobs_[0]->count(), channels)
55          << "Scale size is inconsistent with prototxt config";
56    }
57    this->param_propagate_down_.resize(this->blobs_.size(), true);
58  }
</span>59  template <typename Dtype>
60  void NormalizeLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
61        const vector<Blob<Dtype>*>& top) {
62    CHECK_GE(bottom[0]->num_axes(), 2)
63        << "Number of axes of bottom blob must be >=2.";
64    top[0]->ReshapeLike(*bottom[0]);
65    buffer_.Reshape(1, bottom[0]->channels(),
66                     bottom[0]->height(), bottom[0]->width());
67    if (!across_spatial_) {
68      norm_.Reshape(bottom[0]->num(), 1, bottom[0]->height(), bottom[0]->width());
69    }
70    int spatial_dim = bottom[0]->height() * bottom[0]->width();
71    if (spatial_dim != sum_spatial_multiplier_.count()) {
72      sum_spatial_multiplier_.Reshape(
73          1, 1, bottom[0]->height(), bottom[0]->width());
74      caffe_set(spatial_dim, Dtype(1),
75                sum_spatial_multiplier_.mutable_cpu_data());
76      buffer_spatial_.Reshape(1, 1, bottom[0]->height(), bottom[0]->width());
77    }
78  }
79  template <typename Dtype>
80  void NormalizeLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
81      const vector<Blob<Dtype>*>& top) {
82    const Dtype* bottom_data = bottom[0]->cpu_data();
83    Dtype* top_data = top[0]->mutable_cpu_data();
84    const Dtype* scale = this->blobs_[0]->cpu_data();
85    Dtype* buffer_data = buffer_.mutable_cpu_data();
86    Dtype* norm_data = norm_.mutable_cpu_data();
87    caffe_set<Dtype>(norm_.count(), Dtype(eps_), norm_data);
88    const Dtype* sum_channel_multiplier = sum_channel_multiplier_.cpu_data();
89    const Dtype* sum_spatial_multiplier = sum_spatial_multiplier_.cpu_data();
90    int num = bottom[0]->num();
91    int dim = bottom[0]->count() / num;
92    int spatial_dim = bottom[0]->height() * bottom[0]->width();
93    int channels = bottom[0]->channels();
94    for (int n = 0; n < num; ++n) {
95      caffe_sqr<Dtype>(dim, bottom_data, buffer_data);
96      if (across_spatial_) {
97        norm_data[n] = pow(caffe_cpu_asum<Dtype>(dim, buffer_data)+eps_,
98                           Dtype(0.5));
99        caffe_cpu_scale<Dtype>(dim, Dtype(1.0 / norm_data[n]), bottom_data,
100                               top_data);
101      } else {
102        caffe_cpu_gemv<Dtype>(CblasTrans, channels, spatial_dim, Dtype(1),
103                              buffer_data, sum_channel_multiplier, Dtype(1),
104                              norm_data);
105        caffe_powx<Dtype>(spatial_dim, norm_data, Dtype(0.5), norm_data);
106        caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
107                              1, Dtype(1), sum_channel_multiplier, norm_data,
108                              Dtype(0), buffer_data);
109        caffe_div<Dtype>(dim, bottom_data, buffer_data, top_data);
110        norm_data += spatial_dim;
111      }
112      if (channel_shared_) {
113        caffe_scal<Dtype>(dim, scale[0], top_data);
114      } else {
115        caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
116                              1, Dtype(1), scale, sum_spatial_multiplier,
117                              Dtype(0),
118                              buffer_data);
119        caffe_mul<Dtype>(dim, top_data, buffer_data, top_data);
120      }
121      bottom_data += dim;
122      top_data += dim;
123    }
124  }
125  template <typename Dtype>
126  void NormalizeLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
127      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
128    const Dtype* top_diff = top[0]->cpu_diff();
129    const Dtype* top_data = top[0]->cpu_data();
130    const Dtype* bottom_data = bottom[0]->cpu_data();
131    Dtype* bottom_diff = bottom[0]->mutable_cpu_diff();
132    const Dtype* scale = this->blobs_[0]->cpu_data();
133    const Dtype* norm_data = norm_.cpu_data();
134    Dtype* buffer_data = buffer_.mutable_cpu_data();
135    Dtype* buffer_channel = buffer_channel_.mutable_cpu_data();
136    Dtype* buffer_spatial = buffer_spatial_.mutable_cpu_data();
137    const Dtype* sum_channel_multiplier = sum_channel_multiplier_.cpu_data();
138    const Dtype* sum_spatial_multiplier = sum_spatial_multiplier_.cpu_data();
139    int count = top[0]->count();
140    int num = top[0]->num();
141    int dim = count / num;
142    int spatial_dim = top[0]->height() * top[0]->width();
143    int channels = top[0]->channels();
144    if (this->param_propagate_down_[0]) {
145      Dtype* scale_diff = this->blobs_[0]->mutable_cpu_diff();
146      if (channel_shared_) {
147        scale_diff[0] +=
148            caffe_cpu_dot<Dtype>(count, top_data, top_diff) / scale[0];
149      } else {
150        for (int n = 0; n < num; ++n) {
151          caffe_mul<Dtype>(dim, top_data+n*dim, top_diff+n*dim, buffer_data);
152          caffe_cpu_gemv<Dtype>(CblasNoTrans, channels, spatial_dim, Dtype(1),
153                                buffer_data, sum_spatial_multiplier, Dtype(0),
154                                buffer_channel);
155          caffe_div<Dtype>(channels, buffer_channel, scale, buffer_channel);
156          caffe_add<Dtype>(channels, buffer_channel, scale_diff, scale_diff);
157        }
158      }
159    }
160    if (propagate_down[0]) {
161      for (int n = 0; n < num; ++n) {
162        if (across_spatial_) {
163          Dtype a = caffe_cpu_dot<Dtype>(dim, bottom_data, top_diff);
164          caffe_cpu_scale<Dtype>(dim, a / norm_data[n] / norm_data[n],
165                                 bottom_data, bottom_diff);
166          caffe_sub<Dtype>(dim, top_diff, bottom_diff, bottom_diff);
167          caffe_scal<Dtype>(dim, Dtype(1.0 / norm_data[n]), bottom_diff);
168        } else {
169          caffe_mul<Dtype>(dim, bottom_data, top_diff, buffer_data);
170          caffe_cpu_gemv<Dtype>(CblasTrans, channels, spatial_dim, Dtype(1),
171                                buffer_data, sum_channel_multiplier, Dtype(0),
172                                buffer_spatial);
173          caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
174                                1, Dtype(1), sum_channel_multiplier,
175                                buffer_spatial, Dtype(0), buffer_data);
176          caffe_mul<Dtype>(dim, bottom_data, buffer_data, bottom_diff);
177          caffe_powx<Dtype>(spatial_dim, norm_data, Dtype(2), buffer_spatial);
178          caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
179                                1, Dtype(1), sum_channel_multiplier,
180                                buffer_spatial, Dtype(0), buffer_data);
181          caffe_div<Dtype>(dim, bottom_diff, buffer_data, bottom_diff);
182          caffe_sub<Dtype>(dim, top_diff, bottom_diff, bottom_diff);
183          caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
184                                1, Dtype(1), sum_channel_multiplier, norm_data,
185                                Dtype(0), buffer_data);
186          caffe_div<Dtype>(dim, bottom_diff, buffer_data, bottom_diff);
187          norm_data += spatial_dim;
188        }
189        if (channel_shared_) {
190          caffe_scal<Dtype>(dim, scale[0], bottom_diff);
191        } else {
192          caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels, spatial_dim,
193                                1, Dtype(1), scale, sum_spatial_multiplier,
194                                Dtype(0), buffer_data);
195          caffe_mul<Dtype>(dim, bottom_diff, buffer_data, bottom_diff);
196        }
197        bottom_data += dim;
198        top_diff += dim;
199        bottom_diff += dim;
200      }
201    }
202  }
203  #ifdef CPU_ONLY
204  STUB_GPU(NormalizeLayer);
205  #endif
206  INSTANTIATE_CLASS(NormalizeLayer);
207  REGISTER_LAYER_CLASS(Normalize);
208  }  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-normalize_layer.cpp</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-normalize_layer.cpp</div>
                </div>
                <div class="column column_space"><pre><code>45        filler_param.set_value(1.0);
46        scale_filler.reset(GetFiller<Dtype>(filler_param));
47      }
48      scale_filler->Fill(this->blobs_[0].get());
49    }
50    if (channel_shared_) {
51      CHECK_EQ(this->blobs_[0]->count(), 1)
52          << "Scale size is inconsistent with prototxt config";
53    } else {
54      CHECK_EQ(this->blobs_[0]->count(), channels)
55          << "Scale size is inconsistent with prototxt config";
56    }
57    this->param_propagate_down_.resize(this->blobs_.size(), true);
58  }
</pre></code></div>
                <div class="column column_space"><pre><code>45        filler_param.set_value(1.0);
46        scale_filler.reset(GetFiller<Dtype>(filler_param));
47      }
48      scale_filler->Fill(this->blobs_[0].get());
49    }
50    if (channel_shared_) {
51      CHECK_EQ(this->blobs_[0]->count(), 1)
52          << "Scale size is inconsistent with prototxt config";
53    } else {
54      CHECK_EQ(this->blobs_[0]->count(), channels)
55          << "Scale size is inconsistent with prototxt config";
56    }
57    this->param_propagate_down_.resize(this->blobs_.size(), true);
58  }
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    