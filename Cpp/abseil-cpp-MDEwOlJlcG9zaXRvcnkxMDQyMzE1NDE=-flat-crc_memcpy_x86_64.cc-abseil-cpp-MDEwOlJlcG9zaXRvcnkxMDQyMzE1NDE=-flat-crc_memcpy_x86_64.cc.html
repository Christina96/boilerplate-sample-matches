
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 23, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>abseil-cpp-MDEwOlJlcG9zaXRvcnkxMDQyMzE1NDE=-flat-crc_memcpy_x86_64.cc</h3>
            <pre><code>1  #ifdef __SSE4_2__
2  #include <immintrin.h>
3  #endif
4  #ifdef _MSC_VER
5  #include <intrin.h>
6  #endif
7  #include <array>
8  #include <cstddef>
9  #include <cstdint>
10  #include <type_traits>
11  #include "absl/base/dynamic_annotations.h"
12  #include "absl/base/optimization.h"
13  #include "absl/base/prefetch.h"
14  #include "absl/crc/crc32c.h"
15  #include "absl/crc/internal/cpu_detect.h"
16  #include "absl/crc/internal/crc_memcpy.h"
17  #include "absl/strings/string_view.h"
18  #ifdef ABSL_INTERNAL_HAVE_X86_64_ACCELERATED_CRC_MEMCPY_ENGINE
19  namespace absl {
20  ABSL_NAMESPACE_BEGIN
21  namespace crc_internal {
22  namespace {
23  inline crc32c_t ShortCrcCopy(char* dst, const char* src, std::size_t length,
24                               crc32c_t crc) {
25    uint32_t crc_uint32 = static_cast<uint32_t>(crc);
26    for (std::size_t i = 0; i < length; i++) {
27      uint8_t data = *reinterpret_cast<const uint8_t*>(src);
28      crc_uint32 = _mm_crc32_u8(crc_uint32, data);
29      *reinterpret_cast<uint8_t*>(dst) = data;
30      ++src;
31      ++dst;
32    }
33    return crc32c_t{crc_uint32};
34  }
35  constexpr size_t kIntLoadsPerVec = sizeof(__m128i) / sizeof(uint64_t);
36  template <size_t vec_regions, size_t int_regions>
37  inline void LargeTailCopy(crc32c_t* crcs, char** dst, const char** src,
38                            size_t region_size, size_t copy_rounds) {
39    std::array<__m128i, vec_regions> data;
40    std::array<uint64_t, kIntLoadsPerVec * int_regions> int_data;
41    while (copy_rounds > 0) {
42      for (size_t i = 0; i < vec_regions; i++) {
43        size_t region = i;
44        auto* vsrc =
45            reinterpret_cast<const __m128i*>(*src + region_size * region);
46        auto* vdst = reinterpret_cast<__m128i*>(*dst + region_size * region);
47        data[i] = _mm_loadu_si128(vsrc);
48        _mm_store_si128(vdst, data[i]);
49        crcs[region] = crc32c_t{static_cast<uint32_t>(
50            _mm_crc32_u64(static_cast<uint32_t>(crcs[region]),
51                          static_cast<uint64_t>(_mm_extract_epi64(data[i], 0))))};
52        crcs[region] = crc32c_t{static_cast<uint32_t>(
53            _mm_crc32_u64(static_cast<uint32_t>(crcs[region]),
54                          static_cast<uint64_t>(_mm_extract_epi64(data[i], 1))))};
55      }
56      for (size_t i = 0; i < int_regions; i++) {
57        size_t region = vec_regions + i;
58        auto* usrc =
59            reinterpret_cast<const uint64_t*>(*src + region_size * region);
60        auto* udst = reinterpret_cast<uint64_t*>(*dst + region_size * region);
61        for (size_t j = 0; j < kIntLoadsPerVec; j++) {
62          size_t data_index = i * kIntLoadsPerVec + j;
63          int_data[data_index] = *(usrc + j);
64          crcs[region] = crc32c_t{static_cast<uint32_t>(_mm_crc32_u64(
65              static_cast<uint32_t>(crcs[region]), int_data[data_index]))};
66          *(udst + j) = int_data[data_index];
67        }
68      }
69      *src += sizeof(__m128i);
70      *dst += sizeof(__m128i);
71      --copy_rounds;
72    }
73  }
74  }  
75  template <size_t vec_regions, size_t int_regions>
76  class AcceleratedCrcMemcpyEngine : public CrcMemcpyEngine {
77   public:
78    AcceleratedCrcMemcpyEngine() = default;
79    AcceleratedCrcMemcpyEngine(const AcceleratedCrcMemcpyEngine&) = delete;
80    AcceleratedCrcMemcpyEngine operator=(const AcceleratedCrcMemcpyEngine&) =
81        delete;
82    crc32c_t Compute(void* __restrict dst, const void* __restrict src,
83                     std::size_t length, crc32c_t initial_crc) const override;
84  };
85  template <size_t vec_regions, size_t int_regions>
86  crc32c_t AcceleratedCrcMemcpyEngine<vec_regions, int_regions>::Compute(
87      void* __restrict dst, const void* __restrict src, std::size_t length,
88      crc32c_t initial_crc) const {
89    constexpr std::size_t kRegions = vec_regions + int_regions;
90    constexpr uint32_t kCrcDataXor = uint32_t{0xffffffff};
91    constexpr std::size_t kBlockSize = sizeof(__m128i);
92    constexpr std::size_t kCopyRoundSize = kRegions * kBlockSize;
93    constexpr std::size_t kBlocksPerCacheLine = ABSL_CACHELINE_SIZE / kBlockSize;
94    char* dst_bytes = static_cast<char*>(dst);
95    const char* src_bytes = static_cast<const char*>(src);
96    static_assert(ABSL_CACHELINE_SIZE % kBlockSize == 0,
97                  "Cache lines are not divided evenly into blocks, may have "
98                  "unintended behavior!");
99    constexpr size_t kCrcSmallSize = 256;
100    constexpr std::size_t kPrefetchAhead = 2 * ABSL_CACHELINE_SIZE;
101    if (length < kCrcSmallSize) {
102      crc32c_t crc =
103          ExtendCrc32c(initial_crc, absl::string_view(src_bytes, length));
104      memcpy(dst, src, length);
105      return crc;
106    }
107    initial_crc = crc32c_t{static_cast<uint32_t>(initial_crc) ^ kCrcDataXor};
108    std::size_t bytes_from_last_aligned =
109        reinterpret_cast<uintptr_t>(dst) & (kBlockSize - 1);
110    if (bytes_from_last_aligned != 0) {
111      std::size_t bytes_for_alignment = kBlockSize - bytes_from_last_aligned;
112      initial_crc =
113          ShortCrcCopy(dst_bytes, src_bytes, bytes_for_alignment, initial_crc);
114      src_bytes += bytes_for_alignment;
115      dst_bytes += bytes_for_alignment;
116      length -= bytes_for_alignment;
117    }
118    crc32c_t crcs[kRegions];
119    crcs[0] = initial_crc;
120    for (size_t i = 1; i < kRegions; i++) {
121      crcs[i] = crc32c_t{kCrcDataXor};
122    }
123    size_t copy_rounds = length / kCopyRoundSize;
124    const std::size_t region_size = copy_rounds * kBlockSize;
125    const std::size_t tail_size = length - (kRegions * region_size);
126    std::array<__m128i, vec_regions> vec_data;
127    std::array<uint64_t, int_regions * kIntLoadsPerVec> int_data;
128    while (copy_rounds > kBlocksPerCacheLine) {
129      for (size_t i = 0; i < kRegions; i++) {
130        absl::PrefetchToLocalCache(src_bytes + kPrefetchAhead + region_size * i);
131        absl::PrefetchToLocalCache(dst_bytes + kPrefetchAhead + region_size * i);
132      }
133      for (size_t i = 0; i < kBlocksPerCacheLine; i++) {
134        for (size_t j = 0; j < vec_regions; j++) {
135          size_t region = (j + i) % kRegions;
136          auto* vsrc =
137              reinterpret_cast<const __m128i*>(src_bytes + region_size * region);
138          auto* vdst =
139              reinterpret_cast<__m128i*>(dst_bytes + region_size * region);
140          vec_data[j] = _mm_loadu_si128(vsrc + i);
141          crcs[region] = crc32c_t{static_cast<uint32_t>(_mm_crc32_u64(
142              static_cast<uint32_t>(crcs[region]),
143              static_cast<uint64_t>(_mm_extract_epi64(vec_data[j], 0))))};
144          crcs[region] = crc32c_t{static_cast<uint32_t>(_mm_crc32_u64(
145              static_cast<uint32_t>(crcs[region]),
146              static_cast<uint64_t>(_mm_extract_epi64(vec_data[j], 1))))};
147          _mm_store_si128(vdst + i, vec_data[j]);
148        }
149        for (size_t j = 0; j < int_regions; j++) {
150          size_t region = (j + vec_regions + i) % kRegions;
151          auto* usrc =
152              reinterpret_cast<const uint64_t*>(src_bytes + region_size * region);
153          auto* udst =
154              reinterpret_cast<uint64_t*>(dst_bytes + region_size * region);
155          for (size_t k = 0; k < kIntLoadsPerVec; k++) {
156            size_t data_index = j * kIntLoadsPerVec + k;
157            int_data[data_index] = *(usrc + i * kIntLoadsPerVec + k);
158            crcs[region] = crc32c_t{static_cast<uint32_t>(_mm_crc32_u64(
159                static_cast<uint32_t>(crcs[region]), int_data[data_index]))};
160            *(udst + i * kIntLoadsPerVec + k) = int_data[data_index];
161          }
162        }
163      }
164      src_bytes += kBlockSize * kBlocksPerCacheLine;
165      dst_bytes += kBlockSize * kBlocksPerCacheLine;
166      copy_rounds -= kBlocksPerCacheLine;
167    }
168    LargeTailCopy<vec_regions, int_regions>(crcs, &dst_bytes, &src_bytes,
169                                            region_size, copy_rounds);
170    src_bytes += region_size * (kRegions - 1);
171    dst_bytes += region_size * (kRegions - 1);
172    for (size_t i = 0; i + 1 < kRegions; i++) {
173      crcs[i] = crc32c_t{static_cast<uint32_t>(crcs[i]) ^ kCrcDataXor};
174    }
175    crc32c_t full_crc = crcs[0];
176    for (size_t i = 1; i + 1 < kRegions; i++) {
177      full_crc = ConcatCrc32c(full_crc, crcs[i], region_size);
178    }
179    std::size_t tail_blocks = tail_size / kBlockSize;
180    LargeTailCopy<0, 1>(&crcs[kRegions - 1], &dst_bytes, &src_bytes, 0,
181                        tail_blocks);
182    crcs[kRegions - 1] =
183        ShortCrcCopy(dst_bytes, src_bytes, tail_size - tail_blocks * kBlockSize,
184                     crcs[kRegions - 1]);
185    crcs[kRegions - 1] =
186        crc32c_t{static_cast<uint32_t>(crcs[kRegions - 1]) ^ kCrcDataXor};
187    return ConcatCrc32c(full_crc, crcs[kRegions - 1], region_size + tail_size);
188  }
189  CrcMemcpy::ArchSpecificEngines CrcMemcpy::GetArchSpecificEngines() {
190  #ifdef UNDEFINED_BEHAVIOR_SANITIZER
191    CpuType cpu_type = GetCpuType();
192    switch (cpu_type) {
193      case CpuType::kUnknown:
194      case CpuType::kAmdRome:
195      case CpuType::kAmdNaples:
196      case CpuType::kIntelCascadelakeXeon:
197      case CpuType::kIntelSkylakeXeon:
198      case CpuType::kIntelSkylake:
199      case CpuType::kIntelBroadwell:
200      case CpuType::kIntelHaswell:
201      case CpuType::kIntelIvybridge:
202        return {
203            new FallbackCrcMemcpyEngine(),
204            new CrcNonTemporalMemcpyAVXEngine(),
205        };
206      case CpuType::kIntelSandybridge:
207        return {
208            new FallbackCrcMemcpyEngine(),
209            new CrcNonTemporalMemcpyEngine(),
210        };
211      default:
212        return {&bsol;*.temporal=*/new FallbackCrcMemcpyEngine(),
213                new FallbackCrcMemcpyEngine()};
214    }
215  #else
216    CpuType cpu_type = GetCpuType();
217    switch (cpu_type) {
218      case CpuType::kAmdRome:
219      case CpuType::kAmdNaples:
220        return {
221            new AcceleratedCrcMemcpyEngine<1, 2>(),
222            new CrcNonTemporalMemcpyAVXEngine(),
223        };
224      case CpuType::kIntelCascadelakeXeon:
225      case CpuType::kIntelSkylakeXeon:
226      case CpuType::kIntelSkylake:
227      case CpuType::kIntelBroadwell:
228      case CpuType::kIntelHaswell:
229      case CpuType::kIntelIvybridge:
230        return {
231            new AcceleratedCrcMemcpyEngine<3, 0>(),
232            new CrcNonTemporalMemcpyAVXEngine(),
233        };
234      case CpuType::kIntelSandybridge:
235        return {
236            new AcceleratedCrcMemcpyEngine<3, 0>(),
237            new CrcNonTemporalMemcpyEngine(),
238        };
239      default:
<span onclick='openModal()' class='match'>240        return {&bsol;*.temporal=*/new FallbackCrcMemcpyEngine(),
241                new FallbackCrcMemcpyEngine()};
242    }
243  #endif  
</span>244  }
245  std::unique_ptr<CrcMemcpyEngine> CrcMemcpy::GetTestEngine(int vector,
246                                                            int integer) {
247    if (vector == 3 && integer == 0) {
248      return std::make_unique<AcceleratedCrcMemcpyEngine<3, 0>>();
249    } else if (vector == 1 && integer == 2) {
250      return std::make_unique<AcceleratedCrcMemcpyEngine<1, 2>>();
251    }
252    return nullptr;
253  }
254  }  
255  ABSL_NAMESPACE_END
256  }  
257  #endif  
</code></pre>
        </div>
        <div class="column">
            <h3>abseil-cpp-MDEwOlJlcG9zaXRvcnkxMDQyMzE1NDE=-flat-crc_memcpy_x86_64.cc</h3>
            <pre><code>1  #ifdef __SSE4_2__
2  #include <immintrin.h>
3  #endif
4  #ifdef _MSC_VER
5  #include <intrin.h>
6  #endif
7  #include <array>
8  #include <cstddef>
9  #include <cstdint>
10  #include <type_traits>
11  #include "absl/base/dynamic_annotations.h"
12  #include "absl/base/optimization.h"
13  #include "absl/base/prefetch.h"
14  #include "absl/crc/crc32c.h"
15  #include "absl/crc/internal/cpu_detect.h"
16  #include "absl/crc/internal/crc_memcpy.h"
17  #include "absl/strings/string_view.h"
18  #ifdef ABSL_INTERNAL_HAVE_X86_64_ACCELERATED_CRC_MEMCPY_ENGINE
19  namespace absl {
20  ABSL_NAMESPACE_BEGIN
21  namespace crc_internal {
22  namespace {
23  inline crc32c_t ShortCrcCopy(char* dst, const char* src, std::size_t length,
24                               crc32c_t crc) {
25    uint32_t crc_uint32 = static_cast<uint32_t>(crc);
26    for (std::size_t i = 0; i < length; i++) {
27      uint8_t data = *reinterpret_cast<const uint8_t*>(src);
28      crc_uint32 = _mm_crc32_u8(crc_uint32, data);
29      *reinterpret_cast<uint8_t*>(dst) = data;
30      ++src;
31      ++dst;
32    }
33    return crc32c_t{crc_uint32};
34  }
35  constexpr size_t kIntLoadsPerVec = sizeof(__m128i) / sizeof(uint64_t);
36  template <size_t vec_regions, size_t int_regions>
37  inline void LargeTailCopy(crc32c_t* crcs, char** dst, const char** src,
38                            size_t region_size, size_t copy_rounds) {
39    std::array<__m128i, vec_regions> data;
40    std::array<uint64_t, kIntLoadsPerVec * int_regions> int_data;
41    while (copy_rounds > 0) {
42      for (size_t i = 0; i < vec_regions; i++) {
43        size_t region = i;
44        auto* vsrc =
45            reinterpret_cast<const __m128i*>(*src + region_size * region);
46        auto* vdst = reinterpret_cast<__m128i*>(*dst + region_size * region);
47        data[i] = _mm_loadu_si128(vsrc);
48        _mm_store_si128(vdst, data[i]);
49        crcs[region] = crc32c_t{static_cast<uint32_t>(
50            _mm_crc32_u64(static_cast<uint32_t>(crcs[region]),
51                          static_cast<uint64_t>(_mm_extract_epi64(data[i], 0))))};
52        crcs[region] = crc32c_t{static_cast<uint32_t>(
53            _mm_crc32_u64(static_cast<uint32_t>(crcs[region]),
54                          static_cast<uint64_t>(_mm_extract_epi64(data[i], 1))))};
55      }
56      for (size_t i = 0; i < int_regions; i++) {
57        size_t region = vec_regions + i;
58        auto* usrc =
59            reinterpret_cast<const uint64_t*>(*src + region_size * region);
60        auto* udst = reinterpret_cast<uint64_t*>(*dst + region_size * region);
61        for (size_t j = 0; j < kIntLoadsPerVec; j++) {
62          size_t data_index = i * kIntLoadsPerVec + j;
63          int_data[data_index] = *(usrc + j);
64          crcs[region] = crc32c_t{static_cast<uint32_t>(_mm_crc32_u64(
65              static_cast<uint32_t>(crcs[region]), int_data[data_index]))};
66          *(udst + j) = int_data[data_index];
67        }
68      }
69      *src += sizeof(__m128i);
70      *dst += sizeof(__m128i);
71      --copy_rounds;
72    }
73  }
74  }  
75  template <size_t vec_regions, size_t int_regions>
76  class AcceleratedCrcMemcpyEngine : public CrcMemcpyEngine {
77   public:
78    AcceleratedCrcMemcpyEngine() = default;
79    AcceleratedCrcMemcpyEngine(const AcceleratedCrcMemcpyEngine&) = delete;
80    AcceleratedCrcMemcpyEngine operator=(const AcceleratedCrcMemcpyEngine&) =
81        delete;
82    crc32c_t Compute(void* __restrict dst, const void* __restrict src,
83                     std::size_t length, crc32c_t initial_crc) const override;
84  };
85  template <size_t vec_regions, size_t int_regions>
86  crc32c_t AcceleratedCrcMemcpyEngine<vec_regions, int_regions>::Compute(
87      void* __restrict dst, const void* __restrict src, std::size_t length,
88      crc32c_t initial_crc) const {
89    constexpr std::size_t kRegions = vec_regions + int_regions;
90    constexpr uint32_t kCrcDataXor = uint32_t{0xffffffff};
91    constexpr std::size_t kBlockSize = sizeof(__m128i);
92    constexpr std::size_t kCopyRoundSize = kRegions * kBlockSize;
93    constexpr std::size_t kBlocksPerCacheLine = ABSL_CACHELINE_SIZE / kBlockSize;
94    char* dst_bytes = static_cast<char*>(dst);
95    const char* src_bytes = static_cast<const char*>(src);
96    static_assert(ABSL_CACHELINE_SIZE % kBlockSize == 0,
97                  "Cache lines are not divided evenly into blocks, may have "
98                  "unintended behavior!");
99    constexpr size_t kCrcSmallSize = 256;
100    constexpr std::size_t kPrefetchAhead = 2 * ABSL_CACHELINE_SIZE;
101    if (length < kCrcSmallSize) {
102      crc32c_t crc =
103          ExtendCrc32c(initial_crc, absl::string_view(src_bytes, length));
104      memcpy(dst, src, length);
105      return crc;
106    }
107    initial_crc = crc32c_t{static_cast<uint32_t>(initial_crc) ^ kCrcDataXor};
108    std::size_t bytes_from_last_aligned =
109        reinterpret_cast<uintptr_t>(dst) & (kBlockSize - 1);
110    if (bytes_from_last_aligned != 0) {
111      std::size_t bytes_for_alignment = kBlockSize - bytes_from_last_aligned;
112      initial_crc =
113          ShortCrcCopy(dst_bytes, src_bytes, bytes_for_alignment, initial_crc);
114      src_bytes += bytes_for_alignment;
115      dst_bytes += bytes_for_alignment;
116      length -= bytes_for_alignment;
117    }
118    crc32c_t crcs[kRegions];
119    crcs[0] = initial_crc;
120    for (size_t i = 1; i < kRegions; i++) {
121      crcs[i] = crc32c_t{kCrcDataXor};
122    }
123    size_t copy_rounds = length / kCopyRoundSize;
124    const std::size_t region_size = copy_rounds * kBlockSize;
125    const std::size_t tail_size = length - (kRegions * region_size);
126    std::array<__m128i, vec_regions> vec_data;
127    std::array<uint64_t, int_regions * kIntLoadsPerVec> int_data;
128    while (copy_rounds > kBlocksPerCacheLine) {
129      for (size_t i = 0; i < kRegions; i++) {
130        absl::PrefetchToLocalCache(src_bytes + kPrefetchAhead + region_size * i);
131        absl::PrefetchToLocalCache(dst_bytes + kPrefetchAhead + region_size * i);
132      }
133      for (size_t i = 0; i < kBlocksPerCacheLine; i++) {
134        for (size_t j = 0; j < vec_regions; j++) {
135          size_t region = (j + i) % kRegions;
136          auto* vsrc =
137              reinterpret_cast<const __m128i*>(src_bytes + region_size * region);
138          auto* vdst =
139              reinterpret_cast<__m128i*>(dst_bytes + region_size * region);
140          vec_data[j] = _mm_loadu_si128(vsrc + i);
141          crcs[region] = crc32c_t{static_cast<uint32_t>(_mm_crc32_u64(
142              static_cast<uint32_t>(crcs[region]),
143              static_cast<uint64_t>(_mm_extract_epi64(vec_data[j], 0))))};
144          crcs[region] = crc32c_t{static_cast<uint32_t>(_mm_crc32_u64(
145              static_cast<uint32_t>(crcs[region]),
146              static_cast<uint64_t>(_mm_extract_epi64(vec_data[j], 1))))};
147          _mm_store_si128(vdst + i, vec_data[j]);
148        }
149        for (size_t j = 0; j < int_regions; j++) {
150          size_t region = (j + vec_regions + i) % kRegions;
151          auto* usrc =
152              reinterpret_cast<const uint64_t*>(src_bytes + region_size * region);
153          auto* udst =
154              reinterpret_cast<uint64_t*>(dst_bytes + region_size * region);
155          for (size_t k = 0; k < kIntLoadsPerVec; k++) {
156            size_t data_index = j * kIntLoadsPerVec + k;
157            int_data[data_index] = *(usrc + i * kIntLoadsPerVec + k);
158            crcs[region] = crc32c_t{static_cast<uint32_t>(_mm_crc32_u64(
159                static_cast<uint32_t>(crcs[region]), int_data[data_index]))};
160            *(udst + i * kIntLoadsPerVec + k) = int_data[data_index];
161          }
162        }
163      }
164      src_bytes += kBlockSize * kBlocksPerCacheLine;
165      dst_bytes += kBlockSize * kBlocksPerCacheLine;
166      copy_rounds -= kBlocksPerCacheLine;
167    }
168    LargeTailCopy<vec_regions, int_regions>(crcs, &dst_bytes, &src_bytes,
169                                            region_size, copy_rounds);
170    src_bytes += region_size * (kRegions - 1);
171    dst_bytes += region_size * (kRegions - 1);
172    for (size_t i = 0; i + 1 < kRegions; i++) {
173      crcs[i] = crc32c_t{static_cast<uint32_t>(crcs[i]) ^ kCrcDataXor};
174    }
175    crc32c_t full_crc = crcs[0];
176    for (size_t i = 1; i + 1 < kRegions; i++) {
177      full_crc = ConcatCrc32c(full_crc, crcs[i], region_size);
178    }
179    std::size_t tail_blocks = tail_size / kBlockSize;
180    LargeTailCopy<0, 1>(&crcs[kRegions - 1], &dst_bytes, &src_bytes, 0,
181                        tail_blocks);
182    crcs[kRegions - 1] =
183        ShortCrcCopy(dst_bytes, src_bytes, tail_size - tail_blocks * kBlockSize,
184                     crcs[kRegions - 1]);
185    crcs[kRegions - 1] =
186        crc32c_t{static_cast<uint32_t>(crcs[kRegions - 1]) ^ kCrcDataXor};
187    return ConcatCrc32c(full_crc, crcs[kRegions - 1], region_size + tail_size);
188  }
189  CrcMemcpy::ArchSpecificEngines CrcMemcpy::GetArchSpecificEngines() {
190  #ifdef UNDEFINED_BEHAVIOR_SANITIZER
191    CpuType cpu_type = GetCpuType();
192    switch (cpu_type) {
193      case CpuType::kUnknown:
194      case CpuType::kAmdRome:
195      case CpuType::kAmdNaples:
196      case CpuType::kIntelCascadelakeXeon:
197      case CpuType::kIntelSkylakeXeon:
198      case CpuType::kIntelSkylake:
199      case CpuType::kIntelBroadwell:
200      case CpuType::kIntelHaswell:
201      case CpuType::kIntelIvybridge:
202        return {
203            new FallbackCrcMemcpyEngine(),
204            new CrcNonTemporalMemcpyAVXEngine(),
205        };
206      case CpuType::kIntelSandybridge:
207        return {
208            new FallbackCrcMemcpyEngine(),
209            new CrcNonTemporalMemcpyEngine(),
210        };
211      default:
<span onclick='openModal()' class='match'>212        return {&bsol;*.temporal=*/new FallbackCrcMemcpyEngine(),
213                new FallbackCrcMemcpyEngine()};
214    }
215  #else
</span>216    CpuType cpu_type = GetCpuType();
217    switch (cpu_type) {
218      case CpuType::kAmdRome:
219      case CpuType::kAmdNaples:
220        return {
221            new AcceleratedCrcMemcpyEngine<1, 2>(),
222            new CrcNonTemporalMemcpyAVXEngine(),
223        };
224      case CpuType::kIntelCascadelakeXeon:
225      case CpuType::kIntelSkylakeXeon:
226      case CpuType::kIntelSkylake:
227      case CpuType::kIntelBroadwell:
228      case CpuType::kIntelHaswell:
229      case CpuType::kIntelIvybridge:
230        return {
231            new AcceleratedCrcMemcpyEngine<3, 0>(),
232            new CrcNonTemporalMemcpyAVXEngine(),
233        };
234      case CpuType::kIntelSandybridge:
235        return {
236            new AcceleratedCrcMemcpyEngine<3, 0>(),
237            new CrcNonTemporalMemcpyEngine(),
238        };
239      default:
240        return {&bsol;*.temporal=*/new FallbackCrcMemcpyEngine(),
241                new FallbackCrcMemcpyEngine()};
242    }
243  #endif  
244  }
245  std::unique_ptr<CrcMemcpyEngine> CrcMemcpy::GetTestEngine(int vector,
246                                                            int integer) {
247    if (vector == 3 && integer == 0) {
248      return std::make_unique<AcceleratedCrcMemcpyEngine<3, 0>>();
249    } else if (vector == 1 && integer == 2) {
250      return std::make_unique<AcceleratedCrcMemcpyEngine<1, 2>>();
251    }
252    return nullptr;
253  }
254  }  
255  ABSL_NAMESPACE_END
256  }  
257  #endif  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from abseil-cpp-MDEwOlJlcG9zaXRvcnkxMDQyMzE1NDE=-flat-crc_memcpy_x86_64.cc</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from abseil-cpp-MDEwOlJlcG9zaXRvcnkxMDQyMzE1NDE=-flat-crc_memcpy_x86_64.cc</div>
                </div>
                <div class="column column_space"><pre><code>240        return {&bsol;*.temporal=*/new FallbackCrcMemcpyEngine(),
241                new FallbackCrcMemcpyEngine()};
242    }
243  #endif  
</pre></code></div>
                <div class="column column_space"><pre><code>212        return {&bsol;*.temporal=*/new FallbackCrcMemcpyEngine(),
213                new FallbackCrcMemcpyEngine()};
214    }
215  #else
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    