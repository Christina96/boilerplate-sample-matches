<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for test_split_layer.cpp & test_slice_layer.cpp</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for test_split_layer.cpp & test_slice_layer.cpp
      </h3>
      <h1 align="center">
        8.8%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>test_split_layer.cpp (13.846154%)<TH>test_slice_layer.cpp (6.5454545%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match2941-0.html#0',2,'match2941-1.html#0',3)" NAME="0">(54-70)<TD><A HREF="javascript:ZweiFrames('match2941-0.html#0',2,'match2941-1.html#0',3)" NAME="0">(68-81)</A><TD ALIGN=center><FONT COLOR="#ff0000">18</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_split_layer.cpp</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
#include &lt;string&gt;
#include &lt;vector&gt;

#include &quot;google/protobuf/text_format.h&quot;
#include &quot;gtest/gtest.h&quot;

#include &quot;caffe/blob.hpp&quot;
#include &quot;caffe/common.hpp&quot;
#include &quot;caffe/filler.hpp&quot;
#include &quot;caffe/layers/split_layer.hpp&quot;
#include &quot;caffe/proto/caffe.pb.h&quot;
#include &quot;caffe/util/insert_splits.hpp&quot;

#include &quot;caffe/test/test_caffe_main.hpp&quot;
#include &quot;caffe/test/test_gradient_check_util.hpp&quot;

namespace caffe {

template &lt;typename TypeParam&gt;
class SplitLayerTest : public MultiDeviceTest&lt;TypeParam&gt; {
  typedef typename TypeParam::Dtype Dtype;

 protected:
  SplitLayerTest()
      : blob_bottom_(new Blob&lt;Dtype&gt;(2, 3, 6, 5)),
        blob_top_a_(new Blob&lt;Dtype&gt;()),
        blob_top_b_(new Blob&lt;Dtype&gt;()) {
    // fill the values
    FillerParameter filler_param;
    GaussianFiller&lt;Dtype&gt; filler(filler_param);
    filler.Fill(this-&gt;blob_bottom_);
    blob_bottom_vec_.push_back(blob_bottom_);
    blob_top_vec_.push_back(blob_top_a_);
    blob_top_vec_.push_back(blob_top_b_);
  }
  virtual ~SplitLayerTest() {
    delete blob_bottom_;
    delete blob_top_a_;
    delete blob_top_b_;
  }
  Blob&lt;Dtype&gt;* const blob_bottom_;
  Blob&lt;Dtype&gt;* const blob_top_a_;
  Blob&lt;Dtype&gt;* const blob_top_b_;
  vector&lt;Blob&lt;Dtype&gt;*&gt; blob_bottom_vec_;
  vector&lt;Blob&lt;Dtype&gt;*&gt; blob_top_vec_;
};

TYPED_TEST_CASE(SplitLayerTest, TestDtypesAndDevices);

TYPED_TEST(SplitLayerTest, TestSetup) {
<A NAME="0"></A>  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  SplitLayer&lt;Dtype&gt; layer(layer_param);
<FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match2941-1.html#0',3,'match2941-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>  layer.SetUp(this-&gt;blob_bottom_vec_, this-&gt;blob_top_vec_);
  EXPECT_EQ(this-&gt;blob_top_a_-&gt;num(), 2);
  EXPECT_EQ(this-&gt;blob_top_a_-&gt;channels(), 3);
  EXPECT_EQ(this-&gt;blob_top_a_-&gt;height(), 6);
  EXPECT_EQ(this-&gt;blob_top_a_-&gt;width(), 5);
  EXPECT_EQ(this-&gt;blob_top_b_-&gt;num(), 2);
  EXPECT_EQ(this-&gt;blob_top_b_-&gt;channels(), 3);
  EXPECT_EQ(this-&gt;blob_top_b_-&gt;height(), 6);
  EXPECT_EQ(this-&gt;blob_top_b_-&gt;width(), 5);
}

TYPED_TEST(SplitLayerTest, Test) {
  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  SplitLayer&lt;Dtype&gt; layer(layer_param);
  layer.SetUp(this-&gt;blob_bottom_vec_, this-&gt;blob_top_vec_);
  layer.Forward(this-&gt;blob_bottom_vec_, this-&gt;blob_top_vec_);</B></FONT>
  for (int i = 0; i &lt; this-&gt;blob_bottom_-&gt;count(); ++i) {
    Dtype bottom_value = this-&gt;blob_bottom_-&gt;cpu_data()[i];
    EXPECT_EQ(bottom_value, this-&gt;blob_top_a_-&gt;cpu_data()[i]);
    EXPECT_EQ(bottom_value, this-&gt;blob_top_b_-&gt;cpu_data()[i]);
  }
}

TYPED_TEST(SplitLayerTest, TestGradient) {
  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  SplitLayer&lt;Dtype&gt; layer(layer_param);
  GradientChecker&lt;Dtype&gt; checker(1e-2, 1e-2);
  checker.CheckGradientEltwise(&amp;layer, this-&gt;blob_bottom_vec_,
      this-&gt;blob_top_vec_);
}


class SplitLayerInsertionTest : public ::testing::Test {
 protected:
  void RunInsertionTest(
      const string&amp; input_param_string, const string&amp; output_param_string) {
    // Test that InsertSplits called on the proto specified by
    // input_param_string results in the proto specified by
    // output_param_string.
    NetParameter input_param;
    CHECK(google::protobuf::TextFormat::ParseFromString(
        input_param_string, &amp;input_param));
    NetParameter expected_output_param;
    CHECK(google::protobuf::TextFormat::ParseFromString(
        output_param_string, &amp;expected_output_param));
    NetParameter actual_output_param;
    InsertSplits(input_param, &amp;actual_output_param);
    EXPECT_EQ(expected_output_param.DebugString(),
        actual_output_param.DebugString());
    // Also test idempotence.
    NetParameter double_split_insert_param;
    InsertSplits(actual_output_param, &amp;double_split_insert_param);
    EXPECT_EQ(actual_output_param.DebugString(),
       double_split_insert_param.DebugString());
  }
};

TEST_F(SplitLayerInsertionTest, TestNoInsertion1) {
  const string&amp; input_proto =
      &quot;name: 'TestNetwork' &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'Data' &quot;
      &quot;  top: 'data' &quot;
      &quot;  top: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'innerprod' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss' &quot;
      &quot;  type: 'SoftmaxWithLoss' &quot;
      &quot;  bottom: 'innerprod' &quot;
      &quot;  bottom: 'label' &quot;
      &quot;} &quot;;
  this-&gt;RunInsertionTest(input_proto, input_proto);
}

TEST_F(SplitLayerInsertionTest, TestNoInsertion2) {
  const string&amp; input_proto =
      &quot;name: 'TestNetwork' &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'Data' &quot;
      &quot;  top: 'data' &quot;
      &quot;  top: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'data_split' &quot;
      &quot;  type: 'Split' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'data_split_0' &quot;
      &quot;  top: 'data_split_1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod1' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data_split_0' &quot;
      &quot;  top: 'innerprod1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod2' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data_split_1' &quot;
      &quot;  top: 'innerprod2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod1' &quot;
      &quot;  bottom: 'innerprod2' &quot;
      &quot;} &quot;;
  this-&gt;RunInsertionTest(input_proto, input_proto);
}

TEST_F(SplitLayerInsertionTest, TestNoInsertionImageNet) {
  const string&amp; input_proto =
      &quot;name: 'CaffeNet' &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'Data' &quot;
      &quot;  data_param { &quot;
      &quot;    source: '/home/jiayq/Data/ILSVRC12/train-leveldb' &quot;
      &quot;    batch_size: 256 &quot;
      &quot;  } &quot;
      &quot;  transform_param { &quot;
      &quot;    crop_size: 227 &quot;
      &quot;    mirror: true &quot;
      &quot;    mean_file: '/home/jiayq/Data/ILSVRC12/image_mean.binaryproto' &quot;
      &quot;  } &quot;
      &quot;  top: 'data' &quot;
      &quot;  top: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'conv1' &quot;
      &quot;  type: 'Convolution' &quot;
      &quot;  convolution_param { &quot;
      &quot;    num_output: 96 &quot;
      &quot;    kernel_size: 11 &quot;
      &quot;    stride: 4 &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 0.01 &quot;
      &quot;    } &quot;
      &quot;    bias_filler { &quot;
      &quot;      type: 'constant' &quot;
      &quot;      value: 0. &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 1 &quot;
      &quot;    decay_mult: 1 &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 2 &quot;
      &quot;    decay_mult: 0 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'conv1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'relu1' &quot;
      &quot;  type: 'ReLU' &quot;
      &quot;  bottom: 'conv1' &quot;
      &quot;  top: 'conv1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'pool1' &quot;
      &quot;  type: 'Pooling' &quot;
      &quot;  pooling_param { &quot;
      &quot;    pool: MAX &quot;
      &quot;    kernel_size: 3 &quot;
      &quot;    stride: 2 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'conv1' &quot;
      &quot;  top: 'pool1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'norm1' &quot;
      &quot;  type: 'LRN' &quot;
      &quot;  lrn_param { &quot;
      &quot;    local_size: 5 &quot;
      &quot;    alpha: 0.0001 &quot;
      &quot;    beta: 0.75 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'pool1' &quot;
      &quot;  top: 'norm1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'conv2' &quot;
      &quot;  type: 'Convolution' &quot;
      &quot;  convolution_param { &quot;
      &quot;    num_output: 256 &quot;
      &quot;    group: 2 &quot;
      &quot;    kernel_size: 5 &quot;
      &quot;    pad: 2 &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 0.01 &quot;
      &quot;    } &quot;
      &quot;    bias_filler { &quot;
      &quot;      type: 'constant' &quot;
      &quot;      value: 1. &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 1 &quot;
      &quot;    decay_mult: 1 &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 2 &quot;
      &quot;    decay_mult: 0 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'norm1' &quot;
      &quot;  top: 'conv2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'relu2' &quot;
      &quot;  type: 'ReLU' &quot;
      &quot;  bottom: 'conv2' &quot;
      &quot;  top: 'conv2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'pool2' &quot;
      &quot;  type: 'Pooling' &quot;
      &quot;  pooling_param { &quot;
      &quot;    pool: MAX &quot;
      &quot;    kernel_size: 3 &quot;
      &quot;    stride: 2 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'conv2' &quot;
      &quot;  top: 'pool2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'norm2' &quot;
      &quot;  type: 'LRN' &quot;
      &quot;  lrn_param { &quot;
      &quot;    local_size: 5 &quot;
      &quot;    alpha: 0.0001 &quot;
      &quot;    beta: 0.75 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'pool2' &quot;
      &quot;  top: 'norm2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'conv3' &quot;
      &quot;  type: 'Convolution' &quot;
      &quot;  convolution_param { &quot;
      &quot;    num_output: 384 &quot;
      &quot;    kernel_size: 3 &quot;
      &quot;    pad: 1 &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 0.01 &quot;
      &quot;    } &quot;
      &quot;    bias_filler { &quot;
      &quot;      type: 'constant' &quot;
      &quot;      value: 0. &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 1 &quot;
      &quot;    decay_mult: 1 &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 2 &quot;
      &quot;    decay_mult: 0 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'norm2' &quot;
      &quot;  top: 'conv3' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'relu3' &quot;
      &quot;  type: 'ReLU' &quot;
      &quot;  bottom: 'conv3' &quot;
      &quot;  top: 'conv3' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'conv4' &quot;
      &quot;  type: 'Convolution' &quot;
      &quot;  convolution_param { &quot;
      &quot;    num_output: 384 &quot;
      &quot;    group: 2 &quot;
      &quot;    kernel_size: 3 &quot;
      &quot;    pad: 1 &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 0.01 &quot;
      &quot;    } &quot;
      &quot;    bias_filler { &quot;
      &quot;      type: 'constant' &quot;
      &quot;      value: 1. &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 1 &quot;
      &quot;    decay_mult: 1 &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 2 &quot;
      &quot;    decay_mult: 0 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'conv3' &quot;
      &quot;  top: 'conv4' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'relu4' &quot;
      &quot;  type: 'ReLU' &quot;
      &quot;  bottom: 'conv4' &quot;
      &quot;  top: 'conv4' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'conv5' &quot;
      &quot;  type: 'Convolution' &quot;
      &quot;  convolution_param { &quot;
      &quot;    num_output: 256 &quot;
      &quot;    group: 2 &quot;
      &quot;    kernel_size: 3 &quot;
      &quot;    pad: 1 &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 0.01 &quot;
      &quot;    } &quot;
      &quot;    bias_filler { &quot;
      &quot;      type: 'constant' &quot;
      &quot;      value: 1. &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 1 &quot;
      &quot;    decay_mult: 1 &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 2 &quot;
      &quot;    decay_mult: 0 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'conv4' &quot;
      &quot;  top: 'conv5' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'relu5' &quot;
      &quot;  type: 'ReLU' &quot;
      &quot;  bottom: 'conv5' &quot;
      &quot;  top: 'conv5' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'pool5' &quot;
      &quot;  type: 'Pooling' &quot;
      &quot;  pooling_param { &quot;
      &quot;    kernel_size: 3 &quot;
      &quot;    pool: MAX &quot;
      &quot;    stride: 2 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'conv5' &quot;
      &quot;  top: 'pool5' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'fc6' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  inner_product_param { &quot;
      &quot;    num_output: 4096 &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 0.005 &quot;
      &quot;    } &quot;
      &quot;    bias_filler { &quot;
      &quot;      type: 'constant' &quot;
      &quot;      value: 1. &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 1 &quot;
      &quot;    decay_mult: 1 &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 2 &quot;
      &quot;    decay_mult: 0 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'pool5' &quot;
      &quot;  top: 'fc6' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'relu6' &quot;
      &quot;  type: 'ReLU' &quot;
      &quot;  bottom: 'fc6' &quot;
      &quot;  top: 'fc6' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'drop6' &quot;
      &quot;  type: 'Dropout' &quot;
      &quot;  dropout_param { &quot;
      &quot;    dropout_ratio: 0.5 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'fc6' &quot;
      &quot;  top: 'fc6' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'fc7' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  inner_product_param { &quot;
      &quot;    num_output: 4096 &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 0.005 &quot;
      &quot;    } &quot;
      &quot;    bias_filler { &quot;
      &quot;      type: 'constant' &quot;
      &quot;      value: 1. &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 1 &quot;
      &quot;    decay_mult: 1 &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 2 &quot;
      &quot;    decay_mult: 0 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'fc6' &quot;
      &quot;  top: 'fc7' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'relu7' &quot;
      &quot;  type: 'ReLU' &quot;
      &quot;  bottom: 'fc7' &quot;
      &quot;  top: 'fc7' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'drop7' &quot;
      &quot;  type: 'Dropout' &quot;
      &quot;  dropout_param { &quot;
      &quot;    dropout_ratio: 0.5 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'fc7' &quot;
      &quot;  top: 'fc7' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'fc8' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  inner_product_param { &quot;
      &quot;    num_output: 1000 &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 0.01 &quot;
      &quot;    } &quot;
      &quot;    bias_filler { &quot;
      &quot;      type: 'constant' &quot;
      &quot;      value: 0 &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 1 &quot;
      &quot;    decay_mult: 1 &quot;
      &quot;  } &quot;
      &quot;  param { &quot;
      &quot;    lr_mult: 2 &quot;
      &quot;    decay_mult: 0 &quot;
      &quot;  } &quot;
      &quot;  bottom: 'fc7' &quot;
      &quot;  top: 'fc8' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss' &quot;
      &quot;  type: 'SoftmaxWithLoss' &quot;
      &quot;  bottom: 'fc8' &quot;
      &quot;  bottom: 'label' &quot;
      &quot;} &quot;;
  this-&gt;RunInsertionTest(input_proto, input_proto);
}

TEST_F(SplitLayerInsertionTest, TestNoInsertionWithInPlace) {
  const string&amp; input_proto =
      &quot;name: 'TestNetwork' &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'Data' &quot;
      &quot;  top: 'data' &quot;
      &quot;  top: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'innerprod' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'relu' &quot;
      &quot;  type: 'ReLU' &quot;
      &quot;  bottom: 'innerprod' &quot;
      &quot;  top: 'innerprod' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss' &quot;
      &quot;  type: 'SoftmaxWithLoss' &quot;
      &quot;  bottom: 'innerprod' &quot;
      &quot;  bottom: 'label' &quot;
      &quot;} &quot;;
  this-&gt;RunInsertionTest(input_proto, input_proto);
}

TEST_F(SplitLayerInsertionTest, TestLossInsertion) {
  const string&amp; input_proto =
      &quot;name: 'UnsharedWeightsNetwork' &quot;
      &quot;force_backward: true &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'DummyData' &quot;
      &quot;  dummy_data_param { &quot;
      &quot;    num: 5 &quot;
      &quot;    channels: 2 &quot;
      &quot;    height: 3 &quot;
      &quot;    width: 4 &quot;
      &quot;    data_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 0.01 &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  top: 'data' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerproduct1' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  inner_product_param { &quot;
      &quot;    num_output: 10 &quot;
      &quot;    bias_term: false &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 10 &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { name: 'unsharedweights1' } &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'innerproduct1' &quot;
      &quot;  loss_weight: 2.5 &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerproduct2' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  inner_product_param { &quot;
      &quot;    num_output: 10 &quot;
      &quot;    bias_term: false &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 10 &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { name: 'unsharedweights2' } &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'innerproduct2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerproduct1' &quot;
      &quot;  bottom: 'innerproduct2' &quot;
      &quot;} &quot;;
  const string&amp; expected_output_proto =
      &quot;name: 'UnsharedWeightsNetwork' &quot;
      &quot;force_backward: true &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'DummyData' &quot;
      &quot;  dummy_data_param { &quot;
      &quot;    num: 5 &quot;
      &quot;    channels: 2 &quot;
      &quot;    height: 3 &quot;
      &quot;    width: 4 &quot;
      &quot;    data_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 0.01 &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  top: 'data' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'data_data_0_split' &quot;
      &quot;  type: 'Split' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'data_data_0_split_0' &quot;
      &quot;  top: 'data_data_0_split_1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerproduct1' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  inner_product_param { &quot;
      &quot;    num_output: 10 &quot;
      &quot;    bias_term: false &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 10 &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { name: 'unsharedweights1' } &quot;
      &quot;  bottom: 'data_data_0_split_0' &quot;
      &quot;  top: 'innerproduct1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerproduct1_innerproduct1_0_split' &quot;
      &quot;  type: 'Split' &quot;
      &quot;  bottom: 'innerproduct1' &quot;
      &quot;  top: 'innerproduct1_innerproduct1_0_split_0' &quot;
      &quot;  top: 'innerproduct1_innerproduct1_0_split_1' &quot;
      &quot;  loss_weight: 2.5 &quot;
      &quot;  loss_weight: 0 &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerproduct2' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  inner_product_param { &quot;
      &quot;    num_output: 10 &quot;
      &quot;    bias_term: false &quot;
      &quot;    weight_filler { &quot;
      &quot;      type: 'gaussian' &quot;
      &quot;      std: 10 &quot;
      &quot;    } &quot;
      &quot;  } &quot;
      &quot;  param { name: 'unsharedweights2' } &quot;
      &quot;  bottom: 'data_data_0_split_1' &quot;
      &quot;  top: 'innerproduct2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerproduct1_innerproduct1_0_split_1' &quot;
      &quot;  bottom: 'innerproduct2' &quot;
      &quot;} &quot;;
  this-&gt;RunInsertionTest(input_proto, expected_output_proto);
}

TEST_F(SplitLayerInsertionTest, TestInsertion) {
  const string&amp; input_proto =
      &quot;name: 'TestNetwork' &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'Data' &quot;
      &quot;  top: 'data' &quot;
      &quot;  top: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod1' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'innerprod1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod2' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'innerprod2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod3' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'innerprod3' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss1' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod1' &quot;
      &quot;  bottom: 'innerprod2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss2' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod2' &quot;
      &quot;  bottom: 'innerprod3' &quot;
      &quot;} &quot;;
  const string&amp; expected_output_proto =
      &quot;name: 'TestNetwork' &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'Data' &quot;
      &quot;  top: 'data' &quot;
      &quot;  top: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'data_data_0_split' &quot;
      &quot;  type: 'Split' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'data_data_0_split_0' &quot;
      &quot;  top: 'data_data_0_split_1' &quot;
      &quot;  top: 'data_data_0_split_2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod1' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data_data_0_split_0' &quot;
      &quot;  top: 'innerprod1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod2' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data_data_0_split_1' &quot;
      &quot;  top: 'innerprod2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod2_innerprod2_0_split' &quot;
      &quot;  type: 'Split' &quot;
      &quot;  bottom: 'innerprod2' &quot;
      &quot;  top: 'innerprod2_innerprod2_0_split_0' &quot;
      &quot;  top: 'innerprod2_innerprod2_0_split_1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod3' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data_data_0_split_2' &quot;
      &quot;  top: 'innerprod3' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss1' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod1' &quot;
      &quot;  bottom: 'innerprod2_innerprod2_0_split_0' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss2' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod2_innerprod2_0_split_1' &quot;
      &quot;  bottom: 'innerprod3' &quot;
      &quot;} &quot;;
  this-&gt;RunInsertionTest(input_proto, expected_output_proto);
}

TEST_F(SplitLayerInsertionTest, TestInsertionTwoTop) {
  const string&amp; input_proto =
      &quot;name: 'TestNetwork' &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'Data' &quot;
      &quot;  top: 'data' &quot;
      &quot;  top: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod1' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'innerprod1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod2' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'label' &quot;
      &quot;  top: 'innerprod2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod3' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'innerprod3' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod4' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'label' &quot;
      &quot;  top: 'innerprod4' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss1' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod1' &quot;
      &quot;  bottom: 'innerprod3' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss2' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod2' &quot;
      &quot;  bottom: 'innerprod4' &quot;
      &quot;} &quot;;
  const string&amp; expected_output_proto =
      &quot;name: 'TestNetwork' &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'Data' &quot;
      &quot;  top: 'data' &quot;
      &quot;  top: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'data_data_0_split' &quot;
      &quot;  type: 'Split' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'data_data_0_split_0' &quot;
      &quot;  top: 'data_data_0_split_1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'label_data_1_split' &quot;
      &quot;  type: 'Split' &quot;
      &quot;  bottom: 'label' &quot;
      &quot;  top: 'label_data_1_split_0' &quot;
      &quot;  top: 'label_data_1_split_1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod1' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data_data_0_split_0' &quot;
      &quot;  top: 'innerprod1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod2' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'label_data_1_split_0' &quot;
      &quot;  top: 'innerprod2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod3' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data_data_0_split_1' &quot;
      &quot;  top: 'innerprod3' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod4' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'label_data_1_split_1' &quot;
      &quot;  top: 'innerprod4' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss1' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod1' &quot;
      &quot;  bottom: 'innerprod3' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss2' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod2' &quot;
      &quot;  bottom: 'innerprod4' &quot;
      &quot;} &quot;;
  this-&gt;RunInsertionTest(input_proto, expected_output_proto);
}

TEST_F(SplitLayerInsertionTest, TestWithInPlace) {
  const string&amp; input_proto =
      &quot;name: 'TestNetwork' &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'Data' &quot;
      &quot;  top: 'data' &quot;
      &quot;  top: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod1' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'innerprod1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'relu1' &quot;
      &quot;  type: 'ReLU' &quot;
      &quot;  bottom: 'innerprod1' &quot;
      &quot;  top: 'innerprod1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod2' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'innerprod1' &quot;
      &quot;  top: 'innerprod2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss1' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod1' &quot;
      &quot;  bottom: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss2' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod2' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;} &quot;;
  const string&amp; expected_output_proto =
      &quot;name: 'TestNetwork' &quot;
      &quot;layer { &quot;
      &quot;  name: 'data' &quot;
      &quot;  type: 'Data' &quot;
      &quot;  top: 'data' &quot;
      &quot;  top: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'data_data_0_split' &quot;
      &quot;  type: 'Split' &quot;
      &quot;  bottom: 'data' &quot;
      &quot;  top: 'data_data_0_split_0' &quot;
      &quot;  top: 'data_data_0_split_1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod1' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'data_data_0_split_0' &quot;
      &quot;  top: 'innerprod1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'relu1' &quot;
      &quot;  type: 'ReLU' &quot;
      &quot;  bottom: 'innerprod1' &quot;
      &quot;  top: 'innerprod1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod1_relu1_0_split' &quot;
      &quot;  type: 'Split' &quot;
      &quot;  bottom: 'innerprod1' &quot;
      &quot;  top: 'innerprod1_relu1_0_split_0' &quot;
      &quot;  top: 'innerprod1_relu1_0_split_1' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'innerprod2' &quot;
      &quot;  type: 'InnerProduct' &quot;
      &quot;  bottom: 'innerprod1_relu1_0_split_0' &quot;
      &quot;  top: 'innerprod2' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss1' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod1_relu1_0_split_1' &quot;
      &quot;  bottom: 'label' &quot;
      &quot;} &quot;
      &quot;layer { &quot;
      &quot;  name: 'loss2' &quot;
      &quot;  type: 'EuclideanLoss' &quot;
      &quot;  bottom: 'innerprod2' &quot;
      &quot;  bottom: 'data_data_0_split_1' &quot;
      &quot;} &quot;;
  this-&gt;RunInsertionTest(input_proto, expected_output_proto);
}

}  // namespace caffe
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_slice_layer.cpp</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
#include &lt;vector&gt;

#include &quot;gtest/gtest.h&quot;

#include &quot;caffe/blob.hpp&quot;
#include &quot;caffe/common.hpp&quot;
#include &quot;caffe/filler.hpp&quot;
#include &quot;caffe/layers/slice_layer.hpp&quot;

#include &quot;caffe/test/test_caffe_main.hpp&quot;
#include &quot;caffe/test/test_gradient_check_util.hpp&quot;

namespace caffe {

template &lt;typename TypeParam&gt;
class SliceLayerTest : public MultiDeviceTest&lt;TypeParam&gt; {
  typedef typename TypeParam::Dtype Dtype;

 protected:
  SliceLayerTest()
      : blob_bottom_(new Blob&lt;Dtype&gt;(6, 12, 2, 3)),
        blob_top_0_(new Blob&lt;Dtype&gt;()),
        blob_top_1_(new Blob&lt;Dtype&gt;()),
        blob_top_2_(new Blob&lt;Dtype&gt;()) {}
  virtual void SetUp() {
    // fill the values
    Caffe::set_random_seed(1701);
    FillerParameter filler_param;
    GaussianFiller&lt;Dtype&gt; filler(filler_param);
    filler.Fill(this-&gt;blob_bottom_);
    blob_top_vec_0_.push_back(blob_top_0_);
    blob_top_vec_0_.push_back(blob_top_1_);
    blob_top_vec_1_.push_back(blob_top_0_);
    blob_top_vec_1_.push_back(blob_top_1_);
    blob_top_vec_1_.push_back(blob_top_2_);
    blob_bottom_vec_.push_back(blob_bottom_);
  }

  virtual void ReduceBottomBlobSize() {
    blob_bottom_-&gt;Reshape(4, 5, 2, 2);
    FillerParameter filler_param;
    GaussianFiller&lt;Dtype&gt; filler(filler_param);
    filler.Fill(this-&gt;blob_bottom_);
  }

  virtual ~SliceLayerTest() {
    delete blob_top_0_; delete blob_top_1_;
    delete blob_top_2_; delete blob_bottom_;
  }

  Blob&lt;Dtype&gt;* const blob_bottom_;
  Blob&lt;Dtype&gt;* const blob_top_0_;
  Blob&lt;Dtype&gt;* const blob_top_1_;
  Blob&lt;Dtype&gt;* const blob_top_2_;
  vector&lt;Blob&lt;Dtype&gt;*&gt; blob_top_vec_0_, blob_top_vec_1_;
  vector&lt;Blob&lt;Dtype&gt;*&gt; blob_bottom_vec_;
};

TYPED_TEST_CASE(SliceLayerTest, TestDtypesAndDevices);

TYPED_TEST(SliceLayerTest, TestSetupNum) {
  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  layer_param.mutable_slice_param()-&gt;set_axis(0);
<A NAME="0"></A>  SliceLayer&lt;Dtype&gt; layer(layer_param);
  layer.SetUp(this-&gt;blob_bottom_vec_, this-&gt;blob_top_vec_1_);
  EXPECT_EQ(this-&gt;blob_bottom_-&gt;num(), 3 * this-&gt;blob_top_0_-&gt;num());
<FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2941-0.html#0',2,'match2941-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>  EXPECT_EQ(this-&gt;blob_top_0_-&gt;num(), this-&gt;blob_top_1_-&gt;num());
  EXPECT_EQ(this-&gt;blob_top_0_-&gt;num(), this-&gt;blob_top_2_-&gt;num());
  EXPECT_EQ(this-&gt;blob_bottom_-&gt;channels(), this-&gt;blob_top_0_-&gt;channels());
  EXPECT_EQ(this-&gt;blob_bottom_-&gt;height(), this-&gt;blob_top_0_-&gt;height());
  EXPECT_EQ(this-&gt;blob_bottom_-&gt;width(), this-&gt;blob_top_0_-&gt;width());
}

TYPED_TEST(SliceLayerTest, TestSetupChannels) {
  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  layer_param.mutable_slice_param()-&gt;add_slice_point(3);
  SliceLayer&lt;Dtype&gt; layer(layer_param);
  layer.SetUp(this-&gt;blob_bottom_vec_, this-&gt;blob_top_vec_0_);
  EXPECT_EQ(this-&gt;blob_top_0_-&gt;num(), this-&gt;blob_bottom_-&gt;num());</B></FONT>
  EXPECT_EQ(this-&gt;blob_top_0_-&gt;channels(), 3);
  EXPECT_EQ(this-&gt;blob_top_1_-&gt;channels(), 9);
  EXPECT_EQ(this-&gt;blob_bottom_-&gt;channels(),
    this-&gt;blob_top_0_-&gt;channels() + this-&gt;blob_top_1_-&gt;channels());
  EXPECT_EQ(this-&gt;blob_bottom_-&gt;height(), this-&gt;blob_top_0_-&gt;height());
  EXPECT_EQ(this-&gt;blob_bottom_-&gt;width(), this-&gt;blob_top_0_-&gt;width());
}

TYPED_TEST(SliceLayerTest, TestTrivialSlice) {
  // Test the trivial (single output) &quot;slice&quot; operation --
  // should be the identity.
  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  SliceLayer&lt;Dtype&gt; layer(layer_param);
  this-&gt;blob_top_vec_0_.resize(1);
  layer.SetUp(this-&gt;blob_bottom_vec_, this-&gt;blob_top_vec_0_);
  ASSERT_EQ(this-&gt;blob_bottom_-&gt;shape(), this-&gt;blob_top_0_-&gt;shape());
  for (int i = 0; i &lt; this-&gt;blob_bottom_-&gt;count(); ++i) {
    EXPECT_EQ(this-&gt;blob_bottom_-&gt;cpu_data()[i],
              this-&gt;blob_top_0_-&gt;cpu_data()[i]);
  }
}

TYPED_TEST(SliceLayerTest, TestSliceAcrossNum) {
  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  layer_param.mutable_slice_param()-&gt;set_axis(0);
  SliceLayer&lt;Dtype&gt; layer(layer_param);
  layer.SetUp(this-&gt;blob_bottom_vec_, this-&gt;blob_top_vec_0_);
  const int top_num = this-&gt;blob_bottom_-&gt;num() / 2;
  ASSERT_EQ(top_num, this-&gt;blob_top_0_-&gt;num());
  ASSERT_EQ(top_num, this-&gt;blob_top_1_-&gt;num());
  layer.Forward(this-&gt;blob_bottom_vec_, this-&gt;blob_top_vec_0_);
  for (int n = 0; n &lt; top_num; ++n) {
    for (int c = 0; c &lt; this-&gt;blob_top_0_-&gt;channels(); ++c) {
      for (int h = 0; h &lt; this-&gt;blob_bottom_-&gt;height(); ++h) {
        for (int w = 0; w &lt; this-&gt;blob_bottom_-&gt;width(); ++w) {
          EXPECT_EQ(this-&gt;blob_bottom_-&gt;data_at(n, c, h, w),
                    this-&gt;blob_top_0_-&gt;data_at(n, c, h, w));
        }
      }
    }
    for (int c = 0; c &lt; this-&gt;blob_top_1_-&gt;channels(); ++c) {
      for (int h = 0; h &lt; this-&gt;blob_bottom_-&gt;height(); ++h) {
        for (int w = 0; w &lt; this-&gt;blob_bottom_-&gt;width(); ++w) {
          EXPECT_EQ(this-&gt;blob_bottom_-&gt;data_at(n + 3, c, h, w),
                    this-&gt;blob_top_1_-&gt;data_at(n, c, h, w));
        }
      }
    }
  }
}

TYPED_TEST(SliceLayerTest, TestSliceAcrossChannels) {
  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  // Slice at 2, 8: should produce output blobs with #channels 2, 6, 4.
  const int kSlicePoint0 = 2;
  const int kSlicePoint1 = 8;
  layer_param.mutable_slice_param()-&gt;add_slice_point(kSlicePoint0);
  layer_param.mutable_slice_param()-&gt;add_slice_point(kSlicePoint1);
  SliceLayer&lt;Dtype&gt; layer(layer_param);
  layer.SetUp(this-&gt;blob_bottom_vec_, this-&gt;blob_top_vec_1_);
  ASSERT_EQ(kSlicePoint0, this-&gt;blob_top_0_-&gt;channels());
  ASSERT_EQ(kSlicePoint1 - kSlicePoint0, this-&gt;blob_top_1_-&gt;channels());
  ASSERT_EQ(this-&gt;blob_bottom_-&gt;channels() - kSlicePoint1,
            this-&gt;blob_top_2_-&gt;channels());
  layer.Forward(this-&gt;blob_bottom_vec_, this-&gt;blob_top_vec_1_);
  for (int n = 0; n &lt; this-&gt;blob_bottom_-&gt;num(); ++n) {
    for (int c = 0; c &lt; this-&gt;blob_top_0_-&gt;channels(); ++c) {
      for (int h = 0; h &lt; this-&gt;blob_bottom_-&gt;height(); ++h) {
        for (int w = 0; w &lt; this-&gt;blob_bottom_-&gt;width(); ++w) {
          EXPECT_EQ(this-&gt;blob_bottom_-&gt;data_at(n, c, h, w),
              this-&gt;blob_top_0_-&gt;data_at(n, c, h, w));
        }
      }
    }
    for (int c = 0; c &lt; this-&gt;blob_top_1_-&gt;channels(); ++c) {
      for (int h = 0; h &lt; this-&gt;blob_bottom_-&gt;height(); ++h) {
        for (int w = 0; w &lt; this-&gt;blob_bottom_-&gt;width(); ++w) {
          EXPECT_EQ(this-&gt;blob_bottom_-&gt;data_at(n, c + kSlicePoint0, h, w),
              this-&gt;blob_top_1_-&gt;data_at(n, c, h, w));
        }
      }
    }
    for (int c = 0; c &lt; this-&gt;blob_top_2_-&gt;channels(); ++c) {
      for (int h = 0; h &lt; this-&gt;blob_bottom_-&gt;height(); ++h) {
        for (int w = 0; w &lt; this-&gt;blob_bottom_-&gt;width(); ++w) {
          EXPECT_EQ(this-&gt;blob_bottom_-&gt;data_at(n, c + kSlicePoint1, h, w),
              this-&gt;blob_top_2_-&gt;data_at(n, c, h, w));
        }
      }
    }
  }
}

TYPED_TEST(SliceLayerTest, TestGradientTrivial) {
  // Test the trivial (single output) &quot;slice&quot; operation --
  // should be the identity.
  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  SliceLayer&lt;Dtype&gt; layer(layer_param);
  GradientChecker&lt;Dtype&gt; checker(1e-2, 1e-3);
  this-&gt;blob_top_vec_0_.resize(1);
  checker.CheckGradientEltwise(&amp;layer, this-&gt;blob_bottom_vec_,
      this-&gt;blob_top_vec_0_);
}

TYPED_TEST(SliceLayerTest, TestGradientAcrossNum) {
  typedef typename TypeParam::Dtype Dtype;
  // Gradient checks are slow; reduce blob size.
  this-&gt;ReduceBottomBlobSize();
  LayerParameter layer_param;
  layer_param.mutable_slice_param()-&gt;set_axis(0);
  SliceLayer&lt;Dtype&gt; layer(layer_param);
  GradientChecker&lt;Dtype&gt; checker(1e-2, 1e-3);
  checker.CheckGradientExhaustive(&amp;layer, this-&gt;blob_bottom_vec_,
    this-&gt;blob_top_vec_0_);
}

TYPED_TEST(SliceLayerTest, TestGradientAcrossChannels) {
  typedef typename TypeParam::Dtype Dtype;
  // Gradient checks are slow; reduce blob size.
  this-&gt;ReduceBottomBlobSize();
  LayerParameter layer_param;
  const int kSlicePoint = 4;
  layer_param.mutable_slice_param()-&gt;add_slice_point(kSlicePoint);
  SliceLayer&lt;Dtype&gt; layer(layer_param);
  GradientChecker&lt;Dtype&gt; checker(1e-2, 1e-3);
  checker.CheckGradientExhaustive(&amp;layer, this-&gt;blob_bottom_vec_,
    this-&gt;blob_top_vec_0_);
}

}  // namespace caffe
</PRE>
</div>
  </div>
</body>
</html>
