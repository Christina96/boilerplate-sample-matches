
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 2.2277227722772275%, Tokens: 9</h2>
        <div class="column">
            <h3>snap-MDEwOlJlcG9zaXRvcnk0Mjg4MzU3-flat-anf.cpp</h3>
            <pre><code>1  namespace TSnap {
2  namespace TSnapDetail {
3  double CalcEffDiam(const TIntFltKdV& DistNbrsCdfV, const double& Percentile) {
4    const double EffPairs = Percentile * DistNbrsCdfV.Last().Dat;
5    int ValN;
6    for (ValN = 0; ValN < DistNbrsCdfV.Len(); ValN++) {
7      if (DistNbrsCdfV[ValN].Dat() > EffPairs) {  break; }
8    }
9    if (ValN >= DistNbrsCdfV.Len()) return DistNbrsCdfV.Last().Key;
10    if (ValN == 0) return 1;
11    const double DeltaNbrs = DistNbrsCdfV[ValN].Dat - DistNbrsCdfV[ValN-1].Dat;
12    if (DeltaNbrs == 0) return DistNbrsCdfV[ValN].Key;
13    return DistNbrsCdfV[ValN-1].Key + (EffPairs - DistNbrsCdfV[ValN-1].Dat)/DeltaNbrs;
14  }
15  double CalcEffDiam(const TFltPrV& DistNbrsCdfV, const double& Percentile) {
16    TIntFltKdV KdV(DistNbrsCdfV.Len(), 0);
17    for (int i = 0; i < DistNbrsCdfV.Len(); i++) {
18      KdV.Add(TIntFltKd(int(DistNbrsCdfV[i].Val1()), DistNbrsCdfV[i].Val2));
19    }
20    return CalcEffDiam(KdV, Percentile);
21  }
22  double CalcEffDiamPdf(const TIntFltKdV& DistNbrsPdfV, const double& Percentile) {
23    TIntFltKdV CdfV;
24    TGUtil::GetCdf(DistNbrsPdfV, CdfV);
25    return CalcEffDiam(CdfV, Percentile);
26  }
27  double CalcEffDiamPdf(const TFltPrV& DistNbrsPdfV, const double& Percentile) {
28    TFltPrV CdfV;
29    TGUtil::GetCdf(DistNbrsPdfV, CdfV);
30    return CalcEffDiam(CdfV, Percentile);
31  }
32  double CalcAvgDiamPdf(const TIntFltKdV& DistNbrsPdfV) {
<span onclick='openModal()' class='match'>33    double Paths=0, SumLen=0;
34    for (int i = 0; i < DistNbrsPdfV.Len(); i++) {
35      SumLen += DistNbrsPdfV[i].Key * DistNbrsPdfV[i].Dat;
36      Paths += DistNbrsPdfV[i].Dat;
37    }
</span>38    return SumLen/Paths;
39  }
40  double CalcAvgDiamPdf(const TFltPrV& DistNbrsPdfV) {
41    double Paths=0, SumLen=0;
42    for (int i = 0; i < DistNbrsPdfV.Len(); i++) {
43      SumLen += DistNbrsPdfV[i].Val1 * DistNbrsPdfV[i].Val2;
44      Paths += DistNbrsPdfV[i].Val2;
45    }
46    return SumLen/Paths;
47  }
48  } 
49  } 
</code></pre>
        </div>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-solver.cpp</h3>
            <pre><code>1  #include <algorithm>
2  #include <map>
3  #include <cstdio>
4  #include <functional>
5  #include <string>
6  #include <utility>
7  #include <vector>
8  #include <numeric>
9  #include "boost/bind.hpp"
10  #include "caffe/solver.hpp"
11  #include "caffe/util/bbox_util.hpp"
12  #include "caffe/util/format.hpp"
13  #include "caffe/util/hdf5.hpp"
14  #include "caffe/util/io.hpp"
15  #include "caffe/util/performance.hpp"
16  #include "caffe/util/upgrade_proto.hpp"
17  #ifdef USE_MLSL
18  #include "caffe/multinode/mlsl.hpp"
19  #endif
20  namespace caffe {
21  template<typename Dtype>
22  void Solver<Dtype>::SetActionFunction(ActionCallback func) {
23    action_request_function_ = func;
24  }
25  template<typename Dtype>
26  SolverAction::Enum Solver<Dtype>::GetRequestedAction() {
27    if (action_request_function_) {
28      return action_request_function_();
29    }
30    return SolverAction::NONE;
31  }
32  template <typename Dtype>
33  Solver<Dtype>::Solver(const SolverParameter& param, const Solver* root_solver)
34      : net_(), callbacks_(), root_solver_(root_solver),
35        requested_early_exit_(false),
36        forward_backward_(boost::bind(&Solver<Dtype>::ForwardBackward, this)) {
37    Init(param);
38    Caffe::set_iter_size(param_.iter_size());
39  }
40  template <typename Dtype>
41  Solver<Dtype>::Solver(const string& param_file, const Solver* root_solver)
42      : net_(), callbacks_(), root_solver_(root_solver),
43        requested_early_exit_(false),
44        forward_backward_(boost::bind(&Solver<Dtype>::ForwardBackward, this)) {
45    SolverParameter param;
46    ReadSolverParamsFromTextFileOrDie(param_file, &param);
47    Init(param);
48    Caffe::set_iter_size(param_.iter_size());
49  }
50  template <typename Dtype>
51  void Solver<Dtype>::Init(const SolverParameter& param) {
52    CHECK(Caffe::root_solver() || root_solver_)
53        << "root_solver_ needs to be set for all non-root solvers";
54    param_ = param;
55  #ifdef USE_MLSL
56    ReplaceMultinodeSolverParams(&param_);
57  #endif
58    LOG_IF(INFO, Caffe::root_solver()) << "Initializing solver from parameters: "
59      << std::endl << param_.DebugString();
60    CHECK_GE(param_.average_loss(), 1) << "average_loss should be non-negative.";
61  #ifndef USE_MLSL
62    CheckSnapshotWritePermissions();
63  #endif
64    if (Caffe::root_solver() && param_.random_seed() >= 0) {
65      Caffe::set_random_seed(param_.random_seed());
66    }
67    InitTrainNet();
68    if (Caffe::root_solver()) {
69      InitTestNets();
70      LOG(INFO) << "Solver scaffolding done.";
71    }
72    iter_ = 0;
73    current_step_ = 0;
74  }
75  template <typename Dtype>
76  void Solver<Dtype>::InitTrainNet() {
77    const int num_train_nets = param_.has_net() + param_.has_net_param() +
78        param_.has_train_net() + param_.has_train_net_param();
79    const string& field_names = "net, net_param, train_net, train_net_param";
80    CHECK_GE(num_train_nets, 1) << "SolverParameter must specify a train net "
81        << "using one of these fields: " << field_names;
82    CHECK_LE(num_train_nets, 1) << "SolverParameter must not contain more than "
83        << "one of these fields specifying a train_net: " << field_names;
84    NetParameter net_param;
85    if (param_.has_train_net_param()) {
86      LOG_IF(INFO, Caffe::root_solver())
87          << "Creating training net specified in train_net_param.";
88      net_param.CopyFrom(param_.train_net_param());
89    } else if (param_.has_train_net()) {
90      LOG_IF(INFO, Caffe::root_solver())
91          << "Creating training net from train_net file: " << param_.train_net();
92      ReadNetParamsFromTextFileOrDie(param_.train_net(), &net_param);
93    }
94    if (param_.has_net_param()) {
95      LOG_IF(INFO, Caffe::root_solver())
96          << "Creating training net specified in net_param.";
97      net_param.CopyFrom(param_.net_param());
98    }
99    if (param_.has_net()) {
100      LOG_IF(INFO, Caffe::root_solver())
101          << "Creating training net from net file: " << param_.net();
102      ReadNetParamsFromTextFileOrDie(param_.net(), &net_param);
103    }
104    if (param_.engine() != "")
105      net_param.set_engine(param_.engine());
106    NetState net_state;
107    net_state.set_phase(TRAIN);
108    net_state.MergeFrom(net_param.state());
109    net_state.MergeFrom(param_.train_state());
110    net_param.mutable_state()->CopyFrom(net_state);
111    if (Caffe::root_solver()) {
112      net_.reset(new Net<Dtype>(net_param));
113    } else {
114      net_.reset(new Net<Dtype>(net_param, root_solver_->net_.get()));
115    }
116  }
117  template <typename Dtype>
118  void Solver<Dtype>::InitTestNets() {
119    CHECK(Caffe::root_solver());
120    const bool has_net_param = param_.has_net_param();
121    const bool has_net_file = param_.has_net();
122    const int num_generic_nets = has_net_param + has_net_file;
123    CHECK_LE(num_generic_nets, 1)
124        << "Both net_param and net_file may not be specified.";
125    const int num_test_net_params = param_.test_net_param_size();
126    const int num_test_net_files = param_.test_net_size();
127    const int num_test_nets = num_test_net_params + num_test_net_files;
128    if (num_generic_nets) {
129        CHECK_GE(param_.test_iter_size(), num_test_nets)
130            << "test_iter must be specified for each test network.";
131    } else {
132        CHECK_EQ(param_.test_iter_size(), num_test_nets)
133            << "test_iter must be specified for each test network.";
134    }
135    const int num_generic_net_instances = param_.test_iter_size() - num_test_nets;
136    const int num_test_net_instances = num_test_nets + num_generic_net_instances;
137    if (param_.test_state_size()) {
138      CHECK_EQ(param_.test_state_size(), num_test_net_instances)
139          << "test_state must be unspecified or specified once per test net.";
140    }
141    if (num_test_net_instances) {
142      CHECK_GT(param_.test_interval(), 0);
143    }
144    int test_net_id = 0;
145    vector<string> sources(num_test_net_instances);
146    vector<NetParameter> net_params(num_test_net_instances);
147    for (int i = 0; i < num_test_net_params; ++i, ++test_net_id) {
148        sources[test_net_id] = "test_net_param";
149        net_params[test_net_id].CopyFrom(param_.test_net_param(i));
150    }
151    for (int i = 0; i < num_test_net_files; ++i, ++test_net_id) {
152        sources[test_net_id] = "test_net file: " + param_.test_net(i);
153        ReadNetParamsFromTextFileOrDie(param_.test_net(i),
154            &net_params[test_net_id]);
155    }
156    const int remaining_test_nets = param_.test_iter_size() - test_net_id;
157    if (has_net_param) {
158      for (int i = 0; i < remaining_test_nets; ++i, ++test_net_id) {
159        sources[test_net_id] = "net_param";
160        net_params[test_net_id].CopyFrom(param_.net_param());
161      }
162    }
163    if (has_net_file) {
164      for (int i = 0; i < remaining_test_nets; ++i, ++test_net_id) {
165        sources[test_net_id] = "net file: " + param_.net();
166        ReadNetParamsFromTextFileOrDie(param_.net(), &net_params[test_net_id]);
167      }
168    }
169    test_nets_.resize(num_test_net_instances);
170    for (int i = 0; i < num_test_net_instances; ++i) {
171      NetState net_state;
172      net_state.set_phase(TEST);
173      net_state.MergeFrom(net_params[i].state());
174      if (param_.test_state_size()) {
175        net_state.MergeFrom(param_.test_state(i));
176      }
177      net_params[i].mutable_state()->CopyFrom(net_state);
178      if (param_.engine() != "")
179        net_params[i].set_engine(param_.engine());
180      LOG(INFO)
181          << "Creating test net (#" << i << ") specified by " << sources[i];
182      if (Caffe::root_solver()) {
183        test_nets_[i].reset(new Net<Dtype>(net_params[i]));
184      } else {
185        test_nets_[i].reset(new Net<Dtype>(net_params[i],
186            root_solver_->test_nets_[i].get()));
187      }
188      test_nets_[i]->set_debug_info(param_.debug_info());
189    }
190  }
191  template <typename Dtype>
192  Dtype Solver<Dtype>::ForwardBackward() {
193    net_->ClearParamDiffs();
194    Dtype loss = Dtype();
195    vector<Blob<Dtype>*> bottom_vec;
196    for (int i = 0; i < param_.iter_size(); ++i) {
197      loss += net_->ForwardBackward();
198    }
199    return loss / param_.iter_size();
200  }
201  template <typename Dtype>
202  void Solver<Dtype>::Step(int iters) {
203    const int start_iter = iter_;
204    const int stop_iter = iter_ + iters;
205    int average_loss = this->param_.average_loss();
206    losses_.clear();
207    smoothed_loss_ = 0;
208    while (iter_ < stop_iter) {
209      if (param_.test_interval() && (iter_ - param_.test_offset()) % param_.test_interval() == 0
210          && (iter_ > 0 || param_.test_initialization())
211          && Caffe::root_solver()) {
212        TestAll();
213        if (requested_early_exit_) {
214          break;
215        }
216      }
217      for (int i = 0; i < callbacks_.size(); ++i) {
218        callbacks_[i]->on_start();
219      }
220      const bool display = param_.display() && iter_ % param_.display() == 0;
221      net_->set_debug_info(display && param_.debug_info());
222      Timer iter_timer;
223      double iter_time = 0.0;
224      iter_timer.Start();
225      Dtype loss = forward_backward_();
226      iter_time += iter_timer.MilliSeconds();
227      UpdateSmoothedLoss(loss, start_iter, average_loss);
228      if (display) {
229        LOG_IF(INFO, Caffe::root_solver()) << "Iteration " << iter_
230            << ", loss = " << smoothed_loss_;
231        const vector<Blob<Dtype>*>& result = net_->output_blobs();
232        int score_index = 0;
233        for (int j = 0; j < result.size(); ++j) {
234          const Dtype* result_vec = result[j]->cpu_data();
235          const string& output_name =
236              net_->blob_names()[net_->output_blob_indices()[j]];
237          const Dtype loss_weight =
238              net_->blob_loss_weights()[net_->output_blob_indices()[j]]
239  #ifdef USE_MLSL
240              * mn::get_distrib()->get_data_parts()
241  #endif
242                ;
243          for (int k = 0; k < result[j]->count(); ++k) {
244            ostringstream loss_msg_stream;
245            if (loss_weight) {
246              loss_msg_stream << " (* " << loss_weight
247                              << " = " << loss_weight * result_vec[k] << " loss)";
248            }
249            LOG_IF(INFO, Caffe::root_solver()) << "    Train net output #"
250                << score_index++ << ": " << output_name << " = "
251                << result_vec[k] << loss_msg_stream.str();
252          }
253        }
254      }
255      iter_timer.Start();
256      for (int i = 0; i < callbacks_.size(); ++i) {
257        callbacks_[i]->on_gradients_ready();
258      }
259      if (!param().disabled_update()) {
260        PERFORMANCE_MEASUREMENT_BEGIN();
261        ApplyUpdate();
262        PERFORMANCE_MEASUREMENT_END_STATIC("weights_update");
263      }else{
264        PrintLearningRate();
265      }
266      iter_time += iter_timer.MilliSeconds();
267  #ifdef CAFFE_PER_LAYER_TIMINGS
268      net_->SaveTimeline();
269      net_->PrintTimers(false);
270      net_->ResetTimers();
271  #ifdef USE_MLSL
272      if (mn::is_root())
273  #endif
274      LOG(INFO) << "iter " << iter_ << ", forward_backward_update_time: "
275              << iter_time << " ms";
276  #endif
277      ++iter_;
278      SolverAction::Enum request = GetRequestedAction();
279      if ((param_.snapshot()
280           && iter_ % param_.snapshot() == 0
281           && Caffe::root_solver()) ||
282           (request == SolverAction::SNAPSHOT)) {
283        Snapshot();
284      }
285      if (SolverAction::STOP == request) {
286        requested_early_exit_ = true;
287        break;
288      }
289    }
290  #ifdef CAFFE_PER_LAYER_TIMINGS
291    net_->ResetTimers();
292    net_->PrintTimers(true);
293    net_->PrintPayloadSize();
294  #endif
295  }
296  template <typename Dtype>
297  void Solver<Dtype>::Solve(const char* resume_file) {
298    CHECK(Caffe::root_solver());
299    LOG(INFO) << "Solving " << net_->name();
300    LOG(INFO) << "Learning Rate Policy: " << param_.lr_policy();
301    PERFORMANCE_INIT_MONITOR();
302    requested_early_exit_ = false;
303    if (resume_file) {
304      LOG(INFO) << "Restoring previous solver status from " << resume_file;
305      Restore(resume_file);
306    }
307    int start_iter = iter_;
308    Step(param_.max_iter() - iter_);
309    if (param_.snapshot_after_train()
310        && (!param_.snapshot() || iter_ % param_.snapshot() != 0)) {
311      Snapshot();
312    }
313    if (requested_early_exit_) {
314      LOG(INFO) << "Optimization stopped early.";
315      return;
316    }
317    if (param_.display() && iter_ % param_.display() == 0) {
318      int average_loss = this->param_.average_loss();
319      Dtype loss;
320      net_->Forward(&loss);
321      UpdateSmoothedLoss(loss, start_iter, average_loss);
322      LOG(INFO) << "Iteration " << iter_ << ", loss = " << smoothed_loss_;
323    }
324    if (param_.test_interval() && (iter_ - param_.test_offset()) % param_.test_interval() == 0)
325      TestAll();
326    LOG(INFO) << "Optimization Done.";
327  }
328  template <typename Dtype>
329  void Solver<Dtype>::TestAll() {
330  #ifdef USE_MLSL
331    for (int i = 0; i < callbacks_.size(); ++i) {
332      callbacks_[i]->on_before_test();
333    }
334  #endif
335    for (int test_net_id = 0;
336         test_net_id < test_nets_.size() && !requested_early_exit_;
337         ++test_net_id) {
338      if (param_.eval_type() == "classification") {
339        TestClassification(test_net_id);
340      } else if (param_.eval_type() == "detection") {
341        TestDetection(test_net_id);
342      } else {
343        LOG(FATAL) << "Unknown evaluation type: " << param_.eval_type();
344      }
345    }
346  #ifdef USE_MLSL
347    for (int i = 0; i < callbacks_.size(); ++i) {
348      callbacks_[i]->on_after_test();
349    }
350  #endif
351  }
352  template <typename Dtype>
353  void Solver<Dtype>::TestClassification(const int test_net_id) {
354    CHECK(Caffe::root_solver());
355    LOG(INFO) << "Iteration " << iter_
356              << ", Testing net (#" << test_net_id << ")";
357    CHECK_NOTNULL(test_nets_[test_net_id].get())->
358        ShareTrainedLayersWith(net_.get());
359    vector<Dtype> test_score;
360    vector<int> test_score_output_id;
361    const shared_ptr<Net<Dtype> >& test_net = test_nets_[test_net_id];
362    Dtype loss = 0;
363    int global_test_iter = param_.test_iter(test_net_id);
364  #ifdef USE_MLSL
365    int local_test_iter = global_test_iter / mn::get_nodes_count(); 
366    int left_test_iter = global_test_iter % mn::get_nodes_count();
367    if (mn::get_node_id() < left_test_iter)
368      local_test_iter += 1;
369  #else
370    int local_test_iter = global_test_iter;
371  #endif
372    for (int i = 0; i < local_test_iter; ++i) {
373      SolverAction::Enum request = GetRequestedAction();
374      while (request != SolverAction::NONE) {
375          if (SolverAction::SNAPSHOT == request) {
376            Snapshot();
377          } else if (SolverAction::STOP == request) {
378            requested_early_exit_ = true;
379          }
380          request = GetRequestedAction();
381      }
382      if (requested_early_exit_) {
383        break;
384      }
385      Dtype iter_loss;
386      const vector<Blob<Dtype>*>& result =
387          test_net->Forward(&iter_loss);
388      if (param_.test_compute_loss()) {
389        loss += iter_loss;
390      }
391      if (i == 0) {
392        for (int j = 0; j < result.size(); ++j) {
393          const Dtype* result_vec = result[j]->cpu_data();
394          for (int k = 0; k < result[j]->count(); ++k) {
395            test_score.push_back(result_vec[k]);
396            test_score_output_id.push_back(j);
397          }
398        }
399      } else {
400        int idx = 0;
401        for (int j = 0; j < result.size(); ++j) {
<span onclick='openModal()' class='match'>402          const Dtype* result_vec = result[j]->cpu_data();
403          for (int k = 0; k < result[j]->count(); ++k) {
404            test_score[idx++] += result_vec[k];
405          }
</span>406        }
407      }
408    }
409    if (requested_early_exit_) {
410      LOG(INFO)     << "Test interrupted.";
411      return;
412    }
413    if (param_.test_compute_loss()) {
414  #ifdef USE_MLSL
415      mn::allreduce(&loss, 1);
416      if (mn::is_root()) {
417  #endif &bsol;* USE_MLSL */
418      loss /= global_test_iter;
419      LOG(INFO) << "Test loss: " << loss;
420  #ifdef USE_MLSL
421      }
422  #endif &bsol;* USE_MLSL */
423    }
424  #ifdef USE_MLSL
425    mn::allreduce(test_score.data(), test_score.size());
426    if (mn::is_root())
427  #endif &bsol;* USE_MLSL */
428    for (int i = 0; i < test_score.size(); ++i) {
429      const int output_blob_index =
430          test_net->output_blob_indices()[test_score_output_id[i]];
431      const string& output_name = test_net->blob_names()[output_blob_index];
432      const Dtype loss_weight = test_net->blob_loss_weights()[output_blob_index];
433      ostringstream loss_msg_stream;
434      const Dtype mean_score = test_score[i] / global_test_iter;
435      if (loss_weight) {
436        loss_msg_stream << " (* " << loss_weight
437                        << " = " << loss_weight * mean_score << " loss)";
438      }
439      LOG(INFO) << "    Test net output #" << i << ": " << output_name << " = "
440                << mean_score << loss_msg_stream.str();
441    }
442  }
443  template <typename Dtype>
444  void Solver<Dtype>::TestDetection(const int test_net_id) {
445    CHECK(Caffe::root_solver());
446    LOG(INFO) << "Iteration " << iter_
447              << ", Testing net (#" << test_net_id << ")";
448    CHECK_NOTNULL(test_nets_[test_net_id].get())->
449        ShareTrainedLayersWith(net_.get());
450    map<int, map<int, vector<pair<float, int> > > > all_true_pos;
451    map<int, map<int, vector<pair<float, int> > > > all_false_pos;
452    map<int, map<int, int> > all_num_pos;
453    const shared_ptr<Net<Dtype> >& test_net = test_nets_[test_net_id];
454    Dtype loss = 0;
455    for (int i = 0; i < param_.test_iter(test_net_id); ++i) {
456      SolverAction::Enum request = GetRequestedAction();
457      while (request != SolverAction::NONE) {
458          if (SolverAction::SNAPSHOT == request) {
459            Snapshot();
460          } else if (SolverAction::STOP == request) {
461            requested_early_exit_ = true;
462          }
463          request = GetRequestedAction();
464      }
465      if (requested_early_exit_) {
466        break;
467      }
468      Dtype iter_loss;
469      const vector<Blob<Dtype>*>& result = test_net->Forward(&iter_loss);
470      if (param_.test_compute_loss()) {
471        loss += iter_loss;
472      }
473      for (int j = 0; j < result.size(); ++j) {
474        CHECK_EQ(result[j]->width(), 5);
475        const Dtype* result_vec = result[j]->cpu_data();
476        int num_det = result[j]->height();
477        for (int k = 0; k < num_det; ++k) {
478          int item_id = static_cast<int>(result_vec[k * 5]);
479          int label = static_cast<int>(result_vec[k * 5 + 1]);
480          if (item_id == -1) {
481            if (all_num_pos[j].find(label) == all_num_pos[j].end()) {
482              all_num_pos[j][label] = static_cast<int>(result_vec[k * 5 + 2]);
483            } else {
484              all_num_pos[j][label] += static_cast<int>(result_vec[k * 5 + 2]);
485            }
486          } else {
487            float score = result_vec[k * 5 + 2];
488            int tp = static_cast<int>(result_vec[k * 5 + 3]);
489            int fp = static_cast<int>(result_vec[k * 5 + 4]);
490            if (tp == 0 && fp == 0) {
491              continue;
492            }
493            all_true_pos[j][label].push_back(std::make_pair(score, tp));
494            all_false_pos[j][label].push_back(std::make_pair(score, fp));
495          }
496        }
497      }
498    }
499    if (requested_early_exit_) {
500      LOG(INFO)     << "Test interrupted.";
501      return;
502    }
503    if (param_.test_compute_loss()) {
504  #ifdef USE_MLSL
505      mn::allreduce(&loss, 1);
506      loss /= (param_.test_iter(test_net_id) * mn::get_group_size());
507      if (mn::is_root() == true)
508        LOG(INFO) << "Test loss: " << loss;
509  #else &bsol;* !USE_MLSL */
510      loss /= param_.test_iter(test_net_id);
511      LOG(INFO) << "Test loss: " << loss;
512  #endif &bsol;* USE_MLSL */
513    }
514    for (int i = 0; i < all_true_pos.size(); ++i) {
515      if (all_true_pos.find(i) == all_true_pos.end()) {
516        LOG(FATAL) << "Missing output_blob true_pos: " << i;
517      }
518      const map<int, vector<pair<float, int> > >& true_pos =
519          all_true_pos.find(i)->second;
520      if (all_false_pos.find(i) == all_false_pos.end()) {
521        LOG(FATAL) << "Missing output_blob false_pos: " << i;
522      }
523      const map<int, vector<pair<float, int> > >& false_pos =
524          all_false_pos.find(i)->second;
525      if (all_num_pos.find(i) == all_num_pos.end()) {
526        LOG(FATAL) << "Missing output_blob num_pos: " << i;
527      }
528      const map<int, int>& num_pos = all_num_pos.find(i)->second;
529      map<int, float> APs;
530      float mAP = 0.;
531      for (map<int, int>::const_iterator it = num_pos.begin();
532           it != num_pos.end(); ++it) {
533        int label = it->first;
534        int label_num_pos = it->second;
535        if (true_pos.find(label) == true_pos.end()) {
536          LOG(WARNING) << "Missing true_pos for label: " << label;
537          continue;
538        }
539        const vector<pair<float, int> >& label_true_pos =
540            true_pos.find(label)->second;
541        if (false_pos.find(label) == false_pos.end()) {
542          LOG(WARNING) << "Missing false_pos for label: " << label;
543          continue;
544        }
545        const vector<pair<float, int> >& label_false_pos =
546            false_pos.find(label)->second;
547        vector<float> prec, rec;
548        ComputeAP(label_true_pos, label_num_pos, label_false_pos,
549                  param_.ap_version(), &prec, &rec, &(APs[label]));
550        mAP += APs[label];
551      }
552  #ifdef USE_MLSL
553      Dtype allnodes_mAP = static_cast<Dtype>(mAP);
554      mn::allreduce(&allnodes_mAP, 1);
555      mAP = allnodes_mAP;
556      Dtype allnodes_num_pos = static_cast<Dtype>(num_pos.size());
557      mn::allreduce(&allnodes_num_pos, 1);
558      if (mn::is_root() == true)
559        mAP /= allnodes_num_pos;
560  #else &bsol;* USE_MLSL */
561      mAP /= num_pos.size();
562  #endif
563      const int output_blob_index = test_net->output_blob_indices()[i];
564      const string& output_name = test_net->blob_names()[output_blob_index];
565  #ifdef USE_MLSL
566      if (mn::is_root() == true)
567  #endif
568      LOG(INFO) << "    Test net output #" << i << ": " << output_name << " = "
569                << mAP;
570    }
571  }
572  template <typename Dtype>
573  void Solver<Dtype>::Snapshot() {
574    LOG(INFO)<<"Snapshot begin";
575    CHECK(Caffe::root_solver());
576  #ifdef USE_MLSL
577    for (int i = 0; i < callbacks_.size(); ++i) {
578      callbacks_[i]->on_before_snapshot();
579    }
580  #endif &bsol;* USE_MLSL */
581    string model_filename;
582    switch (param_.snapshot_format()) {
583    case caffe::SolverParameter_SnapshotFormat_BINARYPROTO:
584      model_filename = SnapshotToBinaryProto();
585      break;
586    case caffe::SolverParameter_SnapshotFormat_HDF5:
587      model_filename = SnapshotToHDF5();
588      break;
589    default:
590      LOG(FATAL) << "Unsupported snapshot format.";
591    }
592    SnapshotSolverState(model_filename);
593  #ifdef USE_MLSL
594    for (int i = 0; i < callbacks_.size(); ++i) {
595      callbacks_[i]->on_after_snapshot();
596    }
597  #endif
598    LOG(INFO)<<"Snapshot end";
599  }
600  template <typename Dtype>
601  void Solver<Dtype>::CheckSnapshotWritePermissions() {
602    if (Caffe::root_solver() && param_.snapshot()) {
603      CHECK(param_.has_snapshot_prefix())
604          << "In solver params, snapshot is specified but snapshot_prefix is not";
605      string probe_filename = SnapshotFilename(".tempfile");
606      std::ofstream probe_ofs(probe_filename.c_str());
607      if (probe_ofs.good()) {
608        probe_ofs.close();
609        std::remove(probe_filename.c_str());
610      } else {
611        LOG(FATAL) << "Cannot write to snapshot prefix '"
612            << param_.snapshot_prefix() << "'.  Make sure "
613            << "that the directory exists and is writeable.";
614      }
615    }
616  }
617  template <typename Dtype>
618  string Solver<Dtype>::SnapshotFilename(const string extension) {
619    return param_.snapshot_prefix() + "_iter_" + caffe::format_int(iter_)
620      + extension;
621  }
622  template <typename Dtype>
623  string Solver<Dtype>::SnapshotToBinaryProto() {
624    string model_filename = SnapshotFilename(".caffemodel");
625    NetParameter net_param;
626    net_->ToProto(&net_param, param_.snapshot_diff());
627  #ifdef USE_MLSL
628    if (mn::is_root()) {
629  #endif
630    LOG(INFO) << "Snapshotting to binary proto file " << model_filename;
631    WriteProtoToBinaryFile(net_param, model_filename);
632  #ifdef USE_MLSL
633    }
634  #endif
635    return model_filename;
636  }
637  template <typename Dtype>
638  string Solver<Dtype>::SnapshotToHDF5() {
639    string model_filename = SnapshotFilename(".caffemodel.h5");
640  #ifdef USE_MLSL
641    if (mn::is_root()) {
642  #endif
643    LOG(INFO) << "Snapshotting to HDF5 file " << model_filename;
644  #ifdef USE_MLSL
645    }
646  #endif
647    net_->ToHDF5(model_filename, param_.snapshot_diff());
648    return model_filename;
649  }
650  template <typename Dtype>
651  void Solver<Dtype>::Restore(const char* state_file) {
652    CHECK(Caffe::root_solver());
653    string state_filename(state_file);
654    if (state_filename.size() >= 3 &&
655        state_filename.compare(state_filename.size() - 3, 3, ".h5") == 0) {
656      RestoreSolverStateFromHDF5(state_filename);
657    } else {
658      RestoreSolverStateFromBinaryProto(state_filename);
659    }
660  }
661  template <typename Dtype>
662  void Solver<Dtype>::UpdateSmoothedLoss(Dtype loss, int start_iter,
663      int average_loss) {
664  #ifdef USE_MLSL
665    loss *= mn::get_distrib()->get_data_parts();
666  #endif
667    if (losses_.size() < average_loss) {
668      losses_.push_back(loss);
669      int size = losses_.size();
670      smoothed_loss_ = (smoothed_loss_ * (size - 1) + loss) / size;
671    } else {
672      int idx = (iter_ - start_iter) % average_loss;
673      smoothed_loss_ += (loss - losses_[idx]) / average_loss;
674      losses_[idx] = loss;
675    }
676  }
677  INSTANTIATE_CLASS(Solver);
678  }  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from snap-MDEwOlJlcG9zaXRvcnk0Mjg4MzU3-flat-anf.cpp</div>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-solver.cpp</div>
                <div class="column column_space"><pre><code>33    double Paths=0, SumLen=0;
34    for (int i = 0; i < DistNbrsPdfV.Len(); i++) {
35      SumLen += DistNbrsPdfV[i].Key * DistNbrsPdfV[i].Dat;
36      Paths += DistNbrsPdfV[i].Dat;
37    }
</pre></code></div>
                <div class="column column_space"><pre><code>402          const Dtype* result_vec = result[j]->cpu_data();
403          for (int k = 0; k < result[j]->count(); ++k) {
404            test_score[idx++] += result_vec[k];
405          }
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    