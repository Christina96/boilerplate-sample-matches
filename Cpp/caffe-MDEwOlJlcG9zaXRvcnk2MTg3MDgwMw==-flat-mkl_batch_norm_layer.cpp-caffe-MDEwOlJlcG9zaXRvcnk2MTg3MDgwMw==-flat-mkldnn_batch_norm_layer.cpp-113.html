
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 36, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-mkl_batch_norm_layer.cpp</h3>
            <pre><code>1  #if defined(MKL2017_SUPPORTED)
2  #include &lt;vector&gt;
3  #include &quot;caffe/filler.hpp&quot;
4  #include &quot;caffe/layer.hpp&quot;
5  #include &quot;caffe/layers/mkl_layers.hpp&quot;
6  #include &quot;caffe/util/math_functions.hpp&quot;
7  #include &quot;caffe/util/performance.hpp&quot;
8  namespace caffe {
9  template &lt;typename Dtype&gt;
10  MKLBatchNormLayer&lt;Dtype&gt;::~MKLBatchNormLayer() {
11    dnnDelete&lt;Dtype&gt;(batchNormFwd);
12    dnnDelete&lt;Dtype&gt;(batchNormFwdInference);
13    dnnDelete&lt;Dtype&gt;(batchNormBwd);
14    dnnLayoutDelete&lt;Dtype&gt;(layout_usr_);
15    for (int i = 0; i &lt; mean_buffers_.size(); i++) {
16      dnnReleaseBuffer&lt;Dtype&gt;(mean_buffers_[i]);
17    }
18    for (int i = 0; i &lt; variance_buffers_.size(); i++) {
19      dnnReleaseBuffer&lt;Dtype&gt;(variance_buffers_[i]);
20    }
21    dnnReleaseBuffer&lt;Dtype&gt;(scaleShift_buffer_);
22    dnnReleaseBuffer&lt;Dtype&gt;(diffScaleShift_buffer_);
23  }
24  template &lt;typename Dtype&gt;
25  void MKLBatchNormLayer&lt;Dtype&gt;::Init(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
26        const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
27    moving_average_fraction_ =
28                  this-&gt;layer_param_.batch_norm_param().moving_average_fraction();
29    eps_ = this-&gt;layer_param_.batch_norm_param().eps();
30    use_weight_bias_ = this-&gt;layer_param_.batch_norm_param().use_weight_bias();
31    bias_term_ = this-&gt;layer_param_.batch_norm_param().bias_term();
<span onclick='openModal()' class='match'>32    use_global_stats_ = this-&gt;phase_ == TEST;
33    if (this-&gt;layer_param_.batch_norm_param().has_use_global_stats())
34      use_global_stats_ = this-&gt;layer_param_.batch_norm_param().use_global_stats();
35    num_stats_batches_ = 1;
</span>36    stats_batch_size_ = bottom[0]-&gt;shape(0);
37    BatchNormParameter param = this-&gt;layer_param_.batch_norm_param();
38    if (!use_global_stats_ &amp;&amp; param.stats_batch_size() &gt; 0) {
39      CHECK_EQ(bottom[0]-&gt;shape(0) % param.stats_batch_size(), 0);
40      num_stats_batches_ = bottom[0]-&gt;shape(0) / param.stats_batch_size();
41      stats_batch_size_ = param.stats_batch_size();
42    }
43    CHECK(use_weight_bias_) &lt;&lt; &quot;BatchNorm without scaling have not supported yet&quot;;
44    size_t dim = 4, sizes[4], strides[4];
45    channels_ = bottom[0]-&gt;channels();
46    height_   = bottom[0]-&gt;height();
47    width_    = bottom[0]-&gt;width();
48    num_      = bottom[0]-&gt;num();
49    sizes[0] = width_;
50    sizes[1] = height_;
51    sizes[2] = channels_;
52    sizes[3] = num_;
53    strides[0] = 1;
54    strides[1] = sizes[0];
55    strides[2] = sizes[0]*sizes[1];
56    strides[3] = sizes[0]*sizes[1]*sizes[2];
57    fwd_bottom_data-&gt;name = &quot;fwd_bottom_data   @ &quot; + this-&gt;layer_param_.name();
58    fwd_top_data-&gt;name =    &quot;fwd_top_data      @ &quot; + this-&gt;layer_param_.name();
59    bwd_bottom_diff-&gt;name = &quot;bwd_bottom_diff   @ &quot; + this-&gt;layer_param_.name();
60    bwd_top_diff-&gt;name =    &quot;bwd_top_diff      @ &quot; + this-&gt;layer_param_.name();
61    fwd_bottom_data-&gt;create_user_layout(dim, sizes, strides, false);
62    fwd_top_data   -&gt;create_user_layout(dim, sizes, strides, false);
63    bwd_bottom_diff-&gt;create_user_layout(dim, sizes, strides, false);
64    bwd_top_diff   -&gt;create_user_layout(dim, sizes, strides, false);
65    sizes[3] /= num_stats_batches_;
66    dnnError_t e;
67    dnnLayoutDelete&lt;Dtype&gt;(layout_usr_);
68    e = dnnLayoutCreate&lt;Dtype&gt;(&amp;layout_usr_, dim, sizes, strides);
69    CHECK_EQ(e, E_SUCCESS);
70    for (int i = 0; i &lt; mean_buffers_.size(); i++) {
71      dnnReleaseBuffer&lt;Dtype&gt;(mean_buffers_[i]);
72    }
73    for (int i = 0; i &lt; variance_buffers_.size(); i++) {
74      dnnReleaseBuffer&lt;Dtype&gt;(variance_buffers_[i]);
75    }
76    mean_buffers_.resize(num_stats_batches_, NULL);
77    variance_buffers_.resize(num_stats_batches_, NULL);
78    dnnReleaseBuffer&lt;Dtype&gt;(scaleShift_buffer_);
79    dnnReleaseBuffer&lt;Dtype&gt;(diffScaleShift_buffer_);
80    dnnDelete&lt;Dtype&gt;(batchNormFwd);
81    dnnDelete&lt;Dtype&gt;(batchNormFwdInference);
82    dnnDelete&lt;Dtype&gt;(batchNormBwd);
83    this-&gt;blobs_.resize(3);
84    if (use_weight_bias_) {
85      if ( bias_term_ ) {
86          this-&gt;blobs_.resize(5);
87      } else {
88          this-&gt;blobs_.resize(4);
89      }
90      vector&lt;int&gt; scaleshift_shape(1);
91      scaleshift_shape[0] = channels_;
92      this-&gt;blobs_[3].reset(new Blob&lt;Dtype&gt;(scaleshift_shape));
93      FillerParameter filler_param(
94        this-&gt;layer_param_.batch_norm_param().filler());
95      if (!this-&gt;layer_param_.batch_norm_param().has_filler()) {
96        filler_param.set_type(&quot;constant&quot;);
97        filler_param.set_value(1);
98      }
99      shared_ptr&lt;Filler&lt;Dtype&gt; &gt; filler(GetFiller&lt;Dtype&gt;(filler_param));
100      filler-&gt;Fill(this-&gt;blobs_[3].get());
101      if ( bias_term_ ) {
102        this-&gt;blobs_[4].reset(new Blob&lt;Dtype&gt;(scaleshift_shape));
103        FillerParameter bias_filler_param(
104          this-&gt;layer_param_.batch_norm_param().bias_filler());
105        if (!this-&gt;layer_param_.batch_norm_param().has_bias_filler()) {
106          bias_filler_param.set_type(&quot;constant&quot;);
107          bias_filler_param.set_value(0);
108        }
109        shared_ptr&lt;Filler&lt;Dtype&gt; &gt; bias_filler(
110          GetFiller&lt;Dtype&gt;(bias_filler_param));
111        bias_filler-&gt;Fill(this-&gt;blobs_[4].get());
112      }
113    }
114    vector&lt;int&gt; sz;
115    sz.push_back(channels_);
116    this-&gt;blobs_[0].reset(new Blob&lt;Dtype&gt;(sz));
117    this-&gt;blobs_[1].reset(new Blob&lt;Dtype&gt;(sz));
118    sz[0]=1;
119    this-&gt;blobs_[2].reset(new Blob&lt;Dtype&gt;(sz));
120    for (int i = 0; i &lt; 3; ++i) {
121      caffe_set(this-&gt;blobs_[i]-&gt;count(), Dtype(0),
122                this-&gt;blobs_[i]-&gt;mutable_cpu_data());
123    }
124    for (int i = 0; i &lt; 3; ++i) {
125      if (this-&gt;layer_param_.param_size() == i) {
126        ParamSpec* fixed_param_spec = this-&gt;layer_param_.add_param();
127        fixed_param_spec-&gt;set_lr_mult(0.f);
128      } else {
129        CHECK_EQ(this-&gt;layer_param_.param(i).lr_mult(), 0.f)
130            &lt;&lt; &quot;Cannot configure batch normalization statistics as layer &quot;
131            &lt;&lt; &quot;parameters.&quot;;
132      }
133    }
134  }
135  template &lt;typename Dtype&gt;
136  void MKLBatchNormLayer&lt;Dtype&gt;::LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
137        const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
138    Init(bottom, top);
139  }
140  template &lt;typename Dtype&gt;
141  void MKLBatchNormLayer&lt;Dtype&gt;::Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
142        const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
143    bool re_init = true;
144    if (channels_ == bottom[0]-&gt;channels() &amp;&amp;
145        height_ == bottom[0]-&gt;height() &amp;&amp;
146        width_ == bottom[0]-&gt;width()) {
147      re_init = false;
148    }
149    if (bottom[0] == top[0]) {  
150      temp_.ReshapeLike(*bottom[0]);
151    } else {
152      channels_ = bottom[0]-&gt;channels();
153      height_ = bottom[0]-&gt;height();
154      width_ = bottom[0]-&gt;width();
155      num_ = bottom[0]-&gt;num();
156      top[0]-&gt;Reshape(num_, channels_, height_, width_);
157    }
158    if (re_init == true) {
159      Init(bottom, top);
160    } else if (num_ != bottom[0]-&gt;num()) { 
161      size_t dim = 4, sizes[4], strides[4];
162      sizes[0] = width_;
163      sizes[1] = height_;
164      sizes[2] = channels_;
165      sizes[3] = num_;
166      strides[0] = 1;
167      strides[1] = sizes[0];
168      strides[2] = sizes[0]*sizes[1];
169      strides[3] = sizes[0]*sizes[1]*sizes[2];
170      fwd_bottom_data-&gt;create_user_layout(dim, sizes, strides, false);
171      fwd_top_data   -&gt;create_user_layout(dim, sizes, strides, false);
172      bwd_bottom_diff-&gt;create_user_layout(dim, sizes, strides, false);
173      bwd_top_diff   -&gt;create_user_layout(dim, sizes, strides, false);
174      sizes[3] /= num_stats_batches_;
175      dnnError_t e;
176      dnnLayoutDelete&lt;Dtype&gt;(layout_usr_);
177      e = dnnLayoutCreate&lt;Dtype&gt;(&amp;layout_usr_, dim, sizes, strides);
178      CHECK_EQ(e, E_SUCCESS);
179    }
180  }
181  template &lt;typename Dtype&gt;
182  void MKLBatchNormLayer&lt;Dtype&gt;::ForwardStatsBatch_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
183      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top, int stats_batch_idx) {
184    long data_offset = stats_batch_idx * stats_batch_size_ * bottom[0]-&gt;count(1);
185    void* bottom_data =
186      reinterpret_cast&lt;void *&gt;(const_cast&lt;Dtype*&gt;(bottom[0]-&gt;prv_data()));
187    int is_first_pass = 0;
188    long amount_to_copy =0;
189    if (NULL != bottom_data &amp;&amp; num_stats_batches_ == 1) {
190      amount_to_copy = bottom[0]-&gt;prv_data_count();
191      if (batchNormFwd == NULL) {
192        is_first_pass = 1;
193        CHECK((bottom[0]-&gt;get_prv_data_descriptor())-&gt;get_descr_type() ==
194          PrvMemDescr::PRV_DESCR_MKL2017);
195        shared_ptr&lt;MKLData&lt;Dtype&gt; &gt; mem_descr
196          =  boost::static_pointer_cast&lt;MKLData&lt;Dtype&gt; &gt;(
197             bottom[0]-&gt;get_prv_data_descriptor());
198        CHECK(mem_descr != NULL);
199        DLOG(INFO) &lt;&lt; &quot;Using layout of &quot; &lt;&lt; mem_descr-&gt;name
200                &lt;&lt; &quot; as input layout for &quot; &lt;&lt; this-&gt;layer_param_.name();
201        fwd_bottom_data = mem_descr;
202        dnnError_t e;
203        e = dnnBatchNormalizationCreateForward&lt;Dtype&gt;(
204          &amp;batchNormFwd, NULL, mem_descr-&gt;layout_int, eps_, dnnUseScaleShift);
205        CHECK_EQ(e, E_SUCCESS);
206        e = dnnBatchNormalizationCreateForward&lt;Dtype&gt;(
207          &amp;batchNormFwdInference, NULL, mem_descr-&gt;layout_int, eps_,
208                                      dnnUseScaleShift | dnnUseInputMeanVariance);
209        CHECK_EQ(e, E_SUCCESS);
210        fwd_top_data   -&gt;create_internal_layout(batchNormFwd, dnnResourceDst);
211        bwd_top_diff   -&gt;create_internal_layout(batchNormFwd, dnnResourceDst);
212        bwd_bottom_diff-&gt;create_internal_layout(batchNormFwd, dnnResourceSrc);
213         if (!use_global_stats_) {
214           e = dnnBatchNormalizationCreateBackward&lt;Dtype&gt;(
215              &amp;batchNormBwd, NULL, mem_descr-&gt;layout_int, eps_, dnnUseScaleShift);
216           CHECK_EQ(e, E_SUCCESS);
217         } else {
218           e = dnnBatchNormalizationCreateBackward&lt;Dtype&gt;(
219              &amp;batchNormBwd, NULL, mem_descr-&gt;layout_int, eps_, dnnUseScaleShift | dnnUseInputMeanVariance);
220           CHECK_EQ(e, E_SUCCESS);
221         }
222      }
223    } else {
224      DLOG(INFO) &lt;&lt; &quot;Using cpu_data in MKLBatchNormLayer.&quot;;
225      if (batchNormFwd == NULL) {
226        is_first_pass = 1;
227        dnnError_t e;
228        e = dnnBatchNormalizationCreateForward&lt;Dtype&gt;(
229          &amp;batchNormFwd, NULL, layout_usr_, eps_, dnnUseScaleShift);
230        CHECK_EQ(e, E_SUCCESS);
231        e = dnnBatchNormalizationCreateForward&lt;Dtype&gt;(
232          &amp;batchNormFwdInference, NULL, layout_usr_, eps_,
233                                      dnnUseScaleShift | dnnUseInputMeanVariance);
234        CHECK_EQ(e, E_SUCCESS);
235        if (!use_global_stats_) {
236          e = dnnBatchNormalizationCreateBackward&lt;Dtype&gt;(
237            &amp;batchNormBwd, NULL, layout_usr_, eps_, dnnUseScaleShift);
238          CHECK_EQ(e, E_SUCCESS);
239        } else {
240          e = dnnBatchNormalizationCreateBackward&lt;Dtype&gt;(
241            &amp;batchNormBwd, NULL, layout_usr_, eps_, dnnUseScaleShift | dnnUseInputMeanVariance);
242          CHECK_EQ(e, E_SUCCESS);
243        }
244      }
245      bottom_data =
246        reinterpret_cast&lt;void *&gt;(const_cast&lt;Dtype*&gt;(bottom[0]-&gt;cpu_data()));
247      amount_to_copy = bottom[0]-&gt;count() / num_stats_batches_;
248    }
249    if (is_first_pass == 1) {
250        dnnError_t e;
251        dnnLayout_t mean_buffer_l = NULL;
252        e = dnnLayoutCreateFromPrimitive&lt;Dtype&gt;(
253          &amp;mean_buffer_l, batchNormFwd, dnnResourceMean);
254        CHECK_EQ(e, E_SUCCESS);
255        for (int i = 0; i &lt; num_stats_batches_; i++) {
256          e = dnnAllocateBuffer&lt;Dtype&gt;(
257            reinterpret_cast&lt;void**&gt;(&amp;mean_buffers_[i]), mean_buffer_l);
258          CHECK_EQ(e, E_SUCCESS);
259        }
260        dnnLayoutDelete&lt;Dtype&gt;(mean_buffer_l);
261        dnnLayout_t variance_buffer_l = NULL;
262        e = dnnLayoutCreateFromPrimitive&lt;Dtype&gt;(
263          &amp;variance_buffer_l, batchNormFwd, dnnResourceVariance);
264        CHECK_EQ(e, E_SUCCESS);
265        for (int i = 0; i &lt; num_stats_batches_; i++) {
266          e = dnnAllocateBuffer&lt;Dtype&gt;(
267            reinterpret_cast&lt;void**&gt;(&amp;variance_buffers_[i]), variance_buffer_l);
268          CHECK_EQ(e, E_SUCCESS);
269        }
270        dnnLayoutDelete&lt;Dtype&gt;(variance_buffer_l);
271         dnnLayout_t diffScaleShift_buffer_l = NULL;
272        e = dnnLayoutCreateFromPrimitive&lt;Dtype&gt;(
273          &amp;diffScaleShift_buffer_l, batchNormBwd, dnnResourceDiffScaleShift);
274        CHECK_EQ(e, E_SUCCESS);
275        e = dnnAllocateBuffer&lt;Dtype&gt;(
276          reinterpret_cast&lt;void**&gt;(&amp;diffScaleShift_buffer_), diffScaleShift_buffer_l);
277        CHECK_EQ(e, E_SUCCESS);
278        dnnLayoutDelete&lt;Dtype&gt;(diffScaleShift_buffer_l);
279        dnnLayout_t scaleShift_buffer_l = NULL;
280        e = dnnLayoutCreateFromPrimitive&lt;Dtype&gt;(
281          &amp;scaleShift_buffer_l, batchNormFwd, dnnResourceScaleShift);
282        CHECK_EQ(e, E_SUCCESS);
283        e = dnnAllocateBuffer&lt;Dtype&gt;(
284          reinterpret_cast&lt;void**&gt;(&amp;scaleShift_buffer_), scaleShift_buffer_l);
285        CHECK_EQ(e, E_SUCCESS);
286        dnnLayoutDelete&lt;Dtype&gt;(scaleShift_buffer_l);
287        if (!use_weight_bias_) {
288           for (int i = 0; i &lt; channels_; i++) {
289              scaleShift_buffer_[i] = 1.0;
290              scaleShift_buffer_[channels_ + i] = 0;
291           }
292        }
293    }
294    if (use_weight_bias_) {
295      for (int i = 0; i &lt; channels_; i++) {
296        scaleShift_buffer_[i] = this-&gt;blobs_[3]-&gt;cpu_data()[i];
297        scaleShift_buffer_[channels_ + i] = 0;
298        if (bias_term_) {
299           scaleShift_buffer_[channels_ + i] = this-&gt;blobs_[4]-&gt;cpu_data()[i];
300        }
301      }
302    }
303    if (bottom[0] == top[0] &amp;&amp; this-&gt;phase_ == TRAIN) {
304      caffe_copy(amount_to_copy, static_cast&lt;Dtype*&gt;(bottom_data) + data_offset,
305                 temp_.mutable_cpu_data() + data_offset);
306    }
307    if (use_global_stats_) {
308      const Dtype scale_factor = this-&gt;blobs_[2]-&gt;cpu_data()[0] == 0 ?
309                                 0 : 1 / this-&gt;blobs_[2]-&gt;cpu_data()[0];
310      caffe_cpu_scale(this-&gt;blobs_[0]-&gt;count(), scale_factor,
311                      this-&gt;blobs_[0]-&gt;cpu_data(), mean_buffers_[stats_batch_idx]);
312      caffe_cpu_scale(this-&gt;blobs_[1]-&gt;count(), scale_factor,
313                      this-&gt;blobs_[1]-&gt;cpu_data(), variance_buffers_[stats_batch_idx]);
314    }
315    dnnError_t e;
316    void* BatchNorm_res[dnnResourceNumber];
317    BatchNorm_res[dnnResourceMean] = mean_buffers_[stats_batch_idx];
318    BatchNorm_res[dnnResourceVariance] = variance_buffers_[stats_batch_idx];
319    BatchNorm_res[dnnResourceSrc] = (Dtype*)bottom_data + data_offset;
320    BatchNorm_res[dnnResourceScaleShift] = scaleShift_buffer_;
321    if (fwd_top_data-&gt;conversion_needed()) {
322      top[0]-&gt;set_prv_data_descriptor(fwd_top_data);
323      data_offset = stats_batch_idx * (top[0]-&gt;prv_data_count() / num_stats_batches_);
324      BatchNorm_res[dnnResourceDst] =
325              reinterpret_cast&lt;void *&gt;(top[0]-&gt;mutable_prv_data() + data_offset);
326    } else {
327      BatchNorm_res[dnnResourceDst] =
328              reinterpret_cast&lt;void *&gt;(top[0]-&gt;mutable_cpu_data() + data_offset);
329      DLOG(INFO) &lt;&lt; &quot;Using cpu_data for top in DnnBatchNorm.&quot;;
330    }
331    PERFORMANCE_EVENT_ID_INIT(perf_id_fw_, PERFORMANCE_MKL_NAME(&quot;FW&quot;));
332    PERFORMANCE_MEASUREMENT_BEGIN();
333    e = dnnExecute&lt;Dtype&gt;(use_global_stats_? batchNormFwdInference : batchNormFwd,
334                                                                   BatchNorm_res);
335    PERFORMANCE_MEASUREMENT_END_ID(perf_id_fw_);
336    CHECK_EQ(e, E_SUCCESS);
337    if (!use_global_stats_) {
338      this-&gt;blobs_[2]-&gt;mutable_cpu_data()[0] *= moving_average_fraction_;
339      this-&gt;blobs_[2]-&gt;mutable_cpu_data()[0] += 1;
340      caffe_cpu_axpby(this-&gt;blobs_[0]-&gt;count(), Dtype(1), mean_buffers_[stats_batch_idx],
341          moving_average_fraction_, this-&gt;blobs_[0]-&gt;mutable_cpu_data());
342      int m = bottom[0]-&gt;count()/num_stats_batches_/channels_;
343      Dtype bias_correction_factor = m &gt; 1 ? Dtype(m)/(m-1) : 1;
344      caffe_cpu_axpby(this-&gt;blobs_[1]-&gt;count(), bias_correction_factor,
345          variance_buffers_[stats_batch_idx], moving_average_fraction_,
346          this-&gt;blobs_[1]-&gt;mutable_cpu_data());
347    }
348  }
349  template &lt;typename Dtype&gt;
350  void MKLBatchNormLayer&lt;Dtype&gt;::BackwardStatsBatch_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
351      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
352      int stats_batch_idx) {
353    long data_offset = stats_batch_idx * stats_batch_size_ * bottom[0]-&gt;count(1);
354    void *bottom_data = NULL;
355    if (bottom[0] == top[0]) {
356      bottom_data = reinterpret_cast&lt;void *&gt;(
357                          const_cast&lt;Dtype*&gt;(temp_.cpu_data()));
358    } else {
359      bottom_data =
360              reinterpret_cast&lt;void *&gt;(
361                          const_cast&lt;Dtype*&gt;(bottom[0]-&gt;prv_data()));
362      if (NULL == bottom_data || num_stats_batches_ &gt; 1)
363        bottom_data =
364              reinterpret_cast&lt;void *&gt;(
365                          const_cast&lt;Dtype*&gt;(bottom[0]-&gt;cpu_data()));
366    }
367    dnnError_t e;
368    void* BatchNorm_res[dnnResourceNumber];
369    BatchNorm_res[dnnResourceMean] = mean_buffers_[stats_batch_idx];
370    BatchNorm_res[dnnResourceVariance] = variance_buffers_[stats_batch_idx];
371    BatchNorm_res[dnnResourceSrc] = (Dtype*)bottom_data + data_offset;
372    BatchNorm_res[dnnResourceScaleShift] = scaleShift_buffer_;
373    BatchNorm_res[dnnResourceDiffScaleShift] = diffScaleShift_buffer_;
374    BatchNorm_res[dnnResourceDiffDst] =
375      bwd_top_diff-&gt;get_converted_prv(top[0], true) + data_offset;
376    if (bwd_bottom_diff-&gt;conversion_needed()) {
377      bottom[0]-&gt;set_prv_diff_descriptor(bwd_bottom_diff);
378      data_offset = stats_batch_idx * (bottom[0]-&gt;prv_diff_count() / num_stats_batches_);
379      BatchNorm_res[dnnResourceDiffSrc] = bottom[0]-&gt;mutable_prv_diff() + data_offset;
380    } else {
381      BatchNorm_res[dnnResourceDiffSrc] = bottom[0]-&gt;mutable_cpu_diff() + data_offset;
382    }
383    PERFORMANCE_EVENT_ID_INIT(perf_id_bw_, PERFORMANCE_MKL_NAME(&quot;BW&quot;));
384    PERFORMANCE_MEASUREMENT_BEGIN();
385    e = dnnExecute&lt;Dtype&gt;(batchNormBwd, BatchNorm_res);
386    PERFORMANCE_MEASUREMENT_END_ID(perf_id_bw_);
387    CHECK_EQ(e, E_SUCCESS);
388    if (use_weight_bias_) {
389      caffe_cpu_axpby(this-&gt;blobs_[3]-&gt;count(), (Dtype)1.,
390                      diffScaleShift_buffer_, (Dtype)1., this-&gt;blobs_[3]-&gt;mutable_cpu_diff());
391      if (bias_term_)
392        caffe_cpu_axpby(this-&gt;blobs_[4]-&gt;count(), (Dtype)1.,
393                        diffScaleShift_buffer_ + channels_,
394                        (Dtype)1., this-&gt;blobs_[4]-&gt;mutable_cpu_diff());
395      else
396        caffe_set(this-&gt;blobs_[4]-&gt;count(),
397                      static_cast&lt;Dtype&gt;(0), this-&gt;blobs_[4]-&gt;mutable_cpu_diff());
398    }
399  }
400  template &lt;typename Dtype&gt;
401  void MKLBatchNormLayer&lt;Dtype&gt;::Forward_cpu(
402      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
403    for (int i = 0; i &lt; num_stats_batches_; i++) {
404      ForwardStatsBatch_cpu(bottom, top, i);
405    }
406  }
407  template &lt;typename Dtype&gt;
408  void MKLBatchNormLayer&lt;Dtype&gt;::Backward_cpu(
409      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top, const vector&lt;bool&gt;&amp; propagate_down,
410      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {
411    for (int i = 0; i &lt; num_stats_batches_; i++) {
412      BackwardStatsBatch_cpu(top, propagate_down, bottom, i);
413    }
414  }
415  #ifdef CPU_ONLY
416  STUB_GPU(MKLBatchNormLayer);
417  #else
418  template &lt;typename Dtype&gt;
419  void MKLBatchNormLayer&lt;Dtype&gt;::Forward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
420      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {NOT_IMPLEMENTED;}
421  template &lt;typename Dtype&gt;
422  void MKLBatchNormLayer&lt;Dtype&gt;::Backward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
423      const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom)
424    {NOT_IMPLEMENTED;}
425  #endif
426  INSTANTIATE_CLASS(MKLBatchNormLayer);
427  }  
428  #endif  
</code></pre>
        </div>
        <div class="column">
            <h3>caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-mkldnn_batch_norm_layer.cpp</h3>
            <pre><code>1  #ifdef MKLDNN_SUPPORTED
2  #include &lt;algorithm&gt;
3  #include &lt;vector&gt;
4  #include &quot;caffe/filler.hpp&quot;
5  #include &quot;caffe/layers/mkldnn_layers.hpp&quot;
6  namespace caffe {
7  template &lt;typename Dtype&gt;
8  void MKLDNNBatchNormLayer&lt;Dtype&gt;::InitStatsBatchVars(int batch_size) {
9      num_stats_batches_ = 1;
10      stats_batch_size_ = batch_size;
11      BatchNormParameter param = this-&gt;layer_param_.batch_norm_param();
12      if (!use_global_stats_ &amp;&amp; param.stats_batch_size() &gt; 0) {
13        CHECK_EQ(batch_size % param.stats_batch_size(), 0);
14        num_stats_batches_ = batch_size / param.stats_batch_size();
15        stats_batch_size_ = param.stats_batch_size();
16      }
17  }
18  template &lt;typename Dtype&gt;
19  void MKLDNNBatchNormLayer&lt;Dtype&gt;::LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom
20                                          ,const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)
21  {
22      VLOG(1) &lt;&lt; &quot;MKLDNNBatchNormLayer&lt;Dtype&gt;::LayerSetUp: &quot; &lt;&lt; this-&gt;layer_param_.name();
23      Layer&lt;Dtype&gt;::LayerSetUp(bottom, top);
24      shape_ = bottom[0]-&gt;shape();
25      const int channels = shape_[1];
26      eps_ = this-&gt;layer_param_.batch_norm_param().eps();
27      use_weight_bias_ = this-&gt;layer_param_.batch_norm_param().use_weight_bias();
28      bias_term_ = this-&gt;layer_param_.batch_norm_param().bias_term();
29      moving_average_fraction_ = this-&gt;layer_param_.batch_norm_param().moving_average_fraction();
<span onclick='openModal()' class='match'>30      use_global_stats_ = this-&gt;phase_ == TEST;
31      if (this-&gt;layer_param_.batch_norm_param().has_use_global_stats())
32        use_global_stats_ = this-&gt;layer_param_.batch_norm_param().use_global_stats();
33      InitStatsBatchVars(shape_[0]);
</span>34      this-&gt;blobs_.resize(3 + (use_weight_bias_ ? 1:0) + (use_weight_bias_ &amp;&amp; bias_term_ ? 1:0));
35      vector&lt;int&gt; sz;
36      sz.push_back(channels);
37      this-&gt;blobs_[0].reset(new Blob&lt;Dtype&gt;(sz));
38      this-&gt;blobs_[1].reset(new Blob&lt;Dtype&gt;(sz));
39      sz[0]=1;
40      this-&gt;blobs_[2].reset(new Blob&lt;Dtype&gt;(sz));
41      for (int i = 0; i &lt; 3; ++i) {
42          caffe_set(this-&gt;blobs_[i]-&gt;count(), Dtype(0),
43              this-&gt;blobs_[i]-&gt;mutable_cpu_data());
44      }
45      vector&lt;int&gt; scaleshift_blob_shape(1);
46      scaleshift_blob_shape[0] = 2*channels;
47      scaleshift_blob_.reset(new Blob&lt;Dtype&gt;(scaleshift_blob_shape));
48      caffe_set(scaleshift_blob_shape[0], static_cast&lt;Dtype&gt;(0),
49                scaleshift_blob_-&gt;mutable_cpu_data());
50      shared_ptr&lt;Blob&lt;Dtype&gt; &gt; scaleshift_diff_blob = scaleshift_blob_;
51      scaleshift_acc_ = scaleshift_blob_;
52      if (num_stats_batches_ &gt; 1) {
53        this-&gt;scaleshift_acc_.reset(new Blob&lt;Dtype&gt;(scaleshift_blob_shape));
54        scaleshift_diff_blob = scaleshift_acc_;
55      }
56      if (use_weight_bias_) {
57          vector&lt;int&gt; scaleshift_shape(1);
58          scaleshift_shape[0] = channels;
59          VLOG(1) &lt;&lt; &quot;MKLDNNBatchNormLayer&lt;Dtype&gt;::LayerSetUp: channels_  = &quot; &lt;&lt; channels;
60          this-&gt;blobs_[3].reset(new Blob&lt;Dtype&gt;(scaleshift_shape));
61          this-&gt;blobs_[3]-&gt;set_cpu_data(scaleshift_blob_-&gt;mutable_cpu_data());
62          this-&gt;blobs_[3]-&gt;set_cpu_diff(scaleshift_diff_blob-&gt;mutable_cpu_diff());
63          FillerParameter filler_param(this-&gt;layer_param_.batch_norm_param().filler());
64          if (!this-&gt;layer_param_.batch_norm_param().has_filler()) {
65              filler_param.set_type(&quot;constant&quot;);
66              filler_param.set_value(1);
67          }
68          shared_ptr&lt;Filler&lt;Dtype&gt; &gt; filler(GetFiller&lt;Dtype&gt;(filler_param));
69          VLOG(1) &lt;&lt; &quot;MKLDNNBatchNormLayer&lt;Dtype&gt;::LayerSetUp: scaleshift &quot; &lt;&lt; __LINE__ &lt;&lt; &quot;:&quot; &lt;&lt; this-&gt;layer_param_.name();
70          filler-&gt;Fill(this-&gt;blobs_[3].get());
71          if (bias_term_) {
72              this-&gt;blobs_[4].reset(new Blob&lt;Dtype&gt;(scaleshift_shape));
73              this-&gt;blobs_[4]-&gt;set_cpu_data(scaleshift_blob_-&gt;mutable_cpu_data() + scaleshift_blob_-&gt;offset(channels));
74              this-&gt;blobs_[4]-&gt;set_cpu_diff(scaleshift_diff_blob-&gt;mutable_cpu_diff() + scaleshift_blob_-&gt;offset(channels));
75              FillerParameter bias_filler_param(this-&gt;layer_param_.batch_norm_param().bias_filler());
76              if (!this-&gt;layer_param_.batch_norm_param().has_bias_filler()) {
77                  bias_filler_param.set_type(&quot;constant&quot;);
78                  bias_filler_param.set_value(0);
79              }
80              shared_ptr&lt;Filler&lt;Dtype&gt; &gt; bias_filler(GetFiller&lt;Dtype&gt;(bias_filler_param));
81              VLOG(1) &lt;&lt; &quot;MKLDNNBatchNormLayer&lt;Dtype&gt;::LayerSetUp: bias &quot; &lt;&lt; __LINE__ &lt;&lt; &quot;:&quot; &lt;&lt; this-&gt;layer_param_.name();
82              bias_filler-&gt;Fill(this-&gt;blobs_[4].get());
83          }
84      }
85      for (int i = 0; i &lt; 3; ++i) {
86        if (this-&gt;layer_param_.param_size() == i) {
87          ParamSpec* fixed_param_spec = this-&gt;layer_param_.add_param();
88          fixed_param_spec-&gt;set_lr_mult(0.f);
89        } else {
90          CHECK_EQ(this-&gt;layer_param_.param(i).lr_mult(), 0.f)
91              &lt;&lt; &quot;Cannot configure batch normalization statistics as layer &quot;
92              &lt;&lt; &quot;parameters.&quot;;
93        }
94      }
95  }
96  template &lt;typename Dtype&gt;
97  void MKLDNNBatchNormLayer&lt;Dtype&gt;::Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom
98                                      ,const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)
99  {
100      VLOG(1) &lt;&lt; &quot;MKLDNNBatchNormLayer&lt;Dtype&gt;::Reshape: &quot; &lt;&lt; this-&gt;layer_param_.name();
101      this-&gt;reshape = (this-&gt;shape_ == bottom[0]-&gt;shape()) ? false : true;
102      this-&gt;shape_ = bottom[0]-&gt;shape();
103      InitStatsBatchVars(this-&gt;shape_[0]);
104  #ifdef DEBUG
105      LOG(INFO) &lt;&lt; &quot;size of bottom blob: &quot; &lt;&lt; bottom[0]-&gt;shape().size();
106  #endif
107      top[0]-&gt;ReshapeLike(*bottom[0]);
108      if(bottom[0] == top[0] &amp;&amp; this-&gt;phase_ == TRAIN)
109          inplace_buffer.ReshapeLike(*bottom[0]);
110  }
111  template &lt;typename Dtype&gt;
112  void MKLDNNBatchNormLayer&lt;Dtype&gt;::InitBatchNorm(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)
113  {
114      if (std::is_same&lt;Dtype, double&gt;::value) NOT_IMPLEMENTED;
115      auto propagation = this-&gt;phase_ == TEST ? prop_kind::forward_scoring : prop_kind::forward_training;
116      unsigned flags = 0;
117      if (use_weight_bias_) flags |= use_scale_shift;
118      if (use_global_stats_) flags |= use_global_stats;
119      memory::format src_mfmt;
120      auto tensor_size = this-&gt;shape_.size();
121      memory::dims dim = this-&gt;shape_;
122      if(tensor_size == 5) {
123          src_mfmt = memory::format::ncdhw;
124      } else {
125          CHECK_LE(tensor_size, 4)
126              &lt;&lt; &quot;mkldnn batch normalization layer only supports dim size &lt;= 5!&quot;;
127          if (tensor_size &lt; 4) dim.resize(4, 1); 
128          src_mfmt = memory::format::nchw;
129      }
130      const int channels = this-&gt;shape_[1];
131      bool bottom_data_is_prv = (const_cast&lt;Dtype*&gt;(bottom[0]-&gt;prv_data()) != NULL);
132      bool inplace = (bottom[0] == top[0]);
133      engine cpu_engine = CpuEngine::Instance().get_engine();
134      memory::data_type mpcsn = memory::data_type::f32;
135      shared_ptr&lt;memory::desc&gt; input_md, input_stats_md, output_md, scaleshift_md;
136      shared_ptr&lt;memory::primitive_desc&gt; usr_mpd, prv_mpd;
137      shared_ptr&lt;memory::primitive_desc&gt; scaleshift_mpd;
138      if (bottom_data_is_prv) {
139          shared_ptr&lt;MKLDNNMemoryDescriptor&lt;Dtype, false&gt; &gt; mem_descr
140              = get_mkldnn_prv_descriptor&lt;Dtype, false&gt;(bottom[0]);
141          input_md.reset(new memory::desc(mem_descr-&gt;prv_memory_pd()-&gt;desc()));
142          usr_mpd = mem_descr-&gt;usr_memory_pd();
143          prv_mpd = mem_descr-&gt;prv_memory_pd();
144      } else {
145          input_md.reset(new memory::desc({dim}, mpcsn, src_mfmt));
146          usr_mpd.reset(new memory::primitive_desc(*input_md, cpu_engine));
147      }
148      output_md = input_md;
149      input_stats_md.reset(new memory::desc(*input_md));
150      CHECK(input_stats_md-&gt;data.ndims &gt; 0 &amp;&amp;
151            input_stats_md-&gt;data.dims[0] == this-&gt;shape_[0]);
152      input_stats_md-&gt;data.dims[0] = stats_batch_size_;
153      batch_normalization_forward::desc BatchNormFwd_desc(propagation, *input_stats_md, eps_, flags);
154      std::string subengines = this-&gt;layer_param_.engine();
155      if (subengines.find(&quot;MKLDNN&quot;) == std::string::npos || subengines == &quot;MKLDNN&quot;)
156        subengines = &quot;MKLDNN:CPU&quot;;
157      EngineParser ep(subengines);
158      unsigned subEngineIndex = 0;
159      BatchNormFwd_pd = NULL;
160      bool relu = this-&gt;layer_param_.batch_norm_param().relu();
161      mkldnn::primitive_attr attr;
162      mkldnn::post_ops ops;
163      if (relu) {
164          ops.append_eltwise(1.f, eltwise_relu, 0.f, 0.f);
165          attr.set_post_ops(ops);
166      }
167      for(; subEngineIndex &lt; ep.getNumberOfSubEngines(); subEngineIndex++) {
168        try {
169          if (relu)
170              BatchNormFwd_pd.reset(new batch_normalization_forward::primitive_desc(BatchNormFwd_desc, attr,
171                  ep.getMKLDNNSubEngine(subEngineIndex)));
172          else
173              BatchNormFwd_pd.reset(new batch_normalization_forward::primitive_desc(BatchNormFwd_desc,
174                  ep.getMKLDNNSubEngine(subEngineIndex)));
175        }
176        catch(...) {
177          continue;
178        }
179        break;
180      }
181      CHECK(BatchNormFwd_pd);
182      if (use_weight_bias_) {
183          if((this-&gt;blobs_[3]-&gt;mutable_cpu_data() + this-&gt;blobs_[3]-&gt;offset(channels)) == this-&gt;blobs_[4]-&gt;mutable_cpu_data()){
184              scaleshift_memory.reset(new memory(BatchNormFwd_pd-&gt;weights_primitive_desc(), this-&gt;blobs_[3]-&gt;mutable_cpu_data()));
185          }else {
186              scaleshift_memory.reset(new memory(BatchNormFwd_pd-&gt;weights_primitive_desc(), this-&gt;scaleshift_blob_-&gt;mutable_cpu_data()));
187          }
188      }
189      fwd_bottom_data.reset(new MKLDNNData&lt;Dtype&gt;(usr_mpd, prv_mpd, bottom[0], this));
190      input_primitive = fwd_bottom_data-&gt;create_input(false);
191      if(inplace &amp;&amp; this-&gt;phase_ == TRAIN) {
192          fwd_top_data.reset(new MKLDNNData&lt;Dtype&gt;(usr_mpd, prv_mpd, &amp;inplace_buffer, this));
193      } else {
194          fwd_top_data.reset(new MKLDNNData&lt;Dtype&gt;(usr_mpd, prv_mpd, top[0], this));
195      }
196      output_memory = fwd_top_data-&gt;create_output_memory();
197      mean_memory.resize(num_stats_batches_);
198      variance_memory.resize(num_stats_batches_);
199      input_stats.resize(num_stats_batches_);
200      output_stats.resize(num_stats_batches_);
201      BatchNormFwd.resize(num_stats_batches_);
202      for (int i = 0; i &lt; num_stats_batches_; i++) {
203        InitBatchNormFwdPrimitive(i);
204      }
205      MKLDNNPrimitive&lt;Dtype&gt; fwd_bottom_data_primitive_transfer(input_primitive);
206      fwd_bottom_data-&gt;set_mkldnn_primitive(fwd_bottom_data_primitive_transfer);
207      MKLDNNPrimitive&lt;Dtype&gt; fwd_top_data_memory_transfer(output_memory);
208      fwd_top_data-&gt;set_mkldnn_primitive(fwd_top_data_memory_transfer);
209      bool has_spatial = (bottom[0]-&gt;shape().size() != 2);
210  #ifdef DEBUG
211      LOG(INFO) &lt;&lt; &quot;has_spatial flag value: &quot; &lt;&lt; has_spatial;
212  #endif
213      if (has_spatial == false)
214      {
215  #ifdef DEBUG
216          LOG(INFO) &lt;&lt; &quot;size of bottom blob: &quot; &lt;&lt; bottom[0]-&gt;shape().size();
217          LOG(INFO) &lt;&lt; &quot;MKLDNN batch norm only support 4D memory descriptor! Use 4D for calculation and reshape to 2D for output!&quot;;
218  #endif
219          vector&lt;int&gt; top_shape;
220          top_shape.push_back(bottom[0]-&gt;shape(0));
221          top_shape.push_back(bottom[0]-&gt;shape(1));
222          top[0]-&gt;Reshape(top_shape);
223      }
224  }
225  template &lt;typename Dtype&gt;
226  template &lt;bool diff&gt;
227  shared_ptr&lt;memory&gt; MKLDNNBatchNormLayer&lt;Dtype&gt;::GetStatsBatchMemory(
228    shared_ptr&lt;MKLDNNMemoryDescriptor&lt;Dtype, diff&gt; &gt; mkldnn_mem, int idx) {
229      int length = this-&gt;shape_[1];
230      for(int i=2;i&lt;this-&gt;shape_.size();i++)
231          length *= this-&gt;shape_[i];
232      long data_offset =  idx * stats_batch_size_ * length;
233      engine cpu_engine = CpuEngine::Instance().get_engine();
234      shared_ptr&lt;memory::desc&gt; stats_md = mkldnn_mem-&gt;get_memory_desc();
235      CHECK(stats_md-&gt;data.ndims &gt; 0 &amp;&amp;
236            stats_md-&gt;data.dims[0] == this-&gt;shape_[0]);
237      stats_md-&gt;data.dims[0] = stats_batch_size_;
238      shared_ptr&lt;memory::primitive_desc&gt; stats_mpd(
239        new memory::primitive_desc(*stats_md, cpu_engine));
240      shared_ptr&lt;memory&gt; stats(
241        new memory(*stats_mpd, mkldnn_mem-&gt;get_memory_ptr(data_offset)));
242      return stats;
243  }
244  template &lt;typename Dtype&gt;
245  void MKLDNNBatchNormLayer&lt;Dtype&gt;::InitBatchNormFwdPrimitive(int idx) {
246      input_stats[idx] = GetStatsBatchMemory&lt;false&gt;(fwd_bottom_data, idx);
247      output_stats[idx] = GetStatsBatchMemory&lt;false&gt;(fwd_top_data, idx);
248      const int channels = this-&gt;shape_[1];
249      if (this-&gt;phase_ == TEST &amp;&amp; !use_global_stats_) {
250          if (use_weight_bias_) {
251              BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
252                      *input_stats[idx], *scaleshift_memory,
253                      *output_stats[idx]));
254          } else {
255              BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
256                      *input_stats[idx], *output_stats[idx]));
257          }
258      } else {
259          mean_memory[idx].reset(new memory(BatchNormFwd_pd-&gt;mean_primitive_desc()));
260          variance_memory[idx].reset(new memory(BatchNormFwd_pd-&gt;variance_primitive_desc()));
261          if (use_global_stats_) {
262              caffe_copy&lt;Dtype&gt;(channels, this-&gt;blobs_[0]-&gt;cpu_data(),
263                  static_cast&lt;Dtype *&gt;(mean_memory[idx]-&gt;get_data_handle()));
264              caffe_copy&lt;Dtype&gt;(channels, this-&gt;blobs_[1]-&gt;cpu_data(),
265                 static_cast&lt;Dtype *&gt;(variance_memory[idx]-&gt;get_data_handle()));
266              if (use_weight_bias_) {
267                  BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
268                          *input_stats[idx], (const primitive::at)*mean_memory[idx],
269                          (const primitive::at)*variance_memory[idx], *scaleshift_memory,
270                          *output_stats[idx]));
271              } else {
272                  BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
273                          *input_stats[idx], (const primitive::at)*mean_memory[idx],
274                          (const primitive::at)*variance_memory[idx], *output_stats[idx]));
275              }
276          } else {
277              if (use_weight_bias_) {
278                  BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
279                          *input_stats[idx], *scaleshift_memory, *output_stats[idx],
280                          *mean_memory[idx], *variance_memory[idx]));
281              } else {
282                  BatchNormFwd[idx].reset(new batch_normalization_forward(*BatchNormFwd_pd,
283                          *input_stats[idx], *output_stats[idx], *mean_memory[idx], *variance_memory[idx]));
284              }
285          }
286      }
287  }
288  template &lt;typename Dtype&gt;
289  void MKLDNNBatchNormLayer&lt;Dtype&gt;::Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom
290                                          ,const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)
291  {
292      VLOG(1) &lt;&lt; &quot;MKLDNNBatchNormLayer&lt;Dtype&gt;::Forward_cpu: &quot; &lt;&lt; this-&gt;layer_param_.name();
293  #ifdef DEBUG
294      LOG(INFO) &lt;&lt; &quot;MKLDNNBatchNormLayer&lt;Dtype&gt;::Forward_cpu: &quot; &lt;&lt; this-&gt;layer_param_.name();
295  #endif
296      if(BatchNormFwd_pd == NULL || this-&gt;reshape)
297          InitBatchNorm(bottom, top);
298      bool inplace = (bottom[0] == top[0]);
299      fwd_bottom_data-&gt;sync_before_read();
300      fwd_top_data-&gt;sync_before_write();
301      const int channels = this-&gt;shape_[1];
302      if((this-&gt;blobs_[3]-&gt;mutable_cpu_data() + this-&gt;blobs_[3]-&gt;offset(channels)) != this-&gt;blobs_[4]-&gt;mutable_cpu_data()){
303          caffe_copy(channels, this-&gt;blobs_[3]-&gt;cpu_data(), this-&gt;scaleshift_blob_-&gt;mutable_cpu_data());
304          caffe_copy(channels, this-&gt;blobs_[4]-&gt;cpu_data(), this-&gt;scaleshift_blob_-&gt;mutable_cpu_data() + scaleshift_blob_-&gt;offset(channels));
305      }
306      for (int stats_batch_idx = 0; stats_batch_idx &lt; num_stats_batches_; stats_batch_idx++) {
307        if (use_global_stats_) {
308          const Dtype scale_factor = this-&gt;blobs_[2]-&gt;cpu_data()[0] == 0 ?
309              0 : 1 / this-&gt;blobs_[2]-&gt;cpu_data()[0];
310          Dtype *mean_buffer_ = (Dtype *)(mean_memory[stats_batch_idx]-&gt;get_data_handle());
311          Dtype *variance_buffer_ = (Dtype *)(variance_memory[stats_batch_idx]-&gt;get_data_handle());
312          caffe_cpu_scale(this-&gt;blobs_[0]-&gt;count(), scale_factor,
313                      this-&gt;blobs_[0]-&gt;cpu_data(), mean_buffer_);
314          caffe_cpu_scale(this-&gt;blobs_[1]-&gt;count(), scale_factor,
315                      this-&gt;blobs_[1]-&gt;cpu_data(), variance_buffer_);
316        }
317        PERFORMANCE_EVENT_ID_INIT(perf_id_fw_, PERFORMANCE_MKLDNN_NAME(&quot;FW&quot;));
318        PERFORMANCE_MEASUREMENT_BEGIN();
319        BatchNormFwd[stats_batch_idx].submit();
320        PERFORMANCE_MEASUREMENT_END_ID(perf_id_fw_);
321        if (this-&gt;phase_ == TRAIN &amp;&amp; !use_global_stats_) {
322          Dtype *mean_buffer_ = (Dtype *)(mean_memory[stats_batch_idx]-&gt;get_data_handle());
323          Dtype *variance_buffer_ = (Dtype *)(variance_memory[stats_batch_idx]-&gt;get_data_handle());
324          this-&gt;blobs_[2]-&gt;mutable_cpu_data()[0] *= moving_average_fraction_;
325          this-&gt;blobs_[2]-&gt;mutable_cpu_data()[0] += 1;
326          caffe_cpu_axpby&lt;Dtype&gt;(channels, Dtype(1), mean_buffer_,
327              moving_average_fraction_, this-&gt;blobs_[0]-&gt;mutable_cpu_data());
328          int m = bottom[0]-&gt;count()/num_stats_batches_/channels;
329          Dtype bias_correction_factor = m &gt; 1 ? Dtype(m)/(m-1) : 1;
330          caffe_cpu_axpby&lt;Dtype&gt;(channels, bias_correction_factor,
331              variance_buffer_, moving_average_fraction_,
332              this-&gt;blobs_[1]-&gt;mutable_cpu_data());
333        }
334      }
335      if(inplace &amp;&amp; this-&gt;phase_ == TRAIN)
336          bottom[0]-&gt;data()-&gt;swap((inplace_buffer.data()));
337  }
338  template &lt;typename Dtype&gt;
339  void MKLDNNBatchNormLayer&lt;Dtype&gt;::InitBatchNormBwd(
340          const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top, const vector&lt;bool&gt;&amp; propagate_down,
341          const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom)
342  {
343      if (std::is_same&lt;Dtype, double&gt;::value) NOT_IMPLEMENTED;
344      memory::format src_mfmt;
345      auto tensor_size = this-&gt;shape_.size();
346      memory::dims dim = this-&gt;shape_;
347      if(tensor_size == 5) {
348          src_mfmt = memory::format::ncdhw;
349      } else {
350          CHECK_LE(tensor_size, 4)
351              &lt;&lt; &quot;mkldnn batch normalization layer only supports dim size &lt;= 5!&quot;;
352          if (tensor_size &lt; 4) dim.resize(4, 1); 
353          src_mfmt = memory::format::nchw;
354      }
355      unsigned flags = 0;
356      if (use_weight_bias_) flags |= use_scale_shift;
357      if (use_global_stats_) flags |= use_global_stats;
358      bool top_diff_is_prv = (const_cast&lt;Dtype*&gt;(top[0]-&gt;prv_diff()) != NULL);
359      bool inplace = (bottom[0] == top[0]);
360      engine cpu_engine = CpuEngine::Instance().get_engine();
361      memory::data_type mpcsn = memory::data_type::f32;
362      shared_ptr&lt;memory::desc&gt; top_diff_md, top_diff_stats_md, top_data_md, output_stats_md;
363      shared_ptr&lt;memory::primitive_desc&gt; usr_diff_mpd(NULL), prv_diff_mpd(NULL);
364      if (top_diff_is_prv) {
365          shared_ptr&lt;MKLDNNMemoryDescriptor&lt;Dtype, true&gt; &gt; mem_descr
366              = get_mkldnn_prv_descriptor&lt;Dtype, true&gt;(top[0]);
367          top_diff_md.reset(new memory::desc(mem_descr-&gt;prv_memory_pd()-&gt;desc()));
368          usr_diff_mpd = mem_descr-&gt;usr_memory_pd();
369          prv_diff_mpd = mem_descr-&gt;prv_memory_pd();
370      } else {
371          top_diff_md.reset(new memory::desc({dim}, mpcsn, src_mfmt));   
372          usr_diff_mpd.reset(new memory::primitive_desc(*top_diff_md, cpu_engine));
373      }
374      top_diff_stats_md.reset(new memory::desc(*top_diff_md));
375      CHECK(top_diff_stats_md-&gt;data.ndims &gt; 0 &amp;&amp;
376            top_diff_stats_md-&gt;data.dims[0] == this-&gt;shape_[0]);
377      top_diff_stats_md-&gt;data.dims[0] = stats_batch_size_;
378      output_stats_md.reset(new memory::desc(output_memory-&gt;get_primitive_desc().desc()));
379      CHECK(output_stats_md-&gt;data.ndims &gt; 0 &amp;&amp;
380            output_stats_md-&gt;data.dims[0] == this-&gt;shape_[0]);
381      output_stats_md-&gt;data.dims[0] = stats_batch_size_;
382      batch_normalization_backward::desc BatchNormBwd_desc(prop_kind::backward,
383              *top_diff_stats_md, *output_stats_md, eps_,
384              flags);
385      std::string subengines = this-&gt;layer_param_.engine();
386      if (subengines.find(&quot;MKLDNN&quot;) == std::string::npos || subengines == &quot;MKLDNN&quot;)
387        subengines = &quot;MKLDNN:CPU&quot;;
388      EngineParser ep(subengines);
389      unsigned subEngineIndex = 0;
390      BatchNormBwd_pd = NULL;
391      for(; subEngineIndex &lt; ep.getNumberOfSubEngines(); subEngineIndex++) {
392        try {
393          BatchNormBwd_pd.reset(new batch_normalization_backward::primitive_desc(
394                      BatchNormBwd_desc, ep.getMKLDNNSubEngine(subEngineIndex),
395                      *BatchNormFwd_pd));
396        }
397        catch(...) {
398          continue;
399        }
400        break;
401      }
402      CHECK(BatchNormBwd_pd);
403      if (use_weight_bias_) {
404          bwd_scaleshift_diff_memory.reset(new memory(
405                      BatchNormFwd_pd-&gt;weights_primitive_desc(), this-&gt;scaleshift_blob_-&gt;mutable_cpu_diff()));
406      }
407      bwd_top_diff.reset(new MKLDNNDiff&lt;Dtype&gt;(usr_diff_mpd, prv_diff_mpd, top[0], this));
408      bwd_top_diff-&gt;name = &quot;bwd_top_diff_data   @ &quot; + this-&gt;layer_param_.name();
409      bwd_top_diff_primitive = bwd_top_diff-&gt;create_input(false);
410      bwd_bottom_diff.reset(new MKLDNNDiff&lt;Dtype&gt;(usr_diff_mpd, prv_diff_mpd, bottom[0], this));
411      bwd_bottom_diff-&gt;name = &quot;bwd_bottom_diff_data   @ &quot; + this-&gt;layer_param_.name();
412      bwd_bottom_diff_memory = bwd_bottom_diff-&gt;create_output_memory(inplace);
413      top_diff_stats.resize(num_stats_batches_);
414      bottom_diff_stats.resize(num_stats_batches_);
415      BatchNormBwd.resize(num_stats_batches_);
416      for (int i = 0; i &lt; num_stats_batches_; i++) {
417        InitBatchNormBwdPrimitive(i);
418      }
419      MKLDNNPrimitive&lt;Dtype&gt; bwd_top_diff_primitive_transfer(bwd_top_diff_primitive);
420      bwd_top_diff-&gt;set_mkldnn_primitive(bwd_top_diff_primitive_transfer);
421      MKLDNNPrimitive&lt;Dtype&gt; bwd_bottom_diff_memory_transfer(bwd_bottom_diff_memory);
422      bwd_bottom_diff-&gt;set_mkldnn_primitive(bwd_bottom_diff_memory_transfer);
423  }
424  template &lt;typename Dtype&gt;
425  void MKLDNNBatchNormLayer&lt;Dtype&gt;::InitBatchNormBwdPrimitive(int idx) {
426      top_diff_stats[idx] = GetStatsBatchMemory&lt;true&gt;(bwd_top_diff, idx);
427      bottom_diff_stats[idx] = GetStatsBatchMemory&lt;true&gt;(bwd_bottom_diff, idx);
428      if (use_weight_bias_) {
429          BatchNormBwd[idx].reset(new batch_normalization_backward(*BatchNormBwd_pd,
430                      *input_stats[idx], *mean_memory[idx], *variance_memory[idx],
431                      *top_diff_stats[idx], *scaleshift_memory,
432                      *bottom_diff_stats[idx], *bwd_scaleshift_diff_memory));
433      } else {
434          BatchNormBwd[idx].reset(new batch_normalization_backward(*BatchNormBwd_pd,
435                      *input_stats[idx], *mean_memory[idx], *variance_memory[idx],
436                      *top_diff_stats[idx], *bottom_diff_stats[idx]));
437      }
438  }
439  template &lt;typename Dtype&gt;
440  void MKLDNNBatchNormLayer&lt;Dtype&gt;::Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
441          const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom)
442  {
443      VLOG(1) &lt;&lt; &quot;MKLDNNBatchNormLayer&lt;Dtype&gt;::Backward_cpu: &quot; &lt;&lt; this-&gt;layer_param_.name();
444  #ifdef DEBUG
445      LOG(INFO) &lt;&lt; &quot;MKLDNNBatchNormLayer&lt;Dtype&gt;::Backward_cpu: &quot; &lt;&lt; this-&gt;layer_param_.name();
446  #endif
447      if (BatchNormBwd_pd == NULL || this-&gt;reshape)
448          InitBatchNormBwd(top, propagate_down, bottom);
449      bwd_top_diff-&gt;sync_before_read();
450      bwd_bottom_diff-&gt;sync_before_write();
451      for (int stats_batch_idx = 0; stats_batch_idx &lt; num_stats_batches_; stats_batch_idx++) {
452        PERFORMANCE_EVENT_ID_INIT(perf_id_bw_, PERFORMANCE_MKLDNN_NAME(&quot;BW&quot;));
453        PERFORMANCE_MEASUREMENT_BEGIN();
454  #ifdef DEBUG
455        if (bottom[0]-&gt;prv_data() != NULL)
456        {
457          LOG(INFO) &lt;&lt; &quot;Debug: Bottom prv data: &quot; &lt;&lt; *bottom[0]-&gt;prv_data();
458        }
459        else
460        {
461          LOG(INFO) &lt;&lt; &quot;Debug: Bottom prv data is NULL!&quot;;
462        }
463        if (top[0]-&gt;prv_diff() != NULL)
464        {
465          LOG(INFO) &lt;&lt; &quot;Debug: Top prv diff: &quot; &lt;&lt; *top[0]-&gt;prv_diff();
466        }
467        else
468        {
469          LOG(INFO) &lt;&lt; &quot;Debug: Top prv diff is NULL!&quot;;
470          LOG(INFO) &lt;&lt; &quot;Debug: Top cpu diff: &quot; &lt;&lt; *top[0]-&gt;cpu_diff();
471        }
472  #endif
473        BatchNormBwd[stats_batch_idx].submit();
474  #ifdef DEBUG
475        if (bottom[0]-&gt;prv_diff() != NULL)
476        {
477          LOG(INFO) &lt;&lt; &quot;Debug: Bottom prv diff: &quot; &lt;&lt; *bottom[0]-&gt;prv_diff();
478        }
479        else
480        {
481          LOG(INFO) &lt;&lt; &quot;Debug: Bottom prv diff is NULL!&quot;;
482          LOG(INFO) &lt;&lt; &quot;Debug: Bottom cpu diff: &quot; &lt;&lt; *bottom[0]-&gt;cpu_diff();
483        }
484  #endif
485        PERFORMANCE_MEASUREMENT_END_ID(perf_id_bw_);
486        if (num_stats_batches_ &gt; 1) {
487          CHECK(scaleshift_blob_ != scaleshift_acc_);
488          CHECK(scaleshift_blob_-&gt;count() == scaleshift_acc_-&gt;count());
489          caffe_cpu_axpby(scaleshift_acc_-&gt;count(), Dtype(1),
490                          scaleshift_blob_-&gt;mutable_cpu_diff(),
491                          Dtype(1), scaleshift_acc_-&gt;mutable_cpu_diff());
492        }
493      }
494  }
495  #ifdef CPU_ONLY
496  STUB_GPU(MKLDNNBatchNormLayer);
497  #else
498  template &lt;typename Dtype&gt;
499  void MKLDNNBatchNormLayer&lt;Dtype&gt;::Forward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom
500                                          ,const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top)
501  { NOT_IMPLEMENTED; }
502  template &lt;typename Dtype&gt;
503  void MKLDNNBatchNormLayer&lt;Dtype&gt;::Backward_gpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top
504                                              ,const vector&lt;bool&gt;&amp; propagate_down
505                                              ,const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom)
506  { NOT_IMPLEMENTED; }
507  #endif
508  INSTANTIATE_CLASS(MKLDNNBatchNormLayer);
509  }  
510  #endif  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-mkl_batch_norm_layer.cpp</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from caffe-MDEwOlJlcG9zaXRvcnk2MTg3MDgwMw==-flat-mkldnn_batch_norm_layer.cpp</div>
                </div>
                <div class="column column_space"><pre><code>32    use_global_stats_ = this-&gt;phase_ == TEST;
33    if (this-&gt;layer_param_.batch_norm_param().has_use_global_stats())
34      use_global_stats_ = this-&gt;layer_param_.batch_norm_param().use_global_stats();
35    num_stats_batches_ = 1;
</pre></code></div>
                <div class="column column_space"><pre><code>30      use_global_stats_ = this-&gt;phase_ == TEST;
31      if (this-&gt;layer_param_.batch_norm_param().has_use_global_stats())
32        use_global_stats_ = this-&gt;layer_param_.batch_norm_param().use_global_stats();
33      InitStatsBatchVars(shape_[0]);
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    