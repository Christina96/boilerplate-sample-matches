<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for tanh_layer.cpp &amp; pooling_layer.cpp</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for tanh_layer.cpp &amp; pooling_layer.cpp
      </h3>
<h1 align="center">
        4.9%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>tanh_layer.cpp (24.489796%)<th>pooling_layer.cpp (2.7522936%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(10-15)<td><a href="#" name="0">(140-145)</a><td align="center"><font color="#ff0000">12</font>
</td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>tanh_layer.cpp</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 #include &lt;vector&gt;
2 #include "caffe/layers/tanh_layer.hpp"
3 <a name="0"></a>
4 namespace caffe {
5 <font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>template &lt;typename Dtype&gt;
6 void TanHLayer&lt;Dtype&gt;::Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
7     const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
8   const Dtype* bottom_data = bottom[0]-&gt;cpu_data();
9   Dtype* top_data = top[0]-&gt;mutable_cpu_data();
10   const int count = bottom[0]-&gt;count();</b></font>
11   for (int i = 0; i &lt; count; ++i) {
12     top_data[i] = tanh(bottom_data[i]);
13   }
14 }
15 template &lt;typename Dtype&gt;
16 void TanHLayer&lt;Dtype&gt;::Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
17     const vector&lt;bool&gt;&amp; propagate_down,
18     const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {
19   if (propagate_down[0]) {
20     const Dtype* top_data = top[0]-&gt;cpu_data();
21     const Dtype* top_diff = top[0]-&gt;cpu_diff();
22     Dtype* bottom_diff = bottom[0]-&gt;mutable_cpu_diff();
23     const int count = bottom[0]-&gt;count();
24     Dtype tanhx;
25     for (int i = 0; i &lt; count; ++i) {
26       tanhx = top_data[i];
27       bottom_diff[i] = top_diff[i] * (1 - tanhx * tanhx);
28     }
29   }
30 }
31 #ifdef CPU_ONLY
32 STUB_GPU(TanHLayer);
33 #endif
34 INSTANTIATE_CLASS(TanHLayer);
}  </pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>pooling_layer.cpp</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 #include &lt;algorithm&gt;
2 #include &lt;cfloat&gt;
3 #include &lt;vector&gt;
4 #include "caffe/layers/pooling_layer.hpp"
5 #include "caffe/util/math_functions.hpp"
6 namespace caffe {
7 using std::min;
8 using std::max;
9 template &lt;typename Dtype&gt;
10 void PoolingLayer&lt;Dtype&gt;::LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
11       const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
12   PoolingParameter pool_param = this-&gt;layer_param_.pooling_param();
13   if (pool_param.global_pooling()) {
14     CHECK(!(pool_param.has_kernel_size() ||
15       pool_param.has_kernel_h() || pool_param.has_kernel_w()))
16       &lt;&lt; "With Global_pooling: true Filter size cannot specified";
17   } else {
18     CHECK(!pool_param.has_kernel_size() !=
19       !(pool_param.has_kernel_h() &amp;&amp; pool_param.has_kernel_w()))
20       &lt;&lt; "Filter size is kernel_size OR kernel_h and kernel_w; not both";
21     CHECK(pool_param.has_kernel_size() ||
22       (pool_param.has_kernel_h() &amp;&amp; pool_param.has_kernel_w()))
23       &lt;&lt; "For non-square filters both kernel_h and kernel_w are required.";
24   }
25   CHECK((!pool_param.has_pad() &amp;&amp; pool_param.has_pad_h()
26       &amp;&amp; pool_param.has_pad_w())
27       || (!pool_param.has_pad_h() &amp;&amp; !pool_param.has_pad_w()))
28       &lt;&lt; "pad is pad OR pad_h and pad_w are required.";
29   CHECK((!pool_param.has_stride() &amp;&amp; pool_param.has_stride_h()
30       &amp;&amp; pool_param.has_stride_w())
31       || (!pool_param.has_stride_h() &amp;&amp; !pool_param.has_stride_w()))
32       &lt;&lt; "Stride is stride OR stride_h and stride_w are required.";
33   global_pooling_ = pool_param.global_pooling();
34   round_mode_ = pool_param.round_mode();
35   if (global_pooling_) {
36     kernel_h_ = bottom[0]-&gt;height();
37     kernel_w_ = bottom[0]-&gt;width();
38   } else {
39     if (pool_param.has_kernel_size()) {
40       kernel_h_ = kernel_w_ = pool_param.kernel_size();
41     } else {
42       kernel_h_ = pool_param.kernel_h();
43       kernel_w_ = pool_param.kernel_w();
44     }
45   }
46   CHECK_GT(kernel_h_, 0) &lt;&lt; "Filter dimensions cannot be zero.";
47   CHECK_GT(kernel_w_, 0) &lt;&lt; "Filter dimensions cannot be zero.";
48   if (!pool_param.has_pad_h()) {
49     pad_h_ = pad_w_ = pool_param.pad();
50   } else {
51     pad_h_ = pool_param.pad_h();
52     pad_w_ = pool_param.pad_w();
53   }
54   if (!pool_param.has_stride_h()) {
55     stride_h_ = stride_w_ = pool_param.stride();
56   } else {
57     stride_h_ = pool_param.stride_h();
58     stride_w_ = pool_param.stride_w();
59   }
60   if (global_pooling_) {
61     CHECK(pad_h_ == 0 &amp;&amp; pad_w_ == 0 &amp;&amp; stride_h_ == 1 &amp;&amp; stride_w_ == 1)
62       &lt;&lt; "With Global_pooling: true; only pad = 0 and stride = 1";
63   }
64   if (pad_h_ != 0 || pad_w_ != 0) {
65     CHECK(this-&gt;layer_param_.pooling_param().pool()
66         == PoolingParameter_PoolMethod_AVE
67         || this-&gt;layer_param_.pooling_param().pool()
68         == PoolingParameter_PoolMethod_MAX)
69         &lt;&lt; "Padding implemented only for average and max pooling.";
70     CHECK_LT(pad_h_, kernel_h_);
71     CHECK_LT(pad_w_, kernel_w_);
72   }
73 }
74 template &lt;typename Dtype&gt;
75 void PoolingLayer&lt;Dtype&gt;::Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
76       const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
77   CHECK_EQ(4, bottom[0]-&gt;num_axes()) &lt;&lt; "Input must have 4 axes, "
78       &lt;&lt; "corresponding to (num, channels, height, width)";
79   channels_ = bottom[0]-&gt;channels();
80   height_ = bottom[0]-&gt;height();
81   width_ = bottom[0]-&gt;width();
82   if (global_pooling_) {
83     kernel_h_ = bottom[0]-&gt;height();
84     kernel_w_ = bottom[0]-&gt;width();
85   }
86   switch (round_mode_) {
87   case PoolingParameter_RoundMode_CEIL:
88     pooled_height_ = static_cast&lt;int&gt;(ceil(static_cast&lt;float&gt;(
89         height_ + 2 * pad_h_ - kernel_h_) / stride_h_)) + 1;
90     pooled_width_ = static_cast&lt;int&gt;(ceil(static_cast&lt;float&gt;(
91         width_ + 2 * pad_w_ - kernel_w_) / stride_w_)) + 1;
92     break;
93   case PoolingParameter_RoundMode_FLOOR:
94     pooled_height_ = static_cast&lt;int&gt;(floor(static_cast&lt;float&gt;(
95         height_ + 2 * pad_h_ - kernel_h_) / stride_h_)) + 1;
96     pooled_width_ = static_cast&lt;int&gt;(floor(static_cast&lt;float&gt;(
97         width_ + 2 * pad_w_ - kernel_w_) / stride_w_)) + 1;
98     break;
99   default:
100     LOG(FATAL) &lt;&lt; "Unknown rounding mode.";
101   }
102   if (pad_h_ || pad_w_) {
103     if ((pooled_height_ - 1) * stride_h_ &gt;= height_ + pad_h_) {
104       --pooled_height_;
105     }
106     if ((pooled_width_ - 1) * stride_w_ &gt;= width_ + pad_w_) {
107       --pooled_width_;
108     }
109     CHECK_LT((pooled_height_ - 1) * stride_h_, height_ + pad_h_);
110     CHECK_LT((pooled_width_ - 1) * stride_w_, width_ + pad_w_);
111   }
112   top[0]-&gt;Reshape(bottom[0]-&gt;num(), channels_, pooled_height_,
113       pooled_width_);
114   if (top.size() &gt; 1) {
115     top[1]-&gt;ReshapeLike(*top[0]);
116   }
117   if (this-&gt;layer_param_.pooling_param().pool() ==
118       PoolingParameter_PoolMethod_MAX &amp;&amp; top.size() == 1) {
119     max_idx_.Reshape(bottom[0]-&gt;num(), channels_, pooled_height_,
120         pooled_width_);
121   }
122   if (this-&gt;layer_param_.pooling_param().pool() ==
123       PoolingParameter_PoolMethod_STOCHASTIC) {
124     rand_idx_.Reshape(bottom[0]-&gt;num(), channels_, pooled_height_,
125       pooled_width_);
126   }
127 }
128 <a name="0"></a>
129 <font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>template &lt;typename Dtype&gt;
130 void PoolingLayer&lt;Dtype&gt;::Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
131       const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
132   const Dtype* bottom_data = bottom[0]-&gt;cpu_data();
133   Dtype* top_data = top[0]-&gt;mutable_cpu_data();
134   const int top_count = top[0]-&gt;count();</b></font>
135   const bool use_top_mask = top.size() &gt; 1;
136   int* mask = NULL;    Dtype* top_mask = NULL;
137   switch (this-&gt;layer_param_.pooling_param().pool()) {
138   case PoolingParameter_PoolMethod_MAX:
139     if (use_top_mask) {
140       top_mask = top[1]-&gt;mutable_cpu_data();
141       caffe_set(top_count, Dtype(-1), top_mask);
142     } else {
143       mask = max_idx_.mutable_cpu_data();
144       caffe_set(top_count, -1, mask);
145     }
146     caffe_set(top_count, Dtype(-FLT_MAX), top_data);
147     for (int n = 0; n &lt; bottom[0]-&gt;num(); ++n) {
148       for (int c = 0; c &lt; channels_; ++c) {
149         for (int ph = 0; ph &lt; pooled_height_; ++ph) {
150           for (int pw = 0; pw &lt; pooled_width_; ++pw) {
151             int hstart = ph * stride_h_ - pad_h_;
152             int wstart = pw * stride_w_ - pad_w_;
153             int hend = min(hstart + kernel_h_, height_);
154             int wend = min(wstart + kernel_w_, width_);
155             hstart = max(hstart, 0);
156             wstart = max(wstart, 0);
157             const int pool_index = ph * pooled_width_ + pw;
158             for (int h = hstart; h &lt; hend; ++h) {
159               for (int w = wstart; w &lt; wend; ++w) {
160                 const int index = h * width_ + w;
161                 if (bottom_data[index] &gt; top_data[pool_index]) {
162                   top_data[pool_index] = bottom_data[index];
163                   if (use_top_mask) {
164                     top_mask[pool_index] = static_cast&lt;Dtype&gt;(index);
165                   } else {
166                     mask[pool_index] = index;
167                   }
168                 }
169               }
170             }
171           }
172         }
173         bottom_data += bottom[0]-&gt;offset(0, 1);
174         top_data += top[0]-&gt;offset(0, 1);
175         if (use_top_mask) {
176           top_mask += top[0]-&gt;offset(0, 1);
177         } else {
178           mask += top[0]-&gt;offset(0, 1);
179         }
180       }
181     }
182     break;
183   case PoolingParameter_PoolMethod_AVE:
184     for (int i = 0; i &lt; top_count; ++i) {
185       top_data[i] = 0;
186     }
187     for (int n = 0; n &lt; bottom[0]-&gt;num(); ++n) {
188       for (int c = 0; c &lt; channels_; ++c) {
189         for (int ph = 0; ph &lt; pooled_height_; ++ph) {
190           for (int pw = 0; pw &lt; pooled_width_; ++pw) {
191             int hstart = ph * stride_h_ - pad_h_;
192             int wstart = pw * stride_w_ - pad_w_;
193             int hend = min(hstart + kernel_h_, height_ + pad_h_);
194             int wend = min(wstart + kernel_w_, width_ + pad_w_);
195             int pool_size = (hend - hstart) * (wend - wstart);
196             hstart = max(hstart, 0);
197             wstart = max(wstart, 0);
198             hend = min(hend, height_);
199             wend = min(wend, width_);
200             for (int h = hstart; h &lt; hend; ++h) {
201               for (int w = wstart; w &lt; wend; ++w) {
202                 top_data[ph * pooled_width_ + pw] +=
203                     bottom_data[h * width_ + w];
204               }
205             }
206             top_data[ph * pooled_width_ + pw] /= pool_size;
207           }
208         }
209         bottom_data += bottom[0]-&gt;offset(0, 1);
210         top_data += top[0]-&gt;offset(0, 1);
211       }
212     }
213     break;
214   case PoolingParameter_PoolMethod_STOCHASTIC:
215     NOT_IMPLEMENTED;
216     break;
217   default:
218     LOG(FATAL) &lt;&lt; "Unknown pooling method.";
219   }
220 }
221 template &lt;typename Dtype&gt;
222 void PoolingLayer&lt;Dtype&gt;::Backward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
223       const vector&lt;bool&gt;&amp; propagate_down, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {
224   if (!propagate_down[0]) {
225     return;
226   }
227   const Dtype* top_diff = top[0]-&gt;cpu_diff();
228   Dtype* bottom_diff = bottom[0]-&gt;mutable_cpu_diff();
229   caffe_set(bottom[0]-&gt;count(), Dtype(0), bottom_diff);
230   const bool use_top_mask = top.size() &gt; 1;
231   const int* mask = NULL;    const Dtype* top_mask = NULL;
232   switch (this-&gt;layer_param_.pooling_param().pool()) {
233   case PoolingParameter_PoolMethod_MAX:
234     if (use_top_mask) {
235       top_mask = top[1]-&gt;cpu_data();
236     } else {
237       mask = max_idx_.cpu_data();
238     }
239     for (int n = 0; n &lt; top[0]-&gt;num(); ++n) {
240       for (int c = 0; c &lt; channels_; ++c) {
241         for (int ph = 0; ph &lt; pooled_height_; ++ph) {
242           for (int pw = 0; pw &lt; pooled_width_; ++pw) {
243             const int index = ph * pooled_width_ + pw;
244             const int bottom_index =
245                 use_top_mask ? top_mask[index] : mask[index];
246             bottom_diff[bottom_index] += top_diff[index];
247           }
248         }
249         bottom_diff += bottom[0]-&gt;offset(0, 1);
250         top_diff += top[0]-&gt;offset(0, 1);
251         if (use_top_mask) {
252           top_mask += top[0]-&gt;offset(0, 1);
253         } else {
254           mask += top[0]-&gt;offset(0, 1);
255         }
256       }
257     }
258     break;
259   case PoolingParameter_PoolMethod_AVE:
260     for (int n = 0; n &lt; top[0]-&gt;num(); ++n) {
261       for (int c = 0; c &lt; channels_; ++c) {
262         for (int ph = 0; ph &lt; pooled_height_; ++ph) {
263           for (int pw = 0; pw &lt; pooled_width_; ++pw) {
264             int hstart = ph * stride_h_ - pad_h_;
265             int wstart = pw * stride_w_ - pad_w_;
266             int hend = min(hstart + kernel_h_, height_ + pad_h_);
267             int wend = min(wstart + kernel_w_, width_ + pad_w_);
268             int pool_size = (hend - hstart) * (wend - wstart);
269             hstart = max(hstart, 0);
270             wstart = max(wstart, 0);
271             hend = min(hend, height_);
272             wend = min(wend, width_);
273             for (int h = hstart; h &lt; hend; ++h) {
274               for (int w = wstart; w &lt; wend; ++w) {
275                 bottom_diff[h * width_ + w] +=
276                   top_diff[ph * pooled_width_ + pw] / pool_size;
277               }
278             }
279           }
280         }
281         bottom_diff += bottom[0]-&gt;offset(0, 1);
282         top_diff += top[0]-&gt;offset(0, 1);
283       }
284     }
285     break;
286   case PoolingParameter_PoolMethod_STOCHASTIC:
287     NOT_IMPLEMENTED;
288     break;
289   default:
290     LOG(FATAL) &lt;&lt; "Unknown pooling method.";
291   }
292 }
293 #ifdef CPU_ONLY
294 STUB_GPU(PoolingLayer);
295 #endif
296 INSTANTIATE_CLASS(PoolingLayer);
}  </pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
