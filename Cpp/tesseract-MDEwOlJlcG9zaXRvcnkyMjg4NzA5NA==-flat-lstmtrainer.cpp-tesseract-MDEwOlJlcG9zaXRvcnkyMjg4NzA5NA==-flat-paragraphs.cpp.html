
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 11.524911927528938%, Tokens: 10</h2>
        <div class="column">
            <h3>tesseract-MDEwOlJlcG9zaXRvcnkyMjg4NzA5NA==-flat-lstmtrainer.cpp</h3>
            <pre><code>1  #define _USE_MATH_DEFINES 
2  #ifdef HAVE_CONFIG_H
3  #  include "config_auto.h"
4  #endif
5  #include <cmath>
6  #include <iomanip>             
7  #include <locale>              
8  #include <string>
9  #include "lstmtrainer.h"
10  #include <allheaders.h>
11  #include "boxread.h"
12  #include "ctc.h"
13  #include "imagedata.h"
14  #include "input.h"
15  #include "networkbuilder.h"
16  #include "ratngs.h"
17  #include "recodebeam.h"
18  #ifdef INCLUDE_TENSORFLOW
19  #  include "tfnetwork.h"
20  #endif
21  #include "tprintf.h"
22  namespace tesseract {
23  const double kMinDivergenceRate = 50.0;
24  const int kMinStallIterations = 10000;
25  const double kSubTrainerMarginFraction = 3.0 / 128;
26  const double kLearningRateDecay = M_SQRT1_2;
27  const int kNumAdjustmentIterations = 100;
28  const int kErrorGraphInterval = 1000;
29  const int kNumPagesPerBatch = 100;
30  const int kMinStartedErrorRate = 75;
31  const double kStageTransitionThreshold = 10.0;
32  const double kHighConfidence = 0.9375; 
33  const double kImprovementFraction = 15.0 / 16.0;
34  const double kBestCheckpointFraction = 31.0 / 32.0;
35  #ifndef GRAPHICS_DISABLED
36  const int kTargetXScale = 5;
37  const int kTargetYScale = 100;
38  #endif 
39  LSTMTrainer::LSTMTrainer()
40      : randomly_rotate_(false), training_data_(0), sub_trainer_(nullptr) {
41    EmptyConstructor();
42    debug_interval_ = 0;
43  }
44  LSTMTrainer::LSTMTrainer(const char *model_base, const char *checkpoint_name,
45                           int debug_interval, int64_t max_memory)
46      : randomly_rotate_(false),
47        training_data_(max_memory),
48        sub_trainer_(nullptr) {
49    EmptyConstructor();
50    debug_interval_ = debug_interval;
51    model_base_ = model_base;
52    checkpoint_name_ = checkpoint_name;
53  }
54  LSTMTrainer::~LSTMTrainer() {
55  #ifndef GRAPHICS_DISABLED
56    delete align_win_;
57    delete target_win_;
58    delete ctc_win_;
59    delete recon_win_;
60  #endif
61  }
62  bool LSTMTrainer::TryLoadingCheckpoint(const char *filename,
63                                         const char *old_traineddata) {
64    std::vector<char> data;
65    if (!LoadDataFromFile(filename, &data)) {
66      return false;
67    }
68    tprintf("Loaded file %s, unpacking...\n", filename);
69    if (!ReadTrainingDump(data, *this)) {
70      return false;
71    }
72    if (IsIntMode()) {
73      tprintf("Error, %s is an integer (fast) model, cannot continue training\n",
74              filename);
75      return false;
76    }
77    if (((old_traineddata == nullptr || *old_traineddata == '\0') &&
78         network_->NumOutputs() == recoder_.code_range()) ||
79        filename == old_traineddata) {
80      return true; 
81    }
82    tprintf("Code range changed from %d to %d!\n", network_->NumOutputs(),
83            recoder_.code_range());
84    if (old_traineddata == nullptr || *old_traineddata == '\0') {
85      tprintf("Must supply the old traineddata for code conversion!\n");
86      return false;
87    }
88    TessdataManager old_mgr;
89    ASSERT_HOST(old_mgr.Init(old_traineddata));
90    TFile fp;
91    if (!old_mgr.GetComponent(TESSDATA_LSTM_UNICHARSET, &fp)) {
92      return false;
93    }
94    UNICHARSET old_chset;
95    if (!old_chset.load_from_file(&fp, false)) {
96      return false;
97    }
98    if (!old_mgr.GetComponent(TESSDATA_LSTM_RECODER, &fp)) {
99      return false;
100    }
101    UnicharCompress old_recoder;
102    if (!old_recoder.DeSerialize(&fp)) {
103      return false;
104    }
105    std::vector<int> code_map = MapRecoder(old_chset, old_recoder);
106    int old_null_char = null_char_;
107    SetNullChar();
108    network_->RemapOutputs(old_recoder.code_range(), code_map);
109    tprintf("Previous null char=%d mapped to %d\n", old_null_char, null_char_);
110    return true;
111  }
112  bool LSTMTrainer::InitNetwork(const char *network_spec, int append_index,
113                                int net_flags, float weight_range,
114                                float learning_rate, float momentum,
115                                float adam_beta) {
116    mgr_.SetVersionString(mgr_.VersionString() + ":" + network_spec);
117    adam_beta_ = adam_beta;
118    learning_rate_ = learning_rate;
119    momentum_ = momentum;
120    SetNullChar();
121    if (!NetworkBuilder::InitNetwork(recoder_.code_range(), network_spec,
122                                     append_index, net_flags, weight_range,
123                                     &randomizer_, &network_)) {
124      return false;
125    }
126    network_str_ += network_spec;
127    tprintf("Built network:%s from request %s\n", network_->spec().c_str(),
128            network_spec);
129    tprintf(
130        "Training parameters:\n  Debug interval = %d,"
131        " weights = %g, learning rate = %g, momentum=%g\n",
132        debug_interval_, weight_range, learning_rate_, momentum_);
133    tprintf("null char=%d\n", null_char_);
134    return true;
135  }
136  #ifdef INCLUDE_TENSORFLOW
137  int LSTMTrainer::InitTensorFlowNetwork(const std::string &tf_proto) {
138    delete network_;
139    TFNetwork *tf_net = new TFNetwork("TensorFlow");
140    training_iteration_ = tf_net->InitFromProtoStr(tf_proto);
141    if (training_iteration_ == 0) {
142      tprintf("InitFromProtoStr failed!!\n");
143      return 0;
144    }
145    network_ = tf_net;
146    ASSERT_HOST(recoder_.code_range() == tf_net->num_classes());
147    return training_iteration_;
148  }
149  #endif
150  void LSTMTrainer::InitIterations() {
151    sample_iteration_ = 0;
152    training_iteration_ = 0;
153    learning_iteration_ = 0;
154    prev_sample_iteration_ = 0;
155    best_error_rate_ = 100.0;
156    best_iteration_ = 0;
157    worst_error_rate_ = 0.0;
158    worst_iteration_ = 0;
159    stall_iteration_ = kMinStallIterations;
160    best_error_history_.clear();
161    best_error_iterations_.clear();
162    improvement_steps_ = kMinStallIterations;
163    perfect_delay_ = 0;
164    last_perfect_training_iteration_ = 0;
165    for (int i = 0; i < ET_COUNT; ++i) {
166      best_error_rates_[i] = 100.0;
167      worst_error_rates_[i] = 0.0;
168      error_buffers_[i].clear();
169      error_buffers_[i].resize(kRollingBufferSize_);
170      error_rates_[i] = 100.0;
171    }
172    error_rate_of_last_saved_best_ = kMinStartedErrorRate;
173  }
174  Trainability LSTMTrainer::GridSearchDictParams(
175      const ImageData *trainingdata, int iteration, double min_dict_ratio,
176      double dict_ratio_step, double max_dict_ratio, double min_cert_offset,
177      double cert_offset_step, double max_cert_offset, std::string &results) {
178    sample_iteration_ = iteration;
179    NetworkIO fwd_outputs, targets;
180    Trainability result =
181        PrepareForBackward(trainingdata, &fwd_outputs, &targets);
182    if (result == UNENCODABLE || result == HI_PRECISION_ERR || dict_ == nullptr) {
183      return result;
184    }
185    std::vector<int> truth_labels, ocr_labels, xcoords;
186    ASSERT_HOST(EncodeString(trainingdata->transcription(), &truth_labels));
187    RecodeBeamSearch base_search(recoder_, null_char_, SimpleTextOutput(),
188                                 nullptr);
189    base_search.Decode(fwd_outputs, 1.0, 0.0, RecodeBeamSearch::kMinCertainty,
190                       nullptr);
191    base_search.ExtractBestPathAsLabels(&ocr_labels, &xcoords);
192    std::string truth_text = DecodeLabels(truth_labels);
193    std::string ocr_text = DecodeLabels(ocr_labels);
194    double baseline_error = ComputeWordError(&truth_text, &ocr_text);
195    results += "0,0=" + std::to_string(baseline_error);
196    RecodeBeamSearch search(recoder_, null_char_, SimpleTextOutput(), dict_);
197    for (double r = min_dict_ratio; r < max_dict_ratio; r += dict_ratio_step) {
198      for (double c = min_cert_offset; c < max_cert_offset;
199           c += cert_offset_step) {
200        search.Decode(fwd_outputs, r, c, RecodeBeamSearch::kMinCertainty,
201                      nullptr);
202        search.ExtractBestPathAsLabels(&ocr_labels, &xcoords);
203        truth_text = DecodeLabels(truth_labels);
204        ocr_text = DecodeLabels(ocr_labels);
205        double word_error = ComputeWordError(&truth_text, &ocr_text);
206        if ((r == min_dict_ratio && c == min_cert_offset) ||
207            !std::isfinite(word_error)) {
208          std::string t = DecodeLabels(truth_labels);
209          std::string o = DecodeLabels(ocr_labels);
210          tprintf("r=%g, c=%g, truth=%s, ocr=%s, wderr=%g, truth[0]=%d\n", r, c,
211                  t.c_str(), o.c_str(), word_error, truth_labels[0]);
212        }
213        results += " " + std::to_string(r);
214        results += "," + std::to_string(c);
215        results += "=" + std::to_string(word_error);
216      }
217    }
218    return result;
219  }
220  void LSTMTrainer::DebugNetwork() {
221    network_->DebugWeights();
222  }
223  bool LSTMTrainer::LoadAllTrainingData(const std::vector<std::string> &filenames,
224                                        CachingStrategy cache_strategy,
225                                        bool randomly_rotate) {
226    randomly_rotate_ = randomly_rotate;
227    training_data_.Clear();
228    return training_data_.LoadDocuments(filenames, cache_strategy,
229                                        LoadDataFromFile);
230  }
231  bool LSTMTrainer::MaintainCheckpoints(const TestCallback &tester,
232                                        std::stringstream &log_msg) {
233    PrepareLogMsg(log_msg);
234    double error_rate = CharError();
235    int iteration = learning_iteration();
236    if (iteration >= stall_iteration_ &&
237        error_rate > best_error_rate_ * (1.0 + kSubTrainerMarginFraction) &&
238        best_error_rate_ < kMinStartedErrorRate && !best_trainer_.empty()) {
239      StartSubtrainer(log_msg);
240    }
241    SubTrainerResult sub_trainer_result = STR_NONE;
242    if (sub_trainer_ != nullptr) {
243      sub_trainer_result = UpdateSubtrainer(log_msg);
244      if (sub_trainer_result == STR_REPLACED) {
245        error_rate = CharError();
246        iteration = learning_iteration();
247        PrepareLogMsg(log_msg);
248      }
249    }
250    bool result = true; 
251    std::vector<char> rec_model_data;
252    if (error_rate < best_error_rate_) {
253      SaveRecognitionDump(&rec_model_data);
254      log_msg << " New best BCER = " << error_rate;
255      log_msg << UpdateErrorGraph(iteration, error_rate, rec_model_data, tester);
256      sub_trainer_.reset();
257      stall_iteration_ = learning_iteration() + kMinStallIterations;
258      if (TransitionTrainingStage(kStageTransitionThreshold)) {
259        log_msg << " Transitioned to stage " << CurrentTrainingStage();
260      }
261      SaveTrainingDump(NO_BEST_TRAINER, *this, &best_trainer_);
262      if (error_rate < error_rate_of_last_saved_best_ * kBestCheckpointFraction) {
263        std::string best_model_name = DumpFilename();
264        if (!SaveDataToFile(best_trainer_, best_model_name.c_str())) {
265          log_msg << " failed to write best model:";
266        } else {
267          log_msg << " wrote best model:";
268          error_rate_of_last_saved_best_ = best_error_rate_;
269        }
270        log_msg << best_model_name;
271      }
272    } else if (error_rate > worst_error_rate_) {
273      SaveRecognitionDump(&rec_model_data);
274      log_msg << " New worst BCER = " << error_rate;
275      log_msg << UpdateErrorGraph(iteration, error_rate, rec_model_data, tester);
276      if (worst_error_rate_ > best_error_rate_ + kMinDivergenceRate &&
277          best_error_rate_ < kMinStartedErrorRate && !best_trainer_.empty()) {
278        log_msg << "\nDivergence! ";
279        std::vector<char> revert_data(best_trainer_);
280        if (ReadTrainingDump(revert_data, *this)) {
281          LogIterations("Reverted to", log_msg);
282          ReduceLearningRates(this, log_msg);
283        } else {
284          LogIterations("Failed to Revert at", log_msg);
285        }
286        stall_iteration_ = iteration + 2 * (iteration - learning_iteration());
287        SaveTrainingDump(NO_BEST_TRAINER, *this, &best_trainer_);
288      }
289    } else {
290      result = sub_trainer_result != STR_NONE;
291    }
292    if (checkpoint_name_.length() > 0) {
293      std::vector<char> checkpoint;
294      if (!SaveTrainingDump(FULL, *this, &checkpoint) ||
295          !SaveDataToFile(checkpoint, checkpoint_name_.c_str())) {
296        log_msg << " failed to write checkpoint.";
297      } else {
298        log_msg << " wrote checkpoint.";
299      }
300    }
301    return result;
302  }
303  void LSTMTrainer::PrepareLogMsg(std::stringstream &log_msg) const {
304    LogIterations("At", log_msg);
305    log_msg << std::fixed << std::setprecision(3)
306            << ", mean rms=" << error_rates_[ET_RMS]
307            << "%, delta=" << error_rates_[ET_DELTA]
308            << "%, BCER train=" << error_rates_[ET_CHAR_ERROR]
309            << "%, BWER train=" << error_rates_[ET_WORD_RECERR]
310            << "%, skip ratio=" << error_rates_[ET_SKIP_RATIO] << "%,";
311  }
312  void LSTMTrainer::LogIterations(const char *intro_str,
313                                  std::stringstream &log_msg) const {
314    log_msg << intro_str
315            << " iteration " << learning_iteration()
316            << "/" << training_iteration()
317            << "/" << sample_iteration();
318  }
319  bool LSTMTrainer::TransitionTrainingStage(float error_threshold) {
320    if (best_error_rate_ < error_threshold &&
321        training_stage_ + 1 < num_training_stages_) {
322      ++training_stage_;
323      return true;
324    }
325    return false;
326  }
327  bool LSTMTrainer::Serialize(SerializeAmount serialize_amount,
328                              const TessdataManager *mgr, TFile *fp) const {
329    if (!LSTMRecognizer::Serialize(mgr, fp)) {
330      return false;
331    }
332    if (!fp->Serialize(&learning_iteration_)) {
333      return false;
334    }
335    if (!fp->Serialize(&prev_sample_iteration_)) {
336      return false;
337    }
338    if (!fp->Serialize(&perfect_delay_)) {
339      return false;
340    }
341    if (!fp->Serialize(&last_perfect_training_iteration_)) {
342      return false;
343    }
344    for (const auto &error_buffer : error_buffers_) {
345      if (!fp->Serialize(error_buffer)) {
346        return false;
347      }
348    }
349    if (!fp->Serialize(&error_rates_[0], countof(error_rates_))) {
350      return false;
351    }
352    if (!fp->Serialize(&training_stage_)) {
353      return false;
354    }
355    uint8_t amount = serialize_amount;
356    if (!fp->Serialize(&amount)) {
357      return false;
358    }
359    if (serialize_amount == LIGHT) {
360      return true; 
361    }
362    if (!fp->Serialize(&best_error_rate_)) {
363      return false;
364    }
365    if (!fp->Serialize(&best_error_rates_[0], countof(best_error_rates_))) {
366      return false;
367    }
368    if (!fp->Serialize(&best_iteration_)) {
369      return false;
370    }
371    if (!fp->Serialize(&worst_error_rate_)) {
372      return false;
373    }
374    if (!fp->Serialize(&worst_error_rates_[0], countof(worst_error_rates_))) {
375      return false;
376    }
377    if (!fp->Serialize(&worst_iteration_)) {
378      return false;
379    }
380    if (!fp->Serialize(&stall_iteration_)) {
381      return false;
382    }
383    if (!fp->Serialize(best_model_data_)) {
384      return false;
385    }
386    if (!fp->Serialize(worst_model_data_)) {
387      return false;
388    }
389    if (serialize_amount != NO_BEST_TRAINER && !fp->Serialize(best_trainer_)) {
390      return false;
391    }
392    std::vector<char> sub_data;
393    if (sub_trainer_ != nullptr &&
394        !SaveTrainingDump(LIGHT, *sub_trainer_, &sub_data)) {
395      return false;
396    }
397    if (!fp->Serialize(sub_data)) {
398      return false;
399    }
400    if (!fp->Serialize(best_error_history_)) {
401      return false;
402    }
403    if (!fp->Serialize(best_error_iterations_)) {
404      return false;
405    }
406    return fp->Serialize(&improvement_steps_);
407  }
408  bool LSTMTrainer::DeSerialize(const TessdataManager *mgr, TFile *fp) {
409    if (!LSTMRecognizer::DeSerialize(mgr, fp)) {
410      return false;
411    }
412    if (!fp->DeSerialize(&learning_iteration_)) {
413      tprintf("Warning: LSTMTrainer deserialized an LSTMRecognizer!\n");
414      learning_iteration_ = 0;
415      network_->SetEnableTraining(TS_ENABLED);
416      return true;
417    }
418    if (!fp->DeSerialize(&prev_sample_iteration_)) {
419      return false;
420    }
421    if (!fp->DeSerialize(&perfect_delay_)) {
422      return false;
423    }
424    if (!fp->DeSerialize(&last_perfect_training_iteration_)) {
425      return false;
426    }
427    for (auto &error_buffer : error_buffers_) {
428      if (!fp->DeSerialize(error_buffer)) {
429        return false;
430      }
431    }
432    if (!fp->DeSerialize(&error_rates_[0], countof(error_rates_))) {
433      return false;
434    }
435    if (!fp->DeSerialize(&training_stage_)) {
436      return false;
437    }
438    uint8_t amount;
439    if (!fp->DeSerialize(&amount)) {
440      return false;
441    }
442    if (amount == LIGHT) {
443      return true; 
444    }
445    if (!fp->DeSerialize(&best_error_rate_)) {
446      return false;
447    }
448    if (!fp->DeSerialize(&best_error_rates_[0], countof(best_error_rates_))) {
449      return false;
450    }
451    if (!fp->DeSerialize(&best_iteration_)) {
452      return false;
453    }
454    if (!fp->DeSerialize(&worst_error_rate_)) {
455      return false;
456    }
457    if (!fp->DeSerialize(&worst_error_rates_[0], countof(worst_error_rates_))) {
458      return false;
459    }
460    if (!fp->DeSerialize(&worst_iteration_)) {
461      return false;
462    }
463    if (!fp->DeSerialize(&stall_iteration_)) {
464      return false;
465    }
466    if (!fp->DeSerialize(best_model_data_)) {
467      return false;
468    }
469    if (!fp->DeSerialize(worst_model_data_)) {
470      return false;
471    }
472    if (amount != NO_BEST_TRAINER && !fp->DeSerialize(best_trainer_)) {
473      return false;
474    }
475    std::vector<char> sub_data;
476    if (!fp->DeSerialize(sub_data)) {
477      return false;
478    }
479    if (sub_data.empty()) {
480      sub_trainer_ = nullptr;
481    } else {
482      sub_trainer_ = std::make_unique<LSTMTrainer>();
483      if (!ReadTrainingDump(sub_data, *sub_trainer_)) {
484        return false;
485      }
486    }
487    if (!fp->DeSerialize(best_error_history_)) {
488      return false;
489    }
490    if (!fp->DeSerialize(best_error_iterations_)) {
491      return false;
492    }
493    return fp->DeSerialize(&improvement_steps_);
494  }
495  void LSTMTrainer::StartSubtrainer(std::stringstream &log_msg) {
496    sub_trainer_ = std::make_unique<LSTMTrainer>();
497    if (!ReadTrainingDump(best_trainer_, *sub_trainer_)) {
498      log_msg << " Failed to revert to previous best for trial!";
499      sub_trainer_.reset();
500    } else {
501      log_msg << " Trial sub_trainer_ from iteration "
502              << sub_trainer_->training_iteration();
503      sub_trainer_->ReduceLearningRates(this, log_msg);
504      int stall_offset =
505          learning_iteration() - sub_trainer_->learning_iteration();
506      stall_iteration_ = learning_iteration() + 2 * stall_offset;
507      sub_trainer_->stall_iteration_ = stall_iteration_;
508      SaveTrainingDump(NO_BEST_TRAINER, *sub_trainer_, &best_trainer_);
509    }
510  }
511  SubTrainerResult LSTMTrainer::UpdateSubtrainer(std::stringstream &log_msg) {
512    double training_error = CharError();
513    double sub_error = sub_trainer_->CharError();
514    double sub_margin = (training_error - sub_error) / sub_error;
515    if (sub_margin >= kSubTrainerMarginFraction) {
516      log_msg << " sub_trainer=" << sub_error
517              << " margin=" << 100.0 * sub_margin << "\n";
518      int end_iteration = training_iteration();
519      while (sub_trainer_->training_iteration() < end_iteration &&
520             sub_margin >= kSubTrainerMarginFraction) {
521        int target_iteration =
522            sub_trainer_->training_iteration() + kNumPagesPerBatch;
523        while (sub_trainer_->training_iteration() < target_iteration) {
524          sub_trainer_->TrainOnLine(this, false);
525        }
526        std::stringstream batch_log("Sub:");
527        batch_log.imbue(std::locale::classic());
528        sub_trainer_->PrepareLogMsg(batch_log);
529        batch_log << "\n";
530        tprintf("UpdateSubtrainer:%s", batch_log.str().c_str());
531        log_msg << batch_log.str();
532        sub_error = sub_trainer_->CharError();
533        sub_margin = (training_error - sub_error) / sub_error;
534      }
535      if (sub_error < best_error_rate_ &&
536          sub_margin >= kSubTrainerMarginFraction) {
537        std::vector<char> updated_trainer;
538        SaveTrainingDump(LIGHT, *sub_trainer_, &updated_trainer);
539        ReadTrainingDump(updated_trainer, *this);
540        log_msg << " Sub trainer wins at iteration "
541                << training_iteration() << "\n";
542        return STR_REPLACED;
543      }
544      return STR_UPDATED;
545    }
546    return STR_NONE;
547  }
548  void LSTMTrainer::ReduceLearningRates(LSTMTrainer *samples_trainer,
549                                        std::stringstream &log_msg) {
550    if (network_->TestFlag(NF_LAYER_SPECIFIC_LR)) {
551      int num_reduced = ReduceLayerLearningRates(
552          kLearningRateDecay, kNumAdjustmentIterations, samples_trainer);
553      log_msg << "\nReduced learning rate on layers: " << num_reduced;
554    } else {
555      ScaleLearningRate(kLearningRateDecay);
556      log_msg << "\nReduced learning rate to :" << learning_rate_;
557    }
558    log_msg << "\n";
559  }
560  int LSTMTrainer::ReduceLayerLearningRates(TFloat factor, int num_samples,
561                                            LSTMTrainer *samples_trainer) {
562    enum WhichWay {
563      LR_DOWN, 
564      LR_SAME, 
565      LR_COUNT 
566    };
567    std::vector<std::string> layers = EnumerateLayers();
568    int num_layers = layers.size();
569    std::vector<int> num_weights(num_layers);
570    std::vector<TFloat> bad_sums[LR_COUNT];
571    std::vector<TFloat> ok_sums[LR_COUNT];
572    for (int i = 0; i < LR_COUNT; ++i) {
573      bad_sums[i].resize(num_layers, 0.0);
574      ok_sums[i].resize(num_layers, 0.0);
575    }
576    auto momentum_factor = 1 / (1 - momentum_);
577    std::vector<char> orig_trainer;
578    samples_trainer->SaveTrainingDump(LIGHT, *this, &orig_trainer);
579    for (int i = 0; i < num_layers; ++i) {
580      Network *layer = GetLayer(layers[i]);
581      num_weights[i] = layer->IsTraining() ? layer->num_weights() : 0;
582    }
583    int iteration = sample_iteration();
584    for (int s = 0; s < num_samples; ++s) {
585      for (int ww = 0; ww < LR_COUNT; ++ww) {
586        auto ww_factor = momentum_factor;
587        if (ww == LR_DOWN) {
588          ww_factor *= factor;
589        }
590        LSTMTrainer copy_trainer;
591        samples_trainer->ReadTrainingDump(orig_trainer, copy_trainer);
592        copy_trainer.network_->Update(0.0, 0.0, 0.0, 0);
593        for (int i = 0; i < num_layers; ++i) {
594          if (num_weights[i] == 0) {
595            continue;
596          }
597          copy_trainer.ScaleLayerLearningRate(layers[i], ww_factor);
598        }
599        copy_trainer.SetIteration(iteration);
600        const ImageData *trainingdata =
601            copy_trainer.TrainOnLine(samples_trainer, true);
602        if (trainingdata == nullptr) {
603          continue;
604        }
605        std::vector<char> updated_trainer;
606        samples_trainer->SaveTrainingDump(LIGHT, copy_trainer, &updated_trainer);
607        for (int i = 0; i < num_layers; ++i) {
608          if (num_weights[i] == 0) {
609            continue;
610          }
611          LSTMTrainer layer_trainer;
612          samples_trainer->ReadTrainingDump(updated_trainer, layer_trainer);
613          Network *layer = layer_trainer.GetLayer(layers[i]);
614          layer->Update(0.0, momentum_, adam_beta_,
615                        layer_trainer.training_iteration_ + 1);
616          layer->Update(0.0, 0.0, 0.0, 0);
617          layer_trainer.TrainOnLine(trainingdata, true);
618          float before_bad = bad_sums[ww][i];
619          float before_ok = ok_sums[ww][i];
620          layer->CountAlternators(*copy_trainer.GetLayer(layers[i]),
621                                  &ok_sums[ww][i], &bad_sums[ww][i]);
622          float bad_frac =
623              bad_sums[ww][i] + ok_sums[ww][i] - before_bad - before_ok;
624          if (bad_frac > 0.0f) {
625            bad_frac = (bad_sums[ww][i] - before_bad) / bad_frac;
626          }
627        }
628      }
629      ++iteration;
630    }
631    int num_lowered = 0;
632    for (int i = 0; i < num_layers; ++i) {
633      if (num_weights[i] == 0) {
634        continue;
635      }
636      Network *layer = GetLayer(layers[i]);
637      float lr = GetLayerLearningRate(layers[i]);
638      TFloat total_down = bad_sums[LR_DOWN][i] + ok_sums[LR_DOWN][i];
639      TFloat total_same = bad_sums[LR_SAME][i] + ok_sums[LR_SAME][i];
640      TFloat frac_down = bad_sums[LR_DOWN][i] / total_down;
641      TFloat frac_same = bad_sums[LR_SAME][i] / total_same;
642      tprintf("Layer %d=%s: lr %g->%g%%, lr %g->%g%%", i, layer->name().c_str(),
643              lr * factor, 100.0 * frac_down, lr, 100.0 * frac_same);
644      if (frac_down < frac_same * kImprovementFraction) {
645        tprintf(" REDUCED\n");
646        ScaleLayerLearningRate(layers[i], factor);
647        ++num_lowered;
648      } else {
649        tprintf(" SAME\n");
650      }
651    }
652    if (num_lowered == 0) {
653      for (int i = 0; i < num_layers; ++i) {
654        if (num_weights[i] > 0) {
655          ScaleLayerLearningRate(layers[i], factor);
656          ++num_lowered;
657        }
658      }
659    }
660    return num_lowered;
661  }
662  bool LSTMTrainer::EncodeString(const std::string &str,
663                                 const UNICHARSET &unicharset,
664                                 const UnicharCompress *recoder, bool simple_text,
665                                 int null_char, std::vector<int> *labels) {
666    if (str.c_str() == nullptr || str.length() <= 0) {
667      tprintf("Empty truth string!\n");
668      return false;
669    }
670    unsigned err_index;
671    std::vector<int> internal_labels;
672    labels->clear();
673    if (!simple_text) {
674      labels->push_back(null_char);
675    }
676    std::string cleaned = unicharset.CleanupString(str.c_str());
677    if (unicharset.encode_string(cleaned.c_str(), true, &internal_labels, nullptr,
678                                 &err_index)) {
679      bool success = true;
680      for (auto internal_label : internal_labels) {
681        if (recoder != nullptr) {
682          RecodedCharID code;
683          int len = recoder->EncodeUnichar(internal_label, &code);
684          if (len > 0) {
685            for (int j = 0; j < len; ++j) {
686              labels->push_back(code(j));
687              if (!simple_text) {
688                labels->push_back(null_char);
689              }
690            }
691          } else {
692            success = false;
693            err_index = 0;
694            break;
695          }
696        } else {
697          labels->push_back(internal_label);
698          if (!simple_text) {
699            labels->push_back(null_char);
700          }
701        }
702      }
703      if (success) {
704        return true;
705      }
706    }
707    tprintf("Encoding of string failed! Failure bytes:");
708    while (err_index < cleaned.size()) {
709      tprintf(" %x", cleaned[err_index++] & 0xff);
710    }
711    tprintf("\n");
712    return false;
713  }
714  Trainability LSTMTrainer::TrainOnLine(const ImageData *trainingdata,
715                                        bool batch) {
716    NetworkIO fwd_outputs, targets;
717    Trainability trainable =
718        PrepareForBackward(trainingdata, &fwd_outputs, &targets);
719    ++sample_iteration_;
720    if (trainable == UNENCODABLE || trainable == NOT_BOXED) {
721      return trainable; 
722    }
723    bool debug =
724        debug_interval_ > 0 && training_iteration() % debug_interval_ == 0;
725    NetworkIO bp_deltas;
726    if (network_->IsTraining() &&
727        (trainable != PERFECT ||
728         training_iteration() >
729             last_perfect_training_iteration_ + perfect_delay_)) {
730      network_->Backward(debug, targets, &scratch_space_, &bp_deltas);
731      network_->Update(learning_rate_, batch ? -1.0f : momentum_, adam_beta_,
732                       training_iteration_ + 1);
733    }
734  #ifndef GRAPHICS_DISABLED
735    if (debug_interval_ == 1 && debug_win_ != nullptr) {
736      debug_win_->AwaitEvent(SVET_CLICK);
737    }
738  #endif 
739    RollErrorBuffers();
740    return trainable;
741  }
742  Trainability LSTMTrainer::PrepareForBackward(const ImageData *trainingdata,
743                                               NetworkIO *fwd_outputs,
744                                               NetworkIO *targets) {
745    if (trainingdata == nullptr) {
746      tprintf("Null trainingdata.\n");
747      return UNENCODABLE;
748    }
749    bool debug =
750        debug_interval_ > 0 && training_iteration() % debug_interval_ == 0;
751    std::vector<int> truth_labels;
752    if (!EncodeString(trainingdata->transcription(), &truth_labels)) {
753      tprintf("Can't encode transcription: '%s' in language '%s'\n",
754              trainingdata->transcription().c_str(),
755              trainingdata->language().c_str());
756      return UNENCODABLE;
757    }
758    bool upside_down = false;
759    if (randomly_rotate_) {
760      SetRandomSeed();
761      upside_down = randomizer_.SignedRand(1.0) > 0.0;
762      if (upside_down) {
763        for (auto truth_label : truth_labels) {
764          if (truth_label != UNICHAR_SPACE && truth_label != null_char_) {
765            ++truth_label;
766          }
767        }
768        std::reverse(truth_labels.begin(), truth_labels.end());
769      }
770    }
771    unsigned w = 0;
772    while (w < truth_labels.size() &&
773           (truth_labels[w] == UNICHAR_SPACE || truth_labels[w] == null_char_)) {
774      ++w;
775    }
776    if (w == truth_labels.size()) {
777      tprintf("Blank transcription: %s\n", trainingdata->transcription().c_str());
778      return UNENCODABLE;
779    }
780    float image_scale;
781    NetworkIO inputs;
782    bool invert = trainingdata->boxes().empty();
783    if (!RecognizeLine(*trainingdata, invert ? 0.5f : 0.0f, debug, invert, upside_down,
784                       &image_scale, &inputs, fwd_outputs)) {
785      tprintf("Image %s not trainable\n", trainingdata->imagefilename().c_str());
786      return UNENCODABLE;
787    }
788    targets->Resize(*fwd_outputs, network_->NumOutputs());
789    LossType loss_type = OutputLossType();
790    if (loss_type == LT_SOFTMAX) {
791      if (!ComputeTextTargets(*fwd_outputs, truth_labels, targets)) {
792        tprintf("Compute simple targets failed for %s!\n",
793                trainingdata->imagefilename().c_str());
794        return UNENCODABLE;
795      }
796    } else if (loss_type == LT_CTC) {
797      if (!ComputeCTCTargets(truth_labels, fwd_outputs, targets)) {
798        tprintf("Compute CTC targets failed for %s!\n",
799                trainingdata->imagefilename().c_str());
800        return UNENCODABLE;
801      }
802    } else {
803      tprintf("Logistic outputs not implemented yet!\n");
804      return UNENCODABLE;
805    }
806    std::vector<int> ocr_labels;
807    std::vector<int> xcoords;
808    LabelsFromOutputs(*fwd_outputs, &ocr_labels, &xcoords);
809    if (loss_type != LT_CTC) {
810      LabelsFromOutputs(*targets, &truth_labels, &xcoords);
811    }
812    if (!DebugLSTMTraining(inputs, *trainingdata, *fwd_outputs, truth_labels,
813                           *targets)) {
814      tprintf("Input width was %d\n", inputs.Width());
815      return UNENCODABLE;
816    }
817    std::string ocr_text = DecodeLabels(ocr_labels);
818    std::string truth_text = DecodeLabels(truth_labels);
819    targets->SubtractAllFromFloat(*fwd_outputs);
820    if (debug_interval_ != 0) {
821      if (truth_text != ocr_text) {
822        tprintf("Iteration %d: BEST OCR TEXT : %s\n", training_iteration(),
823                ocr_text.c_str());
<span onclick='openModal()' class='match'>824      }
825    }
826    double char_error = ComputeCharError(truth_labels, ocr_labels);
827    double word_error = ComputeWordError(&truth_text, &ocr_text);
828    double delta_error = ComputeErrorRates(*targets, char_error, word_error);
829    if (debug_interval_ != 0) {
</span>830      tprintf("File %s line %d %s:\n", trainingdata->imagefilename().c_str(),
831              trainingdata->page_number(), delta_error == 0.0 ? "(Perfect)" : "");
832    }
833    if (delta_error == 0.0) {
834      return PERFECT;
835    }
836    if (targets->AnySuspiciousTruth(kHighConfidence)) {
837      return HI_PRECISION_ERR;
838    }
839    return TRAINABLE;
840  }
841  bool LSTMTrainer::SaveTrainingDump(SerializeAmount serialize_amount,
842                                     const LSTMTrainer &trainer,
843                                     std::vector<char> *data) const {
844    TFile fp;
845    fp.OpenWrite(data);
846    return trainer.Serialize(serialize_amount, &mgr_, &fp);
847  }
848  bool LSTMTrainer::ReadLocalTrainingDump(const TessdataManager *mgr,
849                                          const char *data, int size) {
850    if (size == 0) {
851      tprintf("Warning: data size is 0 in LSTMTrainer::ReadLocalTrainingDump\n");
852      return false;
853    }
854    TFile fp;
855    fp.Open(data, size);
856    return DeSerialize(mgr, &fp);
857  }
858  bool LSTMTrainer::SaveTraineddata(const char *filename) {
859    std::vector<char> recognizer_data;
860    SaveRecognitionDump(&recognizer_data);
861    mgr_.OverwriteEntry(TESSDATA_LSTM, &recognizer_data[0],
862                        recognizer_data.size());
863    return mgr_.SaveFile(filename, SaveDataToFile);
864  }
865  void LSTMTrainer::SaveRecognitionDump(std::vector<char> *data) const {
866    TFile fp;
867    fp.OpenWrite(data);
868    network_->SetEnableTraining(TS_TEMP_DISABLE);
869    ASSERT_HOST(LSTMRecognizer::Serialize(&mgr_, &fp));
870    network_->SetEnableTraining(TS_RE_ENABLE);
871  }
872  std::string LSTMTrainer::DumpFilename() const {
873    std::stringstream filename;
874    filename.imbue(std::locale::classic());
875    filename << model_base_ << std::fixed << std::setprecision(3)
876             << "_" << best_error_rate_
877             << "_" << best_iteration_
878             << "_" << training_iteration_
879             << ".checkpoint";
880    return filename.str();
881  }
882  void LSTMTrainer::FillErrorBuffer(double new_error, ErrorTypes type) {
883    for (int i = 0; i < kRollingBufferSize_; ++i) {
884      error_buffers_[type][i] = new_error;
885    }
886    error_rates_[type] = 100.0 * new_error;
887  }
888  std::vector<int> LSTMTrainer::MapRecoder(
889      const UNICHARSET &old_chset, const UnicharCompress &old_recoder) const {
890    int num_new_codes = recoder_.code_range();
891    int num_new_unichars = GetUnicharset().size();
892    std::vector<int> code_map(num_new_codes, -1);
893    for (int c = 0; c < num_new_codes; ++c) {
894      int old_code = -1;
895      for (int uid = 0; uid <= num_new_unichars; ++uid) {
896        RecodedCharID codes;
897        int length = recoder_.EncodeUnichar(uid, &codes);
898        int code_index = 0;
899        while (code_index < length && codes(code_index) != c) {
900          ++code_index;
901        }
902        if (code_index == length) {
903          continue;
904        }
905        int old_uid =
906            uid < num_new_unichars
907                ? old_chset.unichar_to_id(GetUnicharset().id_to_unichar(uid))
908                : old_chset.size() - 1;
909        if (old_uid == INVALID_UNICHAR_ID) {
910          continue;
911        }
912        RecodedCharID old_codes;
913        if (code_index < old_recoder.EncodeUnichar(old_uid, &old_codes)) {
914          old_code = old_codes(code_index);
915          break;
916        }
917      }
918      code_map[c] = old_code;
919    }
920    return code_map;
921  }
922  void LSTMTrainer::InitCharSet() {
923    EmptyConstructor();
924    training_flags_ = TF_COMPRESS_UNICHARSET;
925    if (!LoadCharsets(&mgr_)) {
926      ASSERT_HOST(
927          "Must provide a traineddata containing lstm_unicharset and"
928          " lstm_recoder!\n" != nullptr);
929    }
930    SetNullChar();
931  }
932  void LSTMTrainer::SetNullChar() {
933    null_char_ = GetUnicharset().has_special_codes() ? UNICHAR_BROKEN
934                                                     : GetUnicharset().size();
935    RecodedCharID code;
936    recoder_.EncodeUnichar(null_char_, &code);
937    null_char_ = code(0);
938  }
939  void LSTMTrainer::EmptyConstructor() {
940  #ifndef GRAPHICS_DISABLED
941    align_win_ = nullptr;
942    target_win_ = nullptr;
943    ctc_win_ = nullptr;
944    recon_win_ = nullptr;
945  #endif
946    checkpoint_iteration_ = 0;
947    training_stage_ = 0;
948    num_training_stages_ = 2;
949    InitIterations();
950  }
951  bool LSTMTrainer::DebugLSTMTraining(const NetworkIO &inputs,
952                                      const ImageData &trainingdata,
953                                      const NetworkIO &fwd_outputs,
954                                      const std::vector<int> &truth_labels,
955                                      const NetworkIO &outputs) {
956    const std::string &truth_text = DecodeLabels(truth_labels);
957    if (truth_text.c_str() == nullptr || truth_text.length() <= 0) {
958      tprintf("Empty truth string at decode time!\n");
959      return false;
960    }
961    if (debug_interval_ != 0) {
962      std::vector<int> labels;
963      std::vector<int> xcoords;
964      LabelsFromOutputs(outputs, &labels, &xcoords);
965      std::string text = DecodeLabels(labels);
966      tprintf("Iteration %d: GROUND  TRUTH : %s\n", training_iteration(),
967              truth_text.c_str());
968      if (truth_text != text) {
969        tprintf("Iteration %d: ALIGNED TRUTH : %s\n", training_iteration(),
970                text.c_str());
971      }
972      if (debug_interval_ > 0 && training_iteration() % debug_interval_ == 0) {
973        tprintf("TRAINING activation path for truth string %s\n",
974                truth_text.c_str());
975        DebugActivationPath(outputs, labels, xcoords);
976  #ifndef GRAPHICS_DISABLED
977        DisplayForward(inputs, labels, xcoords, "LSTMTraining", &align_win_);
978        if (OutputLossType() == LT_CTC) {
979          DisplayTargets(fwd_outputs, "CTC Outputs", &ctc_win_);
980          DisplayTargets(outputs, "CTC Targets", &target_win_);
981        }
982  #endif
983      }
984    }
985    return true;
986  }
987  #ifndef GRAPHICS_DISABLED
988  void LSTMTrainer::DisplayTargets(const NetworkIO &targets,
989                                   const char *window_name, ScrollView **window) {
990    int width = targets.Width();
991    int num_features = targets.NumFeatures();
992    Network::ClearWindow(true, window_name, width * kTargetXScale, kTargetYScale,
993                         window);
994    for (int c = 0; c < num_features; ++c) {
995      int color = c % (ScrollView::GREEN_YELLOW - 1) + 2;
996      (*window)->Pen(static_cast<ScrollView::Color>(color));
997      int start_t = -1;
998      for (int t = 0; t < width; ++t) {
999        double target = targets.f(t)[c];
1000        target *= kTargetYScale;
1001        if (target >= 1) {
1002          if (start_t < 0) {
1003            (*window)->SetCursor(t - 1, 0);
1004            start_t = t;
1005          }
1006          (*window)->DrawTo(t, target);
1007        } else if (start_t >= 0) {
1008          (*window)->DrawTo(t, 0);
1009          (*window)->DrawTo(start_t - 1, 0);
1010          start_t = -1;
1011        }
1012      }
1013      if (start_t >= 0) {
1014        (*window)->DrawTo(width, 0);
1015        (*window)->DrawTo(start_t - 1, 0);
1016      }
1017    }
1018    (*window)->Update();
1019  }
1020  #endif 
1021  bool LSTMTrainer::ComputeTextTargets(const NetworkIO &outputs,
1022                                       const std::vector<int> &truth_labels,
1023                                       NetworkIO *targets) {
1024    if (truth_labels.size() > targets->Width()) {
1025      tprintf("Error: transcription %s too long to fit into target of width %d\n",
1026              DecodeLabels(truth_labels).c_str(), targets->Width());
1027      return false;
1028    }
1029    int i = 0;
1030    for (auto truth_label : truth_labels) {
1031      targets->SetActivations(i, truth_label, 1.0);
1032      ++i;
1033    }
1034    for (i = truth_labels.size(); i < targets->Width(); ++i) {
1035      targets->SetActivations(i, null_char_, 1.0);
1036    }
1037    return true;
1038  }
1039  bool LSTMTrainer::ComputeCTCTargets(const std::vector<int> &truth_labels,
1040                                      NetworkIO *outputs, NetworkIO *targets) {
1041    CTC::NormalizeProbs(outputs);
1042    return CTC::ComputeCTCTargets(truth_labels, null_char_,
1043                                  outputs->float_array(), targets);
1044  }
1045  double LSTMTrainer::ComputeErrorRates(const NetworkIO &deltas,
1046                                        double char_error, double word_error) {
1047    UpdateErrorBuffer(ComputeRMSError(deltas), ET_RMS);
1048    double delta_error = ComputeWinnerError(deltas);
1049    UpdateErrorBuffer(delta_error, ET_DELTA);
1050    UpdateErrorBuffer(word_error, ET_WORD_RECERR);
1051    UpdateErrorBuffer(char_error, ET_CHAR_ERROR);
1052    double skip_count = sample_iteration_ - prev_sample_iteration_;
1053    UpdateErrorBuffer(skip_count, ET_SKIP_RATIO);
1054    return delta_error;
1055  }
1056  double LSTMTrainer::ComputeRMSError(const NetworkIO &deltas) {
1057    double total_error = 0.0;
1058    int width = deltas.Width();
1059    int num_classes = deltas.NumFeatures();
1060    for (int t = 0; t < width; ++t) {
1061      const float *class_errs = deltas.f(t);
1062      for (int c = 0; c < num_classes; ++c) {
1063        double error = class_errs[c];
1064        total_error += error * error;
1065      }
1066    }
1067    return sqrt(total_error / (width * num_classes));
1068  }
1069  double LSTMTrainer::ComputeWinnerError(const NetworkIO &deltas) {
1070    int num_errors = 0;
1071    int width = deltas.Width();
1072    int num_classes = deltas.NumFeatures();
1073    for (int t = 0; t < width; ++t) {
1074      const float *class_errs = deltas.f(t);
1075      for (int c = 0; c < num_classes; ++c) {
1076        float abs_delta = std::fabs(class_errs[c]);
1077        if (0.5 <= abs_delta) {
1078          ++num_errors;
1079        }
1080      }
1081    }
1082    return static_cast<double>(num_errors) / width;
1083  }
1084  double LSTMTrainer::ComputeCharError(const std::vector<int> &truth_str,
1085                                       const std::vector<int> &ocr_str) {
1086    std::vector<int> label_counts(NumOutputs());
1087    unsigned truth_size = 0;
1088    for (auto ch : truth_str) {
1089      if (ch != null_char_) {
1090        ++label_counts[ch];
1091        ++truth_size;
1092      }
1093    }
1094    for (auto ch : ocr_str) {
1095      if (ch != null_char_) {
1096        --label_counts[ch];
1097      }
1098    }
1099    unsigned char_errors = 0;
1100    for (auto label_count : label_counts) {
1101      char_errors += abs(label_count);
1102    }
1103    if (truth_size <= char_errors) {
1104      return (char_errors == 0) ? 0.0 : 1.0;
1105    }
1106    return static_cast<double>(char_errors) / truth_size;
1107  }
1108  double LSTMTrainer::ComputeWordError(std::string *truth_str,
1109                                       std::string *ocr_str) {
1110    using StrMap = std::unordered_map<std::string, int, std::hash<std::string>>;
1111    std::vector<std::string> truth_words = split(*truth_str, ' ');
1112    if (truth_words.empty()) {
1113      return 0.0;
1114    }
1115    std::vector<std::string> ocr_words = split(*ocr_str, ' ');
1116    StrMap word_counts;
1117    for (const auto &truth_word : truth_words) {
1118      std::string truth_word_string(truth_word.c_str());
1119      auto it = word_counts.find(truth_word_string);
1120      if (it == word_counts.end()) {
1121        word_counts.insert(std::make_pair(truth_word_string, 1));
1122      } else {
1123        ++it->second;
1124      }
1125    }
1126    for (const auto &ocr_word : ocr_words) {
1127      std::string ocr_word_string(ocr_word.c_str());
1128      auto it = word_counts.find(ocr_word_string);
1129      if (it == word_counts.end()) {
1130        word_counts.insert(std::make_pair(ocr_word_string, -1));
1131      } else {
1132        --it->second;
1133      }
1134    }
1135    int word_recall_errs = 0;
1136    for (const auto &word_count : word_counts) {
1137      if (word_count.second > 0) {
1138        word_recall_errs += word_count.second;
1139      }
1140    }
1141    return static_cast<double>(word_recall_errs) / truth_words.size();
1142  }
1143  void LSTMTrainer::UpdateErrorBuffer(double new_error, ErrorTypes type) {
1144    int index = training_iteration_ % kRollingBufferSize_;
1145    error_buffers_[type][index] = new_error;
1146    int mean_count =
1147        std::min<int>(training_iteration_ + 1, error_buffers_[type].size());
1148    double buffer_sum = 0.0;
1149    for (int i = 0; i < mean_count; ++i) {
1150      buffer_sum += error_buffers_[type][i];
1151    }
1152    double mean = buffer_sum / mean_count;
1153    error_rates_[type] = IntCastRounded(100000.0 * mean) / 1000.0;
1154  }
1155  void LSTMTrainer::RollErrorBuffers() {
1156    prev_sample_iteration_ = sample_iteration_;
1157    if (NewSingleError(ET_DELTA) > 0.0) {
1158      ++learning_iteration_;
1159    } else {
1160      last_perfect_training_iteration_ = training_iteration_;
1161    }
1162    ++training_iteration_;
1163    if (debug_interval_ != 0) {
1164      tprintf("Mean rms=%g%%, delta=%g%%, train=%g%%(%g%%), skip ratio=%g%%\n",
1165              error_rates_[ET_RMS], error_rates_[ET_DELTA],
1166              error_rates_[ET_CHAR_ERROR], error_rates_[ET_WORD_RECERR],
1167              error_rates_[ET_SKIP_RATIO]);
1168    }
1169  }
1170  std::string LSTMTrainer::UpdateErrorGraph(int iteration, double error_rate,
1171                                            const std::vector<char> &model_data,
1172                                            const TestCallback &tester) {
1173    if (error_rate > best_error_rate_ &&
1174        iteration < best_iteration_ + kErrorGraphInterval) {
1175      if (tester != nullptr && !worst_model_data_.empty()) {
1176        mgr_.OverwriteEntry(TESSDATA_LSTM, &worst_model_data_[0],
1177                            worst_model_data_.size());
1178        return tester(worst_iteration_, nullptr, mgr_, CurrentTrainingStage());
1179      } else {
1180        return "";
1181      }
1182    }
1183    std::string result;
1184    if (error_rate < best_error_rate_) {
1185      if (tester != nullptr && !worst_model_data_.empty()) {
1186        mgr_.OverwriteEntry(TESSDATA_LSTM, &worst_model_data_[0],
1187                            worst_model_data_.size());
1188        result = tester(worst_iteration_, worst_error_rates_, mgr_,
1189                        CurrentTrainingStage());
1190        worst_model_data_.clear();
1191        best_model_data_ = model_data;
1192      }
1193      best_error_rate_ = error_rate;
1194      memcpy(best_error_rates_, error_rates_, sizeof(error_rates_));
1195      best_iteration_ = iteration;
1196      best_error_history_.push_back(error_rate);
1197      best_error_iterations_.push_back(iteration);
1198      double two_percent_more = error_rate + 2.0;
1199      int i;
1200      for (i = best_error_history_.size() - 1;
1201           i >= 0 && best_error_history_[i] < two_percent_more; --i) {
1202      }
1203      int old_iteration = i >= 0 ? best_error_iterations_[i] : 0;
1204      improvement_steps_ = iteration - old_iteration;
1205      tprintf("2 Percent improvement time=%d, best error was %g @ %d\n",
1206              improvement_steps_, i >= 0 ? best_error_history_[i] : 100.0,
1207              old_iteration);
1208    } else if (error_rate > best_error_rate_) {
1209      if (tester != nullptr) {
1210        if (!best_model_data_.empty()) {
1211          mgr_.OverwriteEntry(TESSDATA_LSTM, &best_model_data_[0],
1212                              best_model_data_.size());
1213          result = tester(best_iteration_, best_error_rates_, mgr_,
1214                          CurrentTrainingStage());
1215        } else if (!worst_model_data_.empty()) {
1216          mgr_.OverwriteEntry(TESSDATA_LSTM, &worst_model_data_[0],
1217                              worst_model_data_.size());
1218          result = tester(worst_iteration_, worst_error_rates_, mgr_,
1219                          CurrentTrainingStage());
1220        }
1221        if (result.length() > 0) {
1222          best_model_data_.clear();
1223        }
1224        worst_model_data_ = model_data;
1225      }
1226    }
1227    worst_error_rate_ = error_rate;
1228    memcpy(worst_error_rates_, error_rates_, sizeof(error_rates_));
1229    worst_iteration_ = iteration;
1230    return result;
1231  }
1232  } 
</code></pre>
        </div>
        <div class="column">
            <h3>tesseract-MDEwOlJlcG9zaXRvcnkyMjg4NzA5NA==-flat-paragraphs.cpp</h3>
            <pre><code>1  #include "paragraphs.h"
2  #include "helpers.h"             
3  #include "host.h"                
4  #include "mutableiterator.h"     
5  #include "ocrblock.h"            
6  #include "ocrpara.h"             
7  #include "ocrrow.h"              
8  #include "pageres.h"             
9  #include "paragraphs_internal.h" 
10  #include "pdblock.h"             
11  #include "polyblk.h"             
12  #include "ratngs.h"              
13  #include "rect.h"                
14  #include "statistc.h"            
15  #include "tprintf.h"             
16  #include "unicharset.h"          
17  #include "werd.h"                
18  #include <tesseract/pageiterator.h> 
19  #include <tesseract/publictypes.h>  
20  #include <tesseract/unichar.h>      
21  #include <algorithm> 
22  #include <cctype>    
23  #include <cmath>     
24  #include <cstdio>    
25  #include <cstdlib>   
26  #include <cstring>   
27  #include <memory>    
28  static const char *const kRLE = "\u202A"; 
29  static const char *const kPDF = "\u202C"; 
30  namespace tesseract {
31  const ParagraphModel *kCrownLeft =
32      reinterpret_cast<ParagraphModel *>(static_cast<uintptr_t>(0xDEAD111F));
33  const ParagraphModel *kCrownRight =
34      reinterpret_cast<ParagraphModel *>(static_cast<uintptr_t>(0xDEAD888F));
35  static bool LikelyParagraphStart(const RowScratchRegisters &before,
36                                   const RowScratchRegisters &after,
37                                   tesseract::ParagraphJustification j);
38  static int Epsilon(int space_pix) {
39    return space_pix * 4 / 5;
40  }
41  static bool AcceptableRowArgs(int debug_level, int min_num_rows, const char *function_name,
42                                const std::vector<RowScratchRegisters> *rows, int row_start,
43                                int row_end) {
44    if (row_start < 0 || static_cast<size_t>(row_end) > rows->size() || row_start > row_end) {
45      tprintf("Invalid arguments rows[%d, %d) while rows is of size %zu.\n", row_start, row_end,
46              rows->size());
47      return false;
48    }
49    if (row_end - row_start < min_num_rows) {
50      if (debug_level > 1) {
51        tprintf("# Too few rows[%d, %d) for %s.\n", row_start, row_end, function_name);
52      }
53      return false;
54    }
55    return true;
56  }
57  static void PrintTable(const std::vector<std::vector<std::string>> &rows, const char *colsep) {
58    std::vector<int> max_col_widths;
59    for (const auto &row : rows) {
60      auto num_columns = row.size();
61      for (size_t c = 0; c < num_columns; c++) {
62        int num_unicodes = 0;
63        for (char i : row[c]) {
64          if ((i & 0xC0) != 0x80) {
65            num_unicodes++;
66          }
67        }
68        if (c >= max_col_widths.size()) {
69          max_col_widths.push_back(num_unicodes);
70        } else {
71          if (num_unicodes > max_col_widths[c]) {
72            max_col_widths[c] = num_unicodes;
73          }
74        }
75      }
76    }
77    std::vector<std::string> col_width_patterns;
78    col_width_patterns.reserve(max_col_widths.size());
79    for (int max_col_width : max_col_widths) {
80      col_width_patterns.push_back(std::string("%-") + std::to_string(max_col_width) + "s");
81    }
82    for (const auto &row : rows) {
83      for (unsigned c = 0; c < row.size(); c++) {
84        if (c > 0) {
85          tprintf("%s", colsep);
86        }
87        tprintf(col_width_patterns[c].c_str(), row[c].c_str());
88      }
89      tprintf("\n");
90    }
91  }
92  static std::string RtlEmbed(const std::string &word, bool rtlify) {
93    if (rtlify) {
94      return std::string(kRLE) + word + std::string(kPDF);
95    }
96    return word;
97  }
98  static void PrintDetectorState(const ParagraphTheory &theory,
99                                 const std::vector<RowScratchRegisters> &rows) {
100    std::vector<std::vector<std::string>> output;
101    output.emplace_back();
102    output.back().push_back("#row");
103    output.back().push_back("space");
104    output.back().push_back("..");
105    output.back().push_back("lword[widthSEL]");
106    output.back().push_back("rword[widthSEL]");
107    RowScratchRegisters::AppendDebugHeaderFields(output.back());
108    output.back().push_back("text");
109    for (unsigned i = 0; i < rows.size(); i++) {
110      output.emplace_back();
111      std::vector<std::string> &row = output.back();
112      const RowInfo &ri = *rows[i].ri_;
113      row.push_back(std::to_string(i));
114      row.push_back(std::to_string(ri.average_interword_space));
115      row.emplace_back(ri.has_leaders ? ".." : " ");
116      row.push_back(RtlEmbed(ri.lword_text, !ri.ltr) + "[" + std::to_string(ri.lword_box.width()) +
117                    (ri.lword_likely_starts_idea ? "S" : "s") +
118                    (ri.lword_likely_ends_idea ? "E" : "e") +
119                    (ri.lword_indicates_list_item ? "L" : "l") + "]");
120      row.push_back(RtlEmbed(ri.rword_text, !ri.ltr) + "[" + std::to_string(ri.rword_box.width()) +
121                    (ri.rword_likely_starts_idea ? "S" : "s") +
122                    (ri.rword_likely_ends_idea ? "E" : "e") +
123                    (ri.rword_indicates_list_item ? "L" : "l") + "]");
124      rows[i].AppendDebugInfo(theory, row);
125      row.push_back(RtlEmbed(ri.text, !ri.ltr));
126    }
127    PrintTable(output, " ");
128    tprintf("Active Paragraph Models:\n");
129    unsigned m = 0;
130    for (const auto &model : theory.models()) {
131      tprintf(" %d: %s\n", ++m, model->ToString().c_str());
132    }
133  }
134  static void DebugDump(bool should_print, const char *phase, const ParagraphTheory &theory,
135                        const std::vector<RowScratchRegisters> &rows) {
136    if (!should_print) {
137      return;
138    }
139    tprintf("# %s\n", phase);
140    PrintDetectorState(theory, rows);
141  }
142  static void PrintRowRange(const std::vector<RowScratchRegisters> &rows, int row_start,
143                            int row_end) {
144    tprintf("======================================\n");
145    for (int row = row_start; row < row_end; row++) {
146      tprintf("%s\n", rows[row].ri_->text.c_str());
147    }
148    tprintf("======================================\n");
149  }
150  static bool IsLatinLetter(int ch) {
151    return (ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z');
152  }
153  static bool IsDigitLike(int ch) {
154    return ch == 'o' || ch == 'O' || ch == 'l' || ch == 'I';
155  }
156  static bool IsOpeningPunct(int ch) {
157    return strchr("'\"({[", ch) != nullptr;
158  }
159  static bool IsTerminalPunct(int ch) {
160    return strchr(":'\".?!]})", ch) != nullptr;
161  }
162  static const char *SkipChars(const char *str, const char *toskip) {
163    while (*str != '\0' && strchr(toskip, *str)) {
164      str++;
165    }
166    return str;
167  }
168  static const char *SkipChars(const char *str, bool (*skip)(int)) {
169    while (*str != '\0' && skip(*str)) {
170      str++;
171    }
172    return str;
173  }
174  static const char *SkipOne(const char *str, const char *toskip) {
175    if (*str != '\0' && strchr(toskip, *str)) {
176      return str + 1;
177    }
178    return str;
179  }
180  static bool LikelyListNumeral(const std::string &word) {
181    const char *kRomans = "ivxlmdIVXLMD";
182    const char *kDigits = "012345789";
183    const char *kOpen = "[{(";
184    const char *kSep = ":;-.,";
185    const char *kClose = "]})";
186    int num_segments = 0;
187    const char *pos = word.c_str();
188    while (*pos != '\0' && num_segments < 3) {
189      const char *numeral_start = SkipOne(SkipOne(pos, kOpen), kOpen);
190      const char *numeral_end = SkipChars(numeral_start, kRomans);
191      if (numeral_end != numeral_start) {
192      } else {
193        numeral_end = SkipChars(numeral_start, kDigits);
194        if (numeral_end == numeral_start) {
195          numeral_end = SkipChars(numeral_start, IsLatinLetter);
196          if (numeral_end - numeral_start != 1) {
197            break;
198          }
199        }
200      }
201      num_segments++;
202      pos = SkipChars(SkipChars(numeral_end, kClose), kSep);
203      if (pos == numeral_end) {
204        break;
205      }
206    }
207    return *pos == '\0';
208  }
209  static bool LikelyListMark(const std::string &word) {
210    const char *kListMarks = "0Oo*.,+.";
211    return word.size() == 1 && strchr(kListMarks, word[0]) != nullptr;
212  }
213  bool AsciiLikelyListItem(const std::string &word) {
214    return LikelyListMark(word) || LikelyListNumeral(word);
215  }
216  static int UnicodeFor(const UNICHARSET *u, const WERD_CHOICE *werd, unsigned pos) {
217    if (!u || !werd || pos > werd->length()) {
218      return 0;
219    }
220    return UNICHAR(u->id_to_unichar(werd->unichar_id(pos)), -1).first_uni();
221  }
222  class UnicodeSpanSkipper {
223  public:
224    UnicodeSpanSkipper(const UNICHARSET *unicharset, const WERD_CHOICE *word)
225        : u_(unicharset), word_(word), wordlen_(word->length()) {
226    }
227    unsigned SkipPunc(unsigned pos);
228    unsigned SkipDigits(unsigned pos);
229    unsigned SkipRomans(unsigned pos);
230    unsigned SkipAlpha(unsigned pos);
231  private:
232    const UNICHARSET *u_;
233    const WERD_CHOICE *word_;
234    unsigned wordlen_;
235  };
236  unsigned UnicodeSpanSkipper::SkipPunc(unsigned pos) {
237    while (pos < wordlen_ && u_->get_ispunctuation(word_->unichar_id(pos))) {
238      pos++;
239    }
240    return pos;
241  }
242  unsigned UnicodeSpanSkipper::SkipDigits(unsigned pos) {
243    while (pos < wordlen_ &&
244           (u_->get_isdigit(word_->unichar_id(pos)) || IsDigitLike(UnicodeFor(u_, word_, pos)))) {
245      pos++;
246    }
247    return pos;
248  }
249  unsigned UnicodeSpanSkipper::SkipRomans(unsigned pos) {
250    const char *kRomans = "ivxlmdIVXLMD";
251    while (pos < wordlen_) {
252      int ch = UnicodeFor(u_, word_, pos);
253      if (ch >= 0xF0 || strchr(kRomans, ch) == nullptr) {
254        break;
255      }
256      pos++;
257    }
258    return pos;
259  }
260  unsigned UnicodeSpanSkipper::SkipAlpha(unsigned pos) {
261    while (pos < wordlen_ && u_->get_isalpha(word_->unichar_id(pos))) {
262      pos++;
263    }
264    return pos;
265  }
266  static bool LikelyListMarkUnicode(int ch) {
267    if (ch < 0x80) {
268      std::string single_ch;
269      single_ch += ch;
270      return LikelyListMark(single_ch);
271    }
272    switch (ch) {
273      case 0x00B0: 
274      case 0x2022: 
275      case 0x25E6: 
276      case 0x00B7: 
277      case 0x25A1: 
278      case 0x25A0: 
279      case 0x25AA: 
280      case 0x2B1D: 
281      case 0x25BA: 
282      case 0x25CF: 
283      case 0x25CB: 
284        return true;
285      default:
286        break; 
287    }
288    return false;
289  }
290  static bool UniLikelyListItem(const UNICHARSET *u, const WERD_CHOICE *werd) {
291    if (werd->length() == 1 && LikelyListMarkUnicode(UnicodeFor(u, werd, 0))) {
292      return true;
293    }
294    UnicodeSpanSkipper m(u, werd);
295    int num_segments = 0;
296    unsigned pos = 0;
297    while (pos < werd->length() && num_segments < 3) {
298      auto numeral_start = m.SkipPunc(pos);
299      if (numeral_start > pos + 1) {
300        break;
301      }
302      auto numeral_end = m.SkipRomans(numeral_start);
303      if (numeral_end == numeral_start) {
304        numeral_end = m.SkipDigits(numeral_start);
305        if (numeral_end == numeral_start) {
306          numeral_end = m.SkipAlpha(numeral_start);
307          if (numeral_end - numeral_start != 1) {
308            break;
309          }
310        }
311      }
312      num_segments++;
313      pos = m.SkipPunc(numeral_end);
314      if (pos == numeral_end) {
315        break;
316      }
317    }
318    return pos == werd->length();
319  }
320  template<class T>
321  void push_back_new(std::vector<T> &vector, const T &data) {
322    if (std::find(vector.begin(), vector.end(), data) == vector.end()) {
323      vector.push_back(data);
324    }
325  }
326  void LeftWordAttributes(const UNICHARSET *unicharset, const WERD_CHOICE *werd, const std::string &utf8,
327                          bool *is_list, bool *starts_idea, bool *ends_idea) {
328    *is_list = false;
329    *starts_idea = false;
330    *ends_idea = false;
331    if (utf8.empty() || (werd != nullptr && werd->empty())) { 
332      *ends_idea = true;
333      return;
334    }
335    if (unicharset && werd) { 
336      if (UniLikelyListItem(unicharset, werd)) {
337        *is_list = true;
338        *starts_idea = true;
339        *ends_idea = true;
340      }
341      if (unicharset->get_isupper(werd->unichar_id(0))) {
342        *starts_idea = true;
343      }
344      if (unicharset->get_ispunctuation(werd->unichar_id(0))) {
345        *starts_idea = true;
346        *ends_idea = true;
347      }
348    } else { 
349      if (AsciiLikelyListItem(utf8)) {
350        *is_list = true;
351        *starts_idea = true;
352      }
353      int start_letter = utf8[0];
354      if (IsOpeningPunct(start_letter)) {
355        *starts_idea = true;
356      }
357      if (IsTerminalPunct(start_letter)) {
358        *ends_idea = true;
359      }
360      if (start_letter >= 'A' && start_letter <= 'Z') {
361        *starts_idea = true;
362      }
363    }
364  }
365  void RightWordAttributes(const UNICHARSET *unicharset, const WERD_CHOICE *werd, const std::string &utf8,
366                           bool *is_list, bool *starts_idea, bool *ends_idea) {
367    *is_list = false;
368    *starts_idea = false;
369    *ends_idea = false;
370    if (utf8.empty() || (werd != nullptr && werd->empty())) { 
371      *ends_idea = true;
372      return;
373    }
374    if (unicharset && werd) { 
375      if (UniLikelyListItem(unicharset, werd)) {
376        *is_list = true;
377        *starts_idea = true;
378      }
379      UNICHAR_ID last_letter = werd->unichar_id(werd->length() - 1);
380      if (unicharset->get_ispunctuation(last_letter)) {
381        *ends_idea = true;
382      }
383    } else { 
384      if (AsciiLikelyListItem(utf8)) {
385        *is_list = true;
386        *starts_idea = true;
387      }
388      int last_letter = utf8[utf8.size() - 1];
389      if (IsOpeningPunct(last_letter) || IsTerminalPunct(last_letter)) {
390        *ends_idea = true;
391      }
392    }
393  }
394  void RowScratchRegisters::AppendDebugHeaderFields(std::vector<std::string> &header) {
395    header.emplace_back("[lmarg,lind;rind,rmarg]");
396    header.emplace_back("model");
397  }
398  void RowScratchRegisters::AppendDebugInfo(const ParagraphTheory &theory,
399                                            std::vector<std::string> &dbg) const {
400    char s[60];
401    snprintf(s, sizeof(s), "[%4d,%5d;%5d,%4d]", lmargin_, lindent_, rindent_, rmargin_);
402    dbg.emplace_back(s);
403    std::string model_string;
404    model_string += static_cast<char>(GetLineType());
405    model_string += ":";
406    int model_numbers = 0;
407    for (const auto &hypothese : hypotheses_) {
408      if (hypothese.model == nullptr) {
409        continue;
410      }
411      if (model_numbers > 0) {
412        model_string += ",";
413      }
414      if (StrongModel(hypothese.model)) {
415        model_string += std::to_string(1 + theory.IndexOf(hypothese.model));
416      } else if (hypothese.model == kCrownLeft) {
417        model_string += "CrL";
418      } else if (hypothese.model == kCrownRight) {
419        model_string += "CrR";
420      }
421      model_numbers++;
422    }
423    if (model_numbers == 0) {
424      model_string += "0";
425    }
426    dbg.push_back(model_string);
427  }
428  void RowScratchRegisters::Init(const RowInfo &row) {
429    ri_ = &row;
430    lmargin_ = 0;
431    lindent_ = row.pix_ldistance;
432    rmargin_ = 0;
433    rindent_ = row.pix_rdistance;
434  }
435  LineType RowScratchRegisters::GetLineType() const {
436    if (hypotheses_.empty()) {
437      return LT_UNKNOWN;
438    }
439    bool has_start = false;
440    bool has_body = false;
441    for (const auto &hypothese : hypotheses_) {
442      switch (hypothese.ty) {
443        case LT_START:
444          has_start = true;
445          break;
446        case LT_BODY:
447          has_body = true;
448          break;
449        default:
450          tprintf("Encountered bad value in hypothesis list: %c\n", hypothese.ty);
451          break;
452      }
453    }
454    if (has_start && has_body) {
455      return LT_MULTIPLE;
456    }
457    return has_start ? LT_START : LT_BODY;
458  }
459  LineType RowScratchRegisters::GetLineType(const ParagraphModel *model) const {
460    if (hypotheses_.empty()) {
461      return LT_UNKNOWN;
462    }
463    bool has_start = false;
464    bool has_body = false;
465    for (const auto &hypothese : hypotheses_) {
466      if (hypothese.model != model) {
467        continue;
468      }
469      switch (hypothese.ty) {
470        case LT_START:
471          has_start = true;
472          break;
473        case LT_BODY:
474          has_body = true;
475          break;
476        default:
477          tprintf("Encountered bad value in hypothesis list: %c\n", hypothese.ty);
478          break;
479      }
480    }
481    if (has_start && has_body) {
482      return LT_MULTIPLE;
483    }
484    return has_start ? LT_START : LT_BODY;
485  }
486  void RowScratchRegisters::SetStartLine() {
487    LineType current_lt = GetLineType();
488    if (current_lt != LT_UNKNOWN && current_lt != LT_START) {
489      tprintf("Trying to set a line to be START when it's already BODY.\n");
490    }
491    if (current_lt == LT_UNKNOWN || current_lt == LT_BODY) {
492      push_back_new(hypotheses_, LineHypothesis(LT_START, nullptr));
493    }
494  }
495  void RowScratchRegisters::SetBodyLine() {
496    LineType current_lt = GetLineType();
497    if (current_lt != LT_UNKNOWN && current_lt != LT_BODY) {
498      tprintf("Trying to set a line to be BODY when it's already START.\n");
499    }
500    if (current_lt == LT_UNKNOWN || current_lt == LT_START) {
501      push_back_new(hypotheses_, LineHypothesis(LT_BODY, nullptr));
502    }
503  }
504  void RowScratchRegisters::AddStartLine(const ParagraphModel *model) {
505    push_back_new(hypotheses_, LineHypothesis(LT_START, model));
506    auto found = std::find(hypotheses_.begin(), hypotheses_.end(), LineHypothesis(LT_START, nullptr));
507    if (found != hypotheses_.end()) {
508      hypotheses_.erase(found);
509    }
510  }
511  void RowScratchRegisters::AddBodyLine(const ParagraphModel *model) {
512    push_back_new(hypotheses_, LineHypothesis(LT_BODY, model));
513    auto found = std::find(hypotheses_.begin(), hypotheses_.end(), LineHypothesis(LT_BODY, nullptr));
514    if (found != hypotheses_.end()) {
515      hypotheses_.erase(found);
516    }
517  }
518  void RowScratchRegisters::StartHypotheses(SetOfModels *models) const {
519    for (const auto &hypothese : hypotheses_) {
520      if (hypothese.ty == LT_START && StrongModel(hypothese.model)) {
521        push_back_new(*models, hypothese.model);
522      }
523    }
524  }
525  void RowScratchRegisters::StrongHypotheses(SetOfModels *models) const {
526    for (const auto &hypothese : hypotheses_) {
527      if (StrongModel(hypothese.model)) {
528        push_back_new(*models, hypothese.model);
529      }
530    }
531  }
532  void RowScratchRegisters::NonNullHypotheses(SetOfModels *models) const {
533    for (const auto &hypothese : hypotheses_) {
534      if (hypothese.model != nullptr) {
535        push_back_new(*models, hypothese.model);
536      }
537    }
538  }
539  const ParagraphModel *RowScratchRegisters::UniqueStartHypothesis() const {
540    if (hypotheses_.size() != 1 || hypotheses_[0].ty != LT_START) {
541      return nullptr;
542    }
543    return hypotheses_[0].model;
544  }
545  const ParagraphModel *RowScratchRegisters::UniqueBodyHypothesis() const {
546    if (hypotheses_.size() != 1 || hypotheses_[0].ty != LT_BODY) {
547      return nullptr;
548    }
549    return hypotheses_[0].model;
550  }
551  void RowScratchRegisters::DiscardNonMatchingHypotheses(const SetOfModels &models) {
552    if (models.empty()) {
553      return;
554    }
555    for (int h = hypotheses_.size() - 1; h >= 0; h--) {
556      if (!contains(models, hypotheses_[h].model)) {
557        hypotheses_.erase(hypotheses_.begin() + h);
558      }
559    }
560  }
561  struct Cluster {
562    Cluster() : center(0), count(0) {}
563    Cluster(int cen, int num) : center(cen), count(num) {}
564    int center; 
565    int count;  
566  };
567  class SimpleClusterer {
568  public:
569    explicit SimpleClusterer(int max_cluster_width) : max_cluster_width_(max_cluster_width) {}
570    void Add(int value) {
571      values_.push_back(value);
572    }
573    size_t size() const {
574      return values_.size();
575    }
576    void GetClusters(std::vector<Cluster> *clusters);
577  private:
578    int max_cluster_width_;
579    std::vector<int> values_;
580  };
581  static int ClosestCluster(const std::vector<Cluster> &clusters, int value) {
582    unsigned best_index = 0;
583    for (unsigned i = 0; i < clusters.size(); i++) {
584      if (abs(value - clusters[i].center) < abs(value - clusters[best_index].center)) {
585        best_index = i;
586      }
587    }
588    return best_index;
589  }
590  void SimpleClusterer::GetClusters(std::vector<Cluster> *clusters) {
591    clusters->clear();
592    std::sort(values_.begin(), values_.end());
593    for (unsigned i = 0; i < values_.size();) {
594      int orig_i = i;
595      int lo = values_[i];
596      int hi = lo;
597      while (++i < values_.size() && values_[i] <= lo + max_cluster_width_) {
598        hi = values_[i];
599      }
600      clusters->push_back(Cluster((hi + lo) / 2, i - orig_i));
601    }
602  }
603  static void CalculateTabStops(std::vector<RowScratchRegisters> *rows, int row_start, int row_end,
604                                int tolerance, std::vector<Cluster> *left_tabs,
605                                std::vector<Cluster> *right_tabs) {
606    if (!AcceptableRowArgs(0, 1, __func__, rows, row_start, row_end)) {
607      return;
608    }
609    SimpleClusterer initial_lefts(tolerance);
610    SimpleClusterer initial_rights(tolerance);
611    std::vector<Cluster> initial_left_tabs;
612    std::vector<Cluster> initial_right_tabs;
613    for (int i = row_start; i < row_end; i++) {
614      initial_lefts.Add((*rows)[i].lindent_);
615      initial_rights.Add((*rows)[i].rindent_);
616    }
617    initial_lefts.GetClusters(&initial_left_tabs);
618    initial_rights.GetClusters(&initial_right_tabs);
619    SimpleClusterer lefts(tolerance);
620    SimpleClusterer rights(tolerance);
621    int infrequent_enough_to_ignore = 0;
622    if (row_end - row_start >= 8) {
623      infrequent_enough_to_ignore = 1;
624    }
625    if (row_end - row_start >= 20) {
626      infrequent_enough_to_ignore = 2;
627    }
628    for (int i = row_start; i < row_end; i++) {
629      int lidx = ClosestCluster(initial_left_tabs, (*rows)[i].lindent_);
630      int ridx = ClosestCluster(initial_right_tabs, (*rows)[i].rindent_);
631      if (initial_left_tabs[lidx].count > infrequent_enough_to_ignore ||
632          initial_right_tabs[ridx].count > infrequent_enough_to_ignore) {
633        lefts.Add((*rows)[i].lindent_);
634        rights.Add((*rows)[i].rindent_);
635      }
636    }
637    lefts.GetClusters(left_tabs);
638    rights.GetClusters(right_tabs);
639    if ((left_tabs->size() == 1 && right_tabs->size() >= 4) ||
640        (right_tabs->size() == 1 && left_tabs->size() >= 4)) {
641      for (int i = row_start; i < row_end; i++) {
642        int lidx = ClosestCluster(initial_left_tabs, (*rows)[i].lindent_);
643        int ridx = ClosestCluster(initial_right_tabs, (*rows)[i].rindent_);
644        if (!(initial_left_tabs[lidx].count > infrequent_enough_to_ignore ||
645              initial_right_tabs[ridx].count > infrequent_enough_to_ignore)) {
646          lefts.Add((*rows)[i].lindent_);
647          rights.Add((*rows)[i].rindent_);
648        }
649      }
650    }
651    lefts.GetClusters(left_tabs);
652    rights.GetClusters(right_tabs);
653    if (left_tabs->size() == 3 && right_tabs->size() >= 4) {
654      int to_prune = -1;
655      for (int i = left_tabs->size() - 1; i >= 0; i--) {
656        if (to_prune < 0 || (*left_tabs)[i].count < (*left_tabs)[to_prune].count) {
657          to_prune = i;
658        }
659      }
660      if (to_prune >= 0 && (*left_tabs)[to_prune].count <= infrequent_enough_to_ignore) {
661        left_tabs->erase(left_tabs->begin() + to_prune);
662      }
663    }
664    if (right_tabs->size() == 3 && left_tabs->size() >= 4) {
665      int to_prune = -1;
666      for (int i = right_tabs->size() - 1; i >= 0; i--) {
667        if (to_prune < 0 || (*right_tabs)[i].count < (*right_tabs)[to_prune].count) {
668          to_prune = i;
669        }
670      }
671      if (to_prune >= 0 && (*right_tabs)[to_prune].count <= infrequent_enough_to_ignore) {
672        right_tabs->erase(right_tabs->begin() + to_prune);
673      }
674    }
675  }
676  static void MarkRowsWithModel(std::vector<RowScratchRegisters> *rows, int row_start, int row_end,
677                                const ParagraphModel *model, bool ltr, int eop_threshold) {
678    if (!AcceptableRowArgs(0, 0, __func__, rows, row_start, row_end)) {
679      return;
680    }
681    for (int row = row_start; row < row_end; row++) {
682      bool valid_first = ValidFirstLine(rows, row, model);
683      bool valid_body = ValidBodyLine(rows, row, model);
684      if (valid_first && !valid_body) {
685        (*rows)[row].AddStartLine(model);
686      } else if (valid_body && !valid_first) {
687        (*rows)[row].AddBodyLine(model);
688      } else if (valid_body && valid_first) {
689        bool after_eop = (row == row_start);
690        if (row > row_start) {
691          if (eop_threshold > 0) {
692            if (model->justification() == JUSTIFICATION_LEFT) {
693              after_eop = (*rows)[row - 1].rindent_ > eop_threshold;
694            } else {
695              after_eop = (*rows)[row - 1].lindent_ > eop_threshold;
696            }
697          } else {
698            after_eop = FirstWordWouldHaveFit((*rows)[row - 1], (*rows)[row], model->justification());
699          }
700        }
701        if (after_eop) {
702          (*rows)[row].AddStartLine(model);
703        } else {
704          (*rows)[row].AddBodyLine(model);
705        }
706      } else {
707      }
708    }
709  }
710  struct GeometricClassifierState {
711    GeometricClassifierState(int dbg_level, std::vector<RowScratchRegisters> *r, int r_start,
712                             int r_end)
713        : debug_level(dbg_level), rows(r), row_start(r_start), row_end(r_end) {
714      tolerance = InterwordSpace(*r, r_start, r_end);
715      CalculateTabStops(r, r_start, r_end, tolerance, &left_tabs, &right_tabs);
716      if (debug_level >= 3) {
717        tprintf(
718            "Geometry: TabStop cluster tolerance = %d; "
719            "%zu left tabs; %zu right tabs\n",
720            tolerance, left_tabs.size(), right_tabs.size());
721      }
722      ltr = (*r)[r_start].ri_->ltr;
723    }
724    void AssumeLeftJustification() {
725      just = tesseract::JUSTIFICATION_LEFT;
726      margin = (*rows)[row_start].lmargin_;
727    }
728    void AssumeRightJustification() {
729      just = tesseract::JUSTIFICATION_RIGHT;
730      margin = (*rows)[row_start].rmargin_;
731    }
732    const std::vector<Cluster> &AlignTabs() const {
733      if (just == tesseract::JUSTIFICATION_RIGHT) {
734        return right_tabs;
735      }
736      return left_tabs;
737    }
738    const std::vector<Cluster> &OffsideTabs() const {
739      if (just == tesseract::JUSTIFICATION_RIGHT) {
740        return left_tabs;
741      }
742      return right_tabs;
743    }
744    bool IsFullRow(int i) const {
745      return ClosestCluster(left_tabs, (*rows)[i].lindent_) == 0 &&
746             ClosestCluster(right_tabs, (*rows)[i].rindent_) == 0;
747    }
748    int AlignsideTabIndex(int row_idx) const {
749      return ClosestCluster(AlignTabs(), (*rows)[row_idx].AlignsideIndent(just));
750    }
751    bool FirstWordWouldHaveFit(int row_a, int row_b) {
752      return ::tesseract::FirstWordWouldHaveFit((*rows)[row_a], (*rows)[row_b], just);
753    }
754    void PrintRows() const {
755      PrintRowRange(*rows, row_start, row_end);
756    }
757    void Fail(int min_debug_level, const char *why) const {
758      if (debug_level < min_debug_level) {
759        return;
760      }
761      tprintf("# %s\n", why);
762      PrintRows();
763    }
764    ParagraphModel Model() const {
765      return ParagraphModel(just, margin, first_indent, body_indent, tolerance);
766    }
767    int debug_level = 0;
768    std::vector<RowScratchRegisters> *rows;
769    int row_start = 0;
770    int row_end = 0;
771    int tolerance = 0;
772    bool ltr = false;
773    std::vector<Cluster> left_tabs;
774    std::vector<Cluster> right_tabs;
775    tesseract::ParagraphJustification just = JUSTIFICATION_UNKNOWN;
776    int margin = 0;
777    int first_indent = 0;
778    int body_indent = 0;
779    int eop_threshold = 0;
780  };
781  static void GeometricClassifyThreeTabStopTextBlock(int debug_level, GeometricClassifierState &s,
782                                                     ParagraphTheory *theory) {
783    int num_rows = s.row_end - s.row_start;
784    int num_full_rows = 0;
785    int last_row_full = 0;
786    for (int i = s.row_start; i < s.row_end; i++) {
787      if (s.IsFullRow(i)) {
788        num_full_rows++;
789        if (i == s.row_end - 1) {
790          last_row_full++;
791        }
792      }
793    }
794    if (num_full_rows < 0.7 * num_rows) {
795      s.Fail(1, "Not enough full lines to know which lines start paras.");
796      return;
797    }
798    s.eop_threshold = 0;
799    if (s.ltr) {
800      s.AssumeLeftJustification();
801    } else {
802      s.AssumeRightJustification();
803    }
804    if (debug_level > 0) {
805      tprintf(
806          "# Not enough variety for clear outline classification. "
807          "Guessing these are %s aligned based on script.\n",
808          s.ltr ? "left" : "right");
809      s.PrintRows();
810    }
811    if (s.AlignTabs().size() == 2) { 
812      s.first_indent = s.AlignTabs()[1].center;
813      s.body_indent = s.AlignTabs()[0].center;
814    } else { 
815      if (num_rows - 1 == num_full_rows - last_row_full) {
816        const ParagraphModel *model = s.ltr ? kCrownLeft : kCrownRight;
817        (*s.rows)[s.row_start].AddStartLine(model);
818        for (int i = s.row_start + 1; i < s.row_end; i++) {
819          (*s.rows)[i].AddBodyLine(model);
820        }
821        return;
822      } else {
823        s.first_indent = s.body_indent = s.AlignTabs()[0].center;
824        s.eop_threshold = (s.OffsideTabs()[0].center + s.OffsideTabs()[1].center) / 2;
825      }
826    }
827    const ParagraphModel *model = theory->AddModel(s.Model());
828    MarkRowsWithModel(s.rows, s.row_start, s.row_end, model, s.ltr, s.eop_threshold);
829    return;
830  }
831  static void GeometricClassify(int debug_level, std::vector<RowScratchRegisters> *rows,
832                                int row_start, int row_end, ParagraphTheory *theory) {
833    if (!AcceptableRowArgs(debug_level, 4, __func__, rows, row_start, row_end)) {
834      return;
835    }
836    if (debug_level > 1) {
837      tprintf("###############################################\n");
838      tprintf("##### GeometricClassify( rows[%d:%d) )   ####\n", row_start, row_end);
839      tprintf("###############################################\n");
840    }
841    RecomputeMarginsAndClearHypotheses(rows, row_start, row_end, 10);
842    GeometricClassifierState s(debug_level, rows, row_start, row_end);
843    if (s.left_tabs.size() > 2 && s.right_tabs.size() > 2) {
844      s.Fail(2, "Too much variety for simple outline classification.");
845      return;
846    }
847    if (s.left_tabs.size() <= 1 && s.right_tabs.size() <= 1) {
848      s.Fail(1, "Not enough variety for simple outline classification.");
849      return;
850    }
851    if (s.left_tabs.size() + s.right_tabs.size() == 3) {
852      GeometricClassifyThreeTabStopTextBlock(debug_level, s, theory);
853      return;
854    }
855    if (s.right_tabs.size() > 2) {
856      s.AssumeLeftJustification();
857    } else if (s.left_tabs.size() > 2) {
858      s.AssumeRightJustification();
859    } else if (s.ltr) { 
860      s.AssumeLeftJustification();
861    } else {
862      s.AssumeRightJustification();
863    }
864    if (s.AlignTabs().size() == 2) {
865      int firsts[2] = {0, 0};
866      firsts[s.AlignsideTabIndex(s.row_start)]++;
867      bool jam_packed = true;
868      for (int i = s.row_start + 1; i < s.row_end; i++) {
869        if (s.FirstWordWouldHaveFit(i - 1, i)) {
870          firsts[s.AlignsideTabIndex(i)]++;
871          jam_packed = false;
872        }
873      }
874      if (jam_packed && s.FirstWordWouldHaveFit(s.row_end - 1, s.row_end - 1)) {
875        firsts[1 - s.AlignsideTabIndex(s.row_end - 1)]++;
876      }
877      int percent0firsts, percent1firsts;
878      percent0firsts = (100 * firsts[0]) / s.AlignTabs()[0].count;
879      percent1firsts = (100 * firsts[1]) / s.AlignTabs()[1].count;
880      if ((percent0firsts < 20 && 30 < percent1firsts) || percent0firsts + 30 < percent1firsts) {
881        s.first_indent = s.AlignTabs()[1].center;
882        s.body_indent = s.AlignTabs()[0].center;
883      } else if ((percent1firsts < 20 && 30 < percent0firsts) ||
884                 percent1firsts + 30 < percent0firsts) {
885        s.first_indent = s.AlignTabs()[0].center;
886        s.body_indent = s.AlignTabs()[1].center;
887      } else {
888        if (debug_level > 1) {
889          tprintf("# Cannot determine %s indent likely to start paragraphs.\n",
890                  s.just == tesseract::JUSTIFICATION_LEFT ? "left" : "right");
891          tprintf("# Indent of %d looks like a first line %d%% of the time.\n",
892                  s.AlignTabs()[0].center, percent0firsts);
893          tprintf("# Indent of %d looks like a first line %d%% of the time.\n",
894                  s.AlignTabs()[1].center, percent1firsts);
895          s.PrintRows();
896        }
897        return;
898      }
899    } else {
900      s.first_indent = s.body_indent = s.AlignTabs()[0].center;
901    }
902    const ParagraphModel *model = theory->AddModel(s.Model());
903    s.eop_threshold = (s.OffsideTabs()[0].center + s.OffsideTabs()[1].center) / 2;
904    if (s.AlignTabs().size() == 2) {
905      for (int i = s.row_start; i < s.row_end - 1; i++) {
906        if (ValidFirstLine(s.rows, i + 1, model) &&
907            !NearlyEqual(s.OffsideTabs()[0].center, (*s.rows)[i].OffsideIndent(s.just),
908                         s.tolerance)) {
909          s.eop_threshold = 0;
910          break;
911        }
912      }
913    } else {
914      for (int i = s.row_start; i < s.row_end - 1; i++) {
915        if (!s.FirstWordWouldHaveFit(i, i + 1) &&
916            !NearlyEqual(s.OffsideTabs()[0].center, (*s.rows)[i].OffsideIndent(s.just),
917                         s.tolerance)) {
918          s.eop_threshold = 0;
919          break;
920        }
921      }
922    }
923    MarkRowsWithModel(rows, row_start, row_end, model, s.ltr, s.eop_threshold);
924  }
925  const ParagraphModel *ParagraphTheory::AddModel(const ParagraphModel &model) {
926    for (const auto &m : *models_) {
927      if (m->Comparable(model)) {
928        return m;
929      }
930    }
931    auto *m = new ParagraphModel(model);
932    models_->push_back(m);
933    push_back_new(models_we_added_, m);
934    return m;
935  }
936  void ParagraphTheory::DiscardUnusedModels(const SetOfModels &used_models) {
937    size_t w = 0;
938    for (size_t r = 0; r < models_->size(); r++) {
939      ParagraphModel *m = (*models_)[r];
940      if (!contains(used_models, static_cast<const ParagraphModel *>(m)) && contains(models_we_added_, m)) {
941        delete m;
942      } else {
943        if (r > w) {
944          (*models_)[w] = m;
945        }
946        w++;
947      }
948    }
949    models_->resize(w);
950  }
951  const ParagraphModel *ParagraphTheory::Fits(const std::vector<RowScratchRegisters> *rows,
952                                              int start, int end) const {
953    for (const auto *model : *models_) {
954      if (model->justification() != JUSTIFICATION_CENTER && RowsFitModel(rows, start, end, model)) {
955        return model;
956      }
957    }
958    return nullptr;
959  }
960  void ParagraphTheory::NonCenteredModels(SetOfModels *models) {
961    for (const auto *model : *models_) {
962      if (model->justification() != JUSTIFICATION_CENTER) {
963        push_back_new(*models, model);
964      }
965    }
966  }
967  int ParagraphTheory::IndexOf(const ParagraphModel *model) const {
968    int i = 0;
969    for (const auto *m : *models_) {
970      if (m == model) {
971        return i;
972      }
973      i++;
974    }
975    return -1;
976  }
977  bool ValidFirstLine(const std::vector<RowScratchRegisters> *rows, int row,
978                      const ParagraphModel *model) {
979    if (!StrongModel(model)) {
980      tprintf("ValidFirstLine() should only be called with strong models!\n");
981    }
982    return StrongModel(model) && model->ValidFirstLine((*rows)[row].lmargin_, (*rows)[row].lindent_,
983                                                       (*rows)[row].rindent_, (*rows)[row].rmargin_);
984  }
985  bool ValidBodyLine(const std::vector<RowScratchRegisters> *rows, int row,
986                     const ParagraphModel *model) {
987    if (!StrongModel(model)) {
988      tprintf("ValidBodyLine() should only be called with strong models!\n");
989    }
990    return StrongModel(model) && model->ValidBodyLine((*rows)[row].lmargin_, (*rows)[row].lindent_,
991                                                      (*rows)[row].rindent_, (*rows)[row].rmargin_);
992  }
993  bool CrownCompatible(const std::vector<RowScratchRegisters> *rows, int a, int b,
994                       const ParagraphModel *model) {
995    if (model != kCrownRight && model != kCrownLeft) {
996      tprintf("CrownCompatible() should only be called with crown models!\n");
997      return false;
998    }
999    auto &row_a = (*rows)[a];
1000    auto &row_b = (*rows)[b];
1001    if (model == kCrownRight) {
1002      return NearlyEqual(row_a.rindent_ + row_a.rmargin_, row_b.rindent_ + row_b.rmargin_,
1003                         Epsilon(row_a.ri_->average_interword_space));
1004    }
1005    return NearlyEqual(row_a.lindent_ + row_a.lmargin_, row_b.lindent_ + row_b.lmargin_,
1006                       Epsilon(row_a.ri_->average_interword_space));
1007  }
1008  ParagraphModelSmearer::ParagraphModelSmearer(std::vector<RowScratchRegisters> *rows,
1009                                               int row_start, int row_end, ParagraphTheory *theory)
1010      : theory_(theory), rows_(rows), row_start_(row_start), row_end_(row_end) {
1011    if (!AcceptableRowArgs(0, 0, __func__, rows, row_start, row_end)) {
1012      row_start_ = 0;
1013      row_end_ = 0;
1014      return;
1015    }
1016    open_models_.resize(open_models_.size() + row_end - row_start + 2);
1017  }
1018  void ParagraphModelSmearer::CalculateOpenModels(int row_start, int row_end) {
1019    SetOfModels no_models;
1020    if (row_start < row_start_) {
1021      row_start = row_start_;
1022    }
1023    if (row_end > row_end_) {
1024      row_end = row_end_;
1025    }
1026    for (int row = (row_start > 0) ? row_start - 1 : row_start; row < row_end; row++) {
1027      if ((*rows_)[row].ri_->num_words == 0) {
1028        OpenModels(row + 1) = no_models;
1029      } else {
1030        SetOfModels &opened = OpenModels(row);
1031        (*rows_)[row].StartHypotheses(&opened);
1032        SetOfModels still_open;
1033        for (auto &m : opened) {
1034          if (ValidFirstLine(rows_, row, m) || ValidBodyLine(rows_, row, m)) {
1035            push_back_new(still_open, m);
1036          }
1037        }
1038        OpenModels(row + 1) = still_open;
1039      }
1040    }
1041  }
1042  void ParagraphModelSmearer::Smear() {
1043    CalculateOpenModels(row_start_, row_end_);
1044    for (int i = row_start_; i < row_end_; i++) {
1045      RowScratchRegisters &row = (*rows_)[i];
1046      if (row.ri_->num_words == 0) {
1047        continue;
1048      }
1049      bool left_align_open = false;
1050      bool right_align_open = false;
1051      for (auto &m : OpenModels(i)) {
1052        switch (m->justification()) {
1053          case JUSTIFICATION_LEFT:
1054            left_align_open = true;
1055            break;
1056          case JUSTIFICATION_RIGHT:
1057            right_align_open = true;
1058            break;
1059          default:
1060            left_align_open = right_align_open = true;
1061        }
1062      }
1063      bool likely_start;
1064      if (i == 0) {
1065        likely_start = true;
1066      } else {
1067        if ((left_align_open && right_align_open) || (!left_align_open && !right_align_open)) {
1068          likely_start = LikelyParagraphStart((*rows_)[i - 1], row, JUSTIFICATION_LEFT) ||
1069                         LikelyParagraphStart((*rows_)[i - 1], row, JUSTIFICATION_RIGHT);
1070        } else if (left_align_open) {
1071          likely_start = LikelyParagraphStart((*rows_)[i - 1], row, JUSTIFICATION_LEFT);
1072        } else {
1073          likely_start = LikelyParagraphStart((*rows_)[i - 1], row, JUSTIFICATION_RIGHT);
1074        }
1075      }
1076      if (likely_start) {
1077        for (unsigned m = 0; m < OpenModels(i).size(); m++) {
1078          if (ValidFirstLine(rows_, i, OpenModels(i)[m])) {
1079            row.AddStartLine(OpenModels(i)[m]);
1080          }
1081        }
1082      } else {
1083        SetOfModels last_line_models;
1084        if (i > 0) {
1085          (*rows_)[i - 1].StrongHypotheses(&last_line_models);
1086        } else {
1087          theory_->NonCenteredModels(&last_line_models);
1088        }
1089        for (auto model : last_line_models) {
1090          if (ValidBodyLine(rows_, i, model)) {
1091            row.AddBodyLine(model);
1092          }
1093        }
1094      }
1095      if (row.GetLineType() == LT_UNKNOWN ||
1096          (row.GetLineType() == LT_START && !row.UniqueStartHypothesis())) {
1097        SetOfModels all_models;
1098        theory_->NonCenteredModels(&all_models);
1099        for (auto &all_model : all_models) {
1100          if (ValidFirstLine(rows_, i, all_model)) {
1101            row.AddStartLine(all_model);
1102          }
1103        }
1104      }
1105      if (row.GetLineType() != LT_UNKNOWN) {
1106        CalculateOpenModels(i + 1, row_end_);
1107      }
1108    }
1109  }
1110  static void DiscardUnusedModels(const std::vector<RowScratchRegisters> &rows,
1111                                  ParagraphTheory *theory) {
1112    SetOfModels used_models;
1113    for (const auto &row : rows) {
1114      row.StrongHypotheses(&used_models);
1115    }
1116    theory->DiscardUnusedModels(used_models);
1117  }
1118  static void DowngradeWeakestToCrowns(int debug_level, ParagraphTheory *theory,
1119                                       std::vector<RowScratchRegisters> *rows) {
1120    int start;
1121    for (int end = rows->size(); end > 0; end = start) {
1122      const ParagraphModel *model = nullptr;
1123      while (end > 0 && (model = (*rows)[end - 1].UniqueBodyHypothesis()) == nullptr) {
1124        end--;
1125      }
1126      if (end == 0) {
1127        break;
1128      }
1129      start = end - 1;
1130      while (start >= 0 && (*rows)[start].UniqueBodyHypothesis() == model) {
1131        start--; 
1132      }
1133      if (start >= 0 && (*rows)[start].UniqueStartHypothesis() == model && StrongModel(model) &&
1134          NearlyEqual(model->first_indent(), model->body_indent(), model->tolerance())) {
1135        start--;
1136      }
1137      start++;
1138      if (StrongModel(model) && model->justification() == JUSTIFICATION_CENTER) {
1139        continue;
1140      }
1141      if (!StrongModel(model)) {
1142        while (start > 0 && CrownCompatible(rows, start - 1, start, model)) {
1143          start--;
1144        }
1145      }
1146      if (start == 0 || (!StrongModel(model)) ||
1147          (StrongModel(model) && !ValidFirstLine(rows, start - 1, model))) {
1148        const ParagraphModel *crown_model = model;
1149        if (StrongModel(model)) {
1150          if (model->justification() == JUSTIFICATION_LEFT) {
1151            crown_model = kCrownLeft;
1152          } else {
1153            crown_model = kCrownRight;
1154          }
1155        }
1156        (*rows)[start].SetUnknown();
1157        (*rows)[start].AddStartLine(crown_model);
1158        for (int row = start + 1; row < end; row++) {
1159          (*rows)[row].SetUnknown();
1160          (*rows)[row].AddBodyLine(crown_model);
1161        }
1162      }
1163    }
1164    DiscardUnusedModels(*rows, theory);
1165  }
1166  void RecomputeMarginsAndClearHypotheses(std::vector<RowScratchRegisters> *rows, int start,
1167                                          int end, int percentile) {
1168    if (!AcceptableRowArgs(0, 0, __func__, rows, start, end)) {
1169      return;
1170    }
1171    int lmin, lmax, rmin, rmax;
1172    lmin = lmax = (*rows)[start].lmargin_ + (*rows)[start].lindent_;
1173    rmin = rmax = (*rows)[start].rmargin_ + (*rows)[start].rindent_;
1174    for (int i = start; i < end; i++) {
1175      RowScratchRegisters &sr = (*rows)[i];
1176      sr.SetUnknown();
1177      if (sr.ri_->num_words == 0) {
1178        continue;
1179      }
1180      UpdateRange(sr.lmargin_ + sr.lindent_, &lmin, &lmax);
1181      UpdateRange(sr.rmargin_ + sr.rindent_, &rmin, &rmax);
1182    }
1183    STATS lefts(lmin, lmax);
1184    STATS rights(rmin, rmax);
1185    for (int i = start; i < end; i++) {
1186      RowScratchRegisters &sr = (*rows)[i];
1187      if (sr.ri_->num_words == 0) {
1188        continue;
1189      }
1190      lefts.add(sr.lmargin_ + sr.lindent_, 1);
1191      rights.add(sr.rmargin_ + sr.rindent_, 1);
1192    }
1193    int ignorable_left = lefts.ile(ClipToRange(percentile, 0, 100) / 100.0);
1194    int ignorable_right = rights.ile(ClipToRange(percentile, 0, 100) / 100.0);
1195    for (int i = start; i < end; i++) {
1196      RowScratchRegisters &sr = (*rows)[i];
1197      int ldelta = ignorable_left - sr.lmargin_;
1198      sr.lmargin_ += ldelta;
1199      sr.lindent_ -= ldelta;
1200      int rdelta = ignorable_right - sr.rmargin_;
1201      sr.rmargin_ += rdelta;
1202      sr.rindent_ -= rdelta;
1203    }
1204  }
1205  int InterwordSpace(const std::vector<RowScratchRegisters> &rows, int row_start, int row_end) {
1206    if (row_end < row_start + 1) {
1207      return 1;
1208    }
1209    int word_height =
1210        (rows[row_start].ri_->lword_box.height() + rows[row_end - 1].ri_->lword_box.height()) / 2;
1211    int word_width =
1212        (rows[row_start].ri_->lword_box.width() + rows[row_end - 1].ri_->lword_box.width()) / 2;
1213    STATS spacing_widths(0, 4 + word_width);
1214    for (int i = row_start; i < row_end; i++) {
1215      if (rows[i].ri_->num_words > 1) {
1216        spacing_widths.add(rows[i].ri_->average_interword_space, 1);
1217      }
1218    }
1219    int minimum_reasonable_space = word_height / 3;
1220    if (minimum_reasonable_space < 2) {
1221      minimum_reasonable_space = 2;
1222    }
1223    int median = spacing_widths.median();
1224    return (median > minimum_reasonable_space) ? median : minimum_reasonable_space;
1225  }
1226  bool FirstWordWouldHaveFit(const RowScratchRegisters &before, const RowScratchRegisters &after,
1227                             tesseract::ParagraphJustification justification) {
1228    if (before.ri_->num_words == 0 || after.ri_->num_words == 0) {
1229      return true;
1230    }
1231    if (justification == JUSTIFICATION_UNKNOWN) {
1232      tprintf("Don't call FirstWordWouldHaveFit(r, s, JUSTIFICATION_UNKNOWN).\n");
1233    }
1234    int available_space;
1235    if (justification == JUSTIFICATION_CENTER) {
1236      available_space = before.lindent_ + before.rindent_;
1237    } else {
1238      available_space = before.OffsideIndent(justification);
1239    }
1240    available_space -= before.ri_->average_interword_space;
1241    if (before.ri_->ltr) {
1242      return after.ri_->lword_box.width() < available_space;
1243    }
1244    return after.ri_->rword_box.width() < available_space;
1245  }
1246  bool FirstWordWouldHaveFit(const RowScratchRegisters &before, const RowScratchRegisters &after) {
1247    if (before.ri_->num_words == 0 || after.ri_->num_words == 0) {
1248      return true;
1249    }
1250    int available_space = before.lindent_;
1251    if (before.rindent_ > available_space) {
1252      available_space = before.rindent_;
1253    }
1254    available_space -= before.ri_->average_interword_space;
1255    if (before.ri_->ltr) {
1256      return after.ri_->lword_box.width() < available_space;
1257    }
1258    return after.ri_->rword_box.width() < available_space;
1259  }
1260  static bool TextSupportsBreak(const RowScratchRegisters &before, const RowScratchRegisters &after) {
1261    if (before.ri_->ltr) {
1262      return before.ri_->rword_likely_ends_idea && after.ri_->lword_likely_starts_idea;
1263    } else {
1264      return before.ri_->lword_likely_ends_idea && after.ri_->rword_likely_starts_idea;
1265    }
1266  }
1267  static bool LikelyParagraphStart(const RowScratchRegisters &before,
1268                                   const RowScratchRegisters &after,
1269                                   tesseract::ParagraphJustification j) {
1270    return before.ri_->num_words == 0 ||
1271           (FirstWordWouldHaveFit(before, after, j) && TextSupportsBreak(before, after));
1272  }
1273  static ParagraphModel InternalParagraphModelByOutline(
1274      const std::vector<RowScratchRegisters> *rows, int start, int end, int tolerance,
1275      bool *consistent) {
1276    int ltr_line_count = 0;
1277    for (int i = start; i < end; i++) {
1278      ltr_line_count += static_cast<int>((*rows)[i].ri_->ltr);
1279    }
1280    bool ltr = (ltr_line_count >= (end - start) / 2);
1281    *consistent = true;
1282    if (!AcceptableRowArgs(0, 2, __func__, rows, start, end)) {
1283      return ParagraphModel();
1284    }
1285    int lmargin = (*rows)[start].lmargin_;
1286    int rmargin = (*rows)[start].rmargin_;
1287    int lmin, lmax, rmin, rmax, cmin, cmax;
1288    lmin = lmax = (*rows)[start + 1].lindent_;
1289    rmin = rmax = (*rows)[start + 1].rindent_;
1290    cmin = cmax = 0;
1291    for (int i = start + 1; i < end; i++) {
1292      if ((*rows)[i].lmargin_ != lmargin || (*rows)[i].rmargin_ != rmargin) {
1293        tprintf("Margins don't match! Software error.\n");
1294        *consistent = false;
1295        return ParagraphModel();
<span onclick='openModal()' class='match'>1296      }
1297      UpdateRange((*rows)[i].lindent_, &lmin, &lmax);
1298      UpdateRange((*rows)[i].rindent_, &rmin, &rmax);
1299      UpdateRange((*rows)[i].rindent_ - (*rows)[i].lindent_, &cmin, &cmax);
1300    }
1301    int ldiff = lmax - lmin;
1302    int rdiff = rmax - rmin;
1303    int cdiff = cmax - cmin;
1304    if (rdiff > tolerance && ldiff > tolerance) {
</span>1305      if (cdiff < tolerance * 2) {
1306        if (end - start < 3) {
1307          return ParagraphModel();
1308        }
1309        return ParagraphModel(JUSTIFICATION_CENTER, 0, 0, 0, tolerance);
1310      }
1311      *consistent = false;
1312      return ParagraphModel();
1313    }
1314    if (end - start < 3) { 
1315      return ParagraphModel();
1316    }
1317    bool body_admits_left_alignment = ldiff < tolerance;
1318    bool body_admits_right_alignment = rdiff < tolerance;
1319    ParagraphModel left_model = ParagraphModel(JUSTIFICATION_LEFT, lmargin, (*rows)[start].lindent_,
1320                                               (lmin + lmax) / 2, tolerance);
1321    ParagraphModel right_model = ParagraphModel(JUSTIFICATION_RIGHT, rmargin, (*rows)[start].rindent_,
1322                                                (rmin + rmax) / 2, tolerance);
1323    bool text_admits_left_alignment = ltr || left_model.is_flush();
1324    bool text_admits_right_alignment = !ltr || right_model.is_flush();
1325    if (tolerance < rdiff) {
1326      if (body_admits_left_alignment && text_admits_left_alignment) {
1327        return left_model;
1328      }
1329      *consistent = false;
1330      return ParagraphModel();
1331    }
1332    if (tolerance < ldiff) {
1333      if (body_admits_right_alignment && text_admits_right_alignment) {
1334        return right_model;
1335      }
1336      *consistent = false;
1337      return ParagraphModel();
1338    }
1339    int first_left = (*rows)[start].lindent_;
1340    int first_right = (*rows)[start].rindent_;
1341    if (ltr && body_admits_left_alignment && (first_left < lmin || first_left > lmax)) {
1342      return left_model;
1343    }
1344    if (!ltr && body_admits_right_alignment && (first_right < rmin || first_right > rmax)) {
1345      return right_model;
1346    }
1347    *consistent = false;
1348    return ParagraphModel();
1349  }
1350  static ParagraphModel ParagraphModelByOutline(int debug_level,
1351                                                const std::vector<RowScratchRegisters> *rows,
1352                                                int start, int end, int tolerance) {
1353    bool unused_consistent;
1354    ParagraphModel retval =
1355        InternalParagraphModelByOutline(rows, start, end, tolerance, &unused_consistent);
1356    if (debug_level >= 2 && retval.justification() == JUSTIFICATION_UNKNOWN) {
1357      tprintf("Could not determine a model for this paragraph:\n");
1358      PrintRowRange(*rows, start, end);
1359    }
1360    return retval;
1361  }
1362  bool RowsFitModel(const std::vector<RowScratchRegisters> *rows, int start, int end,
1363                    const ParagraphModel *model) {
1364    if (!AcceptableRowArgs(0, 1, __func__, rows, start, end)) {
1365      return false;
1366    }
1367    if (!ValidFirstLine(rows, start, model)) {
1368      return false;
1369    }
1370    for (int i = start + 1; i < end; i++) {
1371      if (!ValidBodyLine(rows, i, model)) {
1372        return false;
1373      }
1374    }
1375    return true;
1376  }
1377  static void MarkStrongEvidence(std::vector<RowScratchRegisters> *rows, int row_start,
1378                                 int row_end) {
1379    for (int i = row_start + 1; i < row_end; i++) {
1380      const RowScratchRegisters &prev = (*rows)[i - 1];
1381      RowScratchRegisters &curr = (*rows)[i];
1382      tesseract::ParagraphJustification typical_justification =
1383          prev.ri_->ltr ? JUSTIFICATION_LEFT : JUSTIFICATION_RIGHT;
1384      if (!curr.ri_->rword_likely_starts_idea && !curr.ri_->lword_likely_starts_idea &&
1385          !FirstWordWouldHaveFit(prev, curr, typical_justification)) {
1386        curr.SetBodyLine();
1387      }
1388    }
1389    {
1390      RowScratchRegisters &curr = (*rows)[row_start];
1391      RowScratchRegisters &next = (*rows)[row_start + 1];
1392      tesseract::ParagraphJustification j = curr.ri_->ltr ? JUSTIFICATION_LEFT : JUSTIFICATION_RIGHT;
1393      if (curr.GetLineType() == LT_UNKNOWN && !FirstWordWouldHaveFit(curr, next, j) &&
1394          (curr.ri_->lword_likely_starts_idea || curr.ri_->rword_likely_starts_idea)) {
1395        curr.SetStartLine();
1396      }
1397    }
1398    for (int i = row_start + 1; i < row_end - 1; i++) {
1399      RowScratchRegisters &prev = (*rows)[i - 1];
1400      RowScratchRegisters &curr = (*rows)[i];
1401      RowScratchRegisters &next = (*rows)[i + 1];
1402      tesseract::ParagraphJustification j = curr.ri_->ltr ? JUSTIFICATION_LEFT : JUSTIFICATION_RIGHT;
1403      if (curr.GetLineType() == LT_UNKNOWN && !FirstWordWouldHaveFit(curr, next, j) &&
1404          LikelyParagraphStart(prev, curr, j)) {
1405        curr.SetStartLine();
1406      }
1407    }
1408    { 
1409      RowScratchRegisters &prev = (*rows)[row_end - 2];
1410      RowScratchRegisters &curr = (*rows)[row_end - 1];
1411      tesseract::ParagraphJustification j = curr.ri_->ltr ? JUSTIFICATION_LEFT : JUSTIFICATION_RIGHT;
1412      if (curr.GetLineType() == LT_UNKNOWN && !FirstWordWouldHaveFit(curr, curr, j) &&
1413          LikelyParagraphStart(prev, curr, j)) {
1414        curr.SetStartLine();
1415      }
1416    }
1417  }
1418  static void ModelStrongEvidence(int debug_level, std::vector<RowScratchRegisters> *rows,
1419                                  int row_start, int row_end, bool allow_flush_models,
1420                                  ParagraphTheory *theory) {
1421    if (!AcceptableRowArgs(debug_level, 2, __func__, rows, row_start, row_end)) {
1422      return;
1423    }
1424    int start = row_start;
1425    while (start < row_end) {
1426      while (start < row_end && (*rows)[start].GetLineType() != LT_START) {
1427        start++;
1428      }
1429      if (start >= row_end - 1) {
1430        break;
1431      }
1432      int tolerance = Epsilon((*rows)[start + 1].ri_->average_interword_space);
1433      int end = start;
1434      ParagraphModel last_model;
1435      bool next_consistent;
1436      do {
1437        ++end;
1438        if (end < row_end - 1) {
1439          RowScratchRegisters &next = (*rows)[end];
1440          LineType lt = next.GetLineType();
1441          next_consistent = lt == LT_BODY || (lt == LT_UNKNOWN &&
1442                                              !FirstWordWouldHaveFit((*rows)[end - 1], (*rows)[end]));
1443        } else {
1444          next_consistent = false;
1445        }
1446        if (next_consistent) {
1447          ParagraphModel next_model =
1448              InternalParagraphModelByOutline(rows, start, end + 1, tolerance, &next_consistent);
1449          if (((*rows)[start].ri_->ltr && last_model.justification() == JUSTIFICATION_LEFT &&
1450               next_model.justification() != JUSTIFICATION_LEFT) ||
1451              (!(*rows)[start].ri_->ltr && last_model.justification() == JUSTIFICATION_RIGHT &&
1452               next_model.justification() != JUSTIFICATION_RIGHT)) {
1453            next_consistent = false;
1454          }
1455          last_model = next_model;
1456        } else {
1457          next_consistent = false;
1458        }
1459      } while (next_consistent && end < row_end);
1460      if (end > start + 1) {
1461        const ParagraphModel *model = nullptr;
1462        ParagraphModel new_model = ParagraphModelByOutline(
1463            debug_level, rows, start, end, Epsilon(InterwordSpace(*rows, start, end)));
1464        if (new_model.justification() == JUSTIFICATION_UNKNOWN) {
1465        } else if (new_model.is_flush()) {
1466          if (end == start + 2) {
1467            end = start + 1;
1468          } else if (start == row_start) {
1469            if (new_model.justification() == JUSTIFICATION_LEFT) {
1470              model = kCrownLeft;
1471            } else {
1472              model = kCrownRight;
1473            }
1474          } else if (allow_flush_models) {
1475            model = theory->AddModel(new_model);
1476          }
1477        } else {
1478          model = theory->AddModel(new_model);
1479        }
1480        if (model) {
1481          (*rows)[start].AddStartLine(model);
1482          for (int i = start + 1; i < end; i++) {
1483            (*rows)[i].AddBodyLine(model);
1484          }
1485        }
1486      }
1487      start = end;
1488    }
1489  }
1490  static void StrongEvidenceClassify(int debug_level, std::vector<RowScratchRegisters> *rows,
1491                                     int row_start, int row_end, ParagraphTheory *theory) {
1492    if (!AcceptableRowArgs(debug_level, 2, __func__, rows, row_start, row_end)) {
1493      return;
1494    }
1495    if (debug_level > 1) {
1496      tprintf("#############################################\n");
1497      tprintf("# StrongEvidenceClassify( rows[%d:%d) )\n", row_start, row_end);
1498      tprintf("#############################################\n");
1499    }
1500    RecomputeMarginsAndClearHypotheses(rows, row_start, row_end, 10);
1501    MarkStrongEvidence(rows, row_start, row_end);
1502    DebugDump(debug_level > 2, "Initial strong signals.", *theory, *rows);
1503    ModelStrongEvidence(debug_level, rows, row_start, row_end, false, theory);
1504    DebugDump(debug_level > 2, "Unsmeared hypotheses.s.", *theory, *rows);
1505    ParagraphModelSmearer smearer(rows, row_start, row_end, theory);
1506    smearer.Smear();
1507  }
1508  static void SeparateSimpleLeaderLines(std::vector<RowScratchRegisters> *rows, int row_start,
1509                                        int row_end, ParagraphTheory *theory) {
1510    for (int i = row_start + 1; i < row_end - 1; i++) {
1511      if ((*rows)[i - 1].ri_->has_leaders && (*rows)[i].ri_->has_leaders &&
1512          (*rows)[i + 1].ri_->has_leaders) {
1513        const ParagraphModel *model =
1514            theory->AddModel(ParagraphModel(JUSTIFICATION_UNKNOWN, 0, 0, 0, 0));
1515        (*rows)[i].AddStartLine(model);
1516      }
1517    }
1518  }
1519  static void ConvertHypothesizedModelRunsToParagraphs(int debug_level,
1520                                                       std::vector<RowScratchRegisters> &rows,
1521                                                       std::vector<PARA *> *row_owners,
1522                                                       ParagraphTheory *theory) {
1523    int end = rows.size();
1524    int start;
1525    for (; end > 0; end = start) {
1526      start = end - 1;
1527      const ParagraphModel *model = nullptr;
1528      bool single_line_paragraph = false;
1529      SetOfModels models;
1530      rows[start].NonNullHypotheses(&models);
1531      if (!models.empty()) {
1532        model = models[0];
1533        if (rows[start].GetLineType(model) != LT_BODY) {
1534          single_line_paragraph = true;
1535        }
1536      }
1537      if (model && !single_line_paragraph) {
1538        while (--start > 0 && rows[start].GetLineType(model) == LT_BODY) {
1539        }
1540        if (start < 0 || rows[start].GetLineType(model) != LT_START) {
1541          model = nullptr;
1542        }
1543      }
1544      if (model == nullptr) {
1545        continue;
1546      }
1547      PARA *p = new PARA();
1548      if (model == kCrownLeft || model == kCrownRight) {
1549        p->is_very_first_or_continuation = true;
1550        for (unsigned row = end; row < rows.size(); row++) {
1551          if ((*row_owners)[row] &&
1552              (ValidBodyLine(&rows, start, (*row_owners)[row]->model) &&
1553               (start == 0 || ValidFirstLine(&rows, start, (*row_owners)[row]->model)))) {
1554            model = (*row_owners)[row]->model;
1555            break;
1556          }
1557        }
1558        if (model == kCrownLeft) {
1559          model = theory->AddModel(ParagraphModel(JUSTIFICATION_LEFT,
1560                                                  rows[start].lmargin_ + rows[start].lindent_, 0, 0,
1561                                                  Epsilon(rows[start].ri_->average_interword_space)));
1562        } else if (model == kCrownRight) {
1563          model = theory->AddModel(ParagraphModel(JUSTIFICATION_RIGHT,
1564                                                  rows[start].rmargin_ + rows[start].rmargin_, 0, 0,
1565                                                  Epsilon(rows[start].ri_->average_interword_space)));
1566        }
1567      }
1568      rows[start].SetUnknown();
1569      rows[start].AddStartLine(model);
1570      for (int i = start + 1; i < end; i++) {
1571        rows[i].SetUnknown();
1572        rows[i].AddBodyLine(model);
1573      }
1574      p->model = model;
1575      p->has_drop_cap = rows[start].ri_->has_drop_cap;
1576      p->is_list_item = model->justification() == JUSTIFICATION_RIGHT
1577                            ? rows[start].ri_->rword_indicates_list_item
1578                            : rows[start].ri_->lword_indicates_list_item;
1579      for (int row = start; row < end; row++) {
1580        if ((*row_owners)[row] != nullptr) {
1581          tprintf(
1582              "Memory leak! ConvertHypothesizeModelRunsToParagraphs() called "
1583              "more than once!\n");
1584          delete (*row_owners)[row];
1585        }
1586        (*row_owners)[row] = p;
1587      }
1588    }
1589  }
1590  struct Interval {
1591    Interval() : begin(0), end(0) {}
1592    Interval(int b, int e) : begin(b), end(e) {}
1593    int begin;
1594    int end;
1595  };
1596  static bool RowIsStranded(const std::vector<RowScratchRegisters> &rows, int row) {
1597    SetOfModels row_models;
1598    rows[row].StrongHypotheses(&row_models);
1599    for (auto &row_model : row_models) {
1600      bool all_starts = rows[row].GetLineType();
1601      int run_length = 1;
1602      bool continues = true;
1603      for (int i = row - 1; i >= 0 && continues; i--) {
1604        SetOfModels models;
1605        rows[i].NonNullHypotheses(&models);
1606        switch (rows[i].GetLineType(row_model)) {
1607          case LT_START:
1608            run_length++;
1609            break;
1610          case LT_MULTIPLE: 
1611          case LT_BODY:
1612            run_length++;
1613            all_starts = false;
1614            break;
1615          case LT_UNKNOWN: 
1616          default:
1617            continues = false;
1618        }
1619      }
1620      continues = true;
1621      for (unsigned i = row + 1; i < rows.size() && continues; i++) {
1622        SetOfModels models;
1623        rows[i].NonNullHypotheses(&models);
1624        switch (rows[i].GetLineType(row_model)) {
1625          case LT_START:
1626            run_length++;
1627            break;
1628          case LT_MULTIPLE: 
1629          case LT_BODY:
1630            run_length++;
1631            all_starts = false;
1632            break;
1633          case LT_UNKNOWN: 
1634          default:
1635            continues = false;
1636        }
1637      }
1638      if (run_length > 2 || (!all_starts && run_length > 1)) {
1639        return false;
1640      }
1641    }
1642    return true;
1643  }
1644  static void LeftoverSegments(const std::vector<RowScratchRegisters> &rows,
1645                               std::vector<Interval> *to_fix, int row_start, int row_end) {
1646    to_fix->clear();
1647    for (int i = row_start; i < row_end; i++) {
1648      bool needs_fixing = false;
1649      SetOfModels models;
1650      SetOfModels models_w_crowns;
1651      rows[i].StrongHypotheses(&models);
1652      rows[i].NonNullHypotheses(&models_w_crowns);
1653      if (models.empty() && !models_w_crowns.empty()) {
1654        for (unsigned end = i + 1; end < rows.size(); end++) {
1655          SetOfModels end_models;
1656          SetOfModels strong_end_models;
1657          rows[end].NonNullHypotheses(&end_models);
1658          rows[end].StrongHypotheses(&strong_end_models);
1659          if (end_models.empty()) {
1660            needs_fixing = true;
1661            break;
1662          } else if (!strong_end_models.empty()) {
1663            needs_fixing = false;
1664            break;
1665          }
1666        }
1667      } else if (models.empty() && rows[i].ri_->num_words > 0) {
1668        needs_fixing = true;
1669      }
1670      if (!needs_fixing && !models.empty()) {
1671        needs_fixing = RowIsStranded(rows, i);
1672      }
1673      if (needs_fixing) {
1674        if (!to_fix->empty() && to_fix->back().end == i - 1) {
1675          to_fix->back().end = i;
1676        } else {
1677          to_fix->push_back(Interval(i, i));
1678        }
1679      }
1680    }
1681    for (auto &i : *to_fix) {
1682      i.end = i.end + 1;
1683    }
1684  }
1685  void CanonicalizeDetectionResults(std::vector<PARA *> *row_owners, PARA_LIST *paragraphs) {
1686    std::vector<PARA *> &rows = *row_owners;
1687    paragraphs->clear();
1688    PARA_IT out(paragraphs);
1689    PARA *formerly_null = nullptr;
1690    for (unsigned i = 0; i < rows.size(); i++) {
1691      if (rows[i] == nullptr) {
1692        if (i == 0 || rows[i - 1] != formerly_null) {
1693          rows[i] = formerly_null = new PARA();
1694        } else {
1695          rows[i] = formerly_null;
1696          continue;
1697        }
1698      } else if (i > 0 && rows[i - 1] == rows[i]) {
1699        continue;
1700      }
1701      out.add_after_then_move(rows[i]);
1702    }
1703  }
1704  void DetectParagraphs(int debug_level, std::vector<RowInfo> *row_infos,
1705                        std::vector<PARA *> *row_owners, PARA_LIST *paragraphs,
1706                        std::vector<ParagraphModel *> *models) {
1707    ParagraphTheory theory(models);
1708    row_owners->clear();
1709    row_owners->resize(row_infos->size());
1710    std::vector<RowScratchRegisters> rows(row_infos->size());
1711    for (unsigned i = 0; i < row_infos->size(); i++) {
1712      rows[i].Init((*row_infos)[i]);
1713    }
1714    SeparateSimpleLeaderLines(&rows, 0, rows.size(), &theory);
1715    DebugDump(debug_level > 1, "End of Pass 1", theory, rows);
1716    std::vector<Interval> leftovers;
1717    LeftoverSegments(rows, &leftovers, 0, rows.size());
1718    for (auto &leftover : leftovers) {
1719      StrongEvidenceClassify(debug_level, &rows, leftover.begin, leftover.end, &theory);
1720      std::vector<Interval> leftovers2;
1721      LeftoverSegments(rows, &leftovers2, leftover.begin, leftover.end);
1722      bool pass2a_was_useful =
1723          leftovers2.size() > 1 ||
1724          (leftovers2.size() == 1 && (leftovers2[0].begin != 0 || static_cast<size_t>(leftovers2[0].end) != rows.size()));
1725      if (pass2a_was_useful) {
1726        for (auto &leftover2 : leftovers2) {
1727          StrongEvidenceClassify(debug_level, &rows, leftover2.begin, leftover2.end, &theory);
1728        }
1729      }
1730    }
1731    DebugDump(debug_level > 1, "End of Pass 2", theory, rows);
1732    LeftoverSegments(rows, &leftovers, 0, rows.size());
1733    for (auto &leftover : leftovers) {
1734      GeometricClassify(debug_level, &rows, leftover.begin, leftover.end, &theory);
1735    }
1736    DowngradeWeakestToCrowns(debug_level, &theory, &rows);
1737    DebugDump(debug_level > 1, "End of Pass 3", theory, rows);
1738    LeftoverSegments(rows, &leftovers, 0, rows.size());
1739    for (auto &leftover : leftovers) {
1740      for (int j = leftover.begin; j < leftover.end; j++) {
1741        rows[j].SetUnknown();
1742      }
1743    }
1744    DebugDump(debug_level > 1, "End of Pass 4", theory, rows);
1745    ConvertHypothesizedModelRunsToParagraphs(debug_level, rows, row_owners, &theory);
1746    DebugDump(debug_level > 0, "Final Paragraph Segmentation", theory, rows);
1747    CanonicalizeDetectionResults(row_owners, paragraphs);
1748  }
1749  static void InitializeTextAndBoxesPreRecognition(const MutableIterator &it, RowInfo *info) {
1750    std::string fake_text;
1751    PageIterator pit(static_cast<const PageIterator &>(it));
1752    bool first_word = true;
1753    if (!pit.Empty(RIL_WORD)) {
1754      do {
1755        fake_text += "x";
1756        if (first_word) {
1757          info->lword_text += "x";
1758        }
1759        info->rword_text += "x";
1760        if (pit.IsAtFinalElement(RIL_WORD, RIL_SYMBOL) &&
1761            !pit.IsAtFinalElement(RIL_TEXTLINE, RIL_SYMBOL)) {
1762          fake_text += " ";
1763          info->rword_text = "";
1764          first_word = false;
1765        }
1766      } while (!pit.IsAtFinalElement(RIL_TEXTLINE, RIL_SYMBOL) && pit.Next(RIL_SYMBOL));
1767    }
1768    if (fake_text.empty()) {
1769      return;
1770    }
1771    int lspaces = info->pix_ldistance / info->average_interword_space;
1772    for (int i = 0; i < lspaces; i++) {
1773      info->text += ' ';
1774    }
1775    info->text += fake_text;
1776    PAGE_RES_IT page_res_it = *it.PageResIt();
1777    WERD_RES *word_res = page_res_it.restart_row();
1778    ROW_RES *this_row = page_res_it.row();
1779    WERD_RES *lword = nullptr;
1780    WERD_RES *rword = nullptr;
1781    info->num_words = 0;
1782    do {
1783      if (word_res) {
1784        if (!lword) {
1785          lword = word_res;
1786        }
1787        if (rword != word_res) {
1788          info->num_words++;
1789        }
1790        rword = word_res;
1791      }
1792      word_res = page_res_it.forward();
1793    } while (page_res_it.row() == this_row);
1794    if (lword) {
1795      info->lword_box = lword->word->bounding_box();
1796    }
1797    if (rword) {
1798      info->rword_box = rword->word->bounding_box();
1799    }
1800  }
1801  static void InitializeRowInfo(bool after_recognition, const MutableIterator &it, RowInfo *info) {
1802    if (it.PageResIt()->row() != nullptr) {
1803      ROW *row = it.PageResIt()->row()->row;
1804      info->pix_ldistance = row->lmargin();
1805      info->pix_rdistance = row->rmargin();
1806      info->average_interword_space =
1807          row->space() > 0 ? row->space() : std::max(static_cast<int>(row->x_height()), 1);
1808      info->pix_xheight = row->x_height();
1809      info->has_leaders = false;
1810      info->has_drop_cap = row->has_drop_cap();
1811      info->ltr = true; 
1812    } else {
1813      info->pix_ldistance = info->pix_rdistance = 0;
1814      info->average_interword_space = 1;
1815      info->pix_xheight = 1.0;
1816      info->has_leaders = false;
1817      info->has_drop_cap = false;
1818      info->ltr = true;
1819    }
1820    info->num_words = 0;
1821    info->lword_indicates_list_item = false;
1822    info->lword_likely_starts_idea = false;
1823    info->lword_likely_ends_idea = false;
1824    info->rword_indicates_list_item = false;
1825    info->rword_likely_starts_idea = false;
1826    info->rword_likely_ends_idea = false;
1827    info->has_leaders = false;
1828    info->ltr = true;
1829    if (!after_recognition) {
1830      InitializeTextAndBoxesPreRecognition(it, info);
1831      return;
1832    }
1833    info->text = "";
1834    const std::unique_ptr<const char[]> text(it.GetUTF8Text(RIL_TEXTLINE));
1835    int trailing_ws_idx = strlen(text.get()); 
1836    while (trailing_ws_idx > 0 &&
1837           isascii(text[trailing_ws_idx - 1]) && isspace(text[trailing_ws_idx - 1])) {
1838      trailing_ws_idx--;
1839    }
1840    if (trailing_ws_idx > 0) {
1841      int lspaces = info->pix_ldistance / info->average_interword_space;
1842      for (int i = 0; i < lspaces; i++) {
1843        info->text += ' ';
1844      }
1845      for (int i = 0; i < trailing_ws_idx; i++) {
1846        info->text += text[i];
1847      }
1848    }
1849    if (info->text.empty()) {
1850      return;
1851    }
1852    PAGE_RES_IT page_res_it = *it.PageResIt();
1853    std::vector<WERD_RES *> werds;
1854    WERD_RES *word_res = page_res_it.restart_row();
1855    ROW_RES *this_row = page_res_it.row();
1856    int num_leaders = 0;
1857    int ltr = 0;
1858    int rtl = 0;
1859    do {
1860      if (word_res && word_res->best_choice->unichar_string().length() > 0) {
1861        werds.push_back(word_res);
1862        ltr += word_res->AnyLtrCharsInWord() ? 1 : 0;
1863        rtl += word_res->AnyRtlCharsInWord() ? 1 : 0;
1864        if (word_res->word->flag(W_REP_CHAR)) {
1865          num_leaders++;
1866        }
1867      }
1868      word_res = page_res_it.forward();
1869    } while (page_res_it.row() == this_row);
1870    info->ltr = ltr >= rtl;
1871    info->has_leaders = num_leaders > 3;
1872    info->num_words = werds.size();
1873    if (!werds.empty()) {
1874      WERD_RES *lword = werds[0], *rword = werds[werds.size() - 1];
1875      info->lword_text = lword->best_choice->unichar_string().c_str();
1876      info->rword_text = rword->best_choice->unichar_string().c_str();
1877      info->lword_box = lword->word->bounding_box();
1878      info->rword_box = rword->word->bounding_box();
1879      LeftWordAttributes(lword->uch_set, lword->best_choice, info->lword_text,
1880                         &info->lword_indicates_list_item, &info->lword_likely_starts_idea,
1881                         &info->lword_likely_ends_idea);
1882      RightWordAttributes(rword->uch_set, rword->best_choice, info->rword_text,
1883                          &info->rword_indicates_list_item, &info->rword_likely_starts_idea,
1884                          &info->rword_likely_ends_idea);
1885    }
1886  }
1887  void DetectParagraphs(int debug_level, bool after_text_recognition,
1888                        const MutableIterator *block_start, std::vector<ParagraphModel *> *models) {
1889    if (block_start->Empty(RIL_TEXTLINE)) {
1890      return;
1891    }
1892    BLOCK *block = block_start->PageResIt()->block()->block;
1893    block->para_list()->clear();
1894    bool is_image_block = block->pdblk.poly_block() && !block->pdblk.poly_block()->IsText();
1895    MutableIterator row(*block_start);
1896    if (row.Empty(RIL_TEXTLINE)) {
1897      return; 
1898    }
1899    std::vector<RowInfo> row_infos;
1900    do {
1901      if (!row.PageResIt()->row()) {
1902        continue; 
1903      }
1904      row.PageResIt()->row()->row->set_para(nullptr);
1905      row_infos.emplace_back();
1906      RowInfo &ri = row_infos.back();
1907      InitializeRowInfo(after_text_recognition, row, &ri);
1908    } while (!row.IsAtFinalElement(RIL_BLOCK, RIL_TEXTLINE) && row.Next(RIL_TEXTLINE));
1909    if (!row_infos.empty()) {
1910      int min_lmargin = row_infos[0].pix_ldistance;
1911      int min_rmargin = row_infos[0].pix_rdistance;
1912      for (unsigned i = 1; i < row_infos.size(); i++) {
1913        if (row_infos[i].pix_ldistance < min_lmargin) {
1914          min_lmargin = row_infos[i].pix_ldistance;
1915        }
1916        if (row_infos[i].pix_rdistance < min_rmargin) {
1917          min_rmargin = row_infos[i].pix_rdistance;
1918        }
1919      }
1920      if (min_lmargin > 0 || min_rmargin > 0) {
1921        for (auto &row_info : row_infos) {
1922          row_info.pix_ldistance -= min_lmargin;
1923          row_info.pix_rdistance -= min_rmargin;
1924        }
1925      }
1926    }
1927    std::vector<PARA *> row_owners;
1928    std::vector<PARA *> the_paragraphs;
1929    if (!is_image_block) {
1930      DetectParagraphs(debug_level, &row_infos, &row_owners, block->para_list(), models);
1931    } else {
1932      row_owners.resize(row_infos.size());
1933      CanonicalizeDetectionResults(&row_owners, block->para_list());
1934    }
1935    row = *block_start;
1936    for (auto &row_owner : row_owners) {
1937      while (!row.PageResIt()->row()) {
1938        row.Next(RIL_TEXTLINE);
1939      }
1940      row.PageResIt()->row()->row->set_para(row_owner);
1941      row.Next(RIL_TEXTLINE);
1942    }
1943  }
1944  } 
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from tesseract-MDEwOlJlcG9zaXRvcnkyMjg4NzA5NA==-flat-lstmtrainer.cpp</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from tesseract-MDEwOlJlcG9zaXRvcnkyMjg4NzA5NA==-flat-paragraphs.cpp</div>
                </div>
                <div class="column column_space"><pre><code>824      }
825    }
826    double char_error = ComputeCharError(truth_labels, ocr_labels);
827    double word_error = ComputeWordError(&truth_text, &ocr_text);
828    double delta_error = ComputeErrorRates(*targets, char_error, word_error);
829    if (debug_interval_ != 0) {
</pre></code></div>
                <div class="column column_space"><pre><code>1296      }
1297      UpdateRange((*rows)[i].lindent_, &lmin, &lmax);
1298      UpdateRange((*rows)[i].rindent_, &rmin, &rmax);
1299      UpdateRange((*rows)[i].rindent_ - (*rows)[i].lindent_, &cmin, &cmax);
1300    }
1301    int ldiff = lmax - lmin;
1302    int rdiff = rmax - rmin;
1303    int cdiff = cmax - cmin;
1304    if (rdiff > tolerance && ldiff > tolerance) {
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    