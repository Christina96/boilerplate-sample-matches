
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 1.7110266159695817%, Tokens: 9</h2>
        <div class="column">
            <h3>snap-MDEwOlJlcG9zaXRvcnk0Mjg4MzU3-flat-linalg.h</h3>
            <pre><code>1  class TLinAlg;
2  class TLAMisc;
3  class TMatrix {
4  private:
5      bool Transposed;
6  protected:
7      virtual void PMultiply(const TFltVV& B, int ColId, TFltV& Result) const = 0;
8      virtual void PMultiply(const TFltV& Vec, TFltV& Result) const = 0;
9      virtual void PMultiplyT(const TFltVV& B, int ColId, TFltV& Result) const = 0;
10      virtual void PMultiplyT(const TFltV& Vec, TFltV& Result) const = 0;
11      virtual int PGetRows() const = 0;
12      virtual int PGetCols() const = 0;
13  public:
14      TMatrix(): Transposed(false) {}
15      virtual ~TMatrix() { }
16      void Multiply(const TFltVV& B, int ColId, TFltV& Result) const {
17          if (Transposed) { PMultiplyT(B, ColId, Result); }
18          else { PMultiply(B, ColId, Result); }
19      }
20      void Multiply(const TFltV& Vec, TFltV& Result) const {
<span onclick='openModal()' class='match'>21          if (Transposed) { PMultiplyT(Vec, Result); }
22          else { PMultiply(Vec, Result); }
23      }
24      void MultiplyT(const TFltVV& B, int ColId, TFltV& Result) const {
</span>25          if (Transposed) { PMultiply(B, ColId, Result); }
26          else { PMultiplyT(B, ColId, Result); }
27      }
28      void MultiplyT(const TFltV& Vec, TFltV& Result) const{
29          if (Transposed) { PMultiply(Vec, Result); }
30          else { PMultiplyT(Vec, Result); }
31      }
32      int GetRows() const { return Transposed ? PGetCols() : PGetRows(); }
33      int GetCols() const { return Transposed ? PGetRows() : PGetCols(); }
34      void Transpose() { Transposed = !Transposed; }
35  };
36  class TSparseColMatrix: public TMatrix {
37  public:
38      int RowN, ColN;
39      TVec<TIntFltKdV> ColSpVV;
40  protected:
41      virtual void PMultiply(const TFltVV& B, int ColId, TFltV& Result) const;
42      virtual void PMultiply(const TFltV& Vec, TFltV& Result) const;
43      virtual void PMultiplyT(const TFltVV& B, int ColId, TFltV& Result) const;
44      virtual void PMultiplyT(const TFltV& Vec, TFltV& Result) const;
45      int PGetRows() const { return RowN; }
46      int PGetCols() const { return ColN; }
47  public:
48      TSparseColMatrix(): TMatrix() {}
49      TSparseColMatrix(TVec<TIntFltKdV> _ColSpVV): TMatrix(), ColSpVV(_ColSpVV) {}
50      TSparseColMatrix(TVec<TIntFltKdV> _ColSpVV, const int& _RowN, const int& _ColN): 
51  		TMatrix(), RowN(_RowN), ColN(_ColN), ColSpVV(_ColSpVV) {}
52      void Save(TSOut& SOut) {
53          SOut.Save(RowN); SOut.Save(ColN); ColSpVV.Save(SOut); }
54      void Load(TSIn& SIn) {
55          SIn.Load(RowN); SIn.Load(ColN); ColSpVV = TVec<TIntFltKdV>(SIn); }
56  };
57  class TSparseRowMatrix: public TMatrix {
58  public:
59      int RowN, ColN;
60      TVec<TIntFltKdV> RowSpVV;
61  protected:
62      virtual void PMultiply(const TFltVV& B, int ColId, TFltV& Result) const;
63      virtual void PMultiply(const TFltV& Vec, TFltV& Result) const;
64      virtual void PMultiplyT(const TFltVV& B, int ColId, TFltV& Result) const;
65      virtual void PMultiplyT(const TFltV& Vec, TFltV& Result) const;
66      int PGetRows() const { return RowN; }
67      int PGetCols() const { return ColN; }
68  public:
69      TSparseRowMatrix(): TMatrix() {}
70      TSparseRowMatrix(TVec<TIntFltKdV> _RowSpVV): TMatrix(), RowSpVV(_RowSpVV) {}
71      TSparseRowMatrix(TVec<TIntFltKdV> _RowSpVV, const int& _RowN, const int& _ColN): 
72  		TMatrix(), RowN(_RowN), ColN(_ColN), RowSpVV(_RowSpVV) {}
73      TSparseRowMatrix(const TStr& MatlabMatrixFNm);
74      void Save(TSOut& SOut) {
75          SOut.Save(RowN); SOut.Save(ColN); RowSpVV.Save(SOut); }
76      void Load(TSIn& SIn) {
77          SIn.Load(RowN); SIn.Load(ColN); RowSpVV = TVec<TIntFltKdV>(SIn); }
78  };
79  class TFullColMatrix: public TMatrix {
80  public:
81      int RowN, ColN;
82      TVec<TFltV> ColV;
83  protected:
84      virtual void PMultiply(const TFltVV& B, int ColId, TFltV& Result) const;
85      virtual void PMultiply(const TFltV& Vec, TFltV& Result) const;
86      virtual void PMultiplyT(const TFltVV& B, int ColId, TFltV& Result) const;
87      virtual void PMultiplyT(const TFltV& Vec, TFltV& Result) const;
88      int PGetRows() const { return RowN; }
89      int PGetCols() const { return ColN; }
90  public:
91      TFullColMatrix(): TMatrix() {}
92      TFullColMatrix(const TStr& MatlabMatrixFNm);
93      void Save(TSOut& SOut) { ColV.Save(SOut); }
94      void Load(TSIn& SIn) { ColV.Load(SIn); }
95  };
96  class TLinAlg {
97  public:
98      static double DotProduct(const TFltV& x, const TFltV& y);
99      static double DotProduct(const TFltVV& X, int ColIdX, const TFltVV& Y, int ColIdY);
100      static double DotProduct(const TFltVV& X, int ColId, const TFltV& Vec);
101      static double DotProduct(const TIntFltKdV& x, const TIntFltKdV& y);
102      static double DotProduct(const TFltV& x, const TIntFltKdV& y);
103      static double DotProduct(const TFltVV& X, int ColId, const TIntFltKdV& y);
104      static void LinComb(const double& p, const TFltV& x,
105          const double& q, const TFltV& y, TFltV& z);
106      static void ConvexComb(const double& p, const TFltV& x, const TFltV& y, TFltV& z);
107      static void AddVec(const double& k, const TFltV& x, const TFltV& y, TFltV& z);
108      static void AddVec(const double& k, const TIntFltKdV& x, const TFltV& y, TFltV& z);
109      static void AddVec(const double& k, const TIntFltKdV& x, TFltV& y);
110      static void AddVec(double k, const TFltVV& X, int ColIdX, TFltVV& Y, int ColIdY);
111      static void AddVec(double k, const TFltVV& X, int ColId, TFltV& Result);
112      static void AddVec(const TIntFltKdV& x, const TIntFltKdV& y, TIntFltKdV& z);
113      static double SumVec(const TFltV& x);
114      static double SumVec(double k, const TFltV& x, const TFltV& y);
115      static double EuclDist2(const TFltV& x, const TFltV& y);
116      static double EuclDist2(const TFltPr& x, const TFltPr& y);
117      static double EuclDist(const TFltV& x, const TFltV& y);
118      static double EuclDist(const TFltPr& x, const TFltPr& y);
119      static double Norm2(const TFltV& x);
120      static double Norm(const TFltV& x);
121      static void Normalize(TFltV& x);
122      static double Norm2(const TIntFltKdV& x);
123      static double Norm(const TIntFltKdV& x);
124      static void Normalize(TIntFltKdV& x);
125      static double Norm2(const TFltVV& X, int ColId);
126      static double Norm(const TFltVV& X, int ColId);
127      static double NormL1(const TFltV& x);
128      static double NormL1(double k, const TFltV& x, const TFltV& y);
129      static double NormL1(const TIntFltKdV& x);
130      static void NormalizeL1(TFltV& x);
131      static void NormalizeL1(TIntFltKdV& x);
132      static double NormLinf(const TFltV& x);
133      static double NormLinf(const TIntFltKdV& x);
134      static void NormalizeLinf(TFltV& x);
135      static void NormalizeLinf(TIntFltKdV& x);
136      static void MultiplyScalar(const double& k, const TFltV& x, TFltV& y);
137      static void MultiplyScalar(const double& k, const TIntFltKdV& x, TIntFltKdV& y);
138      static void Multiply(const TFltVV& A, const TFltV& x, TFltV& y);
139      static void Multiply(const TFltVV& A, const TFltV& x, TFltVV& C, int ColId);
140      static void Multiply(const TFltVV& A, const TFltVV& B, int ColId, TFltV& y);
141      static void Multiply(const TFltVV& A, const TFltVV& B, int ColIdB, TFltVV& C, int ColIdC);
142      static void MultiplyT(const TFltVV& A, const TFltV& x, TFltV& y);
143      static void Multiply(const TFltVV& A, const TFltVV& B, TFltVV& C);
144  	typedef enum { GEMM_NO_T = 0, GEMM_A_T = 1, GEMM_B_T = 2, GEMM_C_T = 4 } TLinAlgGemmTranspose;
145  	static void Gemm(const double& Alpha, const TFltVV& A, const TFltVV& B, const double& Beta, 
146  		const TFltVV& C, TFltVV& D, const int& TransposeFlags);
147  	typedef enum { DECOMP_SVD } TLinAlgInverseType;
148  	static void Inverse(const TFltVV& A, TFltVV& B, const TLinAlgInverseType& DecompType);
149  	static void InverseSVD(const TFltVV& A, TFltVV& B);
150  	static void Transpose(const TFltVV& A, TFltVV& B);
151      static void GS(TVec<TFltV>& Q);
152      static void GS(TFltVV& Q);
153      static void Rotate(const double& OldX, const double& OldY, const double& Angle, double& NewX, double& NewY);
154      static void AssertOrtogonality(const TVec<TFltV>& Vecs, const double& Threshold);
155      static void AssertOrtogonality(const TFltVV& Vecs, const double& Threshold);
156  };
157  class TNSException : public TExcept {
158  public:
159      TStr Message;
160  public:
161      TNSException(const TStr& Msg): TExcept(Msg) {}
162  };
163  class TNumericalStuff {
164  private:
165    static double sqr(double a);
166    static double sign(double a, double b);
167    static double pythag(double a, double b);
168    static void nrerror(const TStr& error_text);
169  public:
170      static void SymetricToTridiag(TFltVV& a, int n, TFltV& d, TFltV& e);
171  	static void EigSymmetricTridiag(TFltV& d, TFltV& e, int n, TFltVV& z);
172  	static void CholeskyDecomposition(TFltVV& A, TFltV& p);
173  	static void CholeskySolve(const TFltVV& A, const TFltV& p, const TFltV& b, TFltV& x);
174  	static void SolveSymetricSystem(TFltVV& A, const TFltV& b, TFltV& x);
175      static void InverseSubstitute(TFltVV& A, const TFltV& p);
176      static void InverseSymetric(TFltVV& A);
177      static void InverseTriagonal(TFltVV& A);
178      static void LUDecomposition(TFltVV& A, TIntV& indx, double& d);
179      static void LUSolve(const TFltVV& A, const TIntV& indx, TFltV& b);
180      static void SolveLinearSystem(TFltVV& A, const TFltV& b, TFltV& x);
181  };
182  typedef enum { ssotNoOrto, ssotSelective, ssotFull } TSpSVDReOrtoType;
183  class TSparseSVD {
184  private:
185      static void MultiplyATA(const TMatrix& Matrix,
186          const TFltVV& Vec, int ColId, TFltV& Result);
187      static void MultiplyATA(const TMatrix& Matrix,
188          const TFltV& Vec, TFltV& Result);
189  public:
190      static void SimpleLanczos(const TMatrix& Matrix,
191          const int& NumEig, TFltV& EigValV,
192          const bool& DoLocalReortoP = false,
193          const bool& SvdMatrixProductP = false);
194      static void Lanczos(const TMatrix& Matrix,
195          int NumEig, int Iters, const TSpSVDReOrtoType& ReOrtoType,
196          TFltV& EigValV, TFltVV& EigVecVV,
197          const bool& SvdMatrixProductP = false);
198      static void Lanczos2(const TMatrix& Matrix,
199          int MaxNumEig, int MaxSecs, const TSpSVDReOrtoType& ReOrtoType,
200          TFltV& EigValV, TFltVV& EigVecVV,
201          const bool& SvdMatrixProductP = false);
202      static void SimpleLanczosSVD(const TMatrix& Matrix,
203          const int& CalcSV, TFltV& SngValV,
204          const bool& DoLocalReortoP = false);
205      static void LanczosSVD(const TMatrix& Matrix,
206          int NumSV, int Iters, const TSpSVDReOrtoType& ReOrtoType,
207          TFltV& SgnValV, TFltVV& LeftSgnVecVV, TFltVV& RightSgnVecVV);
208      static void OrtoIterSVD(const TMatrix& Matrix,
209          int NumSV, int IterN, TFltV& SgnValV);
210      static void Project(const TIntFltKdV& Vec, const TFltVV& U, TFltV& ProjVec);
211  };
212  class TSigmoid {
213  private:
214      TFlt A;
215      TFlt B;
216  private:
217    static double EvaluateFit(const TFltIntKdV& data, const double A, const double B);
218    static void EvaluateFit(const TFltIntKdV& data, const double A,
219          const double B, double& J, double& JA, double& JB);
220    static void EvaluateFit(const TFltIntKdV& data, const double A,
221          const double B, const double U, const double V, const double lambda,
222      double& J, double& JJ, double& JJJ);
223  public:
224      TSigmoid() { };
225      TSigmoid(const double& A_, const double& B_): A(A_), B(B_) { };
226      TSigmoid(const TFltIntKdV& data);
227      TSigmoid(TSIn& SIn) { A.Load(SIn); B.Load(SIn); }
228      void Load(TSIn& SIn) { A.Load(SIn); B.Load(SIn); }
229      void Save(TSOut& SOut) const {A.Save(SOut); B.Save(SOut);}
230      double GetVal(const double& x) const {
231          return 1.0 / (1.0 + exp(-A * x + B)); }
232      double operator()(const double& x) const {
233          return GetVal(x); }
234      void GetSigmoidAB(double& A_, double& B_) { A_=A; B_=B; }
235  };
236  class TLAMisc {
237  public:
238      static void SaveCsvTFltV(const TFltV& Vec, TSOut& SOut);
239      static void SaveMatlabTFltIntKdV(const TIntFltKdV& SpV, const int& ColN, TSOut& SOut);
240      static void SaveMatlabTFltV(const TFltV& m, const TStr& FName);
241      static void SaveMatlabTIntV(const TIntV& m, const TStr& FName);
242      static void SaveMatlabTFltVVCol(const TFltVV& m, int ColId, const TStr& FName);
243      static void SaveMatlabTFltVV(const TFltVV& m, const TStr& FName);
244  	static void SaveMatlabTFltVVMjrSubMtrx(const TFltVV& m, int rowN, int colN, const TStr& FName);
245      static void LoadMatlabTFltVV(const TStr& FNm, TVec<TFltV>& ColV);
246      static void LoadMatlabTFltVV(const TStr& FNm, TFltVV& MatrixVV);
247      static void PrintTFltV(const TFltV& Vec, const TStr& VecNm);
248  	static void PrintTFltVV(const TFltVV& A, const TStr& MatrixNm);
249      static void PrintTIntV(const TIntV& Vec, const TStr& VecNm);
250      static void FillRnd(TFltV& Vec) { TRnd Rnd(0); FillRnd(Vec, Rnd); }
251      static void FillRnd(TFltV& Vec, TRnd& Rnd);
252      static void Fill(TFltVV& M, const double& Val);
253      static void FillZero(TFltV& Vec) { Vec.PutAll(0.0); }
254      static void FillZero(TFltVV& M) { Fill(M, 0.0); }
255      static void FillIdentity(TFltVV& M);
256      static void FillIdentity(TFltVV& M, const double& Elt);
257      static int SumVec(const TIntV& Vec);
258      static double SumVec(const TFltV& Vec);
259      static void ToSpVec(const TFltV& Vec, TIntFltKdV& SpVec,
260          const double& CutWordWgtSumPrc = 0.0);
261      static void ToVec(const TIntFltKdV& SpVec, TFltV& Vec, const int& VecLen);
262  };
263  template <class TKey, class TDat>
264  class TSparseOps {
265  private:
266  	typedef TVec<TKeyDat<TKey, TDat> > TKeyDatV;
267  public:
268  	static void SparseMerge(const TKeyDatV& SrcV1, const TKeyDatV& SrcV2, TKeyDatV& DstV) {
269  		DstV.Clr();
270  		const int Src1Len = SrcV1.Len();
271  		const int Src2Len = SrcV2.Len();
272  		int Src1N = 0, Src2N = 0;
273  		while (Src1N < Src1Len && Src2N < Src2Len) {
274  			if (SrcV1[Src1N].Key < SrcV2[Src2N].Key) { 
275  				DstV.Add(SrcV1[Src1N]); Src1N++;
276  			} else if (SrcV1[Src1N].Key > SrcV2[Src2N].Key) { 
277  				DstV.Add(SrcV2[Src2N]); Src2N++;
278  			} else { 
279  				DstV.Add(TKeyDat<TKey, TDat>(SrcV1[Src1N].Key, SrcV1[Src1N].Dat + SrcV2[Src2N].Dat));
280  				Src1N++;  Src2N++; 
281  			}
282  		}
283  		while (Src1N < Src1Len) { DstV.Add(SrcV1[Src1N]); Src1N++; }
284  		while (Src2N < Src2Len) { DstV.Add(SrcV2[Src2N]); Src2N++; }
285  	}
286  };
287  typedef TSparseOps<TInt, TFlt> TSparseOpsIntFlt;
</code></pre>
        </div>
        <div class="column">
            <h3>tesseract-MDEwOlJlcG9zaXRvcnkyMjg4NzA5NA==-flat-networkio.cpp</h3>
            <pre><code>1  #include "networkio.h"
2  #include <cfloat> 
3  #include <cmath>
4  #include <allheaders.h>
5  #include "functions.h"
6  #include "statistc.h"
7  #include "tprintf.h"
8  namespace tesseract {
9  const float kMinCertainty = -20.0f;
10  const float kMinProb = std::exp(kMinCertainty);
11  void NetworkIO::Resize2d(bool int_mode, int width, int num_features) {
12    stride_map_ = StrideMap();
13    int_mode_ = int_mode;
<span onclick='openModal()' class='match'>14    if (int_mode_) {
15      i_.ResizeNoInit(width, num_features, GetPadding(num_features));
16    } else {
17      f_.ResizeNoInit(width, num_features);
18    }
19  }
20  void NetworkIO::ResizeToMap(bool int_mode, const StrideMap &stride_map, int num_features) {
</span>21    stride_map_ = stride_map;
22    int_mode_ = int_mode;
23    if (int_mode_) {
24      i_.ResizeNoInit(stride_map.Width(), num_features, GetPadding(num_features));
25    } else {
26      f_.ResizeNoInit(stride_map.Width(), num_features);
27    }
28    ZeroInvalidElements();
29  }
30  void NetworkIO::ResizeScaled(const NetworkIO &src, int x_scale, int y_scale, int num_features) {
31    StrideMap stride_map = src.stride_map_;
32    stride_map.ScaleXY(x_scale, y_scale);
33    ResizeToMap(src.int_mode_, stride_map, num_features);
34  }
35  void NetworkIO::ResizeXTo1(const NetworkIO &src, int num_features) {
36    StrideMap stride_map = src.stride_map_;
37    stride_map.ReduceWidthTo1();
38    ResizeToMap(src.int_mode_, stride_map, num_features);
39  }
40  void NetworkIO::Zero() {
41    int width = Width();
42    for (int t = 0; t < width; ++t) {
43      ZeroTimeStep(t);
44    }
45  }
46  void NetworkIO::ZeroInvalidElements() {
47    int num_features = NumFeatures();
48    int full_width = stride_map_.Size(FD_WIDTH);
49    int full_height = stride_map_.Size(FD_HEIGHT);
50    StrideMap::Index b_index(stride_map_);
51    do {
52      int end_x = b_index.MaxIndexOfDim(FD_WIDTH) + 1;
53      if (end_x < full_width) {
54        StrideMap::Index y_index(b_index);
55        int fill_size = num_features * (full_width - end_x);
56        do {
57          StrideMap::Index z_index(y_index);
58          z_index.AddOffset(end_x, FD_WIDTH);
59          if (int_mode_) {
60            ZeroVector(fill_size, i_[z_index.t()]);
61          } else {
62            ZeroVector(fill_size, f_[z_index.t()]);
63          }
64        } while (y_index.AddOffset(1, FD_HEIGHT));
65      }
66      int end_y = b_index.MaxIndexOfDim(FD_HEIGHT) + 1;
67      if (end_y < full_height) {
68        StrideMap::Index y_index(b_index);
69        y_index.AddOffset(end_y, FD_HEIGHT);
70        int fill_size = num_features * full_width * (full_height - end_y);
71        if (int_mode_) {
72          ZeroVector(fill_size, i_[y_index.t()]);
73        } else {
74          ZeroVector(fill_size, f_[y_index.t()]);
75        }
76      }
77    } while (b_index.AddOffset(1, FD_BATCH));
78  }
79  static void ComputeBlackWhite(Image pix, float *black, float *white) {
80    int width = pixGetWidth(pix);
81    int height = pixGetHeight(pix);
82    STATS mins(0, 255), maxes(0, 255);
83    if (width >= 3) {
84      int y = height / 2;
85      l_uint32 *line = pixGetData(pix) + pixGetWpl(pix) * y;
86      int prev = GET_DATA_BYTE(line, 0);
87      int curr = GET_DATA_BYTE(line, 1);
88      for (int x = 1; x + 1 < width; ++x) {
89        int next = GET_DATA_BYTE(line, x + 1);
90        if ((curr < prev && curr <= next) || (curr <= prev && curr < next)) {
91          mins.add(curr, 1);
92        }
93        if ((curr > prev && curr >= next) || (curr >= prev && curr > next)) {
94          maxes.add(curr, 1);
95        }
96        prev = curr;
97        curr = next;
98      }
99    }
100    if (mins.get_total() == 0) {
101      mins.add(0, 1);
102    }
103    if (maxes.get_total() == 0) {
104      maxes.add(255, 1);
105    }
106    *black = mins.ile(0.25);
107    *white = maxes.ile(0.75);
108  }
109  void NetworkIO::FromPix(const StaticShape &shape, const Image pix, TRand *randomizer) {
110    std::vector<Image> pixes(1, pix);
111    FromPixes(shape, pixes, randomizer);
112  }
113  void NetworkIO::FromPixes(const StaticShape &shape, const std::vector<Image> &pixes,
114                            TRand *randomizer) {
115    int target_height = shape.height();
116    int target_width = shape.width();
117    std::vector<std::pair<int, int>> h_w_pairs;
118    for (auto &&pix : pixes) {
119      Image var_pix = pix;
120      int width = pixGetWidth(var_pix);
121      if (target_width != 0) {
122        width = target_width;
123      }
124      int height = pixGetHeight(var_pix);
125      if (target_height != 0) {
126        height = target_height;
127      }
128      h_w_pairs.emplace_back(height, width);
129    }
130    stride_map_.SetStride(h_w_pairs);
131    ResizeToMap(int_mode(), stride_map_, shape.depth());
132    for (size_t b = 0; b < pixes.size(); ++b) {
133      Image pix = pixes[b];
134      float black = 0.0f, white = 255.0f;
135      if (shape.depth() != 3) {
136        ComputeBlackWhite(pix, &black, &white);
137      }
138      float contrast = (white - black) / 2.0f;
139      if (contrast <= 0.0f) {
140        contrast = 1.0f;
141      }
142      if (shape.height() == 1) {
143        Copy1DGreyImage(b, pix, black, contrast, randomizer);
144      } else {
145        Copy2DImage(b, pix, black, contrast, randomizer);
146      }
147    }
148  }
149  void NetworkIO::Copy2DImage(int batch, Image pix, float black, float contrast, TRand *randomizer) {
150    int width = pixGetWidth(pix);
151    int height = pixGetHeight(pix);
152    int wpl = pixGetWpl(pix);
153    StrideMap::Index index(stride_map_);
154    index.AddOffset(batch, FD_BATCH);
155    int t = index.t();
156    int target_height = stride_map_.Size(FD_HEIGHT);
157    int target_width = stride_map_.Size(FD_WIDTH);
158    int num_features = NumFeatures();
159    bool color = num_features == 3;
160    if (width > target_width) {
161      width = target_width;
162    }
163    uint32_t *line = pixGetData(pix);
164    for (int y = 0; y < target_height; ++y, line += wpl) {
165      int x = 0;
166      if (y < height) {
167        for (x = 0; x < width; ++x, ++t) {
168          if (color) {
169            int f = 0;
170            for (int c = COLOR_RED; c <= COLOR_BLUE; ++c) {
171              int pixel = GET_DATA_BYTE(line + x, c);
172              SetPixel(t, f++, pixel, black, contrast);
173            }
174          } else {
175            int pixel = GET_DATA_BYTE(line, x);
176            SetPixel(t, 0, pixel, black, contrast);
177          }
178        }
179      }
180      for (; x < target_width; ++x) {
181        Randomize(t++, 0, num_features, randomizer);
182      }
183    }
184  }
185  void NetworkIO::Copy1DGreyImage(int batch, Image pix, float black, float contrast,
186                                  TRand *randomizer) {
187    int width = pixGetWidth(pix);
188    int height = pixGetHeight(pix);
189    ASSERT_HOST(height == NumFeatures());
190    int wpl = pixGetWpl(pix);
191    StrideMap::Index index(stride_map_);
192    index.AddOffset(batch, FD_BATCH);
193    int t = index.t();
194    int target_width = stride_map_.Size(FD_WIDTH);
195    if (width > target_width) {
196      width = target_width;
197    }
198    int x;
199    for (x = 0; x < width; ++x, ++t) {
200      for (int y = 0; y < height; ++y) {
201        uint32_t *line = pixGetData(pix) + wpl * y;
202        int pixel = GET_DATA_BYTE(line, x);
203        SetPixel(t, y, pixel, black, contrast);
204      }
205    }
206    for (; x < target_width; ++x) {
207      Randomize(t++, 0, height, randomizer);
208    }
209  }
210  void NetworkIO::SetPixel(int t, int f, int pixel, float black, float contrast) {
211    float float_pixel = (pixel - black) / contrast - 1.0f;
212    if (int_mode_) {
213      i_[t][f] = ClipToRange<int>(IntCastRounded((INT8_MAX + 1) * float_pixel), -INT8_MAX, INT8_MAX);
214    } else {
215      f_[t][f] = float_pixel;
216    }
217  }
218  Image NetworkIO::ToPix() const {
219    int im_width = stride_map_.Size(FD_WIDTH);
220    int im_height = stride_map_.Size(FD_HEIGHT);
221    int num_features = NumFeatures();
222    int feature_factor = 1;
223    if (num_features == 3) {
224      num_features = 1;
225      feature_factor = 3;
226    }
227    Image pix = pixCreate(im_width, im_height * num_features, 32);
228    StrideMap::Index index(stride_map_);
229    do {
230      int im_x = index.index(FD_WIDTH);
231      int top_im_y = index.index(FD_HEIGHT);
232      int im_y = top_im_y;
233      int t = index.t();
234      if (int_mode_) {
235        const int8_t *features = i_[t];
236        for (int y = 0; y < num_features; ++y, im_y += im_height) {
237          int pixel = features[y * feature_factor];
238          int red = ClipToRange<int>(pixel + 128, 0, 255);
239          int green = red, blue = red;
240          if (feature_factor == 3) {
241            green = ClipToRange<int>(features[y * feature_factor + 1] + 128, 0, 255);
242            blue = ClipToRange<int>(features[y * feature_factor + 2] + 128, 0, 255);
243          } else if (num_features > 3) {
244            red = abs(pixel) * 2;
245            if (pixel >= 0) {
246              green = red;
247              blue = 0;
248            } else {
249              blue = red;
250              green = red = 0;
251            }
252          }
253          pixSetPixel(pix, im_x, im_y,
254                      (red << L_RED_SHIFT) | (green << L_GREEN_SHIFT) | (blue << L_BLUE_SHIFT));
255        }
256      } else {
257        const float *features = f_[t];
258        for (int y = 0; y < num_features; ++y, im_y += im_height) {
259          float pixel = features[y * feature_factor];
260          int red = ClipToRange<int>(IntCastRounded((pixel + 1.0f) * 127.5f), 0, 255);
261          int green = red, blue = red;
262          if (feature_factor == 3) {
263            pixel = features[y * feature_factor + 1];
264            green = ClipToRange<int>(IntCastRounded((pixel + 1.0f) * 127.5f), 0, 255);
265            pixel = features[y * feature_factor + 2];
266            blue = ClipToRange<int>(IntCastRounded((pixel + 1.0f) * 127.5f), 0, 255);
267          } else if (num_features > 3) {
268            red = ClipToRange<int>(IntCastRounded(std::fabs(pixel) * 255), 0, 255);
269            if (pixel >= 0) {
270              green = red;
271              blue = 0;
272            } else {
273              blue = red;
274              green = red = 0;
275            }
276          }
277          pixSetPixel(pix, im_x, im_y,
278                      (red << L_RED_SHIFT) | (green << L_GREEN_SHIFT) | (blue << L_BLUE_SHIFT));
279        }
280      }
281    } while (index.Increment());
282    return pix;
283  }
284  void NetworkIO::Print(int num) const {
285    int num_features = NumFeatures();
286    for (int y = 0; y < num_features; ++y) {
287      for (int t = 0; t < Width(); ++t) {
288        if (num == 0 || t < num || t + num >= Width()) {
289          if (int_mode_) {
290            tprintf(" %g", static_cast<float>(i_[t][y]) / INT8_MAX);
291          } else {
292            tprintf(" %g", f_[t][y]);
293          }
294        }
295      }
296      tprintf("\n");
297    }
298  }
299  void NetworkIO::CopyTimeStepFrom(int dest_t, const NetworkIO &src, int src_t) {
300    ASSERT_HOST(int_mode_ == src.int_mode_);
301    if (int_mode_) {
302      memcpy(i_[dest_t], src.i_[src_t], i_.dim2() * sizeof(i_[0][0]));
303    } else {
304      memcpy(f_[dest_t], src.f_[src_t], f_.dim2() * sizeof(f_[0][0]));
305    }
306  }
307  void NetworkIO::CopyTimeStepGeneral(int dest_t, int dest_offset, int num_features,
308                                      const NetworkIO &src, int src_t, int src_offset) {
309    ASSERT_HOST(int_mode_ == src.int_mode_);
310    if (int_mode_) {
311      memcpy(i_[dest_t] + dest_offset, src.i_[src_t] + src_offset, num_features * sizeof(i_[0][0]));
312    } else {
313      memcpy(f_[dest_t] + dest_offset, src.f_[src_t] + src_offset, num_features * sizeof(f_[0][0]));
314    }
315  }
316  void NetworkIO::Randomize(int t, int offset, int num_features, TRand *randomizer) {
317    if (int_mode_) {
318      int8_t *line = i_[t] + offset;
319      for (int i = 0; i < num_features; ++i) {
320        line[i] = IntCastRounded(randomizer->SignedRand(INT8_MAX));
321      }
322    } else {
323      float *line = f_[t] + offset;
324      for (int i = 0; i < num_features; ++i) {
325        line[i] = randomizer->SignedRand(1.0);
326      }
327    }
328  }
329  int NetworkIO::BestChoiceOverRange(int t_start, int t_end, int not_this, int null_ch, float *rating,
330                                     float *certainty) const {
331    if (t_end <= t_start) {
332      return -1;
333    }
334    int max_char = -1;
335    float min_score = 0.0f;
336    for (int c = 0; c < NumFeatures(); ++c) {
337      if (c == not_this || c == null_ch) {
338        continue;
339      }
340      ScoresOverRange(t_start, t_end, c, null_ch, rating, certainty);
341      if (max_char < 0 || *rating < min_score) {
342        min_score = *rating;
343        max_char = c;
344      }
345    }
346    ScoresOverRange(t_start, t_end, max_char, null_ch, rating, certainty);
347    return max_char;
348  }
349  void NetworkIO::ScoresOverRange(int t_start, int t_end, int choice, int null_ch, float *rating,
350                                  float *certainty) const {
351    ASSERT_HOST(!int_mode_);
352    *rating = 0.0f;
353    *certainty = 0.0f;
354    if (t_end <= t_start || t_end <= 0) {
355      return;
356    }
357    float ratings[3] = {0.0f, 0.0f, 0.0f};
358    float certs[3] = {0.0f, 0.0f, 0.0f};
359    for (int t = t_start; t < t_end; ++t) {
360      const float *line = f_[t];
361      float score = ProbToCertainty(line[choice]);
362      float zero = ProbToCertainty(line[null_ch]);
363      if (t == t_start) {
364        ratings[2] = FLT_MAX;
365        ratings[1] = -score;
366        certs[1] = score;
367      } else {
368        for (int i = 2; i >= 1; --i) {
369          if (ratings[i] > ratings[i - 1]) {
370            ratings[i] = ratings[i - 1];
371            certs[i] = certs[i - 1];
372          }
373        }
374        ratings[2] -= zero;
375        if (zero < certs[2]) {
376          certs[2] = zero;
377        }
378        ratings[1] -= score;
379        if (score < certs[1]) {
380          certs[1] = score;
381        }
382      }
383      ratings[0] -= zero;
384      if (zero < certs[0]) {
385        certs[0] = zero;
386      }
387    }
388    int best_i = ratings[2] < ratings[1] ? 2 : 1;
389    *rating = ratings[best_i] + t_end - t_start;
390    *certainty = certs[best_i];
391  }
392  int NetworkIO::BestLabel(int t, int not_this, int not_that, float *score) const {
393    ASSERT_HOST(!int_mode_);
394    int best_index = -1;
395    float best_score = -FLT_MAX;
396    const float *line = f_[t];
397    for (int i = 0; i < f_.dim2(); ++i) {
398      if (line[i] > best_score && i != not_this && i != not_that) {
399        best_score = line[i];
400        best_index = i;
401      }
402    }
403    if (score != nullptr) {
404      *score = ProbToCertainty(best_score);
405    }
406    return best_index;
407  }
408  int NetworkIO::PositionOfBestMatch(const std::vector<int> &labels, int start, int end) const {
409    int length = labels.size();
410    int last_start = end - length;
411    int best_start = -1;
412    TFloat best_score = 0;
413    for (int s = start; s <= last_start; ++s) {
414      TFloat score = ScoreOfLabels(labels, s);
415      if (score > best_score || best_start < 0) {
416        best_score = score;
417        best_start = s;
418      }
419    }
420    return best_start;
421  }
422  TFloat NetworkIO::ScoreOfLabels(const std::vector<int> &labels, int start) const {
423    int length = labels.size();
424    TFloat score = 0;
425    for (int i = 0; i < length; ++i) {
426      score += f_(start + i, labels[i]);
427    }
428    return score;
429  }
430  void NetworkIO::SetActivations(int t, int label, float ok_score) {
431    ASSERT_HOST(!int_mode_);
432    int num_classes = NumFeatures();
433    float bad_score = (1.0f - ok_score) / (num_classes - 1);
434    float *targets = f_[t];
435    for (int i = 0; i < num_classes; ++i) {
436      targets[i] = bad_score;
437    }
438    targets[label] = ok_score;
439  }
440  void NetworkIO::EnsureBestLabel(int t, int label) {
441    ASSERT_HOST(!int_mode_);
442    if (BestLabel(t, nullptr) != label) {
443      int num_classes = NumFeatures();
444      float *targets = f_[t];
445      for (int c = 0; c < num_classes; ++c) {
446        if (c == label) {
447          targets[c] += (1.0 - targets[c]) * (2 / 3.0);
448        } else {
449          targets[c] /= 3.0;
450        }
451      }
452    }
453  }
454  float NetworkIO::ProbToCertainty(float prob) {
455    return prob > kMinProb ? std::log(prob) : kMinCertainty;
456  }
457  bool NetworkIO::AnySuspiciousTruth(float confidence_thr) const {
458    int num_features = NumFeatures();
459    for (int t = 0; t < Width(); ++t) {
460      const float *features = f_[t];
461      for (int y = 0; y < num_features; ++y) {
462        float grad = features[y];
463        if (grad < -confidence_thr) {
464          if ((t == 0 || f_[t - 1][y] < confidence_thr / 2) &&
465              (t + 1 == Width() || f_[t + 1][y] < confidence_thr / 2)) {
466            return true; 
467          }
468        }
469      }
470    }
471    return false;
472  }
473  void NetworkIO::ReadTimeStep(int t, TFloat *output) const {
474    if (int_mode_) {
475      const int8_t *line = i_[t];
476      for (int i = 0; i < i_.dim2(); ++i) {
477        output[i] = static_cast<TFloat>(line[i]) / INT8_MAX;
478      }
479    } else {
480      const float *line = f_[t];
481      for (int i = 0; i < f_.dim2(); ++i) {
482        output[i] = static_cast<TFloat>(line[i]);
483      }
484    }
485  }
486  void NetworkIO::AddTimeStep(int t, TFloat *inout) const {
487    int num_features = NumFeatures();
488    if (int_mode_) {
489      const int8_t *line = i_[t];
490      for (int i = 0; i < num_features; ++i) {
491        inout[i] += static_cast<TFloat>(line[i]) / INT8_MAX;
492      }
493    } else {
494      const float *line = f_[t];
495      for (int i = 0; i < num_features; ++i) {
496        inout[i] += line[i];
497      }
498    }
499  }
500  void NetworkIO::AddTimeStepPart(int t, int offset, int num_features, float *inout) const {
501    if (int_mode_) {
502      const int8_t *line = i_[t] + offset;
503      for (int i = 0; i < num_features; ++i) {
504        inout[i] += static_cast<float>(line[i]) / INT8_MAX;
505      }
506    } else {
507      const float *line = f_[t] + offset;
508      for (int i = 0; i < num_features; ++i) {
509        inout[i] += line[i];
510      }
511    }
512  }
513  void NetworkIO::WriteTimeStep(int t, const TFloat *input) {
514    WriteTimeStepPart(t, 0, NumFeatures(), input);
515  }
516  void NetworkIO::WriteTimeStepPart(int t, int offset, int num_features, const TFloat *input) {
517    if (int_mode_) {
518      int8_t *line = i_[t] + offset;
519      for (int i = 0; i < num_features; ++i) {
520        line[i] = ClipToRange<int>(IntCastRounded(input[i] * INT8_MAX), -INT8_MAX, INT8_MAX);
521      }
522    } else {
523      float *line = f_[t] + offset;
524      for (int i = 0; i < num_features; ++i) {
525        line[i] = static_cast<float>(input[i]);
526      }
527    }
528  }
529  void NetworkIO::MaxpoolTimeStep(int dest_t, const NetworkIO &src, int src_t, int *max_line) {
530    ASSERT_HOST(int_mode_ == src.int_mode_);
531    if (int_mode_) {
532      int dim = i_.dim2();
533      int8_t *dest_line = i_[dest_t];
534      const int8_t *src_line = src.i_[src_t];
535      for (int i = 0; i < dim; ++i) {
536        if (dest_line[i] < src_line[i]) {
537          dest_line[i] = src_line[i];
538          max_line[i] = src_t;
539        }
540      }
541    } else {
542      int dim = f_.dim2();
543      float *dest_line = f_[dest_t];
544      const float *src_line = src.f_[src_t];
545      for (int i = 0; i < dim; ++i) {
546        if (dest_line[i] < src_line[i]) {
547          dest_line[i] = src_line[i];
548          max_line[i] = src_t;
549        }
550      }
551    }
552  }
553  void NetworkIO::MaxpoolBackward(const NetworkIO &fwd, const GENERIC_2D_ARRAY<int> &maxes) {
554    ASSERT_HOST(!int_mode_);
555    Zero();
556    StrideMap::Index index(fwd.stride_map_);
557    do {
558      int t = index.t();
559      const int *max_line = maxes[t];
560      const float *fwd_line = fwd.f_[t];
561      int num_features = fwd.f_.dim2();
562      for (int i = 0; i < num_features; ++i) {
563        f_[max_line[i]][i] = fwd_line[i];
564      }
565    } while (index.Increment());
566  }
567  float NetworkIO::MinOfMaxes() const {
568    float min_max = 0.0f;
569    int width = Width();
570    int num_features = NumFeatures();
571    for (int t = 0; t < width; ++t) {
572      float max_value = -FLT_MAX;
573      if (int_mode_) {
574        const int8_t *column = i_[t];
575        for (int i = 0; i < num_features; ++i) {
576          if (column[i] > max_value) {
577            max_value = column[i];
578          }
579        }
580      } else {
581        const float *column = f_[t];
582        for (int i = 0; i < num_features; ++i) {
583          if (column[i] > max_value) {
584            max_value = column[i];
585          }
586        }
587      }
588      if (t == 0 || max_value < min_max) {
589        min_max = max_value;
590      }
591    }
592    return min_max;
593  }
594  void NetworkIO::CombineOutputs(const NetworkIO &base_output, const NetworkIO &combiner_output) {
595    int no = base_output.NumFeatures();
596    ASSERT_HOST(combiner_output.NumFeatures() == no + 1);
597    Resize(base_output, no);
598    int width = Width();
599    if (int_mode_) {
600      for (int t = 0; t < width; ++t) {
601        int8_t *out_line = i_[t];
602        const int8_t *base_line = base_output.i_[t];
603        const int8_t *comb_line = combiner_output.i_[t];
604        float base_weight = static_cast<float>(comb_line[no]) / INT8_MAX;
605        float boost_weight = 1.0f - base_weight;
606        for (int i = 0; i < no; ++i) {
607          out_line[i] = IntCastRounded(base_line[i] * base_weight + comb_line[i] * boost_weight);
608        }
609      }
610    } else {
611      for (int t = 0; t < width; ++t) {
612        float *out_line = f_[t];
613        const float *base_line = base_output.f_[t];
614        const float *comb_line = combiner_output.f_[t];
615        float base_weight = comb_line[no];
616        float boost_weight = 1.0f - base_weight;
617        for (int i = 0; i < no; ++i) {
618          out_line[i] = base_line[i] * base_weight + comb_line[i] * boost_weight;
619        }
620      }
621    }
622  }
623  void NetworkIO::ComputeCombinerDeltas(const NetworkIO &fwd_deltas, const NetworkIO &base_output) {
624    ASSERT_HOST(!int_mode_);
625    int width = Width();
626    int no = NumFeatures() - 1;
627    ASSERT_HOST(fwd_deltas.NumFeatures() == no);
628    ASSERT_HOST(base_output.NumFeatures() == no);
629    for (int t = 0; t < width; ++t) {
630      const float *delta_line = fwd_deltas.f_[t];
631      const float *base_line = base_output.f_[t];
632      float *comb_line = f_[t];
633      float base_weight = comb_line[no];
634      float boost_weight = 1.0f - base_weight;
635      float max_base_delta = 0.0;
636      for (int i = 0; i < no; ++i) {
637        float output = base_line[i] * base_weight + comb_line[i] * boost_weight;
638        float comb_target = delta_line[i] + output;
639        comb_line[i] = comb_target - comb_line[i];
640        float base_delta = std::fabs(comb_target - base_line[i]);
641        if (base_delta > max_base_delta) {
642          max_base_delta = base_delta;
643        }
644      }
645      if (max_base_delta >= 0.5) {
646        comb_line[no] = 0.0 - base_weight;
647      } else {
648        for (int i = 0; i < no; ++i) {
649          if (comb_line[i] > 0.0) {
650            comb_line[i] -= 1.0;
651          }
652        }
653        comb_line[no] = 1.0 - base_weight;
654      }
655    }
656  }
657  void NetworkIO::CopyAll(const NetworkIO &src) {
658    ASSERT_HOST(src.int_mode_ == int_mode_);
659    f_ = src.f_;
660  }
661  void NetworkIO::AddAllToFloat(const NetworkIO &src) {
662    ASSERT_HOST(!int_mode_);
663    ASSERT_HOST(!src.int_mode_);
664    f_ += src.f_;
665  }
666  void NetworkIO::SubtractAllFromFloat(const NetworkIO &src) {
667    ASSERT_HOST(!int_mode_);
668    ASSERT_HOST(!src.int_mode_);
669    f_ -= src.f_;
670  }
671  void NetworkIO::CopyWithNormalization(const NetworkIO &src, const NetworkIO &scale) {
672    ASSERT_HOST(!int_mode_);
673    ASSERT_HOST(!src.int_mode_);
674    ASSERT_HOST(!scale.int_mode_);
675    float src_max = src.f_.MaxAbs();
676    ASSERT_HOST(std::isfinite(src_max));
677    float scale_max = scale.f_.MaxAbs();
678    ASSERT_HOST(std::isfinite(scale_max));
679    if (src_max > 0.0f) {
680      float factor = scale_max / src_max;
681      for (int t = 0; t < src.Width(); ++t) {
682        const float *src_ptr = src.f_[t];
683        float *dest_ptr = f_[t];
684        for (int i = 0; i < src.f_.dim2(); ++i) {
685          dest_ptr[i] = src_ptr[i] * factor;
686        }
687      }
688    } else {
689      f_.Clear();
690    }
691  }
692  void NetworkIO::CopyWithYReversal(const NetworkIO &src) {
693    int num_features = src.NumFeatures();
694    Resize(src, num_features);
695    StrideMap::Index b_index(src.stride_map_);
696    do {
697      int width = b_index.MaxIndexOfDim(FD_WIDTH) + 1;
698      StrideMap::Index fwd_index(b_index);
699      StrideMap::Index rev_index(b_index);
700      rev_index.AddOffset(rev_index.MaxIndexOfDim(FD_HEIGHT), FD_HEIGHT);
701      do {
702        int fwd_t = fwd_index.t();
703        int rev_t = rev_index.t();
704        for (int x = 0; x < width; ++x) {
705          CopyTimeStepFrom(rev_t++, src, fwd_t++);
706        }
707      } while (fwd_index.AddOffset(1, FD_HEIGHT) && rev_index.AddOffset(-1, FD_HEIGHT));
708    } while (b_index.AddOffset(1, FD_BATCH));
709  }
710  void NetworkIO::CopyWithXReversal(const NetworkIO &src) {
711    int num_features = src.NumFeatures();
712    Resize(src, num_features);
713    StrideMap::Index b_index(src.stride_map_);
714    do {
715      StrideMap::Index y_index(b_index);
716      do {
717        StrideMap::Index fwd_index(y_index);
718        StrideMap::Index rev_index(y_index);
719        rev_index.AddOffset(rev_index.MaxIndexOfDim(FD_WIDTH), FD_WIDTH);
720        do {
721          CopyTimeStepFrom(rev_index.t(), src, fwd_index.t());
722        } while (fwd_index.AddOffset(1, FD_WIDTH) && rev_index.AddOffset(-1, FD_WIDTH));
723      } while (y_index.AddOffset(1, FD_HEIGHT));
724    } while (b_index.AddOffset(1, FD_BATCH));
725  }
726  void NetworkIO::CopyWithXYTranspose(const NetworkIO &src) {
727    int num_features = src.NumFeatures();
728    stride_map_ = src.stride_map_;
729    stride_map_.TransposeXY();
730    ResizeToMap(src.int_mode(), stride_map_, num_features);
731    StrideMap::Index src_b_index(src.stride_map_);
732    StrideMap::Index dest_b_index(stride_map_);
733    do {
734      StrideMap::Index src_y_index(src_b_index);
735      StrideMap::Index dest_x_index(dest_b_index);
736      do {
737        StrideMap::Index src_x_index(src_y_index);
738        StrideMap::Index dest_y_index(dest_x_index);
739        do {
740          CopyTimeStepFrom(dest_y_index.t(), src, src_x_index.t());
741        } while (src_x_index.AddOffset(1, FD_WIDTH) && dest_y_index.AddOffset(1, FD_HEIGHT));
742      } while (src_y_index.AddOffset(1, FD_HEIGHT) && dest_x_index.AddOffset(1, FD_WIDTH));
743    } while (src_b_index.AddOffset(1, FD_BATCH) && dest_b_index.AddOffset(1, FD_BATCH));
744  }
745  int NetworkIO::CopyPacking(const NetworkIO &src, int feature_offset) {
746    ASSERT_HOST(int_mode_ == src.int_mode_);
747    int width = src.Width();
748    ASSERT_HOST(width <= Width());
749    int num_features = src.NumFeatures();
750    ASSERT_HOST(num_features + feature_offset <= NumFeatures());
751    if (int_mode_) {
752      for (int t = 0; t < width; ++t) {
753        memcpy(i_[t] + feature_offset, src.i_[t], num_features * sizeof(i_[t][0]));
754      }
755      for (int t = width; t < i_.dim1(); ++t) {
756        memset(i_[t], 0, num_features * sizeof(i_[t][0]));
757      }
758    } else {
759      for (int t = 0; t < width; ++t) {
760        memcpy(f_[t] + feature_offset, src.f_[t], num_features * sizeof(f_[t][0]));
761      }
762      for (int t = width; t < f_.dim1(); ++t) {
763        memset(f_[t], 0, num_features * sizeof(f_[t][0]));
764      }
765    }
766    return num_features + feature_offset;
767  }
768  void NetworkIO::CopyUnpacking(const NetworkIO &src, int feature_offset, int num_features) {
769    Resize(src, num_features);
770    int width = src.Width();
771    ASSERT_HOST(num_features + feature_offset <= src.NumFeatures());
772    if (int_mode_) {
773      for (int t = 0; t < width; ++t) {
774        memcpy(i_[t], src.i_[t] + feature_offset, num_features * sizeof(i_[t][0]));
775      }
776    } else {
777      for (int t = 0; t < width; ++t) {
778        memcpy(f_[t], src.f_[t] + feature_offset, num_features * sizeof(f_[t][0]));
779      }
780    }
781  }
782  void NetworkIO::Transpose(TransposedArray *dest) const {
783    int width = Width();
784    dest->ResizeNoInit(NumFeatures(), width);
785    for (int t = 0; t < width; ++t) {
786      dest->WriteStrided(t, f_[t]);
787    }
788  }
789  void NetworkIO::ClipVector(int t, float range) {
790    ASSERT_HOST(!int_mode_);
791    float *v = f_[t];
792    int dim = f_.dim2();
793    for (int i = 0; i < dim; ++i) {
794      v[i] = ClipToRange<float>(v[i], -range, range);
795    }
796  }
797  int NetworkIO::GetPadding(int num_features) {
798    int padding = 0;
799    if (IntSimdMatrix::intSimdMatrix) {
800      padding = IntSimdMatrix::intSimdMatrix->RoundInputs(num_features) - num_features;
801    }
802    return padding;
803  }
804  } 
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from snap-MDEwOlJlcG9zaXRvcnk0Mjg4MzU3-flat-linalg.h</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from tesseract-MDEwOlJlcG9zaXRvcnkyMjg4NzA5NA==-flat-networkio.cpp</div>
                </div>
                <div class="column column_space"><pre><code>21          if (Transposed) { PMultiplyT(Vec, Result); }
22          else { PMultiply(Vec, Result); }
23      }
24      void MultiplyT(const TFltVV& B, int ColId, TFltV& Result) const {
</pre></code></div>
                <div class="column column_space"><pre><code>14    if (int_mode_) {
15      i_.ResizeNoInit(width, num_features, GetPadding(num_features));
16    } else {
17      f_.ResizeNoInit(width, num_features);
18    }
19  }
20  void NetworkIO::ResizeToMap(bool int_mode, const StrideMap &stride_map, int num_features) {
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    