<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for test_mysql_2.py &amp; virt_1.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for test_mysql_2.py &amp; virt_1.py
      </h3>
<h1 align="center">
        2.8%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>test_mysql_2.py (11.025641%)<th>virt_1.py (1.663014%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(50-145)<td><a href="#" name="0">(7723-7809)</a><td align="center"><font color="#ff0000">20</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(691-695)<td><a href="#" name="1">(5691-5693)</a><td align="center"><font color="#cc0000">16</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(715-719)<td><a href="#" name="2">(6511-6521)</a><td align="center"><font color="#bf0000">15</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(703-707)<td><a href="#" name="3">(3110-3114)</a><td align="center"><font color="#b20000">14</font>
<tr onclick='openModal("#6cc417")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#6cc417"><font color="#6cc417">-</font><td><a href="#" name="4">(179-227)<td><a href="#" name="4">(3984-4002)</a><td align="center"><font color="#b20000">14</font>
<tr onclick='openModal("#151b8d")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#151b8d"><font color="#151b8d">-</font><td><a href="#" name="5">(785-788)<td><a href="#" name="5">(7820-7829)</a><td align="center"><font color="#a50000">13</font>
<tr onclick='openModal("#8c8774")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#8c8774"><font color="#8c8774">-</font><td><a href="#" name="6">(31-42)<td><a href="#" name="6">(1931-1940)</a><td align="center"><font color="#a50000">13</font>
<tr onclick='openModal("#38a4a5")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#38a4a5"><font color="#38a4a5">-</font><td><a href="#" name="7">(556-560)<td><a href="#" name="7">(6497-6505)</a><td align="center"><font color="#990000">12</font>
<tr onclick='openModal("#c58917")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#c58917"><font color="#c58917">-</font><td><a href="#" name="8">(519-522)<td><a href="#" name="8">(4487-4492)</a><td align="center"><font color="#990000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_mysql_2.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import salt.pillar.mysql as mysql
2 from tests.support.unit import TestCase, skipIf
3 @skipIf(mysql.MySQLdb is None, "MySQL-python module not installed")
4 class MysqlPillarTestCase(TestCase):
5     maxDiff = None
6     def test_001_extract_queries_legacy(self):
7         return_data = mysql.MySQLExtPillar()
8         args, kwargs = ["SELECT blah"], {}
9         qbuffer = return_data.extract_queries(args, kwargs)
10         self.assertEqual(
11             [
12                 [
13                     None,
14                     {
15                         "query": "SELECT blah",
16                         "depth": 0,
17                         "as_list": False,
18                         "as_json": False,
19                         "with_lists": None,
20                         "ignore_null": False,
21                     },
22                 ]
23             ],
24             qbuffer,
25     def test_002_extract_queries_list(self):
26         return_data <font color="#8c8774"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>= mysql.MySQLExtPillar()
27         args, kwargs = (
28             [
29                 "SELECT blah",
30                 "SELECT blah2",
31                 ("SELECT blah3",),
32                 ("SELECT blah4", 2),
33                 {"query": "SELECT blah5"},
34                 {"query": "SELECT blah6", "depth": 2},
35                 {"query": "SELECT blah7", "as_list": True},
36                 {"query": "SELECT blah8", "with_lists": "1"},
37                 {"query"</b></font>: "SELECT blah9", "with_lists": "1,2"},
38                 {"query": "SELECT json1", "as_json": True},
39             ],
40             {},
41         )
42         self.assertEqual(
43             [
44                 <font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>[
45                     None,
46                     {
47                         "query": "SELECT blah",
48                         "depth": 0,
49                         "as_list": False,
50                         "as_json": False,
51                         "with_lists": None,
52                         "ignore_null": False,
53                     },
54                 ],
55                 [
56                     None,
57                     {
58                         "query": "SELECT blah2",
59                         "depth": 0,
60                         "as_list": False,
61                         "as_json": False,
62                         "with_lists": None,
63                         "ignore_null": False,
64                     },
65                 ],
66                 [
67                     None,
68                     {
69                         "query": "SELECT blah3",
70                         "depth": 0,
71                         "as_list": False,
72                         "as_json": False,
73                         "with_lists": None,
74                         "ignore_null": False,
75                     },
76                 ],
77                 [
78                     None,
79                     {
80                         "query": "SELECT blah4",
81                         "depth": 2,
82                         "as_list": False,
83                         "as_json": False,
84                         "with_lists": None,
85                         "ignore_null": False,
86                     },
87                 ],
88                 [
89                     None,
90                     {
91                         "query": "SELECT blah5",
92                         "depth": 0,
93                         "as_list": False,
94                         "as_json": False,
95                         "with_lists": None,
96                         "ignore_null": False,
97                     },
98                 ],
99                 [
100                     None,
101                     {
102                         "query": "SELECT blah6",
103                         "depth": 2,
104                         "as_list": False,
105                         "as_json": False,
106                         "with_lists": None,
107                         "ignore_null": False,
108                     },
109                 ],
110                 [
111                     None,
112                     {
113                         "query": "SELECT blah7",
114                         "depth": 0,
115                         "as_list": True,
116                         "as_json": False,
117                         "with_lists": None,
118                         "ignore_null": False,
119                     },
120                 ],
121                 [
122                     None,
123                     {
124                         "query": "SELECT blah8",
125                         "depth": 0,
126                         "as_list": False,
127                         "as_json": False,
128                         "with_lists": [1],
129                         "ignore_null": False,
130                     },
131                 ],
132                 [
133                     None,
134                     {
135                         "query": "SELECT blah9",
136                         "depth": 0,
137                         "as_list": False,
138                         "as_json": False,
139                         "with_lists": [1</b></font>, 2],
140                         "ignore_null": False,
141                     },
142                 ],
143                 [
144                     None,
145                     {
146                         "query": "SELECT json1",
147                         "depth": 0,
148                         "as_list": False,
149                         "as_json": True,
150                         "with_lists": None,
151                         "ignore_null": False,
152                     },
153                 ],
154             ],
155             qbuffer,
156         )
157     def test_003_extract_queries_kwarg(self):
158         return_data = mysql.MySQLExtPillar()
159         args, kwargs = (
160             [],
161             {
162                 "1": "SELECT blah",
163                 "2": "SELECT blah2",
164                 "3": ("SELECT blah3",),
165                 "4": ("SELECT blah4", 2),
166                 "5": {"query": "SELECT blah5"},
167                 "6": {"query": "SELECT blah6", "depth": 2},
168                 "7": {"query": "SELECT blah7", "as_list": True},
169             },
170         )
171         qbuffer = return_data<font color="#6cc417"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.extract_queries(args, kwargs)
172         self.assertEqual(
173             [
174                 [
175                     "1",
176                     {
177                         "query": "SELECT blah",
178                         "depth": 0,
179                         "as_list": False,
180                         "as_json": False,
181                         "with_lists": None,
182                         "ignore_null": False,
183                     },
184                 ],
185                 [
186                     "2",
187                     {
188                         "query": "SELECT blah2",
189                         "depth": 0,
190                         "as_list": False,
191                         "as_json": False,
192                         "with_lists": None,
193                         "ignore_null": False,
194                     },
195                 ],
196                 [
197                     "3",
198                     {
199                         "query": "SELECT blah3",
200                         "depth": 0,
201                         "as_list": False,
202                         "as_json": False,
203                         "with_lists": None,
204                         "ignore_null": False,
205                     },
206                 ],
207                 [
208                     "4",
209                     {
210                         "query": "SELECT blah4",
211                         "depth": 2,
212                         "as_list": False,
213                         "as_json": False,
214                         "with_lists": None,
215                         "ignore_null": False,
216                     },
217                 ],
218                 [
219                     "5"</b></font>,
220                     {
221                         "query": "SELECT blah5",
222                         "depth": 0,
223                         "as_list": False,
224                         "as_json": False,
225                         "with_lists": None,
226                         "ignore_null": False,
227                     },
228                 ],
229                 [
230                     "6",
231                     {
232                         "query": "SELECT blah6",
233                         "depth": 2,
234                         "as_list": False,
235                         "as_json": False,
236                         "with_lists": None,
237                         "ignore_null": False,
238                     },
239                 ],
240                 [
241                     "7",
242                     {
243                         "query": "SELECT blah7",
244                         "depth": 0,
245                         "as_list": True,
246                         "as_json": False,
247                         "with_lists": None,
248                         "ignore_null": False,
249                     },
250                 ],
251                 [
252                     "8",
253                     {
254                         "query": "SELECT json1",
255                         "depth": 0,
256                         "as_list": False,
257                         "as_json": True,
258                         "with_lists": None,
259                         "ignore_null": False,
260                     },
261                 ],
262             ],
263             qbuffer,
264         )
265     def test_004_extract_queries_mixed(self):
266         return_data = mysql.MySQLExtPillar()
267         args, kwargs = (
268             [
269                 "SELECT blah1",
270                 ("SELECT blah2", 2),
271                 {"query": "SELECT blah3", "as_list": True},
272             ],
273             {
274                 "1": "SELECT blah1",
275                 "2": ("SELECT blah2", 2),
276                 "3": {"query": "SELECT blah3", "as_list": True},
277             },
278         )
279         qbuffer = return_data.extract_queries(args, kwargs)
280         self.assertEqual(
281             [
282                 [
283                     None,
284                     {
285                         "query": "SELECT blah1",
286                         "depth": 0,
287                         "as_list": False,
288                         "as_json": False,
289                         "with_lists": None,
290                         "ignore_null": False,
291                     },
292                 ],
293                 [
294                     None,
295                     {
296                         "query": "SELECT blah2",
297                         "depth": 2,
298                         "as_list": False,
299                         "as_json": False,
300                         "with_lists": None,
301                         "ignore_null": False,
302                     },
303                 ],
304                 [
305                     None,
306                     {
307                         "query": "SELECT blah3",
308                         "depth": 0,
309                         "as_list": True,
310                         "as_json": False,
311                         "with_lists": None,
312                         "ignore_null": False,
313                     },
314                 ],
315                 [
316                     "1",
317                     {
318                         "query": "SELECT blah1",
319                         "depth": 0,
320                         "as_list": False,
321                         "as_json": False,
322                         "with_lists": None,
323                         "ignore_null": False,
324                     },
325                 ],
326                 [
327                     "2",
328                     {
329                         "query": "SELECT blah2",
330                         "depth": 2,
331                         "as_list": False,
332                         "as_json": False,
333                         "with_lists": None,
334                         "ignore_null": False,
335                     },
336                 ],
337                 [
338                     "3",
339                     {
340                         "query": "SELECT blah3",
341                         "depth": 0,
342                         "as_list": True,
343                         "as_json": False,
344                         "with_lists": None,
345                         "ignore_null": False,
346                     },
347                 ],
348             ],
349             qbuffer,
350         )
351     def test_005_extract_queries_bogus_list(self):
352         return_data = mysql.MySQLExtPillar()
353         args, kwargs = (
354             [
355                 "SELECT blah",
356                 "",
357                 "SELECT blah2",
358                 ("SELECT blah3",),
359                 ("",),
360                 ("SELECT blah4", 2),
361                 tuple(),
362                 ("SELECT blah5",),
363                 {"query": "SELECT blah6"},
364                 {"query": ""},
365                 {"query": "SELECT blah7", "depth": 2},
366                 {"not_a_query": "in sight!"},
367                 {"query": "SELECT blah8", "as_list": True},
368             ],
369             {},
370         )
371         qbuffer = return_data.extract_queries(args, kwargs)
372         self.assertEqual(
373             [
374                 [
375                     None,
376                     {
377                         "query": "SELECT blah",
378                         "depth": 0,
379                         "as_list": False,
380                         "as_json": False,
381                         "with_lists": None,
382                         "ignore_null": False,
383                     },
384                 ],
385                 [
386                     None,
387                     {
388                         "query": "SELECT blah2",
389                         "depth": 0,
390                         "as_list": False,
391                         "as_json": False,
392                         "with_lists": None,
393                         "ignore_null": False,
394                     },
395                 ],
396                 [
397                     None,
398                     {
399                         "query": "SELECT blah3",
400                         "depth": 0,
401                         "as_list": False,
402                         "as_json": False,
403                         "with_lists": None,
404                         "ignore_null": False,
405                     },
406                 ],
407                 [
408                     None,
409                     {
410                         "query": "SELECT blah4",
411                         "depth": 2,
412                         "as_list": False,
413                         "as_json": False,
414                         "with_lists": None,
415                         "ignore_null": False,
416                     },
417                 ],
418                 [
419                     None,
420                     {
421                         "query": "SELECT blah5",
422                         "depth": 0,
423                         "as_list": False,
424                         "as_json": False,
425                         "with_lists": None,
426                         "ignore_null": False,
427                     },
428                 ],
429                 [
430                     None,
431                     {
432                         "query": "SELECT blah6",
433                         "depth": 0,
434                         "as_list": False,
435                         "as_json": False,
436                         "with_lists": None,
437                         "ignore_null": False,
438                     },
439                 ],
440                 [
441                     None,
442                     {
443                         "query": "SELECT blah7",
444                         "depth": 2,
445                         "as_list": False,
446                         "as_json": False,
447                         "with_lists": None,
448                         "ignore_null": False,
449                     },
450                 ],
451                 [
452                     None,
453                     {
454                         "query": "SELECT blah8",
455                         "depth": 0,
456                         "as_list": True,
457                         "as_json": False,
458                         "with_lists": None,
459                         "ignore_null": False,
460                     },
461                 ],
462             ],
463             qbuffer,
464         )
465     def test_006_extract_queries_bogus_kwargs(self):
466         return_data = mysql.MySQLExtPillar()
467         args, kwargs = [], {"1": "SELECT blah", "2": "", "3": "SELECT blah2"}
468         qbuffer = return_data.extract_queries(args, kwargs)
469         self.assertEqual(
470             [
471                 [
472                     "1",
473                     {
474                         "query": "SELECT blah",
475                         "depth": 0,
476                         "as_list": False,
477                         "as_json": False,
478                         "with_lists": None,
479                         "ignore_null": False,
480                     },
481                 ],
482                 [
483                     "3",
484                     {
485                         "query": "SELECT blah2",
486                         "depth": 0,
487                         "as_list": False,
488                         "as_json": False,
489                         "with_lists": None,
490                         "ignore_null": False,
491                     },
492                 ],
493             ],
494             qbuffer,
495         )
496     def test_011_enter_root(self):
497         return_data = mysql.MySQLExtPillar()
498         return_data.enter_root("test")
499         self.assertEqual(return_data.result["test"], return_data.focus)
500         return_data.enter_root(None)
501         self.assertEqual(return_data.result, return_data.focus)
502     def test_021_process_fields(self):
503         return_data = mysql.MySQLExtPillar()
504         return_data<font color="#c58917"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.process_fields(["a", "b"], 0)
505         self.assertEqual(return_data.num_fields, 2)
506         self.assertEqual(return_data.depth, 1)
507         return_data.process_fields(["a"</b></font>, "b"], 2)
508         self.assertEqual(return_data.num_fields, 2)
509         self.assertEqual(return_data.depth, 1)
510         return_data.process_fields(["a", "b", "c", "d"], 0)
511         self.assertEqual(return_data.num_fields, 4)
512         self.assertEqual(return_data.depth, 3)
513         return_data.process_fields(["a", "b", "c", "d"], 1)
514         self.assertEqual(return_data.num_fields, 4)
515         self.assertEqual(return_data.depth, 1)
516         return_data.process_fields(["a", "b", "c", "d"], 2)
517         self.assertEqual(return_data.num_fields, 4)
518         self.assertEqual(return_data.depth, 2)
519         return_data.process_fields(["a", "b", "c", "d"], 3)
520         self.assertEqual(return_data.num_fields, 4)
521         self.assertEqual(return_data.depth, 3)
522         return_data.process_fields(["a", "b", "c", "d"], 4)
523         self.assertEqual(return_data.num_fields, 4)
524         self.assertEqual(return_data.depth, 3)
525     def test_111_process_results_legacy(self):
526         return_data = mysql.MySQLExtPillar()
527         return_data.process_fields(["a", "b"], 0)
528         return_data.with_lists = []
529         return_data.process_results([[1, 2]])
530         self.assertEqual({1: 2}, return_data.result)
531     def test_112_process_results_legacy_multiple(self):
532         return_data = mysql.MySQLExtPillar()
533         return_data.process_fields(["a", "b"], 0)
534         return_data.with_lists = []
535         return_data.process_results([[1, 2], [3, 4], [5, 6]])
536     def test_121_process_results_depth_0(self):
537         return_data <font color="#38a4a5"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>= mysql.MySQLExtPillar()
538         return_data.process_fields(["a", "b", "c", "d"], 0)
539         return_data.with_lists = []
540         return_data.enter_root(None)
541         return_data.process_results(</b></font>[[1, 2, 3, 4], [5, 6, 7, 8]])
542         self.assertEqual({1: {2: {3: 4}}, 5: {6: {7: 8}}}, return_data.result)
543     def test_122_process_results_depth_1(self):
544         return_data = mysql.MySQLExtPillar()
545         return_data.process_fields(["a", "b", "c", "d"], 1)
546         return_data.with_lists = []
547         return_data.enter_root(None)
548         return_data.process_results([[1, 2, 3, 4], [5, 6, 7, 8]])
549         self.assertEqual(
550             {1: {"b": 2, "c": 3, "d": 4}, 5: {"b": 6, "c": 7, "d": 8}},
551             return_data.result,
552         )
553     def test_123_process_results_depth_2(self):
554         return_data = mysql.MySQLExtPillar()
555         return_data.process_fields(["a", "b", "c", "d"], 2)
556         return_data.with_lists = []
557         return_data.enter_root(None)
558         return_data.process_results([[1, 2, 3, 4], [5, 6, 7, 8]])
559         self.assertEqual(
560             {1: {2: {"c": 3, "d": 4}}, 5: {6: {"c": 7, "d": 8}}}, return_data.result
561         )
562     def test_124_process_results_depth_3(self):
563         return_data = mysql.MySQLExtPillar()
564         return_data.process_fields(["a", "b", "c", "d"], 3)
565         return_data.with_lists = []
566         return_data.enter_root(None)
567         return_data.process_results([[1, 2, 3, 4], [5, 6, 7, 8]])
568         self.assertEqual({1: {2: {3: 4}}, 5: {6: {7: 8}}}, return_data.result)
569     def test_125_process_results_depth_4(self):
570         return_data = mysql.MySQLExtPillar()
571         return_data.process_fields(["a", "b", "c", "d"], 4)
572         return_data.with_lists = []
573         return_data.enter_root(None)
574         return_data.process_results([[1, 2, 3, 4], [5, 6, 7, 8]])
575         self.assertEqual({1: {2: {3: 4}}, 5: {6: {7: 8}}}, return_data.result)
576     def test_131_process_results_overwrite_legacy_multiple(self):
577         return_data = mysql.MySQLExtPillar()
578         return_data.process_fields(["a", "b"], 0)
579         return_data.with_lists = []
580         return_data.process_results([[1, 2], [3, 4], [1, 6]])
581         self.assertEqual({1: 6, 3: 4}, return_data.result)
582     def test_132_process_results_merge_depth_0(self):
583         return_data = mysql.MySQLExtPillar()
584         return_data.process_fields(["a", "b", "c", "d"], 0)
585         return_data.with_lists = []
586         return_data.enter_root(None)
587         return_data.process_results([[1, 2, 3, 4], [1, 6, 7, 8]])
588         self.assertEqual({1: {2: {3: 4}, 6: {7: 8}}}, return_data.result)
589     def test_133_process_results_overwrite_depth_0(self):
590         return_data = mysql.MySQLExtPillar()
591         return_data.process_fields(["a", "b", "c", "d"], 0)
592         return_data.with_lists = []
593         return_data.enter_root(None)
594         return_data.process_results([[1, 2, 3, 4], [1, 2, 3, 8]])
595         self.assertEqual({1: {2: {3: 8}}}, return_data.result)
596     def test_134_process_results_deepmerge_depth_0(self):
597         return_data = mysql.MySQLExtPillar()
598         return_data.process_fields(["a", "b", "c", "d"], 0)
599         return_data.with_lists = []
600         return_data.enter_root(None)
601         return_data.process_results([[1, 2, 3, 4], [1, 2, 7, 8]])
602         self.assertEqual({1: {2: {3: 4, 7: 8}}}, return_data.result)
603     def test_135_process_results_overwrite_depth_1(self):
604         return_data = mysql.MySQLExtPillar()
605         return_data.process_fields(["a", "b", "c", "d"], 1)
606         return_data.with_lists = []
607         return_data.enter_root(None)
608         return_data.process_results([[1, 2, 3, 4], [1, 6, 7, 8]])
609         self.assertEqual({1: {"b": 6, "c": 7, "d": 8}}, return_data.result)
610     def test_136_process_results_merge_depth_2(self):
611         return_data = mysql.MySQLExtPillar()
612         return_data.process_fields(["a", "b", "c", "d"], 2)
613         return_data.with_lists = []
614         return_data.enter_root(None)
615         return_data.process_results([[1, 2, 3, 4], [1, 6, 7, 8]])
616         self.assertEqual(
617             {1: {2: {"c": 3, "d": 4}, 6: {"c": 7, "d": 8}}}, return_data.result
618         )
619     def test_137_process_results_overwrite_depth_2(self):
620         return_data = mysql.MySQLExtPillar()
621         return_data.process_fields(["a", "b", "c", "d"], 2)
622         return_data.with_lists = []
623         return_data.enter_root(None)
624         return_data.process_results([[1, 2, 3, 4], [1, 2, 7, 8]])
625         self.assertEqual({1: {2: {"c": 7, "d": 8}}}, return_data.result)
626     def test_201_process_results_complexity_multiresults(self):
627         return_data = mysql.MySQLExtPillar()
628         return_data.process_fields(["a", "b", "c", "d"], 2)
629         return_data.with_lists = []
630         return_data.enter_root(None)
631         return_data.process_results([[1, 2, 3, 4]])
632         return_data.process_results([[1, 2, 7, 8]])
633         self.assertEqual({1: {2: {"c": 7, "d": 8}}}, return_data.result)
634     def test_202_process_results_complexity_as_list(self):
635         return_data = mysql.MySQLExtPillar()
636         return_data.process_fields(["a", "b", "c", "d"], 2)
637         return_data.with_lists = []
638         return_data.enter_root(None)
639         return_data.as_list = True
640         return_data.process_results([[1, 2, 3, 4]])
641         return_data.process_results([[1, 2, 7, 8]])
642         self.assertEqual({1: {2: {"c": [3, 7], "d": [4, 8]}}}, return_data.result)
643     def test_203_process_results_complexity_as_list_deeper(self):
644         return_data = mysql.MySQLExtPillar()
645         return_data.process_fields(["a", "b", "c", "d"], 0)
646         return_data.with_lists = []
647         return_data.enter_root(None)
648         return_data.as_list = True
649         return_data.process_results([[1, 2, 3, 4]])
650         return_data.process_results([[1, 2, 3, 8]])
651         self.assertEqual({1: {2: {3: [4, 8]}}}, return_data.result)
652     def test_204_process_results_complexity_as_list_mismatch_depth(self):
653         return_data = mysql.MySQLExtPillar()
654         return_data.with_lists = []
655         return_data.enter_root(None)
656         return_data.process_fields([<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>"a", "b", "c", "d"], 0)
657         return_data.process_results([[1, 2, 3, 4]])
658         return_data.process_results([[1, 2, 3, 5]])
659         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
660         return_data.process_results([[1</b></font>, 2, 3, 6, 7]])
661         self.assertEqual({1: {2: {3: [4, 5, {6: 7}]}}}, return_data.result)
662     def test_205_process_results_complexity_as_list_mismatch_depth_reversed(self):
663         return_data = mysql.MySQLExtPillar()
664         return_data.with_lists = []
665         return_data.enter_root(None)
666         return_data.process_fields([<font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>"a", "b", "c", "d", "e"], 0)
667         return_data.process_results([[1, 2, 3, 6, 7]])
668         return_data.process_results([[1, 2, 3, 8, 9]])
669         return_data.process_fields(["a", "b", "c", "d"], 0)
670         return_data.process_results(</b></font>[[1, 2, 3, 4]])
671         return_data.process_results([[1, 2, 3, 5]])
672         self.assertEqual({1: {2: {3: [{6: 7, 8: 9}, 4, 5]}}}, return_data.result)
673     def test_206_process_results_complexity_as_list_mismatch_depth_weird_order(self):
674         return_data.as_list = True
675         return_data.with_lists = []
676         return_data<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.enter_root(None)
677         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
678         return_data.process_results([[1, 2, 3, 6, 7]])
679         return_data.process_fields(["a", "b", "c", "d"], 0)
680         return_data.process_results([[</b></font>1, 2, 3, 4]])
681         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
682         return_data.process_results([[1, 2, 3, 8, 9]])
683         return_data.process_fields(["a", "b", "c", "d"], 0)
684         return_data.process_results([[1, 2, 3, 5]])
685         self.assertEqual({1: {2: {3: [{6: 7}, 4, {8: 9}, 5]}}}, return_data.result)
686     def test_207_process_results_complexity_collision_mismatch_depth(self):
687         return_data = mysql.MySQLExtPillar()
688         return_data.as_list = False
689         return_data.with_lists = []
690         return_data.enter_root(None)
691         return_data.process_fields(["a", "b", "c", "d"], 0)
692         return_data.process_results([[1, 2, 3, 4]])
693         return_data.process_results([[1, 2, 3, 5]])
694         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
695         return_data.process_results([[1, 2, 3, 6, 7]])
696         self.assertEqual({1: {2: {3: {6: 7}}}}, return_data.result)
697     def test_208_process_results_complexity_collision_mismatch_depth_reversed(self):
698         return_data = mysql.MySQLExtPillar()
699         return_data.as_list = False
700         return_data.with_lists = []
701         return_data.enter_root(None)
702         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
703         return_data.process_results([[1, 2, 3, 6, 7]])
704         return_data.process_results([[1, 2, 3, 8, 9]])
705         return_data.process_fields(["a", "b", "c", "d"], 0)
706         return_data.process_results([[1, 2, 3, 4]])
707         return_data.process_results([[1, 2, 3, 5]])
708         self.assertEqual({1: {2: {3: 5}}}, return_data.result)
709     def test_209_process_results_complexity_collision_mismatch_depth_weird_order(self):
710         return_data = mysql.MySQLExtPillar()
711         return_data.as_list = False
712         return_data.with_lists = []
713         return_data.enter_root(None)
714         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
715         return_data.process_results([[1, 2, 3, 6, 7]])
716         return_data.process_fields(["a", "b", "c", "d"], 0)
717         return_data.process_results([[1, 2, 3, 4]])
718         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
719         return_data.process_results([[1, 2, 3, 8, 9]])
720         return_data.process_fields(["a", "b", "c", "d"], 0)
721         return_data.process_results([[1, 2, 3, 5]])
722         self.assertEqual({1: {2: {3: 5}}}, return_data.result)
723     def test_20A_process_results_complexity_as_list_vary(self):
724         return_data = mysql.MySQLExtPillar()
725         return_data.as_list = True
726         return_data.with_lists = []
727         return_data.enter_root(None)
728         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
729         return_data.process_results([[1, 2, 3, 6, 7]])
730         return_data.process_results([[1, 2, 3, 8, 9]])
731         return_data.process_fields(["a", "b", "c", "d"], 0)
732         return_data.process_results([[1, 2, 3, 4]])
733         return_data.as_list = False
734         return_data.process_results([[1, 2, 3, 5]])
735         self.assertEqual({1: {2: {3: 5}}}, return_data.result)
736     def test_207_process_results_complexity_roots_collision(self):
737         return_data = mysql.MySQLExtPillar()
738         return_data.with_lists = []
739         return_data.enter_root(None)
740         return_data<font color="#151b8d"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.process_fields(["a", "b", "c", "d"], 0)
741         return_data.process_results([[1, 2, 3, 4]])
742         return_data.enter_root(1)
743         return_data.process_results([[5</b></font>, 6, 7, 8]])
744         self.assertEqual({1: {5: {6: {7: 8}}}}, return_data.result)
745     def test_301_process_results_with_lists(self):
746         return_data = mysql.MySQLExtPillar()
747         return_data.as_list = False
748         return_data.with_lists = [1, 3]
749         return_data.enter_root(None)
750         return_data.process_fields(["a", "b", "c", "d", "e", "v"], 0)
751         return_data.process_results(
752             [
753                 ["a", "b", "c", "d", "e", 1],
754                 ["a", "b", "c", "f", "g", 2],
755                 ["a", "z", "h", "y", "j", 3],
756                 ["a", "z", "h", "y", "k", 4],
757             ]
758         )
759         assert "a" in return_data.result
760         for x in return_data.result["a"]:
761             if "c" in x:
762                 assert list(x.keys()) == ["c"], x.keys()
763                 for y in x["c"]:
764                     if "e" in y:
765                         assert list(y.keys()) == ["e"]
766                         assert y["e"] == 1
767                     elif "g" in y:
768                         assert list(y.keys()) == ["g"]
769                         assert y["g"] == 2
770                     else:
771                         raise ValueError("Unexpected value {}".format(y))
772             elif "h" in x:
773                 assert len(x["h"]) == 1
774                 for y in x["h"]:
775                     if "j" in y:
776                         assert len(y.keys()) == 2
777                         assert y["j"] == 3
778                     elif "h" in y:
779                         assert len(y.keys()) == 2
780                         assert y["k"] == 4
781                     else:
782                         raise ValueError("Unexpected value {}".format(y))
783             else:
784                 raise ValueError("Unexpected value {}".format(x))
785     def test_302_process_results_with_lists_consecutive(self):
786         return_data = mysql.MySQLExtPillar()
787         return_data.as_list = False
788         return_data.with_lists = [1, 2, 3]
789         return_data.enter_root(None)
790         return_data.process_fields(["a", "b", "c", "d", "e", "v"], 0)
791         return_data.process_results(
792             [
793                 ["a", "b", "c", "d", "e", 1],
794                 ["a", "b", "c", "f", "g", 2],
795                 ["a", "z", "h", "y", "j", 3],
796                 ["a", "z", "h", "y", "k", 4],
797             ]
798         )
799         assert "a" in return_data.result
800         for x in return_data.result["a"]:
801             assert len(x) == 1
802             if len(x[0][0]) == 1:
803                 for y in x[0]:
804                     if "e" in y:
805                         assert list(y.keys()) == ["e"]
806                         assert y["e"] == 1
807                     elif "g" in y:
808                         assert list(y.keys()) == ["g"]
809                         assert y["g"] == 2
810                     else:
811                         raise ValueError("Unexpected value {}".format(y))
812             elif len(x[0][0]) == 2:
813                 for y in x[0]:
814                     if "j" in y:
815                         assert len(y.keys()) == 2
816                         assert y["j"] == 3
817                     elif "k" in y:
818                         assert len(y.keys()) == 2
819                         assert y["k"] == 4
820                     else:
821                         raise ValueError("Unexpected value {}".format(len(x[0][0])))
822             else:
823                 raise ValueError("Unexpected value {}".format(x))
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>virt_1.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import base64
2 import collections
3 import copy
4 import datetime
5 import logging
6 import os
7 import re
8 import shutil
9 import string  # pylint: disable=deprecated-module
10 import subprocess
11 import sys
12 import time
13 import urllib.parse
14 from xml.etree import ElementTree
15 from xml.sax import saxutils
16 import jinja2.exceptions
17 import salt.utils.data
18 import salt.utils.files
19 import salt.utils.json
20 import salt.utils.path
21 import salt.utils.stringutils
22 import salt.utils.templates
23 import salt.utils.virt
24 import salt.utils.xmlutil as xmlutil
25 import salt.utils.yaml
26 from salt._compat import ipaddress
27 from salt.exceptions import CommandExecutionError, SaltInvocationError
28 try:
29     import libvirt  # pylint: disable=import-error
30     from libvirt import libvirtError
31     HAS_LIBVIRT = True
32 except ImportError:
33     HAS_LIBVIRT = False
34 log = logging.getLogger(__name__)
35 JINJA = jinja2.Environment(
36     loader=jinja2.FileSystemLoader(
37         os.path.join(salt.utils.templates.TEMPLATE_DIRNAME, "virt")
38     )
39 )
40 CACHE_DIR = "/var/lib/libvirt/saltinst"
41 VIRT_STATE_NAME_MAP = {
42     0: "running",
43     1: "running",
44     2: "running",
45     3: "paused",
46     4: "shutdown",
47     5: "shutdown",
48     6: "crashed",
49 }
50 def __virtual__():
51     if not HAS_LIBVIRT:
52         return (False, "Unable to locate or import python libvirt library.")
53     return "virt"
54 def __get_request_auth(username, password):
55     def __request_auth(credentials, user_data):
56         for credential in credentials:
57             if credential[0] == libvirt.VIR_CRED_AUTHNAME:
58                 credential[4] = (
59                     username
60                     if username
61                     else __salt__["config.get"](
62                         "virt:connection:auth:username", credential[3]
63                     )
64                 )
65             elif credential[0] == libvirt.VIR_CRED_NOECHOPROMPT:
66                 credential[4] = (
67                     password
68                     if password
69                     else __salt__["config.get"](
70                         "virt:connection:auth:password", credential[3]
71                     )
72                 )
73             else:
74                 log.info("Unhandled credential type: %s", credential[0])
75         return 0
76 def __get_conn(**kwargs):
77     username = kwargs.get("username", None)
78     password = kwargs.get("password", None)
79     conn_str = kwargs.get("connection", None)
80     if not conn_str:
81         conn_str = __salt__["config.get"]("virt:connection:uri", conn_str)
82     try:
83         auth_types = [
84             libvirt.VIR_CRED_AUTHNAME,
85             libvirt.VIR_CRED_NOECHOPROMPT,
86             libvirt.VIR_CRED_ECHOPROMPT,
87             libvirt.VIR_CRED_PASSPHRASE,
88             libvirt.VIR_CRED_EXTERNAL,
89         ]
90         conn = libvirt.openAuth(
91             conn_str, [auth_types, __get_request_auth(username, password), None], 0
92         )
93     except Exception:  # pylint: disable=broad-except
94         raise CommandExecutionError(
95             "Sorry, {} failed to open a connection to the hypervisor "
96             "software at {}".format(__grains__["fqdn"], conn_str)
97         )
98     return conn
99 def _get_domain(conn, *vms, **kwargs):
100     ret = list()
101     lookup_vms = list()
102     all_vms = []
103     if kwargs.get("active", True):
104         for id_ in conn.listDomainsID():
105             all_vms.append(conn.lookupByID(id_).name())
106     if kwargs.get("inactive", True):
107         for id_ in conn.listDefinedDomains():
108             all_vms.append(id_)
109     if vms and not all_vms:
110         raise CommandExecutionError("No virtual machines found.")
111     if vms:
112         for name in vms:
113             if name not in all_vms:
114                 raise CommandExecutionError(
115                     'The VM "{name}" is not present'.format(name=name)
116                 )
117             else:
118                 lookup_vms.append(name)
119     else:
120         lookup_vms = list(all_vms)
121     for name in lookup_vms:
122         ret.append(conn.lookupByName(name))
123     return len(ret) == 1 and not kwargs.get("iterable") and ret[0] or ret
124 def _parse_qemu_img_info(info):
125     raw_infos = salt.utils.json.loads(info)
126     disks = []
127     for disk_infos in raw_infos:
128         disk = {
129             "file": disk_infos["filename"],
130             "file format": disk_infos["format"],
131             "disk size": disk_infos["actual-size"],
132             "virtual size": disk_infos["virtual-size"],
133             "cluster size": disk_infos["cluster-size"]
134             if "cluster-size" in disk_infos
135             else None,
136         }
137         if "full-backing-filename" in disk_infos.keys():
138             disk["backing file"] = format(disk_infos["full-backing-filename"])
139         if "snapshots" in disk_infos.keys():
140             disk["snapshots"] = [
141                 {
142                     "id": snapshot["id"],
143                     "tag": snapshot["name"],
144                     "vmsize": snapshot["vm-state-size"],
145                     "date": datetime.datetime.fromtimestamp(
146                         float(
147                             "{}.{}".format(snapshot["date-sec"], snapshot["date-nsec"])
148                         )
149                     ).isoformat(),
150                     "vmclock": datetime.datetime.utcfromtimestamp(
151                         float(
152                             "{}.{}".format(
153                                 snapshot["vm-clock-sec"], snapshot["vm-clock-nsec"]
154                             )
155                         )
156                     )
157                     .time()
158                     .isoformat(),
159                 }
160                 for snapshot in disk_infos["snapshots"]
161             ]
162         disks.append(disk)
163     for disk in disks:
164         if "backing file" in disk.keys():
165             candidates = [
166                 info
167                 for info in disks
168                 if "file" in info.keys() and info["file"] == disk["backing file"]
169             ]
170             if candidates:
171                 disk["backing file"] = candidates[0]
172     return disks[0]
173 def _get_uuid(dom):
174     return ElementTree.fromstring(get_xml(dom)).find("uuid").text
175 def _get_on_poweroff(dom):
176     node = ElementTree.fromstring(get_xml(dom)).find("on_poweroff")
177     return node.text if node is not None else ""
178 def _get_on_reboot(dom):
179     node = ElementTree.fromstring(get_xml(dom)).find("on_reboot")
180     return node.text if node is not None else ""
181 def _get_on_crash(dom):
182     node = ElementTree.fromstring(get_xml(dom)).find("on_crash")
183     return node.text if node is not None else ""
184 def _get_nics(dom):
185     nics = {}
186     doc = ElementTree.fromstring(dom.XMLDesc(libvirt.VIR_DOMAIN_XML_INACTIVE))
187     for iface_node in doc.findall("devices/interface"):
188         nic = {}
189         nic["type"] = iface_node.get("type")
190         for v_node in iface_node:
191             if v_node.tag == "mac":
192                 nic["mac"] = v_node.get("address")
193             if v_node.tag == "model":
194                 nic["model"] = v_node.get("type")
195             if v_node.tag == "target":
196                 nic["target"] = v_node.get("dev")
197             if re.match("(driver|source|address)", v_node.tag):
198                 temp = {}
199                 for key, value in v_node.attrib.items():
200                     temp[key] = value
201                 nic[v_node.tag] = temp
202             if v_node.tag == "virtualport":
203                 temp = {}
204                 temp["type"] = v_node.get("type")
205                 for key, value in v_node.attrib.items():
206                     temp[key] = value
207                 nic["virtualport"] = temp
208         if "mac" not in nic:
209             continue
210         nics[nic["mac"]] = nic
211     return nics
212 def _get_graphics(dom):
213     out = {
214         "autoport": "None",
215         "keymap": "None",
216         "listen": "None",
217         "port": "None",
218         "type": "None",
219     }
220     doc = ElementTree.fromstring(dom.XMLDesc(0))
221     for g_node in doc.findall("devices/graphics"):
222         for key, value in g_node.attrib.items():
223             out[key] = value
224     return out
225 def _get_loader(dom):
226     out = {"path": "None"}
227     doc = ElementTree.fromstring(dom.XMLDesc(0))
228     for g_node in doc.findall("os/loader"):
229         out["path"] = g_node.text
230         for key, value in g_node.attrib.items():
231             out[key] = value
232     return out
233 def _get_disks(conn, dom):
234     disks = {}
235     doc = ElementTree.fromstring(dom.XMLDesc(0))
236     all_volumes = _get_all_volumes_paths(conn)
237     for elem in doc.findall("devices/disk"):
238         source = elem.find("source")
239         if source is None:
240             continue
241         target = elem.find("target")
242         driver = elem.find("driver")
243         if target is None:
244             continue
245         qemu_target = None
246         extra_properties = None
247         if "dev" in target.attrib:
248             disk_type = elem.get("type")
249             def _get_disk_volume_data(pool_name, volume_name):
250                 qemu_target = "{}/{}".format(pool_name, volume_name)
251                 pool = conn.storagePoolLookupByName(pool_name)
252                 extra_properties = {}
253                 try:
254                     vol = pool.storageVolLookupByName(volume_name)
255                     vol_info = vol.info()
256                     extra_properties = {
257                         "virtual size": vol_info[1],
258                         "disk size": vol_info[2],
259                     }
260                     backing_files = [
261                         {
262                             "file": node.find("source").get("file"),
263                             "file format": node.find("format").get("type"),
264                         }
265                         for node in elem.findall(".//backingStore[source]")
266                     ]
267                     if backing_files:
268                         extra_properties["backing file"] = backing_files[0]
269                         parent = extra_properties["backing file"]
270                         for sub_backing_file in backing_files[1:]:
271                             parent["backing file"] = sub_backing_file
272                             parent = sub_backing_file
273                     else:
274                         vol_desc = ElementTree.fromstring(vol.XMLDesc())
275                         backing_path = vol_desc.find("./backingStore/path")
276                         backing_format = vol_desc.find("./backingStore/format")
277                         if backing_path is not None:
278                             extra_properties["backing file"] = {
279                                 "file": backing_path.text
280                             }
281                             if backing_format is not None:
282                                 extra_properties["backing file"][
283                                     "file format"
284                                 ] = backing_format.get("type")
285                 except libvirt.libvirtError:
286                     log.info(
287                         "Couldn't extract all volume informations: pool is likely not"
288                         " running or refreshed"
289                     )
290                 return (qemu_target, extra_properties)
291             if disk_type == "file":
292                 qemu_target = source.get("file", "")
293                 if qemu_target.startswith("/dev/zvol/"):
294                     disks[target.get("dev")] = {"file": qemu_target, "zfs": True}
295                     continue
296                 if qemu_target in all_volumes.keys():
297                     volume = all_volumes[qemu_target]
298                     qemu_target, extra_properties = _get_disk_volume_data(
299                         volume["pool"], volume["name"]
300                     )
301                 elif elem.get("device", "disk") != "cdrom":
302                     try:
303                         process = subprocess.Popen(
304                             [
305                                 "qemu-img",
306                                 "info",
307                                 "-U",
308                                 "--output",
309                                 "json",
310                                 "--backing-chain",
311                                 qemu_target,
312                             ],
313                             shell=False,
314                             stdout=subprocess.PIPE,
315                             stderr=subprocess.PIPE,
316                         )
317                         stdout, stderr = process.communicate()
318                         if process.returncode == 0:
319                             qemu_output = salt.utils.stringutils.to_str(stdout)
320                             output = _parse_qemu_img_info(qemu_output)
321                             extra_properties = output
322                         else:
323                             extra_properties = {"error": stderr}
324                     except FileNotFoundError:
325                         extra_properties = {"error": "qemu-img not found"}
326             elif disk_type == "block":
327                 qemu_target = source.get("dev", "")
328                 if qemu_target in all_volumes.keys():
329                     volume = all_volumes[qemu_target]
330                     qemu_target, extra_properties = _get_disk_volume_data(
331                         volume["pool"], volume["name"]
332                     )
333             elif disk_type == "network":
334                 qemu_target = source.get("protocol")
335                 source_name = source.get("name")
336                 if source_name:
337                     qemu_target = "{}:{}".format(qemu_target, source_name)
338                 if source.get("protocol") in ["rbd", "gluster"]:
339                     for pool_i in conn.listAllStoragePools():
340                         pool_i_xml = ElementTree.fromstring(pool_i.XMLDesc())
341                         name_node = pool_i_xml.find("source/name")
342                         if name_node is not None and source_name.startswith(
343                             "{}/".format(name_node.text)
344                         ):
345                             qemu_target = "{}{}".format(
346                                 pool_i.name(), source_name[len(name_node.text) :]
347                             )
348                             break
349                 if elem.get("device", "disk") == "cdrom":
350                     host_node = source.find("host")
351                     if host_node is not None:
352                         hostname = host_node.get("name")
353                         port = host_node.get("port")
354                         qemu_target = urllib.parse.urlunparse(
355                             (
356                                 source.get("protocol"),
357                                 "{}:{}".format(hostname, port) if port else hostname,
358                                 source_name,
359                                 "",
360                                 saxutils.unescape(source.get("query", "")),
361                                 "",
362                             )
363                         )
364             elif disk_type == "volume":
365                 pool_name = source.get("pool")
366                 volume_name = source.get("volume")
367                 qemu_target, extra_properties = _get_disk_volume_data(
368                     pool_name, volume_name
369                 )
370             if not qemu_target:
371                 continue
372             disk = {
373                 "file": qemu_target,
374                 "type": elem.get("device"),
375             }
376             if driver is not None and "type" in driver.attrib:
377                 disk["file format"] = driver.get("type")
378             if extra_properties:
379                 disk.update(extra_properties)
380             disks[target.get("dev")] = disk
381     return disks
382 def _libvirt_creds():
383     g_cmd = ["grep", "^\\s*group", "/etc/libvirt/qemu.conf"]
384     u_cmd = ["grep", "^\\s*user", "/etc/libvirt/qemu.conf"]
385     try:
386         stdout = subprocess.Popen(g_cmd, stdout=subprocess.PIPE).communicate()[0]
387         group = salt.utils.stringutils.to_str(stdout).split('"')[1]
388     except IndexError:
389         group = "root"
390     try:
391         stdout = subprocess.Popen(u_cmd, stdout=subprocess.PIPE).communicate()[0]
392         user = salt.utils.stringutils.to_str(stdout).split('"')[1]
393     except IndexError:
394         user = "root"
395     return {"user": user, "group": group}
396 def _migrate(dom, dst_uri, **kwargs):
397     flags = 0
398     params = {}
399     migrated_state = libvirt.VIR_DOMAIN_RUNNING_MIGRATED
400     if kwargs.get("live", True):
401         flags |= libvirt.VIR_MIGRATE_LIVE
402     if kwargs.get("persistent", True):
403         flags |= libvirt.VIR_MIGRATE_PERSIST_DEST
404     if kwargs.get("undefinesource", True):
405         flags |= libvirt.VIR_MIGRATE_UNDEFINE_SOURCE
406     max_bandwidth = kwargs.get("max_bandwidth")
407     if max_bandwidth:
408         try:
409             bandwidth_value = int(max_bandwidth)
410         except ValueError:
411             raise SaltInvocationError(
412                 "Invalid max_bandwidth value: {}".format(max_bandwidth)
413             )
414         dom.migrateSetMaxSpeed(bandwidth_value)
415     max_downtime = kwargs.get("max_downtime")
416     if max_downtime:
417         try:
418             downtime_value = int(max_downtime)
419         except ValueError:
420             raise SaltInvocationError(
421                 "Invalid max_downtime value: {}".format(max_downtime)
422             )
423         dom.migrateSetMaxDowntime(downtime_value)
424     if kwargs.get("offline") is True:
425         flags |= libvirt.VIR_MIGRATE_OFFLINE
426         migrated_state = libvirt.VIR_DOMAIN_RUNNING_UNPAUSED
427     if kwargs.get("compressed") is True:
428         flags |= libvirt.VIR_MIGRATE_COMPRESSED
429     comp_methods = kwargs.get("comp_methods")
430     if comp_methods:
431         params[libvirt.VIR_MIGRATE_PARAM_COMPRESSION] = comp_methods.split(",")
432     comp_options = {
433         "comp_mt_level": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_LEVEL,
434         "comp_mt_threads": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_THREADS,
435         "comp_mt_dthreads": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_DTHREADS,
436         "comp_xbzrle_cache": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_XBZRLE_CACHE,
437     }
438     for (comp_option, param_key) in comp_options.items():
439         comp_option_value = kwargs.get(comp_option)
440         if comp_option_value:
441             try:
442                 params[param_key] = int(comp_option_value)
443             except ValueError:
444                 raise SaltInvocationError("Invalid {} value".format(comp_option))
445     parallel_connections = kwargs.get("parallel_connections")
446     if parallel_connections:
447         try:
448             params[libvirt.VIR_MIGRATE_PARAM_PARALLEL_CONNECTIONS] = int(
449                 parallel_connections
450             )
451         except ValueError:
452             raise SaltInvocationError("Invalid parallel_connections value")
453         flags |= libvirt.VIR_MIGRATE_PARALLEL
454     if __salt__["config.get"]("virt:tunnel"):
455         if parallel_connections:
456             raise SaltInvocationError(
457                 "Parallel migration isn't compatible with tunneled migration"
458             )
459         flags |= libvirt.VIR_MIGRATE_PEER2PEER
460         flags |= libvirt.VIR_MIGRATE_TUNNELLED
461     if kwargs.get("postcopy") is True:
462         flags |= libvirt.VIR_MIGRATE_POSTCOPY
463     postcopy_bandwidth = kwargs.get("postcopy_bandwidth")
464     if postcopy_bandwidth:
465         try:
466             postcopy_bandwidth_value = int(postcopy_bandwidth)
467         except ValueError:
468             raise SaltInvocationError("Invalid postcopy_bandwidth value")
469         dom.migrateSetMaxSpeed(
470             postcopy_bandwidth_value,
471             flags=libvirt.VIR_DOMAIN_MIGRATE_MAX_SPEED_POSTCOPY,
472         )
473     copy_storage = kwargs.get("copy_storage")
474     if copy_storage:
475         if copy_storage == "all":
476             flags |= libvirt.VIR_MIGRATE_NON_SHARED_DISK
477         elif copy_storage in ["inc", "incremental"]:
478             flags |= libvirt.VIR_MIGRATE_NON_SHARED_INC
479         else:
480             raise SaltInvocationError("invalid copy_storage value")
481     try:
482         state = False
483         dst_conn = __get_conn(
484             connection=dst_uri,
485             username=kwargs.get("username"),
486             password=kwargs.get("password"),
487         )
488         new_dom = dom.migrate3(dconn=dst_conn, params=params, flags=flags)
489         if new_dom:
490             state = new_dom.state()
491         dst_conn.close()
492         return state and migrated_state in state
493     except libvirt.libvirtError as err:
494         dst_conn.close()
495         raise CommandExecutionError(err.get_error_message())
496 def _get_volume_path(pool, volume_name):
497     if volume_name in pool.listVolumes():
498         volume = pool.storageVolLookupByName(volume_name)
499         volume_xml = ElementTree.fromstring(volume.XMLDesc())
500         return volume_xml.find("./target/path").text
501     pool_xml = ElementTree.fromstring(pool.XMLDesc())
502     pool_path = pool_xml.find("./target/path").text
503     return pool_path + "/" + volume_name
504 def _disk_from_pool(conn, pool, pool_xml, volume_name):
505     pool_type = pool_xml.get("type")
506     disk_context = {}
507     if pool_type in ["dir", "netfs", "fs"]:
508         disk_context["type"] = "file"
509         disk_context["source_file"] = _get_volume_path(pool, volume_name)
510     elif pool_type in ["logical", "disk", "iscsi", "scsi"]:
511         disk_context["type"] = "block"
512         disk_context["format"] = "raw"
513         disk_context["source_file"] = _get_volume_path(pool, volume_name)
514     elif pool_type in ["rbd", "gluster", "sheepdog"]:
515         disk_context["type"] = "network"
516         disk_context["protocol"] = pool_type
517         disk_context["hosts"] = [
518             {"name": host.get("name"), "port": host.get("port")}
519             for host in pool_xml.findall(".//host")
520         ]
521         dir_node = pool_xml.find("./source/dir")
522         name_node = pool_xml.find("./source/name")
523         if name_node is not None:
524             disk_context["volume"] = "{}/{}".format(name_node.text, volume_name)
525         auth_node = pool_xml.find("./source/auth")
526         if auth_node is not None:
527             username = auth_node.get("username")
528             secret_node = auth_node.find("./secret")
529             usage = secret_node.get("usage")
530             if not usage:
531                 uuid = secret_node.get("uuid")
532                 usage = conn.secretLookupByUUIDString(uuid).usageID()
533             disk_context["auth"] = {
534                 "type": "ceph",
535                 "username": username,
536                 "usage": usage,
537             }
538     return disk_context
539 def _handle_unit(s, def_unit="m"):
540     m = re.match(r"(?P&lt;value&gt;[0-9.]*)\s*(?P&lt;unit&gt;.*)$", str(s).strip())
541     value = m.group("value")
542     unit = m.group("unit").lower() or def_unit
543     try:
544         value = int(value)
545     except ValueError:
546         try:
547             value = float(value)
548         except ValueError:
549             raise SaltInvocationError("invalid number")
550     dec = False
551     if re.match(r"[kmgtpezy]b$", unit):
552         dec = True
553     elif not re.match(r"(b|[kmgtpezy](ib)?)$", unit):
554         raise SaltInvocationError("invalid units")
555     p = "bkmgtpezy".index(unit[0])
556     value *= 10 ** (p * 3) if dec else 2 ** (p * 10)
557     return int(value)
558 def nesthash(value=None):
559     return collections.defaultdict(nesthash, value or {})
560 def _gen_xml(
561     conn,
562     name,
563     cpu,
564     mem,
565     diskp,
566     nicp,
567     hypervisor,
568     os_type,
569     arch,
570     graphics=None,
571     boot=None,
572     boot_dev=None,
573     numatune=None,
574     hypervisor_features=None,
575     clock=None,
576     serials=None,
577     consoles=None,
578     stop_on_reboot=False,
579     host_devices=None,
580     **kwargs
581 ):
582     context = {
583         "hypervisor": hypervisor,
584         "name": name,
585         "hypervisor_features": hypervisor_features or {},
586         "clock": clock or {},
587         "on_reboot": "destroy" if stop_on_reboot else "restart",
588     }
589     context["to_kib"] = lambda v: int(_handle_unit(v) / 1024)
590     context["yesno"] = lambda v: "yes" if v else "no"
591     context["mem"] = nesthash()
592     if isinstance(mem, int):
593         context["mem"]["boot"] = mem
594         context["mem"]["current"] = mem
595     elif isinstance(mem, dict):
596         context["mem"] = nesthash(mem)
597     context["cpu"] = nesthash()
598     context["cputune"] = nesthash()
599     if isinstance(cpu, int):
600         context["cpu"]["maximum"] = str(cpu)
601     elif isinstance(cpu, dict):
602         context["cpu"] = nesthash(cpu)
603     if clock:
604         offset = "utc" if clock.get("utc", True) else "localtime"
605         if "timezone" in clock:
606             offset = "timezone"
607         context["clock"]["offset"] = offset
608     if hypervisor in ["qemu", "kvm"]:
609         context["numatune"] = numatune if numatune else {}
610         context["controller_model"] = False
611     elif hypervisor == "vmware":
612         context["controller_model"] = "lsilogic"
613     if graphics:
614         if "listen" not in graphics:
615             graphics["listen"] = {"type": "address", "address": "0.0.0.0"}
616         elif (
617             "address" not in graphics["listen"]
618             and graphics["listen"]["type"] == "address"
619         ):
620             graphics["listen"]["address"] = "0.0.0.0"
621         if graphics.get("type", "none") == "none":
622             graphics = None
623     context["graphics"] = graphics
624     context["boot_dev"] = boot_dev.split() if boot_dev is not None else ["hd"]
625     context["boot"] = boot if boot else {}
626     efi_value = context["boot"].get("efi", None) if boot else None
627     if efi_value is True:
628         context["boot"]["os_attrib"] = "firmware='efi'"
629     elif efi_value is not None and type(efi_value) != bool:
630         raise SaltInvocationError("Invalid efi value")
631     if os_type == "xen":
632         if __grains__["os_family"] == "Suse":
633             if not boot or not boot.get("kernel", None):
634                 paths = [
635                     path
636                     for path in ["/usr/share", "/usr/lib"]
637                     if os.path.exists(path + "/grub2/x86_64-xen/grub.xen")
638                 ]
639                 if not paths:
640                     raise CommandExecutionError("grub-x86_64-xen needs to be installed")
641                 context["boot"]["kernel"] = paths[0] + "/grub2/x86_64-xen/grub.xen"
642                 context["boot_dev"] = []
643     default_port = 23023
644     default_chardev_type = "tcp"
645     chardev_types = ["serial", "console"]
646     for chardev_type in chardev_types:
647         context[chardev_type + "s"] = []
648         parameter_value = locals()[chardev_type + "s"]
649         if parameter_value is not None:
650             for chardev in parameter_value:
651                 chardev_context = chardev
652                 chardev_context["type"] = chardev.get("type", default_chardev_type)
653                 if chardev_context["type"] == "tcp":
654                     chardev_context["port"] = chardev.get("port", default_port)
655                     chardev_context["protocol"] = chardev.get("protocol", "telnet")
656                 context[chardev_type + "s"].append(chardev_context)
657     context["disks"] = []
658     disk_bus_map = {"virtio": "vd", "xen": "xvd", "fdc": "fd", "ide": "hd"}
659     targets = []
660     for i, disk in enumerate(diskp):
661         prefix = disk_bus_map.get(disk["model"], "sd")
662         disk_context = {
663             "device": disk.get("device", "disk"),
664             "target_dev": _get_disk_target(targets, len(diskp), prefix),
665             "disk_bus": disk["model"],
666             "format": disk.get("format", "raw"),
667             "index": str(i),
668             "io": disk.get("io", "native"),
669             "iothread": disk.get("iothread_id", None),
670         }
671         targets.append(disk_context["target_dev"])
672         if disk.get("source_file"):
673             url = urllib.parse.urlparse(disk["source_file"])
674             if not url.scheme or not url.hostname:
675                 disk_context["source_file"] = disk["source_file"]
676                 disk_context["type"] = "file"
677             elif url.scheme in ["http", "https", "ftp", "ftps", "tftp"]:
678                 disk_context["type"] = "network"
679                 disk_context["protocol"] = url.scheme
680                 disk_context["volume"] = url.path
681                 disk_context["query"] = saxutils.escape(url.query)
682                 disk_context["hosts"] = [{"name": url.hostname, "port": url.port}]
683         elif disk.get("pool"):
684             disk_context["volume"] = disk["filename"]
685             pool = conn.storagePoolLookupByName(disk["pool"])
686             pool_xml = ElementTree.fromstring(pool.XMLDesc())
687             pool_type = pool_xml.get("type")
688             if hypervisor == "xen" or pool_type in ["rbd", "gluster", "sheepdog"]:
689                 disk_context.update(
690                     _disk_from_pool(conn, pool, pool_xml, disk_context["volume"])
691                 )
692             else:
693                 if pool_type in ["disk", "logical"]:
694                     disk_context["format"] = "raw"
695                 disk_context["type"] = "volume"
696                 disk_context["pool"] = disk["pool"]
697         else:
698             disk_context["type"] = "file"
699         if hypervisor in ["qemu", "kvm", "bhyve", "xen"]:
700             disk_context["address"] = False
701             disk_context["driver"] = True
702         elif hypervisor in ["esxi", "vmware"]:
703             disk_context["address"] = True
704             disk_context["driver"] = False
705         context["disks"].append(disk_context)
706     context["nics"] = nicp
707     hostdev_context = []
708     try:
709         for hostdev_name in host_devices or []:
710             hostdevice = conn.nodeDeviceLookupByName(hostdev_name)
711             doc = ElementTree.fromstring(hostdevice.XMLDesc())
712             if "pci" in hostdevice.listCaps():
713                 hostdev_context.append(
714                     {
715                         "type": "pci",
716                         "domain": "0x{:04x}".format(
717                             int(doc.find("./capability[@type='pci']/domain").text)
718                         ),
719                         "bus": "0x{:02x}".format(
720                             int(doc.find("./capability[@type='pci']/bus").text)
721                         ),
722                         "slot": "0x{:02x}".format(
723                             int(doc.find("./capability[@type='pci']/slot").text)
724                         ),
725                         "function": "0x{}".format(
726                             doc.find("./capability[@type='pci']/function").text
727                         ),
728                     }
729                 )
730             elif "usb_device" in hostdevice.listCaps():
731                 vendor_id = doc.find(".//vendor").get("id")
732                 product_id = doc.find(".//product").get("id")
733                 hostdev_context.append(
734                     {"type": "usb", "vendor": vendor_id, "product": product_id}
735                 )
736     except libvirt.libvirtError as err:
737         conn.close()
738         raise CommandExecutionError(
739             "Failed to get host devices: " + err.get_error_message()
740         )
741     context["hostdevs"] = hostdev_context
742     context["os_type"] = os_type
743     context["arch"] = arch
744     fn_ = "libvirt_domain.jinja"
745     try:
746         template = JINJA.get_template(fn_)
747     except jinja2.exceptions.TemplateNotFound:
748         log.error("Could not load template %s", fn_)
749         return ""
750     return template.render(**context)
751 def _gen_vol_xml(
752     name,
753     size,
754     format=None,
755     allocation=0,
756     type=None,
757     permissions=None,
758     backing_store=None,
759     nocow=False,
760 ):
761     size = int(size) * 1024  # MB
762     context = {
763         "type": type,
764         "name": name,
765         "target": {"permissions": permissions, "nocow": nocow},
766         "format": format,
767         "size": str(size),
768         "allocation": str(int(allocation) * 1024),
769         "backingStore": backing_store,
770     }
771     fn_ = "libvirt_volume.jinja"
772     try:
773         template = JINJA.get_template(fn_)
774     except jinja2.exceptions.TemplateNotFound:
775         log.error("Could not load template %s", fn_)
776         return ""
777     return template.render(**context)
778 def _gen_net_xml(
779     name,
780     bridge,
781     forward,
782     vport,
783     tag=None,
784     ip_configs=None,
785     mtu=None,
786     domain=None,
787     nat=None,
788     interfaces=None,
789     addresses=None,
790     physical_function=None,
791     dns=None,
792 ):
793     if isinstance(vport, str):
794         vport_context = {"type": vport}
795     else:
796         vport_context = vport
797     if isinstance(tag, (str, int)):
798         tag_context = {"tags": [{"id": tag}]}
799     else:
800         tag_context = tag
801     addresses_context = []
802     if addresses:
803         matches = [
804             re.fullmatch(r"([0-9]+):([0-9A-Fa-f]+):([0-9A-Fa-f]+)\.([0-9])", addr)
805             for addr in addresses.lower().split(" ")
806         ]
807         addresses_context = [
808             {
809                 "domain": m.group(1),
810                 "bus": m.group(2),
811                 "slot": m.group(3),
812                 "function": m.group(4),
813             }
814             for m in matches
815             if m
816         ]
817     context = {
818         "name": name,
819         "bridge": bridge,
820         "mtu": mtu,
821         "domain": domain,
822         "forward": forward,
823         "nat": nat,
824         "interfaces": interfaces.split(" ") if interfaces else [],
825         "addresses": addresses_context,
826         "pf": physical_function,
827         "vport": vport_context,
828         "vlan": tag_context,
829         "dns": dns,
830         "ip_configs": [
831             {
832                 "address": ipaddress.ip_network(config["cidr"]),
833                 "dhcp_ranges": config.get("dhcp_ranges", []),
834                 "hosts": config.get("hosts", {}),
835                 "bootp": config.get("bootp", {}),
836                 "tftp": config.get("tftp"),
837             }
838             for config in ip_configs or []
839         ],
840         "yesno": lambda v: "yes" if v else "no",
841     }
842     fn_ = "libvirt_network.jinja"
843     try:
844         template = JINJA.get_template(fn_)
845     except jinja2.exceptions.TemplateNotFound:
846         log.error("Could not load template %s", fn_)
847         return ""
848     return template.render(**context)
849 def _gen_pool_xml(
850     name,
851     ptype,
852     target=None,
853     permissions=None,
854     source_devices=None,
855     source_dir=None,
856     source_adapter=None,
857     source_hosts=None,
858     source_auth=None,
859     source_name=None,
860     source_format=None,
861     source_initiator=None,
862 ):
863     hosts = [host.split(":") for host in source_hosts or []]
864     source = None
865     if any(
866         [
867             source_devices,
868             source_dir,
869             source_adapter,
870             hosts,
871             source_auth,
872             source_name,
873             source_format,
874             source_initiator,
875         ]
876     ):
877         source = {
878             "devices": source_devices or [],
879             "dir": source_dir
880             if source_format != "cifs" or not source_dir
881             else source_dir.lstrip("/"),
882             "adapter": source_adapter,
883             "hosts": [
884                 {"name": host[0], "port": host[1] if len(host) &gt; 1 else None}
885                 for host in hosts
886             ],
887             "auth": source_auth,
888             "name": source_name,
889             "format": source_format,
890             "initiator": source_initiator,
891         }
892     context = {
893         "name": name,
894         "ptype": ptype,
895         "target": {"path": target, "permissions": permissions},
896         "source": source,
897     }
898     fn_ = "libvirt_pool.jinja"
899     try:
900         template = JINJA.get_template(fn_)
901     except jinja2.exceptions.TemplateNotFound:
902         log.error("Could not load template %s", fn_)
903         return ""
904     return template.render(**context)
905 def _gen_secret_xml(auth_type, usage, description):
906     context = {
907         "type": auth_type,
908         "usage": usage,
909         "description": description,
910     }
911     fn_ = "libvirt_secret.jinja"
912     try:
913         template = JINJA.get_template(fn_)
914     except jinja2.exceptions.TemplateNotFound:
915         log.error("Could not load template %s", fn_)
916         return ""
917     return template.render(**context)
918 def _get_images_dir():
919     img_dir = __salt__["config.get"]("virt:images")
920     log.debug("Image directory from config option `virt:images` is %s", img_dir)
921     return img_dir
922 def _zfs_image_create(
923     vm_name,
924     pool,
925     disk_name,
926     hostname_property_name,
927     sparse_volume,
928     disk_size,
929     disk_image_name,
930 ):
931     if not disk_image_name and not disk_size:
932         raise CommandExecutionError(
933             "Unable to create new disk {}, please specify"
934             " the disk image name or disk size argument".format(disk_name)
935         )
936     if not pool:
937         raise CommandExecutionError(
938             "Unable to create new disk {}, please specify the disk pool name".format(
939                 disk_name
940             )
941         )
942     destination_fs = os.path.join(pool, "{}.{}".format(vm_name, disk_name))
943     log.debug("Image destination will be %s", destination_fs)
944     existing_disk = __salt__["zfs.list"](name=pool)
945     if "error" in existing_disk:
946         raise CommandExecutionError(
947             "Unable to create new disk {}. {}".format(
948                 destination_fs, existing_disk["error"]
949             )
950         )
951     elif destination_fs in existing_disk:
952         log.info("ZFS filesystem %s already exists. Skipping creation", destination_fs)
953         blockdevice_path = os.path.join("/dev/zvol", pool, vm_name)
954         return blockdevice_path
955     properties = {}
956     if hostname_property_name:
957         properties[hostname_property_name] = vm_name
958     if disk_image_name:
959         __salt__["zfs.clone"](
960             name_a=disk_image_name, name_b=destination_fs, properties=properties
961         )
962     elif disk_size:
963         __salt__["zfs.create"](
964             name=destination_fs,
965             properties=properties,
966             volume_size=disk_size,
967             sparse=sparse_volume,
968         )
969     blockdevice_path = os.path.join(
970         "/dev/zvol", pool, "{}.{}".format(vm_name, disk_name)
971     )
972     log.debug("Image path will be %s", blockdevice_path)
973     return blockdevice_path
974 def _qemu_image_create(disk, create_overlay=False, saltenv="base"):
975     disk_size = disk.get("size", None)
976     disk_image = disk.get("image", None)
977     if not disk_size and not disk_image:
978         raise CommandExecutionError(
979             "Unable to create new disk {}, please specify"
980             " disk size and/or disk image argument".format(disk["filename"])
981         )
982     img_dest = disk["source_file"]
983     log.debug("Image destination will be %s", img_dest)
984     img_dir = os.path.dirname(img_dest)
985     log.debug("Image destination directory is %s", img_dir)
986     if not os.path.exists(img_dir):
987         os.makedirs(img_dir)
988     if disk_image:
989         log.debug("Create disk from specified image %s", disk_image)
990         sfn = __salt__["cp.cache_file"](disk_image, saltenv)
991         qcow2 = False
992         if salt.utils.path.which("qemu-img"):
993             res = __salt__["cmd.run"]('qemu-img info "{}"'.format(sfn))
994             imageinfo = salt.utils.yaml.safe_load(res)
995             qcow2 = imageinfo["file format"] == "qcow2"
996         try:
997             if create_overlay and qcow2:
998                 log.info("Cloning qcow2 image %s using copy on write", sfn)
999                 __salt__["cmd.run"](
1000                     'qemu-img create -f qcow2 -o backing_file="{}" "{}"'.format(
1001                         sfn, img_dest
1002                     ).split()
1003                 )
1004             else:
1005                 log.debug("Copying %s to %s", sfn, img_dest)
1006                 salt.utils.files.copyfile(sfn, img_dest)
1007             mask = salt.utils.files.get_umask()
1008             if disk_size and qcow2:
1009                 log.debug("Resize qcow2 image to %sM", disk_size)
1010                 __salt__["cmd.run"](
1011                     'qemu-img resize "{}" {}M'.format(img_dest, disk_size)
1012                 )
1013             log.debug("Apply umask and remove exec bit")
1014             mode = (0o0777 ^ mask) &amp; 0o0666
1015             os.chmod(img_dest, mode)
1016         except OSError as err:
1017             raise CommandExecutionError(
1018                 "Problem while copying image. {} - {}".format(disk_image, err)
1019             )
1020     else:
1021         try:
1022             mask = salt.utils.files.get_umask()
1023             if disk_size:
1024                 log.debug("Create empty image with size %sM", disk_size)
1025                 __salt__["cmd.run"](
1026                     'qemu-img create -f {} "{}" {}M'.format(
1027                         disk.get("format", "qcow2"), img_dest, disk_size
1028                     )
1029                 )
1030             else:
1031                 raise CommandExecutionError(
1032                     "Unable to create new disk {},"
1033                     " please specify &lt;size&gt; argument".format(img_dest)
1034                 )
1035             log.debug("Apply umask and remove exec bit")
1036             mode = (0o0777 ^ mask) &amp; 0o0666
1037             os.chmod(img_dest, mode)
1038         except OSError as err:
1039             raise CommandExecutionError(
1040                 "Problem while creating volume {} - {}".format(img_dest, err)
1041             )
1042     return img_dest
1043 def _seed_image(seed_cmd, img_path, name, config, install, pub_key, priv_key):
1044     log.debug("Seeding image")
1045     __salt__[seed_cmd](
1046         img_path,
1047         id_=name,
1048         config=config,
1049         install=install,
1050         pub_key=pub_key,
1051         priv_key=priv_key,
1052     )
1053 def _disk_volume_create(conn, disk, seeder=None, saltenv="base"):
1054     if disk.get("overlay_image"):
1055         raise SaltInvocationError(
1056             "Disk overlay_image property is not supported when creating volumes,"
1057             "use backing_store_path and backing_store_format instead."
1058         )
1059     pool = conn.storagePoolLookupByName(disk["pool"])
1060     if disk["filename"] in pool.listVolumes():
1061         return
1062     pool_type = ElementTree.fromstring(pool.XMLDesc()).get("type")
1063     backing_path = disk.get("backing_store_path")
1064     backing_format = disk.get("backing_store_format")
1065     backing_store = None
1066     if (
1067         backing_path
1068         and backing_format
1069         and (disk.get("format") == "qcow2" or pool_type == "logical")
1070     ):
1071         backing_store = {"path": backing_path, "format": backing_format}
1072     if backing_store and disk.get("image"):
1073         raise SaltInvocationError(
1074             "Using a template image with a backing store is not possible, "
1075             "choose either of them."
1076         )
1077     vol_xml = _gen_vol_xml(
1078         disk["filename"],
1079         disk.get("size", 0),
1080         format=disk.get("format"),
1081         backing_store=backing_store,
1082     )
1083     _define_vol_xml_str(conn, vol_xml, disk.get("pool"))
1084     if disk.get("image"):
1085         log.debug("Caching disk template image: %s", disk.get("image"))
1086         cached_path = __salt__["cp.cache_file"](disk.get("image"), saltenv)
1087         if seeder:
1088             seeder(cached_path)
1089         _volume_upload(
1090             conn,
1091             disk["pool"],
1092             disk["filename"],
1093             cached_path,
1094             sparse=disk.get("format") == "qcow2",
1095         )
1096 def _disk_profile(conn, profile, hypervisor, disks, vm_name):
1097     default = [{"system": {"size": 8192}}]
1098     if hypervisor == "vmware":
1099         overlay = {"format": "vmdk", "model": "scsi", "device": "disk"}
1100     elif hypervisor in ["qemu", "kvm"]:
1101         overlay = {"device": "disk", "model": "virtio"}
1102     elif hypervisor == "xen":
1103         overlay = {"device": "disk", "model": "xen"}
1104     elif hypervisor == "bhyve":
1105         overlay = {"format": "raw", "model": "virtio", "sparse_volume": False}
1106     else:
1107         overlay = {}
1108     disklist = []
1109     if profile:
1110         disklist = copy.deepcopy(
1111             __salt__["config.get"]("virt:disk", {}).get(profile, default)
1112         )
1113         disklist = [dict(d, name=name) for disk in disklist for name, d in disk.items()]
1114     if disks:
1115         for udisk in disks:
1116             if "name" in udisk:
1117                 found = [disk for disk in disklist if udisk["name"] == disk["name"]]
1118                 if found:
1119                     found[0].update(udisk)
1120                 else:
1121                     disklist.append(udisk)
1122     pool_caps = _pool_capabilities(conn)
1123     for disk in disklist:
1124         if disk.get("device", "disk") == "cdrom" and "model" not in disk:
1125             disk["model"] = "ide"
1126         for key, val in overlay.items():
1127             if key not in disk:
1128                 disk[key] = val
1129         if disk.get("source_file") and os.path.exists(disk["source_file"]):
1130             disk["filename"] = os.path.basename(disk["source_file"])
1131             if not disk.get("format"):
1132                 disk["format"] = (
1133                     "qcow2" if disk.get("device", "disk") != "cdrom" else "raw"
1134                 )
1135         elif vm_name and disk.get("device", "disk") == "disk":
1136             _fill_disk_filename(conn, vm_name, disk, hypervisor, pool_caps)
1137     return disklist
1138 def _fill_disk_filename(conn, vm_name, disk, hypervisor, pool_caps):
1139     disk["filename"] = "{}_{}".format(vm_name, disk["name"])
1140     base_dir = disk.get("pool", None)
1141     if hypervisor in ["qemu", "kvm", "xen"]:
1142         if not base_dir:
1143             base_dir = _get_images_dir()
1144         if base_dir not in conn.listStoragePools():
1145             if not disk.get("format"):
1146                 disk["format"] = "qcow2"
1147             disk["filename"] = "{}.{}".format(disk["filename"], disk["format"])
1148             disk["source_file"] = os.path.join(base_dir, disk["filename"])
1149         else:
1150             if "pool" not in disk:
1151                 disk["pool"] = base_dir
1152             pool_obj = conn.storagePoolLookupByName(base_dir)
1153             pool_xml = ElementTree.fromstring(pool_obj.XMLDesc())
1154             pool_type = pool_xml.get("type")
1155             if pool_type == "disk":
1156                 device = pool_xml.find("./source/device").get("path")
1157                 all_volumes = pool_obj.listVolumes()
1158                 if disk.get("source_file") not in all_volumes:
1159                     indexes = [
1160                         int(re.sub("[a-z]+", "", vol_name)) for vol_name in all_volumes
1161                     ] or [0]
1162                     index = min(
1163                         idx for idx in range(1, max(indexes) + 2) if idx not in indexes
1164                     )
1165                     disk["filename"] = "{}{}".format(os.path.basename(device), index)
1166             if disk.get("source_file"):
1167                 if not disk.get("source_file") in pool_obj.listVolumes():
1168                     raise SaltInvocationError(
1169                         "{} volume doesn't exist in pool {}".format(
1170                             disk.get("source_file"), base_dir
1171                         )
1172                     )
1173                 disk["filename"] = disk["source_file"]
1174                 del disk["source_file"]
1175             if not disk.get("format"):
1176                 volume_options = (
1177                     [
1178                         type_caps.get("options", {}).get("volume", {})
1179                         for type_caps in pool_caps.get("pool_types")
1180                         if type_caps["name"] == pool_type
1181                     ]
1182                     or [{}]
1183                 )[0]
1184                 if "qcow2" in volume_options.get("targetFormatType", []):
1185                     disk["format"] = "qcow2"
1186                 else:
1187                     disk["format"] = volume_options.get("default_format", None)
1188     elif hypervisor == "bhyve" and vm_name:
1189         disk["filename"] = "{}.{}".format(vm_name, disk["name"])
1190         disk["source_file"] = os.path.join(
1191             "/dev/zvol", base_dir or "", disk["filename"]
1192         )
1193     elif hypervisor in ["esxi", "vmware"]:
1194         if not base_dir:
1195             base_dir = __salt__["config.get"]("virt:storagepool", "[0] ")
1196         disk["filename"] = "{}.{}".format(disk["filename"], disk["format"])
1197         disk["source_file"] = "{}{}".format(base_dir, disk["filename"])
1198 def _complete_nics(interfaces, hypervisor):
1199     vmware_overlay = {"type": "bridge", "source": "DEFAULT", "model": "e1000"}
1200     kvm_overlay = {"type": "bridge", "source": "br0", "model": "virtio"}
1201     xen_overlay = {"type": "bridge", "source": "br0", "model": None}
1202     bhyve_overlay = {"type": "bridge", "source": "bridge0", "model": "virtio"}
1203     overlays = {
1204         "xen": xen_overlay,
1205         "kvm": kvm_overlay,
1206         "qemu": kvm_overlay,
1207         "vmware": vmware_overlay,
1208         "bhyve": bhyve_overlay,
1209     }
1210     def _normalize_net_types(attributes):
1211         for type_ in ["bridge", "network"]:
1212             if type_ in attributes:
1213                 attributes["type"] = type_
1214                 attributes["source"] = attributes.pop(type_)
1215         attributes["type"] = attributes.get("type", None)
1216         attributes["source"] = attributes.get("source", None)
1217     def _apply_default_overlay(attributes):
1218         for key, value in overlays[hypervisor].items():
1219             if key not in attributes or not attributes[key]:
1220                 attributes[key] = value
1221     for interface in interfaces:
1222         _normalize_net_types(interface)
1223         if hypervisor in overlays:
1224             _apply_default_overlay(interface)
1225     return interfaces
1226 def _nic_profile(profile_name, hypervisor):
1227     config_data = __salt__["config.get"]("virt:nic", {}).get(
1228         profile_name, [{"eth0": {}}]
1229     )
1230     interfaces = []
1231     def append_dict_profile_to_interface_list(profile_dict):
1232         for interface_name, attributes in profile_dict.items():
1233             attributes["name"] = interface_name
1234             interfaces.append(attributes)
1235     if isinstance(config_data, dict):
1236         append_dict_profile_to_interface_list(config_data)
1237     elif isinstance(config_data, list):
1238         for interface in config_data:
1239             if isinstance(interface, dict):
1240                 if len(interface) == 1:
1241                     append_dict_profile_to_interface_list(interface)
1242                 else:
1243                     interfaces.append(interface)
1244     return _complete_nics(interfaces, hypervisor)
1245 def _get_merged_nics(hypervisor, profile, interfaces=None):
1246     nicp = _nic_profile(profile, hypervisor) if profile else []
1247     log.debug("NIC profile is %s", nicp)
1248     if interfaces:
1249         users_nics = _complete_nics(interfaces, hypervisor)
1250         for unic in users_nics:
1251             found = [nic for nic in nicp if nic["name"] == unic["name"]]
1252             if found:
1253                 found[0].update(unic)
1254             else:
1255                 nicp.append(unic)
1256         log.debug("Merged NICs: %s", nicp)
1257     return nicp
1258 def _handle_remote_boot_params(orig_boot):
1259     """
1260     keys <font color="#8c8774"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= orig_boot.keys()
1261     cases = [
1262         {"efi"},
1263         {"kernel", "initrd", "efi"},
1264         {"kernel", "initrd", "cmdline", "efi"},
1265         {"loader", "nvram"},
1266         {"kernel", "initrd"},
1267         {"kernel", "initrd", "cmdline"},
1268         {"kernel", "initrd", "loader", "nvram"},
1269         {"kernel"</b></font>, "initrd", "cmdline", "loader", "nvram"},
1270     ]
1271     if keys in cases:
1272         for key in keys:
1273             if key == "efi" and type(orig_boot.get(key)) == bool:
1274                 new_boot[key] = orig_boot.get(key)
1275             elif orig_boot.get(key) is not None and salt.utils.virt.check_remote(
1276                 orig_boot.get(key)
1277             ):
1278                 if saltinst_dir is None:
1279                     os.makedirs(CACHE_DIR)
1280                     saltinst_dir = CACHE_DIR
1281                 new_boot[key] = salt.utils.virt.download_remote(
1282                     orig_boot.get(key), saltinst_dir
1283                 )
1284         return new_boot
1285     else:
1286         raise SaltInvocationError(
1287             "Invalid boot parameters,It has to follow this combination: [(kernel,"
1288             " initrd) or/and cmdline] or/and [(loader, nvram) or efi]"
1289         )
1290 def _handle_efi_param(boot, desc):
1291     """
1292     Checks if boot parameter contains efi boolean value, if so, handles the firmware attribute.
1293     :param boot: The boot parameters passed to the init or update functions.
1294     :param desc: The XML description of that domain.
1295     :return: A boolean value.
1296     """
1297     efi_value = boot.get("efi", None) if boot else None
1298     parent_tag = desc.find("os")
1299     os_attrib = parent_tag.attrib
1300     if efi_value is False and os_attrib != {}:
1301         parent_tag.attrib.pop("firmware", None)
1302         return True
1303     elif type(efi_value) == bool and os_attrib == {}:
1304         if efi_value is True and parent_tag.find("loader") is None:
1305             parent_tag.set("firmware", "efi")
1306             return True
1307         if efi_value is False and parent_tag.find("loader") is not None:
1308             parent_tag.remove(parent_tag.find("loader"))
1309             parent_tag.remove(parent_tag.find("nvram"))
1310             return True
1311     elif type(efi_value) != bool:
1312         raise SaltInvocationError("Invalid efi value")
1313     return False
1314 def init(
1315     name,
1316     cpu,
1317     mem,
1318     nic="default",
1319     interfaces=None,
1320     hypervisor=None,
1321     start=True,  # pylint: disable=redefined-outer-name
1322     disk="default",
1323     disks=None,
1324     saltenv="base",
1325     seed=True,
1326     install=True,
1327     pub_key=None,
1328     priv_key=None,
1329     seed_cmd="seed.apply",
1330     graphics=None,
1331     os_type=None,
1332     arch=None,
1333     boot=None,
1334     boot_dev=None,
1335     numatune=None,
1336     hypervisor_features=None,
1337     clock=None,
1338     serials=None,
1339     consoles=None,
1340     stop_on_reboot=False,
1341     host_devices=None,
1342     **kwargs
1343 ):
1344     """
1345     Initialize a new vm
1346     :param name: name of the virtual machine to create
1347     :param cpu:
1348         Number of virtual CPUs to assign to the virtual machine or a dictionary with detailed information to configure
1349         cpu model and topology, numa node tuning, cpu tuning and iothreads allocation. The structure of the dictionary is
1350         documented in :ref:`init-cpu-def`.
1351         .. code-block:: yaml
1352              cpu:
1353                placement: static
1354                cpuset: 0-11
1355                current: 5
1356                maximum: 12
1357                vcpus:
1358                  0:
1359                    enabled: True
1360                    hotpluggable: False
1361                    order: 1
1362                  1:
1363                    enabled: False
1364                    hotpluggable: True
1365                match: minimum
1366                mode: custom
1367                check: full
1368                vendor: Intel
1369                model:
1370                  name: core2duo
1371                  fallback: allow
1372                  vendor_id: GenuineIntel
1373                topology:
1374                  sockets: 1
1375                  cores: 12
1376                  threads: 1
1377                cache:
1378                  level: 3
1379                  mode: emulate
1380                features:
1381                  lahf: optional
1382                  pcid: require
1383                numa:
1384                  0:
1385                     cpus: 0-3
1386                     memory: 1g
1387                     discard: True
1388                     distances:
1389                       0: 10     # sibling id : value
1390                       1: 21
1391                       2: 31
1392                       3: 41
1393                  1:
1394                     cpus: 4-6
1395                     memory: 1g
1396                     memAccess: shared
1397                     distances:
1398                       0: 21
1399                       1: 10
1400                       2: 21
1401                       3: 31
1402                tuning:
1403                     vcpupin:
1404                       0: 1-4,^2  # vcpuid : cpuset
1405                       1: 0,1
1406                       2: 2,3
1407                       3: 0,4
1408                     emulatorpin: 1-3
1409                     iothreadpin:
1410                       1: 5,6    # iothread id: cpuset
1411                       2: 7,8
1412                     shares: 2048
1413                     period: 1000000
1414                     quota: -1
1415                     global_period: 1000000
1416                     global_quota: -1
1417                     emulator_period: 1000000
1418                     emulator_quota: -1
1419                     iothread_period: 1000000
1420                     iothread_quota: -1
1421                     vcpusched:
1422                       - scheduler: fifo
1423                         priority: 1
1424                         vcpus: 0,3-5
1425                       - scheduler: rr
1426                         priority: 3
1427                     iothreadsched:
1428                       - scheduler: idle
1429                       - scheduler: batch
1430                         iothreads: 2,3
1431                     emulatorsched:
1432                       - scheduler: batch
1433                     cachetune:
1434                       0-3:      # vcpus set
1435                         0:      # cache id
1436                           level: 3
1437                           type: both
1438                           size: 4
1439                         1:
1440                           level: 3
1441                           type: both
1442                           size: 6
1443                         monitor:
1444                           1: 3
1445                           0-3: 3
1446                       4-5:
1447                         monitor:
1448                           4: 3  # vcpus: level
1449                           5: 3
1450                     memorytune:
1451                       0-3:      # vcpus set
1452                         0: 60   # node id: bandwidth
1453                       4-5:
1454                         0: 60
1455                iothreads: 4
1456         .. versionadded:: 3003
1457     :param mem: Amount of memory to allocate to the virtual machine in MiB. Since 3002, a dictionary can be used to
1458         contain detailed configuration which support memory allocation or tuning. Supported parameters are ``boot``,
1459         ``current``, ``max``, ``slots``, ``hard_limit``, ``soft_limit``, ``swap_hard_limit``, ``min_guarantee``,
1460         ``hugepages`` ,  ``nosharepages``, ``locked``, ``source``, ``access``, ``allocation`` and ``discard``. The structure
1461         of the dictionary is documented in  :ref:`init-mem-def`. Both decimal and binary base are supported. Detail unit
1462         specification is documented  in :ref:`virt-units`. Please note that the value for ``slots`` must be an integer.
1463         .. code-block:: python
1464             {
1465                 'boot': 1g,
1466                 'current': 1g,
1467                 'max': 1g,
1468                 'slots': 10,
1469                 'hard_limit': '1024',
1470                 'soft_limit': '512m',
1471                 'swap_hard_limit': '1g',
1472                 'min_guarantee': '512mib',
1473                 'hugepages': [{'nodeset': '0-3,^2', 'size': '1g'}, {'nodeset': '2', 'size': '2m'}],
1474                 'nosharepages': True,
1475                 'locked': True,
1476                 'source': 'file',
1477                 'access': 'shared',
1478                 'allocation': 'immediate',
1479                 'discard': True
1480             }
1481         .. versionchanged:: 3002
1482     :param nic: NIC profile to use (Default: ``'default'``).
1483                 The profile interfaces can be customized / extended with the interfaces parameter.
1484                 If set to ``None``, no profile will be used.
1485     :param interfaces:
1486         List of dictionaries providing details on the network interfaces to create.
1487         These data are merged with the ones from the nic profile. The structure of
1488         each dictionary is documented in :ref:`init-nic-def`.
1489         .. versionadded:: 2019.2.0
1490     :param hypervisor: the virtual machine type. By default the value will be computed according
1491                        to the virtual host capabilities.
1492     :param start: ``True`` to start the virtual machine after having defined it (Default: ``True``)
1493     :param disk: Disk profile to use (Default: ``'default'``). If set to ``None``, no profile will be used.
1494     :param disks: List of dictionaries providing details on the disk devices to create.
1495                   These data are merged with the ones from the disk profile. The structure of
1496                   each dictionary is documented in :ref:`init-disk-def`.
1497                   .. versionadded:: 2019.2.0
1498     :param saltenv: Fileserver environment (Default: ``'base'``).
1499                     See :mod:`cp module for more details &lt;salt.modules.cp&gt;`
1500     :param seed: ``True`` to seed the disk image. Only used when the ``image`` parameter is provided.
1501                  (Default: ``True``)
1502     :param install: install salt minion if absent (Default: ``True``)
1503     :param pub_key: public key to seed with (Default: ``None``)
1504     :param priv_key: public key to seed with (Default: ``None``)
1505     :param seed_cmd: Salt command to execute to seed the image. (Default: ``'seed.apply'``)
1506     :param graphics:
1507         Dictionary providing details on the graphics device to create. (Default: ``None``)
1508         See :ref:`init-graphics-def` for more details on the possible values.
1509         .. versionadded:: 2019.2.0
1510     :param os_type:
1511         type of virtualization as found in the ``//os/type`` element of the libvirt definition.
1512         The default value is taken from the host capabilities, with a preference for ``hvm``.
1513         .. versionadded:: 2019.2.0
1514     :param arch:
1515         architecture of the virtual machine. The default value is taken from the host capabilities,
1516         but ``x86_64`` is prefed over ``i686``.
1517         .. versionadded:: 2019.2.0
1518     :param config: minion configuration to use when seeding.
1519                    See :mod:`seed module for more details &lt;salt.modules.seed&gt;`
1520     :param boot_dev: String of space-separated devices to boot from (Default: ``'hd'``)
1521     :param connection: libvirt connection URI, overriding defaults
1522                        .. versionadded:: 2019.2.0
1523     :param username: username to connect with, overriding defaults
1524                      .. versionadded:: 2019.2.0
1525     :param password: password to connect with, overriding defaults
1526                      .. versionadded:: 2019.2.0
1527     :param stop_on_reboot:
1528         If set to ``True`` the guest will stop instead of rebooting.
1529         This is specially useful when creating a virtual machine with an installation cdrom or
1530         an autoinstallation needing a special first boot configuration.
1531         Defaults to ``False``
1532         .. versionadded:: 3003
1533     :param boot:
1534         Specifies kernel, initial ramdisk and kernel command line parameters for the virtual machine.
1535         This is an optional parameter, all of the keys are optional within the dictionary. The structure of
1536         the dictionary is documented in :ref:`init-boot-def`. If a remote path is provided to kernel or initrd,
1537         salt will handle the downloading of the specified remote file and modify the XML accordingly.
1538         To boot VM with UEFI, specify loader and nvram path or specify 'efi': ``True`` if your libvirtd version
1539         is &gt;= 5.2.0 and QEMU &gt;= 3.0.0.
1540         .. versionadded:: 3000
1541         .. code-block:: python
1542             {
1543                 'kernel': '/root/f8-i386-vmlinuz',
1544                 'initrd': '/root/f8-i386-initrd',
1545                 'cmdline': 'console=ttyS0 ks=http://example.com/f8-i386/os/',
1546                 'loader': '/usr/share/OVMF/OVMF_CODE.fd',
1547                 'nvram': '/usr/share/OVMF/OVMF_VARS.ms.fd'
1548             }
1549     :param boot_dev:
1550         Space separated list of devices to boot from sorted by decreasing priority.
1551         Values can be ``hd``, ``fd``, ``cdrom`` or ``network``.
1552         By default, the value will ``"hd"``.
1553     :param numatune:
1554         The optional numatune element provides details of how to tune the performance of a NUMA host via controlling NUMA
1555         policy for domain process. The optional ``memory`` element specifies how to allocate memory for the domain process
1556         on a NUMA host. ``memnode`` elements can specify memory allocation policies per each guest NUMA node. The definition
1557         used in the dictionary can be found at :ref:`init-cpu-def`.
1558         .. versionadded:: 3003
1559         .. code-block:: python
1560             {
1561                 'memory': {'mode': 'strict', 'nodeset': '0-11'},
1562                 'memnodes': {0: {'mode': 'strict', 'nodeset': 1}, 1: {'mode': 'preferred', 'nodeset': 2}}
1563             }
1564     :param hypervisor_features:
1565         Enable or disable hypervisor-specific features on the virtual machine.
1566         .. versionadded:: 3003
1567         .. code-block:: yaml
1568             hypervisor_features:
1569               kvm-hint-dedicated: True
1570     :param clock:
1571         Configure the guest clock.
1572         The value is a dictionary with the following keys:
1573         adjustment
1574             time adjustment in seconds or ``reset``
1575         utc
1576             set to ``False`` to use the host local time as the guest clock. Defaults to ``True``.
1577         timezone
1578             synchronize the guest to the correspding timezone
1579         timers
1580             a dictionary associating the timer name with its configuration.
1581             This configuration is a dictionary with the properties ``track``, ``tickpolicy``,
1582             ``catchup``, ``frequency``, ``mode``, ``present``, ``slew``, ``threshold`` and ``limit``.
1583             See `libvirt time keeping documentation &lt;https://libvirt.org/formatdomain.html#time-keeping&gt;`_ for the possible values.
1584         .. versionadded:: 3003
1585         Set the clock to local time using an offset in seconds
1586         .. code-block:: yaml
1587             clock:
1588               adjustment: 3600
1589               utc: False
1590         Set the clock to a specific time zone:
1591         .. code-block:: yaml
1592             clock:
1593               timezone: CEST
1594         Tweak guest timers:
1595         .. code-block:: yaml
1596             clock:
1597               timers:
1598                 tsc:
1599                   frequency: 3504000000
1600                   mode: native
1601                 rtc:
1602                   track: wall
1603                   tickpolicy: catchup
1604                   slew: 4636
1605                   threshold: 123
1606                   limit: 2342
1607                 hpet:
1608                   present: False
1609     :param serials:
1610         Dictionary providing details on the serials connection to create. (Default: ``None``)
1611         See :ref:`init-chardevs-def` for more details on the possible values.
1612         .. versionadded:: 3003
1613     :param consoles:
1614         Dictionary providing details on the consoles device to create. (Default: ``None``)
1615         See :ref:`init-chardevs-def` for more details on the possible values.
1616         .. versionadded:: 3003
1617     :param host_devices:
1618         List of host devices to passthrough to the guest.
1619         The value is a list of device names as provided by the :py:func:`~salt.modules.virt.node_devices` function.
1620         (Default: ``None``)
1621         .. versionadded:: 3003
1622     .. _init-cpu-def:
1623     .. rubric:: cpu parameters definition
1624     The cpu parameters dictionary can contain the following properties:
1625     cpuset
1626         a comma-separated list of physical CPU numbers that domain process and virtual CPUs can be pinned to by default.
1627         eg. ``1-4,^3`` cpuset 3 is excluded.
1628     current
1629         the number of virtual cpus available at startup
1630     placement
1631         indicate the CPU placement mode for domain process. the value can be either ``static`` or ``auto``
1632     vcpus
1633         specify the state of individual vcpu. Possible attribute for each individual vcpu include: ``id``, ``enabled``,
1634         ``hotpluggable`` and ``order``. Valid ``ids`` are from 0 to the maximum vCPU count minus 1. ``enabled`` takes
1635         boolean values which controls the state of the vcpu. ``hotpluggable`` take boolean value which controls whether
1636         given vCPU can be hotplugged and hotunplugged. ``order`` takes an integer value which specifies the order to add
1637         the online vCPUs.
1638     match
1639         The cpu attribute ``match`` attribute specifies how strictly the virtual CPU provided to the guest matches the CPU
1640         requirements, possible values are ``minimum``, ``exact`` or ``strict``.
1641     check
1642         Optional cpu attribute ``check`` attribute can be used to request a specific way of checking whether the virtual
1643         CPU matches the specification, possible values are ``none``, ``partial`` and ``full``.
1644     mode
1645         Optional cpu attribute ``mode`` attribute may be used to make it easier to configure a guest CPU to be as close
1646         to host CPU as possible, possible values are ``custom``, ``host-model`` and ``host-passthrough``.
1647     model
1648         specifies CPU model requested by the guest. An optional ``fallback`` attribute can be used to forbid libvirt falls
1649         back to the closest model supported by the hypervisor, possible values are ``allow`` or ``forbid``. ``vendor_id``
1650         attribute can be used to set the vendor id seen by the guest, the length must be exactly 12 characters long.
1651     vendor
1652         specifies CPU vendor requested by the guest.
1653     topology
1654         specifies requested topology of virtual CPU provided to the guest. Four possible attributes , ``sockets``, ``dies``,
1655         ``cores``, and ``threads``, accept non-zero positive integer values. They refer to the number of CPU sockets per
1656         NUMA node, number of dies per socket, number of cores per die, and number of threads per core, respectively.
1657     features
1658         A dictionary contains a set of cpu features to fine-tune features provided by the selected CPU model. Use cpu
1659         feature ``name`` as the key and the ``policy`` as the value. ``policy`` Attribute takes ``force``, ``require``,
1660         ``optional``, ``disable`` or ``forbid``.
1661     cache
1662         describes the virtual CPU cache. Optional attribute ``level`` takes an integer value which describes cache level
1663         ``mode`` attribute supported three possible values: ``emulate``, ``passthrough``, ``disable``
1664     numa
1665         specify the guest numa topology. ``cell`` element specifies a NUMA cell or a NUMA node, ``cpus`` specifies the
1666         CPU or range of CPUs that are part of the node, ``memory`` specifies the size of the node memory. All cells
1667         should have ``id`` attribute in case referring to some cell is necessary in the code. optional attribute
1668         ``memAccess`` control whether the memory is to be mapped as ``shared`` or ``private``, ``discard`` attribute which
1669         fine tunes the discard feature for given numa node, possible values are ``True`` or ``False``.  ``distances``
1670         element define the distance between NUMA cells and ``sibling`` sub-element is used to specify the distance value
1671         between sibling NUMA cells.
1672     vcpupin
1673         The optional vcpupin element specifies which of host's physical CPUs the domain vCPU will be pinned to.
1674     emulatorpin
1675         The optional emulatorpin element specifies which of host physical CPUs the "emulator", a subset of a domain not
1676         including vCPU or iothreads will be pinned to.
1677     iothreadpin
1678         The optional iothreadpin element specifies which of host physical CPUs the IOThreads will be pinned to.
1679     shares
1680         The optional shares element specifies the proportional weighted share for the domain.
1681     period
1682         The optional period element specifies the enforcement interval (unit: microseconds).
1683     quota
1684         The optional quota element specifies the maximum allowed bandwidth (unit: microseconds).
1685     global_period
1686         The optional global_period element specifies the enforcement CFS scheduler interval (unit: microseconds) for the
1687         whole domain in contrast with period which enforces the interval per vCPU.
1688     global_quota
1689         The optional global_quota element specifies the maximum allowed bandwidth (unit: microseconds) within a period
1690         for the whole domain.
1691     emulator_period
1692         The optional emulator_period element specifies the enforcement interval (unit: microseconds).
1693     emulator_quota
1694         The optional emulator_quota element specifies the maximum allowed bandwidth (unit: microseconds) for domain's
1695         emulator threads (those excluding vCPUs).
1696     iothread_period
1697         The optional iothread_period element specifies the enforcement interval (unit: microseconds) for IOThreads.
1698     iothread_quota
1699         The optional iothread_quota element specifies the maximum allowed bandwidth (unit: microseconds) for IOThreads.
1700     vcpusched
1701         specify the scheduler type for vCPUs.
1702         The value is a list of dictionaries with the ``scheduler`` key (values ``batch``, ``idle``, ``fifo``, ``rr``)
1703         and the optional ``priority`` and ``vcpus`` keys. The ``priority`` value usually is a positive integer and the
1704         ``vcpus`` value is a cpu set like ``1-4,^3,6`` or simply the vcpu id.
1705     iothreadsched
1706         specify the scheduler type for IO threads.
1707         The value is a list of dictionaries with the ``scheduler`` key (values ``batch``, ``idle``, ``fifo``, ``rr``)
1708         and the optional ``priority`` and ``vcpus`` keys. The ``priority`` value usually is a positive integer and the
1709         ``vcpus`` value is a cpu set like ``1-4,^3,6`` or simply the vcpu id.
1710     emulatorsched
1711         specify the scheduler type (values batch, idle, fifo, rr) for particular the emulator.
1712         The value is a dictionary with the ``scheduler`` key (values ``batch``, ``idle``, ``fifo``, ``rr``)
1713         and the optional ``priority`` and ``vcpus`` keys. The ``priority`` value usually is a positive integer.
1714     cachetune
1715         Optional cachetune element can control allocations for CPU caches using the resctrl on the host.
1716     monitor
1717         The optional element monitor creates the cache monitor(s) for current cache allocation.
1718     memorytune
1719         Optional memorytune element can control allocations for memory bandwidth using the resctrl on the host.
1720     iothreads
1721         Number of threads for supported disk devices to perform I/O requests. iothread id will be numbered from 1 to
1722         the provided number (Default: None).
1723     .. _init-boot-def:
1724     .. rubric:: Boot parameters definition
1725     The boot parameters dictionary can contains the following properties:
1726     kernel
1727         The URL or path to the kernel to run the virtual machine with.
1728     initrd
1729         The URL or path to the initrd file to run the virtual machine with.
1730     cmdline
1731         The parameters to pass to the kernel provided in the `kernel` property.
1732     loader
1733         The path to the UEFI binary loader to use.
1734         .. versionadded:: 3001
1735     nvram
1736         The path to the UEFI data template. The file will be copied when creating the virtual machine.
1737         .. versionadded:: 3001
1738     efi
1739        A boolean value.
1740        .. versionadded:: 3001
1741     .. _init-mem-def:
1742     .. rubric:: Memory parameter definition
1743     Memory parameter can contain the following properties:
1744     boot
1745         The maximum allocation of memory for the guest at boot time
1746     current
1747         The actual allocation of memory for the guest
1748     max
1749         The run time maximum memory allocation of the guest
1750     slots
1751          specifies the number of slots available for adding memory to the guest
1752     hard_limit
1753         the maximum memory the guest can use
1754     soft_limit
1755         memory limit to enforce during memory contention
1756     swap_hard_limit
1757         the maximum memory plus swap the guest can use
1758     min_guarantee
1759         the guaranteed minimum memory allocation for the guest
1760     hugepages
1761         memory allocated using ``hugepages`` instead of the normal native page size. It takes a list of
1762         dictionaries with ``nodeset`` and ``size`` keys.
1763         For example ``"hugepages": [{"nodeset": "1-4,^3", "size": "2m"}, {"nodeset": "3", "size": "1g"}]``.
1764     nosharepages
1765         boolean value to instruct hypervisor to disable shared pages (memory merge, KSM) for this domain
1766     locked
1767         boolean value that allows memory pages belonging to the domain will be locked in host's memory and the host will
1768         not be allowed to swap them out, which might be required for some workloads such as real-time.
1769     source
1770         possible values are ``file`` which utilizes file memorybacking, ``anonymous`` by default and ``memfd`` backing.
1771         (QEMU/KVM only)
1772     access
1773         specify if the memory is to be ``shared`` or ``private``. This can be overridden per numa node by memAccess.
1774     allocation
1775         specify when to allocate the memory by supplying either ``immediate`` or ``ondemand``.
1776     discard
1777         boolean value to ensure the memory content is discarded just before guest shuts down (or when DIMM module is
1778         unplugged). Please note that this is just an optimization and is not guaranteed to work in all cases
1779         (e.g. when hypervisor crashes). (QEMU/KVM only)
1780     .. _init-nic-def:
1781     .. rubric:: Network Interfaces Definitions
1782     Network interfaces dictionaries can contain the following properties:
1783     name
1784         Name of the network interface. This is only used as a key to merge with the profile data
1785     type
1786         Network type. One of ``'bridge'``, ``'network'``
1787     source
1788         The network source, typically the bridge or network name
1789     mac
1790         The desired mac address, computed if ``None`` (Default: ``None``).
1791     model
1792         The network card model (Default: depends on the hypervisor)
1793     .. _init-disk-def:
1794     .. rubric:: Disks Definitions
1795     Disk dictionaries can contain the following properties:
1796     name
1797         Name of the disk. This is mostly used in the name of the disk image and as a key to merge
1798         with the profile data.
1799     format
1800         Format of the disk image, like ``'qcow2'``, ``'raw'``, ``'vmdk'``.
1801         (Default: depends on the hypervisor)
1802     size
1803         Disk size in MiB
1804     pool
1805         Path to the folder or name of the pool where disks should be created.
1806         (Default: depends on hypervisor and the virt:storagepool configuration)
1807         .. versionchanged:: 3001
1808         If the value contains no '/', it is considered a pool name where to create a volume.
1809         Using volumes will be mandatory for some pools types like rdb, iscsi, etc.
1810     model
1811         One of the disk busses allowed by libvirt (Default: depends on hypervisor)
1812         See the libvirt `disk element`_ documentation for the allowed bus types.
1813     image
1814         Path to the image to use for the disk. If no image is provided, an empty disk will be created
1815         (Default: ``None``)
1816         Note that some pool types do not support uploading an image. This list can evolve with libvirt
1817         versions.
1818     overlay_image
1819         ``True`` to create a QCOW2 disk image with ``image`` as backing file. If ``False``
1820         the file pointed to by the ``image`` property will simply be copied. (Default: ``False``)
1821         .. versionchanged:: 3001
1822         This property is only valid on path-based disks, not on volumes. To create a volume with a
1823         backing store, set the ``backing_store_path`` and ``backing_store_format`` properties.
1824     backing_store_path
1825         Path to the backing store image to use. This can also be the name of a volume to use as
1826         backing store within the same pool.
1827         .. versionadded:: 3001
1828     backing_store_format
1829         Image format of the disk or volume to use as backing store. This property is mandatory when
1830         using ``backing_store_path`` to avoid `problems &lt;https://libvirt.org/kbase/backing_chains.html#troubleshooting&gt;`_
1831         .. versionadded:: 3001
1832     source_file
1833         Absolute path to the disk image to use. Not to be confused with ``image`` parameter. This
1834         parameter is useful to use disk images that are created outside of this module. Can also
1835         be ``None`` for devices that have no associated image like cdroms.
1836         .. versionchanged:: 3001
1837         For volume disks, this can be the name of a volume already existing in the storage pool.
1838     device
1839         Type of device of the disk. Can be one of 'disk', 'cdrom', 'floppy' or 'lun'.
1840         (Default: ``'disk'``)
1841     hostname_property
1842         When using ZFS volumes, setting this value to a ZFS property ID will make Salt store the name of the
1843         virtual machine inside this property. (Default: ``None``)
1844     sparse_volume
1845         Boolean to specify whether to use a thin provisioned ZFS volume.
1846         Example profile for a bhyve VM with two ZFS disks. The first is
1847         cloned from the specified image. The second disk is a thin
1848         provisioned volume.
1849         .. code-block:: yaml
1850             virt:
1851               disk:
1852                 two_zvols:
1853                   - system:
1854                       image: zroot/bhyve/CentOS-7-x86_64-v1@v1.0.5
1855                       hostname_property: virt:hostname
1856                       pool: zroot/bhyve/guests
1857                   - data:
1858                       pool: tank/disks
1859                       size: 20G
1860                       hostname_property: virt:hostname
1861                       sparse_volume: True
1862     io
1863         I/O control policy. String value amongst ``native``, ``threads`` and ``io_uring``.
1864         (Default: ``native``)
1865         .. versionadded:: 3003
1866     iothread_id
1867         I/O thread id to assign the disk to.
1868         (Default: none assigned)
1869         .. versionadded:: 3003
1870     .. _init-graphics-def:
1871     .. rubric:: Graphics Definition
1872     The graphics dictionary can have the following properties:
1873     type
1874         Graphics type. The possible values are ``none``, ``'spice'``, ``'vnc'`` and other values
1875         allowed as a libvirt graphics type (Default: ``None``)
1876         See the libvirt `graphics element`_ documentation for more details on the possible types.
1877     port
1878         Port to export the graphics on for ``vnc``, ``spice`` and ``rdp`` types.
1879     tls_port
1880         Port to export the graphics over a secured connection for ``spice`` type.
1881     listen
1882         Dictionary defining on what address to listen on for ``vnc``, ``spice`` and ``rdp``.
1883         It has a ``type`` property with ``address`` and ``None`` as possible values, and an
1884         ``address`` property holding the IP or hostname to listen on.
1885         By default, not setting the ``listen`` part of the dictionary will default to
1886         listen on all addresses.
1887     .. _init-chardevs-def:
1888     .. rubric:: Serials and Consoles Definitions
1889     Serial dictionaries can contain the following properties:
1890     type
1891         Type of the serial connection, like ``'tcp'``, ``'pty'``, ``'file'``, ``'udp'``, ``'dev'``,
1892         ``'pipe'``, ``'unix'``.
1893     path
1894         Path to the source device. Can be a log file, a host character device to pass through,
1895         a unix socket, a named pipe path.
1896     host
1897         The serial UDP or TCP host name.
1898         (Default: 23023)
1899     port
1900         The serial UDP or TCP port number.
1901         (Default: 23023)
1902     protocol
1903         Name of the TCP connection protocol.
1904         (Default: telnet)
1905     tls
1906         Boolean value indicating whether to use hypervisor TLS certificates environment for TCP devices.
1907     target_port
1908         The guest device port number starting from 0
1909     target_type
1910         The guest device type. Common values are ``serial``, ``virtio`` or ``usb-serial``, but more are documented in
1911         `the libvirt documentation &lt;https://libvirt.org/formatdomain.html#consoles-serial-parallel-channel-devices&gt;`_.
1912     .. rubric:: CLI Example
1913     .. code-block:: bash
1914         salt 'hypervisor' virt.init vm_name 4 512 salt://path/to/image.raw
1915         salt 'hypervisor' virt.init vm_name 4 512 /var/lib/libvirt/images/img.raw
1916         salt 'hypervisor' virt.init vm_name 4 512 nic=profile disk=profile
1917     The disk images will be created in an image folder within the directory
1918     defined by the ``virt:images`` option. Its default value is
1919     ``/srv/salt-images/`` but this can changed with such a configuration:
1920     .. code-block:: yaml
1921         virt:
1922             images: /data/my/vm/images/
1923     .. _disk element: https://libvirt.org/formatdomain.html#elementsDisks
1924     .. _graphics element: https://libvirt.org/formatdomain.html#elementsGraphics
1925     """
1926     try:
1927         conn = __get_conn(**kwargs)
1928         caps = _capabilities(conn)
1929         os_types = sorted({guest["os_type"] for guest in caps["guests"]})
1930         arches = sorted({guest["arch"]["name"] for guest in caps["guests"]})
1931         virt_hypervisor = hypervisor
1932         if not virt_hypervisor:
1933             hypervisors = sorted(
1934                 {
1935                     x
1936                     for y in [
1937                         guest["arch"]["domains"].keys() for guest in caps["guests"]
1938                     ]
1939                     for x in y
1940                 }
1941             )
1942             if len(hypervisors) == 0:
1943                 raise SaltInvocationError("No supported hypervisors were found")
1944             virt_hypervisor = "kvm" if "kvm" in hypervisors else hypervisors[0]
1945         virt_hypervisor = "vmware" if virt_hypervisor == "esxi" else virt_hypervisor
1946         log.debug("Using hypervisor %s", virt_hypervisor)
1947         nicp = _get_merged_nics(virt_hypervisor, nic, interfaces)
1948         diskp = _disk_profile(conn, disk, virt_hypervisor, disks, name)
1949         for _disk in diskp:
1950             if _disk.get("device", "disk") == "cdrom":
1951                 continue
1952             log.debug("Creating disk for VM [ %s ]: %s", name, _disk)
1953             if virt_hypervisor == "vmware":
1954                 if "image" in _disk:
1955                     raise SaltInvocationError(
1956                         "virt.init does not support image "
1957                         "template in conjunction with esxi hypervisor"
1958                     )
1959                 else:
1960                     log.debug("Generating libvirt XML for %s", _disk)
1961                     volume_name = "{}/{}".format(name, _disk["name"])
1962                     filename = "{}.{}".format(volume_name, _disk["format"])
1963                     vol_xml = _gen_vol_xml(
1964                         filename, _disk["size"], format=_disk["format"]
1965                     )
1966                     _define_vol_xml_str(conn, vol_xml, pool=_disk.get("pool"))
1967             elif virt_hypervisor in ["qemu", "kvm", "xen"]:
1968                 def seeder(path):
1969                     _seed_image(
1970                         seed_cmd,
1971                         path,
1972                         name,
1973                         kwargs.get("config"),
1974                         install,
1975                         pub_key,
1976                         priv_key,
1977                     )
1978                 create_overlay = _disk.get("overlay_image", False)
1979                 format = _disk.get("format")
1980                 if _disk.get("source_file"):
1981                     if os.path.exists(_disk["source_file"]):
1982                         img_dest = _disk["source_file"]
1983                     else:
1984                         img_dest = _qemu_image_create(_disk, create_overlay, saltenv)
1985                 else:
1986                     _disk_volume_create(conn, _disk, seeder if seed else None, saltenv)
1987                     img_dest = None
1988                 if seed and img_dest and _disk.get("image", None):
1989                     seeder(img_dest)
1990             elif hypervisor in ["bhyve"]:
1991                 img_dest = _zfs_image_create(
1992                     vm_name=name,
1993                     pool=_disk.get("pool"),
1994                     disk_name=_disk.get("name"),
1995                     disk_size=_disk.get("size"),
1996                     disk_image_name=_disk.get("image"),
1997                     hostname_property_name=_disk.get("hostname_property"),
1998                     sparse_volume=_disk.get("sparse_volume"),
1999                 )
2000             else:
2001                 raise SaltInvocationError(
2002                     "Unsupported hypervisor when handling disk image: {}".format(
2003                         virt_hypervisor
2004                     )
2005                 )
2006         log.debug("Generating VM XML")
2007         if os_type is None:
2008             os_type = "hvm" if "hvm" in os_types else os_types[0]
2009         if arch is None:
2010             arch = "x86_64" if "x86_64" in arches else arches[0]
2011         if boot is not None:
2012             boot = _handle_remote_boot_params(boot)
2013         vm_xml = _gen_xml(
2014             conn,
2015             name,
2016             cpu,
2017             mem,
2018             diskp,
2019             nicp,
2020             virt_hypervisor,
2021             os_type,
2022             arch,
2023             graphics,
2024             boot,
2025             boot_dev,
2026             numatune,
2027             hypervisor_features,
2028             clock,
2029             serials,
2030             consoles,
2031             stop_on_reboot,
2032             host_devices,
2033             **kwargs
2034         )
2035         log.debug("New virtual machine definition: %s", vm_xml)
2036         conn.defineXML(vm_xml)
2037     except libvirt.libvirtError as err:
2038         conn.close()
2039         raise CommandExecutionError(err.get_error_message())
2040     if start:
2041         log.debug("Starting VM %s", name)
2042         _get_domain(conn, name).create()
2043     conn.close()
2044     return True
2045 def _disks_equal(disk1, disk2):
2046     """
2047     Test if two disk elements should be considered like the same device
2048     """
2049     target1 = disk1.find("target")
2050     target2 = disk2.find("target")
2051     disk1_dict = xmlutil.to_dict(disk1, True)
2052     disk2_dict = xmlutil.to_dict(disk2, True)
2053     source1_dict = disk1_dict.get("source", {})
2054     source2_dict = disk2_dict.get("source", {})
2055     io1 = disk1_dict.get("driver", {}).get("io", "native")
2056     io2 = disk2_dict.get("driver", {}).get("io", "native")
2057     if source1_dict:
2058         source1_dict.pop("index", None)
2059     if source2_dict:
2060         source2_dict.pop("index", None)
2061     return (
2062         source1_dict == source2_dict
2063         and target1 is not None
2064         and target2 is not None
2065         and target1.get("bus") == target2.get("bus")
2066         and disk1.get("device", "disk") == disk2.get("device", "disk")
2067         and target1.get("dev") == target2.get("dev")
2068         and io1 == io2
2069     )
2070 def _nics_equal(nic1, nic2):
2071     """
2072     Test if two interface elements should be considered like the same device
2073     """
2074     def _filter_nic(nic):
2075         """
2076         Filter out elements to ignore when comparing nics
2077         """
2078         source_node = nic.find("source")
2079         source_attrib = source_node.attrib if source_node is not None else {}
2080         source_type = "network" if "network" in source_attrib else nic.attrib["type"]
2081         source_getters = {
2082             "network": lambda n: n.get("network"),
2083             "bridge": lambda n: n.get("bridge"),
2084             "direct": lambda n: n.get("dev"),
2085             "hostdev": lambda n: _format_pci_address(n.find("address")),
2086         }
2087         return {
2088             "type": source_type,
2089             "source": source_getters[source_type](source_node)
2090             if source_node is not None
2091             else None,
2092             "model": nic.find("model").attrib["type"]
2093             if nic.find("model") is not None
2094             else None,
2095         }
2096     def _get_mac(nic):
2097         return (
2098             nic.find("mac").attrib["address"].lower()
2099             if nic.find("mac") is not None
2100             else None
2101         )
2102     mac1 = _get_mac(nic1)
2103     mac2 = _get_mac(nic2)
2104     macs_equal = not mac1 or not mac2 or mac1 == mac2
2105     return _filter_nic(nic1) == _filter_nic(nic2) and macs_equal
2106 def _graphics_equal(gfx1, gfx2):
2107     """
2108     Test if two graphics devices should be considered the same device
2109     """
2110     def _filter_graphics(gfx):
2111         """
2112         When the domain is running, the graphics element may contain additional properties
2113         with the default values. This function will strip down the default values.
2114         """
2115         gfx_copy = copy.deepcopy(gfx)
2116         defaults = [
2117             {"node": ".", "attrib": "port", "values": ["5900", "-1"]},
2118             {"node": ".", "attrib": "address", "values": ["127.0.0.1"]},
2119             {"node": "listen", "attrib": "address", "values": ["127.0.0.1"]},
2120         ]
2121         for default in defaults:
2122             node = gfx_copy.find(default["node"])
2123             attrib = default["attrib"]
2124             if node is not None and (
2125                 attrib in node.attrib and node.attrib[attrib] in default["values"]
2126             ):
2127                 node.attrib.pop(attrib)
2128         return gfx_copy
2129     return xmlutil.to_dict(_filter_graphics(gfx1), True) == xmlutil.to_dict(
2130         _filter_graphics(gfx2), True
2131     )
2132 def _hostdevs_equal(dev1, dev2):
2133     """
2134     Test if two hostdevs devices should be considered the same device
2135     """
2136     def _filter_hostdevs(dev):
2137         """
2138         When the domain is running, the hostdevs element may contain additional properties.
2139         This function will only keep the ones we care about
2140         """
2141         type_ = dev.get("type")
2142         definition = {
2143             "type": type_,
2144         }
2145         if type_ == "pci":
2146             address_node = dev.find("./source/address")
2147             for attr in ["domain", "bus", "slot", "function"]:
2148                 definition[attr] = address_node.get(attr)
2149         elif type_ == "usb":
2150             for attr in ["vendor", "product"]:
2151                 definition[attr] = dev.find("./source/" + attr).get("id")
2152         return definition
2153     return _filter_hostdevs(dev1) == _filter_hostdevs(dev2)
2154 def _diff_lists(old, new, comparator):
2155     """
2156     Compare lists to extract the changes
2157     :param old: old list
2158     :param new: new list
2159     :return: a dictionary with ``unchanged``, ``new``, ``deleted`` and ``sorted`` keys
2160     The sorted list is the union of unchanged and new lists, but keeping the original
2161     order from the new list.
2162     """
2163     def _remove_indent(node):
2164         """
2165         Remove the XML indentation to compare XML trees more easily
2166         """
2167         node_copy = copy.deepcopy(node)
2168         node_copy.text = None
2169         for item in node_copy.iter():
2170             item.tail = None
2171         return node_copy
2172     diff = {"unchanged": [], "new": [], "deleted": [], "sorted": []}
2173     old_devices = copy.deepcopy(old)
2174     for new_item in new:
2175         found = [
2176             item
2177             for item in old_devices
2178             if comparator(_remove_indent(item), _remove_indent(new_item))
2179         if found:
2180             old_devices.remove(found[0])
2181             diff<font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>["unchanged"].append(found[0])
2182             diff["sorted"].append(found[0])
2183         else:
2184             diff["new"].append(new_item)
2185             diff["sorted"].append(</b></font>new_item)
2186     diff["deleted"] = old_devices
2187     return diff
2188 def _get_disk_target(targets, disks_count, prefix):
2189     """
2190     Compute the disk target name for a given prefix.
2191     :param targets: the list of already computed targets
2192     :param disks: the number of disks
2193     :param prefix: the prefix of the target name, i.e. "hd"
2194     """
2195     for i in range(disks_count):
2196         ret = "{}{}".format(prefix, string.ascii_lowercase[i])
2197         if ret not in targets:
2198             return ret
2199     return None
2200 def _diff_disk_lists(old, new):
2201     """
2202     Compare disk definitions to extract the changes and fix target devices
2203     :param old: list of ElementTree nodes representing the old disks
2204     :param new: list of ElementTree nodes representing the new disks
2205     """
2206     targets = []
2207     prefixes = ["fd", "hd", "vd", "sd", "xvd", "ubd"]
2208     for disk in new:
2209         target_node = disk.find("target")
2210         target = target_node.get("dev")
2211         prefix = [item for item in prefixes if target.startswith(item)][0]
2212         new_target = _get_disk_target(targets, len(new), prefix)
2213         target_node.set("dev", new_target)
2214         targets.append(new_target)
2215     return _diff_lists(old, new, _disks_equal)
2216 def _diff_interface_lists(old, new):
2217     """
2218     Compare network interface definitions to extract the changes
2219     :param old: list of ElementTree nodes representing the old interfaces
2220     :param new: list of ElementTree nodes representing the new interfaces
2221     """
2222     return _diff_lists(old, new, _nics_equal)
2223 def _diff_graphics_lists(old, new):
2224     """
2225     Compare graphic devices definitions to extract the changes
2226     :param old: list of ElementTree nodes representing the old graphic devices
2227     :param new: list of ElementTree nodes representing the new graphic devices
2228     """
2229     return _diff_lists(old, new, _graphics_equal)
2230 def _diff_hostdev_lists(old, new):
2231     """
2232     Compare hostdev devices definitions to extract the changes
2233     :param old: list of ElementTree nodes representing the old hostdev devices
2234     :param new: list of ElementTree nodes representing the new hostdev devices
2235     """
2236     return _diff_lists(old, new, _hostdevs_equal)
2237 def _expand_cpuset(cpuset):
2238     """
2239     Expand the libvirt cpuset and nodeset values into a list of cpu/node IDs
2240     """
2241     if cpuset is None:
2242         return None
2243     if isinstance(cpuset, int):
2244         return str(cpuset)
2245     result = set()
2246     toremove = set()
2247     for part in cpuset.split(","):
2248         m = re.match("([0-9]+)-([0-9]+)", part)
2249         if m:
2250             result |= set(range(int(m.group(1)), int(m.group(2)) + 1))
2251         elif part.startswith("^"):
2252             toremove.add(int(part[1:]))
2253         else:
2254             result.add(int(part))
2255     cpus = list(result - toremove)
2256     cpus.sort()
2257     cpus = [str(cpu) for cpu in cpus]
2258     return ",".join(cpus)
2259 def _normalize_cpusets(desc, data):
2260     """
2261     Expand the cpusets that can't be expanded by the change_xml() function,
2262     namely the ones that are used as keys and in the middle of the XPath expressions.
2263     """
2264     xpaths = ["cputune/cachetune", "cputune/cachetune/monitor", "cputune/memorytune"]
2265     for xpath in xpaths:
2266         nodes = desc.findall(xpath)
2267         for node in nodes:
2268             node.set("vcpus", _expand_cpuset(node.get("vcpus")))
2269     if not isinstance(data.get("cpu"), dict):
2270         return
2271     tuning = data["cpu"].get("tuning", {})
2272     for child in ["cachetune", "memorytune"]:
2273         if tuning.get(child):
2274             new_item = dict()
2275             for cpuset, value in tuning[child].items():
2276                 if child == "cachetune" and value.get("monitor"):
2277                     value["monitor"] = {
2278                         _expand_cpuset(monitor_cpus): monitor
2279                         for monitor_cpus, monitor in value["monitor"].items()
2280                     }
2281                 new_item[_expand_cpuset(cpuset)] = value
2282             tuning[child] = new_item
2283 def _serial_or_concole_equal(old, new):
2284     def _filter_serial_or_concole(item):
2285         """
2286         Filter out elements to ignore when comparing items
2287         """
2288         return {
2289             "type": item.attrib["type"],
2290             "port": item.find("source").get("service")
2291             if item.find("source") is not None
2292             else None,
2293             "protocol": item.find("protocol").get("type")
2294             if item.find("protocol") is not None
2295             else None,
2296         }
2297     return _filter_serial_or_concole(old) == _filter_serial_or_concole(new)
2298 def _diff_serial_lists(old, new):
2299     """
2300     Compare serial definitions to extract the changes
2301     :param old: list of ElementTree nodes representing the old serials
2302     :param new: list of ElementTree nodes representing the new serials
2303     """
2304     return _diff_lists(old, new, _serial_or_concole_equal)
2305 def _diff_console_lists(old, new):
2306     """
2307     Compare console definitions to extract the changes
2308     :param old: list of ElementTree nodes representing the old consoles
2309     :param new: list of ElementTree nodes representing the new consoles
2310     """
2311     return _diff_lists(old, new, _serial_or_concole_equal)
2312 def _format_pci_address(node):
2313     return "{}:{}:{}.{}".format(
2314         node.get("domain").replace("0x", ""),
2315         node.get("bus").replace("0x", ""),
2316         node.get("slot").replace("0x", ""),
2317         node.get("function").replace("0x", ""),
2318     )
2319 def _almost_equal(current, new):
2320     """
2321     return True if the parameters are numbers that are almost
2322     """
2323     if current is None or new is None:
2324         return False
2325     return abs(current - new) / current &lt; 1e-03
2326 def _compute_device_changes(old_xml, new_xml, to_skip):
2327     """
2328     Compute the device changes between two domain XML definitions.
2329     """
2330     devices_node = old_xml.find("devices")
2331     changes = {}
2332     for dev_type in to_skip:
2333         changes[dev_type] = {}
2334         if not to_skip[dev_type]:
2335             old = devices_node.findall(dev_type)
2336             new = new_xml.findall("devices/{}".format(dev_type))
2337             changes[dev_type] = globals()["_diff_{}_lists".format(dev_type)](old, new)
2338     return changes
2339 def _get_pci_addresses(node):
2340     """
2341     Get all the pci addresses in the node in 0000:00:00.0 form
2342     """
2343     return {_format_pci_address(address) for address in node.findall(".//address")}
2344 def _correct_networks(conn, desc):
2345     """
2346     Adjust the interface devices matching existing networks.
2347     Returns the network interfaces XML definition as string mapped to the new device node.
2348     """
2349     networks = [ElementTree.fromstring(net.XMLDesc()) for net in conn.listAllNetworks()]
2350     nics = desc.findall("devices/interface")
2351     device_map = {}
2352     for nic in nics:
2353         if nic.get("type") == "hostdev":
2354             addr = _get_pci_addresses(nic.find("source"))
2355             matching_nets = [
2356                 net
2357                 for net in networks
2358                 if net.find("forward").get("mode") == "hostdev"
2359                 and addr &amp; _get_pci_addresses(net)
2360             ]
2361             if matching_nets:
2362                 old_xml = ElementTree.tostring(nic)
2363                 nic.set("type", "network")
2364                 nic.find("source").set("network", matching_nets[0].find("name").text)
2365                 device_map[nic] = old_xml
2366     return device_map
2367 def _update_live(domain, new_desc, mem, cpu, old_mem, old_cpu, to_skip, test):
2368     """
2369     Perform the live update of a domain.
2370     """
2371     status = {}
2372     errors = []
2373     if not domain.isActive():
2374         return status, errors
2375     commands = []
2376     if cpu and (isinstance(cpu, int) or isinstance(cpu, dict) and cpu.get("maximum")):
2377         new_cpu = cpu.get("maximum") if isinstance(cpu, dict) else cpu
2378         if old_cpu != new_cpu and new_cpu is not None:
2379             commands.append(
2380                 {
2381                     "device": "cpu",
2382                     "cmd": "setVcpusFlags",
2383                     "args": [new_cpu, libvirt.VIR_DOMAIN_AFFECT_LIVE],
2384                 }
2385             )
2386     if mem:
2387         if isinstance(mem, dict):
2388             new_mem = (
2389                 int(_handle_unit(mem.get("current")) / 1024)
2390                 if "current" in mem
2391                 else None
2392             )
2393         elif isinstance(mem, int):
2394             new_mem = int(mem * 1024)
2395         if not _almost_equal(old_mem, new_mem) and new_mem is not None:
2396             commands.append(
2397                 {
2398                     "device": "mem",
2399                     "cmd": "setMemoryFlags",
2400                     "args": [new_mem, libvirt.VIR_DOMAIN_AFFECT_LIVE],
2401                 }
2402             )
2403     old_desc = ElementTree.fromstring(domain.XMLDesc(0))
2404     changed_devices = {"interface": _correct_networks(domain.connect(), old_desc)}
2405     changes = _compute_device_changes(old_desc, new_desc, to_skip)
2406     removable_changes = []
2407     new_disks = []
2408     for new_disk in changes["disk"].get("new", []):
2409         device = new_disk.get("device", "disk")
2410         if device not in ["cdrom", "floppy"]:
2411             new_disks.append(new_disk)
2412             continue
2413         target_dev = new_disk.find("target").get("dev")
2414         matching = [
2415             old_disk
2416             for old_disk in changes["disk"].get("deleted", [])
2417             if old_disk.get("device", "disk") == device
2418             and old_disk.find("target").get("dev") == target_dev
2419         ]
2420         if not matching:
2421             new_disks.append(new_disk)
2422         else:
2423             updated_disk = matching[0]
2424             changes["disk"]["deleted"].remove(updated_disk)
2425             removable_changes.append(updated_disk)
2426             source_node = updated_disk.find("source")
2427             new_source_node = new_disk.find("source")
2428             source_file = (
2429                 new_source_node.get("file") if new_source_node is not None else None
2430             )
2431             updated_disk.set("type", "file")
2432             if source_node is not None:
2433                 updated_disk.remove(source_node)
2434             if source_file:
2435                 ElementTree.SubElement(
2436                     updated_disk, "source", attrib={"file": source_file}
2437                 )
2438     changes["disk"]["new"] = new_disks
2439     for dev_type in ["disk", "interface", "hostdev"]:
2440         for added in changes[dev_type].get("new", []):
2441             commands.append(
2442                 {
2443                     "device": dev_type,
2444                     "cmd": "attachDevice",
2445                     "args": [xmlutil.element_to_str(added)],
2446                 }
2447             )
2448         for removed in changes[dev_type].get("deleted", []):
2449             removed_def = changed_devices.get(dev_type, {}).get(
2450                 removed, ElementTree.tostring(removed)
2451             )
2452             commands.append(
2453                 {
2454                     "device": dev_type,
2455                     "cmd": "detachDevice",
2456                     "args": [salt.utils.stringutils.to_str(removed_def)],
2457                 }
2458             )
2459     for updated_disk in removable_changes:
2460         commands.append(
2461             {
2462                 "device": "disk",
2463                 "cmd": "updateDeviceFlags",
2464                 "args": [xmlutil.element_to_str(updated_disk)],
2465             }
2466         )
2467     for cmd in commands:
2468         try:
2469             ret = 0 if test else getattr(domain, cmd["cmd"])(*cmd["args"])
2470             device_type = cmd["device"]
2471             if device_type in ["cpu", "mem"]:
2472                 status[device_type] = not ret
2473             else:
2474                 actions = {
2475                     "attachDevice": "attached",
2476                     "detachDevice": "detached",
2477                     "updateDeviceFlags": "updated",
2478                 }
2479                 device_status = status.setdefault(device_type, {})
2480                 cmd_status = device_status.setdefault(actions[cmd["cmd"]], [])
2481                 cmd_status.append(cmd["args"][0])
2482         except libvirt.libvirtError as err:
2483             errors.append(str(err))
2484     return status, errors
2485 def update(
2486     name,
2487     cpu=0,
2488     mem=0,
2489     disk_profile=None,
2490     disks=None,
2491     nic_profile=None,
2492     interfaces=None,
2493     graphics=None,
2494     live=True,
2495     boot=None,
2496     numatune=None,
2497     test=False,
2498     boot_dev=None,
2499     hypervisor_features=None,
2500     clock=None,
2501     serials=None,
2502     consoles=None,
2503     stop_on_reboot=False,
2504     host_devices=None,
2505     **kwargs
2506 ):
2507     """
2508     Update the definition of an existing domain.
2509     :param name: Name of the domain to update
2510     :param cpu:
2511         Number of virtual CPUs to assign to the virtual machine or a dictionary with detailed information to configure
2512         cpu model and topology, numa node tuning, cpu tuning and iothreads allocation. The structure of the dictionary is
2513         documented in :ref:`init-cpu-def`.
2514         To update any cpu parameters specify the new values to the corresponding tag. To remove any element or attribute,
2515         specify ``None`` object. Please note that ``None`` object is mapped to ``null`` in yaml, use ``null`` in sls file
2516         instead.
2517     :param mem: Amount of memory to allocate to the virtual machine in MiB. Since 3002, a dictionary can be used to
2518         contain detailed configuration which support memory allocation or tuning. Supported parameters are ``boot``,
2519         ``current``, ``max``, ``slots``, ``hard_limit``, ``soft_limit``, ``swap_hard_limit``, ``min_guarantee``,
2520         ``hugepages`` ,  ``nosharepages``, ``locked``, ``source``, ``access``, ``allocation`` and ``discard``. The structure
2521         of the dictionary is documented in  :ref:`init-mem-def`. Both decimal and binary base are supported. Detail unit
2522         specification is documented  in :ref:`virt-units`. Please note that the value for ``slots`` must be an integer.
2523         To remove any parameters, pass a None object, for instance: 'soft_limit': ``None``. Please note  that ``None``
2524         is mapped to ``null`` in sls file, pass ``null`` in sls file instead.
2525         .. code-block:: yaml
2526             - mem:
2527                 hard_limit: null
2528                 soft_limit: null
2529         .. versionchanged:: 3002
2530     :param disk_profile: disk profile to use
2531     :param disks:
2532         Disk definitions as documented in the :func:`init` function.
2533         If neither the profile nor this parameter are defined, the disk devices
2534         will not be changed. However to clear disks set this parameter to empty list.
2535     :param nic_profile: network interfaces profile to use
2536     :param interfaces:
2537         Network interface definitions as documented in the :func:`init` function.
2538         If neither the profile nor this parameter are defined, the interface devices
2539         will not be changed. However to clear network interfaces set this parameter
2540         to empty list.
2541     :param graphics:
2542         The new graphics definition as defined in :ref:`init-graphics-def`. If not set,
2543         the graphics will not be changed. To remove a graphics device, set this parameter
2544         to ``{'type': 'none'}``.
2545     :param live:
2546         ``False`` to avoid trying to live update the definition. In such a case, the
2547         new definition is applied at the next start of the virtual machine. If ``True``,
2548         not all aspects of the definition can be live updated, but as much as possible
2549         will be attempted. (Default: ``True``)
2550     :param connection: libvirt connection URI, overriding defaults
2551     :param username: username to connect with, overriding defaults
2552     :param password: password to connect with, overriding defaults
2553     :param boot:
2554         Specifies kernel, initial ramdisk and kernel command line parameters for the virtual machine.
2555         This is an optional parameter, all of the keys are optional within the dictionary.
2556         Refer to :ref:`init-boot-def` for the complete boot parameter description.
2557         To update any boot parameters, specify the new path for each. To remove any boot parameters, pass ``None`` object,
2558         for instance: 'kernel': ``None``. To switch back to BIOS boot, specify ('loader': ``None`` and 'nvram': ``None``)
2559         or 'efi': ``False``. Please note that ``None`` is mapped to ``null`` in sls file, pass ``null`` in sls file instead.
2560         SLS file Example:
2561         .. code-block:: yaml
2562             - boot:
2563                 loader: null
2564                 nvram: null
2565         .. versionadded:: 3000
2566     :param boot_dev:
2567         Space separated list of devices to boot from sorted by decreasing priority.
2568         Values can be ``hd``, ``fd``, ``cdrom`` or ``network``.
2569         By default, the value will ``"hd"``.
2570         .. versionadded:: 3002
2571     :param numatune:
2572         The optional numatune element provides details of how to tune the performance of a NUMA host via controlling NUMA
2573         policy for domain process. The optional ``memory`` element specifies how to allocate memory for the domain process
2574         on a NUMA host. ``memnode`` elements can specify memory allocation policies per each guest NUMA node. The definition
2575         used in the dictionary can be found at :ref:`init-cpu-def`.
2576         To update any numatune parameters, specify the new value. To remove any ``numatune`` parameters, pass a None object,
2577         for instance: 'numatune': ``None``. Please note that ``None`` is mapped to ``null`` in sls file, pass ``null`` in
2578         sls file instead.
2579         .. versionadded:: 3003
2580     :param serials:
2581         Dictionary providing details on the serials connection to create. (Default: ``None``)
2582         See :ref:`init-chardevs-def` for more details on the possible values.
2583         .. versionadded:: 3003
2584     :param consoles:
2585         Dictionary providing details on the consoles device to create. (Default: ``None``)
2586         See :ref:`init-chardevs-def` for more details on the possible values.
2587         .. versionadded:: 3003
2588     :param stop_on_reboot:
2589         If set to ``True`` the guest will stop instead of rebooting.
2590         This is specially useful when creating a virtual machine with an installation cdrom or
2591         an autoinstallation needing a special first boot configuration.
2592         Defaults to ``False``
2593         .. versionadded:: 3003
2594     :param test: run in dry-run mode if set to True
2595         .. versionadded:: 3001
2596     :param hypervisor_features:
2597         Enable or disable hypervisor-specific features on the virtual machine.
2598         .. versionadded:: 3003
2599         .. code-block:: yaml
2600             hypervisor_features:
2601               kvm-hint-dedicated: True
2602     :param clock:
2603         Configure the guest clock.
2604         The value is a dictionary with the following keys:
2605         adjustment
2606             time adjustment in seconds or ``reset``
2607         utc
2608             set to ``False`` to use the host local time as the guest clock. Defaults to ``True``.
2609         timezone
2610             synchronize the guest to the correspding timezone
2611         timers
2612             a dictionary associating the timer name with its configuration.
2613             This configuration is a dictionary with the properties ``track``, ``tickpolicy``,
2614             ``catchup``, ``frequency``, ``mode``, ``present``, ``slew``, ``threshold`` and ``limit``.
2615             See `libvirt time keeping documentation &lt;https://libvirt.org/formatdomain.html#time-keeping&gt;`_ for the possible values.
2616         .. versionadded:: 3003
2617         Set the clock to local time using an offset in seconds
2618         .. code-block:: yaml
2619             clock:
2620               adjustment: 3600
2621               utc: False
2622         Set the clock to a specific time zone:
2623         .. code-block:: yaml
2624             clock:
2625               timezone: CEST
2626         Tweak guest timers:
2627         .. code-block:: yaml
2628             clock:
2629               timers:
2630                 tsc:
2631                   frequency: 3504000000
2632                   mode: native
2633                 rtc:
2634                   track: wall
2635                   tickpolicy: catchup
2636                   slew: 4636
2637                   threshold: 123
2638                   limit: 2342
2639                 hpet:
2640                   present: False
2641     :param host_devices:
2642         List of host devices to passthrough to the guest.
2643         The value is a list of device names as provided by the :py:func:`~salt.modules.virt.node_devices` function.
2644         (Default: ``None``)
2645         .. versionadded:: 3003
2646     :return:
2647         Returns a dictionary indicating the status of what has been done. It is structured in
2648         the following way:
2649         .. code-block:: python
2650             {
2651               'definition': True,
2652               'cpu': True,
2653               'mem': True,
2654               'disks': {'attached': [list of actually attached disks],
2655                         'detached': [list of actually detached disks]},
2656               'nics': {'attached': [list of actually attached nics],
2657                        'detached': [list of actually detached nics]},
2658               'errors': ['error messages for failures']
2659             }
2660     .. versionadded:: 2019.2.0
2661     CLI Example:
2662     .. code-block:: bash
2663         salt '*' virt.update domain cpu=2 mem=1024
2664     """
2665     status = {
2666         "definition": False,
2667         "disk": {"attached": [], "detached": [], "updated": []},
2668         "interface": {"attached": [], "detached": []},
2669     }
2670     conn = __get_conn(**kwargs)
2671     domain = _get_domain(conn, name)
2672     desc = ElementTree.fromstring(domain.XMLDesc(libvirt.VIR_DOMAIN_XML_INACTIVE))
2673     need_update = False
2674     hypervisor = desc.get("type")
2675     all_disks = _disk_profile(conn, disk_profile, hypervisor, disks, name)
2676     if boot is not None:
2677         boot = _handle_remote_boot_params(boot)
2678         if boot.get("efi", None) is not None:
2679             need_update = _handle_efi_param(boot, desc)
2680     new_desc = ElementTree.fromstring(
2681         _gen_xml(
2682             conn,
2683             name,
2684             cpu,
2685             mem or 0,
2686             all_disks,
2687             _get_merged_nics(hypervisor, nic_profile, interfaces),
2688             hypervisor,
2689             domain.OSType(),
2690             desc.find(".//os/type").get("arch"),
2691             graphics,
2692             boot,
2693             boot_dev,
2694             numatune,
2695             serials=serials,
2696             consoles=consoles,
2697             stop_on_reboot=stop_on_reboot,
2698             host_devices=host_devices,
2699             **kwargs
2700         )
2701     )
2702     if clock:
2703         offset = "utc" if clock.get("utc", True) else "localtime"
2704         if "timezone" in clock:
2705             offset = "timezone"
2706         clock["offset"] = offset
2707     def _set_loader(node, value):
2708         salt.utils.xmlutil.set_node_text(node, value)
2709         if value is not None:
2710             node.set("readonly", "yes")
2711             node.set("type", "pflash")
2712     def _set_nvram(node, value):
2713         node.set("template", value)
2714     def _set_with_byte_unit(attr_name=None):
2715         def _setter(node, value):
2716             if attr_name:
2717                 node.set(attr_name, str(value))
2718             else:
2719                 node.text = str(value)
2720             node.set("unit", "bytes")
2721         return _setter
2722     def _get_with_unit(node):
2723         unit = node.get("unit", "KiB")
2724         unit = unit if unit != "bytes" else "b"
2725         value = node.get("memory") or node.get("size") or node.text
2726         return _handle_unit("{}{}".format(value, unit)) if value else None
2727     def _set_vcpu(node, value):
2728         node.text = str(value)
2729         node.set("current", str(value))
2730     old_mem = int(_get_with_unit(desc.find("memory")) / 1024)
2731     old_cpu = int(desc.find("./vcpu").text)
2732     def _yesno_attribute(path, xpath, attr_name, ignored=None):
2733         return xmlutil.attribute(
2734             path, xpath, attr_name, ignored, lambda v: "yes" if v else "no"
2735         )
2736     def _memory_parameter(path, xpath, attr_name=None, ignored=None):
2737         entry = {
2738             "path": path,
2739             "xpath": xpath,
2740             "convert": _handle_unit,
2741             "get": _get_with_unit,
2742             "set": _set_with_byte_unit(attr_name),
2743             "equals": _almost_equal,
2744         }
2745         if attr_name:
2746             entry["del"] = salt.utils.xmlutil.del_attribute(attr_name, ignored)
2747         return entry
2748     def _cpuset_parameter(path, xpath, attr_name=None, ignored=None):
2749         def _set_cpuset(node, value):
2750             if attr_name:
2751                 node.set(attr_name, value)
2752             else:
2753                 node.text = value
2754         entry = {
2755             "path": path,
2756             "xpath": xpath,
2757             "convert": _expand_cpuset,
2758             "get": lambda n: _expand_cpuset(n.get(attr_name) if attr_name else n.text),
2759             "set": _set_cpuset,
2760         }
2761         if attr_name:
2762             entry["del"] = salt.utils.xmlutil.del_attribute(attr_name, ignored)
2763         return entry
2764     data = {k: v for k, v in locals().items() if bool(v)}
2765     data["stop_on_reboot"] = stop_on_reboot
2766     if boot_dev:
2767         data["boot_dev"] = boot_dev.split()
2768     timer_names = [
2769         "platform",
2770         "hpet",
2771         "kvmclock",
2772         "pit",
2773         "rtc",
2774         "tsc",
2775         "hypervclock",
2776         "armvtimer",
2777     ]
2778     if data.get("clock", {}).get("timers"):
2779         attributes = [
2780             "track",
2781             "tickpolicy",
2782             "frequency",
2783             "mode",
2784             "present",
2785             "slew",
2786             "threshold",
2787             "limit",
2788         ]
2789         for timer in data["clock"]["timers"].values():
2790             for attribute in attributes:
2791                 if attribute not in timer:
2792                     timer[attribute] = None
2793         for timer_name in timer_names:
2794             if timer_name not in data["clock"]["timers"]:
2795                 data["clock"]["timers"][timer_name] = None
2796     _normalize_cpusets(desc, data)
2797     params_mapping = [
2798         {
2799             "path": "stop_on_reboot",
2800             "xpath": "on_reboot",
2801             "convert": lambda v: "destroy" if v else "restart",
2802         },
2803         {"path": "boot:kernel", "xpath": "os/kernel"},
2804         {"path": "boot:initrd", "xpath": "os/initrd"},
2805         {"path": "boot:cmdline", "xpath": "os/cmdline"},
2806         {"path": "boot:loader", "xpath": "os/loader", "set": _set_loader},
2807         {"path": "boot:nvram", "xpath": "os/nvram", "set": _set_nvram},
2808         _memory_parameter("mem", "memory"),
2809         _memory_parameter("mem", "currentMemory"),
2810         _memory_parameter("mem:max", "maxMemory"),
2811         _memory_parameter("mem:boot", "memory"),
2812         _memory_parameter("mem:current", "currentMemory"),
2813         xmlutil.attribute("mem:slots", "maxMemory", "slots", ["unit"]),
2814         _memory_parameter("mem:hard_limit", "memtune/hard_limit"),
2815         _memory_parameter("mem:soft_limit", "memtune/soft_limit"),
2816         _memory_parameter("mem:swap_hard_limit", "memtune/swap_hard_limit"),
2817         _memory_parameter("mem:min_guarantee", "memtune/min_guarantee"),
2818         xmlutil.attribute("boot_dev:{dev}", "os/boot[$dev]", "dev"),
2819         _memory_parameter(
2820             "mem:hugepages:{id}:size",
2821             "memoryBacking/hugepages/page[$id]",
2822             "size",
2823             ["unit", "nodeset"],
2824         ),
2825         _cpuset_parameter(
2826             "mem:hugepages:{id}:nodeset", "memoryBacking/hugepages/page[$id]", "nodeset"
2827         ),
2828         {
2829             "path": "mem:nosharepages",
2830             "xpath": "memoryBacking/nosharepages",
2831             "get": lambda n: n is not None,
2832             "set": lambda n, v: None,
2833         },
2834         {
2835             "path": "mem:locked",
2836             "xpath": "memoryBacking/locked",
2837             "get": lambda n: n is not None,
2838             "set": lambda n, v: None,
2839         },
2840         xmlutil.attribute("mem:source", "memoryBacking/source", "type"),
2841         xmlutil.attribute("mem:access", "memoryBacking/access", "mode"),
2842         xmlutil.attribute("mem:allocation", "memoryBacking/allocation", "mode"),
2843         {"path": "mem:discard", "xpath": "memoryBacking/discard"},
2844         {
2845             "path": "cpu",
2846             "xpath": "vcpu",
2847             "get": lambda n: int(n.text),
2848             "set": _set_vcpu,
2849         },
2850         {"path": "cpu:maximum", "xpath": "vcpu", "get": lambda n: int(n.text)},
2851         xmlutil.attribute("cpu:placement", "vcpu", "placement"),
2852         _cpuset_parameter("cpu:cpuset", "vcpu", "cpuset"),
2853         xmlutil.attribute("cpu:current", "vcpu", "current"),
2854         xmlutil.attribute("cpu:match", "cpu", "match"),
2855         xmlutil.attribute("cpu:mode", "cpu", "mode"),
2856         xmlutil.attribute("cpu:check", "cpu", "check"),
2857         {"path": "cpu:model:name", "xpath": "cpu/model"},
2858         xmlutil.attribute("cpu:model:fallback", "cpu/model", "fallback"),
2859         xmlutil.attribute("cpu:model:vendor_id", "cpu/model", "vendor_id"),
2860         {"path": "cpu:vendor", "xpath": "cpu/vendor"},
2861         xmlutil.attribute("cpu:topology:sockets", "cpu/topology", "sockets"),
2862         xmlutil.attribute("cpu:topology:cores", "cpu/topology", "cores"),
2863         xmlutil.attribute("cpu:topology:threads", "cpu/topology", "threads"),
2864         xmlutil.attribute("cpu:cache:level", "cpu/cache", "level"),
2865         xmlutil.attribute("cpu:cache:mode", "cpu/cache", "mode"),
2866         xmlutil.attribute(
2867             "cpu:features:{id}", "cpu/feature[@name='$id']", "policy", ["name"]
2868         ),
2869         _yesno_attribute(
2870             "cpu:vcpus:{id}:enabled", "vcpus/vcpu[@id='$id']", "enabled", ["id"]
2871         ),
2872         _yesno_attribute(
2873             "cpu:vcpus:{id}:hotpluggable",
2874             "vcpus/vcpu[@id='$id']",
2875             "hotpluggable",
2876             ["id"],
2877         ),
2878         xmlutil.int_attribute(
2879             "cpu:vcpus:{id}:order", "vcpus/vcpu[@id='$id']", "order", ["id"]
2880         ),
2881         _cpuset_parameter(
2882             "cpu:numa:{id}:cpus", "cpu/numa/cell[@id='$id']", "cpus", ["id"]
2883         ),
2884         _memory_parameter(
2885             "cpu:numa:{id}:memory", "cpu/numa/cell[@id='$id']", "memory", ["id"]
2886         ),
2887             "cpu:numa:{id}:discard", "cpu/numa/cell[@id='$id']", "discard", ["id"]
2888         ),
2889         xmlutil<font color="#6cc417"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.attribute(
2890             "cpu:numa:{id}:memAccess", "cpu/numa/cell[@id='$id']", "memAccess", ["id"]
2891         ),
2892         xmlutil.attribute(
2893             "cpu:numa:{id}:distances:{sid}",
2894             "cpu/numa/cell[@id='$id']/distances/sibling[@id='$sid']",
2895             "value",
2896             ["id"],
2897         ),
2898         {"path": "cpu:iothreads", "xpath": "iothreads"},
2899         {"path": "cpu:tuning:shares", "xpath": "cputune/shares"},
2900         {"path": "cpu:tuning:period", "xpath": "cputune/period"},
2901         {"path": "cpu:tuning:quota", "xpath": "cputune/quota"},
2902         {"path": "cpu:tuning:global_period", "xpath": "cputune/global_period"},
2903         {"path": "cpu:tuning:global_quota", "xpath": "cputune/global_quota"},
2904         {"path": "cpu:tuning:emulator_period", "xpath": "cputune/emulator_period"},
2905         {"path": "cpu:tuning:emulator_quota", "xpath": "cputune/emulator_quota"},
2906         {"path": "cpu:tuning:iothread_period", "xpath": "cputune/iothread_period"},
2907         {"path"</b></font>: "cpu:tuning:iothread_quota", "xpath": "cputune/iothread_quota"},
2908         _cpuset_parameter(
2909             "cpu:tuning:vcpupin:{id}",
2910             "cputune/vcpupin[@vcpu='$id']",
2911             "cpuset",
2912             ["vcpu"],
2913         ),
2914         _cpuset_parameter("cpu:tuning:emulatorpin", "cputune/emulatorpin", "cpuset"),
2915         _cpuset_parameter(
2916             "cpu:tuning:iothreadpin:{id}",
2917             "cputune/iothreadpin[@iothread='$id']",
2918             "cpuset",
2919             ["iothread"],
2920         ),
2921         xmlutil.attribute(
2922             "cpu:tuning:vcpusched:{id}:scheduler",
2923             "cputune/vcpusched[$id]",
2924             "scheduler",
2925             ["priority", "vcpus"],
2926         ),
2927         xmlutil.attribute(
2928             "cpu:tuning:vcpusched:{id}:priority", "cputune/vcpusched[$id]", "priority"
2929         ),
2930         _cpuset_parameter(
2931             "cpu:tuning:vcpusched:{id}:vcpus", "cputune/vcpusched[$id]", "vcpus"
2932         ),
2933         xmlutil.attribute(
2934             "cpu:tuning:iothreadsched:{id}:scheduler",
2935             "cputune/iothreadsched[$id]",
2936             "scheduler",
2937             ["priority", "iothreads"],
2938         ),
2939         xmlutil.attribute(
2940             "cpu:tuning:iothreadsched:{id}:priority",
2941             "cputune/iothreadsched[$id]",
2942             "priority",
2943         ),
2944         _cpuset_parameter(
2945             "cpu:tuning:iothreadsched:{id}:iothreads",
2946             "cputune/iothreadsched[$id]",
2947             "iothreads",
2948         ),
2949         xmlutil.attribute(
2950             "cpu:tuning:emulatorsched:scheduler",
2951             "cputune/emulatorsched",
2952             "scheduler",
2953             ["priority"],
2954         ),
2955         xmlutil.attribute(
2956             "cpu:tuning:emulatorsched:priority", "cputune/emulatorsched", "priority"
2957         ),
2958         xmlutil.attribute(
2959             "cpu:tuning:cachetune:{id}:monitor:{sid}",
2960             "cputune/cachetune[@vcpus='$id']/monitor[@vcpus='$sid']",
2961             "level",
2962             ["vcpus"],
2963         ),
2964         xmlutil.attribute(
2965             "cpu:tuning:memorytune:{id}:{sid}",
2966             "cputune/memorytune[@vcpus='$id']/node[@id='$sid']",
2967             "bandwidth",
2968             ["id", "vcpus"],
2969         ),
2970         xmlutil.attribute("clock:offset", "clock", "offset"),
2971         xmlutil.attribute("clock:adjustment", "clock", "adjustment", convert=str),
2972         xmlutil.attribute("clock:timezone", "clock", "timezone"),
2973     ]
2974     for timer in timer_names:
2975         params_mapping += [
2976             xmlutil.attribute(
2977                 "clock:timers:{}:track".format(timer),
2978                 "clock/timer[@name='{}']".format(timer),
2979                 "track",
2980                 ["name"],
2981             ),
2982             xmlutil.attribute(
2983                 "clock:timers:{}:tickpolicy".format(timer),
2984                 "clock/timer[@name='{}']".format(timer),
2985                 "tickpolicy",
2986                 ["name"],
2987             ),
2988             xmlutil.int_attribute(
2989                 "clock:timers:{}:frequency".format(timer),
2990                 "clock/timer[@name='{}']".format(timer),
2991                 "frequency",
2992                 ["name"],
2993             ),
2994             xmlutil.attribute(
2995                 "clock:timers:{}:mode".format(timer),
2996                 "clock/timer[@name='{}']".format(timer),
2997                 "mode",
2998                 ["name"],
2999             ),
3000             _yesno_attribute(
3001                 "clock:timers:{}:present".format(timer),
3002                 "clock/timer[@name='{}']".format(timer),
3003                 "present",
3004                 ["name"],
3005             ),
3006         ]
3007         for attr in ["slew", "threshold", "limit"]:
3008             params_mapping.append(
3009                 xmlutil.int_attribute(
3010                     "clock:timers:{}:{}".format(timer, attr),
3011                     "clock/timer[@name='{}']/catchup".format(timer),
3012                     attr,
3013                 )
3014             )
3015     for attr in ["level", "type", "size"]:
3016         params_mapping.append(
3017             xmlutil.attribute(
3018                 "cpu:tuning:cachetune:{id}:{sid}:" + attr,
3019                 "cputune/cachetune[@vcpus='$id']/cache[@id='$sid']",
3020                 attr,
3021                 ["id", "unit", "vcpus"],
3022             )
3023         )
3024     if hypervisor in ["qemu", "kvm"]:
3025         params_mapping += [
3026             xmlutil.attribute("numatune:memory:mode", "numatune/memory", "mode"),
3027             _cpuset_parameter("numatune:memory:nodeset", "numatune/memory", "nodeset"),
3028             xmlutil.attribute(
3029                 "numatune:memnodes:{id}:mode",
3030                 "numatune/memnode[@cellid='$id']",
3031                 "mode",
3032                 ["cellid"],
3033             ),
3034             _cpuset_parameter(
3035                 "numatune:memnodes:{id}:nodeset",
3036                 "numatune/memnode[@cellid='$id']",
3037                 "nodeset",
3038                 ["cellid"],
3039             ),
3040             xmlutil.attribute(
3041                 "hypervisor_features:kvm-hint-dedicated",
3042                 "features/kvm/hint-dedicated",
3043                 "state",
3044                 convert=lambda v: "on" if v else "off",
3045             ),
3046         ]
3047     need_update = (
3048         salt.utils.xmlutil.change_xml(desc, data, params_mapping) or need_update
3049     )
3050     devices_node = desc.find("devices")
3051     func_locals = locals()
3052     def _skip_update(names):
3053         return all(func_locals.get(n) is None for n in names)
3054     to_skip = {
3055         "disk": _skip_update(["disks", "disk_profile"]),
3056         "interface": _skip_update(["interfaces", "nic_profile"]),
3057         "graphics": _skip_update(["graphics"]),
3058         "serial": _skip_update(["serials"]),
3059         "console": _skip_update(["consoles"]),
3060         "hostdev": _skip_update(["host_devices"]),
3061     }
3062     changes = _compute_device_changes(desc, new_desc, to_skip)
3063     for dev_type in changes:
3064         if not to_skip[dev_type]:
3065             old = devices_node.findall(dev_type)
3066             if changes[dev_type].get("deleted") or changes[dev_type].get("new"):
3067                 for item in old:
3068                     devices_node.remove(item)
3069                 devices_node.extend(changes[dev_type]["sorted"])
3070                 need_update = True
3071     if need_update:
3072         try:
3073             if changes["disk"]:
3074                 for idx, item in enumerate(changes["disk"]["sorted"]):
3075                     source_file = all_disks[idx].get("source_file")
3076                     if all_disks[idx].get("device", "disk") == "cdrom":
3077                         continue
3078                     if (
3079                         item in changes["disk"]["new"]
3080                         and source_file
3081                         and not os.path.exists(source_file)
3082                     ):
3083                         _qemu_image_create(all_disks[idx])
3084                     elif item in changes["disk"]["new"] and not source_file:
3085                         _disk_volume_create(conn, all_disks[idx])
3086             if not test:
3087                 xml_desc = xmlutil.element_to_str(desc)
3088                 log.debug("Update virtual machine definition: %s", xml_desc)
3089                 conn.defineXML(xml_desc)
3090             status["definition"] = True
3091         except libvirt.libvirtError as err:
3092             conn.close()
3093             raise err
3094     if live:
3095         live_status, errors = _update_live(
3096             domain, new_desc, mem, cpu, old_mem, old_cpu, to_skip, test
3097         )
3098         status.update(live_status)
3099         if errors:
3100             status_errors = status.setdefault("errors", [])
3101             status_errors += errors
3102     conn.close()
3103     return status
3104 def list_domains(**kwargs):
3105     """
3106     Return a list of available domains.
3107     :param connection: libvirt connection URI, overriding defaults
3108         .. versionadded:: 2019.2.0
3109     :param username: username to connect with, overriding defaults
3110         .. versionadded:: 2019.2.0
3111     :param password: password to connect with, overriding defaults
3112         .. versionadded:: 2019.2.0
3113     CLI Example:
3114     .. code-block:: bash
3115         salt '*' virt.list_domains
3116     """
3117     vms = []
3118     conn = __get_conn(**kwargs)
3119     for dom in _get_domain(conn, iterable=True):
3120         vms.append(dom.name())
3121     conn.close()
3122     return vms
3123 def list_active_vms(**kwargs):
3124     """
3125     Return a list of names for active virtual machine on the minion
3126     :param connection: libvirt connection URI, overriding defaults
3127         .. versionadded:: 2019.2.0
3128     :param username: username to connect with, overriding defaults
3129         .. versionadded:: 2019.2.0
3130     :param password: password to connect with, overriding defaults
3131         .. versionadded:: 2019.2.0
3132     CLI Example:
3133     .. code-block:: bash
3134         salt '*' virt.list_active_vms
3135     """
3136     vms = []
3137     conn = __get_conn(**kwargs)
3138     for dom in _get_domain(conn, iterable=True, inactive=False):
3139         vms.append(dom.name())
3140     conn.close()
3141     return vms
3142 def list_inactive_vms(**kwargs):
3143     """
3144     Return a list of names for inactive virtual machine on the minion
3145     :param connection: libvirt connection URI, overriding defaults
3146         .. versionadded:: 2019.2.0
3147     :param username: username to connect with, overriding defaults
3148         .. versionadded:: 2019.2.0
3149     :param password: password to connect with, overriding defaults
3150         .. versionadded:: 2019.2.0
3151     CLI Example:
3152     .. code-block:: bash
3153         salt '*' virt.list_inactive_vms
3154     """
3155     vms = []
3156     conn = __get_conn(**kwargs)
3157     for dom in _get_domain(conn, iterable=True, active=False):
3158         vms.append(dom.name())
3159     conn.close()
3160     return vms
3161 def vm_info(vm_=None, **kwargs):
3162     """
3163     Return detailed information about the vms on this hyper in a
3164     list of dicts:
3165     :param vm_: name of the domain
3166     :param connection: libvirt connection URI, overriding defaults
3167         .. versionadded:: 2019.2.0
3168     :param username: username to connect with, overriding defaults
3169         .. versionadded:: 2019.2.0
3170     :param password: password to connect with, overriding defaults
3171         .. versionadded:: 2019.2.0
3172     .. code-block:: python
3173         [
3174             'your-vm': {
3175                 'cpu': &lt;int&gt;,
3176                 'maxMem': &lt;int&gt;,
3177                 'mem': &lt;int&gt;,
3178                 'state': '&lt;state&gt;',
3179                 'cputime' &lt;int&gt;
3180                 },
3181             ...
3182             ]
3183     If you pass a VM name in as an argument then it will return info
3184     for just the named VM, otherwise it will return all VMs.
3185     CLI Example:
3186     .. code-block:: bash
3187         salt '*' virt.vm_info
3188     """
3189     def _info(conn, dom):
3190         """
3191         Compute the infos of a domain
3192         """
3193         raw = dom.info()
3194         return {
3195             "cpu": raw[3],
3196             "cputime": int(raw[4]),
3197             "disks": _get_disks(conn, dom),
3198             "graphics": _get_graphics(dom),
3199             "nics": _get_nics(dom),
3200             "uuid": _get_uuid(dom),
3201             "loader": _get_loader(dom),
3202             "on_crash": _get_on_crash(dom),
3203             "on_reboot": _get_on_reboot(dom),
3204             "on_poweroff": _get_on_poweroff(dom),
3205             "maxMem": int(raw[1]),
3206             "mem": int(raw[2]),
3207             "state": VIRT_STATE_NAME_MAP.get(raw[0], "unknown"),
3208         }
3209     info = {}
3210     conn = __get_conn(**kwargs)
3211     if vm_:
3212         info[vm_] = _info(conn, _get_domain(conn, vm_))
3213     else:
3214         for domain in _get_domain(conn, iterable=True):
3215             info[domain.name()] = _info(conn, domain)
3216     conn.close()
3217     return info
3218 def vm_state(vm_=None, **kwargs):
3219     """
3220     Return list of all the vms and their state.
3221     If you pass a VM name in as an argument then it will return info
3222     for just the named VM, otherwise it will return all VMs.
3223     :param vm_: name of the domain
3224     :param connection: libvirt connection URI, overriding defaults
3225         .. versionadded:: 2019.2.0
3226     :param username: username to connect with, overriding defaults
3227         .. versionadded:: 2019.2.0
3228     :param password: password to connect with, overriding defaults
3229         .. versionadded:: 2019.2.0
3230     CLI Example:
3231     .. code-block:: bash
3232         salt '*' virt.vm_state &lt;domain&gt;
3233     """
3234     def _info(dom):
3235         """
3236         Compute domain state
3237         """
3238         state = ""
3239         raw = dom.info()
3240         state = VIRT_STATE_NAME_MAP.get(raw[0], "unknown")
3241         return state
3242     info = {}
3243     conn = __get_conn(**kwargs)
3244     if vm_:
3245         info[vm_] = _info(_get_domain(conn, vm_))
3246     else:
3247         for domain in _get_domain(conn, iterable=True):
3248             info[domain.name()] = _info(domain)
3249     conn.close()
3250     return info
3251 def _node_info(conn):
3252     """
3253     Internal variant of node_info taking a libvirt connection as parameter
3254     """
3255     raw = conn.getInfo()
3256     info = {
3257         "cpucores": raw[6],
3258         "cpumhz": raw[3],
3259         "cpumodel": str(raw[0]),
3260         "cpus": raw[2],
3261         "cputhreads": raw[7],
3262         "numanodes": raw[4],
3263         "phymemory": raw[1],
3264         "sockets": raw[5],
3265     }
3266     return info
3267 def node_info(**kwargs):
3268     """
3269     Return a dict with information about this node
3270     :param connection: libvirt connection URI, overriding defaults
3271         .. versionadded:: 2019.2.0
3272     :param username: username to connect with, overriding defaults
3273         .. versionadded:: 2019.2.0
3274     :param password: password to connect with, overriding defaults
3275         .. versionadded:: 2019.2.0
3276     CLI Example:
3277     .. code-block:: bash
3278         salt '*' virt.node_info
3279     """
3280     conn = __get_conn(**kwargs)
3281     info = _node_info(conn)
3282     conn.close()
3283     return info
3284 def _node_devices(conn):
3285     """
3286     List the host available devices, using an established connection.
3287     :param conn: the libvirt connection handle to use.
3288     .. versionadded:: 3003
3289     """
3290     devices = conn.listAllDevices()
3291     devices_infos = []
3292     for dev in devices:
3293         root = ElementTree.fromstring(dev.XMLDesc())
3294         if not set(dev.listCaps()) &amp; {"pci", "usb_device", "net"}:
3295             continue
3296         infos = {
3297             "caps": " ".join(dev.listCaps()),
3298         }
3299         if "net" in dev.listCaps():
3300             parent = root.find(".//parent").text
3301             if parent == "computer":
3302                 continue
3303             infos<font color="#c58917"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.update(
3304                 {
3305                     "name": root.find(".//interface").text,
3306                     "address": root.find(".//address").text,
3307                     "device name": parent,
3308                     "state": root.find(".//link").</b></font>get("state"),
3309                 }
3310             )
3311             devices_infos.append(infos)
3312             continue
3313         vendor_node = root.find(".//vendor")
3314         vendor_id = vendor_node.get("id").lower()
3315         product_node = root.find(".//product")
3316         product_id = product_node.get("id").lower()
3317         infos.update(
3318             {"name": dev.name(), "vendor_id": vendor_id, "product_id": product_id}
3319         )
3320         if vendor_node.text:
3321             infos["vendor"] = vendor_node.text
3322         if product_node.text:
3323             infos["product"] = product_node.text
3324         if "pci" in dev.listCaps():
3325             infos["address"] = "{:04x}:{:02x}:{:02x}.{}".format(
3326                 int(root.find(".//domain").text),
3327                 int(root.find(".//bus").text),
3328                 int(root.find(".//slot").text),
3329                 root.find(".//function").text,
3330             )
3331             class_node = root.find(".//class")
3332             if class_node is not None:
3333                 infos["PCI class"] = class_node.text
3334             vf_addresses = [
3335                 _format_pci_address(vf)
3336                 for vf in root.findall(
3337                     "./capability[@type='pci']/capability[@type='virt_functions']/address"
3338                 )
3339             ]
3340             if vf_addresses:
3341                 infos["virtual functions"] = vf_addresses
3342             pf = root.find(
3343                 "./capability[@type='pci']/capability[@type='phys_function']/address"
3344             )
3345             if pf is not None:
3346                 infos["physical function"] = _format_pci_address(pf)
3347         elif "usb_device" in dev.listCaps():
3348             infos["address"] = "{:03}:{:03}".format(
3349                 int(root.find(".//bus").text), int(root.find(".//device").text)
3350             )
3351         linux_usb_host = vendor_id == "0x1d6b" and product_id in [
3352             "0x0001",
3353             "0x0002",
3354             "0x0003",
3355         ]
3356         if (
3357             root.find(".//capability[@type='pci-bridge']") is None
3358             and not linux_usb_host
3359         ):
3360             devices_infos.append(infos)
3361     return devices_infos
3362 def node_devices(**kwargs):
3363     """
3364     List the host available devices.
3365     :param connection: libvirt connection URI, overriding defaults
3366     :param username: username to connect with, overriding defaults
3367     :param password: password to connect with, overriding defaults
3368     .. versionadded:: 3003
3369     """
3370     conn = __get_conn(**kwargs)
3371     devs = _node_devices(conn)
3372     conn.close()
3373     return devs
3374 def get_nics(vm_, **kwargs):
3375     """
3376     Return info about the network interfaces of a named vm
3377     :param vm_: name of the domain
3378     :param connection: libvirt connection URI, overriding defaults
3379         .. versionadded:: 2019.2.0
3380     :param username: username to connect with, overriding defaults
3381         .. versionadded:: 2019.2.0
3382     :param password: password to connect with, overriding defaults
3383         .. versionadded:: 2019.2.0
3384     CLI Example:
3385     .. code-block:: bash
3386         salt '*' virt.get_nics &lt;domain&gt;
3387     """
3388     conn = __get_conn(**kwargs)
3389     nics = _get_nics(_get_domain(conn, vm_))
3390     conn.close()
3391     return nics
3392 def get_macs(vm_, **kwargs):
3393     """
3394     Return a list off MAC addresses from the named vm
3395     :param vm_: name of the domain
3396     :param connection: libvirt connection URI, overriding defaults
3397         .. versionadded:: 2019.2.0
3398     :param username: username to connect with, overriding defaults
3399         .. versionadded:: 2019.2.0
3400     :param password: password to connect with, overriding defaults
3401         .. versionadded:: 2019.2.0
3402     CLI Example:
3403     .. code-block:: bash
3404         salt '*' virt.get_macs &lt;domain&gt;
3405     """
3406     doc = ElementTree.fromstring(get_xml(vm_, **kwargs))
3407     return [node.get("address") for node in doc.findall("devices/interface/mac")]
3408 def get_graphics(vm_, **kwargs):
3409     """
3410     Returns the information on vnc for a given vm
3411     :param vm_: name of the domain
3412     :param connection: libvirt connection URI, overriding defaults
3413         .. versionadded:: 2019.2.0
3414     :param username: username to connect with, overriding defaults
3415         .. versionadded:: 2019.2.0
3416     :param password: password to connect with, overriding defaults
3417         .. versionadded:: 2019.2.0
3418     CLI Example:
3419     .. code-block:: bash
3420         salt '*' virt.get_graphics &lt;domain&gt;
3421     """
3422     conn = __get_conn(**kwargs)
3423     graphics = _get_graphics(_get_domain(conn, vm_))
3424     conn.close()
3425     return graphics
3426 def get_loader(vm_, **kwargs):
3427     """
3428     Returns the information on the loader for a given vm
3429     :param vm_: name of the domain
3430     :param connection: libvirt connection URI, overriding defaults
3431     :param username: username to connect with, overriding defaults
3432     :param password: password to connect with, overriding defaults
3433     CLI Example:
3434     .. code-block:: bash
3435         salt '*' virt.get_loader &lt;domain&gt;
3436     .. versionadded:: 2019.2.0
3437     """
3438     conn = __get_conn(**kwargs)
3439     try:
3440         loader = _get_loader(_get_domain(conn, vm_))
3441         return loader
3442     finally:
3443         conn.close()
3444 def get_disks(vm_, **kwargs):
3445     """
3446     Return the disks of a named vm
3447     :param vm_: name of the domain
3448     :param connection: libvirt connection URI, overriding defaults
3449         .. versionadded:: 2019.2.0
3450     :param username: username to connect with, overriding defaults
3451         .. versionadded:: 2019.2.0
3452     :param password: password to connect with, overriding defaults
3453         .. versionadded:: 2019.2.0
3454     CLI Example:
3455     .. code-block:: bash
3456         salt '*' virt.get_disks &lt;domain&gt;
3457     """
3458     conn = __get_conn(**kwargs)
3459     disks = _get_disks(conn, _get_domain(conn, vm_))
3460     conn.close()
3461     return disks
3462 def setmem(vm_, memory, config=False, **kwargs):
3463     """
3464     Changes the amount of memory allocated to VM. The VM must be shutdown
3465     for this to work.
3466     :param vm_: name of the domain
3467     :param memory: memory amount to set in MB
3468     :param config: if True then libvirt will be asked to modify the config as well
3469     :param connection: libvirt connection URI, overriding defaults
3470         .. versionadded:: 2019.2.0
3471     :param username: username to connect with, overriding defaults
3472         .. versionadded:: 2019.2.0
3473     :param password: password to connect with, overriding defaults
3474         .. versionadded:: 2019.2.0
3475     CLI Example:
3476     .. code-block:: bash
3477         salt '*' virt.setmem &lt;domain&gt; &lt;size&gt;
3478         salt '*' virt.setmem my_domain 768
3479     """
3480     conn = __get_conn(**kwargs)
3481     dom = _get_domain(conn, vm_)
3482     if VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown":
3483         return False
3484     flags = libvirt.VIR_DOMAIN_MEM_MAXIMUM
3485     if config:
3486         flags = flags | libvirt.VIR_DOMAIN_AFFECT_CONFIG
3487     ret1 = dom.setMemoryFlags(memory * 1024, flags)
3488     ret2 = dom.setMemoryFlags(memory * 1024, libvirt.VIR_DOMAIN_AFFECT_CURRENT)
3489     conn.close()
3490     return ret1 == ret2 == 0
3491 def setvcpus(vm_, vcpus, config=False, **kwargs):
3492     """
3493     Changes the amount of vcpus allocated to VM. The VM must be shutdown
3494     for this to work.
3495     If config is True then we ask libvirt to modify the config as well
3496     :param vm_: name of the domain
3497     :param vcpus: integer representing the number of CPUs to be assigned
3498     :param config: if True then libvirt will be asked to modify the config as well
3499     :param connection: libvirt connection URI, overriding defaults
3500         .. versionadded:: 2019.2.0
3501     :param username: username to connect with, overriding defaults
3502         .. versionadded:: 2019.2.0
3503     :param password: password to connect with, overriding defaults
3504         .. versionadded:: 2019.2.0
3505     CLI Example:
3506     .. code-block:: bash
3507         salt '*' virt.setvcpus &lt;domain&gt; &lt;amount&gt;
3508         salt '*' virt.setvcpus my_domain 4
3509     """
3510     conn = __get_conn(**kwargs)
3511     dom = _get_domain(conn, vm_)
3512     if VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown":
3513         return False
3514     flags = libvirt.VIR_DOMAIN_VCPU_MAXIMUM
3515     if config:
3516         flags = flags | libvirt.VIR_DOMAIN_AFFECT_CONFIG
3517     ret1 = dom.setVcpusFlags(vcpus, flags)
3518     ret2 = dom.setVcpusFlags(vcpus, libvirt.VIR_DOMAIN_AFFECT_CURRENT)
3519     conn.close()
3520     return ret1 == ret2 == 0
3521 def _freemem(conn):
3522     """
3523     Internal variant of freemem taking a libvirt connection as parameter
3524     """
3525     mem = conn.getInfo()[1]
3526     mem -= 256
3527     for dom in _get_domain(conn, iterable=True):
3528         if dom.ID() &gt; 0:
3529             mem -= dom.info()[2] / 1024
3530     return mem
3531 def freemem(**kwargs):
3532     """
3533     Return an int representing the amount of memory (in MB) that has not
3534     been given to virtual machines on this node
3535     :param connection: libvirt connection URI, overriding defaults
3536         .. versionadded:: 2019.2.0
3537     :param username: username to connect with, overriding defaults
3538         .. versionadded:: 2019.2.0
3539     :param password: password to connect with, overriding defaults
3540         .. versionadded:: 2019.2.0
3541     CLI Example:
3542     .. code-block:: bash
3543         salt '*' virt.freemem
3544     """
3545     conn = __get_conn(**kwargs)
3546     mem = _freemem(conn)
3547     conn.close()
3548     return mem
3549 def _freecpu(conn):
3550     """
3551     Internal variant of freecpu taking a libvirt connection as parameter
3552     """
3553     cpus = conn.getInfo()[2]
3554     for dom in _get_domain(conn, iterable=True):
3555         if dom.ID() &gt; 0:
3556             cpus -= dom.info()[3]
3557     return cpus
3558 def freecpu(**kwargs):
3559     """
3560     Return an int representing the number of unallocated cpus on this
3561     hypervisor
3562     :param connection: libvirt connection URI, overriding defaults
3563         .. versionadded:: 2019.2.0
3564     :param username: username to connect with, overriding defaults
3565         .. versionadded:: 2019.2.0
3566     :param password: password to connect with, overriding defaults
3567         .. versionadded:: 2019.2.0
3568     CLI Example:
3569     .. code-block:: bash
3570         salt '*' virt.freecpu
3571     """
3572     conn = __get_conn(**kwargs)
3573     cpus = _freecpu(conn)
3574     conn.close()
3575     return cpus
3576 def full_info(**kwargs):
3577     """
3578     Return the node_info, vm_info and freemem
3579     :param connection: libvirt connection URI, overriding defaults
3580         .. versionadded:: 2019.2.0
3581     :param username: username to connect with, overriding defaults
3582         .. versionadded:: 2019.2.0
3583     :param password: password to connect with, overriding defaults
3584         .. versionadded:: 2019.2.0
3585     CLI Example:
3586     .. code-block:: bash
3587         salt '*' virt.full_info
3588     """
3589     conn = __get_conn(**kwargs)
3590     info = {
3591         "freecpu": _freecpu(conn),
3592         "freemem": _freemem(conn),
3593         "node_info": _node_info(conn),
3594         "vm_info": vm_info(),
3595     }
3596     conn.close()
3597     return info
3598 def get_xml(vm_, **kwargs):
3599     """
3600     Returns the XML for a given vm
3601     :param vm_: domain name
3602     :param connection: libvirt connection URI, overriding defaults
3603         .. versionadded:: 2019.2.0
3604     :param username: username to connect with, overriding defaults
3605         .. versionadded:: 2019.2.0
3606     :param password: password to connect with, overriding defaults
3607         .. versionadded:: 2019.2.0
3608     CLI Example:
3609     .. code-block:: bash
3610         salt '*' virt.get_xml &lt;domain&gt;
3611     """
3612     conn = __get_conn(**kwargs)
3613     xml_desc = (
3614         vm_.XMLDesc(0)
3615         if isinstance(vm_, libvirt.virDomain)
3616         else _get_domain(conn, vm_).XMLDesc(0)
3617     )
3618     conn.close()
3619     return xml_desc
3620 def get_profiles(hypervisor=None, **kwargs):
3621     """
3622     Return the virt profiles for hypervisor.
3623     Currently there are profiles for:
3624     - nic
3625     - disk
3626     :param hypervisor: override the default machine type.
3627     :param connection: libvirt connection URI, overriding defaults
3628         .. versionadded:: 2019.2.0
3629     :param username: username to connect with, overriding defaults
3630         .. versionadded:: 2019.2.0
3631     :param password: password to connect with, overriding defaults
3632         .. versionadded:: 2019.2.0
3633     CLI Example:
3634     .. code-block:: bash
3635         salt '*' virt.get_profiles
3636         salt '*' virt.get_profiles hypervisor=vmware
3637     """
3638     conn = __get_conn(**kwargs)
3639     caps = _capabilities(conn)
3640     hypervisors = sorted(
3641         {
3642             x
3643             for y in [guest["arch"]["domains"].keys() for guest in caps["guests"]]
3644             for x in y
3645         }
3646     )
3647     if len(hypervisors) == 0:
3648         raise SaltInvocationError("No supported hypervisors were found")
3649     if not hypervisor:
3650         hypervisor = "kvm" if "kvm" in hypervisors else hypervisors[0]
3651     ret = {
3652         "disk": {"default": _disk_profile(conn, "default", hypervisor, [], None)},
3653         "nic": {"default": _nic_profile("default", hypervisor)},
3654     }
3655     virtconf = __salt__["config.get"]("virt", {})
3656     for profile in virtconf.get("disk", []):
3657         ret["disk"][profile] = _disk_profile(conn, profile, hypervisor, [], None)
3658     for profile in virtconf.get("nic", []):
3659         ret["nic"][profile] = _nic_profile(profile, hypervisor)
3660     return ret
3661 def shutdown(vm_, **kwargs):
3662     """
3663     Send a soft shutdown signal to the named vm
3664     :param vm_: domain name
3665     :param connection: libvirt connection URI, overriding defaults
3666         .. versionadded:: 2019.2.0
3667     :param username: username to connect with, overriding defaults
3668         .. versionadded:: 2019.2.0
3669     :param password: password to connect with, overriding defaults
3670         .. versionadded:: 2019.2.0
3671     CLI Example:
3672     .. code-block:: bash
3673         salt '*' virt.shutdown &lt;domain&gt;
3674     """
3675     conn = __get_conn(**kwargs)
3676     dom = _get_domain(conn, vm_)
3677     ret = dom.shutdown() == 0
3678     conn.close()
3679     return ret
3680 def pause(vm_, **kwargs):
3681     """
3682     Pause the named vm
3683     :param vm_: domain name
3684     :param connection: libvirt connection URI, overriding defaults
3685         .. versionadded:: 2019.2.0
3686     :param username: username to connect with, overriding defaults
3687         .. versionadded:: 2019.2.0
3688     :param password: password to connect with, overriding defaults
3689         .. versionadded:: 2019.2.0
3690     CLI Example:
3691     .. code-block:: bash
3692         salt '*' virt.pause &lt;domain&gt;
3693     """
3694     conn = __get_conn(**kwargs)
3695     dom = _get_domain(conn, vm_)
3696     ret = dom.suspend() == 0
3697     conn.close()
3698     return ret
3699 def resume(vm_, **kwargs):
3700     """
3701     Resume the named vm
3702     :param vm_: domain name
3703     :param connection: libvirt connection URI, overriding defaults
3704         .. versionadded:: 2019.2.0
3705     :param username: username to connect with, overriding defaults
3706         .. versionadded:: 2019.2.0
3707     :param password: password to connect with, overriding defaults
3708         .. versionadded:: 2019.2.0
3709     CLI Example:
3710     .. code-block:: bash
3711         salt '*' virt.resume &lt;domain&gt;
3712     """
3713     conn = __get_conn(**kwargs)
3714     dom = _get_domain(conn, vm_)
3715     ret = dom.resume() == 0
3716     conn.close()
3717     return ret
3718 def start(name, **kwargs):
3719     """
3720     Start a defined domain
3721     :param vm_: domain name
3722     :param connection: libvirt connection URI, overriding defaults
3723         .. versionadded:: 2019.2.0
3724     :param username: username to connect with, overriding defaults
3725         .. versionadded:: 2019.2.0
3726     :param password: password to connect with, overriding defaults
3727         .. versionadded:: 2019.2.0
3728     CLI Example:
3729     .. code-block:: bash
3730         salt '*' virt.start &lt;domain&gt;
3731     """
3732     conn = __get_conn(**kwargs)
3733     ret = _get_domain(conn, name).create() == 0
3734     conn.close()
3735     return ret
3736 def stop(name, **kwargs):
3737     """
3738     Hard power down the virtual machine, this is equivalent to pulling the power.
3739     :param vm_: domain name
3740     :param connection: libvirt connection URI, overriding defaults
3741         .. versionadded:: 2019.2.0
3742     :param username: username to connect with, overriding defaults
3743         .. versionadded:: 2019.2.0
3744     :param password: password to connect with, overriding defaults
3745         .. versionadded:: 2019.2.0
3746     CLI Example:
3747     .. code-block:: bash
3748         salt '*' virt.stop &lt;domain&gt;
3749     """
3750     conn = __get_conn(**kwargs)
3751     ret = _get_domain(conn, name).destroy() == 0
3752     conn.close()
3753     return ret
3754 def reboot(name, **kwargs):
3755     """
3756     Reboot a domain via ACPI request
3757     :param vm_: domain name
3758     :param connection: libvirt connection URI, overriding defaults
3759         .. versionadded:: 2019.2.0
3760     :param username: username to connect with, overriding defaults
3761         .. versionadded:: 2019.2.0
3762     :param password: password to connect with, overriding defaults
3763         .. versionadded:: 2019.2.0
3764     CLI Example:
3765     .. code-block:: bash
3766         salt '*' virt.reboot &lt;domain&gt;
3767     """
3768     conn = __get_conn(**kwargs)
3769     ret = _get_domain(conn, name).reboot(libvirt.VIR_DOMAIN_REBOOT_DEFAULT) == 0
3770     conn.close()
3771     return ret
3772 def reset(vm_, **kwargs):
3773     """
3774     Reset a VM by emulating the reset button on a physical machine
3775     :param vm_: domain name
3776     :param connection: libvirt connection URI, overriding defaults
3777         .. versionadded:: 2019.2.0
3778     :param username: username to connect with, overriding defaults
3779         .. versionadded:: 2019.2.0
3780     :param password: password to connect with, overriding defaults
3781         .. versionadded:: 2019.2.0
3782     CLI Example:
3783     .. code-block:: bash
3784         salt '*' virt.reset &lt;domain&gt;
3785     """
3786     conn = __get_conn(**kwargs)
3787     dom = _get_domain(conn, vm_)
3788     ret = dom.reset(0) == 0
3789     conn.close()
3790     return ret
3791 def ctrl_alt_del(vm_, **kwargs):
3792     """
3793     Sends CTRL+ALT+DEL to a VM
3794     :param vm_: domain name
3795     :param connection: libvirt connection URI, overriding defaults
3796         .. versionadded:: 2019.2.0
3797     :param username: username to connect with, overriding defaults
3798         .. versionadded:: 2019.2.0
3799     :param password: password to connect with, overriding defaults
3800         .. versionadded:: 2019.2.0
3801     CLI Example:
3802     .. code-block:: bash
3803         salt '*' virt.ctrl_alt_del &lt;domain&gt;
3804     """
3805     conn = __get_conn(**kwargs)
3806     dom = _get_domain(conn, vm_)
3807     ret = dom.sendKey(0, 0, [29, 56, 111], 3, 0) == 0
3808     conn.close()
3809     return ret
3810 def create_xml_str(xml, **kwargs):  # pylint: disable=redefined-outer-name
3811     """
3812     Start a transient domain based on the XML passed to the function
3813     :param xml: libvirt XML definition of the domain
3814     :param connection: libvirt connection URI, overriding defaults
3815         .. versionadded:: 2019.2.0
3816     :param username: username to connect with, overriding defaults
3817         .. versionadded:: 2019.2.0
3818     :param password: password to connect with, overriding defaults
3819         .. versionadded:: 2019.2.0
3820     CLI Example:
3821     .. code-block:: bash
3822         salt '*' virt.create_xml_str &lt;XML in string format&gt;
3823     """
3824     conn = __get_conn(**kwargs)
3825     ret = conn.createXML(xml, 0) is not None
3826     conn.close()
3827     return ret
3828 def create_xml_path(path, **kwargs):
3829     """
3830     Start a transient domain based on the XML-file path passed to the function
3831     :param path: path to a file containing the libvirt XML definition of the domain
3832     :param connection: libvirt connection URI, overriding defaults
3833         .. versionadded:: 2019.2.0
3834     :param username: username to connect with, overriding defaults
3835         .. versionadded:: 2019.2.0
3836     :param password: password to connect with, overriding defaults
3837         .. versionadded:: 2019.2.0
3838     CLI Example:
3839     .. code-block:: bash
3840         salt '*' virt.create_xml_path &lt;path to XML file on the node&gt;
3841     """
3842     try:
3843         with salt.utils.files.fopen(path, "r") as fp_:
3844             return create_xml_str(
3845                 salt.utils.stringutils.to_unicode(fp_.read()), **kwargs
3846             )
3847     except OSError:
3848         return False
3849 def define_xml_str(xml, **kwargs):  # pylint: disable=redefined-outer-name
3850     """
3851     Define a persistent domain based on the XML passed to the function
3852     :param xml: libvirt XML definition of the domain
3853     :param connection: libvirt connection URI, overriding defaults
3854         .. versionadded:: 2019.2.0
3855     :param username: username to connect with, overriding defaults
3856         .. versionadded:: 2019.2.0
3857     :param password: password to connect with, overriding defaults
3858         .. versionadded:: 2019.2.0
3859     CLI Example:
3860     .. code-block:: bash
3861         salt '*' virt.define_xml_str &lt;XML in string format&gt;
3862     """
3863     conn = __get_conn(**kwargs)
3864     ret = conn.defineXML(xml) is not None
3865     conn.close()
3866     return ret
3867 def define_xml_path(path, **kwargs):
3868     """
3869     Define a persistent domain based on the XML-file path passed to the function
3870     :param path: path to a file containing the libvirt XML definition of the domain
3871     :param connection: libvirt connection URI, overriding defaults
3872         .. versionadded:: 2019.2.0
3873     :param username: username to connect with, overriding defaults
3874         .. versionadded:: 2019.2.0
3875     :param password: password to connect with, overriding defaults
3876         .. versionadded:: 2019.2.0
3877     CLI Example:
3878     .. code-block:: bash
3879         salt '*' virt.define_xml_path &lt;path to XML file on the node&gt;
3880     """
3881     try:
3882         with salt.utils.files.fopen(path, "r") as fp_:
3883             return define_xml_str(
3884                 salt.utils.stringutils.to_unicode(fp_.read()), **kwargs
3885             )
3886     except OSError:
3887         return False
3888 def _define_vol_xml_str(conn, xml, pool=None):  # pylint: disable=redefined-outer-name
3889     """
3890     Same function than define_vml_xml_str but using an already opened libvirt connection
3891     """
3892     default_pool = "default" if conn.getType() != "ESX" else "0"
3893     poolname = (
3894         pool if pool else __salt__["config.get"]("virt:storagepool", default_pool)
3895     )
3896     pool = conn.storagePoolLookupByName(str(poolname))
3897     ret = pool.createXML(xml, 0) is not None
3898     return ret
3899 def define_vol_xml_str(
3900     xml, pool=None, **kwargs
3901 ):  # pylint: disable=redefined-outer-name
3902     """
3903     Define a volume based on the XML passed to the function
3904     :param xml: libvirt XML definition of the storage volume
3905     :param pool:
3906         storage pool name to define the volume in.
3907         If defined, this parameter will override the configuration setting.
3908         .. versionadded:: 3001
3909     :param connection: libvirt connection URI, overriding defaults
3910         .. versionadded:: 2019.2.0
3911     :param username: username to connect with, overriding defaults
3912         .. versionadded:: 2019.2.0
3913     :param password: password to connect with, overriding defaults
3914         .. versionadded:: 2019.2.0
3915     CLI Example:
3916     .. code-block:: bash
3917         salt '*' virt.define_vol_xml_str &lt;XML in string format&gt;
3918     The storage pool where the disk image will be defined is ``default``
3919     unless changed with the pool parameter or a configuration like this:
3920     .. code-block:: yaml
3921         virt:
3922             storagepool: mine
3923     """
3924     conn = __get_conn(**kwargs)
3925     ret = False
3926     try:
3927         ret = _define_vol_xml_str(conn, xml, pool=pool)
3928     except libvirtError as err:
3929         raise CommandExecutionError(err.get_error_message())
3930     finally:
3931         conn.close()
3932     return ret
3933 def define_vol_xml_path(path, pool=None, **kwargs):
3934     """
3935     Define a volume based on the XML-file path passed to the function
3936     :param path: path to a file containing the libvirt XML definition of the volume
3937     :param pool:
3938         storage pool name to define the volume in.
3939         If defined, this parameter will override the configuration setting.
3940         .. versionadded:: 3001
3941     :param connection: libvirt connection URI, overriding defaults
3942         .. versionadded:: 2019.2.0
3943     :param username: username to connect with, overriding defaults
3944         .. versionadded:: 2019.2.0
3945     :param password: password to connect with, overriding defaults
3946         .. versionadded:: 2019.2.0
3947     CLI Example:
3948     .. code-block:: bash
3949         salt '*' virt.define_vol_xml_path &lt;path to XML file on the node&gt;
3950     """
3951     try:
3952         with salt.utils.files.fopen(path, "r") as fp_:
3953             return define_vol_xml_str(
3954                 salt.utils.stringutils.to_unicode(fp_.read()), pool=pool, **kwargs
3955             )
3956     except OSError:
3957         return False
3958 def migrate(vm_, target, **kwargs):
3959     """
3960     Shared storage migration
3961     :param vm_: domain name
3962     :param target: target libvirt URI or host name
3963     :param kwargs:
3964         - live:            Use live migration. Default value is True.
3965         - persistent:      Leave the domain persistent on destination host.
3966                            Default value is True.
3967         - undefinesource:  Undefine the domain on the source host.
3968                            Default value is True.
3969         - offline:         If set to True it will migrate the domain definition
3970                            without starting the domain on destination and without
3971                            stopping it on source host. Default value is False.
3972         - max_bandwidth:   The maximum bandwidth (in MiB/s) that will be used.
3973         - max_downtime:    Set maximum tolerable downtime for live-migration.
3974                            The value represents a number of milliseconds the guest
3975                            is allowed to be down at the end of live migration.
3976         - parallel_connections: Specify a number of parallel network connections
3977                            to be used to send memory pages to the destination host.
3978         - compressed:      Activate compression.
3979         - comp_methods:    A comma-separated list of compression methods. Supported
3980                            methods are "mt" and "xbzrle" and can be  used in any
3981                            combination. QEMU defaults to "xbzrle".
3982         - comp_mt_level:   Set compression level. Values are in range from 0 to 9,
3983                            where 1 is maximum speed and 9 is  maximum compression.
3984         - comp_mt_threads: Set number of compress threads on source host.
3985         - comp_mt_dthreads: Set number of decompress threads on target host.
3986         - comp_xbzrle_cache: Set the size of page cache for xbzrle compression in bytes.
3987         - copy_storage:    Migrate non-shared storage. It must be one of the following
3988                            values: all (full disk copy) or incremental (Incremental copy)
3989         - postcopy:        Enable the use of post-copy migration.
3990         - postcopy_bandwidth: The maximum bandwidth allowed in post-copy phase. (MiB/s)
3991         - username:        Username to connect with target host
3992         - password:        Password to connect with target host
3993         .. versionadded:: 3002
3994     CLI Example:
3995     .. code-block:: bash
3996         salt '*' virt.migrate &lt;domain&gt; &lt;target hypervisor URI&gt;
3997         salt src virt.migrate guest qemu+ssh://dst/system
3998         salt src virt.migrate guest qemu+tls://dst/system
3999         salt src virt.migrate guest qemu+tcp://dst/system
4000     A tunnel data migration can be performed by setting this in the
4001     configuration:
4002     .. code-block:: yaml
4003         virt:
4004             tunnel: True
4005     For more details on tunnelled data migrations, report to
4006     https://libvirt.org/migration.html#transporttunnel
4007     """
4008     conn = __get_conn()
4009     dom = _get_domain(conn, vm_)
4010     if not urllib.parse.urlparse(target).scheme:
4011         proto = "qemu"
4012         dst_uri = "{}://{}/system".format(proto, target)
4013     else:
4014         dst_uri = target
4015     ret = _migrate(dom, dst_uri, **kwargs)
4016     conn.close()
4017     return ret
4018 def migrate_start_postcopy(vm_):
4019     """
4020     Starts post-copy migration. This function has to be called
4021     while live migration is in progress and it has been initiated
4022     with the `postcopy=True` option.
4023     CLI Example:
4024     .. code-block:: bash
4025         salt '*' virt.migrate_start_postcopy &lt;domain&gt;
4026     """
4027     conn = __get_conn()
4028     dom = _get_domain(conn, vm_)
4029     try:
4030         dom.migrateStartPostCopy()
4031     except libvirt.libvirtError as err:
4032         conn.close()
4033         raise CommandExecutionError(err.get_error_message())
4034     conn.close()
4035 def seed_non_shared_migrate(disks, force=False):
4036     """
4037     Non shared migration requires that the disks be present on the migration
4038     destination, pass the disks information via this function, to the
4039     migration destination before executing the migration.
4040     :param disks: the list of disk data as provided by virt.get_disks
4041     :param force: skip checking the compatibility of source and target disk
4042                   images if True. (default: False)
4043     CLI Example:
4044     .. code-block:: bash
4045         salt '*' virt.seed_non_shared_migrate &lt;disks&gt;
4046     """
4047     for _, data in disks.items():
4048         fn_ = data["file"]
4049         form = data["file format"]
4050         size = data["virtual size"].split()[1][1:]
4051         if os.path.isfile(fn_) and not force:
4052             pre = salt.utils.yaml.safe_load(
4053                 subprocess.Popen(
4054                     ["qemu-img", "info", "arch"], stdout=subprocess.PIPE
4055                 ).communicate()[0]
4056             )
4057             if (
4058                 pre["file format"] != data["file format"]
4059                 and pre["virtual size"] != data["virtual size"]
4060             ):
4061                 return False
4062         if not os.path.isdir(os.path.dirname(fn_)):
4063             os.makedirs(os.path.dirname(fn_))
4064         if os.path.isfile(fn_):
4065             os.remove(fn_)
4066         subprocess.call(["qemu-img", "create", "-f", form, fn_, size])
4067         creds = _libvirt_creds()
4068         subprocess.call(["chown", "{user}:{group}".format(**creds), fn_])
4069     return True
4070 def set_autostart(vm_, state="on", **kwargs):
4071     """
4072     Set the autostart flag on a VM so that the VM will start with the host
4073     system on reboot.
4074     :param vm_: domain name
4075     :param state: 'on' to auto start the pool, anything else to mark the
4076                   pool not to be started when the host boots
4077     :param connection: libvirt connection URI, overriding defaults
4078         .. versionadded:: 2019.2.0
4079     :param username: username to connect with, overriding defaults
4080         .. versionadded:: 2019.2.0
4081     :param password: password to connect with, overriding defaults
4082         .. versionadded:: 2019.2.0
4083     CLI Example:
4084     .. code-block:: bash
4085         salt "*" virt.set_autostart &lt;domain&gt; &lt;on | off&gt;
4086     """
4087     conn = __get_conn(**kwargs)
4088     dom = _get_domain(conn, vm_)
4089     ret = False
4090     if state == "on":
4091         ret = dom.setAutostart(1) == 0
4092     elif state == "off":
4093         ret = dom.setAutostart(0) == 0
4094     conn.close()
4095     return ret
4096 def undefine(vm_, **kwargs):
4097     """
4098     Remove a defined vm, this does not purge the virtual machine image, and
4099     this only works if the vm is powered down
4100     :param vm_: domain name
4101     :param connection: libvirt connection URI, overriding defaults
4102         .. versionadded:: 2019.2.0
4103     :param username: username to connect with, overriding defaults
4104         .. versionadded:: 2019.2.0
4105     :param password: password to connect with, overriding defaults
4106         .. versionadded:: 2019.2.0
4107     CLI Example:
4108     .. code-block:: bash
4109         salt '*' virt.undefine &lt;domain&gt;
4110     """
4111     conn = __get_conn(**kwargs)
4112     dom = _get_domain(conn, vm_)
4113     if getattr(libvirt, "VIR_DOMAIN_UNDEFINE_NVRAM", False):
4114         ret = dom.undefineFlags(libvirt.VIR_DOMAIN_UNDEFINE_NVRAM) == 0
4115     else:
4116         ret = dom.undefine() == 0
4117     conn.close()
4118     return ret
4119 def purge(vm_, dirs=False, removables=False, **kwargs):
4120     """
4121     Recursively destroy and delete a persistent virtual machine, pass True for
4122     dir's to also delete the directories containing the virtual machine disk
4123     images - USE WITH EXTREME CAUTION!
4124     :param vm_: domain name
4125     :param dirs: pass True to remove containing directories
4126     :param removables: pass True to remove removable devices
4127         .. versionadded:: 2019.2.0
4128     :param connection: libvirt connection URI, overriding defaults
4129         .. versionadded:: 2019.2.0
4130     :param username: username to connect with, overriding defaults
4131         .. versionadded:: 2019.2.0
4132     :param password: password to connect with, overriding defaults
4133         .. versionadded:: 2019.2.0
4134     CLI Example:
4135     .. code-block:: bash
4136         salt '*' virt.purge &lt;domain&gt;
4137     """
4138     conn = __get_conn(**kwargs)
4139     dom = _get_domain(conn, vm_)
4140     disks = _get_disks(conn, dom)
4141     if (
4142         VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown"
4143         and dom.destroy() != 0
4144     ):
4145         return False
4146     directories = set()
4147     for disk in disks:
4148         if not removables and disks[disk]["type"] in ["cdrom", "floppy"]:
4149             continue
4150         if disks[disk].get("zfs", False):
4151             time.sleep(3)
4152             log.info("Destroying VM ZFS volume %s", fs_name)
4153             __salt__["zfs.destroy"](name=fs_name, force=True)
4154         elif os<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.path.exists(disks[disk]["file"]):
4155             os.remove(disks[disk]["file"])
4156             directories.add(os.path.dirname(disks[disk][</b></font>"file"]))
4157         else:
4158             matcher = re.match("^(?P&lt;pool&gt;[^/]+)/(?P&lt;volume&gt;.*)$", disks[disk]["file"])
4159             if matcher:
4160                 pool_name = matcher.group("pool")
4161                 pool = None
4162                 if pool_name in conn.listStoragePools():
4163                     pool = conn.storagePoolLookupByName(pool_name)
4164                 if pool and matcher.group("volume") in pool.listVolumes():
4165                     volume = pool.storageVolLookupByName(matcher.group("volume"))
4166                     volume.delete()
4167     if dirs:
4168         for dir_ in directories:
4169             shutil.rmtree(dir_)
4170     if getattr(libvirt, "VIR_DOMAIN_UNDEFINE_NVRAM", False):
4171         try:
4172             dom.undefineFlags(libvirt.VIR_DOMAIN_UNDEFINE_NVRAM)
4173         except Exception:  # pylint: disable=broad-except
4174             dom.undefine()
4175     else:
4176         dom.undefine()
4177     conn.close()
4178     return True
4179 def virt_type():
4180     """
4181     Returns the virtual machine type as a string
4182     CLI Example:
4183     .. code-block:: bash
4184         salt '*' virt.virt_type
4185     """
4186     return __grains__["virtual"]
4187 def _is_kvm_hyper():
4188     """
4189     Returns a bool whether or not this node is a KVM hypervisor
4190     """
4191     if not os.path.exists("/dev/kvm"):
4192         return False
4193     return "libvirtd" in __salt__["cmd.run"](__grains__["ps"])
4194 def _is_xen_hyper():
4195     """
4196     Returns a bool whether or not this node is a XEN hypervisor
4197     """
4198     try:
4199         if __grains__["virtual_subtype"] != "Xen Dom0":
4200             return False
4201     except KeyError:
4202         return False
4203     try:
4204         with salt.utils.files.fopen("/proc/modules") as fp_:
4205             if "xen_" not in salt.utils.stringutils.to_unicode(fp_.read()):
4206                 return False
4207     except OSError:
4208         return False
4209     return "libvirtd" in __salt__["cmd.run"](__grains__["ps"])
4210 def get_hypervisor():
4211     """
4212     Returns the name of the hypervisor running on this node or ``None``.
4213     Detected hypervisors:
4214     - kvm
4215     - xen
4216     - bhyve
4217     CLI Example:
4218     .. code-block:: bash
4219         salt '*' virt.get_hypervisor
4220     .. versionadded:: 2019.2.0
4221         the function and the ``kvm``, ``xen`` and ``bhyve`` hypervisors support
4222     """
4223     hypervisors = ["kvm", "xen", "bhyve"]
4224     result = [
4225         hyper
4226         for hyper in hypervisors
4227         if getattr(sys.modules[__name__], "_is_{}_hyper".format(hyper))()
4228     ]
4229     return result[0] if result else None
4230 def _is_bhyve_hyper():
4231     sysctl_cmd = "sysctl hw.vmm.create"
4232     vmm_enabled = False
4233     try:
4234         stdout = subprocess.Popen(
4235             ["sysctl", "hw.vmm.create"], stdout=subprocess.PIPE
4236         ).communicate()[0]
4237         vmm_enabled = len(salt.utils.stringutils.to_str(stdout).split('"')[1]) != 0
4238     except IndexError:
4239         pass
4240     return vmm_enabled
4241 def is_hyper():
4242     """
4243     Returns a bool whether or not this node is a hypervisor of any kind
4244     CLI Example:
4245     .. code-block:: bash
4246         salt '*' virt.is_hyper
4247     """
4248     if HAS_LIBVIRT:
4249         return _is_xen_hyper() or _is_kvm_hyper() or _is_bhyve_hyper()
4250     return False
4251 def vm_cputime(vm_=None, **kwargs):
4252     """
4253     Return cputime used by the vms on this hyper in a
4254     list of dicts:
4255     :param vm_: domain name
4256     :param connection: libvirt connection URI, overriding defaults
4257         .. versionadded:: 2019.2.0
4258     :param username: username to connect with, overriding defaults
4259         .. versionadded:: 2019.2.0
4260     :param password: password to connect with, overriding defaults
4261         .. versionadded:: 2019.2.0
4262     .. code-block:: python
4263         [
4264             'your-vm': {
4265                 'cputime' &lt;int&gt;
4266                 'cputime_percent' &lt;int&gt;
4267                 },
4268             ...
4269             ]
4270     If you pass a VM name in as an argument then it will return info
4271     for just the named VM, otherwise it will return all VMs.
4272     CLI Example:
4273     .. code-block:: bash
4274         salt '*' virt.vm_cputime
4275     """
4276     conn = __get_conn(**kwargs)
4277     host_cpus = conn.getInfo()[2]
4278     def _info(dom):
4279         """
4280         Compute cputime info of a domain
4281         """
4282         raw = dom.info()
4283         vcpus = int(raw[3])
4284         cputime = int(raw[4])
4285         cputime_percent = 0
4286         if cputime:
4287             cputime_percent = (1.0e-7 * cputime / host_cpus) / vcpus
4288         return {
4289             "cputime": int(raw[4]),
4290             "cputime_percent": int("{:.0f}".format(cputime_percent)),
4291         }
4292     info = {}
4293     if vm_:
4294         info[vm_] = _info(_get_domain(conn, vm_))
4295     else:
4296         for domain in _get_domain(conn, iterable=True):
4297             info[domain.name()] = _info(domain)
4298     conn.close()
4299     return info
4300 def vm_netstats(vm_=None, **kwargs):
4301     """
4302     Return combined network counters used by the vms on this hyper in a
4303     list of dicts:
4304     :param vm_: domain name
4305     :param connection: libvirt connection URI, overriding defaults
4306         .. versionadded:: 2019.2.0
4307     :param username: username to connect with, overriding defaults
4308         .. versionadded:: 2019.2.0
4309     :param password: password to connect with, overriding defaults
4310         .. versionadded:: 2019.2.0
4311     .. code-block:: python
4312         [
4313             'your-vm': {
4314                 'rx_bytes'   : 0,
4315                 'rx_packets' : 0,
4316                 'rx_errs'    : 0,
4317                 'rx_drop'    : 0,
4318                 'tx_bytes'   : 0,
4319                 'tx_packets' : 0,
4320                 'tx_errs'    : 0,
4321                 'tx_drop'    : 0
4322                 },
4323             ...
4324             ]
4325     If you pass a VM name in as an argument then it will return info
4326     for just the named VM, otherwise it will return all VMs.
4327     CLI Example:
4328     .. code-block:: bash
4329         salt '*' virt.vm_netstats
4330     """
4331     def _info(dom):
4332         """
4333         Compute network stats of a domain
4334         """
4335         nics = _get_nics(dom)
4336         ret = {
4337             "rx_bytes": 0,
4338             "rx_packets": 0,
4339             "rx_errs": 0,
4340             "rx_drop": 0,
4341             "tx_bytes": 0,
4342             "tx_packets": 0,
4343             "tx_errs": 0,
4344             "tx_drop": 0,
4345         }
4346         for attrs in nics.values():
4347             if "target" in attrs:
4348                 dev = attrs["target"]
4349                 stats = dom.interfaceStats(dev)
4350                 ret["rx_bytes"] += stats[0]
4351                 ret["rx_packets"] += stats[1]
4352                 ret["rx_errs"] += stats[2]
4353                 ret["rx_drop"] += stats[3]
4354                 ret["tx_bytes"] += stats[4]
4355                 ret["tx_packets"] += stats[5]
4356                 ret["tx_errs"] += stats[6]
4357                 ret["tx_drop"] += stats[7]
4358         return ret
4359     info = {}
4360     conn = __get_conn(**kwargs)
4361     if vm_:
4362         info[vm_] = _info(_get_domain(conn, vm_))
4363     else:
4364         for domain in _get_domain(conn, iterable=True):
4365             info[domain.name()] = _info(domain)
4366     conn.close()
4367     return info
4368 def vm_diskstats(vm_=None, **kwargs):
4369     """
4370     Return disk usage counters used by the vms on this hyper in a
4371     list of dicts:
4372     :param vm_: domain name
4373     :param connection: libvirt connection URI, overriding defaults
4374         .. versionadded:: 2019.2.0
4375     :param username: username to connect with, overriding defaults
4376         .. versionadded:: 2019.2.0
4377     :param password: password to connect with, overriding defaults
4378         .. versionadded:: 2019.2.0
4379     .. code-block:: python
4380         [
4381             'your-vm': {
4382                 'rd_req'   : 0,
4383                 'rd_bytes' : 0,
4384                 'wr_req'   : 0,
4385                 'wr_bytes' : 0,
4386                 'errs'     : 0
4387                 },
4388             ...
4389             ]
4390     If you pass a VM name in as an argument then it will return info
4391     for just the named VM, otherwise it will return all VMs.
4392     CLI Example:
4393     .. code-block:: bash
4394         salt '*' virt.vm_blockstats
4395     """
4396     def get_disk_devs(dom):
4397         """
4398         Extract the disk devices names from the domain XML definition
4399         """
4400         doc = ElementTree.fromstring(get_xml(dom, **kwargs))
4401         return [target.get("dev") for target in doc.findall("devices/disk/target")]
4402     def _info(dom):
4403         """
4404         Compute the disk stats of a domain
4405         """
4406         disks = get_disk_devs(dom)
4407         ret = {"rd_req": 0, "rd_bytes": 0, "wr_req": 0, "wr_bytes": 0, "errs": 0}
4408         for disk in disks:
4409             stats = dom.blockStats(disk)
4410             ret["rd_req"] += stats[0]
4411             ret["rd_bytes"] += stats[1]
4412             ret["wr_req"] += stats[2]
4413             ret["wr_bytes"] += stats[3]
4414             ret["errs"] += stats[4]
4415         return ret
4416     info = {}
4417     conn = __get_conn(**kwargs)
4418     if vm_:
4419         info[vm_] = _info(_get_domain(conn, vm_))
4420     else:
4421         for domain in _get_domain(conn, iterable=True, inactive=False):
4422             info[domain.name()] = _info(domain)
4423     conn.close()
4424     return info
4425 def _parse_snapshot_description(vm_snapshot, unix_time=False):
4426     """
4427     Parse XML doc and return a dict with the status values.
4428     :param xmldoc:
4429     :return:
4430     """
4431     ret = dict()
4432     tree = ElementTree.fromstring(vm_snapshot.getXMLDesc())
4433     for node in tree:
4434         if node.tag == "name":
4435             ret["name"] = node.text
4436         elif node.tag == "creationTime":
4437             ret["created"] = (
4438                 datetime.datetime.fromtimestamp(float(node.text)).isoformat(" ")
4439                 if not unix_time
4440                 else float(node.text)
4441             )
4442         elif node.tag == "state":
4443             ret["running"] = node.text == "running"
4444     ret["current"] = vm_snapshot.isCurrent() == 1
4445     return ret
4446 def list_snapshots(domain=None, **kwargs):
4447     """
4448     List available snapshots for certain vm or for all.
4449     :param domain: domain name
4450     :param connection: libvirt connection URI, overriding defaults
4451         .. versionadded:: 2019.2.0
4452     :param username: username to connect with, overriding defaults
4453         .. versionadded:: 2019.2.0
4454     :param password: password to connect with, overriding defaults
4455         .. versionadded:: 2019.2.0
4456     .. versionadded:: 2016.3.0
4457     CLI Example:
4458     .. code-block:: bash
4459         salt '*' virt.list_snapshots
4460         salt '*' virt.list_snapshots &lt;domain&gt;
4461     """
4462     ret = dict()
4463     conn = __get_conn(**kwargs)
4464     for vm_domain in _get_domain(conn, *(domain and [domain] or list()), iterable=True):
4465         ret[vm_domain.name()] = [
4466             _parse_snapshot_description(snap) for snap in vm_domain.listAllSnapshots()
4467         ] or "N/A"
4468     conn.close()
4469     return ret
4470 def snapshot(domain, name=None, suffix=None, **kwargs):
4471     """
4472     Create a snapshot of a VM.
4473     :param domain: domain name
4474     :param name: Name of the snapshot. If the name is omitted, then will be used original domain
4475                  name with ISO 8601 time as a suffix.
4476     :param suffix: Add suffix for the new name. Useful in states, where such snapshots
4477                    can be distinguished from manually created.
4478     :param connection: libvirt connection URI, overriding defaults
4479         .. versionadded:: 2019.2.0
4480     :param username: username to connect with, overriding defaults
4481         .. versionadded:: 2019.2.0
4482     :param password: password to connect with, overriding defaults
4483         .. versionadded:: 2019.2.0
4484     .. versionadded:: 2016.3.0
4485     CLI Example:
4486     .. code-block:: bash
4487         salt '*' virt.snapshot &lt;domain&gt;
4488     """
4489     if name and name.lower() == domain.lower():
4490         raise CommandExecutionError(
4491             "Virtual Machine {name} is already defined. "
4492             "Please choose another name for the snapshot".format(name=name)
4493         )
4494     if not name:
4495         name = "{domain}-{tsnap}".format(
4496             domain=domain, tsnap=time.strftime("%Y%m%d-%H%M%S", time.localtime())
4497         )
4498     if suffix:
4499         name = "{name}-{suffix}".format(name=name, suffix=suffix)
4500     doc = ElementTree.Element("domainsnapshot")
4501     n_name = ElementTree.SubElement(doc, "name")
4502     n_name.text = name
4503     conn = __get_conn(**kwargs)
4504     _get_domain(conn, domain).snapshotCreateXML(xmlutil.element_to_str(doc))
4505     conn.close()
4506     return {"name": name}
4507 def delete_snapshots(name, *names, **kwargs):
4508     """
4509     Delete one or more snapshots of the given VM.
4510     :param name: domain name
4511     :param names: names of the snapshots to remove
4512     :param connection: libvirt connection URI, overriding defaults
4513         .. versionadded:: 2019.2.0
4514     :param username: username to connect with, overriding defaults
4515         .. versionadded:: 2019.2.0
4516     :param password: password to connect with, overriding defaults
4517         .. versionadded:: 2019.2.0
4518     .. versionadded:: 2016.3.0
4519     CLI Example:
4520     .. code-block:: bash
4521         salt '*' virt.delete_snapshots &lt;domain&gt; all=True
4522         salt '*' virt.delete_snapshots &lt;domain&gt; &lt;snapshot&gt;
4523         salt '*' virt.delete_snapshots &lt;domain&gt; &lt;snapshot1&gt; &lt;snapshot2&gt; ...
4524     """
4525     deleted = dict()
4526     conn = __get_conn(**kwargs)
4527     domain = _get_domain(conn, name)
4528     for snap in domain.listAllSnapshots():
4529         if snap.getName() in names or not names:
4530             deleted[snap.getName()] = _parse_snapshot_description(snap)
4531             snap.delete()
4532     conn.close()
4533     available = {
4534         name: [_parse_snapshot_description(snap) for snap in domain.listAllSnapshots()]
4535         or "N/A"
4536     }
4537     return {"available": available, "deleted": deleted}
4538 def revert_snapshot(name, vm_snapshot=None, cleanup=False, **kwargs):
4539     """
4540     Revert snapshot to the previous from current (if available) or to the specific.
4541     :param name: domain name
4542     :param vm_snapshot: name of the snapshot to revert
4543     :param cleanup: Remove all newer than reverted snapshots. Values: True or False (default False).
4544     :param connection: libvirt connection URI, overriding defaults
4545         .. versionadded:: 2019.2.0
4546     :param username: username to connect with, overriding defaults
4547         .. versionadded:: 2019.2.0
4548     :param password: password to connect with, overriding defaults
4549         .. versionadded:: 2019.2.0
4550     .. versionadded:: 2016.3.0
4551     CLI Example:
4552     .. code-block:: bash
4553         salt '*' virt.revert &lt;domain&gt;
4554         salt '*' virt.revert &lt;domain&gt; &lt;snapshot&gt;
4555     """
4556     ret = dict()
4557     conn = __get_conn(**kwargs)
4558     domain = _get_domain(conn, name)
4559     snapshots = domain.listAllSnapshots()
4560     _snapshots = list()
4561     for snap_obj in snapshots:
4562         _snapshots.append(
4563             {
4564                 "idx": _parse_snapshot_description(snap_obj, unix_time=True)["created"],
4565                 "ptr": snap_obj,
4566             }
4567         )
4568     snapshots = [
4569         w_ptr["ptr"]
4570         for w_ptr in sorted(_snapshots, key=lambda item: item["idx"], reverse=True)
4571     ]
4572     del _snapshots
4573     if not snapshots:
4574         conn.close()
4575         raise CommandExecutionError("No snapshots found")
4576     elif len(snapshots) == 1:
4577         conn.close()
4578         raise CommandExecutionError(
4579             "Cannot revert to itself: only one snapshot is available."
4580         )
4581     snap = None
4582     for p_snap in snapshots:
4583         if not vm_snapshot:
4584             if p_snap.isCurrent() and snapshots[snapshots.index(p_snap) + 1 :]:
4585                 snap = snapshots[snapshots.index(p_snap) + 1 :][0]
4586                 break
4587         elif p_snap.getName() == vm_snapshot:
4588             snap = p_snap
4589             break
4590     if not snap:
4591         conn.close()
4592         raise CommandExecutionError(
4593             snapshot
4594             and 'Snapshot "{}" not found'.format(vm_snapshot)
4595             or "No more previous snapshots available"
4596         )
4597     elif snap.isCurrent():
4598         conn.close()
4599         raise CommandExecutionError("Cannot revert to the currently running snapshot.")
4600     domain.revertToSnapshot(snap)
4601     ret["reverted"] = snap.getName()
4602     if cleanup:
4603         delete = list()
4604         for p_snap in snapshots:
4605             if p_snap.getName() != snap.getName():
4606                 delete.append(p_snap.getName())
4607                 p_snap.delete()
4608             else:
4609                 break
4610         ret["deleted"] = delete
4611     else:
4612         ret["deleted"] = "N/A"
4613     conn.close()
4614     return ret
4615 def _caps_add_machine(machines, node):
4616     """
4617     Parse the &lt;machine&gt; element of the host capabilities and add it
4618     to the machines list.
4619     """
4620     maxcpus = node.get("maxCpus")
4621     canonical = node.get("canonical")
4622     name = node.text
4623     alternate_name = ""
4624     if canonical:
4625         alternate_name = name
4626         name = canonical
4627     machine = machines.get(name)
4628     if not machine:
4629         machine = {"alternate_names": []}
4630         if maxcpus:
4631             machine["maxcpus"] = int(maxcpus)
4632         machines[name] = machine
4633     if alternate_name:
4634         machine["alternate_names"].append(alternate_name)
4635 def _parse_caps_guest(guest):
4636     """
4637     Parse the &lt;guest&gt; element of the connection capabilities XML
4638     """
4639     arch_node = guest.find("arch")
4640     result = {
4641         "os_type": guest.find("os_type").text,
4642         "arch": {"name": arch_node.get("name"), "machines": {}, "domains": {}},
4643     }
4644     child = None
4645     for child in arch_node:
4646         if child.tag == "wordsize":
4647             result["arch"]["wordsize"] = int(child.text)
4648         elif child.tag == "emulator":
4649             result["arch"]["emulator"] = child.text
4650         elif child.tag == "machine":
4651             _caps_add_machine(result["arch"]["machines"], child)
4652         elif child.tag == "domain":
4653             domain_type = child.get("type")
4654             domain = {"emulator": None, "machines": {}}
4655             emulator_node = child.find("emulator")
4656             if emulator_node is not None:
4657                 domain["emulator"] = emulator_node.text
4658             for machine in child.findall("machine"):
4659                 _caps_add_machine(domain["machines"], machine)
4660             result["arch"]["domains"][domain_type] = domain
4661     features_nodes = guest.find("features")
4662     if features_nodes is not None and child is not None:
4663         result["features"] = {
4664             child.tag: {
4665                 "toggle": child.get("toggle", "no") == "yes",
4666                 "default": child.get("default", "on") == "on",
4667             }
4668             for child in features_nodes
4669         }
4670     return result
4671 def _parse_caps_cell(cell):
4672     """
4673     Parse the &lt;cell&gt; nodes of the connection capabilities XML output.
4674     """
4675     result = {"id": int(cell.get("id"))}
4676     mem_node = cell.find("memory")
4677     if mem_node is not None:
4678         unit = mem_node.get("unit", "KiB")
4679         memory = mem_node.text
4680         result["memory"] = "{} {}".format(memory, unit)
4681     pages = [
4682         {
4683             "size": "{} {}".format(page.get("size"), page.get("unit", "KiB")),
4684             "available": int(page.text),
4685         }
4686         for page in cell.findall("pages")
4687     ]
4688     if pages:
4689         result["pages"] = pages
4690     distances = {
4691         int(distance.get("id")): int(distance.get("value"))
4692         for distance in cell.findall("distances/sibling")
4693     }
4694     if distances:
4695         result["distances"] = distances
4696     cpus = []
4697     for cpu_node in cell.findall("cpus/cpu"):
4698         cpu = {"id": int(cpu_node.get("id"))}
4699         socket_id = cpu_node.get("socket_id")
4700         if socket_id:
4701             cpu["socket_id"] = int(socket_id)
4702         core_id = cpu_node.get("core_id")
4703         if core_id:
4704             cpu["core_id"] = int(core_id)
4705         siblings = cpu_node.get("siblings")
4706         if siblings:
4707             cpu["siblings"] = siblings
4708         cpus.append(cpu)
4709     if cpus:
4710         result["cpus"] = cpus
4711     return result
4712 def _parse_caps_bank(bank):
4713     """
4714     Parse the &lt;bank&gt; element of the connection capabilities XML.
4715     """
4716     result = {
4717         "id": int(bank.get("id")),
4718         "level": int(bank.get("level")),
4719         "type": bank.get("type"),
4720         "size": "{} {}".format(bank.get("size"), bank.get("unit")),
4721         "cpus": bank.get("cpus"),
4722     }
4723     controls = []
4724     for control in bank.findall("control"):
4725         unit = control.get("unit")
4726         result_control = {
4727             "granularity": "{} {}".format(control.get("granularity"), unit),
4728             "type": control.get("type"),
4729             "maxAllocs": int(control.get("maxAllocs")),
4730         }
4731         minimum = control.get("min")
4732         if minimum:
4733             result_control["min"] = "{} {}".format(minimum, unit)
4734         controls.append(result_control)
4735     if controls:
4736         result["controls"] = controls
4737     return result
4738 def _parse_caps_host(host):
4739     """
4740     Parse the &lt;host&gt; element of the connection capabilities XML.
4741     """
4742     result = {}
4743     for child in host:
4744         if child.tag == "uuid":
4745             result["uuid"] = child.text
4746         elif child.tag == "cpu":
4747             cpu = {
4748                 "arch": child.find("arch").text
4749                 if child.find("arch") is not None
4750                 else None,
4751                 "model": child.find("model").text
4752                 if child.find("model") is not None
4753                 else None,
4754                 "vendor": child.find("vendor").text
4755                 if child.find("vendor") is not None
4756                 else None,
4757                 "features": [
4758                     feature.get("name") for feature in child.findall("feature")
4759                 ],
4760                 "pages": [
4761                     {"size": "{} {}".format(page.get("size"), page.get("unit", "KiB"))}
4762                     for page in child.findall("pages")
4763                 ],
4764             }
4765             microcode = child.find("microcode")
4766             if microcode is not None:
4767                 cpu["microcode"] = microcode.get("version")
4768             topology = child.find("topology")
4769             if topology is not None:
4770                 cpu["sockets"] = int(topology.get("sockets"))
4771                 cpu["cores"] = int(topology.get("cores"))
4772                 cpu["threads"] = int(topology.get("threads"))
4773             result["cpu"] = cpu
4774         elif child.tag == "power_management":
4775             result["power_management"] = [node.tag for node in child]
4776         elif child.tag == "migration_features":
4777             result["migration"] = {
4778                 "live": child.find("live") is not None,
4779                 "transports": [
4780                     node.text for node in child.findall("uri_transports/uri_transport")
4781                 ],
4782         elif child.tag == "topology":
4783             result["topology"] <font color="#38a4a5"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= {
4784                 "cells": [
4785                     _parse_caps_cell(cell) for cell in child.findall("cells/cell")
4786                 ]
4787             }
4788         elif child.tag == "cache":
4789             result["cache"] = {
4790                 "banks": [_parse_caps_bank(bank) for bank in child.findall(</b></font>"bank")]
4791             }
4792         {
4793             "model": secmodel.find("model").text
4794             if secmodel<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.find("model") is not None
4795             else None,
4796             "doi": secmodel.find("doi").text
4797             if secmodel.find("doi") is not None
4798             else None,
4799             "baselabels": [
4800                 {"type": label.get("type"), "label": label.text}
4801                 for label in secmodel.findall("baselabel")
4802             ],
4803         }
4804         for secmodel in host.</b></font>findall("secmodel")
4805     ]
4806     return result
4807 def _capabilities(conn):
4808     """
4809     Return the hypervisor connection capabilities.
4810     :param conn: opened libvirt connection to use
4811     """
4812     caps = ElementTree.fromstring(conn.getCapabilities())
4813     return {
4814         "host": _parse_caps_host(caps.find("host")),
4815         "guests": [_parse_caps_guest(guest) for guest in caps.findall("guest")],
4816     }
4817 def capabilities(**kwargs):
4818     """
4819     Return the hypervisor connection capabilities.
4820     :param connection: libvirt connection URI, overriding defaults
4821     :param username: username to connect with, overriding defaults
4822     :param password: password to connect with, overriding defaults
4823     .. versionadded:: 2019.2.0
4824     CLI Example:
4825     .. code-block:: bash
4826         salt '*' virt.capabilities
4827     """
4828     conn = __get_conn(**kwargs)
4829     try:
4830         caps = _capabilities(conn)
4831     except libvirt.libvirtError as err:
4832         raise CommandExecutionError(str(err))
4833     finally:
4834         conn.close()
4835     return caps
4836 def _parse_caps_enum(node):
4837     """
4838     Return a tuple containing the name of the enum and the possible values
4839     """
4840     return (node.get("name"), [value.text for value in node.findall("value")])
4841 def _parse_caps_cpu(node):
4842     """
4843     Parse the &lt;cpu&gt; element of the domain capabilities
4844     """
4845     result = {}
4846     for mode in node.findall("mode"):
4847         if not mode.get("supported") == "yes":
4848             continue
4849         name = mode.get("name")
4850         if name == "host-passthrough":
4851             result[name] = True
4852         elif name == "host-model":
4853             host_model = {}
4854             model_node = mode.find("model")
4855             if model_node is not None:
4856                 model = {"name": model_node.text}
4857                 vendor_id = model_node.get("vendor_id")
4858                 if vendor_id:
4859                     model["vendor_id"] = vendor_id
4860                 fallback = model_node.get("fallback")
4861                 if fallback:
4862                     model["fallback"] = fallback
4863                 host_model["model"] = model
4864             vendor = (
4865                 mode.find("vendor").text if mode.find("vendor") is not None else None
4866             )
4867             if vendor:
4868                 host_model["vendor"] = vendor
4869             features = {
4870                 feature.get("name"): feature.get("policy")
4871                 for feature in mode.findall("feature")
4872             }
4873             if features:
4874                 host_model["features"] = features
4875             result[name] = host_model
4876         elif name == "custom":
4877             custom_model = {}
4878             models = {
4879                 model.text: model.get("usable") for model in mode.findall("model")
4880             }
4881             if models:
4882                 custom_model["models"] = models
4883             result[name] = custom_model
4884     return result
4885 def _parse_caps_devices_features(node):
4886     """
4887     Parse the devices or features list of the domain capatilities
4888     """
4889     result = {}
4890     for child in node:
4891         if child.get("supported") == "yes":
4892             enums = [_parse_caps_enum(node) for node in child.findall("enum")]
4893             result[child.tag] = {item[0]: item[1] for item in enums if item[0]}
4894     return result
4895 def _parse_caps_loader(node):
4896     """
4897     Parse the &lt;loader&gt; element of the domain capabilities.
4898     """
4899     enums = [_parse_caps_enum(enum) for enum in node.findall("enum")]
4900     result = {item[0]: item[1] for item in enums if item[0]}
4901     values = [child.text for child in node.findall("value")]
4902     if values:
4903         result["values"] = values
4904     return result
4905 def _parse_domain_caps(caps):
4906     """
4907     Parse the XML document of domain capabilities into a structure.
4908     """
4909     result = {
4910         "emulator": caps.find("path").text if caps.find("path") is not None else None,
4911         "domain": caps.find("domain").text if caps.find("domain") is not None else None,
4912         "machine": caps.find("machine").text
4913         if caps.find("machine") is not None
4914         else None,
4915         "arch": caps.find("arch").text if caps.find("arch") is not None else None,
4916     }
4917     for child in caps:
4918         if child.tag == "vcpu" and child.get("max"):
4919             result["max_vcpus"] = int(child.get("max"))
4920         elif child.tag == "iothreads":
4921             result["iothreads"] = child.get("supported") == "yes"
4922         elif child.tag == "os":
4923             result["os"] = {}
4924             loader_node = child.find("loader")
4925             if loader_node is not None and loader_node.get("supported") == "yes":
4926                 loader = _parse_caps_loader(loader_node)
4927                 result["os"]["loader"] = loader
4928         elif child.tag == "cpu":
4929             cpu = _parse_caps_cpu(child)
4930             if cpu:
4931                 result["cpu"] = cpu
4932         elif child.tag == "devices":
4933             devices = _parse_caps_devices_features(child)
4934             if devices:
4935                 result["devices"] = devices
4936         elif child.tag == "features":
4937             features = _parse_caps_devices_features(child)
4938             if features:
4939                 result["features"] = features
4940     return result
4941 def domain_capabilities(emulator=None, arch=None, machine=None, domain=None, **kwargs):
4942     """
4943     Return the domain capabilities given an emulator, architecture, machine or virtualization type.
4944     .. versionadded:: 2019.2.0
4945     :param emulator: return the capabilities for the given emulator binary
4946     :param arch: return the capabilities for the given CPU architecture
4947     :param machine: return the capabilities for the given emulated machine type
4948     :param domain: return the capabilities for the given virtualization type.
4949     :param connection: libvirt connection URI, overriding defaults
4950     :param username: username to connect with, overriding defaults
4951     :param password: password to connect with, overriding defaults
4952     The list of the possible emulator, arch, machine and domain can be found in
4953     the host capabilities output.
4954     If none of the parameters is provided, the libvirt default one is returned.
4955     CLI Example:
4956     .. code-block:: bash
4957         salt '*' virt.domain_capabilities arch='x86_64' domain='kvm'
4958     """
4959     conn = __get_conn(**kwargs)
4960     result = []
4961     try:
4962         caps = ElementTree.fromstring(
4963             conn.getDomainCapabilities(emulator, arch, machine, domain, 0)
4964         )
4965         result = _parse_domain_caps(caps)
4966     finally:
4967         conn.close()
4968     return result
4969 def all_capabilities(**kwargs):
4970     """
4971     Return the host and domain capabilities in a single call.
4972     .. versionadded:: 3001
4973     :param connection: libvirt connection URI, overriding defaults
4974     :param username: username to connect with, overriding defaults
4975     :param password: password to connect with, overriding defaults
4976     CLI Example:
4977     .. code-block:: bash
4978         salt '*' virt.all_capabilities
4979     """
4980     conn = __get_conn(**kwargs)
4981     try:
4982         host_caps = ElementTree.fromstring(conn.getCapabilities())
4983         domains = [
4984             [
4985                 (
4986                     guest.get("arch", {}).get("name", None),
4987                     key,
4988                     guest.get("arch", {}).get("emulator", None),
4989                 )
4990                 for key in guest.get("arch", {}).get("domains", {}).keys()
4991             ]
4992             for guest in [
4993                 _parse_caps_guest(guest) for guest in host_caps.findall("guest")
4994             ]
4995         ]
4996         flattened = [pair for item in (x for x in domains) for pair in item]
4997         result = {
4998             "host": {
4999                 "host": _parse_caps_host(host_caps.find("host")),
5000                 "guests": [
5001                     _parse_caps_guest(guest) for guest in host_caps.findall("guest")
5002                 ],
5003             },
5004             "domains": [
5005                 _parse_domain_caps(
5006                     ElementTree.fromstring(
5007                         conn.getDomainCapabilities(emulator, arch, None, domain)
5008                     )
5009                 )
5010                 for (arch, domain, emulator) in flattened
5011             ],
5012         }
5013         return result
5014     finally:
5015         conn.close()
5016 def cpu_baseline(full=False, migratable=False, out="libvirt", **kwargs):
5017     """
5018     Return the optimal 'custom' CPU baseline config for VM's on this minion
5019     .. versionadded:: 2016.3.0
5020     :param full: Return all CPU features rather than the ones on top of the closest CPU model
5021     :param migratable: Exclude CPU features that are unmigratable (libvirt 2.13+)
5022     :param out: 'libvirt' (default) for usable libvirt XML definition, 'salt' for nice dict
5023     :param connection: libvirt connection URI, overriding defaults
5024         .. versionadded:: 2019.2.0
5025     :param username: username to connect with, overriding defaults
5026         .. versionadded:: 2019.2.0
5027     :param password: password to connect with, overriding defaults
5028         .. versionadded:: 2019.2.0
5029     CLI Example:
5030     .. code-block:: bash
5031         salt '*' virt.cpu_baseline
5032     """
5033     conn = __get_conn(**kwargs)
5034     caps = ElementTree.fromstring(conn.getCapabilities())
5035     cpu = caps.find("host/cpu")
5036     host_cpu_def = xmlutil.element_to_str(cpu)
5037     log.debug("Host CPU model definition: %s", host_cpu_def)
5038     flags = 0
5039     if migratable:
5040         if getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_MIGRATABLE", False):
5041             flags += libvirt.VIR_CONNECT_BASELINE_CPU_MIGRATABLE
5042         else:
5043             conn.close()
5044             raise ValueError
5045     if full and getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES", False):
5046         flags += libvirt.VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES
5047     cpu = ElementTree.fromstring(conn.baselineCPU([host_cpu_def], flags))
5048     conn.close()
5049     if full and not getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES", False):
5050         with salt.utils.files.fopen("/usr/share/libvirt/cpu_map.xml", "r") as cpu_map:
5051             cpu_map = ElementTree.parse(cpu_map)
5052         cpu_model = cpu.find("model").text
5053         while cpu_model:
5054             cpu_map_models = cpu_map.findall("arch/model")
5055             cpu_specs = [
5056                 el
5057                 for el in cpu_map_models
5058                 if el.get("name") == cpu_model and bool(len(el))
5059             ]
5060             if not cpu_specs:
5061                 raise ValueError("Model {} not found in CPU map".format(cpu_model))
5062             elif len(cpu_specs) &gt; 1:
5063                 raise ValueError(
5064                     "Multiple models {} found in CPU map".format(cpu_model)
5065                 )
5066             cpu_specs = cpu_specs[0]
5067             model_node = cpu_specs.find("model")
5068             if model_node is None:
5069                 cpu_model = None
5070             else:
5071                 cpu_model = model_node.get("name")
5072             cpu.extend([feature for feature in cpu_specs.findall("feature")])
5073     if out == "salt":
5074         return {
5075             "model": cpu.find("model").text,
5076             "vendor": cpu.find("vendor").text,
5077             "features": [feature.get("name") for feature in cpu.findall("feature")],
5078         }
5079     return ElementTree.tostring(cpu)
5080 def network_define(
5081     name,
5082     bridge,
5083     forward,
5084     ipv4_config=None,
5085     ipv6_config=None,
5086     vport=None,
5087     tag=None,
5088     autostart=True,
5089     start=True,
5090     mtu=None,
5091     domain=None,
5092     nat=None,
5093     interfaces=None,
5094     addresses=None,
5095     physical_function=None,
5096     dns=None,
5097     **kwargs
5098 ):
5099     """
5100     Create libvirt network.
5101     :param name: Network name.
5102     :param bridge: Bridge name.
5103     :param forward: Forward mode (bridge, router, nat).
5104         .. versionchanged:: 3003
5105            a ``None`` value creates an isolated network with no forwarding at all
5106     :param vport: Virtualport type.
5107         The value can also be a dictionary with ``type`` and ``parameters`` keys.
5108         The ``parameters`` value is a dictionary of virtual port parameters.
5109         .. code-block:: yaml
5110           - vport:
5111               type: openvswitch
5112               parameters:
5113                 interfaceid: 09b11c53-8b5c-4eeb-8f00-d84eaa0aaa4f
5114         .. versionchanged:: 3003
5115            possible dictionary value
5116     :param tag: Vlan tag.
5117         The value can also be a dictionary with the ``tags`` and optional ``trunk`` keys.
5118         ``trunk`` is a boolean value indicating whether to use VLAN trunking.
5119         ``tags`` is a list of dictionaries with keys ``id`` and ``nativeMode``.
5120         The ``nativeMode`` value can be one of ``tagged`` or ``untagged``.
5121         .. code-block:: yaml
5122           - tag:
5123               trunk: True
5124               tags:
5125                 - id: 42
5126                   nativeMode: untagged
5127                 - id: 47
5128         .. versionchanged:: 3003
5129            possible dictionary value
5130     :param autostart: Network autostart (default True).
5131     :param start: Network start (default True).
5132     :param ipv4_config: IP v4 configuration.
5133         Dictionary describing the IP v4 setup like IP range and
5134         a possible DHCP configuration. The structure is documented
5135         in net-define-ip_.
5136         .. versionadded:: 3000
5137     :type ipv4_config: dict or None
5138     :param ipv6_config: IP v6 configuration.
5139         Dictionary describing the IP v6 setup like IP range and
5140         a possible DHCP configuration. The structure is documented
5141         in net-define-ip_.
5142         .. versionadded:: 3000
5143     :type ipv6_config: dict or None
5144     :param connection: libvirt connection URI, overriding defaults.
5145     :param username: username to connect with, overriding defaults.
5146     :param password: password to connect with, overriding defaults.
5147     :param mtu: size of the Maximum Transmission Unit (MTU) of the network.
5148         (default ``None``)
5149         .. versionadded:: 3003
5150     :param domain: DNS domain name of the DHCP server.
5151         The value is a dictionary with a mandatory ``name`` property and an optional ``localOnly`` boolean one.
5152         (default ``None``)
5153         .. code-block:: yaml
5154           - domain:
5155               name: lab.acme.org
5156               localOnly: True
5157         .. versionadded:: 3003
5158     :param nat: addresses and ports to route in NAT forward mode.
5159         The value is a dictionary with optional keys ``address`` and ``port``.
5160         Both values are a dictionary with ``start`` and ``end`` values.
5161         (default ``None``)
5162         .. code-block:: yaml
5163           - forward: nat
5164           - nat:
5165               address:
5166                 start: 1.2.3.4
5167                 end: 1.2.3.10
5168               port:
5169                 start: 500
5170                 end: 1000
5171         .. versionadded:: 3003
5172     :param interfaces: whitespace separated list of network interfaces devices that can be used for this network.
5173         (default ``None``)
5174         .. code-block:: yaml
5175           - forward: passthrough
5176           - interfaces: "eth10 eth11 eth12"
5177         .. versionadded:: 3003
5178     :param addresses: whitespace separated list of addresses of PCI devices that can be used for this network in `hostdev` forward mode.
5179         (default ``None``)
5180         .. code-block:: yaml
5181           - forward: hostdev
5182           - interfaces: "0000:04:00.1 0000:e3:01.2"
5183         .. versionadded:: 3003
5184     :param physical_function: device name of the physical interface to use in ``hostdev`` forward mode.
5185         (default ``None``)
5186         .. code-block:: yaml
5187           - forward: hostdev
5188           - physical_function: "eth0"
5189         .. versionadded:: 3003
5190     :param dns: virtual network DNS configuration.
5191         The value is a dictionary described in net-define-dns_.
5192         (default ``None``)
5193         .. code-block:: yaml
5194           - dns:
5195               forwarders:
5196                 - domain: example.com
5197                   addr: 192.168.1.1
5198                 - addr: 8.8.8.8
5199                 - domain: www.example.com
5200               txt:
5201                 example.com: "v=spf1 a -all"
5202                 _http.tcp.example.com: "name=value,paper=A4"
5203               hosts:
5204                 192.168.1.2:
5205                   - mirror.acme.lab
5206                   - test.acme.lab
5207               srvs:
5208                 - name: ldap
5209                   protocol: tcp
5210                   domain: ldapserver.example.com
5211                   target: .
5212                   port: 389
5213                   priority: 1
5214                   weight: 10
5215         .. versionadded:: 3003
5216     .. _net-define-ip:
5217     .. rubric:: IP configuration definition
5218     Both the IPv4 and IPv6 configuration dictionaries can contain the following properties:
5219     cidr
5220         CIDR notation for the network. For example '192.168.124.0/24'
5221     dhcp_ranges
5222         A list of dictionaries with ``'start'`` and ``'end'`` properties.
5223     hosts
5224         A list of dictionaries with ``ip`` property and optional ``name``, ``mac`` and ``id`` properties.
5225         .. versionadded:: 3003
5226     bootp
5227         A dictionary with a ``file`` property and an optional ``server`` one.
5228         .. versionadded:: 3003
5229     tftp
5230         The path to the TFTP root directory to serve.
5231         .. versionadded:: 3003
5232     .. _net-define-dns:
5233     .. rubric:: DNS configuration definition
5234     The DNS configuration dictionary contains the following optional properties:
5235     forwarders
5236         List of alternate DNS forwarders to use.
5237         Each item is a dictionary with the optional ``domain`` and ``addr`` keys.
5238         If both are provided, the requests to the domain are forwarded to the server at the ``addr``.
5239         If only ``domain`` is provided the requests matching this domain will be resolved locally.
5240         If only ``addr`` is provided all requests will be forwarded to this DNS server.
5241     txt:
5242         Dictionary of TXT fields to set.
5243     hosts:
5244         Dictionary of host DNS entries.
5245         The key is the IP of the host, and the value is a list of hostnames for it.
5246     srvs:
5247         List of SRV DNS entries.
5248         Each entry is a dictionary with the mandatory ``name`` and ``protocol`` keys.
5249         Entries can also have ``target``, ``port``, ``priority``, ``domain`` and ``weight`` optional properties.
5250     CLI Example:
5251     .. code-block:: bash
5252         salt '*' virt.network_define network main bridge openvswitch
5253     .. versionadded:: 2019.2.0
5254     """
5255     conn = __get_conn(**kwargs)
5256     vport = kwargs.get("vport", None)
5257     tag = kwargs.get("tag", None)
5258     net_xml = _gen_net_xml(
5259         name,
5260         bridge,
5261         forward,
5262         vport,
5263         tag=tag,
5264         ip_configs=[config for config in [ipv4_config, ipv6_config] if config],
5265         mtu=mtu,
5266         domain=domain,
5267         nat=nat,
5268         interfaces=interfaces,
5269         addresses=addresses,
5270         physical_function=physical_function,
5271         dns=dns,
5272     )
5273     try:
5274         conn.networkDefineXML(net_xml)
5275     except libvirt.libvirtError as err:
5276         log.warning(err)
5277         conn.close()
5278         raise err  # a real error we should report upwards
5279     try:
5280         network = conn.networkLookupByName(name)
5281     except libvirt.libvirtError as err:
5282         log.warning(err)
5283         conn.close()
5284         raise err  # a real error we should report upwards
5285     if network is None:
5286         conn.close()
5287         return False
5288     if (start or autostart) and network.isActive() != 1:
5289         network.create()
5290     if autostart and network.autostart() != 1:
5291         network.setAutostart(int(autostart))
5292     elif not autostart and network.autostart() == 1:
5293         network.setAutostart(int(autostart))
5294     conn.close()
5295     return True
5296 def _remove_empty_xml_node(node):
5297     """
5298     Remove the nodes with no children, no text and no attribute
5299     """
5300     for child in node:
5301         if not child.tail and not child.text and not child.items() and not child:
5302             node.remove(child)
5303         else:
5304             _remove_empty_xml_node(child)
5305     return node
5306 def network_update(
5307     name,
5308     bridge,
5309     forward,
5310     ipv4_config=None,
5311     ipv6_config=None,
5312     vport=None,
5313     tag=None,
5314     mtu=None,
5315     domain=None,
5316     nat=None,
5317     interfaces=None,
5318     addresses=None,
5319     physical_function=None,
5320     dns=None,
5321     test=False,
5322     **kwargs
5323 ):
5324     """
5325     Update a virtual network if needed.
5326     :param name: Network name.
5327     :param bridge: Bridge name.
5328     :param forward: Forward mode (bridge, router, nat).
5329         A ``None`` value creates an isolated network with no forwarding at all.
5330     :param vport: Virtualport type.
5331         The value can also be a dictionary with ``type`` and ``parameters`` keys.
5332         The ``parameters`` value is a dictionary of virtual port parameters.
5333         .. code-block:: yaml
5334           - vport:
5335               type: openvswitch
5336               parameters:
5337                 interfaceid: 09b11c53-8b5c-4eeb-8f00-d84eaa0aaa4f
5338     :param tag: Vlan tag.
5339         The value can also be a dictionary with the ``tags`` and optional ``trunk`` keys.
5340         ``trunk`` is a boolean value indicating whether to use VLAN trunking.
5341         ``tags`` is a list of dictionaries with keys ``id`` and ``nativeMode``.
5342         The ``nativeMode`` value can be one of ``tagged`` or ``untagged``.
5343         .. code-block:: yaml
5344           - tag:
5345               trunk: True
5346               tags:
5347                 - id: 42
5348                   nativeMode: untagged
5349                 - id: 47
5350     :param ipv4_config: IP v4 configuration.
5351         Dictionary describing the IP v4 setup like IP range and
5352         a possible DHCP configuration. The structure is documented
5353         in net-define-ip_.
5354     :type ipv4_config: dict or None
5355     :param ipv6_config: IP v6 configuration.
5356         Dictionary describing the IP v6 setup like IP range and
5357         a possible DHCP configuration. The structure is documented
5358         in net-define-ip_.
5359     :type ipv6_config: dict or None
5360     :param connection: libvirt connection URI, overriding defaults.
5361     :param username: username to connect with, overriding defaults.
5362     :param password: password to connect with, overriding defaults.
5363     :param mtu: size of the Maximum Transmission Unit (MTU) of the network.
5364         (default ``None``)
5365     :param domain: DNS domain name of the DHCP server.
5366         The value is a dictionary with a mandatory ``name`` property and an optional ``localOnly`` boolean one.
5367         (default ``None``)
5368         .. code-block:: yaml
5369           - domain:
5370               name: lab.acme.org
5371               localOnly: True
5372     :param nat: addresses and ports to route in NAT forward mode.
5373         The value is a dictionary with optional keys ``address`` and ``port``.
5374         Both values are a dictionary with ``start`` and ``end`` values.
5375         (default ``None``)
5376         .. code-block:: yaml
5377           - forward: nat
5378           - nat:
5379               address:
5380                 start: 1.2.3.4
5381                 end: 1.2.3.10
5382               port:
5383                 start: 500
5384                 end: 1000
5385     :param interfaces: whitespace separated list of network interfaces devices that can be used for this network.
5386         (default ``None``)
5387         .. code-block:: yaml
5388           - forward: passthrough
5389           - interfaces: "eth10 eth11 eth12"
5390     :param addresses: whitespace separated list of addresses of PCI devices that can be used for this network in `hostdev` forward mode.
5391         (default ``None``)
5392         .. code-block:: yaml
5393           - forward: hostdev
5394           - interfaces: "0000:04:00.1 0000:e3:01.2"
5395     :param physical_function: device name of the physical interface to use in ``hostdev`` forward mode.
5396         (default ``None``)
5397         .. code-block:: yaml
5398           - forward: hostdev
5399           - physical_function: "eth0"
5400     :param dns: virtual network DNS configuration.
5401         The value is a dictionary described in net-define-dns_.
5402         (default ``None``)
5403         .. code-block:: yaml
5404           - dns:
5405               forwarders:
5406                 - domain: example.com
5407                   addr: 192.168.1.1
5408                 - addr: 8.8.8.8
5409                 - domain: www.example.com
5410               txt:
5411                 example.com: "v=spf1 a -all"
5412                 _http.tcp.example.com: "name=value,paper=A4"
5413               hosts:
5414                 192.168.1.2:
5415                   - mirror.acme.lab
5416                   - test.acme.lab
5417               srvs:
5418                 - name: ldap
5419                   protocol: tcp
5420                   domain: ldapserver.example.com
5421                   target: .
5422                   port: 389
5423                   priority: 1
5424                   weight: 10
5425     .. versionadded:: 3003
5426     """
5427     conn = __get_conn(**kwargs)
5428     needs_update = False
5429     try:
5430         net = conn.networkLookupByName(name)
5431         old_xml = ElementTree.fromstring(net.XMLDesc())
5432         new_xml = ElementTree.fromstring(
5433             _gen_net_xml(
5434                 name,
5435                 bridge,
5436                 forward,
5437                 vport,
5438                 tag=tag,
5439                 ip_configs=[config for config in [ipv4_config, ipv6_config] if config],
5440                 mtu=mtu,
5441                 domain=domain,
5442                 nat=nat,
5443                 interfaces=interfaces,
5444                 addresses=addresses,
5445                 physical_function=physical_function,
5446                 dns=dns,
5447             )
5448         )
5449         elements_to_copy = ["uuid", "mac"]
5450         for to_copy in elements_to_copy:
5451             element = old_xml.find(to_copy)
5452             if element is not None:
5453                 new_xml.insert(1, element)
5454         old_xml.attrib.pop("connections", None)
5455         if old_xml.find("forward/pf") is not None:
5456             forward_node = old_xml.find("forward")
5457             address_nodes = forward_node.findall("address")
5458             for node in address_nodes:
5459                 forward_node.remove(node)
5460         default_bridge_attribs = {"stp": "on", "delay": "0"}
5461         old_bridge_node = old_xml.find("bridge")
5462         if old_bridge_node is not None:
5463             for key, value in default_bridge_attribs.items():
5464                 if old_bridge_node.get(key, None) == value:
5465                     old_bridge_node.attrib.pop(key, None)
5466             old_forward = (
5467                 old_xml.find("forward").get("mode")
5468                 if old_xml.find("forward") is not None
5469                 else None
5470             )
5471             if (
5472                 old_forward == forward
5473                 and forward in ["nat", "route", "open", None]
5474                 and bridge is None
5475                 and old_bridge_node.get("name", "").startswith("virbr")
5476             ):
5477                 old_bridge_node.attrib.pop("name", None)
5478         ipv4_nodes = [
5479             node
5480             for node in old_xml.findall("ip")
5481             if node.get("family", "ipv4") == "ipv4"
5482         ]
5483         for ip_node in ipv4_nodes:
5484             netmask = ip_node.attrib.pop("netmask", None)
5485             if netmask:
5486                 address = ipaddress.ip_network(
5487                     "{}/{}".format(ip_node.get("address"), netmask), strict=False
5488                 )
5489                 ip_node.set("prefix", str(address.prefixlen))
5490         for doc in [old_xml, new_xml]:
5491             for node in doc.findall("ip"):
5492                 if "family" not in node.keys():
5493                     node.set("family", "ipv4")
5494         _remove_empty_xml_node(xmlutil.strip_spaces(old_xml))
5495         xmlutil.strip_spaces(new_xml)
5496         needs_update = xmlutil.to_dict(old_xml, True) != xmlutil.to_dict(new_xml, True)
5497         if needs_update and not test:
5498             conn.networkDefineXML(xmlutil.element_to_str(new_xml))
5499     finally:
5500         conn.close()
5501     return needs_update
5502 def list_networks(**kwargs):
5503     """
5504     List all virtual networks.
5505     :param connection: libvirt connection URI, overriding defaults
5506     :param username: username to connect with, overriding defaults
5507     :param password: password to connect with, overriding defaults
5508     .. versionadded:: 2019.2.0
5509     CLI Example:
5510     .. code-block:: bash
5511        salt '*' virt.list_networks
5512     """
5513     conn = __get_conn(**kwargs)
5514     try:
5515         return [net.name() for net in conn.listAllNetworks()]
5516     finally:
5517         conn.close()
5518 def network_info(name=None, **kwargs):
5519     """
5520     Return information on a virtual network provided its name.
5521     :param name: virtual network name
5522     :param connection: libvirt connection URI, overriding defaults
5523     :param username: username to connect with, overriding defaults
5524     :param password: password to connect with, overriding defaults
5525     If no name is provided, return the infos for all defined virtual networks.
5526     .. versionadded:: 2019.2.0
5527     CLI Example:
5528     .. code-block:: bash
5529         salt '*' virt.network_info default
5530     """
5531     result = {}
5532     conn = __get_conn(**kwargs)
5533     def _net_get_leases(net):
5534         """
5535         Get all DHCP leases for a network
5536         """
5537         leases = net.DHCPLeases()
5538         for lease in leases:
5539             if lease["type"] == libvirt.VIR_IP_ADDR_TYPE_IPV4:
5540                 lease["type"] = "ipv4"
5541             elif lease["type"] == libvirt.VIR_IP_ADDR_TYPE_IPV6:
5542                 lease["type"] = "ipv6"
5543             else:
5544                 lease["type"] = "unknown"
5545         return leases
5546     def _net_get_bridge(net):
5547         """
5548         Get the bridge of the network or None
5549         """
5550         try:
5551             return net.bridgeName()
5552         except libvirt.libvirtError as err:
5553             return None
5554     try:
5555         nets = [
5556             net for net in conn.listAllNetworks() if name is None or net.name() == name
5557         ]
5558         result = {
5559             net.name(): {
5560                 "uuid": net.UUIDString(),
5561                 "bridge": _net_get_bridge(net),
5562                 "autostart": net.autostart(),
5563                 "active": net.isActive(),
5564                 "persistent": net.isPersistent(),
5565                 "leases": _net_get_leases(net),
5566             }
5567             for net in nets
5568         }
5569     except libvirt.libvirtError as err:
5570         log.debug("Silenced libvirt error: %s", err)
5571     finally:
5572         conn.close()
5573     return result
5574 def network_get_xml(name, **kwargs):
5575     """
5576     Return the XML definition of a virtual network
5577     :param name: libvirt network name
5578     :param connection: libvirt connection URI, overriding defaults
5579     :param username: username to connect with, overriding defaults
5580     :param password: password to connect with, overriding defaults
5581     .. versionadded:: 3000
5582     CLI Example:
5583     .. code-block:: bash
5584         salt '*' virt.network_get_xml default
5585     """
5586     conn = __get_conn(**kwargs)
5587     try:
5588         return conn.networkLookupByName(name).XMLDesc()
5589     finally:
5590         conn.close()
5591 def network_start(name, **kwargs):
5592     """
5593     Start a defined virtual network.
5594     :param name: virtual network name
5595     :param connection: libvirt connection URI, overriding defaults
5596     :param username: username to connect with, overriding defaults
5597     :param password: password to connect with, overriding defaults
5598     .. versionadded:: 2019.2.0
5599     CLI Example:
5600     .. code-block:: bash
5601         salt '*' virt.network_start default
5602     """
5603     conn = __get_conn(**kwargs)
5604     try:
5605         net = conn.networkLookupByName(name)
5606         return not bool(net.create())
5607     finally:
5608         conn.close()
5609 def network_stop(name, **kwargs):
5610     """
5611     Stop a defined virtual network.
5612     :param name: virtual network name
5613     :param connection: libvirt connection URI, overriding defaults
5614     :param username: username to connect with, overriding defaults
5615     :param password: password to connect with, overriding defaults
5616     .. versionadded:: 2019.2.0
5617     CLI Example:
5618     .. code-block:: bash
5619         salt '*' virt.network_stop default
5620     """
5621     conn = __get_conn(**kwargs)
5622     try:
5623         net = conn.networkLookupByName(name)
5624         return not bool(net.destroy())
5625     finally:
5626         conn.close()
5627 def network_undefine(name, **kwargs):
5628     """
5629     Remove a defined virtual network. This does not stop the virtual network.
5630     :param name: virtual network name
5631     :param connection: libvirt connection URI, overriding defaults
5632     :param username: username to connect with, overriding defaults
5633     :param password: password to connect with, overriding defaults
5634     .. versionadded:: 2019.2.0
5635     CLI Example:
5636     .. code-block:: bash
5637         salt '*' virt.network_undefine default
5638     """
5639     conn = __get_conn(**kwargs)
5640     try:
5641         net = conn.networkLookupByName(name)
5642         return not bool(net.undefine())
5643     finally:
5644         conn.close()
5645 def network_set_autostart(name, state="on", **kwargs):
5646     """
5647     Set the autostart flag on a virtual network so that the network
5648     will start with the host system on reboot.
5649     :param name: virtual network name
5650     :param state: 'on' to auto start the network, anything else to mark the
5651                   virtual network not to be started when the host boots
5652     :param connection: libvirt connection URI, overriding defaults
5653     :param username: username to connect with, overriding defaults
5654     :param password: password to connect with, overriding defaults
5655     .. versionadded:: 2019.2.0
5656     CLI Example:
5657     .. code-block:: bash
5658         salt "*" virt.network_set_autostart &lt;pool&gt; &lt;on | off&gt;
5659     """
5660     conn = __get_conn(**kwargs)
5661     try:
5662         net = conn.networkLookupByName(name)
5663         return not bool(net.setAutostart(1 if state == "on" else 0))
5664     finally:
5665         conn.close()
5666 def _parse_pools_caps(doc):
5667     """
5668     Parse libvirt pool capabilities XML
5669     """
5670     def _parse_pool_caps(pool):
5671         pool_caps = {
5672             "name": pool.get("type"),
5673             "supported": pool.get("supported", "no") == "yes",
5674         }
5675         for option_kind in ["pool", "vol"]:
5676             options = {}
5677             default_format_node = pool.find(
5678                 "{}Options/defaultFormat".format(option_kind)
5679             )
5680             if default_format_node is not None:
5681                 options["default_format"] = default_format_node.get("type")
5682             options_enums = {
5683                 enum.get("name"): [value.text for value in enum.findall("value")]
5684                 for enum in pool.findall("{}Options/enum".format(option_kind))
5685             }
5686             if options_enums:
5687                 options.update(options_enums)
5688             if options:
5689                 if "options" not in pool_caps:
5690                     pool_caps["options"] = {}
5691                 kind = option_kind if option_kind != "vol" else "volume"
5692                 pool_caps["options"][kind] = options
5693         return pool_caps
5694     return [_parse_pool_caps(pool) for pool in doc.findall("pool")]
5695 def _pool_capabilities(conn):
5696     """
5697     Return the hypervisor connection storage pool capabilities.
5698     :param conn: opened libvirt connection to use
5699     """
5700     has_pool_capabilities = bool(getattr(conn, "getStoragePoolCapabilities", None))
5701     if has_pool_capabilities:
5702         caps = ElementTree.fromstring(conn.getStoragePoolCapabilities())
5703         pool_types = _parse_pools_caps(caps)
5704     else:
5705         all_hypervisors = ["xen", "kvm", "bhyve"]
5706         images_formats = [
5707             "none",
5708             "raw",
5709             "dir",
5710             "bochs",
5711             "cloop",
5712             "dmg",
5713             "iso",
5714             "vpc",
5715             "vdi",
5716             "fat",
5717             "vhd",
5718             "ploop",
5719             "cow",
5720             "qcow",
5721             "qcow2",
5722             "qed",
5723         ]
5724         common_drivers = [
5725             <font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>{
5726                 "name": "fs",
5727                 "default_source_format": "auto",
5728                 "source_formats": [
5729                     "auto",
5730                     "ext2",
5731                     "ext3",
5732                     "ext4",
5733                     "ufs",
5734                     "iso9660",
5735                     "udf",
5736                     "gfs",
5737                     "gfs2",
5738                     "vfat",
5739                     "hfs+",
5740                     "xfs",
5741                     "ocfs2",
5742                 ],
5743                 "default_target_format": "raw",
5744                 "target_formats": images_formats,
5745             },
5746             {
5747                 "name": "dir",
5748                 "default_target_format": "raw",
5749                 "target_formats": images_formats,
5750             },
5751             {"name": "iscsi"},
5752             {"name": "scsi"},
5753             {
5754                 "name": "logical",
5755                 "default_source_format": "lvm2",
5756                 "source_formats": ["unknown", "lvm2"],
5757             },
5758             {
5759                 "name": "netfs",
5760                 "default_source_format": "auto",
5761                 "source_formats": ["auto", "nfs", "glusterfs", "cifs"],
5762                 "default_target_format": "raw",
5763                 "target_formats": images_formats,
5764             },
5765             {
5766                 "name": "disk",
5767                 "default_source_format": "unknown",
5768                 "source_formats": [
5769                     "unknown",
5770                     "dos",
5771                     "dvh",
5772                     "gpt",
5773                     "mac",
5774                     "bsd",
5775                     "pc98",
5776                     "sun",
5777                     "lvm2",
5778                 ],
5779                 "default_target_format": "none",
5780                 "target_formats": [
5781                     "none",
5782                     "linux",
5783                     "fat16",
5784                     "fat32",
5785                     "linux-swap",
5786                     "linux-lvm",
5787                     "linux-raid",
5788                     "extended",
5789                 ],
5790             },
5791             {"name": "mpath"},
5792             {"name": "rbd", "default_target_format": "raw", "target_formats": []},
5793             {
5794                 "name": "sheepdog",
5795                 "version": 10000,
5796                 "hypervisors": ["kvm"],
5797                 "default_target_format": "raw",
5798                 "target_formats": images_formats,
5799             },
5800             {
5801                 "name": "gluster",
5802                 "version": 1002000,
5803                 "hypervisors": ["kvm"],
5804                 "default_target_format": "raw",
5805                 "target_formats": images_formats,
5806             },
5807             {"name": "zfs", "version": 1002008, "hypervisors": ["bhyve"]},
5808             {
5809                 "name": "iscsi-direct",
5810                 "version": 4007000,
5811                 "hypervisors": ["kvm"</b></font>, "xen"],
5812             },
5813         ]
5814         libvirt_version = conn.getLibVersion()
5815         hypervisor = get_hypervisor()
5816         def _get_backend_output(backend):
5817                 "name": backend["name"],
5818                 "supported": (
5819                     not backend<font color="#151b8d"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.get("version") or libvirt_version &gt;= backend["version"]
5820                 )
5821                 and hypervisor in backend.get("hypervisors", all_hypervisors),
5822                 "options": {
5823                     "pool": {
5824                         "default_format": backend.get("default_source_format"),
5825                         "sourceFormatType": backend.get("source_formats"),
5826                     },
5827                     "volume": {
5828                         "default_format": backend.</b></font>get("default_target_format"),
5829                         "targetFormatType": backend.get("target_formats"),
5830                     },
5831                 },
5832             }
5833             for option_kind in ["pool", "volume"]:
5834                 if not [
5835                     value
5836                     for value in output["options"][option_kind].values()
5837                     if value is not None
5838                 ]:
5839                     del output["options"][option_kind]
5840             if not output["options"]:
5841                 del output["options"]
5842             return output
5843         pool_types = [_get_backend_output(backend) for backend in common_drivers]
5844     return {
5845         "computed": not has_pool_capabilities,
5846         "pool_types": pool_types,
5847     }
5848 def pool_capabilities(**kwargs):
5849     """
5850     Return the hypervisor connection storage pool capabilities.
5851     The returned data are either directly extracted from libvirt or computed.
5852     In the latter case some pool types could be listed as supported while they
5853     are not. To distinguish between the two cases, check the value of the ``computed`` property.
5854     :param connection: libvirt connection URI, overriding defaults
5855     :param username: username to connect with, overriding defaults
5856     :param password: password to connect with, overriding defaults
5857     .. versionadded:: 3000
5858     CLI Example:
5859     .. code-block:: bash
5860         salt '*' virt.pool_capabilities
5861     """
5862     try:
5863         conn = __get_conn(**kwargs)
5864         return _pool_capabilities(conn)
5865     finally:
5866         conn.close()
5867 def pool_define(
5868     name,
5869     ptype,
5870     target=None,
5871     permissions=None,
5872     source_devices=None,
5873     source_dir=None,
5874     source_initiator=None,
5875     source_adapter=None,
5876     source_hosts=None,
5877     source_auth=None,
5878     source_name=None,
5879     source_format=None,
5880     transient=False,
5881     start=True,  # pylint: disable=redefined-outer-name
5882     **kwargs
5883 ):
5884     """
5885     Create libvirt pool.
5886     :param name: Pool name
5887     :param ptype:
5888         Pool type. See `libvirt documentation &lt;https://libvirt.org/storage.html&gt;`_  for the
5889         possible values.
5890     :param target: Pool full path target
5891     :param permissions:
5892         Permissions to set on the target folder. This is mostly used for filesystem-based
5893         pool types. See :ref:`pool-define-permissions` for more details on this structure.
5894     :param source_devices:
5895         List of source devices for pools backed by physical devices. (Default: ``None``)
5896         Each item in the list is a dictionary with ``path`` and optionally ``part_separator``
5897         keys. The path is the qualified name for iSCSI devices.
5898         Report to `this libvirt page &lt;https://libvirt.org/formatstorage.html#StoragePool&gt;`_
5899         for more information on the use of ``part_separator``
5900     :param source_dir:
5901         Path to the source directory for pools of type ``dir``, ``netfs`` or ``gluster``.
5902         (Default: ``None``)
5903     :param source_initiator:
5904         Initiator IQN for libiscsi-direct pool types. (Default: ``None``)
5905         .. versionadded:: 3000
5906     :param source_adapter:
5907         SCSI source definition. The value is a dictionary with ``type``, ``name``, ``parent``,
5908         ``managed``, ``parent_wwnn``, ``parent_wwpn``, ``parent_fabric_wwn``, ``wwnn``, ``wwpn``
5909         and ``parent_address`` keys.
5910         The ``parent_address`` value is a dictionary with ``unique_id`` and ``address`` keys.
5911         The address represents a PCI address and is itself a dictionary with ``domain``, ``bus``,
5912         ``slot`` and ``function`` properties.
5913         Report to `this libvirt page &lt;https://libvirt.org/formatstorage.html#StoragePool&gt;`_
5914         for the meaning and possible values of these properties.
5915     :param source_hosts:
5916         List of source for pools backed by storage from remote servers. Each item is the hostname
5917         optionally followed by the port separated by a colon. (Default: ``None``)
5918     :param source_auth:
5919         Source authentication details. (Default: ``None``)
5920         The value is a dictionary with ``type``, ``username`` and ``secret`` keys. The type
5921         can be one of ``ceph`` for Ceph RBD or ``chap`` for iSCSI sources.
5922         The ``secret`` value links to a libvirt secret object. It is a dictionary with
5923         ``type`` and ``value`` keys. The type value can be either ``uuid`` or ``usage``.
5924         Examples:
5925         .. code-block:: python
5926             source_auth={
5927                 'type': 'ceph',
5928                 'username': 'admin',
5929                 'secret': {
5930                     'type': 'uuid',
5931                     'value': '2ec115d7-3a88-3ceb-bc12-0ac909a6fd87'
5932                 }
5933             }
5934         .. code-block:: python
5935             source_auth={
5936                 'type': 'chap',
5937                 'username': 'myname',
5938                 'secret': {
5939                     'type': 'usage',
5940                     'value': 'mycluster_myname'
5941                 }
5942             }
5943         Since 3000, instead the source authentication can only contain ``username``
5944         and ``password`` properties. In this case the libvirt secret will be defined and used.
5945         For Ceph authentications a base64 encoded key is expected.
5946     :param source_name:
5947         Identifier of name-based sources.
5948     :param source_format:
5949         String representing the source format. The possible values are depending on the
5950         source type. See `libvirt documentation &lt;https://libvirt.org/storage.html&gt;`_ for
5951         the possible values.
5952     :param start: Pool start (default True)
5953     :param transient:
5954         When ``True``, the pool will be automatically undefined after being stopped.
5955         Note that a transient pool will force ``start`` to ``True``. (Default: ``False``)
5956     :param connection: libvirt connection URI, overriding defaults
5957     :param username: username to connect with, overriding defaults
5958     :param password: password to connect with, overriding defaults
5959     .. _pool-define-permissions:
5960     .. rubric:: Permissions definition
5961     The permissions are described by a dictionary containing the following keys:
5962     mode
5963         The octal representation of the permissions. (Default: `0711`)
5964     owner
5965         the numeric user ID of the owner. (Default: from the parent folder)
5966     group
5967         the numeric ID of the group. (Default: from the parent folder)
5968     label
5969         the SELinux label. (Default: `None`)
5970     .. rubric:: CLI Example:
5971     Local folder pool:
5972     .. code-block:: bash
5973         salt '*' virt.pool_define somepool dir target=/srv/mypool \
5974                                   permissions="{'mode': '0744' 'ower': 107, 'group': 107 }"
5975     CIFS backed pool:
5976     .. code-block:: bash
5977         salt '*' virt.pool_define myshare netfs source_format=cifs \
5978                                   source_dir=samba_share source_hosts="['example.com']" target=/mnt/cifs
5979     .. versionadded:: 2019.2.0
5980     """
5981     conn = __get_conn(**kwargs)
5982     auth = _pool_set_secret(conn, ptype, name, source_auth)
5983     pool_xml = _gen_pool_xml(
5984         name,
5985         ptype,
5986         target,
5987         permissions=permissions,
5988         source_devices=source_devices,
5989         source_dir=source_dir,
5990         source_adapter=source_adapter,
5991         source_hosts=source_hosts,
5992         source_auth=auth,
5993         source_name=source_name,
5994         source_format=source_format,
5995         source_initiator=source_initiator,
5996     )
5997     try:
5998         if transient:
5999             pool = conn.storagePoolCreateXML(pool_xml)
6000         else:
6001             pool = conn.storagePoolDefineXML(pool_xml)
6002             if start:
6003                 pool.create()
6004     except libvirt.libvirtError as err:
6005         raise err  # a real error we should report upwards
6006     finally:
6007         conn.close()
6008     return True
6009 def _pool_set_secret(
6010     conn, pool_type, pool_name, source_auth, uuid=None, usage=None, test=False
6011 ):
6012     secret_types = {"rbd": "ceph", "iscsi": "chap", "iscsi-direct": "chap"}
6013     secret_type = secret_types.get(pool_type)
6014     auth = source_auth
6015     if source_auth and "username" in source_auth and "password" in source_auth:
6016         if secret_type:
6017             secret = None
6018             try:
6019                 if usage:
6020                     usage_type = (
6021                         libvirt.VIR_SECRET_USAGE_TYPE_CEPH
6022                         if secret_type == "ceph"
6023                         else libvirt.VIR_SECRET_USAGE_TYPE_ISCSI
6024                     )
6025                     secret = conn.secretLookupByUsage(usage_type, usage)
6026                 elif uuid:
6027                     secret = conn.secretLookupByUUIDString(uuid)
6028             except libvirt.libvirtError as err:
6029                 log.info("Secret not found: %s", err.get_error_message())
6030             if not secret:
6031                 description = "Passphrase for {} pool created by Salt".format(pool_name)
6032                 if not usage:
6033                     usage = "pool_{}".format(pool_name)
6034                 secret_xml = _gen_secret_xml(secret_type, usage, description)
6035                 if not test:
6036                     secret = conn.secretDefineXML(secret_xml)
6037             password = auth["password"]
6038             if pool_type == "rbd":
6039                 password = base64.b64decode(salt.utils.stringutils.to_bytes(password))
6040             if not test:
6041                 secret.setValue(password)
6042             auth["type"] = secret_type
6043             auth["secret"] = {
6044                 "type": "uuid" if uuid else "usage",
6045                 "value": uuid if uuid else usage,
6046             }
6047     return auth
6048 def pool_update(
6049     name,
6050     ptype,
6051     target=None,
6052     permissions=None,
6053     source_devices=None,
6054     source_dir=None,
6055     source_initiator=None,
6056     source_adapter=None,
6057     source_hosts=None,
6058     source_auth=None,
6059     source_name=None,
6060     source_format=None,
6061     test=False,
6062     **kwargs
6063 ):
6064     """
6065     Update a libvirt storage pool if needed.
6066     If called with test=True, this is also reporting whether an update would be performed.
6067     :param name: Pool name
6068     :param ptype:
6069         Pool type. See `libvirt documentation &lt;https://libvirt.org/storage.html&gt;`_  for the
6070         possible values.
6071     :param target: Pool full path target
6072     :param permissions:
6073         Permissions to set on the target folder. This is mostly used for filesystem-based
6074         pool types. See :ref:`pool-define-permissions` for more details on this structure.
6075     :param source_devices:
6076         List of source devices for pools backed by physical devices. (Default: ``None``)
6077         Each item in the list is a dictionary with ``path`` and optionally ``part_separator``
6078         keys. The path is the qualified name for iSCSI devices.
6079         Report to `this libvirt page &lt;https://libvirt.org/formatstorage.html#StoragePool&gt;`_
6080         for more information on the use of ``part_separator``
6081     :param source_dir:
6082         Path to the source directory for pools of type ``dir``, ``netfs`` or ``gluster``.
6083         (Default: ``None``)
6084     :param source_initiator:
6085         Initiator IQN for libiscsi-direct pool types. (Default: ``None``)
6086         .. versionadded:: 3000
6087     :param source_adapter:
6088         SCSI source definition. The value is a dictionary with ``type``, ``name``, ``parent``,
6089         ``managed``, ``parent_wwnn``, ``parent_wwpn``, ``parent_fabric_wwn``, ``wwnn``, ``wwpn``
6090         and ``parent_address`` keys.
6091         The ``parent_address`` value is a dictionary with ``unique_id`` and ``address`` keys.
6092         The address represents a PCI address and is itself a dictionary with ``domain``, ``bus``,
6093         ``slot`` and ``function`` properties.
6094         Report to `this libvirt page &lt;https://libvirt.org/formatstorage.html#StoragePool&gt;`_
6095         for the meaning and possible values of these properties.
6096     :param source_hosts:
6097         List of source for pools backed by storage from remote servers. Each item is the hostname
6098         optionally followed by the port separated by a colon. (Default: ``None``)
6099     :param source_auth:
6100         Source authentication details. (Default: ``None``)
6101         The value is a dictionary with ``type``, ``username`` and ``secret`` keys. The type
6102         can be one of ``ceph`` for Ceph RBD or ``chap`` for iSCSI sources.
6103         The ``secret`` value links to a libvirt secret object. It is a dictionary with
6104         ``type`` and ``value`` keys. The type value can be either ``uuid`` or ``usage``.
6105         Examples:
6106         .. code-block:: python
6107             source_auth={
6108                 'type': 'ceph',
6109                 'username': 'admin',
6110                 'secret': {
6111                     'type': 'uuid',
6112                     'uuid': '2ec115d7-3a88-3ceb-bc12-0ac909a6fd87'
6113                 }
6114             }
6115         .. code-block:: python
6116             source_auth={
6117                 'type': 'chap',
6118                 'username': 'myname',
6119                 'secret': {
6120                     'type': 'usage',
6121                     'uuid': 'mycluster_myname'
6122                 }
6123             }
6124         Since 3000, instead the source authentication can only contain ``username``
6125         and ``password`` properties. In this case the libvirt secret will be defined and used.
6126         For Ceph authentications a base64 encoded key is expected.
6127     :param source_name:
6128         Identifier of name-based sources.
6129     :param source_format:
6130         String representing the source format. The possible values are depending on the
6131         source type. See `libvirt documentation &lt;https://libvirt.org/storage.html&gt;`_ for
6132         the possible values.
6133     :param test: run in dry-run mode if set to True
6134     :param connection: libvirt connection URI, overriding defaults
6135     :param username: username to connect with, overriding defaults
6136     :param password: password to connect with, overriding defaults
6137     .. rubric:: Example:
6138     Local folder pool:
6139     .. code-block:: bash
6140         salt '*' virt.pool_update somepool dir target=/srv/mypool \
6141                                   permissions="{'mode': '0744' 'ower': 107, 'group': 107 }"
6142     CIFS backed pool:
6143     .. code-block:: bash
6144         salt '*' virt.pool_update myshare netfs source_format=cifs \
6145                                   source_dir=samba_share source_hosts="['example.com']" target=/mnt/cifs
6146     .. versionadded:: 3000
6147     """
6148     conn = __get_conn(**kwargs)
6149     needs_update = False
6150     try:
6151         pool = conn.storagePoolLookupByName(name)
6152         old_xml = ElementTree.fromstring(pool.XMLDesc())
6153         secret_node = old_xml.find("source/auth/secret")
6154         usage = secret_node.get("usage") if secret_node is not None else None
6155         uuid = secret_node.get("uuid") if secret_node is not None else None
6156         auth = _pool_set_secret(
6157             conn, ptype, name, source_auth, uuid=uuid, usage=usage, test=test
6158         )
6159         new_xml = ElementTree.fromstring(
6160             _gen_pool_xml(
6161                 name,
6162                 ptype,
6163                 target,
6164                 permissions=permissions,
6165                 source_devices=source_devices,
6166                 source_dir=source_dir,
6167                 source_initiator=source_initiator,
6168                 source_adapter=source_adapter,
6169                 source_hosts=source_hosts,
6170                 source_auth=auth,
6171                 source_name=source_name,
6172                 source_format=source_format,
6173             )
6174         )
6175         elements_to_copy = ["available", "allocation", "capacity", "uuid"]
6176         for to_copy in elements_to_copy:
6177             element = old_xml.find(to_copy)
6178             new_xml.insert(1, element)
6179         _remove_empty_xml_node(xmlutil.strip_spaces(old_xml))
6180         xmlutil.strip_spaces(new_xml)
6181         needs_update = xmlutil.to_dict(old_xml, True) != xmlutil.to_dict(new_xml, True)
6182         if needs_update and not test:
6183             conn.storagePoolDefineXML(xmlutil.element_to_str(new_xml))
6184     finally:
6185         conn.close()
6186     return needs_update
6187 def list_pools(**kwargs):
6188     """
6189     List all storage pools.
6190     :param connection: libvirt connection URI, overriding defaults
6191     :param username: username to connect with, overriding defaults
6192     :param password: password to connect with, overriding defaults
6193     .. versionadded:: 2019.2.0
6194     CLI Example:
6195     .. code-block:: bash
6196         salt '*' virt.list_pools
6197     """
6198     conn = __get_conn(**kwargs)
6199     try:
6200         return [pool.name() for pool in conn.listAllStoragePools()]
6201     finally:
6202         conn.close()
6203 def pool_info(name=None, **kwargs):
6204     """
6205     Return information on a storage pool provided its name.
6206     :param name: libvirt storage pool name
6207     :param connection: libvirt connection URI, overriding defaults
6208     :param username: username to connect with, overriding defaults
6209     :param password: password to connect with, overriding defaults
6210     If no name is provided, return the infos for all defined storage pools.
6211     .. versionadded:: 2019.2.0
6212     CLI Example:
6213     .. code-block:: bash
6214         salt '*' virt.pool_info default
6215     """
6216     result = {}
6217     conn = __get_conn(**kwargs)
6218     def _pool_extract_infos(pool):
6219         """
6220         Format the pool info dictionary
6221         :param pool: the libvirt pool object
6222         """
6223         states = ["inactive", "building", "running", "degraded", "inaccessible"]
6224         infos = pool.info()
6225         state = states[infos[0]] if infos[0] &lt; len(states) else "unknown"
6226         desc = ElementTree.fromstring(pool.XMLDesc())
6227         path_node = desc.find("target/path")
6228         return {
6229             "uuid": pool.UUIDString(),
6230             "state": state,
6231             "capacity": infos[1],
6232             "allocation": infos[2],
6233             "free": infos[3],
6234             "autostart": pool.autostart(),
6235             "persistent": pool.isPersistent(),
6236             "target_path": path_node.text if path_node is not None else None,
6237             "type": desc.get("type"),
6238         }
6239     try:
6240         pools = [
6241             pool
6242             for pool in conn.listAllStoragePools()
6243             if name is None or pool.name() == name
6244         ]
6245         result = {pool.name(): _pool_extract_infos(pool) for pool in pools}
6246     except libvirt.libvirtError as err:
6247         log.debug("Silenced libvirt error: %s", err)
6248     finally:
6249         conn.close()
6250     return result
6251 def pool_get_xml(name, **kwargs):
6252     """
6253     Return the XML definition of a virtual storage pool
6254     :param name: libvirt storage pool name
6255     :param connection: libvirt connection URI, overriding defaults
6256     :param username: username to connect with, overriding defaults
6257     :param password: password to connect with, overriding defaults
6258     .. versionadded:: 3000
6259     CLI Example:
6260     .. code-block:: bash
6261         salt '*' virt.pool_get_xml default
6262     """
6263     conn = __get_conn(**kwargs)
6264     try:
6265         return conn.storagePoolLookupByName(name).XMLDesc()
6266     finally:
6267         conn.close()
6268 def pool_start(name, **kwargs):
6269     """
6270     Start a defined libvirt storage pool.
6271     :param name: libvirt storage pool name
6272     :param connection: libvirt connection URI, overriding defaults
6273     :param username: username to connect with, overriding defaults
6274     :param password: password to connect with, overriding defaults
6275     .. versionadded:: 2019.2.0
6276     CLI Example:
6277     .. code-block:: bash
6278         salt '*' virt.pool_start default
6279     """
6280     conn = __get_conn(**kwargs)
6281     try:
6282         pool = conn.storagePoolLookupByName(name)
6283         return not bool(pool.create())
6284     finally:
6285         conn.close()
6286 def pool_build(name, **kwargs):
6287     """
6288     Build a defined libvirt storage pool.
6289     :param name: libvirt storage pool name
6290     :param connection: libvirt connection URI, overriding defaults
6291     :param username: username to connect with, overriding defaults
6292     :param password: password to connect with, overriding defaults
6293     .. versionadded:: 2019.2.0
6294     CLI Example:
6295     .. code-block:: bash
6296         salt '*' virt.pool_build default
6297     """
6298     conn = __get_conn(**kwargs)
6299     try:
6300         pool = conn.storagePoolLookupByName(name)
6301         return not bool(pool.build())
6302     finally:
6303         conn.close()
6304 def pool_stop(name, **kwargs):
6305     """
6306     Stop a defined libvirt storage pool.
6307     :param name: libvirt storage pool name
6308     :param connection: libvirt connection URI, overriding defaults
6309     :param username: username to connect with, overriding defaults
6310     :param password: password to connect with, overriding defaults
6311     .. versionadded:: 2019.2.0
6312     CLI Example:
6313     .. code-block:: bash
6314         salt '*' virt.pool_stop default
6315     """
6316     conn = __get_conn(**kwargs)
6317     try:
6318         pool = conn.storagePoolLookupByName(name)
6319         return not bool(pool.destroy())
6320     finally:
6321         conn.close()
6322 def pool_undefine(name, **kwargs):
6323     """
6324     Remove a defined libvirt storage pool. The pool needs to be stopped before calling.
6325     :param name: libvirt storage pool name
6326     :param connection: libvirt connection URI, overriding defaults
6327     :param username: username to connect with, overriding defaults
6328     :param password: password to connect with, overriding defaults
6329     .. versionadded:: 2019.2.0
6330     CLI Example:
6331     .. code-block:: bash
6332         salt '*' virt.pool_undefine default
6333     """
6334     conn = __get_conn(**kwargs)
6335     try:
6336         pool = conn.storagePoolLookupByName(name)
6337         desc = ElementTree.fromstring(pool.XMLDesc())
6338         auth_node = desc.find("source/auth")
6339         if auth_node is not None:
6340             auth_types = {
6341                 "ceph": libvirt.VIR_SECRET_USAGE_TYPE_CEPH,
6342                 "iscsi": libvirt.VIR_SECRET_USAGE_TYPE_ISCSI,
6343             }
6344             secret_type = auth_types[auth_node.get("type")]
6345             secret_usage = auth_node.find("secret").get("usage")
6346             if secret_type and "pool_{}".format(name) == secret_usage:
6347                 secret = conn.secretLookupByUsage(secret_type, secret_usage)
6348                 secret.undefine()
6349         return not bool(pool.undefine())
6350     finally:
6351         conn.close()
6352 def pool_delete(name, **kwargs):
6353     """
6354     Delete the resources of a defined libvirt storage pool.
6355     :param name: libvirt storage pool name
6356     :param connection: libvirt connection URI, overriding defaults
6357     :param username: username to connect with, overriding defaults
6358     :param password: password to connect with, overriding defaults
6359     .. versionadded:: 2019.2.0
6360     CLI Example:
6361     .. code-block:: bash
6362         salt '*' virt.pool_delete default
6363     """
6364     conn = __get_conn(**kwargs)
6365     try:
6366         pool = conn.storagePoolLookupByName(name)
6367         return not bool(pool.delete(libvirt.VIR_STORAGE_POOL_DELETE_NORMAL))
6368     finally:
6369         conn.close()
6370 def pool_refresh(name, **kwargs):
6371     """
6372     Refresh a defined libvirt storage pool.
6373     :param name: libvirt storage pool name
6374     :param connection: libvirt connection URI, overriding defaults
6375     :param username: username to connect with, overriding defaults
6376     :param password: password to connect with, overriding defaults
6377     .. versionadded:: 2019.2.0
6378     CLI Example:
6379     .. code-block:: bash
6380         salt '*' virt.pool_refresh default
6381     """
6382     conn = __get_conn(**kwargs)
6383     try:
6384         pool = conn.storagePoolLookupByName(name)
6385         return not bool(pool.refresh())
6386     finally:
6387         conn.close()
6388 def pool_set_autostart(name, state="on", **kwargs):
6389     """
6390     Set the autostart flag on a libvirt storage pool so that the storage pool
6391     will start with the host system on reboot.
6392     :param name: libvirt storage pool name
6393     :param state: 'on' to auto start the pool, anything else to mark the
6394                   pool not to be started when the host boots
6395     :param connection: libvirt connection URI, overriding defaults
6396     :param username: username to connect with, overriding defaults
6397     :param password: password to connect with, overriding defaults
6398     .. versionadded:: 2019.2.0
6399     CLI Example:
6400     .. code-block:: bash
6401         salt "*" virt.pool_set_autostart &lt;pool&gt; &lt;on | off&gt;
6402     """
6403     conn = __get_conn(**kwargs)
6404     try:
6405         pool = conn.storagePoolLookupByName(name)
6406         return not bool(pool.setAutostart(1 if state == "on" else 0))
6407     finally:
6408         conn.close()
6409 def pool_list_volumes(name, **kwargs):
6410     """
6411     List the volumes contained in a defined libvirt storage pool.
6412     :param name: libvirt storage pool name
6413     :param connection: libvirt connection URI, overriding defaults
6414     :param username: username to connect with, overriding defaults
6415     :param password: password to connect with, overriding defaults
6416     .. versionadded:: 2019.2.0
6417     CLI Example:
6418     .. code-block:: bash
6419         salt "*" virt.pool_list_volumes &lt;pool&gt;
6420     """
6421     conn = __get_conn(**kwargs)
6422     try:
6423         pool = conn.storagePoolLookupByName(name)
6424         return pool.listVolumes()
6425     finally:
6426         conn.close()
6427 def _get_storage_vol(conn, pool, vol):
6428     """
6429     Helper function getting a storage volume. Will throw a libvirtError
6430     if the pool or the volume couldn't be found.
6431     :param conn: libvirt connection object to use
6432     :param pool: pool name
6433     :param vol: volume name
6434     """
6435     pool_obj = conn.storagePoolLookupByName(pool)
6436     return pool_obj.storageVolLookupByName(vol)
6437 def _is_valid_volume(vol):
6438     """
6439     Checks whether a volume is valid for further use since those may have disappeared since
6440     the last pool refresh.
6441     """
6442     try:
6443         def discarder(ctxt, error):  # pylint: disable=unused-argument
6444             log.debug("Ignore libvirt error: %s", error[2])
6445         libvirt.registerErrorHandler(discarder, None)
6446         vol.info()
6447         libvirt.registerErrorHandler(None, None)
6448         return True
6449     except libvirt.libvirtError as err:
6450         return False
6451 def _get_all_volumes_paths(conn):
6452     """
6453     Extract the path, name, pool name and backing stores path of all volumes.
6454     :param conn: libvirt connection to use
6455     """
6456     pools = [
6457         pool
6458         for pool in conn.listAllStoragePools()
6459         if pool.info()[0] == libvirt.VIR_STORAGE_POOL_RUNNING
6460     ]
6461     volumes = {}
6462     for pool in pools:
6463         pool_volumes = {
6464             volume.path(): {
6465                 "pool": pool.name(),
6466                 "name": volume.name(),
6467                 "backing_stores": [
6468                     path.text
6469                     for path in ElementTree.fromstring(volume.XMLDesc()).findall(
6470                         ".//backingStore/path"
6471                     )
6472                 ],
6473             }
6474             for volume in pool.listAllVolumes()
6475             if _is_valid_volume(volume)
6476         }
6477         volumes.update(pool_volumes)
6478     return volumes
6479 def volume_infos(pool=None, volume=None, **kwargs):
6480     """
6481     Provide details on a storage volume. If no volume name is provided, the infos
6482     all the volumes contained in the pool are provided. If no pool is provided,
6483     the infos of the volumes of all pools are output.
6484     :param pool: libvirt storage pool name (default: ``None``)
6485     :param volume: name of the volume to get infos from (default: ``None``)
6486     :param connection: libvirt connection URI, overriding defaults
6487     :param username: username to connect with, overriding defaults
6488     :param password: password to connect with, overriding defaults
6489     .. versionadded:: 3000
6490     CLI Example:
6491     .. code-block:: bash
6492         salt "*" virt.volume_infos &lt;pool&gt; &lt;volume&gt;
6493     """
6494     result = {}
6495     conn = __get_conn(**kwargs)
6496     try:
6497         backing_stores = _get_all_volumes_paths(conn)
6498         try:
6499             domains = _get_domain(conn)
6500             domains_list = domains if isinstance(domains, list) else [domains]
6501         except CommandExecutionError:
6502             domains_list = []
6503         disks = {
6504             domain.name(): {
6505                 node.get("file")
6506                 for node in ElementTree.fromstring(domain.XMLDesc(0)).findall(
6507                     ".//disk/source/[@file]"
6508                 )
6509             }
6510             for domain in domains_list
6511         }
6512         def _volume_extract_infos(vol):
6513             """
6514             Format the volume info dictionary
6515             :param vol: the libvirt storage volume object.
6516             """
6517             types = ["file", "block", "dir", "network", "netdir", "ploop"]
6518             infos = vol.info()
6519             vol_xml = ElementTree.fromstring(vol.XMLDesc())
6520             backing_store_path = vol_xml.find("./backingStore/path")
6521             backing_store_format = vol_xml.find("./backingStore/format")
6522             backing_store = None
6523             if backing_store_path is not None:
6524                 backing_store = {
6525                     "path": backing_store_path.text,
6526                     "format": backing_store_format.get("type")
6527                     if backing_store_format is not None
6528                     else None,
6529                 }
6530             format_node = vol_xml.find("./target/format")
6531             used_by = []
6532             if vol.path():
6533                 as_backing_store = {
6534                     path
6535                     for (path, volume) in backing_stores.items()
6536                     if vol.path() in volume.get("backing_stores")
6537                 }
6538                 used_by = [
6539                     vm_name
6540                     for (vm_name, vm_disks) in disks.items()
6541                     if vm_disks &amp; as_backing_store or vol.path() in vm_disks
6542                 ]
6543             return {
6544                 "type": types[infos[0]] if infos[0] &lt; len(types) else "unknown",
6545                 "key": vol.key(),
6546                 "path": vol.path(),
6547                 "capacity": infos[1],
6548                 "allocation": infos[2],
6549                 "used_by": used_by,
6550                 "backing_store": backing_store,
6551                 "format": format_node.get("type") if format_node is not None else None,
6552             }
6553         pools = [
6554             obj
6555             for obj in conn.listAllStoragePools()
6556             if (pool is None or obj.name() == pool)
6557             and obj.info()[0] == libvirt.VIR_STORAGE_POOL_RUNNING
6558         ]
6559         vols = {
6560             pool_obj.name(): {
6561                 vol.name(): _volume_extract_infos(vol)
6562                 for vol in pool_obj.listAllVolumes()
6563                 if (volume is None or vol.name() == volume) and _is_valid_volume(vol)
6564             }
6565             for pool_obj in pools
6566         }
6567         return {pool_name: volumes for (pool_name, volumes) in vols.items() if volumes}
6568     except libvirt.libvirtError as err:
6569         log.debug("Silenced libvirt error: %s", err)
6570     finally:
6571         conn.close()
6572     return result
6573 def volume_delete(pool, volume, **kwargs):
6574     """
6575     Delete a libvirt managed volume.
6576     :param pool: libvirt storage pool name
6577     :param volume: name of the volume to delete
6578     :param connection: libvirt connection URI, overriding defaults
6579     :param username: username to connect with, overriding defaults
6580     :param password: password to connect with, overriding defaults
6581     .. versionadded:: 3000
6582     CLI Example:
6583     .. code-block:: bash
6584         salt "*" virt.volume_delete &lt;pool&gt; &lt;volume&gt;
6585     """
6586     conn = __get_conn(**kwargs)
6587     try:
6588         vol = _get_storage_vol(conn, pool, volume)
6589         return not bool(vol.delete())
6590     finally:
6591         conn.close()
6592 def volume_define(
6593     pool,
6594     name,
6595     size,
6596     allocation=0,
6597     format=None,
6598     type=None,
6599     permissions=None,
6600     backing_store=None,
6601     nocow=False,
6602     **kwargs
6603 ):
6604     """
6605     Create libvirt volume.
6606     :param pool: name of the pool to create the volume in
6607     :param name: name of the volume to define
6608     :param size: capacity of the volume to define in MiB
6609     :param allocation: allocated size of the volume in MiB. Defaults to 0.
6610     :param format:
6611         volume format. The allowed values are depending on the pool type.
6612         Check the virt.pool_capabilities output for the possible values and the default.
6613     :param type:
6614         type of the volume. One of file, block, dir, network, netdiri, ploop or None.
6615         By default, the type is guessed by libvirt from the pool type.
6616     :param permissions:
6617         Permissions to set on the target folder. This is mostly used for filesystem-based
6618         pool types. See :ref:`pool-define-permissions` for more details on this structure.
6619     :param backing_store:
6620         dictionary describing a backing file for the volume. It must contain a ``path``
6621         property pointing to the base volume and a ``format`` property defining the format
6622         of the base volume.
6623         The base volume format will not be guessed for security reasons and is thus mandatory.
6624     :param nocow: disable COW for the volume.
6625     :param connection: libvirt connection URI, overriding defaults
6626     :param username: username to connect with, overriding defaults
6627     :param password: password to connect with, overriding defaults
6628     .. rubric:: CLI Example:
6629     Volume on ESX:
6630     .. code-block:: bash
6631         salt '*' virt.volume_define "[local-storage]" myvm/myvm.vmdk vmdk 8192
6632     QCow2 volume with backing file:
6633     .. code-block:: bash
6634         salt '*' virt.volume_define default myvm.qcow2 qcow2 8192 \
6635                             permissions="{'mode': '0775', 'owner': '123', 'group': '345'"}" \
6636                             backing_store="{'path': '/path/to/base.img', 'format': 'raw'}" \
6637                             nocow=True
6638     .. versionadded:: 3001
6639     """
6640     ret = False
6641     try:
6642         conn = __get_conn(**kwargs)
6643         pool_obj = conn.storagePoolLookupByName(pool)
6644         pool_type = ElementTree.fromstring(pool_obj.XMLDesc()).get("type")
6645         new_allocation = allocation
6646         if pool_type == "logical" and size != allocation:
6647             new_allocation = size
6648         xml = _gen_vol_xml(
6649             name,
6650             size,
6651             format=format,
6652             allocation=new_allocation,
6653             type=type,
6654             permissions=permissions,
6655             backing_store=backing_store,
6656             nocow=nocow,
6657         )
6658         ret = _define_vol_xml_str(conn, xml, pool=pool)
6659     except libvirt.libvirtError as err:
6660         raise CommandExecutionError(err.get_error_message())
6661     finally:
6662         conn.close()
6663     return ret
6664 def _volume_upload(conn, pool, volume, file, offset=0, length=0, sparse=False):
6665     """
6666     Function performing the heavy duty for volume_upload but using an already
6667     opened libvirt connection.
6668     """
6669     def handler(stream, nbytes, opaque):
6670         return os.read(opaque, nbytes)
6671     def holeHandler(stream, opaque):
6672         """
6673         Taken from the sparsestream.py libvirt-python example.
6674         """
6675         fd = opaque
6676         cur = os.lseek(fd, 0, os.SEEK_CUR)
6677         try:
6678             data = os.lseek(fd, cur, os.SEEK_DATA)
6679         except OSError as e:
6680             if e.errno != 6:
6681                 raise e
6682             else:
6683                 data = -1
6684         if data &lt; 0:
6685             inData = False
6686             eof = os.lseek(fd, 0, os.SEEK_END)
6687             if eof &lt; cur:
6688                 raise RuntimeError("Current position in file after EOF: {}".format(cur))
6689             sectionLen = eof - cur
6690         else:
6691             if data &gt; cur:
6692                 inData = False
6693                 sectionLen = data - cur
6694             else:
6695                 inData = True
6696                 hole = os.lseek(fd, data, os.SEEK_HOLE)
6697                 if hole &lt; 0:
6698                     raise RuntimeError("No trailing hole")
6699                 if hole == data:
6700                     raise RuntimeError("Impossible happened")
6701                 else:
6702                     sectionLen = hole - data
6703         os.lseek(fd, cur, os.SEEK_SET)
6704         return [inData, sectionLen]
6705     def skipHandler(stream, length, opaque):
6706         return os.lseek(opaque, length, os.SEEK_CUR)
6707     stream = None
6708     fd = None
6709     ret = False
6710     try:
6711         pool_obj = conn.storagePoolLookupByName(pool)
6712         vol_obj = pool_obj.storageVolLookupByName(volume)
6713         stream = conn.newStream()
6714         fd = os.open(file, os.O_RDONLY)
6715         vol_obj.upload(
6716             stream,
6717             offset,
6718             length,
6719             libvirt.VIR_STORAGE_VOL_UPLOAD_SPARSE_STREAM if sparse else 0,
6720         )
6721         if sparse:
6722             stream.sparseSendAll(handler, holeHandler, skipHandler, fd)
6723         else:
6724             stream.sendAll(handler, fd)
6725         ret = True
6726     except libvirt.libvirtError as err:
6727         raise CommandExecutionError(err.get_error_message())
6728     finally:
6729         if fd:
6730             try:
6731                 os.close(fd)
6732             except OSError as err:
6733                 if stream:
6734                     stream.abort()
6735                 if ret:
6736                     raise CommandExecutionError(
6737                         "Failed to close file: {}".format(err.strerror)
6738                     )
6739         if stream:
6740             try:
6741                 stream.finish()
6742             except libvirt.libvirtError as err:
6743                 if ret:
6744                     raise CommandExecutionError(
6745                         "Failed to finish stream: {}".format(err.get_error_message())
6746                     )
6747     return ret
6748 def volume_upload(pool, volume, file, offset=0, length=0, sparse=False, **kwargs):
6749     """
6750     Create libvirt volume.
6751     :param pool: name of the pool to create the volume in
6752     :param name: name of the volume to define
6753     :param file: the file to upload to the volume
6754     :param offset: where to start writing the data in the volume
6755     :param length: amount of bytes to transfer to the volume
6756     :param sparse: set to True to preserve data sparsiness.
6757     :param connection: libvirt connection URI, overriding defaults
6758     :param username: username to connect with, overriding defaults
6759     :param password: password to connect with, overriding defaults
6760     .. rubric:: CLI Example:
6761     .. code-block:: bash
6762         salt '*' virt.volume_upload default myvm.qcow2 /path/to/disk.qcow2
6763     .. versionadded:: 3001
6764     """
6765     conn = __get_conn(**kwargs)
6766     ret = False
6767     try:
6768         ret = _volume_upload(
6769             conn, pool, volume, file, offset=offset, length=length, sparse=sparse
6770         )
6771     finally:
6772         conn.close()
6773     return ret
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
