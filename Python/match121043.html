<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for test_mysql_2.py &amp; virt_1.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for test_mysql_2.py &amp; virt_1.py
      </h3>
<h1 align="center">
        2.8%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>test_mysql_2.py (11.025641%)<th>virt_1.py (1.663014%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(50-145)<td><a href="#" name="0">(7723-7809)</a><td align="center"><font color="#ff0000">20</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(691-695)<td><a href="#" name="1">(5691-5693)</a><td align="center"><font color="#cc0000">16</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(715-719)<td><a href="#" name="2">(6511-6521)</a><td align="center"><font color="#bf0000">15</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(703-707)<td><a href="#" name="3">(3110-3114)</a><td align="center"><font color="#b20000">14</font>
<tr onclick='openModal("#6cc417")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#6cc417"><font color="#6cc417">-</font><td><a href="#" name="4">(179-227)<td><a href="#" name="4">(3984-4002)</a><td align="center"><font color="#b20000">14</font>
<tr onclick='openModal("#151b8d")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#151b8d"><font color="#151b8d">-</font><td><a href="#" name="5">(785-788)<td><a href="#" name="5">(7820-7829)</a><td align="center"><font color="#a50000">13</font>
<tr onclick='openModal("#8c8774")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#8c8774"><font color="#8c8774">-</font><td><a href="#" name="6">(31-42)<td><a href="#" name="6">(1931-1940)</a><td align="center"><font color="#a50000">13</font>
<tr onclick='openModal("#38a4a5")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#38a4a5"><font color="#38a4a5">-</font><td><a href="#" name="7">(556-560)<td><a href="#" name="7">(6497-6505)</a><td align="center"><font color="#990000">12</font>
<tr onclick='openModal("#c58917")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#c58917"><font color="#c58917">-</font><td><a href="#" name="8">(519-522)<td><a href="#" name="8">(4487-4492)</a><td align="center"><font color="#990000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_mysql_2.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import salt.pillar.mysql as mysql
2 from tests.support.unit import TestCase, skipIf
3 @skipIf(mysql.MySQLdb is None, "MySQL-python module not installed")
4 class MysqlPillarTestCase(TestCase):
5     maxDiff = None
6     def test_001_extract_queries_legacy(self):
7         return_data = mysql.MySQLExtPillar()
8         args, kwargs = ["SELECT blah"], {}
9         qbuffer = return_data.extract_queries(args, kwargs)
10         self.assertEqual(
11             [
12                 [
13                     None,
14                     {
15                         "query": "SELECT blah",
16                         "depth": 0,
17                         "as_list": False,
18                         "as_json": False,
19                         "with_lists": None,
20                         "ignore_null": False,
21                     },
22                 ]
23             ],
24             qbuffer,
25 <a name="6"></a>        )
26     def test_002_extract_queries_list(self):
27         return_data <font color="#8c8774"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>= mysql.MySQLExtPillar()
28         args, kwargs = (
29             [
30                 "SELECT blah",
31                 "SELECT blah2",
32                 ("SELECT blah3",),
33                 ("SELECT blah4", 2),
34                 {"query": "SELECT blah5"},
35                 {"query": "SELECT blah6", "depth": 2},
36                 {"query": "SELECT blah7", "as_list": True},
37                 {"query": "SELECT blah8", "with_lists": "1"},
38                 {"query"</b></font>: "SELECT blah9", "with_lists": "1,2"},
39                 {"query": "SELECT json1", "as_json": True},
40             ],
41             {},
42         )
43 <a name="0"></a>        qbuffer = return_data.extract_queries(args, kwargs)
44         self.assertEqual(
45             [
46                 <font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>[
47                     None,
48                     {
49                         "query": "SELECT blah",
50                         "depth": 0,
51                         "as_list": False,
52                         "as_json": False,
53                         "with_lists": None,
54                         "ignore_null": False,
55                     },
56                 ],
57                 [
58                     None,
59                     {
60                         "query": "SELECT blah2",
61                         "depth": 0,
62                         "as_list": False,
63                         "as_json": False,
64                         "with_lists": None,
65                         "ignore_null": False,
66                     },
67                 ],
68                 [
69                     None,
70                     {
71                         "query": "SELECT blah3",
72                         "depth": 0,
73                         "as_list": False,
74                         "as_json": False,
75                         "with_lists": None,
76                         "ignore_null": False,
77                     },
78                 ],
79                 [
80                     None,
81                     {
82                         "query": "SELECT blah4",
83                         "depth": 2,
84                         "as_list": False,
85                         "as_json": False,
86                         "with_lists": None,
87                         "ignore_null": False,
88                     },
89                 ],
90                 [
91                     None,
92                     {
93                         "query": "SELECT blah5",
94                         "depth": 0,
95                         "as_list": False,
96                         "as_json": False,
97                         "with_lists": None,
98                         "ignore_null": False,
99                     },
100                 ],
101                 [
102                     None,
103                     {
104                         "query": "SELECT blah6",
105                         "depth": 2,
106                         "as_list": False,
107                         "as_json": False,
108                         "with_lists": None,
109                         "ignore_null": False,
110                     },
111                 ],
112                 [
113                     None,
114                     {
115                         "query": "SELECT blah7",
116                         "depth": 0,
117                         "as_list": True,
118                         "as_json": False,
119                         "with_lists": None,
120                         "ignore_null": False,
121                     },
122                 ],
123                 [
124                     None,
125                     {
126                         "query": "SELECT blah8",
127                         "depth": 0,
128                         "as_list": False,
129                         "as_json": False,
130                         "with_lists": [1],
131                         "ignore_null": False,
132                     },
133                 ],
134                 [
135                     None,
136                     {
137                         "query": "SELECT blah9",
138                         "depth": 0,
139                         "as_list": False,
140                         "as_json": False,
141                         "with_lists": [1</b></font>, 2],
142                         "ignore_null": False,
143                     },
144                 ],
145                 [
146                     None,
147                     {
148                         "query": "SELECT json1",
149                         "depth": 0,
150                         "as_list": False,
151                         "as_json": True,
152                         "with_lists": None,
153                         "ignore_null": False,
154                     },
155                 ],
156             ],
157             qbuffer,
158         )
159     def test_003_extract_queries_kwarg(self):
160         return_data = mysql.MySQLExtPillar()
161         args, kwargs = (
162             [],
163             {
164                 "1": "SELECT blah",
165                 "2": "SELECT blah2",
166                 "3": ("SELECT blah3",),
167                 "4": ("SELECT blah4", 2),
168                 "5": {"query": "SELECT blah5"},
169                 "6": {"query": "SELECT blah6", "depth": 2},
170                 "7": {"query": "SELECT blah7", "as_list": True},
171 <a name="4"></a>                "8": {"query": "SELECT json1", "as_json": True},
172             },
173         )
174         qbuffer = return_data<font color="#6cc417"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.extract_queries(args, kwargs)
175         self.assertEqual(
176             [
177                 [
178                     "1",
179                     {
180                         "query": "SELECT blah",
181                         "depth": 0,
182                         "as_list": False,
183                         "as_json": False,
184                         "with_lists": None,
185                         "ignore_null": False,
186                     },
187                 ],
188                 [
189                     "2",
190                     {
191                         "query": "SELECT blah2",
192                         "depth": 0,
193                         "as_list": False,
194                         "as_json": False,
195                         "with_lists": None,
196                         "ignore_null": False,
197                     },
198                 ],
199                 [
200                     "3",
201                     {
202                         "query": "SELECT blah3",
203                         "depth": 0,
204                         "as_list": False,
205                         "as_json": False,
206                         "with_lists": None,
207                         "ignore_null": False,
208                     },
209                 ],
210                 [
211                     "4",
212                     {
213                         "query": "SELECT blah4",
214                         "depth": 2,
215                         "as_list": False,
216                         "as_json": False,
217                         "with_lists": None,
218                         "ignore_null": False,
219                     },
220                 ],
221                 [
222                     "5"</b></font>,
223                     {
224                         "query": "SELECT blah5",
225                         "depth": 0,
226                         "as_list": False,
227                         "as_json": False,
228                         "with_lists": None,
229                         "ignore_null": False,
230                     },
231                 ],
232                 [
233                     "6",
234                     {
235                         "query": "SELECT blah6",
236                         "depth": 2,
237                         "as_list": False,
238                         "as_json": False,
239                         "with_lists": None,
240                         "ignore_null": False,
241                     },
242                 ],
243                 [
244                     "7",
245                     {
246                         "query": "SELECT blah7",
247                         "depth": 0,
248                         "as_list": True,
249                         "as_json": False,
250                         "with_lists": None,
251                         "ignore_null": False,
252                     },
253                 ],
254                 [
255                     "8",
256                     {
257                         "query": "SELECT json1",
258                         "depth": 0,
259                         "as_list": False,
260                         "as_json": True,
261                         "with_lists": None,
262                         "ignore_null": False,
263                     },
264                 ],
265             ],
266             qbuffer,
267         )
268     def test_004_extract_queries_mixed(self):
269         return_data = mysql.MySQLExtPillar()
270         args, kwargs = (
271             [
272                 "SELECT blah1",
273                 ("SELECT blah2", 2),
274                 {"query": "SELECT blah3", "as_list": True},
275             ],
276             {
277                 "1": "SELECT blah1",
278                 "2": ("SELECT blah2", 2),
279                 "3": {"query": "SELECT blah3", "as_list": True},
280             },
281         )
282         qbuffer = return_data.extract_queries(args, kwargs)
283         self.assertEqual(
284             [
285                 [
286                     None,
287                     {
288                         "query": "SELECT blah1",
289                         "depth": 0,
290                         "as_list": False,
291                         "as_json": False,
292                         "with_lists": None,
293                         "ignore_null": False,
294                     },
295                 ],
296                 [
297                     None,
298                     {
299                         "query": "SELECT blah2",
300                         "depth": 2,
301                         "as_list": False,
302                         "as_json": False,
303                         "with_lists": None,
304                         "ignore_null": False,
305                     },
306                 ],
307                 [
308                     None,
309                     {
310                         "query": "SELECT blah3",
311                         "depth": 0,
312                         "as_list": True,
313                         "as_json": False,
314                         "with_lists": None,
315                         "ignore_null": False,
316                     },
317                 ],
318                 [
319                     "1",
320                     {
321                         "query": "SELECT blah1",
322                         "depth": 0,
323                         "as_list": False,
324                         "as_json": False,
325                         "with_lists": None,
326                         "ignore_null": False,
327                     },
328                 ],
329                 [
330                     "2",
331                     {
332                         "query": "SELECT blah2",
333                         "depth": 2,
334                         "as_list": False,
335                         "as_json": False,
336                         "with_lists": None,
337                         "ignore_null": False,
338                     },
339                 ],
340                 [
341                     "3",
342                     {
343                         "query": "SELECT blah3",
344                         "depth": 0,
345                         "as_list": True,
346                         "as_json": False,
347                         "with_lists": None,
348                         "ignore_null": False,
349                     },
350                 ],
351             ],
352             qbuffer,
353         )
354     def test_005_extract_queries_bogus_list(self):
355         return_data = mysql.MySQLExtPillar()
356         args, kwargs = (
357             [
358                 "SELECT blah",
359                 "",
360                 "SELECT blah2",
361                 ("SELECT blah3",),
362                 ("",),
363                 ("SELECT blah4", 2),
364                 tuple(),
365                 ("SELECT blah5",),
366                 {"query": "SELECT blah6"},
367                 {"query": ""},
368                 {"query": "SELECT blah7", "depth": 2},
369                 {"not_a_query": "in sight!"},
370                 {"query": "SELECT blah8", "as_list": True},
371             ],
372             {},
373         )
374         qbuffer = return_data.extract_queries(args, kwargs)
375         self.assertEqual(
376             [
377                 [
378                     None,
379                     {
380                         "query": "SELECT blah",
381                         "depth": 0,
382                         "as_list": False,
383                         "as_json": False,
384                         "with_lists": None,
385                         "ignore_null": False,
386                     },
387                 ],
388                 [
389                     None,
390                     {
391                         "query": "SELECT blah2",
392                         "depth": 0,
393                         "as_list": False,
394                         "as_json": False,
395                         "with_lists": None,
396                         "ignore_null": False,
397                     },
398                 ],
399                 [
400                     None,
401                     {
402                         "query": "SELECT blah3",
403                         "depth": 0,
404                         "as_list": False,
405                         "as_json": False,
406                         "with_lists": None,
407                         "ignore_null": False,
408                     },
409                 ],
410                 [
411                     None,
412                     {
413                         "query": "SELECT blah4",
414                         "depth": 2,
415                         "as_list": False,
416                         "as_json": False,
417                         "with_lists": None,
418                         "ignore_null": False,
419                     },
420                 ],
421                 [
422                     None,
423                     {
424                         "query": "SELECT blah5",
425                         "depth": 0,
426                         "as_list": False,
427                         "as_json": False,
428                         "with_lists": None,
429                         "ignore_null": False,
430                     },
431                 ],
432                 [
433                     None,
434                     {
435                         "query": "SELECT blah6",
436                         "depth": 0,
437                         "as_list": False,
438                         "as_json": False,
439                         "with_lists": None,
440                         "ignore_null": False,
441                     },
442                 ],
443                 [
444                     None,
445                     {
446                         "query": "SELECT blah7",
447                         "depth": 2,
448                         "as_list": False,
449                         "as_json": False,
450                         "with_lists": None,
451                         "ignore_null": False,
452                     },
453                 ],
454                 [
455                     None,
456                     {
457                         "query": "SELECT blah8",
458                         "depth": 0,
459                         "as_list": True,
460                         "as_json": False,
461                         "with_lists": None,
462                         "ignore_null": False,
463                     },
464                 ],
465             ],
466             qbuffer,
467         )
468     def test_006_extract_queries_bogus_kwargs(self):
469         return_data = mysql.MySQLExtPillar()
470         args, kwargs = [], {"1": "SELECT blah", "2": "", "3": "SELECT blah2"}
471         qbuffer = return_data.extract_queries(args, kwargs)
472         self.assertEqual(
473             [
474                 [
475                     "1",
476                     {
477                         "query": "SELECT blah",
478                         "depth": 0,
479                         "as_list": False,
480                         "as_json": False,
481                         "with_lists": None,
482                         "ignore_null": False,
483                     },
484                 ],
485                 [
486                     "3",
487                     {
488                         "query": "SELECT blah2",
489                         "depth": 0,
490                         "as_list": False,
491                         "as_json": False,
492                         "with_lists": None,
493                         "ignore_null": False,
494                     },
495                 ],
496             ],
497             qbuffer,
498         )
499     def test_011_enter_root(self):
500         return_data = mysql.MySQLExtPillar()
501         return_data.enter_root("test")
502         self.assertEqual(return_data.result["test"], return_data.focus)
503         return_data.enter_root(None)
504         self.assertEqual(return_data.result, return_data.focus)
505 <a name="8"></a>
506     def test_021_process_fields(self):
507         return_data = mysql.MySQLExtPillar()
508         return_data<font color="#c58917"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.process_fields(["a", "b"], 0)
509         self.assertEqual(return_data.num_fields, 2)
510         self.assertEqual(return_data.depth, 1)
511         return_data.process_fields(["a"</b></font>, "b"], 2)
512         self.assertEqual(return_data.num_fields, 2)
513         self.assertEqual(return_data.depth, 1)
514         return_data.process_fields(["a", "b", "c", "d"], 0)
515         self.assertEqual(return_data.num_fields, 4)
516         self.assertEqual(return_data.depth, 3)
517         return_data.process_fields(["a", "b", "c", "d"], 1)
518         self.assertEqual(return_data.num_fields, 4)
519         self.assertEqual(return_data.depth, 1)
520         return_data.process_fields(["a", "b", "c", "d"], 2)
521         self.assertEqual(return_data.num_fields, 4)
522         self.assertEqual(return_data.depth, 2)
523         return_data.process_fields(["a", "b", "c", "d"], 3)
524         self.assertEqual(return_data.num_fields, 4)
525         self.assertEqual(return_data.depth, 3)
526         return_data.process_fields(["a", "b", "c", "d"], 4)
527         self.assertEqual(return_data.num_fields, 4)
528         self.assertEqual(return_data.depth, 3)
529     def test_111_process_results_legacy(self):
530         return_data = mysql.MySQLExtPillar()
531         return_data.process_fields(["a", "b"], 0)
532         return_data.with_lists = []
533         return_data.process_results([[1, 2]])
534         self.assertEqual({1: 2}, return_data.result)
535     def test_112_process_results_legacy_multiple(self):
536         return_data = mysql.MySQLExtPillar()
537         return_data.process_fields(["a", "b"], 0)
538         return_data.with_lists = []
539         return_data.process_results([[1, 2], [3, 4], [5, 6]])
540 <a name="7"></a>        self.assertEqual({1: 2, 3: 4, 5: 6}, return_data.result)
541     def test_121_process_results_depth_0(self):
542         return_data <font color="#38a4a5"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>= mysql.MySQLExtPillar()
543         return_data.process_fields(["a", "b", "c", "d"], 0)
544         return_data.with_lists = []
545         return_data.enter_root(None)
546         return_data.process_results(</b></font>[[1, 2, 3, 4], [5, 6, 7, 8]])
547         self.assertEqual({1: {2: {3: 4}}, 5: {6: {7: 8}}}, return_data.result)
548     def test_122_process_results_depth_1(self):
549         return_data = mysql.MySQLExtPillar()
550         return_data.process_fields(["a", "b", "c", "d"], 1)
551         return_data.with_lists = []
552         return_data.enter_root(None)
553         return_data.process_results([[1, 2, 3, 4], [5, 6, 7, 8]])
554         self.assertEqual(
555             {1: {"b": 2, "c": 3, "d": 4}, 5: {"b": 6, "c": 7, "d": 8}},
556             return_data.result,
557         )
558     def test_123_process_results_depth_2(self):
559         return_data = mysql.MySQLExtPillar()
560         return_data.process_fields(["a", "b", "c", "d"], 2)
561         return_data.with_lists = []
562         return_data.enter_root(None)
563         return_data.process_results([[1, 2, 3, 4], [5, 6, 7, 8]])
564         self.assertEqual(
565             {1: {2: {"c": 3, "d": 4}}, 5: {6: {"c": 7, "d": 8}}}, return_data.result
566         )
567     def test_124_process_results_depth_3(self):
568         return_data = mysql.MySQLExtPillar()
569         return_data.process_fields(["a", "b", "c", "d"], 3)
570         return_data.with_lists = []
571         return_data.enter_root(None)
572         return_data.process_results([[1, 2, 3, 4], [5, 6, 7, 8]])
573         self.assertEqual({1: {2: {3: 4}}, 5: {6: {7: 8}}}, return_data.result)
574     def test_125_process_results_depth_4(self):
575         return_data = mysql.MySQLExtPillar()
576         return_data.process_fields(["a", "b", "c", "d"], 4)
577         return_data.with_lists = []
578         return_data.enter_root(None)
579         return_data.process_results([[1, 2, 3, 4], [5, 6, 7, 8]])
580         self.assertEqual({1: {2: {3: 4}}, 5: {6: {7: 8}}}, return_data.result)
581     def test_131_process_results_overwrite_legacy_multiple(self):
582         return_data = mysql.MySQLExtPillar()
583         return_data.process_fields(["a", "b"], 0)
584         return_data.with_lists = []
585         return_data.process_results([[1, 2], [3, 4], [1, 6]])
586         self.assertEqual({1: 6, 3: 4}, return_data.result)
587     def test_132_process_results_merge_depth_0(self):
588         return_data = mysql.MySQLExtPillar()
589         return_data.process_fields(["a", "b", "c", "d"], 0)
590         return_data.with_lists = []
591         return_data.enter_root(None)
592         return_data.process_results([[1, 2, 3, 4], [1, 6, 7, 8]])
593         self.assertEqual({1: {2: {3: 4}, 6: {7: 8}}}, return_data.result)
594     def test_133_process_results_overwrite_depth_0(self):
595         return_data = mysql.MySQLExtPillar()
596         return_data.process_fields(["a", "b", "c", "d"], 0)
597         return_data.with_lists = []
598         return_data.enter_root(None)
599         return_data.process_results([[1, 2, 3, 4], [1, 2, 3, 8]])
600         self.assertEqual({1: {2: {3: 8}}}, return_data.result)
601     def test_134_process_results_deepmerge_depth_0(self):
602         return_data = mysql.MySQLExtPillar()
603         return_data.process_fields(["a", "b", "c", "d"], 0)
604         return_data.with_lists = []
605         return_data.enter_root(None)
606         return_data.process_results([[1, 2, 3, 4], [1, 2, 7, 8]])
607         self.assertEqual({1: {2: {3: 4, 7: 8}}}, return_data.result)
608     def test_135_process_results_overwrite_depth_1(self):
609         return_data = mysql.MySQLExtPillar()
610         return_data.process_fields(["a", "b", "c", "d"], 1)
611         return_data.with_lists = []
612         return_data.enter_root(None)
613         return_data.process_results([[1, 2, 3, 4], [1, 6, 7, 8]])
614         self.assertEqual({1: {"b": 6, "c": 7, "d": 8}}, return_data.result)
615     def test_136_process_results_merge_depth_2(self):
616         return_data = mysql.MySQLExtPillar()
617         return_data.process_fields(["a", "b", "c", "d"], 2)
618         return_data.with_lists = []
619         return_data.enter_root(None)
620         return_data.process_results([[1, 2, 3, 4], [1, 6, 7, 8]])
621         self.assertEqual(
622             {1: {2: {"c": 3, "d": 4}, 6: {"c": 7, "d": 8}}}, return_data.result
623         )
624     def test_137_process_results_overwrite_depth_2(self):
625         return_data = mysql.MySQLExtPillar()
626         return_data.process_fields(["a", "b", "c", "d"], 2)
627         return_data.with_lists = []
628         return_data.enter_root(None)
629         return_data.process_results([[1, 2, 3, 4], [1, 2, 7, 8]])
630         self.assertEqual({1: {2: {"c": 7, "d": 8}}}, return_data.result)
631     def test_201_process_results_complexity_multiresults(self):
632         return_data = mysql.MySQLExtPillar()
633         return_data.process_fields(["a", "b", "c", "d"], 2)
634         return_data.with_lists = []
635         return_data.enter_root(None)
636         return_data.process_results([[1, 2, 3, 4]])
637         return_data.process_results([[1, 2, 7, 8]])
638         self.assertEqual({1: {2: {"c": 7, "d": 8}}}, return_data.result)
639     def test_202_process_results_complexity_as_list(self):
640         return_data = mysql.MySQLExtPillar()
641         return_data.process_fields(["a", "b", "c", "d"], 2)
642         return_data.with_lists = []
643         return_data.enter_root(None)
644         return_data.as_list = True
645         return_data.process_results([[1, 2, 3, 4]])
646         return_data.process_results([[1, 2, 7, 8]])
647         self.assertEqual({1: {2: {"c": [3, 7], "d": [4, 8]}}}, return_data.result)
648     def test_203_process_results_complexity_as_list_deeper(self):
649         return_data = mysql.MySQLExtPillar()
650         return_data.process_fields(["a", "b", "c", "d"], 0)
651         return_data.with_lists = []
652         return_data.enter_root(None)
653         return_data.as_list = True
654         return_data.process_results([[1, 2, 3, 4]])
655         return_data.process_results([[1, 2, 3, 8]])
656         self.assertEqual({1: {2: {3: [4, 8]}}}, return_data.result)
657     def test_204_process_results_complexity_as_list_mismatch_depth(self):
658         return_data = mysql.MySQLExtPillar()
659 <a name="1"></a>        return_data.as_list = True
660         return_data.with_lists = []
661         return_data.enter_root(None)
662         return_data.process_fields([<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>"a", "b", "c", "d"], 0)
663         return_data.process_results([[1, 2, 3, 4]])
664         return_data.process_results([[1, 2, 3, 5]])
665         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
666         return_data.process_results([[1</b></font>, 2, 3, 6, 7]])
667         self.assertEqual({1: {2: {3: [4, 5, {6: 7}]}}}, return_data.result)
668     def test_205_process_results_complexity_as_list_mismatch_depth_reversed(self):
669         return_data = mysql.MySQLExtPillar()
670 <a name="3"></a>        return_data.as_list = True
671         return_data.with_lists = []
672         return_data.enter_root(None)
673         return_data.process_fields([<font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>"a", "b", "c", "d", "e"], 0)
674         return_data.process_results([[1, 2, 3, 6, 7]])
675         return_data.process_results([[1, 2, 3, 8, 9]])
676         return_data.process_fields(["a", "b", "c", "d"], 0)
677         return_data.process_results(</b></font>[[1, 2, 3, 4]])
678         return_data.process_results([[1, 2, 3, 5]])
679         self.assertEqual({1: {2: {3: [{6: 7, 8: 9}, 4, 5]}}}, return_data.result)
680     def test_206_process_results_complexity_as_list_mismatch_depth_weird_order(self):
681 <a name="2"></a>        return_data = mysql.MySQLExtPillar()
682         return_data.as_list = True
683         return_data.with_lists = []
684         return_data<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.enter_root(None)
685         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
686         return_data.process_results([[1, 2, 3, 6, 7]])
687         return_data.process_fields(["a", "b", "c", "d"], 0)
688         return_data.process_results([[</b></font>1, 2, 3, 4]])
689         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
690         return_data.process_results([[1, 2, 3, 8, 9]])
691         return_data.process_fields(["a", "b", "c", "d"], 0)
692         return_data.process_results([[1, 2, 3, 5]])
693         self.assertEqual({1: {2: {3: [{6: 7}, 4, {8: 9}, 5]}}}, return_data.result)
694     def test_207_process_results_complexity_collision_mismatch_depth(self):
695         return_data = mysql.MySQLExtPillar()
696         return_data.as_list = False
697         return_data.with_lists = []
698         return_data.enter_root(None)
699         return_data.process_fields(["a", "b", "c", "d"], 0)
700         return_data.process_results([[1, 2, 3, 4]])
701         return_data.process_results([[1, 2, 3, 5]])
702         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
703         return_data.process_results([[1, 2, 3, 6, 7]])
704         self.assertEqual({1: {2: {3: {6: 7}}}}, return_data.result)
705     def test_208_process_results_complexity_collision_mismatch_depth_reversed(self):
706         return_data = mysql.MySQLExtPillar()
707         return_data.as_list = False
708         return_data.with_lists = []
709         return_data.enter_root(None)
710         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
711         return_data.process_results([[1, 2, 3, 6, 7]])
712         return_data.process_results([[1, 2, 3, 8, 9]])
713         return_data.process_fields(["a", "b", "c", "d"], 0)
714         return_data.process_results([[1, 2, 3, 4]])
715         return_data.process_results([[1, 2, 3, 5]])
716         self.assertEqual({1: {2: {3: 5}}}, return_data.result)
717     def test_209_process_results_complexity_collision_mismatch_depth_weird_order(self):
718         return_data = mysql.MySQLExtPillar()
719         return_data.as_list = False
720         return_data.with_lists = []
721         return_data.enter_root(None)
722         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
723         return_data.process_results([[1, 2, 3, 6, 7]])
724         return_data.process_fields(["a", "b", "c", "d"], 0)
725         return_data.process_results([[1, 2, 3, 4]])
726         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
727         return_data.process_results([[1, 2, 3, 8, 9]])
728         return_data.process_fields(["a", "b", "c", "d"], 0)
729         return_data.process_results([[1, 2, 3, 5]])
730         self.assertEqual({1: {2: {3: 5}}}, return_data.result)
731     def test_20A_process_results_complexity_as_list_vary(self):
732         return_data = mysql.MySQLExtPillar()
733         return_data.as_list = True
734         return_data.with_lists = []
735         return_data.enter_root(None)
736         return_data.process_fields(["a", "b", "c", "d", "e"], 0)
737         return_data.process_results([[1, 2, 3, 6, 7]])
738         return_data.process_results([[1, 2, 3, 8, 9]])
739         return_data.process_fields(["a", "b", "c", "d"], 0)
740         return_data.process_results([[1, 2, 3, 4]])
741         return_data.as_list = False
742         return_data.process_results([[1, 2, 3, 5]])
743         self.assertEqual({1: {2: {3: 5}}}, return_data.result)
744     def test_207_process_results_complexity_roots_collision(self):
745         return_data = mysql.MySQLExtPillar()
746 <a name="5"></a>        return_data.as_list = False
747         return_data.with_lists = []
748         return_data.enter_root(None)
749         return_data<font color="#151b8d"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.process_fields(["a", "b", "c", "d"], 0)
750         return_data.process_results([[1, 2, 3, 4]])
751         return_data.enter_root(1)
752         return_data.process_results([[5</b></font>, 6, 7, 8]])
753         self.assertEqual({1: {5: {6: {7: 8}}}}, return_data.result)
754     def test_301_process_results_with_lists(self):
755         return_data = mysql.MySQLExtPillar()
756         return_data.as_list = False
757         return_data.with_lists = [1, 3]
758         return_data.enter_root(None)
759         return_data.process_fields(["a", "b", "c", "d", "e", "v"], 0)
760         return_data.process_results(
761             [
762                 ["a", "b", "c", "d", "e", 1],
763                 ["a", "b", "c", "f", "g", 2],
764                 ["a", "z", "h", "y", "j", 3],
765                 ["a", "z", "h", "y", "k", 4],
766             ]
767         )
768         assert "a" in return_data.result
769         for x in return_data.result["a"]:
770             if "c" in x:
771                 assert list(x.keys()) == ["c"], x.keys()
772                 for y in x["c"]:
773                     if "e" in y:
774                         assert list(y.keys()) == ["e"]
775                         assert y["e"] == 1
776                     elif "g" in y:
777                         assert list(y.keys()) == ["g"]
778                         assert y["g"] == 2
779                     else:
780                         raise ValueError("Unexpected value {}".format(y))
781             elif "h" in x:
782                 assert len(x["h"]) == 1
783                 for y in x["h"]:
784                     if "j" in y:
785                         assert len(y.keys()) == 2
786                         assert y["j"] == 3
787                     elif "h" in y:
788                         assert len(y.keys()) == 2
789                         assert y["k"] == 4
790                     else:
791                         raise ValueError("Unexpected value {}".format(y))
792             else:
793                 raise ValueError("Unexpected value {}".format(x))
794     def test_302_process_results_with_lists_consecutive(self):
795         return_data = mysql.MySQLExtPillar()
796         return_data.as_list = False
797         return_data.with_lists = [1, 2, 3]
798         return_data.enter_root(None)
799         return_data.process_fields(["a", "b", "c", "d", "e", "v"], 0)
800         return_data.process_results(
801             [
802                 ["a", "b", "c", "d", "e", 1],
803                 ["a", "b", "c", "f", "g", 2],
804                 ["a", "z", "h", "y", "j", 3],
805                 ["a", "z", "h", "y", "k", 4],
806             ]
807         )
808         assert "a" in return_data.result
809         for x in return_data.result["a"]:
810             assert len(x) == 1
811             if len(x[0][0]) == 1:
812                 for y in x[0]:
813                     if "e" in y:
814                         assert list(y.keys()) == ["e"]
815                         assert y["e"] == 1
816                     elif "g" in y:
817                         assert list(y.keys()) == ["g"]
818                         assert y["g"] == 2
819                     else:
820                         raise ValueError("Unexpected value {}".format(y))
821             elif len(x[0][0]) == 2:
822                 for y in x[0]:
823                     if "j" in y:
824                         assert len(y.keys()) == 2
825                         assert y["j"] == 3
826                     elif "k" in y:
827                         assert len(y.keys()) == 2
828                         assert y["k"] == 4
829                     else:
830                         raise ValueError("Unexpected value {}".format(len(x[0][0])))
831             else:
832                 raise ValueError("Unexpected value {}".format(x))
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>virt_1.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import base64
2 import collections
3 import copy
4 import datetime
5 import logging
6 import os
7 import re
8 import shutil
9 import string  # pylint: disable=deprecated-module
10 import subprocess
11 import sys
12 import time
13 import urllib.parse
14 from xml.etree import ElementTree
15 from xml.sax import saxutils
16 import jinja2.exceptions
17 import salt.utils.data
18 import salt.utils.files
19 import salt.utils.json
20 import salt.utils.path
21 import salt.utils.stringutils
22 import salt.utils.templates
23 import salt.utils.virt
24 import salt.utils.xmlutil as xmlutil
25 import salt.utils.yaml
26 from salt._compat import ipaddress
27 from salt.exceptions import CommandExecutionError, SaltInvocationError
28 try:
29     import libvirt  # pylint: disable=import-error
30     from libvirt import libvirtError
31     HAS_LIBVIRT = True
32 except ImportError:
33     HAS_LIBVIRT = False
34 log = logging.getLogger(__name__)
35 JINJA = jinja2.Environment(
36     loader=jinja2.FileSystemLoader(
37         os.path.join(salt.utils.templates.TEMPLATE_DIRNAME, "virt")
38     )
39 )
40 CACHE_DIR = "/var/lib/libvirt/saltinst"
41 VIRT_STATE_NAME_MAP = {
42     0: "running",
43     1: "running",
44     2: "running",
45     3: "paused",
46     4: "shutdown",
47     5: "shutdown",
48     6: "crashed",
49 }
50 def __virtual__():
51     if not HAS_LIBVIRT:
52         return (False, "Unable to locate or import python libvirt library.")
53     return "virt"
54 def __get_request_auth(username, password):
55     def __request_auth(credentials, user_data):
56         for credential in credentials:
57             if credential[0] == libvirt.VIR_CRED_AUTHNAME:
58                 credential[4] = (
59                     username
60                     if username
61                     else __salt__["config.get"](
62                         "virt:connection:auth:username", credential[3]
63                     )
64                 )
65             elif credential[0] == libvirt.VIR_CRED_NOECHOPROMPT:
66                 credential[4] = (
67                     password
68                     if password
69                     else __salt__["config.get"](
70                         "virt:connection:auth:password", credential[3]
71                     )
72                 )
73             else:
74                 log.info("Unhandled credential type: %s", credential[0])
75         return 0
76 def __get_conn(**kwargs):
77     username = kwargs.get("username", None)
78     password = kwargs.get("password", None)
79     conn_str = kwargs.get("connection", None)
80     if not conn_str:
81         conn_str = __salt__["config.get"]("virt:connection:uri", conn_str)
82     try:
83         auth_types = [
84             libvirt.VIR_CRED_AUTHNAME,
85             libvirt.VIR_CRED_NOECHOPROMPT,
86             libvirt.VIR_CRED_ECHOPROMPT,
87             libvirt.VIR_CRED_PASSPHRASE,
88             libvirt.VIR_CRED_EXTERNAL,
89         ]
90         conn = libvirt.openAuth(
91             conn_str, [auth_types, __get_request_auth(username, password), None], 0
92         )
93     except Exception:  # pylint: disable=broad-except
94         raise CommandExecutionError(
95             "Sorry, {} failed to open a connection to the hypervisor "
96             "software at {}".format(__grains__["fqdn"], conn_str)
97         )
98     return conn
99 def _get_domain(conn, *vms, **kwargs):
100     ret = list()
101     lookup_vms = list()
102     all_vms = []
103     if kwargs.get("active", True):
104         for id_ in conn.listDomainsID():
105             all_vms.append(conn.lookupByID(id_).name())
106     if kwargs.get("inactive", True):
107         for id_ in conn.listDefinedDomains():
108             all_vms.append(id_)
109     if vms and not all_vms:
110         raise CommandExecutionError("No virtual machines found.")
111     if vms:
112         for name in vms:
113             if name not in all_vms:
114                 raise CommandExecutionError(
115                     'The VM "{name}" is not present'.format(name=name)
116                 )
117             else:
118                 lookup_vms.append(name)
119     else:
120         lookup_vms = list(all_vms)
121     for name in lookup_vms:
122         ret.append(conn.lookupByName(name))
123     return len(ret) == 1 and not kwargs.get("iterable") and ret[0] or ret
124 def _parse_qemu_img_info(info):
125     raw_infos = salt.utils.json.loads(info)
126     disks = []
127     for disk_infos in raw_infos:
128         disk = {
129             "file": disk_infos["filename"],
130             "file format": disk_infos["format"],
131             "disk size": disk_infos["actual-size"],
132             "virtual size": disk_infos["virtual-size"],
133             "cluster size": disk_infos["cluster-size"]
134             if "cluster-size" in disk_infos
135             else None,
136         }
137         if "full-backing-filename" in disk_infos.keys():
138             disk["backing file"] = format(disk_infos["full-backing-filename"])
139         if "snapshots" in disk_infos.keys():
140             disk["snapshots"] = [
141                 {
142                     "id": snapshot["id"],
143                     "tag": snapshot["name"],
144                     "vmsize": snapshot["vm-state-size"],
145                     "date": datetime.datetime.fromtimestamp(
146                         float(
147                             "{}.{}".format(snapshot["date-sec"], snapshot["date-nsec"])
148                         )
149                     ).isoformat(),
150                     "vmclock": datetime.datetime.utcfromtimestamp(
151                         float(
152                             "{}.{}".format(
153                                 snapshot["vm-clock-sec"], snapshot["vm-clock-nsec"]
154                             )
155                         )
156                     )
157                     .time()
158                     .isoformat(),
159                 }
160                 for snapshot in disk_infos["snapshots"]
161             ]
162         disks.append(disk)
163     for disk in disks:
164         if "backing file" in disk.keys():
165             candidates = [
166                 info
167                 for info in disks
168                 if "file" in info.keys() and info["file"] == disk["backing file"]
169             ]
170             if candidates:
171                 disk["backing file"] = candidates[0]
172     return disks[0]
173 def _get_uuid(dom):
174     return ElementTree.fromstring(get_xml(dom)).find("uuid").text
175 def _get_on_poweroff(dom):
176     node = ElementTree.fromstring(get_xml(dom)).find("on_poweroff")
177     return node.text if node is not None else ""
178 def _get_on_reboot(dom):
179     node = ElementTree.fromstring(get_xml(dom)).find("on_reboot")
180     return node.text if node is not None else ""
181 def _get_on_crash(dom):
182     node = ElementTree.fromstring(get_xml(dom)).find("on_crash")
183     return node.text if node is not None else ""
184 def _get_nics(dom):
185     nics = {}
186     doc = ElementTree.fromstring(dom.XMLDesc(libvirt.VIR_DOMAIN_XML_INACTIVE))
187     for iface_node in doc.findall("devices/interface"):
188         nic = {}
189         nic["type"] = iface_node.get("type")
190         for v_node in iface_node:
191             if v_node.tag == "mac":
192                 nic["mac"] = v_node.get("address")
193             if v_node.tag == "model":
194                 nic["model"] = v_node.get("type")
195             if v_node.tag == "target":
196                 nic["target"] = v_node.get("dev")
197             if re.match("(driver|source|address)", v_node.tag):
198                 temp = {}
199                 for key, value in v_node.attrib.items():
200                     temp[key] = value
201                 nic[v_node.tag] = temp
202             if v_node.tag == "virtualport":
203                 temp = {}
204                 temp["type"] = v_node.get("type")
205                 for key, value in v_node.attrib.items():
206                     temp[key] = value
207                 nic["virtualport"] = temp
208         if "mac" not in nic:
209             continue
210         nics[nic["mac"]] = nic
211     return nics
212 def _get_graphics(dom):
213     out = {
214         "autoport": "None",
215         "keymap": "None",
216         "listen": "None",
217         "port": "None",
218         "type": "None",
219     }
220     doc = ElementTree.fromstring(dom.XMLDesc(0))
221     for g_node in doc.findall("devices/graphics"):
222         for key, value in g_node.attrib.items():
223             out[key] = value
224     return out
225 def _get_loader(dom):
226     out = {"path": "None"}
227     doc = ElementTree.fromstring(dom.XMLDesc(0))
228     for g_node in doc.findall("os/loader"):
229         out["path"] = g_node.text
230         for key, value in g_node.attrib.items():
231             out[key] = value
232     return out
233 def _get_disks(conn, dom):
234     disks = {}
235     doc = ElementTree.fromstring(dom.XMLDesc(0))
236     all_volumes = _get_all_volumes_paths(conn)
237     for elem in doc.findall("devices/disk"):
238         source = elem.find("source")
239         if source is None:
240             continue
241         target = elem.find("target")
242         driver = elem.find("driver")
243         if target is None:
244             continue
245         qemu_target = None
246         extra_properties = None
247         if "dev" in target.attrib:
248             disk_type = elem.get("type")
249             def _get_disk_volume_data(pool_name, volume_name):
250                 qemu_target = "{}/{}".format(pool_name, volume_name)
251                 pool = conn.storagePoolLookupByName(pool_name)
252                 extra_properties = {}
253                 try:
254                     vol = pool.storageVolLookupByName(volume_name)
255                     vol_info = vol.info()
256                     extra_properties = {
257                         "virtual size": vol_info[1],
258                         "disk size": vol_info[2],
259                     }
260                     backing_files = [
261                         {
262                             "file": node.find("source").get("file"),
263                             "file format": node.find("format").get("type"),
264                         }
265                         for node in elem.findall(".//backingStore[source]")
266                     ]
267                     if backing_files:
268                         extra_properties["backing file"] = backing_files[0]
269                         parent = extra_properties["backing file"]
270                         for sub_backing_file in backing_files[1:]:
271                             parent["backing file"] = sub_backing_file
272                             parent = sub_backing_file
273                     else:
274                         vol_desc = ElementTree.fromstring(vol.XMLDesc())
275                         backing_path = vol_desc.find("./backingStore/path")
276                         backing_format = vol_desc.find("./backingStore/format")
277                         if backing_path is not None:
278                             extra_properties["backing file"] = {
279                                 "file": backing_path.text
280                             }
281                             if backing_format is not None:
282                                 extra_properties["backing file"][
283                                     "file format"
284                                 ] = backing_format.get("type")
285                 except libvirt.libvirtError:
286                     log.info(
287                         "Couldn't extract all volume informations: pool is likely not"
288                         " running or refreshed"
289                     )
290                 return (qemu_target, extra_properties)
291             if disk_type == "file":
292                 qemu_target = source.get("file", "")
293                 if qemu_target.startswith("/dev/zvol/"):
294                     disks[target.get("dev")] = {"file": qemu_target, "zfs": True}
295                     continue
296                 if qemu_target in all_volumes.keys():
297                     volume = all_volumes[qemu_target]
298                     qemu_target, extra_properties = _get_disk_volume_data(
299                         volume["pool"], volume["name"]
300                     )
301                 elif elem.get("device", "disk") != "cdrom":
302                     try:
303                         process = subprocess.Popen(
304                             [
305                                 "qemu-img",
306                                 "info",
307                                 "-U",
308                                 "--output",
309                                 "json",
310                                 "--backing-chain",
311                                 qemu_target,
312                             ],
313                             shell=False,
314                             stdout=subprocess.PIPE,
315                             stderr=subprocess.PIPE,
316                         )
317                         stdout, stderr = process.communicate()
318                         if process.returncode == 0:
319                             qemu_output = salt.utils.stringutils.to_str(stdout)
320                             output = _parse_qemu_img_info(qemu_output)
321                             extra_properties = output
322                         else:
323                             extra_properties = {"error": stderr}
324                     except FileNotFoundError:
325                         extra_properties = {"error": "qemu-img not found"}
326             elif disk_type == "block":
327                 qemu_target = source.get("dev", "")
328                 if qemu_target in all_volumes.keys():
329                     volume = all_volumes[qemu_target]
330                     qemu_target, extra_properties = _get_disk_volume_data(
331                         volume["pool"], volume["name"]
332                     )
333             elif disk_type == "network":
334                 qemu_target = source.get("protocol")
335                 source_name = source.get("name")
336                 if source_name:
337                     qemu_target = "{}:{}".format(qemu_target, source_name)
338                 if source.get("protocol") in ["rbd", "gluster"]:
339                     for pool_i in conn.listAllStoragePools():
340                         pool_i_xml = ElementTree.fromstring(pool_i.XMLDesc())
341                         name_node = pool_i_xml.find("source/name")
342                         if name_node is not None and source_name.startswith(
343                             "{}/".format(name_node.text)
344                         ):
345                             qemu_target = "{}{}".format(
346                                 pool_i.name(), source_name[len(name_node.text) :]
347                             )
348                             break
349                 if elem.get("device", "disk") == "cdrom":
350                     host_node = source.find("host")
351                     if host_node is not None:
352                         hostname = host_node.get("name")
353                         port = host_node.get("port")
354                         qemu_target = urllib.parse.urlunparse(
355                             (
356                                 source.get("protocol"),
357                                 "{}:{}".format(hostname, port) if port else hostname,
358                                 source_name,
359                                 "",
360                                 saxutils.unescape(source.get("query", "")),
361                                 "",
362                             )
363                         )
364             elif disk_type == "volume":
365                 pool_name = source.get("pool")
366                 volume_name = source.get("volume")
367                 qemu_target, extra_properties = _get_disk_volume_data(
368                     pool_name, volume_name
369                 )
370             if not qemu_target:
371                 continue
372             disk = {
373                 "file": qemu_target,
374                 "type": elem.get("device"),
375             }
376             if driver is not None and "type" in driver.attrib:
377                 disk["file format"] = driver.get("type")
378             if extra_properties:
379                 disk.update(extra_properties)
380             disks[target.get("dev")] = disk
381     return disks
382 def _libvirt_creds():
383     g_cmd = ["grep", "^\\s*group", "/etc/libvirt/qemu.conf"]
384     u_cmd = ["grep", "^\\s*user", "/etc/libvirt/qemu.conf"]
385     try:
386         stdout = subprocess.Popen(g_cmd, stdout=subprocess.PIPE).communicate()[0]
387         group = salt.utils.stringutils.to_str(stdout).split('"')[1]
388     except IndexError:
389         group = "root"
390     try:
391         stdout = subprocess.Popen(u_cmd, stdout=subprocess.PIPE).communicate()[0]
392         user = salt.utils.stringutils.to_str(stdout).split('"')[1]
393     except IndexError:
394         user = "root"
395     return {"user": user, "group": group}
396 def _migrate(dom, dst_uri, **kwargs):
397     flags = 0
398     params = {}
399     migrated_state = libvirt.VIR_DOMAIN_RUNNING_MIGRATED
400     if kwargs.get("live", True):
401         flags |= libvirt.VIR_MIGRATE_LIVE
402     if kwargs.get("persistent", True):
403         flags |= libvirt.VIR_MIGRATE_PERSIST_DEST
404     if kwargs.get("undefinesource", True):
405         flags |= libvirt.VIR_MIGRATE_UNDEFINE_SOURCE
406     max_bandwidth = kwargs.get("max_bandwidth")
407     if max_bandwidth:
408         try:
409             bandwidth_value = int(max_bandwidth)
410         except ValueError:
411             raise SaltInvocationError(
412                 "Invalid max_bandwidth value: {}".format(max_bandwidth)
413             )
414         dom.migrateSetMaxSpeed(bandwidth_value)
415     max_downtime = kwargs.get("max_downtime")
416     if max_downtime:
417         try:
418             downtime_value = int(max_downtime)
419         except ValueError:
420             raise SaltInvocationError(
421                 "Invalid max_downtime value: {}".format(max_downtime)
422             )
423         dom.migrateSetMaxDowntime(downtime_value)
424     if kwargs.get("offline") is True:
425         flags |= libvirt.VIR_MIGRATE_OFFLINE
426         migrated_state = libvirt.VIR_DOMAIN_RUNNING_UNPAUSED
427     if kwargs.get("compressed") is True:
428         flags |= libvirt.VIR_MIGRATE_COMPRESSED
429     comp_methods = kwargs.get("comp_methods")
430     if comp_methods:
431         params[libvirt.VIR_MIGRATE_PARAM_COMPRESSION] = comp_methods.split(",")
432     comp_options = {
433         "comp_mt_level": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_LEVEL,
434         "comp_mt_threads": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_THREADS,
435         "comp_mt_dthreads": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_DTHREADS,
436         "comp_xbzrle_cache": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_XBZRLE_CACHE,
437     }
438     for (comp_option, param_key) in comp_options.items():
439         comp_option_value = kwargs.get(comp_option)
440         if comp_option_value:
441             try:
442                 params[param_key] = int(comp_option_value)
443             except ValueError:
444                 raise SaltInvocationError("Invalid {} value".format(comp_option))
445     parallel_connections = kwargs.get("parallel_connections")
446     if parallel_connections:
447         try:
448             params[libvirt.VIR_MIGRATE_PARAM_PARALLEL_CONNECTIONS] = int(
449                 parallel_connections
450             )
451         except ValueError:
452             raise SaltInvocationError("Invalid parallel_connections value")
453         flags |= libvirt.VIR_MIGRATE_PARALLEL
454     if __salt__["config.get"]("virt:tunnel"):
455         if parallel_connections:
456             raise SaltInvocationError(
457                 "Parallel migration isn't compatible with tunneled migration"
458             )
459         flags |= libvirt.VIR_MIGRATE_PEER2PEER
460         flags |= libvirt.VIR_MIGRATE_TUNNELLED
461     if kwargs.get("postcopy") is True:
462         flags |= libvirt.VIR_MIGRATE_POSTCOPY
463     postcopy_bandwidth = kwargs.get("postcopy_bandwidth")
464     if postcopy_bandwidth:
465         try:
466             postcopy_bandwidth_value = int(postcopy_bandwidth)
467         except ValueError:
468             raise SaltInvocationError("Invalid postcopy_bandwidth value")
469         dom.migrateSetMaxSpeed(
470             postcopy_bandwidth_value,
471             flags=libvirt.VIR_DOMAIN_MIGRATE_MAX_SPEED_POSTCOPY,
472         )
473     copy_storage = kwargs.get("copy_storage")
474     if copy_storage:
475         if copy_storage == "all":
476             flags |= libvirt.VIR_MIGRATE_NON_SHARED_DISK
477         elif copy_storage in ["inc", "incremental"]:
478             flags |= libvirt.VIR_MIGRATE_NON_SHARED_INC
479         else:
480             raise SaltInvocationError("invalid copy_storage value")
481     try:
482         state = False
483         dst_conn = __get_conn(
484             connection=dst_uri,
485             username=kwargs.get("username"),
486             password=kwargs.get("password"),
487         )
488         new_dom = dom.migrate3(dconn=dst_conn, params=params, flags=flags)
489         if new_dom:
490             state = new_dom.state()
491         dst_conn.close()
492         return state and migrated_state in state
493     except libvirt.libvirtError as err:
494         dst_conn.close()
495         raise CommandExecutionError(err.get_error_message())
496 def _get_volume_path(pool, volume_name):
497     if volume_name in pool.listVolumes():
498         volume = pool.storageVolLookupByName(volume_name)
499         volume_xml = ElementTree.fromstring(volume.XMLDesc())
500         return volume_xml.find("./target/path").text
501     pool_xml = ElementTree.fromstring(pool.XMLDesc())
502     pool_path = pool_xml.find("./target/path").text
503     return pool_path + "/" + volume_name
504 def _disk_from_pool(conn, pool, pool_xml, volume_name):
505     pool_type = pool_xml.get("type")
506     disk_context = {}
507     if pool_type in ["dir", "netfs", "fs"]:
508         disk_context["type"] = "file"
509         disk_context["source_file"] = _get_volume_path(pool, volume_name)
510     elif pool_type in ["logical", "disk", "iscsi", "scsi"]:
511         disk_context["type"] = "block"
512         disk_context["format"] = "raw"
513         disk_context["source_file"] = _get_volume_path(pool, volume_name)
514     elif pool_type in ["rbd", "gluster", "sheepdog"]:
515         disk_context["type"] = "network"
516         disk_context["protocol"] = pool_type
517         disk_context["hosts"] = [
518             {"name": host.get("name"), "port": host.get("port")}
519             for host in pool_xml.findall(".//host")
520         ]
521         dir_node = pool_xml.find("./source/dir")
522         name_node = pool_xml.find("./source/name")
523         if name_node is not None:
524             disk_context["volume"] = "{}/{}".format(name_node.text, volume_name)
525         auth_node = pool_xml.find("./source/auth")
526         if auth_node is not None:
527             username = auth_node.get("username")
528             secret_node = auth_node.find("./secret")
529             usage = secret_node.get("usage")
530             if not usage:
531                 uuid = secret_node.get("uuid")
532                 usage = conn.secretLookupByUUIDString(uuid).usageID()
533             disk_context["auth"] = {
534                 "type": "ceph",
535                 "username": username,
536                 "usage": usage,
537             }
538     return disk_context
539 def _handle_unit(s, def_unit="m"):
540     m = re.match(r"(?P&lt;value&gt;[0-9.]*)\s*(?P&lt;unit&gt;.*)$", str(s).strip())
541     value = m.group("value")
542     unit = m.group("unit").lower() or def_unit
543     try:
544         value = int(value)
545     except ValueError:
546         try:
547             value = float(value)
548         except ValueError:
549             raise SaltInvocationError("invalid number")
550     dec = False
551     if re.match(r"[kmgtpezy]b$", unit):
552         dec = True
553     elif not re.match(r"(b|[kmgtpezy](ib)?)$", unit):
554         raise SaltInvocationError("invalid units")
555     p = "bkmgtpezy".index(unit[0])
556     value *= 10 ** (p * 3) if dec else 2 ** (p * 10)
557     return int(value)
558 def nesthash(value=None):
559     return collections.defaultdict(nesthash, value or {})
560 def _gen_xml(
561     conn,
562     name,
563     cpu,
564     mem,
565     diskp,
566     nicp,
567     hypervisor,
568     os_type,
569     arch,
570     graphics=None,
571     boot=None,
572     boot_dev=None,
573     numatune=None,
574     hypervisor_features=None,
575     clock=None,
576     serials=None,
577     consoles=None,
578     stop_on_reboot=False,
579     host_devices=None,
580     **kwargs
581 ):
582     context = {
583         "hypervisor": hypervisor,
584         "name": name,
585         "hypervisor_features": hypervisor_features or {},
586         "clock": clock or {},
587         "on_reboot": "destroy" if stop_on_reboot else "restart",
588     }
589     context["to_kib"] = lambda v: int(_handle_unit(v) / 1024)
590     context["yesno"] = lambda v: "yes" if v else "no"
591     context["mem"] = nesthash()
592     if isinstance(mem, int):
593         context["mem"]["boot"] = mem
594         context["mem"]["current"] = mem
595     elif isinstance(mem, dict):
596         context["mem"] = nesthash(mem)
597     context["cpu"] = nesthash()
598     context["cputune"] = nesthash()
599     if isinstance(cpu, int):
600         context["cpu"]["maximum"] = str(cpu)
601     elif isinstance(cpu, dict):
602         context["cpu"] = nesthash(cpu)
603     if clock:
604         offset = "utc" if clock.get("utc", True) else "localtime"
605         if "timezone" in clock:
606             offset = "timezone"
607         context["clock"]["offset"] = offset
608     if hypervisor in ["qemu", "kvm"]:
609         context["numatune"] = numatune if numatune else {}
610         context["controller_model"] = False
611     elif hypervisor == "vmware":
612         context["controller_model"] = "lsilogic"
613     if graphics:
614         if "listen" not in graphics:
615             graphics["listen"] = {"type": "address", "address": "0.0.0.0"}
616         elif (
617             "address" not in graphics["listen"]
618             and graphics["listen"]["type"] == "address"
619         ):
620             graphics["listen"]["address"] = "0.0.0.0"
621         if graphics.get("type", "none") == "none":
622             graphics = None
623     context["graphics"] = graphics
624     context["boot_dev"] = boot_dev.split() if boot_dev is not None else ["hd"]
625     context["boot"] = boot if boot else {}
626     efi_value = context["boot"].get("efi", None) if boot else None
627     if efi_value is True:
628         context["boot"]["os_attrib"] = "firmware='efi'"
629     elif efi_value is not None and type(efi_value) != bool:
630         raise SaltInvocationError("Invalid efi value")
631     if os_type == "xen":
632         if __grains__["os_family"] == "Suse":
633             if not boot or not boot.get("kernel", None):
634                 paths = [
635                     path
636                     for path in ["/usr/share", "/usr/lib"]
637                     if os.path.exists(path + "/grub2/x86_64-xen/grub.xen")
638                 ]
639                 if not paths:
640                     raise CommandExecutionError("grub-x86_64-xen needs to be installed")
641                 context["boot"]["kernel"] = paths[0] + "/grub2/x86_64-xen/grub.xen"
642                 context["boot_dev"] = []
643     default_port = 23023
644     default_chardev_type = "tcp"
645     chardev_types = ["serial", "console"]
646     for chardev_type in chardev_types:
647         context[chardev_type + "s"] = []
648         parameter_value = locals()[chardev_type + "s"]
649         if parameter_value is not None:
650             for chardev in parameter_value:
651                 chardev_context = chardev
652                 chardev_context["type"] = chardev.get("type", default_chardev_type)
653                 if chardev_context["type"] == "tcp":
654                     chardev_context["port"] = chardev.get("port", default_port)
655                     chardev_context["protocol"] = chardev.get("protocol", "telnet")
656                 context[chardev_type + "s"].append(chardev_context)
657     context["disks"] = []
658     disk_bus_map = {"virtio": "vd", "xen": "xvd", "fdc": "fd", "ide": "hd"}
659     targets = []
660     for i, disk in enumerate(diskp):
661         prefix = disk_bus_map.get(disk["model"], "sd")
662         disk_context = {
663             "device": disk.get("device", "disk"),
664             "target_dev": _get_disk_target(targets, len(diskp), prefix),
665             "disk_bus": disk["model"],
666             "format": disk.get("format", "raw"),
667             "index": str(i),
668             "io": disk.get("io", "native"),
669             "iothread": disk.get("iothread_id", None),
670         }
671         targets.append(disk_context["target_dev"])
672         if disk.get("source_file"):
673             url = urllib.parse.urlparse(disk["source_file"])
674             if not url.scheme or not url.hostname:
675                 disk_context["source_file"] = disk["source_file"]
676                 disk_context["type"] = "file"
677             elif url.scheme in ["http", "https", "ftp", "ftps", "tftp"]:
678                 disk_context["type"] = "network"
679                 disk_context["protocol"] = url.scheme
680                 disk_context["volume"] = url.path
681                 disk_context["query"] = saxutils.escape(url.query)
682                 disk_context["hosts"] = [{"name": url.hostname, "port": url.port}]
683         elif disk.get("pool"):
684             disk_context["volume"] = disk["filename"]
685             pool = conn.storagePoolLookupByName(disk["pool"])
686             pool_xml = ElementTree.fromstring(pool.XMLDesc())
687             pool_type = pool_xml.get("type")
688             if hypervisor == "xen" or pool_type in ["rbd", "gluster", "sheepdog"]:
689                 disk_context.update(
690                     _disk_from_pool(conn, pool, pool_xml, disk_context["volume"])
691                 )
692             else:
693                 if pool_type in ["disk", "logical"]:
694                     disk_context["format"] = "raw"
695                 disk_context["type"] = "volume"
696                 disk_context["pool"] = disk["pool"]
697         else:
698             disk_context["type"] = "file"
699         if hypervisor in ["qemu", "kvm", "bhyve", "xen"]:
700             disk_context["address"] = False
701             disk_context["driver"] = True
702         elif hypervisor in ["esxi", "vmware"]:
703             disk_context["address"] = True
704             disk_context["driver"] = False
705         context["disks"].append(disk_context)
706     context["nics"] = nicp
707     hostdev_context = []
708     try:
709         for hostdev_name in host_devices or []:
710             hostdevice = conn.nodeDeviceLookupByName(hostdev_name)
711             doc = ElementTree.fromstring(hostdevice.XMLDesc())
712             if "pci" in hostdevice.listCaps():
713                 hostdev_context.append(
714                     {
715                         "type": "pci",
716                         "domain": "0x{:04x}".format(
717                             int(doc.find("./capability[@type='pci']/domain").text)
718                         ),
719                         "bus": "0x{:02x}".format(
720                             int(doc.find("./capability[@type='pci']/bus").text)
721                         ),
722                         "slot": "0x{:02x}".format(
723                             int(doc.find("./capability[@type='pci']/slot").text)
724                         ),
725                         "function": "0x{}".format(
726                             doc.find("./capability[@type='pci']/function").text
727                         ),
728                     }
729                 )
730             elif "usb_device" in hostdevice.listCaps():
731                 vendor_id = doc.find(".//vendor").get("id")
732                 product_id = doc.find(".//product").get("id")
733                 hostdev_context.append(
734                     {"type": "usb", "vendor": vendor_id, "product": product_id}
735                 )
736     except libvirt.libvirtError as err:
737         conn.close()
738         raise CommandExecutionError(
739             "Failed to get host devices: " + err.get_error_message()
740         )
741     context["hostdevs"] = hostdev_context
742     context["os_type"] = os_type
743     context["arch"] = arch
744     fn_ = "libvirt_domain.jinja"
745     try:
746         template = JINJA.get_template(fn_)
747     except jinja2.exceptions.TemplateNotFound:
748         log.error("Could not load template %s", fn_)
749         return ""
750     return template.render(**context)
751 def _gen_vol_xml(
752     name,
753     size,
754     format=None,
755     allocation=0,
756     type=None,
757     permissions=None,
758     backing_store=None,
759     nocow=False,
760 ):
761     size = int(size) * 1024  # MB
762     context = {
763         "type": type,
764         "name": name,
765         "target": {"permissions": permissions, "nocow": nocow},
766         "format": format,
767         "size": str(size),
768         "allocation": str(int(allocation) * 1024),
769         "backingStore": backing_store,
770     }
771     fn_ = "libvirt_volume.jinja"
772     try:
773         template = JINJA.get_template(fn_)
774     except jinja2.exceptions.TemplateNotFound:
775         log.error("Could not load template %s", fn_)
776         return ""
777     return template.render(**context)
778 def _gen_net_xml(
779     name,
780     bridge,
781     forward,
782     vport,
783     tag=None,
784     ip_configs=None,
785     mtu=None,
786     domain=None,
787     nat=None,
788     interfaces=None,
789     addresses=None,
790     physical_function=None,
791     dns=None,
792 ):
793     if isinstance(vport, str):
794         vport_context = {"type": vport}
795     else:
796         vport_context = vport
797     if isinstance(tag, (str, int)):
798         tag_context = {"tags": [{"id": tag}]}
799     else:
800         tag_context = tag
801     addresses_context = []
802     if addresses:
803         matches = [
804             re.fullmatch(r"([0-9]+):([0-9A-Fa-f]+):([0-9A-Fa-f]+)\.([0-9])", addr)
805             for addr in addresses.lower().split(" ")
806         ]
807         addresses_context = [
808             {
809                 "domain": m.group(1),
810                 "bus": m.group(2),
811                 "slot": m.group(3),
812                 "function": m.group(4),
813             }
814             for m in matches
815             if m
816         ]
817     context = {
818         "name": name,
819         "bridge": bridge,
820         "mtu": mtu,
821         "domain": domain,
822         "forward": forward,
823         "nat": nat,
824         "interfaces": interfaces.split(" ") if interfaces else [],
825         "addresses": addresses_context,
826         "pf": physical_function,
827         "vport": vport_context,
828         "vlan": tag_context,
829         "dns": dns,
830         "ip_configs": [
831             {
832                 "address": ipaddress.ip_network(config["cidr"]),
833                 "dhcp_ranges": config.get("dhcp_ranges", []),
834                 "hosts": config.get("hosts", {}),
835                 "bootp": config.get("bootp", {}),
836                 "tftp": config.get("tftp"),
837             }
838             for config in ip_configs or []
839         ],
840         "yesno": lambda v: "yes" if v else "no",
841     }
842     fn_ = "libvirt_network.jinja"
843     try:
844         template = JINJA.get_template(fn_)
845     except jinja2.exceptions.TemplateNotFound:
846         log.error("Could not load template %s", fn_)
847         return ""
848     return template.render(**context)
849 def _gen_pool_xml(
850     name,
851     ptype,
852     target=None,
853     permissions=None,
854     source_devices=None,
855     source_dir=None,
856     source_adapter=None,
857     source_hosts=None,
858     source_auth=None,
859     source_name=None,
860     source_format=None,
861     source_initiator=None,
862 ):
863     hosts = [host.split(":") for host in source_hosts or []]
864     source = None
865     if any(
866         [
867             source_devices,
868             source_dir,
869             source_adapter,
870             hosts,
871             source_auth,
872             source_name,
873             source_format,
874             source_initiator,
875         ]
876     ):
877         source = {
878             "devices": source_devices or [],
879             "dir": source_dir
880             if source_format != "cifs" or not source_dir
881             else source_dir.lstrip("/"),
882             "adapter": source_adapter,
883             "hosts": [
884                 {"name": host[0], "port": host[1] if len(host) &gt; 1 else None}
885                 for host in hosts
886             ],
887             "auth": source_auth,
888             "name": source_name,
889             "format": source_format,
890             "initiator": source_initiator,
891         }
892     context = {
893         "name": name,
894         "ptype": ptype,
895         "target": {"path": target, "permissions": permissions},
896         "source": source,
897     }
898     fn_ = "libvirt_pool.jinja"
899     try:
900         template = JINJA.get_template(fn_)
901     except jinja2.exceptions.TemplateNotFound:
902         log.error("Could not load template %s", fn_)
903         return ""
904     return template.render(**context)
905 def _gen_secret_xml(auth_type, usage, description):
906     context = {
907         "type": auth_type,
908         "usage": usage,
909         "description": description,
910     }
911     fn_ = "libvirt_secret.jinja"
912     try:
913         template = JINJA.get_template(fn_)
914     except jinja2.exceptions.TemplateNotFound:
915         log.error("Could not load template %s", fn_)
916         return ""
917     return template.render(**context)
918 def _get_images_dir():
919     img_dir = __salt__["config.get"]("virt:images")
920     log.debug("Image directory from config option `virt:images` is %s", img_dir)
921     return img_dir
922 def _zfs_image_create(
923     vm_name,
924     pool,
925     disk_name,
926     hostname_property_name,
927     sparse_volume,
928     disk_size,
929     disk_image_name,
930 ):
931     if not disk_image_name and not disk_size:
932         raise CommandExecutionError(
933             "Unable to create new disk {}, please specify"
934             " the disk image name or disk size argument".format(disk_name)
935         )
936     if not pool:
937         raise CommandExecutionError(
938             "Unable to create new disk {}, please specify the disk pool name".format(
939                 disk_name
940             )
941         )
942     destination_fs = os.path.join(pool, "{}.{}".format(vm_name, disk_name))
943     log.debug("Image destination will be %s", destination_fs)
944     existing_disk = __salt__["zfs.list"](name=pool)
945     if "error" in existing_disk:
946         raise CommandExecutionError(
947             "Unable to create new disk {}. {}".format(
948                 destination_fs, existing_disk["error"]
949             )
950         )
951     elif destination_fs in existing_disk:
952         log.info("ZFS filesystem %s already exists. Skipping creation", destination_fs)
953         blockdevice_path = os.path.join("/dev/zvol", pool, vm_name)
954         return blockdevice_path
955     properties = {}
956     if hostname_property_name:
957         properties[hostname_property_name] = vm_name
958     if disk_image_name:
959         __salt__["zfs.clone"](
960             name_a=disk_image_name, name_b=destination_fs, properties=properties
961         )
962     elif disk_size:
963         __salt__["zfs.create"](
964             name=destination_fs,
965             properties=properties,
966             volume_size=disk_size,
967             sparse=sparse_volume,
968         )
969     blockdevice_path = os.path.join(
970         "/dev/zvol", pool, "{}.{}".format(vm_name, disk_name)
971     )
972     log.debug("Image path will be %s", blockdevice_path)
973     return blockdevice_path
974 def _qemu_image_create(disk, create_overlay=False, saltenv="base"):
975     disk_size = disk.get("size", None)
976     disk_image = disk.get("image", None)
977     if not disk_size and not disk_image:
978         raise CommandExecutionError(
979             "Unable to create new disk {}, please specify"
980             " disk size and/or disk image argument".format(disk["filename"])
981         )
982     img_dest = disk["source_file"]
983     log.debug("Image destination will be %s", img_dest)
984     img_dir = os.path.dirname(img_dest)
985     log.debug("Image destination directory is %s", img_dir)
986     if not os.path.exists(img_dir):
987         os.makedirs(img_dir)
988     if disk_image:
989         log.debug("Create disk from specified image %s", disk_image)
990         sfn = __salt__["cp.cache_file"](disk_image, saltenv)
991         qcow2 = False
992         if salt.utils.path.which("qemu-img"):
993             res = __salt__["cmd.run"]('qemu-img info "{}"'.format(sfn))
994             imageinfo = salt.utils.yaml.safe_load(res)
995             qcow2 = imageinfo["file format"] == "qcow2"
996         try:
997             if create_overlay and qcow2:
998                 log.info("Cloning qcow2 image %s using copy on write", sfn)
999                 __salt__["cmd.run"](
1000                     'qemu-img create -f qcow2 -o backing_file="{}" "{}"'.format(
1001                         sfn, img_dest
1002                     ).split()
1003                 )
1004             else:
1005                 log.debug("Copying %s to %s", sfn, img_dest)
1006                 salt.utils.files.copyfile(sfn, img_dest)
1007             mask = salt.utils.files.get_umask()
1008             if disk_size and qcow2:
1009                 log.debug("Resize qcow2 image to %sM", disk_size)
1010                 __salt__["cmd.run"](
1011                     'qemu-img resize "{}" {}M'.format(img_dest, disk_size)
1012                 )
1013             log.debug("Apply umask and remove exec bit")
1014             mode = (0o0777 ^ mask) &amp; 0o0666
1015             os.chmod(img_dest, mode)
1016         except OSError as err:
1017             raise CommandExecutionError(
1018                 "Problem while copying image. {} - {}".format(disk_image, err)
1019             )
1020     else:
1021         try:
1022             mask = salt.utils.files.get_umask()
1023             if disk_size:
1024                 log.debug("Create empty image with size %sM", disk_size)
1025                 __salt__["cmd.run"](
1026                     'qemu-img create -f {} "{}" {}M'.format(
1027                         disk.get("format", "qcow2"), img_dest, disk_size
1028                     )
1029                 )
1030             else:
1031                 raise CommandExecutionError(
1032                     "Unable to create new disk {},"
1033                     " please specify &lt;size&gt; argument".format(img_dest)
1034                 )
1035             log.debug("Apply umask and remove exec bit")
1036             mode = (0o0777 ^ mask) &amp; 0o0666
1037             os.chmod(img_dest, mode)
1038         except OSError as err:
1039             raise CommandExecutionError(
1040                 "Problem while creating volume {} - {}".format(img_dest, err)
1041             )
1042     return img_dest
1043 def _seed_image(seed_cmd, img_path, name, config, install, pub_key, priv_key):
1044     log.debug("Seeding image")
1045     __salt__[seed_cmd](
1046         img_path,
1047         id_=name,
1048         config=config,
1049         install=install,
1050         pub_key=pub_key,
1051         priv_key=priv_key,
1052     )
1053 def _disk_volume_create(conn, disk, seeder=None, saltenv="base"):
1054     if disk.get("overlay_image"):
1055         raise SaltInvocationError(
1056             "Disk overlay_image property is not supported when creating volumes,"
1057             "use backing_store_path and backing_store_format instead."
1058         )
1059     pool = conn.storagePoolLookupByName(disk["pool"])
1060     if disk["filename"] in pool.listVolumes():
1061         return
1062     pool_type = ElementTree.fromstring(pool.XMLDesc()).get("type")
1063     backing_path = disk.get("backing_store_path")
1064     backing_format = disk.get("backing_store_format")
1065     backing_store = None
1066     if (
1067         backing_path
1068         and backing_format
1069         and (disk.get("format") == "qcow2" or pool_type == "logical")
1070     ):
1071         backing_store = {"path": backing_path, "format": backing_format}
1072     if backing_store and disk.get("image"):
1073         raise SaltInvocationError(
1074             "Using a template image with a backing store is not possible, "
1075             "choose either of them."
1076         )
1077     vol_xml = _gen_vol_xml(
1078         disk["filename"],
1079         disk.get("size", 0),
1080         format=disk.get("format"),
1081         backing_store=backing_store,
1082     )
1083     _define_vol_xml_str(conn, vol_xml, disk.get("pool"))
1084     if disk.get("image"):
1085         log.debug("Caching disk template image: %s", disk.get("image"))
1086         cached_path = __salt__["cp.cache_file"](disk.get("image"), saltenv)
1087         if seeder:
1088             seeder(cached_path)
1089         _volume_upload(
1090             conn,
1091             disk["pool"],
1092             disk["filename"],
1093             cached_path,
1094             sparse=disk.get("format") == "qcow2",
1095         )
1096 def _disk_profile(conn, profile, hypervisor, disks, vm_name):
1097     default = [{"system": {"size": 8192}}]
1098     if hypervisor == "vmware":
1099         overlay = {"format": "vmdk", "model": "scsi", "device": "disk"}
1100     elif hypervisor in ["qemu", "kvm"]:
1101         overlay = {"device": "disk", "model": "virtio"}
1102     elif hypervisor == "xen":
1103         overlay = {"device": "disk", "model": "xen"}
1104     elif hypervisor == "bhyve":
1105         overlay = {"format": "raw", "model": "virtio", "sparse_volume": False}
1106     else:
1107         overlay = {}
1108     disklist = []
1109     if profile:
1110         disklist = copy.deepcopy(
1111             __salt__["config.get"]("virt:disk", {}).get(profile, default)
1112         )
1113         disklist = [dict(d, name=name) for disk in disklist for name, d in disk.items()]
1114     if disks:
1115         for udisk in disks:
1116             if "name" in udisk:
1117                 found = [disk for disk in disklist if udisk["name"] == disk["name"]]
1118                 if found:
1119                     found[0].update(udisk)
1120                 else:
1121                     disklist.append(udisk)
1122     pool_caps = _pool_capabilities(conn)
1123     for disk in disklist:
1124         if disk.get("device", "disk") == "cdrom" and "model" not in disk:
1125             disk["model"] = "ide"
1126         for key, val in overlay.items():
1127             if key not in disk:
1128                 disk[key] = val
1129         if disk.get("source_file") and os.path.exists(disk["source_file"]):
1130             disk["filename"] = os.path.basename(disk["source_file"])
1131             if not disk.get("format"):
1132                 disk["format"] = (
1133                     "qcow2" if disk.get("device", "disk") != "cdrom" else "raw"
1134                 )
1135         elif vm_name and disk.get("device", "disk") == "disk":
1136             _fill_disk_filename(conn, vm_name, disk, hypervisor, pool_caps)
1137     return disklist
1138 def _fill_disk_filename(conn, vm_name, disk, hypervisor, pool_caps):
1139     disk["filename"] = "{}_{}".format(vm_name, disk["name"])
1140     base_dir = disk.get("pool", None)
1141     if hypervisor in ["qemu", "kvm", "xen"]:
1142         if not base_dir:
1143             base_dir = _get_images_dir()
1144         if base_dir not in conn.listStoragePools():
1145             if not disk.get("format"):
1146                 disk["format"] = "qcow2"
1147             disk["filename"] = "{}.{}".format(disk["filename"], disk["format"])
1148             disk["source_file"] = os.path.join(base_dir, disk["filename"])
1149         else:
1150             if "pool" not in disk:
1151                 disk["pool"] = base_dir
1152             pool_obj = conn.storagePoolLookupByName(base_dir)
1153             pool_xml = ElementTree.fromstring(pool_obj.XMLDesc())
1154             pool_type = pool_xml.get("type")
1155             if pool_type == "disk":
1156                 device = pool_xml.find("./source/device").get("path")
1157                 all_volumes = pool_obj.listVolumes()
1158                 if disk.get("source_file") not in all_volumes:
1159                     indexes = [
1160                         int(re.sub("[a-z]+", "", vol_name)) for vol_name in all_volumes
1161                     ] or [0]
1162                     index = min(
1163                         idx for idx in range(1, max(indexes) + 2) if idx not in indexes
1164                     )
1165                     disk["filename"] = "{}{}".format(os.path.basename(device), index)
1166             if disk.get("source_file"):
1167                 if not disk.get("source_file") in pool_obj.listVolumes():
1168                     raise SaltInvocationError(
1169                         "{} volume doesn't exist in pool {}".format(
1170                             disk.get("source_file"), base_dir
1171                         )
1172                     )
1173                 disk["filename"] = disk["source_file"]
1174                 del disk["source_file"]
1175             if not disk.get("format"):
1176                 volume_options = (
1177                     [
1178                         type_caps.get("options", {}).get("volume", {})
1179                         for type_caps in pool_caps.get("pool_types")
1180                         if type_caps["name"] == pool_type
1181                     ]
1182                     or [{}]
1183                 )[0]
1184                 if "qcow2" in volume_options.get("targetFormatType", []):
1185                     disk["format"] = "qcow2"
1186                 else:
1187                     disk["format"] = volume_options.get("default_format", None)
1188     elif hypervisor == "bhyve" and vm_name:
1189         disk["filename"] = "{}.{}".format(vm_name, disk["name"])
1190         disk["source_file"] = os.path.join(
1191             "/dev/zvol", base_dir or "", disk["filename"]
1192         )
1193     elif hypervisor in ["esxi", "vmware"]:
1194         if not base_dir:
1195             base_dir = __salt__["config.get"]("virt:storagepool", "[0] ")
1196         disk["filename"] = "{}.{}".format(disk["filename"], disk["format"])
1197         disk["source_file"] = "{}{}".format(base_dir, disk["filename"])
1198 def _complete_nics(interfaces, hypervisor):
1199     vmware_overlay = {"type": "bridge", "source": "DEFAULT", "model": "e1000"}
1200     kvm_overlay = {"type": "bridge", "source": "br0", "model": "virtio"}
1201     xen_overlay = {"type": "bridge", "source": "br0", "model": None}
1202     bhyve_overlay = {"type": "bridge", "source": "bridge0", "model": "virtio"}
1203     overlays = {
1204         "xen": xen_overlay,
1205         "kvm": kvm_overlay,
1206         "qemu": kvm_overlay,
1207         "vmware": vmware_overlay,
1208         "bhyve": bhyve_overlay,
1209     }
1210     def _normalize_net_types(attributes):
1211         for type_ in ["bridge", "network"]:
1212             if type_ in attributes:
1213                 attributes["type"] = type_
1214                 attributes["source"] = attributes.pop(type_)
1215         attributes["type"] = attributes.get("type", None)
1216         attributes["source"] = attributes.get("source", None)
1217     def _apply_default_overlay(attributes):
1218         for key, value in overlays[hypervisor].items():
1219             if key not in attributes or not attributes[key]:
1220                 attributes[key] = value
1221     for interface in interfaces:
1222         _normalize_net_types(interface)
1223         if hypervisor in overlays:
1224             _apply_default_overlay(interface)
1225     return interfaces
1226 def _nic_profile(profile_name, hypervisor):
1227     config_data = __salt__["config.get"]("virt:nic", {}).get(
1228         profile_name, [{"eth0": {}}]
1229     )
1230     interfaces = []
1231     def append_dict_profile_to_interface_list(profile_dict):
1232         for interface_name, attributes in profile_dict.items():
1233             attributes["name"] = interface_name
1234             interfaces.append(attributes)
1235     if isinstance(config_data, dict):
1236         append_dict_profile_to_interface_list(config_data)
1237     elif isinstance(config_data, list):
1238         for interface in config_data:
1239             if isinstance(interface, dict):
1240                 if len(interface) == 1:
1241                     append_dict_profile_to_interface_list(interface)
1242                 else:
1243                     interfaces.append(interface)
1244     return _complete_nics(interfaces, hypervisor)
1245 def _get_merged_nics(hypervisor, profile, interfaces=None):
1246     nicp = _nic_profile(profile, hypervisor) if profile else []
1247     log.debug("NIC profile is %s", nicp)
1248     if interfaces:
1249         users_nics = _complete_nics(interfaces, hypervisor)
1250         for unic in users_nics:
1251             found = [nic for nic in nicp if nic["name"] == unic["name"]]
1252             if found:
1253                 found[0].update(unic)
1254             else:
1255                 nicp.append(unic)
1256         log.debug("Merged NICs: %s", nicp)
1257     return nicp
1258 def _handle_remote_boot_params(orig_boot):
1259     keys <font color="#8c8774"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= orig_boot.keys()
1260     cases = [
1261         {"efi"},
1262         {"kernel", "initrd", "efi"},
1263         {"kernel", "initrd", "cmdline", "efi"},
1264         {"loader", "nvram"},
1265         {"kernel", "initrd"},
1266         {"kernel", "initrd", "cmdline"},
1267         {"kernel", "initrd", "loader", "nvram"},
1268         {"kernel"</b></font>, "initrd", "cmdline", "loader", "nvram"},
1269     ]
1270     if keys in cases:
1271         for key in keys:
1272             if key == "efi" and type(orig_boot.get(key)) == bool:
1273                 new_boot[key] = orig_boot.get(key)
1274             elif orig_boot.get(key) is not None and salt.utils.virt.check_remote(
1275                 orig_boot.get(key)
1276             ):
1277                 if saltinst_dir is None:
1278                     os.makedirs(CACHE_DIR)
1279                     saltinst_dir = CACHE_DIR
1280                 new_boot[key] = salt.utils.virt.download_remote(
1281                     orig_boot.get(key), saltinst_dir
1282                 )
1283         return new_boot
1284     else:
1285         raise SaltInvocationError(
1286             "Invalid boot parameters,It has to follow this combination: [(kernel,"
1287             " initrd) or/and cmdline] or/and [(loader, nvram) or efi]"
1288         )
1289 def _handle_efi_param(boot, desc):
1290     efi_value = boot.get("efi", None) if boot else None
1291     parent_tag = desc.find("os")
1292     os_attrib = parent_tag.attrib
1293     if efi_value is False and os_attrib != {}:
1294         parent_tag.attrib.pop("firmware", None)
1295         return True
1296     elif type(efi_value) == bool and os_attrib == {}:
1297         if efi_value is True and parent_tag.find("loader") is None:
1298             parent_tag.set("firmware", "efi")
1299             return True
1300         if efi_value is False and parent_tag.find("loader") is not None:
1301             parent_tag.remove(parent_tag.find("loader"))
1302             parent_tag.remove(parent_tag.find("nvram"))
1303             return True
1304     elif type(efi_value) != bool:
1305         raise SaltInvocationError("Invalid efi value")
1306     return False
1307 def init(
1308     name,
1309     cpu,
1310     mem,
1311     nic="default",
1312     interfaces=None,
1313     hypervisor=None,
1314     start=True,  # pylint: disable=redefined-outer-name
1315     disk="default",
1316     disks=None,
1317     saltenv="base",
1318     seed=True,
1319     install=True,
1320     pub_key=None,
1321     priv_key=None,
1322     seed_cmd="seed.apply",
1323     graphics=None,
1324     os_type=None,
1325     arch=None,
1326     boot=None,
1327     boot_dev=None,
1328     numatune=None,
1329     hypervisor_features=None,
1330     clock=None,
1331     serials=None,
1332     consoles=None,
1333     stop_on_reboot=False,
1334     host_devices=None,
1335     **kwargs
1336 ):
1337     try:
1338         conn = __get_conn(**kwargs)
1339         caps = _capabilities(conn)
1340         os_types = sorted({guest["os_type"] for guest in caps["guests"]})
1341         arches = sorted({guest["arch"]["name"] for guest in caps["guests"]})
1342         virt_hypervisor = hypervisor
1343         if not virt_hypervisor:
1344             hypervisors = sorted(
1345                 {
1346                     x
1347                     for y in [
1348                         guest["arch"]["domains"].keys() for guest in caps["guests"]
1349                     ]
1350                     for x in y
1351                 }
1352             )
1353             if len(hypervisors) == 0:
1354                 raise SaltInvocationError("No supported hypervisors were found")
1355             virt_hypervisor = "kvm" if "kvm" in hypervisors else hypervisors[0]
1356         virt_hypervisor = "vmware" if virt_hypervisor == "esxi" else virt_hypervisor
1357         log.debug("Using hypervisor %s", virt_hypervisor)
1358         nicp = _get_merged_nics(virt_hypervisor, nic, interfaces)
1359         diskp = _disk_profile(conn, disk, virt_hypervisor, disks, name)
1360         for _disk in diskp:
1361             if _disk.get("device", "disk") == "cdrom":
1362                 continue
1363             log.debug("Creating disk for VM [ %s ]: %s", name, _disk)
1364             if virt_hypervisor == "vmware":
1365                 if "image" in _disk:
1366                     raise SaltInvocationError(
1367                         "virt.init does not support image "
1368                         "template in conjunction with esxi hypervisor"
1369                     )
1370                 else:
1371                     log.debug("Generating libvirt XML for %s", _disk)
1372                     volume_name = "{}/{}".format(name, _disk["name"])
1373                     filename = "{}.{}".format(volume_name, _disk["format"])
1374                     vol_xml = _gen_vol_xml(
1375                         filename, _disk["size"], format=_disk["format"]
1376                     )
1377                     _define_vol_xml_str(conn, vol_xml, pool=_disk.get("pool"))
1378             elif virt_hypervisor in ["qemu", "kvm", "xen"]:
1379                 def seeder(path):
1380                     _seed_image(
1381                         seed_cmd,
1382                         path,
1383                         name,
1384                         kwargs.get("config"),
1385                         install,
1386                         pub_key,
1387                         priv_key,
1388                     )
1389                 create_overlay = _disk.get("overlay_image", False)
1390                 format = _disk.get("format")
1391                 if _disk.get("source_file"):
1392                     if os.path.exists(_disk["source_file"]):
1393                         img_dest = _disk["source_file"]
1394                     else:
1395                         img_dest = _qemu_image_create(_disk, create_overlay, saltenv)
1396                 else:
1397                     _disk_volume_create(conn, _disk, seeder if seed else None, saltenv)
1398                     img_dest = None
1399                 if seed and img_dest and _disk.get("image", None):
1400                     seeder(img_dest)
1401             elif hypervisor in ["bhyve"]:
1402                 img_dest = _zfs_image_create(
1403                     vm_name=name,
1404                     pool=_disk.get("pool"),
1405                     disk_name=_disk.get("name"),
1406                     disk_size=_disk.get("size"),
1407                     disk_image_name=_disk.get("image"),
1408                     hostname_property_name=_disk.get("hostname_property"),
1409                     sparse_volume=_disk.get("sparse_volume"),
1410                 )
1411             else:
1412                 raise SaltInvocationError(
1413                     "Unsupported hypervisor when handling disk image: {}".format(
1414                         virt_hypervisor
1415                     )
1416                 )
1417         log.debug("Generating VM XML")
1418         if os_type is None:
1419             os_type = "hvm" if "hvm" in os_types else os_types[0]
1420         if arch is None:
1421             arch = "x86_64" if "x86_64" in arches else arches[0]
1422         if boot is not None:
1423             boot = _handle_remote_boot_params(boot)
1424         vm_xml = _gen_xml(
1425             conn,
1426             name,
1427             cpu,
1428             mem,
1429             diskp,
1430             nicp,
1431             virt_hypervisor,
1432             os_type,
1433             arch,
1434             graphics,
1435             boot,
1436             boot_dev,
1437             numatune,
1438             hypervisor_features,
1439             clock,
1440             serials,
1441             consoles,
1442             stop_on_reboot,
1443             host_devices,
1444             **kwargs
1445         )
1446         log.debug("New virtual machine definition: %s", vm_xml)
1447         conn.defineXML(vm_xml)
1448     except libvirt.libvirtError as err:
1449         conn.close()
1450         raise CommandExecutionError(err.get_error_message())
1451     if start:
1452         log.debug("Starting VM %s", name)
1453         _get_domain(conn, name).create()
1454     conn.close()
1455     return True
1456 def _disks_equal(disk1, disk2):
1457     target1 = disk1.find("target")
1458     target2 = disk2.find("target")
1459     disk1_dict = xmlutil.to_dict(disk1, True)
1460     disk2_dict = xmlutil.to_dict(disk2, True)
1461     source1_dict = disk1_dict.get("source", {})
1462     source2_dict = disk2_dict.get("source", {})
1463     io1 = disk1_dict.get("driver", {}).get("io", "native")
1464     io2 = disk2_dict.get("driver", {}).get("io", "native")
1465     if source1_dict:
1466         source1_dict.pop("index", None)
1467     if source2_dict:
1468         source2_dict.pop("index", None)
1469     return (
1470         source1_dict == source2_dict
1471         and target1 is not None
1472         and target2 is not None
1473         and target1.get("bus") == target2.get("bus")
1474         and disk1.get("device", "disk") == disk2.get("device", "disk")
1475         and target1.get("dev") == target2.get("dev")
1476         and io1 == io2
1477     )
1478 def _nics_equal(nic1, nic2):
1479     def _filter_nic(nic):
1480         source_node = nic.find("source")
1481         source_attrib = source_node.attrib if source_node is not None else {}
1482         source_type = "network" if "network" in source_attrib else nic.attrib["type"]
1483         source_getters = {
1484             "network": lambda n: n.get("network"),
1485             "bridge": lambda n: n.get("bridge"),
1486             "direct": lambda n: n.get("dev"),
1487             "hostdev": lambda n: _format_pci_address(n.find("address")),
1488         }
1489         return {
1490             "type": source_type,
1491             "source": source_getters[source_type](source_node)
1492             if source_node is not None
1493             else None,
1494             "model": nic.find("model").attrib["type"]
1495             if nic.find("model") is not None
1496             else None,
1497         }
1498     def _get_mac(nic):
1499         return (
1500             nic.find("mac").attrib["address"].lower()
1501             if nic.find("mac") is not None
1502             else None
1503         )
1504     mac1 = _get_mac(nic1)
1505     mac2 = _get_mac(nic2)
1506     macs_equal = not mac1 or not mac2 or mac1 == mac2
1507     return _filter_nic(nic1) == _filter_nic(nic2) and macs_equal
1508 def _graphics_equal(gfx1, gfx2):
1509     def _filter_graphics(gfx):
1510         gfx_copy = copy.deepcopy(gfx)
1511         defaults = [
1512             {"node": ".", "attrib": "port", "values": ["5900", "-1"]},
1513             {"node": ".", "attrib": "address", "values": ["127.0.0.1"]},
1514             {"node": "listen", "attrib": "address", "values": ["127.0.0.1"]},
1515         ]
1516         for default in defaults:
1517             node = gfx_copy.find(default["node"])
1518             attrib = default["attrib"]
1519             if node is not None and (
1520                 attrib in node.attrib and node.attrib[attrib] in default["values"]
1521             ):
1522                 node.attrib.pop(attrib)
1523         return gfx_copy
1524     return xmlutil.to_dict(_filter_graphics(gfx1), True) == xmlutil.to_dict(
1525         _filter_graphics(gfx2), True
1526     )
1527 def _hostdevs_equal(dev1, dev2):
1528     def _filter_hostdevs(dev):
1529         type_ = dev.get("type")
1530         definition = {
1531             "type": type_,
1532         }
1533         if type_ == "pci":
1534             address_node = dev.find("./source/address")
1535             for attr in ["domain", "bus", "slot", "function"]:
1536                 definition[attr] = address_node.get(attr)
1537         elif type_ == "usb":
1538             for attr in ["vendor", "product"]:
1539                 definition[attr] = dev.find("./source/" + attr).get("id")
1540         return definition
1541     return _filter_hostdevs(dev1) == _filter_hostdevs(dev2)
1542 def _diff_lists(old, new, comparator):
1543     def _remove_indent(node):
1544         node_copy = copy.deepcopy(node)
1545         node_copy.text = None
1546         for item in node_copy.iter():
1547             item.tail = None
1548         return node_copy
1549     diff = {"unchanged": [], "new": [], "deleted": [], "sorted": []}
1550     old_devices = copy.deepcopy(old)
1551     for new_item in new:
1552         found = [
1553             item
1554             for item in old_devices
1555             if comparator(_remove_indent(item), _remove_indent(new_item))
1556 <a name="3"></a>        ]
1557         if found:
1558             old_devices.remove(found[0])
1559             diff<font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>["unchanged"].append(found[0])
1560             diff["sorted"].append(found[0])
1561         else:
1562             diff["new"].append(new_item)
1563             diff["sorted"].append(</b></font>new_item)
1564     diff["deleted"] = old_devices
1565     return diff
1566 def _get_disk_target(targets, disks_count, prefix):
1567     for i in range(disks_count):
1568         ret = "{}{}".format(prefix, string.ascii_lowercase[i])
1569         if ret not in targets:
1570             return ret
1571     return None
1572 def _diff_disk_lists(old, new):
1573     targets = []
1574     prefixes = ["fd", "hd", "vd", "sd", "xvd", "ubd"]
1575     for disk in new:
1576         target_node = disk.find("target")
1577         target = target_node.get("dev")
1578         prefix = [item for item in prefixes if target.startswith(item)][0]
1579         new_target = _get_disk_target(targets, len(new), prefix)
1580         target_node.set("dev", new_target)
1581         targets.append(new_target)
1582     return _diff_lists(old, new, _disks_equal)
1583 def _diff_interface_lists(old, new):
1584     return _diff_lists(old, new, _nics_equal)
1585 def _diff_graphics_lists(old, new):
1586     return _diff_lists(old, new, _graphics_equal)
1587 def _diff_hostdev_lists(old, new):
1588     return _diff_lists(old, new, _hostdevs_equal)
1589 def _expand_cpuset(cpuset):
1590     if cpuset is None:
1591         return None
1592     if isinstance(cpuset, int):
1593         return str(cpuset)
1594     result = set()
1595     toremove = set()
1596     for part in cpuset.split(","):
1597         m = re.match("([0-9]+)-([0-9]+)", part)
1598         if m:
1599             result |= set(range(int(m.group(1)), int(m.group(2)) + 1))
1600         elif part.startswith("^"):
1601             toremove.add(int(part[1:]))
1602         else:
1603             result.add(int(part))
1604     cpus = list(result - toremove)
1605     cpus.sort()
1606     cpus = [str(cpu) for cpu in cpus]
1607     return ",".join(cpus)
1608 def _normalize_cpusets(desc, data):
1609     xpaths = ["cputune/cachetune", "cputune/cachetune/monitor", "cputune/memorytune"]
1610     for xpath in xpaths:
1611         nodes = desc.findall(xpath)
1612         for node in nodes:
1613             node.set("vcpus", _expand_cpuset(node.get("vcpus")))
1614     if not isinstance(data.get("cpu"), dict):
1615         return
1616     tuning = data["cpu"].get("tuning", {})
1617     for child in ["cachetune", "memorytune"]:
1618         if tuning.get(child):
1619             new_item = dict()
1620             for cpuset, value in tuning[child].items():
1621                 if child == "cachetune" and value.get("monitor"):
1622                     value["monitor"] = {
1623                         _expand_cpuset(monitor_cpus): monitor
1624                         for monitor_cpus, monitor in value["monitor"].items()
1625                     }
1626                 new_item[_expand_cpuset(cpuset)] = value
1627             tuning[child] = new_item
1628 def _serial_or_concole_equal(old, new):
1629     def _filter_serial_or_concole(item):
1630         return {
1631             "type": item.attrib["type"],
1632             "port": item.find("source").get("service")
1633             if item.find("source") is not None
1634             else None,
1635             "protocol": item.find("protocol").get("type")
1636             if item.find("protocol") is not None
1637             else None,
1638         }
1639     return _filter_serial_or_concole(old) == _filter_serial_or_concole(new)
1640 def _diff_serial_lists(old, new):
1641     return _diff_lists(old, new, _serial_or_concole_equal)
1642 def _diff_console_lists(old, new):
1643     return _diff_lists(old, new, _serial_or_concole_equal)
1644 def _format_pci_address(node):
1645     return "{}:{}:{}.{}".format(
1646         node.get("domain").replace("0x", ""),
1647         node.get("bus").replace("0x", ""),
1648         node.get("slot").replace("0x", ""),
1649         node.get("function").replace("0x", ""),
1650     )
1651 def _almost_equal(current, new):
1652     if current is None or new is None:
1653         return False
1654     return abs(current - new) / current &lt; 1e-03
1655 def _compute_device_changes(old_xml, new_xml, to_skip):
1656     devices_node = old_xml.find("devices")
1657     changes = {}
1658     for dev_type in to_skip:
1659         changes[dev_type] = {}
1660         if not to_skip[dev_type]:
1661             old = devices_node.findall(dev_type)
1662             new = new_xml.findall("devices/{}".format(dev_type))
1663             changes[dev_type] = globals()["_diff_{}_lists".format(dev_type)](old, new)
1664     return changes
1665 def _get_pci_addresses(node):
1666     return {_format_pci_address(address) for address in node.findall(".//address")}
1667 def _correct_networks(conn, desc):
1668     networks = [ElementTree.fromstring(net.XMLDesc()) for net in conn.listAllNetworks()]
1669     nics = desc.findall("devices/interface")
1670     device_map = {}
1671     for nic in nics:
1672         if nic.get("type") == "hostdev":
1673             addr = _get_pci_addresses(nic.find("source"))
1674             matching_nets = [
1675                 net
1676                 for net in networks
1677                 if net.find("forward").get("mode") == "hostdev"
1678                 and addr &amp; _get_pci_addresses(net)
1679             ]
1680             if matching_nets:
1681                 old_xml = ElementTree.tostring(nic)
1682                 nic.set("type", "network")
1683                 nic.find("source").set("network", matching_nets[0].find("name").text)
1684                 device_map[nic] = old_xml
1685     return device_map
1686 def _update_live(domain, new_desc, mem, cpu, old_mem, old_cpu, to_skip, test):
1687     status = {}
1688     errors = []
1689     if not domain.isActive():
1690         return status, errors
1691     commands = []
1692     if cpu and (isinstance(cpu, int) or isinstance(cpu, dict) and cpu.get("maximum")):
1693         new_cpu = cpu.get("maximum") if isinstance(cpu, dict) else cpu
1694         if old_cpu != new_cpu and new_cpu is not None:
1695             commands.append(
1696                 {
1697                     "device": "cpu",
1698                     "cmd": "setVcpusFlags",
1699                     "args": [new_cpu, libvirt.VIR_DOMAIN_AFFECT_LIVE],
1700                 }
1701             )
1702     if mem:
1703         if isinstance(mem, dict):
1704             new_mem = (
1705                 int(_handle_unit(mem.get("current")) / 1024)
1706                 if "current" in mem
1707                 else None
1708             )
1709         elif isinstance(mem, int):
1710             new_mem = int(mem * 1024)
1711         if not _almost_equal(old_mem, new_mem) and new_mem is not None:
1712             commands.append(
1713                 {
1714                     "device": "mem",
1715                     "cmd": "setMemoryFlags",
1716                     "args": [new_mem, libvirt.VIR_DOMAIN_AFFECT_LIVE],
1717                 }
1718             )
1719     old_desc = ElementTree.fromstring(domain.XMLDesc(0))
1720     changed_devices = {"interface": _correct_networks(domain.connect(), old_desc)}
1721     changes = _compute_device_changes(old_desc, new_desc, to_skip)
1722     removable_changes = []
1723     new_disks = []
1724     for new_disk in changes["disk"].get("new", []):
1725         device = new_disk.get("device", "disk")
1726         if device not in ["cdrom", "floppy"]:
1727             new_disks.append(new_disk)
1728             continue
1729         target_dev = new_disk.find("target").get("dev")
1730         matching = [
1731             old_disk
1732             for old_disk in changes["disk"].get("deleted", [])
1733             if old_disk.get("device", "disk") == device
1734             and old_disk.find("target").get("dev") == target_dev
1735         ]
1736         if not matching:
1737             new_disks.append(new_disk)
1738         else:
1739             updated_disk = matching[0]
1740             changes["disk"]["deleted"].remove(updated_disk)
1741             removable_changes.append(updated_disk)
1742             source_node = updated_disk.find("source")
1743             new_source_node = new_disk.find("source")
1744             source_file = (
1745                 new_source_node.get("file") if new_source_node is not None else None
1746             )
1747             updated_disk.set("type", "file")
1748             if source_node is not None:
1749                 updated_disk.remove(source_node)
1750             if source_file:
1751                 ElementTree.SubElement(
1752                     updated_disk, "source", attrib={"file": source_file}
1753                 )
1754     changes["disk"]["new"] = new_disks
1755     for dev_type in ["disk", "interface", "hostdev"]:
1756         for added in changes[dev_type].get("new", []):
1757             commands.append(
1758                 {
1759                     "device": dev_type,
1760                     "cmd": "attachDevice",
1761                     "args": [xmlutil.element_to_str(added)],
1762                 }
1763             )
1764         for removed in changes[dev_type].get("deleted", []):
1765             removed_def = changed_devices.get(dev_type, {}).get(
1766                 removed, ElementTree.tostring(removed)
1767             )
1768             commands.append(
1769                 {
1770                     "device": dev_type,
1771                     "cmd": "detachDevice",
1772                     "args": [salt.utils.stringutils.to_str(removed_def)],
1773                 }
1774             )
1775     for updated_disk in removable_changes:
1776         commands.append(
1777             {
1778                 "device": "disk",
1779                 "cmd": "updateDeviceFlags",
1780                 "args": [xmlutil.element_to_str(updated_disk)],
1781             }
1782         )
1783     for cmd in commands:
1784         try:
1785             ret = 0 if test else getattr(domain, cmd["cmd"])(*cmd["args"])
1786             device_type = cmd["device"]
1787             if device_type in ["cpu", "mem"]:
1788                 status[device_type] = not ret
1789             else:
1790                 actions = {
1791                     "attachDevice": "attached",
1792                     "detachDevice": "detached",
1793                     "updateDeviceFlags": "updated",
1794                 }
1795                 device_status = status.setdefault(device_type, {})
1796                 cmd_status = device_status.setdefault(actions[cmd["cmd"]], [])
1797                 cmd_status.append(cmd["args"][0])
1798         except libvirt.libvirtError as err:
1799             errors.append(str(err))
1800     return status, errors
1801 def update(
1802     name,
1803     cpu=0,
1804     mem=0,
1805     disk_profile=None,
1806     disks=None,
1807     nic_profile=None,
1808     interfaces=None,
1809     graphics=None,
1810     live=True,
1811     boot=None,
1812     numatune=None,
1813     test=False,
1814     boot_dev=None,
1815     hypervisor_features=None,
1816     clock=None,
1817     serials=None,
1818     consoles=None,
1819     stop_on_reboot=False,
1820     host_devices=None,
1821     **kwargs
1822 ):
1823     status = {
1824         "definition": False,
1825         "disk": {"attached": [], "detached": [], "updated": []},
1826         "interface": {"attached": [], "detached": []},
1827     }
1828     conn = __get_conn(**kwargs)
1829     domain = _get_domain(conn, name)
1830     desc = ElementTree.fromstring(domain.XMLDesc(libvirt.VIR_DOMAIN_XML_INACTIVE))
1831     need_update = False
1832     hypervisor = desc.get("type")
1833     all_disks = _disk_profile(conn, disk_profile, hypervisor, disks, name)
1834     if boot is not None:
1835         boot = _handle_remote_boot_params(boot)
1836         if boot.get("efi", None) is not None:
1837             need_update = _handle_efi_param(boot, desc)
1838     new_desc = ElementTree.fromstring(
1839         _gen_xml(
1840             conn,
1841             name,
1842             cpu,
1843             mem or 0,
1844             all_disks,
1845             _get_merged_nics(hypervisor, nic_profile, interfaces),
1846             hypervisor,
1847             domain.OSType(),
1848             desc.find(".//os/type").get("arch"),
1849             graphics,
1850             boot,
1851             boot_dev,
1852             numatune,
1853             serials=serials,
1854             consoles=consoles,
1855             stop_on_reboot=stop_on_reboot,
1856             host_devices=host_devices,
1857             **kwargs
1858         )
1859     )
1860     if clock:
1861         offset = "utc" if clock.get("utc", True) else "localtime"
1862         if "timezone" in clock:
1863             offset = "timezone"
1864         clock["offset"] = offset
1865     def _set_loader(node, value):
1866         salt.utils.xmlutil.set_node_text(node, value)
1867         if value is not None:
1868             node.set("readonly", "yes")
1869             node.set("type", "pflash")
1870     def _set_nvram(node, value):
1871         node.set("template", value)
1872     def _set_with_byte_unit(attr_name=None):
1873         def _setter(node, value):
1874             if attr_name:
1875                 node.set(attr_name, str(value))
1876             else:
1877                 node.text = str(value)
1878             node.set("unit", "bytes")
1879         return _setter
1880     def _get_with_unit(node):
1881         unit = node.get("unit", "KiB")
1882         unit = unit if unit != "bytes" else "b"
1883         value = node.get("memory") or node.get("size") or node.text
1884         return _handle_unit("{}{}".format(value, unit)) if value else None
1885     def _set_vcpu(node, value):
1886         node.text = str(value)
1887         node.set("current", str(value))
1888     old_mem = int(_get_with_unit(desc.find("memory")) / 1024)
1889     old_cpu = int(desc.find("./vcpu").text)
1890     def _yesno_attribute(path, xpath, attr_name, ignored=None):
1891         return xmlutil.attribute(
1892             path, xpath, attr_name, ignored, lambda v: "yes" if v else "no"
1893         )
1894     def _memory_parameter(path, xpath, attr_name=None, ignored=None):
1895         entry = {
1896             "path": path,
1897             "xpath": xpath,
1898             "convert": _handle_unit,
1899             "get": _get_with_unit,
1900             "set": _set_with_byte_unit(attr_name),
1901             "equals": _almost_equal,
1902         }
1903         if attr_name:
1904             entry["del"] = salt.utils.xmlutil.del_attribute(attr_name, ignored)
1905         return entry
1906     def _cpuset_parameter(path, xpath, attr_name=None, ignored=None):
1907         def _set_cpuset(node, value):
1908             if attr_name:
1909                 node.set(attr_name, value)
1910             else:
1911                 node.text = value
1912         entry = {
1913             "path": path,
1914             "xpath": xpath,
1915             "convert": _expand_cpuset,
1916             "get": lambda n: _expand_cpuset(n.get(attr_name) if attr_name else n.text),
1917             "set": _set_cpuset,
1918         }
1919         if attr_name:
1920             entry["del"] = salt.utils.xmlutil.del_attribute(attr_name, ignored)
1921         return entry
1922     data = {k: v for k, v in locals().items() if bool(v)}
1923     data["stop_on_reboot"] = stop_on_reboot
1924     if boot_dev:
1925         data["boot_dev"] = boot_dev.split()
1926     timer_names = [
1927         "platform",
1928         "hpet",
1929         "kvmclock",
1930         "pit",
1931         "rtc",
1932         "tsc",
1933         "hypervclock",
1934         "armvtimer",
1935     ]
1936     if data.get("clock", {}).get("timers"):
1937         attributes = [
1938             "track",
1939             "tickpolicy",
1940             "frequency",
1941             "mode",
1942             "present",
1943             "slew",
1944             "threshold",
1945             "limit",
1946         ]
1947         for timer in data["clock"]["timers"].values():
1948             for attribute in attributes:
1949                 if attribute not in timer:
1950                     timer[attribute] = None
1951         for timer_name in timer_names:
1952             if timer_name not in data["clock"]["timers"]:
1953                 data["clock"]["timers"][timer_name] = None
1954     _normalize_cpusets(desc, data)
1955     params_mapping = [
1956         {
1957             "path": "stop_on_reboot",
1958             "xpath": "on_reboot",
1959             "convert": lambda v: "destroy" if v else "restart",
1960         },
1961         {"path": "boot:kernel", "xpath": "os/kernel"},
1962         {"path": "boot:initrd", "xpath": "os/initrd"},
1963         {"path": "boot:cmdline", "xpath": "os/cmdline"},
1964         {"path": "boot:loader", "xpath": "os/loader", "set": _set_loader},
1965         {"path": "boot:nvram", "xpath": "os/nvram", "set": _set_nvram},
1966         _memory_parameter("mem", "memory"),
1967         _memory_parameter("mem", "currentMemory"),
1968         _memory_parameter("mem:max", "maxMemory"),
1969         _memory_parameter("mem:boot", "memory"),
1970         _memory_parameter("mem:current", "currentMemory"),
1971         xmlutil.attribute("mem:slots", "maxMemory", "slots", ["unit"]),
1972         _memory_parameter("mem:hard_limit", "memtune/hard_limit"),
1973         _memory_parameter("mem:soft_limit", "memtune/soft_limit"),
1974         _memory_parameter("mem:swap_hard_limit", "memtune/swap_hard_limit"),
1975         _memory_parameter("mem:min_guarantee", "memtune/min_guarantee"),
1976         xmlutil.attribute("boot_dev:{dev}", "os/boot[$dev]", "dev"),
1977         _memory_parameter(
1978             "mem:hugepages:{id}:size",
1979             "memoryBacking/hugepages/page[$id]",
1980             "size",
1981             ["unit", "nodeset"],
1982         ),
1983         _cpuset_parameter(
1984             "mem:hugepages:{id}:nodeset", "memoryBacking/hugepages/page[$id]", "nodeset"
1985         ),
1986         {
1987             "path": "mem:nosharepages",
1988             "xpath": "memoryBacking/nosharepages",
1989             "get": lambda n: n is not None,
1990             "set": lambda n, v: None,
1991         },
1992         {
1993             "path": "mem:locked",
1994             "xpath": "memoryBacking/locked",
1995             "get": lambda n: n is not None,
1996             "set": lambda n, v: None,
1997         },
1998         xmlutil.attribute("mem:source", "memoryBacking/source", "type"),
1999         xmlutil.attribute("mem:access", "memoryBacking/access", "mode"),
2000         xmlutil.attribute("mem:allocation", "memoryBacking/allocation", "mode"),
2001         {"path": "mem:discard", "xpath": "memoryBacking/discard"},
2002         {
2003             "path": "cpu",
2004             "xpath": "vcpu",
2005             "get": lambda n: int(n.text),
2006             "set": _set_vcpu,
2007         },
2008         {"path": "cpu:maximum", "xpath": "vcpu", "get": lambda n: int(n.text)},
2009         xmlutil.attribute("cpu:placement", "vcpu", "placement"),
2010         _cpuset_parameter("cpu:cpuset", "vcpu", "cpuset"),
2011         xmlutil.attribute("cpu:current", "vcpu", "current"),
2012         xmlutil.attribute("cpu:match", "cpu", "match"),
2013         xmlutil.attribute("cpu:mode", "cpu", "mode"),
2014         xmlutil.attribute("cpu:check", "cpu", "check"),
2015         {"path": "cpu:model:name", "xpath": "cpu/model"},
2016         xmlutil.attribute("cpu:model:fallback", "cpu/model", "fallback"),
2017         xmlutil.attribute("cpu:model:vendor_id", "cpu/model", "vendor_id"),
2018         {"path": "cpu:vendor", "xpath": "cpu/vendor"},
2019         xmlutil.attribute("cpu:topology:sockets", "cpu/topology", "sockets"),
2020         xmlutil.attribute("cpu:topology:cores", "cpu/topology", "cores"),
2021         xmlutil.attribute("cpu:topology:threads", "cpu/topology", "threads"),
2022         xmlutil.attribute("cpu:cache:level", "cpu/cache", "level"),
2023         xmlutil.attribute("cpu:cache:mode", "cpu/cache", "mode"),
2024         xmlutil.attribute(
2025             "cpu:features:{id}", "cpu/feature[@name='$id']", "policy", ["name"]
2026         ),
2027         _yesno_attribute(
2028             "cpu:vcpus:{id}:enabled", "vcpus/vcpu[@id='$id']", "enabled", ["id"]
2029         ),
2030         _yesno_attribute(
2031             "cpu:vcpus:{id}:hotpluggable",
2032             "vcpus/vcpu[@id='$id']",
2033             "hotpluggable",
2034             ["id"],
2035         ),
2036         xmlutil.int_attribute(
2037             "cpu:vcpus:{id}:order", "vcpus/vcpu[@id='$id']", "order", ["id"]
2038         ),
2039         _cpuset_parameter(
2040             "cpu:numa:{id}:cpus", "cpu/numa/cell[@id='$id']", "cpus", ["id"]
2041         ),
2042         _memory_parameter(
2043             "cpu:numa:{id}:memory", "cpu/numa/cell[@id='$id']", "memory", ["id"]
2044         ),
2045 <a name="4"></a>        _yesno_attribute(
2046             "cpu:numa:{id}:discard", "cpu/numa/cell[@id='$id']", "discard", ["id"]
2047         ),
2048         xmlutil<font color="#6cc417"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.attribute(
2049             "cpu:numa:{id}:memAccess", "cpu/numa/cell[@id='$id']", "memAccess", ["id"]
2050         ),
2051         xmlutil.attribute(
2052             "cpu:numa:{id}:distances:{sid}",
2053             "cpu/numa/cell[@id='$id']/distances/sibling[@id='$sid']",
2054             "value",
2055             ["id"],
2056         ),
2057         {"path": "cpu:iothreads", "xpath": "iothreads"},
2058         {"path": "cpu:tuning:shares", "xpath": "cputune/shares"},
2059         {"path": "cpu:tuning:period", "xpath": "cputune/period"},
2060         {"path": "cpu:tuning:quota", "xpath": "cputune/quota"},
2061         {"path": "cpu:tuning:global_period", "xpath": "cputune/global_period"},
2062         {"path": "cpu:tuning:global_quota", "xpath": "cputune/global_quota"},
2063         {"path": "cpu:tuning:emulator_period", "xpath": "cputune/emulator_period"},
2064         {"path": "cpu:tuning:emulator_quota", "xpath": "cputune/emulator_quota"},
2065         {"path": "cpu:tuning:iothread_period", "xpath": "cputune/iothread_period"},
2066         {"path"</b></font>: "cpu:tuning:iothread_quota", "xpath": "cputune/iothread_quota"},
2067         _cpuset_parameter(
2068             "cpu:tuning:vcpupin:{id}",
2069             "cputune/vcpupin[@vcpu='$id']",
2070             "cpuset",
2071             ["vcpu"],
2072         ),
2073         _cpuset_parameter("cpu:tuning:emulatorpin", "cputune/emulatorpin", "cpuset"),
2074         _cpuset_parameter(
2075             "cpu:tuning:iothreadpin:{id}",
2076             "cputune/iothreadpin[@iothread='$id']",
2077             "cpuset",
2078             ["iothread"],
2079         ),
2080         xmlutil.attribute(
2081             "cpu:tuning:vcpusched:{id}:scheduler",
2082             "cputune/vcpusched[$id]",
2083             "scheduler",
2084             ["priority", "vcpus"],
2085         ),
2086         xmlutil.attribute(
2087             "cpu:tuning:vcpusched:{id}:priority", "cputune/vcpusched[$id]", "priority"
2088         ),
2089         _cpuset_parameter(
2090             "cpu:tuning:vcpusched:{id}:vcpus", "cputune/vcpusched[$id]", "vcpus"
2091         ),
2092         xmlutil.attribute(
2093             "cpu:tuning:iothreadsched:{id}:scheduler",
2094             "cputune/iothreadsched[$id]",
2095             "scheduler",
2096             ["priority", "iothreads"],
2097         ),
2098         xmlutil.attribute(
2099             "cpu:tuning:iothreadsched:{id}:priority",
2100             "cputune/iothreadsched[$id]",
2101             "priority",
2102         ),
2103         _cpuset_parameter(
2104             "cpu:tuning:iothreadsched:{id}:iothreads",
2105             "cputune/iothreadsched[$id]",
2106             "iothreads",
2107         ),
2108         xmlutil.attribute(
2109             "cpu:tuning:emulatorsched:scheduler",
2110             "cputune/emulatorsched",
2111             "scheduler",
2112             ["priority"],
2113         ),
2114         xmlutil.attribute(
2115             "cpu:tuning:emulatorsched:priority", "cputune/emulatorsched", "priority"
2116         ),
2117         xmlutil.attribute(
2118             "cpu:tuning:cachetune:{id}:monitor:{sid}",
2119             "cputune/cachetune[@vcpus='$id']/monitor[@vcpus='$sid']",
2120             "level",
2121             ["vcpus"],
2122         ),
2123         xmlutil.attribute(
2124             "cpu:tuning:memorytune:{id}:{sid}",
2125             "cputune/memorytune[@vcpus='$id']/node[@id='$sid']",
2126             "bandwidth",
2127             ["id", "vcpus"],
2128         ),
2129         xmlutil.attribute("clock:offset", "clock", "offset"),
2130         xmlutil.attribute("clock:adjustment", "clock", "adjustment", convert=str),
2131         xmlutil.attribute("clock:timezone", "clock", "timezone"),
2132     ]
2133     for timer in timer_names:
2134         params_mapping += [
2135             xmlutil.attribute(
2136                 "clock:timers:{}:track".format(timer),
2137                 "clock/timer[@name='{}']".format(timer),
2138                 "track",
2139                 ["name"],
2140             ),
2141             xmlutil.attribute(
2142                 "clock:timers:{}:tickpolicy".format(timer),
2143                 "clock/timer[@name='{}']".format(timer),
2144                 "tickpolicy",
2145                 ["name"],
2146             ),
2147             xmlutil.int_attribute(
2148                 "clock:timers:{}:frequency".format(timer),
2149                 "clock/timer[@name='{}']".format(timer),
2150                 "frequency",
2151                 ["name"],
2152             ),
2153             xmlutil.attribute(
2154                 "clock:timers:{}:mode".format(timer),
2155                 "clock/timer[@name='{}']".format(timer),
2156                 "mode",
2157                 ["name"],
2158             ),
2159             _yesno_attribute(
2160                 "clock:timers:{}:present".format(timer),
2161                 "clock/timer[@name='{}']".format(timer),
2162                 "present",
2163                 ["name"],
2164             ),
2165         ]
2166         for attr in ["slew", "threshold", "limit"]:
2167             params_mapping.append(
2168                 xmlutil.int_attribute(
2169                     "clock:timers:{}:{}".format(timer, attr),
2170                     "clock/timer[@name='{}']/catchup".format(timer),
2171                     attr,
2172                 )
2173             )
2174     for attr in ["level", "type", "size"]:
2175         params_mapping.append(
2176             xmlutil.attribute(
2177                 "cpu:tuning:cachetune:{id}:{sid}:" + attr,
2178                 "cputune/cachetune[@vcpus='$id']/cache[@id='$sid']",
2179                 attr,
2180                 ["id", "unit", "vcpus"],
2181             )
2182         )
2183     if hypervisor in ["qemu", "kvm"]:
2184         params_mapping += [
2185             xmlutil.attribute("numatune:memory:mode", "numatune/memory", "mode"),
2186             _cpuset_parameter("numatune:memory:nodeset", "numatune/memory", "nodeset"),
2187             xmlutil.attribute(
2188                 "numatune:memnodes:{id}:mode",
2189                 "numatune/memnode[@cellid='$id']",
2190                 "mode",
2191                 ["cellid"],
2192             ),
2193             _cpuset_parameter(
2194                 "numatune:memnodes:{id}:nodeset",
2195                 "numatune/memnode[@cellid='$id']",
2196                 "nodeset",
2197                 ["cellid"],
2198             ),
2199             xmlutil.attribute(
2200                 "hypervisor_features:kvm-hint-dedicated",
2201                 "features/kvm/hint-dedicated",
2202                 "state",
2203                 convert=lambda v: "on" if v else "off",
2204             ),
2205         ]
2206     need_update = (
2207         salt.utils.xmlutil.change_xml(desc, data, params_mapping) or need_update
2208     )
2209     devices_node = desc.find("devices")
2210     func_locals = locals()
2211     def _skip_update(names):
2212         return all(func_locals.get(n) is None for n in names)
2213     to_skip = {
2214         "disk": _skip_update(["disks", "disk_profile"]),
2215         "interface": _skip_update(["interfaces", "nic_profile"]),
2216         "graphics": _skip_update(["graphics"]),
2217         "serial": _skip_update(["serials"]),
2218         "console": _skip_update(["consoles"]),
2219         "hostdev": _skip_update(["host_devices"]),
2220     }
2221     changes = _compute_device_changes(desc, new_desc, to_skip)
2222     for dev_type in changes:
2223         if not to_skip[dev_type]:
2224             old = devices_node.findall(dev_type)
2225             if changes[dev_type].get("deleted") or changes[dev_type].get("new"):
2226                 for item in old:
2227                     devices_node.remove(item)
2228                 devices_node.extend(changes[dev_type]["sorted"])
2229                 need_update = True
2230     if need_update:
2231         try:
2232             if changes["disk"]:
2233                 for idx, item in enumerate(changes["disk"]["sorted"]):
2234                     source_file = all_disks[idx].get("source_file")
2235                     if all_disks[idx].get("device", "disk") == "cdrom":
2236                         continue
2237                     if (
2238                         item in changes["disk"]["new"]
2239                         and source_file
2240                         and not os.path.exists(source_file)
2241                     ):
2242                         _qemu_image_create(all_disks[idx])
2243                     elif item in changes["disk"]["new"] and not source_file:
2244                         _disk_volume_create(conn, all_disks[idx])
2245             if not test:
2246                 xml_desc = xmlutil.element_to_str(desc)
2247                 log.debug("Update virtual machine definition: %s", xml_desc)
2248                 conn.defineXML(xml_desc)
2249             status["definition"] = True
2250         except libvirt.libvirtError as err:
2251             conn.close()
2252             raise err
2253     if live:
2254         live_status, errors = _update_live(
2255             domain, new_desc, mem, cpu, old_mem, old_cpu, to_skip, test
2256         )
2257         status.update(live_status)
2258         if errors:
2259             status_errors = status.setdefault("errors", [])
2260             status_errors += errors
2261     conn.close()
2262     return status
2263 def list_domains(**kwargs):
2264     vms = []
2265     conn = __get_conn(**kwargs)
2266     for dom in _get_domain(conn, iterable=True):
2267         vms.append(dom.name())
2268     conn.close()
2269     return vms
2270 def list_active_vms(**kwargs):
2271     vms = []
2272     conn = __get_conn(**kwargs)
2273     for dom in _get_domain(conn, iterable=True, inactive=False):
2274         vms.append(dom.name())
2275     conn.close()
2276     return vms
2277 def list_inactive_vms(**kwargs):
2278     vms = []
2279     conn = __get_conn(**kwargs)
2280     for dom in _get_domain(conn, iterable=True, active=False):
2281         vms.append(dom.name())
2282     conn.close()
2283     return vms
2284 def vm_info(vm_=None, **kwargs):
2285     def _info(conn, dom):
2286         raw = dom.info()
2287         return {
2288             "cpu": raw[3],
2289             "cputime": int(raw[4]),
2290             "disks": _get_disks(conn, dom),
2291             "graphics": _get_graphics(dom),
2292             "nics": _get_nics(dom),
2293             "uuid": _get_uuid(dom),
2294             "loader": _get_loader(dom),
2295             "on_crash": _get_on_crash(dom),
2296             "on_reboot": _get_on_reboot(dom),
2297             "on_poweroff": _get_on_poweroff(dom),
2298             "maxMem": int(raw[1]),
2299             "mem": int(raw[2]),
2300             "state": VIRT_STATE_NAME_MAP.get(raw[0], "unknown"),
2301         }
2302     info = {}
2303     conn = __get_conn(**kwargs)
2304     if vm_:
2305         info[vm_] = _info(conn, _get_domain(conn, vm_))
2306     else:
2307         for domain in _get_domain(conn, iterable=True):
2308             info[domain.name()] = _info(conn, domain)
2309     conn.close()
2310     return info
2311 def vm_state(vm_=None, **kwargs):
2312     def _info(dom):
2313         state = ""
2314         raw = dom.info()
2315         state = VIRT_STATE_NAME_MAP.get(raw[0], "unknown")
2316         return state
2317     info = {}
2318     conn = __get_conn(**kwargs)
2319     if vm_:
2320         info[vm_] = _info(_get_domain(conn, vm_))
2321     else:
2322         for domain in _get_domain(conn, iterable=True):
2323             info[domain.name()] = _info(domain)
2324     conn.close()
2325     return info
2326 def _node_info(conn):
2327     raw = conn.getInfo()
2328     info = {
2329         "cpucores": raw[6],
2330         "cpumhz": raw[3],
2331         "cpumodel": str(raw[0]),
2332         "cpus": raw[2],
2333         "cputhreads": raw[7],
2334         "numanodes": raw[4],
2335         "phymemory": raw[1],
2336         "sockets": raw[5],
2337     }
2338     return info
2339 def node_info(**kwargs):
2340     conn = __get_conn(**kwargs)
2341     info = _node_info(conn)
2342     conn.close()
2343     return info
2344 def _node_devices(conn):
2345     devices = conn.listAllDevices()
2346     devices_infos = []
2347     for dev in devices:
2348         root = ElementTree.fromstring(dev.XMLDesc())
2349         if not set(dev.listCaps()) &amp; {"pci", "usb_device", "net"}:
2350             continue
2351         infos = {
2352             "caps": " ".join(dev.listCaps()),
2353         }
2354         if "net" in dev.listCaps():
2355             parent = root.find(".//parent").text
2356             if parent == "computer":
2357                 continue
2358             infos<font color="#c58917"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.update(
2359                 {
2360                     "name": root.find(".//interface").text,
2361                     "address": root.find(".//address").text,
2362                     "device name": parent,
2363                     "state": root.find(".//link").</b></font>get("state"),
2364                 }
2365             )
2366             devices_infos.append(infos)
2367             continue
2368         vendor_node = root.find(".//vendor")
2369         vendor_id = vendor_node.get("id").lower()
2370         product_node = root.find(".//product")
2371         product_id = product_node.get("id").lower()
2372         infos.update(
2373             {"name": dev.name(), "vendor_id": vendor_id, "product_id": product_id}
2374         )
2375         if vendor_node.text:
2376             infos["vendor"] = vendor_node.text
2377         if product_node.text:
2378             infos["product"] = product_node.text
2379         if "pci" in dev.listCaps():
2380             infos["address"] = "{:04x}:{:02x}:{:02x}.{}".format(
2381                 int(root.find(".//domain").text),
2382                 int(root.find(".//bus").text),
2383                 int(root.find(".//slot").text),
2384                 root.find(".//function").text,
2385             )
2386             class_node = root.find(".//class")
2387             if class_node is not None:
2388                 infos["PCI class"] = class_node.text
2389             vf_addresses = [
2390                 _format_pci_address(vf)
2391                 for vf in root.findall(
2392                     "./capability[@type='pci']/capability[@type='virt_functions']/address"
2393                 )
2394             ]
2395             if vf_addresses:
2396                 infos["virtual functions"] = vf_addresses
2397             pf = root.find(
2398                 "./capability[@type='pci']/capability[@type='phys_function']/address"
2399             )
2400             if pf is not None:
2401                 infos["physical function"] = _format_pci_address(pf)
2402         elif "usb_device" in dev.listCaps():
2403             infos["address"] = "{:03}:{:03}".format(
2404                 int(root.find(".//bus").text), int(root.find(".//device").text)
2405             )
2406         linux_usb_host = vendor_id == "0x1d6b" and product_id in [
2407             "0x0001",
2408             "0x0002",
2409             "0x0003",
2410         ]
2411         if (
2412             root.find(".//capability[@type='pci-bridge']") is None
2413             and not linux_usb_host
2414         ):
2415             devices_infos.append(infos)
2416     return devices_infos
2417 def node_devices(**kwargs):
2418     conn = __get_conn(**kwargs)
2419     devs = _node_devices(conn)
2420     conn.close()
2421     return devs
2422 def get_nics(vm_, **kwargs):
2423     conn = __get_conn(**kwargs)
2424     nics = _get_nics(_get_domain(conn, vm_))
2425     conn.close()
2426     return nics
2427 def get_macs(vm_, **kwargs):
2428     doc = ElementTree.fromstring(get_xml(vm_, **kwargs))
2429     return [node.get("address") for node in doc.findall("devices/interface/mac")]
2430 def get_graphics(vm_, **kwargs):
2431     conn = __get_conn(**kwargs)
2432     graphics = _get_graphics(_get_domain(conn, vm_))
2433     conn.close()
2434     return graphics
2435 def get_loader(vm_, **kwargs):
2436     conn = __get_conn(**kwargs)
2437     try:
2438         loader = _get_loader(_get_domain(conn, vm_))
2439         return loader
2440     finally:
2441         conn.close()
2442 def get_disks(vm_, **kwargs):
2443     conn = __get_conn(**kwargs)
2444     disks = _get_disks(conn, _get_domain(conn, vm_))
2445     conn.close()
2446     return disks
2447 def setmem(vm_, memory, config=False, **kwargs):
2448     conn = __get_conn(**kwargs)
2449     dom = _get_domain(conn, vm_)
2450     if VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown":
2451         return False
2452     flags = libvirt.VIR_DOMAIN_MEM_MAXIMUM
2453     if config:
2454         flags = flags | libvirt.VIR_DOMAIN_AFFECT_CONFIG
2455     ret1 = dom.setMemoryFlags(memory * 1024, flags)
2456     ret2 = dom.setMemoryFlags(memory * 1024, libvirt.VIR_DOMAIN_AFFECT_CURRENT)
2457     conn.close()
2458     return ret1 == ret2 == 0
2459 def setvcpus(vm_, vcpus, config=False, **kwargs):
2460     conn = __get_conn(**kwargs)
2461     dom = _get_domain(conn, vm_)
2462     if VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown":
2463         return False
2464     flags = libvirt.VIR_DOMAIN_VCPU_MAXIMUM
2465     if config:
2466         flags = flags | libvirt.VIR_DOMAIN_AFFECT_CONFIG
2467     ret1 = dom.setVcpusFlags(vcpus, flags)
2468     ret2 = dom.setVcpusFlags(vcpus, libvirt.VIR_DOMAIN_AFFECT_CURRENT)
2469     conn.close()
2470     return ret1 == ret2 == 0
2471 def _freemem(conn):
2472     mem = conn.getInfo()[1]
2473     mem -= 256
2474     for dom in _get_domain(conn, iterable=True):
2475         if dom.ID() &gt; 0:
2476             mem -= dom.info()[2] / 1024
2477     return mem
2478 def freemem(**kwargs):
2479     conn = __get_conn(**kwargs)
2480     mem = _freemem(conn)
2481     conn.close()
2482     return mem
2483 def _freecpu(conn):
2484     cpus = conn.getInfo()[2]
2485     for dom in _get_domain(conn, iterable=True):
2486         if dom.ID() &gt; 0:
2487             cpus -= dom.info()[3]
2488     return cpus
2489 def freecpu(**kwargs):
2490     conn = __get_conn(**kwargs)
2491     cpus = _freecpu(conn)
2492     conn.close()
2493     return cpus
2494 def full_info(**kwargs):
2495     conn = __get_conn(**kwargs)
2496     info = {
2497         "freecpu": _freecpu(conn),
2498         "freemem": _freemem(conn),
2499         "node_info": _node_info(conn),
2500         "vm_info": vm_info(),
2501     }
2502     conn.close()
2503     return info
2504 def get_xml(vm_, **kwargs):
2505     conn = __get_conn(**kwargs)
2506     xml_desc = (
2507         vm_.XMLDesc(0)
2508         if isinstance(vm_, libvirt.virDomain)
2509         else _get_domain(conn, vm_).XMLDesc(0)
2510     )
2511     conn.close()
2512     return xml_desc
2513 def get_profiles(hypervisor=None, **kwargs):
2514     conn = __get_conn(**kwargs)
2515     caps = _capabilities(conn)
2516     hypervisors = sorted(
2517         {
2518             x
2519             for y in [guest["arch"]["domains"].keys() for guest in caps["guests"]]
2520             for x in y
2521         }
2522     )
2523     if len(hypervisors) == 0:
2524         raise SaltInvocationError("No supported hypervisors were found")
2525     if not hypervisor:
2526         hypervisor = "kvm" if "kvm" in hypervisors else hypervisors[0]
2527     ret = {
2528         "disk": {"default": _disk_profile(conn, "default", hypervisor, [], None)},
2529         "nic": {"default": _nic_profile("default", hypervisor)},
2530     }
2531     virtconf = __salt__["config.get"]("virt", {})
2532     for profile in virtconf.get("disk", []):
2533         ret["disk"][profile] = _disk_profile(conn, profile, hypervisor, [], None)
2534     for profile in virtconf.get("nic", []):
2535         ret["nic"][profile] = _nic_profile(profile, hypervisor)
2536     return ret
2537 def shutdown(vm_, **kwargs):
2538     conn = __get_conn(**kwargs)
2539     dom = _get_domain(conn, vm_)
2540     ret = dom.shutdown() == 0
2541     conn.close()
2542     return ret
2543 def pause(vm_, **kwargs):
2544     conn = __get_conn(**kwargs)
2545     dom = _get_domain(conn, vm_)
2546     ret = dom.suspend() == 0
2547     conn.close()
2548     return ret
2549 def resume(vm_, **kwargs):
2550     conn = __get_conn(**kwargs)
2551     dom = _get_domain(conn, vm_)
2552     ret = dom.resume() == 0
2553     conn.close()
2554     return ret
2555 def start(name, **kwargs):
2556     conn = __get_conn(**kwargs)
2557     ret = _get_domain(conn, name).create() == 0
2558     conn.close()
2559     return ret
2560 def stop(name, **kwargs):
2561     conn = __get_conn(**kwargs)
2562     ret = _get_domain(conn, name).destroy() == 0
2563     conn.close()
2564     return ret
2565 def reboot(name, **kwargs):
2566     conn = __get_conn(**kwargs)
2567     ret = _get_domain(conn, name).reboot(libvirt.VIR_DOMAIN_REBOOT_DEFAULT) == 0
2568     conn.close()
2569     return ret
2570 def reset(vm_, **kwargs):
2571     conn = __get_conn(**kwargs)
2572     dom = _get_domain(conn, vm_)
2573     ret = dom.reset(0) == 0
2574     conn.close()
2575     return ret
2576 def ctrl_alt_del(vm_, **kwargs):
2577     conn = __get_conn(**kwargs)
2578     dom = _get_domain(conn, vm_)
2579     ret = dom.sendKey(0, 0, [29, 56, 111], 3, 0) == 0
2580     conn.close()
2581     return ret
2582 def create_xml_str(xml, **kwargs):  # pylint: disable=redefined-outer-name
2583     conn = __get_conn(**kwargs)
2584     ret = conn.createXML(xml, 0) is not None
2585     conn.close()
2586     return ret
2587 def create_xml_path(path, **kwargs):
2588     try:
2589         with salt.utils.files.fopen(path, "r") as fp_:
2590             return create_xml_str(
2591                 salt.utils.stringutils.to_unicode(fp_.read()), **kwargs
2592             )
2593     except OSError:
2594         return False
2595 def define_xml_str(xml, **kwargs):  # pylint: disable=redefined-outer-name
2596     conn = __get_conn(**kwargs)
2597     ret = conn.defineXML(xml) is not None
2598     conn.close()
2599     return ret
2600 def define_xml_path(path, **kwargs):
2601     try:
2602         with salt.utils.files.fopen(path, "r") as fp_:
2603             return define_xml_str(
2604                 salt.utils.stringutils.to_unicode(fp_.read()), **kwargs
2605             )
2606     except OSError:
2607         return False
2608 def _define_vol_xml_str(conn, xml, pool=None):  # pylint: disable=redefined-outer-name
2609     default_pool = "default" if conn.getType() != "ESX" else "0"
2610     poolname = (
2611         pool if pool else __salt__["config.get"]("virt:storagepool", default_pool)
2612     )
2613     pool = conn.storagePoolLookupByName(str(poolname))
2614     ret = pool.createXML(xml, 0) is not None
2615     return ret
2616 def define_vol_xml_str(
2617     xml, pool=None, **kwargs
2618 ):  # pylint: disable=redefined-outer-name
2619     conn = __get_conn(**kwargs)
2620     ret = False
2621     try:
2622         ret = _define_vol_xml_str(conn, xml, pool=pool)
2623     except libvirtError as err:
2624         raise CommandExecutionError(err.get_error_message())
2625     finally:
2626         conn.close()
2627     return ret
2628 def define_vol_xml_path(path, pool=None, **kwargs):
2629     try:
2630         with salt.utils.files.fopen(path, "r") as fp_:
2631             return define_vol_xml_str(
2632                 salt.utils.stringutils.to_unicode(fp_.read()), pool=pool, **kwargs
2633             )
2634     except OSError:
2635         return False
2636 def migrate(vm_, target, **kwargs):
2637     conn = __get_conn()
2638     dom = _get_domain(conn, vm_)
2639     if not urllib.parse.urlparse(target).scheme:
2640         proto = "qemu"
2641         dst_uri = "{}://{}/system".format(proto, target)
2642     else:
2643         dst_uri = target
2644     ret = _migrate(dom, dst_uri, **kwargs)
2645     conn.close()
2646     return ret
2647 def migrate_start_postcopy(vm_):
2648     conn = __get_conn()
2649     dom = _get_domain(conn, vm_)
2650     try:
2651         dom.migrateStartPostCopy()
2652     except libvirt.libvirtError as err:
2653         conn.close()
2654         raise CommandExecutionError(err.get_error_message())
2655     conn.close()
2656 def seed_non_shared_migrate(disks, force=False):
2657     for _, data in disks.items():
2658         fn_ = data["file"]
2659         form = data["file format"]
2660         size = data["virtual size"].split()[1][1:]
2661         if os.path.isfile(fn_) and not force:
2662             pre = salt.utils.yaml.safe_load(
2663                 subprocess.Popen(
2664                     ["qemu-img", "info", "arch"], stdout=subprocess.PIPE
2665                 ).communicate()[0]
2666             )
2667             if (
2668                 pre["file format"] != data["file format"]
2669                 and pre["virtual size"] != data["virtual size"]
2670             ):
2671                 return False
2672         if not os.path.isdir(os.path.dirname(fn_)):
2673             os.makedirs(os.path.dirname(fn_))
2674         if os.path.isfile(fn_):
2675             os.remove(fn_)
2676         subprocess.call(["qemu-img", "create", "-f", form, fn_, size])
2677         creds = _libvirt_creds()
2678         subprocess.call(["chown", "{user}:{group}".format(**creds), fn_])
2679     return True
2680 def set_autostart(vm_, state="on", **kwargs):
2681     conn = __get_conn(**kwargs)
2682     dom = _get_domain(conn, vm_)
2683     ret = False
2684     if state == "on":
2685         ret = dom.setAutostart(1) == 0
2686     elif state == "off":
2687         ret = dom.setAutostart(0) == 0
2688     conn.close()
2689     return ret
2690 def undefine(vm_, **kwargs):
2691     conn = __get_conn(**kwargs)
2692     dom = _get_domain(conn, vm_)
2693     if getattr(libvirt, "VIR_DOMAIN_UNDEFINE_NVRAM", False):
2694         ret = dom.undefineFlags(libvirt.VIR_DOMAIN_UNDEFINE_NVRAM) == 0
2695     else:
2696         ret = dom.undefine() == 0
2697     conn.close()
2698     return ret
2699 def purge(vm_, dirs=False, removables=False, **kwargs):
2700     conn = __get_conn(**kwargs)
2701     dom = _get_domain(conn, vm_)
2702     disks = _get_disks(conn, dom)
2703     if (
2704         VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown"
2705         and dom.destroy() != 0
2706     ):
2707         return False
2708     directories = set()
2709     for disk in disks:
2710         if not removables and disks[disk]["type"] in ["cdrom", "floppy"]:
2711             continue
2712         if disks[disk].get("zfs", False):
2713             time.sleep(3)
2714 <a name="1"></a>            fs_name = disks[disk]["file"][len("/dev/zvol/") :]
2715             log.info("Destroying VM ZFS volume %s", fs_name)
2716             __salt__["zfs.destroy"](name=fs_name, force=True)
2717         elif os<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.path.exists(disks[disk]["file"]):
2718             os.remove(disks[disk]["file"])
2719             directories.add(os.path.dirname(disks[disk][</b></font>"file"]))
2720         else:
2721             matcher = re.match("^(?P&lt;pool&gt;[^/]+)/(?P&lt;volume&gt;.*)$", disks[disk]["file"])
2722             if matcher:
2723                 pool_name = matcher.group("pool")
2724                 pool = None
2725                 if pool_name in conn.listStoragePools():
2726                     pool = conn.storagePoolLookupByName(pool_name)
2727                 if pool and matcher.group("volume") in pool.listVolumes():
2728                     volume = pool.storageVolLookupByName(matcher.group("volume"))
2729                     volume.delete()
2730     if dirs:
2731         for dir_ in directories:
2732             shutil.rmtree(dir_)
2733     if getattr(libvirt, "VIR_DOMAIN_UNDEFINE_NVRAM", False):
2734         try:
2735             dom.undefineFlags(libvirt.VIR_DOMAIN_UNDEFINE_NVRAM)
2736         except Exception:  # pylint: disable=broad-except
2737             dom.undefine()
2738     else:
2739         dom.undefine()
2740     conn.close()
2741     return True
2742 def virt_type():
2743     return __grains__["virtual"]
2744 def _is_kvm_hyper():
2745     if not os.path.exists("/dev/kvm"):
2746         return False
2747     return "libvirtd" in __salt__["cmd.run"](__grains__["ps"])
2748 def _is_xen_hyper():
2749     try:
2750         if __grains__["virtual_subtype"] != "Xen Dom0":
2751             return False
2752     except KeyError:
2753         return False
2754     try:
2755         with salt.utils.files.fopen("/proc/modules") as fp_:
2756             if "xen_" not in salt.utils.stringutils.to_unicode(fp_.read()):
2757                 return False
2758     except OSError:
2759         return False
2760     return "libvirtd" in __salt__["cmd.run"](__grains__["ps"])
2761 def get_hypervisor():
2762     hypervisors = ["kvm", "xen", "bhyve"]
2763     result = [
2764         hyper
2765         for hyper in hypervisors
2766         if getattr(sys.modules[__name__], "_is_{}_hyper".format(hyper))()
2767     ]
2768     return result[0] if result else None
2769 def _is_bhyve_hyper():
2770     sysctl_cmd = "sysctl hw.vmm.create"
2771     vmm_enabled = False
2772     try:
2773         stdout = subprocess.Popen(
2774             ["sysctl", "hw.vmm.create"], stdout=subprocess.PIPE
2775         ).communicate()[0]
2776         vmm_enabled = len(salt.utils.stringutils.to_str(stdout).split('"')[1]) != 0
2777     except IndexError:
2778         pass
2779     return vmm_enabled
2780 def is_hyper():
2781     if HAS_LIBVIRT:
2782         return _is_xen_hyper() or _is_kvm_hyper() or _is_bhyve_hyper()
2783     return False
2784 def vm_cputime(vm_=None, **kwargs):
2785     conn = __get_conn(**kwargs)
2786     host_cpus = conn.getInfo()[2]
2787     def _info(dom):
2788         raw = dom.info()
2789         vcpus = int(raw[3])
2790         cputime = int(raw[4])
2791         cputime_percent = 0
2792         if cputime:
2793             cputime_percent = (1.0e-7 * cputime / host_cpus) / vcpus
2794         return {
2795             "cputime": int(raw[4]),
2796             "cputime_percent": int("{:.0f}".format(cputime_percent)),
2797         }
2798     info = {}
2799     if vm_:
2800         info[vm_] = _info(_get_domain(conn, vm_))
2801     else:
2802         for domain in _get_domain(conn, iterable=True):
2803             info[domain.name()] = _info(domain)
2804     conn.close()
2805     return info
2806 def vm_netstats(vm_=None, **kwargs):
2807     def _info(dom):
2808         nics = _get_nics(dom)
2809         ret = {
2810             "rx_bytes": 0,
2811             "rx_packets": 0,
2812             "rx_errs": 0,
2813             "rx_drop": 0,
2814             "tx_bytes": 0,
2815             "tx_packets": 0,
2816             "tx_errs": 0,
2817             "tx_drop": 0,
2818         }
2819         for attrs in nics.values():
2820             if "target" in attrs:
2821                 dev = attrs["target"]
2822                 stats = dom.interfaceStats(dev)
2823                 ret["rx_bytes"] += stats[0]
2824                 ret["rx_packets"] += stats[1]
2825                 ret["rx_errs"] += stats[2]
2826                 ret["rx_drop"] += stats[3]
2827                 ret["tx_bytes"] += stats[4]
2828                 ret["tx_packets"] += stats[5]
2829                 ret["tx_errs"] += stats[6]
2830                 ret["tx_drop"] += stats[7]
2831         return ret
2832     info = {}
2833     conn = __get_conn(**kwargs)
2834     if vm_:
2835         info[vm_] = _info(_get_domain(conn, vm_))
2836     else:
2837         for domain in _get_domain(conn, iterable=True):
2838             info[domain.name()] = _info(domain)
2839     conn.close()
2840     return info
2841 def vm_diskstats(vm_=None, **kwargs):
2842     def get_disk_devs(dom):
2843         doc = ElementTree.fromstring(get_xml(dom, **kwargs))
2844         return [target.get("dev") for target in doc.findall("devices/disk/target")]
2845     def _info(dom):
2846         disks = get_disk_devs(dom)
2847         ret = {"rd_req": 0, "rd_bytes": 0, "wr_req": 0, "wr_bytes": 0, "errs": 0}
2848         for disk in disks:
2849             stats = dom.blockStats(disk)
2850             ret["rd_req"] += stats[0]
2851             ret["rd_bytes"] += stats[1]
2852             ret["wr_req"] += stats[2]
2853             ret["wr_bytes"] += stats[3]
2854             ret["errs"] += stats[4]
2855         return ret
2856     info = {}
2857     conn = __get_conn(**kwargs)
2858     if vm_:
2859         info[vm_] = _info(_get_domain(conn, vm_))
2860     else:
2861         for domain in _get_domain(conn, iterable=True, inactive=False):
2862             info[domain.name()] = _info(domain)
2863     conn.close()
2864     return info
2865 def _parse_snapshot_description(vm_snapshot, unix_time=False):
2866     ret = dict()
2867     tree = ElementTree.fromstring(vm_snapshot.getXMLDesc())
2868     for node in tree:
2869         if node.tag == "name":
2870             ret["name"] = node.text
2871         elif node.tag == "creationTime":
2872             ret["created"] = (
2873                 datetime.datetime.fromtimestamp(float(node.text)).isoformat(" ")
2874                 if not unix_time
2875                 else float(node.text)
2876             )
2877         elif node.tag == "state":
2878             ret["running"] = node.text == "running"
2879     ret["current"] = vm_snapshot.isCurrent() == 1
2880     return ret
2881 def list_snapshots(domain=None, **kwargs):
2882     ret = dict()
2883     conn = __get_conn(**kwargs)
2884     for vm_domain in _get_domain(conn, *(domain and [domain] or list()), iterable=True):
2885         ret[vm_domain.name()] = [
2886             _parse_snapshot_description(snap) for snap in vm_domain.listAllSnapshots()
2887         ] or "N/A"
2888     conn.close()
2889     return ret
2890 def snapshot(domain, name=None, suffix=None, **kwargs):
2891     if name and name.lower() == domain.lower():
2892         raise CommandExecutionError(
2893             "Virtual Machine {name} is already defined. "
2894             "Please choose another name for the snapshot".format(name=name)
2895         )
2896     if not name:
2897         name = "{domain}-{tsnap}".format(
2898             domain=domain, tsnap=time.strftime("%Y%m%d-%H%M%S", time.localtime())
2899         )
2900     if suffix:
2901         name = "{name}-{suffix}".format(name=name, suffix=suffix)
2902     doc = ElementTree.Element("domainsnapshot")
2903     n_name = ElementTree.SubElement(doc, "name")
2904     n_name.text = name
2905     conn = __get_conn(**kwargs)
2906     _get_domain(conn, domain).snapshotCreateXML(xmlutil.element_to_str(doc))
2907     conn.close()
2908     return {"name": name}
2909 def delete_snapshots(name, *names, **kwargs):
2910     deleted = dict()
2911     conn = __get_conn(**kwargs)
2912     domain = _get_domain(conn, name)
2913     for snap in domain.listAllSnapshots():
2914         if snap.getName() in names or not names:
2915             deleted[snap.getName()] = _parse_snapshot_description(snap)
2916             snap.delete()
2917     conn.close()
2918     available = {
2919         name: [_parse_snapshot_description(snap) for snap in domain.listAllSnapshots()]
2920         or "N/A"
2921     }
2922     return {"available": available, "deleted": deleted}
2923 def revert_snapshot(name, vm_snapshot=None, cleanup=False, **kwargs):
2924     ret = dict()
2925     conn = __get_conn(**kwargs)
2926     domain = _get_domain(conn, name)
2927     snapshots = domain.listAllSnapshots()
2928     _snapshots = list()
2929     for snap_obj in snapshots:
2930         _snapshots.append(
2931             {
2932                 "idx": _parse_snapshot_description(snap_obj, unix_time=True)["created"],
2933                 "ptr": snap_obj,
2934             }
2935         )
2936     snapshots = [
2937         w_ptr["ptr"]
2938         for w_ptr in sorted(_snapshots, key=lambda item: item["idx"], reverse=True)
2939     ]
2940     del _snapshots
2941     if not snapshots:
2942         conn.close()
2943         raise CommandExecutionError("No snapshots found")
2944     elif len(snapshots) == 1:
2945         conn.close()
2946         raise CommandExecutionError(
2947             "Cannot revert to itself: only one snapshot is available."
2948         )
2949     snap = None
2950     for p_snap in snapshots:
2951         if not vm_snapshot:
2952             if p_snap.isCurrent() and snapshots[snapshots.index(p_snap) + 1 :]:
2953                 snap = snapshots[snapshots.index(p_snap) + 1 :][0]
2954                 break
2955         elif p_snap.getName() == vm_snapshot:
2956             snap = p_snap
2957             break
2958     if not snap:
2959         conn.close()
2960         raise CommandExecutionError(
2961             snapshot
2962             and 'Snapshot "{}" not found'.format(vm_snapshot)
2963             or "No more previous snapshots available"
2964         )
2965     elif snap.isCurrent():
2966         conn.close()
2967         raise CommandExecutionError("Cannot revert to the currently running snapshot.")
2968     domain.revertToSnapshot(snap)
2969     ret["reverted"] = snap.getName()
2970     if cleanup:
2971         delete = list()
2972         for p_snap in snapshots:
2973             if p_snap.getName() != snap.getName():
2974                 delete.append(p_snap.getName())
2975                 p_snap.delete()
2976             else:
2977                 break
2978         ret["deleted"] = delete
2979     else:
2980         ret["deleted"] = "N/A"
2981     conn.close()
2982     return ret
2983 def _caps_add_machine(machines, node):
2984     maxcpus = node.get("maxCpus")
2985     canonical = node.get("canonical")
2986     name = node.text
2987     alternate_name = ""
2988     if canonical:
2989         alternate_name = name
2990         name = canonical
2991     machine = machines.get(name)
2992     if not machine:
2993         machine = {"alternate_names": []}
2994         if maxcpus:
2995             machine["maxcpus"] = int(maxcpus)
2996         machines[name] = machine
2997     if alternate_name:
2998         machine["alternate_names"].append(alternate_name)
2999 def _parse_caps_guest(guest):
3000     arch_node = guest.find("arch")
3001     result = {
3002         "os_type": guest.find("os_type").text,
3003         "arch": {"name": arch_node.get("name"), "machines": {}, "domains": {}},
3004     }
3005     child = None
3006     for child in arch_node:
3007         if child.tag == "wordsize":
3008             result["arch"]["wordsize"] = int(child.text)
3009         elif child.tag == "emulator":
3010             result["arch"]["emulator"] = child.text
3011         elif child.tag == "machine":
3012             _caps_add_machine(result["arch"]["machines"], child)
3013         elif child.tag == "domain":
3014             domain_type = child.get("type")
3015             domain = {"emulator": None, "machines": {}}
3016             emulator_node = child.find("emulator")
3017             if emulator_node is not None:
3018                 domain["emulator"] = emulator_node.text
3019             for machine in child.findall("machine"):
3020                 _caps_add_machine(domain["machines"], machine)
3021             result["arch"]["domains"][domain_type] = domain
3022     features_nodes = guest.find("features")
3023     if features_nodes is not None and child is not None:
3024         result["features"] = {
3025             child.tag: {
3026                 "toggle": child.get("toggle", "no") == "yes",
3027                 "default": child.get("default", "on") == "on",
3028             }
3029             for child in features_nodes
3030         }
3031     return result
3032 def _parse_caps_cell(cell):
3033     result = {"id": int(cell.get("id"))}
3034     mem_node = cell.find("memory")
3035     if mem_node is not None:
3036         unit = mem_node.get("unit", "KiB")
3037         memory = mem_node.text
3038         result["memory"] = "{} {}".format(memory, unit)
3039     pages = [
3040         {
3041             "size": "{} {}".format(page.get("size"), page.get("unit", "KiB")),
3042             "available": int(page.text),
3043         }
3044         for page in cell.findall("pages")
3045     ]
3046     if pages:
3047         result["pages"] = pages
3048     distances = {
3049         int(distance.get("id")): int(distance.get("value"))
3050         for distance in cell.findall("distances/sibling")
3051     }
3052     if distances:
3053         result["distances"] = distances
3054     cpus = []
3055     for cpu_node in cell.findall("cpus/cpu"):
3056         cpu = {"id": int(cpu_node.get("id"))}
3057         socket_id = cpu_node.get("socket_id")
3058         if socket_id:
3059             cpu["socket_id"] = int(socket_id)
3060         core_id = cpu_node.get("core_id")
3061         if core_id:
3062             cpu["core_id"] = int(core_id)
3063         siblings = cpu_node.get("siblings")
3064         if siblings:
3065             cpu["siblings"] = siblings
3066         cpus.append(cpu)
3067     if cpus:
3068         result["cpus"] = cpus
3069     return result
3070 def _parse_caps_bank(bank):
3071     result = {
3072         "id": int(bank.get("id")),
3073         "level": int(bank.get("level")),
3074         "type": bank.get("type"),
3075         "size": "{} {}".format(bank.get("size"), bank.get("unit")),
3076         "cpus": bank.get("cpus"),
3077     }
3078     controls = []
3079     for control in bank.findall("control"):
3080         unit = control.get("unit")
3081         result_control = {
3082             "granularity": "{} {}".format(control.get("granularity"), unit),
3083             "type": control.get("type"),
3084             "maxAllocs": int(control.get("maxAllocs")),
3085         }
3086         minimum = control.get("min")
3087         if minimum:
3088             result_control["min"] = "{} {}".format(minimum, unit)
3089         controls.append(result_control)
3090     if controls:
3091         result["controls"] = controls
3092     return result
3093 def _parse_caps_host(host):
3094     result = {}
3095     for child in host:
3096         if child.tag == "uuid":
3097             result["uuid"] = child.text
3098         elif child.tag == "cpu":
3099             cpu = {
3100                 "arch": child.find("arch").text
3101                 if child.find("arch") is not None
3102                 else None,
3103                 "model": child.find("model").text
3104                 if child.find("model") is not None
3105                 else None,
3106                 "vendor": child.find("vendor").text
3107                 if child.find("vendor") is not None
3108                 else None,
3109                 "features": [
3110                     feature.get("name") for feature in child.findall("feature")
3111                 ],
3112                 "pages": [
3113                     {"size": "{} {}".format(page.get("size"), page.get("unit", "KiB"))}
3114                     for page in child.findall("pages")
3115                 ],
3116             }
3117             microcode = child.find("microcode")
3118             if microcode is not None:
3119                 cpu["microcode"] = microcode.get("version")
3120             topology = child.find("topology")
3121             if topology is not None:
3122                 cpu["sockets"] = int(topology.get("sockets"))
3123                 cpu["cores"] = int(topology.get("cores"))
3124                 cpu["threads"] = int(topology.get("threads"))
3125             result["cpu"] = cpu
3126         elif child.tag == "power_management":
3127             result["power_management"] = [node.tag for node in child]
3128         elif child.tag == "migration_features":
3129             result["migration"] = {
3130                 "live": child.find("live") is not None,
3131                 "transports": [
3132                     node.text for node in child.findall("uri_transports/uri_transport")
3133                 ],
3134 <a name="7"></a>            }
3135         elif child.tag == "topology":
3136             result["topology"] <font color="#38a4a5"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= {
3137                 "cells": [
3138                     _parse_caps_cell(cell) for cell in child.findall("cells/cell")
3139                 ]
3140             }
3141         elif child.tag == "cache":
3142             result["cache"] = {
3143                 "banks": [_parse_caps_bank(bank) for bank in child.findall(</b></font>"bank")]
3144             }
3145 <a name="2"></a>    result["security"] = [
3146         {
3147             "model": secmodel.find("model").text
3148             if secmodel<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.find("model") is not None
3149             else None,
3150             "doi": secmodel.find("doi").text
3151             if secmodel.find("doi") is not None
3152             else None,
3153             "baselabels": [
3154                 {"type": label.get("type"), "label": label.text}
3155                 for label in secmodel.findall("baselabel")
3156             ],
3157         }
3158         for secmodel in host.</b></font>findall("secmodel")
3159     ]
3160     return result
3161 def _capabilities(conn):
3162     caps = ElementTree.fromstring(conn.getCapabilities())
3163     return {
3164         "host": _parse_caps_host(caps.find("host")),
3165         "guests": [_parse_caps_guest(guest) for guest in caps.findall("guest")],
3166     }
3167 def capabilities(**kwargs):
3168     conn = __get_conn(**kwargs)
3169     try:
3170         caps = _capabilities(conn)
3171     except libvirt.libvirtError as err:
3172         raise CommandExecutionError(str(err))
3173     finally:
3174         conn.close()
3175     return caps
3176 def _parse_caps_enum(node):
3177     return (node.get("name"), [value.text for value in node.findall("value")])
3178 def _parse_caps_cpu(node):
3179     result = {}
3180     for mode in node.findall("mode"):
3181         if not mode.get("supported") == "yes":
3182             continue
3183         name = mode.get("name")
3184         if name == "host-passthrough":
3185             result[name] = True
3186         elif name == "host-model":
3187             host_model = {}
3188             model_node = mode.find("model")
3189             if model_node is not None:
3190                 model = {"name": model_node.text}
3191                 vendor_id = model_node.get("vendor_id")
3192                 if vendor_id:
3193                     model["vendor_id"] = vendor_id
3194                 fallback = model_node.get("fallback")
3195                 if fallback:
3196                     model["fallback"] = fallback
3197                 host_model["model"] = model
3198             vendor = (
3199                 mode.find("vendor").text if mode.find("vendor") is not None else None
3200             )
3201             if vendor:
3202                 host_model["vendor"] = vendor
3203             features = {
3204                 feature.get("name"): feature.get("policy")
3205                 for feature in mode.findall("feature")
3206             }
3207             if features:
3208                 host_model["features"] = features
3209             result[name] = host_model
3210         elif name == "custom":
3211             custom_model = {}
3212             models = {
3213                 model.text: model.get("usable") for model in mode.findall("model")
3214             }
3215             if models:
3216                 custom_model["models"] = models
3217             result[name] = custom_model
3218     return result
3219 def _parse_caps_devices_features(node):
3220     result = {}
3221     for child in node:
3222         if child.get("supported") == "yes":
3223             enums = [_parse_caps_enum(node) for node in child.findall("enum")]
3224             result[child.tag] = {item[0]: item[1] for item in enums if item[0]}
3225     return result
3226 def _parse_caps_loader(node):
3227     enums = [_parse_caps_enum(enum) for enum in node.findall("enum")]
3228     result = {item[0]: item[1] for item in enums if item[0]}
3229     values = [child.text for child in node.findall("value")]
3230     if values:
3231         result["values"] = values
3232     return result
3233 def _parse_domain_caps(caps):
3234     result = {
3235         "emulator": caps.find("path").text if caps.find("path") is not None else None,
3236         "domain": caps.find("domain").text if caps.find("domain") is not None else None,
3237         "machine": caps.find("machine").text
3238         if caps.find("machine") is not None
3239         else None,
3240         "arch": caps.find("arch").text if caps.find("arch") is not None else None,
3241     }
3242     for child in caps:
3243         if child.tag == "vcpu" and child.get("max"):
3244             result["max_vcpus"] = int(child.get("max"))
3245         elif child.tag == "iothreads":
3246             result["iothreads"] = child.get("supported") == "yes"
3247         elif child.tag == "os":
3248             result["os"] = {}
3249             loader_node = child.find("loader")
3250             if loader_node is not None and loader_node.get("supported") == "yes":
3251                 loader = _parse_caps_loader(loader_node)
3252                 result["os"]["loader"] = loader
3253         elif child.tag == "cpu":
3254             cpu = _parse_caps_cpu(child)
3255             if cpu:
3256                 result["cpu"] = cpu
3257         elif child.tag == "devices":
3258             devices = _parse_caps_devices_features(child)
3259             if devices:
3260                 result["devices"] = devices
3261         elif child.tag == "features":
3262             features = _parse_caps_devices_features(child)
3263             if features:
3264                 result["features"] = features
3265     return result
3266 def domain_capabilities(emulator=None, arch=None, machine=None, domain=None, **kwargs):
3267     conn = __get_conn(**kwargs)
3268     result = []
3269     try:
3270         caps = ElementTree.fromstring(
3271             conn.getDomainCapabilities(emulator, arch, machine, domain, 0)
3272         )
3273         result = _parse_domain_caps(caps)
3274     finally:
3275         conn.close()
3276     return result
3277 def all_capabilities(**kwargs):
3278     conn = __get_conn(**kwargs)
3279     try:
3280         host_caps = ElementTree.fromstring(conn.getCapabilities())
3281         domains = [
3282             [
3283                 (
3284                     guest.get("arch", {}).get("name", None),
3285                     key,
3286                     guest.get("arch", {}).get("emulator", None),
3287                 )
3288                 for key in guest.get("arch", {}).get("domains", {}).keys()
3289             ]
3290             for guest in [
3291                 _parse_caps_guest(guest) for guest in host_caps.findall("guest")
3292             ]
3293         ]
3294         flattened = [pair for item in (x for x in domains) for pair in item]
3295         result = {
3296             "host": {
3297                 "host": _parse_caps_host(host_caps.find("host")),
3298                 "guests": [
3299                     _parse_caps_guest(guest) for guest in host_caps.findall("guest")
3300                 ],
3301             },
3302             "domains": [
3303                 _parse_domain_caps(
3304                     ElementTree.fromstring(
3305                         conn.getDomainCapabilities(emulator, arch, None, domain)
3306                     )
3307                 )
3308                 for (arch, domain, emulator) in flattened
3309             ],
3310         }
3311         return result
3312     finally:
3313         conn.close()
3314 def cpu_baseline(full=False, migratable=False, out="libvirt", **kwargs):
3315     conn = __get_conn(**kwargs)
3316     caps = ElementTree.fromstring(conn.getCapabilities())
3317     cpu = caps.find("host/cpu")
3318     host_cpu_def = xmlutil.element_to_str(cpu)
3319     log.debug("Host CPU model definition: %s", host_cpu_def)
3320     flags = 0
3321     if migratable:
3322         if getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_MIGRATABLE", False):
3323             flags += libvirt.VIR_CONNECT_BASELINE_CPU_MIGRATABLE
3324         else:
3325             conn.close()
3326             raise ValueError
3327     if full and getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES", False):
3328         flags += libvirt.VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES
3329     cpu = ElementTree.fromstring(conn.baselineCPU([host_cpu_def], flags))
3330     conn.close()
3331     if full and not getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES", False):
3332         with salt.utils.files.fopen("/usr/share/libvirt/cpu_map.xml", "r") as cpu_map:
3333             cpu_map = ElementTree.parse(cpu_map)
3334         cpu_model = cpu.find("model").text
3335         while cpu_model:
3336             cpu_map_models = cpu_map.findall("arch/model")
3337             cpu_specs = [
3338                 el
3339                 for el in cpu_map_models
3340                 if el.get("name") == cpu_model and bool(len(el))
3341             ]
3342             if not cpu_specs:
3343                 raise ValueError("Model {} not found in CPU map".format(cpu_model))
3344             elif len(cpu_specs) &gt; 1:
3345                 raise ValueError(
3346                     "Multiple models {} found in CPU map".format(cpu_model)
3347                 )
3348             cpu_specs = cpu_specs[0]
3349             model_node = cpu_specs.find("model")
3350             if model_node is None:
3351                 cpu_model = None
3352             else:
3353                 cpu_model = model_node.get("name")
3354             cpu.extend([feature for feature in cpu_specs.findall("feature")])
3355     if out == "salt":
3356         return {
3357             "model": cpu.find("model").text,
3358             "vendor": cpu.find("vendor").text,
3359             "features": [feature.get("name") for feature in cpu.findall("feature")],
3360         }
3361     return ElementTree.tostring(cpu)
3362 def network_define(
3363     name,
3364     bridge,
3365     forward,
3366     ipv4_config=None,
3367     ipv6_config=None,
3368     vport=None,
3369     tag=None,
3370     autostart=True,
3371     start=True,
3372     mtu=None,
3373     domain=None,
3374     nat=None,
3375     interfaces=None,
3376     addresses=None,
3377     physical_function=None,
3378     dns=None,
3379     **kwargs
3380 ):
3381     conn = __get_conn(**kwargs)
3382     vport = kwargs.get("vport", None)
3383     tag = kwargs.get("tag", None)
3384     net_xml = _gen_net_xml(
3385         name,
3386         bridge,
3387         forward,
3388         vport,
3389         tag=tag,
3390         ip_configs=[config for config in [ipv4_config, ipv6_config] if config],
3391         mtu=mtu,
3392         domain=domain,
3393         nat=nat,
3394         interfaces=interfaces,
3395         addresses=addresses,
3396         physical_function=physical_function,
3397         dns=dns,
3398     )
3399     try:
3400         conn.networkDefineXML(net_xml)
3401     except libvirt.libvirtError as err:
3402         log.warning(err)
3403         conn.close()
3404         raise err  # a real error we should report upwards
3405     try:
3406         network = conn.networkLookupByName(name)
3407     except libvirt.libvirtError as err:
3408         log.warning(err)
3409         conn.close()
3410         raise err  # a real error we should report upwards
3411     if network is None:
3412         conn.close()
3413         return False
3414     if (start or autostart) and network.isActive() != 1:
3415         network.create()
3416     if autostart and network.autostart() != 1:
3417         network.setAutostart(int(autostart))
3418     elif not autostart and network.autostart() == 1:
3419         network.setAutostart(int(autostart))
3420     conn.close()
3421     return True
3422 def _remove_empty_xml_node(node):
3423     for child in node:
3424         if not child.tail and not child.text and not child.items() and not child:
3425             node.remove(child)
3426         else:
3427             _remove_empty_xml_node(child)
3428     return node
3429 def network_update(
3430     name,
3431     bridge,
3432     forward,
3433     ipv4_config=None,
3434     ipv6_config=None,
3435     vport=None,
3436     tag=None,
3437     mtu=None,
3438     domain=None,
3439     nat=None,
3440     interfaces=None,
3441     addresses=None,
3442     physical_function=None,
3443     dns=None,
3444     test=False,
3445     **kwargs
3446 ):
3447     conn = __get_conn(**kwargs)
3448     needs_update = False
3449     try:
3450         net = conn.networkLookupByName(name)
3451         old_xml = ElementTree.fromstring(net.XMLDesc())
3452         new_xml = ElementTree.fromstring(
3453             _gen_net_xml(
3454                 name,
3455                 bridge,
3456                 forward,
3457                 vport,
3458                 tag=tag,
3459                 ip_configs=[config for config in [ipv4_config, ipv6_config] if config],
3460                 mtu=mtu,
3461                 domain=domain,
3462                 nat=nat,
3463                 interfaces=interfaces,
3464                 addresses=addresses,
3465                 physical_function=physical_function,
3466                 dns=dns,
3467             )
3468         )
3469         elements_to_copy = ["uuid", "mac"]
3470         for to_copy in elements_to_copy:
3471             element = old_xml.find(to_copy)
3472             if element is not None:
3473                 new_xml.insert(1, element)
3474         old_xml.attrib.pop("connections", None)
3475         if old_xml.find("forward/pf") is not None:
3476             forward_node = old_xml.find("forward")
3477             address_nodes = forward_node.findall("address")
3478             for node in address_nodes:
3479                 forward_node.remove(node)
3480         default_bridge_attribs = {"stp": "on", "delay": "0"}
3481         old_bridge_node = old_xml.find("bridge")
3482         if old_bridge_node is not None:
3483             for key, value in default_bridge_attribs.items():
3484                 if old_bridge_node.get(key, None) == value:
3485                     old_bridge_node.attrib.pop(key, None)
3486             old_forward = (
3487                 old_xml.find("forward").get("mode")
3488                 if old_xml.find("forward") is not None
3489                 else None
3490             )
3491             if (
3492                 old_forward == forward
3493                 and forward in ["nat", "route", "open", None]
3494                 and bridge is None
3495                 and old_bridge_node.get("name", "").startswith("virbr")
3496             ):
3497                 old_bridge_node.attrib.pop("name", None)
3498         ipv4_nodes = [
3499             node
3500             for node in old_xml.findall("ip")
3501             if node.get("family", "ipv4") == "ipv4"
3502         ]
3503         for ip_node in ipv4_nodes:
3504             netmask = ip_node.attrib.pop("netmask", None)
3505             if netmask:
3506                 address = ipaddress.ip_network(
3507                     "{}/{}".format(ip_node.get("address"), netmask), strict=False
3508                 )
3509                 ip_node.set("prefix", str(address.prefixlen))
3510         for doc in [old_xml, new_xml]:
3511             for node in doc.findall("ip"):
3512                 if "family" not in node.keys():
3513                     node.set("family", "ipv4")
3514         _remove_empty_xml_node(xmlutil.strip_spaces(old_xml))
3515         xmlutil.strip_spaces(new_xml)
3516         needs_update = xmlutil.to_dict(old_xml, True) != xmlutil.to_dict(new_xml, True)
3517         if needs_update and not test:
3518             conn.networkDefineXML(xmlutil.element_to_str(new_xml))
3519     finally:
3520         conn.close()
3521     return needs_update
3522 def list_networks(**kwargs):
3523     conn = __get_conn(**kwargs)
3524     try:
3525         return [net.name() for net in conn.listAllNetworks()]
3526     finally:
3527         conn.close()
3528 def network_info(name=None, **kwargs):
3529     result = {}
3530     conn = __get_conn(**kwargs)
3531     def _net_get_leases(net):
3532         leases = net.DHCPLeases()
3533         for lease in leases:
3534             if lease["type"] == libvirt.VIR_IP_ADDR_TYPE_IPV4:
3535                 lease["type"] = "ipv4"
3536             elif lease["type"] == libvirt.VIR_IP_ADDR_TYPE_IPV6:
3537                 lease["type"] = "ipv6"
3538             else:
3539                 lease["type"] = "unknown"
3540         return leases
3541     def _net_get_bridge(net):
3542         try:
3543             return net.bridgeName()
3544         except libvirt.libvirtError as err:
3545             return None
3546     try:
3547         nets = [
3548             net for net in conn.listAllNetworks() if name is None or net.name() == name
3549         ]
3550         result = {
3551             net.name(): {
3552                 "uuid": net.UUIDString(),
3553                 "bridge": _net_get_bridge(net),
3554                 "autostart": net.autostart(),
3555                 "active": net.isActive(),
3556                 "persistent": net.isPersistent(),
3557                 "leases": _net_get_leases(net),
3558             }
3559             for net in nets
3560         }
3561     except libvirt.libvirtError as err:
3562         log.debug("Silenced libvirt error: %s", err)
3563     finally:
3564         conn.close()
3565     return result
3566 def network_get_xml(name, **kwargs):
3567     conn = __get_conn(**kwargs)
3568     try:
3569         return conn.networkLookupByName(name).XMLDesc()
3570     finally:
3571         conn.close()
3572 def network_start(name, **kwargs):
3573     conn = __get_conn(**kwargs)
3574     try:
3575         net = conn.networkLookupByName(name)
3576         return not bool(net.create())
3577     finally:
3578         conn.close()
3579 def network_stop(name, **kwargs):
3580     conn = __get_conn(**kwargs)
3581     try:
3582         net = conn.networkLookupByName(name)
3583         return not bool(net.destroy())
3584     finally:
3585         conn.close()
3586 def network_undefine(name, **kwargs):
3587     conn = __get_conn(**kwargs)
3588     try:
3589         net = conn.networkLookupByName(name)
3590         return not bool(net.undefine())
3591     finally:
3592         conn.close()
3593 def network_set_autostart(name, state="on", **kwargs):
3594     conn = __get_conn(**kwargs)
3595     try:
3596         net = conn.networkLookupByName(name)
3597         return not bool(net.setAutostart(1 if state == "on" else 0))
3598     finally:
3599         conn.close()
3600 def _parse_pools_caps(doc):
3601     def _parse_pool_caps(pool):
3602         pool_caps = {
3603             "name": pool.get("type"),
3604             "supported": pool.get("supported", "no") == "yes",
3605         }
3606         for option_kind in ["pool", "vol"]:
3607             options = {}
3608             default_format_node = pool.find(
3609                 "{}Options/defaultFormat".format(option_kind)
3610             )
3611             if default_format_node is not None:
3612                 options["default_format"] = default_format_node.get("type")
3613             options_enums = {
3614                 enum.get("name"): [value.text for value in enum.findall("value")]
3615                 for enum in pool.findall("{}Options/enum".format(option_kind))
3616             }
3617             if options_enums:
3618                 options.update(options_enums)
3619             if options:
3620                 if "options" not in pool_caps:
3621                     pool_caps["options"] = {}
3622                 kind = option_kind if option_kind != "vol" else "volume"
3623                 pool_caps["options"][kind] = options
3624         return pool_caps
3625     return [_parse_pool_caps(pool) for pool in doc.findall("pool")]
3626 def _pool_capabilities(conn):
3627     has_pool_capabilities = bool(getattr(conn, "getStoragePoolCapabilities", None))
3628     if has_pool_capabilities:
3629         caps = ElementTree.fromstring(conn.getStoragePoolCapabilities())
3630         pool_types = _parse_pools_caps(caps)
3631     else:
3632         all_hypervisors = ["xen", "kvm", "bhyve"]
3633         images_formats = [
3634             "none",
3635             "raw",
3636             "dir",
3637             "bochs",
3638             "cloop",
3639             "dmg",
3640             "iso",
3641             "vpc",
3642             "vdi",
3643             "fat",
3644             "vhd",
3645             "ploop",
3646             "cow",
3647             "qcow",
3648             "qcow2",
3649             "qed",
3650 <a name="0"></a>            "vmdk",
3651         ]
3652         common_drivers = [
3653             <font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>{
3654                 "name": "fs",
3655                 "default_source_format": "auto",
3656                 "source_formats": [
3657                     "auto",
3658                     "ext2",
3659                     "ext3",
3660                     "ext4",
3661                     "ufs",
3662                     "iso9660",
3663                     "udf",
3664                     "gfs",
3665                     "gfs2",
3666                     "vfat",
3667                     "hfs+",
3668                     "xfs",
3669                     "ocfs2",
3670                 ],
3671                 "default_target_format": "raw",
3672                 "target_formats": images_formats,
3673             },
3674             {
3675                 "name": "dir",
3676                 "default_target_format": "raw",
3677                 "target_formats": images_formats,
3678             },
3679             {"name": "iscsi"},
3680             {"name": "scsi"},
3681             {
3682                 "name": "logical",
3683                 "default_source_format": "lvm2",
3684                 "source_formats": ["unknown", "lvm2"],
3685             },
3686             {
3687                 "name": "netfs",
3688                 "default_source_format": "auto",
3689                 "source_formats": ["auto", "nfs", "glusterfs", "cifs"],
3690                 "default_target_format": "raw",
3691                 "target_formats": images_formats,
3692             },
3693             {
3694                 "name": "disk",
3695                 "default_source_format": "unknown",
3696                 "source_formats": [
3697                     "unknown",
3698                     "dos",
3699                     "dvh",
3700                     "gpt",
3701                     "mac",
3702                     "bsd",
3703                     "pc98",
3704                     "sun",
3705                     "lvm2",
3706                 ],
3707                 "default_target_format": "none",
3708                 "target_formats": [
3709                     "none",
3710                     "linux",
3711                     "fat16",
3712                     "fat32",
3713                     "linux-swap",
3714                     "linux-lvm",
3715                     "linux-raid",
3716                     "extended",
3717                 ],
3718             },
3719             {"name": "mpath"},
3720             {"name": "rbd", "default_target_format": "raw", "target_formats": []},
3721             {
3722                 "name": "sheepdog",
3723                 "version": 10000,
3724                 "hypervisors": ["kvm"],
3725                 "default_target_format": "raw",
3726                 "target_formats": images_formats,
3727             },
3728             {
3729                 "name": "gluster",
3730                 "version": 1002000,
3731                 "hypervisors": ["kvm"],
3732                 "default_target_format": "raw",
3733                 "target_formats": images_formats,
3734             },
3735             {"name": "zfs", "version": 1002008, "hypervisors": ["bhyve"]},
3736             {
3737                 "name": "iscsi-direct",
3738                 "version": 4007000,
3739                 "hypervisors": ["kvm"</b></font>, "xen"],
3740             },
3741         ]
3742         libvirt_version = conn.getLibVersion()
3743         hypervisor = get_hypervisor()
3744         def _get_backend_output(backend):
3745 <a name="5"></a>            output = {
3746                 "name": backend["name"],
3747                 "supported": (
3748                     not backend<font color="#151b8d"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.get("version") or libvirt_version &gt;= backend["version"]
3749                 )
3750                 and hypervisor in backend.get("hypervisors", all_hypervisors),
3751                 "options": {
3752                     "pool": {
3753                         "default_format": backend.get("default_source_format"),
3754                         "sourceFormatType": backend.get("source_formats"),
3755                     },
3756                     "volume": {
3757                         "default_format": backend.</b></font>get("default_target_format"),
3758                         "targetFormatType": backend.get("target_formats"),
3759                     },
3760                 },
3761             }
3762             for option_kind in ["pool", "volume"]:
3763                 if not [
3764                     value
3765                     for value in output["options"][option_kind].values()
3766                     if value is not None
3767                 ]:
3768                     del output["options"][option_kind]
3769             if not output["options"]:
3770                 del output["options"]
3771             return output
3772         pool_types = [_get_backend_output(backend) for backend in common_drivers]
3773     return {
3774         "computed": not has_pool_capabilities,
3775         "pool_types": pool_types,
3776     }
3777 def pool_capabilities(**kwargs):
3778     try:
3779         conn = __get_conn(**kwargs)
3780         return _pool_capabilities(conn)
3781     finally:
3782         conn.close()
3783 def pool_define(
3784     name,
3785     ptype,
3786     target=None,
3787     permissions=None,
3788     source_devices=None,
3789     source_dir=None,
3790     source_initiator=None,
3791     source_adapter=None,
3792     source_hosts=None,
3793     source_auth=None,
3794     source_name=None,
3795     source_format=None,
3796     transient=False,
3797     start=True,  # pylint: disable=redefined-outer-name
3798     **kwargs
3799 ):
3800     conn = __get_conn(**kwargs)
3801     auth = _pool_set_secret(conn, ptype, name, source_auth)
3802     pool_xml = _gen_pool_xml(
3803         name,
3804         ptype,
3805         target,
3806         permissions=permissions,
3807         source_devices=source_devices,
3808         source_dir=source_dir,
3809         source_adapter=source_adapter,
3810         source_hosts=source_hosts,
3811         source_auth=auth,
3812         source_name=source_name,
3813         source_format=source_format,
3814         source_initiator=source_initiator,
3815     )
3816     try:
3817         if transient:
3818             pool = conn.storagePoolCreateXML(pool_xml)
3819         else:
3820             pool = conn.storagePoolDefineXML(pool_xml)
3821             if start:
3822                 pool.create()
3823     except libvirt.libvirtError as err:
3824         raise err  # a real error we should report upwards
3825     finally:
3826         conn.close()
3827     return True
3828 def _pool_set_secret(
3829     conn, pool_type, pool_name, source_auth, uuid=None, usage=None, test=False
3830 ):
3831     secret_types = {"rbd": "ceph", "iscsi": "chap", "iscsi-direct": "chap"}
3832     secret_type = secret_types.get(pool_type)
3833     auth = source_auth
3834     if source_auth and "username" in source_auth and "password" in source_auth:
3835         if secret_type:
3836             secret = None
3837             try:
3838                 if usage:
3839                     usage_type = (
3840                         libvirt.VIR_SECRET_USAGE_TYPE_CEPH
3841                         if secret_type == "ceph"
3842                         else libvirt.VIR_SECRET_USAGE_TYPE_ISCSI
3843                     )
3844                     secret = conn.secretLookupByUsage(usage_type, usage)
3845                 elif uuid:
3846                     secret = conn.secretLookupByUUIDString(uuid)
3847             except libvirt.libvirtError as err:
3848                 log.info("Secret not found: %s", err.get_error_message())
3849             if not secret:
3850                 description = "Passphrase for {} pool created by Salt".format(pool_name)
3851                 if not usage:
3852                     usage = "pool_{}".format(pool_name)
3853                 secret_xml = _gen_secret_xml(secret_type, usage, description)
3854                 if not test:
3855                     secret = conn.secretDefineXML(secret_xml)
3856             password = auth["password"]
3857             if pool_type == "rbd":
3858                 password = base64.b64decode(salt.utils.stringutils.to_bytes(password))
3859             if not test:
3860                 secret.setValue(password)
3861             auth["type"] = secret_type
3862             auth["secret"] = {
3863                 "type": "uuid" if uuid else "usage",
3864                 "value": uuid if uuid else usage,
3865             }
3866     return auth
3867 def pool_update(
3868     name,
3869     ptype,
3870     target=None,
3871     permissions=None,
3872     source_devices=None,
3873     source_dir=None,
3874     source_initiator=None,
3875     source_adapter=None,
3876     source_hosts=None,
3877     source_auth=None,
3878     source_name=None,
3879     source_format=None,
3880     test=False,
3881     **kwargs
3882 ):
3883     conn = __get_conn(**kwargs)
3884     needs_update = False
3885     try:
3886         pool = conn.storagePoolLookupByName(name)
3887         old_xml = ElementTree.fromstring(pool.XMLDesc())
3888         secret_node = old_xml.find("source/auth/secret")
3889         usage = secret_node.get("usage") if secret_node is not None else None
3890         uuid = secret_node.get("uuid") if secret_node is not None else None
3891         auth = _pool_set_secret(
3892             conn, ptype, name, source_auth, uuid=uuid, usage=usage, test=test
3893         )
3894         new_xml = ElementTree.fromstring(
3895             _gen_pool_xml(
3896                 name,
3897                 ptype,
3898                 target,
3899                 permissions=permissions,
3900                 source_devices=source_devices,
3901                 source_dir=source_dir,
3902                 source_initiator=source_initiator,
3903                 source_adapter=source_adapter,
3904                 source_hosts=source_hosts,
3905                 source_auth=auth,
3906                 source_name=source_name,
3907                 source_format=source_format,
3908             )
3909         )
3910         elements_to_copy = ["available", "allocation", "capacity", "uuid"]
3911         for to_copy in elements_to_copy:
3912             element = old_xml.find(to_copy)
3913             new_xml.insert(1, element)
3914         _remove_empty_xml_node(xmlutil.strip_spaces(old_xml))
3915         xmlutil.strip_spaces(new_xml)
3916         needs_update = xmlutil.to_dict(old_xml, True) != xmlutil.to_dict(new_xml, True)
3917         if needs_update and not test:
3918             conn.storagePoolDefineXML(xmlutil.element_to_str(new_xml))
3919     finally:
3920         conn.close()
3921     return needs_update
3922 def list_pools(**kwargs):
3923     conn = __get_conn(**kwargs)
3924     try:
3925         return [pool.name() for pool in conn.listAllStoragePools()]
3926     finally:
3927         conn.close()
3928 def pool_info(name=None, **kwargs):
3929     result = {}
3930     conn = __get_conn(**kwargs)
3931     def _pool_extract_infos(pool):
3932         states = ["inactive", "building", "running", "degraded", "inaccessible"]
3933         infos = pool.info()
3934         state = states[infos[0]] if infos[0] &lt; len(states) else "unknown"
3935         desc = ElementTree.fromstring(pool.XMLDesc())
3936         path_node = desc.find("target/path")
3937         return {
3938             "uuid": pool.UUIDString(),
3939             "state": state,
3940             "capacity": infos[1],
3941             "allocation": infos[2],
3942             "free": infos[3],
3943             "autostart": pool.autostart(),
3944             "persistent": pool.isPersistent(),
3945             "target_path": path_node.text if path_node is not None else None,
3946             "type": desc.get("type"),
3947         }
3948     try:
3949         pools = [
3950             pool
3951             for pool in conn.listAllStoragePools()
3952             if name is None or pool.name() == name
3953         ]
3954         result = {pool.name(): _pool_extract_infos(pool) for pool in pools}
3955     except libvirt.libvirtError as err:
3956         log.debug("Silenced libvirt error: %s", err)
3957     finally:
3958         conn.close()
3959     return result
3960 def pool_get_xml(name, **kwargs):
3961     conn = __get_conn(**kwargs)
3962     try:
3963         return conn.storagePoolLookupByName(name).XMLDesc()
3964     finally:
3965         conn.close()
3966 def pool_start(name, **kwargs):
3967     conn = __get_conn(**kwargs)
3968     try:
3969         pool = conn.storagePoolLookupByName(name)
3970         return not bool(pool.create())
3971     finally:
3972         conn.close()
3973 def pool_build(name, **kwargs):
3974     conn = __get_conn(**kwargs)
3975     try:
3976         pool = conn.storagePoolLookupByName(name)
3977         return not bool(pool.build())
3978     finally:
3979         conn.close()
3980 def pool_stop(name, **kwargs):
3981     conn = __get_conn(**kwargs)
3982     try:
3983         pool = conn.storagePoolLookupByName(name)
3984         return not bool(pool.destroy())
3985     finally:
3986         conn.close()
3987 def pool_undefine(name, **kwargs):
3988     conn = __get_conn(**kwargs)
3989     try:
3990         pool = conn.storagePoolLookupByName(name)
3991         desc = ElementTree.fromstring(pool.XMLDesc())
3992         auth_node = desc.find("source/auth")
3993         if auth_node is not None:
3994             auth_types = {
3995                 "ceph": libvirt.VIR_SECRET_USAGE_TYPE_CEPH,
3996                 "iscsi": libvirt.VIR_SECRET_USAGE_TYPE_ISCSI,
3997             }
3998             secret_type = auth_types[auth_node.get("type")]
3999             secret_usage = auth_node.find("secret").get("usage")
4000             if secret_type and "pool_{}".format(name) == secret_usage:
4001                 secret = conn.secretLookupByUsage(secret_type, secret_usage)
4002                 secret.undefine()
4003         return not bool(pool.undefine())
4004     finally:
4005         conn.close()
4006 def pool_delete(name, **kwargs):
4007     conn = __get_conn(**kwargs)
4008     try:
4009         pool = conn.storagePoolLookupByName(name)
4010         return not bool(pool.delete(libvirt.VIR_STORAGE_POOL_DELETE_NORMAL))
4011     finally:
4012         conn.close()
4013 def pool_refresh(name, **kwargs):
4014     conn = __get_conn(**kwargs)
4015     try:
4016         pool = conn.storagePoolLookupByName(name)
4017         return not bool(pool.refresh())
4018     finally:
4019         conn.close()
4020 def pool_set_autostart(name, state="on", **kwargs):
4021     conn = __get_conn(**kwargs)
4022     try:
4023         pool = conn.storagePoolLookupByName(name)
4024         return not bool(pool.setAutostart(1 if state == "on" else 0))
4025     finally:
4026         conn.close()
4027 def pool_list_volumes(name, **kwargs):
4028     conn = __get_conn(**kwargs)
4029     try:
4030         pool = conn.storagePoolLookupByName(name)
4031         return pool.listVolumes()
4032     finally:
4033         conn.close()
4034 def _get_storage_vol(conn, pool, vol):
4035     pool_obj = conn.storagePoolLookupByName(pool)
4036     return pool_obj.storageVolLookupByName(vol)
4037 def _is_valid_volume(vol):
4038     try:
4039         def discarder(ctxt, error):  # pylint: disable=unused-argument
4040             log.debug("Ignore libvirt error: %s", error[2])
4041         libvirt.registerErrorHandler(discarder, None)
4042         vol.info()
4043         libvirt.registerErrorHandler(None, None)
4044         return True
4045     except libvirt.libvirtError as err:
4046         return False
4047 def _get_all_volumes_paths(conn):
4048     pools = [
4049         pool
4050         for pool in conn.listAllStoragePools()
4051         if pool.info()[0] == libvirt.VIR_STORAGE_POOL_RUNNING
4052     ]
4053     volumes = {}
4054     for pool in pools:
4055         pool_volumes = {
4056             volume.path(): {
4057                 "pool": pool.name(),
4058                 "name": volume.name(),
4059                 "backing_stores": [
4060                     path.text
4061                     for path in ElementTree.fromstring(volume.XMLDesc()).findall(
4062                         ".//backingStore/path"
4063                     )
4064                 ],
4065             }
4066             for volume in pool.listAllVolumes()
4067             if _is_valid_volume(volume)
4068         }
4069         volumes.update(pool_volumes)
4070     return volumes
4071 def volume_infos(pool=None, volume=None, **kwargs):
4072     result = {}
4073     conn = __get_conn(**kwargs)
4074     try:
4075         backing_stores = _get_all_volumes_paths(conn)
4076         try:
4077             domains = _get_domain(conn)
4078             domains_list = domains if isinstance(domains, list) else [domains]
4079         except CommandExecutionError:
4080             domains_list = []
4081         disks = {
4082             domain.name(): {
4083                 node.get("file")
4084                 for node in ElementTree.fromstring(domain.XMLDesc(0)).findall(
4085                     ".//disk/source/[@file]"
4086                 )
4087             }
4088             for domain in domains_list
4089         }
4090         def _volume_extract_infos(vol):
4091             types = ["file", "block", "dir", "network", "netdir", "ploop"]
4092             infos = vol.info()
4093             vol_xml = ElementTree.fromstring(vol.XMLDesc())
4094             backing_store_path = vol_xml.find("./backingStore/path")
4095             backing_store_format = vol_xml.find("./backingStore/format")
4096             backing_store = None
4097             if backing_store_path is not None:
4098                 backing_store = {
4099                     "path": backing_store_path.text,
4100                     "format": backing_store_format.get("type")
4101                     if backing_store_format is not None
4102                     else None,
4103                 }
4104             format_node = vol_xml.find("./target/format")
4105             used_by = []
4106             if vol.path():
4107                 as_backing_store = {
4108                     path
4109                     for (path, volume) in backing_stores.items()
4110                     if vol.path() in volume.get("backing_stores")
4111                 }
4112                 used_by = [
4113                     vm_name
4114                     for (vm_name, vm_disks) in disks.items()
4115                     if vm_disks &amp; as_backing_store or vol.path() in vm_disks
4116                 ]
4117             return {
4118                 "type": types[infos[0]] if infos[0] &lt; len(types) else "unknown",
4119                 "key": vol.key(),
4120                 "path": vol.path(),
4121                 "capacity": infos[1],
4122                 "allocation": infos[2],
4123                 "used_by": used_by,
4124                 "backing_store": backing_store,
4125                 "format": format_node.get("type") if format_node is not None else None,
4126             }
4127         pools = [
4128             obj
4129             for obj in conn.listAllStoragePools()
4130             if (pool is None or obj.name() == pool)
4131             and obj.info()[0] == libvirt.VIR_STORAGE_POOL_RUNNING
4132         ]
4133         vols = {
4134             pool_obj.name(): {
4135                 vol.name(): _volume_extract_infos(vol)
4136                 for vol in pool_obj.listAllVolumes()
4137                 if (volume is None or vol.name() == volume) and _is_valid_volume(vol)
4138             }
4139             for pool_obj in pools
4140         }
4141         return {pool_name: volumes for (pool_name, volumes) in vols.items() if volumes}
4142     except libvirt.libvirtError as err:
4143         log.debug("Silenced libvirt error: %s", err)
4144     finally:
4145         conn.close()
4146     return result
4147 def volume_delete(pool, volume, **kwargs):
4148     conn = __get_conn(**kwargs)
4149     try:
4150         vol = _get_storage_vol(conn, pool, volume)
4151         return not bool(vol.delete())
4152     finally:
4153         conn.close()
4154 def volume_define(
4155     pool,
4156     name,
4157     size,
4158     allocation=0,
4159     format=None,
4160     type=None,
4161     permissions=None,
4162     backing_store=None,
4163     nocow=False,
4164     **kwargs
4165 ):
4166     ret = False
4167     try:
4168         conn = __get_conn(**kwargs)
4169         pool_obj = conn.storagePoolLookupByName(pool)
4170         pool_type = ElementTree.fromstring(pool_obj.XMLDesc()).get("type")
4171         new_allocation = allocation
4172         if pool_type == "logical" and size != allocation:
4173             new_allocation = size
4174         xml = _gen_vol_xml(
4175             name,
4176             size,
4177             format=format,
4178             allocation=new_allocation,
4179             type=type,
4180             permissions=permissions,
4181             backing_store=backing_store,
4182             nocow=nocow,
4183         )
4184         ret = _define_vol_xml_str(conn, xml, pool=pool)
4185     except libvirt.libvirtError as err:
4186         raise CommandExecutionError(err.get_error_message())
4187     finally:
4188         conn.close()
4189     return ret
4190 def _volume_upload(conn, pool, volume, file, offset=0, length=0, sparse=False):
4191     def handler(stream, nbytes, opaque):
4192         return os.read(opaque, nbytes)
4193     def holeHandler(stream, opaque):
4194         fd = opaque
4195         cur = os.lseek(fd, 0, os.SEEK_CUR)
4196         try:
4197             data = os.lseek(fd, cur, os.SEEK_DATA)
4198         except OSError as e:
4199             if e.errno != 6:
4200                 raise e
4201             else:
4202                 data = -1
4203         if data &lt; 0:
4204             inData = False
4205             eof = os.lseek(fd, 0, os.SEEK_END)
4206             if eof &lt; cur:
4207                 raise RuntimeError("Current position in file after EOF: {}".format(cur))
4208             sectionLen = eof - cur
4209         else:
4210             if data &gt; cur:
4211                 inData = False
4212                 sectionLen = data - cur
4213             else:
4214                 inData = True
4215                 hole = os.lseek(fd, data, os.SEEK_HOLE)
4216                 if hole &lt; 0:
4217                     raise RuntimeError("No trailing hole")
4218                 if hole == data:
4219                     raise RuntimeError("Impossible happened")
4220                 else:
4221                     sectionLen = hole - data
4222         os.lseek(fd, cur, os.SEEK_SET)
4223         return [inData, sectionLen]
4224     def skipHandler(stream, length, opaque):
4225         return os.lseek(opaque, length, os.SEEK_CUR)
4226     stream = None
4227     fd = None
4228     ret = False
4229     try:
4230         pool_obj = conn.storagePoolLookupByName(pool)
4231         vol_obj = pool_obj.storageVolLookupByName(volume)
4232         stream = conn.newStream()
4233         fd = os.open(file, os.O_RDONLY)
4234         vol_obj.upload(
4235             stream,
4236             offset,
4237             length,
4238             libvirt.VIR_STORAGE_VOL_UPLOAD_SPARSE_STREAM if sparse else 0,
4239         )
4240         if sparse:
4241             stream.sparseSendAll(handler, holeHandler, skipHandler, fd)
4242         else:
4243             stream.sendAll(handler, fd)
4244         ret = True
4245     except libvirt.libvirtError as err:
4246         raise CommandExecutionError(err.get_error_message())
4247     finally:
4248         if fd:
4249             try:
4250                 os.close(fd)
4251             except OSError as err:
4252                 if stream:
4253                     stream.abort()
4254                 if ret:
4255                     raise CommandExecutionError(
4256                         "Failed to close file: {}".format(err.strerror)
4257                     )
4258         if stream:
4259             try:
4260                 stream.finish()
4261             except libvirt.libvirtError as err:
4262                 if ret:
4263                     raise CommandExecutionError(
4264                         "Failed to finish stream: {}".format(err.get_error_message())
4265                     )
4266     return ret
4267 def volume_upload(pool, volume, file, offset=0, length=0, sparse=False, **kwargs):
4268     conn = __get_conn(**kwargs)
4269     ret = False
4270     try:
4271         ret = _volume_upload(
4272             conn, pool, volume, file, offset=offset, length=length, sparse=sparse
4273         )
4274     finally:
4275         conn.close()
4276     return ret
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
