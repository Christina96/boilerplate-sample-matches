<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for test_mac_softwareupdate_1.py &amp; virt_1.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for test_mac_softwareupdate_1.py &amp; virt_1.py
      </h3>
<h1 align="center">
        1.7%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>test_mac_softwareupdate_1.py (39.325844%)<th>virt_1.py (0.90241075%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(69-78)<td><a href="#" name="0">(4072-4092)</a><td align="center"><font color="#ff0000">24</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(159-167)<td><a href="#" name="1">(3283-3287)</a><td align="center"><font color="#c90000">19</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(88-93)<td><a href="#" name="2">(6763-6767)</a><td align="center"><font color="#940000">14</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(108-118)<td><a href="#" name="3">(2970-2972)</a><td align="center"><font color="#8a0000">13</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_mac_softwareupdate_1.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import pytest
2 from tests.support.case import ModuleCase
3 from tests.support.helpers import runs_on
4 @pytest.mark.skip_if_not_root
5 @runs_on(kernel="Darwin")
6 @pytest.mark.skip_if_binaries_missing("softwareupdate")
7 class MacSoftwareUpdateModuleTest(ModuleCase):
8     IGNORED_LIST = []
9     SCHEDULE = False
10     CATALOG = ""
11     def setUp(self):
12         self.IGNORED_LIST = self.run_function("softwareupdate.list_ignored")
13         self.SCHEDULE = self.run_function("softwareupdate.schedule")
14         self.CATALOG = self.run_function("softwareupdate.get_catalog")
15         super().setUp()
16     def tearDown(self):
17         if self.IGNORED_LIST:
18             for item in self.IGNORED_LIST:
19                 self.run_function("softwareupdate.ignore", [item])
20         else:
21             self.run_function("softwareupdate.reset_ignored")
22         self.run_function("softwareupdate.schedule", [self.SCHEDULE])
23         if self.CATALOG == "Default":
24             self.run_function("softwareupdate.reset_catalog")
25         else:
26             self.run_function("softwareupdate.set_catalog", [self.CATALOG])
27         super().tearDown()
28     @pytest.mark.slow_test
29     def test_list_available(self):
30         self.assertIsInstance(self.run_function("softwareupdate.list_available"), dict)
31     @pytest.mark.destructive_test
32     @pytest.mark.slow_test
33     def test_ignore(self):
34         self<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.assertTrue(self.run_function("softwareupdate.reset_ignored"))
35         self.assertEqual(self.run_function("softwareupdate.list_ignored"), [])
36         self.assertTrue(self.run_function("softwareupdate.ignore", ["spongebob"]))
37         self.assertTrue(self.run_function("softwareupdate.ignore", ["squidward"]))
38         self.assertIn("spongebob", self.run_function("softwareupdate.list_ignored"))
39         self.assertIn("squidward", self.run_function(</b></font>"softwareupdate.list_ignored"))
40     @pytest.mark.destructive_test
41     @pytest.mark.slow_test
42     def test_schedule(self):
43         self<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.assertTrue(self.run_function("softwareupdate.schedule_enable", [True]))
44         self.assertTrue(self.run_function("softwareupdate.schedule_enabled"))
45         self.assertTrue(self.run_function("softwareupdate.schedule_enable", [False]))
46         self.assertFalse(</b></font>self.run_function("softwareupdate.schedule_enabled"))
47     @pytest.mark.destructive_test
48     @pytest.mark.slow_test
49     def test_update(self):
50         """
51         self<font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.assertIsInstance(self.run_function("softwareupdate.update_all"), dict)
52         self.assertFalse(
53             self.run_function("softwareupdate.update_available", ["spongebob"])
54         )
55         self.assertIn(
56             "Update not available",
57             self.run_function(</b></font>"softwareupdate.update", ["spongebob"]),
58         )
59     @pytest.mark.slow_test
60     def test_list_downloads(self):
61         """
62         Test softwareupdate.list_downloads
63         """
64         self.assertIsInstance(self.run_function("softwareupdate.list_downloads"), list)
65     @pytest.mark.destructive_test
66     @pytest.mark.slow_test
67     def test_download(self):
68         """
69         Test softwareupdate.download
70         Need to know the names of updates that are available to properly test
71         the download function
72         """
73         self.assertIn(
74             "Update not available",
75             self.run_function("softwareupdate.download", ["spongebob"]),
76         )
77     @pytest.mark.destructive_test
78     @pytest.mark.slow_test
79     def test_download_all(self):
80         """
81         Test softwareupdate.download_all
82         """
83         self.assertIsInstance(self.run_function("softwareupdate.download_all"), list)
84     @pytest.mark.destructive_test
85     @pytest.mark.slow_test
86     def test_get_set_reset_catalog(self):
87         """
88         Test softwareupdate.download_all
89         self.assertTrue(self.run_function("softwareupdate.reset_catalog"))
90         self.assertEqual(self<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.run_function("softwareupdate.get_catalog"), "Default")
91         self.assertTrue(self.run_function("softwareupdate.set_catalog", ["spongebob"]))
92         self.assertEqual(self.run_function("softwareupdate.get_catalog"), "spongebob")
93         self.assertTrue(self.run_function("softwareupdate.reset_catalog"))
94         self.assertEqual(self.run_function(</b></font>"softwareupdate.get_catalog"), "Default")
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>virt_1.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 """
2 Work with virtual machines managed by libvirt
3 :depends:
4     * libvirt Python module
5     * libvirt client
6     * qemu-img
7     * grep
8 Connection
9 ==========
10 The connection to the virtualization host can be either setup in the minion configuration,
11 pillar data or overridden for each individual call.
12 By default, the libvirt connection URL will be guessed: the first available libvirt
13 hypervisor driver will be used. This can be overridden like this:
14 .. code-block:: yaml
15     virt:
16       connection:
17         uri: lxc:///
18 If the connection requires an authentication like for ESXi, this can be defined in the
19 minion pillar data like this:
20 .. code-block:: yaml
21     virt:
22       connection:
23         uri: esx://10.1.1.101/?no_verify=1&amp;auto_answer=1
24         auth:
25           username: user
26           password: secret
27 Connecting with SSH protocol
28 ----------------------------
29 Libvirt can connect to remote hosts using SSH using one of the ``ssh``, ``libssh`` and
30 ``libssh2`` transports. Note that ``libssh2`` is likely to fail as it doesn't read the
31 ``known_hosts`` file. Libvirt may also have been built without ``libssh`` or ``libssh2``
32 support.
33 To use the SSH transport, on the minion setup an SSH agent with a key authorized on
34 the remote libvirt machine.
35 Per call connection setup
36 -------------------------
37 .. versionadded:: 2019.2.0
38 All the calls requiring the libvirt connection configuration as mentioned above can
39 override this configuration using ``connection``, ``username`` and ``password`` parameters.
40 This means that the following will list the domains on the local LXC libvirt driver,
41 whatever the ``virt:connection`` is.
42 .. code-block:: bash
43     salt 'hypervisor' virt.list_domains connection=lxc:///
44 The calls not using the libvirt connection setup are:
45 - ``seed_non_shared_migrate``
46 - ``virt_type``
47 - ``is_*hyper``
48 - all migration functions
49 - `libvirt ESX URI format &lt;http://libvirt.org/drvesx.html#uriformat&gt;`_
50 - `libvirt URI format &lt;http://libvirt.org/uri.html#URI_config&gt;`_
51 - `libvirt authentication configuration &lt;http://libvirt.org/auth.html#Auth_client_config&gt;`_
52 Units
53 ==========
54 .. _virt-units:
55 .. rubric:: Units specification
56 .. versionadded:: 3002
57 The string should contain a number optionally followed
58 by a unit. The number may have a decimal fraction. If
59 the unit is not given then MiB are set by default.
60 Units can optionally be given in IEC style (such as MiB),
61 although the standard single letter style (such as M) is
62 more convenient.
63 Valid units include:
64 ========== =====    ==========  ==========  ======
65 Standard   IEC      Standard    IEC
66   Unit     Unit     Name        Name        Factor
67 ========== =====    ==========  ==========  ======
68     B               Bytes                   1
69     K       KiB     Kilobytes   Kibibytes   2**10
70     M       MiB     Megabytes   Mebibytes   2**20
71     G       GiB     Gigabytes   Gibibytes   2**30
72     T       TiB     Terabytes   Tebibytes   2**40
73     P       PiB     Petabytes   Pebibytes   2**50
74     E       EiB     Exabytes    Exbibytes   2**60
75     Z       ZiB     Zettabytes  Zebibytes   2**70
76     Y       YiB     Yottabytes  Yobibytes   2**80
77 ========== =====    ==========  ==========  ======
78 Additional decimal based units:
79 ======  =======
80 Unit     Factor
81 ======  =======
82 KB      10**3
83 MB      10**6
84 GB      10**9
85 TB      10**12
86 PB      10**15
87 EB      10**18
88 ZB      10**21
89 YB      10**24
90 ======  =======
91 """
92 import base64
93 import collections
94 import copy
95 import datetime
96 import logging
97 import os
98 import re
99 import shutil
100 import string  # pylint: disable=deprecated-module
101 import subprocess
102 import sys
103 import time
104 import urllib.parse
105 from xml.etree import ElementTree
106 from xml.sax import saxutils
107 import jinja2.exceptions
108 import salt.utils.data
109 import salt.utils.files
110 import salt.utils.json
111 import salt.utils.path
112 import salt.utils.stringutils
113 import salt.utils.templates
114 import salt.utils.virt
115 import salt.utils.xmlutil as xmlutil
116 import salt.utils.yaml
117 from salt._compat import ipaddress
118 from salt.exceptions import CommandExecutionError, SaltInvocationError
119 try:
120     import libvirt  # pylint: disable=import-error
121     from libvirt import libvirtError
122     HAS_LIBVIRT = True
123 except ImportError:
124     HAS_LIBVIRT = False
125 log = logging.getLogger(__name__)
126 JINJA = jinja2.Environment(
127     loader=jinja2.FileSystemLoader(
128         os.path.join(salt.utils.templates.TEMPLATE_DIRNAME, "virt")
129     )
130 )
131 CACHE_DIR = "/var/lib/libvirt/saltinst"
132 VIRT_STATE_NAME_MAP = {
133     0: "running",
134     1: "running",
135     2: "running",
136     3: "paused",
137     4: "shutdown",
138     5: "shutdown",
139     6: "crashed",
140 }
141 def __virtual__():
142     if not HAS_LIBVIRT:
143         return (False, "Unable to locate or import python libvirt library.")
144     return "virt"
145 def __get_request_auth(username, password):
146     """
147     Get libvirt.openAuth callback with username, password values overriding
148     the configuration ones.
149     """
150     def __request_auth(credentials, user_data):
151         """Callback method passed to libvirt.openAuth().
152         The credentials argument is a list of credentials that libvirt
153         would like to request. An element of this list is a list containing
154         5 items (4 inputs, 1 output):
155           - the credential type, e.g. libvirt.VIR_CRED_AUTHNAME
156           - a prompt to be displayed to the user
157           - a challenge
158           - a default result for the request
159           - a place to store the actual result for the request
160         The user_data argument is currently not set in the openAuth call.
161         """
162         for credential in credentials:
163             if credential[0] == libvirt.VIR_CRED_AUTHNAME:
164                 credential[4] = (
165                     username
166                     if username
167                     else __salt__["config.get"](
168                         "virt:connection:auth:username", credential[3]
169                     )
170                 )
171             elif credential[0] == libvirt.VIR_CRED_NOECHOPROMPT:
172                 credential[4] = (
173                     password
174                     if password
175                     else __salt__["config.get"](
176                         "virt:connection:auth:password", credential[3]
177                     )
178                 )
179             else:
180                 log.info("Unhandled credential type: %s", credential[0])
181         return 0
182 def __get_conn(**kwargs):
183     """
184     Detects what type of dom this node is and attempts to connect to the
185     correct hypervisor via libvirt.
186     :param connection: libvirt connection URI, overriding defaults
187     :param username: username to connect with, overriding defaults
188     :param password: password to connect with, overriding defaults
189     """
190     username = kwargs.get("username", None)
191     password = kwargs.get("password", None)
192     conn_str = kwargs.get("connection", None)
193     if not conn_str:
194         conn_str = __salt__["config.get"]("virt:connection:uri", conn_str)
195     try:
196         auth_types = [
197             libvirt.VIR_CRED_AUTHNAME,
198             libvirt.VIR_CRED_NOECHOPROMPT,
199             libvirt.VIR_CRED_ECHOPROMPT,
200             libvirt.VIR_CRED_PASSPHRASE,
201             libvirt.VIR_CRED_EXTERNAL,
202         ]
203         conn = libvirt.openAuth(
204             conn_str, [auth_types, __get_request_auth(username, password), None], 0
205         )
206     except Exception:  # pylint: disable=broad-except
207         raise CommandExecutionError(
208             "Sorry, {} failed to open a connection to the hypervisor "
209             "software at {}".format(__grains__["fqdn"], conn_str)
210         )
211     return conn
212 def _get_domain(conn, *vms, **kwargs):
213     """
214     Return a domain object for the named VM or return domain object for all VMs.
215     :params conn: libvirt connection object
216     :param vms: list of domain names to look for
217     :param iterable: True to return an array in all cases
218     """
219     ret = list()
220     lookup_vms = list()
221     all_vms = []
222     if kwargs.get("active", True):
223         for id_ in conn.listDomainsID():
224             all_vms.append(conn.lookupByID(id_).name())
225     if kwargs.get("inactive", True):
226         for id_ in conn.listDefinedDomains():
227             all_vms.append(id_)
228     if vms and not all_vms:
229         raise CommandExecutionError("No virtual machines found.")
230     if vms:
231         for name in vms:
232             if name not in all_vms:
233                 raise CommandExecutionError(
234                     'The VM "{name}" is not present'.format(name=name)
235                 )
236             else:
237                 lookup_vms.append(name)
238     else:
239         lookup_vms = list(all_vms)
240     for name in lookup_vms:
241         ret.append(conn.lookupByName(name))
242     return len(ret) == 1 and not kwargs.get("iterable") and ret[0] or ret
243 def _parse_qemu_img_info(info):
244     """
245     Parse qemu-img info JSON output into disk infos dictionary
246     """
247     raw_infos = salt.utils.json.loads(info)
248     disks = []
249     for disk_infos in raw_infos:
250         disk = {
251             "file": disk_infos["filename"],
252             "file format": disk_infos["format"],
253             "disk size": disk_infos["actual-size"],
254             "virtual size": disk_infos["virtual-size"],
255             "cluster size": disk_infos["cluster-size"]
256             if "cluster-size" in disk_infos
257             else None,
258         }
259         if "full-backing-filename" in disk_infos.keys():
260             disk["backing file"] = format(disk_infos["full-backing-filename"])
261         if "snapshots" in disk_infos.keys():
262             disk["snapshots"] = [
263                 {
264                     "id": snapshot["id"],
265                     "tag": snapshot["name"],
266                     "vmsize": snapshot["vm-state-size"],
267                     "date": datetime.datetime.fromtimestamp(
268                         float(
269                             "{}.{}".format(snapshot["date-sec"], snapshot["date-nsec"])
270                         )
271                     ).isoformat(),
272                     "vmclock": datetime.datetime.utcfromtimestamp(
273                         float(
274                             "{}.{}".format(
275                                 snapshot["vm-clock-sec"], snapshot["vm-clock-nsec"]
276                             )
277                         )
278                     )
279                     .time()
280                     .isoformat(),
281                 }
282                 for snapshot in disk_infos["snapshots"]
283             ]
284         disks.append(disk)
285     for disk in disks:
286         if "backing file" in disk.keys():
287             candidates = [
288                 info
289                 for info in disks
290                 if "file" in info.keys() and info["file"] == disk["backing file"]
291             ]
292             if candidates:
293                 disk["backing file"] = candidates[0]
294     return disks[0]
295 def _get_uuid(dom):
296     """
297     Return a uuid from the named vm
298     CLI Example:
299     .. code-block:: bash
300         salt '*' virt.get_uuid &lt;domain&gt;
301     """
302     return ElementTree.fromstring(get_xml(dom)).find("uuid").text
303 def _get_on_poweroff(dom):
304     """
305     Return `on_poweroff` setting from the named vm
306     CLI Example:
307     .. code-block:: bash
308         salt '*' virt.get_on_restart &lt;domain&gt;
309     """
310     node = ElementTree.fromstring(get_xml(dom)).find("on_poweroff")
311     return node.text if node is not None else ""
312 def _get_on_reboot(dom):
313     """
314     Return `on_reboot` setting from the named vm
315     CLI Example:
316     .. code-block:: bash
317         salt '*' virt.get_on_reboot &lt;domain&gt;
318     """
319     node = ElementTree.fromstring(get_xml(dom)).find("on_reboot")
320     return node.text if node is not None else ""
321 def _get_on_crash(dom):
322     """
323     Return `on_crash` setting from the named vm
324     CLI Example:
325     .. code-block:: bash
326         salt '*' virt.get_on_crash &lt;domain&gt;
327     """
328     node = ElementTree.fromstring(get_xml(dom)).find("on_crash")
329     return node.text if node is not None else ""
330 def _get_nics(dom):
331     """
332     Get domain network interfaces from a libvirt domain object.
333     """
334     nics = {}
335     doc = ElementTree.fromstring(dom.XMLDesc(libvirt.VIR_DOMAIN_XML_INACTIVE))
336     for iface_node in doc.findall("devices/interface"):
337         nic = {}
338         nic["type"] = iface_node.get("type")
339         for v_node in iface_node:
340             if v_node.tag == "mac":
341                 nic["mac"] = v_node.get("address")
342             if v_node.tag == "model":
343                 nic["model"] = v_node.get("type")
344             if v_node.tag == "target":
345                 nic["target"] = v_node.get("dev")
346             if re.match("(driver|source|address)", v_node.tag):
347                 temp = {}
348                 for key, value in v_node.attrib.items():
349                     temp[key] = value
350                 nic[v_node.tag] = temp
351             if v_node.tag == "virtualport":
352                 temp = {}
353                 temp["type"] = v_node.get("type")
354                 for key, value in v_node.attrib.items():
355                     temp[key] = value
356                 nic["virtualport"] = temp
357         if "mac" not in nic:
358             continue
359         nics[nic["mac"]] = nic
360     return nics
361 def _get_graphics(dom):
362     """
363     Get domain graphics from a libvirt domain object.
364     """
365     out = {
366         "autoport": "None",
367         "keymap": "None",
368         "listen": "None",
369         "port": "None",
370         "type": "None",
371     }
372     doc = ElementTree.fromstring(dom.XMLDesc(0))
373     for g_node in doc.findall("devices/graphics"):
374         for key, value in g_node.attrib.items():
375             out[key] = value
376     return out
377 def _get_loader(dom):
378     """
379     Get domain loader from a libvirt domain object.
380     """
381     out = {"path": "None"}
382     doc = ElementTree.fromstring(dom.XMLDesc(0))
383     for g_node in doc.findall("os/loader"):
384         out["path"] = g_node.text
385         for key, value in g_node.attrib.items():
386             out[key] = value
387     return out
388 def _get_disks(conn, dom):
389     """
390     Get domain disks from a libvirt domain object.
391     """
392     disks = {}
393     doc = ElementTree.fromstring(dom.XMLDesc(0))
394     all_volumes = _get_all_volumes_paths(conn)
395     for elem in doc.findall("devices/disk"):
396         source = elem.find("source")
397         if source is None:
398             continue
399         target = elem.find("target")
400         driver = elem.find("driver")
401         if target is None:
402             continue
403         qemu_target = None
404         extra_properties = None
405         if "dev" in target.attrib:
406             disk_type = elem.get("type")
407             def _get_disk_volume_data(pool_name, volume_name):
408                 qemu_target = "{}/{}".format(pool_name, volume_name)
409                 pool = conn.storagePoolLookupByName(pool_name)
410                 extra_properties = {}
411                 try:
412                     vol = pool.storageVolLookupByName(volume_name)
413                     vol_info = vol.info()
414                     extra_properties = {
415                         "virtual size": vol_info[1],
416                         "disk size": vol_info[2],
417                     }
418                     backing_files = [
419                         {
420                             "file": node.find("source").get("file"),
421                             "file format": node.find("format").get("type"),
422                         }
423                         for node in elem.findall(".//backingStore[source]")
424                     ]
425                     if backing_files:
426                         extra_properties["backing file"] = backing_files[0]
427                         parent = extra_properties["backing file"]
428                         for sub_backing_file in backing_files[1:]:
429                             parent["backing file"] = sub_backing_file
430                             parent = sub_backing_file
431                     else:
432                         vol_desc = ElementTree.fromstring(vol.XMLDesc())
433                         backing_path = vol_desc.find("./backingStore/path")
434                         backing_format = vol_desc.find("./backingStore/format")
435                         if backing_path is not None:
436                             extra_properties["backing file"] = {
437                                 "file": backing_path.text
438                             }
439                             if backing_format is not None:
440                                 extra_properties["backing file"][
441                                     "file format"
442                                 ] = backing_format.get("type")
443                 except libvirt.libvirtError:
444                     log.info(
445                         "Couldn't extract all volume informations: pool is likely not"
446                         " running or refreshed"
447                     )
448                 return (qemu_target, extra_properties)
449             if disk_type == "file":
450                 qemu_target = source.get("file", "")
451                 if qemu_target.startswith("/dev/zvol/"):
452                     disks[target.get("dev")] = {"file": qemu_target, "zfs": True}
453                     continue
454                 if qemu_target in all_volumes.keys():
455                     volume = all_volumes[qemu_target]
456                     qemu_target, extra_properties = _get_disk_volume_data(
457                         volume["pool"], volume["name"]
458                     )
459                 elif elem.get("device", "disk") != "cdrom":
460                     try:
461                         process = subprocess.Popen(
462                             [
463                                 "qemu-img",
464                                 "info",
465                                 "-U",
466                                 "--output",
467                                 "json",
468                                 "--backing-chain",
469                                 qemu_target,
470                             ],
471                             shell=False,
472                             stdout=subprocess.PIPE,
473                             stderr=subprocess.PIPE,
474                         )
475                         stdout, stderr = process.communicate()
476                         if process.returncode == 0:
477                             qemu_output = salt.utils.stringutils.to_str(stdout)
478                             output = _parse_qemu_img_info(qemu_output)
479                             extra_properties = output
480                         else:
481                             extra_properties = {"error": stderr}
482                     except FileNotFoundError:
483                         extra_properties = {"error": "qemu-img not found"}
484             elif disk_type == "block":
485                 qemu_target = source.get("dev", "")
486                 if qemu_target in all_volumes.keys():
487                     volume = all_volumes[qemu_target]
488                     qemu_target, extra_properties = _get_disk_volume_data(
489                         volume["pool"], volume["name"]
490                     )
491             elif disk_type == "network":
492                 qemu_target = source.get("protocol")
493                 source_name = source.get("name")
494                 if source_name:
495                     qemu_target = "{}:{}".format(qemu_target, source_name)
496                 if source.get("protocol") in ["rbd", "gluster"]:
497                     for pool_i in conn.listAllStoragePools():
498                         pool_i_xml = ElementTree.fromstring(pool_i.XMLDesc())
499                         name_node = pool_i_xml.find("source/name")
500                         if name_node is not None and source_name.startswith(
501                             "{}/".format(name_node.text)
502                         ):
503                             qemu_target = "{}{}".format(
504                                 pool_i.name(), source_name[len(name_node.text) :]
505                             )
506                             break
507                 if elem.get("device", "disk") == "cdrom":
508                     host_node = source.find("host")
509                     if host_node is not None:
510                         hostname = host_node.get("name")
511                         port = host_node.get("port")
512                         qemu_target = urllib.parse.urlunparse(
513                             (
514                                 source.get("protocol"),
515                                 "{}:{}".format(hostname, port) if port else hostname,
516                                 source_name,
517                                 "",
518                                 saxutils.unescape(source.get("query", "")),
519                                 "",
520                             )
521                         )
522             elif disk_type == "volume":
523                 pool_name = source.get("pool")
524                 volume_name = source.get("volume")
525                 qemu_target, extra_properties = _get_disk_volume_data(
526                     pool_name, volume_name
527                 )
528             if not qemu_target:
529                 continue
530             disk = {
531                 "file": qemu_target,
532                 "type": elem.get("device"),
533             }
534             if driver is not None and "type" in driver.attrib:
535                 disk["file format"] = driver.get("type")
536             if extra_properties:
537                 disk.update(extra_properties)
538             disks[target.get("dev")] = disk
539     return disks
540 def _libvirt_creds():
541     """
542     Returns the user and group that the disk images should be owned by
543     """
544     g_cmd = ["grep", "^\\s*group", "/etc/libvirt/qemu.conf"]
545     u_cmd = ["grep", "^\\s*user", "/etc/libvirt/qemu.conf"]
546     try:
547         stdout = subprocess.Popen(g_cmd, stdout=subprocess.PIPE).communicate()[0]
548         group = salt.utils.stringutils.to_str(stdout).split('"')[1]
549     except IndexError:
550         group = "root"
551     try:
552         stdout = subprocess.Popen(u_cmd, stdout=subprocess.PIPE).communicate()[0]
553         user = salt.utils.stringutils.to_str(stdout).split('"')[1]
554     except IndexError:
555         user = "root"
556     return {"user": user, "group": group}
557 def _migrate(dom, dst_uri, **kwargs):
558     """
559     Migrate the domain object from its current host to the destination
560     host given by URI.
561     :param dom: domain object to migrate
562     :param dst_uri: destination URI
563     :param kwargs:
564         - live:            Use live migration. Default value is True.
565         - persistent:      Leave the domain persistent on destination host.
566                            Default value is True.
567         - undefinesource:  Undefine the domain on the source host.
568                            Default value is True.
569         - offline:         If set to True it will migrate the domain definition
570                            without starting the domain on destination and without
571                            stopping it on source host. Default value is False.
572         - max_bandwidth:   The maximum bandwidth (in MiB/s) that will be used.
573         - max_downtime:    Set maximum tolerable downtime for live-migration.
574                            The value represents a number of milliseconds the guest
575                            is allowed to be down at the end of live migration.
576         - parallel_connections: Specify a number of parallel network connections
577                            to be used to send memory pages to the destination host.
578         - compressed:      Activate compression.
579         - comp_methods:    A comma-separated list of compression methods. Supported
580                            methods are "mt" and "xbzrle" and can be  used in any
581                            combination. QEMU defaults to "xbzrle".
582         - comp_mt_level:   Set compression level. Values are in range from 0 to 9,
583                            where 1 is maximum speed and 9 is  maximum compression.
584         - comp_mt_threads: Set number of compress threads on source host.
585         - comp_mt_dthreads: Set number of decompress threads on target host.
586         - comp_xbzrle_cache: Set the size of page cache for xbzrle compression in bytes.
587         - copy_storage:    Migrate non-shared storage. It must be one of the following
588                            values: all (full disk copy) or incremental (Incremental copy)
589         - postcopy:        Enable the use of post-copy migration.
590         - postcopy_bandwidth: The maximum bandwidth allowed in post-copy phase. (MiB/s)
591         - username:        Username to connect with target host
592         - password:        Password to connect with target host
593     """
594     flags = 0
595     params = {}
596     migrated_state = libvirt.VIR_DOMAIN_RUNNING_MIGRATED
597     if kwargs.get("live", True):
598         flags |= libvirt.VIR_MIGRATE_LIVE
599     if kwargs.get("persistent", True):
600         flags |= libvirt.VIR_MIGRATE_PERSIST_DEST
601     if kwargs.get("undefinesource", True):
602         flags |= libvirt.VIR_MIGRATE_UNDEFINE_SOURCE
603     max_bandwidth = kwargs.get("max_bandwidth")
604     if max_bandwidth:
605         try:
606             bandwidth_value = int(max_bandwidth)
607         except ValueError:
608             raise SaltInvocationError(
609                 "Invalid max_bandwidth value: {}".format(max_bandwidth)
610             )
611         dom.migrateSetMaxSpeed(bandwidth_value)
612     max_downtime = kwargs.get("max_downtime")
613     if max_downtime:
614         try:
615             downtime_value = int(max_downtime)
616         except ValueError:
617             raise SaltInvocationError(
618                 "Invalid max_downtime value: {}".format(max_downtime)
619             )
620         dom.migrateSetMaxDowntime(downtime_value)
621     if kwargs.get("offline") is True:
622         flags |= libvirt.VIR_MIGRATE_OFFLINE
623         migrated_state = libvirt.VIR_DOMAIN_RUNNING_UNPAUSED
624     if kwargs.get("compressed") is True:
625         flags |= libvirt.VIR_MIGRATE_COMPRESSED
626     comp_methods = kwargs.get("comp_methods")
627     if comp_methods:
628         params[libvirt.VIR_MIGRATE_PARAM_COMPRESSION] = comp_methods.split(",")
629     comp_options = {
630         "comp_mt_level": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_LEVEL,
631         "comp_mt_threads": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_THREADS,
632         "comp_mt_dthreads": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_DTHREADS,
633         "comp_xbzrle_cache": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_XBZRLE_CACHE,
634     }
635     for (comp_option, param_key) in comp_options.items():
636         comp_option_value = kwargs.get(comp_option)
637         if comp_option_value:
638             try:
639                 params[param_key] = int(comp_option_value)
640             except ValueError:
641                 raise SaltInvocationError("Invalid {} value".format(comp_option))
642     parallel_connections = kwargs.get("parallel_connections")
643     if parallel_connections:
644         try:
645             params[libvirt.VIR_MIGRATE_PARAM_PARALLEL_CONNECTIONS] = int(
646                 parallel_connections
647             )
648         except ValueError:
649             raise SaltInvocationError("Invalid parallel_connections value")
650         flags |= libvirt.VIR_MIGRATE_PARALLEL
651     if __salt__["config.get"]("virt:tunnel"):
652         if parallel_connections:
653             raise SaltInvocationError(
654                 "Parallel migration isn't compatible with tunneled migration"
655             )
656         flags |= libvirt.VIR_MIGRATE_PEER2PEER
657         flags |= libvirt.VIR_MIGRATE_TUNNELLED
658     if kwargs.get("postcopy") is True:
659         flags |= libvirt.VIR_MIGRATE_POSTCOPY
660     postcopy_bandwidth = kwargs.get("postcopy_bandwidth")
661     if postcopy_bandwidth:
662         try:
663             postcopy_bandwidth_value = int(postcopy_bandwidth)
664         except ValueError:
665             raise SaltInvocationError("Invalid postcopy_bandwidth value")
666         dom.migrateSetMaxSpeed(
667             postcopy_bandwidth_value,
668             flags=libvirt.VIR_DOMAIN_MIGRATE_MAX_SPEED_POSTCOPY,
669         )
670     copy_storage = kwargs.get("copy_storage")
671     if copy_storage:
672         if copy_storage == "all":
673             flags |= libvirt.VIR_MIGRATE_NON_SHARED_DISK
674         elif copy_storage in ["inc", "incremental"]:
675             flags |= libvirt.VIR_MIGRATE_NON_SHARED_INC
676         else:
677             raise SaltInvocationError("invalid copy_storage value")
678     try:
679         state = False
680         dst_conn = __get_conn(
681             connection=dst_uri,
682             username=kwargs.get("username"),
683             password=kwargs.get("password"),
684         )
685         new_dom = dom.migrate3(dconn=dst_conn, params=params, flags=flags)
686         if new_dom:
687             state = new_dom.state()
688         dst_conn.close()
689         return state and migrated_state in state
690     except libvirt.libvirtError as err:
691         dst_conn.close()
692         raise CommandExecutionError(err.get_error_message())
693 def _get_volume_path(pool, volume_name):
694     """
695     Get the path to a volume. If the volume doesn't exist, compute its path from the pool one.
696     """
697     if volume_name in pool.listVolumes():
698         volume = pool.storageVolLookupByName(volume_name)
699         volume_xml = ElementTree.fromstring(volume.XMLDesc())
700         return volume_xml.find("./target/path").text
701     pool_xml = ElementTree.fromstring(pool.XMLDesc())
702     pool_path = pool_xml.find("./target/path").text
703     return pool_path + "/" + volume_name
704 def _disk_from_pool(conn, pool, pool_xml, volume_name):
705     """
706     Create a disk definition out of the pool XML and volume name.
707     The aim of this function is to replace the volume-based definition when not handled by libvirt.
708     It returns the disk Jinja context to be used when creating the VM
709     """
710     pool_type = pool_xml.get("type")
711     disk_context = {}
712     if pool_type in ["dir", "netfs", "fs"]:
713         disk_context["type"] = "file"
714         disk_context["source_file"] = _get_volume_path(pool, volume_name)
715     elif pool_type in ["logical", "disk", "iscsi", "scsi"]:
716         disk_context["type"] = "block"
717         disk_context["format"] = "raw"
718         disk_context["source_file"] = _get_volume_path(pool, volume_name)
719     elif pool_type in ["rbd", "gluster", "sheepdog"]:
720         disk_context["type"] = "network"
721         disk_context["protocol"] = pool_type
722         disk_context["hosts"] = [
723             {"name": host.get("name"), "port": host.get("port")}
724             for host in pool_xml.findall(".//host")
725         ]
726         dir_node = pool_xml.find("./source/dir")
727         name_node = pool_xml.find("./source/name")
728         if name_node is not None:
729             disk_context["volume"] = "{}/{}".format(name_node.text, volume_name)
730         auth_node = pool_xml.find("./source/auth")
731         if auth_node is not None:
732             username = auth_node.get("username")
733             secret_node = auth_node.find("./secret")
734             usage = secret_node.get("usage")
735             if not usage:
736                 uuid = secret_node.get("uuid")
737                 usage = conn.secretLookupByUUIDString(uuid).usageID()
738             disk_context["auth"] = {
739                 "type": "ceph",
740                 "username": username,
741                 "usage": usage,
742             }
743     return disk_context
744 def _handle_unit(s, def_unit="m"):
745     """
746     Handle the unit conversion, return the value in bytes
747     """
748     m = re.match(r"(?P&lt;value&gt;[0-9.]*)\s*(?P&lt;unit&gt;.*)$", str(s).strip())
749     value = m.group("value")
750     unit = m.group("unit").lower() or def_unit
751     try:
752         value = int(value)
753     except ValueError:
754         try:
755             value = float(value)
756         except ValueError:
757             raise SaltInvocationError("invalid number")
758     dec = False
759     if re.match(r"[kmgtpezy]b$", unit):
760         dec = True
761     elif not re.match(r"(b|[kmgtpezy](ib)?)$", unit):
762         raise SaltInvocationError("invalid units")
763     p = "bkmgtpezy".index(unit[0])
764     value *= 10 ** (p * 3) if dec else 2 ** (p * 10)
765     return int(value)
766 def nesthash(value=None):
767     """
768     create default dict that allows arbitrary level of nesting
769     """
770     return collections.defaultdict(nesthash, value or {})
771 def _gen_xml(
772     conn,
773     name,
774     cpu,
775     mem,
776     diskp,
777     nicp,
778     hypervisor,
779     os_type,
780     arch,
781     graphics=None,
782     boot=None,
783     boot_dev=None,
784     numatune=None,
785     hypervisor_features=None,
786     clock=None,
787     serials=None,
788     consoles=None,
789     stop_on_reboot=False,
790     host_devices=None,
791     **kwargs
792 ):
793     """
794     Generate the XML string to define a libvirt VM
795     """
796     context = {
797         "hypervisor": hypervisor,
798         "name": name,
799         "hypervisor_features": hypervisor_features or {},
800         "clock": clock or {},
801         "on_reboot": "destroy" if stop_on_reboot else "restart",
802     }
803     context["to_kib"] = lambda v: int(_handle_unit(v) / 1024)
804     context["yesno"] = lambda v: "yes" if v else "no"
805     context["mem"] = nesthash()
806     if isinstance(mem, int):
807         context["mem"]["boot"] = mem
808         context["mem"]["current"] = mem
809     elif isinstance(mem, dict):
810         context["mem"] = nesthash(mem)
811     context["cpu"] = nesthash()
812     context["cputune"] = nesthash()
813     if isinstance(cpu, int):
814         context["cpu"]["maximum"] = str(cpu)
815     elif isinstance(cpu, dict):
816         context["cpu"] = nesthash(cpu)
817     if clock:
818         offset = "utc" if clock.get("utc", True) else "localtime"
819         if "timezone" in clock:
820             offset = "timezone"
821         context["clock"]["offset"] = offset
822     if hypervisor in ["qemu", "kvm"]:
823         context["numatune"] = numatune if numatune else {}
824         context["controller_model"] = False
825     elif hypervisor == "vmware":
826         context["controller_model"] = "lsilogic"
827     if graphics:
828         if "listen" not in graphics:
829             graphics["listen"] = {"type": "address", "address": "0.0.0.0"}
830         elif (
831             "address" not in graphics["listen"]
832             and graphics["listen"]["type"] == "address"
833         ):
834             graphics["listen"]["address"] = "0.0.0.0"
835         if graphics.get("type", "none") == "none":
836             graphics = None
837     context["graphics"] = graphics
838     context["boot_dev"] = boot_dev.split() if boot_dev is not None else ["hd"]
839     context["boot"] = boot if boot else {}
840     efi_value = context["boot"].get("efi", None) if boot else None
841     if efi_value is True:
842         context["boot"]["os_attrib"] = "firmware='efi'"
843     elif efi_value is not None and type(efi_value) != bool:
844         raise SaltInvocationError("Invalid efi value")
845     if os_type == "xen":
846         if __grains__["os_family"] == "Suse":
847             if not boot or not boot.get("kernel", None):
848                 paths = [
849                     path
850                     for path in ["/usr/share", "/usr/lib"]
851                     if os.path.exists(path + "/grub2/x86_64-xen/grub.xen")
852                 ]
853                 if not paths:
854                     raise CommandExecutionError("grub-x86_64-xen needs to be installed")
855                 context["boot"]["kernel"] = paths[0] + "/grub2/x86_64-xen/grub.xen"
856                 context["boot_dev"] = []
857     default_port = 23023
858     default_chardev_type = "tcp"
859     chardev_types = ["serial", "console"]
860     for chardev_type in chardev_types:
861         context[chardev_type + "s"] = []
862         parameter_value = locals()[chardev_type + "s"]
863         if parameter_value is not None:
864             for chardev in parameter_value:
865                 chardev_context = chardev
866                 chardev_context["type"] = chardev.get("type", default_chardev_type)
867                 if chardev_context["type"] == "tcp":
868                     chardev_context["port"] = chardev.get("port", default_port)
869                     chardev_context["protocol"] = chardev.get("protocol", "telnet")
870                 context[chardev_type + "s"].append(chardev_context)
871     context["disks"] = []
872     disk_bus_map = {"virtio": "vd", "xen": "xvd", "fdc": "fd", "ide": "hd"}
873     targets = []
874     for i, disk in enumerate(diskp):
875         prefix = disk_bus_map.get(disk["model"], "sd")
876         disk_context = {
877             "device": disk.get("device", "disk"),
878             "target_dev": _get_disk_target(targets, len(diskp), prefix),
879             "disk_bus": disk["model"],
880             "format": disk.get("format", "raw"),
881             "index": str(i),
882             "io": disk.get("io", "native"),
883             "iothread": disk.get("iothread_id", None),
884         }
885         targets.append(disk_context["target_dev"])
886         if disk.get("source_file"):
887             url = urllib.parse.urlparse(disk["source_file"])
888             if not url.scheme or not url.hostname:
889                 disk_context["source_file"] = disk["source_file"]
890                 disk_context["type"] = "file"
891             elif url.scheme in ["http", "https", "ftp", "ftps", "tftp"]:
892                 disk_context["type"] = "network"
893                 disk_context["protocol"] = url.scheme
894                 disk_context["volume"] = url.path
895                 disk_context["query"] = saxutils.escape(url.query)
896                 disk_context["hosts"] = [{"name": url.hostname, "port": url.port}]
897         elif disk.get("pool"):
898             disk_context["volume"] = disk["filename"]
899             pool = conn.storagePoolLookupByName(disk["pool"])
900             pool_xml = ElementTree.fromstring(pool.XMLDesc())
901             pool_type = pool_xml.get("type")
902             if hypervisor == "xen" or pool_type in ["rbd", "gluster", "sheepdog"]:
903                 disk_context.update(
904                     _disk_from_pool(conn, pool, pool_xml, disk_context["volume"])
905                 )
906             else:
907                 if pool_type in ["disk", "logical"]:
908                     disk_context["format"] = "raw"
909                 disk_context["type"] = "volume"
910                 disk_context["pool"] = disk["pool"]
911         else:
912             disk_context["type"] = "file"
913         if hypervisor in ["qemu", "kvm", "bhyve", "xen"]:
914             disk_context["address"] = False
915             disk_context["driver"] = True
916         elif hypervisor in ["esxi", "vmware"]:
917             disk_context["address"] = True
918             disk_context["driver"] = False
919         context["disks"].append(disk_context)
920     context["nics"] = nicp
921     hostdev_context = []
922     try:
923         for hostdev_name in host_devices or []:
924             hostdevice = conn.nodeDeviceLookupByName(hostdev_name)
925             doc = ElementTree.fromstring(hostdevice.XMLDesc())
926             if "pci" in hostdevice.listCaps():
927                 hostdev_context.append(
928                     {
929                         "type": "pci",
930                         "domain": "0x{:04x}".format(
931                             int(doc.find("./capability[@type='pci']/domain").text)
932                         ),
933                         "bus": "0x{:02x}".format(
934                             int(doc.find("./capability[@type='pci']/bus").text)
935                         ),
936                         "slot": "0x{:02x}".format(
937                             int(doc.find("./capability[@type='pci']/slot").text)
938                         ),
939                         "function": "0x{}".format(
940                             doc.find("./capability[@type='pci']/function").text
941                         ),
942                     }
943                 )
944             elif "usb_device" in hostdevice.listCaps():
945                 vendor_id = doc.find(".//vendor").get("id")
946                 product_id = doc.find(".//product").get("id")
947                 hostdev_context.append(
948                     {"type": "usb", "vendor": vendor_id, "product": product_id}
949                 )
950     except libvirt.libvirtError as err:
951         conn.close()
952         raise CommandExecutionError(
953             "Failed to get host devices: " + err.get_error_message()
954         )
955     context["hostdevs"] = hostdev_context
956     context["os_type"] = os_type
957     context["arch"] = arch
958     fn_ = "libvirt_domain.jinja"
959     try:
960         template = JINJA.get_template(fn_)
961     except jinja2.exceptions.TemplateNotFound:
962         log.error("Could not load template %s", fn_)
963         return ""
964     return template.render(**context)
965 def _gen_vol_xml(
966     name,
967     size,
968     format=None,
969     allocation=0,
970     type=None,
971     permissions=None,
972     backing_store=None,
973     nocow=False,
974 ):
975     """
976     Generate the XML string to define a libvirt storage volume
977     """
978     size = int(size) * 1024  # MB
979     context = {
980         "type": type,
981         "name": name,
982         "target": {"permissions": permissions, "nocow": nocow},
983         "format": format,
984         "size": str(size),
985         "allocation": str(int(allocation) * 1024),
986         "backingStore": backing_store,
987     }
988     fn_ = "libvirt_volume.jinja"
989     try:
990         template = JINJA.get_template(fn_)
991     except jinja2.exceptions.TemplateNotFound:
992         log.error("Could not load template %s", fn_)
993         return ""
994     return template.render(**context)
995 def _gen_net_xml(
996     name,
997     bridge,
998     forward,
999     vport,
1000     tag=None,
1001     ip_configs=None,
1002     mtu=None,
1003     domain=None,
1004     nat=None,
1005     interfaces=None,
1006     addresses=None,
1007     physical_function=None,
1008     dns=None,
1009 ):
1010     """
1011     Generate the XML string to define a libvirt network
1012     """
1013     if isinstance(vport, str):
1014         vport_context = {"type": vport}
1015     else:
1016         vport_context = vport
1017     if isinstance(tag, (str, int)):
1018         tag_context = {"tags": [{"id": tag}]}
1019     else:
1020         tag_context = tag
1021     addresses_context = []
1022     if addresses:
1023         matches = [
1024             re.fullmatch(r"([0-9]+):([0-9A-Fa-f]+):([0-9A-Fa-f]+)\.([0-9])", addr)
1025             for addr in addresses.lower().split(" ")
1026         ]
1027         addresses_context = [
1028             {
1029                 "domain": m.group(1),
1030                 "bus": m.group(2),
1031                 "slot": m.group(3),
1032                 "function": m.group(4),
1033             }
1034             for m in matches
1035             if m
1036         ]
1037     context = {
1038         "name": name,
1039         "bridge": bridge,
1040         "mtu": mtu,
1041         "domain": domain,
1042         "forward": forward,
1043         "nat": nat,
1044         "interfaces": interfaces.split(" ") if interfaces else [],
1045         "addresses": addresses_context,
1046         "pf": physical_function,
1047         "vport": vport_context,
1048         "vlan": tag_context,
1049         "dns": dns,
1050         "ip_configs": [
1051             {
1052                 "address": ipaddress.ip_network(config["cidr"]),
1053                 "dhcp_ranges": config.get("dhcp_ranges", []),
1054                 "hosts": config.get("hosts", {}),
1055                 "bootp": config.get("bootp", {}),
1056                 "tftp": config.get("tftp"),
1057             }
1058             for config in ip_configs or []
1059         ],
1060         "yesno": lambda v: "yes" if v else "no",
1061     }
1062     fn_ = "libvirt_network.jinja"
1063     try:
1064         template = JINJA.get_template(fn_)
1065     except jinja2.exceptions.TemplateNotFound:
1066         log.error("Could not load template %s", fn_)
1067         return ""
1068     return template.render(**context)
1069 def _gen_pool_xml(
1070     name,
1071     ptype,
1072     target=None,
1073     permissions=None,
1074     source_devices=None,
1075     source_dir=None,
1076     source_adapter=None,
1077     source_hosts=None,
1078     source_auth=None,
1079     source_name=None,
1080     source_format=None,
1081     source_initiator=None,
1082 ):
1083     """
1084     Generate the XML string to define a libvirt storage pool
1085     """
1086     hosts = [host.split(":") for host in source_hosts or []]
1087     source = None
1088     if any(
1089         [
1090             source_devices,
1091             source_dir,
1092             source_adapter,
1093             hosts,
1094             source_auth,
1095             source_name,
1096             source_format,
1097             source_initiator,
1098         ]
1099     ):
1100         source = {
1101             "devices": source_devices or [],
1102             "dir": source_dir
1103             if source_format != "cifs" or not source_dir
1104             else source_dir.lstrip("/"),
1105             "adapter": source_adapter,
1106             "hosts": [
1107                 {"name": host[0], "port": host[1] if len(host) &gt; 1 else None}
1108                 for host in hosts
1109             ],
1110             "auth": source_auth,
1111             "name": source_name,
1112             "format": source_format,
1113             "initiator": source_initiator,
1114         }
1115     context = {
1116         "name": name,
1117         "ptype": ptype,
1118         "target": {"path": target, "permissions": permissions},
1119         "source": source,
1120     }
1121     fn_ = "libvirt_pool.jinja"
1122     try:
1123         template = JINJA.get_template(fn_)
1124     except jinja2.exceptions.TemplateNotFound:
1125         log.error("Could not load template %s", fn_)
1126         return ""
1127     return template.render(**context)
1128 def _gen_secret_xml(auth_type, usage, description):
1129     """
1130     Generate a libvirt secret definition XML
1131     """
1132     context = {
1133         "type": auth_type,
1134         "usage": usage,
1135         "description": description,
1136     }
1137     fn_ = "libvirt_secret.jinja"
1138     try:
1139         template = JINJA.get_template(fn_)
1140     except jinja2.exceptions.TemplateNotFound:
1141         log.error("Could not load template %s", fn_)
1142         return ""
1143     return template.render(**context)
1144 def _get_images_dir():
1145     """
1146     Extract the images dir from the configuration. First attempts to
1147     find legacy virt.images, then tries virt:images.
1148     """
1149     img_dir = __salt__["config.get"]("virt:images")
1150     log.debug("Image directory from config option `virt:images` is %s", img_dir)
1151     return img_dir
1152 def _zfs_image_create(
1153     vm_name,
1154     pool,
1155     disk_name,
1156     hostname_property_name,
1157     sparse_volume,
1158     disk_size,
1159     disk_image_name,
1160 ):
1161     """
1162     Clones an existing image, or creates a new one.
1163     When cloning an image, disk_image_name refers to the source
1164     of the clone. If not specified, disk_size is used for creating
1165     a new zvol, and sparse_volume determines whether to create
1166     a thin provisioned volume.
1167     The cloned or new volume can have a ZFS property set containing
1168     the vm_name. Use hostname_property_name for specifying the key
1169     of this ZFS property.
1170     """
1171     if not disk_image_name and not disk_size:
1172         raise CommandExecutionError(
1173             "Unable to create new disk {}, please specify"
1174             " the disk image name or disk size argument".format(disk_name)
1175         )
1176     if not pool:
1177         raise CommandExecutionError(
1178             "Unable to create new disk {}, please specify the disk pool name".format(
1179                 disk_name
1180             )
1181         )
1182     destination_fs = os.path.join(pool, "{}.{}".format(vm_name, disk_name))
1183     log.debug("Image destination will be %s", destination_fs)
1184     existing_disk = __salt__["zfs.list"](name=pool)
1185     if "error" in existing_disk:
1186         raise CommandExecutionError(
1187             "Unable to create new disk {}. {}".format(
1188                 destination_fs, existing_disk["error"]
1189             )
1190         )
1191     elif destination_fs in existing_disk:
1192         log.info("ZFS filesystem %s already exists. Skipping creation", destination_fs)
1193         blockdevice_path = os.path.join("/dev/zvol", pool, vm_name)
1194         return blockdevice_path
1195     properties = {}
1196     if hostname_property_name:
1197         properties[hostname_property_name] = vm_name
1198     if disk_image_name:
1199         __salt__["zfs.clone"](
1200             name_a=disk_image_name, name_b=destination_fs, properties=properties
1201         )
1202     elif disk_size:
1203         __salt__["zfs.create"](
1204             name=destination_fs,
1205             properties=properties,
1206             volume_size=disk_size,
1207             sparse=sparse_volume,
1208         )
1209     blockdevice_path = os.path.join(
1210         "/dev/zvol", pool, "{}.{}".format(vm_name, disk_name)
1211     )
1212     log.debug("Image path will be %s", blockdevice_path)
1213     return blockdevice_path
1214 def _qemu_image_create(disk, create_overlay=False, saltenv="base"):
1215     """
1216     Create the image file using specified disk_size or/and disk_image
1217     Return path to the created image file
1218     """
1219     disk_size = disk.get("size", None)
1220     disk_image = disk.get("image", None)
1221     if not disk_size and not disk_image:
1222         raise CommandExecutionError(
1223             "Unable to create new disk {}, please specify"
1224             " disk size and/or disk image argument".format(disk["filename"])
1225         )
1226     img_dest = disk["source_file"]
1227     log.debug("Image destination will be %s", img_dest)
1228     img_dir = os.path.dirname(img_dest)
1229     log.debug("Image destination directory is %s", img_dir)
1230     if not os.path.exists(img_dir):
1231         os.makedirs(img_dir)
1232     if disk_image:
1233         log.debug("Create disk from specified image %s", disk_image)
1234         sfn = __salt__["cp.cache_file"](disk_image, saltenv)
1235         qcow2 = False
1236         if salt.utils.path.which("qemu-img"):
1237             res = __salt__["cmd.run"]('qemu-img info "{}"'.format(sfn))
1238             imageinfo = salt.utils.yaml.safe_load(res)
1239             qcow2 = imageinfo["file format"] == "qcow2"
1240         try:
1241             if create_overlay and qcow2:
1242                 log.info("Cloning qcow2 image %s using copy on write", sfn)
1243                 __salt__["cmd.run"](
1244                     'qemu-img create -f qcow2 -o backing_file="{}" "{}"'.format(
1245                         sfn, img_dest
1246                     ).split()
1247                 )
1248             else:
1249                 log.debug("Copying %s to %s", sfn, img_dest)
1250                 salt.utils.files.copyfile(sfn, img_dest)
1251             mask = salt.utils.files.get_umask()
1252             if disk_size and qcow2:
1253                 log.debug("Resize qcow2 image to %sM", disk_size)
1254                 __salt__["cmd.run"](
1255                     'qemu-img resize "{}" {}M'.format(img_dest, disk_size)
1256                 )
1257             log.debug("Apply umask and remove exec bit")
1258             mode = (0o0777 ^ mask) &amp; 0o0666
1259             os.chmod(img_dest, mode)
1260         except OSError as err:
1261             raise CommandExecutionError(
1262                 "Problem while copying image. {} - {}".format(disk_image, err)
1263             )
1264     else:
1265         try:
1266             mask = salt.utils.files.get_umask()
1267             if disk_size:
1268                 log.debug("Create empty image with size %sM", disk_size)
1269                 __salt__["cmd.run"](
1270                     'qemu-img create -f {} "{}" {}M'.format(
1271                         disk.get("format", "qcow2"), img_dest, disk_size
1272                     )
1273                 )
1274             else:
1275                 raise CommandExecutionError(
1276                     "Unable to create new disk {},"
1277                     " please specify &lt;size&gt; argument".format(img_dest)
1278                 )
1279             log.debug("Apply umask and remove exec bit")
1280             mode = (0o0777 ^ mask) &amp; 0o0666
1281             os.chmod(img_dest, mode)
1282         except OSError as err:
1283             raise CommandExecutionError(
1284                 "Problem while creating volume {} - {}".format(img_dest, err)
1285             )
1286     return img_dest
1287 def _seed_image(seed_cmd, img_path, name, config, install, pub_key, priv_key):
1288     """
1289     Helper function to seed an existing image. Note that this doesn't
1290     handle volumes.
1291     """
1292     log.debug("Seeding image")
1293     __salt__[seed_cmd](
1294         img_path,
1295         id_=name,
1296         config=config,
1297         install=install,
1298         pub_key=pub_key,
1299         priv_key=priv_key,
1300     )
1301 def _disk_volume_create(conn, disk, seeder=None, saltenv="base"):
1302     """
1303     Create a disk volume for use in a VM
1304     """
1305     if disk.get("overlay_image"):
1306         raise SaltInvocationError(
1307             "Disk overlay_image property is not supported when creating volumes,"
1308             "use backing_store_path and backing_store_format instead."
1309         )
1310     pool = conn.storagePoolLookupByName(disk["pool"])
1311     if disk["filename"] in pool.listVolumes():
1312         return
1313     pool_type = ElementTree.fromstring(pool.XMLDesc()).get("type")
1314     backing_path = disk.get("backing_store_path")
1315     backing_format = disk.get("backing_store_format")
1316     backing_store = None
1317     if (
1318         backing_path
1319         and backing_format
1320         and (disk.get("format") == "qcow2" or pool_type == "logical")
1321     ):
1322         backing_store = {"path": backing_path, "format": backing_format}
1323     if backing_store and disk.get("image"):
1324         raise SaltInvocationError(
1325             "Using a template image with a backing store is not possible, "
1326             "choose either of them."
1327         )
1328     vol_xml = _gen_vol_xml(
1329         disk["filename"],
1330         disk.get("size", 0),
1331         format=disk.get("format"),
1332         backing_store=backing_store,
1333     )
1334     _define_vol_xml_str(conn, vol_xml, disk.get("pool"))
1335     if disk.get("image"):
1336         log.debug("Caching disk template image: %s", disk.get("image"))
1337         cached_path = __salt__["cp.cache_file"](disk.get("image"), saltenv)
1338         if seeder:
1339             seeder(cached_path)
1340         _volume_upload(
1341             conn,
1342             disk["pool"],
1343             disk["filename"],
1344             cached_path,
1345             sparse=disk.get("format") == "qcow2",
1346         )
1347 def _disk_profile(conn, profile, hypervisor, disks, vm_name):
1348     """
1349     Gather the disk profile from the config or apply the default based
1350     on the active hypervisor
1351     This is the ``default`` profile for KVM/QEMU, which can be
1352     overridden in the configuration:
1353     .. code-block:: yaml
1354         virt:
1355           disk:
1356             default:
1357               - system:
1358                   size: 8192
1359                   format: qcow2
1360                   model: virtio
1361     Example profile for KVM/QEMU with two disks, first is created
1362     from specified image, the second is empty:
1363     .. code-block:: yaml
1364         virt:
1365           disk:
1366             two_disks:
1367               - system:
1368                   size: 8192
1369                   format: qcow2
1370                   model: virtio
1371                   image: http://path/to/image.qcow2
1372               - lvm:
1373                   size: 32768
1374                   format: qcow2
1375                   model: virtio
1376     The ``format`` and ``model`` parameters are optional, and will
1377     default to whatever is best suitable for the active hypervisor.
1378     """
1379     default = [{"system": {"size": 8192}}]
1380     if hypervisor == "vmware":
1381         overlay = {"format": "vmdk", "model": "scsi", "device": "disk"}
1382     elif hypervisor in ["qemu", "kvm"]:
1383         overlay = {"device": "disk", "model": "virtio"}
1384     elif hypervisor == "xen":
1385         overlay = {"device": "disk", "model": "xen"}
1386     elif hypervisor == "bhyve":
1387         overlay = {"format": "raw", "model": "virtio", "sparse_volume": False}
1388     else:
1389         overlay = {}
1390     disklist = []
1391     if profile:
1392         disklist = copy.deepcopy(
1393             __salt__["config.get"]("virt:disk", {}).get(profile, default)
1394         )
1395         disklist = [dict(d, name=name) for disk in disklist for name, d in disk.items()]
1396     if disks:
1397         for udisk in disks:
1398             if "name" in udisk:
1399                 found = [disk for disk in disklist if udisk["name"] == disk["name"]]
1400                 if found:
1401                     found[0].update(udisk)
1402                 else:
1403                     disklist.append(udisk)
1404     pool_caps = _pool_capabilities(conn)
1405     for disk in disklist:
1406         if disk.get("device", "disk") == "cdrom" and "model" not in disk:
1407             disk["model"] = "ide"
1408         for key, val in overlay.items():
1409             if key not in disk:
1410                 disk[key] = val
1411         if disk.get("source_file") and os.path.exists(disk["source_file"]):
1412             disk["filename"] = os.path.basename(disk["source_file"])
1413             if not disk.get("format"):
1414                 disk["format"] = (
1415                     "qcow2" if disk.get("device", "disk") != "cdrom" else "raw"
1416                 )
1417         elif vm_name and disk.get("device", "disk") == "disk":
1418             _fill_disk_filename(conn, vm_name, disk, hypervisor, pool_caps)
1419     return disklist
1420 def _fill_disk_filename(conn, vm_name, disk, hypervisor, pool_caps):
1421     """
1422     Compute the disk file name and update it in the disk value.
1423     """
1424     disk["filename"] = "{}_{}".format(vm_name, disk["name"])
1425     base_dir = disk.get("pool", None)
1426     if hypervisor in ["qemu", "kvm", "xen"]:
1427         if not base_dir:
1428             base_dir = _get_images_dir()
1429         if base_dir not in conn.listStoragePools():
1430             if not disk.get("format"):
1431                 disk["format"] = "qcow2"
1432             disk["filename"] = "{}.{}".format(disk["filename"], disk["format"])
1433             disk["source_file"] = os.path.join(base_dir, disk["filename"])
1434         else:
1435             if "pool" not in disk:
1436                 disk["pool"] = base_dir
1437             pool_obj = conn.storagePoolLookupByName(base_dir)
1438             pool_xml = ElementTree.fromstring(pool_obj.XMLDesc())
1439             pool_type = pool_xml.get("type")
1440             if pool_type == "disk":
1441                 device = pool_xml.find("./source/device").get("path")
1442                 all_volumes = pool_obj.listVolumes()
1443                 if disk.get("source_file") not in all_volumes:
1444                     indexes = [
1445                         int(re.sub("[a-z]+", "", vol_name)) for vol_name in all_volumes
1446                     ] or [0]
1447                     index = min(
1448                         idx for idx in range(1, max(indexes) + 2) if idx not in indexes
1449                     )
1450                     disk["filename"] = "{}{}".format(os.path.basename(device), index)
1451             if disk.get("source_file"):
1452                 if not disk.get("source_file") in pool_obj.listVolumes():
1453                     raise SaltInvocationError(
1454                         "{} volume doesn't exist in pool {}".format(
1455                             disk.get("source_file"), base_dir
1456                         )
1457                     )
1458                 disk["filename"] = disk["source_file"]
1459                 del disk["source_file"]
1460             if not disk.get("format"):
1461                 volume_options = (
1462                     [
1463                         type_caps.get("options", {}).get("volume", {})
1464                         for type_caps in pool_caps.get("pool_types")
1465                         if type_caps["name"] == pool_type
1466                     ]
1467                     or [{}]
1468                 )[0]
1469                 if "qcow2" in volume_options.get("targetFormatType", []):
1470                     disk["format"] = "qcow2"
1471                 else:
1472                     disk["format"] = volume_options.get("default_format", None)
1473     elif hypervisor == "bhyve" and vm_name:
1474         disk["filename"] = "{}.{}".format(vm_name, disk["name"])
1475         disk["source_file"] = os.path.join(
1476             "/dev/zvol", base_dir or "", disk["filename"]
1477         )
1478     elif hypervisor in ["esxi", "vmware"]:
1479         if not base_dir:
1480             base_dir = __salt__["config.get"]("virt:storagepool", "[0] ")
1481         disk["filename"] = "{}.{}".format(disk["filename"], disk["format"])
1482         disk["source_file"] = "{}{}".format(base_dir, disk["filename"])
1483 def _complete_nics(interfaces, hypervisor):
1484     """
1485     Complete missing data for network interfaces.
1486     """
1487     vmware_overlay = {"type": "bridge", "source": "DEFAULT", "model": "e1000"}
1488     kvm_overlay = {"type": "bridge", "source": "br0", "model": "virtio"}
1489     xen_overlay = {"type": "bridge", "source": "br0", "model": None}
1490     bhyve_overlay = {"type": "bridge", "source": "bridge0", "model": "virtio"}
1491     overlays = {
1492         "xen": xen_overlay,
1493         "kvm": kvm_overlay,
1494         "qemu": kvm_overlay,
1495         "vmware": vmware_overlay,
1496         "bhyve": bhyve_overlay,
1497     }
1498     def _normalize_net_types(attributes):
1499         """
1500         Guess which style of definition:
1501             bridge: br0
1502              or
1503             network: net0
1504              or
1505             type: network
1506             source: net0
1507         """
1508         for type_ in ["bridge", "network"]:
1509             if type_ in attributes:
1510                 attributes["type"] = type_
1511                 attributes["source"] = attributes.pop(type_)
1512         attributes["type"] = attributes.get("type", None)
1513         attributes["source"] = attributes.get("source", None)
1514     def _apply_default_overlay(attributes):
1515         """
1516         Apply the default overlay to attributes
1517         """
1518         for key, value in overlays[hypervisor].items():
1519             if key not in attributes or not attributes[key]:
1520                 attributes[key] = value
1521     for interface in interfaces:
1522         _normalize_net_types(interface)
1523         if hypervisor in overlays:
1524             _apply_default_overlay(interface)
1525     return interfaces
1526 def _nic_profile(profile_name, hypervisor):
1527     """
1528     Compute NIC data based on profile
1529     """
1530     config_data = __salt__["config.get"]("virt:nic", {}).get(
1531         profile_name, [{"eth0": {}}]
1532     )
1533     interfaces = []
1534     def append_dict_profile_to_interface_list(profile_dict):
1535         """
1536         Append dictionary profile data to interfaces list
1537         """
1538         for interface_name, attributes in profile_dict.items():
1539             attributes["name"] = interface_name
1540             interfaces.append(attributes)
1541     if isinstance(config_data, dict):
1542         append_dict_profile_to_interface_list(config_data)
1543     elif isinstance(config_data, list):
1544         for interface in config_data:
1545             if isinstance(interface, dict):
1546                 if len(interface) == 1:
1547                     append_dict_profile_to_interface_list(interface)
1548                 else:
1549                     interfaces.append(interface)
1550     return _complete_nics(interfaces, hypervisor)
1551 def _get_merged_nics(hypervisor, profile, interfaces=None):
1552     """
1553     Get network devices from the profile and merge uer defined ones with them.
1554     """
1555     nicp = _nic_profile(profile, hypervisor) if profile else []
1556     log.debug("NIC profile is %s", nicp)
1557     if interfaces:
1558         users_nics = _complete_nics(interfaces, hypervisor)
1559         for unic in users_nics:
1560             found = [nic for nic in nicp if nic["name"] == unic["name"]]
1561             if found:
1562                 found[0].update(unic)
1563             else:
1564                 nicp.append(unic)
1565         log.debug("Merged NICs: %s", nicp)
1566     return nicp
1567 def _handle_remote_boot_params(orig_boot):
1568     """
1569     Checks if the boot parameters contain a remote path. If so, it will copy
1570     the parameters, download the files specified in the remote path, and return
1571     a new dictionary with updated paths containing the canonical path to the
1572     kernel and/or initrd
1573     :param orig_boot: The original boot parameters passed to the init or update
1574     functions.
1575     """
1576     saltinst_dir = None
1577     new_boot = orig_boot.copy()
1578     keys = orig_boot.keys()
1579     cases = [
1580         {"efi"},
1581         {"kernel", "initrd", "efi"},
1582         {"kernel", "initrd", "cmdline", "efi"},
1583         {"loader", "nvram"},
1584         {"kernel", "initrd"},
1585         {"kernel", "initrd", "cmdline"},
1586         {"kernel", "initrd", "loader", "nvram"},
1587         {"kernel", "initrd", "cmdline", "loader", "nvram"},
1588     ]
1589     if keys in cases:
1590         for key in keys:
1591             if key == "efi" and type(orig_boot.get(key)) == bool:
1592                 new_boot[key] = orig_boot.get(key)
1593             elif orig_boot.get(key) is not None and salt.utils.virt.check_remote(
1594                 orig_boot.get(key)
1595             ):
1596                 if saltinst_dir is None:
1597                     os.makedirs(CACHE_DIR)
1598                     saltinst_dir = CACHE_DIR
1599                 new_boot[key] = salt.utils.virt.download_remote(
1600                     orig_boot.get(key), saltinst_dir
1601                 )
1602         return new_boot
1603     else:
1604         raise SaltInvocationError(
1605             "Invalid boot parameters,It has to follow this combination: [(kernel,"
1606             " initrd) or/and cmdline] or/and [(loader, nvram) or efi]"
1607         )
1608 def _handle_efi_param(boot, desc):
1609     """
1610     Checks if boot parameter contains efi boolean value, if so, handles the firmware attribute.
1611     :param boot: The boot parameters passed to the init or update functions.
1612     :param desc: The XML description of that domain.
1613     :return: A boolean value.
1614     """
1615     efi_value = boot.get("efi", None) if boot else None
1616     parent_tag = desc.find("os")
1617     os_attrib = parent_tag.attrib
1618     if efi_value is False and os_attrib != {}:
1619         parent_tag.attrib.pop("firmware", None)
1620         return True
1621     elif type(efi_value) == bool and os_attrib == {}:
1622         if efi_value is True and parent_tag.find("loader") is None:
1623             parent_tag.set("firmware", "efi")
1624             return True
1625         if efi_value is False and parent_tag.find("loader") is not None:
1626             parent_tag.remove(parent_tag.find("loader"))
1627             parent_tag.remove(parent_tag.find("nvram"))
1628             return True
1629     elif type(efi_value) != bool:
1630         raise SaltInvocationError("Invalid efi value")
1631     return False
1632 def init(
1633     name,
1634     cpu,
1635     mem,
1636     nic="default",
1637     interfaces=None,
1638     hypervisor=None,
1639     start=True,  # pylint: disable=redefined-outer-name
1640     disk="default",
1641     disks=None,
1642     saltenv="base",
1643     seed=True,
1644     install=True,
1645     pub_key=None,
1646     priv_key=None,
1647     seed_cmd="seed.apply",
1648     graphics=None,
1649     os_type=None,
1650     arch=None,
1651     boot=None,
1652     boot_dev=None,
1653     numatune=None,
1654     hypervisor_features=None,
1655     clock=None,
1656     serials=None,
1657     consoles=None,
1658     stop_on_reboot=False,
1659     host_devices=None,
1660     **kwargs
1661 ):
1662     """
1663     Initialize a new vm
1664     :param name: name of the virtual machine to create
1665     :param cpu:
1666         Number of virtual CPUs to assign to the virtual machine or a dictionary with detailed information to configure
1667         cpu model and topology, numa node tuning, cpu tuning and iothreads allocation. The structure of the dictionary is
1668         documented in :ref:`init-cpu-def`.
1669         .. code-block:: yaml
1670              cpu:
1671                placement: static
1672                cpuset: 0-11
1673                current: 5
1674                maximum: 12
1675                vcpus:
1676                  0:
1677                    enabled: True
1678                    hotpluggable: False
1679                    order: 1
1680                  1:
1681                    enabled: False
1682                    hotpluggable: True
1683                match: minimum
1684                mode: custom
1685                check: full
1686                vendor: Intel
1687                model:
1688                  name: core2duo
1689                  fallback: allow
1690                  vendor_id: GenuineIntel
1691                topology:
1692                  sockets: 1
1693                  cores: 12
1694                  threads: 1
1695                cache:
1696                  level: 3
1697                  mode: emulate
1698                features:
1699                  lahf: optional
1700                  pcid: require
1701                numa:
1702                  0:
1703                     cpus: 0-3
1704                     memory: 1g
1705                     discard: True
1706                     distances:
1707                       0: 10     # sibling id : value
1708                       1: 21
1709                       2: 31
1710                       3: 41
1711                  1:
1712                     cpus: 4-6
1713                     memory: 1g
1714                     memAccess: shared
1715                     distances:
1716                       0: 21
1717                       1: 10
1718                       2: 21
1719                       3: 31
1720                tuning:
1721                     vcpupin:
1722                       0: 1-4,^2  # vcpuid : cpuset
1723                       1: 0,1
1724                       2: 2,3
1725                       3: 0,4
1726                     emulatorpin: 1-3
1727                     iothreadpin:
1728                       1: 5,6    # iothread id: cpuset
1729                       2: 7,8
1730                     shares: 2048
1731                     period: 1000000
1732                     quota: -1
1733                     global_period: 1000000
1734                     global_quota: -1
1735                     emulator_period: 1000000
1736                     emulator_quota: -1
1737                     iothread_period: 1000000
1738                     iothread_quota: -1
1739                     vcpusched:
1740                       - scheduler: fifo
1741                         priority: 1
1742                         vcpus: 0,3-5
1743                       - scheduler: rr
1744                         priority: 3
1745                     iothreadsched:
1746                       - scheduler: idle
1747                       - scheduler: batch
1748                         iothreads: 2,3
1749                     emulatorsched:
1750                       - scheduler: batch
1751                     cachetune:
1752                       0-3:      # vcpus set
1753                         0:      # cache id
1754                           level: 3
1755                           type: both
1756                           size: 4
1757                         1:
1758                           level: 3
1759                           type: both
1760                           size: 6
1761                         monitor:
1762                           1: 3
1763                           0-3: 3
1764                       4-5:
1765                         monitor:
1766                           4: 3  # vcpus: level
1767                           5: 3
1768                     memorytune:
1769                       0-3:      # vcpus set
1770                         0: 60   # node id: bandwidth
1771                       4-5:
1772                         0: 60
1773                iothreads: 4
1774         .. versionadded:: 3003
1775     :param mem: Amount of memory to allocate to the virtual machine in MiB. Since 3002, a dictionary can be used to
1776         contain detailed configuration which support memory allocation or tuning. Supported parameters are ``boot``,
1777         ``current``, ``max``, ``slots``, ``hard_limit``, ``soft_limit``, ``swap_hard_limit``, ``min_guarantee``,
1778         ``hugepages`` ,  ``nosharepages``, ``locked``, ``source``, ``access``, ``allocation`` and ``discard``. The structure
1779         of the dictionary is documented in  :ref:`init-mem-def`. Both decimal and binary base are supported. Detail unit
1780         specification is documented  in :ref:`virt-units`. Please note that the value for ``slots`` must be an integer.
1781         .. code-block:: python
1782             {
1783                 'boot': 1g,
1784                 'current': 1g,
1785                 'max': 1g,
1786                 'slots': 10,
1787                 'hard_limit': '1024',
1788                 'soft_limit': '512m',
1789                 'swap_hard_limit': '1g',
1790                 'min_guarantee': '512mib',
1791                 'hugepages': [{'nodeset': '0-3,^2', 'size': '1g'}, {'nodeset': '2', 'size': '2m'}],
1792                 'nosharepages': True,
1793                 'locked': True,
1794                 'source': 'file',
1795                 'access': 'shared',
1796                 'allocation': 'immediate',
1797                 'discard': True
1798             }
1799         .. versionchanged:: 3002
1800     :param nic: NIC profile to use (Default: ``'default'``).
1801                 The profile interfaces can be customized / extended with the interfaces parameter.
1802                 If set to ``None``, no profile will be used.
1803     :param interfaces:
1804         List of dictionaries providing details on the network interfaces to create.
1805         These data are merged with the ones from the nic profile. The structure of
1806         each dictionary is documented in :ref:`init-nic-def`.
1807         .. versionadded:: 2019.2.0
1808     :param hypervisor: the virtual machine type. By default the value will be computed according
1809                        to the virtual host capabilities.
1810     :param start: ``True`` to start the virtual machine after having defined it (Default: ``True``)
1811     :param disk: Disk profile to use (Default: ``'default'``). If set to ``None``, no profile will be used.
1812     :param disks: List of dictionaries providing details on the disk devices to create.
1813                   These data are merged with the ones from the disk profile. The structure of
1814                   each dictionary is documented in :ref:`init-disk-def`.
1815                   .. versionadded:: 2019.2.0
1816     :param saltenv: Fileserver environment (Default: ``'base'``).
1817                     See :mod:`cp module for more details &lt;salt.modules.cp&gt;`
1818     :param seed: ``True`` to seed the disk image. Only used when the ``image`` parameter is provided.
1819                  (Default: ``True``)
1820     :param install: install salt minion if absent (Default: ``True``)
1821     :param pub_key: public key to seed with (Default: ``None``)
1822     :param priv_key: public key to seed with (Default: ``None``)
1823     :param seed_cmd: Salt command to execute to seed the image. (Default: ``'seed.apply'``)
1824     :param graphics:
1825         Dictionary providing details on the graphics device to create. (Default: ``None``)
1826         See :ref:`init-graphics-def` for more details on the possible values.
1827         .. versionadded:: 2019.2.0
1828     :param os_type:
1829         type of virtualization as found in the ``//os/type`` element of the libvirt definition.
1830         The default value is taken from the host capabilities, with a preference for ``hvm``.
1831         .. versionadded:: 2019.2.0
1832     :param arch:
1833         architecture of the virtual machine. The default value is taken from the host capabilities,
1834         but ``x86_64`` is prefed over ``i686``.
1835         .. versionadded:: 2019.2.0
1836     :param config: minion configuration to use when seeding.
1837                    See :mod:`seed module for more details &lt;salt.modules.seed&gt;`
1838     :param boot_dev: String of space-separated devices to boot from (Default: ``'hd'``)
1839     :param connection: libvirt connection URI, overriding defaults
1840                        .. versionadded:: 2019.2.0
1841     :param username: username to connect with, overriding defaults
1842                      .. versionadded:: 2019.2.0
1843     :param password: password to connect with, overriding defaults
1844                      .. versionadded:: 2019.2.0
1845     :param stop_on_reboot:
1846         If set to ``True`` the guest will stop instead of rebooting.
1847         This is specially useful when creating a virtual machine with an installation cdrom or
1848         an autoinstallation needing a special first boot configuration.
1849         Defaults to ``False``
1850         .. versionadded:: 3003
1851     :param boot:
1852         Specifies kernel, initial ramdisk and kernel command line parameters for the virtual machine.
1853         This is an optional parameter, all of the keys are optional within the dictionary. The structure of
1854         the dictionary is documented in :ref:`init-boot-def`. If a remote path is provided to kernel or initrd,
1855         salt will handle the downloading of the specified remote file and modify the XML accordingly.
1856         To boot VM with UEFI, specify loader and nvram path or specify 'efi': ``True`` if your libvirtd version
1857         is &gt;= 5.2.0 and QEMU &gt;= 3.0.0.
1858         .. versionadded:: 3000
1859         .. code-block:: python
1860             {
1861                 'kernel': '/root/f8-i386-vmlinuz',
1862                 'initrd': '/root/f8-i386-initrd',
1863                 'cmdline': 'console=ttyS0 ks=http://example.com/f8-i386/os/',
1864                 'loader': '/usr/share/OVMF/OVMF_CODE.fd',
1865                 'nvram': '/usr/share/OVMF/OVMF_VARS.ms.fd'
1866             }
1867     :param boot_dev:
1868         Space separated list of devices to boot from sorted by decreasing priority.
1869         Values can be ``hd``, ``fd``, ``cdrom`` or ``network``.
1870         By default, the value will ``"hd"``.
1871     :param numatune:
1872         The optional numatune element provides details of how to tune the performance of a NUMA host via controlling NUMA
1873         policy for domain process. The optional ``memory`` element specifies how to allocate memory for the domain process
1874         on a NUMA host. ``memnode`` elements can specify memory allocation policies per each guest NUMA node. The definition
1875         used in the dictionary can be found at :ref:`init-cpu-def`.
1876         .. versionadded:: 3003
1877         .. code-block:: python
1878             {
1879                 'memory': {'mode': 'strict', 'nodeset': '0-11'},
1880                 'memnodes': {0: {'mode': 'strict', 'nodeset': 1}, 1: {'mode': 'preferred', 'nodeset': 2}}
1881             }
1882     :param hypervisor_features:
1883         Enable or disable hypervisor-specific features on the virtual machine.
1884         .. versionadded:: 3003
1885         .. code-block:: yaml
1886             hypervisor_features:
1887               kvm-hint-dedicated: True
1888     :param clock:
1889         Configure the guest clock.
1890         The value is a dictionary with the following keys:
1891         adjustment
1892             time adjustment in seconds or ``reset``
1893         utc
1894             set to ``False`` to use the host local time as the guest clock. Defaults to ``True``.
1895         timezone
1896             synchronize the guest to the correspding timezone
1897         timers
1898             a dictionary associating the timer name with its configuration.
1899             This configuration is a dictionary with the properties ``track``, ``tickpolicy``,
1900             ``catchup``, ``frequency``, ``mode``, ``present``, ``slew``, ``threshold`` and ``limit``.
1901             See `libvirt time keeping documentation &lt;https://libvirt.org/formatdomain.html#time-keeping&gt;`_ for the possible values.
1902         .. versionadded:: 3003
1903         Set the clock to local time using an offset in seconds
1904         .. code-block:: yaml
1905             clock:
1906               adjustment: 3600
1907               utc: False
1908         Set the clock to a specific time zone:
1909         .. code-block:: yaml
1910             clock:
1911               timezone: CEST
1912         Tweak guest timers:
1913         .. code-block:: yaml
1914             clock:
1915               timers:
1916                 tsc:
1917                   frequency: 3504000000
1918                   mode: native
1919                 rtc:
1920                   track: wall
1921                   tickpolicy: catchup
1922                   slew: 4636
1923                   threshold: 123
1924                   limit: 2342
1925                 hpet:
1926                   present: False
1927     :param serials:
1928         Dictionary providing details on the serials connection to create. (Default: ``None``)
1929         See :ref:`init-chardevs-def` for more details on the possible values.
1930         .. versionadded:: 3003
1931     :param consoles:
1932         Dictionary providing details on the consoles device to create. (Default: ``None``)
1933         See :ref:`init-chardevs-def` for more details on the possible values.
1934         .. versionadded:: 3003
1935     :param host_devices:
1936         List of host devices to passthrough to the guest.
1937         The value is a list of device names as provided by the :py:func:`~salt.modules.virt.node_devices` function.
1938         (Default: ``None``)
1939         .. versionadded:: 3003
1940     .. _init-cpu-def:
1941     .. rubric:: cpu parameters definition
1942     The cpu parameters dictionary can contain the following properties:
1943     cpuset
1944         a comma-separated list of physical CPU numbers that domain process and virtual CPUs can be pinned to by default.
1945         eg. ``1-4,^3`` cpuset 3 is excluded.
1946     current
1947         the number of virtual cpus available at startup
1948     placement
1949         indicate the CPU placement mode for domain process. the value can be either ``static`` or ``auto``
1950     vcpus
1951         specify the state of individual vcpu. Possible attribute for each individual vcpu include: ``id``, ``enabled``,
1952         ``hotpluggable`` and ``order``. Valid ``ids`` are from 0 to the maximum vCPU count minus 1. ``enabled`` takes
1953         boolean values which controls the state of the vcpu. ``hotpluggable`` take boolean value which controls whether
1954         given vCPU can be hotplugged and hotunplugged. ``order`` takes an integer value which specifies the order to add
1955         the online vCPUs.
1956     match
1957         The cpu attribute ``match`` attribute specifies how strictly the virtual CPU provided to the guest matches the CPU
1958         requirements, possible values are ``minimum``, ``exact`` or ``strict``.
1959     check
1960         Optional cpu attribute ``check`` attribute can be used to request a specific way of checking whether the virtual
1961         CPU matches the specification, possible values are ``none``, ``partial`` and ``full``.
1962     mode
1963         Optional cpu attribute ``mode`` attribute may be used to make it easier to configure a guest CPU to be as close
1964         to host CPU as possible, possible values are ``custom``, ``host-model`` and ``host-passthrough``.
1965     model
1966         specifies CPU model requested by the guest. An optional ``fallback`` attribute can be used to forbid libvirt falls
1967         back to the closest model supported by the hypervisor, possible values are ``allow`` or ``forbid``. ``vendor_id``
1968         attribute can be used to set the vendor id seen by the guest, the length must be exactly 12 characters long.
1969     vendor
1970         specifies CPU vendor requested by the guest.
1971     topology
1972         specifies requested topology of virtual CPU provided to the guest. Four possible attributes , ``sockets``, ``dies``,
1973         ``cores``, and ``threads``, accept non-zero positive integer values. They refer to the number of CPU sockets per
1974         NUMA node, number of dies per socket, number of cores per die, and number of threads per core, respectively.
1975     features
1976         A dictionary contains a set of cpu features to fine-tune features provided by the selected CPU model. Use cpu
1977         feature ``name`` as the key and the ``policy`` as the value. ``policy`` Attribute takes ``force``, ``require``,
1978         ``optional``, ``disable`` or ``forbid``.
1979     cache
1980         describes the virtual CPU cache. Optional attribute ``level`` takes an integer value which describes cache level
1981         ``mode`` attribute supported three possible values: ``emulate``, ``passthrough``, ``disable``
1982     numa
1983         specify the guest numa topology. ``cell`` element specifies a NUMA cell or a NUMA node, ``cpus`` specifies the
1984         CPU or range of CPUs that are part of the node, ``memory`` specifies the size of the node memory. All cells
1985         should have ``id`` attribute in case referring to some cell is necessary in the code. optional attribute
1986         ``memAccess`` control whether the memory is to be mapped as ``shared`` or ``private``, ``discard`` attribute which
1987         fine tunes the discard feature for given numa node, possible values are ``True`` or ``False``.  ``distances``
1988         element define the distance between NUMA cells and ``sibling`` sub-element is used to specify the distance value
1989         between sibling NUMA cells.
1990     vcpupin
1991         The optional vcpupin element specifies which of host's physical CPUs the domain vCPU will be pinned to.
1992     emulatorpin
1993         The optional emulatorpin element specifies which of host physical CPUs the "emulator", a subset of a domain not
1994         including vCPU or iothreads will be pinned to.
1995     iothreadpin
1996         The optional iothreadpin element specifies which of host physical CPUs the IOThreads will be pinned to.
1997     shares
1998         The optional shares element specifies the proportional weighted share for the domain.
1999     period
2000         The optional period element specifies the enforcement interval (unit: microseconds).
2001     quota
2002         The optional quota element specifies the maximum allowed bandwidth (unit: microseconds).
2003     global_period
2004         The optional global_period element specifies the enforcement CFS scheduler interval (unit: microseconds) for the
2005         whole domain in contrast with period which enforces the interval per vCPU.
2006     global_quota
2007         The optional global_quota element specifies the maximum allowed bandwidth (unit: microseconds) within a period
2008         for the whole domain.
2009     emulator_period
2010         The optional emulator_period element specifies the enforcement interval (unit: microseconds).
2011     emulator_quota
2012         The optional emulator_quota element specifies the maximum allowed bandwidth (unit: microseconds) for domain's
2013         emulator threads (those excluding vCPUs).
2014     iothread_period
2015         The optional iothread_period element specifies the enforcement interval (unit: microseconds) for IOThreads.
2016     iothread_quota
2017         The optional iothread_quota element specifies the maximum allowed bandwidth (unit: microseconds) for IOThreads.
2018     vcpusched
2019         specify the scheduler type for vCPUs.
2020         The value is a list of dictionaries with the ``scheduler`` key (values ``batch``, ``idle``, ``fifo``, ``rr``)
2021         and the optional ``priority`` and ``vcpus`` keys. The ``priority`` value usually is a positive integer and the
2022         ``vcpus`` value is a cpu set like ``1-4,^3,6`` or simply the vcpu id.
2023     iothreadsched
2024         specify the scheduler type for IO threads.
2025         The value is a list of dictionaries with the ``scheduler`` key (values ``batch``, ``idle``, ``fifo``, ``rr``)
2026         and the optional ``priority`` and ``vcpus`` keys. The ``priority`` value usually is a positive integer and the
2027         ``vcpus`` value is a cpu set like ``1-4,^3,6`` or simply the vcpu id.
2028     emulatorsched
2029         specify the scheduler type (values batch, idle, fifo, rr) for particular the emulator.
2030         The value is a dictionary with the ``scheduler`` key (values ``batch``, ``idle``, ``fifo``, ``rr``)
2031         and the optional ``priority`` and ``vcpus`` keys. The ``priority`` value usually is a positive integer.
2032     cachetune
2033         Optional cachetune element can control allocations for CPU caches using the resctrl on the host.
2034     monitor
2035         The optional element monitor creates the cache monitor(s) for current cache allocation.
2036     memorytune
2037         Optional memorytune element can control allocations for memory bandwidth using the resctrl on the host.
2038     iothreads
2039         Number of threads for supported disk devices to perform I/O requests. iothread id will be numbered from 1 to
2040         the provided number (Default: None).
2041     .. _init-boot-def:
2042     .. rubric:: Boot parameters definition
2043     The boot parameters dictionary can contains the following properties:
2044     kernel
2045         The URL or path to the kernel to run the virtual machine with.
2046     initrd
2047         The URL or path to the initrd file to run the virtual machine with.
2048     cmdline
2049         The parameters to pass to the kernel provided in the `kernel` property.
2050     loader
2051         The path to the UEFI binary loader to use.
2052         .. versionadded:: 3001
2053     nvram
2054         The path to the UEFI data template. The file will be copied when creating the virtual machine.
2055         .. versionadded:: 3001
2056     efi
2057        A boolean value.
2058        .. versionadded:: 3001
2059     .. _init-mem-def:
2060     .. rubric:: Memory parameter definition
2061     Memory parameter can contain the following properties:
2062     boot
2063         The maximum allocation of memory for the guest at boot time
2064     current
2065         The actual allocation of memory for the guest
2066     max
2067         The run time maximum memory allocation of the guest
2068     slots
2069          specifies the number of slots available for adding memory to the guest
2070     hard_limit
2071         the maximum memory the guest can use
2072     soft_limit
2073         memory limit to enforce during memory contention
2074     swap_hard_limit
2075         the maximum memory plus swap the guest can use
2076     min_guarantee
2077         the guaranteed minimum memory allocation for the guest
2078     hugepages
2079         memory allocated using ``hugepages`` instead of the normal native page size. It takes a list of
2080         dictionaries with ``nodeset`` and ``size`` keys.
2081         For example ``"hugepages": [{"nodeset": "1-4,^3", "size": "2m"}, {"nodeset": "3", "size": "1g"}]``.
2082     nosharepages
2083         boolean value to instruct hypervisor to disable shared pages (memory merge, KSM) for this domain
2084     locked
2085         boolean value that allows memory pages belonging to the domain will be locked in host's memory and the host will
2086         not be allowed to swap them out, which might be required for some workloads such as real-time.
2087     source
2088         possible values are ``file`` which utilizes file memorybacking, ``anonymous`` by default and ``memfd`` backing.
2089         (QEMU/KVM only)
2090     access
2091         specify if the memory is to be ``shared`` or ``private``. This can be overridden per numa node by memAccess.
2092     allocation
2093         specify when to allocate the memory by supplying either ``immediate`` or ``ondemand``.
2094     discard
2095         boolean value to ensure the memory content is discarded just before guest shuts down (or when DIMM module is
2096         unplugged). Please note that this is just an optimization and is not guaranteed to work in all cases
2097         (e.g. when hypervisor crashes). (QEMU/KVM only)
2098     .. _init-nic-def:
2099     .. rubric:: Network Interfaces Definitions
2100     Network interfaces dictionaries can contain the following properties:
2101     name
2102         Name of the network interface. This is only used as a key to merge with the profile data
2103     type
2104         Network type. One of ``'bridge'``, ``'network'``
2105     source
2106         The network source, typically the bridge or network name
2107     mac
2108         The desired mac address, computed if ``None`` (Default: ``None``).
2109     model
2110         The network card model (Default: depends on the hypervisor)
2111     .. _init-disk-def:
2112     .. rubric:: Disks Definitions
2113     Disk dictionaries can contain the following properties:
2114     name
2115         Name of the disk. This is mostly used in the name of the disk image and as a key to merge
2116         with the profile data.
2117     format
2118         Format of the disk image, like ``'qcow2'``, ``'raw'``, ``'vmdk'``.
2119         (Default: depends on the hypervisor)
2120     size
2121         Disk size in MiB
2122     pool
2123         Path to the folder or name of the pool where disks should be created.
2124         (Default: depends on hypervisor and the virt:storagepool configuration)
2125         .. versionchanged:: 3001
2126         If the value contains no '/', it is considered a pool name where to create a volume.
2127         Using volumes will be mandatory for some pools types like rdb, iscsi, etc.
2128     model
2129         One of the disk busses allowed by libvirt (Default: depends on hypervisor)
2130         See the libvirt `disk element`_ documentation for the allowed bus types.
2131     image
2132         Path to the image to use for the disk. If no image is provided, an empty disk will be created
2133         (Default: ``None``)
2134         Note that some pool types do not support uploading an image. This list can evolve with libvirt
2135         versions.
2136     overlay_image
2137         ``True`` to create a QCOW2 disk image with ``image`` as backing file. If ``False``
2138         the file pointed to by the ``image`` property will simply be copied. (Default: ``False``)
2139         .. versionchanged:: 3001
2140         This property is only valid on path-based disks, not on volumes. To create a volume with a
2141         backing store, set the ``backing_store_path`` and ``backing_store_format`` properties.
2142     backing_store_path
2143         Path to the backing store image to use. This can also be the name of a volume to use as
2144         backing store within the same pool.
2145         .. versionadded:: 3001
2146     backing_store_format
2147         Image format of the disk or volume to use as backing store. This property is mandatory when
2148         using ``backing_store_path`` to avoid `problems &lt;https://libvirt.org/kbase/backing_chains.html#troubleshooting&gt;`_
2149         .. versionadded:: 3001
2150     source_file
2151         Absolute path to the disk image to use. Not to be confused with ``image`` parameter. This
2152         parameter is useful to use disk images that are created outside of this module. Can also
2153         be ``None`` for devices that have no associated image like cdroms.
2154         .. versionchanged:: 3001
2155         For volume disks, this can be the name of a volume already existing in the storage pool.
2156     device
2157         Type of device of the disk. Can be one of 'disk', 'cdrom', 'floppy' or 'lun'.
2158         (Default: ``'disk'``)
2159     hostname_property
2160         When using ZFS volumes, setting this value to a ZFS property ID will make Salt store the name of the
2161         virtual machine inside this property. (Default: ``None``)
2162     sparse_volume
2163         Boolean to specify whether to use a thin provisioned ZFS volume.
2164         Example profile for a bhyve VM with two ZFS disks. The first is
2165         cloned from the specified image. The second disk is a thin
2166         provisioned volume.
2167         .. code-block:: yaml
2168             virt:
2169               disk:
2170                 two_zvols:
2171                   - system:
2172                       image: zroot/bhyve/CentOS-7-x86_64-v1@v1.0.5
2173                       hostname_property: virt:hostname
2174                       pool: zroot/bhyve/guests
2175                   - data:
2176                       pool: tank/disks
2177                       size: 20G
2178                       hostname_property: virt:hostname
2179                       sparse_volume: True
2180     io
2181         I/O control policy. String value amongst ``native``, ``threads`` and ``io_uring``.
2182         (Default: ``native``)
2183         .. versionadded:: 3003
2184     iothread_id
2185         I/O thread id to assign the disk to.
2186         (Default: none assigned)
2187         .. versionadded:: 3003
2188     .. _init-graphics-def:
2189     .. rubric:: Graphics Definition
2190     The graphics dictionary can have the following properties:
2191     type
2192         Graphics type. The possible values are ``none``, ``'spice'``, ``'vnc'`` and other values
2193         allowed as a libvirt graphics type (Default: ``None``)
2194         See the libvirt `graphics element`_ documentation for more details on the possible types.
2195     port
2196         Port to export the graphics on for ``vnc``, ``spice`` and ``rdp`` types.
2197     tls_port
2198         Port to export the graphics over a secured connection for ``spice`` type.
2199     listen
2200         Dictionary defining on what address to listen on for ``vnc``, ``spice`` and ``rdp``.
2201         It has a ``type`` property with ``address`` and ``None`` as possible values, and an
2202         ``address`` property holding the IP or hostname to listen on.
2203         By default, not setting the ``listen`` part of the dictionary will default to
2204         listen on all addresses.
2205     .. _init-chardevs-def:
2206     .. rubric:: Serials and Consoles Definitions
2207     Serial dictionaries can contain the following properties:
2208     type
2209         Type of the serial connection, like ``'tcp'``, ``'pty'``, ``'file'``, ``'udp'``, ``'dev'``,
2210         ``'pipe'``, ``'unix'``.
2211     path
2212         Path to the source device. Can be a log file, a host character device to pass through,
2213         a unix socket, a named pipe path.
2214     host
2215         The serial UDP or TCP host name.
2216         (Default: 23023)
2217     port
2218         The serial UDP or TCP port number.
2219         (Default: 23023)
2220     protocol
2221         Name of the TCP connection protocol.
2222         (Default: telnet)
2223     tls
2224         Boolean value indicating whether to use hypervisor TLS certificates environment for TCP devices.
2225     target_port
2226         The guest device port number starting from 0
2227     target_type
2228         The guest device type. Common values are ``serial``, ``virtio`` or ``usb-serial``, but more are documented in
2229         `the libvirt documentation &lt;https://libvirt.org/formatdomain.html#consoles-serial-parallel-channel-devices&gt;`_.
2230     .. rubric:: CLI Example
2231     .. code-block:: bash
2232         salt 'hypervisor' virt.init vm_name 4 512 salt://path/to/image.raw
2233         salt 'hypervisor' virt.init vm_name 4 512 /var/lib/libvirt/images/img.raw
2234         salt 'hypervisor' virt.init vm_name 4 512 nic=profile disk=profile
2235     The disk images will be created in an image folder within the directory
2236     defined by the ``virt:images`` option. Its default value is
2237     ``/srv/salt-images/`` but this can changed with such a configuration:
2238     .. code-block:: yaml
2239         virt:
2240             images: /data/my/vm/images/
2241     .. _disk element: https://libvirt.org/formatdomain.html#elementsDisks
2242     .. _graphics element: https://libvirt.org/formatdomain.html#elementsGraphics
2243     """
2244     try:
2245         conn = __get_conn(**kwargs)
2246         caps = _capabilities(conn)
2247         os_types = sorted({guest["os_type"] for guest in caps["guests"]})
2248         arches = sorted({guest["arch"]["name"] for guest in caps["guests"]})
2249         virt_hypervisor = hypervisor
2250         if not virt_hypervisor:
2251             hypervisors = sorted(
2252                 {
2253                     x
2254                     for y in [
2255                         guest["arch"]["domains"].keys() for guest in caps["guests"]
2256                     ]
2257                     for x in y
2258                 }
2259             )
2260             if len(hypervisors) == 0:
2261                 raise SaltInvocationError("No supported hypervisors were found")
2262             virt_hypervisor = "kvm" if "kvm" in hypervisors else hypervisors[0]
2263         virt_hypervisor = "vmware" if virt_hypervisor == "esxi" else virt_hypervisor
2264         log.debug("Using hypervisor %s", virt_hypervisor)
2265         nicp = _get_merged_nics(virt_hypervisor, nic, interfaces)
2266         diskp = _disk_profile(conn, disk, virt_hypervisor, disks, name)
2267         for _disk in diskp:
2268             if _disk.get("device", "disk") == "cdrom":
2269                 continue
2270             log.debug("Creating disk for VM [ %s ]: %s", name, _disk)
2271             if virt_hypervisor == "vmware":
2272                 if "image" in _disk:
2273                     raise SaltInvocationError(
2274                         "virt.init does not support image "
2275                         "template in conjunction with esxi hypervisor"
2276                     )
2277                 else:
2278                     log.debug("Generating libvirt XML for %s", _disk)
2279                     volume_name = "{}/{}".format(name, _disk["name"])
2280                     filename = "{}.{}".format(volume_name, _disk["format"])
2281                     vol_xml = _gen_vol_xml(
2282                         filename, _disk["size"], format=_disk["format"]
2283                     )
2284                     _define_vol_xml_str(conn, vol_xml, pool=_disk.get("pool"))
2285             elif virt_hypervisor in ["qemu", "kvm", "xen"]:
2286                 def seeder(path):
2287                     _seed_image(
2288                         seed_cmd,
2289                         path,
2290                         name,
2291                         kwargs.get("config"),
2292                         install,
2293                         pub_key,
2294                         priv_key,
2295                     )
2296                 create_overlay = _disk.get("overlay_image", False)
2297                 format = _disk.get("format")
2298                 if _disk.get("source_file"):
2299                     if os.path.exists(_disk["source_file"]):
2300                         img_dest = _disk["source_file"]
2301                     else:
2302                         img_dest = _qemu_image_create(_disk, create_overlay, saltenv)
2303                 else:
2304                     _disk_volume_create(conn, _disk, seeder if seed else None, saltenv)
2305                     img_dest = None
2306                 if seed and img_dest and _disk.get("image", None):
2307                     seeder(img_dest)
2308             elif hypervisor in ["bhyve"]:
2309                 img_dest = _zfs_image_create(
2310                     vm_name=name,
2311                     pool=_disk.get("pool"),
2312                     disk_name=_disk.get("name"),
2313                     disk_size=_disk.get("size"),
2314                     disk_image_name=_disk.get("image"),
2315                     hostname_property_name=_disk.get("hostname_property"),
2316                     sparse_volume=_disk.get("sparse_volume"),
2317                 )
2318             else:
2319                 raise SaltInvocationError(
2320                     "Unsupported hypervisor when handling disk image: {}".format(
2321                         virt_hypervisor
2322                     )
2323                 )
2324         log.debug("Generating VM XML")
2325         if os_type is None:
2326             os_type = "hvm" if "hvm" in os_types else os_types[0]
2327         if arch is None:
2328             arch = "x86_64" if "x86_64" in arches else arches[0]
2329         if boot is not None:
2330             boot = _handle_remote_boot_params(boot)
2331         vm_xml = _gen_xml(
2332             conn,
2333             name,
2334             cpu,
2335             mem,
2336             diskp,
2337             nicp,
2338             virt_hypervisor,
2339             os_type,
2340             arch,
2341             graphics,
2342             boot,
2343             boot_dev,
2344             numatune,
2345             hypervisor_features,
2346             clock,
2347             serials,
2348             consoles,
2349             stop_on_reboot,
2350             host_devices,
2351             **kwargs
2352         )
2353         log.debug("New virtual machine definition: %s", vm_xml)
2354         conn.defineXML(vm_xml)
2355     except libvirt.libvirtError as err:
2356         conn.close()
2357         raise CommandExecutionError(err.get_error_message())
2358     if start:
2359         log.debug("Starting VM %s", name)
2360         _get_domain(conn, name).create()
2361     conn.close()
2362     return True
2363 def _disks_equal(disk1, disk2):
2364     """
2365     Test if two disk elements should be considered like the same device
2366     """
2367     target1 = disk1.find("target")
2368     target2 = disk2.find("target")
2369     disk1_dict = xmlutil.to_dict(disk1, True)
2370     disk2_dict = xmlutil.to_dict(disk2, True)
2371     source1_dict = disk1_dict.get("source", {})
2372     source2_dict = disk2_dict.get("source", {})
2373     io1 = disk1_dict.get("driver", {}).get("io", "native")
2374     io2 = disk2_dict.get("driver", {}).get("io", "native")
2375     if source1_dict:
2376         source1_dict.pop("index", None)
2377     if source2_dict:
2378         source2_dict.pop("index", None)
2379     return (
2380         and target1 is not None
2381         and target2 is not None
2382         and target1<font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.get("bus") == target2.get("bus")
2383         and disk1.get("device", "disk") == disk2.get("device", "disk")
2384         and target1.get("dev") == target2.get(</b></font>"dev")
2385         and io1 == io2
2386     )
2387 def _nics_equal(nic1, nic2):
2388     """
2389     Test if two interface elements should be considered like the same device
2390     """
2391     def _filter_nic(nic):
2392         """
2393         Filter out elements to ignore when comparing nics
2394         """
2395         source_node = nic.find("source")
2396         source_attrib = source_node.attrib if source_node is not None else {}
2397         source_type = "network" if "network" in source_attrib else nic.attrib["type"]
2398         source_getters = {
2399             "network": lambda n: n.get("network"),
2400             "bridge": lambda n: n.get("bridge"),
2401             "direct": lambda n: n.get("dev"),
2402             "hostdev": lambda n: _format_pci_address(n.find("address")),
2403         }
2404         return {
2405             "type": source_type,
2406             "source": source_getters[source_type](source_node)
2407             if source_node is not None
2408             else None,
2409             "model": nic.find("model").attrib["type"]
2410             if nic.find("model") is not None
2411             else None,
2412         }
2413     def _get_mac(nic):
2414         return (
2415             nic.find("mac").attrib["address"].lower()
2416             if nic.find("mac") is not None
2417             else None
2418         )
2419     mac1 = _get_mac(nic1)
2420     mac2 = _get_mac(nic2)
2421     macs_equal = not mac1 or not mac2 or mac1 == mac2
2422     return _filter_nic(nic1) == _filter_nic(nic2) and macs_equal
2423 def _graphics_equal(gfx1, gfx2):
2424     """
2425     Test if two graphics devices should be considered the same device
2426     """
2427     def _filter_graphics(gfx):
2428         """
2429         When the domain is running, the graphics element may contain additional properties
2430         with the default values. This function will strip down the default values.
2431         """
2432         gfx_copy = copy.deepcopy(gfx)
2433         defaults = [
2434             {"node": ".", "attrib": "port", "values": ["5900", "-1"]},
2435             {"node": ".", "attrib": "address", "values": ["127.0.0.1"]},
2436             {"node": "listen", "attrib": "address", "values": ["127.0.0.1"]},
2437         ]
2438         for default in defaults:
2439             node = gfx_copy.find(default["node"])
2440             attrib = default["attrib"]
2441             if node is not None and (
2442                 attrib in node.attrib and node.attrib[attrib] in default["values"]
2443             ):
2444                 node.attrib.pop(attrib)
2445         return gfx_copy
2446     return xmlutil.to_dict(_filter_graphics(gfx1), True) == xmlutil.to_dict(
2447         _filter_graphics(gfx2), True
2448     )
2449 def _hostdevs_equal(dev1, dev2):
2450     """
2451     Test if two hostdevs devices should be considered the same device
2452     """
2453     def _filter_hostdevs(dev):
2454         """
2455         When the domain is running, the hostdevs element may contain additional properties.
2456         This function will only keep the ones we care about
2457         """
2458         type_ = dev.get("type")
2459         definition = {
2460             "type": type_,
2461         }
2462         if type_ == "pci":
2463             address_node = dev.find("./source/address")
2464             for attr in ["domain", "bus", "slot", "function"]:
2465                 definition[attr] = address_node.get(attr)
2466         elif type_ == "usb":
2467             for attr in ["vendor", "product"]:
2468                 definition[attr] = dev.find("./source/" + attr).get("id")
2469         return definition
2470     return _filter_hostdevs(dev1) == _filter_hostdevs(dev2)
2471 def _diff_lists(old, new, comparator):
2472     """
2473     Compare lists to extract the changes
2474     :param old: old list
2475     :param new: new list
2476     :return: a dictionary with ``unchanged``, ``new``, ``deleted`` and ``sorted`` keys
2477     The sorted list is the union of unchanged and new lists, but keeping the original
2478     order from the new list.
2479     """
2480     def _remove_indent(node):
2481         """
2482         Remove the XML indentation to compare XML trees more easily
2483         """
2484         node_copy = copy.deepcopy(node)
2485         node_copy.text = None
2486         for item in node_copy.iter():
2487             item.tail = None
2488         return node_copy
2489     diff = {"unchanged": [], "new": [], "deleted": [], "sorted": []}
2490     old_devices = copy.deepcopy(old)
2491     for new_item in new:
2492         found = [
2493             item
2494             for item in old_devices
2495             if comparator(_remove_indent(item), _remove_indent(new_item))
2496         ]
2497         if found:
2498             old_devices.remove(found[0])
2499             diff["unchanged"].append(found[0])
2500             diff["sorted"].append(found[0])
2501         else:
2502             diff["new"].append(new_item)
2503             diff["sorted"].append(new_item)
2504     diff["deleted"] = old_devices
2505     return diff
2506 def _get_disk_target(targets, disks_count, prefix):
2507     """
2508     Compute the disk target name for a given prefix.
2509     :param targets: the list of already computed targets
2510     :param disks: the number of disks
2511     :param prefix: the prefix of the target name, i.e. "hd"
2512     """
2513     for i in range(disks_count):
2514         ret = "{}{}".format(prefix, string.ascii_lowercase[i])
2515         if ret not in targets:
2516             return ret
2517     return None
2518 def _diff_disk_lists(old, new):
2519     """
2520     Compare disk definitions to extract the changes and fix target devices
2521     :param old: list of ElementTree nodes representing the old disks
2522     :param new: list of ElementTree nodes representing the new disks
2523     """
2524     targets = []
2525     prefixes = ["fd", "hd", "vd", "sd", "xvd", "ubd"]
2526     for disk in new:
2527         target_node = disk.find("target")
2528         target = target_node.get("dev")
2529         prefix = [item for item in prefixes if target.startswith(item)][0]
2530         new_target = _get_disk_target(targets, len(new), prefix)
2531         target_node.set("dev", new_target)
2532         targets.append(new_target)
2533     return _diff_lists(old, new, _disks_equal)
2534 def _diff_interface_lists(old, new):
2535     """
2536     Compare network interface definitions to extract the changes
2537     :param old: list of ElementTree nodes representing the old interfaces
2538     :param new: list of ElementTree nodes representing the new interfaces
2539     """
2540     return _diff_lists(old, new, _nics_equal)
2541 def _diff_graphics_lists(old, new):
2542     """
2543     Compare graphic devices definitions to extract the changes
2544     :param old: list of ElementTree nodes representing the old graphic devices
2545     :param new: list of ElementTree nodes representing the new graphic devices
2546     """
2547     return _diff_lists(old, new, _graphics_equal)
2548 def _diff_hostdev_lists(old, new):
2549     """
2550     Compare hostdev devices definitions to extract the changes
2551     :param old: list of ElementTree nodes representing the old hostdev devices
2552     :param new: list of ElementTree nodes representing the new hostdev devices
2553     """
2554     return _diff_lists(old, new, _hostdevs_equal)
2555 def _expand_cpuset(cpuset):
2556     """
2557     Expand the libvirt cpuset and nodeset values into a list of cpu/node IDs
2558     """
2559     if cpuset is None:
2560         return None
2561     if isinstance(cpuset, int):
2562         return str(cpuset)
2563     result = set()
2564     toremove = set()
2565     for part in cpuset.split(","):
2566         m = re.match("([0-9]+)-([0-9]+)", part)
2567         if m:
2568             result |= set(range(int(m.group(1)), int(m.group(2)) + 1))
2569         elif part.startswith("^"):
2570             toremove.add(int(part[1:]))
2571         else:
2572             result.add(int(part))
2573     cpus = list(result - toremove)
2574     cpus.sort()
2575     cpus = [str(cpu) for cpu in cpus]
2576     return ",".join(cpus)
2577 def _normalize_cpusets(desc, data):
2578     """
2579     Expand the cpusets that can't be expanded by the change_xml() function,
2580     namely the ones that are used as keys and in the middle of the XPath expressions.
2581     """
2582     xpaths = ["cputune/cachetune", "cputune/cachetune/monitor", "cputune/memorytune"]
2583     for xpath in xpaths:
2584         nodes = desc.findall(xpath)
2585         for node in nodes:
2586             node.set("vcpus", _expand_cpuset(node.get("vcpus")))
2587     if not isinstance(data.get("cpu"), dict):
2588         return
2589     tuning = data["cpu"].get("tuning", {})
2590     for child in ["cachetune", "memorytune"]:
2591         if tuning.get(child):
2592             new_item = dict()
2593             for cpuset, value in tuning[child].items():
2594                 if child == "cachetune" and value.get("monitor"):
2595                     value["monitor"] = {
2596                         _expand_cpuset(monitor_cpus): monitor
2597                         for monitor_cpus, monitor in value["monitor"].items()
2598                     }
2599                 new_item[_expand_cpuset(cpuset)] = value
2600             tuning[child] = new_item
2601 def _serial_or_concole_equal(old, new):
2602     def _filter_serial_or_concole(item):
2603         """
2604         Filter out elements to ignore when comparing items
2605         """
2606         return {
2607             "type": item.attrib["type"],
2608             "port": item.find("source").get("service")
2609             if item.find("source") is not None
2610             else None,
2611             "protocol": item.find("protocol").get("type")
2612             if item.find("protocol") is not None
2613             else None,
2614         }
2615     return _filter_serial_or_concole(old) == _filter_serial_or_concole(new)
2616 def _diff_serial_lists(old, new):
2617     """
2618     Compare serial definitions to extract the changes
2619     :param old: list of ElementTree nodes representing the old serials
2620     :param new: list of ElementTree nodes representing the new serials
2621     """
2622     return _diff_lists(old, new, _serial_or_concole_equal)
2623 def _diff_console_lists(old, new):
2624     """
2625     Compare console definitions to extract the changes
2626     :param old: list of ElementTree nodes representing the old consoles
2627     :param new: list of ElementTree nodes representing the new consoles
2628     """
2629     return _diff_lists(old, new, _serial_or_concole_equal)
2630 def _format_pci_address(node):
2631     return "{}:{}:{}.{}"<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.format(
2632         node.get("domain").replace("0x", ""),
2633         node.get("bus").replace("0x", ""),
2634         node.get("slot").replace("0x", ""),
2635         node.get("function").replace(</b></font>"0x", ""),
2636     )
2637 def _almost_equal(current, new):
2638     """
2639     return True if the parameters are numbers that are almost
2640     """
2641     if current is None or new is None:
2642         return False
2643     return abs(current - new) / current &lt; 1e-03
2644 def _compute_device_changes(old_xml, new_xml, to_skip):
2645     """
2646     Compute the device changes between two domain XML definitions.
2647     """
2648     devices_node = old_xml.find("devices")
2649     changes = {}
2650     for dev_type in to_skip:
2651         changes[dev_type] = {}
2652         if not to_skip[dev_type]:
2653             old = devices_node.findall(dev_type)
2654             new = new_xml.findall("devices/{}".format(dev_type))
2655             changes[dev_type] = globals()["_diff_{}_lists".format(dev_type)](old, new)
2656     return changes
2657 def _get_pci_addresses(node):
2658     """
2659     Get all the pci addresses in the node in 0000:00:00.0 form
2660     """
2661     return {_format_pci_address(address) for address in node.findall(".//address")}
2662 def _correct_networks(conn, desc):
2663     """
2664     Adjust the interface devices matching existing networks.
2665     Returns the network interfaces XML definition as string mapped to the new device node.
2666     """
2667     networks = [ElementTree.fromstring(net.XMLDesc()) for net in conn.listAllNetworks()]
2668     nics = desc.findall("devices/interface")
2669     device_map = {}
2670     for nic in nics:
2671         if nic.get("type") == "hostdev":
2672             addr = _get_pci_addresses(nic.find("source"))
2673             matching_nets = [
2674                 net
2675                 for net in networks
2676                 if net.find("forward").get("mode") == "hostdev"
2677                 and addr &amp; _get_pci_addresses(net)
2678             ]
2679             if matching_nets:
2680                 old_xml = ElementTree.tostring(nic)
2681                 nic.set("type", "network")
2682                 nic.find("source").set("network", matching_nets[0].find("name").text)
2683                 device_map[nic] = old_xml
2684     return device_map
2685 def _update_live(domain, new_desc, mem, cpu, old_mem, old_cpu, to_skip, test):
2686     """
2687     Perform the live update of a domain.
2688     """
2689     status = {}
2690     errors = []
2691     if not domain.isActive():
2692         return status, errors
2693     commands = []
2694     if cpu and (isinstance(cpu, int) or isinstance(cpu, dict) and cpu.get("maximum")):
2695         new_cpu = cpu.get("maximum") if isinstance(cpu, dict) else cpu
2696         if old_cpu != new_cpu and new_cpu is not None:
2697             commands.append(
2698                 {
2699                     "device": "cpu",
2700                     "cmd": "setVcpusFlags",
2701                     "args": [new_cpu, libvirt.VIR_DOMAIN_AFFECT_LIVE],
2702                 }
2703             )
2704     if mem:
2705         if isinstance(mem, dict):
2706             new_mem = (
2707                 int(_handle_unit(mem.get("current")) / 1024)
2708                 if "current" in mem
2709                 else None
2710             )
2711         elif isinstance(mem, int):
2712             new_mem = int(mem * 1024)
2713         if not _almost_equal(old_mem, new_mem) and new_mem is not None:
2714             commands.append(
2715                 {
2716                     "device": "mem",
2717                     "cmd": "setMemoryFlags",
2718                     "args": [new_mem, libvirt.VIR_DOMAIN_AFFECT_LIVE],
2719                 }
2720             )
2721     old_desc = ElementTree.fromstring(domain.XMLDesc(0))
2722     changed_devices = {"interface": _correct_networks(domain.connect(), old_desc)}
2723     changes = _compute_device_changes(old_desc, new_desc, to_skip)
2724     removable_changes = []
2725     new_disks = []
2726     for new_disk in changes["disk"].get("new", []):
2727         device = new_disk.get("device", "disk")
2728         if device not in ["cdrom", "floppy"]:
2729             new_disks.append(new_disk)
2730             continue
2731         target_dev = new_disk.find("target").get("dev")
2732         matching = [
2733             old_disk
2734             for old_disk in changes["disk"].get("deleted", [])
2735             if old_disk.get("device", "disk") == device
2736             and old_disk.find("target").get("dev") == target_dev
2737         ]
2738         if not matching:
2739             new_disks.append(new_disk)
2740         else:
2741             updated_disk = matching[0]
2742             changes["disk"]["deleted"].remove(updated_disk)
2743             removable_changes.append(updated_disk)
2744             source_node = updated_disk.find("source")
2745             new_source_node = new_disk.find("source")
2746             source_file = (
2747                 new_source_node.get("file") if new_source_node is not None else None
2748             )
2749             updated_disk.set("type", "file")
2750             if source_node is not None:
2751                 updated_disk.remove(source_node)
2752             if source_file:
2753                 ElementTree.SubElement(
2754                     updated_disk, "source", attrib={"file": source_file}
2755                 )
2756     changes["disk"]["new"] = new_disks
2757     for dev_type in ["disk", "interface", "hostdev"]:
2758         for added in changes[dev_type].get("new", []):
2759             commands.append(
2760                 {
2761                     "device": dev_type,
2762                     "cmd": "attachDevice",
2763                     "args": [xmlutil.element_to_str(added)],
2764                 }
2765             )
2766         for removed in changes[dev_type].get("deleted", []):
2767             removed_def = changed_devices.get(dev_type, {}).get(
2768                 removed, ElementTree.tostring(removed)
2769             )
2770             commands.append(
2771                 {
2772                     "device": dev_type,
2773                     "cmd": "detachDevice",
2774                     "args": [salt.utils.stringutils.to_str(removed_def)],
2775                 }
2776             )
2777     for updated_disk in removable_changes:
2778         commands.append(
2779             {
2780                 "device": "disk",
2781                 "cmd": "updateDeviceFlags",
2782                 "args": [xmlutil.element_to_str(updated_disk)],
2783             }
2784         )
2785     for cmd in commands:
2786         try:
2787             ret = 0 if test else getattr(domain, cmd["cmd"])(*cmd["args"])
2788             device_type = cmd["device"]
2789             if device_type in ["cpu", "mem"]:
2790                 status[device_type] = not ret
2791             else:
2792                 actions = {
2793                     "attachDevice": "attached",
2794                     "detachDevice": "detached",
2795                     "updateDeviceFlags": "updated",
2796                 }
2797                 device_status = status.setdefault(device_type, {})
2798                 cmd_status = device_status.setdefault(actions[cmd["cmd"]], [])
2799                 cmd_status.append(cmd["args"][0])
2800         except libvirt.libvirtError as err:
2801             errors.append(str(err))
2802     return status, errors
2803 def update(
2804     name,
2805     cpu=0,
2806     mem=0,
2807     disk_profile=None,
2808     disks=None,
2809     nic_profile=None,
2810     interfaces=None,
2811     graphics=None,
2812     live=True,
2813     boot=None,
2814     numatune=None,
2815     test=False,
2816     boot_dev=None,
2817     hypervisor_features=None,
2818     clock=None,
2819     serials=None,
2820     consoles=None,
2821     stop_on_reboot=False,
2822     host_devices=None,
2823     **kwargs
2824 ):
2825     """
2826     Update the definition of an existing domain.
2827     :param name: Name of the domain to update
2828     :param cpu:
2829         Number of virtual CPUs to assign to the virtual machine or a dictionary with detailed information to configure
2830         cpu model and topology, numa node tuning, cpu tuning and iothreads allocation. The structure of the dictionary is
2831         documented in :ref:`init-cpu-def`.
2832         To update any cpu parameters specify the new values to the corresponding tag. To remove any element or attribute,
2833         specify ``None`` object. Please note that ``None`` object is mapped to ``null`` in yaml, use ``null`` in sls file
2834         instead.
2835     :param mem: Amount of memory to allocate to the virtual machine in MiB. Since 3002, a dictionary can be used to
2836         contain detailed configuration which support memory allocation or tuning. Supported parameters are ``boot``,
2837         ``current``, ``max``, ``slots``, ``hard_limit``, ``soft_limit``, ``swap_hard_limit``, ``min_guarantee``,
2838         ``hugepages`` ,  ``nosharepages``, ``locked``, ``source``, ``access``, ``allocation`` and ``discard``. The structure
2839         of the dictionary is documented in  :ref:`init-mem-def`. Both decimal and binary base are supported. Detail unit
2840         specification is documented  in :ref:`virt-units`. Please note that the value for ``slots`` must be an integer.
2841         To remove any parameters, pass a None object, for instance: 'soft_limit': ``None``. Please note  that ``None``
2842         is mapped to ``null`` in sls file, pass ``null`` in sls file instead.
2843         .. code-block:: yaml
2844             - mem:
2845                 hard_limit: null
2846                 soft_limit: null
2847         .. versionchanged:: 3002
2848     :param disk_profile: disk profile to use
2849     :param disks:
2850         Disk definitions as documented in the :func:`init` function.
2851         If neither the profile nor this parameter are defined, the disk devices
2852         will not be changed. However to clear disks set this parameter to empty list.
2853     :param nic_profile: network interfaces profile to use
2854     :param interfaces:
2855         Network interface definitions as documented in the :func:`init` function.
2856         If neither the profile nor this parameter are defined, the interface devices
2857         will not be changed. However to clear network interfaces set this parameter
2858         to empty list.
2859     :param graphics:
2860         The new graphics definition as defined in :ref:`init-graphics-def`. If not set,
2861         the graphics will not be changed. To remove a graphics device, set this parameter
2862         to ``{'type': 'none'}``.
2863     :param live:
2864         ``False`` to avoid trying to live update the definition. In such a case, the
2865         new definition is applied at the next start of the virtual machine. If ``True``,
2866         not all aspects of the definition can be live updated, but as much as possible
2867         will be attempted. (Default: ``True``)
2868     :param connection: libvirt connection URI, overriding defaults
2869     :param username: username to connect with, overriding defaults
2870     :param password: password to connect with, overriding defaults
2871     :param boot:
2872         Specifies kernel, initial ramdisk and kernel command line parameters for the virtual machine.
2873         This is an optional parameter, all of the keys are optional within the dictionary.
2874         Refer to :ref:`init-boot-def` for the complete boot parameter description.
2875         To update any boot parameters, specify the new path for each. To remove any boot parameters, pass ``None`` object,
2876         for instance: 'kernel': ``None``. To switch back to BIOS boot, specify ('loader': ``None`` and 'nvram': ``None``)
2877         or 'efi': ``False``. Please note that ``None`` is mapped to ``null`` in sls file, pass ``null`` in sls file instead.
2878         SLS file Example:
2879         .. code-block:: yaml
2880             - boot:
2881                 loader: null
2882                 nvram: null
2883         .. versionadded:: 3000
2884     :param boot_dev:
2885         Space separated list of devices to boot from sorted by decreasing priority.
2886         Values can be ``hd``, ``fd``, ``cdrom`` or ``network``.
2887         By default, the value will ``"hd"``.
2888         .. versionadded:: 3002
2889     :param numatune:
2890         The optional numatune element provides details of how to tune the performance of a NUMA host via controlling NUMA
2891         policy for domain process. The optional ``memory`` element specifies how to allocate memory for the domain process
2892         on a NUMA host. ``memnode`` elements can specify memory allocation policies per each guest NUMA node. The definition
2893         used in the dictionary can be found at :ref:`init-cpu-def`.
2894         To update any numatune parameters, specify the new value. To remove any ``numatune`` parameters, pass a None object,
2895         for instance: 'numatune': ``None``. Please note that ``None`` is mapped to ``null`` in sls file, pass ``null`` in
2896         sls file instead.
2897         .. versionadded:: 3003
2898     :param serials:
2899         Dictionary providing details on the serials connection to create. (Default: ``None``)
2900         See :ref:`init-chardevs-def` for more details on the possible values.
2901         .. versionadded:: 3003
2902     :param consoles:
2903         Dictionary providing details on the consoles device to create. (Default: ``None``)
2904         See :ref:`init-chardevs-def` for more details on the possible values.
2905         .. versionadded:: 3003
2906     :param stop_on_reboot:
2907         If set to ``True`` the guest will stop instead of rebooting.
2908         This is specially useful when creating a virtual machine with an installation cdrom or
2909         an autoinstallation needing a special first boot configuration.
2910         Defaults to ``False``
2911         .. versionadded:: 3003
2912     :param test: run in dry-run mode if set to True
2913         .. versionadded:: 3001
2914     :param hypervisor_features:
2915         Enable or disable hypervisor-specific features on the virtual machine.
2916         .. versionadded:: 3003
2917         .. code-block:: yaml
2918             hypervisor_features:
2919               kvm-hint-dedicated: True
2920     :param clock:
2921         Configure the guest clock.
2922         The value is a dictionary with the following keys:
2923         adjustment
2924             time adjustment in seconds or ``reset``
2925         utc
2926             set to ``False`` to use the host local time as the guest clock. Defaults to ``True``.
2927         timezone
2928             synchronize the guest to the correspding timezone
2929         timers
2930             a dictionary associating the timer name with its configuration.
2931             This configuration is a dictionary with the properties ``track``, ``tickpolicy``,
2932             ``catchup``, ``frequency``, ``mode``, ``present``, ``slew``, ``threshold`` and ``limit``.
2933             See `libvirt time keeping documentation &lt;https://libvirt.org/formatdomain.html#time-keeping&gt;`_ for the possible values.
2934         .. versionadded:: 3003
2935         Set the clock to local time using an offset in seconds
2936         .. code-block:: yaml
2937             clock:
2938               adjustment: 3600
2939               utc: False
2940         Set the clock to a specific time zone:
2941         .. code-block:: yaml
2942             clock:
2943               timezone: CEST
2944         Tweak guest timers:
2945         .. code-block:: yaml
2946             clock:
2947               timers:
2948                 tsc:
2949                   frequency: 3504000000
2950                   mode: native
2951                 rtc:
2952                   track: wall
2953                   tickpolicy: catchup
2954                   slew: 4636
2955                   threshold: 123
2956                   limit: 2342
2957                 hpet:
2958                   present: False
2959     :param host_devices:
2960         List of host devices to passthrough to the guest.
2961         The value is a list of device names as provided by the :py:func:`~salt.modules.virt.node_devices` function.
2962         (Default: ``None``)
2963         .. versionadded:: 3003
2964     :return:
2965         Returns a dictionary indicating the status of what has been done. It is structured in
2966         the following way:
2967         .. code-block:: python
2968             {
2969               'definition': True,
2970               'cpu': True,
2971               'mem': True,
2972               'disks': {'attached': [list of actually attached disks],
2973                         'detached': [list of actually detached disks]},
2974               'nics': {'attached': [list of actually attached nics],
2975                        'detached': [list of actually detached nics]},
2976               'errors': ['error messages for failures']
2977             }
2978     .. versionadded:: 2019.2.0
2979     CLI Example:
2980     .. code-block:: bash
2981         salt '*' virt.update domain cpu=2 mem=1024
2982     """
2983     status = {
2984         "definition": False,
2985         "disk": {"attached": [], "detached": [], "updated": []},
2986         "interface": {"attached": [], "detached": []},
2987     }
2988     conn = __get_conn(**kwargs)
2989     domain = _get_domain(conn, name)
2990     desc = ElementTree.fromstring(domain.XMLDesc(libvirt.VIR_DOMAIN_XML_INACTIVE))
2991     need_update = False
2992     hypervisor = desc.get("type")
2993     all_disks = _disk_profile(conn, disk_profile, hypervisor, disks, name)
2994     if boot is not None:
2995         boot = _handle_remote_boot_params(boot)
2996         if boot.get("efi", None) is not None:
2997             need_update = _handle_efi_param(boot, desc)
2998     new_desc = ElementTree.fromstring(
2999         _gen_xml(
3000             conn,
3001             name,
3002             cpu,
3003             mem or 0,
3004             all_disks,
3005             _get_merged_nics(hypervisor, nic_profile, interfaces),
3006             hypervisor,
3007             domain.OSType(),
3008             desc.find(".//os/type").get("arch"),
3009             graphics,
3010             boot,
3011             boot_dev,
3012             numatune,
3013             serials=serials,
3014             consoles=consoles,
3015             stop_on_reboot=stop_on_reboot,
3016             host_devices=host_devices,
3017             **kwargs
3018         )
3019     )
3020     if clock:
3021         offset = "utc" if clock.get("utc", True) else "localtime"
3022         if "timezone" in clock:
3023             offset = "timezone"
3024         clock["offset"] = offset
3025     def _set_loader(node, value):
3026         salt.utils.xmlutil.set_node_text(node, value)
3027         if value is not None:
3028             node.set("readonly", "yes")
3029             node.set("type", "pflash")
3030     def _set_nvram(node, value):
3031         node.set("template", value)
3032     def _set_with_byte_unit(attr_name=None):
3033         def _setter(node, value):
3034             if attr_name:
3035                 node.set(attr_name, str(value))
3036             else:
3037                 node.text = str(value)
3038             node.set("unit", "bytes")
3039         return _setter
3040     def _get_with_unit(node):
3041         unit = node.get("unit", "KiB")
3042         unit = unit if unit != "bytes" else "b"
3043         value = node.get("memory") or node.get("size") or node.text
3044         return _handle_unit("{}{}".format(value, unit)) if value else None
3045     def _set_vcpu(node, value):
3046         node.text = str(value)
3047         node.set("current", str(value))
3048     old_mem = int(_get_with_unit(desc.find("memory")) / 1024)
3049     old_cpu = int(desc.find("./vcpu").text)
3050     def _yesno_attribute(path, xpath, attr_name, ignored=None):
3051         return xmlutil.attribute(
3052             path, xpath, attr_name, ignored, lambda v: "yes" if v else "no"
3053         )
3054     def _memory_parameter(path, xpath, attr_name=None, ignored=None):
3055         entry = {
3056             "path": path,
3057             "xpath": xpath,
3058             "convert": _handle_unit,
3059             "get": _get_with_unit,
3060             "set": _set_with_byte_unit(attr_name),
3061             "equals": _almost_equal,
3062         }
3063         if attr_name:
3064             entry["del"] = salt.utils.xmlutil.del_attribute(attr_name, ignored)
3065         return entry
3066     def _cpuset_parameter(path, xpath, attr_name=None, ignored=None):
3067         def _set_cpuset(node, value):
3068             if attr_name:
3069                 node.set(attr_name, value)
3070             else:
3071                 node.text = value
3072         entry = {
3073             "path": path,
3074             "xpath": xpath,
3075             "convert": _expand_cpuset,
3076             "get": lambda n: _expand_cpuset(n.get(attr_name) if attr_name else n.text),
3077             "set": _set_cpuset,
3078         }
3079         if attr_name:
3080             entry["del"] = salt.utils.xmlutil.del_attribute(attr_name, ignored)
3081         return entry
3082     data = {k: v for k, v in locals().items() if bool(v)}
3083     data["stop_on_reboot"] = stop_on_reboot
3084     if boot_dev:
3085         data["boot_dev"] = boot_dev.split()
3086     timer_names = [
3087         "platform",
3088         "hpet",
3089         "kvmclock",
3090         "pit",
3091         "rtc",
3092         "tsc",
3093         "hypervclock",
3094         "armvtimer",
3095     ]
3096     if data.get("clock", {}).get("timers"):
3097         attributes = [
3098             "track",
3099             "tickpolicy",
3100             "frequency",
3101             "mode",
3102             "present",
3103             "slew",
3104             "threshold",
3105             "limit",
3106         ]
3107         for timer in data["clock"]["timers"].values():
3108             for attribute in attributes:
3109                 if attribute not in timer:
3110                     timer[attribute] = None
3111         for timer_name in timer_names:
3112             if timer_name not in data["clock"]["timers"]:
3113                 data["clock"]["timers"][timer_name] = None
3114     _normalize_cpusets(desc, data)
3115     params_mapping = [
3116         {
3117             "path": "stop_on_reboot",
3118             "xpath": "on_reboot",
3119             "convert": lambda v: "destroy" if v else "restart",
3120         },
3121         {"path": "boot:kernel", "xpath": "os/kernel"},
3122         {"path": "boot:initrd", "xpath": "os/initrd"},
3123         {"path": "boot:cmdline", "xpath": "os/cmdline"},
3124         {"path": "boot:loader", "xpath": "os/loader", "set": _set_loader},
3125         {"path": "boot:nvram", "xpath": "os/nvram", "set": _set_nvram},
3126         _memory_parameter("mem", "memory"),
3127         _memory_parameter("mem", "currentMemory"),
3128         _memory_parameter("mem:max", "maxMemory"),
3129         _memory_parameter("mem:boot", "memory"),
3130         _memory_parameter("mem:current", "currentMemory"),
3131         xmlutil.attribute("mem:slots", "maxMemory", "slots", ["unit"]),
3132         _memory_parameter("mem:hard_limit", "memtune/hard_limit"),
3133         _memory_parameter("mem:soft_limit", "memtune/soft_limit"),
3134         _memory_parameter("mem:swap_hard_limit", "memtune/swap_hard_limit"),
3135         _memory_parameter("mem:min_guarantee", "memtune/min_guarantee"),
3136         xmlutil.attribute("boot_dev:{dev}", "os/boot[$dev]", "dev"),
3137         _memory_parameter(
3138             "mem:hugepages:{id}:size",
3139             "memoryBacking/hugepages/page[$id]",
3140             "size",
3141             ["unit", "nodeset"],
3142         ),
3143         _cpuset_parameter(
3144             "mem:hugepages:{id}:nodeset", "memoryBacking/hugepages/page[$id]", "nodeset"
3145         ),
3146         {
3147             "path": "mem:nosharepages",
3148             "xpath": "memoryBacking/nosharepages",
3149             "get": lambda n: n is not None,
3150             "set": lambda n, v: None,
3151         },
3152         {
3153             "path": "mem:locked",
3154             "xpath": "memoryBacking/locked",
3155             "get": lambda n: n is not None,
3156             "set": lambda n, v: None,
3157         },
3158         xmlutil.attribute("mem:source", "memoryBacking/source", "type"),
3159         xmlutil.attribute("mem:access", "memoryBacking/access", "mode"),
3160         xmlutil.attribute("mem:allocation", "memoryBacking/allocation", "mode"),
3161         {"path": "mem:discard", "xpath": "memoryBacking/discard"},
3162         {
3163             "path": "cpu",
3164             "xpath": "vcpu",
3165             "get": lambda n: int(n.text),
3166             "set": _set_vcpu,
3167         },
3168         {"path": "cpu:maximum", "xpath": "vcpu", "get": lambda n: int(n.text)},
3169         xmlutil.attribute("cpu:placement", "vcpu", "placement"),
3170         _cpuset_parameter("cpu:cpuset", "vcpu", "cpuset"),
3171         xmlutil.attribute("cpu:current", "vcpu", "current"),
3172         xmlutil.attribute("cpu:match", "cpu", "match"),
3173         xmlutil.attribute("cpu:mode", "cpu", "mode"),
3174         xmlutil.attribute("cpu:check", "cpu", "check"),
3175         {"path": "cpu:model:name", "xpath": "cpu/model"},
3176         xmlutil.attribute("cpu:model:fallback", "cpu/model", "fallback"),
3177         xmlutil.attribute("cpu:model:vendor_id", "cpu/model", "vendor_id"),
3178         {"path": "cpu:vendor", "xpath": "cpu/vendor"},
3179         xmlutil.attribute("cpu:topology:sockets", "cpu/topology", "sockets"),
3180         xmlutil.attribute("cpu:topology:cores", "cpu/topology", "cores"),
3181         xmlutil.attribute("cpu:topology:threads", "cpu/topology", "threads"),
3182         xmlutil.attribute("cpu:cache:level", "cpu/cache", "level"),
3183         xmlutil.attribute("cpu:cache:mode", "cpu/cache", "mode"),
3184         xmlutil.attribute(
3185             "cpu:features:{id}", "cpu/feature[@name='$id']", "policy", ["name"]
3186         ),
3187         _yesno_attribute(
3188             "cpu:vcpus:{id}:enabled", "vcpus/vcpu[@id='$id']", "enabled", ["id"]
3189         ),
3190         _yesno_attribute(
3191             "cpu:vcpus:{id}:hotpluggable",
3192             "vcpus/vcpu[@id='$id']",
3193             "hotpluggable",
3194             ["id"],
3195         ),
3196         xmlutil.int_attribute(
3197             "cpu:vcpus:{id}:order", "vcpus/vcpu[@id='$id']", "order", ["id"]
3198         ),
3199         _cpuset_parameter(
3200             "cpu:numa:{id}:cpus", "cpu/numa/cell[@id='$id']", "cpus", ["id"]
3201         ),
3202         _memory_parameter(
3203             "cpu:numa:{id}:memory", "cpu/numa/cell[@id='$id']", "memory", ["id"]
3204         ),
3205         _yesno_attribute(
3206             "cpu:numa:{id}:discard", "cpu/numa/cell[@id='$id']", "discard", ["id"]
3207         ),
3208         xmlutil.attribute(
3209             "cpu:numa:{id}:memAccess", "cpu/numa/cell[@id='$id']", "memAccess", ["id"]
3210         ),
3211         xmlutil.attribute(
3212             "cpu:numa:{id}:distances:{sid}",
3213             "cpu/numa/cell[@id='$id']/distances/sibling[@id='$sid']",
3214             "value",
3215             ["id"],
3216         ),
3217         {"path": "cpu:iothreads", "xpath": "iothreads"},
3218         {"path": "cpu:tuning:shares", "xpath": "cputune/shares"},
3219         {"path": "cpu:tuning:period", "xpath": "cputune/period"},
3220         {"path": "cpu:tuning:quota", "xpath": "cputune/quota"},
3221         {"path": "cpu:tuning:global_period", "xpath": "cputune/global_period"},
3222         {"path": "cpu:tuning:global_quota", "xpath": "cputune/global_quota"},
3223         {"path": "cpu:tuning:emulator_period", "xpath": "cputune/emulator_period"},
3224         {"path": "cpu:tuning:emulator_quota", "xpath": "cputune/emulator_quota"},
3225         {"path": "cpu:tuning:iothread_period", "xpath": "cputune/iothread_period"},
3226         {"path": "cpu:tuning:iothread_quota", "xpath": "cputune/iothread_quota"},
3227         _cpuset_parameter(
3228             "cpu:tuning:vcpupin:{id}",
3229             "cputune/vcpupin[@vcpu='$id']",
3230             "cpuset",
3231             ["vcpu"],
3232         ),
3233         _cpuset_parameter("cpu:tuning:emulatorpin", "cputune/emulatorpin", "cpuset"),
3234         _cpuset_parameter(
3235             "cpu:tuning:iothreadpin:{id}",
3236             "cputune/iothreadpin[@iothread='$id']",
3237             "cpuset",
3238             ["iothread"],
3239         ),
3240         xmlutil.attribute(
3241             "cpu:tuning:vcpusched:{id}:scheduler",
3242             "cputune/vcpusched[$id]",
3243             "scheduler",
3244             ["priority", "vcpus"],
3245         ),
3246         xmlutil.attribute(
3247             "cpu:tuning:vcpusched:{id}:priority", "cputune/vcpusched[$id]", "priority"
3248         ),
3249         _cpuset_parameter(
3250             "cpu:tuning:vcpusched:{id}:vcpus", "cputune/vcpusched[$id]", "vcpus"
3251         ),
3252         xmlutil.attribute(
3253             "cpu:tuning:iothreadsched:{id}:scheduler",
3254             "cputune/iothreadsched[$id]",
3255             "scheduler",
3256             ["priority", "iothreads"],
3257         ),
3258         xmlutil.attribute(
3259             "cpu:tuning:iothreadsched:{id}:priority",
3260             "cputune/iothreadsched[$id]",
3261             "priority",
3262         ),
3263         _cpuset_parameter(
3264             "cpu:tuning:iothreadsched:{id}:iothreads",
3265             "cputune/iothreadsched[$id]",
3266             "iothreads",
3267         ),
3268         xmlutil.attribute(
3269             "cpu:tuning:emulatorsched:scheduler",
3270             "cputune/emulatorsched",
3271             "scheduler",
3272             ["priority"],
3273         ),
3274         xmlutil.attribute(
3275             "cpu:tuning:emulatorsched:priority", "cputune/emulatorsched", "priority"
3276         ),
3277         xmlutil.attribute(
3278             "cpu:tuning:cachetune:{id}:monitor:{sid}",
3279             "cputune/cachetune[@vcpus='$id']/monitor[@vcpus='$sid']",
3280             "level",
3281             ["vcpus"],
3282         ),
3283         xmlutil.attribute(
3284             "cpu:tuning:memorytune:{id}:{sid}",
3285             "cputune/memorytune[@vcpus='$id']/node[@id='$sid']",
3286             "bandwidth",
3287             ["id", "vcpus"],
3288         ),
3289         xmlutil.attribute("clock:offset", "clock", "offset"),
3290         xmlutil.attribute("clock:adjustment", "clock", "adjustment", convert=str),
3291         xmlutil.attribute("clock:timezone", "clock", "timezone"),
3292     ]
3293     for timer in timer_names:
3294         params_mapping += [
3295             xmlutil<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.attribute(
3296                 "clock:timers:{}:track".format(timer),
3297                 "clock/timer[@name='{}']".format(timer),
3298                 "track",
3299                 ["name"],
3300             ),
3301             xmlutil.attribute(
3302                 "clock:timers:{}:tickpolicy".format(timer),
3303                 "clock/timer[@name='{}']".format(timer),
3304                 "tickpolicy",
3305                 ["name"],
3306             ),
3307             xmlutil.int_attribute(
3308                 "clock:timers:{}:frequency".format(timer),
3309                 "clock/timer[@name='{}']".format(timer),
3310                 "frequency",
3311                 ["name"],
3312             ),
3313             xmlutil.attribute(
3314                 "clock:timers:{}:mode".format(timer),
3315                 "clock/timer[@name='{}']".format(</b></font>timer),
3316                 "mode",
3317                 ["name"],
3318             ),
3319             _yesno_attribute(
3320                 "clock:timers:{}:present".format(timer),
3321                 "clock/timer[@name='{}']".format(timer),
3322                 "present",
3323                 ["name"],
3324             ),
3325         ]
3326         for attr in ["slew", "threshold", "limit"]:
3327             params_mapping.append(
3328                 xmlutil.int_attribute(
3329                     "clock:timers:{}:{}".format(timer, attr),
3330                     "clock/timer[@name='{}']/catchup".format(timer),
3331                     attr,
3332                 )
3333             )
3334     for attr in ["level", "type", "size"]:
3335         params_mapping.append(
3336             xmlutil.attribute(
3337                 "cpu:tuning:cachetune:{id}:{sid}:" + attr,
3338                 "cputune/cachetune[@vcpus='$id']/cache[@id='$sid']",
3339                 attr,
3340                 ["id", "unit", "vcpus"],
3341             )
3342         )
3343     if hypervisor in ["qemu", "kvm"]:
3344         params_mapping += [
3345             xmlutil.attribute("numatune:memory:mode", "numatune/memory", "mode"),
3346             _cpuset_parameter("numatune:memory:nodeset", "numatune/memory", "nodeset"),
3347             xmlutil.attribute(
3348                 "numatune:memnodes:{id}:mode",
3349                 "numatune/memnode[@cellid='$id']",
3350                 "mode",
3351                 ["cellid"],
3352             ),
3353             _cpuset_parameter(
3354                 "numatune:memnodes:{id}:nodeset",
3355                 "numatune/memnode[@cellid='$id']",
3356                 "nodeset",
3357                 ["cellid"],
3358             ),
3359             xmlutil.attribute(
3360                 "hypervisor_features:kvm-hint-dedicated",
3361                 "features/kvm/hint-dedicated",
3362                 "state",
3363                 convert=lambda v: "on" if v else "off",
3364             ),
3365         ]
3366     need_update = (
3367         salt.utils.xmlutil.change_xml(desc, data, params_mapping) or need_update
3368     )
3369     devices_node = desc.find("devices")
3370     func_locals = locals()
3371     def _skip_update(names):
3372         return all(func_locals.get(n) is None for n in names)
3373     to_skip = {
3374         "disk": _skip_update(["disks", "disk_profile"]),
3375         "interface": _skip_update(["interfaces", "nic_profile"]),
3376         "graphics": _skip_update(["graphics"]),
3377         "serial": _skip_update(["serials"]),
3378         "console": _skip_update(["consoles"]),
3379         "hostdev": _skip_update(["host_devices"]),
3380     }
3381     changes = _compute_device_changes(desc, new_desc, to_skip)
3382     for dev_type in changes:
3383         if not to_skip[dev_type]:
3384             old = devices_node.findall(dev_type)
3385             if changes[dev_type].get("deleted") or changes[dev_type].get("new"):
3386                 for item in old:
3387                     devices_node.remove(item)
3388                 devices_node.extend(changes[dev_type]["sorted"])
3389                 need_update = True
3390     if need_update:
3391         try:
3392             if changes["disk"]:
3393                 for idx, item in enumerate(changes["disk"]["sorted"]):
3394                     source_file = all_disks[idx].get("source_file")
3395                     if all_disks[idx].get("device", "disk") == "cdrom":
3396                         continue
3397                     if (
3398                         item in changes["disk"]["new"]
3399                         and source_file
3400                         and not os.path.exists(source_file)
3401                     ):
3402                         _qemu_image_create(all_disks[idx])
3403                     elif item in changes["disk"]["new"] and not source_file:
3404                         _disk_volume_create(conn, all_disks[idx])
3405             if not test:
3406                 xml_desc = xmlutil.element_to_str(desc)
3407                 log.debug("Update virtual machine definition: %s", xml_desc)
3408                 conn.defineXML(xml_desc)
3409             status["definition"] = True
3410         except libvirt.libvirtError as err:
3411             conn.close()
3412             raise err
3413     if live:
3414         live_status, errors = _update_live(
3415             domain, new_desc, mem, cpu, old_mem, old_cpu, to_skip, test
3416         )
3417         status.update(live_status)
3418         if errors:
3419             status_errors = status.setdefault("errors", [])
3420             status_errors += errors
3421     conn.close()
3422     return status
3423 def list_domains(**kwargs):
3424     """
3425     Return a list of available domains.
3426     :param connection: libvirt connection URI, overriding defaults
3427         .. versionadded:: 2019.2.0
3428     :param username: username to connect with, overriding defaults
3429         .. versionadded:: 2019.2.0
3430     :param password: password to connect with, overriding defaults
3431         .. versionadded:: 2019.2.0
3432     CLI Example:
3433     .. code-block:: bash
3434         salt '*' virt.list_domains
3435     """
3436     vms = []
3437     conn = __get_conn(**kwargs)
3438     for dom in _get_domain(conn, iterable=True):
3439         vms.append(dom.name())
3440     conn.close()
3441     return vms
3442 def list_active_vms(**kwargs):
3443     """
3444     Return a list of names for active virtual machine on the minion
3445     :param connection: libvirt connection URI, overriding defaults
3446         .. versionadded:: 2019.2.0
3447     :param username: username to connect with, overriding defaults
3448         .. versionadded:: 2019.2.0
3449     :param password: password to connect with, overriding defaults
3450         .. versionadded:: 2019.2.0
3451     CLI Example:
3452     .. code-block:: bash
3453         salt '*' virt.list_active_vms
3454     """
3455     vms = []
3456     conn = __get_conn(**kwargs)
3457     for dom in _get_domain(conn, iterable=True, inactive=False):
3458         vms.append(dom.name())
3459     conn.close()
3460     return vms
3461 def list_inactive_vms(**kwargs):
3462     """
3463     Return a list of names for inactive virtual machine on the minion
3464     :param connection: libvirt connection URI, overriding defaults
3465         .. versionadded:: 2019.2.0
3466     :param username: username to connect with, overriding defaults
3467         .. versionadded:: 2019.2.0
3468     :param password: password to connect with, overriding defaults
3469         .. versionadded:: 2019.2.0
3470     CLI Example:
3471     .. code-block:: bash
3472         salt '*' virt.list_inactive_vms
3473     """
3474     vms = []
3475     conn = __get_conn(**kwargs)
3476     for dom in _get_domain(conn, iterable=True, active=False):
3477         vms.append(dom.name())
3478     conn.close()
3479     return vms
3480 def vm_info(vm_=None, **kwargs):
3481     """
3482     Return detailed information about the vms on this hyper in a
3483     list of dicts:
3484     :param vm_: name of the domain
3485     :param connection: libvirt connection URI, overriding defaults
3486         .. versionadded:: 2019.2.0
3487     :param username: username to connect with, overriding defaults
3488         .. versionadded:: 2019.2.0
3489     :param password: password to connect with, overriding defaults
3490         .. versionadded:: 2019.2.0
3491     .. code-block:: python
3492         [
3493             'your-vm': {
3494                 'cpu': &lt;int&gt;,
3495                 'maxMem': &lt;int&gt;,
3496                 'mem': &lt;int&gt;,
3497                 'state': '&lt;state&gt;',
3498                 'cputime' &lt;int&gt;
3499                 },
3500             ...
3501             ]
3502     If you pass a VM name in as an argument then it will return info
3503     for just the named VM, otherwise it will return all VMs.
3504     CLI Example:
3505     .. code-block:: bash
3506         salt '*' virt.vm_info
3507     """
3508     def _info(conn, dom):
3509         """
3510         Compute the infos of a domain
3511         """
3512         raw = dom.info()
3513         return {
3514             "cpu": raw[3],
3515             "cputime": int(raw[4]),
3516             "disks": _get_disks(conn, dom),
3517             "graphics": _get_graphics(dom),
3518             "nics": _get_nics(dom),
3519             "uuid": _get_uuid(dom),
3520             "loader": _get_loader(dom),
3521             "on_crash": _get_on_crash(dom),
3522             "on_reboot": _get_on_reboot(dom),
3523             "on_poweroff": _get_on_poweroff(dom),
3524             "maxMem": int(raw[1]),
3525             "mem": int(raw[2]),
3526             "state": VIRT_STATE_NAME_MAP.get(raw[0], "unknown"),
3527         }
3528     info = {}
3529     conn = __get_conn(**kwargs)
3530     if vm_:
3531         info[vm_] = _info(conn, _get_domain(conn, vm_))
3532     else:
3533         for domain in _get_domain(conn, iterable=True):
3534             info[domain.name()] = _info(conn, domain)
3535     conn.close()
3536     return info
3537 def vm_state(vm_=None, **kwargs):
3538     """
3539     Return list of all the vms and their state.
3540     If you pass a VM name in as an argument then it will return info
3541     for just the named VM, otherwise it will return all VMs.
3542     :param vm_: name of the domain
3543     :param connection: libvirt connection URI, overriding defaults
3544         .. versionadded:: 2019.2.0
3545     :param username: username to connect with, overriding defaults
3546         .. versionadded:: 2019.2.0
3547     :param password: password to connect with, overriding defaults
3548         .. versionadded:: 2019.2.0
3549     CLI Example:
3550     .. code-block:: bash
3551         salt '*' virt.vm_state &lt;domain&gt;
3552     """
3553     def _info(dom):
3554         """
3555         Compute domain state
3556         """
3557         state = ""
3558         raw = dom.info()
3559         state = VIRT_STATE_NAME_MAP.get(raw[0], "unknown")
3560         return state
3561     info = {}
3562     conn = __get_conn(**kwargs)
3563     if vm_:
3564         info[vm_] = _info(_get_domain(conn, vm_))
3565     else:
3566         for domain in _get_domain(conn, iterable=True):
3567             info[domain.name()] = _info(domain)
3568     conn.close()
3569     return info
3570 def _node_info(conn):
3571     """
3572     Internal variant of node_info taking a libvirt connection as parameter
3573     """
3574     raw = conn.getInfo()
3575     info = {
3576         "cpucores": raw[6],
3577         "cpumhz": raw[3],
3578         "cpumodel": str(raw[0]),
3579         "cpus": raw[2],
3580         "cputhreads": raw[7],
3581         "numanodes": raw[4],
3582         "phymemory": raw[1],
3583         "sockets": raw[5],
3584     }
3585     return info
3586 def node_info(**kwargs):
3587     """
3588     Return a dict with information about this node
3589     :param connection: libvirt connection URI, overriding defaults
3590         .. versionadded:: 2019.2.0
3591     :param username: username to connect with, overriding defaults
3592         .. versionadded:: 2019.2.0
3593     :param password: password to connect with, overriding defaults
3594         .. versionadded:: 2019.2.0
3595     CLI Example:
3596     .. code-block:: bash
3597         salt '*' virt.node_info
3598     """
3599     conn = __get_conn(**kwargs)
3600     info = _node_info(conn)
3601     conn.close()
3602     return info
3603 def _node_devices(conn):
3604     """
3605     List the host available devices, using an established connection.
3606     :param conn: the libvirt connection handle to use.
3607     .. versionadded:: 3003
3608     """
3609     devices = conn.listAllDevices()
3610     devices_infos = []
3611     for dev in devices:
3612         root = ElementTree.fromstring(dev.XMLDesc())
3613         if not set(dev.listCaps()) &amp; {"pci", "usb_device", "net"}:
3614             continue
3615         infos = {
3616             "caps": " ".join(dev.listCaps()),
3617         }
3618         if "net" in dev.listCaps():
3619             parent = root.find(".//parent").text
3620             if parent == "computer":
3621                 continue
3622             infos.update(
3623                 {
3624                     "name": root.find(".//interface").text,
3625                     "address": root.find(".//address").text,
3626                     "device name": parent,
3627                     "state": root.find(".//link").get("state"),
3628                 }
3629             )
3630             devices_infos.append(infos)
3631             continue
3632         vendor_node = root.find(".//vendor")
3633         vendor_id = vendor_node.get("id").lower()
3634         product_node = root.find(".//product")
3635         product_id = product_node.get("id").lower()
3636         infos.update(
3637             {"name": dev.name(), "vendor_id": vendor_id, "product_id": product_id}
3638         )
3639         if vendor_node.text:
3640             infos["vendor"] = vendor_node.text
3641         if product_node.text:
3642             infos["product"] = product_node.text
3643         if "pci" in dev.listCaps():
3644             infos["address"] = "{:04x}:{:02x}:{:02x}.{}".format(
3645                 int(root.find(".//domain").text),
3646                 int(root.find(".//bus").text),
3647                 int(root.find(".//slot").text),
3648                 root.find(".//function").text,
3649             )
3650             class_node = root.find(".//class")
3651             if class_node is not None:
3652                 infos["PCI class"] = class_node.text
3653             vf_addresses = [
3654                 _format_pci_address(vf)
3655                 for vf in root.findall(
3656                     "./capability[@type='pci']/capability[@type='virt_functions']/address"
3657                 )
3658             ]
3659             if vf_addresses:
3660                 infos["virtual functions"] = vf_addresses
3661             pf = root.find(
3662                 "./capability[@type='pci']/capability[@type='phys_function']/address"
3663             )
3664             if pf is not None:
3665                 infos["physical function"] = _format_pci_address(pf)
3666         elif "usb_device" in dev.listCaps():
3667             infos["address"] = "{:03}:{:03}".format(
3668                 int(root.find(".//bus").text), int(root.find(".//device").text)
3669             )
3670         linux_usb_host = vendor_id == "0x1d6b" and product_id in [
3671             "0x0001",
3672             "0x0002",
3673             "0x0003",
3674         ]
3675         if (
3676             root.find(".//capability[@type='pci-bridge']") is None
3677             and not linux_usb_host
3678         ):
3679             devices_infos.append(infos)
3680     return devices_infos
3681 def node_devices(**kwargs):
3682     """
3683     List the host available devices.
3684     :param connection: libvirt connection URI, overriding defaults
3685     :param username: username to connect with, overriding defaults
3686     :param password: password to connect with, overriding defaults
3687     .. versionadded:: 3003
3688     """
3689     conn = __get_conn(**kwargs)
3690     devs = _node_devices(conn)
3691     conn.close()
3692     return devs
3693 def get_nics(vm_, **kwargs):
3694     """
3695     Return info about the network interfaces of a named vm
3696     :param vm_: name of the domain
3697     :param connection: libvirt connection URI, overriding defaults
3698         .. versionadded:: 2019.2.0
3699     :param username: username to connect with, overriding defaults
3700         .. versionadded:: 2019.2.0
3701     :param password: password to connect with, overriding defaults
3702         .. versionadded:: 2019.2.0
3703     CLI Example:
3704     .. code-block:: bash
3705         salt '*' virt.get_nics &lt;domain&gt;
3706     """
3707     conn = __get_conn(**kwargs)
3708     nics = _get_nics(_get_domain(conn, vm_))
3709     conn.close()
3710     return nics
3711 def get_macs(vm_, **kwargs):
3712     """
3713     Return a list off MAC addresses from the named vm
3714     :param vm_: name of the domain
3715     :param connection: libvirt connection URI, overriding defaults
3716         .. versionadded:: 2019.2.0
3717     :param username: username to connect with, overriding defaults
3718         .. versionadded:: 2019.2.0
3719     :param password: password to connect with, overriding defaults
3720         .. versionadded:: 2019.2.0
3721     CLI Example:
3722     .. code-block:: bash
3723         salt '*' virt.get_macs &lt;domain&gt;
3724     """
3725     doc = ElementTree.fromstring(get_xml(vm_, **kwargs))
3726     return [node.get("address") for node in doc.findall("devices/interface/mac")]
3727 def get_graphics(vm_, **kwargs):
3728     """
3729     Returns the information on vnc for a given vm
3730     :param vm_: name of the domain
3731     :param connection: libvirt connection URI, overriding defaults
3732         .. versionadded:: 2019.2.0
3733     :param username: username to connect with, overriding defaults
3734         .. versionadded:: 2019.2.0
3735     :param password: password to connect with, overriding defaults
3736         .. versionadded:: 2019.2.0
3737     CLI Example:
3738     .. code-block:: bash
3739         salt '*' virt.get_graphics &lt;domain&gt;
3740     """
3741     conn = __get_conn(**kwargs)
3742     graphics = _get_graphics(_get_domain(conn, vm_))
3743     conn.close()
3744     return graphics
3745 def get_loader(vm_, **kwargs):
3746     """
3747     Returns the information on the loader for a given vm
3748     :param vm_: name of the domain
3749     :param connection: libvirt connection URI, overriding defaults
3750     :param username: username to connect with, overriding defaults
3751     :param password: password to connect with, overriding defaults
3752     CLI Example:
3753     .. code-block:: bash
3754         salt '*' virt.get_loader &lt;domain&gt;
3755     .. versionadded:: 2019.2.0
3756     """
3757     conn = __get_conn(**kwargs)
3758     try:
3759         loader = _get_loader(_get_domain(conn, vm_))
3760         return loader
3761     finally:
3762         conn.close()
3763 def get_disks(vm_, **kwargs):
3764     """
3765     Return the disks of a named vm
3766     :param vm_: name of the domain
3767     :param connection: libvirt connection URI, overriding defaults
3768         .. versionadded:: 2019.2.0
3769     :param username: username to connect with, overriding defaults
3770         .. versionadded:: 2019.2.0
3771     :param password: password to connect with, overriding defaults
3772         .. versionadded:: 2019.2.0
3773     CLI Example:
3774     .. code-block:: bash
3775         salt '*' virt.get_disks &lt;domain&gt;
3776     """
3777     conn = __get_conn(**kwargs)
3778     disks = _get_disks(conn, _get_domain(conn, vm_))
3779     conn.close()
3780     return disks
3781 def setmem(vm_, memory, config=False, **kwargs):
3782     """
3783     Changes the amount of memory allocated to VM. The VM must be shutdown
3784     for this to work.
3785     :param vm_: name of the domain
3786     :param memory: memory amount to set in MB
3787     :param config: if True then libvirt will be asked to modify the config as well
3788     :param connection: libvirt connection URI, overriding defaults
3789         .. versionadded:: 2019.2.0
3790     :param username: username to connect with, overriding defaults
3791         .. versionadded:: 2019.2.0
3792     :param password: password to connect with, overriding defaults
3793         .. versionadded:: 2019.2.0
3794     CLI Example:
3795     .. code-block:: bash
3796         salt '*' virt.setmem &lt;domain&gt; &lt;size&gt;
3797         salt '*' virt.setmem my_domain 768
3798     """
3799     conn = __get_conn(**kwargs)
3800     dom = _get_domain(conn, vm_)
3801     if VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown":
3802         return False
3803     flags = libvirt.VIR_DOMAIN_MEM_MAXIMUM
3804     if config:
3805         flags = flags | libvirt.VIR_DOMAIN_AFFECT_CONFIG
3806     ret1 = dom.setMemoryFlags(memory * 1024, flags)
3807     ret2 = dom.setMemoryFlags(memory * 1024, libvirt.VIR_DOMAIN_AFFECT_CURRENT)
3808     conn.close()
3809     return ret1 == ret2 == 0
3810 def setvcpus(vm_, vcpus, config=False, **kwargs):
3811     """
3812     Changes the amount of vcpus allocated to VM. The VM must be shutdown
3813     for this to work.
3814     If config is True then we ask libvirt to modify the config as well
3815     :param vm_: name of the domain
3816     :param vcpus: integer representing the number of CPUs to be assigned
3817     :param config: if True then libvirt will be asked to modify the config as well
3818     :param connection: libvirt connection URI, overriding defaults
3819         .. versionadded:: 2019.2.0
3820     :param username: username to connect with, overriding defaults
3821         .. versionadded:: 2019.2.0
3822     :param password: password to connect with, overriding defaults
3823         .. versionadded:: 2019.2.0
3824     CLI Example:
3825     .. code-block:: bash
3826         salt '*' virt.setvcpus &lt;domain&gt; &lt;amount&gt;
3827         salt '*' virt.setvcpus my_domain 4
3828     """
3829     conn = __get_conn(**kwargs)
3830     dom = _get_domain(conn, vm_)
3831     if VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown":
3832         return False
3833     flags = libvirt.VIR_DOMAIN_VCPU_MAXIMUM
3834     if config:
3835         flags = flags | libvirt.VIR_DOMAIN_AFFECT_CONFIG
3836     ret1 = dom.setVcpusFlags(vcpus, flags)
3837     ret2 = dom.setVcpusFlags(vcpus, libvirt.VIR_DOMAIN_AFFECT_CURRENT)
3838     conn.close()
3839     return ret1 == ret2 == 0
3840 def _freemem(conn):
3841     """
3842     Internal variant of freemem taking a libvirt connection as parameter
3843     """
3844     mem = conn.getInfo()[1]
3845     mem -= 256
3846     for dom in _get_domain(conn, iterable=True):
3847         if dom.ID() &gt; 0:
3848             mem -= dom.info()[2] / 1024
3849     return mem
3850 def freemem(**kwargs):
3851     """
3852     Return an int representing the amount of memory (in MB) that has not
3853     been given to virtual machines on this node
3854     :param connection: libvirt connection URI, overriding defaults
3855         .. versionadded:: 2019.2.0
3856     :param username: username to connect with, overriding defaults
3857         .. versionadded:: 2019.2.0
3858     :param password: password to connect with, overriding defaults
3859         .. versionadded:: 2019.2.0
3860     CLI Example:
3861     .. code-block:: bash
3862         salt '*' virt.freemem
3863     """
3864     conn = __get_conn(**kwargs)
3865     mem = _freemem(conn)
3866     conn.close()
3867     return mem
3868 def _freecpu(conn):
3869     """
3870     Internal variant of freecpu taking a libvirt connection as parameter
3871     """
3872     cpus = conn.getInfo()[2]
3873     for dom in _get_domain(conn, iterable=True):
3874         if dom.ID() &gt; 0:
3875             cpus -= dom.info()[3]
3876     return cpus
3877 def freecpu(**kwargs):
3878     """
3879     Return an int representing the number of unallocated cpus on this
3880     hypervisor
3881     :param connection: libvirt connection URI, overriding defaults
3882         .. versionadded:: 2019.2.0
3883     :param username: username to connect with, overriding defaults
3884         .. versionadded:: 2019.2.0
3885     :param password: password to connect with, overriding defaults
3886         .. versionadded:: 2019.2.0
3887     CLI Example:
3888     .. code-block:: bash
3889         salt '*' virt.freecpu
3890     """
3891     conn = __get_conn(**kwargs)
3892     cpus = _freecpu(conn)
3893     conn.close()
3894     return cpus
3895 def full_info(**kwargs):
3896     """
3897     Return the node_info, vm_info and freemem
3898     :param connection: libvirt connection URI, overriding defaults
3899         .. versionadded:: 2019.2.0
3900     :param username: username to connect with, overriding defaults
3901         .. versionadded:: 2019.2.0
3902     :param password: password to connect with, overriding defaults
3903         .. versionadded:: 2019.2.0
3904     CLI Example:
3905     .. code-block:: bash
3906         salt '*' virt.full_info
3907     """
3908     conn = __get_conn(**kwargs)
3909     info = {
3910         "freecpu": _freecpu(conn),
3911         "freemem": _freemem(conn),
3912         "node_info": _node_info(conn),
3913         "vm_info": vm_info(),
3914     }
3915     conn.close()
3916     return info
3917 def get_xml(vm_, **kwargs):
3918     """
3919     Returns the XML for a given vm
3920     :param vm_: domain name
3921     :param connection: libvirt connection URI, overriding defaults
3922         .. versionadded:: 2019.2.0
3923     :param username: username to connect with, overriding defaults
3924         .. versionadded:: 2019.2.0
3925     :param password: password to connect with, overriding defaults
3926         .. versionadded:: 2019.2.0
3927     CLI Example:
3928     .. code-block:: bash
3929         salt '*' virt.get_xml &lt;domain&gt;
3930     """
3931     conn = __get_conn(**kwargs)
3932     xml_desc = (
3933         vm_.XMLDesc(0)
3934         if isinstance(vm_, libvirt.virDomain)
3935         else _get_domain(conn, vm_).XMLDesc(0)
3936     )
3937     conn.close()
3938     return xml_desc
3939 def get_profiles(hypervisor=None, **kwargs):
3940     """
3941     Return the virt profiles for hypervisor.
3942     Currently there are profiles for:
3943     - nic
3944     - disk
3945     :param hypervisor: override the default machine type.
3946     :param connection: libvirt connection URI, overriding defaults
3947         .. versionadded:: 2019.2.0
3948     :param username: username to connect with, overriding defaults
3949         .. versionadded:: 2019.2.0
3950     :param password: password to connect with, overriding defaults
3951         .. versionadded:: 2019.2.0
3952     CLI Example:
3953     .. code-block:: bash
3954         salt '*' virt.get_profiles
3955         salt '*' virt.get_profiles hypervisor=vmware
3956     """
3957     conn = __get_conn(**kwargs)
3958     caps = _capabilities(conn)
3959     hypervisors = sorted(
3960         {
3961             x
3962             for y in [guest["arch"]["domains"].keys() for guest in caps["guests"]]
3963             for x in y
3964         }
3965     )
3966     if len(hypervisors) == 0:
3967         raise SaltInvocationError("No supported hypervisors were found")
3968     if not hypervisor:
3969         hypervisor = "kvm" if "kvm" in hypervisors else hypervisors[0]
3970     ret = {
3971         "disk": {"default": _disk_profile(conn, "default", hypervisor, [], None)},
3972         "nic": {"default": _nic_profile("default", hypervisor)},
3973     }
3974     virtconf = __salt__["config.get"]("virt", {})
3975     for profile in virtconf.get("disk", []):
3976         ret["disk"][profile] = _disk_profile(conn, profile, hypervisor, [], None)
3977     for profile in virtconf.get("nic", []):
3978         ret["nic"][profile] = _nic_profile(profile, hypervisor)
3979     return ret
3980 def shutdown(vm_, **kwargs):
3981     """
3982     Send a soft shutdown signal to the named vm
3983     :param vm_: domain name
3984     :param connection: libvirt connection URI, overriding defaults
3985         .. versionadded:: 2019.2.0
3986     :param username: username to connect with, overriding defaults
3987         .. versionadded:: 2019.2.0
3988     :param password: password to connect with, overriding defaults
3989         .. versionadded:: 2019.2.0
3990     CLI Example:
3991     .. code-block:: bash
3992         salt '*' virt.shutdown &lt;domain&gt;
3993     """
3994     conn = __get_conn(**kwargs)
3995     dom = _get_domain(conn, vm_)
3996     ret = dom.shutdown() == 0
3997     conn.close()
3998     return ret
3999 def pause(vm_, **kwargs):
4000     """
4001     Pause the named vm
4002     :param vm_: domain name
4003     :param connection: libvirt connection URI, overriding defaults
4004         .. versionadded:: 2019.2.0
4005     :param username: username to connect with, overriding defaults
4006         .. versionadded:: 2019.2.0
4007     :param password: password to connect with, overriding defaults
4008         .. versionadded:: 2019.2.0
4009     CLI Example:
4010     .. code-block:: bash
4011         salt '*' virt.pause &lt;domain&gt;
4012     """
4013     conn = __get_conn(**kwargs)
4014     dom = _get_domain(conn, vm_)
4015     ret = dom.suspend() == 0
4016     conn.close()
4017     return ret
4018 def resume(vm_, **kwargs):
4019     """
4020     Resume the named vm
4021     :param vm_: domain name
4022     :param connection: libvirt connection URI, overriding defaults
4023         .. versionadded:: 2019.2.0
4024     :param username: username to connect with, overriding defaults
4025         .. versionadded:: 2019.2.0
4026     :param password: password to connect with, overriding defaults
4027         .. versionadded:: 2019.2.0
4028     CLI Example:
4029     .. code-block:: bash
4030         salt '*' virt.resume &lt;domain&gt;
4031     """
4032     conn = __get_conn(**kwargs)
4033     dom = _get_domain(conn, vm_)
4034     ret = dom.resume() == 0
4035     conn.close()
4036     return ret
4037 def start(name, **kwargs):
4038     """
4039     Start a defined domain
4040     :param vm_: domain name
4041     :param connection: libvirt connection URI, overriding defaults
4042         .. versionadded:: 2019.2.0
4043     :param username: username to connect with, overriding defaults
4044         .. versionadded:: 2019.2.0
4045     :param password: password to connect with, overriding defaults
4046         .. versionadded:: 2019.2.0
4047     CLI Example:
4048     .. code-block:: bash
4049         salt '*' virt.start &lt;domain&gt;
4050     """
4051     conn = __get_conn(**kwargs)
4052     ret = _get_domain(conn, name).create() == 0
4053     conn.close()
4054     return ret
4055 def stop(name, **kwargs):
4056     """
4057     Hard power down the virtual machine, this is equivalent to pulling the power.
4058     :param vm_: domain name
4059     :param connection: libvirt connection URI, overriding defaults
4060         .. versionadded:: 2019.2.0
4061     :param username: username to connect with, overriding defaults
4062         .. versionadded:: 2019.2.0
4063     :param password: password to connect with, overriding defaults
4064         .. versionadded:: 2019.2.0
4065     CLI Example:
4066     .. code-block:: bash
4067         salt '*' virt.stop &lt;domain&gt;
4068     """
4069     conn = __get_conn(**kwargs)
4070     ret = _get_domain(conn, name).destroy() == 0
4071     conn.close()
4072     return ret
4073 def reboot(name, **kwargs):
4074     """
4075     Reboot a domain via ACPI request
4076     :param vm_: domain name
4077     :param connection: libvirt connection URI, overriding defaults
4078         .. versionadded:: 2019.2.0
4079     :param username: username to connect with, overriding defaults
4080         .. versionadded:: 2019.2.0
4081     :param password: password to connect with, overriding defaults
4082         .. versionadded:: 2019.2.0
4083     CLI Example:
4084     .. code-block:: bash
4085         salt '*' virt.reboot &lt;domain&gt;
4086     """
4087     conn = __get_conn(**kwargs)
4088     ret = _get_domain(conn, name).reboot(libvirt.VIR_DOMAIN_REBOOT_DEFAULT) == 0
4089     conn.close()
4090     return ret
4091 def reset(vm_, **kwargs):
4092     """
4093     Reset a VM by emulating the reset button on a physical machine
4094     :param vm_: domain name
4095     :param connection: libvirt connection URI, overriding defaults
4096         .. versionadded:: 2019.2.0
4097     :param username: username to connect with, overriding defaults
4098         .. versionadded:: 2019.2.0
4099     :param password: password to connect with, overriding defaults
4100         .. versionadded:: 2019.2.0
4101     CLI Example:
4102     .. code-block:: bash
4103         salt '*' virt.reset &lt;domain&gt;
4104     """
4105     conn = __get_conn(**kwargs)
4106     dom = _get_domain(conn, vm_)
4107     ret = dom.reset(0) == 0
4108     conn.close()
4109     return ret
4110 def ctrl_alt_del(vm_, **kwargs):
4111     """
4112     Sends CTRL+ALT+DEL to a VM
4113     :param vm_: domain name
4114     :param connection: libvirt connection URI, overriding defaults
4115         .. versionadded:: 2019.2.0
4116     :param username: username to connect with, overriding defaults
4117         .. versionadded:: 2019.2.0
4118     :param password: password to connect with, overriding defaults
4119         .. versionadded:: 2019.2.0
4120     CLI Example:
4121     .. code-block:: bash
4122         salt '*' virt.ctrl_alt_del &lt;domain&gt;
4123     """
4124     conn = __get_conn(**kwargs)
4125     dom = _get_domain(conn, vm_)
4126     ret = dom.sendKey(0, 0, [29, 56, 111], 3, 0) == 0
4127     conn.close()
4128     return ret
4129 def create_xml_str(xml, **kwargs):  # pylint: disable=redefined-outer-name
4130     """
4131     Start a transient domain based on the XML passed to the function
4132     :param xml: libvirt XML definition of the domain
4133     :param connection: libvirt connection URI, overriding defaults
4134         .. versionadded:: 2019.2.0
4135     :param username: username to connect with, overriding defaults
4136         .. versionadded:: 2019.2.0
4137     :param password: password to connect with, overriding defaults
4138         .. versionadded:: 2019.2.0
4139     CLI Example:
4140     .. code-block:: bash
4141         salt '*' virt.create_xml_str &lt;XML in string format&gt;
4142     """
4143     conn = __get_conn(**kwargs)
4144     ret = conn.createXML(xml, 0) is not None
4145     conn.close()
4146     return ret
4147 def create_xml_path(path, **kwargs):
4148     """
4149     Start a transient domain based on the XML-file path passed to the function
4150     :param path: path to a file containing the libvirt XML definition of the domain
4151     :param connection: libvirt connection URI, overriding defaults
4152         .. versionadded:: 2019.2.0
4153     :param username: username to connect with, overriding defaults
4154         .. versionadded:: 2019.2.0
4155     :param password: password to connect with, overriding defaults
4156         .. versionadded:: 2019.2.0
4157     CLI Example:
4158     .. code-block:: bash
4159         salt '*' virt.create_xml_path &lt;path to XML file on the node&gt;
4160     """
4161     try:
4162         with salt.utils.files.fopen(path, "r") as fp_:
4163             return create_xml_str(
4164                 salt.utils.stringutils.to_unicode(fp_.read()), **kwargs
4165             )
4166     except OSError:
4167         return False
4168 def define_xml_str(xml, **kwargs):  # pylint: disable=redefined-outer-name
4169     """
4170     Define a persistent domain based on the XML passed to the function
4171     :param xml: libvirt XML definition of the domain
4172     :param connection: libvirt connection URI, overriding defaults
4173         .. versionadded:: 2019.2.0
4174     :param username: username to connect with, overriding defaults
4175         .. versionadded:: 2019.2.0
4176     :param password: password to connect with, overriding defaults
4177         .. versionadded:: 2019.2.0
4178     CLI Example:
4179     .. code-block:: bash
4180         salt '*' virt.define_xml_str &lt;XML in string format&gt;
4181     """
4182     conn = __get_conn(**kwargs)
4183     ret = conn.defineXML(xml) is not None
4184     conn.close()
4185     return ret
4186 def define_xml_path(path, **kwargs):
4187     """
4188     Define a persistent domain based on the XML-file path passed to the function
4189     :param path: path to a file containing the libvirt XML definition of the domain
4190     :param connection: libvirt connection URI, overriding defaults
4191         .. versionadded:: 2019.2.0
4192     :param username: username to connect with, overriding defaults
4193         .. versionadded:: 2019.2.0
4194     :param password: password to connect with, overriding defaults
4195         .. versionadded:: 2019.2.0
4196     CLI Example:
4197     .. code-block:: bash
4198         salt '*' virt.define_xml_path &lt;path to XML file on the node&gt;
4199     """
4200     try:
4201         with salt.utils.files.fopen(path, "r") as fp_:
4202             return define_xml_str(
4203                 salt.utils.stringutils.to_unicode(fp_.read()), **kwargs
4204             )
4205     except OSError:
4206         return False
4207 def _define_vol_xml_str(conn, xml, pool=None):  # pylint: disable=redefined-outer-name
4208     """
4209     Same function than define_vml_xml_str but using an already opened libvirt connection
4210     """
4211     default_pool = "default" if conn.getType() != "ESX" else "0"
4212     poolname = (
4213         pool if pool else __salt__["config.get"]("virt:storagepool", default_pool)
4214     )
4215     pool = conn.storagePoolLookupByName(str(poolname))
4216     ret = pool.createXML(xml, 0) is not None
4217     return ret
4218 def define_vol_xml_str(
4219     xml, pool=None, **kwargs
4220 ):  # pylint: disable=redefined-outer-name
4221     """
4222     Define a volume based on the XML passed to the function
4223     :param xml: libvirt XML definition of the storage volume
4224     :param pool:
4225         storage pool name to define the volume in.
4226         If defined, this parameter will override the configuration setting.
4227         .. versionadded:: 3001
4228     :param connection: libvirt connection URI, overriding defaults
4229         .. versionadded:: 2019.2.0
4230     :param username: username to connect with, overriding defaults
4231         .. versionadded:: 2019.2.0
4232     :param password: password to connect with, overriding defaults
4233         .. versionadded:: 2019.2.0
4234     CLI Example:
4235     .. code-block:: bash
4236         salt '*' virt.define_vol_xml_str &lt;XML in string format&gt;
4237     The storage pool where the disk image will be defined is ``default``
4238     unless changed with the pool parameter or a configuration like this:
4239     .. code-block:: yaml
4240         virt:
4241             storagepool: mine
4242     """
4243     conn = __get_conn(**kwargs)
4244     ret = False
4245     try:
4246         ret = _define_vol_xml_str(conn, xml, pool=pool)
4247     except libvirtError as err:
4248         raise CommandExecutionError(err.get_error_message())
4249     finally:
4250         conn.close()
4251     return ret
4252 def define_vol_xml_path(path, pool=None, **kwargs):
4253     """
4254     Define a volume based on the XML-file path passed to the function
4255     :param path: path to a file containing the libvirt XML definition of the volume
4256     :param pool:
4257         storage pool name to define the volume in.
4258         If defined, this parameter will override the configuration setting.
4259         .. versionadded:: 3001
4260     :param connection: libvirt connection URI, overriding defaults
4261         .. versionadded:: 2019.2.0
4262     :param username: username to connect with, overriding defaults
4263         .. versionadded:: 2019.2.0
4264     :param password: password to connect with, overriding defaults
4265         .. versionadded:: 2019.2.0
4266     CLI Example:
4267     .. code-block:: bash
4268         salt '*' virt.define_vol_xml_path &lt;path to XML file on the node&gt;
4269     """
4270     try:
4271         with salt.utils.files.fopen(path, "r") as fp_:
4272             return define_vol_xml_str(
4273                 salt.utils.stringutils.to_unicode(fp_.read()), pool=pool, **kwargs
4274             )
4275     except OSError:
4276         return False
4277 def migrate(vm_, target, **kwargs):
4278     """
4279     Shared storage migration
4280     :param vm_: domain name
4281     :param target: target libvirt URI or host name
4282     :param kwargs:
4283         - live:            Use live migration. Default value is True.
4284         - persistent:      Leave the domain persistent on destination host.
4285                            Default value is True.
4286         - undefinesource:  Undefine the domain on the source host.
4287                            Default value is True.
4288         - offline:         If set to True it will migrate the domain definition
4289                            without starting the domain on destination and without
4290                            stopping it on source host. Default value is False.
4291         - max_bandwidth:   The maximum bandwidth (in MiB/s) that will be used.
4292         - max_downtime:    Set maximum tolerable downtime for live-migration.
4293                            The value represents a number of milliseconds the guest
4294                            is allowed to be down at the end of live migration.
4295         - parallel_connections: Specify a number of parallel network connections
4296                            to be used to send memory pages to the destination host.
4297         - compressed:      Activate compression.
4298         - comp_methods:    A comma-separated list of compression methods. Supported
4299                            methods are "mt" and "xbzrle" and can be  used in any
4300                            combination. QEMU defaults to "xbzrle".
4301         - comp_mt_level:   Set compression level. Values are in range from 0 to 9,
4302                            where 1 is maximum speed and 9 is  maximum compression.
4303         - comp_mt_threads: Set number of compress threads on source host.
4304         - comp_mt_dthreads: Set number of decompress threads on target host.
4305         - comp_xbzrle_cache: Set the size of page cache for xbzrle compression in bytes.
4306         - copy_storage:    Migrate non-shared storage. It must be one of the following
4307                            values: all (full disk copy) or incremental (Incremental copy)
4308         - postcopy:        Enable the use of post-copy migration.
4309         - postcopy_bandwidth: The maximum bandwidth allowed in post-copy phase. (MiB/s)
4310         - username:        Username to connect with target host
4311         - password:        Password to connect with target host
4312         .. versionadded:: 3002
4313     CLI Example:
4314     .. code-block:: bash
4315         salt '*' virt.migrate &lt;domain&gt; &lt;target hypervisor URI&gt;
4316         salt src virt.migrate guest qemu+ssh://dst/system
4317         salt src virt.migrate guest qemu+tls://dst/system
4318         salt src virt.migrate guest qemu+tcp://dst/system
4319     A tunnel data migration can be performed by setting this in the
4320     configuration:
4321     .. code-block:: yaml
4322         virt:
4323             tunnel: True
4324     For more details on tunnelled data migrations, report to
4325     https://libvirt.org/migration.html#transporttunnel
4326     """
4327     conn = __get_conn()
4328     dom = _get_domain(conn, vm_)
4329     if not urllib.parse.urlparse(target).scheme:
4330         proto = "qemu"
4331         dst_uri = "{}://{}/system".format(proto, target)
4332     else:
4333         dst_uri = target
4334     ret = _migrate(dom, dst_uri, **kwargs)
4335     conn.close()
4336     return ret
4337 def migrate_start_postcopy(vm_):
4338     """
4339     Starts post-copy migration. This function has to be called
4340     while live migration is in progress and it has been initiated
4341     with the `postcopy=True` option.
4342     CLI Example:
4343     .. code-block:: bash
4344         salt '*' virt.migrate_start_postcopy &lt;domain&gt;
4345     """
4346     conn = __get_conn()
4347     dom = _get_domain(conn, vm_)
4348     try:
4349         dom.migrateStartPostCopy()
4350     except libvirt.libvirtError as err:
4351         conn.close()
4352         raise CommandExecutionError(err.get_error_message())
4353     conn.close()
4354 def seed_non_shared_migrate(disks, force=False):
4355     """
4356     Non shared migration requires that the disks be present on the migration
4357     destination, pass the disks information via this function, to the
4358     migration destination before executing the migration.
4359     :param disks: the list of disk data as provided by virt.get_disks
4360     :param force: skip checking the compatibility of source and target disk
4361                   images if True. (default: False)
4362     CLI Example:
4363     .. code-block:: bash
4364         salt '*' virt.seed_non_shared_migrate &lt;disks&gt;
4365     """
4366     for _, data in disks.items():
4367         fn_ = data["file"]
4368         form = data["file format"]
4369         size = data["virtual size"].split()[1][1:]
4370         if os.path.isfile(fn_) and not force:
4371             pre = salt.utils.yaml.safe_load(
4372                 subprocess.Popen(
4373                     ["qemu-img", "info", "arch"], stdout=subprocess.PIPE
4374                 ).communicate()[0]
4375             )
4376             if (
4377                 pre["file format"] != data["file format"]
4378                 and pre["virtual size"] != data["virtual size"]
4379             ):
4380                 return False
4381         if not os.path.isdir(os.path.dirname(fn_)):
4382             os.makedirs(os.path.dirname(fn_))
4383         if os.path.isfile(fn_):
4384             os.remove(fn_)
4385         subprocess.call(["qemu-img", "create", "-f", form, fn_, size])
4386         creds = _libvirt_creds()
4387         subprocess.call(["chown", "{user}:{group}".format(**creds), fn_])
4388     return True
4389 def set_autostart(vm_, state="on", **kwargs):
4390     """
4391     Set the autostart flag on a VM so that the VM will start with the host
4392     system on reboot.
4393     :param vm_: domain name
4394     :param state: 'on' to auto start the pool, anything else to mark the
4395                   pool not to be started when the host boots
4396     :param connection: libvirt connection URI, overriding defaults
4397         .. versionadded:: 2019.2.0
4398     :param username: username to connect with, overriding defaults
4399         .. versionadded:: 2019.2.0
4400     :param password: password to connect with, overriding defaults
4401         .. versionadded:: 2019.2.0
4402     CLI Example:
4403     .. code-block:: bash
4404         salt "*" virt.set_autostart &lt;domain&gt; &lt;on | off&gt;
4405     """
4406     conn = __get_conn(**kwargs)
4407     dom = _get_domain(conn, vm_)
4408     ret = False
4409     if state == "on":
4410         ret = dom.setAutostart(1) == 0
4411     elif state == "off":
4412         ret = dom.setAutostart(0) == 0
4413     conn.close()
4414     return ret
4415 def undefine(vm_, **kwargs):
4416     """
4417     Remove a defined vm, this does not purge the virtual machine image, and
4418     this only works if the vm is powered down
4419     :param vm_: domain name
4420     :param connection: libvirt connection URI, overriding defaults
4421         .. versionadded:: 2019.2.0
4422     :param username: username to connect with, overriding defaults
4423         .. versionadded:: 2019.2.0
4424     :param password: password to connect with, overriding defaults
4425         .. versionadded:: 2019.2.0
4426     CLI Example:
4427     .. code-block:: bash
4428         salt '*' virt.undefine &lt;domain&gt;
4429     """
4430     conn = __get_conn(**kwargs)
4431     dom = _get_domain(conn, vm_)
4432     if getattr(libvirt, "VIR_DOMAIN_UNDEFINE_NVRAM", False):
4433         ret = dom.undefineFlags(libvirt.VIR_DOMAIN_UNDEFINE_NVRAM) == 0
4434     else:
4435         ret = dom.undefine() == 0
4436     conn.close()
4437     return ret
4438 def purge(vm_, dirs=False, removables=False, **kwargs):
4439     """
4440     Recursively destroy and delete a persistent virtual machine, pass True for
4441     dir's to also delete the directories containing the virtual machine disk
4442     images - USE WITH EXTREME CAUTION!
4443     :param vm_: domain name
4444     :param dirs: pass True to remove containing directories
4445     :param removables: pass True to remove removable devices
4446         .. versionadded:: 2019.2.0
4447     :param connection: libvirt connection URI, overriding defaults
4448         .. versionadded:: 2019.2.0
4449     :param username: username to connect with, overriding defaults
4450         .. versionadded:: 2019.2.0
4451     :param password: password to connect with, overriding defaults
4452         .. versionadded:: 2019.2.0
4453     CLI Example:
4454     .. code-block:: bash
4455         salt '*' virt.purge &lt;domain&gt;
4456     """
4457     conn = __get_conn(**kwargs)
4458     dom = _get_domain(conn, vm_)
4459     disks = _get_disks(conn, dom)
4460     if (
4461         VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown"
4462         and dom.destroy() != 0
4463     ):
4464         return False
4465     directories = set()
4466     for disk in disks:
4467         if not removables and disks[disk]["type"] in ["cdrom", "floppy"]:
4468             continue
4469         if disks[disk].get("zfs", False):
4470             time.sleep(3)
4471             fs_name = disks[disk]["file"][len("/dev/zvol/") :]
4472             log.info("Destroying VM ZFS volume %s", fs_name)
4473             __salt__["zfs.destroy"](name=fs_name, force=True)
4474         elif os.path.exists(disks[disk]["file"]):
4475             os.remove(disks[disk]["file"])
4476             directories.add(os.path.dirname(disks[disk]["file"]))
4477         else:
4478             matcher = re.match("^(?P&lt;pool&gt;[^/]+)/(?P&lt;volume&gt;.*)$", disks[disk]["file"])
4479             if matcher:
4480                 pool_name = matcher.group("pool")
4481                 pool = None
4482                 if pool_name in conn.listStoragePools():
4483                     pool = conn.storagePoolLookupByName(pool_name)
4484                 if pool and matcher.group("volume") in pool.listVolumes():
4485                     volume = pool.storageVolLookupByName(matcher.group("volume"))
4486                     volume.delete()
4487     if dirs:
4488         for dir_ in directories:
4489             shutil.rmtree(dir_)
4490     if getattr(libvirt, "VIR_DOMAIN_UNDEFINE_NVRAM", False):
4491         try:
4492             dom.undefineFlags(libvirt.VIR_DOMAIN_UNDEFINE_NVRAM)
4493         except Exception:  # pylint: disable=broad-except
4494             dom.undefine()
4495     else:
4496         dom.undefine()
4497     conn.close()
4498     return True
4499 def virt_type():
4500     """
4501     Returns the virtual machine type as a string
4502     CLI Example:
4503     .. code-block:: bash
4504         salt '*' virt.virt_type
4505     """
4506     return __grains__["virtual"]
4507 def _is_kvm_hyper():
4508     """
4509     Returns a bool whether or not this node is a KVM hypervisor
4510     """
4511     if not os.path.exists("/dev/kvm"):
4512         return False
4513     return "libvirtd" in __salt__["cmd.run"](__grains__["ps"])
4514 def _is_xen_hyper():
4515     """
4516     Returns a bool whether or not this node is a XEN hypervisor
4517     """
4518     try:
4519         if __grains__["virtual_subtype"] != "Xen Dom0":
4520             return False
4521     except KeyError:
4522         return False
4523     try:
4524         with salt.utils.files.fopen("/proc/modules") as fp_:
4525             if "xen_" not in salt.utils.stringutils.to_unicode(fp_.read()):
4526                 return False
4527     except OSError:
4528         return False
4529     return "libvirtd" in __salt__["cmd.run"](__grains__["ps"])
4530 def get_hypervisor():
4531     """
4532     Returns the name of the hypervisor running on this node or ``None``.
4533     Detected hypervisors:
4534     - kvm
4535     - xen
4536     - bhyve
4537     CLI Example:
4538     .. code-block:: bash
4539         salt '*' virt.get_hypervisor
4540     .. versionadded:: 2019.2.0
4541         the function and the ``kvm``, ``xen`` and ``bhyve`` hypervisors support
4542     """
4543     hypervisors = ["kvm", "xen", "bhyve"]
4544     result = [
4545         hyper
4546         for hyper in hypervisors
4547         if getattr(sys.modules[__name__], "_is_{}_hyper".format(hyper))()
4548     ]
4549     return result[0] if result else None
4550 def _is_bhyve_hyper():
4551     sysctl_cmd = "sysctl hw.vmm.create"
4552     vmm_enabled = False
4553     try:
4554         stdout = subprocess.Popen(
4555             ["sysctl", "hw.vmm.create"], stdout=subprocess.PIPE
4556         ).communicate()[0]
4557         vmm_enabled = len(salt.utils.stringutils.to_str(stdout).split('"')[1]) != 0
4558     except IndexError:
4559         pass
4560     return vmm_enabled
4561 def is_hyper():
4562     """
4563     Returns a bool whether or not this node is a hypervisor of any kind
4564     CLI Example:
4565     .. code-block:: bash
4566         salt '*' virt.is_hyper
4567     """
4568     if HAS_LIBVIRT:
4569         return _is_xen_hyper() or _is_kvm_hyper() or _is_bhyve_hyper()
4570     return False
4571 def vm_cputime(vm_=None, **kwargs):
4572     """
4573     Return cputime used by the vms on this hyper in a
4574     list of dicts:
4575     :param vm_: domain name
4576     :param connection: libvirt connection URI, overriding defaults
4577         .. versionadded:: 2019.2.0
4578     :param username: username to connect with, overriding defaults
4579         .. versionadded:: 2019.2.0
4580     :param password: password to connect with, overriding defaults
4581         .. versionadded:: 2019.2.0
4582     .. code-block:: python
4583         [
4584             'your-vm': {
4585                 'cputime' &lt;int&gt;
4586                 'cputime_percent' &lt;int&gt;
4587                 },
4588             ...
4589             ]
4590     If you pass a VM name in as an argument then it will return info
4591     for just the named VM, otherwise it will return all VMs.
4592     CLI Example:
4593     .. code-block:: bash
4594         salt '*' virt.vm_cputime
4595     """
4596     conn = __get_conn(**kwargs)
4597     host_cpus = conn.getInfo()[2]
4598     def _info(dom):
4599         """
4600         Compute cputime info of a domain
4601         """
4602         raw = dom.info()
4603         vcpus = int(raw[3])
4604         cputime = int(raw[4])
4605         cputime_percent = 0
4606         if cputime:
4607             cputime_percent = (1.0e-7 * cputime / host_cpus) / vcpus
4608         return {
4609             "cputime": int(raw[4]),
4610             "cputime_percent": int("{:.0f}".format(cputime_percent)),
4611         }
4612     info = {}
4613     if vm_:
4614         info[vm_] = _info(_get_domain(conn, vm_))
4615     else:
4616         for domain in _get_domain(conn, iterable=True):
4617             info[domain.name()] = _info(domain)
4618     conn.close()
4619     return info
4620 def vm_netstats(vm_=None, **kwargs):
4621     """
4622     Return combined network counters used by the vms on this hyper in a
4623     list of dicts:
4624     :param vm_: domain name
4625     :param connection: libvirt connection URI, overriding defaults
4626         .. versionadded:: 2019.2.0
4627     :param username: username to connect with, overriding defaults
4628         .. versionadded:: 2019.2.0
4629     :param password: password to connect with, overriding defaults
4630         .. versionadded:: 2019.2.0
4631     .. code-block:: python
4632         [
4633             'your-vm': {
4634                 'rx_bytes'   : 0,
4635                 'rx_packets' : 0,
4636                 'rx_errs'    : 0,
4637                 'rx_drop'    : 0,
4638                 'tx_bytes'   : 0,
4639                 'tx_packets' : 0,
4640                 'tx_errs'    : 0,
4641                 'tx_drop'    : 0
4642                 },
4643             ...
4644             ]
4645     If you pass a VM name in as an argument then it will return info
4646     for just the named VM, otherwise it will return all VMs.
4647     CLI Example:
4648     .. code-block:: bash
4649         salt '*' virt.vm_netstats
4650     """
4651     def _info(dom):
4652         """
4653         Compute network stats of a domain
4654         """
4655         nics = _get_nics(dom)
4656         ret = {
4657             "rx_bytes": 0,
4658             "rx_packets": 0,
4659             "rx_errs": 0,
4660             "rx_drop": 0,
4661             "tx_bytes": 0,
4662             "tx_packets": 0,
4663             "tx_errs": 0,
4664             "tx_drop": 0,
4665         }
4666         for attrs in nics.values():
4667             if "target" in attrs:
4668                 dev = attrs["target"]
4669                 stats = dom.interfaceStats(dev)
4670                 ret["rx_bytes"] += stats[0]
4671                 ret["rx_packets"] += stats[1]
4672                 ret["rx_errs"] += stats[2]
4673                 ret["rx_drop"] += stats[3]
4674                 ret["tx_bytes"] += stats[4]
4675                 ret["tx_packets"] += stats[5]
4676                 ret["tx_errs"] += stats[6]
4677                 ret["tx_drop"] += stats[7]
4678         return ret
4679     info = {}
4680     conn = __get_conn(**kwargs)
4681     if vm_:
4682         info[vm_] = _info(_get_domain(conn, vm_))
4683     else:
4684         for domain in _get_domain(conn, iterable=True):
4685             info[domain.name()] = _info(domain)
4686     conn.close()
4687     return info
4688 def vm_diskstats(vm_=None, **kwargs):
4689     """
4690     Return disk usage counters used by the vms on this hyper in a
4691     list of dicts:
4692     :param vm_: domain name
4693     :param connection: libvirt connection URI, overriding defaults
4694         .. versionadded:: 2019.2.0
4695     :param username: username to connect with, overriding defaults
4696         .. versionadded:: 2019.2.0
4697     :param password: password to connect with, overriding defaults
4698         .. versionadded:: 2019.2.0
4699     .. code-block:: python
4700         [
4701             'your-vm': {
4702                 'rd_req'   : 0,
4703                 'rd_bytes' : 0,
4704                 'wr_req'   : 0,
4705                 'wr_bytes' : 0,
4706                 'errs'     : 0
4707                 },
4708             ...
4709             ]
4710     If you pass a VM name in as an argument then it will return info
4711     for just the named VM, otherwise it will return all VMs.
4712     CLI Example:
4713     .. code-block:: bash
4714         salt '*' virt.vm_blockstats
4715     """
4716     def get_disk_devs(dom):
4717         """
4718         Extract the disk devices names from the domain XML definition
4719         """
4720         doc = ElementTree.fromstring(get_xml(dom, **kwargs))
4721         return [target.get("dev") for target in doc.findall("devices/disk/target")]
4722     def _info(dom):
4723         """
4724         Compute the disk stats of a domain
4725         """
4726         disks = get_disk_devs(dom)
4727         ret = {"rd_req": 0, "rd_bytes": 0, "wr_req": 0, "wr_bytes": 0, "errs": 0}
4728         for disk in disks:
4729             stats = dom.blockStats(disk)
4730             ret["rd_req"] += stats[0]
4731             ret["rd_bytes"] += stats[1]
4732             ret["wr_req"] += stats[2]
4733             ret["wr_bytes"] += stats[3]
4734             ret["errs"] += stats[4]
4735         return ret
4736     info = {}
4737     conn = __get_conn(**kwargs)
4738     if vm_:
4739         info[vm_] = _info(_get_domain(conn, vm_))
4740     else:
4741         for domain in _get_domain(conn, iterable=True, inactive=False):
4742             info[domain.name()] = _info(domain)
4743     conn.close()
4744     return info
4745 def _parse_snapshot_description(vm_snapshot, unix_time=False):
4746     """
4747     Parse XML doc and return a dict with the status values.
4748     :param xmldoc:
4749     :return:
4750     """
4751     ret = dict()
4752     tree = ElementTree.fromstring(vm_snapshot.getXMLDesc())
4753     for node in tree:
4754         if node.tag == "name":
4755             ret["name"] = node.text
4756         elif node.tag == "creationTime":
4757             ret["created"] = (
4758                 datetime.datetime.fromtimestamp(float(node.text)).isoformat(" ")
4759                 if not unix_time
4760                 else float(node.text)
4761             )
4762         elif node.tag == "state":
4763             ret["running"] = node.text == "running"
4764     ret["current"] = vm_snapshot.isCurrent() == 1
4765     return ret
4766 def list_snapshots(domain=None, **kwargs):
4767     """
4768     List available snapshots for certain vm or for all.
4769     :param domain: domain name
4770     :param connection: libvirt connection URI, overriding defaults
4771         .. versionadded:: 2019.2.0
4772     :param username: username to connect with, overriding defaults
4773         .. versionadded:: 2019.2.0
4774     :param password: password to connect with, overriding defaults
4775         .. versionadded:: 2019.2.0
4776     .. versionadded:: 2016.3.0
4777     CLI Example:
4778     .. code-block:: bash
4779         salt '*' virt.list_snapshots
4780         salt '*' virt.list_snapshots &lt;domain&gt;
4781     """
4782     ret = dict()
4783     conn = __get_conn(**kwargs)
4784     for vm_domain in _get_domain(conn, *(domain and [domain] or list()), iterable=True):
4785         ret[vm_domain.name()] = [
4786             _parse_snapshot_description(snap) for snap in vm_domain.listAllSnapshots()
4787         ] or "N/A"
4788     conn.close()
4789     return ret
4790 def snapshot(domain, name=None, suffix=None, **kwargs):
4791     """
4792     Create a snapshot of a VM.
4793     :param domain: domain name
4794     :param name: Name of the snapshot. If the name is omitted, then will be used original domain
4795                  name with ISO 8601 time as a suffix.
4796     :param suffix: Add suffix for the new name. Useful in states, where such snapshots
4797                    can be distinguished from manually created.
4798     :param connection: libvirt connection URI, overriding defaults
4799         .. versionadded:: 2019.2.0
4800     :param username: username to connect with, overriding defaults
4801         .. versionadded:: 2019.2.0
4802     :param password: password to connect with, overriding defaults
4803         .. versionadded:: 2019.2.0
4804     .. versionadded:: 2016.3.0
4805     CLI Example:
4806     .. code-block:: bash
4807         salt '*' virt.snapshot &lt;domain&gt;
4808     """
4809     if name and name.lower() == domain.lower():
4810         raise CommandExecutionError(
4811             "Virtual Machine {name} is already defined. "
4812             "Please choose another name for the snapshot".format(name=name)
4813         )
4814     if not name:
4815         name = "{domain}-{tsnap}".format(
4816             domain=domain, tsnap=time.strftime("%Y%m%d-%H%M%S", time.localtime())
4817         )
4818     if suffix:
4819         name = "{name}-{suffix}".format(name=name, suffix=suffix)
4820     doc = ElementTree.Element("domainsnapshot")
4821     n_name = ElementTree.SubElement(doc, "name")
4822     n_name.text = name
4823     conn = __get_conn(**kwargs)
4824     _get_domain(conn, domain).snapshotCreateXML(xmlutil.element_to_str(doc))
4825     conn.close()
4826     return {"name": name}
4827 def delete_snapshots(name, *names, **kwargs):
4828     """
4829     Delete one or more snapshots of the given VM.
4830     :param name: domain name
4831     :param names: names of the snapshots to remove
4832     :param connection: libvirt connection URI, overriding defaults
4833         .. versionadded:: 2019.2.0
4834     :param username: username to connect with, overriding defaults
4835         .. versionadded:: 2019.2.0
4836     :param password: password to connect with, overriding defaults
4837         .. versionadded:: 2019.2.0
4838     .. versionadded:: 2016.3.0
4839     CLI Example:
4840     .. code-block:: bash
4841         salt '*' virt.delete_snapshots &lt;domain&gt; all=True
4842         salt '*' virt.delete_snapshots &lt;domain&gt; &lt;snapshot&gt;
4843         salt '*' virt.delete_snapshots &lt;domain&gt; &lt;snapshot1&gt; &lt;snapshot2&gt; ...
4844     """
4845     deleted = dict()
4846     conn = __get_conn(**kwargs)
4847     domain = _get_domain(conn, name)
4848     for snap in domain.listAllSnapshots():
4849         if snap.getName() in names or not names:
4850             deleted[snap.getName()] = _parse_snapshot_description(snap)
4851             snap.delete()
4852     conn.close()
4853     available = {
4854         name: [_parse_snapshot_description(snap) for snap in domain.listAllSnapshots()]
4855         or "N/A"
4856     }
4857     return {"available": available, "deleted": deleted}
4858 def revert_snapshot(name, vm_snapshot=None, cleanup=False, **kwargs):
4859     """
4860     Revert snapshot to the previous from current (if available) or to the specific.
4861     :param name: domain name
4862     :param vm_snapshot: name of the snapshot to revert
4863     :param cleanup: Remove all newer than reverted snapshots. Values: True or False (default False).
4864     :param connection: libvirt connection URI, overriding defaults
4865         .. versionadded:: 2019.2.0
4866     :param username: username to connect with, overriding defaults
4867         .. versionadded:: 2019.2.0
4868     :param password: password to connect with, overriding defaults
4869         .. versionadded:: 2019.2.0
4870     .. versionadded:: 2016.3.0
4871     CLI Example:
4872     .. code-block:: bash
4873         salt '*' virt.revert &lt;domain&gt;
4874         salt '*' virt.revert &lt;domain&gt; &lt;snapshot&gt;
4875     """
4876     ret = dict()
4877     conn = __get_conn(**kwargs)
4878     domain = _get_domain(conn, name)
4879     snapshots = domain.listAllSnapshots()
4880     _snapshots = list()
4881     for snap_obj in snapshots:
4882         _snapshots.append(
4883             {
4884                 "idx": _parse_snapshot_description(snap_obj, unix_time=True)["created"],
4885                 "ptr": snap_obj,
4886             }
4887         )
4888     snapshots = [
4889         w_ptr["ptr"]
4890         for w_ptr in sorted(_snapshots, key=lambda item: item["idx"], reverse=True)
4891     ]
4892     del _snapshots
4893     if not snapshots:
4894         conn.close()
4895         raise CommandExecutionError("No snapshots found")
4896     elif len(snapshots) == 1:
4897         conn.close()
4898         raise CommandExecutionError(
4899             "Cannot revert to itself: only one snapshot is available."
4900         )
4901     snap = None
4902     for p_snap in snapshots:
4903         if not vm_snapshot:
4904             if p_snap.isCurrent() and snapshots[snapshots.index(p_snap) + 1 :]:
4905                 snap = snapshots[snapshots.index(p_snap) + 1 :][0]
4906                 break
4907         elif p_snap.getName() == vm_snapshot:
4908             snap = p_snap
4909             break
4910     if not snap:
4911         conn.close()
4912         raise CommandExecutionError(
4913             snapshot
4914             and 'Snapshot "{}" not found'.format(vm_snapshot)
4915             or "No more previous snapshots available"
4916         )
4917     elif snap.isCurrent():
4918         conn.close()
4919         raise CommandExecutionError("Cannot revert to the currently running snapshot.")
4920     domain.revertToSnapshot(snap)
4921     ret["reverted"] = snap.getName()
4922     if cleanup:
4923         delete = list()
4924         for p_snap in snapshots:
4925             if p_snap.getName() != snap.getName():
4926                 delete.append(p_snap.getName())
4927                 p_snap.delete()
4928             else:
4929                 break
4930         ret["deleted"] = delete
4931     else:
4932         ret["deleted"] = "N/A"
4933     conn.close()
4934     return ret
4935 def _caps_add_machine(machines, node):
4936     """
4937     Parse the &lt;machine&gt; element of the host capabilities and add it
4938     to the machines list.
4939     """
4940     maxcpus = node.get("maxCpus")
4941     canonical = node.get("canonical")
4942     name = node.text
4943     alternate_name = ""
4944     if canonical:
4945         alternate_name = name
4946         name = canonical
4947     machine = machines.get(name)
4948     if not machine:
4949         machine = {"alternate_names": []}
4950         if maxcpus:
4951             machine["maxcpus"] = int(maxcpus)
4952         machines[name] = machine
4953     if alternate_name:
4954         machine["alternate_names"].append(alternate_name)
4955 def _parse_caps_guest(guest):
4956     """
4957     Parse the &lt;guest&gt; element of the connection capabilities XML
4958     """
4959     arch_node = guest.find("arch")
4960     result = {
4961         "os_type": guest.find("os_type").text,
4962         "arch": {"name": arch_node.get("name"), "machines": {}, "domains": {}},
4963     }
4964     child = None
4965     for child in arch_node:
4966         if child.tag == "wordsize":
4967             result["arch"]["wordsize"] = int(child.text)
4968         elif child.tag == "emulator":
4969             result["arch"]["emulator"] = child.text
4970         elif child.tag == "machine":
4971             _caps_add_machine(result["arch"]["machines"], child)
4972         elif child.tag == "domain":
4973             domain_type = child.get("type")
4974             domain = {"emulator": None, "machines": {}}
4975             emulator_node = child.find("emulator")
4976             if emulator_node is not None:
4977                 domain["emulator"] = emulator_node.text
4978             for machine in child.findall("machine"):
4979                 _caps_add_machine(domain["machines"], machine)
4980             result["arch"]["domains"][domain_type] = domain
4981     features_nodes = guest.find("features")
4982     if features_nodes is not None and child is not None:
4983         result["features"] = {
4984             child.tag: {
4985                 "toggle": child.get("toggle", "no") == "yes",
4986                 "default": child.get("default", "on") == "on",
4987             }
4988             for child in features_nodes
4989         }
4990     return result
4991 def _parse_caps_cell(cell):
4992     """
4993     Parse the &lt;cell&gt; nodes of the connection capabilities XML output.
4994     """
4995     result = {"id": int(cell.get("id"))}
4996     mem_node = cell.find("memory")
4997     if mem_node is not None:
4998         unit = mem_node.get("unit", "KiB")
4999         memory = mem_node.text
5000         result["memory"] = "{} {}".format(memory, unit)
5001     pages = [
5002         {
5003             "size": "{} {}".format(page.get("size"), page.get("unit", "KiB")),
5004             "available": int(page.text),
5005         }
5006         for page in cell.findall("pages")
5007     ]
5008     if pages:
5009         result["pages"] = pages
5010     distances = {
5011         int(distance.get("id")): int(distance.get("value"))
5012         for distance in cell.findall("distances/sibling")
5013     }
5014     if distances:
5015         result["distances"] = distances
5016     cpus = []
5017     for cpu_node in cell.findall("cpus/cpu"):
5018         cpu = {"id": int(cpu_node.get("id"))}
5019         socket_id = cpu_node.get("socket_id")
5020         if socket_id:
5021             cpu["socket_id"] = int(socket_id)
5022         core_id = cpu_node.get("core_id")
5023         if core_id:
5024             cpu["core_id"] = int(core_id)
5025         siblings = cpu_node.get("siblings")
5026         if siblings:
5027             cpu["siblings"] = siblings
5028         cpus.append(cpu)
5029     if cpus:
5030         result["cpus"] = cpus
5031     return result
5032 def _parse_caps_bank(bank):
5033     """
5034     Parse the &lt;bank&gt; element of the connection capabilities XML.
5035     """
5036     result = {
5037         "id": int(bank.get("id")),
5038         "level": int(bank.get("level")),
5039         "type": bank.get("type"),
5040         "size": "{} {}".format(bank.get("size"), bank.get("unit")),
5041         "cpus": bank.get("cpus"),
5042     }
5043     controls = []
5044     for control in bank.findall("control"):
5045         unit = control.get("unit")
5046         result_control = {
5047             "granularity": "{} {}".format(control.get("granularity"), unit),
5048             "type": control.get("type"),
5049             "maxAllocs": int(control.get("maxAllocs")),
5050         }
5051         minimum = control.get("min")
5052         if minimum:
5053             result_control["min"] = "{} {}".format(minimum, unit)
5054         controls.append(result_control)
5055     if controls:
5056         result["controls"] = controls
5057     return result
5058 def _parse_caps_host(host):
5059     """
5060     Parse the &lt;host&gt; element of the connection capabilities XML.
5061     """
5062     result = {}
5063     for child in host:
5064         if child.tag == "uuid":
5065             result["uuid"] = child.text
5066         elif child.tag == "cpu":
5067             cpu = {
5068                 "arch": child.find("arch").text
5069                 if child.find("arch") is not None
5070                 else None,
5071                 "model": child.find("model").text
5072                 if child.find("model") is not None
5073                 else None,
5074                 "vendor": child.find("vendor").text
5075                 if child.find("vendor") is not None
5076                 else None,
5077                 "features": [
5078                     feature.get("name") for feature in child.findall("feature")
5079                 ],
5080                 "pages": [
5081                     {"size": "{} {}".format(page.get("size"), page.get("unit", "KiB"))}
5082                     for page in child.findall("pages")
5083                 ],
5084             }
5085             microcode = child.find("microcode")
5086             if microcode is not None:
5087                 cpu["microcode"] = microcode.get("version")
5088             topology = child.find("topology")
5089             if topology is not None:
5090                 cpu["sockets"] = int(topology.get("sockets"))
5091                 cpu["cores"] = int(topology.get("cores"))
5092                 cpu["threads"] = int(topology.get("threads"))
5093             result["cpu"] = cpu
5094         elif child.tag == "power_management":
5095             result["power_management"] = [node.tag for node in child]
5096         elif child.tag == "migration_features":
5097             result["migration"] = {
5098                 "live": child.find("live") is not None,
5099                 "transports": [
5100                     node.text for node in child.findall("uri_transports/uri_transport")
5101                 ],
5102             }
5103         elif child.tag == "topology":
5104             result["topology"] = {
5105                 "cells": [
5106                     _parse_caps_cell(cell) for cell in child.findall("cells/cell")
5107                 ]
5108             }
5109         elif child.tag == "cache":
5110             result["cache"] = {
5111                 "banks": [_parse_caps_bank(bank) for bank in child.findall("bank")]
5112             }
5113     result["security"] = [
5114         {
5115             "model": secmodel.find("model").text
5116             if secmodel.find("model") is not None
5117             else None,
5118             "doi": secmodel.find("doi").text
5119             if secmodel.find("doi") is not None
5120             else None,
5121             "baselabels": [
5122                 {"type": label.get("type"), "label": label.text}
5123                 for label in secmodel.findall("baselabel")
5124             ],
5125         }
5126         for secmodel in host.findall("secmodel")
5127     ]
5128     return result
5129 def _capabilities(conn):
5130     """
5131     Return the hypervisor connection capabilities.
5132     :param conn: opened libvirt connection to use
5133     """
5134     caps = ElementTree.fromstring(conn.getCapabilities())
5135     return {
5136         "host": _parse_caps_host(caps.find("host")),
5137         "guests": [_parse_caps_guest(guest) for guest in caps.findall("guest")],
5138     }
5139 def capabilities(**kwargs):
5140     """
5141     Return the hypervisor connection capabilities.
5142     :param connection: libvirt connection URI, overriding defaults
5143     :param username: username to connect with, overriding defaults
5144     :param password: password to connect with, overriding defaults
5145     .. versionadded:: 2019.2.0
5146     CLI Example:
5147     .. code-block:: bash
5148         salt '*' virt.capabilities
5149     """
5150     conn = __get_conn(**kwargs)
5151     try:
5152         caps = _capabilities(conn)
5153     except libvirt.libvirtError as err:
5154         raise CommandExecutionError(str(err))
5155     finally:
5156         conn.close()
5157     return caps
5158 def _parse_caps_enum(node):
5159     """
5160     Return a tuple containing the name of the enum and the possible values
5161     """
5162     return (node.get("name"), [value.text for value in node.findall("value")])
5163 def _parse_caps_cpu(node):
5164     """
5165     Parse the &lt;cpu&gt; element of the domain capabilities
5166     """
5167     result = {}
5168     for mode in node.findall("mode"):
5169         if not mode.get("supported") == "yes":
5170             continue
5171         name = mode.get("name")
5172         if name == "host-passthrough":
5173             result[name] = True
5174         elif name == "host-model":
5175             host_model = {}
5176             model_node = mode.find("model")
5177             if model_node is not None:
5178                 model = {"name": model_node.text}
5179                 vendor_id = model_node.get("vendor_id")
5180                 if vendor_id:
5181                     model["vendor_id"] = vendor_id
5182                 fallback = model_node.get("fallback")
5183                 if fallback:
5184                     model["fallback"] = fallback
5185                 host_model["model"] = model
5186             vendor = (
5187                 mode.find("vendor").text if mode.find("vendor") is not None else None
5188             )
5189             if vendor:
5190                 host_model["vendor"] = vendor
5191             features = {
5192                 feature.get("name"): feature.get("policy")
5193                 for feature in mode.findall("feature")
5194             }
5195             if features:
5196                 host_model["features"] = features
5197             result[name] = host_model
5198         elif name == "custom":
5199             custom_model = {}
5200             models = {
5201                 model.text: model.get("usable") for model in mode.findall("model")
5202             }
5203             if models:
5204                 custom_model["models"] = models
5205             result[name] = custom_model
5206     return result
5207 def _parse_caps_devices_features(node):
5208     """
5209     Parse the devices or features list of the domain capatilities
5210     """
5211     result = {}
5212     for child in node:
5213         if child.get("supported") == "yes":
5214             enums = [_parse_caps_enum(node) for node in child.findall("enum")]
5215             result[child.tag] = {item[0]: item[1] for item in enums if item[0]}
5216     return result
5217 def _parse_caps_loader(node):
5218     """
5219     Parse the &lt;loader&gt; element of the domain capabilities.
5220     """
5221     enums = [_parse_caps_enum(enum) for enum in node.findall("enum")]
5222     result = {item[0]: item[1] for item in enums if item[0]}
5223     values = [child.text for child in node.findall("value")]
5224     if values:
5225         result["values"] = values
5226     return result
5227 def _parse_domain_caps(caps):
5228     """
5229     Parse the XML document of domain capabilities into a structure.
5230     """
5231     result = {
5232         "emulator": caps.find("path").text if caps.find("path") is not None else None,
5233         "domain": caps.find("domain").text if caps.find("domain") is not None else None,
5234         "machine": caps.find("machine").text
5235         if caps.find("machine") is not None
5236         else None,
5237         "arch": caps.find("arch").text if caps.find("arch") is not None else None,
5238     }
5239     for child in caps:
5240         if child.tag == "vcpu" and child.get("max"):
5241             result["max_vcpus"] = int(child.get("max"))
5242         elif child.tag == "iothreads":
5243             result["iothreads"] = child.get("supported") == "yes"
5244         elif child.tag == "os":
5245             result["os"] = {}
5246             loader_node = child.find("loader")
5247             if loader_node is not None and loader_node.get("supported") == "yes":
5248                 loader = _parse_caps_loader(loader_node)
5249                 result["os"]["loader"] = loader
5250         elif child.tag == "cpu":
5251             cpu = _parse_caps_cpu(child)
5252             if cpu:
5253                 result["cpu"] = cpu
5254         elif child.tag == "devices":
5255             devices = _parse_caps_devices_features(child)
5256             if devices:
5257                 result["devices"] = devices
5258         elif child.tag == "features":
5259             features = _parse_caps_devices_features(child)
5260             if features:
5261                 result["features"] = features
5262     return result
5263 def domain_capabilities(emulator=None, arch=None, machine=None, domain=None, **kwargs):
5264     """
5265     Return the domain capabilities given an emulator, architecture, machine or virtualization type.
5266     .. versionadded:: 2019.2.0
5267     :param emulator: return the capabilities for the given emulator binary
5268     :param arch: return the capabilities for the given CPU architecture
5269     :param machine: return the capabilities for the given emulated machine type
5270     :param domain: return the capabilities for the given virtualization type.
5271     :param connection: libvirt connection URI, overriding defaults
5272     :param username: username to connect with, overriding defaults
5273     :param password: password to connect with, overriding defaults
5274     The list of the possible emulator, arch, machine and domain can be found in
5275     the host capabilities output.
5276     If none of the parameters is provided, the libvirt default one is returned.
5277     CLI Example:
5278     .. code-block:: bash
5279         salt '*' virt.domain_capabilities arch='x86_64' domain='kvm'
5280     """
5281     conn = __get_conn(**kwargs)
5282     result = []
5283     try:
5284         caps = ElementTree.fromstring(
5285             conn.getDomainCapabilities(emulator, arch, machine, domain, 0)
5286         )
5287         result = _parse_domain_caps(caps)
5288     finally:
5289         conn.close()
5290     return result
5291 def all_capabilities(**kwargs):
5292     """
5293     Return the host and domain capabilities in a single call.
5294     .. versionadded:: 3001
5295     :param connection: libvirt connection URI, overriding defaults
5296     :param username: username to connect with, overriding defaults
5297     :param password: password to connect with, overriding defaults
5298     CLI Example:
5299     .. code-block:: bash
5300         salt '*' virt.all_capabilities
5301     """
5302     conn = __get_conn(**kwargs)
5303     try:
5304         host_caps = ElementTree.fromstring(conn.getCapabilities())
5305             [
5306                 (
5307                     guest<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.get("arch", {}).get("name", None),
5308                     key,
5309                     guest.get("arch", {}).get("emulator", None),
5310                 )
5311                 for key in guest.get("arch", {}).get("domains", {}).keys(</b></font>)
5312             ]
5313             for guest in [
5314                 _parse_caps_guest(guest) for guest in host_caps.findall("guest")
5315             ]
5316         ]
5317         flattened = [pair for item in (x for x in domains) for pair in item]
5318         result = {
5319             "host": {
5320                 "host": _parse_caps_host(host_caps.find("host")),
5321                 "guests": [
5322                     _parse_caps_guest(guest) for guest in host_caps.findall("guest")
5323                 ],
5324             },
5325             "domains": [
5326                 _parse_domain_caps(
5327                     ElementTree.fromstring(
5328                         conn.getDomainCapabilities(emulator, arch, None, domain)
5329                     )
5330                 )
5331                 for (arch, domain, emulator) in flattened
5332             ],
5333         }
5334         return result
5335     finally:
5336         conn.close()
5337 def cpu_baseline(full=False, migratable=False, out="libvirt", **kwargs):
5338     """
5339     Return the optimal 'custom' CPU baseline config for VM's on this minion
5340     .. versionadded:: 2016.3.0
5341     :param full: Return all CPU features rather than the ones on top of the closest CPU model
5342     :param migratable: Exclude CPU features that are unmigratable (libvirt 2.13+)
5343     :param out: 'libvirt' (default) for usable libvirt XML definition, 'salt' for nice dict
5344     :param connection: libvirt connection URI, overriding defaults
5345         .. versionadded:: 2019.2.0
5346     :param username: username to connect with, overriding defaults
5347         .. versionadded:: 2019.2.0
5348     :param password: password to connect with, overriding defaults
5349         .. versionadded:: 2019.2.0
5350     CLI Example:
5351     .. code-block:: bash
5352         salt '*' virt.cpu_baseline
5353     """
5354     conn = __get_conn(**kwargs)
5355     caps = ElementTree.fromstring(conn.getCapabilities())
5356     cpu = caps.find("host/cpu")
5357     host_cpu_def = xmlutil.element_to_str(cpu)
5358     log.debug("Host CPU model definition: %s", host_cpu_def)
5359     flags = 0
5360     if migratable:
5361         if getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_MIGRATABLE", False):
5362             flags += libvirt.VIR_CONNECT_BASELINE_CPU_MIGRATABLE
5363         else:
5364             conn.close()
5365             raise ValueError
5366     if full and getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES", False):
5367         flags += libvirt.VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES
5368     cpu = ElementTree.fromstring(conn.baselineCPU([host_cpu_def], flags))
5369     conn.close()
5370     if full and not getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES", False):
5371         with salt.utils.files.fopen("/usr/share/libvirt/cpu_map.xml", "r") as cpu_map:
5372             cpu_map = ElementTree.parse(cpu_map)
5373         cpu_model = cpu.find("model").text
5374         while cpu_model:
5375             cpu_map_models = cpu_map.findall("arch/model")
5376             cpu_specs = [
5377                 el
5378                 for el in cpu_map_models
5379                 if el.get("name") == cpu_model and bool(len(el))
5380             ]
5381             if not cpu_specs:
5382                 raise ValueError("Model {} not found in CPU map".format(cpu_model))
5383             elif len(cpu_specs) &gt; 1:
5384                 raise ValueError(
5385                     "Multiple models {} found in CPU map".format(cpu_model)
5386                 )
5387             cpu_specs = cpu_specs[0]
5388             model_node = cpu_specs.find("model")
5389             if model_node is None:
5390                 cpu_model = None
5391             else:
5392                 cpu_model = model_node.get("name")
5393             cpu.extend([feature for feature in cpu_specs.findall("feature")])
5394     if out == "salt":
5395         return {
5396             "model": cpu.find("model").text,
5397             "vendor": cpu.find("vendor").text,
5398             "features": [feature.get("name") for feature in cpu.findall("feature")],
5399         }
5400     return ElementTree.tostring(cpu)
5401 def network_define(
5402     name,
5403     bridge,
5404     forward,
5405     ipv4_config=None,
5406     ipv6_config=None,
5407     vport=None,
5408     tag=None,
5409     autostart=True,
5410     start=True,
5411     mtu=None,
5412     domain=None,
5413     nat=None,
5414     interfaces=None,
5415     addresses=None,
5416     physical_function=None,
5417     dns=None,
5418     **kwargs
5419 ):
5420     """
5421     Create libvirt network.
5422     :param name: Network name.
5423     :param bridge: Bridge name.
5424     :param forward: Forward mode (bridge, router, nat).
5425         .. versionchanged:: 3003
5426            a ``None`` value creates an isolated network with no forwarding at all
5427     :param vport: Virtualport type.
5428         The value can also be a dictionary with ``type`` and ``parameters`` keys.
5429         The ``parameters`` value is a dictionary of virtual port parameters.
5430         .. code-block:: yaml
5431           - vport:
5432               type: openvswitch
5433               parameters:
5434                 interfaceid: 09b11c53-8b5c-4eeb-8f00-d84eaa0aaa4f
5435         .. versionchanged:: 3003
5436            possible dictionary value
5437     :param tag: Vlan tag.
5438         The value can also be a dictionary with the ``tags`` and optional ``trunk`` keys.
5439         ``trunk`` is a boolean value indicating whether to use VLAN trunking.
5440         ``tags`` is a list of dictionaries with keys ``id`` and ``nativeMode``.
5441         The ``nativeMode`` value can be one of ``tagged`` or ``untagged``.
5442         .. code-block:: yaml
5443           - tag:
5444               trunk: True
5445               tags:
5446                 - id: 42
5447                   nativeMode: untagged
5448                 - id: 47
5449         .. versionchanged:: 3003
5450            possible dictionary value
5451     :param autostart: Network autostart (default True).
5452     :param start: Network start (default True).
5453     :param ipv4_config: IP v4 configuration.
5454         Dictionary describing the IP v4 setup like IP range and
5455         a possible DHCP configuration. The structure is documented
5456         in net-define-ip_.
5457         .. versionadded:: 3000
5458     :type ipv4_config: dict or None
5459     :param ipv6_config: IP v6 configuration.
5460         Dictionary describing the IP v6 setup like IP range and
5461         a possible DHCP configuration. The structure is documented
5462         in net-define-ip_.
5463         .. versionadded:: 3000
5464     :type ipv6_config: dict or None
5465     :param connection: libvirt connection URI, overriding defaults.
5466     :param username: username to connect with, overriding defaults.
5467     :param password: password to connect with, overriding defaults.
5468     :param mtu: size of the Maximum Transmission Unit (MTU) of the network.
5469         (default ``None``)
5470         .. versionadded:: 3003
5471     :param domain: DNS domain name of the DHCP server.
5472         The value is a dictionary with a mandatory ``name`` property and an optional ``localOnly`` boolean one.
5473         (default ``None``)
5474         .. code-block:: yaml
5475           - domain:
5476               name: lab.acme.org
5477               localOnly: True
5478         .. versionadded:: 3003
5479     :param nat: addresses and ports to route in NAT forward mode.
5480         The value is a dictionary with optional keys ``address`` and ``port``.
5481         Both values are a dictionary with ``start`` and ``end`` values.
5482         (default ``None``)
5483         .. code-block:: yaml
5484           - forward: nat
5485           - nat:
5486               address:
5487                 start: 1.2.3.4
5488                 end: 1.2.3.10
5489               port:
5490                 start: 500
5491                 end: 1000
5492         .. versionadded:: 3003
5493     :param interfaces: whitespace separated list of network interfaces devices that can be used for this network.
5494         (default ``None``)
5495         .. code-block:: yaml
5496           - forward: passthrough
5497           - interfaces: "eth10 eth11 eth12"
5498         .. versionadded:: 3003
5499     :param addresses: whitespace separated list of addresses of PCI devices that can be used for this network in `hostdev` forward mode.
5500         (default ``None``)
5501         .. code-block:: yaml
5502           - forward: hostdev
5503           - interfaces: "0000:04:00.1 0000:e3:01.2"
5504         .. versionadded:: 3003
5505     :param physical_function: device name of the physical interface to use in ``hostdev`` forward mode.
5506         (default ``None``)
5507         .. code-block:: yaml
5508           - forward: hostdev
5509           - physical_function: "eth0"
5510         .. versionadded:: 3003
5511     :param dns: virtual network DNS configuration.
5512         The value is a dictionary described in net-define-dns_.
5513         (default ``None``)
5514         .. code-block:: yaml
5515           - dns:
5516               forwarders:
5517                 - domain: example.com
5518                   addr: 192.168.1.1
5519                 - addr: 8.8.8.8
5520                 - domain: www.example.com
5521               txt:
5522                 example.com: "v=spf1 a -all"
5523                 _http.tcp.example.com: "name=value,paper=A4"
5524               hosts:
5525                 192.168.1.2:
5526                   - mirror.acme.lab
5527                   - test.acme.lab
5528               srvs:
5529                 - name: ldap
5530                   protocol: tcp
5531                   domain: ldapserver.example.com
5532                   target: .
5533                   port: 389
5534                   priority: 1
5535                   weight: 10
5536         .. versionadded:: 3003
5537     .. _net-define-ip:
5538     .. rubric:: IP configuration definition
5539     Both the IPv4 and IPv6 configuration dictionaries can contain the following properties:
5540     cidr
5541         CIDR notation for the network. For example '192.168.124.0/24'
5542     dhcp_ranges
5543         A list of dictionaries with ``'start'`` and ``'end'`` properties.
5544     hosts
5545         A list of dictionaries with ``ip`` property and optional ``name``, ``mac`` and ``id`` properties.
5546         .. versionadded:: 3003
5547     bootp
5548         A dictionary with a ``file`` property and an optional ``server`` one.
5549         .. versionadded:: 3003
5550     tftp
5551         The path to the TFTP root directory to serve.
5552         .. versionadded:: 3003
5553     .. _net-define-dns:
5554     .. rubric:: DNS configuration definition
5555     The DNS configuration dictionary contains the following optional properties:
5556     forwarders
5557         List of alternate DNS forwarders to use.
5558         Each item is a dictionary with the optional ``domain`` and ``addr`` keys.
5559         If both are provided, the requests to the domain are forwarded to the server at the ``addr``.
5560         If only ``domain`` is provided the requests matching this domain will be resolved locally.
5561         If only ``addr`` is provided all requests will be forwarded to this DNS server.
5562     txt:
5563         Dictionary of TXT fields to set.
5564     hosts:
5565         Dictionary of host DNS entries.
5566         The key is the IP of the host, and the value is a list of hostnames for it.
5567     srvs:
5568         List of SRV DNS entries.
5569         Each entry is a dictionary with the mandatory ``name`` and ``protocol`` keys.
5570         Entries can also have ``target``, ``port``, ``priority``, ``domain`` and ``weight`` optional properties.
5571     CLI Example:
5572     .. code-block:: bash
5573         salt '*' virt.network_define network main bridge openvswitch
5574     .. versionadded:: 2019.2.0
5575     """
5576     conn = __get_conn(**kwargs)
5577     vport = kwargs.get("vport", None)
5578     tag = kwargs.get("tag", None)
5579     net_xml = _gen_net_xml(
5580         name,
5581         bridge,
5582         forward,
5583         vport,
5584         tag=tag,
5585         ip_configs=[config for config in [ipv4_config, ipv6_config] if config],
5586         mtu=mtu,
5587         domain=domain,
5588         nat=nat,
5589         interfaces=interfaces,
5590         addresses=addresses,
5591         physical_function=physical_function,
5592         dns=dns,
5593     )
5594     try:
5595         conn.networkDefineXML(net_xml)
5596     except libvirt.libvirtError as err:
5597         log.warning(err)
5598         conn.close()
5599         raise err  # a real error we should report upwards
5600     try:
5601         network = conn.networkLookupByName(name)
5602     except libvirt.libvirtError as err:
5603         log.warning(err)
5604         conn.close()
5605         raise err  # a real error we should report upwards
5606     if network is None:
5607         conn.close()
5608         return False
5609     if (start or autostart) and network.isActive() != 1:
5610         network.create()
5611     if autostart and network.autostart() != 1:
5612         network.setAutostart(int(autostart))
5613     elif not autostart and network.autostart() == 1:
5614         network.setAutostart(int(autostart))
5615     conn.close()
5616     return True
5617 def _remove_empty_xml_node(node):
5618     """
5619     Remove the nodes with no children, no text and no attribute
5620     """
5621     for child in node:
5622         if not child.tail and not child.text and not child.items() and not child:
5623             node.remove(child)
5624         else:
5625             _remove_empty_xml_node(child)
5626     return node
5627 def network_update(
5628     name,
5629     bridge,
5630     forward,
5631     ipv4_config=None,
5632     ipv6_config=None,
5633     vport=None,
5634     tag=None,
5635     mtu=None,
5636     domain=None,
5637     nat=None,
5638     interfaces=None,
5639     addresses=None,
5640     physical_function=None,
5641     dns=None,
5642     test=False,
5643     **kwargs
5644 ):
5645     """
5646     Update a virtual network if needed.
5647     :param name: Network name.
5648     :param bridge: Bridge name.
5649     :param forward: Forward mode (bridge, router, nat).
5650         A ``None`` value creates an isolated network with no forwarding at all.
5651     :param vport: Virtualport type.
5652         The value can also be a dictionary with ``type`` and ``parameters`` keys.
5653         The ``parameters`` value is a dictionary of virtual port parameters.
5654         .. code-block:: yaml
5655           - vport:
5656               type: openvswitch
5657               parameters:
5658                 interfaceid: 09b11c53-8b5c-4eeb-8f00-d84eaa0aaa4f
5659     :param tag: Vlan tag.
5660         The value can also be a dictionary with the ``tags`` and optional ``trunk`` keys.
5661         ``trunk`` is a boolean value indicating whether to use VLAN trunking.
5662         ``tags`` is a list of dictionaries with keys ``id`` and ``nativeMode``.
5663         The ``nativeMode`` value can be one of ``tagged`` or ``untagged``.
5664         .. code-block:: yaml
5665           - tag:
5666               trunk: True
5667               tags:
5668                 - id: 42
5669                   nativeMode: untagged
5670                 - id: 47
5671     :param ipv4_config: IP v4 configuration.
5672         Dictionary describing the IP v4 setup like IP range and
5673         a possible DHCP configuration. The structure is documented
5674         in net-define-ip_.
5675     :type ipv4_config: dict or None
5676     :param ipv6_config: IP v6 configuration.
5677         Dictionary describing the IP v6 setup like IP range and
5678         a possible DHCP configuration. The structure is documented
5679         in net-define-ip_.
5680     :type ipv6_config: dict or None
5681     :param connection: libvirt connection URI, overriding defaults.
5682     :param username: username to connect with, overriding defaults.
5683     :param password: password to connect with, overriding defaults.
5684     :param mtu: size of the Maximum Transmission Unit (MTU) of the network.
5685         (default ``None``)
5686     :param domain: DNS domain name of the DHCP server.
5687         The value is a dictionary with a mandatory ``name`` property and an optional ``localOnly`` boolean one.
5688         (default ``None``)
5689         .. code-block:: yaml
5690           - domain:
5691               name: lab.acme.org
5692               localOnly: True
5693     :param nat: addresses and ports to route in NAT forward mode.
5694         The value is a dictionary with optional keys ``address`` and ``port``.
5695         Both values are a dictionary with ``start`` and ``end`` values.
5696         (default ``None``)
5697         .. code-block:: yaml
5698           - forward: nat
5699           - nat:
5700               address:
5701                 start: 1.2.3.4
5702                 end: 1.2.3.10
5703               port:
5704                 start: 500
5705                 end: 1000
5706     :param interfaces: whitespace separated list of network interfaces devices that can be used for this network.
5707         (default ``None``)
5708         .. code-block:: yaml
5709           - forward: passthrough
5710           - interfaces: "eth10 eth11 eth12"
5711     :param addresses: whitespace separated list of addresses of PCI devices that can be used for this network in `hostdev` forward mode.
5712         (default ``None``)
5713         .. code-block:: yaml
5714           - forward: hostdev
5715           - interfaces: "0000:04:00.1 0000:e3:01.2"
5716     :param physical_function: device name of the physical interface to use in ``hostdev`` forward mode.
5717         (default ``None``)
5718         .. code-block:: yaml
5719           - forward: hostdev
5720           - physical_function: "eth0"
5721     :param dns: virtual network DNS configuration.
5722         The value is a dictionary described in net-define-dns_.
5723         (default ``None``)
5724         .. code-block:: yaml
5725           - dns:
5726               forwarders:
5727                 - domain: example.com
5728                   addr: 192.168.1.1
5729                 - addr: 8.8.8.8
5730                 - domain: www.example.com
5731               txt:
5732                 example.com: "v=spf1 a -all"
5733                 _http.tcp.example.com: "name=value,paper=A4"
5734               hosts:
5735                 192.168.1.2:
5736                   - mirror.acme.lab
5737                   - test.acme.lab
5738               srvs:
5739                 - name: ldap
5740                   protocol: tcp
5741                   domain: ldapserver.example.com
5742                   target: .
5743                   port: 389
5744                   priority: 1
5745                   weight: 10
5746     .. versionadded:: 3003
5747     """
5748     conn = __get_conn(**kwargs)
5749     needs_update = False
5750     try:
5751         net = conn.networkLookupByName(name)
5752         old_xml = ElementTree.fromstring(net.XMLDesc())
5753         new_xml = ElementTree.fromstring(
5754             _gen_net_xml(
5755                 name,
5756                 bridge,
5757                 forward,
5758                 vport,
5759                 tag=tag,
5760                 ip_configs=[config for config in [ipv4_config, ipv6_config] if config],
5761                 mtu=mtu,
5762                 domain=domain,
5763                 nat=nat,
5764                 interfaces=interfaces,
5765                 addresses=addresses,
5766                 physical_function=physical_function,
5767                 dns=dns,
5768             )
5769         )
5770         elements_to_copy = ["uuid", "mac"]
5771         for to_copy in elements_to_copy:
5772             element = old_xml.find(to_copy)
5773             if element is not None:
5774                 new_xml.insert(1, element)
5775         old_xml.attrib.pop("connections", None)
5776         if old_xml.find("forward/pf") is not None:
5777             forward_node = old_xml.find("forward")
5778             address_nodes = forward_node.findall("address")
5779             for node in address_nodes:
5780                 forward_node.remove(node)
5781         default_bridge_attribs = {"stp": "on", "delay": "0"}
5782         old_bridge_node = old_xml.find("bridge")
5783         if old_bridge_node is not None:
5784             for key, value in default_bridge_attribs.items():
5785                 if old_bridge_node.get(key, None) == value:
5786                     old_bridge_node.attrib.pop(key, None)
5787             old_forward = (
5788                 old_xml.find("forward").get("mode")
5789                 if old_xml.find("forward") is not None
5790                 else None
5791             )
5792             if (
5793                 old_forward == forward
5794                 and forward in ["nat", "route", "open", None]
5795                 and bridge is None
5796                 and old_bridge_node.get("name", "").startswith("virbr")
5797             ):
5798                 old_bridge_node.attrib.pop("name", None)
5799         ipv4_nodes = [
5800             node
5801             for node in old_xml.findall("ip")
5802             if node.get("family", "ipv4") == "ipv4"
5803         ]
5804         for ip_node in ipv4_nodes:
5805             netmask = ip_node.attrib.pop("netmask", None)
5806             if netmask:
5807                 address = ipaddress.ip_network(
5808                     "{}/{}".format(ip_node.get("address"), netmask), strict=False
5809                 )
5810                 ip_node.set("prefix", str(address.prefixlen))
5811         for doc in [old_xml, new_xml]:
5812             for node in doc.findall("ip"):
5813                 if "family" not in node.keys():
5814                     node.set("family", "ipv4")
5815         _remove_empty_xml_node(xmlutil.strip_spaces(old_xml))
5816         xmlutil.strip_spaces(new_xml)
5817         needs_update = xmlutil.to_dict(old_xml, True) != xmlutil.to_dict(new_xml, True)
5818         if needs_update and not test:
5819             conn.networkDefineXML(xmlutil.element_to_str(new_xml))
5820     finally:
5821         conn.close()
5822     return needs_update
5823 def list_networks(**kwargs):
5824     """
5825     List all virtual networks.
5826     :param connection: libvirt connection URI, overriding defaults
5827     :param username: username to connect with, overriding defaults
5828     :param password: password to connect with, overriding defaults
5829     .. versionadded:: 2019.2.0
5830     CLI Example:
5831     .. code-block:: bash
5832        salt '*' virt.list_networks
5833     """
5834     conn = __get_conn(**kwargs)
5835     try:
5836         return [net.name() for net in conn.listAllNetworks()]
5837     finally:
5838         conn.close()
5839 def network_info(name=None, **kwargs):
5840     """
5841     Return information on a virtual network provided its name.
5842     :param name: virtual network name
5843     :param connection: libvirt connection URI, overriding defaults
5844     :param username: username to connect with, overriding defaults
5845     :param password: password to connect with, overriding defaults
5846     If no name is provided, return the infos for all defined virtual networks.
5847     .. versionadded:: 2019.2.0
5848     CLI Example:
5849     .. code-block:: bash
5850         salt '*' virt.network_info default
5851     """
5852     result = {}
5853     conn = __get_conn(**kwargs)
5854     def _net_get_leases(net):
5855         """
5856         Get all DHCP leases for a network
5857         """
5858         leases = net.DHCPLeases()
5859         for lease in leases:
5860             if lease["type"] == libvirt.VIR_IP_ADDR_TYPE_IPV4:
5861                 lease["type"] = "ipv4"
5862             elif lease["type"] == libvirt.VIR_IP_ADDR_TYPE_IPV6:
5863                 lease["type"] = "ipv6"
5864             else:
5865                 lease["type"] = "unknown"
5866         return leases
5867     def _net_get_bridge(net):
5868         """
5869         Get the bridge of the network or None
5870         """
5871         try:
5872             return net.bridgeName()
5873         except libvirt.libvirtError as err:
5874             return None
5875     try:
5876         nets = [
5877             net for net in conn.listAllNetworks() if name is None or net.name() == name
5878         ]
5879         result = {
5880             net.name(): {
5881                 "uuid": net.UUIDString(),
5882                 "bridge": _net_get_bridge(net),
5883                 "autostart": net.autostart(),
5884                 "active": net.isActive(),
5885                 "persistent": net.isPersistent(),
5886                 "leases": _net_get_leases(net),
5887             }
5888             for net in nets
5889         }
5890     except libvirt.libvirtError as err:
5891         log.debug("Silenced libvirt error: %s", err)
5892     finally:
5893         conn.close()
5894     return result
5895 def network_get_xml(name, **kwargs):
5896     """
5897     Return the XML definition of a virtual network
5898     :param name: libvirt network name
5899     :param connection: libvirt connection URI, overriding defaults
5900     :param username: username to connect with, overriding defaults
5901     :param password: password to connect with, overriding defaults
5902     .. versionadded:: 3000
5903     CLI Example:
5904     .. code-block:: bash
5905         salt '*' virt.network_get_xml default
5906     """
5907     conn = __get_conn(**kwargs)
5908     try:
5909         return conn.networkLookupByName(name).XMLDesc()
5910     finally:
5911         conn.close()
5912 def network_start(name, **kwargs):
5913     """
5914     Start a defined virtual network.
5915     :param name: virtual network name
5916     :param connection: libvirt connection URI, overriding defaults
5917     :param username: username to connect with, overriding defaults
5918     :param password: password to connect with, overriding defaults
5919     .. versionadded:: 2019.2.0
5920     CLI Example:
5921     .. code-block:: bash
5922         salt '*' virt.network_start default
5923     """
5924     conn = __get_conn(**kwargs)
5925     try:
5926         net = conn.networkLookupByName(name)
5927         return not bool(net.create())
5928     finally:
5929         conn.close()
5930 def network_stop(name, **kwargs):
5931     """
5932     Stop a defined virtual network.
5933     :param name: virtual network name
5934     :param connection: libvirt connection URI, overriding defaults
5935     :param username: username to connect with, overriding defaults
5936     :param password: password to connect with, overriding defaults
5937     .. versionadded:: 2019.2.0
5938     CLI Example:
5939     .. code-block:: bash
5940         salt '*' virt.network_stop default
5941     """
5942     conn = __get_conn(**kwargs)
5943     try:
5944         net = conn.networkLookupByName(name)
5945         return not bool(net.destroy())
5946     finally:
5947         conn.close()
5948 def network_undefine(name, **kwargs):
5949     """
5950     Remove a defined virtual network. This does not stop the virtual network.
5951     :param name: virtual network name
5952     :param connection: libvirt connection URI, overriding defaults
5953     :param username: username to connect with, overriding defaults
5954     :param password: password to connect with, overriding defaults
5955     .. versionadded:: 2019.2.0
5956     CLI Example:
5957     .. code-block:: bash
5958         salt '*' virt.network_undefine default
5959     """
5960     conn = __get_conn(**kwargs)
5961     try:
5962         net = conn.networkLookupByName(name)
5963         return not bool(net.undefine())
5964     finally:
5965         conn.close()
5966 def network_set_autostart(name, state="on", **kwargs):
5967     """
5968     Set the autostart flag on a virtual network so that the network
5969     will start with the host system on reboot.
5970     :param name: virtual network name
5971     :param state: 'on' to auto start the network, anything else to mark the
5972                   virtual network not to be started when the host boots
5973     :param connection: libvirt connection URI, overriding defaults
5974     :param username: username to connect with, overriding defaults
5975     :param password: password to connect with, overriding defaults
5976     .. versionadded:: 2019.2.0
5977     CLI Example:
5978     .. code-block:: bash
5979         salt "*" virt.network_set_autostart &lt;pool&gt; &lt;on | off&gt;
5980     """
5981     conn = __get_conn(**kwargs)
5982     try:
5983         net = conn.networkLookupByName(name)
5984         return not bool(net.setAutostart(1 if state == "on" else 0))
5985     finally:
5986         conn.close()
5987 def _parse_pools_caps(doc):
5988     """
5989     Parse libvirt pool capabilities XML
5990     """
5991     def _parse_pool_caps(pool):
5992         pool_caps = {
5993             "name": pool.get("type"),
5994             "supported": pool.get("supported", "no") == "yes",
5995         }
5996         for option_kind in ["pool", "vol"]:
5997             options = {}
5998             default_format_node = pool.find(
5999                 "{}Options/defaultFormat".format(option_kind)
6000             )
6001             if default_format_node is not None:
6002                 options["default_format"] = default_format_node.get("type")
6003             options_enums = {
6004                 enum.get("name"): [value.text for value in enum.findall("value")]
6005                 for enum in pool.findall("{}Options/enum".format(option_kind))
6006             }
6007             if options_enums:
6008                 options.update(options_enums)
6009             if options:
6010                 if "options" not in pool_caps:
6011                     pool_caps["options"] = {}
6012                 kind = option_kind if option_kind != "vol" else "volume"
6013                 pool_caps["options"][kind] = options
6014         return pool_caps
6015     return [_parse_pool_caps(pool) for pool in doc.findall("pool")]
6016 def _pool_capabilities(conn):
6017     """
6018     Return the hypervisor connection storage pool capabilities.
6019     :param conn: opened libvirt connection to use
6020     """
6021     has_pool_capabilities = bool(getattr(conn, "getStoragePoolCapabilities", None))
6022     if has_pool_capabilities:
6023         caps = ElementTree.fromstring(conn.getStoragePoolCapabilities())
6024         pool_types = _parse_pools_caps(caps)
6025     else:
6026         all_hypervisors = ["xen", "kvm", "bhyve"]
6027         images_formats = [
6028             "none",
6029             "raw",
6030             "dir",
6031             "bochs",
6032             "cloop",
6033             "dmg",
6034             "iso",
6035             "vpc",
6036             "vdi",
6037             "fat",
6038             "vhd",
6039             "ploop",
6040             "cow",
6041             "qcow",
6042             "qcow2",
6043             "qed",
6044             "vmdk",
6045         ]
6046         common_drivers = [
6047             {
6048                 "name": "fs",
6049                 "default_source_format": "auto",
6050                 "source_formats": [
6051                     "auto",
6052                     "ext2",
6053                     "ext3",
6054                     "ext4",
6055                     "ufs",
6056                     "iso9660",
6057                     "udf",
6058                     "gfs",
6059                     "gfs2",
6060                     "vfat",
6061                     "hfs+",
6062                     "xfs",
6063                     "ocfs2",
6064                 ],
6065                 "default_target_format": "raw",
6066                 "target_formats": images_formats,
6067             },
6068             {
6069                 "name": "dir",
6070                 "default_target_format": "raw",
6071                 "target_formats": images_formats,
6072             },
6073             {"name": "iscsi"},
6074             {"name": "scsi"},
6075             {
6076                 "name": "logical",
6077                 "default_source_format": "lvm2",
6078                 "source_formats": ["unknown", "lvm2"],
6079             },
6080             {
6081                 "name": "netfs",
6082                 "default_source_format": "auto",
6083                 "source_formats": ["auto", "nfs", "glusterfs", "cifs"],
6084                 "default_target_format": "raw",
6085                 "target_formats": images_formats,
6086             },
6087             {
6088                 "name": "disk",
6089                 "default_source_format": "unknown",
6090                 "source_formats": [
6091                     "unknown",
6092                     "dos",
6093                     "dvh",
6094                     "gpt",
6095                     "mac",
6096                     "bsd",
6097                     "pc98",
6098                     "sun",
6099                     "lvm2",
6100                 ],
6101                 "default_target_format": "none",
6102                 "target_formats": [
6103                     "none",
6104                     "linux",
6105                     "fat16",
6106                     "fat32",
6107                     "linux-swap",
6108                     "linux-lvm",
6109                     "linux-raid",
6110                     "extended",
6111                 ],
6112             },
6113             {"name": "mpath"},
6114             {"name": "rbd", "default_target_format": "raw", "target_formats": []},
6115             {
6116                 "name": "sheepdog",
6117                 "version": 10000,
6118                 "hypervisors": ["kvm"],
6119                 "default_target_format": "raw",
6120                 "target_formats": images_formats,
6121             },
6122             {
6123                 "name": "gluster",
6124                 "version": 1002000,
6125                 "hypervisors": ["kvm"],
6126                 "default_target_format": "raw",
6127                 "target_formats": images_formats,
6128             },
6129             {"name": "zfs", "version": 1002008, "hypervisors": ["bhyve"]},
6130             {
6131                 "name": "iscsi-direct",
6132                 "version": 4007000,
6133                 "hypervisors": ["kvm", "xen"],
6134             },
6135         ]
6136         libvirt_version = conn.getLibVersion()
6137         hypervisor = get_hypervisor()
6138         def _get_backend_output(backend):
6139             output = {
6140                 "name": backend["name"],
6141                 "supported": (
6142                     not backend.get("version") or libvirt_version &gt;= backend["version"]
6143                 )
6144                 and hypervisor in backend.get("hypervisors", all_hypervisors),
6145                 "options": {
6146                     "pool": {
6147                         "default_format": backend.get("default_source_format"),
6148                         "sourceFormatType": backend.get("source_formats"),
6149                     },
6150                     "volume": {
6151                         "default_format": backend.get("default_target_format"),
6152                         "targetFormatType": backend.get("target_formats"),
6153                     },
6154                 },
6155             }
6156             for option_kind in ["pool", "volume"]:
6157                 if not [
6158                     value
6159                     for value in output["options"][option_kind].values()
6160                     if value is not None
6161                 ]:
6162                     del output["options"][option_kind]
6163             if not output["options"]:
6164                 del output["options"]
6165             return output
6166         pool_types = [_get_backend_output(backend) for backend in common_drivers]
6167     return {
6168         "computed": not has_pool_capabilities,
6169         "pool_types": pool_types,
6170     }
6171 def pool_capabilities(**kwargs):
6172     """
6173     Return the hypervisor connection storage pool capabilities.
6174     The returned data are either directly extracted from libvirt or computed.
6175     In the latter case some pool types could be listed as supported while they
6176     are not. To distinguish between the two cases, check the value of the ``computed`` property.
6177     :param connection: libvirt connection URI, overriding defaults
6178     :param username: username to connect with, overriding defaults
6179     :param password: password to connect with, overriding defaults
6180     .. versionadded:: 3000
6181     CLI Example:
6182     .. code-block:: bash
6183         salt '*' virt.pool_capabilities
6184     """
6185     try:
6186         conn = __get_conn(**kwargs)
6187         return _pool_capabilities(conn)
6188     finally:
6189         conn.close()
6190 def pool_define(
6191     name,
6192     ptype,
6193     target=None,
6194     permissions=None,
6195     source_devices=None,
6196     source_dir=None,
6197     source_initiator=None,
6198     source_adapter=None,
6199     source_hosts=None,
6200     source_auth=None,
6201     source_name=None,
6202     source_format=None,
6203     transient=False,
6204     start=True,  # pylint: disable=redefined-outer-name
6205     **kwargs
6206 ):
6207     """
6208     Create libvirt pool.
6209     :param name: Pool name
6210     :param ptype:
6211         Pool type. See `libvirt documentation &lt;https://libvirt.org/storage.html&gt;`_  for the
6212         possible values.
6213     :param target: Pool full path target
6214     :param permissions:
6215         Permissions to set on the target folder. This is mostly used for filesystem-based
6216         pool types. See :ref:`pool-define-permissions` for more details on this structure.
6217     :param source_devices:
6218         List of source devices for pools backed by physical devices. (Default: ``None``)
6219         Each item in the list is a dictionary with ``path`` and optionally ``part_separator``
6220         keys. The path is the qualified name for iSCSI devices.
6221         Report to `this libvirt page &lt;https://libvirt.org/formatstorage.html#StoragePool&gt;`_
6222         for more information on the use of ``part_separator``
6223     :param source_dir:
6224         Path to the source directory for pools of type ``dir``, ``netfs`` or ``gluster``.
6225         (Default: ``None``)
6226     :param source_initiator:
6227         Initiator IQN for libiscsi-direct pool types. (Default: ``None``)
6228         .. versionadded:: 3000
6229     :param source_adapter:
6230         SCSI source definition. The value is a dictionary with ``type``, ``name``, ``parent``,
6231         ``managed``, ``parent_wwnn``, ``parent_wwpn``, ``parent_fabric_wwn``, ``wwnn``, ``wwpn``
6232         and ``parent_address`` keys.
6233         The ``parent_address`` value is a dictionary with ``unique_id`` and ``address`` keys.
6234         The address represents a PCI address and is itself a dictionary with ``domain``, ``bus``,
6235         ``slot`` and ``function`` properties.
6236         Report to `this libvirt page &lt;https://libvirt.org/formatstorage.html#StoragePool&gt;`_
6237         for the meaning and possible values of these properties.
6238     :param source_hosts:
6239         List of source for pools backed by storage from remote servers. Each item is the hostname
6240         optionally followed by the port separated by a colon. (Default: ``None``)
6241     :param source_auth:
6242         Source authentication details. (Default: ``None``)
6243         The value is a dictionary with ``type``, ``username`` and ``secret`` keys. The type
6244         can be one of ``ceph`` for Ceph RBD or ``chap`` for iSCSI sources.
6245         The ``secret`` value links to a libvirt secret object. It is a dictionary with
6246         ``type`` and ``value`` keys. The type value can be either ``uuid`` or ``usage``.
6247         Examples:
6248         .. code-block:: python
6249             source_auth={
6250                 'type': 'ceph',
6251                 'username': 'admin',
6252                 'secret': {
6253                     'type': 'uuid',
6254                     'value': '2ec115d7-3a88-3ceb-bc12-0ac909a6fd87'
6255                 }
6256             }
6257         .. code-block:: python
6258             source_auth={
6259                 'type': 'chap',
6260                 'username': 'myname',
6261                 'secret': {
6262                     'type': 'usage',
6263                     'value': 'mycluster_myname'
6264                 }
6265             }
6266         Since 3000, instead the source authentication can only contain ``username``
6267         and ``password`` properties. In this case the libvirt secret will be defined and used.
6268         For Ceph authentications a base64 encoded key is expected.
6269     :param source_name:
6270         Identifier of name-based sources.
6271     :param source_format:
6272         String representing the source format. The possible values are depending on the
6273         source type. See `libvirt documentation &lt;https://libvirt.org/storage.html&gt;`_ for
6274         the possible values.
6275     :param start: Pool start (default True)
6276     :param transient:
6277         When ``True``, the pool will be automatically undefined after being stopped.
6278         Note that a transient pool will force ``start`` to ``True``. (Default: ``False``)
6279     :param connection: libvirt connection URI, overriding defaults
6280     :param username: username to connect with, overriding defaults
6281     :param password: password to connect with, overriding defaults
6282     .. _pool-define-permissions:
6283     .. rubric:: Permissions definition
6284     The permissions are described by a dictionary containing the following keys:
6285     mode
6286         The octal representation of the permissions. (Default: `0711`)
6287     owner
6288         the numeric user ID of the owner. (Default: from the parent folder)
6289     group
6290         the numeric ID of the group. (Default: from the parent folder)
6291     label
6292         the SELinux label. (Default: `None`)
6293     .. rubric:: CLI Example:
6294     Local folder pool:
6295     .. code-block:: bash
6296         salt '*' virt.pool_define somepool dir target=/srv/mypool \
6297                                   permissions="{'mode': '0744' 'ower': 107, 'group': 107 }"
6298     CIFS backed pool:
6299     .. code-block:: bash
6300         salt '*' virt.pool_define myshare netfs source_format=cifs \
6301                                   source_dir=samba_share source_hosts="['example.com']" target=/mnt/cifs
6302     .. versionadded:: 2019.2.0
6303     """
6304     conn = __get_conn(**kwargs)
6305     auth = _pool_set_secret(conn, ptype, name, source_auth)
6306     pool_xml = _gen_pool_xml(
6307         name,
6308         ptype,
6309         target,
6310         permissions=permissions,
6311         source_devices=source_devices,
6312         source_dir=source_dir,
6313         source_adapter=source_adapter,
6314         source_hosts=source_hosts,
6315         source_auth=auth,
6316         source_name=source_name,
6317         source_format=source_format,
6318         source_initiator=source_initiator,
6319     )
6320     try:
6321         if transient:
6322             pool = conn.storagePoolCreateXML(pool_xml)
6323         else:
6324             pool = conn.storagePoolDefineXML(pool_xml)
6325             if start:
6326                 pool.create()
6327     except libvirt.libvirtError as err:
6328         raise err  # a real error we should report upwards
6329     finally:
6330         conn.close()
6331     return True
6332 def _pool_set_secret(
6333     conn, pool_type, pool_name, source_auth, uuid=None, usage=None, test=False
6334 ):
6335     secret_types = {"rbd": "ceph", "iscsi": "chap", "iscsi-direct": "chap"}
6336     secret_type = secret_types.get(pool_type)
6337     auth = source_auth
6338     if source_auth and "username" in source_auth and "password" in source_auth:
6339         if secret_type:
6340             secret = None
6341             try:
6342                 if usage:
6343                     usage_type = (
6344                         libvirt.VIR_SECRET_USAGE_TYPE_CEPH
6345                         if secret_type == "ceph"
6346                         else libvirt.VIR_SECRET_USAGE_TYPE_ISCSI
6347                     )
6348                     secret = conn.secretLookupByUsage(usage_type, usage)
6349                 elif uuid:
6350                     secret = conn.secretLookupByUUIDString(uuid)
6351             except libvirt.libvirtError as err:
6352                 log.info("Secret not found: %s", err.get_error_message())
6353             if not secret:
6354                 description = "Passphrase for {} pool created by Salt".format(pool_name)
6355                 if not usage:
6356                     usage = "pool_{}".format(pool_name)
6357                 secret_xml = _gen_secret_xml(secret_type, usage, description)
6358                 if not test:
6359                     secret = conn.secretDefineXML(secret_xml)
6360             password = auth["password"]
6361             if pool_type == "rbd":
6362                 password = base64.b64decode(salt.utils.stringutils.to_bytes(password))
6363             if not test:
6364                 secret.setValue(password)
6365             auth["type"] = secret_type
6366             auth["secret"] = {
6367                 "type": "uuid" if uuid else "usage",
6368                 "value": uuid if uuid else usage,
6369             }
6370     return auth
6371 def pool_update(
6372     name,
6373     ptype,
6374     target=None,
6375     permissions=None,
6376     source_devices=None,
6377     source_dir=None,
6378     source_initiator=None,
6379     source_adapter=None,
6380     source_hosts=None,
6381     source_auth=None,
6382     source_name=None,
6383     source_format=None,
6384     test=False,
6385     **kwargs
6386 ):
6387     """
6388     Update a libvirt storage pool if needed.
6389     If called with test=True, this is also reporting whether an update would be performed.
6390     :param name: Pool name
6391     :param ptype:
6392         Pool type. See `libvirt documentation &lt;https://libvirt.org/storage.html&gt;`_  for the
6393         possible values.
6394     :param target: Pool full path target
6395     :param permissions:
6396         Permissions to set on the target folder. This is mostly used for filesystem-based
6397         pool types. See :ref:`pool-define-permissions` for more details on this structure.
6398     :param source_devices:
6399         List of source devices for pools backed by physical devices. (Default: ``None``)
6400         Each item in the list is a dictionary with ``path`` and optionally ``part_separator``
6401         keys. The path is the qualified name for iSCSI devices.
6402         Report to `this libvirt page &lt;https://libvirt.org/formatstorage.html#StoragePool&gt;`_
6403         for more information on the use of ``part_separator``
6404     :param source_dir:
6405         Path to the source directory for pools of type ``dir``, ``netfs`` or ``gluster``.
6406         (Default: ``None``)
6407     :param source_initiator:
6408         Initiator IQN for libiscsi-direct pool types. (Default: ``None``)
6409         .. versionadded:: 3000
6410     :param source_adapter:
6411         SCSI source definition. The value is a dictionary with ``type``, ``name``, ``parent``,
6412         ``managed``, ``parent_wwnn``, ``parent_wwpn``, ``parent_fabric_wwn``, ``wwnn``, ``wwpn``
6413         and ``parent_address`` keys.
6414         The ``parent_address`` value is a dictionary with ``unique_id`` and ``address`` keys.
6415         The address represents a PCI address and is itself a dictionary with ``domain``, ``bus``,
6416         ``slot`` and ``function`` properties.
6417         Report to `this libvirt page &lt;https://libvirt.org/formatstorage.html#StoragePool&gt;`_
6418         for the meaning and possible values of these properties.
6419     :param source_hosts:
6420         List of source for pools backed by storage from remote servers. Each item is the hostname
6421         optionally followed by the port separated by a colon. (Default: ``None``)
6422     :param source_auth:
6423         Source authentication details. (Default: ``None``)
6424         The value is a dictionary with ``type``, ``username`` and ``secret`` keys. The type
6425         can be one of ``ceph`` for Ceph RBD or ``chap`` for iSCSI sources.
6426         The ``secret`` value links to a libvirt secret object. It is a dictionary with
6427         ``type`` and ``value`` keys. The type value can be either ``uuid`` or ``usage``.
6428         Examples:
6429         .. code-block:: python
6430             source_auth={
6431                 'type': 'ceph',
6432                 'username': 'admin',
6433                 'secret': {
6434                     'type': 'uuid',
6435                     'uuid': '2ec115d7-3a88-3ceb-bc12-0ac909a6fd87'
6436                 }
6437             }
6438         .. code-block:: python
6439             source_auth={
6440                 'type': 'chap',
6441                 'username': 'myname',
6442                 'secret': {
6443                     'type': 'usage',
6444                     'uuid': 'mycluster_myname'
6445                 }
6446             }
6447         Since 3000, instead the source authentication can only contain ``username``
6448         and ``password`` properties. In this case the libvirt secret will be defined and used.
6449         For Ceph authentications a base64 encoded key is expected.
6450     :param source_name:
6451         Identifier of name-based sources.
6452     :param source_format:
6453         String representing the source format. The possible values are depending on the
6454         source type. See `libvirt documentation &lt;https://libvirt.org/storage.html&gt;`_ for
6455         the possible values.
6456     :param test: run in dry-run mode if set to True
6457     :param connection: libvirt connection URI, overriding defaults
6458     :param username: username to connect with, overriding defaults
6459     :param password: password to connect with, overriding defaults
6460     .. rubric:: Example:
6461     Local folder pool:
6462     .. code-block:: bash
6463         salt '*' virt.pool_update somepool dir target=/srv/mypool \
6464                                   permissions="{'mode': '0744' 'ower': 107, 'group': 107 }"
6465     CIFS backed pool:
6466     .. code-block:: bash
6467         salt '*' virt.pool_update myshare netfs source_format=cifs \
6468                                   source_dir=samba_share source_hosts="['example.com']" target=/mnt/cifs
6469     .. versionadded:: 3000
6470     """
6471     conn = __get_conn(**kwargs)
6472     needs_update = False
6473     try:
6474         pool = conn.storagePoolLookupByName(name)
6475         old_xml = ElementTree.fromstring(pool.XMLDesc())
6476         secret_node = old_xml.find("source/auth/secret")
6477         usage = secret_node.get("usage") if secret_node is not None else None
6478         uuid = secret_node.get("uuid") if secret_node is not None else None
6479         auth = _pool_set_secret(
6480             conn, ptype, name, source_auth, uuid=uuid, usage=usage, test=test
6481         )
6482         new_xml = ElementTree.fromstring(
6483             _gen_pool_xml(
6484                 name,
6485                 ptype,
6486                 target,
6487                 permissions=permissions,
6488                 source_devices=source_devices,
6489                 source_dir=source_dir,
6490                 source_initiator=source_initiator,
6491                 source_adapter=source_adapter,
6492                 source_hosts=source_hosts,
6493                 source_auth=auth,
6494                 source_name=source_name,
6495                 source_format=source_format,
6496             )
6497         )
6498         elements_to_copy = ["available", "allocation", "capacity", "uuid"]
6499         for to_copy in elements_to_copy:
6500             element = old_xml.find(to_copy)
6501             new_xml.insert(1, element)
6502         _remove_empty_xml_node(xmlutil.strip_spaces(old_xml))
6503         xmlutil.strip_spaces(new_xml)
6504         needs_update = xmlutil.to_dict(old_xml, True) != xmlutil.to_dict(new_xml, True)
6505         if needs_update and not test:
6506             conn.storagePoolDefineXML(xmlutil.element_to_str(new_xml))
6507     finally:
6508         conn.close()
6509     return needs_update
6510 def list_pools(**kwargs):
6511     """
6512     List all storage pools.
6513     :param connection: libvirt connection URI, overriding defaults
6514     :param username: username to connect with, overriding defaults
6515     :param password: password to connect with, overriding defaults
6516     .. versionadded:: 2019.2.0
6517     CLI Example:
6518     .. code-block:: bash
6519         salt '*' virt.list_pools
6520     """
6521     conn = __get_conn(**kwargs)
6522     try:
6523         return [pool.name() for pool in conn.listAllStoragePools()]
6524     finally:
6525         conn.close()
6526 def pool_info(name=None, **kwargs):
6527     """
6528     Return information on a storage pool provided its name.
6529     :param name: libvirt storage pool name
6530     :param connection: libvirt connection URI, overriding defaults
6531     :param username: username to connect with, overriding defaults
6532     :param password: password to connect with, overriding defaults
6533     If no name is provided, return the infos for all defined storage pools.
6534     .. versionadded:: 2019.2.0
6535     CLI Example:
6536     .. code-block:: bash
6537         salt '*' virt.pool_info default
6538     """
6539     result = {}
6540     conn = __get_conn(**kwargs)
6541     def _pool_extract_infos(pool):
6542         """
6543         Format the pool info dictionary
6544         :param pool: the libvirt pool object
6545         """
6546         states = ["inactive", "building", "running", "degraded", "inaccessible"]
6547         infos = pool.info()
6548         state = states[infos[0]] if infos[0] &lt; len(states) else "unknown"
6549         desc = ElementTree.fromstring(pool.XMLDesc())
6550         path_node = desc.find("target/path")
6551         return {
6552             "uuid": pool.UUIDString(),
6553             "state": state,
6554             "capacity": infos[1],
6555             "allocation": infos[2],
6556             "free": infos[3],
6557             "autostart": pool.autostart(),
6558             "persistent": pool.isPersistent(),
6559             "target_path": path_node.text if path_node is not None else None,
6560             "type": desc.get("type"),
6561         }
6562     try:
6563         pools = [
6564             pool
6565             for pool in conn.listAllStoragePools()
6566             if name is None or pool.name() == name
6567         ]
6568         result = {pool.name(): _pool_extract_infos(pool) for pool in pools}
6569     except libvirt.libvirtError as err:
6570         log.debug("Silenced libvirt error: %s", err)
6571     finally:
6572         conn.close()
6573     return result
6574 def pool_get_xml(name, **kwargs):
6575     """
6576     Return the XML definition of a virtual storage pool
6577     :param name: libvirt storage pool name
6578     :param connection: libvirt connection URI, overriding defaults
6579     :param username: username to connect with, overriding defaults
6580     :param password: password to connect with, overriding defaults
6581     .. versionadded:: 3000
6582     CLI Example:
6583     .. code-block:: bash
6584         salt '*' virt.pool_get_xml default
6585     """
6586     conn = __get_conn(**kwargs)
6587     try:
6588         return conn.storagePoolLookupByName(name).XMLDesc()
6589     finally:
6590         conn.close()
6591 def pool_start(name, **kwargs):
6592     """
6593     Start a defined libvirt storage pool.
6594     :param name: libvirt storage pool name
6595     :param connection: libvirt connection URI, overriding defaults
6596     :param username: username to connect with, overriding defaults
6597     :param password: password to connect with, overriding defaults
6598     .. versionadded:: 2019.2.0
6599     CLI Example:
6600     .. code-block:: bash
6601         salt '*' virt.pool_start default
6602     """
6603     conn = __get_conn(**kwargs)
6604     try:
6605         pool = conn.storagePoolLookupByName(name)
6606         return not bool(pool.create())
6607     finally:
6608         conn.close()
6609 def pool_build(name, **kwargs):
6610     """
6611     Build a defined libvirt storage pool.
6612     :param name: libvirt storage pool name
6613     :param connection: libvirt connection URI, overriding defaults
6614     :param username: username to connect with, overriding defaults
6615     :param password: password to connect with, overriding defaults
6616     .. versionadded:: 2019.2.0
6617     CLI Example:
6618     .. code-block:: bash
6619         salt '*' virt.pool_build default
6620     """
6621     conn = __get_conn(**kwargs)
6622     try:
6623         pool = conn.storagePoolLookupByName(name)
6624         return not bool(pool.build())
6625     finally:
6626         conn.close()
6627 def pool_stop(name, **kwargs):
6628     """
6629     Stop a defined libvirt storage pool.
6630     :param name: libvirt storage pool name
6631     :param connection: libvirt connection URI, overriding defaults
6632     :param username: username to connect with, overriding defaults
6633     :param password: password to connect with, overriding defaults
6634     .. versionadded:: 2019.2.0
6635     CLI Example:
6636     .. code-block:: bash
6637         salt '*' virt.pool_stop default
6638     """
6639     conn = __get_conn(**kwargs)
6640     try:
6641         pool = conn.storagePoolLookupByName(name)
6642         return not bool(pool.destroy())
6643     finally:
6644         conn.close()
6645 def pool_undefine(name, **kwargs):
6646     """
6647     Remove a defined libvirt storage pool. The pool needs to be stopped before calling.
6648     :param name: libvirt storage pool name
6649     :param connection: libvirt connection URI, overriding defaults
6650     :param username: username to connect with, overriding defaults
6651     :param password: password to connect with, overriding defaults
6652     .. versionadded:: 2019.2.0
6653     CLI Example:
6654     .. code-block:: bash
6655         salt '*' virt.pool_undefine default
6656     """
6657     conn = __get_conn(**kwargs)
6658     try:
6659         pool = conn.storagePoolLookupByName(name)
6660         desc = ElementTree.fromstring(pool.XMLDesc())
6661         auth_node = desc.find("source/auth")
6662         if auth_node is not None:
6663             auth_types = {
6664                 "ceph": libvirt.VIR_SECRET_USAGE_TYPE_CEPH,
6665                 "iscsi": libvirt.VIR_SECRET_USAGE_TYPE_ISCSI,
6666             }
6667             secret_type = auth_types[auth_node.get("type")]
6668             secret_usage = auth_node.find("secret").get("usage")
6669             if secret_type and "pool_{}".format(name) == secret_usage:
6670                 secret = conn.secretLookupByUsage(secret_type, secret_usage)
6671                 secret.undefine()
6672         return not bool(pool.undefine())
6673     finally:
6674         conn.close()
6675 def pool_delete(name, **kwargs):
6676     """
6677     Delete the resources of a defined libvirt storage pool.
6678     :param name: libvirt storage pool name
6679     :param connection: libvirt connection URI, overriding defaults
6680     :param username: username to connect with, overriding defaults
6681     :param password: password to connect with, overriding defaults
6682     .. versionadded:: 2019.2.0
6683     CLI Example:
6684     .. code-block:: bash
6685         salt '*' virt.pool_delete default
6686     """
6687     conn = __get_conn(**kwargs)
6688     try:
6689         pool = conn.storagePoolLookupByName(name)
6690         return not bool(pool.delete(libvirt.VIR_STORAGE_POOL_DELETE_NORMAL))
6691     finally:
6692         conn.close()
6693 def pool_refresh(name, **kwargs):
6694     """
6695     Refresh a defined libvirt storage pool.
6696     :param name: libvirt storage pool name
6697     :param connection: libvirt connection URI, overriding defaults
6698     :param username: username to connect with, overriding defaults
6699     :param password: password to connect with, overriding defaults
6700     .. versionadded:: 2019.2.0
6701     CLI Example:
6702     .. code-block:: bash
6703         salt '*' virt.pool_refresh default
6704     """
6705     conn = __get_conn(**kwargs)
6706     try:
6707         pool = conn.storagePoolLookupByName(name)
6708         return not bool(pool.refresh())
6709     finally:
6710         conn.close()
6711 def pool_set_autostart(name, state="on", **kwargs):
6712     """
6713     Set the autostart flag on a libvirt storage pool so that the storage pool
6714     will start with the host system on reboot.
6715     :param name: libvirt storage pool name
6716     :param state: 'on' to auto start the pool, anything else to mark the
6717                   pool not to be started when the host boots
6718     :param connection: libvirt connection URI, overriding defaults
6719     :param username: username to connect with, overriding defaults
6720     :param password: password to connect with, overriding defaults
6721     .. versionadded:: 2019.2.0
6722     CLI Example:
6723     .. code-block:: bash
6724         salt "*" virt.pool_set_autostart &lt;pool&gt; &lt;on | off&gt;
6725     """
6726     conn = __get_conn(**kwargs)
6727     try:
6728         pool = conn.storagePoolLookupByName(name)
6729         return not bool(pool.setAutostart(1 if state == "on" else 0))
6730     finally:
6731         conn.close()
6732 def pool_list_volumes(name, **kwargs):
6733     """
6734     List the volumes contained in a defined libvirt storage pool.
6735     :param name: libvirt storage pool name
6736     :param connection: libvirt connection URI, overriding defaults
6737     :param username: username to connect with, overriding defaults
6738     :param password: password to connect with, overriding defaults
6739     .. versionadded:: 2019.2.0
6740     CLI Example:
6741     .. code-block:: bash
6742         salt "*" virt.pool_list_volumes &lt;pool&gt;
6743     """
6744     conn = __get_conn(**kwargs)
6745     try:
6746         pool = conn.storagePoolLookupByName(name)
6747         return pool.listVolumes()
6748     finally:
6749         conn.close()
6750 def _get_storage_vol(conn, pool, vol):
6751     """
6752     Helper function getting a storage volume. Will throw a libvirtError
6753     if the pool or the volume couldn't be found.
6754     :param conn: libvirt connection object to use
6755     :param pool: pool name
6756     :param vol: volume name
6757     """
6758     pool_obj = conn.storagePoolLookupByName(pool)
6759     return pool_obj.storageVolLookupByName(vol)
6760 def _is_valid_volume(vol):
6761     """
6762     Checks whether a volume is valid for further use since those may have disappeared since
6763     the last pool refresh.
6764     """
6765     try:
6766         def discarder(ctxt, error):  # pylint: disable=unused-argument
6767             log.debug("Ignore libvirt error: %s", error[2])
6768         libvirt.registerErrorHandler(discarder, None)
6769         vol.info()
6770         libvirt.registerErrorHandler(None, None)
6771         return True
6772     except libvirt.libvirtError as err:
6773         return False
6774 def _get_all_volumes_paths(conn):
6775     """
6776     Extract the path, name, pool name and backing stores path of all volumes.
6777     :param conn: libvirt connection to use
6778     """
6779     pools = [
6780         pool
6781         for pool in conn.listAllStoragePools()
6782         if pool.info()[0] == libvirt.VIR_STORAGE_POOL_RUNNING
6783     ]
6784     volumes = {}
6785     for pool in pools:
6786         pool_volumes = {
6787             volume.path(): {
6788                 "pool": pool.name(),
6789                 "name": volume.name(),
6790                 "backing_stores": [
6791                     path.text
6792                     for path in ElementTree.fromstring(volume.XMLDesc()).findall(
6793                         ".//backingStore/path"
6794                     )
6795                 ],
6796             }
6797             for volume in pool.listAllVolumes()
6798             if _is_valid_volume(volume)
6799         }
6800         volumes.update(pool_volumes)
6801     return volumes
6802 def volume_infos(pool=None, volume=None, **kwargs):
6803     """
6804     Provide details on a storage volume. If no volume name is provided, the infos
6805     all the volumes contained in the pool are provided. If no pool is provided,
6806     the infos of the volumes of all pools are output.
6807     :param pool: libvirt storage pool name (default: ``None``)
6808     :param volume: name of the volume to get infos from (default: ``None``)
6809     :param connection: libvirt connection URI, overriding defaults
6810     :param username: username to connect with, overriding defaults
6811     :param password: password to connect with, overriding defaults
6812     .. versionadded:: 3000
6813     CLI Example:
6814     .. code-block:: bash
6815         salt "*" virt.volume_infos &lt;pool&gt; &lt;volume&gt;
6816     """
6817     result = {}
6818     conn = __get_conn(**kwargs)
6819     try:
6820         backing_stores = _get_all_volumes_paths(conn)
6821         try:
6822             domains = _get_domain(conn)
6823             domains_list = domains if isinstance(domains, list) else [domains]
6824         except CommandExecutionError:
6825             domains_list = []
6826         disks = {
6827             domain.name(): {
6828                 node.get("file")
6829                 for node in ElementTree.fromstring(domain.XMLDesc(0)).findall(
6830                     ".//disk/source/[@file]"
6831                 )
6832             }
6833             for domain in domains_list
6834         }
6835         def _volume_extract_infos(vol):
6836             """
6837             Format the volume info dictionary
6838             :param vol: the libvirt storage volume object.
6839             """
6840             types = ["file", "block", "dir", "network", "netdir", "ploop"]
6841             infos = vol.info()
6842             vol_xml = ElementTree.fromstring(vol.XMLDesc())
6843             backing_store_path = vol_xml.find("./backingStore/path")
6844             backing_store_format = vol_xml.find("./backingStore/format")
6845             backing_store = None
6846             if backing_store_path is not None:
6847                 backing_store = {
6848                     "path": backing_store_path.text,
6849                     "format": backing_store_format.get("type")
6850                     if backing_store_format is not None
6851                     else None,
6852                 }
6853             format_node = vol_xml.find("./target/format")
6854             used_by = []
6855             if vol.path():
6856                 as_backing_store = {
6857                     path
6858                     for (path, volume) in backing_stores.items()
6859                     if vol.path() in volume.get("backing_stores")
6860                 }
6861                 used_by = [
6862                     vm_name
6863                     for (vm_name, vm_disks) in disks.items()
6864                     if vm_disks &amp; as_backing_store or vol.path() in vm_disks
6865                 ]
6866             return {
6867                 "type": types[infos[0]] if infos[0] &lt; len(types) else "unknown",
6868                 "key": vol.key(),
6869                 "path": vol.path(),
6870                 "capacity": infos[1],
6871                 "allocation": infos[2],
6872                 "used_by": used_by,
6873                 "backing_store": backing_store,
6874                 "format": format_node.get("type") if format_node is not None else None,
6875             }
6876         pools = [
6877             obj
6878             for obj in conn.listAllStoragePools()
6879             if (pool is None or obj.name() == pool)
6880             and obj.info()[0] == libvirt.VIR_STORAGE_POOL_RUNNING
6881         ]
6882         vols = {
6883             pool_obj.name(): {
6884                 vol.name(): _volume_extract_infos(vol)
6885                 for vol in pool_obj.listAllVolumes()
6886                 if (volume is None or vol.name() == volume) and _is_valid_volume(vol)
6887             }
6888             for pool_obj in pools
6889         }
6890         return {pool_name: volumes for (pool_name, volumes) in vols.items() if volumes}
6891     except libvirt.libvirtError as err:
6892         log.debug("Silenced libvirt error: %s", err)
6893     finally:
6894         conn.close()
6895     return result
6896 def volume_delete(pool, volume, **kwargs):
6897     """
6898     Delete a libvirt managed volume.
6899     :param pool: libvirt storage pool name
6900     :param volume: name of the volume to delete
6901     :param connection: libvirt connection URI, overriding defaults
6902     :param username: username to connect with, overriding defaults
6903     :param password: password to connect with, overriding defaults
6904     .. versionadded:: 3000
6905     CLI Example:
6906     .. code-block:: bash
6907         salt "*" virt.volume_delete &lt;pool&gt; &lt;volume&gt;
6908     """
6909     conn = __get_conn(**kwargs)
6910     try:
6911         vol = _get_storage_vol(conn, pool, volume)
6912         return not bool(vol.delete())
6913     finally:
6914         conn.close()
6915 def volume_define(
6916     pool,
6917     name,
6918     size,
6919     allocation=0,
6920     format=None,
6921     type=None,
6922     permissions=None,
6923     backing_store=None,
6924     nocow=False,
6925     **kwargs
6926 ):
6927     """
6928     Create libvirt volume.
6929     :param pool: name of the pool to create the volume in
6930     :param name: name of the volume to define
6931     :param size: capacity of the volume to define in MiB
6932     :param allocation: allocated size of the volume in MiB. Defaults to 0.
6933     :param format:
6934         volume format. The allowed values are depending on the pool type.
6935         Check the virt.pool_capabilities output for the possible values and the default.
6936     :param type:
6937         type of the volume. One of file, block, dir, network, netdiri, ploop or None.
6938         By default, the type is guessed by libvirt from the pool type.
6939     :param permissions:
6940         Permissions to set on the target folder. This is mostly used for filesystem-based
6941         pool types. See :ref:`pool-define-permissions` for more details on this structure.
6942     :param backing_store:
6943         dictionary describing a backing file for the volume. It must contain a ``path``
6944         property pointing to the base volume and a ``format`` property defining the format
6945         of the base volume.
6946         The base volume format will not be guessed for security reasons and is thus mandatory.
6947     :param nocow: disable COW for the volume.
6948     :param connection: libvirt connection URI, overriding defaults
6949     :param username: username to connect with, overriding defaults
6950     :param password: password to connect with, overriding defaults
6951     .. rubric:: CLI Example:
6952     Volume on ESX:
6953     .. code-block:: bash
6954         salt '*' virt.volume_define "[local-storage]" myvm/myvm.vmdk vmdk 8192
6955     QCow2 volume with backing file:
6956     .. code-block:: bash
6957         salt '*' virt.volume_define default myvm.qcow2 qcow2 8192 \
6958                             permissions="{'mode': '0775', 'owner': '123', 'group': '345'"}" \
6959                             backing_store="{'path': '/path/to/base.img', 'format': 'raw'}" \
6960                             nocow=True
6961     .. versionadded:: 3001
6962     """
6963     ret = False
6964     try:
6965         conn = __get_conn(**kwargs)
6966         pool_obj = conn.storagePoolLookupByName(pool)
6967         pool_type = ElementTree.fromstring(pool_obj.XMLDesc()).get("type")
6968         new_allocation = allocation
6969         if pool_type == "logical" and size != allocation:
6970             new_allocation = size
6971         xml = _gen_vol_xml(
6972             name,
6973             size,
6974             format=format,
6975             allocation=new_allocation,
6976             type=type,
6977             permissions=permissions,
6978             backing_store=backing_store,
6979             nocow=nocow,
6980         )
6981         ret = _define_vol_xml_str(conn, xml, pool=pool)
6982     except libvirt.libvirtError as err:
6983         raise CommandExecutionError(err.get_error_message())
6984     finally:
6985         conn.close()
6986     return ret
6987 def _volume_upload(conn, pool, volume, file, offset=0, length=0, sparse=False):
6988     """
6989     Function performing the heavy duty for volume_upload but using an already
6990     opened libvirt connection.
6991     """
6992     def handler(stream, nbytes, opaque):
6993         return os.read(opaque, nbytes)
6994     def holeHandler(stream, opaque):
6995         """
6996         Taken from the sparsestream.py libvirt-python example.
6997         """
6998         fd = opaque
6999         cur = os.lseek(fd, 0, os.SEEK_CUR)
7000         try:
7001             data = os.lseek(fd, cur, os.SEEK_DATA)
7002         except OSError as e:
7003             if e.errno != 6:
7004                 raise e
7005             else:
7006                 data = -1
7007         if data &lt; 0:
7008             inData = False
7009             eof = os.lseek(fd, 0, os.SEEK_END)
7010             if eof &lt; cur:
7011                 raise RuntimeError("Current position in file after EOF: {}".format(cur))
7012             sectionLen = eof - cur
7013         else:
7014             if data &gt; cur:
7015                 inData = False
7016                 sectionLen = data - cur
7017             else:
7018                 inData = True
7019                 hole = os.lseek(fd, data, os.SEEK_HOLE)
7020                 if hole &lt; 0:
7021                     raise RuntimeError("No trailing hole")
7022                 if hole == data:
7023                     raise RuntimeError("Impossible happened")
7024                 else:
7025                     sectionLen = hole - data
7026         os.lseek(fd, cur, os.SEEK_SET)
7027         return [inData, sectionLen]
7028     def skipHandler(stream, length, opaque):
7029         return os.lseek(opaque, length, os.SEEK_CUR)
7030     stream = None
7031     fd = None
7032     ret = False
7033     try:
7034         pool_obj = conn.storagePoolLookupByName(pool)
7035         vol_obj = pool_obj.storageVolLookupByName(volume)
7036         stream = conn.newStream()
7037         fd = os.open(file, os.O_RDONLY)
7038         vol_obj.upload(
7039             stream,
7040             offset,
7041             length,
7042             libvirt.VIR_STORAGE_VOL_UPLOAD_SPARSE_STREAM if sparse else 0,
7043         )
7044         if sparse:
7045             stream.sparseSendAll(handler, holeHandler, skipHandler, fd)
7046         else:
7047             stream.sendAll(handler, fd)
7048         ret = True
7049     except libvirt.libvirtError as err:
7050         raise CommandExecutionError(err.get_error_message())
7051     finally:
7052         if fd:
7053             try:
7054                 os.close(fd)
7055             except OSError as err:
7056                 if stream:
7057                     stream.abort()
7058                 if ret:
7059                     raise CommandExecutionError(
7060                         "Failed to close file: {}".format(err.strerror)
7061                     )
7062         if stream:
7063             try:
7064                 stream.finish()
7065             except libvirt.libvirtError as err:
7066                 if ret:
7067                     raise CommandExecutionError(
7068                         "Failed to finish stream: {}".format(err.get_error_message())
7069                     )
7070     return ret
7071 def volume_upload(pool, volume, file, offset=0, length=0, sparse=False, **kwargs):
7072     """
7073     Create libvirt volume.
7074     :param pool: name of the pool to create the volume in
7075     :param name: name of the volume to define
7076     :param file: the file to upload to the volume
7077     :param offset: where to start writing the data in the volume
7078     :param length: amount of bytes to transfer to the volume
7079     :param sparse: set to True to preserve data sparsiness.
7080     :param connection: libvirt connection URI, overriding defaults
7081     :param username: username to connect with, overriding defaults
7082     :param password: password to connect with, overriding defaults
7083     .. rubric:: CLI Example:
7084     .. code-block:: bash
7085         salt '*' virt.volume_upload default myvm.qcow2 /path/to/disk.qcow2
7086     .. versionadded:: 3001
7087     """
7088     conn = __get_conn(**kwargs)
7089     ret = False
7090     try:
7091         ret = _volume_upload(
7092             conn, pool, volume, file, offset=offset, length=length, sparse=sparse
7093         )
7094     finally:
7095         conn.close()
7096     return ret
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
