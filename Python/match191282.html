<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for test_mac_softwareupdate_1.py &amp; virt_1.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for test_mac_softwareupdate_1.py &amp; virt_1.py
      </h3>
<h1 align="center">
        1.7%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>test_mac_softwareupdate_1.py (39.325844%)<th>virt_1.py (0.90241075%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(69-78)<td><a href="#" name="0">(4072-4092)</a><td align="center"><font color="#ff0000">24</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(159-167)<td><a href="#" name="1">(3283-3287)</a><td align="center"><font color="#c90000">19</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(88-93)<td><a href="#" name="2">(6763-6767)</a><td align="center"><font color="#940000">14</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(108-118)<td><a href="#" name="3">(2970-2972)</a><td align="center"><font color="#8a0000">13</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_mac_softwareupdate_1.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import pytest
2 from tests.support.case import ModuleCase
3 from tests.support.helpers import runs_on
4 @pytest.mark.skip_if_not_root
5 @runs_on(kernel="Darwin")
6 @pytest.mark.skip_if_binaries_missing("softwareupdate")
7 class MacSoftwareUpdateModuleTest(ModuleCase):
8     IGNORED_LIST = []
9     SCHEDULE = False
10     CATALOG = ""
11     def setUp(self):
12         self.IGNORED_LIST = self.run_function("softwareupdate.list_ignored")
13         self.SCHEDULE = self.run_function("softwareupdate.schedule")
14         self.CATALOG = self.run_function("softwareupdate.get_catalog")
15         super().setUp()
16     def tearDown(self):
17         if self.IGNORED_LIST:
18             for item in self.IGNORED_LIST:
19                 self.run_function("softwareupdate.ignore", [item])
20         else:
21             self.run_function("softwareupdate.reset_ignored")
22         self.run_function("softwareupdate.schedule", [self.SCHEDULE])
23         if self.CATALOG == "Default":
24             self.run_function("softwareupdate.reset_catalog")
25         else:
26             self.run_function("softwareupdate.set_catalog", [self.CATALOG])
27         super().tearDown()
28     @pytest.mark.slow_test
29     def test_list_available(self):
30         self.assertIsInstance(self.run_function("softwareupdate.list_available"), dict)
31     @pytest.mark.destructive_test
32     @pytest.mark.slow_test
33     def test_ignore(self):
34         self<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.assertTrue(self.run_function("softwareupdate.reset_ignored"))
35         self.assertEqual(self.run_function("softwareupdate.list_ignored"), [])
36         self.assertTrue(self.run_function("softwareupdate.ignore", ["spongebob"]))
37         self.assertTrue(self.run_function("softwareupdate.ignore", ["squidward"]))
38         self.assertIn("spongebob", self.run_function("softwareupdate.list_ignored"))
39         self.assertIn("squidward", self.run_function(</b></font>"softwareupdate.list_ignored"))
40     @pytest.mark.destructive_test
41     @pytest.mark.slow_test
42     def test_schedule(self):
43         self<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.assertTrue(self.run_function("softwareupdate.schedule_enable", [True]))
44         self.assertTrue(self.run_function("softwareupdate.schedule_enabled"))
45         self.assertTrue(self.run_function("softwareupdate.schedule_enable", [False]))
46         self.assertFalse(</b></font>self.run_function("softwareupdate.schedule_enabled"))
47     @pytest.mark.destructive_test
48     @pytest.mark.slow_test
49     def test_update(self):
50         self<font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.assertIsInstance(self.run_function("softwareupdate.update_all"), dict)
51         self.assertFalse(
52             self.run_function("softwareupdate.update_available", ["spongebob"])
53         )
54         self.assertIn(
55             "Update not available",
56             self.run_function(</b></font>"softwareupdate.update", ["spongebob"]),
57         )
58     @pytest.mark.slow_test
59     def test_list_downloads(self):
60         self.assertIsInstance(self.run_function("softwareupdate.list_downloads"), list)
61     @pytest.mark.destructive_test
62     @pytest.mark.slow_test
63     def test_download(self):
64         self.assertIn(
65             "Update not available",
66             self.run_function("softwareupdate.download", ["spongebob"]),
67         )
68     @pytest.mark.destructive_test
69     @pytest.mark.slow_test
70     def test_download_all(self):
71         self.assertIsInstance(self.run_function("softwareupdate.download_all"), list)
72     @pytest.mark.destructive_test
73     @pytest.mark.slow_test
74     def test_get_set_reset_catalog(self):
75         self.assertEqual(self<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.run_function("softwareupdate.get_catalog"), "Default")
76         self.assertTrue(self.run_function("softwareupdate.set_catalog", ["spongebob"]))
77         self.assertEqual(self.run_function("softwareupdate.get_catalog"), "spongebob")
78         self.assertTrue(self.run_function("softwareupdate.reset_catalog"))
79         self.assertEqual(self.run_function(</b></font>"softwareupdate.get_catalog"), "Default")
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>virt_1.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import base64
2 import collections
3 import copy
4 import datetime
5 import logging
6 import os
7 import re
8 import shutil
9 import string  # pylint: disable=deprecated-module
10 import subprocess
11 import sys
12 import time
13 import urllib.parse
14 from xml.etree import ElementTree
15 from xml.sax import saxutils
16 import jinja2.exceptions
17 import salt.utils.data
18 import salt.utils.files
19 import salt.utils.json
20 import salt.utils.path
21 import salt.utils.stringutils
22 import salt.utils.templates
23 import salt.utils.virt
24 import salt.utils.xmlutil as xmlutil
25 import salt.utils.yaml
26 from salt._compat import ipaddress
27 from salt.exceptions import CommandExecutionError, SaltInvocationError
28 try:
29     import libvirt  # pylint: disable=import-error
30     from libvirt import libvirtError
31     HAS_LIBVIRT = True
32 except ImportError:
33     HAS_LIBVIRT = False
34 log = logging.getLogger(__name__)
35 JINJA = jinja2.Environment(
36     loader=jinja2.FileSystemLoader(
37         os.path.join(salt.utils.templates.TEMPLATE_DIRNAME, "virt")
38     )
39 )
40 CACHE_DIR = "/var/lib/libvirt/saltinst"
41 VIRT_STATE_NAME_MAP = {
42     0: "running",
43     1: "running",
44     2: "running",
45     3: "paused",
46     4: "shutdown",
47     5: "shutdown",
48     6: "crashed",
49 }
50 def __virtual__():
51     if not HAS_LIBVIRT:
52         return (False, "Unable to locate or import python libvirt library.")
53     return "virt"
54 def __get_request_auth(username, password):
55     def __request_auth(credentials, user_data):
56         for credential in credentials:
57             if credential[0] == libvirt.VIR_CRED_AUTHNAME:
58                 credential[4] = (
59                     username
60                     if username
61                     else __salt__["config.get"](
62                         "virt:connection:auth:username", credential[3]
63                     )
64                 )
65             elif credential[0] == libvirt.VIR_CRED_NOECHOPROMPT:
66                 credential[4] = (
67                     password
68                     if password
69                     else __salt__["config.get"](
70                         "virt:connection:auth:password", credential[3]
71                     )
72                 )
73             else:
74                 log.info("Unhandled credential type: %s", credential[0])
75         return 0
76 def __get_conn(**kwargs):
77     username = kwargs.get("username", None)
78     password = kwargs.get("password", None)
79     conn_str = kwargs.get("connection", None)
80     if not conn_str:
81         conn_str = __salt__["config.get"]("virt:connection:uri", conn_str)
82     try:
83         auth_types = [
84             libvirt.VIR_CRED_AUTHNAME,
85             libvirt.VIR_CRED_NOECHOPROMPT,
86             libvirt.VIR_CRED_ECHOPROMPT,
87             libvirt.VIR_CRED_PASSPHRASE,
88             libvirt.VIR_CRED_EXTERNAL,
89         ]
90         conn = libvirt.openAuth(
91             conn_str, [auth_types, __get_request_auth(username, password), None], 0
92         )
93     except Exception:  # pylint: disable=broad-except
94         raise CommandExecutionError(
95             "Sorry, {} failed to open a connection to the hypervisor "
96             "software at {}".format(__grains__["fqdn"], conn_str)
97         )
98     return conn
99 def _get_domain(conn, *vms, **kwargs):
100     ret = list()
101     lookup_vms = list()
102     all_vms = []
103     if kwargs.get("active", True):
104         for id_ in conn.listDomainsID():
105             all_vms.append(conn.lookupByID(id_).name())
106     if kwargs.get("inactive", True):
107         for id_ in conn.listDefinedDomains():
108             all_vms.append(id_)
109     if vms and not all_vms:
110         raise CommandExecutionError("No virtual machines found.")
111     if vms:
112         for name in vms:
113             if name not in all_vms:
114                 raise CommandExecutionError(
115                     'The VM "{name}" is not present'.format(name=name)
116                 )
117             else:
118                 lookup_vms.append(name)
119     else:
120         lookup_vms = list(all_vms)
121     for name in lookup_vms:
122         ret.append(conn.lookupByName(name))
123     return len(ret) == 1 and not kwargs.get("iterable") and ret[0] or ret
124 def _parse_qemu_img_info(info):
125     raw_infos = salt.utils.json.loads(info)
126     disks = []
127     for disk_infos in raw_infos:
128         disk = {
129             "file": disk_infos["filename"],
130             "file format": disk_infos["format"],
131             "disk size": disk_infos["actual-size"],
132             "virtual size": disk_infos["virtual-size"],
133             "cluster size": disk_infos["cluster-size"]
134             if "cluster-size" in disk_infos
135             else None,
136         }
137         if "full-backing-filename" in disk_infos.keys():
138             disk["backing file"] = format(disk_infos["full-backing-filename"])
139         if "snapshots" in disk_infos.keys():
140             disk["snapshots"] = [
141                 {
142                     "id": snapshot["id"],
143                     "tag": snapshot["name"],
144                     "vmsize": snapshot["vm-state-size"],
145                     "date": datetime.datetime.fromtimestamp(
146                         float(
147                             "{}.{}".format(snapshot["date-sec"], snapshot["date-nsec"])
148                         )
149                     ).isoformat(),
150                     "vmclock": datetime.datetime.utcfromtimestamp(
151                         float(
152                             "{}.{}".format(
153                                 snapshot["vm-clock-sec"], snapshot["vm-clock-nsec"]
154                             )
155                         )
156                     )
157                     .time()
158                     .isoformat(),
159                 }
160                 for snapshot in disk_infos["snapshots"]
161             ]
162         disks.append(disk)
163     for disk in disks:
164         if "backing file" in disk.keys():
165             candidates = [
166                 info
167                 for info in disks
168                 if "file" in info.keys() and info["file"] == disk["backing file"]
169             ]
170             if candidates:
171                 disk["backing file"] = candidates[0]
172     return disks[0]
173 def _get_uuid(dom):
174     return ElementTree.fromstring(get_xml(dom)).find("uuid").text
175 def _get_on_poweroff(dom):
176     node = ElementTree.fromstring(get_xml(dom)).find("on_poweroff")
177     return node.text if node is not None else ""
178 def _get_on_reboot(dom):
179     node = ElementTree.fromstring(get_xml(dom)).find("on_reboot")
180     return node.text if node is not None else ""
181 def _get_on_crash(dom):
182     node = ElementTree.fromstring(get_xml(dom)).find("on_crash")
183     return node.text if node is not None else ""
184 def _get_nics(dom):
185     nics = {}
186     doc = ElementTree.fromstring(dom.XMLDesc(libvirt.VIR_DOMAIN_XML_INACTIVE))
187     for iface_node in doc.findall("devices/interface"):
188         nic = {}
189         nic["type"] = iface_node.get("type")
190         for v_node in iface_node:
191             if v_node.tag == "mac":
192                 nic["mac"] = v_node.get("address")
193             if v_node.tag == "model":
194                 nic["model"] = v_node.get("type")
195             if v_node.tag == "target":
196                 nic["target"] = v_node.get("dev")
197             if re.match("(driver|source|address)", v_node.tag):
198                 temp = {}
199                 for key, value in v_node.attrib.items():
200                     temp[key] = value
201                 nic[v_node.tag] = temp
202             if v_node.tag == "virtualport":
203                 temp = {}
204                 temp["type"] = v_node.get("type")
205                 for key, value in v_node.attrib.items():
206                     temp[key] = value
207                 nic["virtualport"] = temp
208         if "mac" not in nic:
209             continue
210         nics[nic["mac"]] = nic
211     return nics
212 def _get_graphics(dom):
213     out = {
214         "autoport": "None",
215         "keymap": "None",
216         "listen": "None",
217         "port": "None",
218         "type": "None",
219     }
220     doc = ElementTree.fromstring(dom.XMLDesc(0))
221     for g_node in doc.findall("devices/graphics"):
222         for key, value in g_node.attrib.items():
223             out[key] = value
224     return out
225 def _get_loader(dom):
226     out = {"path": "None"}
227     doc = ElementTree.fromstring(dom.XMLDesc(0))
228     for g_node in doc.findall("os/loader"):
229         out["path"] = g_node.text
230         for key, value in g_node.attrib.items():
231             out[key] = value
232     return out
233 def _get_disks(conn, dom):
234     disks = {}
235     doc = ElementTree.fromstring(dom.XMLDesc(0))
236     all_volumes = _get_all_volumes_paths(conn)
237     for elem in doc.findall("devices/disk"):
238         source = elem.find("source")
239         if source is None:
240             continue
241         target = elem.find("target")
242         driver = elem.find("driver")
243         if target is None:
244             continue
245         qemu_target = None
246         extra_properties = None
247         if "dev" in target.attrib:
248             disk_type = elem.get("type")
249             def _get_disk_volume_data(pool_name, volume_name):
250                 qemu_target = "{}/{}".format(pool_name, volume_name)
251                 pool = conn.storagePoolLookupByName(pool_name)
252                 extra_properties = {}
253                 try:
254                     vol = pool.storageVolLookupByName(volume_name)
255                     vol_info = vol.info()
256                     extra_properties = {
257                         "virtual size": vol_info[1],
258                         "disk size": vol_info[2],
259                     }
260                     backing_files = [
261                         {
262                             "file": node.find("source").get("file"),
263                             "file format": node.find("format").get("type"),
264                         }
265                         for node in elem.findall(".//backingStore[source]")
266                     ]
267                     if backing_files:
268                         extra_properties["backing file"] = backing_files[0]
269                         parent = extra_properties["backing file"]
270                         for sub_backing_file in backing_files[1:]:
271                             parent["backing file"] = sub_backing_file
272                             parent = sub_backing_file
273                     else:
274                         vol_desc = ElementTree.fromstring(vol.XMLDesc())
275                         backing_path = vol_desc.find("./backingStore/path")
276                         backing_format = vol_desc.find("./backingStore/format")
277                         if backing_path is not None:
278                             extra_properties["backing file"] = {
279                                 "file": backing_path.text
280                             }
281                             if backing_format is not None:
282                                 extra_properties["backing file"][
283                                     "file format"
284                                 ] = backing_format.get("type")
285                 except libvirt.libvirtError:
286                     log.info(
287                         "Couldn't extract all volume informations: pool is likely not"
288                         " running or refreshed"
289                     )
290                 return (qemu_target, extra_properties)
291             if disk_type == "file":
292                 qemu_target = source.get("file", "")
293                 if qemu_target.startswith("/dev/zvol/"):
294                     disks[target.get("dev")] = {"file": qemu_target, "zfs": True}
295                     continue
296                 if qemu_target in all_volumes.keys():
297                     volume = all_volumes[qemu_target]
298                     qemu_target, extra_properties = _get_disk_volume_data(
299                         volume["pool"], volume["name"]
300                     )
301                 elif elem.get("device", "disk") != "cdrom":
302                     try:
303                         process = subprocess.Popen(
304                             [
305                                 "qemu-img",
306                                 "info",
307                                 "-U",
308                                 "--output",
309                                 "json",
310                                 "--backing-chain",
311                                 qemu_target,
312                             ],
313                             shell=False,
314                             stdout=subprocess.PIPE,
315                             stderr=subprocess.PIPE,
316                         )
317                         stdout, stderr = process.communicate()
318                         if process.returncode == 0:
319                             qemu_output = salt.utils.stringutils.to_str(stdout)
320                             output = _parse_qemu_img_info(qemu_output)
321                             extra_properties = output
322                         else:
323                             extra_properties = {"error": stderr}
324                     except FileNotFoundError:
325                         extra_properties = {"error": "qemu-img not found"}
326             elif disk_type == "block":
327                 qemu_target = source.get("dev", "")
328                 if qemu_target in all_volumes.keys():
329                     volume = all_volumes[qemu_target]
330                     qemu_target, extra_properties = _get_disk_volume_data(
331                         volume["pool"], volume["name"]
332                     )
333             elif disk_type == "network":
334                 qemu_target = source.get("protocol")
335                 source_name = source.get("name")
336                 if source_name:
337                     qemu_target = "{}:{}".format(qemu_target, source_name)
338                 if source.get("protocol") in ["rbd", "gluster"]:
339                     for pool_i in conn.listAllStoragePools():
340                         pool_i_xml = ElementTree.fromstring(pool_i.XMLDesc())
341                         name_node = pool_i_xml.find("source/name")
342                         if name_node is not None and source_name.startswith(
343                             "{}/".format(name_node.text)
344                         ):
345                             qemu_target = "{}{}".format(
346                                 pool_i.name(), source_name[len(name_node.text) :]
347                             )
348                             break
349                 if elem.get("device", "disk") == "cdrom":
350                     host_node = source.find("host")
351                     if host_node is not None:
352                         hostname = host_node.get("name")
353                         port = host_node.get("port")
354                         qemu_target = urllib.parse.urlunparse(
355                             (
356                                 source.get("protocol"),
357                                 "{}:{}".format(hostname, port) if port else hostname,
358                                 source_name,
359                                 "",
360                                 saxutils.unescape(source.get("query", "")),
361                                 "",
362                             )
363                         )
364             elif disk_type == "volume":
365                 pool_name = source.get("pool")
366                 volume_name = source.get("volume")
367                 qemu_target, extra_properties = _get_disk_volume_data(
368                     pool_name, volume_name
369                 )
370             if not qemu_target:
371                 continue
372             disk = {
373                 "file": qemu_target,
374                 "type": elem.get("device"),
375             }
376             if driver is not None and "type" in driver.attrib:
377                 disk["file format"] = driver.get("type")
378             if extra_properties:
379                 disk.update(extra_properties)
380             disks[target.get("dev")] = disk
381     return disks
382 def _libvirt_creds():
383     g_cmd = ["grep", "^\\s*group", "/etc/libvirt/qemu.conf"]
384     u_cmd = ["grep", "^\\s*user", "/etc/libvirt/qemu.conf"]
385     try:
386         stdout = subprocess.Popen(g_cmd, stdout=subprocess.PIPE).communicate()[0]
387         group = salt.utils.stringutils.to_str(stdout).split('"')[1]
388     except IndexError:
389         group = "root"
390     try:
391         stdout = subprocess.Popen(u_cmd, stdout=subprocess.PIPE).communicate()[0]
392         user = salt.utils.stringutils.to_str(stdout).split('"')[1]
393     except IndexError:
394         user = "root"
395     return {"user": user, "group": group}
396 def _migrate(dom, dst_uri, **kwargs):
397     flags = 0
398     params = {}
399     migrated_state = libvirt.VIR_DOMAIN_RUNNING_MIGRATED
400     if kwargs.get("live", True):
401         flags |= libvirt.VIR_MIGRATE_LIVE
402     if kwargs.get("persistent", True):
403         flags |= libvirt.VIR_MIGRATE_PERSIST_DEST
404     if kwargs.get("undefinesource", True):
405         flags |= libvirt.VIR_MIGRATE_UNDEFINE_SOURCE
406     max_bandwidth = kwargs.get("max_bandwidth")
407     if max_bandwidth:
408         try:
409             bandwidth_value = int(max_bandwidth)
410         except ValueError:
411             raise SaltInvocationError(
412                 "Invalid max_bandwidth value: {}".format(max_bandwidth)
413             )
414         dom.migrateSetMaxSpeed(bandwidth_value)
415     max_downtime = kwargs.get("max_downtime")
416     if max_downtime:
417         try:
418             downtime_value = int(max_downtime)
419         except ValueError:
420             raise SaltInvocationError(
421                 "Invalid max_downtime value: {}".format(max_downtime)
422             )
423         dom.migrateSetMaxDowntime(downtime_value)
424     if kwargs.get("offline") is True:
425         flags |= libvirt.VIR_MIGRATE_OFFLINE
426         migrated_state = libvirt.VIR_DOMAIN_RUNNING_UNPAUSED
427     if kwargs.get("compressed") is True:
428         flags |= libvirt.VIR_MIGRATE_COMPRESSED
429     comp_methods = kwargs.get("comp_methods")
430     if comp_methods:
431         params[libvirt.VIR_MIGRATE_PARAM_COMPRESSION] = comp_methods.split(",")
432     comp_options = {
433         "comp_mt_level": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_LEVEL,
434         "comp_mt_threads": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_THREADS,
435         "comp_mt_dthreads": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_DTHREADS,
436         "comp_xbzrle_cache": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_XBZRLE_CACHE,
437     }
438     for (comp_option, param_key) in comp_options.items():
439         comp_option_value = kwargs.get(comp_option)
440         if comp_option_value:
441             try:
442                 params[param_key] = int(comp_option_value)
443             except ValueError:
444                 raise SaltInvocationError("Invalid {} value".format(comp_option))
445     parallel_connections = kwargs.get("parallel_connections")
446     if parallel_connections:
447         try:
448             params[libvirt.VIR_MIGRATE_PARAM_PARALLEL_CONNECTIONS] = int(
449                 parallel_connections
450             )
451         except ValueError:
452             raise SaltInvocationError("Invalid parallel_connections value")
453         flags |= libvirt.VIR_MIGRATE_PARALLEL
454     if __salt__["config.get"]("virt:tunnel"):
455         if parallel_connections:
456             raise SaltInvocationError(
457                 "Parallel migration isn't compatible with tunneled migration"
458             )
459         flags |= libvirt.VIR_MIGRATE_PEER2PEER
460         flags |= libvirt.VIR_MIGRATE_TUNNELLED
461     if kwargs.get("postcopy") is True:
462         flags |= libvirt.VIR_MIGRATE_POSTCOPY
463     postcopy_bandwidth = kwargs.get("postcopy_bandwidth")
464     if postcopy_bandwidth:
465         try:
466             postcopy_bandwidth_value = int(postcopy_bandwidth)
467         except ValueError:
468             raise SaltInvocationError("Invalid postcopy_bandwidth value")
469         dom.migrateSetMaxSpeed(
470             postcopy_bandwidth_value,
471             flags=libvirt.VIR_DOMAIN_MIGRATE_MAX_SPEED_POSTCOPY,
472         )
473     copy_storage = kwargs.get("copy_storage")
474     if copy_storage:
475         if copy_storage == "all":
476             flags |= libvirt.VIR_MIGRATE_NON_SHARED_DISK
477         elif copy_storage in ["inc", "incremental"]:
478             flags |= libvirt.VIR_MIGRATE_NON_SHARED_INC
479         else:
480             raise SaltInvocationError("invalid copy_storage value")
481     try:
482         state = False
483         dst_conn = __get_conn(
484             connection=dst_uri,
485             username=kwargs.get("username"),
486             password=kwargs.get("password"),
487         )
488         new_dom = dom.migrate3(dconn=dst_conn, params=params, flags=flags)
489         if new_dom:
490             state = new_dom.state()
491         dst_conn.close()
492         return state and migrated_state in state
493     except libvirt.libvirtError as err:
494         dst_conn.close()
495         raise CommandExecutionError(err.get_error_message())
496 def _get_volume_path(pool, volume_name):
497     if volume_name in pool.listVolumes():
498         volume = pool.storageVolLookupByName(volume_name)
499         volume_xml = ElementTree.fromstring(volume.XMLDesc())
500         return volume_xml.find("./target/path").text
501     pool_xml = ElementTree.fromstring(pool.XMLDesc())
502     pool_path = pool_xml.find("./target/path").text
503     return pool_path + "/" + volume_name
504 def _disk_from_pool(conn, pool, pool_xml, volume_name):
505     pool_type = pool_xml.get("type")
506     disk_context = {}
507     if pool_type in ["dir", "netfs", "fs"]:
508         disk_context["type"] = "file"
509         disk_context["source_file"] = _get_volume_path(pool, volume_name)
510     elif pool_type in ["logical", "disk", "iscsi", "scsi"]:
511         disk_context["type"] = "block"
512         disk_context["format"] = "raw"
513         disk_context["source_file"] = _get_volume_path(pool, volume_name)
514     elif pool_type in ["rbd", "gluster", "sheepdog"]:
515         disk_context["type"] = "network"
516         disk_context["protocol"] = pool_type
517         disk_context["hosts"] = [
518             {"name": host.get("name"), "port": host.get("port")}
519             for host in pool_xml.findall(".//host")
520         ]
521         dir_node = pool_xml.find("./source/dir")
522         name_node = pool_xml.find("./source/name")
523         if name_node is not None:
524             disk_context["volume"] = "{}/{}".format(name_node.text, volume_name)
525         auth_node = pool_xml.find("./source/auth")
526         if auth_node is not None:
527             username = auth_node.get("username")
528             secret_node = auth_node.find("./secret")
529             usage = secret_node.get("usage")
530             if not usage:
531                 uuid = secret_node.get("uuid")
532                 usage = conn.secretLookupByUUIDString(uuid).usageID()
533             disk_context["auth"] = {
534                 "type": "ceph",
535                 "username": username,
536                 "usage": usage,
537             }
538     return disk_context
539 def _handle_unit(s, def_unit="m"):
540     m = re.match(r"(?P&lt;value&gt;[0-9.]*)\s*(?P&lt;unit&gt;.*)$", str(s).strip())
541     value = m.group("value")
542     unit = m.group("unit").lower() or def_unit
543     try:
544         value = int(value)
545     except ValueError:
546         try:
547             value = float(value)
548         except ValueError:
549             raise SaltInvocationError("invalid number")
550     dec = False
551     if re.match(r"[kmgtpezy]b$", unit):
552         dec = True
553     elif not re.match(r"(b|[kmgtpezy](ib)?)$", unit):
554         raise SaltInvocationError("invalid units")
555     p = "bkmgtpezy".index(unit[0])
556     value *= 10 ** (p * 3) if dec else 2 ** (p * 10)
557     return int(value)
558 def nesthash(value=None):
559     return collections.defaultdict(nesthash, value or {})
560 def _gen_xml(
561     conn,
562     name,
563     cpu,
564     mem,
565     diskp,
566     nicp,
567     hypervisor,
568     os_type,
569     arch,
570     graphics=None,
571     boot=None,
572     boot_dev=None,
573     numatune=None,
574     hypervisor_features=None,
575     clock=None,
576     serials=None,
577     consoles=None,
578     stop_on_reboot=False,
579     host_devices=None,
580     **kwargs
581 ):
582     context = {
583         "hypervisor": hypervisor,
584         "name": name,
585         "hypervisor_features": hypervisor_features or {},
586         "clock": clock or {},
587         "on_reboot": "destroy" if stop_on_reboot else "restart",
588     }
589     context["to_kib"] = lambda v: int(_handle_unit(v) / 1024)
590     context["yesno"] = lambda v: "yes" if v else "no"
591     context["mem"] = nesthash()
592     if isinstance(mem, int):
593         context["mem"]["boot"] = mem
594         context["mem"]["current"] = mem
595     elif isinstance(mem, dict):
596         context["mem"] = nesthash(mem)
597     context["cpu"] = nesthash()
598     context["cputune"] = nesthash()
599     if isinstance(cpu, int):
600         context["cpu"]["maximum"] = str(cpu)
601     elif isinstance(cpu, dict):
602         context["cpu"] = nesthash(cpu)
603     if clock:
604         offset = "utc" if clock.get("utc", True) else "localtime"
605         if "timezone" in clock:
606             offset = "timezone"
607         context["clock"]["offset"] = offset
608     if hypervisor in ["qemu", "kvm"]:
609         context["numatune"] = numatune if numatune else {}
610         context["controller_model"] = False
611     elif hypervisor == "vmware":
612         context["controller_model"] = "lsilogic"
613     if graphics:
614         if "listen" not in graphics:
615             graphics["listen"] = {"type": "address", "address": "0.0.0.0"}
616         elif (
617             "address" not in graphics["listen"]
618             and graphics["listen"]["type"] == "address"
619         ):
620             graphics["listen"]["address"] = "0.0.0.0"
621         if graphics.get("type", "none") == "none":
622             graphics = None
623     context["graphics"] = graphics
624     context["boot_dev"] = boot_dev.split() if boot_dev is not None else ["hd"]
625     context["boot"] = boot if boot else {}
626     efi_value = context["boot"].get("efi", None) if boot else None
627     if efi_value is True:
628         context["boot"]["os_attrib"] = "firmware='efi'"
629     elif efi_value is not None and type(efi_value) != bool:
630         raise SaltInvocationError("Invalid efi value")
631     if os_type == "xen":
632         if __grains__["os_family"] == "Suse":
633             if not boot or not boot.get("kernel", None):
634                 paths = [
635                     path
636                     for path in ["/usr/share", "/usr/lib"]
637                     if os.path.exists(path + "/grub2/x86_64-xen/grub.xen")
638                 ]
639                 if not paths:
640                     raise CommandExecutionError("grub-x86_64-xen needs to be installed")
641                 context["boot"]["kernel"] = paths[0] + "/grub2/x86_64-xen/grub.xen"
642                 context["boot_dev"] = []
643     default_port = 23023
644     default_chardev_type = "tcp"
645     chardev_types = ["serial", "console"]
646     for chardev_type in chardev_types:
647         context[chardev_type + "s"] = []
648         parameter_value = locals()[chardev_type + "s"]
649         if parameter_value is not None:
650             for chardev in parameter_value:
651                 chardev_context = chardev
652                 chardev_context["type"] = chardev.get("type", default_chardev_type)
653                 if chardev_context["type"] == "tcp":
654                     chardev_context["port"] = chardev.get("port", default_port)
655                     chardev_context["protocol"] = chardev.get("protocol", "telnet")
656                 context[chardev_type + "s"].append(chardev_context)
657     context["disks"] = []
658     disk_bus_map = {"virtio": "vd", "xen": "xvd", "fdc": "fd", "ide": "hd"}
659     targets = []
660     for i, disk in enumerate(diskp):
661         prefix = disk_bus_map.get(disk["model"], "sd")
662         disk_context = {
663             "device": disk.get("device", "disk"),
664             "target_dev": _get_disk_target(targets, len(diskp), prefix),
665             "disk_bus": disk["model"],
666             "format": disk.get("format", "raw"),
667             "index": str(i),
668             "io": disk.get("io", "native"),
669             "iothread": disk.get("iothread_id", None),
670         }
671         targets.append(disk_context["target_dev"])
672         if disk.get("source_file"):
673             url = urllib.parse.urlparse(disk["source_file"])
674             if not url.scheme or not url.hostname:
675                 disk_context["source_file"] = disk["source_file"]
676                 disk_context["type"] = "file"
677             elif url.scheme in ["http", "https", "ftp", "ftps", "tftp"]:
678                 disk_context["type"] = "network"
679                 disk_context["protocol"] = url.scheme
680                 disk_context["volume"] = url.path
681                 disk_context["query"] = saxutils.escape(url.query)
682                 disk_context["hosts"] = [{"name": url.hostname, "port": url.port}]
683         elif disk.get("pool"):
684             disk_context["volume"] = disk["filename"]
685             pool = conn.storagePoolLookupByName(disk["pool"])
686             pool_xml = ElementTree.fromstring(pool.XMLDesc())
687             pool_type = pool_xml.get("type")
688             if hypervisor == "xen" or pool_type in ["rbd", "gluster", "sheepdog"]:
689                 disk_context.update(
690                     _disk_from_pool(conn, pool, pool_xml, disk_context["volume"])
691                 )
692             else:
693                 if pool_type in ["disk", "logical"]:
694                     disk_context["format"] = "raw"
695                 disk_context["type"] = "volume"
696                 disk_context["pool"] = disk["pool"]
697         else:
698             disk_context["type"] = "file"
699         if hypervisor in ["qemu", "kvm", "bhyve", "xen"]:
700             disk_context["address"] = False
701             disk_context["driver"] = True
702         elif hypervisor in ["esxi", "vmware"]:
703             disk_context["address"] = True
704             disk_context["driver"] = False
705         context["disks"].append(disk_context)
706     context["nics"] = nicp
707     hostdev_context = []
708     try:
709         for hostdev_name in host_devices or []:
710             hostdevice = conn.nodeDeviceLookupByName(hostdev_name)
711             doc = ElementTree.fromstring(hostdevice.XMLDesc())
712             if "pci" in hostdevice.listCaps():
713                 hostdev_context.append(
714                     {
715                         "type": "pci",
716                         "domain": "0x{:04x}".format(
717                             int(doc.find("./capability[@type='pci']/domain").text)
718                         ),
719                         "bus": "0x{:02x}".format(
720                             int(doc.find("./capability[@type='pci']/bus").text)
721                         ),
722                         "slot": "0x{:02x}".format(
723                             int(doc.find("./capability[@type='pci']/slot").text)
724                         ),
725                         "function": "0x{}".format(
726                             doc.find("./capability[@type='pci']/function").text
727                         ),
728                     }
729                 )
730             elif "usb_device" in hostdevice.listCaps():
731                 vendor_id = doc.find(".//vendor").get("id")
732                 product_id = doc.find(".//product").get("id")
733                 hostdev_context.append(
734                     {"type": "usb", "vendor": vendor_id, "product": product_id}
735                 )
736     except libvirt.libvirtError as err:
737         conn.close()
738         raise CommandExecutionError(
739             "Failed to get host devices: " + err.get_error_message()
740         )
741     context["hostdevs"] = hostdev_context
742     context["os_type"] = os_type
743     context["arch"] = arch
744     fn_ = "libvirt_domain.jinja"
745     try:
746         template = JINJA.get_template(fn_)
747     except jinja2.exceptions.TemplateNotFound:
748         log.error("Could not load template %s", fn_)
749         return ""
750     return template.render(**context)
751 def _gen_vol_xml(
752     name,
753     size,
754     format=None,
755     allocation=0,
756     type=None,
757     permissions=None,
758     backing_store=None,
759     nocow=False,
760 ):
761     size = int(size) * 1024  # MB
762     context = {
763         "type": type,
764         "name": name,
765         "target": {"permissions": permissions, "nocow": nocow},
766         "format": format,
767         "size": str(size),
768         "allocation": str(int(allocation) * 1024),
769         "backingStore": backing_store,
770     }
771     fn_ = "libvirt_volume.jinja"
772     try:
773         template = JINJA.get_template(fn_)
774     except jinja2.exceptions.TemplateNotFound:
775         log.error("Could not load template %s", fn_)
776         return ""
777     return template.render(**context)
778 def _gen_net_xml(
779     name,
780     bridge,
781     forward,
782     vport,
783     tag=None,
784     ip_configs=None,
785     mtu=None,
786     domain=None,
787     nat=None,
788     interfaces=None,
789     addresses=None,
790     physical_function=None,
791     dns=None,
792 ):
793     if isinstance(vport, str):
794         vport_context = {"type": vport}
795     else:
796         vport_context = vport
797     if isinstance(tag, (str, int)):
798         tag_context = {"tags": [{"id": tag}]}
799     else:
800         tag_context = tag
801     addresses_context = []
802     if addresses:
803         matches = [
804             re.fullmatch(r"([0-9]+):([0-9A-Fa-f]+):([0-9A-Fa-f]+)\.([0-9])", addr)
805             for addr in addresses.lower().split(" ")
806         ]
807         addresses_context = [
808             {
809                 "domain": m.group(1),
810                 "bus": m.group(2),
811                 "slot": m.group(3),
812                 "function": m.group(4),
813             }
814             for m in matches
815             if m
816         ]
817     context = {
818         "name": name,
819         "bridge": bridge,
820         "mtu": mtu,
821         "domain": domain,
822         "forward": forward,
823         "nat": nat,
824         "interfaces": interfaces.split(" ") if interfaces else [],
825         "addresses": addresses_context,
826         "pf": physical_function,
827         "vport": vport_context,
828         "vlan": tag_context,
829         "dns": dns,
830         "ip_configs": [
831             {
832                 "address": ipaddress.ip_network(config["cidr"]),
833                 "dhcp_ranges": config.get("dhcp_ranges", []),
834                 "hosts": config.get("hosts", {}),
835                 "bootp": config.get("bootp", {}),
836                 "tftp": config.get("tftp"),
837             }
838             for config in ip_configs or []
839         ],
840         "yesno": lambda v: "yes" if v else "no",
841     }
842     fn_ = "libvirt_network.jinja"
843     try:
844         template = JINJA.get_template(fn_)
845     except jinja2.exceptions.TemplateNotFound:
846         log.error("Could not load template %s", fn_)
847         return ""
848     return template.render(**context)
849 def _gen_pool_xml(
850     name,
851     ptype,
852     target=None,
853     permissions=None,
854     source_devices=None,
855     source_dir=None,
856     source_adapter=None,
857     source_hosts=None,
858     source_auth=None,
859     source_name=None,
860     source_format=None,
861     source_initiator=None,
862 ):
863     hosts = [host.split(":") for host in source_hosts or []]
864     source = None
865     if any(
866         [
867             source_devices,
868             source_dir,
869             source_adapter,
870             hosts,
871             source_auth,
872             source_name,
873             source_format,
874             source_initiator,
875         ]
876     ):
877         source = {
878             "devices": source_devices or [],
879             "dir": source_dir
880             if source_format != "cifs" or not source_dir
881             else source_dir.lstrip("/"),
882             "adapter": source_adapter,
883             "hosts": [
884                 {"name": host[0], "port": host[1] if len(host) &gt; 1 else None}
885                 for host in hosts
886             ],
887             "auth": source_auth,
888             "name": source_name,
889             "format": source_format,
890             "initiator": source_initiator,
891         }
892     context = {
893         "name": name,
894         "ptype": ptype,
895         "target": {"path": target, "permissions": permissions},
896         "source": source,
897     }
898     fn_ = "libvirt_pool.jinja"
899     try:
900         template = JINJA.get_template(fn_)
901     except jinja2.exceptions.TemplateNotFound:
902         log.error("Could not load template %s", fn_)
903         return ""
904     return template.render(**context)
905 def _gen_secret_xml(auth_type, usage, description):
906     context = {
907         "type": auth_type,
908         "usage": usage,
909         "description": description,
910     }
911     fn_ = "libvirt_secret.jinja"
912     try:
913         template = JINJA.get_template(fn_)
914     except jinja2.exceptions.TemplateNotFound:
915         log.error("Could not load template %s", fn_)
916         return ""
917     return template.render(**context)
918 def _get_images_dir():
919     img_dir = __salt__["config.get"]("virt:images")
920     log.debug("Image directory from config option `virt:images` is %s", img_dir)
921     return img_dir
922 def _zfs_image_create(
923     vm_name,
924     pool,
925     disk_name,
926     hostname_property_name,
927     sparse_volume,
928     disk_size,
929     disk_image_name,
930 ):
931     if not disk_image_name and not disk_size:
932         raise CommandExecutionError(
933             "Unable to create new disk {}, please specify"
934             " the disk image name or disk size argument".format(disk_name)
935         )
936     if not pool:
937         raise CommandExecutionError(
938             "Unable to create new disk {}, please specify the disk pool name".format(
939                 disk_name
940             )
941         )
942     destination_fs = os.path.join(pool, "{}.{}".format(vm_name, disk_name))
943     log.debug("Image destination will be %s", destination_fs)
944     existing_disk = __salt__["zfs.list"](name=pool)
945     if "error" in existing_disk:
946         raise CommandExecutionError(
947             "Unable to create new disk {}. {}".format(
948                 destination_fs, existing_disk["error"]
949             )
950         )
951     elif destination_fs in existing_disk:
952         log.info("ZFS filesystem %s already exists. Skipping creation", destination_fs)
953         blockdevice_path = os.path.join("/dev/zvol", pool, vm_name)
954         return blockdevice_path
955     properties = {}
956     if hostname_property_name:
957         properties[hostname_property_name] = vm_name
958     if disk_image_name:
959         __salt__["zfs.clone"](
960             name_a=disk_image_name, name_b=destination_fs, properties=properties
961         )
962     elif disk_size:
963         __salt__["zfs.create"](
964             name=destination_fs,
965             properties=properties,
966             volume_size=disk_size,
967             sparse=sparse_volume,
968         )
969     blockdevice_path = os.path.join(
970         "/dev/zvol", pool, "{}.{}".format(vm_name, disk_name)
971     )
972     log.debug("Image path will be %s", blockdevice_path)
973     return blockdevice_path
974 def _qemu_image_create(disk, create_overlay=False, saltenv="base"):
975     disk_size = disk.get("size", None)
976     disk_image = disk.get("image", None)
977     if not disk_size and not disk_image:
978         raise CommandExecutionError(
979             "Unable to create new disk {}, please specify"
980             " disk size and/or disk image argument".format(disk["filename"])
981         )
982     img_dest = disk["source_file"]
983     log.debug("Image destination will be %s", img_dest)
984     img_dir = os.path.dirname(img_dest)
985     log.debug("Image destination directory is %s", img_dir)
986     if not os.path.exists(img_dir):
987         os.makedirs(img_dir)
988     if disk_image:
989         log.debug("Create disk from specified image %s", disk_image)
990         sfn = __salt__["cp.cache_file"](disk_image, saltenv)
991         qcow2 = False
992         if salt.utils.path.which("qemu-img"):
993             res = __salt__["cmd.run"]('qemu-img info "{}"'.format(sfn))
994             imageinfo = salt.utils.yaml.safe_load(res)
995             qcow2 = imageinfo["file format"] == "qcow2"
996         try:
997             if create_overlay and qcow2:
998                 log.info("Cloning qcow2 image %s using copy on write", sfn)
999                 __salt__["cmd.run"](
1000                     'qemu-img create -f qcow2 -o backing_file="{}" "{}"'.format(
1001                         sfn, img_dest
1002                     ).split()
1003                 )
1004             else:
1005                 log.debug("Copying %s to %s", sfn, img_dest)
1006                 salt.utils.files.copyfile(sfn, img_dest)
1007             mask = salt.utils.files.get_umask()
1008             if disk_size and qcow2:
1009                 log.debug("Resize qcow2 image to %sM", disk_size)
1010                 __salt__["cmd.run"](
1011                     'qemu-img resize "{}" {}M'.format(img_dest, disk_size)
1012                 )
1013             log.debug("Apply umask and remove exec bit")
1014             mode = (0o0777 ^ mask) &amp; 0o0666
1015             os.chmod(img_dest, mode)
1016         except OSError as err:
1017             raise CommandExecutionError(
1018                 "Problem while copying image. {} - {}".format(disk_image, err)
1019             )
1020     else:
1021         try:
1022             mask = salt.utils.files.get_umask()
1023             if disk_size:
1024                 log.debug("Create empty image with size %sM", disk_size)
1025                 __salt__["cmd.run"](
1026                     'qemu-img create -f {} "{}" {}M'.format(
1027                         disk.get("format", "qcow2"), img_dest, disk_size
1028                     )
1029                 )
1030             else:
1031                 raise CommandExecutionError(
1032                     "Unable to create new disk {},"
1033                     " please specify &lt;size&gt; argument".format(img_dest)
1034                 )
1035             log.debug("Apply umask and remove exec bit")
1036             mode = (0o0777 ^ mask) &amp; 0o0666
1037             os.chmod(img_dest, mode)
1038         except OSError as err:
1039             raise CommandExecutionError(
1040                 "Problem while creating volume {} - {}".format(img_dest, err)
1041             )
1042     return img_dest
1043 def _seed_image(seed_cmd, img_path, name, config, install, pub_key, priv_key):
1044     log.debug("Seeding image")
1045     __salt__[seed_cmd](
1046         img_path,
1047         id_=name,
1048         config=config,
1049         install=install,
1050         pub_key=pub_key,
1051         priv_key=priv_key,
1052     )
1053 def _disk_volume_create(conn, disk, seeder=None, saltenv="base"):
1054     if disk.get("overlay_image"):
1055         raise SaltInvocationError(
1056             "Disk overlay_image property is not supported when creating volumes,"
1057             "use backing_store_path and backing_store_format instead."
1058         )
1059     pool = conn.storagePoolLookupByName(disk["pool"])
1060     if disk["filename"] in pool.listVolumes():
1061         return
1062     pool_type = ElementTree.fromstring(pool.XMLDesc()).get("type")
1063     backing_path = disk.get("backing_store_path")
1064     backing_format = disk.get("backing_store_format")
1065     backing_store = None
1066     if (
1067         backing_path
1068         and backing_format
1069         and (disk.get("format") == "qcow2" or pool_type == "logical")
1070     ):
1071         backing_store = {"path": backing_path, "format": backing_format}
1072     if backing_store and disk.get("image"):
1073         raise SaltInvocationError(
1074             "Using a template image with a backing store is not possible, "
1075             "choose either of them."
1076         )
1077     vol_xml = _gen_vol_xml(
1078         disk["filename"],
1079         disk.get("size", 0),
1080         format=disk.get("format"),
1081         backing_store=backing_store,
1082     )
1083     _define_vol_xml_str(conn, vol_xml, disk.get("pool"))
1084     if disk.get("image"):
1085         log.debug("Caching disk template image: %s", disk.get("image"))
1086         cached_path = __salt__["cp.cache_file"](disk.get("image"), saltenv)
1087         if seeder:
1088             seeder(cached_path)
1089         _volume_upload(
1090             conn,
1091             disk["pool"],
1092             disk["filename"],
1093             cached_path,
1094             sparse=disk.get("format") == "qcow2",
1095         )
1096 def _disk_profile(conn, profile, hypervisor, disks, vm_name):
1097     default = [{"system": {"size": 8192}}]
1098     if hypervisor == "vmware":
1099         overlay = {"format": "vmdk", "model": "scsi", "device": "disk"}
1100     elif hypervisor in ["qemu", "kvm"]:
1101         overlay = {"device": "disk", "model": "virtio"}
1102     elif hypervisor == "xen":
1103         overlay = {"device": "disk", "model": "xen"}
1104     elif hypervisor == "bhyve":
1105         overlay = {"format": "raw", "model": "virtio", "sparse_volume": False}
1106     else:
1107         overlay = {}
1108     disklist = []
1109     if profile:
1110         disklist = copy.deepcopy(
1111             __salt__["config.get"]("virt:disk", {}).get(profile, default)
1112         )
1113         disklist = [dict(d, name=name) for disk in disklist for name, d in disk.items()]
1114     if disks:
1115         for udisk in disks:
1116             if "name" in udisk:
1117                 found = [disk for disk in disklist if udisk["name"] == disk["name"]]
1118                 if found:
1119                     found[0].update(udisk)
1120                 else:
1121                     disklist.append(udisk)
1122     pool_caps = _pool_capabilities(conn)
1123     for disk in disklist:
1124         if disk.get("device", "disk") == "cdrom" and "model" not in disk:
1125             disk["model"] = "ide"
1126         for key, val in overlay.items():
1127             if key not in disk:
1128                 disk[key] = val
1129         if disk.get("source_file") and os.path.exists(disk["source_file"]):
1130             disk["filename"] = os.path.basename(disk["source_file"])
1131             if not disk.get("format"):
1132                 disk["format"] = (
1133                     "qcow2" if disk.get("device", "disk") != "cdrom" else "raw"
1134                 )
1135         elif vm_name and disk.get("device", "disk") == "disk":
1136             _fill_disk_filename(conn, vm_name, disk, hypervisor, pool_caps)
1137     return disklist
1138 def _fill_disk_filename(conn, vm_name, disk, hypervisor, pool_caps):
1139     disk["filename"] = "{}_{}".format(vm_name, disk["name"])
1140     base_dir = disk.get("pool", None)
1141     if hypervisor in ["qemu", "kvm", "xen"]:
1142         if not base_dir:
1143             base_dir = _get_images_dir()
1144         if base_dir not in conn.listStoragePools():
1145             if not disk.get("format"):
1146                 disk["format"] = "qcow2"
1147             disk["filename"] = "{}.{}".format(disk["filename"], disk["format"])
1148             disk["source_file"] = os.path.join(base_dir, disk["filename"])
1149         else:
1150             if "pool" not in disk:
1151                 disk["pool"] = base_dir
1152             pool_obj = conn.storagePoolLookupByName(base_dir)
1153             pool_xml = ElementTree.fromstring(pool_obj.XMLDesc())
1154             pool_type = pool_xml.get("type")
1155             if pool_type == "disk":
1156                 device = pool_xml.find("./source/device").get("path")
1157                 all_volumes = pool_obj.listVolumes()
1158                 if disk.get("source_file") not in all_volumes:
1159                     indexes = [
1160                         int(re.sub("[a-z]+", "", vol_name)) for vol_name in all_volumes
1161                     ] or [0]
1162                     index = min(
1163                         idx for idx in range(1, max(indexes) + 2) if idx not in indexes
1164                     )
1165                     disk["filename"] = "{}{}".format(os.path.basename(device), index)
1166             if disk.get("source_file"):
1167                 if not disk.get("source_file") in pool_obj.listVolumes():
1168                     raise SaltInvocationError(
1169                         "{} volume doesn't exist in pool {}".format(
1170                             disk.get("source_file"), base_dir
1171                         )
1172                     )
1173                 disk["filename"] = disk["source_file"]
1174                 del disk["source_file"]
1175             if not disk.get("format"):
1176                 volume_options = (
1177                     [
1178                         type_caps.get("options", {}).get("volume", {})
1179                         for type_caps in pool_caps.get("pool_types")
1180                         if type_caps["name"] == pool_type
1181                     ]
1182                     or [{}]
1183                 )[0]
1184                 if "qcow2" in volume_options.get("targetFormatType", []):
1185                     disk["format"] = "qcow2"
1186                 else:
1187                     disk["format"] = volume_options.get("default_format", None)
1188     elif hypervisor == "bhyve" and vm_name:
1189         disk["filename"] = "{}.{}".format(vm_name, disk["name"])
1190         disk["source_file"] = os.path.join(
1191             "/dev/zvol", base_dir or "", disk["filename"]
1192         )
1193     elif hypervisor in ["esxi", "vmware"]:
1194         if not base_dir:
1195             base_dir = __salt__["config.get"]("virt:storagepool", "[0] ")
1196         disk["filename"] = "{}.{}".format(disk["filename"], disk["format"])
1197         disk["source_file"] = "{}{}".format(base_dir, disk["filename"])
1198 def _complete_nics(interfaces, hypervisor):
1199     vmware_overlay = {"type": "bridge", "source": "DEFAULT", "model": "e1000"}
1200     kvm_overlay = {"type": "bridge", "source": "br0", "model": "virtio"}
1201     xen_overlay = {"type": "bridge", "source": "br0", "model": None}
1202     bhyve_overlay = {"type": "bridge", "source": "bridge0", "model": "virtio"}
1203     overlays = {
1204         "xen": xen_overlay,
1205         "kvm": kvm_overlay,
1206         "qemu": kvm_overlay,
1207         "vmware": vmware_overlay,
1208         "bhyve": bhyve_overlay,
1209     }
1210     def _normalize_net_types(attributes):
1211         for type_ in ["bridge", "network"]:
1212             if type_ in attributes:
1213                 attributes["type"] = type_
1214                 attributes["source"] = attributes.pop(type_)
1215         attributes["type"] = attributes.get("type", None)
1216         attributes["source"] = attributes.get("source", None)
1217     def _apply_default_overlay(attributes):
1218         for key, value in overlays[hypervisor].items():
1219             if key not in attributes or not attributes[key]:
1220                 attributes[key] = value
1221     for interface in interfaces:
1222         _normalize_net_types(interface)
1223         if hypervisor in overlays:
1224             _apply_default_overlay(interface)
1225     return interfaces
1226 def _nic_profile(profile_name, hypervisor):
1227     config_data = __salt__["config.get"]("virt:nic", {}).get(
1228         profile_name, [{"eth0": {}}]
1229     )
1230     interfaces = []
1231     def append_dict_profile_to_interface_list(profile_dict):
1232         for interface_name, attributes in profile_dict.items():
1233             attributes["name"] = interface_name
1234             interfaces.append(attributes)
1235     if isinstance(config_data, dict):
1236         append_dict_profile_to_interface_list(config_data)
1237     elif isinstance(config_data, list):
1238         for interface in config_data:
1239             if isinstance(interface, dict):
1240                 if len(interface) == 1:
1241                     append_dict_profile_to_interface_list(interface)
1242                 else:
1243                     interfaces.append(interface)
1244     return _complete_nics(interfaces, hypervisor)
1245 def _get_merged_nics(hypervisor, profile, interfaces=None):
1246     nicp = _nic_profile(profile, hypervisor) if profile else []
1247     log.debug("NIC profile is %s", nicp)
1248     if interfaces:
1249         users_nics = _complete_nics(interfaces, hypervisor)
1250         for unic in users_nics:
1251             found = [nic for nic in nicp if nic["name"] == unic["name"]]
1252             if found:
1253                 found[0].update(unic)
1254             else:
1255                 nicp.append(unic)
1256         log.debug("Merged NICs: %s", nicp)
1257     return nicp
1258 def _handle_remote_boot_params(orig_boot):
1259     saltinst_dir = None
1260     new_boot = orig_boot.copy()
1261     keys = orig_boot.keys()
1262     cases = [
1263         {"efi"},
1264         {"kernel", "initrd", "efi"},
1265         {"kernel", "initrd", "cmdline", "efi"},
1266         {"loader", "nvram"},
1267         {"kernel", "initrd"},
1268         {"kernel", "initrd", "cmdline"},
1269         {"kernel", "initrd", "loader", "nvram"},
1270         {"kernel", "initrd", "cmdline", "loader", "nvram"},
1271     ]
1272     if keys in cases:
1273         for key in keys:
1274             if key == "efi" and type(orig_boot.get(key)) == bool:
1275                 new_boot[key] = orig_boot.get(key)
1276             elif orig_boot.get(key) is not None and salt.utils.virt.check_remote(
1277                 orig_boot.get(key)
1278             ):
1279                 if saltinst_dir is None:
1280                     os.makedirs(CACHE_DIR)
1281                     saltinst_dir = CACHE_DIR
1282                 new_boot[key] = salt.utils.virt.download_remote(
1283                     orig_boot.get(key), saltinst_dir
1284                 )
1285         return new_boot
1286     else:
1287         raise SaltInvocationError(
1288             "Invalid boot parameters,It has to follow this combination: [(kernel,"
1289             " initrd) or/and cmdline] or/and [(loader, nvram) or efi]"
1290         )
1291 def _handle_efi_param(boot, desc):
1292     efi_value = boot.get("efi", None) if boot else None
1293     parent_tag = desc.find("os")
1294     os_attrib = parent_tag.attrib
1295     if efi_value is False and os_attrib != {}:
1296         parent_tag.attrib.pop("firmware", None)
1297         return True
1298     elif type(efi_value) == bool and os_attrib == {}:
1299         if efi_value is True and parent_tag.find("loader") is None:
1300             parent_tag.set("firmware", "efi")
1301             return True
1302         if efi_value is False and parent_tag.find("loader") is not None:
1303             parent_tag.remove(parent_tag.find("loader"))
1304             parent_tag.remove(parent_tag.find("nvram"))
1305             return True
1306     elif type(efi_value) != bool:
1307         raise SaltInvocationError("Invalid efi value")
1308     return False
1309 def init(
1310     name,
1311     cpu,
1312     mem,
1313     nic="default",
1314     interfaces=None,
1315     hypervisor=None,
1316     start=True,  # pylint: disable=redefined-outer-name
1317     disk="default",
1318     disks=None,
1319     saltenv="base",
1320     seed=True,
1321     install=True,
1322     pub_key=None,
1323     priv_key=None,
1324     seed_cmd="seed.apply",
1325     graphics=None,
1326     os_type=None,
1327     arch=None,
1328     boot=None,
1329     boot_dev=None,
1330     numatune=None,
1331     hypervisor_features=None,
1332     clock=None,
1333     serials=None,
1334     consoles=None,
1335     stop_on_reboot=False,
1336     host_devices=None,
1337     **kwargs
1338 ):
1339     try:
1340         conn = __get_conn(**kwargs)
1341         caps = _capabilities(conn)
1342         os_types = sorted({guest["os_type"] for guest in caps["guests"]})
1343         arches = sorted({guest["arch"]["name"] for guest in caps["guests"]})
1344         virt_hypervisor = hypervisor
1345         if not virt_hypervisor:
1346             hypervisors = sorted(
1347                 {
1348                     x
1349                     for y in [
1350                         guest["arch"]["domains"].keys() for guest in caps["guests"]
1351                     ]
1352                     for x in y
1353                 }
1354             )
1355             if len(hypervisors) == 0:
1356                 raise SaltInvocationError("No supported hypervisors were found")
1357             virt_hypervisor = "kvm" if "kvm" in hypervisors else hypervisors[0]
1358         virt_hypervisor = "vmware" if virt_hypervisor == "esxi" else virt_hypervisor
1359         log.debug("Using hypervisor %s", virt_hypervisor)
1360         nicp = _get_merged_nics(virt_hypervisor, nic, interfaces)
1361         diskp = _disk_profile(conn, disk, virt_hypervisor, disks, name)
1362         for _disk in diskp:
1363             if _disk.get("device", "disk") == "cdrom":
1364                 continue
1365             log.debug("Creating disk for VM [ %s ]: %s", name, _disk)
1366             if virt_hypervisor == "vmware":
1367                 if "image" in _disk:
1368                     raise SaltInvocationError(
1369                         "virt.init does not support image "
1370                         "template in conjunction with esxi hypervisor"
1371                     )
1372                 else:
1373                     log.debug("Generating libvirt XML for %s", _disk)
1374                     volume_name = "{}/{}".format(name, _disk["name"])
1375                     filename = "{}.{}".format(volume_name, _disk["format"])
1376                     vol_xml = _gen_vol_xml(
1377                         filename, _disk["size"], format=_disk["format"]
1378                     )
1379                     _define_vol_xml_str(conn, vol_xml, pool=_disk.get("pool"))
1380             elif virt_hypervisor in ["qemu", "kvm", "xen"]:
1381                 def seeder(path):
1382                     _seed_image(
1383                         seed_cmd,
1384                         path,
1385                         name,
1386                         kwargs.get("config"),
1387                         install,
1388                         pub_key,
1389                         priv_key,
1390                     )
1391                 create_overlay = _disk.get("overlay_image", False)
1392                 format = _disk.get("format")
1393                 if _disk.get("source_file"):
1394                     if os.path.exists(_disk["source_file"]):
1395                         img_dest = _disk["source_file"]
1396                     else:
1397                         img_dest = _qemu_image_create(_disk, create_overlay, saltenv)
1398                 else:
1399                     _disk_volume_create(conn, _disk, seeder if seed else None, saltenv)
1400                     img_dest = None
1401                 if seed and img_dest and _disk.get("image", None):
1402                     seeder(img_dest)
1403             elif hypervisor in ["bhyve"]:
1404                 img_dest = _zfs_image_create(
1405                     vm_name=name,
1406                     pool=_disk.get("pool"),
1407                     disk_name=_disk.get("name"),
1408                     disk_size=_disk.get("size"),
1409                     disk_image_name=_disk.get("image"),
1410                     hostname_property_name=_disk.get("hostname_property"),
1411                     sparse_volume=_disk.get("sparse_volume"),
1412                 )
1413             else:
1414                 raise SaltInvocationError(
1415                     "Unsupported hypervisor when handling disk image: {}".format(
1416                         virt_hypervisor
1417                     )
1418                 )
1419         log.debug("Generating VM XML")
1420         if os_type is None:
1421             os_type = "hvm" if "hvm" in os_types else os_types[0]
1422         if arch is None:
1423             arch = "x86_64" if "x86_64" in arches else arches[0]
1424         if boot is not None:
1425             boot = _handle_remote_boot_params(boot)
1426         vm_xml = _gen_xml(
1427             conn,
1428             name,
1429             cpu,
1430             mem,
1431             diskp,
1432             nicp,
1433             virt_hypervisor,
1434             os_type,
1435             arch,
1436             graphics,
1437             boot,
1438             boot_dev,
1439             numatune,
1440             hypervisor_features,
1441             clock,
1442             serials,
1443             consoles,
1444             stop_on_reboot,
1445             host_devices,
1446             **kwargs
1447         )
1448         log.debug("New virtual machine definition: %s", vm_xml)
1449         conn.defineXML(vm_xml)
1450     except libvirt.libvirtError as err:
1451         conn.close()
1452         raise CommandExecutionError(err.get_error_message())
1453     if start:
1454         log.debug("Starting VM %s", name)
1455         _get_domain(conn, name).create()
1456     conn.close()
1457     return True
1458 def _disks_equal(disk1, disk2):
1459     target1 = disk1.find("target")
1460     target2 = disk2.find("target")
1461     disk1_dict = xmlutil.to_dict(disk1, True)
1462     disk2_dict = xmlutil.to_dict(disk2, True)
1463     source1_dict = disk1_dict.get("source", {})
1464     source2_dict = disk2_dict.get("source", {})
1465     io1 = disk1_dict.get("driver", {}).get("io", "native")
1466     io2 = disk2_dict.get("driver", {}).get("io", "native")
1467     if source1_dict:
1468         source1_dict.pop("index", None)
1469     if source2_dict:
1470         source2_dict.pop("index", None)
1471     return (
1472 <a name="3"></a>        source1_dict == source2_dict
1473         and target1 is not None
1474         and target2 is not None
1475         and target1<font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.get("bus") == target2.get("bus")
1476         and disk1.get("device", "disk") == disk2.get("device", "disk")
1477         and target1.get("dev") == target2.get(</b></font>"dev")
1478         and io1 == io2
1479     )
1480 def _nics_equal(nic1, nic2):
1481     def _filter_nic(nic):
1482         source_node = nic.find("source")
1483         source_attrib = source_node.attrib if source_node is not None else {}
1484         source_type = "network" if "network" in source_attrib else nic.attrib["type"]
1485         source_getters = {
1486             "network": lambda n: n.get("network"),
1487             "bridge": lambda n: n.get("bridge"),
1488             "direct": lambda n: n.get("dev"),
1489             "hostdev": lambda n: _format_pci_address(n.find("address")),
1490         }
1491         return {
1492             "type": source_type,
1493             "source": source_getters[source_type](source_node)
1494             if source_node is not None
1495             else None,
1496             "model": nic.find("model").attrib["type"]
1497             if nic.find("model") is not None
1498             else None,
1499         }
1500     def _get_mac(nic):
1501         return (
1502             nic.find("mac").attrib["address"].lower()
1503             if nic.find("mac") is not None
1504             else None
1505         )
1506     mac1 = _get_mac(nic1)
1507     mac2 = _get_mac(nic2)
1508     macs_equal = not mac1 or not mac2 or mac1 == mac2
1509     return _filter_nic(nic1) == _filter_nic(nic2) and macs_equal
1510 def _graphics_equal(gfx1, gfx2):
1511     def _filter_graphics(gfx):
1512         gfx_copy = copy.deepcopy(gfx)
1513         defaults = [
1514             {"node": ".", "attrib": "port", "values": ["5900", "-1"]},
1515             {"node": ".", "attrib": "address", "values": ["127.0.0.1"]},
1516             {"node": "listen", "attrib": "address", "values": ["127.0.0.1"]},
1517         ]
1518         for default in defaults:
1519             node = gfx_copy.find(default["node"])
1520             attrib = default["attrib"]
1521             if node is not None and (
1522                 attrib in node.attrib and node.attrib[attrib] in default["values"]
1523             ):
1524                 node.attrib.pop(attrib)
1525         return gfx_copy
1526     return xmlutil.to_dict(_filter_graphics(gfx1), True) == xmlutil.to_dict(
1527         _filter_graphics(gfx2), True
1528     )
1529 def _hostdevs_equal(dev1, dev2):
1530     def _filter_hostdevs(dev):
1531         type_ = dev.get("type")
1532         definition = {
1533             "type": type_,
1534         }
1535         if type_ == "pci":
1536             address_node = dev.find("./source/address")
1537             for attr in ["domain", "bus", "slot", "function"]:
1538                 definition[attr] = address_node.get(attr)
1539         elif type_ == "usb":
1540             for attr in ["vendor", "product"]:
1541                 definition[attr] = dev.find("./source/" + attr).get("id")
1542         return definition
1543     return _filter_hostdevs(dev1) == _filter_hostdevs(dev2)
1544 def _diff_lists(old, new, comparator):
1545     def _remove_indent(node):
1546         node_copy = copy.deepcopy(node)
1547         node_copy.text = None
1548         for item in node_copy.iter():
1549             item.tail = None
1550         return node_copy
1551     diff = {"unchanged": [], "new": [], "deleted": [], "sorted": []}
1552     old_devices = copy.deepcopy(old)
1553     for new_item in new:
1554         found = [
1555             item
1556             for item in old_devices
1557             if comparator(_remove_indent(item), _remove_indent(new_item))
1558         ]
1559         if found:
1560             old_devices.remove(found[0])
1561             diff["unchanged"].append(found[0])
1562             diff["sorted"].append(found[0])
1563         else:
1564             diff["new"].append(new_item)
1565             diff["sorted"].append(new_item)
1566     diff["deleted"] = old_devices
1567     return diff
1568 def _get_disk_target(targets, disks_count, prefix):
1569     for i in range(disks_count):
1570         ret = "{}{}".format(prefix, string.ascii_lowercase[i])
1571         if ret not in targets:
1572             return ret
1573     return None
1574 def _diff_disk_lists(old, new):
1575     targets = []
1576     prefixes = ["fd", "hd", "vd", "sd", "xvd", "ubd"]
1577     for disk in new:
1578         target_node = disk.find("target")
1579         target = target_node.get("dev")
1580         prefix = [item for item in prefixes if target.startswith(item)][0]
1581         new_target = _get_disk_target(targets, len(new), prefix)
1582         target_node.set("dev", new_target)
1583         targets.append(new_target)
1584     return _diff_lists(old, new, _disks_equal)
1585 def _diff_interface_lists(old, new):
1586     return _diff_lists(old, new, _nics_equal)
1587 def _diff_graphics_lists(old, new):
1588     return _diff_lists(old, new, _graphics_equal)
1589 def _diff_hostdev_lists(old, new):
1590     return _diff_lists(old, new, _hostdevs_equal)
1591 def _expand_cpuset(cpuset):
1592     if cpuset is None:
1593         return None
1594     if isinstance(cpuset, int):
1595         return str(cpuset)
1596     result = set()
1597     toremove = set()
1598     for part in cpuset.split(","):
1599         m = re.match("([0-9]+)-([0-9]+)", part)
1600         if m:
1601             result |= set(range(int(m.group(1)), int(m.group(2)) + 1))
1602         elif part.startswith("^"):
1603             toremove.add(int(part[1:]))
1604         else:
1605             result.add(int(part))
1606     cpus = list(result - toremove)
1607     cpus.sort()
1608     cpus = [str(cpu) for cpu in cpus]
1609     return ",".join(cpus)
1610 def _normalize_cpusets(desc, data):
1611     xpaths = ["cputune/cachetune", "cputune/cachetune/monitor", "cputune/memorytune"]
1612     for xpath in xpaths:
1613         nodes = desc.findall(xpath)
1614         for node in nodes:
1615             node.set("vcpus", _expand_cpuset(node.get("vcpus")))
1616     if not isinstance(data.get("cpu"), dict):
1617         return
1618     tuning = data["cpu"].get("tuning", {})
1619     for child in ["cachetune", "memorytune"]:
1620         if tuning.get(child):
1621             new_item = dict()
1622             for cpuset, value in tuning[child].items():
1623                 if child == "cachetune" and value.get("monitor"):
1624                     value["monitor"] = {
1625                         _expand_cpuset(monitor_cpus): monitor
1626                         for monitor_cpus, monitor in value["monitor"].items()
1627                     }
1628                 new_item[_expand_cpuset(cpuset)] = value
1629             tuning[child] = new_item
1630 def _serial_or_concole_equal(old, new):
1631     def _filter_serial_or_concole(item):
1632         return {
1633             "type": item.attrib["type"],
1634             "port": item.find("source").get("service")
1635             if item.find("source") is not None
1636             else None,
1637             "protocol": item.find("protocol").get("type")
1638             if item.find("protocol") is not None
1639             else None,
1640         }
1641     return _filter_serial_or_concole(old) == _filter_serial_or_concole(new)
1642 def _diff_serial_lists(old, new):
1643     return _diff_lists(old, new, _serial_or_concole_equal)
1644 def _diff_console_lists(old, new):
1645     return _diff_lists(old, new, _serial_or_concole_equal)
1646 <a name="1"></a>
1647 def _format_pci_address(node):
1648     return "{}:{}:{}.{}"<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.format(
1649         node.get("domain").replace("0x", ""),
1650         node.get("bus").replace("0x", ""),
1651         node.get("slot").replace("0x", ""),
1652         node.get("function").replace(</b></font>"0x", ""),
1653     )
1654 def _almost_equal(current, new):
1655     if current is None or new is None:
1656         return False
1657     return abs(current - new) / current &lt; 1e-03
1658 def _compute_device_changes(old_xml, new_xml, to_skip):
1659     devices_node = old_xml.find("devices")
1660     changes = {}
1661     for dev_type in to_skip:
1662         changes[dev_type] = {}
1663         if not to_skip[dev_type]:
1664             old = devices_node.findall(dev_type)
1665             new = new_xml.findall("devices/{}".format(dev_type))
1666             changes[dev_type] = globals()["_diff_{}_lists".format(dev_type)](old, new)
1667     return changes
1668 def _get_pci_addresses(node):
1669     return {_format_pci_address(address) for address in node.findall(".//address")}
1670 def _correct_networks(conn, desc):
1671     networks = [ElementTree.fromstring(net.XMLDesc()) for net in conn.listAllNetworks()]
1672     nics = desc.findall("devices/interface")
1673     device_map = {}
1674     for nic in nics:
1675         if nic.get("type") == "hostdev":
1676             addr = _get_pci_addresses(nic.find("source"))
1677             matching_nets = [
1678                 net
1679                 for net in networks
1680                 if net.find("forward").get("mode") == "hostdev"
1681                 and addr &amp; _get_pci_addresses(net)
1682             ]
1683             if matching_nets:
1684                 old_xml = ElementTree.tostring(nic)
1685                 nic.set("type", "network")
1686                 nic.find("source").set("network", matching_nets[0].find("name").text)
1687                 device_map[nic] = old_xml
1688     return device_map
1689 def _update_live(domain, new_desc, mem, cpu, old_mem, old_cpu, to_skip, test):
1690     status = {}
1691     errors = []
1692     if not domain.isActive():
1693         return status, errors
1694     commands = []
1695     if cpu and (isinstance(cpu, int) or isinstance(cpu, dict) and cpu.get("maximum")):
1696         new_cpu = cpu.get("maximum") if isinstance(cpu, dict) else cpu
1697         if old_cpu != new_cpu and new_cpu is not None:
1698             commands.append(
1699                 {
1700                     "device": "cpu",
1701                     "cmd": "setVcpusFlags",
1702                     "args": [new_cpu, libvirt.VIR_DOMAIN_AFFECT_LIVE],
1703                 }
1704             )
1705     if mem:
1706         if isinstance(mem, dict):
1707             new_mem = (
1708                 int(_handle_unit(mem.get("current")) / 1024)
1709                 if "current" in mem
1710                 else None
1711             )
1712         elif isinstance(mem, int):
1713             new_mem = int(mem * 1024)
1714         if not _almost_equal(old_mem, new_mem) and new_mem is not None:
1715             commands.append(
1716                 {
1717                     "device": "mem",
1718                     "cmd": "setMemoryFlags",
1719                     "args": [new_mem, libvirt.VIR_DOMAIN_AFFECT_LIVE],
1720                 }
1721             )
1722     old_desc = ElementTree.fromstring(domain.XMLDesc(0))
1723     changed_devices = {"interface": _correct_networks(domain.connect(), old_desc)}
1724     changes = _compute_device_changes(old_desc, new_desc, to_skip)
1725     removable_changes = []
1726     new_disks = []
1727     for new_disk in changes["disk"].get("new", []):
1728         device = new_disk.get("device", "disk")
1729         if device not in ["cdrom", "floppy"]:
1730             new_disks.append(new_disk)
1731             continue
1732         target_dev = new_disk.find("target").get("dev")
1733         matching = [
1734             old_disk
1735             for old_disk in changes["disk"].get("deleted", [])
1736             if old_disk.get("device", "disk") == device
1737             and old_disk.find("target").get("dev") == target_dev
1738         ]
1739         if not matching:
1740             new_disks.append(new_disk)
1741         else:
1742             updated_disk = matching[0]
1743             changes["disk"]["deleted"].remove(updated_disk)
1744             removable_changes.append(updated_disk)
1745             source_node = updated_disk.find("source")
1746             new_source_node = new_disk.find("source")
1747             source_file = (
1748                 new_source_node.get("file") if new_source_node is not None else None
1749             )
1750             updated_disk.set("type", "file")
1751             if source_node is not None:
1752                 updated_disk.remove(source_node)
1753             if source_file:
1754                 ElementTree.SubElement(
1755                     updated_disk, "source", attrib={"file": source_file}
1756                 )
1757     changes["disk"]["new"] = new_disks
1758     for dev_type in ["disk", "interface", "hostdev"]:
1759         for added in changes[dev_type].get("new", []):
1760             commands.append(
1761                 {
1762                     "device": dev_type,
1763                     "cmd": "attachDevice",
1764                     "args": [xmlutil.element_to_str(added)],
1765                 }
1766             )
1767         for removed in changes[dev_type].get("deleted", []):
1768             removed_def = changed_devices.get(dev_type, {}).get(
1769                 removed, ElementTree.tostring(removed)
1770             )
1771             commands.append(
1772                 {
1773                     "device": dev_type,
1774                     "cmd": "detachDevice",
1775                     "args": [salt.utils.stringutils.to_str(removed_def)],
1776                 }
1777             )
1778     for updated_disk in removable_changes:
1779         commands.append(
1780             {
1781                 "device": "disk",
1782                 "cmd": "updateDeviceFlags",
1783                 "args": [xmlutil.element_to_str(updated_disk)],
1784             }
1785         )
1786     for cmd in commands:
1787         try:
1788             ret = 0 if test else getattr(domain, cmd["cmd"])(*cmd["args"])
1789             device_type = cmd["device"]
1790             if device_type in ["cpu", "mem"]:
1791                 status[device_type] = not ret
1792             else:
1793                 actions = {
1794                     "attachDevice": "attached",
1795                     "detachDevice": "detached",
1796                     "updateDeviceFlags": "updated",
1797                 }
1798                 device_status = status.setdefault(device_type, {})
1799                 cmd_status = device_status.setdefault(actions[cmd["cmd"]], [])
1800                 cmd_status.append(cmd["args"][0])
1801         except libvirt.libvirtError as err:
1802             errors.append(str(err))
1803     return status, errors
1804 def update(
1805     name,
1806     cpu=0,
1807     mem=0,
1808     disk_profile=None,
1809     disks=None,
1810     nic_profile=None,
1811     interfaces=None,
1812     graphics=None,
1813     live=True,
1814     boot=None,
1815     numatune=None,
1816     test=False,
1817     boot_dev=None,
1818     hypervisor_features=None,
1819     clock=None,
1820     serials=None,
1821     consoles=None,
1822     stop_on_reboot=False,
1823     host_devices=None,
1824     **kwargs
1825 ):
1826     status = {
1827         "definition": False,
1828         "disk": {"attached": [], "detached": [], "updated": []},
1829         "interface": {"attached": [], "detached": []},
1830     }
1831     conn = __get_conn(**kwargs)
1832     domain = _get_domain(conn, name)
1833     desc = ElementTree.fromstring(domain.XMLDesc(libvirt.VIR_DOMAIN_XML_INACTIVE))
1834     need_update = False
1835     hypervisor = desc.get("type")
1836     all_disks = _disk_profile(conn, disk_profile, hypervisor, disks, name)
1837     if boot is not None:
1838         boot = _handle_remote_boot_params(boot)
1839         if boot.get("efi", None) is not None:
1840             need_update = _handle_efi_param(boot, desc)
1841     new_desc = ElementTree.fromstring(
1842         _gen_xml(
1843             conn,
1844             name,
1845             cpu,
1846             mem or 0,
1847             all_disks,
1848             _get_merged_nics(hypervisor, nic_profile, interfaces),
1849             hypervisor,
1850             domain.OSType(),
1851             desc.find(".//os/type").get("arch"),
1852             graphics,
1853             boot,
1854             boot_dev,
1855             numatune,
1856             serials=serials,
1857             consoles=consoles,
1858             stop_on_reboot=stop_on_reboot,
1859             host_devices=host_devices,
1860             **kwargs
1861         )
1862     )
1863     if clock:
1864         offset = "utc" if clock.get("utc", True) else "localtime"
1865         if "timezone" in clock:
1866             offset = "timezone"
1867         clock["offset"] = offset
1868     def _set_loader(node, value):
1869         salt.utils.xmlutil.set_node_text(node, value)
1870         if value is not None:
1871             node.set("readonly", "yes")
1872             node.set("type", "pflash")
1873     def _set_nvram(node, value):
1874         node.set("template", value)
1875     def _set_with_byte_unit(attr_name=None):
1876         def _setter(node, value):
1877             if attr_name:
1878                 node.set(attr_name, str(value))
1879             else:
1880                 node.text = str(value)
1881             node.set("unit", "bytes")
1882         return _setter
1883     def _get_with_unit(node):
1884         unit = node.get("unit", "KiB")
1885         unit = unit if unit != "bytes" else "b"
1886         value = node.get("memory") or node.get("size") or node.text
1887         return _handle_unit("{}{}".format(value, unit)) if value else None
1888     def _set_vcpu(node, value):
1889         node.text = str(value)
1890         node.set("current", str(value))
1891     old_mem = int(_get_with_unit(desc.find("memory")) / 1024)
1892     old_cpu = int(desc.find("./vcpu").text)
1893     def _yesno_attribute(path, xpath, attr_name, ignored=None):
1894         return xmlutil.attribute(
1895             path, xpath, attr_name, ignored, lambda v: "yes" if v else "no"
1896         )
1897     def _memory_parameter(path, xpath, attr_name=None, ignored=None):
1898         entry = {
1899             "path": path,
1900             "xpath": xpath,
1901             "convert": _handle_unit,
1902             "get": _get_with_unit,
1903             "set": _set_with_byte_unit(attr_name),
1904             "equals": _almost_equal,
1905         }
1906         if attr_name:
1907             entry["del"] = salt.utils.xmlutil.del_attribute(attr_name, ignored)
1908         return entry
1909     def _cpuset_parameter(path, xpath, attr_name=None, ignored=None):
1910         def _set_cpuset(node, value):
1911             if attr_name:
1912                 node.set(attr_name, value)
1913             else:
1914                 node.text = value
1915         entry = {
1916             "path": path,
1917             "xpath": xpath,
1918             "convert": _expand_cpuset,
1919             "get": lambda n: _expand_cpuset(n.get(attr_name) if attr_name else n.text),
1920             "set": _set_cpuset,
1921         }
1922         if attr_name:
1923             entry["del"] = salt.utils.xmlutil.del_attribute(attr_name, ignored)
1924         return entry
1925     data = {k: v for k, v in locals().items() if bool(v)}
1926     data["stop_on_reboot"] = stop_on_reboot
1927     if boot_dev:
1928         data["boot_dev"] = boot_dev.split()
1929     timer_names = [
1930         "platform",
1931         "hpet",
1932         "kvmclock",
1933         "pit",
1934         "rtc",
1935         "tsc",
1936         "hypervclock",
1937         "armvtimer",
1938     ]
1939     if data.get("clock", {}).get("timers"):
1940         attributes = [
1941             "track",
1942             "tickpolicy",
1943             "frequency",
1944             "mode",
1945             "present",
1946             "slew",
1947             "threshold",
1948             "limit",
1949         ]
1950         for timer in data["clock"]["timers"].values():
1951             for attribute in attributes:
1952                 if attribute not in timer:
1953                     timer[attribute] = None
1954         for timer_name in timer_names:
1955             if timer_name not in data["clock"]["timers"]:
1956                 data["clock"]["timers"][timer_name] = None
1957     _normalize_cpusets(desc, data)
1958     params_mapping = [
1959         {
1960             "path": "stop_on_reboot",
1961             "xpath": "on_reboot",
1962             "convert": lambda v: "destroy" if v else "restart",
1963         },
1964         {"path": "boot:kernel", "xpath": "os/kernel"},
1965         {"path": "boot:initrd", "xpath": "os/initrd"},
1966         {"path": "boot:cmdline", "xpath": "os/cmdline"},
1967         {"path": "boot:loader", "xpath": "os/loader", "set": _set_loader},
1968         {"path": "boot:nvram", "xpath": "os/nvram", "set": _set_nvram},
1969         _memory_parameter("mem", "memory"),
1970         _memory_parameter("mem", "currentMemory"),
1971         _memory_parameter("mem:max", "maxMemory"),
1972         _memory_parameter("mem:boot", "memory"),
1973         _memory_parameter("mem:current", "currentMemory"),
1974         xmlutil.attribute("mem:slots", "maxMemory", "slots", ["unit"]),
1975         _memory_parameter("mem:hard_limit", "memtune/hard_limit"),
1976         _memory_parameter("mem:soft_limit", "memtune/soft_limit"),
1977         _memory_parameter("mem:swap_hard_limit", "memtune/swap_hard_limit"),
1978         _memory_parameter("mem:min_guarantee", "memtune/min_guarantee"),
1979         xmlutil.attribute("boot_dev:{dev}", "os/boot[$dev]", "dev"),
1980         _memory_parameter(
1981             "mem:hugepages:{id}:size",
1982             "memoryBacking/hugepages/page[$id]",
1983             "size",
1984             ["unit", "nodeset"],
1985         ),
1986         _cpuset_parameter(
1987             "mem:hugepages:{id}:nodeset", "memoryBacking/hugepages/page[$id]", "nodeset"
1988         ),
1989         {
1990             "path": "mem:nosharepages",
1991             "xpath": "memoryBacking/nosharepages",
1992             "get": lambda n: n is not None,
1993             "set": lambda n, v: None,
1994         },
1995         {
1996             "path": "mem:locked",
1997             "xpath": "memoryBacking/locked",
1998             "get": lambda n: n is not None,
1999             "set": lambda n, v: None,
2000         },
2001         xmlutil.attribute("mem:source", "memoryBacking/source", "type"),
2002         xmlutil.attribute("mem:access", "memoryBacking/access", "mode"),
2003         xmlutil.attribute("mem:allocation", "memoryBacking/allocation", "mode"),
2004         {"path": "mem:discard", "xpath": "memoryBacking/discard"},
2005         {
2006             "path": "cpu",
2007             "xpath": "vcpu",
2008             "get": lambda n: int(n.text),
2009             "set": _set_vcpu,
2010         },
2011         {"path": "cpu:maximum", "xpath": "vcpu", "get": lambda n: int(n.text)},
2012         xmlutil.attribute("cpu:placement", "vcpu", "placement"),
2013         _cpuset_parameter("cpu:cpuset", "vcpu", "cpuset"),
2014         xmlutil.attribute("cpu:current", "vcpu", "current"),
2015         xmlutil.attribute("cpu:match", "cpu", "match"),
2016         xmlutil.attribute("cpu:mode", "cpu", "mode"),
2017         xmlutil.attribute("cpu:check", "cpu", "check"),
2018         {"path": "cpu:model:name", "xpath": "cpu/model"},
2019         xmlutil.attribute("cpu:model:fallback", "cpu/model", "fallback"),
2020         xmlutil.attribute("cpu:model:vendor_id", "cpu/model", "vendor_id"),
2021         {"path": "cpu:vendor", "xpath": "cpu/vendor"},
2022         xmlutil.attribute("cpu:topology:sockets", "cpu/topology", "sockets"),
2023         xmlutil.attribute("cpu:topology:cores", "cpu/topology", "cores"),
2024         xmlutil.attribute("cpu:topology:threads", "cpu/topology", "threads"),
2025         xmlutil.attribute("cpu:cache:level", "cpu/cache", "level"),
2026         xmlutil.attribute("cpu:cache:mode", "cpu/cache", "mode"),
2027         xmlutil.attribute(
2028             "cpu:features:{id}", "cpu/feature[@name='$id']", "policy", ["name"]
2029         ),
2030         _yesno_attribute(
2031             "cpu:vcpus:{id}:enabled", "vcpus/vcpu[@id='$id']", "enabled", ["id"]
2032         ),
2033         _yesno_attribute(
2034             "cpu:vcpus:{id}:hotpluggable",
2035             "vcpus/vcpu[@id='$id']",
2036             "hotpluggable",
2037             ["id"],
2038         ),
2039         xmlutil.int_attribute(
2040             "cpu:vcpus:{id}:order", "vcpus/vcpu[@id='$id']", "order", ["id"]
2041         ),
2042         _cpuset_parameter(
2043             "cpu:numa:{id}:cpus", "cpu/numa/cell[@id='$id']", "cpus", ["id"]
2044         ),
2045         _memory_parameter(
2046             "cpu:numa:{id}:memory", "cpu/numa/cell[@id='$id']", "memory", ["id"]
2047         ),
2048         _yesno_attribute(
2049             "cpu:numa:{id}:discard", "cpu/numa/cell[@id='$id']", "discard", ["id"]
2050         ),
2051         xmlutil.attribute(
2052             "cpu:numa:{id}:memAccess", "cpu/numa/cell[@id='$id']", "memAccess", ["id"]
2053         ),
2054         xmlutil.attribute(
2055             "cpu:numa:{id}:distances:{sid}",
2056             "cpu/numa/cell[@id='$id']/distances/sibling[@id='$sid']",
2057             "value",
2058             ["id"],
2059         ),
2060         {"path": "cpu:iothreads", "xpath": "iothreads"},
2061         {"path": "cpu:tuning:shares", "xpath": "cputune/shares"},
2062         {"path": "cpu:tuning:period", "xpath": "cputune/period"},
2063         {"path": "cpu:tuning:quota", "xpath": "cputune/quota"},
2064         {"path": "cpu:tuning:global_period", "xpath": "cputune/global_period"},
2065         {"path": "cpu:tuning:global_quota", "xpath": "cputune/global_quota"},
2066         {"path": "cpu:tuning:emulator_period", "xpath": "cputune/emulator_period"},
2067         {"path": "cpu:tuning:emulator_quota", "xpath": "cputune/emulator_quota"},
2068         {"path": "cpu:tuning:iothread_period", "xpath": "cputune/iothread_period"},
2069         {"path": "cpu:tuning:iothread_quota", "xpath": "cputune/iothread_quota"},
2070         _cpuset_parameter(
2071             "cpu:tuning:vcpupin:{id}",
2072             "cputune/vcpupin[@vcpu='$id']",
2073             "cpuset",
2074             ["vcpu"],
2075         ),
2076         _cpuset_parameter("cpu:tuning:emulatorpin", "cputune/emulatorpin", "cpuset"),
2077         _cpuset_parameter(
2078             "cpu:tuning:iothreadpin:{id}",
2079             "cputune/iothreadpin[@iothread='$id']",
2080             "cpuset",
2081             ["iothread"],
2082         ),
2083         xmlutil.attribute(
2084             "cpu:tuning:vcpusched:{id}:scheduler",
2085             "cputune/vcpusched[$id]",
2086             "scheduler",
2087             ["priority", "vcpus"],
2088         ),
2089         xmlutil.attribute(
2090             "cpu:tuning:vcpusched:{id}:priority", "cputune/vcpusched[$id]", "priority"
2091         ),
2092         _cpuset_parameter(
2093             "cpu:tuning:vcpusched:{id}:vcpus", "cputune/vcpusched[$id]", "vcpus"
2094         ),
2095         xmlutil.attribute(
2096             "cpu:tuning:iothreadsched:{id}:scheduler",
2097             "cputune/iothreadsched[$id]",
2098             "scheduler",
2099             ["priority", "iothreads"],
2100         ),
2101         xmlutil.attribute(
2102             "cpu:tuning:iothreadsched:{id}:priority",
2103             "cputune/iothreadsched[$id]",
2104             "priority",
2105         ),
2106         _cpuset_parameter(
2107             "cpu:tuning:iothreadsched:{id}:iothreads",
2108             "cputune/iothreadsched[$id]",
2109             "iothreads",
2110         ),
2111         xmlutil.attribute(
2112             "cpu:tuning:emulatorsched:scheduler",
2113             "cputune/emulatorsched",
2114             "scheduler",
2115             ["priority"],
2116         ),
2117         xmlutil.attribute(
2118             "cpu:tuning:emulatorsched:priority", "cputune/emulatorsched", "priority"
2119         ),
2120         xmlutil.attribute(
2121             "cpu:tuning:cachetune:{id}:monitor:{sid}",
2122             "cputune/cachetune[@vcpus='$id']/monitor[@vcpus='$sid']",
2123             "level",
2124             ["vcpus"],
2125         ),
2126         xmlutil.attribute(
2127             "cpu:tuning:memorytune:{id}:{sid}",
2128             "cputune/memorytune[@vcpus='$id']/node[@id='$sid']",
2129             "bandwidth",
2130             ["id", "vcpus"],
2131         ),
2132         xmlutil.attribute("clock:offset", "clock", "offset"),
2133         xmlutil.attribute("clock:adjustment", "clock", "adjustment", convert=str),
2134         xmlutil.attribute("clock:timezone", "clock", "timezone"),
2135     ]
2136 <a name="0"></a>
2137     for timer in timer_names:
2138         params_mapping += [
2139             xmlutil<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.attribute(
2140                 "clock:timers:{}:track".format(timer),
2141                 "clock/timer[@name='{}']".format(timer),
2142                 "track",
2143                 ["name"],
2144             ),
2145             xmlutil.attribute(
2146                 "clock:timers:{}:tickpolicy".format(timer),
2147                 "clock/timer[@name='{}']".format(timer),
2148                 "tickpolicy",
2149                 ["name"],
2150             ),
2151             xmlutil.int_attribute(
2152                 "clock:timers:{}:frequency".format(timer),
2153                 "clock/timer[@name='{}']".format(timer),
2154                 "frequency",
2155                 ["name"],
2156             ),
2157             xmlutil.attribute(
2158                 "clock:timers:{}:mode".format(timer),
2159                 "clock/timer[@name='{}']".format(</b></font>timer),
2160                 "mode",
2161                 ["name"],
2162             ),
2163             _yesno_attribute(
2164                 "clock:timers:{}:present".format(timer),
2165                 "clock/timer[@name='{}']".format(timer),
2166                 "present",
2167                 ["name"],
2168             ),
2169         ]
2170         for attr in ["slew", "threshold", "limit"]:
2171             params_mapping.append(
2172                 xmlutil.int_attribute(
2173                     "clock:timers:{}:{}".format(timer, attr),
2174                     "clock/timer[@name='{}']/catchup".format(timer),
2175                     attr,
2176                 )
2177             )
2178     for attr in ["level", "type", "size"]:
2179         params_mapping.append(
2180             xmlutil.attribute(
2181                 "cpu:tuning:cachetune:{id}:{sid}:" + attr,
2182                 "cputune/cachetune[@vcpus='$id']/cache[@id='$sid']",
2183                 attr,
2184                 ["id", "unit", "vcpus"],
2185             )
2186         )
2187     if hypervisor in ["qemu", "kvm"]:
2188         params_mapping += [
2189             xmlutil.attribute("numatune:memory:mode", "numatune/memory", "mode"),
2190             _cpuset_parameter("numatune:memory:nodeset", "numatune/memory", "nodeset"),
2191             xmlutil.attribute(
2192                 "numatune:memnodes:{id}:mode",
2193                 "numatune/memnode[@cellid='$id']",
2194                 "mode",
2195                 ["cellid"],
2196             ),
2197             _cpuset_parameter(
2198                 "numatune:memnodes:{id}:nodeset",
2199                 "numatune/memnode[@cellid='$id']",
2200                 "nodeset",
2201                 ["cellid"],
2202             ),
2203             xmlutil.attribute(
2204                 "hypervisor_features:kvm-hint-dedicated",
2205                 "features/kvm/hint-dedicated",
2206                 "state",
2207                 convert=lambda v: "on" if v else "off",
2208             ),
2209         ]
2210     need_update = (
2211         salt.utils.xmlutil.change_xml(desc, data, params_mapping) or need_update
2212     )
2213     devices_node = desc.find("devices")
2214     func_locals = locals()
2215     def _skip_update(names):
2216         return all(func_locals.get(n) is None for n in names)
2217     to_skip = {
2218         "disk": _skip_update(["disks", "disk_profile"]),
2219         "interface": _skip_update(["interfaces", "nic_profile"]),
2220         "graphics": _skip_update(["graphics"]),
2221         "serial": _skip_update(["serials"]),
2222         "console": _skip_update(["consoles"]),
2223         "hostdev": _skip_update(["host_devices"]),
2224     }
2225     changes = _compute_device_changes(desc, new_desc, to_skip)
2226     for dev_type in changes:
2227         if not to_skip[dev_type]:
2228             old = devices_node.findall(dev_type)
2229             if changes[dev_type].get("deleted") or changes[dev_type].get("new"):
2230                 for item in old:
2231                     devices_node.remove(item)
2232                 devices_node.extend(changes[dev_type]["sorted"])
2233                 need_update = True
2234     if need_update:
2235         try:
2236             if changes["disk"]:
2237                 for idx, item in enumerate(changes["disk"]["sorted"]):
2238                     source_file = all_disks[idx].get("source_file")
2239                     if all_disks[idx].get("device", "disk") == "cdrom":
2240                         continue
2241                     if (
2242                         item in changes["disk"]["new"]
2243                         and source_file
2244                         and not os.path.exists(source_file)
2245                     ):
2246                         _qemu_image_create(all_disks[idx])
2247                     elif item in changes["disk"]["new"] and not source_file:
2248                         _disk_volume_create(conn, all_disks[idx])
2249             if not test:
2250                 xml_desc = xmlutil.element_to_str(desc)
2251                 log.debug("Update virtual machine definition: %s", xml_desc)
2252                 conn.defineXML(xml_desc)
2253             status["definition"] = True
2254         except libvirt.libvirtError as err:
2255             conn.close()
2256             raise err
2257     if live:
2258         live_status, errors = _update_live(
2259             domain, new_desc, mem, cpu, old_mem, old_cpu, to_skip, test
2260         )
2261         status.update(live_status)
2262         if errors:
2263             status_errors = status.setdefault("errors", [])
2264             status_errors += errors
2265     conn.close()
2266     return status
2267 def list_domains(**kwargs):
2268     vms = []
2269     conn = __get_conn(**kwargs)
2270     for dom in _get_domain(conn, iterable=True):
2271         vms.append(dom.name())
2272     conn.close()
2273     return vms
2274 def list_active_vms(**kwargs):
2275     vms = []
2276     conn = __get_conn(**kwargs)
2277     for dom in _get_domain(conn, iterable=True, inactive=False):
2278         vms.append(dom.name())
2279     conn.close()
2280     return vms
2281 def list_inactive_vms(**kwargs):
2282     vms = []
2283     conn = __get_conn(**kwargs)
2284     for dom in _get_domain(conn, iterable=True, active=False):
2285         vms.append(dom.name())
2286     conn.close()
2287     return vms
2288 def vm_info(vm_=None, **kwargs):
2289     def _info(conn, dom):
2290         raw = dom.info()
2291         return {
2292             "cpu": raw[3],
2293             "cputime": int(raw[4]),
2294             "disks": _get_disks(conn, dom),
2295             "graphics": _get_graphics(dom),
2296             "nics": _get_nics(dom),
2297             "uuid": _get_uuid(dom),
2298             "loader": _get_loader(dom),
2299             "on_crash": _get_on_crash(dom),
2300             "on_reboot": _get_on_reboot(dom),
2301             "on_poweroff": _get_on_poweroff(dom),
2302             "maxMem": int(raw[1]),
2303             "mem": int(raw[2]),
2304             "state": VIRT_STATE_NAME_MAP.get(raw[0], "unknown"),
2305         }
2306     info = {}
2307     conn = __get_conn(**kwargs)
2308     if vm_:
2309         info[vm_] = _info(conn, _get_domain(conn, vm_))
2310     else:
2311         for domain in _get_domain(conn, iterable=True):
2312             info[domain.name()] = _info(conn, domain)
2313     conn.close()
2314     return info
2315 def vm_state(vm_=None, **kwargs):
2316     def _info(dom):
2317         state = ""
2318         raw = dom.info()
2319         state = VIRT_STATE_NAME_MAP.get(raw[0], "unknown")
2320         return state
2321     info = {}
2322     conn = __get_conn(**kwargs)
2323     if vm_:
2324         info[vm_] = _info(_get_domain(conn, vm_))
2325     else:
2326         for domain in _get_domain(conn, iterable=True):
2327             info[domain.name()] = _info(domain)
2328     conn.close()
2329     return info
2330 def _node_info(conn):
2331     raw = conn.getInfo()
2332     info = {
2333         "cpucores": raw[6],
2334         "cpumhz": raw[3],
2335         "cpumodel": str(raw[0]),
2336         "cpus": raw[2],
2337         "cputhreads": raw[7],
2338         "numanodes": raw[4],
2339         "phymemory": raw[1],
2340         "sockets": raw[5],
2341     }
2342     return info
2343 def node_info(**kwargs):
2344     conn = __get_conn(**kwargs)
2345     info = _node_info(conn)
2346     conn.close()
2347     return info
2348 def _node_devices(conn):
2349     devices = conn.listAllDevices()
2350     devices_infos = []
2351     for dev in devices:
2352         root = ElementTree.fromstring(dev.XMLDesc())
2353         if not set(dev.listCaps()) &amp; {"pci", "usb_device", "net"}:
2354             continue
2355         infos = {
2356             "caps": " ".join(dev.listCaps()),
2357         }
2358         if "net" in dev.listCaps():
2359             parent = root.find(".//parent").text
2360             if parent == "computer":
2361                 continue
2362             infos.update(
2363                 {
2364                     "name": root.find(".//interface").text,
2365                     "address": root.find(".//address").text,
2366                     "device name": parent,
2367                     "state": root.find(".//link").get("state"),
2368                 }
2369             )
2370             devices_infos.append(infos)
2371             continue
2372         vendor_node = root.find(".//vendor")
2373         vendor_id = vendor_node.get("id").lower()
2374         product_node = root.find(".//product")
2375         product_id = product_node.get("id").lower()
2376         infos.update(
2377             {"name": dev.name(), "vendor_id": vendor_id, "product_id": product_id}
2378         )
2379         if vendor_node.text:
2380             infos["vendor"] = vendor_node.text
2381         if product_node.text:
2382             infos["product"] = product_node.text
2383         if "pci" in dev.listCaps():
2384             infos["address"] = "{:04x}:{:02x}:{:02x}.{}".format(
2385                 int(root.find(".//domain").text),
2386                 int(root.find(".//bus").text),
2387                 int(root.find(".//slot").text),
2388                 root.find(".//function").text,
2389             )
2390             class_node = root.find(".//class")
2391             if class_node is not None:
2392                 infos["PCI class"] = class_node.text
2393             vf_addresses = [
2394                 _format_pci_address(vf)
2395                 for vf in root.findall(
2396                     "./capability[@type='pci']/capability[@type='virt_functions']/address"
2397                 )
2398             ]
2399             if vf_addresses:
2400                 infos["virtual functions"] = vf_addresses
2401             pf = root.find(
2402                 "./capability[@type='pci']/capability[@type='phys_function']/address"
2403             )
2404             if pf is not None:
2405                 infos["physical function"] = _format_pci_address(pf)
2406         elif "usb_device" in dev.listCaps():
2407             infos["address"] = "{:03}:{:03}".format(
2408                 int(root.find(".//bus").text), int(root.find(".//device").text)
2409             )
2410         linux_usb_host = vendor_id == "0x1d6b" and product_id in [
2411             "0x0001",
2412             "0x0002",
2413             "0x0003",
2414         ]
2415         if (
2416             root.find(".//capability[@type='pci-bridge']") is None
2417             and not linux_usb_host
2418         ):
2419             devices_infos.append(infos)
2420     return devices_infos
2421 def node_devices(**kwargs):
2422     conn = __get_conn(**kwargs)
2423     devs = _node_devices(conn)
2424     conn.close()
2425     return devs
2426 def get_nics(vm_, **kwargs):
2427     conn = __get_conn(**kwargs)
2428     nics = _get_nics(_get_domain(conn, vm_))
2429     conn.close()
2430     return nics
2431 def get_macs(vm_, **kwargs):
2432     doc = ElementTree.fromstring(get_xml(vm_, **kwargs))
2433     return [node.get("address") for node in doc.findall("devices/interface/mac")]
2434 def get_graphics(vm_, **kwargs):
2435     conn = __get_conn(**kwargs)
2436     graphics = _get_graphics(_get_domain(conn, vm_))
2437     conn.close()
2438     return graphics
2439 def get_loader(vm_, **kwargs):
2440     conn = __get_conn(**kwargs)
2441     try:
2442         loader = _get_loader(_get_domain(conn, vm_))
2443         return loader
2444     finally:
2445         conn.close()
2446 def get_disks(vm_, **kwargs):
2447     conn = __get_conn(**kwargs)
2448     disks = _get_disks(conn, _get_domain(conn, vm_))
2449     conn.close()
2450     return disks
2451 def setmem(vm_, memory, config=False, **kwargs):
2452     conn = __get_conn(**kwargs)
2453     dom = _get_domain(conn, vm_)
2454     if VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown":
2455         return False
2456     flags = libvirt.VIR_DOMAIN_MEM_MAXIMUM
2457     if config:
2458         flags = flags | libvirt.VIR_DOMAIN_AFFECT_CONFIG
2459     ret1 = dom.setMemoryFlags(memory * 1024, flags)
2460     ret2 = dom.setMemoryFlags(memory * 1024, libvirt.VIR_DOMAIN_AFFECT_CURRENT)
2461     conn.close()
2462     return ret1 == ret2 == 0
2463 def setvcpus(vm_, vcpus, config=False, **kwargs):
2464     conn = __get_conn(**kwargs)
2465     dom = _get_domain(conn, vm_)
2466     if VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown":
2467         return False
2468     flags = libvirt.VIR_DOMAIN_VCPU_MAXIMUM
2469     if config:
2470         flags = flags | libvirt.VIR_DOMAIN_AFFECT_CONFIG
2471     ret1 = dom.setVcpusFlags(vcpus, flags)
2472     ret2 = dom.setVcpusFlags(vcpus, libvirt.VIR_DOMAIN_AFFECT_CURRENT)
2473     conn.close()
2474     return ret1 == ret2 == 0
2475 def _freemem(conn):
2476     mem = conn.getInfo()[1]
2477     mem -= 256
2478     for dom in _get_domain(conn, iterable=True):
2479         if dom.ID() &gt; 0:
2480             mem -= dom.info()[2] / 1024
2481     return mem
2482 def freemem(**kwargs):
2483     conn = __get_conn(**kwargs)
2484     mem = _freemem(conn)
2485     conn.close()
2486     return mem
2487 def _freecpu(conn):
2488     cpus = conn.getInfo()[2]
2489     for dom in _get_domain(conn, iterable=True):
2490         if dom.ID() &gt; 0:
2491             cpus -= dom.info()[3]
2492     return cpus
2493 def freecpu(**kwargs):
2494     conn = __get_conn(**kwargs)
2495     cpus = _freecpu(conn)
2496     conn.close()
2497     return cpus
2498 def full_info(**kwargs):
2499     conn = __get_conn(**kwargs)
2500     info = {
2501         "freecpu": _freecpu(conn),
2502         "freemem": _freemem(conn),
2503         "node_info": _node_info(conn),
2504         "vm_info": vm_info(),
2505     }
2506     conn.close()
2507     return info
2508 def get_xml(vm_, **kwargs):
2509     conn = __get_conn(**kwargs)
2510     xml_desc = (
2511         vm_.XMLDesc(0)
2512         if isinstance(vm_, libvirt.virDomain)
2513         else _get_domain(conn, vm_).XMLDesc(0)
2514     )
2515     conn.close()
2516     return xml_desc
2517 def get_profiles(hypervisor=None, **kwargs):
2518     conn = __get_conn(**kwargs)
2519     caps = _capabilities(conn)
2520     hypervisors = sorted(
2521         {
2522             x
2523             for y in [guest["arch"]["domains"].keys() for guest in caps["guests"]]
2524             for x in y
2525         }
2526     )
2527     if len(hypervisors) == 0:
2528         raise SaltInvocationError("No supported hypervisors were found")
2529     if not hypervisor:
2530         hypervisor = "kvm" if "kvm" in hypervisors else hypervisors[0]
2531     ret = {
2532         "disk": {"default": _disk_profile(conn, "default", hypervisor, [], None)},
2533         "nic": {"default": _nic_profile("default", hypervisor)},
2534     }
2535     virtconf = __salt__["config.get"]("virt", {})
2536     for profile in virtconf.get("disk", []):
2537         ret["disk"][profile] = _disk_profile(conn, profile, hypervisor, [], None)
2538     for profile in virtconf.get("nic", []):
2539         ret["nic"][profile] = _nic_profile(profile, hypervisor)
2540     return ret
2541 def shutdown(vm_, **kwargs):
2542     conn = __get_conn(**kwargs)
2543     dom = _get_domain(conn, vm_)
2544     ret = dom.shutdown() == 0
2545     conn.close()
2546     return ret
2547 def pause(vm_, **kwargs):
2548     conn = __get_conn(**kwargs)
2549     dom = _get_domain(conn, vm_)
2550     ret = dom.suspend() == 0
2551     conn.close()
2552     return ret
2553 def resume(vm_, **kwargs):
2554     conn = __get_conn(**kwargs)
2555     dom = _get_domain(conn, vm_)
2556     ret = dom.resume() == 0
2557     conn.close()
2558     return ret
2559 def start(name, **kwargs):
2560     conn = __get_conn(**kwargs)
2561     ret = _get_domain(conn, name).create() == 0
2562     conn.close()
2563     return ret
2564 def stop(name, **kwargs):
2565     conn = __get_conn(**kwargs)
2566     ret = _get_domain(conn, name).destroy() == 0
2567     conn.close()
2568     return ret
2569 def reboot(name, **kwargs):
2570     conn = __get_conn(**kwargs)
2571     ret = _get_domain(conn, name).reboot(libvirt.VIR_DOMAIN_REBOOT_DEFAULT) == 0
2572     conn.close()
2573     return ret
2574 def reset(vm_, **kwargs):
2575     conn = __get_conn(**kwargs)
2576     dom = _get_domain(conn, vm_)
2577     ret = dom.reset(0) == 0
2578     conn.close()
2579     return ret
2580 def ctrl_alt_del(vm_, **kwargs):
2581     conn = __get_conn(**kwargs)
2582     dom = _get_domain(conn, vm_)
2583     ret = dom.sendKey(0, 0, [29, 56, 111], 3, 0) == 0
2584     conn.close()
2585     return ret
2586 def create_xml_str(xml, **kwargs):  # pylint: disable=redefined-outer-name
2587     conn = __get_conn(**kwargs)
2588     ret = conn.createXML(xml, 0) is not None
2589     conn.close()
2590     return ret
2591 def create_xml_path(path, **kwargs):
2592     try:
2593         with salt.utils.files.fopen(path, "r") as fp_:
2594             return create_xml_str(
2595                 salt.utils.stringutils.to_unicode(fp_.read()), **kwargs
2596             )
2597     except OSError:
2598         return False
2599 def define_xml_str(xml, **kwargs):  # pylint: disable=redefined-outer-name
2600     conn = __get_conn(**kwargs)
2601     ret = conn.defineXML(xml) is not None
2602     conn.close()
2603     return ret
2604 def define_xml_path(path, **kwargs):
2605     try:
2606         with salt.utils.files.fopen(path, "r") as fp_:
2607             return define_xml_str(
2608                 salt.utils.stringutils.to_unicode(fp_.read()), **kwargs
2609             )
2610     except OSError:
2611         return False
2612 def _define_vol_xml_str(conn, xml, pool=None):  # pylint: disable=redefined-outer-name
2613     default_pool = "default" if conn.getType() != "ESX" else "0"
2614     poolname = (
2615         pool if pool else __salt__["config.get"]("virt:storagepool", default_pool)
2616     )
2617     pool = conn.storagePoolLookupByName(str(poolname))
2618     ret = pool.createXML(xml, 0) is not None
2619     return ret
2620 def define_vol_xml_str(
2621     xml, pool=None, **kwargs
2622 ):  # pylint: disable=redefined-outer-name
2623     conn = __get_conn(**kwargs)
2624     ret = False
2625     try:
2626         ret = _define_vol_xml_str(conn, xml, pool=pool)
2627     except libvirtError as err:
2628         raise CommandExecutionError(err.get_error_message())
2629     finally:
2630         conn.close()
2631     return ret
2632 def define_vol_xml_path(path, pool=None, **kwargs):
2633     try:
2634         with salt.utils.files.fopen(path, "r") as fp_:
2635             return define_vol_xml_str(
2636                 salt.utils.stringutils.to_unicode(fp_.read()), pool=pool, **kwargs
2637             )
2638     except OSError:
2639         return False
2640 def migrate(vm_, target, **kwargs):
2641     conn = __get_conn()
2642     dom = _get_domain(conn, vm_)
2643     if not urllib.parse.urlparse(target).scheme:
2644         proto = "qemu"
2645         dst_uri = "{}://{}/system".format(proto, target)
2646     else:
2647         dst_uri = target
2648     ret = _migrate(dom, dst_uri, **kwargs)
2649     conn.close()
2650     return ret
2651 def migrate_start_postcopy(vm_):
2652     conn = __get_conn()
2653     dom = _get_domain(conn, vm_)
2654     try:
2655         dom.migrateStartPostCopy()
2656     except libvirt.libvirtError as err:
2657         conn.close()
2658         raise CommandExecutionError(err.get_error_message())
2659     conn.close()
2660 def seed_non_shared_migrate(disks, force=False):
2661     for _, data in disks.items():
2662         fn_ = data["file"]
2663         form = data["file format"]
2664         size = data["virtual size"].split()[1][1:]
2665         if os.path.isfile(fn_) and not force:
2666             pre = salt.utils.yaml.safe_load(
2667                 subprocess.Popen(
2668                     ["qemu-img", "info", "arch"], stdout=subprocess.PIPE
2669                 ).communicate()[0]
2670             )
2671             if (
2672                 pre["file format"] != data["file format"]
2673                 and pre["virtual size"] != data["virtual size"]
2674             ):
2675                 return False
2676         if not os.path.isdir(os.path.dirname(fn_)):
2677             os.makedirs(os.path.dirname(fn_))
2678         if os.path.isfile(fn_):
2679             os.remove(fn_)
2680         subprocess.call(["qemu-img", "create", "-f", form, fn_, size])
2681         creds = _libvirt_creds()
2682         subprocess.call(["chown", "{user}:{group}".format(**creds), fn_])
2683     return True
2684 def set_autostart(vm_, state="on", **kwargs):
2685     conn = __get_conn(**kwargs)
2686     dom = _get_domain(conn, vm_)
2687     ret = False
2688     if state == "on":
2689         ret = dom.setAutostart(1) == 0
2690     elif state == "off":
2691         ret = dom.setAutostart(0) == 0
2692     conn.close()
2693     return ret
2694 def undefine(vm_, **kwargs):
2695     conn = __get_conn(**kwargs)
2696     dom = _get_domain(conn, vm_)
2697     if getattr(libvirt, "VIR_DOMAIN_UNDEFINE_NVRAM", False):
2698         ret = dom.undefineFlags(libvirt.VIR_DOMAIN_UNDEFINE_NVRAM) == 0
2699     else:
2700         ret = dom.undefine() == 0
2701     conn.close()
2702     return ret
2703 def purge(vm_, dirs=False, removables=False, **kwargs):
2704     conn = __get_conn(**kwargs)
2705     dom = _get_domain(conn, vm_)
2706     disks = _get_disks(conn, dom)
2707     if (
2708         VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown"
2709         and dom.destroy() != 0
2710     ):
2711         return False
2712     directories = set()
2713     for disk in disks:
2714         if not removables and disks[disk]["type"] in ["cdrom", "floppy"]:
2715             continue
2716         if disks[disk].get("zfs", False):
2717             time.sleep(3)
2718             fs_name = disks[disk]["file"][len("/dev/zvol/") :]
2719             log.info("Destroying VM ZFS volume %s", fs_name)
2720             __salt__["zfs.destroy"](name=fs_name, force=True)
2721         elif os.path.exists(disks[disk]["file"]):
2722             os.remove(disks[disk]["file"])
2723             directories.add(os.path.dirname(disks[disk]["file"]))
2724         else:
2725             matcher = re.match("^(?P&lt;pool&gt;[^/]+)/(?P&lt;volume&gt;.*)$", disks[disk]["file"])
2726             if matcher:
2727                 pool_name = matcher.group("pool")
2728                 pool = None
2729                 if pool_name in conn.listStoragePools():
2730                     pool = conn.storagePoolLookupByName(pool_name)
2731                 if pool and matcher.group("volume") in pool.listVolumes():
2732                     volume = pool.storageVolLookupByName(matcher.group("volume"))
2733                     volume.delete()
2734     if dirs:
2735         for dir_ in directories:
2736             shutil.rmtree(dir_)
2737     if getattr(libvirt, "VIR_DOMAIN_UNDEFINE_NVRAM", False):
2738         try:
2739             dom.undefineFlags(libvirt.VIR_DOMAIN_UNDEFINE_NVRAM)
2740         except Exception:  # pylint: disable=broad-except
2741             dom.undefine()
2742     else:
2743         dom.undefine()
2744     conn.close()
2745     return True
2746 def virt_type():
2747     return __grains__["virtual"]
2748 def _is_kvm_hyper():
2749     if not os.path.exists("/dev/kvm"):
2750         return False
2751     return "libvirtd" in __salt__["cmd.run"](__grains__["ps"])
2752 def _is_xen_hyper():
2753     try:
2754         if __grains__["virtual_subtype"] != "Xen Dom0":
2755             return False
2756     except KeyError:
2757         return False
2758     try:
2759         with salt.utils.files.fopen("/proc/modules") as fp_:
2760             if "xen_" not in salt.utils.stringutils.to_unicode(fp_.read()):
2761                 return False
2762     except OSError:
2763         return False
2764     return "libvirtd" in __salt__["cmd.run"](__grains__["ps"])
2765 def get_hypervisor():
2766     hypervisors = ["kvm", "xen", "bhyve"]
2767     result = [
2768         hyper
2769         for hyper in hypervisors
2770         if getattr(sys.modules[__name__], "_is_{}_hyper".format(hyper))()
2771     ]
2772     return result[0] if result else None
2773 def _is_bhyve_hyper():
2774     sysctl_cmd = "sysctl hw.vmm.create"
2775     vmm_enabled = False
2776     try:
2777         stdout = subprocess.Popen(
2778             ["sysctl", "hw.vmm.create"], stdout=subprocess.PIPE
2779         ).communicate()[0]
2780         vmm_enabled = len(salt.utils.stringutils.to_str(stdout).split('"')[1]) != 0
2781     except IndexError:
2782         pass
2783     return vmm_enabled
2784 def is_hyper():
2785     if HAS_LIBVIRT:
2786         return _is_xen_hyper() or _is_kvm_hyper() or _is_bhyve_hyper()
2787     return False
2788 def vm_cputime(vm_=None, **kwargs):
2789     conn = __get_conn(**kwargs)
2790     host_cpus = conn.getInfo()[2]
2791     def _info(dom):
2792         raw = dom.info()
2793         vcpus = int(raw[3])
2794         cputime = int(raw[4])
2795         cputime_percent = 0
2796         if cputime:
2797             cputime_percent = (1.0e-7 * cputime / host_cpus) / vcpus
2798         return {
2799             "cputime": int(raw[4]),
2800             "cputime_percent": int("{:.0f}".format(cputime_percent)),
2801         }
2802     info = {}
2803     if vm_:
2804         info[vm_] = _info(_get_domain(conn, vm_))
2805     else:
2806         for domain in _get_domain(conn, iterable=True):
2807             info[domain.name()] = _info(domain)
2808     conn.close()
2809     return info
2810 def vm_netstats(vm_=None, **kwargs):
2811     def _info(dom):
2812         nics = _get_nics(dom)
2813         ret = {
2814             "rx_bytes": 0,
2815             "rx_packets": 0,
2816             "rx_errs": 0,
2817             "rx_drop": 0,
2818             "tx_bytes": 0,
2819             "tx_packets": 0,
2820             "tx_errs": 0,
2821             "tx_drop": 0,
2822         }
2823         for attrs in nics.values():
2824             if "target" in attrs:
2825                 dev = attrs["target"]
2826                 stats = dom.interfaceStats(dev)
2827                 ret["rx_bytes"] += stats[0]
2828                 ret["rx_packets"] += stats[1]
2829                 ret["rx_errs"] += stats[2]
2830                 ret["rx_drop"] += stats[3]
2831                 ret["tx_bytes"] += stats[4]
2832                 ret["tx_packets"] += stats[5]
2833                 ret["tx_errs"] += stats[6]
2834                 ret["tx_drop"] += stats[7]
2835         return ret
2836     info = {}
2837     conn = __get_conn(**kwargs)
2838     if vm_:
2839         info[vm_] = _info(_get_domain(conn, vm_))
2840     else:
2841         for domain in _get_domain(conn, iterable=True):
2842             info[domain.name()] = _info(domain)
2843     conn.close()
2844     return info
2845 def vm_diskstats(vm_=None, **kwargs):
2846     def get_disk_devs(dom):
2847         doc = ElementTree.fromstring(get_xml(dom, **kwargs))
2848         return [target.get("dev") for target in doc.findall("devices/disk/target")]
2849     def _info(dom):
2850         disks = get_disk_devs(dom)
2851         ret = {"rd_req": 0, "rd_bytes": 0, "wr_req": 0, "wr_bytes": 0, "errs": 0}
2852         for disk in disks:
2853             stats = dom.blockStats(disk)
2854             ret["rd_req"] += stats[0]
2855             ret["rd_bytes"] += stats[1]
2856             ret["wr_req"] += stats[2]
2857             ret["wr_bytes"] += stats[3]
2858             ret["errs"] += stats[4]
2859         return ret
2860     info = {}
2861     conn = __get_conn(**kwargs)
2862     if vm_:
2863         info[vm_] = _info(_get_domain(conn, vm_))
2864     else:
2865         for domain in _get_domain(conn, iterable=True, inactive=False):
2866             info[domain.name()] = _info(domain)
2867     conn.close()
2868     return info
2869 def _parse_snapshot_description(vm_snapshot, unix_time=False):
2870     ret = dict()
2871     tree = ElementTree.fromstring(vm_snapshot.getXMLDesc())
2872     for node in tree:
2873         if node.tag == "name":
2874             ret["name"] = node.text
2875         elif node.tag == "creationTime":
2876             ret["created"] = (
2877                 datetime.datetime.fromtimestamp(float(node.text)).isoformat(" ")
2878                 if not unix_time
2879                 else float(node.text)
2880             )
2881         elif node.tag == "state":
2882             ret["running"] = node.text == "running"
2883     ret["current"] = vm_snapshot.isCurrent() == 1
2884     return ret
2885 def list_snapshots(domain=None, **kwargs):
2886     ret = dict()
2887     conn = __get_conn(**kwargs)
2888     for vm_domain in _get_domain(conn, *(domain and [domain] or list()), iterable=True):
2889         ret[vm_domain.name()] = [
2890             _parse_snapshot_description(snap) for snap in vm_domain.listAllSnapshots()
2891         ] or "N/A"
2892     conn.close()
2893     return ret
2894 def snapshot(domain, name=None, suffix=None, **kwargs):
2895     if name and name.lower() == domain.lower():
2896         raise CommandExecutionError(
2897             "Virtual Machine {name} is already defined. "
2898             "Please choose another name for the snapshot".format(name=name)
2899         )
2900     if not name:
2901         name = "{domain}-{tsnap}".format(
2902             domain=domain, tsnap=time.strftime("%Y%m%d-%H%M%S", time.localtime())
2903         )
2904     if suffix:
2905         name = "{name}-{suffix}".format(name=name, suffix=suffix)
2906     doc = ElementTree.Element("domainsnapshot")
2907     n_name = ElementTree.SubElement(doc, "name")
2908     n_name.text = name
2909     conn = __get_conn(**kwargs)
2910     _get_domain(conn, domain).snapshotCreateXML(xmlutil.element_to_str(doc))
2911     conn.close()
2912     return {"name": name}
2913 def delete_snapshots(name, *names, **kwargs):
2914     deleted = dict()
2915     conn = __get_conn(**kwargs)
2916     domain = _get_domain(conn, name)
2917     for snap in domain.listAllSnapshots():
2918         if snap.getName() in names or not names:
2919             deleted[snap.getName()] = _parse_snapshot_description(snap)
2920             snap.delete()
2921     conn.close()
2922     available = {
2923         name: [_parse_snapshot_description(snap) for snap in domain.listAllSnapshots()]
2924         or "N/A"
2925     }
2926     return {"available": available, "deleted": deleted}
2927 def revert_snapshot(name, vm_snapshot=None, cleanup=False, **kwargs):
2928     ret = dict()
2929     conn = __get_conn(**kwargs)
2930     domain = _get_domain(conn, name)
2931     snapshots = domain.listAllSnapshots()
2932     _snapshots = list()
2933     for snap_obj in snapshots:
2934         _snapshots.append(
2935             {
2936                 "idx": _parse_snapshot_description(snap_obj, unix_time=True)["created"],
2937                 "ptr": snap_obj,
2938             }
2939         )
2940     snapshots = [
2941         w_ptr["ptr"]
2942         for w_ptr in sorted(_snapshots, key=lambda item: item["idx"], reverse=True)
2943     ]
2944     del _snapshots
2945     if not snapshots:
2946         conn.close()
2947         raise CommandExecutionError("No snapshots found")
2948     elif len(snapshots) == 1:
2949         conn.close()
2950         raise CommandExecutionError(
2951             "Cannot revert to itself: only one snapshot is available."
2952         )
2953     snap = None
2954     for p_snap in snapshots:
2955         if not vm_snapshot:
2956             if p_snap.isCurrent() and snapshots[snapshots.index(p_snap) + 1 :]:
2957                 snap = snapshots[snapshots.index(p_snap) + 1 :][0]
2958                 break
2959         elif p_snap.getName() == vm_snapshot:
2960             snap = p_snap
2961             break
2962     if not snap:
2963         conn.close()
2964         raise CommandExecutionError(
2965             snapshot
2966             and 'Snapshot "{}" not found'.format(vm_snapshot)
2967             or "No more previous snapshots available"
2968         )
2969     elif snap.isCurrent():
2970         conn.close()
2971         raise CommandExecutionError("Cannot revert to the currently running snapshot.")
2972     domain.revertToSnapshot(snap)
2973     ret["reverted"] = snap.getName()
2974     if cleanup:
2975         delete = list()
2976         for p_snap in snapshots:
2977             if p_snap.getName() != snap.getName():
2978                 delete.append(p_snap.getName())
2979                 p_snap.delete()
2980             else:
2981                 break
2982         ret["deleted"] = delete
2983     else:
2984         ret["deleted"] = "N/A"
2985     conn.close()
2986     return ret
2987 def _caps_add_machine(machines, node):
2988     maxcpus = node.get("maxCpus")
2989     canonical = node.get("canonical")
2990     name = node.text
2991     alternate_name = ""
2992     if canonical:
2993         alternate_name = name
2994         name = canonical
2995     machine = machines.get(name)
2996     if not machine:
2997         machine = {"alternate_names": []}
2998         if maxcpus:
2999             machine["maxcpus"] = int(maxcpus)
3000         machines[name] = machine
3001     if alternate_name:
3002         machine["alternate_names"].append(alternate_name)
3003 def _parse_caps_guest(guest):
3004     arch_node = guest.find("arch")
3005     result = {
3006         "os_type": guest.find("os_type").text,
3007         "arch": {"name": arch_node.get("name"), "machines": {}, "domains": {}},
3008     }
3009     child = None
3010     for child in arch_node:
3011         if child.tag == "wordsize":
3012             result["arch"]["wordsize"] = int(child.text)
3013         elif child.tag == "emulator":
3014             result["arch"]["emulator"] = child.text
3015         elif child.tag == "machine":
3016             _caps_add_machine(result["arch"]["machines"], child)
3017         elif child.tag == "domain":
3018             domain_type = child.get("type")
3019             domain = {"emulator": None, "machines": {}}
3020             emulator_node = child.find("emulator")
3021             if emulator_node is not None:
3022                 domain["emulator"] = emulator_node.text
3023             for machine in child.findall("machine"):
3024                 _caps_add_machine(domain["machines"], machine)
3025             result["arch"]["domains"][domain_type] = domain
3026     features_nodes = guest.find("features")
3027     if features_nodes is not None and child is not None:
3028         result["features"] = {
3029             child.tag: {
3030                 "toggle": child.get("toggle", "no") == "yes",
3031                 "default": child.get("default", "on") == "on",
3032             }
3033             for child in features_nodes
3034         }
3035     return result
3036 def _parse_caps_cell(cell):
3037     result = {"id": int(cell.get("id"))}
3038     mem_node = cell.find("memory")
3039     if mem_node is not None:
3040         unit = mem_node.get("unit", "KiB")
3041         memory = mem_node.text
3042         result["memory"] = "{} {}".format(memory, unit)
3043     pages = [
3044         {
3045             "size": "{} {}".format(page.get("size"), page.get("unit", "KiB")),
3046             "available": int(page.text),
3047         }
3048         for page in cell.findall("pages")
3049     ]
3050     if pages:
3051         result["pages"] = pages
3052     distances = {
3053         int(distance.get("id")): int(distance.get("value"))
3054         for distance in cell.findall("distances/sibling")
3055     }
3056     if distances:
3057         result["distances"] = distances
3058     cpus = []
3059     for cpu_node in cell.findall("cpus/cpu"):
3060         cpu = {"id": int(cpu_node.get("id"))}
3061         socket_id = cpu_node.get("socket_id")
3062         if socket_id:
3063             cpu["socket_id"] = int(socket_id)
3064         core_id = cpu_node.get("core_id")
3065         if core_id:
3066             cpu["core_id"] = int(core_id)
3067         siblings = cpu_node.get("siblings")
3068         if siblings:
3069             cpu["siblings"] = siblings
3070         cpus.append(cpu)
3071     if cpus:
3072         result["cpus"] = cpus
3073     return result
3074 def _parse_caps_bank(bank):
3075     result = {
3076         "id": int(bank.get("id")),
3077         "level": int(bank.get("level")),
3078         "type": bank.get("type"),
3079         "size": "{} {}".format(bank.get("size"), bank.get("unit")),
3080         "cpus": bank.get("cpus"),
3081     }
3082     controls = []
3083     for control in bank.findall("control"):
3084         unit = control.get("unit")
3085         result_control = {
3086             "granularity": "{} {}".format(control.get("granularity"), unit),
3087             "type": control.get("type"),
3088             "maxAllocs": int(control.get("maxAllocs")),
3089         }
3090         minimum = control.get("min")
3091         if minimum:
3092             result_control["min"] = "{} {}".format(minimum, unit)
3093         controls.append(result_control)
3094     if controls:
3095         result["controls"] = controls
3096     return result
3097 def _parse_caps_host(host):
3098     result = {}
3099     for child in host:
3100         if child.tag == "uuid":
3101             result["uuid"] = child.text
3102         elif child.tag == "cpu":
3103             cpu = {
3104                 "arch": child.find("arch").text
3105                 if child.find("arch") is not None
3106                 else None,
3107                 "model": child.find("model").text
3108                 if child.find("model") is not None
3109                 else None,
3110                 "vendor": child.find("vendor").text
3111                 if child.find("vendor") is not None
3112                 else None,
3113                 "features": [
3114                     feature.get("name") for feature in child.findall("feature")
3115                 ],
3116                 "pages": [
3117                     {"size": "{} {}".format(page.get("size"), page.get("unit", "KiB"))}
3118                     for page in child.findall("pages")
3119                 ],
3120             }
3121             microcode = child.find("microcode")
3122             if microcode is not None:
3123                 cpu["microcode"] = microcode.get("version")
3124             topology = child.find("topology")
3125             if topology is not None:
3126                 cpu["sockets"] = int(topology.get("sockets"))
3127                 cpu["cores"] = int(topology.get("cores"))
3128                 cpu["threads"] = int(topology.get("threads"))
3129             result["cpu"] = cpu
3130         elif child.tag == "power_management":
3131             result["power_management"] = [node.tag for node in child]
3132         elif child.tag == "migration_features":
3133             result["migration"] = {
3134                 "live": child.find("live") is not None,
3135                 "transports": [
3136                     node.text for node in child.findall("uri_transports/uri_transport")
3137                 ],
3138             }
3139         elif child.tag == "topology":
3140             result["topology"] = {
3141                 "cells": [
3142                     _parse_caps_cell(cell) for cell in child.findall("cells/cell")
3143                 ]
3144             }
3145         elif child.tag == "cache":
3146             result["cache"] = {
3147                 "banks": [_parse_caps_bank(bank) for bank in child.findall("bank")]
3148             }
3149     result["security"] = [
3150         {
3151             "model": secmodel.find("model").text
3152             if secmodel.find("model") is not None
3153             else None,
3154             "doi": secmodel.find("doi").text
3155             if secmodel.find("doi") is not None
3156             else None,
3157             "baselabels": [
3158                 {"type": label.get("type"), "label": label.text}
3159                 for label in secmodel.findall("baselabel")
3160             ],
3161         }
3162         for secmodel in host.findall("secmodel")
3163     ]
3164     return result
3165 def _capabilities(conn):
3166     caps = ElementTree.fromstring(conn.getCapabilities())
3167     return {
3168         "host": _parse_caps_host(caps.find("host")),
3169         "guests": [_parse_caps_guest(guest) for guest in caps.findall("guest")],
3170     }
3171 def capabilities(**kwargs):
3172     conn = __get_conn(**kwargs)
3173     try:
3174         caps = _capabilities(conn)
3175     except libvirt.libvirtError as err:
3176         raise CommandExecutionError(str(err))
3177     finally:
3178         conn.close()
3179     return caps
3180 def _parse_caps_enum(node):
3181     return (node.get("name"), [value.text for value in node.findall("value")])
3182 def _parse_caps_cpu(node):
3183     result = {}
3184     for mode in node.findall("mode"):
3185         if not mode.get("supported") == "yes":
3186             continue
3187         name = mode.get("name")
3188         if name == "host-passthrough":
3189             result[name] = True
3190         elif name == "host-model":
3191             host_model = {}
3192             model_node = mode.find("model")
3193             if model_node is not None:
3194                 model = {"name": model_node.text}
3195                 vendor_id = model_node.get("vendor_id")
3196                 if vendor_id:
3197                     model["vendor_id"] = vendor_id
3198                 fallback = model_node.get("fallback")
3199                 if fallback:
3200                     model["fallback"] = fallback
3201                 host_model["model"] = model
3202             vendor = (
3203                 mode.find("vendor").text if mode.find("vendor") is not None else None
3204             )
3205             if vendor:
3206                 host_model["vendor"] = vendor
3207             features = {
3208                 feature.get("name"): feature.get("policy")
3209                 for feature in mode.findall("feature")
3210             }
3211             if features:
3212                 host_model["features"] = features
3213             result[name] = host_model
3214         elif name == "custom":
3215             custom_model = {}
3216             models = {
3217                 model.text: model.get("usable") for model in mode.findall("model")
3218             }
3219             if models:
3220                 custom_model["models"] = models
3221             result[name] = custom_model
3222     return result
3223 def _parse_caps_devices_features(node):
3224     result = {}
3225     for child in node:
3226         if child.get("supported") == "yes":
3227             enums = [_parse_caps_enum(node) for node in child.findall("enum")]
3228             result[child.tag] = {item[0]: item[1] for item in enums if item[0]}
3229     return result
3230 def _parse_caps_loader(node):
3231     enums = [_parse_caps_enum(enum) for enum in node.findall("enum")]
3232     result = {item[0]: item[1] for item in enums if item[0]}
3233     values = [child.text for child in node.findall("value")]
3234     if values:
3235         result["values"] = values
3236     return result
3237 def _parse_domain_caps(caps):
3238     result = {
3239         "emulator": caps.find("path").text if caps.find("path") is not None else None,
3240         "domain": caps.find("domain").text if caps.find("domain") is not None else None,
3241         "machine": caps.find("machine").text
3242         if caps.find("machine") is not None
3243         else None,
3244         "arch": caps.find("arch").text if caps.find("arch") is not None else None,
3245     }
3246     for child in caps:
3247         if child.tag == "vcpu" and child.get("max"):
3248             result["max_vcpus"] = int(child.get("max"))
3249         elif child.tag == "iothreads":
3250             result["iothreads"] = child.get("supported") == "yes"
3251         elif child.tag == "os":
3252             result["os"] = {}
3253             loader_node = child.find("loader")
3254             if loader_node is not None and loader_node.get("supported") == "yes":
3255                 loader = _parse_caps_loader(loader_node)
3256                 result["os"]["loader"] = loader
3257         elif child.tag == "cpu":
3258             cpu = _parse_caps_cpu(child)
3259             if cpu:
3260                 result["cpu"] = cpu
3261         elif child.tag == "devices":
3262             devices = _parse_caps_devices_features(child)
3263             if devices:
3264                 result["devices"] = devices
3265         elif child.tag == "features":
3266             features = _parse_caps_devices_features(child)
3267             if features:
3268                 result["features"] = features
3269     return result
3270 def domain_capabilities(emulator=None, arch=None, machine=None, domain=None, **kwargs):
3271     conn = __get_conn(**kwargs)
3272     result = []
3273     try:
3274         caps = ElementTree.fromstring(
3275             conn.getDomainCapabilities(emulator, arch, machine, domain, 0)
3276         )
3277         result = _parse_domain_caps(caps)
3278     finally:
3279         conn.close()
3280     return result
3281 def all_capabilities(**kwargs):
3282     conn = __get_conn(**kwargs)
3283     try:
3284         host_caps = ElementTree.fromstring(conn.getCapabilities())
3285 <a name="2"></a>        domains = [
3286             [
3287                 (
3288                     guest<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.get("arch", {}).get("name", None),
3289                     key,
3290                     guest.get("arch", {}).get("emulator", None),
3291                 )
3292                 for key in guest.get("arch", {}).get("domains", {}).keys(</b></font>)
3293             ]
3294             for guest in [
3295                 _parse_caps_guest(guest) for guest in host_caps.findall("guest")
3296             ]
3297         ]
3298         flattened = [pair for item in (x for x in domains) for pair in item]
3299         result = {
3300             "host": {
3301                 "host": _parse_caps_host(host_caps.find("host")),
3302                 "guests": [
3303                     _parse_caps_guest(guest) for guest in host_caps.findall("guest")
3304                 ],
3305             },
3306             "domains": [
3307                 _parse_domain_caps(
3308                     ElementTree.fromstring(
3309                         conn.getDomainCapabilities(emulator, arch, None, domain)
3310                     )
3311                 )
3312                 for (arch, domain, emulator) in flattened
3313             ],
3314         }
3315         return result
3316     finally:
3317         conn.close()
3318 def cpu_baseline(full=False, migratable=False, out="libvirt", **kwargs):
3319     conn = __get_conn(**kwargs)
3320     caps = ElementTree.fromstring(conn.getCapabilities())
3321     cpu = caps.find("host/cpu")
3322     host_cpu_def = xmlutil.element_to_str(cpu)
3323     log.debug("Host CPU model definition: %s", host_cpu_def)
3324     flags = 0
3325     if migratable:
3326         if getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_MIGRATABLE", False):
3327             flags += libvirt.VIR_CONNECT_BASELINE_CPU_MIGRATABLE
3328         else:
3329             conn.close()
3330             raise ValueError
3331     if full and getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES", False):
3332         flags += libvirt.VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES
3333     cpu = ElementTree.fromstring(conn.baselineCPU([host_cpu_def], flags))
3334     conn.close()
3335     if full and not getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES", False):
3336         with salt.utils.files.fopen("/usr/share/libvirt/cpu_map.xml", "r") as cpu_map:
3337             cpu_map = ElementTree.parse(cpu_map)
3338         cpu_model = cpu.find("model").text
3339         while cpu_model:
3340             cpu_map_models = cpu_map.findall("arch/model")
3341             cpu_specs = [
3342                 el
3343                 for el in cpu_map_models
3344                 if el.get("name") == cpu_model and bool(len(el))
3345             ]
3346             if not cpu_specs:
3347                 raise ValueError("Model {} not found in CPU map".format(cpu_model))
3348             elif len(cpu_specs) &gt; 1:
3349                 raise ValueError(
3350                     "Multiple models {} found in CPU map".format(cpu_model)
3351                 )
3352             cpu_specs = cpu_specs[0]
3353             model_node = cpu_specs.find("model")
3354             if model_node is None:
3355                 cpu_model = None
3356             else:
3357                 cpu_model = model_node.get("name")
3358             cpu.extend([feature for feature in cpu_specs.findall("feature")])
3359     if out == "salt":
3360         return {
3361             "model": cpu.find("model").text,
3362             "vendor": cpu.find("vendor").text,
3363             "features": [feature.get("name") for feature in cpu.findall("feature")],
3364         }
3365     return ElementTree.tostring(cpu)
3366 def network_define(
3367     name,
3368     bridge,
3369     forward,
3370     ipv4_config=None,
3371     ipv6_config=None,
3372     vport=None,
3373     tag=None,
3374     autostart=True,
3375     start=True,
3376     mtu=None,
3377     domain=None,
3378     nat=None,
3379     interfaces=None,
3380     addresses=None,
3381     physical_function=None,
3382     dns=None,
3383     **kwargs
3384 ):
3385     conn = __get_conn(**kwargs)
3386     vport = kwargs.get("vport", None)
3387     tag = kwargs.get("tag", None)
3388     net_xml = _gen_net_xml(
3389         name,
3390         bridge,
3391         forward,
3392         vport,
3393         tag=tag,
3394         ip_configs=[config for config in [ipv4_config, ipv6_config] if config],
3395         mtu=mtu,
3396         domain=domain,
3397         nat=nat,
3398         interfaces=interfaces,
3399         addresses=addresses,
3400         physical_function=physical_function,
3401         dns=dns,
3402     )
3403     try:
3404         conn.networkDefineXML(net_xml)
3405     except libvirt.libvirtError as err:
3406         log.warning(err)
3407         conn.close()
3408         raise err  # a real error we should report upwards
3409     try:
3410         network = conn.networkLookupByName(name)
3411     except libvirt.libvirtError as err:
3412         log.warning(err)
3413         conn.close()
3414         raise err  # a real error we should report upwards
3415     if network is None:
3416         conn.close()
3417         return False
3418     if (start or autostart) and network.isActive() != 1:
3419         network.create()
3420     if autostart and network.autostart() != 1:
3421         network.setAutostart(int(autostart))
3422     elif not autostart and network.autostart() == 1:
3423         network.setAutostart(int(autostart))
3424     conn.close()
3425     return True
3426 def _remove_empty_xml_node(node):
3427     for child in node:
3428         if not child.tail and not child.text and not child.items() and not child:
3429             node.remove(child)
3430         else:
3431             _remove_empty_xml_node(child)
3432     return node
3433 def network_update(
3434     name,
3435     bridge,
3436     forward,
3437     ipv4_config=None,
3438     ipv6_config=None,
3439     vport=None,
3440     tag=None,
3441     mtu=None,
3442     domain=None,
3443     nat=None,
3444     interfaces=None,
3445     addresses=None,
3446     physical_function=None,
3447     dns=None,
3448     test=False,
3449     **kwargs
3450 ):
3451     conn = __get_conn(**kwargs)
3452     needs_update = False
3453     try:
3454         net = conn.networkLookupByName(name)
3455         old_xml = ElementTree.fromstring(net.XMLDesc())
3456         new_xml = ElementTree.fromstring(
3457             _gen_net_xml(
3458                 name,
3459                 bridge,
3460                 forward,
3461                 vport,
3462                 tag=tag,
3463                 ip_configs=[config for config in [ipv4_config, ipv6_config] if config],
3464                 mtu=mtu,
3465                 domain=domain,
3466                 nat=nat,
3467                 interfaces=interfaces,
3468                 addresses=addresses,
3469                 physical_function=physical_function,
3470                 dns=dns,
3471             )
3472         )
3473         elements_to_copy = ["uuid", "mac"]
3474         for to_copy in elements_to_copy:
3475             element = old_xml.find(to_copy)
3476             if element is not None:
3477                 new_xml.insert(1, element)
3478         old_xml.attrib.pop("connections", None)
3479         if old_xml.find("forward/pf") is not None:
3480             forward_node = old_xml.find("forward")
3481             address_nodes = forward_node.findall("address")
3482             for node in address_nodes:
3483                 forward_node.remove(node)
3484         default_bridge_attribs = {"stp": "on", "delay": "0"}
3485         old_bridge_node = old_xml.find("bridge")
3486         if old_bridge_node is not None:
3487             for key, value in default_bridge_attribs.items():
3488                 if old_bridge_node.get(key, None) == value:
3489                     old_bridge_node.attrib.pop(key, None)
3490             old_forward = (
3491                 old_xml.find("forward").get("mode")
3492                 if old_xml.find("forward") is not None
3493                 else None
3494             )
3495             if (
3496                 old_forward == forward
3497                 and forward in ["nat", "route", "open", None]
3498                 and bridge is None
3499                 and old_bridge_node.get("name", "").startswith("virbr")
3500             ):
3501                 old_bridge_node.attrib.pop("name", None)
3502         ipv4_nodes = [
3503             node
3504             for node in old_xml.findall("ip")
3505             if node.get("family", "ipv4") == "ipv4"
3506         ]
3507         for ip_node in ipv4_nodes:
3508             netmask = ip_node.attrib.pop("netmask", None)
3509             if netmask:
3510                 address = ipaddress.ip_network(
3511                     "{}/{}".format(ip_node.get("address"), netmask), strict=False
3512                 )
3513                 ip_node.set("prefix", str(address.prefixlen))
3514         for doc in [old_xml, new_xml]:
3515             for node in doc.findall("ip"):
3516                 if "family" not in node.keys():
3517                     node.set("family", "ipv4")
3518         _remove_empty_xml_node(xmlutil.strip_spaces(old_xml))
3519         xmlutil.strip_spaces(new_xml)
3520         needs_update = xmlutil.to_dict(old_xml, True) != xmlutil.to_dict(new_xml, True)
3521         if needs_update and not test:
3522             conn.networkDefineXML(xmlutil.element_to_str(new_xml))
3523     finally:
3524         conn.close()
3525     return needs_update
3526 def list_networks(**kwargs):
3527     conn = __get_conn(**kwargs)
3528     try:
3529         return [net.name() for net in conn.listAllNetworks()]
3530     finally:
3531         conn.close()
3532 def network_info(name=None, **kwargs):
3533     result = {}
3534     conn = __get_conn(**kwargs)
3535     def _net_get_leases(net):
3536         leases = net.DHCPLeases()
3537         for lease in leases:
3538             if lease["type"] == libvirt.VIR_IP_ADDR_TYPE_IPV4:
3539                 lease["type"] = "ipv4"
3540             elif lease["type"] == libvirt.VIR_IP_ADDR_TYPE_IPV6:
3541                 lease["type"] = "ipv6"
3542             else:
3543                 lease["type"] = "unknown"
3544         return leases
3545     def _net_get_bridge(net):
3546         try:
3547             return net.bridgeName()
3548         except libvirt.libvirtError as err:
3549             return None
3550     try:
3551         nets = [
3552             net for net in conn.listAllNetworks() if name is None or net.name() == name
3553         ]
3554         result = {
3555             net.name(): {
3556                 "uuid": net.UUIDString(),
3557                 "bridge": _net_get_bridge(net),
3558                 "autostart": net.autostart(),
3559                 "active": net.isActive(),
3560                 "persistent": net.isPersistent(),
3561                 "leases": _net_get_leases(net),
3562             }
3563             for net in nets
3564         }
3565     except libvirt.libvirtError as err:
3566         log.debug("Silenced libvirt error: %s", err)
3567     finally:
3568         conn.close()
3569     return result
3570 def network_get_xml(name, **kwargs):
3571     conn = __get_conn(**kwargs)
3572     try:
3573         return conn.networkLookupByName(name).XMLDesc()
3574     finally:
3575         conn.close()
3576 def network_start(name, **kwargs):
3577     conn = __get_conn(**kwargs)
3578     try:
3579         net = conn.networkLookupByName(name)
3580         return not bool(net.create())
3581     finally:
3582         conn.close()
3583 def network_stop(name, **kwargs):
3584     conn = __get_conn(**kwargs)
3585     try:
3586         net = conn.networkLookupByName(name)
3587         return not bool(net.destroy())
3588     finally:
3589         conn.close()
3590 def network_undefine(name, **kwargs):
3591     conn = __get_conn(**kwargs)
3592     try:
3593         net = conn.networkLookupByName(name)
3594         return not bool(net.undefine())
3595     finally:
3596         conn.close()
3597 def network_set_autostart(name, state="on", **kwargs):
3598     conn = __get_conn(**kwargs)
3599     try:
3600         net = conn.networkLookupByName(name)
3601         return not bool(net.setAutostart(1 if state == "on" else 0))
3602     finally:
3603         conn.close()
3604 def _parse_pools_caps(doc):
3605     def _parse_pool_caps(pool):
3606         pool_caps = {
3607             "name": pool.get("type"),
3608             "supported": pool.get("supported", "no") == "yes",
3609         }
3610         for option_kind in ["pool", "vol"]:
3611             options = {}
3612             default_format_node = pool.find(
3613                 "{}Options/defaultFormat".format(option_kind)
3614             )
3615             if default_format_node is not None:
3616                 options["default_format"] = default_format_node.get("type")
3617             options_enums = {
3618                 enum.get("name"): [value.text for value in enum.findall("value")]
3619                 for enum in pool.findall("{}Options/enum".format(option_kind))
3620             }
3621             if options_enums:
3622                 options.update(options_enums)
3623             if options:
3624                 if "options" not in pool_caps:
3625                     pool_caps["options"] = {}
3626                 kind = option_kind if option_kind != "vol" else "volume"
3627                 pool_caps["options"][kind] = options
3628         return pool_caps
3629     return [_parse_pool_caps(pool) for pool in doc.findall("pool")]
3630 def _pool_capabilities(conn):
3631     has_pool_capabilities = bool(getattr(conn, "getStoragePoolCapabilities", None))
3632     if has_pool_capabilities:
3633         caps = ElementTree.fromstring(conn.getStoragePoolCapabilities())
3634         pool_types = _parse_pools_caps(caps)
3635     else:
3636         all_hypervisors = ["xen", "kvm", "bhyve"]
3637         images_formats = [
3638             "none",
3639             "raw",
3640             "dir",
3641             "bochs",
3642             "cloop",
3643             "dmg",
3644             "iso",
3645             "vpc",
3646             "vdi",
3647             "fat",
3648             "vhd",
3649             "ploop",
3650             "cow",
3651             "qcow",
3652             "qcow2",
3653             "qed",
3654             "vmdk",
3655         ]
3656         common_drivers = [
3657             {
3658                 "name": "fs",
3659                 "default_source_format": "auto",
3660                 "source_formats": [
3661                     "auto",
3662                     "ext2",
3663                     "ext3",
3664                     "ext4",
3665                     "ufs",
3666                     "iso9660",
3667                     "udf",
3668                     "gfs",
3669                     "gfs2",
3670                     "vfat",
3671                     "hfs+",
3672                     "xfs",
3673                     "ocfs2",
3674                 ],
3675                 "default_target_format": "raw",
3676                 "target_formats": images_formats,
3677             },
3678             {
3679                 "name": "dir",
3680                 "default_target_format": "raw",
3681                 "target_formats": images_formats,
3682             },
3683             {"name": "iscsi"},
3684             {"name": "scsi"},
3685             {
3686                 "name": "logical",
3687                 "default_source_format": "lvm2",
3688                 "source_formats": ["unknown", "lvm2"],
3689             },
3690             {
3691                 "name": "netfs",
3692                 "default_source_format": "auto",
3693                 "source_formats": ["auto", "nfs", "glusterfs", "cifs"],
3694                 "default_target_format": "raw",
3695                 "target_formats": images_formats,
3696             },
3697             {
3698                 "name": "disk",
3699                 "default_source_format": "unknown",
3700                 "source_formats": [
3701                     "unknown",
3702                     "dos",
3703                     "dvh",
3704                     "gpt",
3705                     "mac",
3706                     "bsd",
3707                     "pc98",
3708                     "sun",
3709                     "lvm2",
3710                 ],
3711                 "default_target_format": "none",
3712                 "target_formats": [
3713                     "none",
3714                     "linux",
3715                     "fat16",
3716                     "fat32",
3717                     "linux-swap",
3718                     "linux-lvm",
3719                     "linux-raid",
3720                     "extended",
3721                 ],
3722             },
3723             {"name": "mpath"},
3724             {"name": "rbd", "default_target_format": "raw", "target_formats": []},
3725             {
3726                 "name": "sheepdog",
3727                 "version": 10000,
3728                 "hypervisors": ["kvm"],
3729                 "default_target_format": "raw",
3730                 "target_formats": images_formats,
3731             },
3732             {
3733                 "name": "gluster",
3734                 "version": 1002000,
3735                 "hypervisors": ["kvm"],
3736                 "default_target_format": "raw",
3737                 "target_formats": images_formats,
3738             },
3739             {"name": "zfs", "version": 1002008, "hypervisors": ["bhyve"]},
3740             {
3741                 "name": "iscsi-direct",
3742                 "version": 4007000,
3743                 "hypervisors": ["kvm", "xen"],
3744             },
3745         ]
3746         libvirt_version = conn.getLibVersion()
3747         hypervisor = get_hypervisor()
3748         def _get_backend_output(backend):
3749             output = {
3750                 "name": backend["name"],
3751                 "supported": (
3752                     not backend.get("version") or libvirt_version &gt;= backend["version"]
3753                 )
3754                 and hypervisor in backend.get("hypervisors", all_hypervisors),
3755                 "options": {
3756                     "pool": {
3757                         "default_format": backend.get("default_source_format"),
3758                         "sourceFormatType": backend.get("source_formats"),
3759                     },
3760                     "volume": {
3761                         "default_format": backend.get("default_target_format"),
3762                         "targetFormatType": backend.get("target_formats"),
3763                     },
3764                 },
3765             }
3766             for option_kind in ["pool", "volume"]:
3767                 if not [
3768                     value
3769                     for value in output["options"][option_kind].values()
3770                     if value is not None
3771                 ]:
3772                     del output["options"][option_kind]
3773             if not output["options"]:
3774                 del output["options"]
3775             return output
3776         pool_types = [_get_backend_output(backend) for backend in common_drivers]
3777     return {
3778         "computed": not has_pool_capabilities,
3779         "pool_types": pool_types,
3780     }
3781 def pool_capabilities(**kwargs):
3782     try:
3783         conn = __get_conn(**kwargs)
3784         return _pool_capabilities(conn)
3785     finally:
3786         conn.close()
3787 def pool_define(
3788     name,
3789     ptype,
3790     target=None,
3791     permissions=None,
3792     source_devices=None,
3793     source_dir=None,
3794     source_initiator=None,
3795     source_adapter=None,
3796     source_hosts=None,
3797     source_auth=None,
3798     source_name=None,
3799     source_format=None,
3800     transient=False,
3801     start=True,  # pylint: disable=redefined-outer-name
3802     **kwargs
3803 ):
3804     conn = __get_conn(**kwargs)
3805     auth = _pool_set_secret(conn, ptype, name, source_auth)
3806     pool_xml = _gen_pool_xml(
3807         name,
3808         ptype,
3809         target,
3810         permissions=permissions,
3811         source_devices=source_devices,
3812         source_dir=source_dir,
3813         source_adapter=source_adapter,
3814         source_hosts=source_hosts,
3815         source_auth=auth,
3816         source_name=source_name,
3817         source_format=source_format,
3818         source_initiator=source_initiator,
3819     )
3820     try:
3821         if transient:
3822             pool = conn.storagePoolCreateXML(pool_xml)
3823         else:
3824             pool = conn.storagePoolDefineXML(pool_xml)
3825             if start:
3826                 pool.create()
3827     except libvirt.libvirtError as err:
3828         raise err  # a real error we should report upwards
3829     finally:
3830         conn.close()
3831     return True
3832 def _pool_set_secret(
3833     conn, pool_type, pool_name, source_auth, uuid=None, usage=None, test=False
3834 ):
3835     secret_types = {"rbd": "ceph", "iscsi": "chap", "iscsi-direct": "chap"}
3836     secret_type = secret_types.get(pool_type)
3837     auth = source_auth
3838     if source_auth and "username" in source_auth and "password" in source_auth:
3839         if secret_type:
3840             secret = None
3841             try:
3842                 if usage:
3843                     usage_type = (
3844                         libvirt.VIR_SECRET_USAGE_TYPE_CEPH
3845                         if secret_type == "ceph"
3846                         else libvirt.VIR_SECRET_USAGE_TYPE_ISCSI
3847                     )
3848                     secret = conn.secretLookupByUsage(usage_type, usage)
3849                 elif uuid:
3850                     secret = conn.secretLookupByUUIDString(uuid)
3851             except libvirt.libvirtError as err:
3852                 log.info("Secret not found: %s", err.get_error_message())
3853             if not secret:
3854                 description = "Passphrase for {} pool created by Salt".format(pool_name)
3855                 if not usage:
3856                     usage = "pool_{}".format(pool_name)
3857                 secret_xml = _gen_secret_xml(secret_type, usage, description)
3858                 if not test:
3859                     secret = conn.secretDefineXML(secret_xml)
3860             password = auth["password"]
3861             if pool_type == "rbd":
3862                 password = base64.b64decode(salt.utils.stringutils.to_bytes(password))
3863             if not test:
3864                 secret.setValue(password)
3865             auth["type"] = secret_type
3866             auth["secret"] = {
3867                 "type": "uuid" if uuid else "usage",
3868                 "value": uuid if uuid else usage,
3869             }
3870     return auth
3871 def pool_update(
3872     name,
3873     ptype,
3874     target=None,
3875     permissions=None,
3876     source_devices=None,
3877     source_dir=None,
3878     source_initiator=None,
3879     source_adapter=None,
3880     source_hosts=None,
3881     source_auth=None,
3882     source_name=None,
3883     source_format=None,
3884     test=False,
3885     **kwargs
3886 ):
3887     conn = __get_conn(**kwargs)
3888     needs_update = False
3889     try:
3890         pool = conn.storagePoolLookupByName(name)
3891         old_xml = ElementTree.fromstring(pool.XMLDesc())
3892         secret_node = old_xml.find("source/auth/secret")
3893         usage = secret_node.get("usage") if secret_node is not None else None
3894         uuid = secret_node.get("uuid") if secret_node is not None else None
3895         auth = _pool_set_secret(
3896             conn, ptype, name, source_auth, uuid=uuid, usage=usage, test=test
3897         )
3898         new_xml = ElementTree.fromstring(
3899             _gen_pool_xml(
3900                 name,
3901                 ptype,
3902                 target,
3903                 permissions=permissions,
3904                 source_devices=source_devices,
3905                 source_dir=source_dir,
3906                 source_initiator=source_initiator,
3907                 source_adapter=source_adapter,
3908                 source_hosts=source_hosts,
3909                 source_auth=auth,
3910                 source_name=source_name,
3911                 source_format=source_format,
3912             )
3913         )
3914         elements_to_copy = ["available", "allocation", "capacity", "uuid"]
3915         for to_copy in elements_to_copy:
3916             element = old_xml.find(to_copy)
3917             new_xml.insert(1, element)
3918         _remove_empty_xml_node(xmlutil.strip_spaces(old_xml))
3919         xmlutil.strip_spaces(new_xml)
3920         needs_update = xmlutil.to_dict(old_xml, True) != xmlutil.to_dict(new_xml, True)
3921         if needs_update and not test:
3922             conn.storagePoolDefineXML(xmlutil.element_to_str(new_xml))
3923     finally:
3924         conn.close()
3925     return needs_update
3926 def list_pools(**kwargs):
3927     conn = __get_conn(**kwargs)
3928     try:
3929         return [pool.name() for pool in conn.listAllStoragePools()]
3930     finally:
3931         conn.close()
3932 def pool_info(name=None, **kwargs):
3933     result = {}
3934     conn = __get_conn(**kwargs)
3935     def _pool_extract_infos(pool):
3936         states = ["inactive", "building", "running", "degraded", "inaccessible"]
3937         infos = pool.info()
3938         state = states[infos[0]] if infos[0] &lt; len(states) else "unknown"
3939         desc = ElementTree.fromstring(pool.XMLDesc())
3940         path_node = desc.find("target/path")
3941         return {
3942             "uuid": pool.UUIDString(),
3943             "state": state,
3944             "capacity": infos[1],
3945             "allocation": infos[2],
3946             "free": infos[3],
3947             "autostart": pool.autostart(),
3948             "persistent": pool.isPersistent(),
3949             "target_path": path_node.text if path_node is not None else None,
3950             "type": desc.get("type"),
3951         }
3952     try:
3953         pools = [
3954             pool
3955             for pool in conn.listAllStoragePools()
3956             if name is None or pool.name() == name
3957         ]
3958         result = {pool.name(): _pool_extract_infos(pool) for pool in pools}
3959     except libvirt.libvirtError as err:
3960         log.debug("Silenced libvirt error: %s", err)
3961     finally:
3962         conn.close()
3963     return result
3964 def pool_get_xml(name, **kwargs):
3965     conn = __get_conn(**kwargs)
3966     try:
3967         return conn.storagePoolLookupByName(name).XMLDesc()
3968     finally:
3969         conn.close()
3970 def pool_start(name, **kwargs):
3971     conn = __get_conn(**kwargs)
3972     try:
3973         pool = conn.storagePoolLookupByName(name)
3974         return not bool(pool.create())
3975     finally:
3976         conn.close()
3977 def pool_build(name, **kwargs):
3978     conn = __get_conn(**kwargs)
3979     try:
3980         pool = conn.storagePoolLookupByName(name)
3981         return not bool(pool.build())
3982     finally:
3983         conn.close()
3984 def pool_stop(name, **kwargs):
3985     conn = __get_conn(**kwargs)
3986     try:
3987         pool = conn.storagePoolLookupByName(name)
3988         return not bool(pool.destroy())
3989     finally:
3990         conn.close()
3991 def pool_undefine(name, **kwargs):
3992     conn = __get_conn(**kwargs)
3993     try:
3994         pool = conn.storagePoolLookupByName(name)
3995         desc = ElementTree.fromstring(pool.XMLDesc())
3996         auth_node = desc.find("source/auth")
3997         if auth_node is not None:
3998             auth_types = {
3999                 "ceph": libvirt.VIR_SECRET_USAGE_TYPE_CEPH,
4000                 "iscsi": libvirt.VIR_SECRET_USAGE_TYPE_ISCSI,
4001             }
4002             secret_type = auth_types[auth_node.get("type")]
4003             secret_usage = auth_node.find("secret").get("usage")
4004             if secret_type and "pool_{}".format(name) == secret_usage:
4005                 secret = conn.secretLookupByUsage(secret_type, secret_usage)
4006                 secret.undefine()
4007         return not bool(pool.undefine())
4008     finally:
4009         conn.close()
4010 def pool_delete(name, **kwargs):
4011     conn = __get_conn(**kwargs)
4012     try:
4013         pool = conn.storagePoolLookupByName(name)
4014         return not bool(pool.delete(libvirt.VIR_STORAGE_POOL_DELETE_NORMAL))
4015     finally:
4016         conn.close()
4017 def pool_refresh(name, **kwargs):
4018     conn = __get_conn(**kwargs)
4019     try:
4020         pool = conn.storagePoolLookupByName(name)
4021         return not bool(pool.refresh())
4022     finally:
4023         conn.close()
4024 def pool_set_autostart(name, state="on", **kwargs):
4025     conn = __get_conn(**kwargs)
4026     try:
4027         pool = conn.storagePoolLookupByName(name)
4028         return not bool(pool.setAutostart(1 if state == "on" else 0))
4029     finally:
4030         conn.close()
4031 def pool_list_volumes(name, **kwargs):
4032     conn = __get_conn(**kwargs)
4033     try:
4034         pool = conn.storagePoolLookupByName(name)
4035         return pool.listVolumes()
4036     finally:
4037         conn.close()
4038 def _get_storage_vol(conn, pool, vol):
4039     pool_obj = conn.storagePoolLookupByName(pool)
4040     return pool_obj.storageVolLookupByName(vol)
4041 def _is_valid_volume(vol):
4042     try:
4043         def discarder(ctxt, error):  # pylint: disable=unused-argument
4044             log.debug("Ignore libvirt error: %s", error[2])
4045         libvirt.registerErrorHandler(discarder, None)
4046         vol.info()
4047         libvirt.registerErrorHandler(None, None)
4048         return True
4049     except libvirt.libvirtError as err:
4050         return False
4051 def _get_all_volumes_paths(conn):
4052     pools = [
4053         pool
4054         for pool in conn.listAllStoragePools()
4055         if pool.info()[0] == libvirt.VIR_STORAGE_POOL_RUNNING
4056     ]
4057     volumes = {}
4058     for pool in pools:
4059         pool_volumes = {
4060             volume.path(): {
4061                 "pool": pool.name(),
4062                 "name": volume.name(),
4063                 "backing_stores": [
4064                     path.text
4065                     for path in ElementTree.fromstring(volume.XMLDesc()).findall(
4066                         ".//backingStore/path"
4067                     )
4068                 ],
4069             }
4070             for volume in pool.listAllVolumes()
4071             if _is_valid_volume(volume)
4072         }
4073         volumes.update(pool_volumes)
4074     return volumes
4075 def volume_infos(pool=None, volume=None, **kwargs):
4076     result = {}
4077     conn = __get_conn(**kwargs)
4078     try:
4079         backing_stores = _get_all_volumes_paths(conn)
4080         try:
4081             domains = _get_domain(conn)
4082             domains_list = domains if isinstance(domains, list) else [domains]
4083         except CommandExecutionError:
4084             domains_list = []
4085         disks = {
4086             domain.name(): {
4087                 node.get("file")
4088                 for node in ElementTree.fromstring(domain.XMLDesc(0)).findall(
4089                     ".//disk/source/[@file]"
4090                 )
4091             }
4092             for domain in domains_list
4093         }
4094         def _volume_extract_infos(vol):
4095             types = ["file", "block", "dir", "network", "netdir", "ploop"]
4096             infos = vol.info()
4097             vol_xml = ElementTree.fromstring(vol.XMLDesc())
4098             backing_store_path = vol_xml.find("./backingStore/path")
4099             backing_store_format = vol_xml.find("./backingStore/format")
4100             backing_store = None
4101             if backing_store_path is not None:
4102                 backing_store = {
4103                     "path": backing_store_path.text,
4104                     "format": backing_store_format.get("type")
4105                     if backing_store_format is not None
4106                     else None,
4107                 }
4108             format_node = vol_xml.find("./target/format")
4109             used_by = []
4110             if vol.path():
4111                 as_backing_store = {
4112                     path
4113                     for (path, volume) in backing_stores.items()
4114                     if vol.path() in volume.get("backing_stores")
4115                 }
4116                 used_by = [
4117                     vm_name
4118                     for (vm_name, vm_disks) in disks.items()
4119                     if vm_disks &amp; as_backing_store or vol.path() in vm_disks
4120                 ]
4121             return {
4122                 "type": types[infos[0]] if infos[0] &lt; len(types) else "unknown",
4123                 "key": vol.key(),
4124                 "path": vol.path(),
4125                 "capacity": infos[1],
4126                 "allocation": infos[2],
4127                 "used_by": used_by,
4128                 "backing_store": backing_store,
4129                 "format": format_node.get("type") if format_node is not None else None,
4130             }
4131         pools = [
4132             obj
4133             for obj in conn.listAllStoragePools()
4134             if (pool is None or obj.name() == pool)
4135             and obj.info()[0] == libvirt.VIR_STORAGE_POOL_RUNNING
4136         ]
4137         vols = {
4138             pool_obj.name(): {
4139                 vol.name(): _volume_extract_infos(vol)
4140                 for vol in pool_obj.listAllVolumes()
4141                 if (volume is None or vol.name() == volume) and _is_valid_volume(vol)
4142             }
4143             for pool_obj in pools
4144         }
4145         return {pool_name: volumes for (pool_name, volumes) in vols.items() if volumes}
4146     except libvirt.libvirtError as err:
4147         log.debug("Silenced libvirt error: %s", err)
4148     finally:
4149         conn.close()
4150     return result
4151 def volume_delete(pool, volume, **kwargs):
4152     conn = __get_conn(**kwargs)
4153     try:
4154         vol = _get_storage_vol(conn, pool, volume)
4155         return not bool(vol.delete())
4156     finally:
4157         conn.close()
4158 def volume_define(
4159     pool,
4160     name,
4161     size,
4162     allocation=0,
4163     format=None,
4164     type=None,
4165     permissions=None,
4166     backing_store=None,
4167     nocow=False,
4168     **kwargs
4169 ):
4170     ret = False
4171     try:
4172         conn = __get_conn(**kwargs)
4173         pool_obj = conn.storagePoolLookupByName(pool)
4174         pool_type = ElementTree.fromstring(pool_obj.XMLDesc()).get("type")
4175         new_allocation = allocation
4176         if pool_type == "logical" and size != allocation:
4177             new_allocation = size
4178         xml = _gen_vol_xml(
4179             name,
4180             size,
4181             format=format,
4182             allocation=new_allocation,
4183             type=type,
4184             permissions=permissions,
4185             backing_store=backing_store,
4186             nocow=nocow,
4187         )
4188         ret = _define_vol_xml_str(conn, xml, pool=pool)
4189     except libvirt.libvirtError as err:
4190         raise CommandExecutionError(err.get_error_message())
4191     finally:
4192         conn.close()
4193     return ret
4194 def _volume_upload(conn, pool, volume, file, offset=0, length=0, sparse=False):
4195     def handler(stream, nbytes, opaque):
4196         return os.read(opaque, nbytes)
4197     def holeHandler(stream, opaque):
4198         fd = opaque
4199         cur = os.lseek(fd, 0, os.SEEK_CUR)
4200         try:
4201             data = os.lseek(fd, cur, os.SEEK_DATA)
4202         except OSError as e:
4203             if e.errno != 6:
4204                 raise e
4205             else:
4206                 data = -1
4207         if data &lt; 0:
4208             inData = False
4209             eof = os.lseek(fd, 0, os.SEEK_END)
4210             if eof &lt; cur:
4211                 raise RuntimeError("Current position in file after EOF: {}".format(cur))
4212             sectionLen = eof - cur
4213         else:
4214             if data &gt; cur:
4215                 inData = False
4216                 sectionLen = data - cur
4217             else:
4218                 inData = True
4219                 hole = os.lseek(fd, data, os.SEEK_HOLE)
4220                 if hole &lt; 0:
4221                     raise RuntimeError("No trailing hole")
4222                 if hole == data:
4223                     raise RuntimeError("Impossible happened")
4224                 else:
4225                     sectionLen = hole - data
4226         os.lseek(fd, cur, os.SEEK_SET)
4227         return [inData, sectionLen]
4228     def skipHandler(stream, length, opaque):
4229         return os.lseek(opaque, length, os.SEEK_CUR)
4230     stream = None
4231     fd = None
4232     ret = False
4233     try:
4234         pool_obj = conn.storagePoolLookupByName(pool)
4235         vol_obj = pool_obj.storageVolLookupByName(volume)
4236         stream = conn.newStream()
4237         fd = os.open(file, os.O_RDONLY)
4238         vol_obj.upload(
4239             stream,
4240             offset,
4241             length,
4242             libvirt.VIR_STORAGE_VOL_UPLOAD_SPARSE_STREAM if sparse else 0,
4243         )
4244         if sparse:
4245             stream.sparseSendAll(handler, holeHandler, skipHandler, fd)
4246         else:
4247             stream.sendAll(handler, fd)
4248         ret = True
4249     except libvirt.libvirtError as err:
4250         raise CommandExecutionError(err.get_error_message())
4251     finally:
4252         if fd:
4253             try:
4254                 os.close(fd)
4255             except OSError as err:
4256                 if stream:
4257                     stream.abort()
4258                 if ret:
4259                     raise CommandExecutionError(
4260                         "Failed to close file: {}".format(err.strerror)
4261                     )
4262         if stream:
4263             try:
4264                 stream.finish()
4265             except libvirt.libvirtError as err:
4266                 if ret:
4267                     raise CommandExecutionError(
4268                         "Failed to finish stream: {}".format(err.get_error_message())
4269                     )
4270     return ret
4271 def volume_upload(pool, volume, file, offset=0, length=0, sparse=False, **kwargs):
4272     conn = __get_conn(**kwargs)
4273     ret = False
4274     try:
4275         ret = _volume_upload(
4276             conn, pool, volume, file, offset=offset, length=length, sparse=sparse
4277         )
4278     finally:
4279         conn.close()
4280     return ret
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
