
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 13, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-mixed_precision_test.py</h3>
            <pre><code>1  from absl.testing import parameterized
2  from sonnet.src import base
3  from sonnet.src import mixed_precision
4  from sonnet.src import test_utils
5  import tensorflow as tf
6  import tree
7  class DummyVar(base.Module, test_utils.TestCase):
8    def __init__(self, x):
9      super().__init__()
10      test_utils.TestCase.__init__(self)
11      self.x = x
12    def check_type(self, _, dtype):
13      self.assertTrue(self.x.dtype == dtype)  # pylint: disable=g-generic-assert
14      return self.x
15    def check_type_structure(self, _, dtype):
16      tree.map_structure(lambda y: self.assertTrue(y.dtype == dtype), self.x)
17      return self.x
18    def runTest(self):
19      pass
20  class DummyInput(test_utils.TestCase):
21    def __init__(self, _):
22      super().__init__()
23      test_utils.TestCase.__init__(self)
24    def check_type(self, x, dtype):
25      self.assertEqual(x.dtype, dtype)
26      return x
27    def check_type_structure(self, x, dtype):
28      tree.map_structure(lambda y: self.assertEqual(y.dtype, dtype), x)
29      return x
30    def runTest(self):
31      pass
32  @parameterized.parameters(DummyVar, DummyInput)
33  class MixedPrecisionClassTest(test_utils.TestCase):
34    def test_float16_mode_variable_eligible_class(self, test_class):
35      mixed_precision.enable(tf.float32)
36      x = tf.Variable([[1., 9.], [5., 0.]])
37      d = test_class(x)
38      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
39      mixed_precision.enable(tf.float16)
40      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
41      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
42    def test_float16_mode_disable_class(self, test_class):
43      mixed_precision.enable(tf.float32)
44      x = tf.Variable([[1., 9.], [5., 0.]])
45      d = test_class(x)
46      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
47      mixed_precision.enable(tf.float16)
48      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
49      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
50      mixed_precision.disable()
51      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
52    def test_float16_mode_nested_eligible_class(self, test_class):
53      mixed_precision.enable(tf.float32)
54      x = tf.Variable([[1., 9.], [5., 0.]])
55      y = tf.Variable([[1., 9.], [8., 9.]])
56      z = (x, y)
57      d = test_class(z)
58      d.check_type_structure = mixed_precision.modes([tf.float32, tf.float16])(
59          d.check_type_structure)
60      self.assertTrue(tree.is_nested(z))
61      mixed_precision.enable(tf.float16)
62      first_run = d.check_type_structure(z, tf.float32)
63      self.assertEqual(first_run[0].dtype, tf.float32)
64      self.assertEqual(first_run[1].dtype, tf.float32)
65      second_run = d.check_type_structure(z, tf.float16)
66      self.assertEqual(second_run[0].dtype, tf.float32)
67      self.assertEqual(second_run[1].dtype, tf.float32)
68    def test_float16_mode_eligible_multiple_instances_class(self, test_class):
69      mixed_precision.enable(tf.float32)
70      x = tf.Variable([[1., 9.], [5., 0.]])
71      d = test_class(x)
72      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
73      d2 = test_class(x)
74      d2.check_type = mixed_precision.modes([tf.float32, tf.float16])(
75          d2.check_type)
76      mixed_precision.enable(tf.float16)
77      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
78      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
79      self.assertEqual(d2.check_type(x, tf.float32).dtype, tf.float32)
80      self.assertEqual(d2.check_type(x, tf.float16).dtype, tf.float32)
81    def test_float16_mode_ineligible_multiple_instances_class(self, test_class):
82      mixed_precision.enable(tf.float32)
83      x = tf.Variable([[1., 9.], [5., 0.]])
84      d = test_class(x)
85      d.check_type = mixed_precision.modes([tf.float32, tf.bfloat16])(
86          d.check_type)
87      d2 = test_class(x)
88      d2.check_type = mixed_precision.modes([tf.float32, tf.bfloat16])(
89          d2.check_type)
90      mixed_precision.enable(tf.float16)
91      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
92      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
93      self.assertEqual(d2.check_type(x, tf.float32).dtype, tf.float32)
94      self.assertEqual(d2.check_type(x, tf.float32).dtype, tf.float32)
95    def test_float16_mode_multiple_instances_different_eligibility_class(
96        self, test_class):
97      mixed_precision.enable(tf.float32)
98      x = tf.Variable([[1., 9.], [5., 0.]])
99      d = test_class(x)
100      d.check_type = mixed_precision.modes([tf.float32, tf.bfloat16])(
101          d.check_type)
102      d2 = test_class(x)
103      d2.check_type = mixed_precision.modes([tf.float32, tf.float16])(
104          d2.check_type)
105      mixed_precision.enable(tf.float16)
106      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
107      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
108      self.assertEqual(d2.check_type(x, tf.float32).dtype, tf.float32)
109      self.assertEqual(d2.check_type(x, tf.float16).dtype, tf.float32)
110    def test_bfloat16_input_float16_mode_eligible_class(self, test_class):
111      mixed_precision.enable(tf.float32)
112      x = tf.Variable([[1., 9.], [5., 0.]], dtype=tf.bfloat16)
113      d = test_class(x)
114      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
115      mixed_precision.enable(tf.float16)
116      self.assertEqual(d.check_type(x, tf.bfloat16).dtype, tf.bfloat16)
117      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
118    def test_float16_input_float32_mode_eligible_class(self, test_class):
119      if self.primary_device == 'TPU':
120        self.skipTest('float16 not supported on TPU')
121      mixed_precision.enable(tf.float32)
122      x = tf.Variable([[1., 9.], [5., 0.]], dtype=tf.float16)
123      d = test_class(x)
124      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
125      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float16)
126      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
127    def test_function_create_module_eligible(self, test_class):
128      mixed_precision.enable(tf.float16)
129      @mixed_precision.modes([tf.float32, tf.float16])
130      def model():
131        x = tf.Variable([[1., 9.], [8., 9.]])
132        d = test_class(x)
133        d.check_type = mixed_precision.modes([tf.float32, tf.float16])(
134            d.check_type)
135        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
136        self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
137      model()
138    def test_function_create_module_ineligible(self, test_class):
139      mixed_precision.enable(tf.float16)
140      @mixed_precision.modes([tf.float32, tf.float16])
141      def model():
142        x = tf.Variable([[1., 9.], [8., 9.]])
143        d = test_class(x)
144        d.check_type = mixed_precision.modes([tf.float32, tf.bfloat16])(
145            d.check_type)
146        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
147        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
148      model()
149    def test_function_create_module_not_decorated(self, test_class):
150      mixed_precision.enable(tf.float16)
151      @mixed_precision.modes([tf.float32, tf.float16])
152      def model():
153        x = tf.Variable([[1., 9.], [8., 9.]])
154        d = test_class(x)
155        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
156        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
157      model()
158    def test_scoping_option(self, test_class):
159      mixed_precision.enable(tf.float32)
160      x = tf.Variable([[1., 9.], [8., 9.]])
161      d = test_class(x)
162      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
163      with mixed_precision.scope(tf.float16):
164        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
165        self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
166      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
167    def test_scoping_disable(self, test_class):
168      mixed_precision.enable(tf.float32)
169      x = tf.Variable([[1., 9.], [8., 9.]])
170      d = test_class(x)
171      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
172      with mixed_precision.scope(tf.float16):
173        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
174        self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
175        mixed_precision.disable()
176        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
177    def test_nested_scoping(self, test_class):
178      mixed_precision.enable(tf.float32)
179      x = tf.Variable([[1., 9.], [8., 9.]])
180      d = test_class(x)
181      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
182      with mixed_precision.scope(tf.float16):
183        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
184        self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
185        with mixed_precision.scope(tf.float32):
186          self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
187          with mixed_precision.scope(tf.float16):
188            self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
189      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
190  class MixedPrecisionTest(test_utils.TestCase):
191    def test_float16_mode_eligible_func(self):
192      mixed_precision.enable(tf.float32)
193      self.assertEqual(mixed_precision._get_mixed_precision_mode(), tf.float32)
194      @mixed_precision.modes([tf.float32, tf.float16])
195      def check_type(x, expected_dtype):
196        self.assertEqual(x.dtype, expected_dtype)
197        return x
198      mixed_precision.enable(tf.float16)
199      x = tf.Variable([[1., 3], [5., 7.]])
200      self.assertEqual(x.dtype, tf.float32)
201      self.assertEqual(check_type(x, tf.float32).dtype, tf.float32)
202      self.assertEqual(check_type(x, tf.float16).dtype, tf.float32)
203    def test_float32_mode_eligible_func(self):
204      mixed_precision.enable(tf.float32)
205      self.assertEqual(mixed_precision._get_mixed_precision_mode(), tf.float32)
206      @mixed_precision.modes([tf.float32, tf.float16])
207      def fwd_func(x):
208        self.assertEqual(x.dtype, tf.float32)
209        return x
210      x = tf.Variable([[1., 3], [5., 7.]])
211      self.assertEqual(x.dtype, tf.float32)
212      self.assertEqual(fwd_func(x).dtype, tf.float32)
213      self.assertEqual(fwd_func(x).dtype, tf.float32)
214    def test_float16_mode_ineligible_func(self):
215      mixed_precision.enable(tf.float32)
216      @mixed_precision.modes([tf.float32, tf.bfloat16])
217      def fwd_func(x):
218        self.assertEqual(x.dtype, tf.float32)
219        return x
220      x = tf.Variable([[1., 3], [5., 7.]])
221      self.assertEqual(x.dtype, tf.float32)
222      mixed_precision.enable(tf.float16)
223      self.assertEqual(fwd_func(x).dtype, tf.float32)
224      self.assertEqual(fwd_func(x).dtype, tf.float32)
225    def test_dont_cast_non_floats_func(self):
226      mixed_precision.enable(tf.float32)
227      @mixed_precision.modes([tf.float32, tf.float16])
228      def fwd_func(x):
229        self.assertTrue(x.dtype.is_integer)
230        return x
231      x = tf.Variable([[1, 9], [8, 9]])
232      self.assertTrue(x.dtype.is_integer)
233      mixed_precision.enable(tf.float16)
<span onclick='openModal()' class='match'>234      self.assertTrue(fwd_func(x).dtype.is_integer)
235      self.assertTrue(fwd_func(x).dtype.is_integer)
</span>236    def test_non_tensor_variable_input_no_cast_func(self):
237      mixed_precision.enable(tf.float32)
238      @mixed_precision.modes([tf.float32, tf.float16])
239      def fwd_func(x):
240        self.assertEqual(type(x[0][0]), float)
241        return x
242      x = [[1., 3], [5., 7.]]
243      self.assertEqual(type(x[0][0]), float)
244      mixed_precision.enable(tf.float16)
245      self.assertEqual(type(fwd_func(x)[0][0]), float)
246      self.assertEqual(type(fwd_func(x)[0][0]), float)
247    def test_float16_mode_enabled_call_function(self):
248      mixed_precision.enable(tf.float32)
249      class DummyCall(base.Module, test_utils.TestCase):
250        def __init__(self):
251          super().__init__()
252          test_utils.TestCase.__init__(self)
253          self.y = tf.Variable([[1., 3], [5., 7.]])
254        @mixed_precision.modes([tf.float16, tf.float32])
255        def __call__(self, x, dtype):
256          self.assertTrue(self.y.dtype == dtype)
257          self.assertTrue(x.dtype == dtype)
258          return x
259        def runTest(self):
260          pass
261      x = tf.Variable([[1., 3], [5., 7.]])
262      self.assertEqual(x.dtype, tf.float32)
263      d = DummyCall()
264      mixed_precision.enable(tf.float16)
265      self.assertEqual(d(x, tf.float32).dtype, tf.float32)
266      self.assertEqual(d(x, tf.float16).dtype, tf.float32)
267    def test_float16_mode_tensor_eligible_class(self):
268      mixed_precision.enable(tf.float32)
269      x = tf.constant([[1., 9.], [5., 0.]])
270      d = DummyInput(x)
271      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
272      mixed_precision.enable(tf.float16)
273      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
274      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
275  if __name__ == '__main__':
276    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-mixed_precision_test.py</h3>
            <pre><code>1  from absl.testing import parameterized
2  from sonnet.src import base
3  from sonnet.src import mixed_precision
4  from sonnet.src import test_utils
5  import tensorflow as tf
6  import tree
7  class DummyVar(base.Module, test_utils.TestCase):
8    def __init__(self, x):
9      super().__init__()
10      test_utils.TestCase.__init__(self)
11      self.x = x
12    def check_type(self, _, dtype):
13      self.assertTrue(self.x.dtype == dtype)  # pylint: disable=g-generic-assert
14      return self.x
15    def check_type_structure(self, _, dtype):
16      tree.map_structure(lambda y: self.assertTrue(y.dtype == dtype), self.x)
17      return self.x
18    def runTest(self):
19      pass
20  class DummyInput(test_utils.TestCase):
21    def __init__(self, _):
22      super().__init__()
23      test_utils.TestCase.__init__(self)
24    def check_type(self, x, dtype):
25      self.assertEqual(x.dtype, dtype)
26      return x
27    def check_type_structure(self, x, dtype):
28      tree.map_structure(lambda y: self.assertEqual(y.dtype, dtype), x)
29      return x
30    def runTest(self):
31      pass
32  @parameterized.parameters(DummyVar, DummyInput)
33  class MixedPrecisionClassTest(test_utils.TestCase):
34    def test_float16_mode_variable_eligible_class(self, test_class):
35      mixed_precision.enable(tf.float32)
36      x = tf.Variable([[1., 9.], [5., 0.]])
37      d = test_class(x)
38      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
39      mixed_precision.enable(tf.float16)
40      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
41      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
42    def test_float16_mode_disable_class(self, test_class):
43      mixed_precision.enable(tf.float32)
44      x = tf.Variable([[1., 9.], [5., 0.]])
45      d = test_class(x)
46      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
47      mixed_precision.enable(tf.float16)
48      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
49      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
50      mixed_precision.disable()
51      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
52    def test_float16_mode_nested_eligible_class(self, test_class):
53      mixed_precision.enable(tf.float32)
54      x = tf.Variable([[1., 9.], [5., 0.]])
55      y = tf.Variable([[1., 9.], [8., 9.]])
56      z = (x, y)
57      d = test_class(z)
58      d.check_type_structure = mixed_precision.modes([tf.float32, tf.float16])(
59          d.check_type_structure)
60      self.assertTrue(tree.is_nested(z))
61      mixed_precision.enable(tf.float16)
62      first_run = d.check_type_structure(z, tf.float32)
63      self.assertEqual(first_run[0].dtype, tf.float32)
64      self.assertEqual(first_run[1].dtype, tf.float32)
65      second_run = d.check_type_structure(z, tf.float16)
66      self.assertEqual(second_run[0].dtype, tf.float32)
67      self.assertEqual(second_run[1].dtype, tf.float32)
68    def test_float16_mode_eligible_multiple_instances_class(self, test_class):
69      mixed_precision.enable(tf.float32)
70      x = tf.Variable([[1., 9.], [5., 0.]])
71      d = test_class(x)
72      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
73      d2 = test_class(x)
74      d2.check_type = mixed_precision.modes([tf.float32, tf.float16])(
75          d2.check_type)
76      mixed_precision.enable(tf.float16)
77      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
78      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
79      self.assertEqual(d2.check_type(x, tf.float32).dtype, tf.float32)
80      self.assertEqual(d2.check_type(x, tf.float16).dtype, tf.float32)
81    def test_float16_mode_ineligible_multiple_instances_class(self, test_class):
82      mixed_precision.enable(tf.float32)
83      x = tf.Variable([[1., 9.], [5., 0.]])
84      d = test_class(x)
85      d.check_type = mixed_precision.modes([tf.float32, tf.bfloat16])(
86          d.check_type)
87      d2 = test_class(x)
88      d2.check_type = mixed_precision.modes([tf.float32, tf.bfloat16])(
89          d2.check_type)
90      mixed_precision.enable(tf.float16)
91      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
92      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
93      self.assertEqual(d2.check_type(x, tf.float32).dtype, tf.float32)
94      self.assertEqual(d2.check_type(x, tf.float32).dtype, tf.float32)
95    def test_float16_mode_multiple_instances_different_eligibility_class(
96        self, test_class):
97      mixed_precision.enable(tf.float32)
98      x = tf.Variable([[1., 9.], [5., 0.]])
99      d = test_class(x)
100      d.check_type = mixed_precision.modes([tf.float32, tf.bfloat16])(
101          d.check_type)
102      d2 = test_class(x)
103      d2.check_type = mixed_precision.modes([tf.float32, tf.float16])(
104          d2.check_type)
105      mixed_precision.enable(tf.float16)
106      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
107      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
108      self.assertEqual(d2.check_type(x, tf.float32).dtype, tf.float32)
109      self.assertEqual(d2.check_type(x, tf.float16).dtype, tf.float32)
110    def test_bfloat16_input_float16_mode_eligible_class(self, test_class):
111      mixed_precision.enable(tf.float32)
112      x = tf.Variable([[1., 9.], [5., 0.]], dtype=tf.bfloat16)
113      d = test_class(x)
114      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
115      mixed_precision.enable(tf.float16)
116      self.assertEqual(d.check_type(x, tf.bfloat16).dtype, tf.bfloat16)
117      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
118    def test_float16_input_float32_mode_eligible_class(self, test_class):
119      if self.primary_device == 'TPU':
120        self.skipTest('float16 not supported on TPU')
121      mixed_precision.enable(tf.float32)
122      x = tf.Variable([[1., 9.], [5., 0.]], dtype=tf.float16)
123      d = test_class(x)
124      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
125      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float16)
126      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
127    def test_function_create_module_eligible(self, test_class):
128      mixed_precision.enable(tf.float16)
129      @mixed_precision.modes([tf.float32, tf.float16])
130      def model():
131        x = tf.Variable([[1., 9.], [8., 9.]])
132        d = test_class(x)
133        d.check_type = mixed_precision.modes([tf.float32, tf.float16])(
134            d.check_type)
135        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
136        self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
137      model()
138    def test_function_create_module_ineligible(self, test_class):
139      mixed_precision.enable(tf.float16)
140      @mixed_precision.modes([tf.float32, tf.float16])
141      def model():
142        x = tf.Variable([[1., 9.], [8., 9.]])
143        d = test_class(x)
144        d.check_type = mixed_precision.modes([tf.float32, tf.bfloat16])(
145            d.check_type)
146        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
147        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
148      model()
149    def test_function_create_module_not_decorated(self, test_class):
150      mixed_precision.enable(tf.float16)
151      @mixed_precision.modes([tf.float32, tf.float16])
152      def model():
153        x = tf.Variable([[1., 9.], [8., 9.]])
154        d = test_class(x)
155        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
156        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
157      model()
158    def test_scoping_option(self, test_class):
159      mixed_precision.enable(tf.float32)
160      x = tf.Variable([[1., 9.], [8., 9.]])
161      d = test_class(x)
162      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
163      with mixed_precision.scope(tf.float16):
164        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
165        self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
166      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
167    def test_scoping_disable(self, test_class):
168      mixed_precision.enable(tf.float32)
169      x = tf.Variable([[1., 9.], [8., 9.]])
170      d = test_class(x)
171      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
172      with mixed_precision.scope(tf.float16):
173        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
174        self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
175        mixed_precision.disable()
176        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
177    def test_nested_scoping(self, test_class):
178      mixed_precision.enable(tf.float32)
179      x = tf.Variable([[1., 9.], [8., 9.]])
180      d = test_class(x)
181      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
182      with mixed_precision.scope(tf.float16):
183        self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
184        self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
185        with mixed_precision.scope(tf.float32):
186          self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
187          with mixed_precision.scope(tf.float16):
188            self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
189      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
190  class MixedPrecisionTest(test_utils.TestCase):
191    def test_float16_mode_eligible_func(self):
192      mixed_precision.enable(tf.float32)
193      self.assertEqual(mixed_precision._get_mixed_precision_mode(), tf.float32)
194      @mixed_precision.modes([tf.float32, tf.float16])
195      def check_type(x, expected_dtype):
196        self.assertEqual(x.dtype, expected_dtype)
197        return x
198      mixed_precision.enable(tf.float16)
199      x = tf.Variable([[1., 3], [5., 7.]])
200      self.assertEqual(x.dtype, tf.float32)
201      self.assertEqual(check_type(x, tf.float32).dtype, tf.float32)
202      self.assertEqual(check_type(x, tf.float16).dtype, tf.float32)
203    def test_float32_mode_eligible_func(self):
204      mixed_precision.enable(tf.float32)
205      self.assertEqual(mixed_precision._get_mixed_precision_mode(), tf.float32)
206      @mixed_precision.modes([tf.float32, tf.float16])
207      def fwd_func(x):
208        self.assertEqual(x.dtype, tf.float32)
209        return x
210      x = tf.Variable([[1., 3], [5., 7.]])
211      self.assertEqual(x.dtype, tf.float32)
212      self.assertEqual(fwd_func(x).dtype, tf.float32)
213      self.assertEqual(fwd_func(x).dtype, tf.float32)
214    def test_float16_mode_ineligible_func(self):
215      mixed_precision.enable(tf.float32)
216      @mixed_precision.modes([tf.float32, tf.bfloat16])
217      def fwd_func(x):
218        self.assertEqual(x.dtype, tf.float32)
219        return x
220      x = tf.Variable([[1., 3], [5., 7.]])
221      self.assertEqual(x.dtype, tf.float32)
222      mixed_precision.enable(tf.float16)
223      self.assertEqual(fwd_func(x).dtype, tf.float32)
224      self.assertEqual(fwd_func(x).dtype, tf.float32)
225    def test_dont_cast_non_floats_func(self):
226      mixed_precision.enable(tf.float32)
227      @mixed_precision.modes([tf.float32, tf.float16])
228      def fwd_func(x):
229        self.assertTrue(x.dtype.is_integer)
230        return x
231      x = tf.Variable([[1, 9], [8, 9]])
232      self.assertTrue(x.dtype.is_integer)
233      mixed_precision.enable(tf.float16)
234      self.assertTrue(fwd_func(x).dtype.is_integer)
<span onclick='openModal()' class='match'>235      self.assertTrue(fwd_func(x).dtype.is_integer)
236    def test_non_tensor_variable_input_no_cast_func(self):
</span>237      mixed_precision.enable(tf.float32)
238      @mixed_precision.modes([tf.float32, tf.float16])
239      def fwd_func(x):
240        self.assertEqual(type(x[0][0]), float)
241        return x
242      x = [[1., 3], [5., 7.]]
243      self.assertEqual(type(x[0][0]), float)
244      mixed_precision.enable(tf.float16)
245      self.assertEqual(type(fwd_func(x)[0][0]), float)
246      self.assertEqual(type(fwd_func(x)[0][0]), float)
247    def test_float16_mode_enabled_call_function(self):
248      mixed_precision.enable(tf.float32)
249      class DummyCall(base.Module, test_utils.TestCase):
250        def __init__(self):
251          super().__init__()
252          test_utils.TestCase.__init__(self)
253          self.y = tf.Variable([[1., 3], [5., 7.]])
254        @mixed_precision.modes([tf.float16, tf.float32])
255        def __call__(self, x, dtype):
256          self.assertTrue(self.y.dtype == dtype)
257          self.assertTrue(x.dtype == dtype)
258          return x
259        def runTest(self):
260          pass
261      x = tf.Variable([[1., 3], [5., 7.]])
262      self.assertEqual(x.dtype, tf.float32)
263      d = DummyCall()
264      mixed_precision.enable(tf.float16)
265      self.assertEqual(d(x, tf.float32).dtype, tf.float32)
266      self.assertEqual(d(x, tf.float16).dtype, tf.float32)
267    def test_float16_mode_tensor_eligible_class(self):
268      mixed_precision.enable(tf.float32)
269      x = tf.constant([[1., 9.], [5., 0.]])
270      d = DummyInput(x)
271      d.check_type = mixed_precision.modes([tf.float32, tf.float16])(d.check_type)
272      mixed_precision.enable(tf.float16)
273      self.assertEqual(d.check_type(x, tf.float32).dtype, tf.float32)
274      self.assertEqual(d.check_type(x, tf.float16).dtype, tf.float32)
275  if __name__ == '__main__':
276    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-mixed_precision_test.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-mixed_precision_test.py</div>
                </div>
                <div class="column column_space"><pre><code>234      self.assertTrue(fwd_func(x).dtype.is_integer)
235      self.assertTrue(fwd_func(x).dtype.is_integer)
</pre></code></div>
                <div class="column column_space"><pre><code>235      self.assertTrue(fwd_func(x).dtype.is_integer)
236    def test_non_tensor_variable_input_no_cast_func(self):
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    