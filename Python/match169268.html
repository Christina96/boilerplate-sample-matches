<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for master.py &amp; virt_1.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for master.py &amp; virt_1.py
      </h3>
<h1 align="center">
        2.0%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>master.py (3.2759109%)<th>virt_1.py (1.4954234%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(40-73)<td><a href="#" name="0">(122-152)</a><td align="center"><font color="#ff0000">29</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(1555-1563)<td><a href="#" name="1">(2948-2957)</a><td align="center"><font color="#b80000">21</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(1068-1078)<td><a href="#" name="2">(6459-6469)</a><td align="center"><font color="#950000">17</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(658-665)<td><a href="#" name="3">(216-231)</a><td align="center"><font color="#720000">13</font>
<tr onclick='openModal("#6cc417")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#6cc417"><font color="#6cc417">-</font><td><a href="#" name="4">(2131-2133)<td><a href="#" name="4">(7509-7514)</a><td align="center"><font color="#690000">12</font>
<tr onclick='openModal("#151b8d")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#151b8d"><font color="#151b8d">-</font><td><a href="#" name="5">(328-333)<td><a href="#" name="5">(249-253)</a><td align="center"><font color="#690000">12</font>
<tr onclick='openModal("#8c8774")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#8c8774"><font color="#8c8774">-</font><td><a href="#" name="6">(221-225)<td><a href="#" name="6">(1480-1487)</a><td align="center"><font color="#690000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>master.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
import collections
import copy
import ctypes
import functools
import logging
import multiprocessing
import os
import re
import signal
import stat
import sys
import threading
import time
import salt.acl
import salt.auth
import salt.channel.server
import salt.client
import salt.client.ssh.client
import salt.crypt
import salt.daemons.masterapi
import salt.defaults.exitcodes
import salt.engines
import salt.exceptions
import salt.ext.tornado.gen
import salt.key
import salt.minion
import salt.payload
import salt.pillar
import salt.runner
import salt.serializers.msgpack
import salt.state
<a name="0"></a>import salt.utils.args
import salt.utils.atomicfile
import salt.utils.crypt
<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>import salt.utils.event
import salt.utils.files
import salt.utils.gitfs
import salt.utils.gzip_util
import salt.utils.jid
import salt.utils.job
import salt.utils.master
import salt.utils.minions
import salt.utils.platform
import salt.utils.process
import salt.utils.schedule
import salt.utils.ssdp
import salt.utils.stringutils
import salt.utils.user
import salt.utils.verify
import salt.utils.zeromq
import salt.wheel
from salt.config import DEFAULT_INTERVAL
from salt.defaults import DEFAULT_TARGET_DELIM
from salt.ext.tornado.stack_context import StackContext
from salt.transport import TRANSPORTS
from salt.utils.channel import iter_transport_opts
from salt.utils.ctx import RequestContext
from salt.utils.debug import (
    enable_sigusr1_handler,
    enable_sigusr2_handler,
    inspect_stack,
)
from salt.utils.event import tagify
from salt.utils.odict import OrderedDict
from salt.utils.zeromq import ZMQ_VERSION_INFO, zmq
try:
    import</b></font> resource
    HAS_RESOURCE = True
except ImportError:
    HAS_RESOURCE = False
log = logging.getLogger(__name__)
class SMaster:
    secrets = (
        {}
    )  # mapping of key -&gt; {'secret': multiprocessing type, 'reload': FUNCTION}
    def __init__(self, opts):
        self.opts = opts
        self.master_key = salt.crypt.MasterKeys(self.opts)
        self.key = self.__prep_key()
    def __setstate__(self, state):
        super().__setstate__(state)
        self.master_key = state["master_key"]
        self.key = state["key"]
        SMaster.secrets = state["secrets"]
    def __getstate__(self):
        state = super().__getstate__()
        state.update(
            {
                "key": self.key,
                "master_key": self.master_key,
                "secrets": SMaster.secrets,
            }
        )
        return state
    def __prep_key(self):
        return salt.daemons.masterapi.access_keys(self.opts)
class Maintenance(salt.utils.process.SignalHandlingProcess):
    def __init__(self, opts, **kwargs):
        super().__init__(**kwargs)
        self.opts = opts
        self.loop_interval = int(self.opts["loop_interval"])
        self.rotate = int(time.time())
    def _post_fork_init(self):
        ropts = dict(self.opts)
        ropts["quiet"] = True
        runner_client = salt.runner.RunnerClient(ropts)
        self.returners = salt.loader.returners(self.opts, {})
        self.schedule = salt.utils.schedule.Schedule(
            self.opts, runner_client.functions_dict(), returners=self.returners
        )
        self.ckminions = salt.utils.minions.CkMinions(self.opts)
        self.event = salt.utils.event.get_master_event(
            self.opts, self.opts["sock_dir"], listen=False
        )
        self.git_pillar = salt.daemons.masterapi.init_git_pillar(self.opts)
        if self.opts["maintenance_niceness"] and not salt.utils.platform.is_windows():
            log.info(
                "setting Maintenance niceness to %d", self.opts["maintenance_niceness"]
            )
            os.nice(self.opts["maintenance_niceness"])
        self.presence_events = False
        if self.opts.get("presence_events", False):
            tcp_only = True
            for transport, _ in iter_transport_opts(self.opts):
                if transport != "tcp":
                    tcp_only = False
            if not tcp_only:
                self.presence_events = True
    def run(self):
        self._post_fork_init()
        last = int(time.time())
        last_git_pillar_update = 0
        git_pillar_update_interval = self.opts.get("git_pillar_update_interval", 0)
        old_present = set()
        while True:
            now = int(time.time())
            if (now - last) &gt;= self.loop_interval:
                salt.daemons.masterapi.clean_old_jobs(self.opts)
                salt.daemons.masterapi.clean_expired_tokens(self.opts)
                salt.daemons.masterapi.clean_pub_auth(self.opts)
<a name="6"></a>            if (now - last_git_pillar_update) &gt;= git_pillar_update_interval:
                last_git_pillar_update = now
                self.handle_git_pillar()
            self<font color="#8c8774"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.handle_schedule()
            self.handle_key_cache()
            self.handle_presence(old_present)
            self.handle_key_rotate(now)
            salt.utils.verify.check_max_open_files(</b></font>self.opts)
            last = now
            time.sleep(self.loop_interval)
    def handle_key_cache(self):
        if self.opts["key_cache"] == "sched":
            keys = []
            if self.opts["transport"] in TRANSPORTS:
                acc = "minions"
            else:
                acc = "accepted"
            for fn_ in os.listdir(os.path.join(self.opts["pki_dir"], acc)):
                if not fn_.startswith(".") and os.path.isfile(
                    os.path.join(self.opts["pki_dir"], acc, fn_)
                ):
                    keys.append(fn_)
            log.debug("Writing master key cache")
            with salt.utils.atomicfile.atomic_open(
                os.path.join(self.opts["pki_dir"], acc, ".key_cache"), mode="wb"
            ) as cache_file:
                salt.payload.dump(keys, cache_file)
    def handle_key_rotate(self, now):
        to_rotate = False
        dfn = os.path.join(self.opts["cachedir"], ".dfn")
        try:
            stats = os.stat(dfn)
            if salt.utils.platform.is_windows() and not os.access(dfn, os.W_OK):
                to_rotate = True
                os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)
            elif stats.st_mode == 0o100400:
                to_rotate = True
            else:
                log.error("Found dropfile with incorrect permissions, ignoring...")
            os.remove(dfn)
        except os.error:
            pass
        if self.opts.get("publish_session"):
            if now - self.rotate &gt;= self.opts["publish_session"]:
                to_rotate = True
        if to_rotate:
            log.info("Rotating master AES key")
            for secret_key, secret_map in SMaster.secrets.items():
                with secret_map["secret"].get_lock():
                    secret_map["secret"].value = salt.utils.stringutils.to_bytes(
                        secret_map["reload"]()
                    )
                self.event.fire_event(
                    {"rotate_{}_key".format(secret_key): True}, tag="key"
                )
            self.rotate = now
            if self.opts.get("ping_on_rotate"):
                log.debug("Pinging all connected minions due to key rotation")
                salt.utils.master.ping_all_connected_minions(self.opts)
    def handle_git_pillar(self):
        try:
            for pillar in self.git_pillar:
                pillar.fetch_remotes()
        except Exception as exc:  # pylint: disable=broad-except
            log.error("Exception caught while updating git_pillar", exc_info=True)
    def handle_schedule(self):
        try:
            self.schedule.eval()
            if self.schedule.loop_interval &lt; self.loop_interval:
                self.loop_interval = self.schedule.loop_interval
        except Exception as exc:  # pylint: disable=broad-except
            log.error("Exception %s occurred in scheduled job", exc)
        self.schedule.cleanup_subprocesses()
    def handle_presence(self, old_present):
        if self.presence_events and self.event.connect_pull(timeout=3):
            present = self.ckminions<font color="#151b8d"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.connected_ids()
            new = present.difference(old_present)
            lost = old_present.difference(present)
            if new or lost:
                data = {"new": list(</b></font>new), "lost": list(lost)}
                self.event.fire_event(data, tagify("change", "presence"))
            data = {"present": list(present)}
            self.event.fire_event(data, tagify("present", "presence"))
            old_present.clear()
            old_present.update(present)
class FileserverUpdate(salt.utils.process.SignalHandlingProcess):
    def __init__(self, opts, **kwargs):
        super().__init__(**kwargs)
        self.opts = opts
        self.update_threads = {}
        import salt.fileserver
        self.fileserver = salt.fileserver.Fileserver(self.opts)
        self.fill_buckets()
    def fill_buckets(self):
        update_intervals = self.fileserver.update_intervals()
        self.buckets = {}
        for backend in self.fileserver.backends():
            fstr = "{}.update".format(backend)
            try:
                update_func = self.fileserver.servers[fstr]
            except KeyError:
                log.debug("No update function for the %s filserver backend", backend)
                continue
            if backend in update_intervals:
                for id_, interval in update_intervals[backend].items():
                    if not interval:
                        interval = DEFAULT_INTERVAL
                        log.debug(
                            "An update_interval of 0 is not supported, "
                            "falling back to %s",
                            interval,
                        )
                    i_ptr = self.buckets.setdefault(interval, OrderedDict())
                    i_ptr.setdefault((backend, update_func), []).append(id_)
            else:
                try:
                    interval_key = "{}_update_interval".format(backend)
                    interval = self.opts[interval_key]
                except KeyError:
                    interval = DEFAULT_INTERVAL
                    log.warning(
                        "%s key missing from configuration. Falling back to "
                        "default interval of %d seconds",
                        interval_key,
                        interval,
                    )
                self.buckets.setdefault(interval, OrderedDict())[
                    (backend, update_func)
                ] = None
    @staticmethod
    def _do_update(backends):
        for backend, update_args in backends.items():
            backend_name, update_func = backend
            try:
                if update_args:
                    log.debug(
                        "Updating %s fileserver cache for the following targets: %s",
                        backend_name,
                        update_args,
                    )
                    args = (update_args,)
                else:
                    log.debug("Updating %s fileserver cache", backend_name)
                    args = ()
                update_func(*args)
            except Exception as exc:  # pylint: disable=broad-except
                log.exception(
                    "Uncaught exception while updating %s fileserver cache",
                    backend_name,
                )
    @classmethod
    def update(cls, interval, backends, timeout=300):
        start = time.time()
        condition = threading.Condition()
        while time.time() - start &lt; timeout:
            log.debug(
                "Performing fileserver updates for items with an update interval of %d",
                interval,
            )
            cls._do_update(backends)
            log.debug(
                "Completed fileserver updates for items with an update "
                "interval of %d, waiting %d seconds",
                interval,
                interval,
            )
            with condition:
                condition.wait(interval)
    def run(self):
        if (
            self.opts["fileserver_update_niceness"]
            and not salt.utils.platform.is_windows()
        ):
            log.info(
                "setting FileServerUpdate niceness to %d",
                self.opts["fileserver_update_niceness"],
            )
            os.nice(self.opts["fileserver_update_niceness"])
        salt.daemons.masterapi.clean_fsbackend(self.opts)
        for interval in self.buckets:
            self.update_threads[interval] = threading.Thread(
                target=self.update,
                args=(interval, self.buckets[interval]),
            )
            self.update_threads[interval].start()
        while self.update_threads:
            for name, thread in list(self.update_threads.items()):
                thread.join(1)
                if not thread.is_alive():
                    self.update_threads.pop(name)
class Master(SMaster):
    def __init__(self, opts):
        if zmq and ZMQ_VERSION_INFO &lt; (3, 2):
            log.warning(
                "You have a version of ZMQ less than ZMQ 3.2! There are "
                "known connection keep-alive issues with ZMQ &lt; 3.2 which "
                "may result in loss of contact with minions. Please "
                "upgrade your ZMQ!"
            )
        SMaster.__init__(self, opts)
    def __set_max_open_files(self):
        if not HAS_RESOURCE:
            return
        mof_s, mof_h = resource.getrlimit(resource.RLIMIT_NOFILE)
        if mof_h == resource.RLIM_INFINITY:
            mof_h = mof_s
        log.info(
            "Current values for max open files soft/hard setting: %s/%s", mof_s, mof_h
        )
        mof_c = self.opts["max_open_files"]
        if mof_c &gt; mof_h:
            log.info(
                "The value for the 'max_open_files' setting, %s, is higher "
                "than the highest value the user running salt is allowed to "
                "set (%s). Defaulting to %s.",
                mof_c,
                mof_h,
                mof_h,
            )
            mof_c = mof_h
        if mof_s &lt; mof_c:
            log.info("Raising max open files value to %s", mof_c)
            resource.setrlimit(resource.RLIMIT_NOFILE, (mof_c, mof_h))
            try:
                mof_s, mof_h = resource.getrlimit(resource.RLIMIT_NOFILE)
                log.info(
                    "New values for max open files soft/hard values: %s/%s",
                    mof_s,
                    mof_h,
                )
            except ValueError:
                log.critical(
                    "Failed to raise max open files setting to %s. If this "
                    "value is too low, the salt-master will most likely fail "
                    "to run properly.",
                    mof_c,
                )
    def _pre_flight(self):
        errors = []
        critical_errors = []
        try:
            os.chdir("/")
        except OSError as err:
            errors.append("Cannot change to root directory ({})".format(err))
        if self.opts.get("fileserver_verify_config", True):
            import salt.fileserver
            fileserver = salt.fileserver.Fileserver(self.opts)
            if not fileserver.servers:
                errors.append(
                    "Failed to load fileserver backends, the configured backends "
                    "are: {}".format(", ".join(self.opts["fileserver_backend"]))
                )
            else:
                try:
                    fileserver.init()
                except salt.exceptions.FileserverConfigError as exc:
                    critical_errors.append("{}".format(exc))
        if not self.opts["fileserver_backend"]:
            errors.append("No fileserver backends are configured")
        if self.opts["pillar_cache"] and not os.path.isdir(
            os.path.join(self.opts["cachedir"], "pillar_cache")
        ):
            try:
                with salt.utils.files.set_umask(0o077):
                    os.mkdir(os.path.join(self.opts["cachedir"], "pillar_cache"))
            except OSError:
                pass
        if self.opts.get("git_pillar_verify_config", True):
            try:
                git_pillars = [
                    x
                    for x in self.opts.get("ext_pillar", [])
                    if "git" in x and not isinstance(x["git"], str)
                ]
            except TypeError:
                git_pillars = []
                critical_errors.append(
                    "Invalid ext_pillar configuration. It is likely that the "
                    "external pillar type was not specified for one or more "
                    "external pillars."
                )
            if git_pillars:
                try:
                    new_opts = copy.deepcopy(self.opts)
                    import salt.pillar.git_pillar
                    for repo in git_pillars:
                        new_opts["ext_pillar"] = [repo]
                        try:
                            git_pillar = salt.utils.gitfs.GitPillar(
                                new_opts,
                                repo["git"],
                                per_remote_overrides=salt.pillar.git_pillar.PER_REMOTE_OVERRIDES,
                                per_remote_only=salt.pillar.git_pillar.PER_REMOTE_ONLY,
                                global_only=salt.pillar.git_pillar.GLOBAL_ONLY,
                            )
                        except salt.exceptions.FileserverConfigError as exc:
                            critical_errors.append(exc.strerror)
                finally:
                    del new_opts
        if errors or critical_errors:
            for error in errors:
                log.error(error)
            for error in critical_errors:
                log.critical(error)
            log.critical("Master failed pre flight checks, exiting\n")
            sys.exit(salt.defaults.exitcodes.EX_GENERIC)
    def start(self):
        self._pre_flight()
        log.info("salt-master is starting as user '%s'", salt.utils.user.get_user())
        enable_sigusr1_handler()
        enable_sigusr2_handler()
        self.__set_max_open_files()
        with salt.utils<font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.process.default_signals(signal.SIGINT, signal.SIGTERM):
            SMaster.secrets["aes"] = {
                "secret": multiprocessing.Array(
                    ctypes.c_char,
                    salt.</b></font>utils.stringutils.to_bytes(
                        salt.crypt.Crypticle.generate_key_string()
                    ),
                ),
                "reload": salt.crypt.Crypticle.generate_key_string,
            }
            log.info("Creating master process manager")
            self.process_manager = salt.utils.process.ProcessManager(wait_for_kill=5)
            pub_channels = []
            log.info("Creating master publisher process")
            for _, opts in iter_transport_opts(self.opts):
                chan = salt.channel.server.PubServerChannel.factory(opts)
                chan.pre_fork(self.process_manager)
                pub_channels.append(chan)
            log.info("Creating master event publisher process")
            self.process_manager.add_process(
                salt.utils.event.EventPublisher,
                args=(self.opts,),
                name="EventPublisher",
            )
            if self.opts.get("reactor"):
                if isinstance(self.opts["engines"], list):
                    rine = False
                    for item in self.opts["engines"]:
                        if "reactor" in item:
                            rine = True
                            break
                    if not rine:
                        self.opts["engines"].append({"reactor": {}})
                else:
                    if "reactor" not in self.opts["engines"]:
                        log.info("Enabling the reactor engine")
                        self.opts["engines"]["reactor"] = {}
            salt.engines.start_engines(self.opts, self.process_manager)
            log.info("Creating master maintenance process")
            self.process_manager.add_process(
                Maintenance, args=(self.opts,), name="Maintenance"
            )
            if self.opts.get("event_return"):
                log.info("Creating master event return process")
                self.process_manager.add_process(
                    salt.utils.event.EventReturn, args=(self.opts,), name="EventReturn"
                )
            ext_procs = self.opts.get("ext_processes", [])
            for proc in ext_procs:
                log.info("Creating ext_processes process: %s", proc)
                try:
                    mod = ".".join(proc.split(".")[:-1])
                    cls = proc.split(".")[-1]
                    _tmp = __import__(mod, globals(), locals(), [cls], -1)
                    cls = _tmp.__getattribute__(cls)
                    name = "ExtProcess({})".format(cls.__qualname__)
                    self.process_manager.add_process(cls, args=(self.opts,), name=name)
                except Exception:  # pylint: disable=broad-except
                    log.error("Error creating ext_processes process: %s", proc)
            if self.opts["con_cache"]:
                log.info("Creating master concache process")
                self.process_manager.add_process(
                    salt.utils.master.ConnectedCache,
                    args=(self.opts,),
                    name="ConnectedCache",
                )
                log.debug("Sleeping for two seconds to let concache rest")
                time.sleep(2)
            log.info("Creating master request server process")
            kwargs = {}
            if salt.utils.platform.spawning_platform():
                kwargs["secrets"] = SMaster.secrets
            self.process_manager.add_process(
                ReqServer,
                args=(self.opts, self.key, self.master_key),
                kwargs=kwargs,
                name="ReqServer",
            )
            self.process_manager.add_process(
                FileserverUpdate, args=(self.opts,), name="FileServerUpdate"
            )
            if self.opts["discovery"]:
                if salt.utils.ssdp.SSDPDiscoveryServer.is_available():
                    self.process_manager.add_process(
                        salt.utils.ssdp.SSDPDiscoveryServer(
                            port=self.opts["discovery"]["port"],
                            listen_ip=self.opts["interface"],
                            answer={
                                "mapping": self.opts["discovery"].get("mapping", {})
                            },
                        ).run,
                        name="SSDPDiscoveryServer",
                    )
                else:
                    log.error("Unable to load SSDP: asynchronous IO is not available.")
                    if sys.version_info.major == 2:
                        log.error(
                            'You are using Python 2, please install "trollius" module'
                            " to enable SSDP discovery."
                        )
        if signal.getsignal(signal.SIGINT) is signal.SIG_DFL:
            signal.signal(signal.SIGINT, self._handle_signals)
        if signal.getsignal(signal.SIGTERM) is signal.SIG_DFL:
            signal.signal(signal.SIGTERM, self._handle_signals)
        self.process_manager.run()
    def _handle_signals(self, signum, sigframe):
        self.process_manager._handle_signals(signum, sigframe)
        time.sleep(1)
        sys.exit(0)
class ReqServer(salt.utils.process.SignalHandlingProcess):
    def __init__(self, opts, key, mkey, secrets=None, **kwargs):
        super().__init__(**kwargs)
        self.opts = opts
        self.master_key = mkey
        self.key = key
        self.secrets = secrets
    def _handle_signals(self, signum, sigframe):  # pylint: disable=unused-argument
        self.destroy(signum)
        super()._handle_signals(signum, sigframe)
    def __bind(self):
        if self.secrets is not None:
            SMaster.secrets = self.secrets
        dfn = os.path.join(self.opts["cachedir"], ".dfn")
        if os.path.isfile(dfn):
            try:
                if salt.utils.platform.is_windows() and not os.access(dfn, os.W_OK):
                    os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)
                os.remove(dfn)
            except os.error:
                pass
        self.process_manager = salt.utils.process.ProcessManager(
            name="ReqServer_ProcessManager", wait_for_kill=1
        )
        req_channels = []
        tcp_only = True
        for transport, opts in iter_transport_opts(self.opts):
            chan = salt.channel.server.ReqServerChannel.factory(opts)
            chan.pre_fork(self.process_manager)
            req_channels.append(chan)
            if transport != "tcp":
                tcp_only = False
        if self.opts["req_server_niceness"] and not salt.utils.platform.is_windows():
            log.info(
                "setting ReqServer_ProcessManager niceness to %d",
                self.opts["req_server_niceness"],
            )
            os.nice(self.opts["req_server_niceness"])
        with salt.utils.process.default_signals(signal.SIGINT, signal.SIGTERM):
            for ind in range(int(self.opts["worker_threads"])):
                name = "MWorker-{}".format(ind)
                self.process_manager.add_process(
                    MWorker,
                    args=(self.opts, self.master_key, self.key, req_channels),
                    name=name,
                )
        self.process_manager.run()
    def run(self):
        self.__bind()
    def destroy(self, signum=signal.SIGTERM):
        if hasattr(self, "process_manager"):
            self.process_manager.stop_restarting()
            self.process_manager.send_signal_to_processes(signum)
            self.process_manager.kill_children()
    def __del__(self):
        self.destroy()
class MWorker(salt.utils.process.SignalHandlingProcess):
    def __init__(self, opts, mkey, key, req_channels, **kwargs):
        super().__init__(**kwargs)
        self.opts = opts
        self.req_channels = req_channels
        self.mkey = mkey
        self.key = key
        self.k_mtime = 0
        self.stats = collections.defaultdict(lambda: {"mean": 0, "runs": 0})
        self.stat_clock = time.time()
    def __setstate__(self, state):
        super().__setstate__(state)
        self.k_mtime = state["k_mtime"]
        SMaster.secrets = state["secrets"]
    def __getstate__(self):
        state = super().__getstate__()
        state.update({"k_mtime": self.k_mtime, "secrets": SMaster.secrets})
        return state
    def _handle_signals(self, signum, sigframe):
        for channel in getattr(self, "req_channels", ()):
            channel.close()
        self.clear_funcs.destroy()
        super()._handle_signals(signum, sigframe)
    def __bind(self):
        self.io_loop = salt.ext.tornado.ioloop.IOLoop()
        self.io_loop.make_current()
        for req_channel in self.req_channels:
            req_channel.post_fork(
                self._handle_payload, io_loop=self.io_loop
            )  # TODO: cleaner? Maybe lazily?
        try:
            self.io_loop.start()
        except (KeyboardInterrupt, SystemExit):
            pass
    @salt.ext.tornado.gen.coroutine
    def _handle_payload(self, payload):
        key = payload["enc"]
        load = payload["load"]
        ret = {"aes": self._handle_aes, "clear": self._handle_clear}[key](load)
        raise salt.ext.tornado.gen.Return(ret)
    def _post_stats(self, start, cmd):
        end = time.time()
        duration = end - start
        self.stats[cmd]["mean"] = (
            self.stats[cmd]["mean"] * (self.stats[cmd]["runs"] - 1) + duration
        ) / self.stats[cmd]["runs"]
        if end - self.stat_clock &gt; self.opts["master_stats_event_iter"]:
            self.aes_funcs.event.fire_event(
                {
                    "time": end - self.stat_clock,
                    "worker": self.name,
                    "stats": self.stats,
                },
                tagify(self.name, "stats"),
            )
            self.stats = collections.defaultdict(lambda: {"mean": 0, "runs": 0})
            self.stat_clock = end
    def _handle_clear(self, load):
        log.trace("Clear payload received with command %s", load["cmd"])
        cmd = load["cmd"]
        method = self.clear_funcs.get_method(cmd)
        if not method:
            return {}, {"fun": "send_clear"}
        if self.opts["master_stats"]:
            start = time.time()
            self.stats[cmd]["runs"] += 1
        ret = method(load), {"fun": "send_clear"}
        if self.opts["master_stats"]:
            self._post_stats(start, cmd)
        return ret
    def _handle_aes(self, data):
        if "cmd" not in data:
            log.error("Received malformed command %s", data)
            return {}
        cmd = data["cmd"]
        log.trace("AES payload received with command %s", data["cmd"])
        method = self.aes_funcs.get_method(cmd)
        if not method:
            return {}, {"fun": "send"}
        if self.opts["master_stats"]:
            start = time.time()
            self.stats[cmd]["runs"] += 1
        def run_func(data):
            return self.aes_funcs.run_func(data["cmd"], data)
        with StackContext(
            functools.partial(RequestContext, {"data": data, "opts": self.opts})
        ):
            ret = run_func(data)
        if self.opts["master_stats"]:
            self._post_stats(start, cmd)
        return ret
    def run(self):
<a name="2"></a>        if not salt.utils.platform.is_windows():
            enforce_mworker_niceness = True
            if self.opts["req_server_niceness"]:
                if salt.utils<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.user.get_user() == "root":
                    log.info(
                        "%s decrementing inherited ReqServer niceness to 0", self.name
                    )
                    log.info(os.nice())
                    os.nice(-1 * self.opts["req_server_niceness"])
                else:
                    log.error(
                        "%s unable to decrement niceness for MWorker, not running as"
                        " root",
                        self.</b></font>name,
                    )
                    enforce_mworker_niceness = False
            if enforce_mworker_niceness and self.opts["mworker_niceness"]:
                log.info(
                    "setting %s niceness to %i",
                    self.name,
                    self.opts["mworker_niceness"],
                )
                os.nice(self.opts["mworker_niceness"])
        self.clear_funcs = ClearFuncs(
            self.opts,
            self.key,
        )
        self.clear_funcs.connect()
        self.aes_funcs = AESFuncs(self.opts)
        salt.utils.crypt.reinit_crypto()
        self.__bind()
class TransportMethods:
    expose_methods = ()
    def get_method(self, name):
        if name in self.expose_methods:
            try:
                return getattr(self, name)
            except AttributeError:
                log.error("Requested method not exposed: %s", name)
        else:
            log.error("Requested method not exposed: %s", name)
class AESFuncs(TransportMethods):
    expose_methods = (
        "verify_minion",
        "_master_tops",
        "_master_opts",
        "_mine_get",
        "_mine",
        "_mine_delete",
        "_mine_flush",
        "_file_recv",
        "_pillar",
        "_minion_event",
        "_handle_minion_event",
        "_return",
        "_syndic_return",
        "minion_runner",
        "pub_ret",
        "minion_pub",
        "minion_publish",
        "revoke_auth",
        "_serve_file",
        "_file_find",
        "_file_hash",
        "_file_hash_and_stat",
        "_file_list",
        "_file_list_emptydirs",
        "_dir_list",
        "_symlink_list",
        "_file_envs",
        "_ext_nodes",  # To be removed in 3006 (Sulfur) #60980
    )
    def __init__(self, opts):
        self.opts = opts
        self.event = salt.utils.event.get_master_event(
            self.opts, self.opts["sock_dir"], listen=False
        )
        self.ckminions = salt.utils.minions.CkMinions(opts)
        self.local = salt.client.get_local_client(self.opts["conf_file"])
        self.mminion = salt.minion.MasterMinion(
            self.opts, states=False, rend=False, ignore_config_errors=True
        )
        self.__setup_fileserver()
        self.masterapi = salt.daemons.masterapi.RemoteFuncs(opts)
    def __setup_fileserver(self):
        import salt.fileserver
        self.fs_ = salt.fileserver.Fileserver(self.opts)
        self._serve_file = self.fs_.serve_file
        self._file_find = self.fs_._find_file
        self._file_hash = self.fs_.file_hash
        self._file_hash_and_stat = self.fs_.file_hash_and_stat
        self._file_list = self.fs_.file_list
        self._file_list_emptydirs = self.fs_.file_list_emptydirs
        self._dir_list = self.fs_.dir_list
        self._symlink_list = self.fs_.symlink_list
        self._file_envs = self.fs_.file_envs
    def __verify_minion(self, id_, token):
        if not salt.utils.verify.valid_id(self.opts, id_):
            return False
        pub_path = os.path.join(self.opts["pki_dir"], "minions", id_)
        try:
            pub = salt.crypt.get_rsa_pub_key(pub_path)
        except OSError:
            log.warning(
                "Salt minion claiming to be %s attempted to communicate with "
                "master, but key could not be read and verification was denied.",
                id_,
            )
            return False
        except (ValueError, IndexError, TypeError) as err:
            log.error('Unable to load public key "%s": %s', pub_path, err)
        try:
            if salt.crypt.public_decrypt(pub, token) == b"salt":
                return True
        except ValueError as err:
            log.error("Unable to decrypt token: %s", err)
        log.error(
            "Salt minion claiming to be %s has attempted to communicate with "
            "the master and could not be verified",
            id_,
        )
        return False
    def verify_minion(self, id_, token):
        return self.__verify_minion(id_, token)
    def __verify_minion_publish(self, clear_load):
        if "peer" not in self.opts:
            return False
        if not isinstance(self.opts["peer"], dict):
            return False
        if any(
            key not in clear_load for key in ("fun", "arg", "tgt", "ret", "tok", "id")
        ):
            return False
        if clear_load["fun"].startswith("publish."):
            return False
        if not self.__verify_minion(clear_load["id"], clear_load["tok"]):
            log.warning(
                "Minion id %s is not who it says it is and is attempting "
                "to issue a peer command",
                clear_load["id"],
            )
            return False
        clear_load.pop("tok")
        perms = []
        for match in self.opts["peer"]:
            if re.match(match, clear_load["id"]):
                if isinstance(self.opts["peer"][match], list):
                    perms.extend(self.opts["peer"][match])
        if "," in clear_load["fun"]:
            clear_load["fun"] = clear_load["fun"].split(",")
            arg_ = []
            for arg in clear_load["arg"]:
                arg_.append(arg.split())
            clear_load["arg"] = arg_
        return self.ckminions.auth_check(
            perms,
            clear_load["fun"],
            clear_load["arg"],
            clear_load["tgt"],
            clear_load.get("tgt_type", "glob"),
            publish_validate=True,
        )
    def __verify_load(self, load, verify_keys):
        if any(key not in load for key in verify_keys):
            return False
        if "tok" not in load:
            log.error(
                "Received incomplete call from %s for '%s', missing '%s'",
                load["id"],
                inspect_stack()["co_name"],
                "tok",
            )
            return False
        if not self.__verify_minion(load["id"], load["tok"]):
            log.warning("Minion id %s is not who it says it is!", load["id"])
            return False
        if "tok" in load:
            load.pop("tok")
        return load
    def _master_tops(self, load):
        load = self.__verify_load(load, ("id", "tok"))
        if load is False:
            return {}
        return self.masterapi._master_tops(load, skip_verify=True)
    _ext_nodes = _master_tops
    def _master_opts(self, load):
        mopts = {}
        file_roots = {}
        envs = self._file_envs()
        for saltenv in envs:
            if saltenv not in file_roots:
                file_roots[saltenv] = []
        mopts["file_roots"] = file_roots
        mopts["top_file_merging_strategy"] = self.opts["top_file_merging_strategy"]
        mopts["env_order"] = self.opts["env_order"]
        mopts["default_top"] = self.opts["default_top"]
        if load.get("env_only"):
            return mopts
        mopts["renderer"] = self.opts["renderer"]
        mopts["failhard"] = self.opts["failhard"]
        mopts["state_top"] = self.opts["state_top"]
        mopts["state_top_saltenv"] = self.opts["state_top_saltenv"]
        mopts["nodegroups"] = self.opts["nodegroups"]
        mopts["state_auto_order"] = self.opts["state_auto_order"]
        mopts["state_events"] = self.opts["state_events"]
        mopts["state_aggregate"] = self.opts["state_aggregate"]
        mopts["jinja_env"] = self.opts["jinja_env"]
        mopts["jinja_sls_env"] = self.opts["jinja_sls_env"]
        mopts["jinja_lstrip_blocks"] = self.opts["jinja_lstrip_blocks"]
        mopts["jinja_trim_blocks"] = self.opts["jinja_trim_blocks"]
        return mopts
    def _mine_get(self, load):
        load = self.__verify_load(load, ("id", "tgt", "fun", "tok"))
        if load is False:
            return {}
        else:
            return self.masterapi._mine_get(load, skip_verify=True)
    def _mine(self, load):
        load = self.__verify_load(load, ("id", "data", "tok"))
        if load is False:
            return {}
        return self.masterapi._mine(load, skip_verify=True)
    def _mine_delete(self, load):
        load = self.__verify_load(load, ("id", "fun", "tok"))
        if load is False:
            return {}
        else:
            return self.masterapi._mine_delete(load)
    def _mine_flush(self, load):
        load = self.__verify_load(load, ("id", "tok"))
        if load is False:
            return {}
        else:
            return self.masterapi._mine_flush(load, skip_verify=True)
    def _file_recv(self, load):
        if any(key not in load for key in ("id", "path", "loc")):
            return False
        if not isinstance(load["path"], list):
            return False
        if not self.opts["file_recv"]:
            return False
        if not salt.utils.verify.valid_id(self.opts, load["id"]):
            return False
        file_recv_max_size = 1024 * 1024 * self.opts["file_recv_max_size"]
        if "loc" in load and load["loc"] &lt; 0:
            log.error("Invalid file pointer: load[loc] &lt; 0")
            return False
        if len(load["data"]) + load.get("loc", 0) &gt; file_recv_max_size:
            log.error(
                "file_recv_max_size limit of %d MB exceeded! %s will be "
                "truncated. To successfully push this file, adjust "
                "file_recv_max_size to an integer (in MB) large enough to "
                "accommodate it.",
                file_recv_max_size,
                load["path"],
            )
            return False
        if "tok" not in load:
            log.error(
                "Received incomplete call from %s for '%s', missing '%s'",
                load["id"],
                inspect_stack()["co_name"],
                "tok",
            )
            return False
        if not self.__verify_minion(load["id"], load["tok"]):
            log.warning("Minion id %s is not who it says it is!", load["id"])
            return {}
        load.pop("tok")
        sep_path = os.sep.join(load["path"])
        normpath = os.path.normpath(sep_path)
        if os.path.isabs(normpath) or "../" in load["path"]:
            return False
        cpath = os.path.join(
            self.opts["cachedir"], "minions", load["id"], "files", normpath
        )
        if not os.path.normpath(cpath).startswith(self.opts["cachedir"]):
            log.warning(
                "Attempt to write received file outside of master cache "
                "directory! Requested path: %s. Access denied.",
                cpath,
            )
            return False
        cdir = os.path.dirname(cpath)
        if not os.path.isdir(cdir):
            try:
                os.makedirs(cdir)
            except os.error:
                pass
        if os.path.isfile(cpath) and load["loc"] != 0:
            mode = "ab"
        else:
            mode = "wb"
        with salt.utils.files.fopen(cpath, mode) as fp_:
            if load["loc"]:
                fp_.seek(load["loc"])
            fp_.write(salt.utils.stringutils.to_bytes(load["data"]))
        return True
    def _pillar(self, load):
        if any(key not in load for key in ("id", "grains")):
            return False
        if not salt.utils.verify.valid_id(self.opts, load["id"]):
            return False
        load["grains"]["id"] = load["id"]
        pillar = salt.pillar.get_pillar(
<a name="1"></a>            self.opts,
            load["grains"],
            load["id"],
            load.get("saltenv", load<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.get("env")),
            ext=load.get("ext"),
            pillar_override=load.get("pillar_override", {}),
            pillarenv=load.get("pillarenv"),
            extra_minion_data=load.get("extra_minion_data"),
            clean_cache=load.get("clean_cache"),
        )
        data = pillar.compile_pillar()
        self.</b></font>fs_.update_opts()
        if self.opts.get("minion_data_cache", False):
            self.masterapi.cache.store(
                "minions/{}".format(load["id"]),
                "data",
                {"grains": load["grains"], "pillar": data},
            )
            if self.opts.get("minion_data_cache_events") is True:
                self.event.fire_event(
                    {"Minion data cache refresh": load["id"]},
                    tagify(load["id"], "refresh", "minion"),
                )
        return data
    def _minion_event(self, load):
        load = self.__verify_load(load, ("id", "tok"))
        if load is False:
            return {}
        self.masterapi._minion_event(load)
        self._handle_minion_event(load)
    def _handle_minion_event(self, load):
        id_ = load["id"]
        if load.get("tag", "") == "_salt_error":
            log.error(
                "Received minion error from [%s]: %s", id_, load["data"]["message"]
            )
        for event in load.get("events", []):
            event_data = event.get("data", {})
            if "minions" in event_data:
                jid = event_data.get("jid")
                if not jid:
                    continue
                minions = event_data["minions"]
                try:
                    salt.utils.job.store_minions(
                        self.opts, jid, minions, mminion=self.mminion, syndic_id=id_
                    )
                except (KeyError, salt.exceptions.SaltCacheError) as exc:
                    log.error(
                        "Could not add minion(s) %s for job %s: %s", minions, jid, exc
                    )
    def _return(self, load):
        if self.opts["require_minion_sign_messages"] and "sig" not in load:
            log.critical(
                "_return: Master is requiring minions to sign their "
                "messages, but there is no signature in this payload from "
                "%s.",
                load["id"],
            )
            return False
        if "sig" in load:
            log.trace("Verifying signed event publish from minion")
            sig = load.pop("sig")
            this_minion_pubkey = os.path.join(
                self.opts["pki_dir"], "minions/{}".format(load["id"])
            )
            serialized_load = salt.serializers.msgpack.serialize(load)
            if not salt.crypt.verify_signature(
                this_minion_pubkey, serialized_load, sig
            ):
                log.info("Failed to verify event signature from minion %s.", load["id"])
                if self.opts["drop_messages_signature_fail"]:
                    log.critical(
                        "drop_messages_signature_fail is enabled, dropping "
                        "message from %s",
                        load["id"],
                    )
                    return False
                else:
                    log.info(
                        "But 'drop_message_signature_fail' is disabled, so message is"
                        " still accepted."
                    )
            load["sig"] = sig
        try:
            salt.utils.job.store_job(
                self.opts, load, event=self.event, mminion=self.mminion
            )
        except salt.exceptions.SaltCacheError:
            log.error("Could not store job information for load: %s", load)
    def _syndic_return(self, load):
        loads = load.get("load")
        if not isinstance(loads, list):
            loads = [load]  # support old syndics not aggregating returns
        for load in loads:
            if any(key not in load for key in ("return", "jid", "id")):
                continue
            if load.get("load"):
                fstr = "{}.save_load".format(self.opts["master_job_cache"])
                self.mminion.returners[fstr](load["jid"], load["load"])
            syndic_cache_path = os.path.join(
                self.opts["cachedir"], "syndics", load["id"]
            )
            if not os.path.exists(syndic_cache_path):
                path_name = os.path.split(syndic_cache_path)[0]
                if not os.path.exists(path_name):
                    os.makedirs(path_name)
                with salt.utils.files.fopen(syndic_cache_path, "w") as wfh:
                    wfh.write("")
            for key, item in load["return"].items():
                ret = {"jid": load["jid"], "id": key}
                ret.update(item)
                if "master_id" in load:
                    ret["master_id"] = load["master_id"]
                if "fun" in load:
                    ret["fun"] = load["fun"]
                if "arg" in load:
                    ret["fun_args"] = load["arg"]
                if "out" in load:
                    ret["out"] = load["out"]
                if "sig" in load:
                    ret["sig"] = load["sig"]
                self._return(ret)
    def minion_runner(self, clear_load):
        load = self.__verify_load(clear_load, ("fun", "arg", "id", "tok"))
        if load is False:
            return {}
        else:
            return self.masterapi.minion_runner(clear_load)
    def pub_ret(self, load):
        load = self.__verify_load(load, ("jid", "id", "tok"))
        if load is False:
            return {}
        auth_cache = os.path.join(self.opts["cachedir"], "publish_auth")
        if not os.path.isdir(auth_cache):
            os.makedirs(auth_cache)
        jid_fn = os.path.join(auth_cache, str(load["jid"]))
        with salt.utils.files.fopen(jid_fn, "r") as fp_:
            if not load["id"] == fp_.read():
                return {}
        return self.local.get_cache_returns(load["jid"])
    def minion_pub(self, clear_load):
        if not self.__verify_minion_publish(clear_load):
            return {}
        else:
            return self.masterapi.minion_pub(clear_load)
    def minion_publish(self, clear_load):
        if not self.__verify_minion_publish(clear_load):
            return {}
        else:
            return self.masterapi.minion_publish(clear_load)
    def revoke_auth(self, load):
        load = self.__verify_load(load, ("id", "tok"))
        if not self.opts.get("allow_minion_key_revoke", False):
            log.warning(
                "Minion %s requested key revoke, but allow_minion_key_revoke "
                "is set to False",
                load["id"],
            )
            return load
        if load is False:
            return load
        else:
            return self.masterapi.revoke_auth(load)
    def run_func(self, func, load):
        if func.startswith("__"):
            return {}, {"fun": "send"}
        if hasattr(self, func):
            try:
                start = time.time()
                ret = getattr(self, func)(load)
                log.trace(
                    "Master function call %s took %s seconds", func, time.time() - start
                )
            except Exception:  # pylint: disable=broad-except
                ret = ""
                log.error("Error in function %s:\n", func, exc_info=True)
        else:
            log.error(
                "Received function %s which is unavailable on the master, "
                "returning False",
                func,
            )
            return False, {"fun": "send"}
        if func == "_return":
            return ret, {"fun": "send"}
        if func == "_pillar" and "id" in load:
            if load.get("ver") != "2" and self.opts["pillar_version"] == 1:
                return ret, {"fun": "send"}
            return ret, {"fun": "send_private", "key": "pillar", "tgt": load["id"]}
        return ret, {"fun": "send"}
    def destroy(self):
        self.masterapi.destroy()
        if self.local is not None:
            self.local.destroy()
            self.local = None
class ClearFuncs(TransportMethods):
    expose_methods = (
        "ping",
        "publish",
        "get_token",
        "mk_token",
        "wheel",
        "runner",
    )
    def __init__(self, opts, key):
        self.opts = opts
        self.key = key
        self.event = salt.utils.event.get_master_event(
            self.opts, self.opts["sock_dir"], listen=False
        )
        self.local = salt.client.get_local_client(self.opts["conf_file"])
        self.ckminions = salt.utils.minions.CkMinions(opts)
        self.loadauth = salt.auth.LoadAuth(opts)
        self.mminion = salt.minion.MasterMinion(
            self.opts, states=False, rend=False, ignore_config_errors=True
        )
        self.wheel_ = salt.wheel.Wheel(opts)
        self.masterapi = salt.daemons.masterapi.LocalFuncs(opts, key)
        self.channels = []
    def runner(self, clear_load):
        auth_type, err_name, key, sensitive_load_keys = self._prep_auth_info(clear_load)
        auth_check = self.loadauth.check_authentication(clear_load, auth_type, key=key)
        error = auth_check.get("error")
        if error:
            return {"error": error}
        username = auth_check.get("username")
        if auth_type != "user":
            runner_check = self.ckminions.runner_check(
                auth_check.get("auth_list", []),
                clear_load["fun"],
                clear_load.get("kwarg", {}),
            )
            if not runner_check:
                return {
                    "error": {
                        "name": err_name,
                        "message": (
                            'Authentication failure of type "{}" occurred for '
                            "user {}.".format(auth_type, username)
                        ),
                    }
                }
            elif isinstance(runner_check, dict) and "error" in runner_check:
                return runner_check
            for item in sensitive_load_keys:
                clear_load.pop(item, None)
        else:
            if "user" in clear_load:
                username = clear_load["user"]
                if salt.auth.AuthUser(username).is_sudo():
                    username = self.opts.get("user", "root")
            else:
                username = salt.utils.user.get_user()
        try:
            fun = clear_load.pop("fun")
            runner_client = salt.runner.RunnerClient(self.opts)
            return runner_client.asynchronous(
                fun, clear_load.get("kwarg", {}), username, local=True
            )
        except Exception as exc:  # pylint: disable=broad-except
            log.error("Exception occurred while introspecting %s: %s", fun, exc)
            return {
                "error": {
                    "name": exc.__class__.__name__,
                    "args": exc.args,
                    "message": str(exc),
                }
            }
    def wheel(self, clear_load):
        auth_type, err_name, key, sensitive_load_keys = self._prep_auth_info(clear_load)
        auth_check = self.loadauth.check_authentication(clear_load, auth_type, key=key)
        error = auth_check.get("error")
        if error:
            return {"error": error}
        username = auth_check.get("username")
        if auth_type != "user":
            wheel_check = self.ckminions.wheel_check(
                auth_check.get("auth_list", []),
                clear_load["fun"],
                clear_load.get("kwarg", {}),
            )
            if not wheel_check:
                return {
                    "error": {
                        "name": err_name,
                        "message": (
                            'Authentication failure of type "{}" occurred for '
                            "user {}.".format(auth_type, username)
                        ),
                    }
                }
            elif isinstance(wheel_check, dict) and "error" in wheel_check:
                return wheel_check
            for item in sensitive_load_keys:
                clear_load.pop(item, None)
        else:
            if "user" in clear_load:
                username = clear_load["user"]
                if salt.auth.AuthUser(username).is_sudo():
                    username = self.opts.get("user", "root")
            else:
                username = salt.utils.user.get_user()
        try:
            jid = salt.utils.jid.gen_jid(self.opts)
            fun = clear_load.pop("fun")
            tag = tagify(jid, prefix="wheel")
            data = {
                "fun": "wheel.{}".format(fun),
                "jid": jid,
                "tag": tag,
                "user": username,
            }
            self.event.fire_event(data, tagify([jid, "new"], "wheel"))
            ret = self.wheel_.call_func(fun, full_return=True, **clear_load)
            data["return"] = ret["return"]
            data["success"] = ret["success"]
            self.event.fire_event(data, tagify([jid, "ret"], "wheel"))
            return {"tag": tag, "data": data}
        except Exception as exc:  # pylint: disable=broad-except
            log.error("Exception occurred while introspecting %s: %s", fun, exc)
            data["return"] = "Exception occurred in wheel {}: {}: {}".format(
                fun,
                exc.__class__.__name__,
                exc,
            )
            data["success"] = False
            self.event.fire_event(data, tagify([jid, "ret"], "wheel"))
            return {"tag": tag, "data": data}
    def mk_token(self, clear_load):
        token = self.loadauth.mk_token(clear_load)
        if not token:
            log.warning('Authentication failure of type "eauth" occurred.')
            return ""
        return token
    def get_token(self, clear_load):
        if "token" not in clear_load:
            return False
        return self.loadauth.get_tok(clear_load["token"])
    def publish(self, clear_load):
        extra = clear_load.get("kwargs", {})
        publisher_acl = salt.acl.PublisherACL(self.opts["publisher_acl_blacklist"])
        if publisher_acl.user_is_blacklisted(
            clear_load["user"]
        ) or publisher_acl.cmd_is_blacklisted(clear_load["fun"]):
            log.error(
                "%s does not have permissions to run %s. Please contact "
                "your local administrator if you believe this is in "
                "error.\n",
                clear_load["user"],
                clear_load["fun"],
            )
            return {
                "error": {
                    "name": "AuthorizationError",
                    "message": "Authorization error occurred.",
                }
<a name="4"></a>            }
        delimiter <font color="#6cc417"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>= clear_load.get("kwargs", {}).get("delimiter", DEFAULT_TARGET_DELIM)
        _res = self.ckminions.check_minions(
            clear_load["tgt"], clear_load.get(</b></font>"tgt_type", "glob"), delimiter
        )
        minions = _res.get("minions", list())
        missing = _res.get("missing", list())
        ssh_minions = _res.get("ssh_minions", False)
        auth_type, err_name, key, sensitive_load_keys = self._prep_auth_info(extra)
        if auth_type == "user":
            auth_check = self.loadauth.check_authentication(
                clear_load, auth_type, key=key
            )
        else:
            auth_check = self.loadauth.check_authentication(extra, auth_type)
        auth_list = auth_check.get("auth_list", [])
        err_msg = 'Authentication failure of type "{}" occurred.'.format(auth_type)
        if auth_check.get("error"):
            log.warning(err_msg)
            return {
                "error": {
                    "name": "AuthenticationError",
                    "message": "Authentication error occurred.",
                }
            }
        if auth_type != "user" or (auth_type == "user" and auth_list):
            authorized = self.ckminions.auth_check(
                auth_list,
                clear_load["fun"],
                clear_load["arg"],
                clear_load["tgt"],
                clear_load.get("tgt_type", "glob"),
                minions=minions,
                whitelist=["saltutil.find_job"],
            )
            if not authorized:
                if (
                    auth_type == "eauth"
                    and not auth_list
                    and "username" in extra
                    and "eauth" in extra
                ):
                    log.debug(
                        'Auth configuration for eauth "%s" and user "%s" is empty',
                        extra["eauth"],
                        extra["username"],
                    )
                log.warning(err_msg)
                return {
                    "error": {
                        "name": "AuthorizationError",
                        "message": "Authorization error occurred.",
                    }
                }
            if auth_type == "token":
                username = auth_check.get("username")
                clear_load["user"] = username
                log.debug('Minion tokenized user = "%s"', username)
            elif auth_type == "eauth":
                clear_load["user"] = self.loadauth.load_name(extra)
        if not self.opts.get("order_masters"):
            if not minions:
                return {
                    "enc": "clear",
                    "load": {
                        "jid": None,
                        "minions": minions,
                        "error": (
                            "Master could not resolve minions for target {}".format(
                                clear_load["tgt"]
                            )
                        ),
                    },
                }
        jid = self._prep_jid(clear_load, extra)
        if jid is None:
            return {"enc": "clear", "load": {"error": "Master failed to assign jid"}}
        payload = self._prep_pub(minions, jid, clear_load, extra, missing)
        self._send_ssh_pub(payload, ssh_minions=ssh_minions)
        self._send_pub(payload)
        return {
            "enc": "clear",
            "load": {"jid": clear_load["jid"], "minions": minions, "missing": missing},
        }
    def _prep_auth_info(self, clear_load):
        sensitive_load_keys = []
        key = None
        if "token" in clear_load:
            auth_type = "token"
            err_name = "TokenAuthenticationError"
            sensitive_load_keys = ["token"]
        elif "eauth" in clear_load:
            auth_type = "eauth"
            err_name = "EauthAuthenticationError"
            sensitive_load_keys = ["username", "password"]
        else:
            auth_type = "user"
            err_name = "UserAuthenticationError"
            key = self.key
        return auth_type, err_name, key, sensitive_load_keys
    def _prep_jid(self, clear_load, extra):
        passed_jid = clear_load["jid"] if clear_load.get("jid") else None
        nocache = extra.get("nocache", False)
        fstr = "{}.prep_jid".format(self.opts["master_job_cache"])
        try:
            jid = self.mminion.returners[fstr](nocache=nocache, passed_jid=passed_jid)
        except (KeyError, TypeError):
            msg = (
                "Failed to allocate a jid. The requested returner '{}' "
                "could not be loaded.".format(fstr.split(".")[0])
            )
            log.error(msg)
            return {"error": msg}
        return jid
    def _send_pub(self, load):
        if not self.channels:
            for transport, opts in iter_transport_opts(self.opts):
                chan = salt.channel.server.PubServerChannel.factory(opts)
                self.channels.append(chan)
        for chan in self.channels:
            chan.publish(load)
    @property
    def ssh_client(self):
        if not hasattr(self, "_ssh_client"):
            self._ssh_client = salt.client.ssh.client.SSHClient(mopts=self.opts)
        return self._ssh_client
    def _send_ssh_pub(self, load, ssh_minions=False):
        if self.opts["enable_ssh_minions"] is True and ssh_minions is True:
            log.debug("Send payload to ssh minions")
            threading.Thread(target=self.ssh_client.cmd, kwargs=load).start()
    def _prep_pub(self, minions, jid, clear_load, extra, missing):
        clear_load["jid"] = jid
        delimiter = clear_load.get("kwargs", {}).get("delimiter", DEFAULT_TARGET_DELIM)
        self.event.fire_event({"minions": minions}, clear_load["jid"])
        new_job_load = {
            "jid": clear_load["jid"],
            "tgt_type": clear_load["tgt_type"],
            "tgt": clear_load["tgt"],
            "user": clear_load["user"],
            "fun": clear_load["fun"],
            "arg": clear_load["arg"],
            "minions": minions,
            "missing": missing,
        }
        self.event.fire_event(new_job_load, tagify([clear_load["jid"], "new"], "job"))
        if self.opts["ext_job_cache"]:
            fstr = "{}.save_load".format(self.opts["ext_job_cache"])
            save_load_func = True
            try:
                arg_spec = salt.utils.args.get_function_argspec(
                    self.mminion.returners[fstr]
                )
                if "minions" not in arg_spec.args:
                    log.critical(
                        "The specified returner used for the external job cache "
                        "'%s' does not have a 'minions' kwarg in the returner's "
                        "save_load function.",
                        self.opts["ext_job_cache"],
                    )
            except (AttributeError, KeyError):
                save_load_func = False
                log.critical(
                    "The specified returner used for the external job cache "
                    '"%s" does not have a save_load function!',
                    self.opts["ext_job_cache"],
                )
            if save_load_func:
                try:
                    self.mminion.returners[fstr](
                        clear_load["jid"], clear_load, minions=minions
                    )
                except Exception:  # pylint: disable=broad-except
                    log.critical(
                        "The specified returner threw a stack trace:\n", exc_info=True
                    )
        try:
            fstr = "{}.save_load".format(self.opts["master_job_cache"])
            self.mminion.returners[fstr](clear_load["jid"], clear_load, minions)
        except KeyError:
            log.critical(
                "The specified returner used for the master job cache "
                '"%s" does not have a save_load function!',
                self.opts["master_job_cache"],
            )
        except Exception:  # pylint: disable=broad-except
            log.critical("The specified returner threw a stack trace:\n", exc_info=True)
        payload = {"enc": "aes"}
        load = {
            "fun": clear_load["fun"],
            "arg": clear_load["arg"],
            "tgt": clear_load["tgt"],
            "jid": clear_load["jid"],
            "ret": clear_load["ret"],
        }
        if "master_id" in self.opts:
            load["master_id"] = self.opts["master_id"]
        if "master_id" in extra:
            load["master_id"] = extra["master_id"]
        if delimiter != DEFAULT_TARGET_DELIM:
            load["delimiter"] = delimiter
        if "id" in extra:
            load["id"] = extra["id"]
        if "tgt_type" in clear_load:
            load["tgt_type"] = clear_load["tgt_type"]
        if "to" in clear_load:
            load["to"] = clear_load["to"]
        if "kwargs" in clear_load:
            if "ret_config" in clear_load["kwargs"]:
                load["ret_config"] = clear_load["kwargs"].get("ret_config")
            if "metadata" in clear_load["kwargs"]:
                load["metadata"] = clear_load["kwargs"].get("metadata")
            if "module_executors" in clear_load["kwargs"]:
                load["module_executors"] = clear_load["kwargs"].get("module_executors")
            if "executor_opts" in clear_load["kwargs"]:
                load["executor_opts"] = clear_load["kwargs"].get("executor_opts")
            if "ret_kwargs" in clear_load["kwargs"]:
                load["ret_kwargs"] = clear_load["kwargs"].get("ret_kwargs")
        if "user" in clear_load:
            log.info(
                "User %s Published command %s with jid %s",
                clear_load["user"],
                clear_load["fun"],
                clear_load["jid"],
            )
            load["user"] = clear_load["user"]
        else:
            log.info(
                "Published command %s with jid %s", clear_load["fun"], clear_load["jid"]
            )
        log.debug("Published command details %s", load)
        return load
    def ping(self, clear_load):
        return clear_load
    def destroy(self):
        if self.masterapi is not None:
            self.masterapi.destroy()
            self.masterapi = None
        if self.local is not None:
            self.local.destroy()
            self.local = None
        while self.channels:
            chan = self.channels.pop()
            chan.close()
    def connect(self):
        if self.channels:
            return
        for transport, opts in iter_transport_opts(self.opts):
            chan = salt.channel.server.PubServerChannel.factory(opts)
            self.channels.append(chan)
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>virt_1.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>import base64
import collections
import copy
import datetime
import logging
import os
import re
import shutil
import string  # pylint: disable=deprecated-module
import subprocess
import sys
import time
import urllib.parse
from xml.etree import ElementTree
from xml.sax import saxutils
import jinja2.exceptions
import salt.utils.data
import salt.utils.files
import salt.utils.json
import salt.utils.path
import salt.utils.stringutils
import salt.utils.templates
import salt.utils.virt
import salt.utils.xmlutil as xmlutil
import salt.utils.yaml
from salt._compat import ipaddress
from salt.exceptions import CommandExecutionError, SaltInvocationError
try:
    import</b></font> libvirt  # pylint: disable=import-error
    from libvirt import libvirtError
    HAS_LIBVIRT = True
except ImportError:
    HAS_LIBVIRT = False
log = logging.getLogger(__name__)
JINJA = jinja2.Environment(
    loader=jinja2.FileSystemLoader(
        os.path.join(salt.utils.templates.TEMPLATE_DIRNAME, "virt")
    )
)
CACHE_DIR = "/var/lib/libvirt/saltinst"
VIRT_STATE_NAME_MAP = {
    0: "running",
    1: "running",
    2: "running",
    3: "paused",
    4: "shutdown",
    5: "shutdown",
    6: "crashed",
}
def __virtual__():
    if not HAS_LIBVIRT:
        return (False, "Unable to locate or import python libvirt library.")
    return "virt"
def __get_request_auth(username, password):
    def __request_auth(credentials, user_data):
<a name="3"></a>        for credential in credentials:
            if credential[0] == libvirt.VIR_CRED_AUTHNAME:
                credential[4] = (
                    <font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>username
                    if username
                    else __salt__["config.get"](
                        "virt:connection:auth:username", credential[3]
                    )
                )
            elif credential[0] == libvirt.VIR_CRED_NOECHOPROMPT:
                credential[4] = (
                    password
                    if password
                    else __salt__["config.get"](
                        "virt:connection:auth:password", credential[3]
                    )
                )
            else:
                log.</b></font>info("Unhandled credential type: %s", credential[0])
        return 0
def __get_conn(**kwargs):
    username = kwargs<font color="#151b8d"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.get("username", None)
    password = kwargs.get("password", None)
    conn_str = kwargs.get("connection", None)
    if not conn_str:
        conn_str = __salt__["config.get"](</b></font>"virt:connection:uri", conn_str)
    try:
        auth_types = [
            libvirt.VIR_CRED_AUTHNAME,
            libvirt.VIR_CRED_NOECHOPROMPT,
            libvirt.VIR_CRED_ECHOPROMPT,
            libvirt.VIR_CRED_PASSPHRASE,
            libvirt.VIR_CRED_EXTERNAL,
        ]
        conn = libvirt.openAuth(
            conn_str, [auth_types, __get_request_auth(username, password), None], 0
        )
    except Exception:  # pylint: disable=broad-except
        raise CommandExecutionError(
            "Sorry, {} failed to open a connection to the hypervisor "
            "software at {}".format(__grains__["fqdn"], conn_str)
        )
    return conn
def _get_domain(conn, *vms, **kwargs):
    ret = list()
    lookup_vms = list()
    all_vms = []
    if kwargs.get("active", True):
        for id_ in conn.listDomainsID():
            all_vms.append(conn.lookupByID(id_).name())
    if kwargs.get("inactive", True):
        for id_ in conn.listDefinedDomains():
            all_vms.append(id_)
    if vms and not all_vms:
        raise CommandExecutionError("No virtual machines found.")
    if vms:
        for name in vms:
            if name not in all_vms:
                raise CommandExecutionError(
                    'The VM "{name}" is not present'.format(name=name)
                )
            else:
                lookup_vms.append(name)
    else:
        lookup_vms = list(all_vms)
    for name in lookup_vms:
        ret.append(conn.lookupByName(name))
    return len(ret) == 1 and not kwargs.get("iterable") and ret[0] or ret
def _parse_qemu_img_info(info):
    raw_infos = salt.utils.json.loads(info)
    disks = []
    for disk_infos in raw_infos:
        disk = {
            "file": disk_infos["filename"],
            "file format": disk_infos["format"],
            "disk size": disk_infos["actual-size"],
            "virtual size": disk_infos["virtual-size"],
            "cluster size": disk_infos["cluster-size"]
            if "cluster-size" in disk_infos
            else None,
        }
        if "full-backing-filename" in disk_infos.keys():
            disk["backing file"] = format(disk_infos["full-backing-filename"])
        if "snapshots" in disk_infos.keys():
            disk["snapshots"] = [
                {
                    "id": snapshot["id"],
                    "tag": snapshot["name"],
                    "vmsize": snapshot["vm-state-size"],
                    "date": datetime.datetime.fromtimestamp(
                        float(
                            "{}.{}".format(snapshot["date-sec"], snapshot["date-nsec"])
                        )
                    ).isoformat(),
                    "vmclock": datetime.datetime.utcfromtimestamp(
                        float(
                            "{}.{}".format(
                                snapshot["vm-clock-sec"], snapshot["vm-clock-nsec"]
                            )
                        )
                    )
                    .time()
                    .isoformat(),
                }
                for snapshot in disk_infos["snapshots"]
            ]
        disks.append(disk)
    for disk in disks:
        if "backing file" in disk.keys():
            candidates = [
                info
                for info in disks
                if "file" in info.keys() and info["file"] == disk["backing file"]
            ]
            if candidates:
                disk["backing file"] = candidates[0]
    return disks[0]
def _get_uuid(dom):
    return ElementTree.fromstring(get_xml(dom)).find("uuid").text
def _get_on_poweroff(dom):
    node = ElementTree.fromstring(get_xml(dom)).find("on_poweroff")
    return node.text if node is not None else ""
def _get_on_reboot(dom):
    node = ElementTree.fromstring(get_xml(dom)).find("on_reboot")
    return node.text if node is not None else ""
def _get_on_crash(dom):
    node = ElementTree.fromstring(get_xml(dom)).find("on_crash")
    return node.text if node is not None else ""
def _get_nics(dom):
    nics = {}
    doc = ElementTree.fromstring(dom.XMLDesc(libvirt.VIR_DOMAIN_XML_INACTIVE))
    for iface_node in doc.findall("devices/interface"):
        nic = {}
        nic["type"] = iface_node.get("type")
        for v_node in iface_node:
            if v_node.tag == "mac":
                nic["mac"] = v_node.get("address")
            if v_node.tag == "model":
                nic["model"] = v_node.get("type")
            if v_node.tag == "target":
                nic["target"] = v_node.get("dev")
            if re.match("(driver|source|address)", v_node.tag):
                temp = {}
                for key, value in v_node.attrib.items():
                    temp[key] = value
                nic[v_node.tag] = temp
            if v_node.tag == "virtualport":
                temp = {}
                temp["type"] = v_node.get("type")
                for key, value in v_node.attrib.items():
                    temp[key] = value
                nic["virtualport"] = temp
        if "mac" not in nic:
            continue
        nics[nic["mac"]] = nic
    return nics
def _get_graphics(dom):
    out = {
        "autoport": "None",
        "keymap": "None",
        "listen": "None",
        "port": "None",
        "type": "None",
    }
    doc = ElementTree.fromstring(dom.XMLDesc(0))
    for g_node in doc.findall("devices/graphics"):
        for key, value in g_node.attrib.items():
            out[key] = value
    return out
def _get_loader(dom):
    out = {"path": "None"}
    doc = ElementTree.fromstring(dom.XMLDesc(0))
    for g_node in doc.findall("os/loader"):
        out["path"] = g_node.text
        for key, value in g_node.attrib.items():
            out[key] = value
    return out
def _get_disks(conn, dom):
    disks = {}
    doc = ElementTree.fromstring(dom.XMLDesc(0))
    all_volumes = _get_all_volumes_paths(conn)
    for elem in doc.findall("devices/disk"):
        source = elem.find("source")
        if source is None:
            continue
        target = elem.find("target")
        driver = elem.find("driver")
        if target is None:
            continue
        qemu_target = None
        extra_properties = None
        if "dev" in target.attrib:
            disk_type = elem.get("type")
            def _get_disk_volume_data(pool_name, volume_name):
                qemu_target = "{}/{}".format(pool_name, volume_name)
                pool = conn.storagePoolLookupByName(pool_name)
                extra_properties = {}
                try:
                    vol = pool.storageVolLookupByName(volume_name)
                    vol_info = vol.info()
                    extra_properties = {
                        "virtual size": vol_info[1],
                        "disk size": vol_info[2],
                    }
                    backing_files = [
                        {
                            "file": node.find("source").get("file"),
                            "file format": node.find("format").get("type"),
                        }
                        for node in elem.findall(".//backingStore[source]")
                    ]
                    if backing_files:
                        extra_properties["backing file"] = backing_files[0]
                        parent = extra_properties["backing file"]
                        for sub_backing_file in backing_files[1:]:
                            parent["backing file"] = sub_backing_file
                            parent = sub_backing_file
                    else:
                        vol_desc = ElementTree.fromstring(vol.XMLDesc())
                        backing_path = vol_desc.find("./backingStore/path")
                        backing_format = vol_desc.find("./backingStore/format")
                        if backing_path is not None:
                            extra_properties["backing file"] = {
                                "file": backing_path.text
                            }
                            if backing_format is not None:
                                extra_properties["backing file"][
                                    "file format"
                                ] = backing_format.get("type")
                except libvirt.libvirtError:
                    log.info(
                        "Couldn't extract all volume informations: pool is likely not"
                        " running or refreshed"
                    )
                return (qemu_target, extra_properties)
            if disk_type == "file":
                qemu_target = source.get("file", "")
                if qemu_target.startswith("/dev/zvol/"):
                    disks[target.get("dev")] = {"file": qemu_target, "zfs": True}
                    continue
                if qemu_target in all_volumes.keys():
                    volume = all_volumes[qemu_target]
                    qemu_target, extra_properties = _get_disk_volume_data(
                        volume["pool"], volume["name"]
                    )
                elif elem.get("device", "disk") != "cdrom":
                    try:
                        process = subprocess.Popen(
                            [
                                "qemu-img",
                                "info",
                                "-U",
                                "--output",
                                "json",
                                "--backing-chain",
                                qemu_target,
                            ],
                            shell=False,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE,
                        )
                        stdout, stderr = process.communicate()
                        if process.returncode == 0:
                            qemu_output = salt.utils.stringutils.to_str(stdout)
                            output = _parse_qemu_img_info(qemu_output)
                            extra_properties = output
                        else:
                            extra_properties = {"error": stderr}
                    except FileNotFoundError:
                        extra_properties = {"error": "qemu-img not found"}
            elif disk_type == "block":
                qemu_target = source.get("dev", "")
                if qemu_target in all_volumes.keys():
                    volume = all_volumes[qemu_target]
                    qemu_target, extra_properties = _get_disk_volume_data(
                        volume["pool"], volume["name"]
                    )
            elif disk_type == "network":
                qemu_target = source.get("protocol")
                source_name = source.get("name")
                if source_name:
                    qemu_target = "{}:{}".format(qemu_target, source_name)
                if source.get("protocol") in ["rbd", "gluster"]:
                    for pool_i in conn.listAllStoragePools():
                        pool_i_xml = ElementTree.fromstring(pool_i.XMLDesc())
                        name_node = pool_i_xml.find("source/name")
                        if name_node is not None and source_name.startswith(
                            "{}/".format(name_node.text)
                        ):
                            qemu_target = "{}{}".format(
                                pool_i.name(), source_name[len(name_node.text) :]
                            )
                            break
                if elem.get("device", "disk") == "cdrom":
                    host_node = source.find("host")
                    if host_node is not None:
                        hostname = host_node.get("name")
                        port = host_node.get("port")
                        qemu_target = urllib.parse.urlunparse(
                            (
                                source.get("protocol"),
                                "{}:{}".format(hostname, port) if port else hostname,
                                source_name,
                                "",
                                saxutils.unescape(source.get("query", "")),
                                "",
                            )
                        )
            elif disk_type == "volume":
                pool_name = source.get("pool")
                volume_name = source.get("volume")
                qemu_target, extra_properties = _get_disk_volume_data(
                    pool_name, volume_name
                )
            if not qemu_target:
                continue
            disk = {
                "file": qemu_target,
                "type": elem.get("device"),
            }
            if driver is not None and "type" in driver.attrib:
                disk["file format"] = driver.get("type")
            if extra_properties:
                disk.update(extra_properties)
            disks[target.get("dev")] = disk
    return disks
def _libvirt_creds():
    g_cmd = ["grep", "^\\s*group", "/etc/libvirt/qemu.conf"]
    u_cmd = ["grep", "^\\s*user", "/etc/libvirt/qemu.conf"]
    try:
        stdout = subprocess.Popen(g_cmd, stdout=subprocess.PIPE).communicate()[0]
        group = salt.utils.stringutils.to_str(stdout).split('"')[1]
    except IndexError:
        group = "root"
    try:
        stdout = subprocess.Popen(u_cmd, stdout=subprocess.PIPE).communicate()[0]
        user = salt.utils.stringutils.to_str(stdout).split('"')[1]
    except IndexError:
        user = "root"
    return {"user": user, "group": group}
def _migrate(dom, dst_uri, **kwargs):
    flags = 0
    params = {}
    migrated_state = libvirt.VIR_DOMAIN_RUNNING_MIGRATED
    if kwargs.get("live", True):
        flags |= libvirt.VIR_MIGRATE_LIVE
    if kwargs.get("persistent", True):
        flags |= libvirt.VIR_MIGRATE_PERSIST_DEST
    if kwargs.get("undefinesource", True):
        flags |= libvirt.VIR_MIGRATE_UNDEFINE_SOURCE
    max_bandwidth = kwargs.get("max_bandwidth")
    if max_bandwidth:
        try:
            bandwidth_value = int(max_bandwidth)
        except ValueError:
            raise SaltInvocationError(
                "Invalid max_bandwidth value: {}".format(max_bandwidth)
            )
        dom.migrateSetMaxSpeed(bandwidth_value)
    max_downtime = kwargs.get("max_downtime")
    if max_downtime:
        try:
            downtime_value = int(max_downtime)
        except ValueError:
            raise SaltInvocationError(
                "Invalid max_downtime value: {}".format(max_downtime)
            )
        dom.migrateSetMaxDowntime(downtime_value)
    if kwargs.get("offline") is True:
        flags |= libvirt.VIR_MIGRATE_OFFLINE
        migrated_state = libvirt.VIR_DOMAIN_RUNNING_UNPAUSED
    if kwargs.get("compressed") is True:
        flags |= libvirt.VIR_MIGRATE_COMPRESSED
    comp_methods = kwargs.get("comp_methods")
    if comp_methods:
        params[libvirt.VIR_MIGRATE_PARAM_COMPRESSION] = comp_methods.split(",")
    comp_options = {
        "comp_mt_level": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_LEVEL,
        "comp_mt_threads": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_THREADS,
        "comp_mt_dthreads": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_MT_DTHREADS,
        "comp_xbzrle_cache": libvirt.VIR_MIGRATE_PARAM_COMPRESSION_XBZRLE_CACHE,
    }
    for (comp_option, param_key) in comp_options.items():
        comp_option_value = kwargs.get(comp_option)
        if comp_option_value:
            try:
                params[param_key] = int(comp_option_value)
            except ValueError:
                raise SaltInvocationError("Invalid {} value".format(comp_option))
    parallel_connections = kwargs.get("parallel_connections")
    if parallel_connections:
        try:
            params[libvirt.VIR_MIGRATE_PARAM_PARALLEL_CONNECTIONS] = int(
                parallel_connections
            )
        except ValueError:
            raise SaltInvocationError("Invalid parallel_connections value")
        flags |= libvirt.VIR_MIGRATE_PARALLEL
    if __salt__["config.get"]("virt:tunnel"):
        if parallel_connections:
            raise SaltInvocationError(
                "Parallel migration isn't compatible with tunneled migration"
            )
        flags |= libvirt.VIR_MIGRATE_PEER2PEER
        flags |= libvirt.VIR_MIGRATE_TUNNELLED
    if kwargs.get("postcopy") is True:
        flags |= libvirt.VIR_MIGRATE_POSTCOPY
    postcopy_bandwidth = kwargs.get("postcopy_bandwidth")
    if postcopy_bandwidth:
        try:
            postcopy_bandwidth_value = int(postcopy_bandwidth)
        except ValueError:
            raise SaltInvocationError("Invalid postcopy_bandwidth value")
        dom.migrateSetMaxSpeed(
            postcopy_bandwidth_value,
            flags=libvirt.VIR_DOMAIN_MIGRATE_MAX_SPEED_POSTCOPY,
        )
    copy_storage = kwargs.get("copy_storage")
    if copy_storage:
        if copy_storage == "all":
            flags |= libvirt.VIR_MIGRATE_NON_SHARED_DISK
        elif copy_storage in ["inc", "incremental"]:
            flags |= libvirt.VIR_MIGRATE_NON_SHARED_INC
        else:
            raise SaltInvocationError("invalid copy_storage value")
    try:
        state = False
        dst_conn = __get_conn(
            connection=dst_uri,
            username=kwargs.get("username"),
            password=kwargs.get("password"),
        )
        new_dom = dom.migrate3(dconn=dst_conn, params=params, flags=flags)
        if new_dom:
            state = new_dom.state()
        dst_conn.close()
        return state and migrated_state in state
    except libvirt.libvirtError as err:
        dst_conn.close()
        raise CommandExecutionError(err.get_error_message())
def _get_volume_path(pool, volume_name):
    if volume_name in pool.listVolumes():
        volume = pool.storageVolLookupByName(volume_name)
        volume_xml = ElementTree.fromstring(volume.XMLDesc())
        return volume_xml.find("./target/path").text
    pool_xml = ElementTree.fromstring(pool.XMLDesc())
    pool_path = pool_xml.find("./target/path").text
    return pool_path + "/" + volume_name
def _disk_from_pool(conn, pool, pool_xml, volume_name):
    pool_type = pool_xml.get("type")
    disk_context = {}
    if pool_type in ["dir", "netfs", "fs"]:
        disk_context["type"] = "file"
        disk_context["source_file"] = _get_volume_path(pool, volume_name)
    elif pool_type in ["logical", "disk", "iscsi", "scsi"]:
        disk_context["type"] = "block"
        disk_context["format"] = "raw"
        disk_context["source_file"] = _get_volume_path(pool, volume_name)
    elif pool_type in ["rbd", "gluster", "sheepdog"]:
        disk_context["type"] = "network"
        disk_context["protocol"] = pool_type
        disk_context["hosts"] = [
            {"name": host.get("name"), "port": host.get("port")}
            for host in pool_xml.findall(".//host")
        ]
        dir_node = pool_xml.find("./source/dir")
        name_node = pool_xml.find("./source/name")
        if name_node is not None:
            disk_context["volume"] = "{}/{}".format(name_node.text, volume_name)
        auth_node = pool_xml.find("./source/auth")
        if auth_node is not None:
            username = auth_node.get("username")
            secret_node = auth_node.find("./secret")
            usage = secret_node.get("usage")
            if not usage:
                uuid = secret_node.get("uuid")
                usage = conn.secretLookupByUUIDString(uuid).usageID()
            disk_context["auth"] = {
                "type": "ceph",
                "username": username,
                "usage": usage,
            }
    return disk_context
def _handle_unit(s, def_unit="m"):
    m = re.match(r"(?P&lt;value&gt;[0-9.]*)\s*(?P&lt;unit&gt;.*)$", str(s).strip())
    value = m.group("value")
    unit = m.group("unit").lower() or def_unit
    try:
        value = int(value)
    except ValueError:
        try:
            value = float(value)
        except ValueError:
            raise SaltInvocationError("invalid number")
    dec = False
    if re.match(r"[kmgtpezy]b$", unit):
        dec = True
    elif not re.match(r"(b|[kmgtpezy](ib)?)$", unit):
        raise SaltInvocationError("invalid units")
    p = "bkmgtpezy".index(unit[0])
    value *= 10 ** (p * 3) if dec else 2 ** (p * 10)
    return int(value)
def nesthash(value=None):
    return collections.defaultdict(nesthash, value or {})
def _gen_xml(
    conn,
    name,
    cpu,
    mem,
    diskp,
    nicp,
    hypervisor,
    os_type,
    arch,
    graphics=None,
    boot=None,
    boot_dev=None,
    numatune=None,
    hypervisor_features=None,
    clock=None,
    serials=None,
    consoles=None,
    stop_on_reboot=False,
    host_devices=None,
    **kwargs
):
    context = {
        "hypervisor": hypervisor,
        "name": name,
        "hypervisor_features": hypervisor_features or {},
        "clock": clock or {},
        "on_reboot": "destroy" if stop_on_reboot else "restart",
    }
    context["to_kib"] = lambda v: int(_handle_unit(v) / 1024)
    context["yesno"] = lambda v: "yes" if v else "no"
    context["mem"] = nesthash()
    if isinstance(mem, int):
        context["mem"]["boot"] = mem
        context["mem"]["current"] = mem
    elif isinstance(mem, dict):
        context["mem"] = nesthash(mem)
    context["cpu"] = nesthash()
    context["cputune"] = nesthash()
    if isinstance(cpu, int):
        context["cpu"]["maximum"] = str(cpu)
    elif isinstance(cpu, dict):
        context["cpu"] = nesthash(cpu)
    if clock:
        offset = "utc" if clock.get("utc", True) else "localtime"
        if "timezone" in clock:
            offset = "timezone"
        context["clock"]["offset"] = offset
    if hypervisor in ["qemu", "kvm"]:
        context["numatune"] = numatune if numatune else {}
        context["controller_model"] = False
    elif hypervisor == "vmware":
        context["controller_model"] = "lsilogic"
    if graphics:
        if "listen" not in graphics:
            graphics["listen"] = {"type": "address", "address": "0.0.0.0"}
        elif (
            "address" not in graphics["listen"]
            and graphics["listen"]["type"] == "address"
        ):
            graphics["listen"]["address"] = "0.0.0.0"
        if graphics.get("type", "none") == "none":
            graphics = None
    context["graphics"] = graphics
    context["boot_dev"] = boot_dev.split() if boot_dev is not None else ["hd"]
    context["boot"] = boot if boot else {}
    efi_value = context["boot"].get("efi", None) if boot else None
    if efi_value is True:
        context["boot"]["os_attrib"] = "firmware='efi'"
    elif efi_value is not None and type(efi_value) != bool:
        raise SaltInvocationError("Invalid efi value")
    if os_type == "xen":
        if __grains__["os_family"] == "Suse":
            if not boot or not boot.get("kernel", None):
                paths = [
                    path
                    for path in ["/usr/share", "/usr/lib"]
                    if os.path.exists(path + "/grub2/x86_64-xen/grub.xen")
                ]
                if not paths:
                    raise CommandExecutionError("grub-x86_64-xen needs to be installed")
                context["boot"]["kernel"] = paths[0] + "/grub2/x86_64-xen/grub.xen"
                context["boot_dev"] = []
    default_port = 23023
    default_chardev_type = "tcp"
    chardev_types = ["serial", "console"]
    for chardev_type in chardev_types:
        context[chardev_type + "s"] = []
        parameter_value = locals()[chardev_type + "s"]
        if parameter_value is not None:
            for chardev in parameter_value:
                chardev_context = chardev
                chardev_context["type"] = chardev.get("type", default_chardev_type)
                if chardev_context["type"] == "tcp":
                    chardev_context["port"] = chardev.get("port", default_port)
                    chardev_context["protocol"] = chardev.get("protocol", "telnet")
                context[chardev_type + "s"].append(chardev_context)
    context["disks"] = []
    disk_bus_map = {"virtio": "vd", "xen": "xvd", "fdc": "fd", "ide": "hd"}
    targets = []
    for i, disk in enumerate(diskp):
        prefix = disk_bus_map.get(disk["model"], "sd")
        disk_context = {
            "device": disk.get("device", "disk"),
            "target_dev": _get_disk_target(targets, len(diskp), prefix),
            "disk_bus": disk["model"],
            "format": disk.get("format", "raw"),
            "index": str(i),
            "io": disk.get("io", "native"),
            "iothread": disk.get("iothread_id", None),
        }
        targets.append(disk_context["target_dev"])
        if disk.get("source_file"):
            url = urllib.parse.urlparse(disk["source_file"])
            if not url.scheme or not url.hostname:
                disk_context["source_file"] = disk["source_file"]
                disk_context["type"] = "file"
            elif url.scheme in ["http", "https", "ftp", "ftps", "tftp"]:
                disk_context["type"] = "network"
                disk_context["protocol"] = url.scheme
                disk_context["volume"] = url.path
                disk_context["query"] = saxutils.escape(url.query)
                disk_context["hosts"] = [{"name": url.hostname, "port": url.port}]
        elif disk.get("pool"):
            disk_context["volume"] = disk["filename"]
            pool = conn.storagePoolLookupByName(disk["pool"])
            pool_xml = ElementTree.fromstring(pool.XMLDesc())
            pool_type = pool_xml.get("type")
            if hypervisor == "xen" or pool_type in ["rbd", "gluster", "sheepdog"]:
                disk_context.update(
                    _disk_from_pool(conn, pool, pool_xml, disk_context["volume"])
                )
            else:
                if pool_type in ["disk", "logical"]:
                    disk_context["format"] = "raw"
                disk_context["type"] = "volume"
                disk_context["pool"] = disk["pool"]
        else:
            disk_context["type"] = "file"
        if hypervisor in ["qemu", "kvm", "bhyve", "xen"]:
            disk_context["address"] = False
            disk_context["driver"] = True
        elif hypervisor in ["esxi", "vmware"]:
            disk_context["address"] = True
            disk_context["driver"] = False
        context["disks"].append(disk_context)
    context["nics"] = nicp
    hostdev_context = []
    try:
        for hostdev_name in host_devices or []:
            hostdevice = conn.nodeDeviceLookupByName(hostdev_name)
            doc = ElementTree.fromstring(hostdevice.XMLDesc())
            if "pci" in hostdevice.listCaps():
                hostdev_context.append(
                    {
                        "type": "pci",
                        "domain": "0x{:04x}".format(
                            int(doc.find("./capability[@type='pci']/domain").text)
                        ),
                        "bus": "0x{:02x}".format(
                            int(doc.find("./capability[@type='pci']/bus").text)
                        ),
                        "slot": "0x{:02x}".format(
                            int(doc.find("./capability[@type='pci']/slot").text)
                        ),
                        "function": "0x{}".format(
                            doc.find("./capability[@type='pci']/function").text
                        ),
                    }
                )
            elif "usb_device" in hostdevice.listCaps():
                vendor_id = doc.find(".//vendor").get("id")
                product_id = doc.find(".//product").get("id")
                hostdev_context.append(
                    {"type": "usb", "vendor": vendor_id, "product": product_id}
                )
    except libvirt.libvirtError as err:
        conn.close()
        raise CommandExecutionError(
            "Failed to get host devices: " + err.get_error_message()
        )
    context["hostdevs"] = hostdev_context
    context["os_type"] = os_type
    context["arch"] = arch
    fn_ = "libvirt_domain.jinja"
    try:
        template = JINJA.get_template(fn_)
    except jinja2.exceptions.TemplateNotFound:
        log.error("Could not load template %s", fn_)
        return ""
    return template.render(**context)
def _gen_vol_xml(
    name,
    size,
    format=None,
    allocation=0,
    type=None,
    permissions=None,
    backing_store=None,
    nocow=False,
):
    size = int(size) * 1024  # MB
    context = {
        "type": type,
        "name": name,
        "target": {"permissions": permissions, "nocow": nocow},
        "format": format,
        "size": str(size),
        "allocation": str(int(allocation) * 1024),
        "backingStore": backing_store,
    }
    fn_ = "libvirt_volume.jinja"
    try:
        template = JINJA.get_template(fn_)
    except jinja2.exceptions.TemplateNotFound:
        log.error("Could not load template %s", fn_)
        return ""
    return template.render(**context)
def _gen_net_xml(
    name,
    bridge,
    forward,
    vport,
    tag=None,
    ip_configs=None,
    mtu=None,
    domain=None,
    nat=None,
    interfaces=None,
    addresses=None,
    physical_function=None,
    dns=None,
):
    if isinstance(vport, str):
        vport_context = {"type": vport}
    else:
        vport_context = vport
    if isinstance(tag, (str, int)):
        tag_context = {"tags": [{"id": tag}]}
    else:
        tag_context = tag
    addresses_context = []
    if addresses:
        matches = [
            re.fullmatch(r"([0-9]+):([0-9A-Fa-f]+):([0-9A-Fa-f]+)\.([0-9])", addr)
            for addr in addresses.lower().split(" ")
        ]
        addresses_context = [
            {
                "domain": m.group(1),
                "bus": m.group(2),
                "slot": m.group(3),
                "function": m.group(4),
            }
            for m in matches
            if m
        ]
    context = {
        "name": name,
        "bridge": bridge,
        "mtu": mtu,
        "domain": domain,
        "forward": forward,
        "nat": nat,
        "interfaces": interfaces.split(" ") if interfaces else [],
        "addresses": addresses_context,
        "pf": physical_function,
        "vport": vport_context,
        "vlan": tag_context,
        "dns": dns,
        "ip_configs": [
            {
                "address": ipaddress.ip_network(config["cidr"]),
                "dhcp_ranges": config.get("dhcp_ranges", []),
                "hosts": config.get("hosts", {}),
                "bootp": config.get("bootp", {}),
                "tftp": config.get("tftp"),
            }
            for config in ip_configs or []
        ],
        "yesno": lambda v: "yes" if v else "no",
    }
    fn_ = "libvirt_network.jinja"
    try:
        template = JINJA.get_template(fn_)
    except jinja2.exceptions.TemplateNotFound:
        log.error("Could not load template %s", fn_)
        return ""
    return template.render(**context)
def _gen_pool_xml(
    name,
    ptype,
    target=None,
    permissions=None,
    source_devices=None,
    source_dir=None,
    source_adapter=None,
    source_hosts=None,
    source_auth=None,
    source_name=None,
    source_format=None,
    source_initiator=None,
):
    hosts = [host.split(":") for host in source_hosts or []]
    source = None
    if any(
        [
            source_devices,
            source_dir,
            source_adapter,
            hosts,
            source_auth,
            source_name,
            source_format,
            source_initiator,
        ]
    ):
        source = {
            "devices": source_devices or [],
            "dir": source_dir
            if source_format != "cifs" or not source_dir
            else source_dir.lstrip("/"),
            "adapter": source_adapter,
            "hosts": [
                {"name": host[0], "port": host[1] if len(host) &gt; 1 else None}
                for host in hosts
            ],
            "auth": source_auth,
            "name": source_name,
            "format": source_format,
            "initiator": source_initiator,
        }
    context = {
        "name": name,
        "ptype": ptype,
        "target": {"path": target, "permissions": permissions},
        "source": source,
    }
    fn_ = "libvirt_pool.jinja"
    try:
        template = JINJA.get_template(fn_)
    except jinja2.exceptions.TemplateNotFound:
        log.error("Could not load template %s", fn_)
        return ""
    return template.render(**context)
def _gen_secret_xml(auth_type, usage, description):
    context = {
        "type": auth_type,
        "usage": usage,
        "description": description,
    }
    fn_ = "libvirt_secret.jinja"
    try:
        template = JINJA.get_template(fn_)
    except jinja2.exceptions.TemplateNotFound:
        log.error("Could not load template %s", fn_)
        return ""
    return template.render(**context)
def _get_images_dir():
    img_dir = __salt__["config.get"]("virt:images")
    log.debug("Image directory from config option `virt:images` is %s", img_dir)
    return img_dir
def _zfs_image_create(
    vm_name,
    pool,
    disk_name,
    hostname_property_name,
    sparse_volume,
    disk_size,
    disk_image_name,
):
    if not disk_image_name and not disk_size:
        raise CommandExecutionError(
            "Unable to create new disk {}, please specify"
            " the disk image name or disk size argument".format(disk_name)
        )
    if not pool:
        raise CommandExecutionError(
            "Unable to create new disk {}, please specify the disk pool name".format(
                disk_name
            )
        )
    destination_fs = os.path.join(pool, "{}.{}".format(vm_name, disk_name))
    log.debug("Image destination will be %s", destination_fs)
    existing_disk = __salt__["zfs.list"](name=pool)
    if "error" in existing_disk:
        raise CommandExecutionError(
            "Unable to create new disk {}. {}".format(
                destination_fs, existing_disk["error"]
            )
        )
    elif destination_fs in existing_disk:
        log.info("ZFS filesystem %s already exists. Skipping creation", destination_fs)
        blockdevice_path = os.path.join("/dev/zvol", pool, vm_name)
        return blockdevice_path
    properties = {}
    if hostname_property_name:
        properties[hostname_property_name] = vm_name
    if disk_image_name:
        __salt__["zfs.clone"](
            name_a=disk_image_name, name_b=destination_fs, properties=properties
        )
    elif disk_size:
        __salt__["zfs.create"](
            name=destination_fs,
            properties=properties,
            volume_size=disk_size,
            sparse=sparse_volume,
        )
    blockdevice_path = os.path.join(
        "/dev/zvol", pool, "{}.{}".format(vm_name, disk_name)
    )
    log.debug("Image path will be %s", blockdevice_path)
    return blockdevice_path
def _qemu_image_create(disk, create_overlay=False, saltenv="base"):
    disk_size = disk.get("size", None)
    disk_image = disk.get("image", None)
    if not disk_size and not disk_image:
        raise CommandExecutionError(
            "Unable to create new disk {}, please specify"
            " disk size and/or disk image argument".format(disk["filename"])
        )
    img_dest = disk["source_file"]
    log.debug("Image destination will be %s", img_dest)
    img_dir = os.path.dirname(img_dest)
    log.debug("Image destination directory is %s", img_dir)
    if not os.path.exists(img_dir):
        os.makedirs(img_dir)
    if disk_image:
        log.debug("Create disk from specified image %s", disk_image)
        sfn = __salt__["cp.cache_file"](disk_image, saltenv)
        qcow2 = False
        if salt.utils.path.which("qemu-img"):
            res = __salt__["cmd.run"]('qemu-img info "{}"'.format(sfn))
            imageinfo = salt.utils.yaml.safe_load(res)
            qcow2 = imageinfo["file format"] == "qcow2"
<a name="6"></a>        try:
            if create_overlay and qcow2:
                log.info("Cloning qcow2 image %s using copy on write", sfn)
                __salt__<font color="#8c8774"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>["cmd.run"](
                    'qemu-img create -f qcow2 -o backing_file="{}" "{}"'.format(
                        sfn, img_dest
                    ).split()
                )
            else:
                log.debug("Copying %s to %s", sfn, img_dest)
                salt.utils.files.copyfile(</b></font>sfn, img_dest)
            mask = salt.utils.files.get_umask()
            if disk_size and qcow2:
                log.debug("Resize qcow2 image to %sM", disk_size)
                __salt__["cmd.run"](
                    'qemu-img resize "{}" {}M'.format(img_dest, disk_size)
                )
            log.debug("Apply umask and remove exec bit")
            mode = (0o0777 ^ mask) &amp; 0o0666
            os.chmod(img_dest, mode)
        except OSError as err:
            raise CommandExecutionError(
                "Problem while copying image. {} - {}".format(disk_image, err)
            )
    else:
        try:
            mask = salt.utils.files.get_umask()
            if disk_size:
                log.debug("Create empty image with size %sM", disk_size)
                __salt__["cmd.run"](
                    'qemu-img create -f {} "{}" {}M'.format(
                        disk.get("format", "qcow2"), img_dest, disk_size
                    )
                )
            else:
                raise CommandExecutionError(
                    "Unable to create new disk {},"
                    " please specify &lt;size&gt; argument".format(img_dest)
                )
            log.debug("Apply umask and remove exec bit")
            mode = (0o0777 ^ mask) &amp; 0o0666
            os.chmod(img_dest, mode)
        except OSError as err:
            raise CommandExecutionError(
                "Problem while creating volume {} - {}".format(img_dest, err)
            )
    return img_dest
def _seed_image(seed_cmd, img_path, name, config, install, pub_key, priv_key):
    log.debug("Seeding image")
    __salt__[seed_cmd](
        img_path,
        id_=name,
        config=config,
        install=install,
        pub_key=pub_key,
        priv_key=priv_key,
    )
def _disk_volume_create(conn, disk, seeder=None, saltenv="base"):
    if disk.get("overlay_image"):
        raise SaltInvocationError(
            "Disk overlay_image property is not supported when creating volumes,"
            "use backing_store_path and backing_store_format instead."
        )
    pool = conn.storagePoolLookupByName(disk["pool"])
    if disk["filename"] in pool.listVolumes():
        return
    pool_type = ElementTree.fromstring(pool.XMLDesc()).get("type")
    backing_path = disk.get("backing_store_path")
    backing_format = disk.get("backing_store_format")
    backing_store = None
    if (
        backing_path
        and backing_format
        and (disk.get("format") == "qcow2" or pool_type == "logical")
    ):
        backing_store = {"path": backing_path, "format": backing_format}
    if backing_store and disk.get("image"):
        raise SaltInvocationError(
            "Using a template image with a backing store is not possible, "
            "choose either of them."
        )
    vol_xml = _gen_vol_xml(
        disk["filename"],
        disk.get("size", 0),
        format=disk.get("format"),
        backing_store=backing_store,
    )
    _define_vol_xml_str(conn, vol_xml, disk.get("pool"))
    if disk.get("image"):
        log.debug("Caching disk template image: %s", disk.get("image"))
        cached_path = __salt__["cp.cache_file"](disk.get("image"), saltenv)
        if seeder:
            seeder(cached_path)
        _volume_upload(
            conn,
            disk["pool"],
            disk["filename"],
            cached_path,
            sparse=disk.get("format") == "qcow2",
        )
def _disk_profile(conn, profile, hypervisor, disks, vm_name):
    default = [{"system": {"size": 8192}}]
    if hypervisor == "vmware":
        overlay = {"format": "vmdk", "model": "scsi", "device": "disk"}
    elif hypervisor in ["qemu", "kvm"]:
        overlay = {"device": "disk", "model": "virtio"}
    elif hypervisor == "xen":
        overlay = {"device": "disk", "model": "xen"}
    elif hypervisor == "bhyve":
        overlay = {"format": "raw", "model": "virtio", "sparse_volume": False}
    else:
        overlay = {}
    disklist = []
    if profile:
        disklist = copy.deepcopy(
            __salt__["config.get"]("virt:disk", {}).get(profile, default)
        )
        disklist = [dict(d, name=name) for disk in disklist for name, d in disk.items()]
    if disks:
        for udisk in disks:
            if "name" in udisk:
                found = [disk for disk in disklist if udisk["name"] == disk["name"]]
                if found:
                    found[0].update(udisk)
                else:
                    disklist.append(udisk)
    pool_caps = _pool_capabilities(conn)
    for disk in disklist:
        if disk.get("device", "disk") == "cdrom" and "model" not in disk:
            disk["model"] = "ide"
        for key, val in overlay.items():
            if key not in disk:
                disk[key] = val
        if disk.get("source_file") and os.path.exists(disk["source_file"]):
            disk["filename"] = os.path.basename(disk["source_file"])
            if not disk.get("format"):
                disk["format"] = (
                    "qcow2" if disk.get("device", "disk") != "cdrom" else "raw"
                )
        elif vm_name and disk.get("device", "disk") == "disk":
            _fill_disk_filename(conn, vm_name, disk, hypervisor, pool_caps)
    return disklist
def _fill_disk_filename(conn, vm_name, disk, hypervisor, pool_caps):
    disk["filename"] = "{}_{}".format(vm_name, disk["name"])
    base_dir = disk.get("pool", None)
    if hypervisor in ["qemu", "kvm", "xen"]:
        if not base_dir:
            base_dir = _get_images_dir()
        if base_dir not in conn.listStoragePools():
            if not disk.get("format"):
                disk["format"] = "qcow2"
            disk["filename"] = "{}.{}".format(disk["filename"], disk["format"])
            disk["source_file"] = os.path.join(base_dir, disk["filename"])
        else:
            if "pool" not in disk:
                disk["pool"] = base_dir
            pool_obj = conn.storagePoolLookupByName(base_dir)
            pool_xml = ElementTree.fromstring(pool_obj.XMLDesc())
            pool_type = pool_xml.get("type")
            if pool_type == "disk":
                device = pool_xml.find("./source/device").get("path")
                all_volumes = pool_obj.listVolumes()
                if disk.get("source_file") not in all_volumes:
                    indexes = [
                        int(re.sub("[a-z]+", "", vol_name)) for vol_name in all_volumes
                    ] or [0]
                    index = min(
                        idx for idx in range(1, max(indexes) + 2) if idx not in indexes
                    )
                    disk["filename"] = "{}{}".format(os.path.basename(device), index)
            if disk.get("source_file"):
                if not disk.get("source_file") in pool_obj.listVolumes():
                    raise SaltInvocationError(
                        "{} volume doesn't exist in pool {}".format(
                            disk.get("source_file"), base_dir
                        )
                    )
                disk["filename"] = disk["source_file"]
                del disk["source_file"]
            if not disk.get("format"):
                volume_options = (
                    [
                        type_caps.get("options", {}).get("volume", {})
                        for type_caps in pool_caps.get("pool_types")
                        if type_caps["name"] == pool_type
                    ]
                    or [{}]
                )[0]
                if "qcow2" in volume_options.get("targetFormatType", []):
                    disk["format"] = "qcow2"
                else:
                    disk["format"] = volume_options.get("default_format", None)
    elif hypervisor == "bhyve" and vm_name:
        disk["filename"] = "{}.{}".format(vm_name, disk["name"])
        disk["source_file"] = os.path.join(
            "/dev/zvol", base_dir or "", disk["filename"]
        )
    elif hypervisor in ["esxi", "vmware"]:
        if not base_dir:
            base_dir = __salt__["config.get"]("virt:storagepool", "[0] ")
        disk["filename"] = "{}.{}".format(disk["filename"], disk["format"])
        disk["source_file"] = "{}{}".format(base_dir, disk["filename"])
def _complete_nics(interfaces, hypervisor):
    vmware_overlay = {"type": "bridge", "source": "DEFAULT", "model": "e1000"}
    kvm_overlay = {"type": "bridge", "source": "br0", "model": "virtio"}
    xen_overlay = {"type": "bridge", "source": "br0", "model": None}
    bhyve_overlay = {"type": "bridge", "source": "bridge0", "model": "virtio"}
    overlays = {
        "xen": xen_overlay,
        "kvm": kvm_overlay,
        "qemu": kvm_overlay,
        "vmware": vmware_overlay,
        "bhyve": bhyve_overlay,
    }
    def _normalize_net_types(attributes):
        for type_ in ["bridge", "network"]:
            if type_ in attributes:
                attributes["type"] = type_
                attributes["source"] = attributes.pop(type_)
        attributes["type"] = attributes.get("type", None)
        attributes["source"] = attributes.get("source", None)
    def _apply_default_overlay(attributes):
        for key, value in overlays[hypervisor].items():
            if key not in attributes or not attributes[key]:
                attributes[key] = value
    for interface in interfaces:
        _normalize_net_types(interface)
        if hypervisor in overlays:
            _apply_default_overlay(interface)
    return interfaces
def _nic_profile(profile_name, hypervisor):
    config_data = __salt__["config.get"]("virt:nic", {}).get(
        profile_name, [{"eth0": {}}]
    )
    interfaces = []
    def append_dict_profile_to_interface_list(profile_dict):
        for interface_name, attributes in profile_dict.items():
            attributes["name"] = interface_name
            interfaces.append(attributes)
    if isinstance(config_data, dict):
        append_dict_profile_to_interface_list(config_data)
    elif isinstance(config_data, list):
        for interface in config_data:
            if isinstance(interface, dict):
                if len(interface) == 1:
                    append_dict_profile_to_interface_list(interface)
                else:
                    interfaces.append(interface)
    return _complete_nics(interfaces, hypervisor)
def _get_merged_nics(hypervisor, profile, interfaces=None):
    nicp = _nic_profile(profile, hypervisor) if profile else []
    log.debug("NIC profile is %s", nicp)
    if interfaces:
        users_nics = _complete_nics(interfaces, hypervisor)
        for unic in users_nics:
            found = [nic for nic in nicp if nic["name"] == unic["name"]]
            if found:
                found[0].update(unic)
            else:
                nicp.append(unic)
        log.debug("Merged NICs: %s", nicp)
    return nicp
def _handle_remote_boot_params(orig_boot):
    saltinst_dir = None
    new_boot = orig_boot.copy()
    keys = orig_boot.keys()
    cases = [
        {"efi"},
        {"kernel", "initrd", "efi"},
        {"kernel", "initrd", "cmdline", "efi"},
        {"loader", "nvram"},
        {"kernel", "initrd"},
        {"kernel", "initrd", "cmdline"},
        {"kernel", "initrd", "loader", "nvram"},
        {"kernel", "initrd", "cmdline", "loader", "nvram"},
    ]
    if keys in cases:
        for key in keys:
            if key == "efi" and type(orig_boot.get(key)) == bool:
                new_boot[key] = orig_boot.get(key)
            elif orig_boot.get(key) is not None and salt.utils.virt.check_remote(
                orig_boot.get(key)
            ):
                if saltinst_dir is None:
                    os.makedirs(CACHE_DIR)
                    saltinst_dir = CACHE_DIR
                new_boot[key] = salt.utils.virt.download_remote(
                    orig_boot.get(key), saltinst_dir
                )
        return new_boot
    else:
        raise SaltInvocationError(
            "Invalid boot parameters,It has to follow this combination: [(kernel,"
            " initrd) or/and cmdline] or/and [(loader, nvram) or efi]"
        )
def _handle_efi_param(boot, desc):
    efi_value = boot.get("efi", None) if boot else None
    parent_tag = desc.find("os")
    os_attrib = parent_tag.attrib
    if efi_value is False and os_attrib != {}:
        parent_tag.attrib.pop("firmware", None)
        return True
    elif type(efi_value) == bool and os_attrib == {}:
        if efi_value is True and parent_tag.find("loader") is None:
            parent_tag.set("firmware", "efi")
            return True
        if efi_value is False and parent_tag.find("loader") is not None:
            parent_tag.remove(parent_tag.find("loader"))
            parent_tag.remove(parent_tag.find("nvram"))
            return True
    elif type(efi_value) != bool:
        raise SaltInvocationError("Invalid efi value")
    return False
def init(
    name,
    cpu,
    mem,
    nic="default",
    interfaces=None,
    hypervisor=None,
    start=True,  # pylint: disable=redefined-outer-name
    disk="default",
    disks=None,
    saltenv="base",
    seed=True,
    install=True,
    pub_key=None,
    priv_key=None,
    seed_cmd="seed.apply",
    graphics=None,
    os_type=None,
    arch=None,
    boot=None,
    boot_dev=None,
    numatune=None,
    hypervisor_features=None,
    clock=None,
    serials=None,
    consoles=None,
    stop_on_reboot=False,
    host_devices=None,
    **kwargs
):
    try:
        conn = __get_conn(**kwargs)
        caps = _capabilities(conn)
        os_types = sorted({guest["os_type"] for guest in caps["guests"]})
        arches = sorted({guest["arch"]["name"] for guest in caps["guests"]})
        virt_hypervisor = hypervisor
        if not virt_hypervisor:
            hypervisors = sorted(
                {
                    x
                    for y in [
                        guest["arch"]["domains"].keys() for guest in caps["guests"]
                    ]
                    for x in y
                }
            )
            if len(hypervisors) == 0:
                raise SaltInvocationError("No supported hypervisors were found")
            virt_hypervisor = "kvm" if "kvm" in hypervisors else hypervisors[0]
        virt_hypervisor = "vmware" if virt_hypervisor == "esxi" else virt_hypervisor
        log.debug("Using hypervisor %s", virt_hypervisor)
        nicp = _get_merged_nics(virt_hypervisor, nic, interfaces)
        diskp = _disk_profile(conn, disk, virt_hypervisor, disks, name)
        for _disk in diskp:
            if _disk.get("device", "disk") == "cdrom":
                continue
            log.debug("Creating disk for VM [ %s ]: %s", name, _disk)
            if virt_hypervisor == "vmware":
                if "image" in _disk:
                    raise SaltInvocationError(
                        "virt.init does not support image "
                        "template in conjunction with esxi hypervisor"
                    )
                else:
                    log.debug("Generating libvirt XML for %s", _disk)
                    volume_name = "{}/{}".format(name, _disk["name"])
                    filename = "{}.{}".format(volume_name, _disk["format"])
                    vol_xml = _gen_vol_xml(
                        filename, _disk["size"], format=_disk["format"]
                    )
                    _define_vol_xml_str(conn, vol_xml, pool=_disk.get("pool"))
            elif virt_hypervisor in ["qemu", "kvm", "xen"]:
                def seeder(path):
                    _seed_image(
                        seed_cmd,
                        path,
                        name,
                        kwargs.get("config"),
                        install,
                        pub_key,
                        priv_key,
                    )
                create_overlay = _disk.get("overlay_image", False)
                format = _disk.get("format")
                if _disk.get("source_file"):
                    if os.path.exists(_disk["source_file"]):
                        img_dest = _disk["source_file"]
                    else:
                        img_dest = _qemu_image_create(_disk, create_overlay, saltenv)
                else:
                    _disk_volume_create(conn, _disk, seeder if seed else None, saltenv)
                    img_dest = None
                if seed and img_dest and _disk.get("image", None):
                    seeder(img_dest)
            elif hypervisor in ["bhyve"]:
                img_dest = _zfs_image_create(
                    vm_name=name,
                    pool=_disk.get("pool"),
                    disk_name=_disk.get("name"),
                    disk_size=_disk.get("size"),
                    disk_image_name=_disk.get("image"),
                    hostname_property_name=_disk.get("hostname_property"),
                    sparse_volume=_disk.get("sparse_volume"),
                )
            else:
                raise SaltInvocationError(
                    "Unsupported hypervisor when handling disk image: {}".format(
                        virt_hypervisor
                    )
                )
        log.debug("Generating VM XML")
        if os_type is None:
            os_type = "hvm" if "hvm" in os_types else os_types[0]
        if arch is None:
            arch = "x86_64" if "x86_64" in arches else arches[0]
        if boot is not None:
            boot = _handle_remote_boot_params(boot)
        vm_xml = _gen_xml(
            conn,
            name,
            cpu,
            mem,
            diskp,
            nicp,
            virt_hypervisor,
            os_type,
            arch,
            graphics,
            boot,
            boot_dev,
            numatune,
            hypervisor_features,
            clock,
            serials,
            consoles,
            stop_on_reboot,
            host_devices,
            **kwargs
        )
        log.debug("New virtual machine definition: %s", vm_xml)
        conn.defineXML(vm_xml)
    except libvirt.libvirtError as err:
        conn.close()
        raise CommandExecutionError(err.get_error_message())
    if start:
        log.debug("Starting VM %s", name)
        _get_domain(conn, name).create()
    conn.close()
    return True
def _disks_equal(disk1, disk2):
<a name="1"></a>    """
    Test if two disk elements should be considered like the same device
    target1 = disk1<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.find("target")
    target2 = disk2.find("target")
    disk1_dict = xmlutil.to_dict(disk1, True)
    disk2_dict = xmlutil.to_dict(disk2, True)
    source1_dict = disk1_dict.get("source", {})
    source2_dict = disk2_dict.get("source", {})
    io1 = disk1_dict.get("driver", {}).</b></font>get("io", "native")
    io2 = disk2_dict.get("driver", {}).get("io", "native")
    if source1_dict:
        source1_dict.pop("index", None)
    if source2_dict:
        source2_dict.pop("index", None)
    return (
        source1_dict == source2_dict
        and target1 is not None
        and target2 is not None
        and target1.get("bus") == target2.get("bus")
        and disk1.get("device", "disk") == disk2.get("device", "disk")
        and target1.get("dev") == target2.get("dev")
        and io1 == io2
    )
def _nics_equal(nic1, nic2):
    def _filter_nic(nic):
        source_node = nic.find("source")
        source_attrib = source_node.attrib if source_node is not None else {}
        source_type = "network" if "network" in source_attrib else nic.attrib["type"]
        source_getters = {
            "network": lambda n: n.get("network"),
            "bridge": lambda n: n.get("bridge"),
            "direct": lambda n: n.get("dev"),
            "hostdev": lambda n: _format_pci_address(n.find("address")),
        }
        return {
            "type": source_type,
            "source": source_getters[source_type](source_node)
            if source_node is not None
            else None,
            "model": nic.find("model").attrib["type"]
            if nic.find("model") is not None
            else None,
        }
    def _get_mac(nic):
        return (
            nic.find("mac").attrib["address"].lower()
            if nic.find("mac") is not None
            else None
        )
    mac1 = _get_mac(nic1)
    mac2 = _get_mac(nic2)
    macs_equal = not mac1 or not mac2 or mac1 == mac2
    return _filter_nic(nic1) == _filter_nic(nic2) and macs_equal
def _graphics_equal(gfx1, gfx2):
    def _filter_graphics(gfx):
        gfx_copy = copy.deepcopy(gfx)
        defaults = [
            {"node": ".", "attrib": "port", "values": ["5900", "-1"]},
            {"node": ".", "attrib": "address", "values": ["127.0.0.1"]},
            {"node": "listen", "attrib": "address", "values": ["127.0.0.1"]},
        ]
        for default in defaults:
            node = gfx_copy.find(default["node"])
            attrib = default["attrib"]
            if node is not None and (
                attrib in node.attrib and node.attrib[attrib] in default["values"]
            ):
                node.attrib.pop(attrib)
        return gfx_copy
    return xmlutil.to_dict(_filter_graphics(gfx1), True) == xmlutil.to_dict(
        _filter_graphics(gfx2), True
    )
def _hostdevs_equal(dev1, dev2):
    def _filter_hostdevs(dev):
        type_ = dev.get("type")
        definition = {
            "type": type_,
        }
        if type_ == "pci":
            address_node = dev.find("./source/address")
            for attr in ["domain", "bus", "slot", "function"]:
                definition[attr] = address_node.get(attr)
        elif type_ == "usb":
            for attr in ["vendor", "product"]:
                definition[attr] = dev.find("./source/" + attr).get("id")
        return definition
    return _filter_hostdevs(dev1) == _filter_hostdevs(dev2)
def _diff_lists(old, new, comparator):
    def _remove_indent(node):
        node_copy = copy.deepcopy(node)
        node_copy.text = None
        for item in node_copy.iter():
            item.tail = None
        return node_copy
    diff = {"unchanged": [], "new": [], "deleted": [], "sorted": []}
    old_devices = copy.deepcopy(old)
    for new_item in new:
        found = [
            item
            for item in old_devices
            if comparator(_remove_indent(item), _remove_indent(new_item))
        ]
        if found:
            old_devices.remove(found[0])
            diff["unchanged"].append(found[0])
            diff["sorted"].append(found[0])
        else:
            diff["new"].append(new_item)
            diff["sorted"].append(new_item)
    diff["deleted"] = old_devices
    return diff
def _get_disk_target(targets, disks_count, prefix):
    for i in range(disks_count):
        ret = "{}{}".format(prefix, string.ascii_lowercase[i])
        if ret not in targets:
            return ret
    return None
def _diff_disk_lists(old, new):
    targets = []
    prefixes = ["fd", "hd", "vd", "sd", "xvd", "ubd"]
    for disk in new:
        target_node = disk.find("target")
        target = target_node.get("dev")
        prefix = [item for item in prefixes if target.startswith(item)][0]
        new_target = _get_disk_target(targets, len(new), prefix)
        target_node.set("dev", new_target)
        targets.append(new_target)
    return _diff_lists(old, new, _disks_equal)
def _diff_interface_lists(old, new):
    return _diff_lists(old, new, _nics_equal)
def _diff_graphics_lists(old, new):
    return _diff_lists(old, new, _graphics_equal)
def _diff_hostdev_lists(old, new):
    return _diff_lists(old, new, _hostdevs_equal)
def _expand_cpuset(cpuset):
    if cpuset is None:
        return None
    if isinstance(cpuset, int):
        return str(cpuset)
    result = set()
    toremove = set()
    for part in cpuset.split(","):
        m = re.match("([0-9]+)-([0-9]+)", part)
        if m:
            result |= set(range(int(m.group(1)), int(m.group(2)) + 1))
        elif part.startswith("^"):
            toremove.add(int(part[1:]))
        else:
            result.add(int(part))
    cpus = list(result - toremove)
    cpus.sort()
    cpus = [str(cpu) for cpu in cpus]
    return ",".join(cpus)
def _normalize_cpusets(desc, data):
    xpaths = ["cputune/cachetune", "cputune/cachetune/monitor", "cputune/memorytune"]
    for xpath in xpaths:
        nodes = desc.findall(xpath)
        for node in nodes:
            node.set("vcpus", _expand_cpuset(node.get("vcpus")))
    if not isinstance(data.get("cpu"), dict):
        return
    tuning = data["cpu"].get("tuning", {})
    for child in ["cachetune", "memorytune"]:
        if tuning.get(child):
            new_item = dict()
            for cpuset, value in tuning[child].items():
                if child == "cachetune" and value.get("monitor"):
                    value["monitor"] = {
                        _expand_cpuset(monitor_cpus): monitor
                        for monitor_cpus, monitor in value["monitor"].items()
                    }
                new_item[_expand_cpuset(cpuset)] = value
            tuning[child] = new_item
def _serial_or_concole_equal(old, new):
    def _filter_serial_or_concole(item):
        return {
            "type": item.attrib["type"],
            "port": item.find("source").get("service")
            if item.find("source") is not None
            else None,
            "protocol": item.find("protocol").get("type")
            if item.find("protocol") is not None
            else None,
        }
    return _filter_serial_or_concole(old) == _filter_serial_or_concole(new)
def _diff_serial_lists(old, new):
    return _diff_lists(old, new, _serial_or_concole_equal)
def _diff_console_lists(old, new):
    return _diff_lists(old, new, _serial_or_concole_equal)
def _format_pci_address(node):
    return "{}:{}:{}.{}".format(
        node.get("domain").replace("0x", ""),
        node.get("bus").replace("0x", ""),
        node.get("slot").replace("0x", ""),
        node.get("function").replace("0x", ""),
    )
def _almost_equal(current, new):
    if current is None or new is None:
        return False
    return abs(current - new) / current &lt; 1e-03
def _compute_device_changes(old_xml, new_xml, to_skip):
    devices_node = old_xml.find("devices")
    changes = {}
    for dev_type in to_skip:
        changes[dev_type] = {}
        if not to_skip[dev_type]:
            old = devices_node.findall(dev_type)
            new = new_xml.findall("devices/{}".format(dev_type))
            changes[dev_type] = globals()["_diff_{}_lists".format(dev_type)](old, new)
    return changes
def _get_pci_addresses(node):
    return {_format_pci_address(address) for address in node.findall(".//address")}
def _correct_networks(conn, desc):
    networks = [ElementTree.fromstring(net.XMLDesc()) for net in conn.listAllNetworks()]
    nics = desc.findall("devices/interface")
    device_map = {}
    for nic in nics:
        if nic.get("type") == "hostdev":
            addr = _get_pci_addresses(nic.find("source"))
            matching_nets = [
                net
                for net in networks
                if net.find("forward").get("mode") == "hostdev"
                and addr &amp; _get_pci_addresses(net)
            ]
            if matching_nets:
                old_xml = ElementTree.tostring(nic)
                nic.set("type", "network")
                nic.find("source").set("network", matching_nets[0].find("name").text)
                device_map[nic] = old_xml
    return device_map
def _update_live(domain, new_desc, mem, cpu, old_mem, old_cpu, to_skip, test):
    status = {}
    errors = []
    if not domain.isActive():
        return status, errors
    commands = []
    if cpu and (isinstance(cpu, int) or isinstance(cpu, dict) and cpu.get("maximum")):
        new_cpu = cpu.get("maximum") if isinstance(cpu, dict) else cpu
        if old_cpu != new_cpu and new_cpu is not None:
            commands.append(
                {
                    "device": "cpu",
                    "cmd": "setVcpusFlags",
                    "args": [new_cpu, libvirt.VIR_DOMAIN_AFFECT_LIVE],
                }
            )
    if mem:
        if isinstance(mem, dict):
            new_mem = (
                int(_handle_unit(mem.get("current")) / 1024)
                if "current" in mem
                else None
            )
        elif isinstance(mem, int):
            new_mem = int(mem * 1024)
        if not _almost_equal(old_mem, new_mem) and new_mem is not None:
            commands.append(
                {
                    "device": "mem",
                    "cmd": "setMemoryFlags",
                    "args": [new_mem, libvirt.VIR_DOMAIN_AFFECT_LIVE],
                }
            )
    old_desc = ElementTree.fromstring(domain.XMLDesc(0))
    changed_devices = {"interface": _correct_networks(domain.connect(), old_desc)}
    changes = _compute_device_changes(old_desc, new_desc, to_skip)
    removable_changes = []
    new_disks = []
    for new_disk in changes["disk"].get("new", []):
        device = new_disk.get("device", "disk")
        if device not in ["cdrom", "floppy"]:
            new_disks.append(new_disk)
            continue
        target_dev = new_disk.find("target").get("dev")
        matching = [
            old_disk
            for old_disk in changes["disk"].get("deleted", [])
            if old_disk.get("device", "disk") == device
            and old_disk.find("target").get("dev") == target_dev
        ]
        if not matching:
            new_disks.append(new_disk)
        else:
            updated_disk = matching[0]
            changes["disk"]["deleted"].remove(updated_disk)
            removable_changes.append(updated_disk)
            source_node = updated_disk.find("source")
            new_source_node = new_disk.find("source")
            source_file = (
                new_source_node.get("file") if new_source_node is not None else None
            )
            updated_disk.set("type", "file")
            if source_node is not None:
                updated_disk.remove(source_node)
            if source_file:
                ElementTree.SubElement(
                    updated_disk, "source", attrib={"file": source_file}
                )
    changes["disk"]["new"] = new_disks
    for dev_type in ["disk", "interface", "hostdev"]:
        for added in changes[dev_type].get("new", []):
            commands.append(
                {
                    "device": dev_type,
                    "cmd": "attachDevice",
                    "args": [xmlutil.element_to_str(added)],
                }
            )
        for removed in changes[dev_type].get("deleted", []):
            removed_def = changed_devices.get(dev_type, {}).get(
                removed, ElementTree.tostring(removed)
            )
            commands.append(
                {
                    "device": dev_type,
                    "cmd": "detachDevice",
                    "args": [salt.utils.stringutils.to_str(removed_def)],
                }
            )
    for updated_disk in removable_changes:
        commands.append(
            {
                "device": "disk",
                "cmd": "updateDeviceFlags",
                "args": [xmlutil.element_to_str(updated_disk)],
            }
        )
    for cmd in commands:
        try:
            ret = 0 if test else getattr(domain, cmd["cmd"])(*cmd["args"])
            device_type = cmd["device"]
            if device_type in ["cpu", "mem"]:
                status[device_type] = not ret
            else:
                actions = {
                    "attachDevice": "attached",
                    "detachDevice": "detached",
                    "updateDeviceFlags": "updated",
                }
                device_status = status.setdefault(device_type, {})
                cmd_status = device_status.setdefault(actions[cmd["cmd"]], [])
                cmd_status.append(cmd["args"][0])
        except libvirt.libvirtError as err:
            errors.append(str(err))
    return status, errors
def update(
    name,
    cpu=0,
    mem=0,
    disk_profile=None,
    disks=None,
    nic_profile=None,
    interfaces=None,
    graphics=None,
    live=True,
    boot=None,
    numatune=None,
    test=False,
    boot_dev=None,
    hypervisor_features=None,
    clock=None,
    serials=None,
    consoles=None,
    stop_on_reboot=False,
    host_devices=None,
    **kwargs
):
    status = {
        "definition": False,
        "disk": {"attached": [], "detached": [], "updated": []},
        "interface": {"attached": [], "detached": []},
    }
    conn = __get_conn(**kwargs)
    domain = _get_domain(conn, name)
    desc = ElementTree.fromstring(domain.XMLDesc(libvirt.VIR_DOMAIN_XML_INACTIVE))
    need_update = False
    hypervisor = desc.get("type")
    all_disks = _disk_profile(conn, disk_profile, hypervisor, disks, name)
    if boot is not None:
        boot = _handle_remote_boot_params(boot)
        if boot.get("efi", None) is not None:
            need_update = _handle_efi_param(boot, desc)
    new_desc = ElementTree.fromstring(
        _gen_xml(
            conn,
            name,
            cpu,
            mem or 0,
            all_disks,
            _get_merged_nics(hypervisor, nic_profile, interfaces),
            hypervisor,
            domain.OSType(),
            desc.find(".//os/type").get("arch"),
            graphics,
            boot,
            boot_dev,
            numatune,
            serials=serials,
            consoles=consoles,
            stop_on_reboot=stop_on_reboot,
            host_devices=host_devices,
            **kwargs
        )
    )
    if clock:
        offset = "utc" if clock.get("utc", True) else "localtime"
        if "timezone" in clock:
            offset = "timezone"
        clock["offset"] = offset
    def _set_loader(node, value):
        salt.utils.xmlutil.set_node_text(node, value)
        if value is not None:
            node.set("readonly", "yes")
            node.set("type", "pflash")
    def _set_nvram(node, value):
        node.set("template", value)
    def _set_with_byte_unit(attr_name=None):
        def _setter(node, value):
            if attr_name:
                node.set(attr_name, str(value))
            else:
                node.text = str(value)
            node.set("unit", "bytes")
        return _setter
    def _get_with_unit(node):
        unit = node.get("unit", "KiB")
        unit = unit if unit != "bytes" else "b"
        value = node.get("memory") or node.get("size") or node.text
        return _handle_unit("{}{}".format(value, unit)) if value else None
    def _set_vcpu(node, value):
        node.text = str(value)
        node.set("current", str(value))
    old_mem = int(_get_with_unit(desc.find("memory")) / 1024)
    old_cpu = int(desc.find("./vcpu").text)
    def _yesno_attribute(path, xpath, attr_name, ignored=None):
        return xmlutil.attribute(
            path, xpath, attr_name, ignored, lambda v: "yes" if v else "no"
        )
    def _memory_parameter(path, xpath, attr_name=None, ignored=None):
        entry = {
            "path": path,
            "xpath": xpath,
            "convert": _handle_unit,
            "get": _get_with_unit,
            "set": _set_with_byte_unit(attr_name),
            "equals": _almost_equal,
        }
        if attr_name:
            entry["del"] = salt.utils.xmlutil.del_attribute(attr_name, ignored)
        return entry
    def _cpuset_parameter(path, xpath, attr_name=None, ignored=None):
        def _set_cpuset(node, value):
            if attr_name:
                node.set(attr_name, value)
            else:
                node.text = value
        entry = {
            "path": path,
            "xpath": xpath,
            "convert": _expand_cpuset,
            "get": lambda n: _expand_cpuset(n.get(attr_name) if attr_name else n.text),
            "set": _set_cpuset,
        }
        if attr_name:
            entry["del"] = salt.utils.xmlutil.del_attribute(attr_name, ignored)
        return entry
    data = {k: v for k, v in locals().items() if bool(v)}
    data["stop_on_reboot"] = stop_on_reboot
    if boot_dev:
        data["boot_dev"] = boot_dev.split()
    timer_names = [
        "platform",
        "hpet",
        "kvmclock",
        "pit",
        "rtc",
        "tsc",
        "hypervclock",
        "armvtimer",
    ]
    if data.get("clock", {}).get("timers"):
        attributes = [
            "track",
            "tickpolicy",
            "frequency",
            "mode",
            "present",
            "slew",
            "threshold",
            "limit",
        ]
        for timer in data["clock"]["timers"].values():
            for attribute in attributes:
                if attribute not in timer:
                    timer[attribute] = None
        for timer_name in timer_names:
            if timer_name not in data["clock"]["timers"]:
                data["clock"]["timers"][timer_name] = None
    _normalize_cpusets(desc, data)
    params_mapping = [
        {
            "path": "stop_on_reboot",
            "xpath": "on_reboot",
            "convert": lambda v: "destroy" if v else "restart",
        },
        {"path": "boot:kernel", "xpath": "os/kernel"},
        {"path": "boot:initrd", "xpath": "os/initrd"},
        {"path": "boot:cmdline", "xpath": "os/cmdline"},
        {"path": "boot:loader", "xpath": "os/loader", "set": _set_loader},
        {"path": "boot:nvram", "xpath": "os/nvram", "set": _set_nvram},
        _memory_parameter("mem", "memory"),
        _memory_parameter("mem", "currentMemory"),
        _memory_parameter("mem:max", "maxMemory"),
        _memory_parameter("mem:boot", "memory"),
        _memory_parameter("mem:current", "currentMemory"),
        xmlutil.attribute("mem:slots", "maxMemory", "slots", ["unit"]),
        _memory_parameter("mem:hard_limit", "memtune/hard_limit"),
        _memory_parameter("mem:soft_limit", "memtune/soft_limit"),
        _memory_parameter("mem:swap_hard_limit", "memtune/swap_hard_limit"),
        _memory_parameter("mem:min_guarantee", "memtune/min_guarantee"),
        xmlutil.attribute("boot_dev:{dev}", "os/boot[$dev]", "dev"),
        _memory_parameter(
            "mem:hugepages:{id}:size",
            "memoryBacking/hugepages/page[$id]",
            "size",
            ["unit", "nodeset"],
        ),
        _cpuset_parameter(
            "mem:hugepages:{id}:nodeset", "memoryBacking/hugepages/page[$id]", "nodeset"
        ),
        {
            "path": "mem:nosharepages",
            "xpath": "memoryBacking/nosharepages",
            "get": lambda n: n is not None,
            "set": lambda n, v: None,
        },
        {
            "path": "mem:locked",
            "xpath": "memoryBacking/locked",
            "get": lambda n: n is not None,
            "set": lambda n, v: None,
        },
        xmlutil.attribute("mem:source", "memoryBacking/source", "type"),
        xmlutil.attribute("mem:access", "memoryBacking/access", "mode"),
        xmlutil.attribute("mem:allocation", "memoryBacking/allocation", "mode"),
        {"path": "mem:discard", "xpath": "memoryBacking/discard"},
        {
            "path": "cpu",
            "xpath": "vcpu",
            "get": lambda n: int(n.text),
            "set": _set_vcpu,
        },
        {"path": "cpu:maximum", "xpath": "vcpu", "get": lambda n: int(n.text)},
        xmlutil.attribute("cpu:placement", "vcpu", "placement"),
        _cpuset_parameter("cpu:cpuset", "vcpu", "cpuset"),
        xmlutil.attribute("cpu:current", "vcpu", "current"),
        xmlutil.attribute("cpu:match", "cpu", "match"),
        xmlutil.attribute("cpu:mode", "cpu", "mode"),
        xmlutil.attribute("cpu:check", "cpu", "check"),
        {"path": "cpu:model:name", "xpath": "cpu/model"},
        xmlutil.attribute("cpu:model:fallback", "cpu/model", "fallback"),
        xmlutil.attribute("cpu:model:vendor_id", "cpu/model", "vendor_id"),
        {"path": "cpu:vendor", "xpath": "cpu/vendor"},
        xmlutil.attribute("cpu:topology:sockets", "cpu/topology", "sockets"),
        xmlutil.attribute("cpu:topology:cores", "cpu/topology", "cores"),
        xmlutil.attribute("cpu:topology:threads", "cpu/topology", "threads"),
        xmlutil.attribute("cpu:cache:level", "cpu/cache", "level"),
        xmlutil.attribute("cpu:cache:mode", "cpu/cache", "mode"),
        xmlutil.attribute(
            "cpu:features:{id}", "cpu/feature[@name='$id']", "policy", ["name"]
        ),
        _yesno_attribute(
            "cpu:vcpus:{id}:enabled", "vcpus/vcpu[@id='$id']", "enabled", ["id"]
        ),
        _yesno_attribute(
            "cpu:vcpus:{id}:hotpluggable",
            "vcpus/vcpu[@id='$id']",
            "hotpluggable",
            ["id"],
        ),
        xmlutil.int_attribute(
            "cpu:vcpus:{id}:order", "vcpus/vcpu[@id='$id']", "order", ["id"]
        ),
        _cpuset_parameter(
            "cpu:numa:{id}:cpus", "cpu/numa/cell[@id='$id']", "cpus", ["id"]
        ),
        _memory_parameter(
            "cpu:numa:{id}:memory", "cpu/numa/cell[@id='$id']", "memory", ["id"]
        ),
        _yesno_attribute(
            "cpu:numa:{id}:discard", "cpu/numa/cell[@id='$id']", "discard", ["id"]
        ),
        xmlutil.attribute(
            "cpu:numa:{id}:memAccess", "cpu/numa/cell[@id='$id']", "memAccess", ["id"]
        ),
        xmlutil.attribute(
            "cpu:numa:{id}:distances:{sid}",
            "cpu/numa/cell[@id='$id']/distances/sibling[@id='$sid']",
            "value",
            ["id"],
        ),
        {"path": "cpu:iothreads", "xpath": "iothreads"},
        {"path": "cpu:tuning:shares", "xpath": "cputune/shares"},
        {"path": "cpu:tuning:period", "xpath": "cputune/period"},
        {"path": "cpu:tuning:quota", "xpath": "cputune/quota"},
        {"path": "cpu:tuning:global_period", "xpath": "cputune/global_period"},
        {"path": "cpu:tuning:global_quota", "xpath": "cputune/global_quota"},
        {"path": "cpu:tuning:emulator_period", "xpath": "cputune/emulator_period"},
        {"path": "cpu:tuning:emulator_quota", "xpath": "cputune/emulator_quota"},
        {"path": "cpu:tuning:iothread_period", "xpath": "cputune/iothread_period"},
        {"path": "cpu:tuning:iothread_quota", "xpath": "cputune/iothread_quota"},
        _cpuset_parameter(
            "cpu:tuning:vcpupin:{id}",
            "cputune/vcpupin[@vcpu='$id']",
            "cpuset",
            ["vcpu"],
        ),
        _cpuset_parameter("cpu:tuning:emulatorpin", "cputune/emulatorpin", "cpuset"),
        _cpuset_parameter(
            "cpu:tuning:iothreadpin:{id}",
            "cputune/iothreadpin[@iothread='$id']",
            "cpuset",
            ["iothread"],
        ),
        xmlutil.attribute(
            "cpu:tuning:vcpusched:{id}:scheduler",
            "cputune/vcpusched[$id]",
            "scheduler",
            ["priority", "vcpus"],
        ),
        xmlutil.attribute(
            "cpu:tuning:vcpusched:{id}:priority", "cputune/vcpusched[$id]", "priority"
        ),
        _cpuset_parameter(
            "cpu:tuning:vcpusched:{id}:vcpus", "cputune/vcpusched[$id]", "vcpus"
        ),
        xmlutil.attribute(
            "cpu:tuning:iothreadsched:{id}:scheduler",
            "cputune/iothreadsched[$id]",
            "scheduler",
            ["priority", "iothreads"],
        ),
        xmlutil.attribute(
            "cpu:tuning:iothreadsched:{id}:priority",
            "cputune/iothreadsched[$id]",
            "priority",
        ),
        _cpuset_parameter(
            "cpu:tuning:iothreadsched:{id}:iothreads",
            "cputune/iothreadsched[$id]",
            "iothreads",
        ),
        xmlutil.attribute(
            "cpu:tuning:emulatorsched:scheduler",
            "cputune/emulatorsched",
            "scheduler",
            ["priority"],
        ),
        xmlutil.attribute(
            "cpu:tuning:emulatorsched:priority", "cputune/emulatorsched", "priority"
        ),
        xmlutil.attribute(
            "cpu:tuning:cachetune:{id}:monitor:{sid}",
            "cputune/cachetune[@vcpus='$id']/monitor[@vcpus='$sid']",
            "level",
            ["vcpus"],
        ),
        xmlutil.attribute(
            "cpu:tuning:memorytune:{id}:{sid}",
            "cputune/memorytune[@vcpus='$id']/node[@id='$sid']",
            "bandwidth",
            ["id", "vcpus"],
        ),
        xmlutil.attribute("clock:offset", "clock", "offset"),
        xmlutil.attribute("clock:adjustment", "clock", "adjustment", convert=str),
        xmlutil.attribute("clock:timezone", "clock", "timezone"),
    ]
    for timer in timer_names:
        params_mapping += [
            xmlutil.attribute(
                "clock:timers:{}:track".format(timer),
                "clock/timer[@name='{}']".format(timer),
                "track",
                ["name"],
            ),
            xmlutil.attribute(
                "clock:timers:{}:tickpolicy".format(timer),
                "clock/timer[@name='{}']".format(timer),
                "tickpolicy",
                ["name"],
            ),
            xmlutil.int_attribute(
                "clock:timers:{}:frequency".format(timer),
                "clock/timer[@name='{}']".format(timer),
                "frequency",
                ["name"],
            ),
            xmlutil.attribute(
                "clock:timers:{}:mode".format(timer),
                "clock/timer[@name='{}']".format(timer),
                "mode",
                ["name"],
            ),
            _yesno_attribute(
                "clock:timers:{}:present".format(timer),
                "clock/timer[@name='{}']".format(timer),
                "present",
                ["name"],
            ),
        ]
        for attr in ["slew", "threshold", "limit"]:
            params_mapping.append(
                xmlutil.int_attribute(
                    "clock:timers:{}:{}".format(timer, attr),
                    "clock/timer[@name='{}']/catchup".format(timer),
                    attr,
                )
            )
    for attr in ["level", "type", "size"]:
        params_mapping.append(
            xmlutil.attribute(
                "cpu:tuning:cachetune:{id}:{sid}:" + attr,
                "cputune/cachetune[@vcpus='$id']/cache[@id='$sid']",
                attr,
                ["id", "unit", "vcpus"],
            )
        )
    if hypervisor in ["qemu", "kvm"]:
        params_mapping += [
            xmlutil.attribute("numatune:memory:mode", "numatune/memory", "mode"),
            _cpuset_parameter("numatune:memory:nodeset", "numatune/memory", "nodeset"),
            xmlutil.attribute(
                "numatune:memnodes:{id}:mode",
                "numatune/memnode[@cellid='$id']",
                "mode",
                ["cellid"],
            ),
            _cpuset_parameter(
                "numatune:memnodes:{id}:nodeset",
                "numatune/memnode[@cellid='$id']",
                "nodeset",
                ["cellid"],
            ),
            xmlutil.attribute(
                "hypervisor_features:kvm-hint-dedicated",
                "features/kvm/hint-dedicated",
                "state",
                convert=lambda v: "on" if v else "off",
            ),
        ]
    need_update = (
        salt.utils.xmlutil.change_xml(desc, data, params_mapping) or need_update
    )
    devices_node = desc.find("devices")
    func_locals = locals()
    def _skip_update(names):
        return all(func_locals.get(n) is None for n in names)
    to_skip = {
        "disk": _skip_update(["disks", "disk_profile"]),
        "interface": _skip_update(["interfaces", "nic_profile"]),
        "graphics": _skip_update(["graphics"]),
        "serial": _skip_update(["serials"]),
        "console": _skip_update(["consoles"]),
        "hostdev": _skip_update(["host_devices"]),
    }
    changes = _compute_device_changes(desc, new_desc, to_skip)
    for dev_type in changes:
        if not to_skip[dev_type]:
            old = devices_node.findall(dev_type)
            if changes[dev_type].get("deleted") or changes[dev_type].get("new"):
                for item in old:
                    devices_node.remove(item)
                devices_node.extend(changes[dev_type]["sorted"])
                need_update = True
    if need_update:
        try:
            if changes["disk"]:
                for idx, item in enumerate(changes["disk"]["sorted"]):
                    source_file = all_disks[idx].get("source_file")
                    if all_disks[idx].get("device", "disk") == "cdrom":
                        continue
                    if (
                        item in changes["disk"]["new"]
                        and source_file
                        and not os.path.exists(source_file)
                    ):
                        _qemu_image_create(all_disks[idx])
                    elif item in changes["disk"]["new"] and not source_file:
                        _disk_volume_create(conn, all_disks[idx])
            if not test:
                xml_desc = xmlutil.element_to_str(desc)
                log.debug("Update virtual machine definition: %s", xml_desc)
                conn.defineXML(xml_desc)
            status["definition"] = True
        except libvirt.libvirtError as err:
            conn.close()
            raise err
    if live:
        live_status, errors = _update_live(
            domain, new_desc, mem, cpu, old_mem, old_cpu, to_skip, test
        )
        status.update(live_status)
        if errors:
            status_errors = status.setdefault("errors", [])
            status_errors += errors
    conn.close()
    return status
def list_domains(**kwargs):
    vms = []
    conn = __get_conn(**kwargs)
    for dom in _get_domain(conn, iterable=True):
        vms.append(dom.name())
    conn.close()
    return vms
def list_active_vms(**kwargs):
    vms = []
    conn = __get_conn(**kwargs)
    for dom in _get_domain(conn, iterable=True, inactive=False):
        vms.append(dom.name())
    conn.close()
    return vms
def list_inactive_vms(**kwargs):
    vms = []
    conn = __get_conn(**kwargs)
    for dom in _get_domain(conn, iterable=True, active=False):
        vms.append(dom.name())
    conn.close()
    return vms
def vm_info(vm_=None, **kwargs):
    def _info(conn, dom):
        raw = dom.info()
        return {
            "cpu": raw[3],
            "cputime": int(raw[4]),
            "disks": _get_disks(conn, dom),
            "graphics": _get_graphics(dom),
            "nics": _get_nics(dom),
            "uuid": _get_uuid(dom),
            "loader": _get_loader(dom),
            "on_crash": _get_on_crash(dom),
            "on_reboot": _get_on_reboot(dom),
            "on_poweroff": _get_on_poweroff(dom),
            "maxMem": int(raw[1]),
            "mem": int(raw[2]),
            "state": VIRT_STATE_NAME_MAP.get(raw[0], "unknown"),
        }
    info = {}
    conn = __get_conn(**kwargs)
    if vm_:
        info[vm_] = _info(conn, _get_domain(conn, vm_))
    else:
        for domain in _get_domain(conn, iterable=True):
            info[domain.name()] = _info(conn, domain)
    conn.close()
    return info
def vm_state(vm_=None, **kwargs):
    def _info(dom):
        state = ""
        raw = dom.info()
        state = VIRT_STATE_NAME_MAP.get(raw[0], "unknown")
        return state
    info = {}
    conn = __get_conn(**kwargs)
    if vm_:
        info[vm_] = _info(_get_domain(conn, vm_))
    else:
        for domain in _get_domain(conn, iterable=True):
            info[domain.name()] = _info(domain)
    conn.close()
    return info
def _node_info(conn):
    raw = conn.getInfo()
    info = {
        "cpucores": raw[6],
        "cpumhz": raw[3],
        "cpumodel": str(raw[0]),
        "cpus": raw[2],
        "cputhreads": raw[7],
        "numanodes": raw[4],
        "phymemory": raw[1],
        "sockets": raw[5],
    }
    return info
def node_info(**kwargs):
    conn = __get_conn(**kwargs)
    info = _node_info(conn)
    conn.close()
    return info
def _node_devices(conn):
    devices = conn.listAllDevices()
    devices_infos = []
    for dev in devices:
        root = ElementTree.fromstring(dev.XMLDesc())
        if not set(dev.listCaps()) &amp; {"pci", "usb_device", "net"}:
            continue
        infos = {
            "caps": " ".join(dev.listCaps()),
        }
        if "net" in dev.listCaps():
            parent = root.find(".//parent").text
            if parent == "computer":
                continue
            infos.update(
                {
                    "name": root.find(".//interface").text,
                    "address": root.find(".//address").text,
                    "device name": parent,
                    "state": root.find(".//link").get("state"),
                }
            )
            devices_infos.append(infos)
            continue
        vendor_node = root.find(".//vendor")
        vendor_id = vendor_node.get("id").lower()
        product_node = root.find(".//product")
        product_id = product_node.get("id").lower()
        infos.update(
            {"name": dev.name(), "vendor_id": vendor_id, "product_id": product_id}
        )
        if vendor_node.text:
            infos["vendor"] = vendor_node.text
        if product_node.text:
            infos["product"] = product_node.text
        if "pci" in dev.listCaps():
            infos["address"] = "{:04x}:{:02x}:{:02x}.{}".format(
                int(root.find(".//domain").text),
                int(root.find(".//bus").text),
                int(root.find(".//slot").text),
                root.find(".//function").text,
            )
            class_node = root.find(".//class")
            if class_node is not None:
                infos["PCI class"] = class_node.text
            vf_addresses = [
                _format_pci_address(vf)
                for vf in root.findall(
                    "./capability[@type='pci']/capability[@type='virt_functions']/address"
                )
            ]
            if vf_addresses:
                infos["virtual functions"] = vf_addresses
            pf = root.find(
                "./capability[@type='pci']/capability[@type='phys_function']/address"
            )
            if pf is not None:
                infos["physical function"] = _format_pci_address(pf)
        elif "usb_device" in dev.listCaps():
            infos["address"] = "{:03}:{:03}".format(
                int(root.find(".//bus").text), int(root.find(".//device").text)
            )
        linux_usb_host = vendor_id == "0x1d6b" and product_id in [
            "0x0001",
            "0x0002",
            "0x0003",
        ]
        if (
            root.find(".//capability[@type='pci-bridge']") is None
            and not linux_usb_host
        ):
            devices_infos.append(infos)
    return devices_infos
def node_devices(**kwargs):
    conn = __get_conn(**kwargs)
    devs = _node_devices(conn)
    conn.close()
    return devs
def get_nics(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    nics = _get_nics(_get_domain(conn, vm_))
    conn.close()
    return nics
def get_macs(vm_, **kwargs):
    doc = ElementTree.fromstring(get_xml(vm_, **kwargs))
    return [node.get("address") for node in doc.findall("devices/interface/mac")]
def get_graphics(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    graphics = _get_graphics(_get_domain(conn, vm_))
    conn.close()
    return graphics
def get_loader(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        loader = _get_loader(_get_domain(conn, vm_))
        return loader
    finally:
        conn.close()
def get_disks(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    disks = _get_disks(conn, _get_domain(conn, vm_))
    conn.close()
    return disks
def setmem(vm_, memory, config=False, **kwargs):
    conn = __get_conn(**kwargs)
    dom = _get_domain(conn, vm_)
    if VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown":
        return False
    flags = libvirt.VIR_DOMAIN_MEM_MAXIMUM
    if config:
        flags = flags | libvirt.VIR_DOMAIN_AFFECT_CONFIG
    ret1 = dom.setMemoryFlags(memory * 1024, flags)
    ret2 = dom.setMemoryFlags(memory * 1024, libvirt.VIR_DOMAIN_AFFECT_CURRENT)
    conn.close()
    return ret1 == ret2 == 0
def setvcpus(vm_, vcpus, config=False, **kwargs):
    conn = __get_conn(**kwargs)
    dom = _get_domain(conn, vm_)
    if VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown":
        return False
    flags = libvirt.VIR_DOMAIN_VCPU_MAXIMUM
    if config:
        flags = flags | libvirt.VIR_DOMAIN_AFFECT_CONFIG
    ret1 = dom.setVcpusFlags(vcpus, flags)
    ret2 = dom.setVcpusFlags(vcpus, libvirt.VIR_DOMAIN_AFFECT_CURRENT)
    conn.close()
    return ret1 == ret2 == 0
def _freemem(conn):
    mem = conn.getInfo()[1]
    mem -= 256
    for dom in _get_domain(conn, iterable=True):
        if dom.ID() &gt; 0:
            mem -= dom.info()[2] / 1024
    return mem
def freemem(**kwargs):
    conn = __get_conn(**kwargs)
    mem = _freemem(conn)
    conn.close()
    return mem
def _freecpu(conn):
    cpus = conn.getInfo()[2]
    for dom in _get_domain(conn, iterable=True):
        if dom.ID() &gt; 0:
            cpus -= dom.info()[3]
    return cpus
def freecpu(**kwargs):
    conn = __get_conn(**kwargs)
    cpus = _freecpu(conn)
    conn.close()
    return cpus
def full_info(**kwargs):
    conn = __get_conn(**kwargs)
    info = {
        "freecpu": _freecpu(conn),
        "freemem": _freemem(conn),
        "node_info": _node_info(conn),
        "vm_info": vm_info(),
    }
    conn.close()
    return info
def get_xml(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    xml_desc = (
        vm_.XMLDesc(0)
        if isinstance(vm_, libvirt.virDomain)
        else _get_domain(conn, vm_).XMLDesc(0)
    )
    conn.close()
    return xml_desc
def get_profiles(hypervisor=None, **kwargs):
    conn = __get_conn(**kwargs)
    caps = _capabilities(conn)
    hypervisors = sorted(
        {
            x
            for y in [guest["arch"]["domains"].keys() for guest in caps["guests"]]
            for x in y
        }
    )
    if len(hypervisors) == 0:
        raise SaltInvocationError("No supported hypervisors were found")
    if not hypervisor:
        hypervisor = "kvm" if "kvm" in hypervisors else hypervisors[0]
    ret = {
        "disk": {"default": _disk_profile(conn, "default", hypervisor, [], None)},
        "nic": {"default": _nic_profile("default", hypervisor)},
    }
    virtconf = __salt__["config.get"]("virt", {})
    for profile in virtconf.get("disk", []):
        ret["disk"][profile] = _disk_profile(conn, profile, hypervisor, [], None)
    for profile in virtconf.get("nic", []):
        ret["nic"][profile] = _nic_profile(profile, hypervisor)
    return ret
def shutdown(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    dom = _get_domain(conn, vm_)
    ret = dom.shutdown() == 0
    conn.close()
    return ret
def pause(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    dom = _get_domain(conn, vm_)
    ret = dom.suspend() == 0
    conn.close()
    return ret
def resume(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    dom = _get_domain(conn, vm_)
    ret = dom.resume() == 0
    conn.close()
    return ret
def start(name, **kwargs):
    conn = __get_conn(**kwargs)
    ret = _get_domain(conn, name).create() == 0
    conn.close()
    return ret
def stop(name, **kwargs):
    conn = __get_conn(**kwargs)
    ret = _get_domain(conn, name).destroy() == 0
    conn.close()
    return ret
def reboot(name, **kwargs):
    conn = __get_conn(**kwargs)
    ret = _get_domain(conn, name).reboot(libvirt.VIR_DOMAIN_REBOOT_DEFAULT) == 0
    conn.close()
    return ret
def reset(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    dom = _get_domain(conn, vm_)
    ret = dom.reset(0) == 0
    conn.close()
    return ret
def ctrl_alt_del(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    dom = _get_domain(conn, vm_)
    ret = dom.sendKey(0, 0, [29, 56, 111], 3, 0) == 0
    conn.close()
    return ret
def create_xml_str(xml, **kwargs):  # pylint: disable=redefined-outer-name
    conn = __get_conn(**kwargs)
    ret = conn.createXML(xml, 0) is not None
    conn.close()
    return ret
def create_xml_path(path, **kwargs):
    try:
        with salt.utils.files.fopen(path, "r") as fp_:
            return create_xml_str(
                salt.utils.stringutils.to_unicode(fp_.read()), **kwargs
            )
    except OSError:
        return False
def define_xml_str(xml, **kwargs):  # pylint: disable=redefined-outer-name
    conn = __get_conn(**kwargs)
    ret = conn.defineXML(xml) is not None
    conn.close()
    return ret
def define_xml_path(path, **kwargs):
    try:
        with salt.utils.files.fopen(path, "r") as fp_:
            return define_xml_str(
                salt.utils.stringutils.to_unicode(fp_.read()), **kwargs
            )
    except OSError:
        return False
def _define_vol_xml_str(conn, xml, pool=None):  # pylint: disable=redefined-outer-name
    default_pool = "default" if conn.getType() != "ESX" else "0"
    poolname = (
        pool if pool else __salt__["config.get"]("virt:storagepool", default_pool)
    )
    pool = conn.storagePoolLookupByName(str(poolname))
    ret = pool.createXML(xml, 0) is not None
    return ret
def define_vol_xml_str(
    xml, pool=None, **kwargs
):  # pylint: disable=redefined-outer-name
    conn = __get_conn(**kwargs)
    ret = False
    try:
        ret = _define_vol_xml_str(conn, xml, pool=pool)
    except libvirtError as err:
        raise CommandExecutionError(err.get_error_message())
    finally:
        conn.close()
    return ret
def define_vol_xml_path(path, pool=None, **kwargs):
    try:
        with salt.utils.files.fopen(path, "r") as fp_:
            return define_vol_xml_str(
                salt.utils.stringutils.to_unicode(fp_.read()), pool=pool, **kwargs
            )
    except OSError:
        return False
def migrate(vm_, target, **kwargs):
    conn = __get_conn()
    dom = _get_domain(conn, vm_)
    if not urllib.parse.urlparse(target).scheme:
        proto = "qemu"
        dst_uri = "{}://{}/system".format(proto, target)
    else:
        dst_uri = target
    ret = _migrate(dom, dst_uri, **kwargs)
    conn.close()
    return ret
def migrate_start_postcopy(vm_):
    conn = __get_conn()
    dom = _get_domain(conn, vm_)
    try:
        dom.migrateStartPostCopy()
    except libvirt.libvirtError as err:
        conn.close()
        raise CommandExecutionError(err.get_error_message())
    conn.close()
def seed_non_shared_migrate(disks, force=False):
    for _, data in disks.items():
        fn_ = data["file"]
        form = data["file format"]
        size = data["virtual size"].split()[1][1:]
        if os.path.isfile(fn_) and not force:
            pre = salt.utils.yaml.safe_load(
                subprocess.Popen(
                    ["qemu-img", "info", "arch"], stdout=subprocess.PIPE
                ).communicate()[0]
            )
            if (
                pre["file format"] != data["file format"]
                and pre["virtual size"] != data["virtual size"]
            ):
                return False
        if not os.path.isdir(os.path.dirname(fn_)):
            os.makedirs(os.path.dirname(fn_))
        if os.path.isfile(fn_):
            os.remove(fn_)
        subprocess.call(["qemu-img", "create", "-f", form, fn_, size])
        creds = _libvirt_creds()
        subprocess.call(["chown", "{user}:{group}".format(**creds), fn_])
    return True
def set_autostart(vm_, state="on", **kwargs):
    conn = __get_conn(**kwargs)
    dom = _get_domain(conn, vm_)
    ret = False
    if state == "on":
        ret = dom.setAutostart(1) == 0
    elif state == "off":
        ret = dom.setAutostart(0) == 0
    conn.close()
    return ret
def undefine(vm_, **kwargs):
    conn = __get_conn(**kwargs)
    dom = _get_domain(conn, vm_)
    if getattr(libvirt, "VIR_DOMAIN_UNDEFINE_NVRAM", False):
        ret = dom.undefineFlags(libvirt.VIR_DOMAIN_UNDEFINE_NVRAM) == 0
    else:
        ret = dom.undefine() == 0
    conn.close()
    return ret
def purge(vm_, dirs=False, removables=False, **kwargs):
    conn = __get_conn(**kwargs)
    dom = _get_domain(conn, vm_)
    disks = _get_disks(conn, dom)
    if (
        VIRT_STATE_NAME_MAP.get(dom.info()[0], "unknown") != "shutdown"
        and dom.destroy() != 0
    ):
        return False
    directories = set()
    for disk in disks:
        if not removables and disks[disk]["type"] in ["cdrom", "floppy"]:
            continue
        if disks[disk].get("zfs", False):
            time.sleep(3)
            fs_name = disks[disk]["file"][len("/dev/zvol/") :]
            log.info("Destroying VM ZFS volume %s", fs_name)
            __salt__["zfs.destroy"](name=fs_name, force=True)
        elif os.path.exists(disks[disk]["file"]):
            os.remove(disks[disk]["file"])
            directories.add(os.path.dirname(disks[disk]["file"]))
        else:
            matcher = re.match("^(?P&lt;pool&gt;[^/]+)/(?P&lt;volume&gt;.*)$", disks[disk]["file"])
            if matcher:
                pool_name = matcher.group("pool")
                pool = None
                if pool_name in conn.listStoragePools():
                    pool = conn.storagePoolLookupByName(pool_name)
                if pool and matcher.group("volume") in pool.listVolumes():
                    volume = pool.storageVolLookupByName(matcher.group("volume"))
                    volume.delete()
    if dirs:
        for dir_ in directories:
            shutil.rmtree(dir_)
    if getattr(libvirt, "VIR_DOMAIN_UNDEFINE_NVRAM", False):
        try:
            dom.undefineFlags(libvirt.VIR_DOMAIN_UNDEFINE_NVRAM)
        except Exception:  # pylint: disable=broad-except
            dom.undefine()
    else:
        dom.undefine()
    conn.close()
    return True
def virt_type():
    return __grains__["virtual"]
def _is_kvm_hyper():
    if not os.path.exists("/dev/kvm"):
        return False
    return "libvirtd" in __salt__["cmd.run"](__grains__["ps"])
def _is_xen_hyper():
    try:
        if __grains__["virtual_subtype"] != "Xen Dom0":
            return False
    except KeyError:
        return False
    try:
        with salt.utils.files.fopen("/proc/modules") as fp_:
            if "xen_" not in salt.utils.stringutils.to_unicode(fp_.read()):
                return False
    except OSError:
        return False
    return "libvirtd" in __salt__["cmd.run"](__grains__["ps"])
def get_hypervisor():
    hypervisors = ["kvm", "xen", "bhyve"]
    result = [
        hyper
        for hyper in hypervisors
        if getattr(sys.modules[__name__], "_is_{}_hyper".format(hyper))()
    ]
    return result[0] if result else None
def _is_bhyve_hyper():
    sysctl_cmd = "sysctl hw.vmm.create"
    vmm_enabled = False
    try:
        stdout = subprocess.Popen(
            ["sysctl", "hw.vmm.create"], stdout=subprocess.PIPE
        ).communicate()[0]
        vmm_enabled = len(salt.utils.stringutils.to_str(stdout).split('"')[1]) != 0
    except IndexError:
        pass
    return vmm_enabled
def is_hyper():
    if HAS_LIBVIRT:
        return _is_xen_hyper() or _is_kvm_hyper() or _is_bhyve_hyper()
    return False
def vm_cputime(vm_=None, **kwargs):
    conn = __get_conn(**kwargs)
    host_cpus = conn.getInfo()[2]
    def _info(dom):
        raw = dom.info()
        vcpus = int(raw[3])
        cputime = int(raw[4])
        cputime_percent = 0
        if cputime:
            cputime_percent = (1.0e-7 * cputime / host_cpus) / vcpus
        return {
            "cputime": int(raw[4]),
            "cputime_percent": int("{:.0f}".format(cputime_percent)),
        }
    info = {}
    if vm_:
        info[vm_] = _info(_get_domain(conn, vm_))
    else:
        for domain in _get_domain(conn, iterable=True):
            info[domain.name()] = _info(domain)
    conn.close()
    return info
def vm_netstats(vm_=None, **kwargs):
    def _info(dom):
        nics = _get_nics(dom)
        ret = {
            "rx_bytes": 0,
            "rx_packets": 0,
            "rx_errs": 0,
            "rx_drop": 0,
            "tx_bytes": 0,
            "tx_packets": 0,
            "tx_errs": 0,
            "tx_drop": 0,
        }
        for attrs in nics.values():
            if "target" in attrs:
                dev = attrs["target"]
                stats = dom.interfaceStats(dev)
                ret["rx_bytes"] += stats[0]
                ret["rx_packets"] += stats[1]
                ret["rx_errs"] += stats[2]
                ret["rx_drop"] += stats[3]
                ret["tx_bytes"] += stats[4]
                ret["tx_packets"] += stats[5]
                ret["tx_errs"] += stats[6]
                ret["tx_drop"] += stats[7]
        return ret
    info = {}
    conn = __get_conn(**kwargs)
    if vm_:
        info[vm_] = _info(_get_domain(conn, vm_))
    else:
        for domain in _get_domain(conn, iterable=True):
            info[domain.name()] = _info(domain)
    conn.close()
    return info
def vm_diskstats(vm_=None, **kwargs):
    def get_disk_devs(dom):
        doc = ElementTree.fromstring(get_xml(dom, **kwargs))
        return [target.get("dev") for target in doc.findall("devices/disk/target")]
    def _info(dom):
        disks = get_disk_devs(dom)
        ret = {"rd_req": 0, "rd_bytes": 0, "wr_req": 0, "wr_bytes": 0, "errs": 0}
        for disk in disks:
            stats = dom.blockStats(disk)
            ret["rd_req"] += stats[0]
            ret["rd_bytes"] += stats[1]
            ret["wr_req"] += stats[2]
            ret["wr_bytes"] += stats[3]
            ret["errs"] += stats[4]
        return ret
    info = {}
    conn = __get_conn(**kwargs)
    if vm_:
        info[vm_] = _info(_get_domain(conn, vm_))
    else:
        for domain in _get_domain(conn, iterable=True, inactive=False):
            info[domain.name()] = _info(domain)
    conn.close()
    return info
def _parse_snapshot_description(vm_snapshot, unix_time=False):
    ret = dict()
    tree = ElementTree.fromstring(vm_snapshot.getXMLDesc())
    for node in tree:
        if node.tag == "name":
            ret["name"] = node.text
        elif node.tag == "creationTime":
            ret["created"] = (
                datetime.datetime.fromtimestamp(float(node.text)).isoformat(" ")
                if not unix_time
                else float(node.text)
            )
        elif node.tag == "state":
            ret["running"] = node.text == "running"
    ret["current"] = vm_snapshot.isCurrent() == 1
    return ret
def list_snapshots(domain=None, **kwargs):
    ret = dict()
    conn = __get_conn(**kwargs)
    for vm_domain in _get_domain(conn, *(domain and [domain] or list()), iterable=True):
        ret[vm_domain.name()] = [
            _parse_snapshot_description(snap) for snap in vm_domain.listAllSnapshots()
        ] or "N/A"
    conn.close()
    return ret
def snapshot(domain, name=None, suffix=None, **kwargs):
    if name and name.lower() == domain.lower():
        raise CommandExecutionError(
            "Virtual Machine {name} is already defined. "
            "Please choose another name for the snapshot".format(name=name)
        )
    if not name:
        name = "{domain}-{tsnap}".format(
            domain=domain, tsnap=time.strftime("%Y%m%d-%H%M%S", time.localtime())
        )
    if suffix:
        name = "{name}-{suffix}".format(name=name, suffix=suffix)
    doc = ElementTree.Element("domainsnapshot")
    n_name = ElementTree.SubElement(doc, "name")
    n_name.text = name
    conn = __get_conn(**kwargs)
    _get_domain(conn, domain).snapshotCreateXML(xmlutil.element_to_str(doc))
    conn.close()
    return {"name": name}
def delete_snapshots(name, *names, **kwargs):
    deleted = dict()
    conn = __get_conn(**kwargs)
    domain = _get_domain(conn, name)
    for snap in domain.listAllSnapshots():
        if snap.getName() in names or not names:
            deleted[snap.getName()] = _parse_snapshot_description(snap)
            snap.delete()
    conn.close()
    available = {
        name: [_parse_snapshot_description(snap) for snap in domain.listAllSnapshots()]
        or "N/A"
    }
    return {"available": available, "deleted": deleted}
def revert_snapshot(name, vm_snapshot=None, cleanup=False, **kwargs):
    ret = dict()
    conn = __get_conn(**kwargs)
    domain = _get_domain(conn, name)
    snapshots = domain.listAllSnapshots()
    _snapshots = list()
    for snap_obj in snapshots:
        _snapshots.append(
            {
                "idx": _parse_snapshot_description(snap_obj, unix_time=True)["created"],
                "ptr": snap_obj,
            }
        )
    snapshots = [
        w_ptr["ptr"]
        for w_ptr in sorted(_snapshots, key=lambda item: item["idx"], reverse=True)
    ]
    del _snapshots
    if not snapshots:
        conn.close()
        raise CommandExecutionError("No snapshots found")
    elif len(snapshots) == 1:
        conn.close()
        raise CommandExecutionError(
            "Cannot revert to itself: only one snapshot is available."
        )
    snap = None
    for p_snap in snapshots:
        if not vm_snapshot:
            if p_snap.isCurrent() and snapshots[snapshots.index(p_snap) + 1 :]:
                snap = snapshots[snapshots.index(p_snap) + 1 :][0]
                break
        elif p_snap.getName() == vm_snapshot:
            snap = p_snap
            break
    if not snap:
        conn.close()
        raise CommandExecutionError(
            snapshot
            and 'Snapshot "{}" not found'.format(vm_snapshot)
            or "No more previous snapshots available"
        )
    elif snap.isCurrent():
        conn.close()
        raise CommandExecutionError("Cannot revert to the currently running snapshot.")
    domain.revertToSnapshot(snap)
    ret["reverted"] = snap.getName()
    if cleanup:
        delete = list()
        for p_snap in snapshots:
            if p_snap.getName() != snap.getName():
                delete.append(p_snap.getName())
                p_snap.delete()
            else:
                break
        ret["deleted"] = delete
    else:
        ret["deleted"] = "N/A"
    conn.close()
    return ret
def _caps_add_machine(machines, node):
    maxcpus = node.get("maxCpus")
    canonical = node.get("canonical")
    name = node.text
    alternate_name = ""
    if canonical:
        alternate_name = name
        name = canonical
    machine = machines.get(name)
    if not machine:
        machine = {"alternate_names": []}
        if maxcpus:
            machine["maxcpus"] = int(maxcpus)
        machines[name] = machine
    if alternate_name:
        machine["alternate_names"].append(alternate_name)
def _parse_caps_guest(guest):
    arch_node = guest.find("arch")
    result = {
        "os_type": guest.find("os_type").text,
        "arch": {"name": arch_node.get("name"), "machines": {}, "domains": {}},
    }
    child = None
    for child in arch_node:
        if child.tag == "wordsize":
            result["arch"]["wordsize"] = int(child.text)
        elif child.tag == "emulator":
            result["arch"]["emulator"] = child.text
        elif child.tag == "machine":
            _caps_add_machine(result["arch"]["machines"], child)
        elif child.tag == "domain":
            domain_type = child.get("type")
            domain = {"emulator": None, "machines": {}}
            emulator_node = child.find("emulator")
            if emulator_node is not None:
                domain["emulator"] = emulator_node.text
            for machine in child.findall("machine"):
                _caps_add_machine(domain["machines"], machine)
            result["arch"]["domains"][domain_type] = domain
    features_nodes = guest.find("features")
    if features_nodes is not None and child is not None:
        result["features"] = {
            child.tag: {
                "toggle": child.get("toggle", "no") == "yes",
                "default": child.get("default", "on") == "on",
            }
            for child in features_nodes
        }
    return result
def _parse_caps_cell(cell):
    result = {"id": int(cell.get("id"))}
    mem_node = cell.find("memory")
    if mem_node is not None:
        unit = mem_node.get("unit", "KiB")
        memory = mem_node.text
        result["memory"] = "{} {}".format(memory, unit)
    pages = [
        {
            "size": "{} {}".format(page.get("size"), page.get("unit", "KiB")),
            "available": int(page.text),
        }
        for page in cell.findall("pages")
    ]
    if pages:
        result["pages"] = pages
    distances = {
        int(distance.get("id")): int(distance.get("value"))
        for distance in cell.findall("distances/sibling")
    }
    if distances:
        result["distances"] = distances
    cpus = []
    for cpu_node in cell.findall("cpus/cpu"):
        cpu = {"id": int(cpu_node.get("id"))}
        socket_id = cpu_node.get("socket_id")
        if socket_id:
            cpu["socket_id"] = int(socket_id)
        core_id = cpu_node.get("core_id")
        if core_id:
            cpu["core_id"] = int(core_id)
        siblings = cpu_node.get("siblings")
        if siblings:
            cpu["siblings"] = siblings
        cpus.append(cpu)
    if cpus:
        result["cpus"] = cpus
    return result
def _parse_caps_bank(bank):
    result = {
        "id": int(bank.get("id")),
        "level": int(bank.get("level")),
        "type": bank.get("type"),
        "size": "{} {}".format(bank.get("size"), bank.get("unit")),
        "cpus": bank.get("cpus"),
    }
    controls = []
    for control in bank.findall("control"):
        unit = control.get("unit")
        result_control = {
            "granularity": "{} {}".format(control.get("granularity"), unit),
            "type": control.get("type"),
            "maxAllocs": int(control.get("maxAllocs")),
        }
        minimum = control.get("min")
        if minimum:
            result_control["min"] = "{} {}".format(minimum, unit)
        controls.append(result_control)
    if controls:
        result["controls"] = controls
    return result
def _parse_caps_host(host):
    result = {}
    for child in host:
        if child.tag == "uuid":
            result["uuid"] = child.text
        elif child.tag == "cpu":
            cpu = {
<a name="2"></a>                "arch": child.find("arch").text
                if child.find("arch") is not None
                else None,
                "model": child.find("model")<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.text
                if child.find("model") is not None
                else None,
                "vendor": child.find("vendor").text
                if child.find("vendor") is not None
                else None,
                "features": [
                    feature.get("name") for feature in child.findall("feature")
                ],
                "pages": [
                    {"size": "{} {}".format(page.</b></font>get("size"), page.get("unit", "KiB"))}
                    for page in child.findall("pages")
                ],
            }
            microcode = child.find("microcode")
            if microcode is not None:
                cpu["microcode"] = microcode.get("version")
            topology = child.find("topology")
            if topology is not None:
                cpu["sockets"] = int(topology.get("sockets"))
                cpu["cores"] = int(topology.get("cores"))
                cpu["threads"] = int(topology.get("threads"))
            result["cpu"] = cpu
        elif child.tag == "power_management":
            result["power_management"] = [node.tag for node in child]
        elif child.tag == "migration_features":
            result["migration"] = {
                "live": child.find("live") is not None,
                "transports": [
                    node.text for node in child.findall("uri_transports/uri_transport")
                ],
            }
        elif child.tag == "topology":
            result["topology"] = {
                "cells": [
                    _parse_caps_cell(cell) for cell in child.findall("cells/cell")
                ]
            }
        elif child.tag == "cache":
            result["cache"] = {
                "banks": [_parse_caps_bank(bank) for bank in child.findall("bank")]
            }
    result["security"] = [
        {
            "model": secmodel.find("model").text
            if secmodel.find("model") is not None
            else None,
            "doi": secmodel.find("doi").text
            if secmodel.find("doi") is not None
            else None,
            "baselabels": [
                {"type": label.get("type"), "label": label.text}
                for label in secmodel.findall("baselabel")
            ],
        }
        for secmodel in host.findall("secmodel")
    ]
    return result
def _capabilities(conn):
    caps = ElementTree.fromstring(conn.getCapabilities())
    return {
        "host": _parse_caps_host(caps.find("host")),
        "guests": [_parse_caps_guest(guest) for guest in caps.findall("guest")],
    }
def capabilities(**kwargs):
    conn = __get_conn(**kwargs)
    try:
        caps = _capabilities(conn)
    except libvirt.libvirtError as err:
        raise CommandExecutionError(str(err))
    finally:
        conn.close()
    return caps
def _parse_caps_enum(node):
    return (node.get("name"), [value.text for value in node.findall("value")])
def _parse_caps_cpu(node):
    result = {}
    for mode in node.findall("mode"):
        if not mode.get("supported") == "yes":
            continue
        name = mode.get("name")
        if name == "host-passthrough":
            result[name] = True
        elif name == "host-model":
            host_model = {}
            model_node = mode.find("model")
            if model_node is not None:
                model = {"name": model_node.text}
                vendor_id = model_node.get("vendor_id")
                if vendor_id:
                    model["vendor_id"] = vendor_id
                fallback = model_node.get("fallback")
                if fallback:
                    model["fallback"] = fallback
                host_model["model"] = model
            vendor = (
                mode.find("vendor").text if mode.find("vendor") is not None else None
            )
            if vendor:
                host_model["vendor"] = vendor
            features = {
                feature.get("name"): feature.get("policy")
                for feature in mode.findall("feature")
            }
            if features:
                host_model["features"] = features
            result[name] = host_model
        elif name == "custom":
            custom_model = {}
            models = {
                model.text: model.get("usable") for model in mode.findall("model")
            }
            if models:
                custom_model["models"] = models
            result[name] = custom_model
    return result
def _parse_caps_devices_features(node):
    result = {}
    for child in node:
        if child.get("supported") == "yes":
            enums = [_parse_caps_enum(node) for node in child.findall("enum")]
            result[child.tag] = {item[0]: item[1] for item in enums if item[0]}
    return result
def _parse_caps_loader(node):
    enums = [_parse_caps_enum(enum) for enum in node.findall("enum")]
    result = {item[0]: item[1] for item in enums if item[0]}
    values = [child.text for child in node.findall("value")]
    if values:
        result["values"] = values
    return result
def _parse_domain_caps(caps):
    result = {
        "emulator": caps.find("path").text if caps.find("path") is not None else None,
        "domain": caps.find("domain").text if caps.find("domain") is not None else None,
        "machine": caps.find("machine").text
        if caps.find("machine") is not None
        else None,
        "arch": caps.find("arch").text if caps.find("arch") is not None else None,
    }
    for child in caps:
        if child.tag == "vcpu" and child.get("max"):
            result["max_vcpus"] = int(child.get("max"))
        elif child.tag == "iothreads":
            result["iothreads"] = child.get("supported") == "yes"
        elif child.tag == "os":
            result["os"] = {}
            loader_node = child.find("loader")
            if loader_node is not None and loader_node.get("supported") == "yes":
                loader = _parse_caps_loader(loader_node)
                result["os"]["loader"] = loader
        elif child.tag == "cpu":
            cpu = _parse_caps_cpu(child)
            if cpu:
                result["cpu"] = cpu
        elif child.tag == "devices":
            devices = _parse_caps_devices_features(child)
            if devices:
                result["devices"] = devices
        elif child.tag == "features":
            features = _parse_caps_devices_features(child)
            if features:
                result["features"] = features
    return result
def domain_capabilities(emulator=None, arch=None, machine=None, domain=None, **kwargs):
    conn = __get_conn(**kwargs)
    result = []
    try:
        caps = ElementTree.fromstring(
            conn.getDomainCapabilities(emulator, arch, machine, domain, 0)
        )
        result = _parse_domain_caps(caps)
    finally:
        conn.close()
    return result
def all_capabilities(**kwargs):
    conn = __get_conn(**kwargs)
    try:
        host_caps = ElementTree.fromstring(conn.getCapabilities())
        domains = [
            [
                (
                    guest.get("arch", {}).get("name", None),
                    key,
                    guest.get("arch", {}).get("emulator", None),
                )
                for key in guest.get("arch", {}).get("domains", {}).keys()
            ]
            for guest in [
                _parse_caps_guest(guest) for guest in host_caps.findall("guest")
            ]
        ]
        flattened = [pair for item in (x for x in domains) for pair in item]
        result = {
            "host": {
                "host": _parse_caps_host(host_caps.find("host")),
                "guests": [
                    _parse_caps_guest(guest) for guest in host_caps.findall("guest")
                ],
            },
            "domains": [
                _parse_domain_caps(
                    ElementTree.fromstring(
                        conn.getDomainCapabilities(emulator, arch, None, domain)
                    )
                )
                for (arch, domain, emulator) in flattened
            ],
        }
        return result
    finally:
        conn.close()
def cpu_baseline(full=False, migratable=False, out="libvirt", **kwargs):
    conn = __get_conn(**kwargs)
    caps = ElementTree.fromstring(conn.getCapabilities())
    cpu = caps.find("host/cpu")
    host_cpu_def = xmlutil.element_to_str(cpu)
    log.debug("Host CPU model definition: %s", host_cpu_def)
    flags = 0
    if migratable:
        if getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_MIGRATABLE", False):
            flags += libvirt.VIR_CONNECT_BASELINE_CPU_MIGRATABLE
        else:
            conn.close()
            raise ValueError
    if full and getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES", False):
        flags += libvirt.VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES
    cpu = ElementTree.fromstring(conn.baselineCPU([host_cpu_def], flags))
    conn.close()
    if full and not getattr(libvirt, "VIR_CONNECT_BASELINE_CPU_EXPAND_FEATURES", False):
        with salt.utils.files.fopen("/usr/share/libvirt/cpu_map.xml", "r") as cpu_map:
            cpu_map = ElementTree.parse(cpu_map)
        cpu_model = cpu.find("model").text
        while cpu_model:
            cpu_map_models = cpu_map.findall("arch/model")
            cpu_specs = [
                el
                for el in cpu_map_models
                if el.get("name") == cpu_model and bool(len(el))
            ]
            if not cpu_specs:
                raise ValueError("Model {} not found in CPU map".format(cpu_model))
            elif len(cpu_specs) &gt; 1:
                raise ValueError(
                    "Multiple models {} found in CPU map".format(cpu_model)
                )
            cpu_specs = cpu_specs[0]
            model_node = cpu_specs.find("model")
            if model_node is None:
                cpu_model = None
            else:
                cpu_model = model_node.get("name")
            cpu.extend([feature for feature in cpu_specs.findall("feature")])
    if out == "salt":
        return {
            "model": cpu.find("model").text,
            "vendor": cpu.find("vendor").text,
            "features": [feature.get("name") for feature in cpu.findall("feature")],
        }
    return ElementTree.tostring(cpu)
def network_define(
    name,
    bridge,
    forward,
    ipv4_config=None,
    ipv6_config=None,
    vport=None,
    tag=None,
    autostart=True,
    start=True,
    mtu=None,
    domain=None,
    nat=None,
    interfaces=None,
    addresses=None,
    physical_function=None,
    dns=None,
    **kwargs
):
    conn = __get_conn(**kwargs)
    vport = kwargs.get("vport", None)
    tag = kwargs.get("tag", None)
    net_xml = _gen_net_xml(
        name,
        bridge,
        forward,
        vport,
        tag=tag,
        ip_configs=[config for config in [ipv4_config, ipv6_config] if config],
        mtu=mtu,
        domain=domain,
        nat=nat,
        interfaces=interfaces,
        addresses=addresses,
        physical_function=physical_function,
        dns=dns,
    )
    try:
        conn.networkDefineXML(net_xml)
    except libvirt.libvirtError as err:
        log.warning(err)
        conn.close()
        raise err  # a real error we should report upwards
    try:
        network = conn.networkLookupByName(name)
    except libvirt.libvirtError as err:
        log.warning(err)
        conn.close()
        raise err  # a real error we should report upwards
    if network is None:
        conn.close()
        return False
    if (start or autostart) and network.isActive() != 1:
        network.create()
    if autostart and network.autostart() != 1:
        network.setAutostart(int(autostart))
    elif not autostart and network.autostart() == 1:
        network.setAutostart(int(autostart))
    conn.close()
    return True
def _remove_empty_xml_node(node):
    for child in node:
        if not child.tail and not child.text and not child.items() and not child:
            node.remove(child)
        else:
            _remove_empty_xml_node(child)
    return node
def network_update(
    name,
    bridge,
    forward,
    ipv4_config=None,
    ipv6_config=None,
    vport=None,
    tag=None,
    mtu=None,
    domain=None,
    nat=None,
    interfaces=None,
    addresses=None,
    physical_function=None,
    dns=None,
    test=False,
    **kwargs
):
    conn = __get_conn(**kwargs)
    needs_update = False
    try:
        net = conn.networkLookupByName(name)
        old_xml = ElementTree.fromstring(net.XMLDesc())
        new_xml = ElementTree.fromstring(
            _gen_net_xml(
                name,
                bridge,
                forward,
                vport,
                tag=tag,
                ip_configs=[config for config in [ipv4_config, ipv6_config] if config],
                mtu=mtu,
                domain=domain,
                nat=nat,
                interfaces=interfaces,
                addresses=addresses,
                physical_function=physical_function,
                dns=dns,
            )
        )
        elements_to_copy = ["uuid", "mac"]
        for to_copy in elements_to_copy:
            element = old_xml.find(to_copy)
            if element is not None:
                new_xml.insert(1, element)
        old_xml.attrib.pop("connections", None)
        if old_xml.find("forward/pf") is not None:
            forward_node = old_xml.find("forward")
            address_nodes = forward_node.findall("address")
            for node in address_nodes:
                forward_node.remove(node)
        default_bridge_attribs = {"stp": "on", "delay": "0"}
        old_bridge_node = old_xml.find("bridge")
        if old_bridge_node is not None:
            for key, value in default_bridge_attribs.items():
                if old_bridge_node.get(key, None) == value:
                    old_bridge_node.attrib.pop(key, None)
            old_forward = (
                old_xml.find("forward").get("mode")
                if old_xml.find("forward") is not None
                else None
            )
            if (
                old_forward == forward
                and forward in ["nat", "route", "open", None]
                and bridge is None
                and old_bridge_node.get("name", "").startswith("virbr")
            ):
                old_bridge_node.attrib.pop("name", None)
        ipv4_nodes = [
            node
            for node in old_xml.findall("ip")
            if node.get("family", "ipv4") == "ipv4"
        ]
        for ip_node in ipv4_nodes:
            netmask = ip_node.attrib.pop("netmask", None)
            if netmask:
                address = ipaddress.ip_network(
                    "{}/{}".format(ip_node.get("address"), netmask), strict=False
                )
                ip_node.set("prefix", str(address.prefixlen))
        for doc in [old_xml, new_xml]:
            for node in doc.findall("ip"):
                if "family" not in node.keys():
                    node.set("family", "ipv4")
        _remove_empty_xml_node(xmlutil.strip_spaces(old_xml))
        xmlutil.strip_spaces(new_xml)
        needs_update = xmlutil.to_dict(old_xml, True) != xmlutil.to_dict(new_xml, True)
        if needs_update and not test:
            conn.networkDefineXML(xmlutil.element_to_str(new_xml))
    finally:
        conn.close()
    return needs_update
def list_networks(**kwargs):
    conn = __get_conn(**kwargs)
    try:
        return [net.name() for net in conn.listAllNetworks()]
    finally:
        conn.close()
def network_info(name=None, **kwargs):
    result = {}
    conn = __get_conn(**kwargs)
    def _net_get_leases(net):
        leases = net.DHCPLeases()
        for lease in leases:
            if lease["type"] == libvirt.VIR_IP_ADDR_TYPE_IPV4:
                lease["type"] = "ipv4"
            elif lease["type"] == libvirt.VIR_IP_ADDR_TYPE_IPV6:
                lease["type"] = "ipv6"
            else:
                lease["type"] = "unknown"
        return leases
    def _net_get_bridge(net):
        try:
            return net.bridgeName()
        except libvirt.libvirtError as err:
<a name="4"></a>            return None
    try:
        nets <font color="#6cc417"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= [
            net for net in conn.listAllNetworks() if name is None or net.name() == name
        ]
        result = {
            net.name(): {
                "uuid": net.UUIDString(</b></font>),
                "bridge": _net_get_bridge(net),
                "autostart": net.autostart(),
                "active": net.isActive(),
                "persistent": net.isPersistent(),
                "leases": _net_get_leases(net),
            }
            for net in nets
        }
    except libvirt.libvirtError as err:
        log.debug("Silenced libvirt error: %s", err)
    finally:
        conn.close()
    return result
def network_get_xml(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        return conn.networkLookupByName(name).XMLDesc()
    finally:
        conn.close()
def network_start(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        net = conn.networkLookupByName(name)
        return not bool(net.create())
    finally:
        conn.close()
def network_stop(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        net = conn.networkLookupByName(name)
        return not bool(net.destroy())
    finally:
        conn.close()
def network_undefine(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        net = conn.networkLookupByName(name)
        return not bool(net.undefine())
    finally:
        conn.close()
def network_set_autostart(name, state="on", **kwargs):
    conn = __get_conn(**kwargs)
    try:
        net = conn.networkLookupByName(name)
        return not bool(net.setAutostart(1 if state == "on" else 0))
    finally:
        conn.close()
def _parse_pools_caps(doc):
    def _parse_pool_caps(pool):
        pool_caps = {
            "name": pool.get("type"),
            "supported": pool.get("supported", "no") == "yes",
        }
        for option_kind in ["pool", "vol"]:
            options = {}
            default_format_node = pool.find(
                "{}Options/defaultFormat".format(option_kind)
            )
            if default_format_node is not None:
                options["default_format"] = default_format_node.get("type")
            options_enums = {
                enum.get("name"): [value.text for value in enum.findall("value")]
                for enum in pool.findall("{}Options/enum".format(option_kind))
            }
            if options_enums:
                options.update(options_enums)
            if options:
                if "options" not in pool_caps:
                    pool_caps["options"] = {}
                kind = option_kind if option_kind != "vol" else "volume"
                pool_caps["options"][kind] = options
        return pool_caps
    return [_parse_pool_caps(pool) for pool in doc.findall("pool")]
def _pool_capabilities(conn):
    has_pool_capabilities = bool(getattr(conn, "getStoragePoolCapabilities", None))
    if has_pool_capabilities:
        caps = ElementTree.fromstring(conn.getStoragePoolCapabilities())
        pool_types = _parse_pools_caps(caps)
    else:
        all_hypervisors = ["xen", "kvm", "bhyve"]
        images_formats = [
            "none",
            "raw",
            "dir",
            "bochs",
            "cloop",
            "dmg",
            "iso",
            "vpc",
            "vdi",
            "fat",
            "vhd",
            "ploop",
            "cow",
            "qcow",
            "qcow2",
            "qed",
            "vmdk",
        ]
        common_drivers = [
            {
                "name": "fs",
                "default_source_format": "auto",
                "source_formats": [
                    "auto",
                    "ext2",
                    "ext3",
                    "ext4",
                    "ufs",
                    "iso9660",
                    "udf",
                    "gfs",
                    "gfs2",
                    "vfat",
                    "hfs+",
                    "xfs",
                    "ocfs2",
                ],
                "default_target_format": "raw",
                "target_formats": images_formats,
            },
            {
                "name": "dir",
                "default_target_format": "raw",
                "target_formats": images_formats,
            },
            {"name": "iscsi"},
            {"name": "scsi"},
            {
                "name": "logical",
                "default_source_format": "lvm2",
                "source_formats": ["unknown", "lvm2"],
            },
            {
                "name": "netfs",
                "default_source_format": "auto",
                "source_formats": ["auto", "nfs", "glusterfs", "cifs"],
                "default_target_format": "raw",
                "target_formats": images_formats,
            },
            {
                "name": "disk",
                "default_source_format": "unknown",
                "source_formats": [
                    "unknown",
                    "dos",
                    "dvh",
                    "gpt",
                    "mac",
                    "bsd",
                    "pc98",
                    "sun",
                    "lvm2",
                ],
                "default_target_format": "none",
                "target_formats": [
                    "none",
                    "linux",
                    "fat16",
                    "fat32",
                    "linux-swap",
                    "linux-lvm",
                    "linux-raid",
                    "extended",
                ],
            },
            {"name": "mpath"},
            {"name": "rbd", "default_target_format": "raw", "target_formats": []},
            {
                "name": "sheepdog",
                "version": 10000,
                "hypervisors": ["kvm"],
                "default_target_format": "raw",
                "target_formats": images_formats,
            },
            {
                "name": "gluster",
                "version": 1002000,
                "hypervisors": ["kvm"],
                "default_target_format": "raw",
                "target_formats": images_formats,
            },
            {"name": "zfs", "version": 1002008, "hypervisors": ["bhyve"]},
            {
                "name": "iscsi-direct",
                "version": 4007000,
                "hypervisors": ["kvm", "xen"],
            },
        ]
        libvirt_version = conn.getLibVersion()
        hypervisor = get_hypervisor()
        def _get_backend_output(backend):
            output = {
                "name": backend["name"],
                "supported": (
                    not backend.get("version") or libvirt_version &gt;= backend["version"]
                )
                and hypervisor in backend.get("hypervisors", all_hypervisors),
                "options": {
                    "pool": {
                        "default_format": backend.get("default_source_format"),
                        "sourceFormatType": backend.get("source_formats"),
                    },
                    "volume": {
                        "default_format": backend.get("default_target_format"),
                        "targetFormatType": backend.get("target_formats"),
                    },
                },
            }
            for option_kind in ["pool", "volume"]:
                if not [
                    value
                    for value in output["options"][option_kind].values()
                    if value is not None
                ]:
                    del output["options"][option_kind]
            if not output["options"]:
                del output["options"]
            return output
        pool_types = [_get_backend_output(backend) for backend in common_drivers]
    return {
        "computed": not has_pool_capabilities,
        "pool_types": pool_types,
    }
def pool_capabilities(**kwargs):
    try:
        conn = __get_conn(**kwargs)
        return _pool_capabilities(conn)
    finally:
        conn.close()
def pool_define(
    name,
    ptype,
    target=None,
    permissions=None,
    source_devices=None,
    source_dir=None,
    source_initiator=None,
    source_adapter=None,
    source_hosts=None,
    source_auth=None,
    source_name=None,
    source_format=None,
    transient=False,
    start=True,  # pylint: disable=redefined-outer-name
    **kwargs
):
    conn = __get_conn(**kwargs)
    auth = _pool_set_secret(conn, ptype, name, source_auth)
    pool_xml = _gen_pool_xml(
        name,
        ptype,
        target,
        permissions=permissions,
        source_devices=source_devices,
        source_dir=source_dir,
        source_adapter=source_adapter,
        source_hosts=source_hosts,
        source_auth=auth,
        source_name=source_name,
        source_format=source_format,
        source_initiator=source_initiator,
    )
    try:
        if transient:
            pool = conn.storagePoolCreateXML(pool_xml)
        else:
            pool = conn.storagePoolDefineXML(pool_xml)
            if start:
                pool.create()
    except libvirt.libvirtError as err:
        raise err  # a real error we should report upwards
    finally:
        conn.close()
    return True
def _pool_set_secret(
    conn, pool_type, pool_name, source_auth, uuid=None, usage=None, test=False
):
    secret_types = {"rbd": "ceph", "iscsi": "chap", "iscsi-direct": "chap"}
    secret_type = secret_types.get(pool_type)
    auth = source_auth
    if source_auth and "username" in source_auth and "password" in source_auth:
        if secret_type:
            secret = None
            try:
                if usage:
                    usage_type = (
                        libvirt.VIR_SECRET_USAGE_TYPE_CEPH
                        if secret_type == "ceph"
                        else libvirt.VIR_SECRET_USAGE_TYPE_ISCSI
                    )
                    secret = conn.secretLookupByUsage(usage_type, usage)
                elif uuid:
                    secret = conn.secretLookupByUUIDString(uuid)
            except libvirt.libvirtError as err:
                log.info("Secret not found: %s", err.get_error_message())
            if not secret:
                description = "Passphrase for {} pool created by Salt".format(pool_name)
                if not usage:
                    usage = "pool_{}".format(pool_name)
                secret_xml = _gen_secret_xml(secret_type, usage, description)
                if not test:
                    secret = conn.secretDefineXML(secret_xml)
            password = auth["password"]
            if pool_type == "rbd":
                password = base64.b64decode(salt.utils.stringutils.to_bytes(password))
            if not test:
                secret.setValue(password)
            auth["type"] = secret_type
            auth["secret"] = {
                "type": "uuid" if uuid else "usage",
                "value": uuid if uuid else usage,
            }
    return auth
def pool_update(
    name,
    ptype,
    target=None,
    permissions=None,
    source_devices=None,
    source_dir=None,
    source_initiator=None,
    source_adapter=None,
    source_hosts=None,
    source_auth=None,
    source_name=None,
    source_format=None,
    test=False,
    **kwargs
):
    conn = __get_conn(**kwargs)
    needs_update = False
    try:
        pool = conn.storagePoolLookupByName(name)
        old_xml = ElementTree.fromstring(pool.XMLDesc())
        secret_node = old_xml.find("source/auth/secret")
        usage = secret_node.get("usage") if secret_node is not None else None
        uuid = secret_node.get("uuid") if secret_node is not None else None
        auth = _pool_set_secret(
            conn, ptype, name, source_auth, uuid=uuid, usage=usage, test=test
        )
        new_xml = ElementTree.fromstring(
            _gen_pool_xml(
                name,
                ptype,
                target,
                permissions=permissions,
                source_devices=source_devices,
                source_dir=source_dir,
                source_initiator=source_initiator,
                source_adapter=source_adapter,
                source_hosts=source_hosts,
                source_auth=auth,
                source_name=source_name,
                source_format=source_format,
            )
        )
        elements_to_copy = ["available", "allocation", "capacity", "uuid"]
        for to_copy in elements_to_copy:
            element = old_xml.find(to_copy)
            new_xml.insert(1, element)
        _remove_empty_xml_node(xmlutil.strip_spaces(old_xml))
        xmlutil.strip_spaces(new_xml)
        needs_update = xmlutil.to_dict(old_xml, True) != xmlutil.to_dict(new_xml, True)
        if needs_update and not test:
            conn.storagePoolDefineXML(xmlutil.element_to_str(new_xml))
    finally:
        conn.close()
    return needs_update
def list_pools(**kwargs):
    conn = __get_conn(**kwargs)
    try:
        return [pool.name() for pool in conn.listAllStoragePools()]
    finally:
        conn.close()
def pool_info(name=None, **kwargs):
    result = {}
    conn = __get_conn(**kwargs)
    def _pool_extract_infos(pool):
        states = ["inactive", "building", "running", "degraded", "inaccessible"]
        infos = pool.info()
        state = states[infos[0]] if infos[0] &lt; len(states) else "unknown"
        desc = ElementTree.fromstring(pool.XMLDesc())
        path_node = desc.find("target/path")
        return {
            "uuid": pool.UUIDString(),
            "state": state,
            "capacity": infos[1],
            "allocation": infos[2],
            "free": infos[3],
            "autostart": pool.autostart(),
            "persistent": pool.isPersistent(),
            "target_path": path_node.text if path_node is not None else None,
            "type": desc.get("type"),
        }
    try:
        pools = [
            pool
            for pool in conn.listAllStoragePools()
            if name is None or pool.name() == name
        ]
        result = {pool.name(): _pool_extract_infos(pool) for pool in pools}
    except libvirt.libvirtError as err:
        log.debug("Silenced libvirt error: %s", err)
    finally:
        conn.close()
    return result
def pool_get_xml(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        return conn.storagePoolLookupByName(name).XMLDesc()
    finally:
        conn.close()
def pool_start(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        pool = conn.storagePoolLookupByName(name)
        return not bool(pool.create())
    finally:
        conn.close()
def pool_build(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        pool = conn.storagePoolLookupByName(name)
        return not bool(pool.build())
    finally:
        conn.close()
def pool_stop(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        pool = conn.storagePoolLookupByName(name)
        return not bool(pool.destroy())
    finally:
        conn.close()
def pool_undefine(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        pool = conn.storagePoolLookupByName(name)
        desc = ElementTree.fromstring(pool.XMLDesc())
        auth_node = desc.find("source/auth")
        if auth_node is not None:
            auth_types = {
                "ceph": libvirt.VIR_SECRET_USAGE_TYPE_CEPH,
                "iscsi": libvirt.VIR_SECRET_USAGE_TYPE_ISCSI,
            }
            secret_type = auth_types[auth_node.get("type")]
            secret_usage = auth_node.find("secret").get("usage")
            if secret_type and "pool_{}".format(name) == secret_usage:
                secret = conn.secretLookupByUsage(secret_type, secret_usage)
                secret.undefine()
        return not bool(pool.undefine())
    finally:
        conn.close()
def pool_delete(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        pool = conn.storagePoolLookupByName(name)
        return not bool(pool.delete(libvirt.VIR_STORAGE_POOL_DELETE_NORMAL))
    finally:
        conn.close()
def pool_refresh(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        pool = conn.storagePoolLookupByName(name)
        return not bool(pool.refresh())
    finally:
        conn.close()
def pool_set_autostart(name, state="on", **kwargs):
    conn = __get_conn(**kwargs)
    try:
        pool = conn.storagePoolLookupByName(name)
        return not bool(pool.setAutostart(1 if state == "on" else 0))
    finally:
        conn.close()
def pool_list_volumes(name, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        pool = conn.storagePoolLookupByName(name)
        return pool.listVolumes()
    finally:
        conn.close()
def _get_storage_vol(conn, pool, vol):
    pool_obj = conn.storagePoolLookupByName(pool)
    return pool_obj.storageVolLookupByName(vol)
def _is_valid_volume(vol):
    try:
        def discarder(ctxt, error):  # pylint: disable=unused-argument
            log.debug("Ignore libvirt error: %s", error[2])
        libvirt.registerErrorHandler(discarder, None)
        vol.info()
        libvirt.registerErrorHandler(None, None)
        return True
    except libvirt.libvirtError as err:
        return False
def _get_all_volumes_paths(conn):
    pools = [
        pool
        for pool in conn.listAllStoragePools()
        if pool.info()[0] == libvirt.VIR_STORAGE_POOL_RUNNING
    ]
    volumes = {}
    for pool in pools:
        pool_volumes = {
            volume.path(): {
                "pool": pool.name(),
                "name": volume.name(),
                "backing_stores": [
                    path.text
                    for path in ElementTree.fromstring(volume.XMLDesc()).findall(
                        ".//backingStore/path"
                    )
                ],
            }
            for volume in pool.listAllVolumes()
            if _is_valid_volume(volume)
        }
        volumes.update(pool_volumes)
    return volumes
def volume_infos(pool=None, volume=None, **kwargs):
    result = {}
    conn = __get_conn(**kwargs)
    try:
        backing_stores = _get_all_volumes_paths(conn)
        try:
            domains = _get_domain(conn)
            domains_list = domains if isinstance(domains, list) else [domains]
        except CommandExecutionError:
            domains_list = []
        disks = {
            domain.name(): {
                node.get("file")
                for node in ElementTree.fromstring(domain.XMLDesc(0)).findall(
                    ".//disk/source/[@file]"
                )
            }
            for domain in domains_list
        }
        def _volume_extract_infos(vol):
            types = ["file", "block", "dir", "network", "netdir", "ploop"]
            infos = vol.info()
            vol_xml = ElementTree.fromstring(vol.XMLDesc())
            backing_store_path = vol_xml.find("./backingStore/path")
            backing_store_format = vol_xml.find("./backingStore/format")
            backing_store = None
            if backing_store_path is not None:
                backing_store = {
                    "path": backing_store_path.text,
                    "format": backing_store_format.get("type")
                    if backing_store_format is not None
                    else None,
                }
            format_node = vol_xml.find("./target/format")
            used_by = []
            if vol.path():
                as_backing_store = {
                    path
                    for (path, volume) in backing_stores.items()
                    if vol.path() in volume.get("backing_stores")
                }
                used_by = [
                    vm_name
                    for (vm_name, vm_disks) in disks.items()
                    if vm_disks &amp; as_backing_store or vol.path() in vm_disks
                ]
            return {
                "type": types[infos[0]] if infos[0] &lt; len(types) else "unknown",
                "key": vol.key(),
                "path": vol.path(),
                "capacity": infos[1],
                "allocation": infos[2],
                "used_by": used_by,
                "backing_store": backing_store,
                "format": format_node.get("type") if format_node is not None else None,
            }
        pools = [
            obj
            for obj in conn.listAllStoragePools()
            if (pool is None or obj.name() == pool)
            and obj.info()[0] == libvirt.VIR_STORAGE_POOL_RUNNING
        ]
        vols = {
            pool_obj.name(): {
                vol.name(): _volume_extract_infos(vol)
                for vol in pool_obj.listAllVolumes()
                if (volume is None or vol.name() == volume) and _is_valid_volume(vol)
            }
            for pool_obj in pools
        }
        return {pool_name: volumes for (pool_name, volumes) in vols.items() if volumes}
    except libvirt.libvirtError as err:
        log.debug("Silenced libvirt error: %s", err)
    finally:
        conn.close()
    return result
def volume_delete(pool, volume, **kwargs):
    conn = __get_conn(**kwargs)
    try:
        vol = _get_storage_vol(conn, pool, volume)
        return not bool(vol.delete())
    finally:
        conn.close()
def volume_define(
    pool,
    name,
    size,
    allocation=0,
    format=None,
    type=None,
    permissions=None,
    backing_store=None,
    nocow=False,
    **kwargs
):
    ret = False
    try:
        conn = __get_conn(**kwargs)
        pool_obj = conn.storagePoolLookupByName(pool)
        pool_type = ElementTree.fromstring(pool_obj.XMLDesc()).get("type")
        new_allocation = allocation
        if pool_type == "logical" and size != allocation:
            new_allocation = size
        xml = _gen_vol_xml(
            name,
            size,
            format=format,
            allocation=new_allocation,
            type=type,
            permissions=permissions,
            backing_store=backing_store,
            nocow=nocow,
        )
        ret = _define_vol_xml_str(conn, xml, pool=pool)
    except libvirt.libvirtError as err:
        raise CommandExecutionError(err.get_error_message())
    finally:
        conn.close()
    return ret
def _volume_upload(conn, pool, volume, file, offset=0, length=0, sparse=False):
    def handler(stream, nbytes, opaque):
        return os.read(opaque, nbytes)
    def holeHandler(stream, opaque):
        fd = opaque
        cur = os.lseek(fd, 0, os.SEEK_CUR)
        try:
            data = os.lseek(fd, cur, os.SEEK_DATA)
        except OSError as e:
            if e.errno != 6:
                raise e
            else:
                data = -1
        if data &lt; 0:
            inData = False
            eof = os.lseek(fd, 0, os.SEEK_END)
            if eof &lt; cur:
                raise RuntimeError("Current position in file after EOF: {}".format(cur))
            sectionLen = eof - cur
        else:
            if data &gt; cur:
                inData = False
                sectionLen = data - cur
            else:
                inData = True
                hole = os.lseek(fd, data, os.SEEK_HOLE)
                if hole &lt; 0:
                    raise RuntimeError("No trailing hole")
                if hole == data:
                    raise RuntimeError("Impossible happened")
                else:
                    sectionLen = hole - data
        os.lseek(fd, cur, os.SEEK_SET)
        return [inData, sectionLen]
    def skipHandler(stream, length, opaque):
        return os.lseek(opaque, length, os.SEEK_CUR)
    stream = None
    fd = None
    ret = False
    try:
        pool_obj = conn.storagePoolLookupByName(pool)
        vol_obj = pool_obj.storageVolLookupByName(volume)
        stream = conn.newStream()
        fd = os.open(file, os.O_RDONLY)
        vol_obj.upload(
            stream,
            offset,
            length,
            libvirt.VIR_STORAGE_VOL_UPLOAD_SPARSE_STREAM if sparse else 0,
        )
        if sparse:
            stream.sparseSendAll(handler, holeHandler, skipHandler, fd)
        else:
            stream.sendAll(handler, fd)
        ret = True
    except libvirt.libvirtError as err:
        raise CommandExecutionError(err.get_error_message())
    finally:
        if fd:
            try:
                os.close(fd)
            except OSError as err:
                if stream:
                    stream.abort()
                if ret:
                    raise CommandExecutionError(
                        "Failed to close file: {}".format(err.strerror)
                    )
        if stream:
            try:
                stream.finish()
            except libvirt.libvirtError as err:
                if ret:
                    raise CommandExecutionError(
                        "Failed to finish stream: {}".format(err.get_error_message())
                    )
    return ret
def volume_upload(pool, volume, file, offset=0, length=0, sparse=False, **kwargs):
    conn = __get_conn(**kwargs)
    ret = False
    try:
        ret = _volume_upload(
            conn, pool, volume, file, offset=offset, length=length, sparse=sparse
        )
    finally:
        conn.close()
    return ret
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
