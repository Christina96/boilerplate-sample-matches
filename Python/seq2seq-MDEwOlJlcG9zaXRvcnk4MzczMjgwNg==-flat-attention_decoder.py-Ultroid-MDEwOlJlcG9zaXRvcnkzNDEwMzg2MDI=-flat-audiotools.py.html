
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 3.7422037422037424%, Tokens: 9, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-attention_decoder.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  from collections import namedtuple
6  import tensorflow as tf
7  from seq2seq.decoders.rnn_decoder import RNNDecoder
8  from seq2seq.contrib.seq2seq.helper import CustomHelper
9  class AttentionDecoderOutput(
10      namedtuple("DecoderOutput", [
11          "logits", "predicted_ids", "cell_output", "attention_scores",
12          "attention_context"
13      ])):
14    pass
15  class AttentionDecoder(RNNDecoder):
16    def __init__(self,
17                 params,
18                 mode,
19                 vocab_size,
20                 attention_keys,
21                 attention_values,
22                 attention_values_length,
23                 attention_fn,
24                 reverse_scores_lengths=None,
25                 name="attention_decoder"):
26      super(AttentionDecoder, self).__init__(params, mode, name)
27      self.vocab_size = vocab_size
28      self.attention_keys = attention_keys
29      self.attention_values = attention_values
30      self.attention_values_length = attention_values_length
31      self.attention_fn = attention_fn
32      self.reverse_scores_lengths = reverse_scores_lengths
33    @property
34    def output_size(self):
35      return AttentionDecoderOutput(
36          logits=self.vocab_size,
37          predicted_ids=tf.TensorShape([]),
38          cell_output=self.cell.output_size,
39          attention_scores=tf.shape(self.attention_values)[1:-1],
40          attention_context=self.attention_values.get_shape()[-1])
41    @property
42    def output_dtype(self):
43      return AttentionDecoderOutput(
44          logits=tf.float32,
45          predicted_ids=tf.int32,
46          cell_output=tf.float32,
47          attention_scores=tf.float32,
48          attention_context=tf.float32)
49    def initialize(self, name=None):
50      finished, first_inputs = self.helper.initialize()
51      attention_context = tf.zeros([
52          tf.shape(first_inputs)[0],
53          self.attention_values.get_shape().as_list()[-1]
54      ])
55      first_inputs = tf.concat([first_inputs, attention_context], 1)
56      return finished, first_inputs, self.initial_state
57    def compute_output(self, cell_output):
58      att_scores, attention_context = self.attention_fn(
59          query=cell_output,
60          keys=self.attention_keys,
61          values=self.attention_values,
62          values_length=self.attention_values_length)
63      softmax_input = tf.contrib.layers.fully_connected(
<span onclick='openModal()' class='match'>64          inputs=tf.concat([cell_output, attention_context], 1),
65          num_outputs=self.cell.output_size,
66          activation_fn=tf.nn.tanh,
67          scope="attention_mix")
</span>68      logits = tf.contrib.layers.fully_connected(
69          inputs=softmax_input,
70          num_outputs=self.vocab_size,
71          activation_fn=None,
72          scope="logits")
73      return softmax_input, logits, att_scores, attention_context
74    def _setup(self, initial_state, helper):
75      self.initial_state = initial_state
76      def att_next_inputs(time, outputs, state, sample_ids, name=None):
77        finished, next_inputs, next_state = helper.next_inputs(
78            time=time,
79            outputs=outputs,
80            state=state,
81            sample_ids=sample_ids,
82            name=name)
83        next_inputs = tf.concat([next_inputs, outputs.attention_context], 1)
84        return (finished, next_inputs, next_state)
85      self.helper = CustomHelper(
86          initialize_fn=helper.initialize,
87          sample_fn=helper.sample,
88          next_inputs_fn=att_next_inputs)
89    def step(self, time_, inputs, state, name=None):
90      cell_output, cell_state = self.cell(inputs, state)
91      cell_output_new, logits, attention_scores, attention_context = \
92        self.compute_output(cell_output)
93      if self.reverse_scores_lengths is not None:
94        attention_scores = tf.reverse_sequence(
95            input=attention_scores,
96            seq_lengths=self.reverse_scores_lengths,
97            seq_dim=1,
98            batch_dim=0)
99      sample_ids = self.helper.sample(
100          time=time_, outputs=logits, state=cell_state)
101      outputs = AttentionDecoderOutput(
102          logits=logits,
103          predicted_ids=sample_ids,
104          cell_output=cell_output_new,
105          attention_scores=attention_scores,
106          attention_context=attention_context)
107      finished, next_inputs, next_state = self.helper.next_inputs(
108          time=time_, outputs=outputs, state=cell_state, sample_ids=sample_ids)
109      return (outputs, next_state, next_inputs, finished)
</code></pre>
        </div>
        <div class="column">
            <h3>Ultroid-MDEwOlJlcG9zaXRvcnkzNDEwMzg2MDI=-flat-audiotools.py</h3>
            <pre><code>1  import os
2  import time
3  from datetime import datetime as dt
4  from pyUltroid.fns.tools import set_attributes
5  from . import (
6      LOGS,
7      ULTConfig,
8      bash,
9      downloader,
10      eod,
11      eor,
12      genss,
13      get_help,
14      get_string,
15      humanbytes,
16      mediainfo,
17      stdr,
18      time_formatter,
19      ultroid_cmd,
20      uploader,
21  )
22  __doc__ = get_help("help_audiotools")
23  @ultroid_cmd(pattern="makevoice$")
24  async def vnc(e):
25      if not e.reply_to:
26          return await eod(e, get_string("audiotools_1"))
27      r = await e.get_reply_message()
28      if not mediainfo(r.media).startswith(("audio", "video")):
29          return await eod(e, get_string("spcltool_1"))
30      xxx = await e.eor(get_string("com_1"))
31      file, _ = await e.client.fast_downloader(
32          r.document,
33      )
34      await xxx.edit(get_string("audiotools_2"))
35      await bash(
36          f"ffmpeg -i '{file.name}' -map 0:a -codec:a libopus -b:a 100k -vbr on out.opus"
37      )
38      try:
39          await e.client.send_message(
40              e.chat_id, file="out.opus", force_document=False, reply_to=r
41          )
42      except Exception as er:
43          LOGS.exception(er)
44          return await xxx.edit("`Failed to convert in Voice...`")
45      await xxx.delete()
46      os.remove(file.name)
47      os.remove("out.opus")
48  @ultroid_cmd(pattern="atrim( (.*)|$)")
49  async def trim_aud(e):
50      sec = e.pattern_match.group(1).strip()
51      if not sec or "-" not in sec:
52          return await eod(e, get_string("audiotools_3"))
53      a, b = sec.split("-")
54      if int(a) >= int(b):
55          return await eod(e, get_string("audiotools_4"))
56      vido = await e.get_reply_message()
57      if vido and vido.media and mediainfo(vido.media).startswith(("video", "audio")):
<span onclick='openModal()' class='match'>58          if hasattr(vido.media, "document"):
59              vfile = vido.media.document
60              name = vido.file.name
61          else:
62              vfile = vido.media
</span>63              name = ""
64          if not name:
65              name = dt.now().isoformat("_", "seconds") + ".mp4"
66          xxx = await e.eor(get_string("audiotools_5"))
67          c_time = time.time()
68          file = await downloader(
69              f"resources/downloads/{name}",
70              vfile,
71              xxx,
72              c_time,
73              f"Downloading {name}...",
74          )
75          o_size = os.path.getsize(file.name)
76          d_time = time.time()
77          diff = time_formatter((d_time - c_time) * 1000)
78          file_name = (file.name).split("/")[-1]
79          out = file_name.replace(file_name.split(".")[-1], "_trimmed.aac")
80          if int(b) > int(await genss(file.name)):
81              os.remove(file.name)
82              return await eod(xxx, get_string("audiotools_6"))
83          ss, dd = stdr(int(a)), stdr(int(b))
84          xxx = await xxx.edit(
85              f"Downloaded `{file.name}` of `{humanbytes(o_size)}` in `{diff}`.\n\nNow Trimming Audio from `{ss}` to `{dd}`..."
86          )
87          cmd = f'ffmpeg -i "{file.name}" -preset ultrafast -ss {ss} -to {dd} -vn -acodec copy "{out}" -y'
88          await bash(cmd)
89          os.remove(file.name)
90          f_time = time.time()
91          mmmm = await uploader(out, out, f_time, xxx, f"Uploading {out}...")
92          attributes = await set_attributes(out)
93          caption = get_string("audiotools_7").format(ss, dd)
94          await e.client.send_file(
95              e.chat_id,
96              mmmm,
97              thumb=ULTConfig.thumb,
98              caption=caption,
99              attributes=attributes,
100              force_document=False,
101              reply_to=e.reply_to_msg_id,
102          )
103          await xxx.delete()
104      else:
105          await e.eor(get_string("audiotools_1"), time=5)
106  @ultroid_cmd(pattern="extractaudio$")
107  async def ex_aud(e):
108      reply = await e.get_reply_message()
109      if not (reply and reply.media and mediainfo(reply.media).startswith("video")):
110          return await e.eor(get_string("audiotools_8"))
111      name = reply.file.name or "video.mp4"
112      vfile = reply.media.document
113      msg = await e.eor(get_string("com_1"))
114      c_time = time.time()
115      file = await downloader(
116          f"resources/downloads/{name}",
117          vfile,
118          msg,
119          c_time,
120          f"Downloading {name}...",
121      )
122      out_file = f"{file.name}.aac"
123      cmd = f"ffmpeg -i {file.name} -vn -acodec copy {out_file}"
124      o, err = await bash(cmd)
125      os.remove(file.name)
126      attributes = await set_attributes(out_file)
127      f_time = time.time()
128      try:
129          fo = await uploader(out_file, out_file, f_time, msg, f"Uploading {out_file}...")
130      except FileNotFoundError:
131          return await eor(msg, get_string("audiotools_9"))
132      await e.reply(
133          get_string("audiotools_10"),
134          file=fo,
135          thumb=ULTConfig.thumb,
136          attributes=attributes,
137      )
138      await msg.delete()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-attention_decoder.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from Ultroid-MDEwOlJlcG9zaXRvcnkzNDEwMzg2MDI=-flat-audiotools.py</div>
                </div>
                <div class="column column_space"><pre><code>64          inputs=tf.concat([cell_output, attention_context], 1),
65          num_outputs=self.cell.output_size,
66          activation_fn=tf.nn.tanh,
67          scope="attention_mix")
</pre></code></div>
                <div class="column column_space"><pre><code>58          if hasattr(vido.media, "document"):
59              vfile = vido.media.document
60              name = vido.file.name
61          else:
62              vfile = vido.media
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    