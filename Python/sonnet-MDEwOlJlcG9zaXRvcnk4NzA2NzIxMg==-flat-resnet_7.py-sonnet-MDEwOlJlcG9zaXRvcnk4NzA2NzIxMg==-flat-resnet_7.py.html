
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 113, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-resnet_7.py</h3>
            <pre><code>1  from typing import Mapping, Optional, Sequence, Union
2  from sonnet.src import base
3  from sonnet.src import batch_norm
4  from sonnet.src import conv
5  from sonnet.src import initializers
6  from sonnet.src import linear
7  from sonnet.src import pad
8  import tensorflow as tf
9  class BottleNeckBlockV1(base.Module):
10    def __init__(self,
11                 channels: int,
12                 stride: Union[int, Sequence[int]],
13                 use_projection: bool,
<span onclick='openModal()' class='match'>14                 bn_config: Mapping[str, float],
15                 name: Optional[str] = None):
16      super().__init__(name=name)
17      self._channels = channels
18      self._stride = stride
19      self._use_projection = use_projection
20      self._bn_config = bn_config
21      batchnorm_args = {"create_scale": True, "create_offset": True}
22      batchnorm_args.update(bn_config)
23      if self._use_projection:
24        self._proj_conv = conv.Conv2D(
25            output_channels=channels,
26            kernel_shape=1,
27            stride=stride,
28            with_bias=False,
29            padding=pad.same,
30            name="shortcut_conv")
31        self._proj_batchnorm = batch_norm.BatchNorm(
32            name="shortcut_batchnorm", **batchnorm_args)
</span>33      self._layers = []
34      conv_0 = conv.Conv2D(
35          output_channels=channels // 4,
36          kernel_shape=1,
37          stride=1,
38          with_bias=False,
39          padding=pad.same,
40          name="conv_0")
41      self._layers.append(
42          [conv_0,
43           batch_norm.BatchNorm(name="batchnorm_0", **batchnorm_args)])
44      conv_1 = conv.Conv2D(
45          output_channels=channels // 4,
46          kernel_shape=3,
47          stride=stride,
48          with_bias=False,
49          padding=pad.same,
50          name="conv_1")
51      self._layers.append(
52          [conv_1,
53           batch_norm.BatchNorm(name="batchnorm_1", **batchnorm_args)])
54      conv_2 = conv.Conv2D(
55          output_channels=channels,
56          kernel_shape=1,
57          stride=1,
58          with_bias=False,
59          padding=pad.same,
60          name="conv_2")
61      batchnorm_2 = batch_norm.BatchNorm(
62          name="batchnorm_2", scale_init=initializers.Zeros(), **batchnorm_args)
63      self._layers.append([conv_2, batchnorm_2])
64    def __call__(self, inputs, is_training):
65      if self._use_projection:
66        shortcut = self._proj_conv(inputs)
67        shortcut = self._proj_batchnorm(shortcut, is_training=is_training)
68      else:
69        shortcut = inputs
70      net = inputs
71      for i, [conv_layer, batchnorm_layer] in enumerate(self._layers):
72        net = conv_layer(net)
73        net = batchnorm_layer(net, is_training=is_training)
74        net = tf.nn.relu(net) if i < 2 else net  # Don't apply relu on last layer
75      return tf.nn.relu(net + shortcut)
76  class BottleNeckBlockV2(base.Module):
77    def __init__(self,
78                 channels: int,
79                 stride: Union[int, Sequence[int]],
80                 use_projection: bool,
81                 bn_config: Mapping[str, float],
82                 name: Optional[str] = None):
83      super().__init__(name=name)
84      self._channels = channels
85      self._stride = stride
86      self._use_projection = use_projection
87      self._bn_config = bn_config
88      batchnorm_args = {"create_scale": True, "create_offset": True}
89      batchnorm_args.update(bn_config)
90      if self._use_projection:
91        self._proj_conv = conv.Conv2D(
92            output_channels=channels,
93            kernel_shape=1,
94            stride=stride,
95            with_bias=False,
96            padding=pad.same,
97            name="shortcut_conv")
98      self._conv_0 = conv.Conv2D(
99          output_channels=channels // 4,
100          kernel_shape=1,
101          stride=1,
102          with_bias=False,
103          padding=pad.same,
104          name="conv_0")
105      self._bn_0 = batch_norm.BatchNorm(name="batchnorm_0", **batchnorm_args)
106      self._conv_1 = conv.Conv2D(
107          output_channels=channels // 4,
108          kernel_shape=3,
109          stride=stride,
110          with_bias=False,
111          padding=pad.same,
112          name="conv_1")
113      self._bn_1 = batch_norm.BatchNorm(name="batchnorm_1", **batchnorm_args)
114      self._conv_2 = conv.Conv2D(
115          output_channels=channels,
116          kernel_shape=1,
117          stride=1,
118          with_bias=False,
119          padding=pad.same,
120          name="conv_2")
121      self._bn_2 = batch_norm.BatchNorm(name="batchnorm_2", **batchnorm_args)
122    def __call__(self, inputs, is_training):
123      net = inputs
124      shortcut = inputs
125      for i, (conv_i, bn_i) in enumerate(((self._conv_0, self._bn_0),
126                                          (self._conv_1, self._bn_1),
127                                          (self._conv_2, self._bn_2))):
128        net = bn_i(net, is_training=is_training)
129        net = tf.nn.relu(net)
130        if i == 0 and self._use_projection:
131          shortcut = self._proj_conv(net)
132        net = conv_i(net)
133      return net + shortcut
134  class BlockGroup(base.Module):
135    def __init__(self,
136                 channels: int,
137                 num_blocks: int,
138                 stride: Union[int, Sequence[int]],
139                 bn_config: Mapping[str, float],
140                 resnet_v2: bool = False,
141                 name: Optional[str] = None):
142      super().__init__(name=name)
143      self._channels = channels
144      self._num_blocks = num_blocks
145      self._stride = stride
146      self._bn_config = bn_config
147      if resnet_v2:
148        bottle_neck_block = BottleNeckBlockV2
149      else:
150        bottle_neck_block = BottleNeckBlockV1
151      self._blocks = []
152      for id_block in range(num_blocks):
153        self._blocks.append(
154            bottle_neck_block(
155                channels=channels,
156                stride=stride if id_block == 0 else 1,
157                use_projection=(id_block == 0),
158                bn_config=bn_config,
159                name="block_%d" % (id_block)))
160    def __call__(self, inputs, is_training):
161      net = inputs
162      for block in self._blocks:
163        net = block(net, is_training=is_training)
164      return net
165  class ResNet(base.Module):
166    def __init__(self,
167                 blocks_per_group_list: Sequence[int],
168                 num_classes: int,
169                 bn_config: Optional[Mapping[str, float]] = None,
170                 resnet_v2: bool = False,
171                 channels_per_group_list: Sequence[int] = (256, 512, 1024, 2048),
172                 name: Optional[str] = None):
173      super().__init__(name=name)
174      if bn_config is None:
175        bn_config = {"decay_rate": 0.9, "eps": 1e-5}
176      self._bn_config = bn_config
177      self._resnet_v2 = resnet_v2
178      if len(blocks_per_group_list) != 4:
179        raise ValueError(
180            "`blocks_per_group_list` must be of length 4 not {}".format(
181                len(blocks_per_group_list)))
182      self._blocks_per_group_list = blocks_per_group_list
183      if len(channels_per_group_list) != 4:
184        raise ValueError(
185            "`channels_per_group_list` must be of length 4 not {}".format(
186                len(channels_per_group_list)))
187      self._channels_per_group_list = channels_per_group_list
188      self._initial_conv = conv.Conv2D(
189          output_channels=64,
190          kernel_shape=7,
191          stride=2,
192          with_bias=False,
193          padding=pad.same,
194          name="initial_conv")
195      if not self._resnet_v2:
196        self._initial_batchnorm = batch_norm.BatchNorm(
197            create_scale=True,
198            create_offset=True,
199            name="initial_batchnorm",
200            **bn_config)
201      self._block_groups = []
202      strides = [1, 2, 2, 2]
203      for i in range(4):
204        self._block_groups.append(
205            BlockGroup(
206                channels=self._channels_per_group_list[i],
207                num_blocks=self._blocks_per_group_list[i],
208                stride=strides[i],
209                bn_config=bn_config,
210                resnet_v2=resnet_v2,
211                name="block_group_%d" % (i)))
212      if self._resnet_v2:
213        self._final_batchnorm = batch_norm.BatchNorm(
214            create_scale=True,
215            create_offset=True,
216            name="final_batchnorm",
217            **bn_config)
218      self._logits = linear.Linear(
219          output_size=num_classes, w_init=initializers.Zeros(), name="logits")
220    def __call__(self, inputs, is_training):
221      net = inputs
222      net = self._initial_conv(net)
223      if not self._resnet_v2:
224        net = self._initial_batchnorm(net, is_training=is_training)
225        net = tf.nn.relu(net)
226      net = tf.nn.max_pool2d(
227          net, ksize=3, strides=2, padding="SAME", name="initial_max_pool")
228      for block_group in self._block_groups:
229        net = block_group(net, is_training)
230      if self._resnet_v2:
231        net = self._final_batchnorm(net, is_training=is_training)
232        net = tf.nn.relu(net)
233      net = tf.reduce_mean(net, axis=[1, 2], name="final_avg_pool")
234      return self._logits(net)
235  class ResNet50(ResNet):
236    def __init__(self,
237                 num_classes: int,
238                 bn_config: Optional[Mapping[str, float]] = None,
239                 resnet_v2: bool = False,
240                 name: Optional[str] = None):
241      super().__init__([3, 4, 6, 3],
242                       num_classes=num_classes,
243                       bn_config=bn_config,
244                       resnet_v2=resnet_v2,
245                       name=name)
</code></pre>
        </div>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-resnet_7.py</h3>
            <pre><code>1  from typing import Mapping, Optional, Sequence, Union
2  from sonnet.src import base
3  from sonnet.src import batch_norm
4  from sonnet.src import conv
5  from sonnet.src import initializers
6  from sonnet.src import linear
7  from sonnet.src import pad
8  import tensorflow as tf
9  class BottleNeckBlockV1(base.Module):
10    def __init__(self,
11                 channels: int,
12                 stride: Union[int, Sequence[int]],
13                 use_projection: bool,
14                 bn_config: Mapping[str, float],
15                 name: Optional[str] = None):
16      super().__init__(name=name)
17      self._channels = channels
18      self._stride = stride
19      self._use_projection = use_projection
20      self._bn_config = bn_config
21      batchnorm_args = {"create_scale": True, "create_offset": True}
22      batchnorm_args.update(bn_config)
23      if self._use_projection:
24        self._proj_conv = conv.Conv2D(
25            output_channels=channels,
26            kernel_shape=1,
27            stride=stride,
28            with_bias=False,
29            padding=pad.same,
30            name="shortcut_conv")
31        self._proj_batchnorm = batch_norm.BatchNorm(
32            name="shortcut_batchnorm", **batchnorm_args)
33      self._layers = []
34      conv_0 = conv.Conv2D(
35          output_channels=channels // 4,
36          kernel_shape=1,
37          stride=1,
38          with_bias=False,
39          padding=pad.same,
40          name="conv_0")
41      self._layers.append(
42          [conv_0,
43           batch_norm.BatchNorm(name="batchnorm_0", **batchnorm_args)])
44      conv_1 = conv.Conv2D(
45          output_channels=channels // 4,
46          kernel_shape=3,
47          stride=stride,
48          with_bias=False,
49          padding=pad.same,
50          name="conv_1")
51      self._layers.append(
52          [conv_1,
53           batch_norm.BatchNorm(name="batchnorm_1", **batchnorm_args)])
54      conv_2 = conv.Conv2D(
55          output_channels=channels,
56          kernel_shape=1,
57          stride=1,
58          with_bias=False,
59          padding=pad.same,
60          name="conv_2")
61      batchnorm_2 = batch_norm.BatchNorm(
62          name="batchnorm_2", scale_init=initializers.Zeros(), **batchnorm_args)
63      self._layers.append([conv_2, batchnorm_2])
64    def __call__(self, inputs, is_training):
65      if self._use_projection:
66        shortcut = self._proj_conv(inputs)
67        shortcut = self._proj_batchnorm(shortcut, is_training=is_training)
68      else:
69        shortcut = inputs
70      net = inputs
71      for i, [conv_layer, batchnorm_layer] in enumerate(self._layers):
72        net = conv_layer(net)
73        net = batchnorm_layer(net, is_training=is_training)
74        net = tf.nn.relu(net) if i < 2 else net  # Don't apply relu on last layer
75      return tf.nn.relu(net + shortcut)
76  class BottleNeckBlockV2(base.Module):
77    def __init__(self,
78                 channels: int,
79                 stride: Union[int, Sequence[int]],
80                 use_projection: bool,
<span onclick='openModal()' class='match'>81                 bn_config: Mapping[str, float],
82                 name: Optional[str] = None):
83      super().__init__(name=name)
84      self._channels = channels
85      self._stride = stride
86      self._use_projection = use_projection
87      self._bn_config = bn_config
88      batchnorm_args = {"create_scale": True, "create_offset": True}
89      batchnorm_args.update(bn_config)
90      if self._use_projection:
91        self._proj_conv = conv.Conv2D(
92            output_channels=channels,
93            kernel_shape=1,
94            stride=stride,
95            with_bias=False,
96            padding=pad.same,
97            name="shortcut_conv")
98      self._conv_0 = conv.Conv2D(
99          output_channels=channels // 4,
</span>100          kernel_shape=1,
101          stride=1,
102          with_bias=False,
103          padding=pad.same,
104          name="conv_0")
105      self._bn_0 = batch_norm.BatchNorm(name="batchnorm_0", **batchnorm_args)
106      self._conv_1 = conv.Conv2D(
107          output_channels=channels // 4,
108          kernel_shape=3,
109          stride=stride,
110          with_bias=False,
111          padding=pad.same,
112          name="conv_1")
113      self._bn_1 = batch_norm.BatchNorm(name="batchnorm_1", **batchnorm_args)
114      self._conv_2 = conv.Conv2D(
115          output_channels=channels,
116          kernel_shape=1,
117          stride=1,
118          with_bias=False,
119          padding=pad.same,
120          name="conv_2")
121      self._bn_2 = batch_norm.BatchNorm(name="batchnorm_2", **batchnorm_args)
122    def __call__(self, inputs, is_training):
123      net = inputs
124      shortcut = inputs
125      for i, (conv_i, bn_i) in enumerate(((self._conv_0, self._bn_0),
126                                          (self._conv_1, self._bn_1),
127                                          (self._conv_2, self._bn_2))):
128        net = bn_i(net, is_training=is_training)
129        net = tf.nn.relu(net)
130        if i == 0 and self._use_projection:
131          shortcut = self._proj_conv(net)
132        net = conv_i(net)
133      return net + shortcut
134  class BlockGroup(base.Module):
135    def __init__(self,
136                 channels: int,
137                 num_blocks: int,
138                 stride: Union[int, Sequence[int]],
139                 bn_config: Mapping[str, float],
140                 resnet_v2: bool = False,
141                 name: Optional[str] = None):
142      super().__init__(name=name)
143      self._channels = channels
144      self._num_blocks = num_blocks
145      self._stride = stride
146      self._bn_config = bn_config
147      if resnet_v2:
148        bottle_neck_block = BottleNeckBlockV2
149      else:
150        bottle_neck_block = BottleNeckBlockV1
151      self._blocks = []
152      for id_block in range(num_blocks):
153        self._blocks.append(
154            bottle_neck_block(
155                channels=channels,
156                stride=stride if id_block == 0 else 1,
157                use_projection=(id_block == 0),
158                bn_config=bn_config,
159                name="block_%d" % (id_block)))
160    def __call__(self, inputs, is_training):
161      net = inputs
162      for block in self._blocks:
163        net = block(net, is_training=is_training)
164      return net
165  class ResNet(base.Module):
166    def __init__(self,
167                 blocks_per_group_list: Sequence[int],
168                 num_classes: int,
169                 bn_config: Optional[Mapping[str, float]] = None,
170                 resnet_v2: bool = False,
171                 channels_per_group_list: Sequence[int] = (256, 512, 1024, 2048),
172                 name: Optional[str] = None):
173      super().__init__(name=name)
174      if bn_config is None:
175        bn_config = {"decay_rate": 0.9, "eps": 1e-5}
176      self._bn_config = bn_config
177      self._resnet_v2 = resnet_v2
178      if len(blocks_per_group_list) != 4:
179        raise ValueError(
180            "`blocks_per_group_list` must be of length 4 not {}".format(
181                len(blocks_per_group_list)))
182      self._blocks_per_group_list = blocks_per_group_list
183      if len(channels_per_group_list) != 4:
184        raise ValueError(
185            "`channels_per_group_list` must be of length 4 not {}".format(
186                len(channels_per_group_list)))
187      self._channels_per_group_list = channels_per_group_list
188      self._initial_conv = conv.Conv2D(
189          output_channels=64,
190          kernel_shape=7,
191          stride=2,
192          with_bias=False,
193          padding=pad.same,
194          name="initial_conv")
195      if not self._resnet_v2:
196        self._initial_batchnorm = batch_norm.BatchNorm(
197            create_scale=True,
198            create_offset=True,
199            name="initial_batchnorm",
200            **bn_config)
201      self._block_groups = []
202      strides = [1, 2, 2, 2]
203      for i in range(4):
204        self._block_groups.append(
205            BlockGroup(
206                channels=self._channels_per_group_list[i],
207                num_blocks=self._blocks_per_group_list[i],
208                stride=strides[i],
209                bn_config=bn_config,
210                resnet_v2=resnet_v2,
211                name="block_group_%d" % (i)))
212      if self._resnet_v2:
213        self._final_batchnorm = batch_norm.BatchNorm(
214            create_scale=True,
215            create_offset=True,
216            name="final_batchnorm",
217            **bn_config)
218      self._logits = linear.Linear(
219          output_size=num_classes, w_init=initializers.Zeros(), name="logits")
220    def __call__(self, inputs, is_training):
221      net = inputs
222      net = self._initial_conv(net)
223      if not self._resnet_v2:
224        net = self._initial_batchnorm(net, is_training=is_training)
225        net = tf.nn.relu(net)
226      net = tf.nn.max_pool2d(
227          net, ksize=3, strides=2, padding="SAME", name="initial_max_pool")
228      for block_group in self._block_groups:
229        net = block_group(net, is_training)
230      if self._resnet_v2:
231        net = self._final_batchnorm(net, is_training=is_training)
232        net = tf.nn.relu(net)
233      net = tf.reduce_mean(net, axis=[1, 2], name="final_avg_pool")
234      return self._logits(net)
235  class ResNet50(ResNet):
236    def __init__(self,
237                 num_classes: int,
238                 bn_config: Optional[Mapping[str, float]] = None,
239                 resnet_v2: bool = False,
240                 name: Optional[str] = None):
241      super().__init__([3, 4, 6, 3],
242                       num_classes=num_classes,
243                       bn_config=bn_config,
244                       resnet_v2=resnet_v2,
245                       name=name)
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-resnet_7.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-resnet_7.py</div>
                </div>
                <div class="column column_space"><pre><code>14                 bn_config: Mapping[str, float],
15                 name: Optional[str] = None):
16      super().__init__(name=name)
17      self._channels = channels
18      self._stride = stride
19      self._use_projection = use_projection
20      self._bn_config = bn_config
21      batchnorm_args = {"create_scale": True, "create_offset": True}
22      batchnorm_args.update(bn_config)
23      if self._use_projection:
24        self._proj_conv = conv.Conv2D(
25            output_channels=channels,
26            kernel_shape=1,
27            stride=stride,
28            with_bias=False,
29            padding=pad.same,
30            name="shortcut_conv")
31        self._proj_batchnorm = batch_norm.BatchNorm(
32            name="shortcut_batchnorm", **batchnorm_args)
</pre></code></div>
                <div class="column column_space"><pre><code>81                 bn_config: Mapping[str, float],
82                 name: Optional[str] = None):
83      super().__init__(name=name)
84      self._channels = channels
85      self._stride = stride
86      self._use_projection = use_projection
87      self._bn_config = bn_config
88      batchnorm_args = {"create_scale": True, "create_offset": True}
89      batchnorm_args.update(bn_config)
90      if self._use_projection:
91        self._proj_conv = conv.Conv2D(
92            output_channels=channels,
93            kernel_shape=1,
94            stride=stride,
95            with_bias=False,
96            padding=pad.same,
97            name="shortcut_conv")
98      self._conv_0 = conv.Conv2D(
99          output_channels=channels // 4,
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    