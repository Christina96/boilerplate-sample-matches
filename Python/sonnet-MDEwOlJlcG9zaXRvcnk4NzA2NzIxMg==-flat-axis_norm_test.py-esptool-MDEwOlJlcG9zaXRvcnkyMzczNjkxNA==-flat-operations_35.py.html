
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 9.31470392548237%, Tokens: 9</h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-axis_norm_test.py</h3>
            <pre><code>1  from absl.testing import parameterized
2  import numpy as np
3  from sonnet.src import axis_norm
4  from sonnet.src import initializers
5  from sonnet.src import test_utils
6  import tensorflow as tf
7  class LayerNormTest(test_utils.TestCase, parameterized.TestCase):
8    def testSimpleCase(self):
9      layer = axis_norm.LayerNorm([1, 2], create_scale=False, create_offset=False)
10      inputs = tf.ones([2, 3, 3, 5])
11      outputs = layer(inputs).numpy()
12      for x in np.nditer(outputs):
13        self.assertEqual(x, 0.0)
14    def testSimpleCaseVar(self):
15      layer = axis_norm.LayerNorm([1, 2],
16                                  create_scale=True,
17                                  create_offset=True,
18                                  scale_init=initializers.Constant(0.5),
19                                  offset_init=initializers.Constant(2.0))
20      inputs = tf.ones([2, 3, 3, 5])
21      outputs = layer(inputs).numpy()
22      for x in np.nditer(outputs):
23        self.assertEqual(x, 2.0)
24    def testSimpleCaseNCHWVar(self):
25      layer = axis_norm.LayerNorm([1, 2],
26                                  create_scale=True,
27                                  create_offset=True,
28                                  scale_init=initializers.Constant(0.5),
29                                  offset_init=initializers.Constant(2.0),
30                                  data_format="NCHW")
31      inputs = tf.ones([2, 5, 3, 3])
32      outputs = layer(inputs).numpy()
33      for x in np.nditer(outputs):
34        self.assertEqual(x, 2.0)
35    def testDataFormatAgnosticVar(self):
36      c_last_layer = axis_norm.LayerNorm([1, 2],
37                                         create_scale=True,
38                                         create_offset=True)
39      c_first_layer = axis_norm.LayerNorm([2, 3],
40                                          create_scale=True,
41                                          create_offset=True,
42                                          data_format="NCHW")
43      inputs = tf.random.uniform([3, 4, 4, 5], 0, 10)
44      c_last_output = c_last_layer(inputs)
45      inputs = tf.transpose(inputs, [0, 3, 1, 2])
46      c_first_output = c_first_layer(inputs)
47      c_first_output = tf.transpose(c_first_output, [0, 2, 3, 1])
48      self.assertAllClose(c_last_output.numpy(), c_first_output.numpy())
49    def testSimpleCaseTensor(self):
50      layer = axis_norm.LayerNorm([1, 2], create_scale=False, create_offset=False)
51      inputs = tf.ones([2, 3, 3, 5])
52      scale = tf.constant(0.5, shape=(5,))
53      offset = tf.constant(2.0, shape=(5,))
54      outputs = layer(inputs, scale, offset).numpy()
55      for x in np.nditer(outputs):
56        self.assertEqual(x, 2.0)
57    def testSimpleCaseNCHWTensor(self):
58      layer = axis_norm.LayerNorm([1, 2],
59                                  data_format="NCHW",
60                                  create_scale=False,
61                                  create_offset=False)
62      inputs = tf.ones([2, 5, 3, 3])
63      scale = tf.constant(0.5, shape=(5, 1, 1))
64      offset = tf.constant(2.0, shape=(5, 1, 1))
65      outputs = layer(inputs, scale, offset).numpy()
66      for x in np.nditer(outputs):
67        self.assertEqual(x, 2.0)
68    def testDataFormatAgnosticTensor(self):
69      c_last_layer = axis_norm.LayerNorm([1, 2],
70                                         create_scale=False,
71                                         create_offset=False)
72      c_first_layer = axis_norm.LayerNorm([2, 3],
73                                          data_format="NCHW",
74                                          create_scale=False,
75                                          create_offset=False)
76      inputs = tf.random.uniform([3, 4, 4, 5], 0, 10)
77      scale = tf.random.normal((5,), mean=1.0)
78      offset = tf.random.normal((5,))
79      c_last_output = c_last_layer(inputs, scale, offset)
80      inputs = tf.transpose(inputs, [0, 3, 1, 2])
81      scale = tf.reshape(scale, (5, 1, 1))
82      offset = tf.reshape(offset, (5, 1, 1))
83      c_first_output = c_first_layer(inputs, scale, offset)
84      c_first_output = tf.transpose(c_first_output, [0, 2, 3, 1])
85      self.assertAllClose(c_last_output.numpy(), c_first_output.numpy())
86    @parameterized.parameters("NHW", "HWC", "channel_last")
87    def testInvalidDataFormat(self, data_format):
88      with self.assertRaisesRegex(
89          ValueError,
90          "Unable to extract channel information from '{}'.".format(data_format)):
91        axis_norm.LayerNorm(
92            3, data_format=data_format, create_scale=False, create_offset=False)
93    @parameterized.parameters("NCHW", "NCW", "channels_first")
94    def testValidDataFormatChannelsFirst(self, data_format):
95      test = axis_norm.LayerNorm(
96          3, data_format=data_format, create_scale=False, create_offset=False)
97      self.assertEqual(test._channel_index, 1)
98    @parameterized.parameters("NHWC", "NWC", "channels_last")
99    def testValidDataFormatChannelsLast(self, data_format):
100      test = axis_norm.LayerNorm(
101          3, data_format=data_format, create_scale=False, create_offset=False)
102      self.assertEqual(test._channel_index, -1)
103    @parameterized.named_parameters(("String", "foo"), ("ListString", ["foo"]))
104    def testInvalidAxis(self, axis):
105      with self.assertRaisesRegex(
106          ValueError, "`axis` should be an int, slice or iterable of ints."):
107        axis_norm.LayerNorm(axis, create_scale=False, create_offset=False)
108    def testNoScaleAndInitProvided(self):
109      with self.assertRaisesRegex(
110          ValueError, "Cannot set `scale_init` if `create_scale=False`."):
111        axis_norm.LayerNorm(
112            3,
113            create_scale=False,
114            create_offset=True,
115            scale_init=initializers.Ones())
116    def testNoOffsetBetaInitProvided(self):
117      with self.assertRaisesRegex(
118          ValueError, "Cannot set `offset_init` if `create_offset=False`."):
119        axis_norm.LayerNorm(
120            3,
121            create_scale=True,
122            create_offset=False,
123            offset_init=initializers.Zeros())
124    def testCreateScaleAndScaleProvided(self):
125      layer = axis_norm.LayerNorm([2], create_scale=True, create_offset=False)
126      with self.assertRaisesRegex(
127          ValueError, "Cannot pass `scale` at call time if `create_scale=True`."):
128        layer(tf.ones([2, 3, 4]), scale=tf.ones([4]))
129    def testCreateOffsetAndOffsetProvided(self):
130      layer = axis_norm.LayerNorm([2], create_offset=True, create_scale=False)
131      with self.assertRaisesRegex(
132          ValueError,
133          "Cannot pass `offset` at call time if `create_offset=True`."):
134        layer(tf.ones([2, 3, 4]), offset=tf.ones([4]))
135    def testSliceAxis(self):
136      slice_layer = axis_norm.LayerNorm(
137          slice(1, -1), create_scale=False, create_offset=False)
138      axis_layer = axis_norm.LayerNorm((1, 2),
139                                       create_scale=False,
140                                       create_offset=False)
141      inputs = tf.random.uniform([3, 4, 4, 5], 0, 10)
142      scale = tf.random.normal((5,), mean=1.0)
143      offset = tf.random.normal((5,))
144      slice_outputs = slice_layer(inputs, scale, offset)
145      axis_outputs = axis_layer(inputs, scale, offset)
146      self.assertAllEqual(slice_outputs.numpy(), axis_outputs.numpy())
147    def testRankChanges(self):
148      layer = axis_norm.LayerNorm((1, 2), create_scale=False, create_offset=False)
149      inputs = tf.ones([2, 3, 3, 5])
150      scale = tf.constant(0.5, shape=(5,))
151      offset = tf.constant(2.0, shape=(5,))
152      layer(inputs, scale, offset)
153      with self.assertRaisesRegex(
154          ValueError,
155          "The rank of the inputs cannot change between calls, the original"):
156        layer(tf.ones([2, 3, 3, 4, 5]), scale, offset)
157    def testWorksWithFunction(self):
158      layer = axis_norm.LayerNorm((1, 2), create_scale=False, create_offset=False)
159      function_layer = tf.function(layer)
160      inputs = tf.ones([2, 3, 3, 5])
161      scale = tf.constant(0.5, shape=(5,))
162      offset = tf.constant(2.0, shape=(5,))
163      outputs = layer(inputs, scale, offset)
164      function_outputs = function_layer(inputs, scale, offset)
165      self.assertAllEqual(outputs.numpy(), function_outputs.numpy())
166    def testShapeAgnostic(self):
167      layer = axis_norm.LayerNorm((1, 2), create_scale=False, create_offset=False)
168      inputs_spec = tf.TensorSpec([None, None, None, None], dtype=tf.float32)
169      params_spec = tf.TensorSpec([None], dtype=tf.float32)
170      function_layer = tf.function(layer).get_concrete_function(
171          inputs_spec, params_spec, params_spec)
172      scale = tf.constant(0.5, shape=(5,))
173      offset = tf.constant(2.0, shape=(5,))
174      outputs = function_layer(tf.ones([2, 3, 3, 5]), scale, offset)
175      self.assertEqual(outputs.shape, [2, 3, 3, 5])
176      for x in np.nditer(outputs):
177        self.assertEqual(x, 2.0)
178      scale = tf.constant(0.5, shape=(3,))
179      offset = tf.constant(2.0, shape=(3,))
180      outputs = function_layer(tf.ones([3, 4, 6, 3]), scale, offset)
181      self.assertEqual(outputs.shape, [3, 4, 6, 3])
182      for x in np.nditer(outputs):
183        self.assertEqual(x, 2.0)
184    def test5DDataFormatAgnostic(self):
185      c_last_layer = axis_norm.LayerNorm([1, 2, 3],
186                                         create_scale=False,
187                                         create_offset=False)
188      c_first_layer = axis_norm.LayerNorm([2, 3, 4],
189                                          create_scale=False,
190                                          create_offset=False,
191                                          data_format="NCDHW")
192      inputs = tf.random.uniform([3, 4, 4, 4, 5], 0, 10)
193      scale = tf.random.normal((5,), mean=1.0)
194      offset = tf.random.normal((5,))
195      c_last_output = c_last_layer(inputs, scale, offset)
196      inputs = tf.transpose(inputs, [0, 4, 1, 2, 3])
197      scale = tf.reshape(scale, [-1, 1, 1, 1])
198      offset = tf.reshape(offset, [-1, 1, 1, 1])
199      c_first_output = c_first_layer(inputs, scale, offset)
200      c_first_output = tf.transpose(c_first_output, [0, 2, 3, 4, 1])
201      self.assertAllClose(
202          c_last_output.numpy(), c_first_output.numpy(), atol=1e-5, rtol=1e-5)
203    def test3DDataFormatAgnostic(self):
204      c_last_layer = axis_norm.LayerNorm([1],
205                                         create_scale=False,
206                                         create_offset=False)
207      c_first_layer = axis_norm.LayerNorm([2],
208                                          create_scale=False,
209                                          create_offset=False,
210                                          data_format="NCW")
211      inputs = tf.random.uniform([3, 4, 5], 0, 10)
212      scale = tf.random.normal((5,), mean=1.0)
213      offset = tf.random.normal((5,))
214      c_last_output = c_last_layer(inputs, scale, offset)
215      inputs = tf.transpose(inputs, [0, 2, 1])
216      scale = tf.reshape(scale, [-1, 1])
217      offset = tf.reshape(offset, [-1, 1])
218      c_first_output = c_first_layer(inputs, scale, offset)
219      c_first_output = tf.transpose(c_first_output, [0, 2, 1])
220      self.assertAllClose(
221          c_last_output.numpy(), c_first_output.numpy(), atol=1e-5, rtol=1e-5)
222    def testInstanceNormCorrectAxis(self):
<span onclick='openModal()' class='match'>223      layer = axis_norm.InstanceNorm(create_scale=True, create_offset=True)
224      inputs = tf.ones([3, 4, 5, 6])
225      layer(inputs)
</span>226      self.assertEqual(layer._axis, (1, 2))
227    def testInstanceNormCorrectNCW(self):
228      layer = axis_norm.InstanceNorm(
229          create_scale=True, create_offset=True, data_format="channels_first")
230      inputs = tf.ones([3, 4, 5, 6])
231      layer(inputs)
232      self.assertEqual(layer._axis, (2, 3))
233  if __name__ == "__main__":
234    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-operations_35.py</h3>
            <pre><code>1  import argparse
2  import io
3  import os  # noqa: F401. It is used in IDF scripts
4  import traceback
5  import espsecure
6  import esptool
7  from . import fields
8  from .. import util
9  from ..base_operations import (
10      add_common_commands,
11      add_force_write_always,
12      add_show_sensitive_info_option,
13      burn_bit,
14      burn_block_data,
15      burn_efuse,
16      check_error,
17      dump,
18      read_protect_efuse,
19      summary,
20      write_protect_efuse,
21  )
22  def protect_options(p):
23      p.add_argument(
24          "--no-write-protect",
25          help="Disable write-protecting of the key. The key remains writable. "
26          "(The keys use the RS coding scheme that does not support post-write "
27          "data changes. Forced write can damage RS encoding bits.) "
28          "The write-protecting of keypurposes does not depend on the option, "
29          "it will be set anyway.",
30          action="store_true",
31      )
32      p.add_argument(
33          "--no-read-protect",
34          help="Disable read-protecting of the key. The key remains readable software."
35          "The key with keypurpose[USER, RESERVED and *_DIGEST] "
36          "will remain readable anyway. "
37          "For the rest keypurposes the read-protection will be defined the option "
38          "(Read-protect by default).",
39          action="store_true",
40      )
41  def add_commands(subparsers, efuses):
42      add_common_commands(subparsers, efuses)
43      burn_key = subparsers.add_parser(
44          "burn_key", help="Burn the key block with the specified name"
45      )
46      protect_options(burn_key)
47      add_force_write_always(burn_key)
48      add_show_sensitive_info_option(burn_key)
49      burn_key.add_argument(
50          "block",
51          help="Key block to burn",
52          action="append",
53          choices=efuses.BLOCKS_FOR_KEYS,
54      )
<span onclick='openModal()' class='match'>55      burn_key.add_argument(
56          "keyfile",
57          help="File containing 256 bits of binary key data",
58          action="append",
59          type=argparse.FileType("rb"),
60      )
61      burn_key.add_argument(
</span>62          "keypurpose",
63          help="Purpose to set.",
64          action="append",
65          choices=fields.EfuseKeyPurposeField.KEY_PURPOSES_NAME,
66      )
67      for _ in efuses.BLOCKS_FOR_KEYS:
68          burn_key.add_argument(
69              "block",
70              help="Key block to burn",
71              nargs="?",
72              action="append",
73              metavar="BLOCK",
74              choices=efuses.BLOCKS_FOR_KEYS,
75          )
76          burn_key.add_argument(
77              "keyfile",
78              help="File containing 256 bits of binary key data",
79              nargs="?",
80              action="append",
81              metavar="KEYFILE",
82              type=argparse.FileType("rb"),
83          )
84          burn_key.add_argument(
85              "keypurpose",
86              help="Purpose to set.",
87              nargs="?",
88              action="append",
89              metavar="KEYPURPOSE",
90              choices=fields.EfuseKeyPurposeField.KEY_PURPOSES_NAME,
91          )
92      burn_key_digest = subparsers.add_parser(
93          "burn_key_digest",
94          help="Parse a RSA public key and burn the digest to key efuse block",
95      )
96      protect_options(burn_key_digest)
97      add_force_write_always(burn_key_digest)
98      add_show_sensitive_info_option(burn_key_digest)
99      burn_key_digest.add_argument(
100          "block",
101          help="Key block to burn",
102          action="append",
103          choices=efuses.BLOCKS_FOR_KEYS,
104      )
105      burn_key_digest.add_argument(
106          "keyfile",
107          help="Key file to digest (PEM format)",
108          action="append",
109          type=argparse.FileType("rb"),
110      )
111      burn_key_digest.add_argument(
112          "keypurpose",
113          help="Purpose to set.",
114          action="append",
115          choices=fields.EfuseKeyPurposeField.DIGEST_KEY_PURPOSES,
116      )
117      for _ in efuses.BLOCKS_FOR_KEYS:
118          burn_key_digest.add_argument(
119              "block",
120              help="Key block to burn",
121              nargs="?",
122              action="append",
123              metavar="BLOCK",
124              choices=efuses.BLOCKS_FOR_KEYS,
125          )
126          burn_key_digest.add_argument(
127              "keyfile",
128              help="Key file to digest (PEM format)",
129              nargs="?",
130              action="append",
131              metavar="KEYFILE",
132              type=argparse.FileType("rb"),
133          )
134          burn_key_digest.add_argument(
135              "keypurpose",
136              help="Purpose to set.",
137              nargs="?",
138              action="append",
139              metavar="KEYPURPOSE",
140              choices=fields.EfuseKeyPurposeField.DIGEST_KEY_PURPOSES,
141          )
142      p = subparsers.add_parser(
143          "set_flash_voltage",
144          help="Permanently set the internal flash voltage regulator "
145          "to either 1.8V, 3.3V or OFF. This means GPIO45 can be high or low at reset "
146          "without changing the flash voltage.",
147      )
148      p.add_argument("voltage", help="Voltage selection", choices=["1.8V", "3.3V", "OFF"])
149      p = subparsers.add_parser(
150          "burn_custom_mac", help="Burn a 48-bit Custom MAC Address to EFUSE BLOCK3."
151      )
152      p.add_argument(
153          "mac",
154          help="Custom MAC Address to burn given in hexadecimal format with "
155          "bytes separated by colons (e.g. AA:CD:EF:01:02:03).",
156          type=fields.base_fields.CheckArgValue(efuses, "CUSTOM_MAC"),
157      )
158      add_force_write_always(p)
159      p = subparsers.add_parser("get_custom_mac", help="Prints the Custom MAC Address.")
160  def burn_custom_mac(esp, efuses, args):
161      efuses["CUSTOM_MAC"].save(args.mac)
162      if not efuses.burn_all(check_batch_mode=True):
163          return
164      get_custom_mac(esp, efuses, args)
165      print("Successful")
166  def get_custom_mac(esp, efuses, args):
167      print("Custom MAC Address: {}".format(efuses["CUSTOM_MAC"].get()))
168  def set_flash_voltage(esp, efuses, args):
169      sdio_force = efuses["VDD_SPI_FORCE"]
170      sdio_tieh = efuses["VDD_SPI_TIEH"]
171      sdio_reg = efuses["VDD_SPI_XPD"]
172      if args.voltage == "OFF" and sdio_reg.get() != 0:
173          raise esptool.FatalError(
174              "Can't set flash regulator to OFF as VDD_SPI_XPD efuse is already burned"
175          )
176      if args.voltage == "1.8V" and sdio_tieh.get() != 0:
177          raise esptool.FatalError(
178              "Can't set regulator to 1.8V is VDD_SPI_TIEH efuse is already burned"
179          )
180      if args.voltage == "OFF":
181          msg = "Disable internal flash voltage regulator (VDD_SPI). "
182          "SPI flash will need to be powered from an external source.\n"
183          "The following efuse is burned: VDD_SPI_FORCE.\n"
184          "It is possible to later re-enable the internal regulator (%s) " % (
185              "to 3.3V" if sdio_tieh.get() != 0 else "to 1.8V or 3.3V"
186          )
187          "by burning an additional efuse"
188      elif args.voltage == "1.8V":
189          msg = "Set internal flash voltage regulator (VDD_SPI) to 1.8V.\n"
190          "The following efuses are burned: VDD_SPI_FORCE, VDD_SPI_XPD.\n"
191          "It is possible to later increase the voltage to 3.3V (permanently) "
192          "by burning additional efuse VDD_SPI_TIEH"
193      elif args.voltage == "3.3V":
194          msg = "Enable internal flash voltage regulator (VDD_SPI) to 3.3V.\n"
195          "The following efuses are burned: VDD_SPI_FORCE, VDD_SPI_XPD, VDD_SPI_TIEH."
196      print(msg)
197      sdio_force.save(1)  # Disable GPIO45
198      if args.voltage != "OFF":
199          sdio_reg.save(1)  # Enable internal regulator
200      if args.voltage == "3.3V":
201          sdio_tieh.save(1)
202      print("VDD_SPI setting complete.")
203      if not efuses.burn_all(check_batch_mode=True):
204          return
205      print("Successful")
206  def adc_info(esp, efuses, args):
207      print("")
208      if efuses["BLK_VERSION_MAJOR"].get() == 1:
209          print("Temperature Sensor Calibration = {}C".format(efuses["TEMP_SENSOR_CAL"].get()))
210          print("")
211          print("ADC1 readings stored in efuse BLOCK2:")
212          print("    MODE0 D1 reading  (250mV):  {}".format(efuses["ADC1_MODE0_D1"].get()))
213          print("    MODE0 D2 reading  (600mV):  {}".format(efuses["ADC1_MODE0_D2"].get()))
214          print("    MODE1 D1 reading  (250mV):  {}".format(efuses["ADC1_MODE1_D1"].get()))
215          print("    MODE1 D2 reading  (800mV):  {}".format(efuses["ADC1_MODE1_D2"].get()))
216          print("    MODE2 D1 reading  (250mV):  {}".format(efuses["ADC1_MODE2_D1"].get()))
217          print("    MODE2 D2 reading  (1000mV): {}".format(efuses["ADC1_MODE2_D2"].get()))
218          print("    MODE3 D1 reading  (250mV):  {}".format(efuses["ADC1_MODE3_D1"].get()))
219          print("    MODE3 D2 reading  (2000mV): {}".format(efuses["ADC1_MODE3_D2"].get()))
220          print("")
221          print("ADC2 readings stored in efuse BLOCK2:")
222          print("    MODE0 D1 reading  (250mV):  {}".format(efuses["ADC2_MODE0_D1"].get()))
223          print("    MODE0 D2 reading  (600mV):  {}".format(efuses["ADC2_MODE0_D2"].get()))
224          print("    MODE1 D1 reading  (250mV):  {}".format(efuses["ADC2_MODE1_D1"].get()))
225          print("    MODE1 D2 reading  (800mV):  {}".format(efuses["ADC2_MODE1_D2"].get()))
226          print("    MODE2 D1 reading  (250mV):  {}".format(efuses["ADC2_MODE2_D1"].get()))
227          print("    MODE2 D2 reading  (1000mV): {}".format(efuses["ADC2_MODE2_D2"].get()))
228          print("    MODE3 D1 reading  (250mV):  {}".format(efuses["ADC2_MODE3_D1"].get()))
229          print("    MODE3 D2 reading  (2000mV): {}".format(efuses["ADC2_MODE3_D2"].get()))
230      else:
231          print("BLK_VERSION_MAJOR = {}".format(efuses["BLK_VERSION_MAJOR"].get_meaning()))
232  def key_block_is_unused(block, key_purpose_block):
233      if not block.is_readable() or not block.is_writeable():
234          return False
235      if key_purpose_block.get() != "USER" or not key_purpose_block.is_writeable():
236          return False
237      if not block.get_bitstring().all(False):
238          return False
239      return True
240  def get_next_key_block(efuses, current_key_block, block_name_list):
241      key_blocks = [b for b in efuses.blocks if b.key_purpose_name]
242      start = key_blocks.index(current_key_block)
243      key_blocks = key_blocks[start:] + key_blocks[0:start]
244      key_blocks = [b for b in key_blocks if b.name not in block_name_list]
245      for block in key_blocks:
246          key_purpose_block = efuses[block.key_purpose_name]
247          if key_block_is_unused(block, key_purpose_block):
248              return block
249      return None
250  def split_512_bit_key(efuses, block_name_list, datafile_list, keypurpose_list):
251      i = keypurpose_list.index("XTS_AES_256_KEY")
252      block_name = block_name_list[i]
253      block_num = efuses.get_index_block_by_name(block_name)
254      block = efuses.blocks[block_num]
255      data = datafile_list[i].read()
256      if len(data) != 64:
257          raise esptool.FatalError(
258              "Incorrect key file size %d, XTS_AES_256_KEY should be 64 bytes" % len(data)
259          )
260      key_block_2 = get_next_key_block(efuses, block, block_name_list)
261      if not key_block_2:
262          raise esptool.FatalError("XTS_AES_256_KEY requires two free keyblocks")
263      keypurpose_list.append("XTS_AES_256_KEY_1")
264      datafile_list.append(io.BytesIO(data[:32]))
265      block_name_list.append(block_name)
266      keypurpose_list.append("XTS_AES_256_KEY_2")
267      datafile_list.append(io.BytesIO(data[32:]))
268      block_name_list.append(key_block_2.name)
269      keypurpose_list.pop(i)
270      datafile_list.pop(i)
271      block_name_list.pop(i)
272  def burn_key(esp, efuses, args, digest=None):
273      if digest is None:
274          datafile_list = args.keyfile[
275              0 : len([name for name in args.keyfile if name is not None]) :
276          ]
277      else:
278          datafile_list = digest[0 : len([name for name in digest if name is not None]) :]
279      efuses.force_write_always = args.force_write_always
280      block_name_list = args.block[
281          0 : len([name for name in args.block if name is not None]) :
282      ]
283      keypurpose_list = args.keypurpose[
284          0 : len([name for name in args.keypurpose if name is not None]) :
285      ]
286      if "XTS_AES_256_KEY" in keypurpose_list:
287          split_512_bit_key(efuses, block_name_list, datafile_list, keypurpose_list)
288      util.check_duplicate_name_in_list(block_name_list)
289      if len(block_name_list) != len(datafile_list) or len(block_name_list) != len(
290          keypurpose_list
291      ):
292          raise esptool.FatalError(
293              "The number of blocks (%d), datafile (%d) and keypurpose (%d) "
294              "should be the same."
295              % (len(block_name_list), len(datafile_list), len(keypurpose_list))
296          )
297      print("Burn keys to blocks:")
298      for block_name, datafile, keypurpose in zip(
299          block_name_list, datafile_list, keypurpose_list
300      ):
301          efuse = None
302          for block in efuses.blocks:
303              if block_name == block.name or block_name in block.alias:
304                  efuse = efuses[block.name]
305          if efuse is None:
306              raise esptool.FatalError("Unknown block name - %s" % (block_name))
307          num_bytes = efuse.bit_len // 8
308          block_num = efuses.get_index_block_by_name(block_name)
309          block = efuses.blocks[block_num]
310          if digest is None:
311              data = datafile.read()
312          else:
313              data = datafile
314          print(" - %s" % (efuse.name), end=" ")
315          revers_msg = None
316          if efuses[block.key_purpose_name].need_reverse(keypurpose):
317              revers_msg = "\tReversing byte order for AES-XTS hardware peripheral"
318              data = data[::-1]
319          print(
320              "-> [{}]".format(
321                  util.hexify(data, " ")
322                  if args.show_sensitive_info
323                  else " ".join(["??"] * len(data))
324              )
325          )
326          if revers_msg:
327              print(revers_msg)
328          if len(data) != num_bytes:
329              raise esptool.FatalError(
330                  "Incorrect key file size %d. Key file must be %d bytes (%d bits) "
331                  "of raw binary key data." % (len(data), num_bytes, num_bytes * 8)
332              )
333          if efuses[block.key_purpose_name].need_rd_protect(keypurpose):
334              read_protect = False if args.no_read_protect else True
335          else:
336              read_protect = False
337          write_protect = not args.no_write_protect
338          efuse.save(data)
339          disable_wr_protect_key_purpose = False
340          if efuses[block.key_purpose_name].get() != keypurpose:
341              if efuses[block.key_purpose_name].is_writeable():
342                  print(
343                      "\t'%s': '%s' -> '%s'."
344                      % (
345                          block.key_purpose_name,
346                          efuses[block.key_purpose_name].get(),
347                          keypurpose,
348                      )
349                  )
350                  efuses[block.key_purpose_name].save(keypurpose)
351                  disable_wr_protect_key_purpose = True
352              else:
353                  raise esptool.FatalError(
354                      "It is not possible to change '%s' to '%s' because "
355                      "write protection bit is set."
356                      % (block.key_purpose_name, keypurpose)
357                  )
358          else:
359              print("\t'%s' is already '%s'." % (block.key_purpose_name, keypurpose))
360              if efuses[block.key_purpose_name].is_writeable():
361                  disable_wr_protect_key_purpose = True
362          if disable_wr_protect_key_purpose:
363              print("\tDisabling write to '%s'." % block.key_purpose_name)
364              efuses[block.key_purpose_name].disable_write()
365          if read_protect:
366              print("\tDisabling read to key block")
367              efuse.disable_read()
368          if write_protect:
369              print("\tDisabling write to key block")
370              efuse.disable_write()
371          print("")
372      if not write_protect:
373          print("Keys will remain writeable (due to --no-write-protect)")
374      if args.no_read_protect:
375          print("Keys will remain readable (due to --no-read-protect)")
376      if not efuses.burn_all(check_batch_mode=True):
377          return
378      print("Successful")
379  def burn_key_digest(esp, efuses, args):
380      digest_list = []
381      datafile_list = args.keyfile[
382          0 : len([name for name in args.keyfile if name is not None]) :
383      ]
384      block_list = args.block[
385          0 : len([block for block in args.block if block is not None]) :
386      ]
387      for block_name, datafile in zip(block_list, datafile_list):
388          efuse = None
389          for block in efuses.blocks:
390              if block_name == block.name or block_name in block.alias:
391                  efuse = efuses[block.name]
392          if efuse is None:
393              raise esptool.FatalError("Unknown block name - %s" % (block_name))
394          num_bytes = efuse.bit_len // 8
395          digest = espsecure._digest_sbv2_public_key(datafile)
396          if len(digest) != num_bytes:
397              raise esptool.FatalError(
398                  "Incorrect digest size %d. Digest must be %d bytes (%d bits) "
399                  "of raw binary key data." % (len(digest), num_bytes, num_bytes * 8)
400              )
401          digest_list.append(digest)
402      burn_key(esp, efuses, args, digest=digest_list)
403  def espefuse(esp, efuses, args, command):
404      parser = argparse.ArgumentParser()
405      subparsers = parser.add_subparsers(dest="operation")
406      add_commands(subparsers, efuses)
407      try:
408          cmd_line_args = parser.parse_args(command.split())
409      except SystemExit:
410          traceback.print_stack()
411          raise esptool.FatalError('"{}" - incorrect command'.format(command))
412      if cmd_line_args.operation == "execute_scripts":
413          configfiles = cmd_line_args.configfiles
414          index = cmd_line_args.index
415      vars(cmd_line_args).update(vars(args))
416      if cmd_line_args.operation == "execute_scripts":
417          cmd_line_args.configfiles = configfiles
418          cmd_line_args.index = index
419      if cmd_line_args.operation is None:
420          parser.print_help()
421          parser.exit(1)
422      operation_func = globals()[cmd_line_args.operation]
423      operation_func(esp, efuses, cmd_line_args)
424  def execute_scripts(esp, efuses, args):
425      efuses.batch_mode_cnt += 1
426      del args.operation
427      scripts = args.scripts
428      del args.scripts
429      for file in scripts:
430          with open(file.name, "r") as file:
431              exec(compile(file.read(), file.name, "exec"))
432      if args.debug:
433          for block in efuses.blocks:
434              data = block.get_bitstring(from_read=False)
435              block.print_block(data, "regs_for_burn", args.debug)
436      efuses.batch_mode_cnt -= 1
437      if not efuses.burn_all(check_batch_mode=True):
438          return
439      print("Successful")
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-axis_norm_test.py</div>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-operations_35.py</div>
                <div class="column column_space"><pre><code>223      layer = axis_norm.InstanceNorm(create_scale=True, create_offset=True)
224      inputs = tf.ones([3, 4, 5, 6])
225      layer(inputs)
</pre></code></div>
                <div class="column column_space"><pre><code>55      burn_key.add_argument(
56          "keyfile",
57          help="File containing 256 bits of binary key data",
58          action="append",
59          type=argparse.FileType("rb"),
60      )
61      burn_key.add_argument(
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    