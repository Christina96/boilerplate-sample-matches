
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 24, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-config.py</h3>
            <pre><code>1  from backbone import ResNetBackbone, VGGBackbone, ResNetBackboneGN, DarkNetBackbone
2  from math import sqrt
3  import torch
4  COLORS = ((244,  67,  54),
5            (233,  30,  99),
6            (156,  39, 176),
7            (103,  58, 183),
8            ( 63,  81, 181),
9            ( 33, 150, 243),
10            (  3, 169, 244),
11            (  0, 188, 212),
12            (  0, 150, 136),
13            ( 76, 175,  80),
14            (139, 195,  74),
15            (205, 220,  57),
16            (255, 235,  59),
17            (255, 193,   7),
18            (255, 152,   0),
19            (255,  87,  34),
20            (121,  85,  72),
21            (158, 158, 158),
22            ( 96, 125, 139))
23  MEANS = (103.94, 116.78, 123.68)
24  STD   = (57.38, 57.12, 58.40)
25  COCO_CLASSES = (&#x27;person&#x27;, &#x27;bicycle&#x27;, &#x27;car&#x27;, &#x27;motorcycle&#x27;, &#x27;airplane&#x27;, &#x27;bus&#x27;,
26                  &#x27;train&#x27;, &#x27;truck&#x27;, &#x27;boat&#x27;, &#x27;traffic light&#x27;, &#x27;fire hydrant&#x27;,
27                  &#x27;stop sign&#x27;, &#x27;parking meter&#x27;, &#x27;bench&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;, &#x27;dog&#x27;,
28                  &#x27;horse&#x27;, &#x27;sheep&#x27;, &#x27;cow&#x27;, &#x27;elephant&#x27;, &#x27;bear&#x27;, &#x27;zebra&#x27;, &#x27;giraffe&#x27;,
29                  &#x27;backpack&#x27;, &#x27;umbrella&#x27;, &#x27;handbag&#x27;, &#x27;tie&#x27;, &#x27;suitcase&#x27;, &#x27;frisbee&#x27;,
30                  &#x27;skis&#x27;, &#x27;snowboard&#x27;, &#x27;sports ball&#x27;, &#x27;kite&#x27;, &#x27;baseball bat&#x27;,
31                  &#x27;baseball glove&#x27;, &#x27;skateboard&#x27;, &#x27;surfboard&#x27;, &#x27;tennis racket&#x27;,
32                  &#x27;bottle&#x27;, &#x27;wine glass&#x27;, &#x27;cup&#x27;, &#x27;fork&#x27;, &#x27;knife&#x27;, &#x27;spoon&#x27;, &#x27;bowl&#x27;,
33                  &#x27;banana&#x27;, &#x27;apple&#x27;, &#x27;sandwich&#x27;, &#x27;orange&#x27;, &#x27;broccoli&#x27;, &#x27;carrot&#x27;,
34                  &#x27;hot dog&#x27;, &#x27;pizza&#x27;, &#x27;donut&#x27;, &#x27;cake&#x27;, &#x27;chair&#x27;, &#x27;couch&#x27;,
35                  &#x27;potted plant&#x27;, &#x27;bed&#x27;, &#x27;dining table&#x27;, &#x27;toilet&#x27;, &#x27;tv&#x27;, &#x27;laptop&#x27;,
36                  &#x27;mouse&#x27;, &#x27;remote&#x27;, &#x27;keyboard&#x27;, &#x27;cell phone&#x27;, &#x27;microwave&#x27;, &#x27;oven&#x27;,
37                  &#x27;toaster&#x27;, &#x27;sink&#x27;, &#x27;refrigerator&#x27;, &#x27;book&#x27;, &#x27;clock&#x27;, &#x27;vase&#x27;,
38                  &#x27;scissors&#x27;, &#x27;teddy bear&#x27;, &#x27;hair drier&#x27;, &#x27;toothbrush&#x27;)
39  COCO_LABEL_MAP = { 1:  1,  2:  2,  3:  3,  4:  4,  5:  5,  6:  6,  7:  7,  8:  8,
40                     9:  9, 10: 10, 11: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16,
41                    18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24,
42                    27: 25, 28: 26, 31: 27, 32: 28, 33: 29, 34: 30, 35: 31, 36: 32,
43                    37: 33, 38: 34, 39: 35, 40: 36, 41: 37, 42: 38, 43: 39, 44: 40,
44                    46: 41, 47: 42, 48: 43, 49: 44, 50: 45, 51: 46, 52: 47, 53: 48,
45                    54: 49, 55: 50, 56: 51, 57: 52, 58: 53, 59: 54, 60: 55, 61: 56,
46                    62: 57, 63: 58, 64: 59, 65: 60, 67: 61, 70: 62, 72: 63, 73: 64,
47                    74: 65, 75: 66, 76: 67, 77: 68, 78: 69, 79: 70, 80: 71, 81: 72,
48                    82: 73, 84: 74, 85: 75, 86: 76, 87: 77, 88: 78, 89: 79, 90: 80}
49  class Config(object):
50      def __init__(self, config_dict):
51          for key, val in config_dict.items():
52              self.__setattr__(key, val)
53      def copy(self, new_config_dict={}):
54          ret = Config(vars(self))
55          for key, val in new_config_dict.items():
56              ret.__setattr__(key, val)
57          return ret
58      def replace(self, new_config_dict):
59          if isinstance(new_config_dict, Config):
60              new_config_dict = vars(new_config_dict)
61          for key, val in new_config_dict.items():
62              self.__setattr__(key, val)
63      def print(self):
64          for k, v in vars(self).items():
65              print(k, &#x27; = &#x27;, v)
66  dataset_base = Config({
67      &#x27;name&#x27;: &#x27;Base Dataset&#x27;,
68      &#x27;train_images&#x27;: &#x27;./data/coco/images/&#x27;,
69      &#x27;train_info&#x27;:   &#x27;path_to_annotation_file&#x27;,
70      &#x27;valid_images&#x27;: &#x27;./data/coco/images/&#x27;,
71      &#x27;valid_info&#x27;:   &#x27;path_to_annotation_file&#x27;,
72      &#x27;has_gt&#x27;: True,
73      &#x27;class_names&#x27;: COCO_CLASSES,
74      &#x27;label_map&#x27;: None
75  })
76  coco2014_dataset = dataset_base.copy({
77      &#x27;name&#x27;: &#x27;COCO 2014&#x27;,
78      &#x27;train_info&#x27;: &#x27;./data/coco/annotations/instances_train2014.json&#x27;,
79      &#x27;valid_info&#x27;: &#x27;./data/coco/annotations/instances_val2014.json&#x27;,
80      &#x27;label_map&#x27;: COCO_LABEL_MAP
81  })
82  coco2017_dataset = dataset_base.copy({
83      &#x27;name&#x27;: &#x27;COCO 2017&#x27;,
84      &#x27;train_info&#x27;: &#x27;./data/coco/annotations/instances_train2017.json&#x27;,
85      &#x27;valid_info&#x27;: &#x27;./data/coco/annotations/instances_val2017.json&#x27;,
86      &#x27;label_map&#x27;: COCO_LABEL_MAP
87  })
88  coco2017_testdev_dataset = dataset_base.copy({
89      &#x27;name&#x27;: &#x27;COCO 2017 Test-Dev&#x27;,
90      &#x27;valid_info&#x27;: &#x27;./data/coco/annotations/image_info_test-dev2017.json&#x27;,
91      &#x27;has_gt&#x27;: False,
92      &#x27;label_map&#x27;: COCO_LABEL_MAP
93  })
94  PASCAL_CLASSES = (&quot;aeroplane&quot;, &quot;bicycle&quot;, &quot;bird&quot;, &quot;boat&quot;, &quot;bottle&quot;,
95                    &quot;bus&quot;, &quot;car&quot;, &quot;cat&quot;, &quot;chair&quot;, &quot;cow&quot;, &quot;diningtable&quot;,
96                    &quot;dog&quot;, &quot;horse&quot;, &quot;motorbike&quot;, &quot;person&quot;, &quot;pottedplant&quot;,
97                    &quot;sheep&quot;, &quot;sofa&quot;, &quot;train&quot;, &quot;tvmonitor&quot;)
98  pascal_sbd_dataset = dataset_base.copy({
99      &#x27;name&#x27;: &#x27;Pascal SBD 2012&#x27;,
100      &#x27;train_images&#x27;: &#x27;./data/sbd/img&#x27;,
101      &#x27;valid_images&#x27;: &#x27;./data/sbd/img&#x27;,
102      &#x27;train_info&#x27;: &#x27;./data/sbd/pascal_sbd_train.json&#x27;,
103      &#x27;valid_info&#x27;: &#x27;./data/sbd/pascal_sbd_val.json&#x27;,
104      &#x27;class_names&#x27;: PASCAL_CLASSES,
105  })
106  resnet_transform = Config({
107      &#x27;channel_order&#x27;: &#x27;RGB&#x27;,
108      &#x27;normalize&#x27;: True,
109      &#x27;subtract_means&#x27;: False,
110      &#x27;to_float&#x27;: False,
111  })
112  vgg_transform = Config({
113      &#x27;channel_order&#x27;: &#x27;RGB&#x27;,
114      &#x27;normalize&#x27;: False,
115      &#x27;subtract_means&#x27;: True,
116      &#x27;to_float&#x27;: False,
117  })
118  darknet_transform = Config({
119      &#x27;channel_order&#x27;: &#x27;RGB&#x27;,
120      &#x27;normalize&#x27;: False,
121      &#x27;subtract_means&#x27;: False,
122      &#x27;to_float&#x27;: True,
123  })
124  backbone_base = Config({
125      &#x27;name&#x27;: &#x27;Base Backbone&#x27;,
126      &#x27;path&#x27;: &#x27;path/to/pretrained/weights&#x27;,
127      &#x27;type&#x27;: object,
128      &#x27;args&#x27;: tuple(),
129      &#x27;transform&#x27;: resnet_transform,
130      &#x27;selected_layers&#x27;: list(),
131      &#x27;pred_scales&#x27;: list(),
132      &#x27;pred_aspect_ratios&#x27;: list(),
133      &#x27;use_pixel_scales&#x27;: False,
134      &#x27;preapply_sqrt&#x27;: True,
135      &#x27;use_square_anchors&#x27;: False,
136  })
137  resnet101_backbone = backbone_base.copy({
138      &#x27;name&#x27;: &#x27;ResNet101&#x27;,
139      &#x27;path&#x27;: &#x27;resnet101_reducedfc.pth&#x27;,
140      &#x27;type&#x27;: ResNetBackbone,
141      &#x27;args&#x27;: ([3, 4, 23, 3],),
142      &#x27;transform&#x27;: resnet_transform,
143      &#x27;selected_layers&#x27;: list(range(2, 8)),
144      &#x27;pred_scales&#x27;: [[1]]*6,
145      &#x27;pred_aspect_ratios&#x27;: [ [[0.66685089, 1.7073535, 0.87508774, 1.16524493, 0.49059086]] ] * 6,
146  })
147  resnet101_gn_backbone = backbone_base.copy({
148      &#x27;name&#x27;: &#x27;ResNet101_GN&#x27;,
149      &#x27;path&#x27;: &#x27;R-101-GN.pkl&#x27;,
150      &#x27;type&#x27;: ResNetBackboneGN,
151      &#x27;args&#x27;: ([3, 4, 23, 3],),
152      &#x27;transform&#x27;: resnet_transform,
153      &#x27;selected_layers&#x27;: list(range(2, 8)),
154      &#x27;pred_scales&#x27;: [[1]]*6,
155      &#x27;pred_aspect_ratios&#x27;: [ [[0.66685089, 1.7073535, 0.87508774, 1.16524493, 0.49059086]] ] * 6,
156  })
157  resnet101_dcn_inter3_backbone = resnet101_backbone.copy({
158      &#x27;name&#x27;: &#x27;ResNet101_DCN_Interval3&#x27;,
159      &#x27;args&#x27;: ([3, 4, 23, 3], [0, 4, 23, 3], 3),
160  })
161  resnet50_backbone = resnet101_backbone.copy({
162      &#x27;name&#x27;: &#x27;ResNet50&#x27;,
163      &#x27;path&#x27;: &#x27;resnet50-19c8e357.pth&#x27;,
164      &#x27;type&#x27;: ResNetBackbone,
165      &#x27;args&#x27;: ([3, 4, 6, 3],),
166      &#x27;transform&#x27;: resnet_transform,
167  })
168  resnet50_dcnv2_backbone = resnet50_backbone.copy({
169      &#x27;name&#x27;: &#x27;ResNet50_DCNv2&#x27;,
170      &#x27;args&#x27;: ([3, 4, 6, 3], [0, 4, 6, 3]),
171  })
172  darknet53_backbone = backbone_base.copy({
173      &#x27;name&#x27;: &#x27;DarkNet53&#x27;,
174      &#x27;path&#x27;: &#x27;darknet53.pth&#x27;,
175      &#x27;type&#x27;: DarkNetBackbone,
176      &#x27;args&#x27;: ([1, 2, 8, 8, 4],),
177      &#x27;transform&#x27;: darknet_transform,
178      &#x27;selected_layers&#x27;: list(range(3, 9)),
179      &#x27;pred_scales&#x27;: [[3.5, 4.95], [3.6, 4.90], [3.3, 4.02], [2.7, 3.10], [2.1, 2.37], [1.8, 1.92]],
180      &#x27;pred_aspect_ratios&#x27;: [ [[1, sqrt(2), 1/sqrt(2), sqrt(3), 1/sqrt(3)][:n], [1]] for n in [3, 5, 5, 5, 3, 3] ],
181  })
182  vgg16_arch = [[64, 64],
183                [ &#x27;M&#x27;, 128, 128],
184                [ &#x27;M&#x27;, 256, 256, 256],
185                [(&#x27;M&#x27;, {&#x27;kernel_size&#x27;: 2, &#x27;stride&#x27;: 2, &#x27;ceil_mode&#x27;: True}), 512, 512, 512],
186                [ &#x27;M&#x27;, 512, 512, 512],
187                [(&#x27;M&#x27;,  {&#x27;kernel_size&#x27;: 3, &#x27;stride&#x27;:  1, &#x27;padding&#x27;:  1}),
188                 (1024, {&#x27;kernel_size&#x27;: 3, &#x27;padding&#x27;: 6, &#x27;dilation&#x27;: 6}),
189                 (1024, {&#x27;kernel_size&#x27;: 1})]]
190  vgg16_backbone = backbone_base.copy({
191      &#x27;name&#x27;: &#x27;VGG16&#x27;,
192      &#x27;path&#x27;: &#x27;vgg16_reducedfc.pth&#x27;,
193      &#x27;type&#x27;: VGGBackbone,
194      &#x27;args&#x27;: (vgg16_arch, [(256, 2), (128, 2), (128, 1), (128, 1)], [3]),
195      &#x27;transform&#x27;: vgg_transform,
196      &#x27;selected_layers&#x27;: [3] + list(range(5, 10)),
197      &#x27;pred_scales&#x27;: [[5, 4]]*6,
198      &#x27;pred_aspect_ratios&#x27;: [ [[1], [1, sqrt(2), 1/sqrt(2), sqrt(3), 1/sqrt(3)][:n]] for n in [3, 5, 5, 5, 3, 3] ],
199  })
200  mask_type = Config({
201      &#x27;direct&#x27;: 0,
202      &#x27;lincomb&#x27;: 1,
203  })
204  activation_func = Config({
205      &#x27;tanh&#x27;:    torch.tanh,
206      &#x27;sigmoid&#x27;: torch.sigmoid,
207      &#x27;softmax&#x27;: lambda x: torch.nn.functional.softmax(x, dim=-1),
208      &#x27;relu&#x27;:    lambda x: torch.nn.functional.relu(x, inplace=True),
209      &#x27;none&#x27;:    lambda x: x,
210  })
211  fpn_base = Config({
212      &#x27;num_features&#x27;: 256,
213      &#x27;interpolation_mode&#x27;: &#x27;bilinear&#x27;,
214      &#x27;num_downsample&#x27;: 1,
215      &#x27;use_conv_downsample&#x27;: False,
216      &#x27;pad&#x27;: True,
217      &#x27;relu_downsample_layers&#x27;: False,
218      &#x27;relu_pred_layers&#x27;: True,
219  })
220  coco_base_config = Config({
221      &#x27;dataset&#x27;: coco2014_dataset,
222      &#x27;num_classes&#x27;: 81, # This should include the background class
223      &#x27;max_iter&#x27;: 400000,
224      &#x27;max_num_detections&#x27;: 100,
225      &#x27;lr&#x27;: 1e-3,
226      &#x27;momentum&#x27;: 0.9,
227      &#x27;decay&#x27;: 5e-4,
228      &#x27;gamma&#x27;: 0.1,
229      &#x27;lr_steps&#x27;: (280000, 360000, 400000),
230      &#x27;lr_warmup_init&#x27;: 1e-4,
231      &#x27;lr_warmup_until&#x27;: 500,
232      &#x27;conf_alpha&#x27;: 1,
233      &#x27;bbox_alpha&#x27;: 1.5,
234      &#x27;mask_alpha&#x27;: 0.4 / 256 * 140 * 140, # Some funky equation. Don&#x27;t worry about it.
235      &#x27;eval_mask_branch&#x27;: True,
236      &#x27;nms_top_k&#x27;: 200,
237      &#x27;nms_conf_thresh&#x27;: 0.05,
238      &#x27;nms_thresh&#x27;: 0.5,
239      &#x27;mask_type&#x27;: mask_type.direct,
240      &#x27;mask_size&#x27;: 16,
241      &#x27;masks_to_train&#x27;: 100,
242      &#x27;mask_proto_src&#x27;: None,
243      &#x27;mask_proto_net&#x27;: [(256, 3, {}), (256, 3, {})],
244      &#x27;mask_proto_bias&#x27;: False,
245      &#x27;mask_proto_prototype_activation&#x27;: activation_func.relu,
246      &#x27;mask_proto_mask_activation&#x27;: activation_func.sigmoid,
247      &#x27;mask_proto_coeff_activation&#x27;: activation_func.tanh,
248      &#x27;mask_proto_crop&#x27;: True,
249      &#x27;mask_proto_crop_expand&#x27;: 0,
250      &#x27;mask_proto_loss&#x27;: None,
251      &#x27;mask_proto_binarize_downsampled_gt&#x27;: True,
252      &#x27;mask_proto_normalize_mask_loss_by_sqrt_area&#x27;: False,
253      &#x27;mask_proto_reweight_mask_loss&#x27;: False,
254      &#x27;mask_proto_grid_file&#x27;: &#x27;data/grid.npy&#x27;,
255      &#x27;mask_proto_use_grid&#x27;:  False,
256      &#x27;mask_proto_coeff_gate&#x27;: False,
257      &#x27;mask_proto_prototypes_as_features&#x27;: False,
258      &#x27;mask_proto_prototypes_as_features_no_grad&#x27;: False,
259      &#x27;mask_proto_remove_empty_masks&#x27;: False,
260      &#x27;mask_proto_reweight_coeff&#x27;: 1,
261      &#x27;mask_proto_coeff_diversity_loss&#x27;: False,
262      &#x27;mask_proto_coeff_diversity_alpha&#x27;: 1,
263      &#x27;mask_proto_normalize_emulate_roi_pooling&#x27;: False,
264      &#x27;mask_proto_double_loss&#x27;: False,
265      &#x27;mask_proto_double_loss_alpha&#x27;: 1,
266      &#x27;mask_proto_split_prototypes_by_head&#x27;: False,
267      &#x27;mask_proto_crop_with_pred_box&#x27;: False,
268      &#x27;augment_photometric_distort&#x27;: True,
269      &#x27;augment_expand&#x27;: True,
270      &#x27;augment_random_sample_crop&#x27;: True,
271      &#x27;augment_random_mirror&#x27;: True,
272      &#x27;augment_random_flip&#x27;: False,
273      &#x27;augment_random_rot90&#x27;: False,
274      &#x27;discard_box_width&#x27;: 4 / 550,
275      &#x27;discard_box_height&#x27;: 4 / 550,
276      &#x27;freeze_bn&#x27;: False,
277      &#x27;fpn&#x27;: None,
278      &#x27;share_prediction_module&#x27;: False,
279      &#x27;ohem_use_most_confident&#x27;: False,
280      &#x27;use_focal_loss&#x27;: False,
281      &#x27;focal_loss_alpha&#x27;: 0.25,
282      &#x27;focal_loss_gamma&#x27;: 2,
283      &#x27;focal_loss_init_pi&#x27;: 0.01,
284      &#x27;use_class_balanced_conf&#x27;: False,
285      &#x27;use_sigmoid_focal_loss&#x27;: False,
286      &#x27;use_objectness_score&#x27;: False,
287      &#x27;use_class_existence_loss&#x27;: False,
288      &#x27;class_existence_alpha&#x27;: 1,
289      &#x27;use_semantic_segmentation_loss&#x27;: False,
290      &#x27;semantic_segmentation_alpha&#x27;: 1,
291      &#x27;use_mask_scoring&#x27;: False,
292      &#x27;mask_scoring_alpha&#x27;: 1,
293      &#x27;use_change_matching&#x27;: False,
294      &#x27;extra_head_net&#x27;: None,
295      &#x27;head_layer_params&#x27;: {&#x27;kernel_size&#x27;: 3, &#x27;padding&#x27;: 1},
296      &#x27;extra_layers&#x27;: (0, 0, 0),
297      &#x27;positive_iou_threshold&#x27;: 0.5,
298      &#x27;negative_iou_threshold&#x27;: 0.5,
299      &#x27;ohem_negpos_ratio&#x27;: 3,
300      &#x27;crowd_iou_threshold&#x27;: 1,
301      &#x27;mask_dim&#x27;: None,
302      &#x27;max_size&#x27;: 300,
303      &#x27;force_cpu_nms&#x27;: True,
304      &#x27;use_coeff_nms&#x27;: False,
305      &#x27;use_instance_coeff&#x27;: False,
306      &#x27;num_instance_coeffs&#x27;: 64,
307      &#x27;train_masks&#x27;: True,
308      &#x27;train_boxes&#x27;: True,
309      &#x27;use_gt_bboxes&#x27;: False,
310      &#x27;preserve_aspect_ratio&#x27;: False,
311      &#x27;use_prediction_module&#x27;: False,
312      &#x27;use_yolo_regressors&#x27;: False,
313      &#x27;use_prediction_matching&#x27;: False,
314      &#x27;delayed_settings&#x27;: [],
315      &#x27;no_jit&#x27;: False,
316      &#x27;backbone&#x27;: None,
317      &#x27;name&#x27;: &#x27;base_config&#x27;,
318      &#x27;use_maskiou&#x27;: False,
319      &#x27;maskiou_net&#x27;: [],
320      &#x27;discard_mask_area&#x27;: -1,
321      &#x27;maskiou_alpha&#x27;: 1.0,
322      &#x27;rescore_mask&#x27;: False,
323      &#x27;rescore_bbox&#x27;: False,
324      &#x27;maskious_to_train&#x27;: -1,
325  })
326  yolact_base_config = coco_base_config.copy({
327      &#x27;name&#x27;: &#x27;yolact_base&#x27;,
328      &#x27;dataset&#x27;: coco2017_dataset,
329      &#x27;num_classes&#x27;: len(coco2017_dataset.class_names) + 1,
330      &#x27;max_size&#x27;: 550,
331      &#x27;lr_steps&#x27;: (280000, 600000, 700000, 750000),
332      &#x27;max_iter&#x27;: 800000,
333      &#x27;backbone&#x27;: resnet101_backbone.copy({
334          &#x27;selected_layers&#x27;: list(range(1, 4)),
335          &#x27;use_pixel_scales&#x27;: True,
336          &#x27;preapply_sqrt&#x27;: False,
337          &#x27;use_square_anchors&#x27;: True, # This is for backward compatability with a bug
338          &#x27;pred_aspect_ratios&#x27;: [ [[1, 1/2, 2]] ]*5,
<span onclick='openModal()' class='match'>339          &#x27;pred_scales&#x27;: [[24], [48], [96], [192], [384]],
340      }),
</span>341      &#x27;fpn&#x27;: fpn_base.copy({
342          &#x27;use_conv_downsample&#x27;: True,
343          &#x27;num_downsample&#x27;: 2,
344      }),
345      &#x27;mask_type&#x27;: mask_type.lincomb,
346      &#x27;mask_alpha&#x27;: 6.125,
347      &#x27;mask_proto_src&#x27;: 0,
348      &#x27;mask_proto_net&#x27;: [(256, 3, {&#x27;padding&#x27;: 1})] * 3 + [(None, -2, {}), (256, 3, {&#x27;padding&#x27;: 1})] + [(32, 1, {})],
349      &#x27;mask_proto_normalize_emulate_roi_pooling&#x27;: True,
350      &#x27;share_prediction_module&#x27;: True,
351      &#x27;extra_head_net&#x27;: [(256, 3, {&#x27;padding&#x27;: 1})],
352      &#x27;positive_iou_threshold&#x27;: 0.5,
353      &#x27;negative_iou_threshold&#x27;: 0.4,
354      &#x27;crowd_iou_threshold&#x27;: 0.7,
355      &#x27;use_semantic_segmentation_loss&#x27;: True,
356  })
357  yolact_im400_config = yolact_base_config.copy({
358      &#x27;name&#x27;: &#x27;yolact_im400&#x27;,
359      &#x27;max_size&#x27;: 400,
360      &#x27;backbone&#x27;: yolact_base_config.backbone.copy({
361          &#x27;pred_scales&#x27;: [[int(x[0] / yolact_base_config.max_size * 400)] for x in yolact_base_config.backbone.pred_scales],
362      }),
363  })
364  yolact_im700_config = yolact_base_config.copy({
365      &#x27;name&#x27;: &#x27;yolact_im700&#x27;,
366      &#x27;masks_to_train&#x27;: 300,
367      &#x27;max_size&#x27;: 700,
368      &#x27;backbone&#x27;: yolact_base_config.backbone.copy({
369          &#x27;pred_scales&#x27;: [[int(x[0] / yolact_base_config.max_size * 700)] for x in yolact_base_config.backbone.pred_scales],
370      }),
371  })
372  yolact_darknet53_config = yolact_base_config.copy({
373      &#x27;name&#x27;: &#x27;yolact_darknet53&#x27;,
374      &#x27;backbone&#x27;: darknet53_backbone.copy({
375          &#x27;selected_layers&#x27;: list(range(2, 5)),
376          &#x27;pred_scales&#x27;: yolact_base_config.backbone.pred_scales,
377          &#x27;pred_aspect_ratios&#x27;: yolact_base_config.backbone.pred_aspect_ratios,
378          &#x27;use_pixel_scales&#x27;: True,
379          &#x27;preapply_sqrt&#x27;: False,
380          &#x27;use_square_anchors&#x27;: True, # This is for backward compatability with a bug
381      }),
382  })
383  yolact_resnet50_config = yolact_base_config.copy({
384      &#x27;name&#x27;: &#x27;yolact_resnet50&#x27;,
385      &#x27;backbone&#x27;: resnet50_backbone.copy({
386          &#x27;selected_layers&#x27;: list(range(1, 4)),
387          &#x27;pred_scales&#x27;: yolact_base_config.backbone.pred_scales,
388          &#x27;pred_aspect_ratios&#x27;: yolact_base_config.backbone.pred_aspect_ratios,
389          &#x27;use_pixel_scales&#x27;: True,
390          &#x27;preapply_sqrt&#x27;: False,
391          &#x27;use_square_anchors&#x27;: True, # This is for backward compatability with a bug
392      }),
393  })
394  yolact_resnet50_pascal_config = yolact_resnet50_config.copy({
395      &#x27;name&#x27;: None, # Will default to yolact_resnet50_pascal
396      &#x27;dataset&#x27;: pascal_sbd_dataset,
397      &#x27;num_classes&#x27;: len(pascal_sbd_dataset.class_names) + 1,
398      &#x27;max_iter&#x27;: 120000,
399      &#x27;lr_steps&#x27;: (60000, 100000),
400      &#x27;backbone&#x27;: yolact_resnet50_config.backbone.copy({
401          &#x27;pred_scales&#x27;: [[32], [64], [128], [256], [512]],
402          &#x27;use_square_anchors&#x27;: False,
403      })
404  })
405  yolact_plus_base_config = yolact_base_config.copy({
406      &#x27;name&#x27;: &#x27;yolact_plus_base&#x27;,
407      &#x27;backbone&#x27;: resnet101_dcn_inter3_backbone.copy({
408          &#x27;selected_layers&#x27;: list(range(1, 4)),
409          &#x27;pred_aspect_ratios&#x27;: [ [[1, 1/2, 2]] ]*5,
410          &#x27;pred_scales&#x27;: [[i * 2 ** (j / 3.0) for j in range(3)] for i in [24, 48, 96, 192, 384]],
411          &#x27;use_pixel_scales&#x27;: True,
412          &#x27;preapply_sqrt&#x27;: False,
413          &#x27;use_square_anchors&#x27;: False,
414      }),
415      &#x27;use_maskiou&#x27;: True,
416      &#x27;maskiou_net&#x27;: [(8, 3, {&#x27;stride&#x27;: 2}), (16, 3, {&#x27;stride&#x27;: 2}), (32, 3, {&#x27;stride&#x27;: 2}), (64, 3, {&#x27;stride&#x27;: 2}), (128, 3, {&#x27;stride&#x27;: 2})],
417      &#x27;maskiou_alpha&#x27;: 25,
418      &#x27;rescore_bbox&#x27;: False,
419      &#x27;rescore_mask&#x27;: True,
420      &#x27;discard_mask_area&#x27;: 5*5,
421  })
422  yolact_plus_resnet50_config = yolact_plus_base_config.copy({
423      &#x27;name&#x27;: &#x27;yolact_plus_resnet50&#x27;,
424      &#x27;backbone&#x27;: resnet50_dcnv2_backbone.copy({
425          &#x27;selected_layers&#x27;: list(range(1, 4)),
426          &#x27;pred_aspect_ratios&#x27;: [ [[1, 1/2, 2]] ]*5,
427          &#x27;pred_scales&#x27;: [[i * 2 ** (j / 3.0) for j in range(3)] for i in [24, 48, 96, 192, 384]],
428          &#x27;use_pixel_scales&#x27;: True,
429          &#x27;preapply_sqrt&#x27;: False,
430          &#x27;use_square_anchors&#x27;: False,
431      }),
432  })
433  cfg = yolact_base_config.copy()
434  def set_cfg(config_name:str):
435      global cfg
436      cfg.replace(eval(config_name))
437      if cfg.name is None:
438          cfg.name = config_name.split(&#x27;_config&#x27;)[0]
439  def set_dataset(dataset_name:str):
440      cfg.dataset = eval(dataset_name)
</code></pre>
        </div>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-config.py</h3>
            <pre><code>1  from backbone import ResNetBackbone, VGGBackbone, ResNetBackboneGN, DarkNetBackbone
2  from math import sqrt
3  import torch
4  COLORS = ((244,  67,  54),
5            (233,  30,  99),
6            (156,  39, 176),
7            (103,  58, 183),
8            ( 63,  81, 181),
9            ( 33, 150, 243),
10            (  3, 169, 244),
11            (  0, 188, 212),
12            (  0, 150, 136),
13            ( 76, 175,  80),
14            (139, 195,  74),
15            (205, 220,  57),
16            (255, 235,  59),
17            (255, 193,   7),
18            (255, 152,   0),
19            (255,  87,  34),
20            (121,  85,  72),
21            (158, 158, 158),
22            ( 96, 125, 139))
23  MEANS = (103.94, 116.78, 123.68)
24  STD   = (57.38, 57.12, 58.40)
25  COCO_CLASSES = (&#x27;person&#x27;, &#x27;bicycle&#x27;, &#x27;car&#x27;, &#x27;motorcycle&#x27;, &#x27;airplane&#x27;, &#x27;bus&#x27;,
26                  &#x27;train&#x27;, &#x27;truck&#x27;, &#x27;boat&#x27;, &#x27;traffic light&#x27;, &#x27;fire hydrant&#x27;,
27                  &#x27;stop sign&#x27;, &#x27;parking meter&#x27;, &#x27;bench&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;, &#x27;dog&#x27;,
28                  &#x27;horse&#x27;, &#x27;sheep&#x27;, &#x27;cow&#x27;, &#x27;elephant&#x27;, &#x27;bear&#x27;, &#x27;zebra&#x27;, &#x27;giraffe&#x27;,
29                  &#x27;backpack&#x27;, &#x27;umbrella&#x27;, &#x27;handbag&#x27;, &#x27;tie&#x27;, &#x27;suitcase&#x27;, &#x27;frisbee&#x27;,
30                  &#x27;skis&#x27;, &#x27;snowboard&#x27;, &#x27;sports ball&#x27;, &#x27;kite&#x27;, &#x27;baseball bat&#x27;,
31                  &#x27;baseball glove&#x27;, &#x27;skateboard&#x27;, &#x27;surfboard&#x27;, &#x27;tennis racket&#x27;,
32                  &#x27;bottle&#x27;, &#x27;wine glass&#x27;, &#x27;cup&#x27;, &#x27;fork&#x27;, &#x27;knife&#x27;, &#x27;spoon&#x27;, &#x27;bowl&#x27;,
33                  &#x27;banana&#x27;, &#x27;apple&#x27;, &#x27;sandwich&#x27;, &#x27;orange&#x27;, &#x27;broccoli&#x27;, &#x27;carrot&#x27;,
34                  &#x27;hot dog&#x27;, &#x27;pizza&#x27;, &#x27;donut&#x27;, &#x27;cake&#x27;, &#x27;chair&#x27;, &#x27;couch&#x27;,
35                  &#x27;potted plant&#x27;, &#x27;bed&#x27;, &#x27;dining table&#x27;, &#x27;toilet&#x27;, &#x27;tv&#x27;, &#x27;laptop&#x27;,
36                  &#x27;mouse&#x27;, &#x27;remote&#x27;, &#x27;keyboard&#x27;, &#x27;cell phone&#x27;, &#x27;microwave&#x27;, &#x27;oven&#x27;,
37                  &#x27;toaster&#x27;, &#x27;sink&#x27;, &#x27;refrigerator&#x27;, &#x27;book&#x27;, &#x27;clock&#x27;, &#x27;vase&#x27;,
38                  &#x27;scissors&#x27;, &#x27;teddy bear&#x27;, &#x27;hair drier&#x27;, &#x27;toothbrush&#x27;)
39  COCO_LABEL_MAP = { 1:  1,  2:  2,  3:  3,  4:  4,  5:  5,  6:  6,  7:  7,  8:  8,
40                     9:  9, 10: 10, 11: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16,
41                    18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24,
42                    27: 25, 28: 26, 31: 27, 32: 28, 33: 29, 34: 30, 35: 31, 36: 32,
43                    37: 33, 38: 34, 39: 35, 40: 36, 41: 37, 42: 38, 43: 39, 44: 40,
44                    46: 41, 47: 42, 48: 43, 49: 44, 50: 45, 51: 46, 52: 47, 53: 48,
45                    54: 49, 55: 50, 56: 51, 57: 52, 58: 53, 59: 54, 60: 55, 61: 56,
46                    62: 57, 63: 58, 64: 59, 65: 60, 67: 61, 70: 62, 72: 63, 73: 64,
47                    74: 65, 75: 66, 76: 67, 77: 68, 78: 69, 79: 70, 80: 71, 81: 72,
48                    82: 73, 84: 74, 85: 75, 86: 76, 87: 77, 88: 78, 89: 79, 90: 80}
49  class Config(object):
50      def __init__(self, config_dict):
51          for key, val in config_dict.items():
52              self.__setattr__(key, val)
53      def copy(self, new_config_dict={}):
54          ret = Config(vars(self))
55          for key, val in new_config_dict.items():
56              ret.__setattr__(key, val)
57          return ret
58      def replace(self, new_config_dict):
59          if isinstance(new_config_dict, Config):
60              new_config_dict = vars(new_config_dict)
61          for key, val in new_config_dict.items():
62              self.__setattr__(key, val)
63      def print(self):
64          for k, v in vars(self).items():
65              print(k, &#x27; = &#x27;, v)
66  dataset_base = Config({
67      &#x27;name&#x27;: &#x27;Base Dataset&#x27;,
68      &#x27;train_images&#x27;: &#x27;./data/coco/images/&#x27;,
69      &#x27;train_info&#x27;:   &#x27;path_to_annotation_file&#x27;,
70      &#x27;valid_images&#x27;: &#x27;./data/coco/images/&#x27;,
71      &#x27;valid_info&#x27;:   &#x27;path_to_annotation_file&#x27;,
72      &#x27;has_gt&#x27;: True,
73      &#x27;class_names&#x27;: COCO_CLASSES,
74      &#x27;label_map&#x27;: None
75  })
76  coco2014_dataset = dataset_base.copy({
77      &#x27;name&#x27;: &#x27;COCO 2014&#x27;,
78      &#x27;train_info&#x27;: &#x27;./data/coco/annotations/instances_train2014.json&#x27;,
79      &#x27;valid_info&#x27;: &#x27;./data/coco/annotations/instances_val2014.json&#x27;,
80      &#x27;label_map&#x27;: COCO_LABEL_MAP
81  })
82  coco2017_dataset = dataset_base.copy({
83      &#x27;name&#x27;: &#x27;COCO 2017&#x27;,
84      &#x27;train_info&#x27;: &#x27;./data/coco/annotations/instances_train2017.json&#x27;,
85      &#x27;valid_info&#x27;: &#x27;./data/coco/annotations/instances_val2017.json&#x27;,
86      &#x27;label_map&#x27;: COCO_LABEL_MAP
87  })
88  coco2017_testdev_dataset = dataset_base.copy({
89      &#x27;name&#x27;: &#x27;COCO 2017 Test-Dev&#x27;,
90      &#x27;valid_info&#x27;: &#x27;./data/coco/annotations/image_info_test-dev2017.json&#x27;,
91      &#x27;has_gt&#x27;: False,
92      &#x27;label_map&#x27;: COCO_LABEL_MAP
93  })
94  PASCAL_CLASSES = (&quot;aeroplane&quot;, &quot;bicycle&quot;, &quot;bird&quot;, &quot;boat&quot;, &quot;bottle&quot;,
95                    &quot;bus&quot;, &quot;car&quot;, &quot;cat&quot;, &quot;chair&quot;, &quot;cow&quot;, &quot;diningtable&quot;,
96                    &quot;dog&quot;, &quot;horse&quot;, &quot;motorbike&quot;, &quot;person&quot;, &quot;pottedplant&quot;,
97                    &quot;sheep&quot;, &quot;sofa&quot;, &quot;train&quot;, &quot;tvmonitor&quot;)
98  pascal_sbd_dataset = dataset_base.copy({
99      &#x27;name&#x27;: &#x27;Pascal SBD 2012&#x27;,
100      &#x27;train_images&#x27;: &#x27;./data/sbd/img&#x27;,
101      &#x27;valid_images&#x27;: &#x27;./data/sbd/img&#x27;,
102      &#x27;train_info&#x27;: &#x27;./data/sbd/pascal_sbd_train.json&#x27;,
103      &#x27;valid_info&#x27;: &#x27;./data/sbd/pascal_sbd_val.json&#x27;,
104      &#x27;class_names&#x27;: PASCAL_CLASSES,
105  })
106  resnet_transform = Config({
107      &#x27;channel_order&#x27;: &#x27;RGB&#x27;,
108      &#x27;normalize&#x27;: True,
109      &#x27;subtract_means&#x27;: False,
110      &#x27;to_float&#x27;: False,
111  })
112  vgg_transform = Config({
113      &#x27;channel_order&#x27;: &#x27;RGB&#x27;,
114      &#x27;normalize&#x27;: False,
115      &#x27;subtract_means&#x27;: True,
116      &#x27;to_float&#x27;: False,
117  })
118  darknet_transform = Config({
119      &#x27;channel_order&#x27;: &#x27;RGB&#x27;,
120      &#x27;normalize&#x27;: False,
121      &#x27;subtract_means&#x27;: False,
122      &#x27;to_float&#x27;: True,
123  })
124  backbone_base = Config({
125      &#x27;name&#x27;: &#x27;Base Backbone&#x27;,
126      &#x27;path&#x27;: &#x27;path/to/pretrained/weights&#x27;,
127      &#x27;type&#x27;: object,
128      &#x27;args&#x27;: tuple(),
129      &#x27;transform&#x27;: resnet_transform,
130      &#x27;selected_layers&#x27;: list(),
131      &#x27;pred_scales&#x27;: list(),
132      &#x27;pred_aspect_ratios&#x27;: list(),
133      &#x27;use_pixel_scales&#x27;: False,
134      &#x27;preapply_sqrt&#x27;: True,
135      &#x27;use_square_anchors&#x27;: False,
136  })
137  resnet101_backbone = backbone_base.copy({
138      &#x27;name&#x27;: &#x27;ResNet101&#x27;,
139      &#x27;path&#x27;: &#x27;resnet101_reducedfc.pth&#x27;,
140      &#x27;type&#x27;: ResNetBackbone,
141      &#x27;args&#x27;: ([3, 4, 23, 3],),
142      &#x27;transform&#x27;: resnet_transform,
143      &#x27;selected_layers&#x27;: list(range(2, 8)),
144      &#x27;pred_scales&#x27;: [[1]]*6,
145      &#x27;pred_aspect_ratios&#x27;: [ [[0.66685089, 1.7073535, 0.87508774, 1.16524493, 0.49059086]] ] * 6,
146  })
147  resnet101_gn_backbone = backbone_base.copy({
148      &#x27;name&#x27;: &#x27;ResNet101_GN&#x27;,
149      &#x27;path&#x27;: &#x27;R-101-GN.pkl&#x27;,
150      &#x27;type&#x27;: ResNetBackboneGN,
151      &#x27;args&#x27;: ([3, 4, 23, 3],),
152      &#x27;transform&#x27;: resnet_transform,
153      &#x27;selected_layers&#x27;: list(range(2, 8)),
154      &#x27;pred_scales&#x27;: [[1]]*6,
155      &#x27;pred_aspect_ratios&#x27;: [ [[0.66685089, 1.7073535, 0.87508774, 1.16524493, 0.49059086]] ] * 6,
156  })
157  resnet101_dcn_inter3_backbone = resnet101_backbone.copy({
158      &#x27;name&#x27;: &#x27;ResNet101_DCN_Interval3&#x27;,
159      &#x27;args&#x27;: ([3, 4, 23, 3], [0, 4, 23, 3], 3),
160  })
161  resnet50_backbone = resnet101_backbone.copy({
162      &#x27;name&#x27;: &#x27;ResNet50&#x27;,
163      &#x27;path&#x27;: &#x27;resnet50-19c8e357.pth&#x27;,
164      &#x27;type&#x27;: ResNetBackbone,
165      &#x27;args&#x27;: ([3, 4, 6, 3],),
166      &#x27;transform&#x27;: resnet_transform,
167  })
168  resnet50_dcnv2_backbone = resnet50_backbone.copy({
169      &#x27;name&#x27;: &#x27;ResNet50_DCNv2&#x27;,
170      &#x27;args&#x27;: ([3, 4, 6, 3], [0, 4, 6, 3]),
171  })
172  darknet53_backbone = backbone_base.copy({
173      &#x27;name&#x27;: &#x27;DarkNet53&#x27;,
174      &#x27;path&#x27;: &#x27;darknet53.pth&#x27;,
175      &#x27;type&#x27;: DarkNetBackbone,
176      &#x27;args&#x27;: ([1, 2, 8, 8, 4],),
177      &#x27;transform&#x27;: darknet_transform,
178      &#x27;selected_layers&#x27;: list(range(3, 9)),
179      &#x27;pred_scales&#x27;: [[3.5, 4.95], [3.6, 4.90], [3.3, 4.02], [2.7, 3.10], [2.1, 2.37], [1.8, 1.92]],
180      &#x27;pred_aspect_ratios&#x27;: [ [[1, sqrt(2), 1/sqrt(2), sqrt(3), 1/sqrt(3)][:n], [1]] for n in [3, 5, 5, 5, 3, 3] ],
181  })
182  vgg16_arch = [[64, 64],
183                [ &#x27;M&#x27;, 128, 128],
184                [ &#x27;M&#x27;, 256, 256, 256],
185                [(&#x27;M&#x27;, {&#x27;kernel_size&#x27;: 2, &#x27;stride&#x27;: 2, &#x27;ceil_mode&#x27;: True}), 512, 512, 512],
186                [ &#x27;M&#x27;, 512, 512, 512],
187                [(&#x27;M&#x27;,  {&#x27;kernel_size&#x27;: 3, &#x27;stride&#x27;:  1, &#x27;padding&#x27;:  1}),
188                 (1024, {&#x27;kernel_size&#x27;: 3, &#x27;padding&#x27;: 6, &#x27;dilation&#x27;: 6}),
189                 (1024, {&#x27;kernel_size&#x27;: 1})]]
190  vgg16_backbone = backbone_base.copy({
191      &#x27;name&#x27;: &#x27;VGG16&#x27;,
192      &#x27;path&#x27;: &#x27;vgg16_reducedfc.pth&#x27;,
193      &#x27;type&#x27;: VGGBackbone,
194      &#x27;args&#x27;: (vgg16_arch, [(256, 2), (128, 2), (128, 1), (128, 1)], [3]),
195      &#x27;transform&#x27;: vgg_transform,
196      &#x27;selected_layers&#x27;: [3] + list(range(5, 10)),
197      &#x27;pred_scales&#x27;: [[5, 4]]*6,
198      &#x27;pred_aspect_ratios&#x27;: [ [[1], [1, sqrt(2), 1/sqrt(2), sqrt(3), 1/sqrt(3)][:n]] for n in [3, 5, 5, 5, 3, 3] ],
199  })
200  mask_type = Config({
201      &#x27;direct&#x27;: 0,
202      &#x27;lincomb&#x27;: 1,
203  })
204  activation_func = Config({
205      &#x27;tanh&#x27;:    torch.tanh,
206      &#x27;sigmoid&#x27;: torch.sigmoid,
207      &#x27;softmax&#x27;: lambda x: torch.nn.functional.softmax(x, dim=-1),
208      &#x27;relu&#x27;:    lambda x: torch.nn.functional.relu(x, inplace=True),
209      &#x27;none&#x27;:    lambda x: x,
210  })
211  fpn_base = Config({
212      &#x27;num_features&#x27;: 256,
213      &#x27;interpolation_mode&#x27;: &#x27;bilinear&#x27;,
214      &#x27;num_downsample&#x27;: 1,
215      &#x27;use_conv_downsample&#x27;: False,
216      &#x27;pad&#x27;: True,
217      &#x27;relu_downsample_layers&#x27;: False,
218      &#x27;relu_pred_layers&#x27;: True,
219  })
220  coco_base_config = Config({
221      &#x27;dataset&#x27;: coco2014_dataset,
222      &#x27;num_classes&#x27;: 81, # This should include the background class
223      &#x27;max_iter&#x27;: 400000,
224      &#x27;max_num_detections&#x27;: 100,
225      &#x27;lr&#x27;: 1e-3,
226      &#x27;momentum&#x27;: 0.9,
227      &#x27;decay&#x27;: 5e-4,
228      &#x27;gamma&#x27;: 0.1,
229      &#x27;lr_steps&#x27;: (280000, 360000, 400000),
230      &#x27;lr_warmup_init&#x27;: 1e-4,
231      &#x27;lr_warmup_until&#x27;: 500,
232      &#x27;conf_alpha&#x27;: 1,
233      &#x27;bbox_alpha&#x27;: 1.5,
234      &#x27;mask_alpha&#x27;: 0.4 / 256 * 140 * 140, # Some funky equation. Don&#x27;t worry about it.
235      &#x27;eval_mask_branch&#x27;: True,
236      &#x27;nms_top_k&#x27;: 200,
237      &#x27;nms_conf_thresh&#x27;: 0.05,
238      &#x27;nms_thresh&#x27;: 0.5,
239      &#x27;mask_type&#x27;: mask_type.direct,
240      &#x27;mask_size&#x27;: 16,
241      &#x27;masks_to_train&#x27;: 100,
242      &#x27;mask_proto_src&#x27;: None,
243      &#x27;mask_proto_net&#x27;: [(256, 3, {}), (256, 3, {})],
244      &#x27;mask_proto_bias&#x27;: False,
245      &#x27;mask_proto_prototype_activation&#x27;: activation_func.relu,
246      &#x27;mask_proto_mask_activation&#x27;: activation_func.sigmoid,
247      &#x27;mask_proto_coeff_activation&#x27;: activation_func.tanh,
248      &#x27;mask_proto_crop&#x27;: True,
249      &#x27;mask_proto_crop_expand&#x27;: 0,
250      &#x27;mask_proto_loss&#x27;: None,
251      &#x27;mask_proto_binarize_downsampled_gt&#x27;: True,
252      &#x27;mask_proto_normalize_mask_loss_by_sqrt_area&#x27;: False,
253      &#x27;mask_proto_reweight_mask_loss&#x27;: False,
254      &#x27;mask_proto_grid_file&#x27;: &#x27;data/grid.npy&#x27;,
255      &#x27;mask_proto_use_grid&#x27;:  False,
256      &#x27;mask_proto_coeff_gate&#x27;: False,
257      &#x27;mask_proto_prototypes_as_features&#x27;: False,
258      &#x27;mask_proto_prototypes_as_features_no_grad&#x27;: False,
259      &#x27;mask_proto_remove_empty_masks&#x27;: False,
260      &#x27;mask_proto_reweight_coeff&#x27;: 1,
261      &#x27;mask_proto_coeff_diversity_loss&#x27;: False,
262      &#x27;mask_proto_coeff_diversity_alpha&#x27;: 1,
263      &#x27;mask_proto_normalize_emulate_roi_pooling&#x27;: False,
264      &#x27;mask_proto_double_loss&#x27;: False,
265      &#x27;mask_proto_double_loss_alpha&#x27;: 1,
266      &#x27;mask_proto_split_prototypes_by_head&#x27;: False,
267      &#x27;mask_proto_crop_with_pred_box&#x27;: False,
268      &#x27;augment_photometric_distort&#x27;: True,
269      &#x27;augment_expand&#x27;: True,
270      &#x27;augment_random_sample_crop&#x27;: True,
271      &#x27;augment_random_mirror&#x27;: True,
272      &#x27;augment_random_flip&#x27;: False,
273      &#x27;augment_random_rot90&#x27;: False,
274      &#x27;discard_box_width&#x27;: 4 / 550,
275      &#x27;discard_box_height&#x27;: 4 / 550,
276      &#x27;freeze_bn&#x27;: False,
277      &#x27;fpn&#x27;: None,
278      &#x27;share_prediction_module&#x27;: False,
279      &#x27;ohem_use_most_confident&#x27;: False,
280      &#x27;use_focal_loss&#x27;: False,
281      &#x27;focal_loss_alpha&#x27;: 0.25,
282      &#x27;focal_loss_gamma&#x27;: 2,
283      &#x27;focal_loss_init_pi&#x27;: 0.01,
284      &#x27;use_class_balanced_conf&#x27;: False,
285      &#x27;use_sigmoid_focal_loss&#x27;: False,
286      &#x27;use_objectness_score&#x27;: False,
287      &#x27;use_class_existence_loss&#x27;: False,
288      &#x27;class_existence_alpha&#x27;: 1,
289      &#x27;use_semantic_segmentation_loss&#x27;: False,
290      &#x27;semantic_segmentation_alpha&#x27;: 1,
291      &#x27;use_mask_scoring&#x27;: False,
292      &#x27;mask_scoring_alpha&#x27;: 1,
293      &#x27;use_change_matching&#x27;: False,
294      &#x27;extra_head_net&#x27;: None,
295      &#x27;head_layer_params&#x27;: {&#x27;kernel_size&#x27;: 3, &#x27;padding&#x27;: 1},
296      &#x27;extra_layers&#x27;: (0, 0, 0),
297      &#x27;positive_iou_threshold&#x27;: 0.5,
298      &#x27;negative_iou_threshold&#x27;: 0.5,
299      &#x27;ohem_negpos_ratio&#x27;: 3,
300      &#x27;crowd_iou_threshold&#x27;: 1,
301      &#x27;mask_dim&#x27;: None,
302      &#x27;max_size&#x27;: 300,
303      &#x27;force_cpu_nms&#x27;: True,
304      &#x27;use_coeff_nms&#x27;: False,
305      &#x27;use_instance_coeff&#x27;: False,
306      &#x27;num_instance_coeffs&#x27;: 64,
307      &#x27;train_masks&#x27;: True,
308      &#x27;train_boxes&#x27;: True,
309      &#x27;use_gt_bboxes&#x27;: False,
310      &#x27;preserve_aspect_ratio&#x27;: False,
311      &#x27;use_prediction_module&#x27;: False,
312      &#x27;use_yolo_regressors&#x27;: False,
313      &#x27;use_prediction_matching&#x27;: False,
314      &#x27;delayed_settings&#x27;: [],
315      &#x27;no_jit&#x27;: False,
316      &#x27;backbone&#x27;: None,
317      &#x27;name&#x27;: &#x27;base_config&#x27;,
318      &#x27;use_maskiou&#x27;: False,
319      &#x27;maskiou_net&#x27;: [],
320      &#x27;discard_mask_area&#x27;: -1,
321      &#x27;maskiou_alpha&#x27;: 1.0,
322      &#x27;rescore_mask&#x27;: False,
323      &#x27;rescore_bbox&#x27;: False,
324      &#x27;maskious_to_train&#x27;: -1,
325  })
326  yolact_base_config = coco_base_config.copy({
327      &#x27;name&#x27;: &#x27;yolact_base&#x27;,
328      &#x27;dataset&#x27;: coco2017_dataset,
329      &#x27;num_classes&#x27;: len(coco2017_dataset.class_names) + 1,
330      &#x27;max_size&#x27;: 550,
331      &#x27;lr_steps&#x27;: (280000, 600000, 700000, 750000),
332      &#x27;max_iter&#x27;: 800000,
333      &#x27;backbone&#x27;: resnet101_backbone.copy({
334          &#x27;selected_layers&#x27;: list(range(1, 4)),
335          &#x27;use_pixel_scales&#x27;: True,
336          &#x27;preapply_sqrt&#x27;: False,
337          &#x27;use_square_anchors&#x27;: True, # This is for backward compatability with a bug
338          &#x27;pred_aspect_ratios&#x27;: [ [[1, 1/2, 2]] ]*5,
339          &#x27;pred_scales&#x27;: [[24], [48], [96], [192], [384]],
340      }),
341      &#x27;fpn&#x27;: fpn_base.copy({
342          &#x27;use_conv_downsample&#x27;: True,
343          &#x27;num_downsample&#x27;: 2,
344      }),
345      &#x27;mask_type&#x27;: mask_type.lincomb,
346      &#x27;mask_alpha&#x27;: 6.125,
347      &#x27;mask_proto_src&#x27;: 0,
348      &#x27;mask_proto_net&#x27;: [(256, 3, {&#x27;padding&#x27;: 1})] * 3 + [(None, -2, {}), (256, 3, {&#x27;padding&#x27;: 1})] + [(32, 1, {})],
349      &#x27;mask_proto_normalize_emulate_roi_pooling&#x27;: True,
350      &#x27;share_prediction_module&#x27;: True,
351      &#x27;extra_head_net&#x27;: [(256, 3, {&#x27;padding&#x27;: 1})],
352      &#x27;positive_iou_threshold&#x27;: 0.5,
353      &#x27;negative_iou_threshold&#x27;: 0.4,
354      &#x27;crowd_iou_threshold&#x27;: 0.7,
355      &#x27;use_semantic_segmentation_loss&#x27;: True,
356  })
357  yolact_im400_config = yolact_base_config.copy({
358      &#x27;name&#x27;: &#x27;yolact_im400&#x27;,
359      &#x27;max_size&#x27;: 400,
360      &#x27;backbone&#x27;: yolact_base_config.backbone.copy({
361          &#x27;pred_scales&#x27;: [[int(x[0] / yolact_base_config.max_size * 400)] for x in yolact_base_config.backbone.pred_scales],
362      }),
363  })
364  yolact_im700_config = yolact_base_config.copy({
365      &#x27;name&#x27;: &#x27;yolact_im700&#x27;,
366      &#x27;masks_to_train&#x27;: 300,
367      &#x27;max_size&#x27;: 700,
368      &#x27;backbone&#x27;: yolact_base_config.backbone.copy({
369          &#x27;pred_scales&#x27;: [[int(x[0] / yolact_base_config.max_size * 700)] for x in yolact_base_config.backbone.pred_scales],
370      }),
371  })
372  yolact_darknet53_config = yolact_base_config.copy({
373      &#x27;name&#x27;: &#x27;yolact_darknet53&#x27;,
374      &#x27;backbone&#x27;: darknet53_backbone.copy({
375          &#x27;selected_layers&#x27;: list(range(2, 5)),
376          &#x27;pred_scales&#x27;: yolact_base_config.backbone.pred_scales,
377          &#x27;pred_aspect_ratios&#x27;: yolact_base_config.backbone.pred_aspect_ratios,
378          &#x27;use_pixel_scales&#x27;: True,
379          &#x27;preapply_sqrt&#x27;: False,
380          &#x27;use_square_anchors&#x27;: True, # This is for backward compatability with a bug
381      }),
382  })
383  yolact_resnet50_config = yolact_base_config.copy({
384      &#x27;name&#x27;: &#x27;yolact_resnet50&#x27;,
385      &#x27;backbone&#x27;: resnet50_backbone.copy({
386          &#x27;selected_layers&#x27;: list(range(1, 4)),
387          &#x27;pred_scales&#x27;: yolact_base_config.backbone.pred_scales,
388          &#x27;pred_aspect_ratios&#x27;: yolact_base_config.backbone.pred_aspect_ratios,
389          &#x27;use_pixel_scales&#x27;: True,
390          &#x27;preapply_sqrt&#x27;: False,
391          &#x27;use_square_anchors&#x27;: True, # This is for backward compatability with a bug
392      }),
393  })
394  yolact_resnet50_pascal_config = yolact_resnet50_config.copy({
395      &#x27;name&#x27;: None, # Will default to yolact_resnet50_pascal
396      &#x27;dataset&#x27;: pascal_sbd_dataset,
397      &#x27;num_classes&#x27;: len(pascal_sbd_dataset.class_names) + 1,
398      &#x27;max_iter&#x27;: 120000,
399      &#x27;lr_steps&#x27;: (60000, 100000),
400      &#x27;backbone&#x27;: yolact_resnet50_config.backbone.copy({
<span onclick='openModal()' class='match'>401          &#x27;pred_scales&#x27;: [[32], [64], [128], [256], [512]],
402          &#x27;use_square_anchors&#x27;: False,
</span>403      })
404  })
405  yolact_plus_base_config = yolact_base_config.copy({
406      &#x27;name&#x27;: &#x27;yolact_plus_base&#x27;,
407      &#x27;backbone&#x27;: resnet101_dcn_inter3_backbone.copy({
408          &#x27;selected_layers&#x27;: list(range(1, 4)),
409          &#x27;pred_aspect_ratios&#x27;: [ [[1, 1/2, 2]] ]*5,
410          &#x27;pred_scales&#x27;: [[i * 2 ** (j / 3.0) for j in range(3)] for i in [24, 48, 96, 192, 384]],
411          &#x27;use_pixel_scales&#x27;: True,
412          &#x27;preapply_sqrt&#x27;: False,
413          &#x27;use_square_anchors&#x27;: False,
414      }),
415      &#x27;use_maskiou&#x27;: True,
416      &#x27;maskiou_net&#x27;: [(8, 3, {&#x27;stride&#x27;: 2}), (16, 3, {&#x27;stride&#x27;: 2}), (32, 3, {&#x27;stride&#x27;: 2}), (64, 3, {&#x27;stride&#x27;: 2}), (128, 3, {&#x27;stride&#x27;: 2})],
417      &#x27;maskiou_alpha&#x27;: 25,
418      &#x27;rescore_bbox&#x27;: False,
419      &#x27;rescore_mask&#x27;: True,
420      &#x27;discard_mask_area&#x27;: 5*5,
421  })
422  yolact_plus_resnet50_config = yolact_plus_base_config.copy({
423      &#x27;name&#x27;: &#x27;yolact_plus_resnet50&#x27;,
424      &#x27;backbone&#x27;: resnet50_dcnv2_backbone.copy({
425          &#x27;selected_layers&#x27;: list(range(1, 4)),
426          &#x27;pred_aspect_ratios&#x27;: [ [[1, 1/2, 2]] ]*5,
427          &#x27;pred_scales&#x27;: [[i * 2 ** (j / 3.0) for j in range(3)] for i in [24, 48, 96, 192, 384]],
428          &#x27;use_pixel_scales&#x27;: True,
429          &#x27;preapply_sqrt&#x27;: False,
430          &#x27;use_square_anchors&#x27;: False,
431      }),
432  })
433  cfg = yolact_base_config.copy()
434  def set_cfg(config_name:str):
435      global cfg
436      cfg.replace(eval(config_name))
437      if cfg.name is None:
438          cfg.name = config_name.split(&#x27;_config&#x27;)[0]
439  def set_dataset(dataset_name:str):
440      cfg.dataset = eval(dataset_name)
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-config.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-config.py</div>
                </div>
                <div class="column column_space"><pre><code>339          &#x27;pred_scales&#x27;: [[24], [48], [96], [192], [384]],
340      }),
</pre></code></div>
                <div class="column column_space"><pre><code>401          &#x27;pred_scales&#x27;: [[32], [64], [128], [256], [512]],
402          &#x27;use_square_anchors&#x27;: False,
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    