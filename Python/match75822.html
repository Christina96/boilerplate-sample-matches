<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for ipc.py &amp; hgfs.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for ipc.py &amp; hgfs.py
      </h3>
<h1 align="center">
        4.2%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>ipc.py (5.1087985%)<th>hgfs.py (3.6784742%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(6-24)<td><a href="#" name="0">(42-60)</a><td align="center"><font color="#ff0000">18</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(541-544)<td><a href="#" name="1">(139-140)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(137-140)<td><a href="#" name="2">(114-115)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(128-131)<td><a href="#" name="3">(214-216)</a><td align="center"><font color="#aa0000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>ipc.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>import errno
import logging
import socket
import time
import salt.ext.tornado
import salt.ext.tornado.concurrent
import salt.ext.tornado.gen
import salt.ext.tornado.ioloop
import salt.ext.tornado.netutil
import salt.transport.client
import salt.transport.frame
import salt.utils.msgpack
from salt.ext.tornado.ioloop import IOLoop
from salt.ext.tornado.ioloop import TimeoutError as TornadoTimeoutError
from salt.ext.tornado.iostream import IOStream, StreamClosedError
from salt.ext.tornado.locks import Lock
log = logging.</b></font>getLogger(__name__)
def future_with_timeout_callback(future):
    if future._future_with_timeout is not None:
        future._future_with_timeout._done_callback(future)
class FutureWithTimeout(salt.ext.tornado.concurrent.Future):
    def __init__(self, io_loop, future, timeout):
        super().__init__()
        self.io_loop = io_loop
        self._future = future
        if timeout is not None:
            if timeout &lt; 0.1:
                timeout = 0.1
            self._timeout_handle = self.io_loop.add_timeout(
                self.io_loop.time() + timeout, self._timeout_callback
            )
        else:
            self._timeout_handle = None
        if hasattr(self._future, "_future_with_timeout"):
            self._future._future_with_timeout = self
            if self._future.done():
                future_with_timeout_callback(self._future)
        else:
            self._future._future_with_timeout = self
            self._future.add_done_callback(future_with_timeout_callback)
    def _timeout_callback(self):
        self._timeout_handle = None
        self._future._future_with_timeout = None
        self.set_exception(TornadoTimeoutError())
    def _done_callback(self, future):
        try:
            if self._timeout_handle is not None:
                self.io_loop.remove_timeout(self._timeout_handle)
                self._timeout_handle = None
            self.set_result(future.result())
        except Exception as exc:  # pylint: disable=broad-except
            self.set_exception(exc)
class IPCServer:
    async_methods = [
        "handle_stream",
    ]
    close_methods = [
        "close",
    ]
    def __init__(self, socket_path, io_loop=None, payload_handler=None):
        self.socket_path = socket_path
        self._started = False
        self.payload_handler = payload_handler
        self.sock = None
        self.io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()
        self._closing = False
    def start(self):
        log.trace("IPCServer: binding to socket: %s", self.socket_path)
        if isinstance(self.socket_path, int):
            self.sock = socket.socket(socket<font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.AF_INET, socket.SOCK_STREAM)
            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            self.sock.setblocking(0)
            self.sock.</b></font>bind(("127.0.0.1", self.socket_path))
            self.sock.listen(128)
<a name="2"></a>        else:
            self.sock = salt.ext.tornado.netutil.bind_unix_socket(self.socket_path)
        with salt<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.utils.asynchronous.current_ioloop(self.io_loop):
            salt.ext.tornado.netutil.add_accept_handler(
                self.sock,
                self.</b></font>handle_connection,
            )
        self._started = True
    @salt.ext.tornado.gen.coroutine
    def handle_stream(self, stream):
        @salt.ext.tornado.gen.coroutine
        def _null(msg):
            raise salt.ext.tornado.gen.Return(None)
        def write_callback(stream, header):
            if header.get("mid"):
                @salt.ext.tornado.gen.coroutine
                def return_message(msg):
                    pack = salt.transport.frame.frame_msg_ipc(
                        msg,
                        header={"mid": header["mid"]},
                        raw_body=True,
                    )
                    yield stream.write(pack)
                return return_message
            else:
                return _null
        if salt.utils.msgpack.version &gt;= (0, 5, 2):
            msgpack_kwargs = {"raw": False}
        else:
            msgpack_kwargs = {"encoding": "utf-8"}
        unpacker = salt.utils.msgpack.Unpacker(**msgpack_kwargs)
        while not stream.closed():
            try:
                wire_bytes = yield stream.read_bytes(4096, partial=True)
                unpacker.feed(wire_bytes)
                for framed_msg in unpacker:
                    body = framed_msg["body"]
                    self.io_loop.spawn_callback(
                        self.payload_handler,
                        body,
                        write_callback(stream, framed_msg["head"]),
                    )
            except StreamClosedError:
                log.trace("Client disconnected from IPC %s", self.socket_path)
                break
            except OSError as exc:
                if exc.errno == 0:
                    log.trace(
                        "Exception occurred with error number 0, "
                        "spurious exception: %s",
                        exc,
                    )
                else:
                    log.error("Exception occurred while handling stream: %s", exc)
            except Exception as exc:  # pylint: disable=broad-except
                log.error("Exception occurred while handling stream: %s", exc)
    def handle_connection(self, connection, address):
        log.trace(
            "IPCServer: Handling connection to address: %s",
            address if address else connection,
        )
        try:
            with salt.utils.asynchronous.current_ioloop(self.io_loop):
                stream = IOStream(
                    connection,
                )
            self.io_loop.spawn_callback(self.handle_stream, stream)
        except Exception as exc:  # pylint: disable=broad-except
            log.error("IPC streaming error: %s", exc)
    def close(self):
        if self._closing:
            return
        self._closing = True
        if hasattr(self.sock, "close"):
            self.sock.close()
    def __del__(self):
        try:
            self.close()
        except TypeError:
            pass
    def __enter__(self):
        return self
    def __exit__(self, *args):
        self.close()
class IPCClient:
    def __init__(self, socket_path, io_loop=None):
        self.io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()
        self.socket_path = socket_path
        self._closing = False
        self.stream = None
        if salt.utils.msgpack.version &gt;= (0, 5, 2):
            msgpack_kwargs = {"raw": False}
        else:
            msgpack_kwargs = {"encoding": "utf-8"}
        self.unpacker = salt.utils.msgpack.Unpacker(**msgpack_kwargs)
        self._connecting_future = None
    def connected(self):
        return self.stream is not None and not self.stream.closed()
    def connect(self, callback=None, timeout=None):
        if self._connecting_future is not None and not self._connecting_future.done():
            future = self._connecting_future
        else:
            if self._connecting_future is not None:
                self._connecting_future.exception()  # pylint: disable=E0203
            future = salt.ext.tornado.concurrent.Future()
            self._connecting_future = future
            self._connect(timeout)
        if callback is not None:
            def handle_future(future):
                response = future.result()
                self.io_loop.add_callback(callback, response)
            future.add_done_callback(handle_future)
        return future
    @salt.ext.tornado.gen.coroutine
    def _connect(self, timeout=None):
        if isinstance(self.socket_path, int):
            sock_type = socket.AF_INET
            sock_addr = ("127.0.0.1", self.socket_path)
        else:
            sock_type = socket.AF_UNIX
            sock_addr = self.socket_path
        self.stream = None
        if timeout is not None:
            timeout_at = time.time() + timeout
        while True:
            if self._closing:
                break
            if self.stream is None:
                with salt.utils.asynchronous.current_ioloop(self.io_loop):
                    self.stream = IOStream(socket.socket(sock_type, socket.SOCK_STREAM))
            try:
                log.trace("IPCClient: Connecting to socket: %s", self.socket_path)
                yield self.stream.connect(sock_addr)
                self._connecting_future.set_result(True)
                break
            except Exception as e:  # pylint: disable=broad-except
                if self.stream.closed():
                    self.stream = None
                if timeout is None or time.time() &gt; timeout_at:
                    if self.stream is not None:
                        self.stream.close()
                        self.stream = None
                    self._connecting_future.set_exception(e)
                    break
                yield salt.ext.tornado.gen.sleep(1)
    def close(self):
        if self._closing:
            return
        self._closing = True
        self._connecting_future = None
        log.debug("Closing %s instance", self.__class__.__name__)
        if self.stream is not None and not self.stream.closed():
            try:
                self.stream.close()
            except OSError as exc:
                if exc.errno != errno.EBADF:
                    raise
    def __del__(self):
        try:
            self.close()
        except TypeError:
            pass
    def __enter__(self):
        return self
    def __exit__(self, *args):
        self.close()
class IPCMessageClient(IPCClient):
    async_methods = [
        "send",
        "connect",
        "_connect",
    ]
    close_methods = [
        "close",
    ]
    @salt.ext.tornado.gen.coroutine
    def send(self, msg, timeout=None, tries=None):
        if not self.connected():
            yield self.connect()
        pack = salt.transport.frame.frame_msg_ipc(msg, raw_body=True)
        yield self.stream.write(pack)
class IPCMessageServer(IPCServer):
class IPCMessagePublisher:
    def __init__(self, opts, socket_path, io_loop=None):
        self.opts = opts
        self.socket_path = socket_path
        self._started = False
        self.sock = None
        self.io_loop = io_loop or IOLoop.current()
        self._closing = False
        self.streams = set()
    def start(self):
        log.trace("IPCMessagePublisher: binding to socket: %s", self.socket_path)
        if isinstance(self.socket_path, int):
            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            self.sock.setblocking(0)
            self.sock.bind(("127.0.0.1", self.socket_path))
            self.sock.listen(128)
<a name="1"></a>        else:
            self.sock = salt.ext.tornado.netutil.bind_unix_socket(self.socket_path)
        with salt<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.utils.asynchronous.current_ioloop(self.io_loop):
            salt.ext.tornado.netutil.add_accept_handler(
                self.sock,
                self.</b></font>handle_connection,
            )
        self._started = True
    @salt.ext.tornado.gen.coroutine
    def _write(self, stream, pack):
        try:
            yield stream.write(pack)
        except StreamClosedError:
            log.trace("Client disconnected from IPC %s", self.socket_path)
            self.streams.discard(stream)
        except Exception as exc:  # pylint: disable=broad-except
            log.error("Exception occurred while handling stream: %s", exc)
            if not stream.closed():
                stream.close()
            self.streams.discard(stream)
    def publish(self, msg):
        if not self.streams:
            return
        pack = salt.transport.frame.frame_msg_ipc(msg, raw_body=True)
        for stream in self.streams:
            self.io_loop.spawn_callback(self._write, stream, pack)
    def handle_connection(self, connection, address):
        log.trace("IPCServer: Handling connection to address: %s", address)
        try:
            kwargs = {}
            if self.opts["ipc_write_buffer"] &gt; 0:
                kwargs["max_write_buffer_size"] = self.opts["ipc_write_buffer"]
                log.trace(
                    "Setting IPC connection write buffer: %s",
                    (self.opts["ipc_write_buffer"]),
                )
            with salt.utils.asynchronous.current_ioloop(self.io_loop):
                stream = IOStream(connection, **kwargs)
            self.streams.add(stream)
            def discard_after_closed():
                self.streams.discard(stream)
            stream.set_close_callback(discard_after_closed)
        except Exception as exc:  # pylint: disable=broad-except
            log.error("IPC streaming error: %s", exc)
    def close(self):
        if self._closing:
            return
        self._closing = True
        for stream in self.streams:
            stream.close()
        self.streams.clear()
        if hasattr(self.sock, "close"):
            self.sock.close()
    def __enter__(self):
        return self
    def __exit__(self, *args):
        self.close()
class IPCMessageSubscriber(IPCClient):
    async_methods = [
        "read",
        "connect",
    ]
    close_methods = [
        "close",
    ]
    def __init__(self, socket_path, io_loop=None):
        super().__init__(socket_path, io_loop=io_loop)
        self._read_stream_future = None
        self._saved_data = []
        self._read_in_progress = Lock()
    @salt.ext.tornado.gen.coroutine
    def _read(self, timeout, callback=None):
        try:
            try:
                yield self._read_in_progress.acquire(timeout=0.00000001)
            except salt.ext.tornado.gen.TimeoutError:
                raise salt.ext.tornado.gen.Return(None)
            exc_to_raise = None
            ret = None
            try:
                while True:
                    if self._read_stream_future is None:
                        self._read_stream_future = self.stream.read_bytes(
                            4096, partial=True
                        )
                    if timeout is None:
                        wire_bytes = yield self._read_stream_future
                    else:
                        wire_bytes = yield FutureWithTimeout(
                            self.io_loop, self._read_stream_future, timeout
                        )
                    self._read_stream_future = None
                    timeout = None
                    self.unpacker.feed(wire_bytes)
                    first_sync_msg = True
                    for framed_msg in self.unpacker:
                        if callback:
                            self.io_loop.spawn_callback(callback, framed_msg["body"])
                        elif first_sync_msg:
                            ret = framed_msg["body"]
                            first_sync_msg = False
                        else:
                            self._saved_data.append(framed_msg["body"])
                    if not first_sync_msg:
                        break
            except TornadoTimeoutError:
                ret = None
            except StreamClosedError as exc:
                log.trace("Subscriber disconnected from IPC %s", self.socket_path)
                self._read_stream_future = None
            except Exception as exc:  # pylint: disable=broad-except
                log.error(
                    "Exception occurred in Subscriber while handling stream: %s", exc
                )
                self._read_stream_future = None
                exc_to_raise = exc
            self._read_in_progress.release()
            if exc_to_raise is not None:
                raise exc_to_raise  # pylint: disable=E0702
            raise salt.ext.tornado.gen.Return(ret)
        except TypeError:
            pass
    @salt.ext.tornado.gen.coroutine
    def read(self, timeout):
        if self._saved_data:
            res = self._saved_data.pop(0)
            raise salt.ext.tornado.gen.Return(res)
        while not self.connected():
            try:
                yield self.connect(timeout=5)
            except StreamClosedError:
                log.trace(
                    "Subscriber closed stream on IPC %s before connect",
                    self.socket_path,
                )
                yield salt.ext.tornado.gen.sleep(1)
            except Exception as exc:  # pylint: disable=broad-except
                log.error("Exception occurred while Subscriber connecting: %s", exc)
                yield salt.ext.tornado.gen.sleep(1)
        res = yield self._read(timeout)
        raise salt.ext.tornado.gen.Return(res)
    def read_sync(self, timeout=None):
        if self._saved_data:
            return self._saved_data.pop(0)
        return self.io_loop.run_sync(lambda: self._read(timeout))
    @salt.ext.tornado.gen.coroutine
    def read_async(self, callback):
        while not self.connected():
            try:
                yield self.connect(timeout=5)
            except StreamClosedError:
                log.trace(
                    "Subscriber closed stream on IPC %s before connect",
                    self.socket_path,
                )
                yield salt.ext.tornado.gen.sleep(1)
            except Exception as exc:  # pylint: disable=broad-except
                log.error("Exception occurred while Subscriber connecting: %s", exc)
                yield salt.ext.tornado.gen.sleep(1)
        yield self._read(None, callback)
    def close(self):
        if self._closing:
            return
        super().close()
        if self._read_stream_future is not None and self._read_stream_future.done():
            exc = self._read_stream_future.exception()
            if exc and not isinstance(exc, StreamClosedError):
                log.error("Read future returned exception %r", exc)
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>hgfs.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
<a name="0"></a>import copy
import errno
import fnmatch
<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>import glob
import hashlib
import logging
import os
import shutil
from datetime import datetime
import salt.fileserver
import salt.utils.data
import salt.utils.files
import salt.utils.gzip_util
import salt.utils.hashutils
import salt.utils.stringutils
import salt.utils.url
import salt.utils.versions
from salt.exceptions import FileserverConfigError
from salt.utils.event import tagify
VALID_BRANCH_METHODS = ("branches"</b></font>, "bookmarks", "mixed")
PER_REMOTE_OVERRIDES = ("base", "branch_method", "mountpoint", "root")
try:
    import hglib
    HAS_HG = True
except ImportError:
    HAS_HG = False
log = logging.getLogger(__name__)
__virtualname__ = "hgfs"
__virtual_aliases__ = ("hg",)
def __virtual__():
    if __virtualname__ not in __opts__["fileserver_backend"]:
        return False
    if not HAS_HG:
        log.error(
            "Mercurial fileserver backend is enabled in configuration "
            "but could not be loaded, is hglib installed?"
        )
        return False
    if __opts__["hgfs_branch_method"] not in VALID_BRANCH_METHODS:
        log.error(
            "Invalid hgfs_branch_method '%s'. Valid methods are: %s",
            __opts__["hgfs_branch_method"],
            VALID_BRANCH_METHODS,
        )
        return False
    if salt.utils.path.which("hg") is None:
        log.error("hgfs requested but hg executable is not available.")
        return False
    return __virtualname__
def _all_branches(repo):
    branches = [
        (salt<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.utils.stringutils.to_str(x[0]), x[1], salt.utils.stringutils.to_str(x[2]))
        for x in repo.</b></font>branches()
    ]
    return branches
def _get_branch(repo, name):
    try:
        return [x for x in _all_branches(repo) if x[0] == name][0]
    except IndexError:
        return False
def _all_bookmarks(repo):
    bookmarks = [
        (salt<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.utils.stringutils.to_str(x[0]), x[1], salt.utils.stringutils.to_str(x[2]))
        for x in repo.</b></font>bookmarks()[0]
    ]
    return bookmarks
def _get_bookmark(repo, name):
    try:
        return [x for x in _all_bookmarks(repo) if x[0] == name][0]
    except IndexError:
        return False
def _all_tags(repo):
    return [
        (
            salt.utils.stringutils.to_str(x[0]),
            x[1],
            salt.utils.stringutils.to_str(x[2]),
            x[3],
        )
        for x in repo.tags()
        if salt.utils.stringutils.to_str(x[0]) != "tip"
    ]
def _get_tag(repo, name):
    try:
        return [x for x in _all_tags(repo) if x[0] == name][0]
    except IndexError:
        return False
def _get_ref(repo, name):
    if name == "base":
        name = repo["base"]
    if name == repo["base"] or name in envs():
        if repo["branch_method"] == "branches":
            return _get_branch(repo["repo"], name) or _get_tag(repo["repo"], name)
        elif repo["branch_method"] == "bookmarks":
            return _get_bookmark(repo["repo"], name) or _get_tag(repo["repo"], name)
        elif repo["branch_method"] == "mixed":
            return (
                _get_branch(repo["repo"], name)
                or _get_bookmark(repo["repo"], name)
                or _get_tag(repo["repo"], name)
            )
    return False
def _get_manifest(repo, ref):
    manifest = [
        (
            <font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>salt.utils.stringutils.to_str(x[0]),
            salt.utils.stringutils.to_str(x[1]),
            x[</b></font>2],
            x[3],
            salt.utils.stringutils.to_str(x[4]),
        )
        for x in repo.manifest(rev=ref[1])
    ]
    return manifest
def _failhard():
    raise FileserverConfigError("Failed to load hg fileserver backend")
def init():
    bp_ = os.path.join(__opts__["cachedir"], "hgfs")
    new_remote = False
    repos = []
    per_remote_defaults = {}
    for param in PER_REMOTE_OVERRIDES:
        per_remote_defaults[param] = str(__opts__["hgfs_{}".format(param)])
    for remote in __opts__["hgfs_remotes"]:
        repo_conf = copy.deepcopy(per_remote_defaults)
        if isinstance(remote, dict):
            repo_url = next(iter(remote))
            per_remote_conf = {
                key: str(val)
                for key, val in salt.utils.data.repack_dictlist(
                    remote[repo_url]
                ).items()
            }
            if not per_remote_conf:
                log.error(
                    "Invalid per-remote configuration for hgfs remote %s. If "
                    "no per-remote parameters are being specified, there may "
                    "be a trailing colon after the URL, which should be "
                    "removed. Check the master configuration file.",
                    repo_url,
                )
                _failhard()
            branch_method = per_remote_conf.get(
                "branch_method", per_remote_defaults["branch_method"]
            )
            if branch_method not in VALID_BRANCH_METHODS:
                log.error(
                    "Invalid branch_method '%s' for remote %s. Valid "
                    "branch methods are: %s. This remote will be ignored.",
                    branch_method,
                    repo_url,
                    ", ".join(VALID_BRANCH_METHODS),
                )
                _failhard()
            per_remote_errors = False
            for param in (x for x in per_remote_conf if x not in PER_REMOTE_OVERRIDES):
                log.error(
                    "Invalid configuration parameter '%s' for remote %s. "
                    "Valid parameters are: %s. See the documentation for "
                    "further information.",
                    param,
                    repo_url,
                    ", ".join(PER_REMOTE_OVERRIDES),
                )
                per_remote_errors = True
            if per_remote_errors:
                _failhard()
            repo_conf.update(per_remote_conf)
        else:
            repo_url = remote
        if not isinstance(repo_url, str):
            log.error(
                "Invalid hgfs remote %s. Remotes must be strings, you may "
                "need to enclose the URL in quotes",
                repo_url,
            )
            _failhard()
        try:
            repo_conf["mountpoint"] = salt.utils.url.strip_proto(
                repo_conf["mountpoint"]
            )
        except TypeError:
            pass
        hash_type = getattr(hashlib, __opts__.get("hash_type", "md5"))
        repo_hash = hash_type(repo_url.encode("utf-8")).hexdigest()
        rp_ = os.path.join(bp_, repo_hash)
        if not os.path.isdir(rp_):
            os.makedirs(rp_)
        if not os.listdir(rp_):
            client = hglib.init(rp_)
            client.close()
            new_remote = True
        repo = None
        try:
            try:
                repo = hglib.open(rp_)
            except hglib.error.ServerError:
                log.error(
                    "Cache path %s (corresponding remote: %s) exists but is not "
                    "a valid mercurial repository. You will need to manually "
                    "delete this directory on the master to continue to use this "
                    "hgfs remote.",
                    rp_,
                    repo_url,
                )
                _failhard()
            except Exception as exc:  # pylint: disable=broad-except
                log.error(
                    "Exception '%s' encountered while initializing hgfs remote %s",
                    exc,
                    repo_url,
                )
                _failhard()
            try:
                refs = repo.config(names=b"paths")
            except hglib.error.CommandError:
                refs = None
            if not refs:
                hgconfpath = os.path.join(rp_, ".hg", "hgrc")
                with salt.utils.files.fopen(hgconfpath, "w+") as hgconfig:
                    hgconfig.write("[paths]\n")
                    hgconfig.write(
                        salt.utils.stringutils.to_str("default = {}\n".format(repo_url))
                    )
            repo_conf.update(
                {
                    "repo": repo,
                    "url": repo_url,
                    "hash": repo_hash,
                    "cachedir": rp_,
                    "lockfile": os.path.join(
                        __opts__["cachedir"], "hgfs", "{}.update.lk".format(repo_hash)
                    ),
                }
            )
            repos.append(repo_conf)
        finally:
            if repo:
                repo.close()
    if new_remote:
        remote_map = os.path.join(__opts__["cachedir"], "hgfs/remote_map.txt")
        try:
            with salt.utils.files.fopen(remote_map, "w+") as fp_:
                timestamp = datetime.now().strftime("%d %b %Y %H:%M:%S.%f")
                fp_.write("# hgfs_remote map as of {}\n".format(timestamp))
                for repo in repos:
                    fp_.write(
                        salt.utils.stringutils.to_str(
                            "{} = {}\n".format(repo["hash"], repo["url"])
                        )
                    )
        except OSError:
            pass
        else:
            log.info("Wrote new hgfs_remote map to %s", remote_map)
    return repos
def _clear_old_remotes():
    bp_ = os.path.join(__opts__["cachedir"], "hgfs")
    try:
        cachedir_ls = os.listdir(bp_)
    except OSError:
        cachedir_ls = []
    repos = init()
    for repo in repos:
        try:
            cachedir_ls.remove(repo["hash"])
        except ValueError:
            pass
    to_remove = []
    for item in cachedir_ls:
        if item in ("hash", "refs"):
            continue
        path = os.path.join(bp_, item)
        if os.path.isdir(path):
            to_remove.append(path)
    failed = []
    if to_remove:
        for rdir in to_remove:
            try:
                shutil.rmtree(rdir)
            except OSError as exc:
                log.error("Unable to remove old hgfs remote cachedir %s: %s", rdir, exc)
                failed.append(rdir)
            else:
                log.debug("hgfs removed old cachedir %s", rdir)
    for fdir in failed:
        to_remove.remove(fdir)
    return bool(to_remove), repos
def clear_cache():
    fsb_cachedir = os.path.join(__opts__["cachedir"], "hgfs")
    list_cachedir = os.path.join(__opts__["cachedir"], "file_lists/hgfs")
    errors = []
    for rdir in (fsb_cachedir, list_cachedir):
        if os.path.exists(rdir):
            try:
                shutil.rmtree(rdir)
            except OSError as exc:
                errors.append("Unable to delete {}: {}".format(rdir, exc))
    return errors
def clear_lock(remote=None):
    def _do_clear_lock(repo):
        def _add_error(errlist, repo, exc):
            msg = "Unable to remove update lock for {} ({}): {} ".format(
                repo["url"], repo["lockfile"], exc
            )
            log.debug(msg)
            errlist.append(msg)
        success = []
        failed = []
        if os.path.exists(repo["lockfile"]):
            try:
                os.remove(repo["lockfile"])
            except OSError as exc:
                if exc.errno == errno.EISDIR:
                    try:
                        shutil.rmtree(repo["lockfile"])
                    except OSError as exc:
                        _add_error(failed, repo, exc)
                else:
                    _add_error(failed, repo, exc)
            else:
                msg = "Removed lock for {}".format(repo["url"])
                log.debug(msg)
                success.append(msg)
        return success, failed
    if isinstance(remote, dict):
        return _do_clear_lock(remote)
    cleared = []
    errors = []
    for repo in init():
        try:
            if remote:
                try:
                    if not fnmatch.fnmatch(repo["url"], remote):
                        continue
                except TypeError:
                    if not fnmatch.fnmatch(repo["url"], str(remote)):
                        continue
            success, failed = _do_clear_lock(repo)
            cleared.extend(success)
            errors.extend(failed)
        finally:
            repo["repo"].close()
    return cleared, errors
def lock(remote=None):
    def _do_lock(repo):
        success = []
        failed = []
        if not os.path.exists(repo["lockfile"]):
            try:
                with salt.utils.files.fopen(repo["lockfile"], "w"):
                    pass
            except OSError as exc:
                msg = "Unable to set update lock for {} ({}): {} ".format(
                    repo["url"], repo["lockfile"], exc
                )
                log.debug(msg)
                failed.append(msg)
            else:
                msg = "Set lock for {}".format(repo["url"])
                log.debug(msg)
                success.append(msg)
        return success, failed
    if isinstance(remote, dict):
        return _do_lock(remote)
    locked = []
    errors = []
    for repo in init():
        try:
            if remote:
                try:
                    if not fnmatch.fnmatch(repo["url"], remote):
                        continue
                except TypeError:
                    if not fnmatch.fnmatch(repo["url"], str(remote)):
                        continue
            success, failed = _do_lock(repo)
            locked.extend(success)
            errors.extend(failed)
        finally:
            repo["repo"].close()
    return locked, errors
def update():
    data = {"changed": False, "backend": "hgfs"}
    data["changed"], repos = _clear_old_remotes()
    for repo in repos:
        try:
            if os.path.exists(repo["lockfile"]):
                log.warning(
                    "Update lockfile is present for hgfs remote %s, skipping. "
                    "If this warning persists, it is possible that the update "
                    "process was interrupted. Removing %s or running "
                    "'salt-run fileserver.clear_lock hgfs' will allow updates "
                    "to continue for this remote.",
                    repo["url"],
                    repo["lockfile"],
                )
                continue
            _, errors = lock(repo)
            if errors:
                log.error(
                    "Unable to set update lock for hgfs remote %s, skipping.",
                    repo["url"],
                )
                continue
            log.debug("hgfs is fetching from %s", repo["url"])
            repo["repo"].open()
            curtip = repo["repo"].tip()
            try:
                repo["repo"].pull()
            except Exception as exc:  # pylint: disable=broad-except
                log.error(
                    "Exception %s caught while updating hgfs remote %s",
                    exc,
                    repo["url"],
                    exc_info_on_loglevel=logging.DEBUG,
                )
            else:
                newtip = repo["repo"].tip()
                if curtip[1] != newtip[1]:
                    data["changed"] = True
        finally:
            repo["repo"].close()
        clear_lock(repo)
    env_cache = os.path.join(__opts__["cachedir"], "hgfs/envs.p")
    if data.get("changed", False) is True or not os.path.isfile(env_cache):
        env_cachedir = os.path.dirname(env_cache)
        if not os.path.exists(env_cachedir):
            os.makedirs(env_cachedir)
        new_envs = envs(ignore_cache=True)
        with salt.utils.files.fopen(env_cache, "wb+") as fp_:
            fp_.write(salt.payload.dumps(new_envs))
            log.trace("Wrote env cache data to %s", env_cache)
    if __opts__.get("fileserver_events", False):
        with salt.utils.event.get_event(
            "master",
            __opts__["sock_dir"],
            opts=__opts__,
            listen=False,
        ) as event:
            event.fire_event(data, tagify(["hgfs", "update"], prefix="fileserver"))
    try:
        salt.fileserver.reap_fileserver_cache_dir(
            os.path.join(__opts__["cachedir"], "hgfs/hash"), find_file
        )
    except OSError:
        pass
def _env_is_exposed(env):
    return salt.utils.stringutils.check_whitelist_blacklist(
        env,
        whitelist=__opts__["hgfs_saltenv_whitelist"],
        blacklist=__opts__["hgfs_saltenv_blacklist"],
    )
def envs(ignore_cache=False):
    if not ignore_cache:
        env_cache = os.path.join(__opts__["cachedir"], "hgfs/envs.p")
        cache_match = salt.fileserver.check_env_cache(__opts__, env_cache)
        if cache_match is not None:
            return cache_match
    ret = set()
    for repo in init():
        try:
            repo["repo"].open()
            if repo["branch_method"] in ("branches", "mixed"):
                for branch in _all_branches(repo["repo"]):
                    branch_name = branch[0]
                    if branch_name == repo["base"]:
                        branch_name = "base"
                    ret.add(branch_name)
            if repo["branch_method"] in ("bookmarks", "mixed"):
                for bookmark in _all_bookmarks(repo["repo"]):
                    bookmark_name = bookmark[0]
                    if bookmark_name == repo["base"]:
                        bookmark_name = "base"
                    ret.add(bookmark_name)
            ret.update([x[0] for x in _all_tags(repo["repo"])])
        finally:
            repo["repo"].close()
    return [x for x in sorted(ret) if _env_is_exposed(x)]
def find_file(path, tgt_env="base", **kwargs):  # pylint: disable=W0613
    fnd = {"path": "", "rel": ""}
    if os.path.isabs(path) or tgt_env not in envs():
        return fnd
    dest = os.path.join(__opts__["cachedir"], "hgfs/refs", tgt_env, path)
    hashes_glob = os.path.join(
        __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.hash.*".format(path)
    )
    blobshadest = os.path.join(
        __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.hash.blob_sha1".format(path)
    )
    lk_fn = os.path.join(
        __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.lk".format(path)
    )
    destdir = os.path.dirname(dest)
    hashdir = os.path.dirname(blobshadest)
    if not os.path.isdir(destdir):
        try:
            os.makedirs(destdir)
        except OSError:
            os.remove(destdir)
            os.makedirs(destdir)
    if not os.path.isdir(hashdir):
        try:
            os.makedirs(hashdir)
        except OSError:
            os.remove(hashdir)
            os.makedirs(hashdir)
    for repo in init():
        try:
            if repo["mountpoint"] and not path.startswith(
                repo["mountpoint"] + os.path.sep
            ):
                continue
            repo_path = path[len(repo["mountpoint"]) :].lstrip(os.path.sep)
            if repo["root"]:
                repo_path = os.path.join(repo["root"], repo_path)
            repo["repo"].open()
            ref = _get_ref(repo, tgt_env)
            if not ref:
                repo["repo"].close()
                continue
            salt.fileserver.wait_lock(lk_fn, dest)
            if os.path.isfile(blobshadest) and os.path.isfile(dest):
                with salt.utils.files.fopen(blobshadest, "r") as fp_:
                    sha = fp_.read()
                    if sha == ref[2]:
                        fnd["rel"] = path
                        fnd["path"] = dest
                        repo["repo"].close()
                        return fnd
            try:
                repo["repo"].cat(
                    [salt.utils.stringutils.to_bytes("path:{}".format(repo_path))],
                    rev=ref[2],
                    output=dest,
                )
            except hglib.error.CommandError:
                repo["repo"].close()
                continue
            with salt.utils.files.fopen(lk_fn, "w"):
                pass
            for filename in glob.glob(hashes_glob):
                try:
                    os.remove(filename)
                except Exception:  # pylint: disable=broad-except
                    pass
            with salt.utils.files.fopen(blobshadest, "w+") as fp_:
                fp_.write(salt.utils.stringutils.to_str(ref[2]))
            try:
                os.remove(lk_fn)
            except OSError:
                pass
            fnd["rel"] = path
            fnd["path"] = dest
            try:
                fnd["stat"] = list(os.stat(dest))
            except Exception:  # pylint: disable=broad-except
                pass
        finally:
            repo["repo"].close()
        return fnd
    return fnd
def serve_file(load, fnd):
    if "env" in load:
        load.pop("env")
    ret = {"data": "", "dest": ""}
    if not all(x in load for x in ("path", "loc", "saltenv")):
        return ret
    if not fnd["path"]:
        return ret
    ret["dest"] = fnd["rel"]
    gzip = load.get("gzip", None)
    fpath = os.path.normpath(fnd["path"])
    with salt.utils.files.fopen(fpath, "rb") as fp_:
        fp_.seek(load["loc"])
        data = fp_.read(__opts__["file_buffer_size"])
        if data and not salt.utils.files.is_binary(fpath):
            data = data.decode(__salt_system_encoding__)
        if gzip and data:
            data = salt.utils.gzip_util.compress(data, gzip)
            ret["gzip"] = gzip
        ret["data"] = data
    return ret
def file_hash(load, fnd):
    if "env" in load:
        load.pop("env")
    if not all(x in load for x in ("path", "saltenv")):
        return ""
    ret = {"hash_type": __opts__["hash_type"]}
    relpath = fnd["rel"]
    path = fnd["path"]
    hashdest = os.path.join(
        __opts__["cachedir"],
        "hgfs/hash",
        load["saltenv"],
        "{}.hash.{}".format(relpath, __opts__["hash_type"]),
    )
    if not os.path.isfile(hashdest):
        ret["hsum"] = salt.utils.hashutils.get_hash(path, __opts__["hash_type"])
        with salt.utils.files.fopen(hashdest, "w+") as fp_:
            fp_.write(ret["hsum"])
        return ret
    else:
        with salt.utils.files.fopen(hashdest, "rb") as fp_:
            ret["hsum"] = salt.utils.stringutils.to_unicode(fp_.read())
        return ret
def _file_lists(load, form):
    if "env" in load:
        load.pop("env")
    list_cachedir = os.path.join(__opts__["cachedir"], "file_lists/hgfs")
    if not os.path.isdir(list_cachedir):
        try:
            os.makedirs(list_cachedir)
        except os.error:
            log.critical("Unable to make cachedir %s", list_cachedir)
            return []
    list_cache = os.path.join(list_cachedir, "{}.p".format(load["saltenv"]))
    w_lock = os.path.join(list_cachedir, ".{}.w".format(load["saltenv"]))
    cache_match, refresh_cache, save_cache = salt.fileserver.check_file_list_cache(
        __opts__, form, list_cache, w_lock
    )
    if cache_match is not None:
        return cache_match
    if refresh_cache:
        ret = {}
        ret["files"] = _get_file_list(load)
        ret["dirs"] = _get_dir_list(load)
        if save_cache:
            salt.fileserver.write_file_list_cache(__opts__, ret, list_cache, w_lock)
        return ret.get(form, [])
    return []
def file_list(load):
    return _file_lists(load, "files")
def _get_file_list(load):
    if "env" in load:
        load.pop("env")
    if "saltenv" not in load or load["saltenv"] not in envs():
        return []
    ret = set()
    for repo in init():
        try:
            repo["repo"].open()
            ref = _get_ref(repo, load["saltenv"])
            if ref:
                manifest = _get_manifest(repo["repo"], ref=ref)
                for tup in manifest:
                    relpath = os.path.relpath(tup[4], repo["root"])
                    if not relpath.startswith("../"):
                        ret.add(os.path.join(repo["mountpoint"], relpath))
        finally:
            repo["repo"].close()
    return sorted(ret)
def file_list_emptydirs(load):  # pylint: disable=W0613
    return []
def dir_list(load):
    return _file_lists(load, "dirs")
def _get_dir_list(load):
    if "env" in load:
        load.pop("env")
    if "saltenv" not in load or load["saltenv"] not in envs():
        return []
    ret = set()
    for repo in init():
        try:
            repo["repo"].open()
            ref = _get_ref(repo, load["saltenv"])
            if ref:
                manifest = _get_manifest(repo["repo"], ref=ref)
                for tup in manifest:
                    filepath = tup[4]
                    split = filepath.rsplit("/", 1)
                    while len(split) &gt; 1:
                        relpath = os.path.relpath(split[0], repo["root"])
                        if relpath != ".":
                            if not relpath.startswith("../"):
                                ret.add(os.path.join(repo["mountpoint"], relpath))
                        split = split[0].rsplit("/", 1)
        finally:
            repo["repo"].close()
    if repo["mountpoint"]:
        ret.add(repo["mountpoint"])
    return sorted(ret)
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
