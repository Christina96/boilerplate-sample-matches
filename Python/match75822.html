<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for ipc.py &amp; hgfs.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for ipc.py &amp; hgfs.py
      </h3>
<h1 align="center">
        4.2%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>ipc.py (5.1087985%)<th>hgfs.py (3.6784742%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(6-24)<td><a href="#" name="0">(42-60)</a><td align="center"><font color="#ff0000">18</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(541-544)<td><a href="#" name="1">(139-140)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(137-140)<td><a href="#" name="2">(114-115)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(128-131)<td><a href="#" name="3">(214-216)</a><td align="center"><font color="#aa0000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>ipc.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 """
2 <font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>import errno
3 import logging
4 import socket
5 import time
6 import salt.ext.tornado
7 import salt.ext.tornado.concurrent
8 import salt.ext.tornado.gen
9 import salt.ext.tornado.ioloop
10 import salt.ext.tornado.netutil
11 import salt.transport.client
12 import salt.transport.frame
13 import salt.utils.msgpack
14 from salt.ext.tornado.ioloop import IOLoop
15 from salt.ext.tornado.ioloop import TimeoutError as TornadoTimeoutError
16 from salt.ext.tornado.iostream import IOStream, StreamClosedError
17 from salt.ext.tornado.locks import Lock
18 log = logging.</b></font>getLogger(__name__)
19 def future_with_timeout_callback(future):
20     if future._future_with_timeout is not None:
21         future._future_with_timeout._done_callback(future)
22 class FutureWithTimeout(salt.ext.tornado.concurrent.Future):
23     def __init__(self, io_loop, future, timeout):
24         super().__init__()
25         self.io_loop = io_loop
26         self._future = future
27         if timeout is not None:
28             if timeout &lt; 0.1:
29                 timeout = 0.1
30             self._timeout_handle = self.io_loop.add_timeout(
31                 self.io_loop.time() + timeout, self._timeout_callback
32             )
33         else:
34             self._timeout_handle = None
35         if hasattr(self._future, "_future_with_timeout"):
36             self._future._future_with_timeout = self
37             if self._future.done():
38                 future_with_timeout_callback(self._future)
39         else:
40             self._future._future_with_timeout = self
41             self._future.add_done_callback(future_with_timeout_callback)
42     def _timeout_callback(self):
43         self._timeout_handle = None
44         self._future._future_with_timeout = None
45         self.set_exception(TornadoTimeoutError())
46     def _done_callback(self, future):
47         try:
48             if self._timeout_handle is not None:
49                 self.io_loop.remove_timeout(self._timeout_handle)
50                 self._timeout_handle = None
51             self.set_result(future.result())
52         except Exception as exc:  # pylint: disable=broad-except
53             self.set_exception(exc)
54 class IPCServer:
55     """
56     A Tornado IPC server very similar to Tornado's TCPServer class
57     but using either UNIX domain sockets or TCP sockets
58     """
59     async_methods = [
60         "handle_stream",
61     ]
62     close_methods = [
63         "close",
64     ]
65     def __init__(self, socket_path, io_loop=None, payload_handler=None):
66         """
67         Create a new Tornado IPC server
68         :param str/int socket_path: Path on the filesystem for the
69                                     socket to bind to. This socket does
70                                     not need to exist prior to calling
71                                     this method, but parent directories
72                                     should.
73                                     It may also be of type 'int', in
74                                     which case it is used as the port
75                                     for a tcp localhost connection.
76         :param IOLoop io_loop: A Tornado ioloop to handle scheduling
77         :param func payload_handler: A function to customize handling of
78                                      incoming data.
79         """
80         self.socket_path = socket_path
81         self._started = False
82         self.payload_handler = payload_handler
83         self.sock = None
84         self.io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()
85         self._closing = False
86     def start(self):
87         """
88         Perform the work necessary to start up a Tornado IPC server
89         Blocks until socket is established
90         """
91         log.trace("IPCServer: binding to socket: %s", self.socket_path)
92         if isinstance(self.socket_path, int):
93             self.sock = socket.socket(socket<font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.AF_INET, socket.SOCK_STREAM)
94             self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
95             self.sock.setblocking(0)
96             self.sock.</b></font>bind(("127.0.0.1", self.socket_path))
97             self.sock.listen(128)
98             self.sock = salt.ext.tornado.netutil.bind_unix_socket(self.socket_path)
99         with salt<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.utils.asynchronous.current_ioloop(self.io_loop):
100             salt.ext.tornado.netutil.add_accept_handler(
101                 self.sock,
102                 self.</b></font>handle_connection,
103             )
104         self._started = True
105     @salt.ext.tornado.gen.coroutine
106     def handle_stream(self, stream):
107         """
108         Override this to handle the streams as they arrive
109         :param IOStream stream: An IOStream for processing
110         See https://tornado.readthedocs.io/en/latest/iostream.html#tornado.iostream.IOStream
111         for additional details.
112         """
113         @salt.ext.tornado.gen.coroutine
114         def _null(msg):
115             raise salt.ext.tornado.gen.Return(None)
116         def write_callback(stream, header):
117             if header.get("mid"):
118                 @salt.ext.tornado.gen.coroutine
119                 def return_message(msg):
120                     pack = salt.transport.frame.frame_msg_ipc(
121                         msg,
122                         header={"mid": header["mid"]},
123                         raw_body=True,
124                     )
125                     yield stream.write(pack)
126                 return return_message
127             else:
128                 return _null
129         if salt.utils.msgpack.version &gt;= (0, 5, 2):
130             msgpack_kwargs = {"raw": False}
131         else:
132             msgpack_kwargs = {"encoding": "utf-8"}
133         unpacker = salt.utils.msgpack.Unpacker(**msgpack_kwargs)
134         while not stream.closed():
135             try:
136                 wire_bytes = yield stream.read_bytes(4096, partial=True)
137                 unpacker.feed(wire_bytes)
138                 for framed_msg in unpacker:
139                     body = framed_msg["body"]
140                     self.io_loop.spawn_callback(
141                         self.payload_handler,
142                         body,
143                         write_callback(stream, framed_msg["head"]),
144                     )
145             except StreamClosedError:
146                 log.trace("Client disconnected from IPC %s", self.socket_path)
147                 break
148             except OSError as exc:
149                 if exc.errno == 0:
150                     log.trace(
151                         "Exception occurred with error number 0, "
152                         "spurious exception: %s",
153                         exc,
154                     )
155                 else:
156                     log.error("Exception occurred while handling stream: %s", exc)
157             except Exception as exc:  # pylint: disable=broad-except
158                 log.error("Exception occurred while handling stream: %s", exc)
159     def handle_connection(self, connection, address):
160         log.trace(
161             "IPCServer: Handling connection to address: %s",
162             address if address else connection,
163         )
164         try:
165             with salt.utils.asynchronous.current_ioloop(self.io_loop):
166                 stream = IOStream(
167                     connection,
168                 )
169             self.io_loop.spawn_callback(self.handle_stream, stream)
170         except Exception as exc:  # pylint: disable=broad-except
171             log.error("IPC streaming error: %s", exc)
172     def close(self):
173         """
174         Routines to handle any cleanup before the instance shuts down.
175         Sockets and filehandles should be closed explicitly, to prevent
176         leaks.
177         """
178         if self._closing:
179             return
180         self._closing = True
181         if hasattr(self.sock, "close"):
182             self.sock.close()
183     def __del__(self):
184         try:
185             self.close()
186         except TypeError:
187             pass
188     def __enter__(self):
189         return self
190     def __exit__(self, *args):
191         self.close()
192 class IPCClient:
193     """
194     A Tornado IPC client very similar to Tornado's TCPClient class
195     but using either UNIX domain sockets or TCP sockets
196     This was written because Tornado does not have its own IPC
197     server/client implementation.
198     :param IOLoop io_loop: A Tornado ioloop to handle scheduling
199     :param str/int socket_path: A path on the filesystem where a socket
200                                 belonging to a running IPCServer can be
201                                 found.
202                                 It may also be of type 'int', in which
203                                 case it is used as the port for a tcp
204                                 localhost connection.
205     """
206     def __init__(self, socket_path, io_loop=None):
207         """
208         Create a new IPC client
209         IPC clients cannot bind to ports, but must connect to
210         existing IPC servers. Clients can then send messages
211         to the server.
212         """
213         self.io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()
214         self.socket_path = socket_path
215         self._closing = False
216         self.stream = None
217         if salt.utils.msgpack.version &gt;= (0, 5, 2):
218             msgpack_kwargs = {"raw": False}
219         else:
220             msgpack_kwargs = {"encoding": "utf-8"}
221         self.unpacker = salt.utils.msgpack.Unpacker(**msgpack_kwargs)
222         self._connecting_future = None
223     def connected(self):
224         return self.stream is not None and not self.stream.closed()
225     def connect(self, callback=None, timeout=None):
226         """
227         Connect to the IPC socket
228         """
229         if self._connecting_future is not None and not self._connecting_future.done():
230             future = self._connecting_future
231         else:
232             if self._connecting_future is not None:
233                 self._connecting_future.exception()  # pylint: disable=E0203
234             future = salt.ext.tornado.concurrent.Future()
235             self._connecting_future = future
236             self._connect(timeout)
237         if callback is not None:
238             def handle_future(future):
239                 response = future.result()
240                 self.io_loop.add_callback(callback, response)
241             future.add_done_callback(handle_future)
242         return future
243     @salt.ext.tornado.gen.coroutine
244     def _connect(self, timeout=None):
245         """
246         Connect to a running IPCServer
247         """
248         if isinstance(self.socket_path, int):
249             sock_type = socket.AF_INET
250             sock_addr = ("127.0.0.1", self.socket_path)
251         else:
252             sock_type = socket.AF_UNIX
253             sock_addr = self.socket_path
254         self.stream = None
255         if timeout is not None:
256             timeout_at = time.time() + timeout
257         while True:
258             if self._closing:
259                 break
260             if self.stream is None:
261                 with salt.utils.asynchronous.current_ioloop(self.io_loop):
262                     self.stream = IOStream(socket.socket(sock_type, socket.SOCK_STREAM))
263             try:
264                 log.trace("IPCClient: Connecting to socket: %s", self.socket_path)
265                 yield self.stream.connect(sock_addr)
266                 self._connecting_future.set_result(True)
267                 break
268             except Exception as e:  # pylint: disable=broad-except
269                 if self.stream.closed():
270                     self.stream = None
271                 if timeout is None or time.time() &gt; timeout_at:
272                     if self.stream is not None:
273                         self.stream.close()
274                         self.stream = None
275                     self._connecting_future.set_exception(e)
276                     break
277                 yield salt.ext.tornado.gen.sleep(1)
278     def close(self):
279         """
280         Routines to handle any cleanup before the instance shuts down.
281         Sockets and filehandles should be closed explicitly, to prevent
282         leaks.
283         """
284         if self._closing:
285             return
286         self._closing = True
287         self._connecting_future = None
288         log.debug("Closing %s instance", self.__class__.__name__)
289         if self.stream is not None and not self.stream.closed():
290             try:
291                 self.stream.close()
292             except OSError as exc:
293                 if exc.errno != errno.EBADF:
294                     raise
295     def __del__(self):
296         try:
297             self.close()
298         except TypeError:
299             pass
300     def __enter__(self):
301         return self
302     def __exit__(self, *args):
303         self.close()
304 class IPCMessageClient(IPCClient):
305     """
306     Salt IPC message client
307     Create an IPC client to send messages to an IPC server
308     An example of a very simple IPCMessageClient connecting to an IPCServer. This
309     example assumes an already running IPCMessage server.
310     IMPORTANT: The below example also assumes a running IOLoop process.
311     import salt.ext.tornado.ioloop
312     import salt.config
313     import salt.transport.ipc
314     io_loop = salt.ext.tornado.ioloop.IOLoop.current()
315     ipc_server_socket_path = '/var/run/ipc_server.ipc'
316     ipc_client = salt.transport.ipc.IPCMessageClient(ipc_server_socket_path, io_loop=io_loop)
317     ipc_client.connect()
318     ipc_client.send('Hello world')
319     """
320     async_methods = [
321         "send",
322         "connect",
323         "_connect",
324     ]
325     close_methods = [
326         "close",
327     ]
328     @salt.ext.tornado.gen.coroutine
329     def send(self, msg, timeout=None, tries=None):
330         """
331         Send a message to an IPC socket
332         If the socket is not currently connected, a connection will be established.
333         :param dict msg: The message to be sent
334         :param int timeout: Timeout when sending message (Currently unimplemented)
335         """
336         if not self.connected():
337             yield self.connect()
338         pack = salt.transport.frame.frame_msg_ipc(msg, raw_body=True)
339         yield self.stream.write(pack)
340 class IPCMessageServer(IPCServer):
341     """
342     Salt IPC message server
343     Creates a message server which can create and bind to a socket on a given
344     path and then respond to messages asynchronously.
345     An example of a very simple IPCServer which prints received messages to
346     a console:
347         import salt.ext.tornado.ioloop
348         import salt.transport.ipc
349         io_loop = salt.ext.tornado.ioloop.IOLoop.current()
350         ipc_server_socket_path = '/var/run/ipc_server.ipc'
351         ipc_server = salt.transport.ipc.IPCMessageServer(ipc_server_socket_path, io_loop=io_loop,
352                                                          payload_handler=print_to_console)
353         ipc_server.start()
354         io_loop.start()
355         def print_to_console(payload):
356             print(payload)
357     See IPCMessageClient() for an example of sending messages to an IPCMessageServer instance
358     """
359 class IPCMessagePublisher:
360     """
361     A Tornado IPC Publisher similar to Tornado's TCPServer class
362     but using either UNIX domain sockets or TCP sockets
363     """
364     def __init__(self, opts, socket_path, io_loop=None):
365         """
366         Create a new Tornado IPC server
367         :param dict opts: Salt options
368         :param str/int socket_path: Path on the filesystem for the
369                                     socket to bind to. This socket does
370                                     not need to exist prior to calling
371                                     this method, but parent directories
372                                     should.
373                                     It may also be of type 'int', in
374                                     which case it is used as the port
375                                     for a tcp localhost connection.
376         :param IOLoop io_loop: A Tornado ioloop to handle scheduling
377         """
378         self.opts = opts
379         self.socket_path = socket_path
380         self._started = False
381         self.sock = None
382         self.io_loop = io_loop or IOLoop.current()
383         self._closing = False
384         self.streams = set()
385     def start(self):
386         """
387         Perform the work necessary to start up a Tornado IPC server
388         Blocks until socket is established
389         """
390         log.trace("IPCMessagePublisher: binding to socket: %s", self.socket_path)
391         if isinstance(self.socket_path, int):
392             self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
393             self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
394             self.sock.setblocking(0)
395             self.sock.bind(("127.0.0.1", self.socket_path))
396             self.sock.listen(128)
397             self.sock = salt.ext.tornado.netutil.bind_unix_socket(self.socket_path)
398         with salt<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.utils.asynchronous.current_ioloop(self.io_loop):
399             salt.ext.tornado.netutil.add_accept_handler(
400                 self.sock,
401                 self.</b></font>handle_connection,
402             )
403         self._started = True
404     @salt.ext.tornado.gen.coroutine
405     def _write(self, stream, pack):
406         try:
407             yield stream.write(pack)
408         except StreamClosedError:
409             log.trace("Client disconnected from IPC %s", self.socket_path)
410             self.streams.discard(stream)
411         except Exception as exc:  # pylint: disable=broad-except
412             log.error("Exception occurred while handling stream: %s", exc)
413             if not stream.closed():
414                 stream.close()
415             self.streams.discard(stream)
416     def publish(self, msg):
417         """
418         Send message to all connected sockets
419         """
420         if not self.streams:
421             return
422         pack = salt.transport.frame.frame_msg_ipc(msg, raw_body=True)
423         for stream in self.streams:
424             self.io_loop.spawn_callback(self._write, stream, pack)
425     def handle_connection(self, connection, address):
426         log.trace("IPCServer: Handling connection to address: %s", address)
427         try:
428             kwargs = {}
429             if self.opts["ipc_write_buffer"] &gt; 0:
430                 kwargs["max_write_buffer_size"] = self.opts["ipc_write_buffer"]
431                 log.trace(
432                     "Setting IPC connection write buffer: %s",
433                     (self.opts["ipc_write_buffer"]),
434                 )
435             with salt.utils.asynchronous.current_ioloop(self.io_loop):
436                 stream = IOStream(connection, **kwargs)
437             self.streams.add(stream)
438             def discard_after_closed():
439                 self.streams.discard(stream)
440             stream.set_close_callback(discard_after_closed)
441         except Exception as exc:  # pylint: disable=broad-except
442             log.error("IPC streaming error: %s", exc)
443     def close(self):
444         """
445         Routines to handle any cleanup before the instance shuts down.
446         Sockets and filehandles should be closed explicitly, to prevent
447         leaks.
448         """
449         if self._closing:
450             return
451         self._closing = True
452         for stream in self.streams:
453             stream.close()
454         self.streams.clear()
455         if hasattr(self.sock, "close"):
456             self.sock.close()
457     def __enter__(self):
458         return self
459     def __exit__(self, *args):
460         self.close()
461 class IPCMessageSubscriber(IPCClient):
462     """
463     Salt IPC message subscriber
464     Create an IPC client to receive messages from IPC publisher
465     An example of a very simple IPCMessageSubscriber connecting to an IPCMessagePublisher.
466     This example assumes an already running IPCMessagePublisher.
467     IMPORTANT: The below example also assumes the IOLoop is NOT running.
468     import salt.ext.tornado.ioloop
469     import salt.config
470     import salt.transport.ipc
471     io_loop = salt.ext.tornado.ioloop.IOLoop()
472     ipc_publisher_socket_path = '/var/run/ipc_publisher.ipc'
473     ipc_subscriber = salt.transport.ipc.IPCMessageSubscriber(ipc_server_socket_path, io_loop=io_loop)
474     io_loop.run_sync(ipc_subscriber.connect)
475     package = ipc_subscriber.read_sync()
476     """
477     async_methods = [
478         "read",
479         "connect",
480     ]
481     close_methods = [
482         "close",
483     ]
484     def __init__(self, socket_path, io_loop=None):
485         super().__init__(socket_path, io_loop=io_loop)
486         self._read_stream_future = None
487         self._saved_data = []
488         self._read_in_progress = Lock()
489     @salt.ext.tornado.gen.coroutine
490     def _read(self, timeout, callback=None):
491         try:
492             try:
493                 yield self._read_in_progress.acquire(timeout=0.00000001)
494             except salt.ext.tornado.gen.TimeoutError:
495                 raise salt.ext.tornado.gen.Return(None)
496             exc_to_raise = None
497             ret = None
498             try:
499                 while True:
500                     if self._read_stream_future is None:
501                         self._read_stream_future = self.stream.read_bytes(
502                             4096, partial=True
503                         )
504                     if timeout is None:
505                         wire_bytes = yield self._read_stream_future
506                     else:
507                         wire_bytes = yield FutureWithTimeout(
508                             self.io_loop, self._read_stream_future, timeout
509                         )
510                     self._read_stream_future = None
511                     timeout = None
512                     self.unpacker.feed(wire_bytes)
513                     first_sync_msg = True
514                     for framed_msg in self.unpacker:
515                         if callback:
516                             self.io_loop.spawn_callback(callback, framed_msg["body"])
517                         elif first_sync_msg:
518                             ret = framed_msg["body"]
519                             first_sync_msg = False
520                         else:
521                             self._saved_data.append(framed_msg["body"])
522                     if not first_sync_msg:
523                         break
524             except TornadoTimeoutError:
525                 ret = None
526             except StreamClosedError as exc:
527                 log.trace("Subscriber disconnected from IPC %s", self.socket_path)
528                 self._read_stream_future = None
529             except Exception as exc:  # pylint: disable=broad-except
530                 log.error(
531                     "Exception occurred in Subscriber while handling stream: %s", exc
532                 )
533                 self._read_stream_future = None
534                 exc_to_raise = exc
535             self._read_in_progress.release()
536             if exc_to_raise is not None:
537                 raise exc_to_raise  # pylint: disable=E0702
538             raise salt.ext.tornado.gen.Return(ret)
539         except TypeError:
540             pass
541     @salt.ext.tornado.gen.coroutine
542     def read(self, timeout):
543         """
544         Asynchronously read messages and invoke a callback when they are ready.
545         :param callback: A callback with the received data
546         """
547         if self._saved_data:
548             res = self._saved_data.pop(0)
549             raise salt.ext.tornado.gen.Return(res)
550         while not self.connected():
551             try:
552                 yield self.connect(timeout=5)
553             except StreamClosedError:
554                 log.trace(
555                     "Subscriber closed stream on IPC %s before connect",
556                     self.socket_path,
557                 )
558                 yield salt.ext.tornado.gen.sleep(1)
559             except Exception as exc:  # pylint: disable=broad-except
560                 log.error("Exception occurred while Subscriber connecting: %s", exc)
561                 yield salt.ext.tornado.gen.sleep(1)
562         res = yield self._read(timeout)
563         raise salt.ext.tornado.gen.Return(res)
564     def read_sync(self, timeout=None):
565         """
566         Read a message from an IPC socket
567         The socket must already be connected.
568         The associated IO Loop must NOT be running.
569         :param int timeout: Timeout when receiving message
570         :return: message data if successful. None if timed out. Will raise an
571                  exception for all other error conditions.
572         """
573         if self._saved_data:
574             return self._saved_data.pop(0)
575         return self.io_loop.run_sync(lambda: self._read(timeout))
576     @salt.ext.tornado.gen.coroutine
577     def read_async(self, callback):
578         """
579         Asynchronously read messages and invoke a callback when they are ready.
580         :param callback: A callback with the received data
581         """
582         while not self.connected():
583             try:
584                 yield self.connect(timeout=5)
585             except StreamClosedError:
586                 log.trace(
587                     "Subscriber closed stream on IPC %s before connect",
588                     self.socket_path,
589                 )
590                 yield salt.ext.tornado.gen.sleep(1)
591             except Exception as exc:  # pylint: disable=broad-except
592                 log.error("Exception occurred while Subscriber connecting: %s", exc)
593                 yield salt.ext.tornado.gen.sleep(1)
594         yield self._read(None, callback)
595     def close(self):
596         """
597         Routines to handle any cleanup before the instance shuts down.
598         Sockets and filehandles should be closed explicitly, to prevent
599         leaks.
600         """
601         if self._closing:
602             return
603         super().close()
604         if self._read_stream_future is not None and self._read_stream_future.done():
605             exc = self._read_stream_future.exception()
606             if exc and not isinstance(exc, StreamClosedError):
607                 log.error("Read future returned exception %r", exc)
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>hgfs.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 """
2 Mercurial Fileserver Backend
3 To enable, add ``hgfs`` to the :conf_master:`fileserver_backend` option in the
4 Master config file.
5 .. code-block:: yaml
6     fileserver_backend:
7       - hgfs
8 .. note::
9     ``hg`` also works here. Prior to the 2018.3.0 release, *only* ``hg`` would
10     work.
11 After enabling this backend, branches, bookmarks, and tags in a remote
12 mercurial repository are exposed to salt as different environments. This
13 feature is managed by the :conf_master:`fileserver_backend` option in the salt
14 master config file.
15 This fileserver has an additional option :conf_master:`hgfs_branch_method` that
16 will set the desired branch method. Possible values are: ``branches``,
17 ``bookmarks``, or ``mixed``. If using ``branches`` or ``mixed``, the
18 ``default`` branch will be mapped to ``base``.
19 .. versionchanged:: 2014.1.0
20     The :conf_master:`hgfs_base` master config parameter was added, allowing
21     for a branch other than ``default`` to be used for the ``base``
22     environment, and allowing for a ``base`` environment to be specified when
23     using an :conf_master:`hgfs_branch_method` of ``bookmarks``.
24 :depends:   - mercurial
25             - python bindings for mercurial (``python-hglib``)
26 """
27 import errno
28 import fnmatch
29 <font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>import glob
30 import hashlib
31 import logging
32 import os
33 import shutil
34 from datetime import datetime
35 import salt.fileserver
36 import salt.utils.data
37 import salt.utils.files
38 import salt.utils.gzip_util
39 import salt.utils.hashutils
40 import salt.utils.stringutils
41 import salt.utils.url
42 import salt.utils.versions
43 from salt.exceptions import FileserverConfigError
44 from salt.utils.event import tagify
45 VALID_BRANCH_METHODS = ("branches"</b></font>, "bookmarks", "mixed")
46 PER_REMOTE_OVERRIDES = ("base", "branch_method", "mountpoint", "root")
47 try:
48     import hglib
49     HAS_HG = True
50 except ImportError:
51     HAS_HG = False
52 log = logging.getLogger(__name__)
53 __virtualname__ = "hgfs"
54 __virtual_aliases__ = ("hg",)
55 def __virtual__():
56     """
57     Only load if mercurial is available
58     """
59     if __virtualname__ not in __opts__["fileserver_backend"]:
60         return False
61     if not HAS_HG:
62         log.error(
63             "Mercurial fileserver backend is enabled in configuration "
64             "but could not be loaded, is hglib installed?"
65         )
66         return False
67     if __opts__["hgfs_branch_method"] not in VALID_BRANCH_METHODS:
68         log.error(
69             "Invalid hgfs_branch_method '%s'. Valid methods are: %s",
70             __opts__["hgfs_branch_method"],
71             VALID_BRANCH_METHODS,
72         )
73         return False
74     if salt.utils.path.which("hg") is None:
75         log.error("hgfs requested but hg executable is not available.")
76         return False
77     return __virtualname__
78 def _all_branches(repo):
79     """
80     Returns all branches for the specified repo
81     """
82     branches = [
83         (salt<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.utils.stringutils.to_str(x[0]), x[1], salt.utils.stringutils.to_str(x[2]))
84         for x in repo.</b></font>branches()
85     ]
86     return branches
87 def _get_branch(repo, name):
88     """
89     Find the requested branch in the specified repo
90     """
91     try:
92         return [x for x in _all_branches(repo) if x[0] == name][0]
93     except IndexError:
94         return False
95 def _all_bookmarks(repo):
96     """
97     Returns all bookmarks for the specified repo
98     """
99     bookmarks = [
100         (salt<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.utils.stringutils.to_str(x[0]), x[1], salt.utils.stringutils.to_str(x[2]))
101         for x in repo.</b></font>bookmarks()[0]
102     ]
103     return bookmarks
104 def _get_bookmark(repo, name):
105     """
106     Find the requested bookmark in the specified repo
107     """
108     try:
109         return [x for x in _all_bookmarks(repo) if x[0] == name][0]
110     except IndexError:
111         return False
112 def _all_tags(repo):
113     """
114     Returns all tags for the specified repo
115     """
116     return [
117         (
118             salt.utils.stringutils.to_str(x[0]),
119             x[1],
120             salt.utils.stringutils.to_str(x[2]),
121             x[3],
122         )
123         for x in repo.tags()
124         if salt.utils.stringutils.to_str(x[0]) != "tip"
125     ]
126 def _get_tag(repo, name):
127     """
128     Find the requested tag in the specified repo
129     """
130     try:
131         return [x for x in _all_tags(repo) if x[0] == name][0]
132     except IndexError:
133         return False
134 def _get_ref(repo, name):
135     """
136     Return ref tuple if ref is in the repo.
137     """
138     if name == "base":
139         name = repo["base"]
140     if name == repo["base"] or name in envs():
141         if repo["branch_method"] == "branches":
142             return _get_branch(repo["repo"], name) or _get_tag(repo["repo"], name)
143         elif repo["branch_method"] == "bookmarks":
144             return _get_bookmark(repo["repo"], name) or _get_tag(repo["repo"], name)
145         elif repo["branch_method"] == "mixed":
146             return (
147                 _get_branch(repo["repo"], name)
148                 or _get_bookmark(repo["repo"], name)
149                 or _get_tag(repo["repo"], name)
150             )
151     return False
152 def _get_manifest(repo, ref):
153     """
154     Get manifest for ref
155     """
156     manifest = [
157         (
158             <font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>salt.utils.stringutils.to_str(x[0]),
159             salt.utils.stringutils.to_str(x[1]),
160             x[</b></font>2],
161             x[3],
162             salt.utils.stringutils.to_str(x[4]),
163         )
164         for x in repo.manifest(rev=ref[1])
165     ]
166     return manifest
167 def _failhard():
168     """
169     Fatal fileserver configuration issue, raise an exception
170     """
171     raise FileserverConfigError("Failed to load hg fileserver backend")
172 def init():
173     """
174     Return a list of hglib objects for the various hgfs remotes
175     """
176     bp_ = os.path.join(__opts__["cachedir"], "hgfs")
177     new_remote = False
178     repos = []
179     per_remote_defaults = {}
180     for param in PER_REMOTE_OVERRIDES:
181         per_remote_defaults[param] = str(__opts__["hgfs_{}".format(param)])
182     for remote in __opts__["hgfs_remotes"]:
183         repo_conf = copy.deepcopy(per_remote_defaults)
184         if isinstance(remote, dict):
185             repo_url = next(iter(remote))
186             per_remote_conf = {
187                 key: str(val)
188                 for key, val in salt.utils.data.repack_dictlist(
189                     remote[repo_url]
190                 ).items()
191             }
192             if not per_remote_conf:
193                 log.error(
194                     "Invalid per-remote configuration for hgfs remote %s. If "
195                     "no per-remote parameters are being specified, there may "
196                     "be a trailing colon after the URL, which should be "
197                     "removed. Check the master configuration file.",
198                     repo_url,
199                 )
200                 _failhard()
201             branch_method = per_remote_conf.get(
202                 "branch_method", per_remote_defaults["branch_method"]
203             )
204             if branch_method not in VALID_BRANCH_METHODS:
205                 log.error(
206                     "Invalid branch_method '%s' for remote %s. Valid "
207                     "branch methods are: %s. This remote will be ignored.",
208                     branch_method,
209                     repo_url,
210                     ", ".join(VALID_BRANCH_METHODS),
211                 )
212                 _failhard()
213             per_remote_errors = False
214             for param in (x for x in per_remote_conf if x not in PER_REMOTE_OVERRIDES):
215                 log.error(
216                     "Invalid configuration parameter '%s' for remote %s. "
217                     "Valid parameters are: %s. See the documentation for "
218                     "further information.",
219                     param,
220                     repo_url,
221                     ", ".join(PER_REMOTE_OVERRIDES),
222                 )
223                 per_remote_errors = True
224             if per_remote_errors:
225                 _failhard()
226             repo_conf.update(per_remote_conf)
227         else:
228             repo_url = remote
229         if not isinstance(repo_url, str):
230             log.error(
231                 "Invalid hgfs remote %s. Remotes must be strings, you may "
232                 "need to enclose the URL in quotes",
233                 repo_url,
234             )
235             _failhard()
236         try:
237             repo_conf["mountpoint"] = salt.utils.url.strip_proto(
238                 repo_conf["mountpoint"]
239             )
240         except TypeError:
241             pass
242         hash_type = getattr(hashlib, __opts__.get("hash_type", "md5"))
243         repo_hash = hash_type(repo_url.encode("utf-8")).hexdigest()
244         rp_ = os.path.join(bp_, repo_hash)
245         if not os.path.isdir(rp_):
246             os.makedirs(rp_)
247         if not os.listdir(rp_):
248             client = hglib.init(rp_)
249             client.close()
250             new_remote = True
251         repo = None
252         try:
253             try:
254                 repo = hglib.open(rp_)
255             except hglib.error.ServerError:
256                 log.error(
257                     "Cache path %s (corresponding remote: %s) exists but is not "
258                     "a valid mercurial repository. You will need to manually "
259                     "delete this directory on the master to continue to use this "
260                     "hgfs remote.",
261                     rp_,
262                     repo_url,
263                 )
264                 _failhard()
265             except Exception as exc:  # pylint: disable=broad-except
266                 log.error(
267                     "Exception '%s' encountered while initializing hgfs remote %s",
268                     exc,
269                     repo_url,
270                 )
271                 _failhard()
272             try:
273                 refs = repo.config(names=b"paths")
274             except hglib.error.CommandError:
275                 refs = None
276             if not refs:
277                 hgconfpath = os.path.join(rp_, ".hg", "hgrc")
278                 with salt.utils.files.fopen(hgconfpath, "w+") as hgconfig:
279                     hgconfig.write("[paths]\n")
280                     hgconfig.write(
281                         salt.utils.stringutils.to_str("default = {}\n".format(repo_url))
282                     )
283             repo_conf.update(
284                 {
285                     "repo": repo,
286                     "url": repo_url,
287                     "hash": repo_hash,
288                     "cachedir": rp_,
289                     "lockfile": os.path.join(
290                         __opts__["cachedir"], "hgfs", "{}.update.lk".format(repo_hash)
291                     ),
292                 }
293             )
294             repos.append(repo_conf)
295         finally:
296             if repo:
297                 repo.close()
298     if new_remote:
299         remote_map = os.path.join(__opts__["cachedir"], "hgfs/remote_map.txt")
300         try:
301             with salt.utils.files.fopen(remote_map, "w+") as fp_:
302                 timestamp = datetime.now().strftime("%d %b %Y %H:%M:%S.%f")
303                 fp_.write("# hgfs_remote map as of {}\n".format(timestamp))
304                 for repo in repos:
305                     fp_.write(
306                         salt.utils.stringutils.to_str(
307                             "{} = {}\n".format(repo["hash"], repo["url"])
308                         )
309                     )
310         except OSError:
311             pass
312         else:
313             log.info("Wrote new hgfs_remote map to %s", remote_map)
314     return repos
315 def _clear_old_remotes():
316     """
317     Remove cache directories for remotes no longer configured
318     """
319     bp_ = os.path.join(__opts__["cachedir"], "hgfs")
320     try:
321         cachedir_ls = os.listdir(bp_)
322     except OSError:
323         cachedir_ls = []
324     repos = init()
325     for repo in repos:
326         try:
327             cachedir_ls.remove(repo["hash"])
328         except ValueError:
329             pass
330     to_remove = []
331     for item in cachedir_ls:
332         if item in ("hash", "refs"):
333             continue
334         path = os.path.join(bp_, item)
335         if os.path.isdir(path):
336             to_remove.append(path)
337     failed = []
338     if to_remove:
339         for rdir in to_remove:
340             try:
341                 shutil.rmtree(rdir)
342             except OSError as exc:
343                 log.error("Unable to remove old hgfs remote cachedir %s: %s", rdir, exc)
344                 failed.append(rdir)
345             else:
346                 log.debug("hgfs removed old cachedir %s", rdir)
347     for fdir in failed:
348         to_remove.remove(fdir)
349     return bool(to_remove), repos
350 def clear_cache():
351     """
352     Completely clear hgfs cache
353     """
354     fsb_cachedir = os.path.join(__opts__["cachedir"], "hgfs")
355     list_cachedir = os.path.join(__opts__["cachedir"], "file_lists/hgfs")
356     errors = []
357     for rdir in (fsb_cachedir, list_cachedir):
358         if os.path.exists(rdir):
359             try:
360                 shutil.rmtree(rdir)
361             except OSError as exc:
362                 errors.append("Unable to delete {}: {}".format(rdir, exc))
363     return errors
364 def clear_lock(remote=None):
365     """
366     Clear update.lk
367     ``remote`` can either be a dictionary containing repo configuration
368     information, or a pattern. If the latter, then remotes for which the URL
369     matches the pattern will be locked.
370     """
371     def _do_clear_lock(repo):
372         def _add_error(errlist, repo, exc):
373             msg = "Unable to remove update lock for {} ({}): {} ".format(
374                 repo["url"], repo["lockfile"], exc
375             )
376             log.debug(msg)
377             errlist.append(msg)
378         success = []
379         failed = []
380         if os.path.exists(repo["lockfile"]):
381             try:
382                 os.remove(repo["lockfile"])
383             except OSError as exc:
384                 if exc.errno == errno.EISDIR:
385                     try:
386                         shutil.rmtree(repo["lockfile"])
387                     except OSError as exc:
388                         _add_error(failed, repo, exc)
389                 else:
390                     _add_error(failed, repo, exc)
391             else:
392                 msg = "Removed lock for {}".format(repo["url"])
393                 log.debug(msg)
394                 success.append(msg)
395         return success, failed
396     if isinstance(remote, dict):
397         return _do_clear_lock(remote)
398     cleared = []
399     errors = []
400     for repo in init():
401         try:
402             if remote:
403                 try:
404                     if not fnmatch.fnmatch(repo["url"], remote):
405                         continue
406                 except TypeError:
407                     if not fnmatch.fnmatch(repo["url"], str(remote)):
408                         continue
409             success, failed = _do_clear_lock(repo)
410             cleared.extend(success)
411             errors.extend(failed)
412         finally:
413             repo["repo"].close()
414     return cleared, errors
415 def lock(remote=None):
416     """
417     Place an update.lk
418     ``remote`` can either be a dictionary containing repo configuration
419     information, or a pattern. If the latter, then remotes for which the URL
420     matches the pattern will be locked.
421     """
422     def _do_lock(repo):
423         success = []
424         failed = []
425         if not os.path.exists(repo["lockfile"]):
426             try:
427                 with salt.utils.files.fopen(repo["lockfile"], "w"):
428                     pass
429             except OSError as exc:
430                 msg = "Unable to set update lock for {} ({}): {} ".format(
431                     repo["url"], repo["lockfile"], exc
432                 )
433                 log.debug(msg)
434                 failed.append(msg)
435             else:
436                 msg = "Set lock for {}".format(repo["url"])
437                 log.debug(msg)
438                 success.append(msg)
439         return success, failed
440     if isinstance(remote, dict):
441         return _do_lock(remote)
442     locked = []
443     errors = []
444     for repo in init():
445         try:
446             if remote:
447                 try:
448                     if not fnmatch.fnmatch(repo["url"], remote):
449                         continue
450                 except TypeError:
451                     if not fnmatch.fnmatch(repo["url"], str(remote)):
452                         continue
453             success, failed = _do_lock(repo)
454             locked.extend(success)
455             errors.extend(failed)
456         finally:
457             repo["repo"].close()
458     return locked, errors
459 def update():
460     """
461     Execute an hg pull on all of the repos
462     """
463     data = {"changed": False, "backend": "hgfs"}
464     data["changed"], repos = _clear_old_remotes()
465     for repo in repos:
466         try:
467             if os.path.exists(repo["lockfile"]):
468                 log.warning(
469                     "Update lockfile is present for hgfs remote %s, skipping. "
470                     "If this warning persists, it is possible that the update "
471                     "process was interrupted. Removing %s or running "
472                     "'salt-run fileserver.clear_lock hgfs' will allow updates "
473                     "to continue for this remote.",
474                     repo["url"],
475                     repo["lockfile"],
476                 )
477                 continue
478             _, errors = lock(repo)
479             if errors:
480                 log.error(
481                     "Unable to set update lock for hgfs remote %s, skipping.",
482                     repo["url"],
483                 )
484                 continue
485             log.debug("hgfs is fetching from %s", repo["url"])
486             repo["repo"].open()
487             curtip = repo["repo"].tip()
488             try:
489                 repo["repo"].pull()
490             except Exception as exc:  # pylint: disable=broad-except
491                 log.error(
492                     "Exception %s caught while updating hgfs remote %s",
493                     exc,
494                     repo["url"],
495                     exc_info_on_loglevel=logging.DEBUG,
496                 )
497             else:
498                 newtip = repo["repo"].tip()
499                 if curtip[1] != newtip[1]:
500                     data["changed"] = True
501         finally:
502             repo["repo"].close()
503         clear_lock(repo)
504     env_cache = os.path.join(__opts__["cachedir"], "hgfs/envs.p")
505     if data.get("changed", False) is True or not os.path.isfile(env_cache):
506         env_cachedir = os.path.dirname(env_cache)
507         if not os.path.exists(env_cachedir):
508             os.makedirs(env_cachedir)
509         new_envs = envs(ignore_cache=True)
510         with salt.utils.files.fopen(env_cache, "wb+") as fp_:
511             fp_.write(salt.payload.dumps(new_envs))
512             log.trace("Wrote env cache data to %s", env_cache)
513     if __opts__.get("fileserver_events", False):
514         with salt.utils.event.get_event(
515             "master",
516             __opts__["sock_dir"],
517             opts=__opts__,
518             listen=False,
519         ) as event:
520             event.fire_event(data, tagify(["hgfs", "update"], prefix="fileserver"))
521     try:
522         salt.fileserver.reap_fileserver_cache_dir(
523             os.path.join(__opts__["cachedir"], "hgfs/hash"), find_file
524         )
525     except OSError:
526         pass
527 def _env_is_exposed(env):
528     """
529     Check if an environment is exposed by comparing it against a whitelist and
530     blacklist.
531     """
532     return salt.utils.stringutils.check_whitelist_blacklist(
533         env,
534         whitelist=__opts__["hgfs_saltenv_whitelist"],
535         blacklist=__opts__["hgfs_saltenv_blacklist"],
536     )
537 def envs(ignore_cache=False):
538     """
539     Return a list of refs that can be used as environments
540     """
541     if not ignore_cache:
542         env_cache = os.path.join(__opts__["cachedir"], "hgfs/envs.p")
543         cache_match = salt.fileserver.check_env_cache(__opts__, env_cache)
544         if cache_match is not None:
545             return cache_match
546     ret = set()
547     for repo in init():
548         try:
549             repo["repo"].open()
550             if repo["branch_method"] in ("branches", "mixed"):
551                 for branch in _all_branches(repo["repo"]):
552                     branch_name = branch[0]
553                     if branch_name == repo["base"]:
554                         branch_name = "base"
555                     ret.add(branch_name)
556             if repo["branch_method"] in ("bookmarks", "mixed"):
557                 for bookmark in _all_bookmarks(repo["repo"]):
558                     bookmark_name = bookmark[0]
559                     if bookmark_name == repo["base"]:
560                         bookmark_name = "base"
561                     ret.add(bookmark_name)
562             ret.update([x[0] for x in _all_tags(repo["repo"])])
563         finally:
564             repo["repo"].close()
565     return [x for x in sorted(ret) if _env_is_exposed(x)]
566 def find_file(path, tgt_env="base", **kwargs):  # pylint: disable=W0613
567     """
568     Find the first file to match the path and ref, read the file out of hg
569     and send the path to the newly cached file
570     """
571     fnd = {"path": "", "rel": ""}
572     if os.path.isabs(path) or tgt_env not in envs():
573         return fnd
574     dest = os.path.join(__opts__["cachedir"], "hgfs/refs", tgt_env, path)
575     hashes_glob = os.path.join(
576         __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.hash.*".format(path)
577     )
578     blobshadest = os.path.join(
579         __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.hash.blob_sha1".format(path)
580     )
581     lk_fn = os.path.join(
582         __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.lk".format(path)
583     )
584     destdir = os.path.dirname(dest)
585     hashdir = os.path.dirname(blobshadest)
586     if not os.path.isdir(destdir):
587         try:
588             os.makedirs(destdir)
589         except OSError:
590             os.remove(destdir)
591             os.makedirs(destdir)
592     if not os.path.isdir(hashdir):
593         try:
594             os.makedirs(hashdir)
595         except OSError:
596             os.remove(hashdir)
597             os.makedirs(hashdir)
598     for repo in init():
599         try:
600             if repo["mountpoint"] and not path.startswith(
601                 repo["mountpoint"] + os.path.sep
602             ):
603                 continue
604             repo_path = path[len(repo["mountpoint"]) :].lstrip(os.path.sep)
605             if repo["root"]:
606                 repo_path = os.path.join(repo["root"], repo_path)
607             repo["repo"].open()
608             ref = _get_ref(repo, tgt_env)
609             if not ref:
610                 repo["repo"].close()
611                 continue
612             salt.fileserver.wait_lock(lk_fn, dest)
613             if os.path.isfile(blobshadest) and os.path.isfile(dest):
614                 with salt.utils.files.fopen(blobshadest, "r") as fp_:
615                     sha = fp_.read()
616                     if sha == ref[2]:
617                         fnd["rel"] = path
618                         fnd["path"] = dest
619                         repo["repo"].close()
620                         return fnd
621             try:
622                 repo["repo"].cat(
623                     [salt.utils.stringutils.to_bytes("path:{}".format(repo_path))],
624                     rev=ref[2],
625                     output=dest,
626                 )
627             except hglib.error.CommandError:
628                 repo["repo"].close()
629                 continue
630             with salt.utils.files.fopen(lk_fn, "w"):
631                 pass
632             for filename in glob.glob(hashes_glob):
633                 try:
634                     os.remove(filename)
635                 except Exception:  # pylint: disable=broad-except
636                     pass
637             with salt.utils.files.fopen(blobshadest, "w+") as fp_:
638                 fp_.write(salt.utils.stringutils.to_str(ref[2]))
639             try:
640                 os.remove(lk_fn)
641             except OSError:
642                 pass
643             fnd["rel"] = path
644             fnd["path"] = dest
645             try:
646                 fnd["stat"] = list(os.stat(dest))
647             except Exception:  # pylint: disable=broad-except
648                 pass
649         finally:
650             repo["repo"].close()
651         return fnd
652     return fnd
653 def serve_file(load, fnd):
654     """
655     Return a chunk from a file based on the data received
656     """
657     if "env" in load:
658         load.pop("env")
659     ret = {"data": "", "dest": ""}
660     if not all(x in load for x in ("path", "loc", "saltenv")):
661         return ret
662     if not fnd["path"]:
663         return ret
664     ret["dest"] = fnd["rel"]
665     gzip = load.get("gzip", None)
666     fpath = os.path.normpath(fnd["path"])
667     with salt.utils.files.fopen(fpath, "rb") as fp_:
668         fp_.seek(load["loc"])
669         data = fp_.read(__opts__["file_buffer_size"])
670         if data and not salt.utils.files.is_binary(fpath):
671             data = data.decode(__salt_system_encoding__)
672         if gzip and data:
673             data = salt.utils.gzip_util.compress(data, gzip)
674             ret["gzip"] = gzip
675         ret["data"] = data
676     return ret
677 def file_hash(load, fnd):
678     """
679     Return a file hash, the hash type is set in the master config file
680     """
681     if "env" in load:
682         load.pop("env")
683     if not all(x in load for x in ("path", "saltenv")):
684         return ""
685     ret = {"hash_type": __opts__["hash_type"]}
686     relpath = fnd["rel"]
687     path = fnd["path"]
688     hashdest = os.path.join(
689         __opts__["cachedir"],
690         "hgfs/hash",
691         load["saltenv"],
692         "{}.hash.{}".format(relpath, __opts__["hash_type"]),
693     )
694     if not os.path.isfile(hashdest):
695         ret["hsum"] = salt.utils.hashutils.get_hash(path, __opts__["hash_type"])
696         with salt.utils.files.fopen(hashdest, "w+") as fp_:
697             fp_.write(ret["hsum"])
698         return ret
699     else:
700         with salt.utils.files.fopen(hashdest, "rb") as fp_:
701             ret["hsum"] = salt.utils.stringutils.to_unicode(fp_.read())
702         return ret
703 def _file_lists(load, form):
704     """
705     Return a dict containing the file lists for files and dirs
706     """
707     if "env" in load:
708         load.pop("env")
709     list_cachedir = os.path.join(__opts__["cachedir"], "file_lists/hgfs")
710     if not os.path.isdir(list_cachedir):
711         try:
712             os.makedirs(list_cachedir)
713         except os.error:
714             log.critical("Unable to make cachedir %s", list_cachedir)
715             return []
716     list_cache = os.path.join(list_cachedir, "{}.p".format(load["saltenv"]))
717     w_lock = os.path.join(list_cachedir, ".{}.w".format(load["saltenv"]))
718     cache_match, refresh_cache, save_cache = salt.fileserver.check_file_list_cache(
719         __opts__, form, list_cache, w_lock
720     )
721     if cache_match is not None:
722         return cache_match
723     if refresh_cache:
724         ret = {}
725         ret["files"] = _get_file_list(load)
726         ret["dirs"] = _get_dir_list(load)
727         if save_cache:
728             salt.fileserver.write_file_list_cache(__opts__, ret, list_cache, w_lock)
729         return ret.get(form, [])
730     return []
731 def file_list(load):
732     """
733     Return a list of all files on the file server in a specified environment
734     """
735     return _file_lists(load, "files")
736 def _get_file_list(load):
737     """
738     Get a list of all files on the file server in a specified environment
739     """
740     if "env" in load:
741         load.pop("env")
742     if "saltenv" not in load or load["saltenv"] not in envs():
743         return []
744     ret = set()
745     for repo in init():
746         try:
747             repo["repo"].open()
748             ref = _get_ref(repo, load["saltenv"])
749             if ref:
750                 manifest = _get_manifest(repo["repo"], ref=ref)
751                 for tup in manifest:
752                     relpath = os.path.relpath(tup[4], repo["root"])
753                     if not relpath.startswith("../"):
754                         ret.add(os.path.join(repo["mountpoint"], relpath))
755         finally:
756             repo["repo"].close()
757     return sorted(ret)
758 def file_list_emptydirs(load):  # pylint: disable=W0613
759     """
760     Return a list of all empty directories on the master
761     """
762     return []
763 def dir_list(load):
764     """
765     Return a list of all directories on the master
766     """
767     return _file_lists(load, "dirs")
768 def _get_dir_list(load):
769     """
770     Get a list of all directories on the master
771     """
772     if "env" in load:
773         load.pop("env")
774     if "saltenv" not in load or load["saltenv"] not in envs():
775         return []
776     ret = set()
777     for repo in init():
778         try:
779             repo["repo"].open()
780             ref = _get_ref(repo, load["saltenv"])
781             if ref:
782                 manifest = _get_manifest(repo["repo"], ref=ref)
783                 for tup in manifest:
784                     filepath = tup[4]
785                     split = filepath.rsplit("/", 1)
786                     while len(split) &gt; 1:
787                         relpath = os.path.relpath(split[0], repo["root"])
788                         if relpath != ".":
789                             if not relpath.startswith("../"):
790                                 ret.add(os.path.join(repo["mountpoint"], relpath))
791                         split = split[0].rsplit("/", 1)
792         finally:
793             repo["repo"].close()
794     if repo["mountpoint"]:
795         ret.add(repo["mountpoint"])
796     return sorted(ret)
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
