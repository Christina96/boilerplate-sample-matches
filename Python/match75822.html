<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for ipc.py &amp; hgfs.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for ipc.py &amp; hgfs.py
      </h3>
<h1 align="center">
        4.2%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>ipc.py (5.1087985%)<th>hgfs.py (3.6784742%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(6-24)<td><a href="#" name="0">(42-60)</a><td align="center"><font color="#ff0000">18</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(541-544)<td><a href="#" name="1">(139-140)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(137-140)<td><a href="#" name="2">(114-115)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(128-131)<td><a href="#" name="3">(214-216)</a><td align="center"><font color="#aa0000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>ipc.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 <font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>import errno
2 import logging
3 import socket
4 import time
5 import salt.ext.tornado
6 import salt.ext.tornado.concurrent
7 import salt.ext.tornado.gen
8 import salt.ext.tornado.ioloop
9 import salt.ext.tornado.netutil
10 import salt.transport.client
11 import salt.transport.frame
12 import salt.utils.msgpack
13 from salt.ext.tornado.ioloop import IOLoop
14 from salt.ext.tornado.ioloop import TimeoutError as TornadoTimeoutError
15 from salt.ext.tornado.iostream import IOStream, StreamClosedError
16 from salt.ext.tornado.locks import Lock
17 log = logging.</b></font>getLogger(__name__)
18 def future_with_timeout_callback(future):
19     if future._future_with_timeout is not None:
20         future._future_with_timeout._done_callback(future)
21 class FutureWithTimeout(salt.ext.tornado.concurrent.Future):
22     def __init__(self, io_loop, future, timeout):
23         super().__init__()
24         self.io_loop = io_loop
25         self._future = future
26         if timeout is not None:
27             if timeout &lt; 0.1:
28                 timeout = 0.1
29             self._timeout_handle = self.io_loop.add_timeout(
30                 self.io_loop.time() + timeout, self._timeout_callback
31             )
32         else:
33             self._timeout_handle = None
34         if hasattr(self._future, "_future_with_timeout"):
35             self._future._future_with_timeout = self
36             if self._future.done():
37                 future_with_timeout_callback(self._future)
38         else:
39             self._future._future_with_timeout = self
40             self._future.add_done_callback(future_with_timeout_callback)
41     def _timeout_callback(self):
42         self._timeout_handle = None
43         self._future._future_with_timeout = None
44         self.set_exception(TornadoTimeoutError())
45     def _done_callback(self, future):
46         try:
47             if self._timeout_handle is not None:
48                 self.io_loop.remove_timeout(self._timeout_handle)
49                 self._timeout_handle = None
50             self.set_result(future.result())
51         except Exception as exc:  # pylint: disable=broad-except
52             self.set_exception(exc)
53 class IPCServer:
54     async_methods = [
55         "handle_stream",
56     ]
57     close_methods = [
58         "close",
59     ]
60     def __init__(self, socket_path, io_loop=None, payload_handler=None):
61         self.socket_path = socket_path
62         self._started = False
63         self.payload_handler = payload_handler
64         self.sock = None
65         self.io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()
66         self._closing = False
67     def start(self):
68         log.trace("IPCServer: binding to socket: %s", self.socket_path)
69         if isinstance(self.socket_path, int):
70             self.sock = socket.socket(socket<font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.AF_INET, socket.SOCK_STREAM)
71             self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
72             self.sock.setblocking(0)
73             self.sock.</b></font>bind(("127.0.0.1", self.socket_path))
74             self.sock.listen(128)
75 <a name="2"></a>        else:
76             self.sock = salt.ext.tornado.netutil.bind_unix_socket(self.socket_path)
77         with salt<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.utils.asynchronous.current_ioloop(self.io_loop):
78             salt.ext.tornado.netutil.add_accept_handler(
79                 self.sock,
80                 self.</b></font>handle_connection,
81             )
82         self._started = True
83     @salt.ext.tornado.gen.coroutine
84     def handle_stream(self, stream):
85         @salt.ext.tornado.gen.coroutine
86         def _null(msg):
87             raise salt.ext.tornado.gen.Return(None)
88         def write_callback(stream, header):
89             if header.get("mid"):
90                 @salt.ext.tornado.gen.coroutine
91                 def return_message(msg):
92                     pack = salt.transport.frame.frame_msg_ipc(
93                         msg,
94                         header={"mid": header["mid"]},
95                         raw_body=True,
96                     )
97                     yield stream.write(pack)
98                 return return_message
99             else:
100                 return _null
101         if salt.utils.msgpack.version &gt;= (0, 5, 2):
102             msgpack_kwargs = {"raw": False}
103         else:
104             msgpack_kwargs = {"encoding": "utf-8"}
105         unpacker = salt.utils.msgpack.Unpacker(**msgpack_kwargs)
106         while not stream.closed():
107             try:
108                 wire_bytes = yield stream.read_bytes(4096, partial=True)
109                 unpacker.feed(wire_bytes)
110                 for framed_msg in unpacker:
111                     body = framed_msg["body"]
112                     self.io_loop.spawn_callback(
113                         self.payload_handler,
114                         body,
115                         write_callback(stream, framed_msg["head"]),
116                     )
117             except StreamClosedError:
118                 log.trace("Client disconnected from IPC %s", self.socket_path)
119                 break
120             except OSError as exc:
121                 if exc.errno == 0:
122                     log.trace(
123                         "Exception occurred with error number 0, "
124                         "spurious exception: %s",
125                         exc,
126                     )
127                 else:
128                     log.error("Exception occurred while handling stream: %s", exc)
129             except Exception as exc:  # pylint: disable=broad-except
130                 log.error("Exception occurred while handling stream: %s", exc)
131     def handle_connection(self, connection, address):
132         log.trace(
133             "IPCServer: Handling connection to address: %s",
134             address if address else connection,
135         )
136         try:
137             with salt.utils.asynchronous.current_ioloop(self.io_loop):
138                 stream = IOStream(
139                     connection,
140                 )
141             self.io_loop.spawn_callback(self.handle_stream, stream)
142         except Exception as exc:  # pylint: disable=broad-except
143             log.error("IPC streaming error: %s", exc)
144     def close(self):
145         if self._closing:
146             return
147         self._closing = True
148         if hasattr(self.sock, "close"):
149             self.sock.close()
150     def __del__(self):
151         try:
152             self.close()
153         except TypeError:
154             pass
155     def __enter__(self):
156         return self
157     def __exit__(self, *args):
158         self.close()
159 class IPCClient:
160     def __init__(self, socket_path, io_loop=None):
161         self.io_loop = io_loop or salt.ext.tornado.ioloop.IOLoop.current()
162         self.socket_path = socket_path
163         self._closing = False
164         self.stream = None
165         if salt.utils.msgpack.version &gt;= (0, 5, 2):
166             msgpack_kwargs = {"raw": False}
167         else:
168             msgpack_kwargs = {"encoding": "utf-8"}
169         self.unpacker = salt.utils.msgpack.Unpacker(**msgpack_kwargs)
170         self._connecting_future = None
171     def connected(self):
172         return self.stream is not None and not self.stream.closed()
173     def connect(self, callback=None, timeout=None):
174         if self._connecting_future is not None and not self._connecting_future.done():
175             future = self._connecting_future
176         else:
177             if self._connecting_future is not None:
178                 self._connecting_future.exception()  # pylint: disable=E0203
179             future = salt.ext.tornado.concurrent.Future()
180             self._connecting_future = future
181             self._connect(timeout)
182         if callback is not None:
183             def handle_future(future):
184                 response = future.result()
185                 self.io_loop.add_callback(callback, response)
186             future.add_done_callback(handle_future)
187         return future
188     @salt.ext.tornado.gen.coroutine
189     def _connect(self, timeout=None):
190         if isinstance(self.socket_path, int):
191             sock_type = socket.AF_INET
192             sock_addr = ("127.0.0.1", self.socket_path)
193         else:
194             sock_type = socket.AF_UNIX
195             sock_addr = self.socket_path
196         self.stream = None
197         if timeout is not None:
198             timeout_at = time.time() + timeout
199         while True:
200             if self._closing:
201                 break
202             if self.stream is None:
203                 with salt.utils.asynchronous.current_ioloop(self.io_loop):
204                     self.stream = IOStream(socket.socket(sock_type, socket.SOCK_STREAM))
205             try:
206                 log.trace("IPCClient: Connecting to socket: %s", self.socket_path)
207                 yield self.stream.connect(sock_addr)
208                 self._connecting_future.set_result(True)
209                 break
210             except Exception as e:  # pylint: disable=broad-except
211                 if self.stream.closed():
212                     self.stream = None
213                 if timeout is None or time.time() &gt; timeout_at:
214                     if self.stream is not None:
215                         self.stream.close()
216                         self.stream = None
217                     self._connecting_future.set_exception(e)
218                     break
219                 yield salt.ext.tornado.gen.sleep(1)
220     def close(self):
221         if self._closing:
222             return
223         self._closing = True
224         self._connecting_future = None
225         log.debug("Closing %s instance", self.__class__.__name__)
226         if self.stream is not None and not self.stream.closed():
227             try:
228                 self.stream.close()
229             except OSError as exc:
230                 if exc.errno != errno.EBADF:
231                     raise
232     def __del__(self):
233         try:
234             self.close()
235         except TypeError:
236             pass
237     def __enter__(self):
238         return self
239     def __exit__(self, *args):
240         self.close()
241 class IPCMessageClient(IPCClient):
242     async_methods = [
243         "send",
244         "connect",
245         "_connect",
246     ]
247     close_methods = [
248         "close",
249     ]
250     @salt.ext.tornado.gen.coroutine
251     def send(self, msg, timeout=None, tries=None):
252         if not self.connected():
253             yield self.connect()
254         pack = salt.transport.frame.frame_msg_ipc(msg, raw_body=True)
255         yield self.stream.write(pack)
256 class IPCMessageServer(IPCServer):
257 class IPCMessagePublisher:
258     def __init__(self, opts, socket_path, io_loop=None):
259         self.opts = opts
260         self.socket_path = socket_path
261         self._started = False
262         self.sock = None
263         self.io_loop = io_loop or IOLoop.current()
264         self._closing = False
265         self.streams = set()
266     def start(self):
267         log.trace("IPCMessagePublisher: binding to socket: %s", self.socket_path)
268         if isinstance(self.socket_path, int):
269             self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
270             self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
271             self.sock.setblocking(0)
272             self.sock.bind(("127.0.0.1", self.socket_path))
273             self.sock.listen(128)
274 <a name="1"></a>        else:
275             self.sock = salt.ext.tornado.netutil.bind_unix_socket(self.socket_path)
276         with salt<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.utils.asynchronous.current_ioloop(self.io_loop):
277             salt.ext.tornado.netutil.add_accept_handler(
278                 self.sock,
279                 self.</b></font>handle_connection,
280             )
281         self._started = True
282     @salt.ext.tornado.gen.coroutine
283     def _write(self, stream, pack):
284         try:
285             yield stream.write(pack)
286         except StreamClosedError:
287             log.trace("Client disconnected from IPC %s", self.socket_path)
288             self.streams.discard(stream)
289         except Exception as exc:  # pylint: disable=broad-except
290             log.error("Exception occurred while handling stream: %s", exc)
291             if not stream.closed():
292                 stream.close()
293             self.streams.discard(stream)
294     def publish(self, msg):
295         if not self.streams:
296             return
297         pack = salt.transport.frame.frame_msg_ipc(msg, raw_body=True)
298         for stream in self.streams:
299             self.io_loop.spawn_callback(self._write, stream, pack)
300     def handle_connection(self, connection, address):
301         log.trace("IPCServer: Handling connection to address: %s", address)
302         try:
303             kwargs = {}
304             if self.opts["ipc_write_buffer"] &gt; 0:
305                 kwargs["max_write_buffer_size"] = self.opts["ipc_write_buffer"]
306                 log.trace(
307                     "Setting IPC connection write buffer: %s",
308                     (self.opts["ipc_write_buffer"]),
309                 )
310             with salt.utils.asynchronous.current_ioloop(self.io_loop):
311                 stream = IOStream(connection, **kwargs)
312             self.streams.add(stream)
313             def discard_after_closed():
314                 self.streams.discard(stream)
315             stream.set_close_callback(discard_after_closed)
316         except Exception as exc:  # pylint: disable=broad-except
317             log.error("IPC streaming error: %s", exc)
318     def close(self):
319         if self._closing:
320             return
321         self._closing = True
322         for stream in self.streams:
323             stream.close()
324         self.streams.clear()
325         if hasattr(self.sock, "close"):
326             self.sock.close()
327     def __enter__(self):
328         return self
329     def __exit__(self, *args):
330         self.close()
331 class IPCMessageSubscriber(IPCClient):
332     async_methods = [
333         "read",
334         "connect",
335     ]
336     close_methods = [
337         "close",
338     ]
339     def __init__(self, socket_path, io_loop=None):
340         super().__init__(socket_path, io_loop=io_loop)
341         self._read_stream_future = None
342         self._saved_data = []
343         self._read_in_progress = Lock()
344     @salt.ext.tornado.gen.coroutine
345     def _read(self, timeout, callback=None):
346         try:
347             try:
348                 yield self._read_in_progress.acquire(timeout=0.00000001)
349             except salt.ext.tornado.gen.TimeoutError:
350                 raise salt.ext.tornado.gen.Return(None)
351             exc_to_raise = None
352             ret = None
353             try:
354                 while True:
355                     if self._read_stream_future is None:
356                         self._read_stream_future = self.stream.read_bytes(
357                             4096, partial=True
358                         )
359                     if timeout is None:
360                         wire_bytes = yield self._read_stream_future
361                     else:
362                         wire_bytes = yield FutureWithTimeout(
363                             self.io_loop, self._read_stream_future, timeout
364                         )
365                     self._read_stream_future = None
366                     timeout = None
367                     self.unpacker.feed(wire_bytes)
368                     first_sync_msg = True
369                     for framed_msg in self.unpacker:
370                         if callback:
371                             self.io_loop.spawn_callback(callback, framed_msg["body"])
372                         elif first_sync_msg:
373                             ret = framed_msg["body"]
374                             first_sync_msg = False
375                         else:
376                             self._saved_data.append(framed_msg["body"])
377                     if not first_sync_msg:
378                         break
379             except TornadoTimeoutError:
380                 ret = None
381             except StreamClosedError as exc:
382                 log.trace("Subscriber disconnected from IPC %s", self.socket_path)
383                 self._read_stream_future = None
384             except Exception as exc:  # pylint: disable=broad-except
385                 log.error(
386                     "Exception occurred in Subscriber while handling stream: %s", exc
387                 )
388                 self._read_stream_future = None
389                 exc_to_raise = exc
390             self._read_in_progress.release()
391             if exc_to_raise is not None:
392                 raise exc_to_raise  # pylint: disable=E0702
393             raise salt.ext.tornado.gen.Return(ret)
394         except TypeError:
395             pass
396     @salt.ext.tornado.gen.coroutine
397     def read(self, timeout):
398         if self._saved_data:
399             res = self._saved_data.pop(0)
400             raise salt.ext.tornado.gen.Return(res)
401         while not self.connected():
402             try:
403                 yield self.connect(timeout=5)
404             except StreamClosedError:
405                 log.trace(
406                     "Subscriber closed stream on IPC %s before connect",
407                     self.socket_path,
408                 )
409                 yield salt.ext.tornado.gen.sleep(1)
410             except Exception as exc:  # pylint: disable=broad-except
411                 log.error("Exception occurred while Subscriber connecting: %s", exc)
412                 yield salt.ext.tornado.gen.sleep(1)
413         res = yield self._read(timeout)
414         raise salt.ext.tornado.gen.Return(res)
415     def read_sync(self, timeout=None):
416         if self._saved_data:
417             return self._saved_data.pop(0)
418         return self.io_loop.run_sync(lambda: self._read(timeout))
419     @salt.ext.tornado.gen.coroutine
420     def read_async(self, callback):
421         while not self.connected():
422             try:
423                 yield self.connect(timeout=5)
424             except StreamClosedError:
425                 log.trace(
426                     "Subscriber closed stream on IPC %s before connect",
427                     self.socket_path,
428                 )
429                 yield salt.ext.tornado.gen.sleep(1)
430             except Exception as exc:  # pylint: disable=broad-except
431                 log.error("Exception occurred while Subscriber connecting: %s", exc)
432                 yield salt.ext.tornado.gen.sleep(1)
433         yield self._read(None, callback)
434     def close(self):
435         if self._closing:
436             return
437         super().close()
438         if self._read_stream_future is not None and self._read_stream_future.done():
439             exc = self._read_stream_future.exception()
440             if exc and not isinstance(exc, StreamClosedError):
441                 log.error("Read future returned exception %r", exc)
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>hgfs.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 <a name="0"></a>import copy
2 import errno
3 import fnmatch
4 <font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>import glob
5 import hashlib
6 import logging
7 import os
8 import shutil
9 from datetime import datetime
10 import salt.fileserver
11 import salt.utils.data
12 import salt.utils.files
13 import salt.utils.gzip_util
14 import salt.utils.hashutils
15 import salt.utils.stringutils
16 import salt.utils.url
17 import salt.utils.versions
18 from salt.exceptions import FileserverConfigError
19 from salt.utils.event import tagify
20 VALID_BRANCH_METHODS = ("branches"</b></font>, "bookmarks", "mixed")
21 PER_REMOTE_OVERRIDES = ("base", "branch_method", "mountpoint", "root")
22 try:
23     import hglib
24     HAS_HG = True
25 except ImportError:
26     HAS_HG = False
27 log = logging.getLogger(__name__)
28 __virtualname__ = "hgfs"
29 __virtual_aliases__ = ("hg",)
30 def __virtual__():
31     if __virtualname__ not in __opts__["fileserver_backend"]:
32         return False
33     if not HAS_HG:
34         log.error(
35             "Mercurial fileserver backend is enabled in configuration "
36             "but could not be loaded, is hglib installed?"
37         )
38         return False
39     if __opts__["hgfs_branch_method"] not in VALID_BRANCH_METHODS:
40         log.error(
41             "Invalid hgfs_branch_method '%s'. Valid methods are: %s",
42             __opts__["hgfs_branch_method"],
43             VALID_BRANCH_METHODS,
44         )
45         return False
46     if salt.utils.path.which("hg") is None:
47         log.error("hgfs requested but hg executable is not available.")
48         return False
49     return __virtualname__
50 def _all_branches(repo):
51     branches = [
52         (salt<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.utils.stringutils.to_str(x[0]), x[1], salt.utils.stringutils.to_str(x[2]))
53         for x in repo.</b></font>branches()
54     ]
55     return branches
56 def _get_branch(repo, name):
57     try:
58         return [x for x in _all_branches(repo) if x[0] == name][0]
59     except IndexError:
60         return False
61 def _all_bookmarks(repo):
62     bookmarks = [
63         (salt<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.utils.stringutils.to_str(x[0]), x[1], salt.utils.stringutils.to_str(x[2]))
64         for x in repo.</b></font>bookmarks()[0]
65     ]
66     return bookmarks
67 def _get_bookmark(repo, name):
68     try:
69         return [x for x in _all_bookmarks(repo) if x[0] == name][0]
70     except IndexError:
71         return False
72 def _all_tags(repo):
73     return [
74         (
75             salt.utils.stringutils.to_str(x[0]),
76             x[1],
77             salt.utils.stringutils.to_str(x[2]),
78             x[3],
79         )
80         for x in repo.tags()
81         if salt.utils.stringutils.to_str(x[0]) != "tip"
82     ]
83 def _get_tag(repo, name):
84     try:
85         return [x for x in _all_tags(repo) if x[0] == name][0]
86     except IndexError:
87         return False
88 def _get_ref(repo, name):
89     if name == "base":
90         name = repo["base"]
91     if name == repo["base"] or name in envs():
92         if repo["branch_method"] == "branches":
93             return _get_branch(repo["repo"], name) or _get_tag(repo["repo"], name)
94         elif repo["branch_method"] == "bookmarks":
95             return _get_bookmark(repo["repo"], name) or _get_tag(repo["repo"], name)
96         elif repo["branch_method"] == "mixed":
97             return (
98                 _get_branch(repo["repo"], name)
99                 or _get_bookmark(repo["repo"], name)
100                 or _get_tag(repo["repo"], name)
101             )
102     return False
103 def _get_manifest(repo, ref):
104     manifest = [
105         (
106             <font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>salt.utils.stringutils.to_str(x[0]),
107             salt.utils.stringutils.to_str(x[1]),
108             x[</b></font>2],
109             x[3],
110             salt.utils.stringutils.to_str(x[4]),
111         )
112         for x in repo.manifest(rev=ref[1])
113     ]
114     return manifest
115 def _failhard():
116     raise FileserverConfigError("Failed to load hg fileserver backend")
117 def init():
118     bp_ = os.path.join(__opts__["cachedir"], "hgfs")
119     new_remote = False
120     repos = []
121     per_remote_defaults = {}
122     for param in PER_REMOTE_OVERRIDES:
123         per_remote_defaults[param] = str(__opts__["hgfs_{}".format(param)])
124     for remote in __opts__["hgfs_remotes"]:
125         repo_conf = copy.deepcopy(per_remote_defaults)
126         if isinstance(remote, dict):
127             repo_url = next(iter(remote))
128             per_remote_conf = {
129                 key: str(val)
130                 for key, val in salt.utils.data.repack_dictlist(
131                     remote[repo_url]
132                 ).items()
133             }
134             if not per_remote_conf:
135                 log.error(
136                     "Invalid per-remote configuration for hgfs remote %s. If "
137                     "no per-remote parameters are being specified, there may "
138                     "be a trailing colon after the URL, which should be "
139                     "removed. Check the master configuration file.",
140                     repo_url,
141                 )
142                 _failhard()
143             branch_method = per_remote_conf.get(
144                 "branch_method", per_remote_defaults["branch_method"]
145             )
146             if branch_method not in VALID_BRANCH_METHODS:
147                 log.error(
148                     "Invalid branch_method '%s' for remote %s. Valid "
149                     "branch methods are: %s. This remote will be ignored.",
150                     branch_method,
151                     repo_url,
152                     ", ".join(VALID_BRANCH_METHODS),
153                 )
154                 _failhard()
155             per_remote_errors = False
156             for param in (x for x in per_remote_conf if x not in PER_REMOTE_OVERRIDES):
157                 log.error(
158                     "Invalid configuration parameter '%s' for remote %s. "
159                     "Valid parameters are: %s. See the documentation for "
160                     "further information.",
161                     param,
162                     repo_url,
163                     ", ".join(PER_REMOTE_OVERRIDES),
164                 )
165                 per_remote_errors = True
166             if per_remote_errors:
167                 _failhard()
168             repo_conf.update(per_remote_conf)
169         else:
170             repo_url = remote
171         if not isinstance(repo_url, str):
172             log.error(
173                 "Invalid hgfs remote %s. Remotes must be strings, you may "
174                 "need to enclose the URL in quotes",
175                 repo_url,
176             )
177             _failhard()
178         try:
179             repo_conf["mountpoint"] = salt.utils.url.strip_proto(
180                 repo_conf["mountpoint"]
181             )
182         except TypeError:
183             pass
184         hash_type = getattr(hashlib, __opts__.get("hash_type", "md5"))
185         repo_hash = hash_type(repo_url.encode("utf-8")).hexdigest()
186         rp_ = os.path.join(bp_, repo_hash)
187         if not os.path.isdir(rp_):
188             os.makedirs(rp_)
189         if not os.listdir(rp_):
190             client = hglib.init(rp_)
191             client.close()
192             new_remote = True
193         repo = None
194         try:
195             try:
196                 repo = hglib.open(rp_)
197             except hglib.error.ServerError:
198                 log.error(
199                     "Cache path %s (corresponding remote: %s) exists but is not "
200                     "a valid mercurial repository. You will need to manually "
201                     "delete this directory on the master to continue to use this "
202                     "hgfs remote.",
203                     rp_,
204                     repo_url,
205                 )
206                 _failhard()
207             except Exception as exc:  # pylint: disable=broad-except
208                 log.error(
209                     "Exception '%s' encountered while initializing hgfs remote %s",
210                     exc,
211                     repo_url,
212                 )
213                 _failhard()
214             try:
215                 refs = repo.config(names=b"paths")
216             except hglib.error.CommandError:
217                 refs = None
218             if not refs:
219                 hgconfpath = os.path.join(rp_, ".hg", "hgrc")
220                 with salt.utils.files.fopen(hgconfpath, "w+") as hgconfig:
221                     hgconfig.write("[paths]\n")
222                     hgconfig.write(
223                         salt.utils.stringutils.to_str("default = {}\n".format(repo_url))
224                     )
225             repo_conf.update(
226                 {
227                     "repo": repo,
228                     "url": repo_url,
229                     "hash": repo_hash,
230                     "cachedir": rp_,
231                     "lockfile": os.path.join(
232                         __opts__["cachedir"], "hgfs", "{}.update.lk".format(repo_hash)
233                     ),
234                 }
235             )
236             repos.append(repo_conf)
237         finally:
238             if repo:
239                 repo.close()
240     if new_remote:
241         remote_map = os.path.join(__opts__["cachedir"], "hgfs/remote_map.txt")
242         try:
243             with salt.utils.files.fopen(remote_map, "w+") as fp_:
244                 timestamp = datetime.now().strftime("%d %b %Y %H:%M:%S.%f")
245                 fp_.write("# hgfs_remote map as of {}\n".format(timestamp))
246                 for repo in repos:
247                     fp_.write(
248                         salt.utils.stringutils.to_str(
249                             "{} = {}\n".format(repo["hash"], repo["url"])
250                         )
251                     )
252         except OSError:
253             pass
254         else:
255             log.info("Wrote new hgfs_remote map to %s", remote_map)
256     return repos
257 def _clear_old_remotes():
258     bp_ = os.path.join(__opts__["cachedir"], "hgfs")
259     try:
260         cachedir_ls = os.listdir(bp_)
261     except OSError:
262         cachedir_ls = []
263     repos = init()
264     for repo in repos:
265         try:
266             cachedir_ls.remove(repo["hash"])
267         except ValueError:
268             pass
269     to_remove = []
270     for item in cachedir_ls:
271         if item in ("hash", "refs"):
272             continue
273         path = os.path.join(bp_, item)
274         if os.path.isdir(path):
275             to_remove.append(path)
276     failed = []
277     if to_remove:
278         for rdir in to_remove:
279             try:
280                 shutil.rmtree(rdir)
281             except OSError as exc:
282                 log.error("Unable to remove old hgfs remote cachedir %s: %s", rdir, exc)
283                 failed.append(rdir)
284             else:
285                 log.debug("hgfs removed old cachedir %s", rdir)
286     for fdir in failed:
287         to_remove.remove(fdir)
288     return bool(to_remove), repos
289 def clear_cache():
290     fsb_cachedir = os.path.join(__opts__["cachedir"], "hgfs")
291     list_cachedir = os.path.join(__opts__["cachedir"], "file_lists/hgfs")
292     errors = []
293     for rdir in (fsb_cachedir, list_cachedir):
294         if os.path.exists(rdir):
295             try:
296                 shutil.rmtree(rdir)
297             except OSError as exc:
298                 errors.append("Unable to delete {}: {}".format(rdir, exc))
299     return errors
300 def clear_lock(remote=None):
301     def _do_clear_lock(repo):
302         def _add_error(errlist, repo, exc):
303             msg = "Unable to remove update lock for {} ({}): {} ".format(
304                 repo["url"], repo["lockfile"], exc
305             )
306             log.debug(msg)
307             errlist.append(msg)
308         success = []
309         failed = []
310         if os.path.exists(repo["lockfile"]):
311             try:
312                 os.remove(repo["lockfile"])
313             except OSError as exc:
314                 if exc.errno == errno.EISDIR:
315                     try:
316                         shutil.rmtree(repo["lockfile"])
317                     except OSError as exc:
318                         _add_error(failed, repo, exc)
319                 else:
320                     _add_error(failed, repo, exc)
321             else:
322                 msg = "Removed lock for {}".format(repo["url"])
323                 log.debug(msg)
324                 success.append(msg)
325         return success, failed
326     if isinstance(remote, dict):
327         return _do_clear_lock(remote)
328     cleared = []
329     errors = []
330     for repo in init():
331         try:
332             if remote:
333                 try:
334                     if not fnmatch.fnmatch(repo["url"], remote):
335                         continue
336                 except TypeError:
337                     if not fnmatch.fnmatch(repo["url"], str(remote)):
338                         continue
339             success, failed = _do_clear_lock(repo)
340             cleared.extend(success)
341             errors.extend(failed)
342         finally:
343             repo["repo"].close()
344     return cleared, errors
345 def lock(remote=None):
346     def _do_lock(repo):
347         success = []
348         failed = []
349         if not os.path.exists(repo["lockfile"]):
350             try:
351                 with salt.utils.files.fopen(repo["lockfile"], "w"):
352                     pass
353             except OSError as exc:
354                 msg = "Unable to set update lock for {} ({}): {} ".format(
355                     repo["url"], repo["lockfile"], exc
356                 )
357                 log.debug(msg)
358                 failed.append(msg)
359             else:
360                 msg = "Set lock for {}".format(repo["url"])
361                 log.debug(msg)
362                 success.append(msg)
363         return success, failed
364     if isinstance(remote, dict):
365         return _do_lock(remote)
366     locked = []
367     errors = []
368     for repo in init():
369         try:
370             if remote:
371                 try:
372                     if not fnmatch.fnmatch(repo["url"], remote):
373                         continue
374                 except TypeError:
375                     if not fnmatch.fnmatch(repo["url"], str(remote)):
376                         continue
377             success, failed = _do_lock(repo)
378             locked.extend(success)
379             errors.extend(failed)
380         finally:
381             repo["repo"].close()
382     return locked, errors
383 def update():
384     data = {"changed": False, "backend": "hgfs"}
385     data["changed"], repos = _clear_old_remotes()
386     for repo in repos:
387         try:
388             if os.path.exists(repo["lockfile"]):
389                 log.warning(
390                     "Update lockfile is present for hgfs remote %s, skipping. "
391                     "If this warning persists, it is possible that the update "
392                     "process was interrupted. Removing %s or running "
393                     "'salt-run fileserver.clear_lock hgfs' will allow updates "
394                     "to continue for this remote.",
395                     repo["url"],
396                     repo["lockfile"],
397                 )
398                 continue
399             _, errors = lock(repo)
400             if errors:
401                 log.error(
402                     "Unable to set update lock for hgfs remote %s, skipping.",
403                     repo["url"],
404                 )
405                 continue
406             log.debug("hgfs is fetching from %s", repo["url"])
407             repo["repo"].open()
408             curtip = repo["repo"].tip()
409             try:
410                 repo["repo"].pull()
411             except Exception as exc:  # pylint: disable=broad-except
412                 log.error(
413                     "Exception %s caught while updating hgfs remote %s",
414                     exc,
415                     repo["url"],
416                     exc_info_on_loglevel=logging.DEBUG,
417                 )
418             else:
419                 newtip = repo["repo"].tip()
420                 if curtip[1] != newtip[1]:
421                     data["changed"] = True
422         finally:
423             repo["repo"].close()
424         clear_lock(repo)
425     env_cache = os.path.join(__opts__["cachedir"], "hgfs/envs.p")
426     if data.get("changed", False) is True or not os.path.isfile(env_cache):
427         env_cachedir = os.path.dirname(env_cache)
428         if not os.path.exists(env_cachedir):
429             os.makedirs(env_cachedir)
430         new_envs = envs(ignore_cache=True)
431         with salt.utils.files.fopen(env_cache, "wb+") as fp_:
432             fp_.write(salt.payload.dumps(new_envs))
433             log.trace("Wrote env cache data to %s", env_cache)
434     if __opts__.get("fileserver_events", False):
435         with salt.utils.event.get_event(
436             "master",
437             __opts__["sock_dir"],
438             opts=__opts__,
439             listen=False,
440         ) as event:
441             event.fire_event(data, tagify(["hgfs", "update"], prefix="fileserver"))
442     try:
443         salt.fileserver.reap_fileserver_cache_dir(
444             os.path.join(__opts__["cachedir"], "hgfs/hash"), find_file
445         )
446     except OSError:
447         pass
448 def _env_is_exposed(env):
449     return salt.utils.stringutils.check_whitelist_blacklist(
450         env,
451         whitelist=__opts__["hgfs_saltenv_whitelist"],
452         blacklist=__opts__["hgfs_saltenv_blacklist"],
453     )
454 def envs(ignore_cache=False):
455     if not ignore_cache:
456         env_cache = os.path.join(__opts__["cachedir"], "hgfs/envs.p")
457         cache_match = salt.fileserver.check_env_cache(__opts__, env_cache)
458         if cache_match is not None:
459             return cache_match
460     ret = set()
461     for repo in init():
462         try:
463             repo["repo"].open()
464             if repo["branch_method"] in ("branches", "mixed"):
465                 for branch in _all_branches(repo["repo"]):
466                     branch_name = branch[0]
467                     if branch_name == repo["base"]:
468                         branch_name = "base"
469                     ret.add(branch_name)
470             if repo["branch_method"] in ("bookmarks", "mixed"):
471                 for bookmark in _all_bookmarks(repo["repo"]):
472                     bookmark_name = bookmark[0]
473                     if bookmark_name == repo["base"]:
474                         bookmark_name = "base"
475                     ret.add(bookmark_name)
476             ret.update([x[0] for x in _all_tags(repo["repo"])])
477         finally:
478             repo["repo"].close()
479     return [x for x in sorted(ret) if _env_is_exposed(x)]
480 def find_file(path, tgt_env="base", **kwargs):  # pylint: disable=W0613
481     fnd = {"path": "", "rel": ""}
482     if os.path.isabs(path) or tgt_env not in envs():
483         return fnd
484     dest = os.path.join(__opts__["cachedir"], "hgfs/refs", tgt_env, path)
485     hashes_glob = os.path.join(
486         __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.hash.*".format(path)
487     )
488     blobshadest = os.path.join(
489         __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.hash.blob_sha1".format(path)
490     )
491     lk_fn = os.path.join(
492         __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.lk".format(path)
493     )
494     destdir = os.path.dirname(dest)
495     hashdir = os.path.dirname(blobshadest)
496     if not os.path.isdir(destdir):
497         try:
498             os.makedirs(destdir)
499         except OSError:
500             os.remove(destdir)
501             os.makedirs(destdir)
502     if not os.path.isdir(hashdir):
503         try:
504             os.makedirs(hashdir)
505         except OSError:
506             os.remove(hashdir)
507             os.makedirs(hashdir)
508     for repo in init():
509         try:
510             if repo["mountpoint"] and not path.startswith(
511                 repo["mountpoint"] + os.path.sep
512             ):
513                 continue
514             repo_path = path[len(repo["mountpoint"]) :].lstrip(os.path.sep)
515             if repo["root"]:
516                 repo_path = os.path.join(repo["root"], repo_path)
517             repo["repo"].open()
518             ref = _get_ref(repo, tgt_env)
519             if not ref:
520                 repo["repo"].close()
521                 continue
522             salt.fileserver.wait_lock(lk_fn, dest)
523             if os.path.isfile(blobshadest) and os.path.isfile(dest):
524                 with salt.utils.files.fopen(blobshadest, "r") as fp_:
525                     sha = fp_.read()
526                     if sha == ref[2]:
527                         fnd["rel"] = path
528                         fnd["path"] = dest
529                         repo["repo"].close()
530                         return fnd
531             try:
532                 repo["repo"].cat(
533                     [salt.utils.stringutils.to_bytes("path:{}".format(repo_path))],
534                     rev=ref[2],
535                     output=dest,
536                 )
537             except hglib.error.CommandError:
538                 repo["repo"].close()
539                 continue
540             with salt.utils.files.fopen(lk_fn, "w"):
541                 pass
542             for filename in glob.glob(hashes_glob):
543                 try:
544                     os.remove(filename)
545                 except Exception:  # pylint: disable=broad-except
546                     pass
547             with salt.utils.files.fopen(blobshadest, "w+") as fp_:
548                 fp_.write(salt.utils.stringutils.to_str(ref[2]))
549             try:
550                 os.remove(lk_fn)
551             except OSError:
552                 pass
553             fnd["rel"] = path
554             fnd["path"] = dest
555             try:
556                 fnd["stat"] = list(os.stat(dest))
557             except Exception:  # pylint: disable=broad-except
558                 pass
559         finally:
560             repo["repo"].close()
561         return fnd
562     return fnd
563 def serve_file(load, fnd):
564     if "env" in load:
565         load.pop("env")
566     ret = {"data": "", "dest": ""}
567     if not all(x in load for x in ("path", "loc", "saltenv")):
568         return ret
569     if not fnd["path"]:
570         return ret
571     ret["dest"] = fnd["rel"]
572     gzip = load.get("gzip", None)
573     fpath = os.path.normpath(fnd["path"])
574     with salt.utils.files.fopen(fpath, "rb") as fp_:
575         fp_.seek(load["loc"])
576         data = fp_.read(__opts__["file_buffer_size"])
577         if data and not salt.utils.files.is_binary(fpath):
578             data = data.decode(__salt_system_encoding__)
579         if gzip and data:
580             data = salt.utils.gzip_util.compress(data, gzip)
581             ret["gzip"] = gzip
582         ret["data"] = data
583     return ret
584 def file_hash(load, fnd):
585     if "env" in load:
586         load.pop("env")
587     if not all(x in load for x in ("path", "saltenv")):
588         return ""
589     ret = {"hash_type": __opts__["hash_type"]}
590     relpath = fnd["rel"]
591     path = fnd["path"]
592     hashdest = os.path.join(
593         __opts__["cachedir"],
594         "hgfs/hash",
595         load["saltenv"],
596         "{}.hash.{}".format(relpath, __opts__["hash_type"]),
597     )
598     if not os.path.isfile(hashdest):
599         ret["hsum"] = salt.utils.hashutils.get_hash(path, __opts__["hash_type"])
600         with salt.utils.files.fopen(hashdest, "w+") as fp_:
601             fp_.write(ret["hsum"])
602         return ret
603     else:
604         with salt.utils.files.fopen(hashdest, "rb") as fp_:
605             ret["hsum"] = salt.utils.stringutils.to_unicode(fp_.read())
606         return ret
607 def _file_lists(load, form):
608     if "env" in load:
609         load.pop("env")
610     list_cachedir = os.path.join(__opts__["cachedir"], "file_lists/hgfs")
611     if not os.path.isdir(list_cachedir):
612         try:
613             os.makedirs(list_cachedir)
614         except os.error:
615             log.critical("Unable to make cachedir %s", list_cachedir)
616             return []
617     list_cache = os.path.join(list_cachedir, "{}.p".format(load["saltenv"]))
618     w_lock = os.path.join(list_cachedir, ".{}.w".format(load["saltenv"]))
619     cache_match, refresh_cache, save_cache = salt.fileserver.check_file_list_cache(
620         __opts__, form, list_cache, w_lock
621     )
622     if cache_match is not None:
623         return cache_match
624     if refresh_cache:
625         ret = {}
626         ret["files"] = _get_file_list(load)
627         ret["dirs"] = _get_dir_list(load)
628         if save_cache:
629             salt.fileserver.write_file_list_cache(__opts__, ret, list_cache, w_lock)
630         return ret.get(form, [])
631     return []
632 def file_list(load):
633     return _file_lists(load, "files")
634 def _get_file_list(load):
635     if "env" in load:
636         load.pop("env")
637     if "saltenv" not in load or load["saltenv"] not in envs():
638         return []
639     ret = set()
640     for repo in init():
641         try:
642             repo["repo"].open()
643             ref = _get_ref(repo, load["saltenv"])
644             if ref:
645                 manifest = _get_manifest(repo["repo"], ref=ref)
646                 for tup in manifest:
647                     relpath = os.path.relpath(tup[4], repo["root"])
648                     if not relpath.startswith("../"):
649                         ret.add(os.path.join(repo["mountpoint"], relpath))
650         finally:
651             repo["repo"].close()
652     return sorted(ret)
653 def file_list_emptydirs(load):  # pylint: disable=W0613
654     return []
655 def dir_list(load):
656     return _file_lists(load, "dirs")
657 def _get_dir_list(load):
658     if "env" in load:
659         load.pop("env")
660     if "saltenv" not in load or load["saltenv"] not in envs():
661         return []
662     ret = set()
663     for repo in init():
664         try:
665             repo["repo"].open()
666             ref = _get_ref(repo, load["saltenv"])
667             if ref:
668                 manifest = _get_manifest(repo["repo"], ref=ref)
669                 for tup in manifest:
670                     filepath = tup[4]
671                     split = filepath.rsplit("/", 1)
672                     while len(split) &gt; 1:
673                         relpath = os.path.relpath(split[0], repo["root"])
674                         if relpath != ".":
675                             if not relpath.startswith("../"):
676                                 ret.add(os.path.join(repo["mountpoint"], relpath))
677                         split = split[0].rsplit("/", 1)
678         finally:
679             repo["repo"].close()
680     if repo["mountpoint"]:
681         ret.add(repo["mountpoint"])
682     return sorted(ret)
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
