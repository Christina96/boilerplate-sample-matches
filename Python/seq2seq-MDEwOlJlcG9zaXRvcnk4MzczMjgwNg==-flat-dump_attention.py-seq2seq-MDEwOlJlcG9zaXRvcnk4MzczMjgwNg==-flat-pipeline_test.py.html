
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 18.45018450184502%, Tokens: 9, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-dump_attention.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import os
6  import numpy as np
7  from matplotlib import pyplot as plt
8  import tensorflow as tf
9  from tensorflow import gfile
10  from seq2seq.tasks.decode_text import _get_prediction_length
11  from seq2seq.tasks.inference_task import InferenceTask, unbatch_dict
12  def _get_scores(predictions_dict):
13    prediction_len = _get_prediction_length(predictions_dict)
14    source_len = predictions_dict["features.source_len"]
15    return predictions_dict["attention_scores"][:prediction_len, :source_len]
16  def _create_figure(predictions_dict):
17    target_words = list(predictions_dict["predicted_tokens"])
18    prediction_len = _get_prediction_length(predictions_dict)
19    source_len = predictions_dict["features.source_len"]
20    source_words = predictions_dict["features.source_tokens"][:source_len]
21    fig = plt.figure(figsize=(8, 8))
22    plt.imshow(
23        X=predictions_dict["attention_scores"][:prediction_len, :source_len],
24        interpolation="nearest",
25        cmap=plt.cm.Blues)
26    plt.xticks(np.arange(source_len), source_words, rotation=45)
27    plt.yticks(np.arange(prediction_len), target_words, rotation=-45)
28    fig.tight_layout()
29    return fig
30  class DumpAttention(InferenceTask):
31    def __init__(self, params):
32      super(DumpAttention, self).__init__(params)
33      self._attention_scores_accum = []
34      self._idx = 0
35      if not self.params["output_dir"]:
36        raise ValueError("Must specify output_dir for DumpAttention")
37    @staticmethod
38    def default_params():
39      params = {}
40      params.update({"output_dir": "", "dump_plots": True})
41      return params
42    def begin(self):
43      super(DumpAttention, self).begin()
44      gfile.MakeDirs(self.params["output_dir"])
45    def before_run(self, _run_context):
46      fetches = {}
47      fetches["predicted_tokens"] = self._predictions["predicted_tokens"]
48      fetches["features.source_len"] = self._predictions["features.source_len"]
49      fetches["features.source_tokens"] = self._predictions[
50          "features.source_tokens"]
51      fetches["attention_scores"] = self._predictions["attention_scores"]
52      return tf.train.SessionRunArgs(fetches)
53    def after_run(self, _run_context, run_values):
54      fetches_batch = run_values.results
55      for fetches in unbatch_dict(fetches_batch):
56        fetches["predicted_tokens"] = np.char.decode(
57            fetches["predicted_tokens"].astype("S"), "utf-8")
58        fetches["features.source_tokens"] = np.char.decode(
59            fetches["features.source_tokens"].astype("S"), "utf-8")
60        if self.params["dump_plots"]:
61          output_path = os.path.join(self.params["output_dir"],
62                                     "{:05d}.png".format(self._idx))
<span onclick='openModal()' class='match'>63          _create_figure(fetches)
64          plt.savefig(output_path)
65          plt.close()
66          tf.logging.info("Wrote %s", output_path)
67          self._idx += 1
</span>68        self._attention_scores_accum.append(_get_scores(fetches))
69    def end(self, _session):
70      scores_path = os.path.join(self.params["output_dir"],
71                                 "attention_scores.npz")
72      np.savez(scores_path, *self._attention_scores_accum)
73      tf.logging.info("Wrote %s", scores_path)
</code></pre>
        </div>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-pipeline_test.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import argparse
6  import imp
7  import os
8  import shutil
9  import tempfile
10  import yaml
11  import numpy as np
12  import tensorflow as tf
13  from tensorflow import gfile
14  from seq2seq.test import utils as test_utils
15  BIN_FOLDER = os.path.abspath(
16      os.path.join(os.path.dirname(__file__), "../../bin"))
17  def _clear_flags():
18    tf.app.flags.FLAGS = tf.app.flags._FlagValues()
19    tf.app.flags._global_parser = argparse.ArgumentParser()
20  class PipelineTest(tf.test.TestCase):
21    def setUp(self):
22      super(PipelineTest, self).setUp()
23      self.output_dir = tempfile.mkdtemp()
24      self.bin_folder = os.path.abspath(
25          os.path.join(os.path.dirname(__file__), "../../bin"))
26      tf.contrib.framework.get_or_create_global_step()
27    def tearDown(self):
28      shutil.rmtree(self.output_dir, ignore_errors=True)
29      super(PipelineTest, self).tearDown()
30    def test_train_infer(self):
31      sources_train, targets_train = test_utils.create_temp_parallel_data(
32          sources=["a a a a", "b b b b", "c c c c", "笑 笑 笑 笑"],
33          targets=["b b b b", "a a a a", "c c c c", "泣 泣 泣 泣"])
34      sources_dev, targets_dev = test_utils.create_temp_parallel_data(
35          sources=["a a", "b b", "c c c", "笑 笑 笑"],
36          targets=["b b", "a a", "c c c", "泣 泣 泣"])
37      vocab_source = test_utils.create_temporary_vocab_file(["a", "b", "c", "笑"])
38      vocab_target = test_utils.create_temporary_vocab_file(["a", "b", "c", "泣"])
39      _clear_flags()
40      tf.reset_default_graph()
41      train_script = imp.load_source("seq2seq.test.train_bin",
42                                     os.path.join(BIN_FOLDER, "train.py"))
43      tf.app.flags.FLAGS.output_dir = self.output_dir
44      tf.app.flags.FLAGS.hooks = 
45      tf.app.flags.FLAGS.metrics = 
46      tf.app.flags.FLAGS.model = "AttentionSeq2Seq"
47      tf.app.flags.FLAGS.model_params = .format(vocab_source.name, vocab_target.name)
48      tf.app.flags.FLAGS.batch_size = 2
49      config_path = os.path.join(self.output_dir, "train_config.yml")
50      with gfile.GFile(config_path, "w") as config_file:
51        yaml.dump({
52            "input_pipeline_train": {
53                "class": "ParallelTextInputPipeline",
54                "params": {
55                    "source_files": [sources_train.name],
56                    "target_files": [targets_train.name],
57                }
58            },
59            "input_pipeline_dev": {
60                "class": "ParallelTextInputPipeline",
61                "params": {
62                    "source_files": [sources_dev.name],
63                    "target_files": [targets_dev.name],
64                }
65            },
66            "train_steps": 50,
67            "model_params": {
68                "embedding.dim": 10,
69                "decoder.params": {
70                    "rnn_cell": {
71                        "cell_class": "GRUCell",
72                        "cell_params": {
73                            "num_units": 8
74                        }
75                    }
76                },
77                "encoder.params": {
78                    "rnn_cell": {
79                        "cell_class": "GRUCell",
80                        "cell_params": {
81                            "num_units": 8
82                        }
83                    }
84                }
85            }
86        }, config_file)
87      tf.app.flags.FLAGS.config_paths = config_path
88      tf.logging.set_verbosity(tf.logging.INFO)
89      train_script.main([])
90      expected_checkpoint = os.path.join(self.output_dir,
91                                         "model.ckpt-50.data-00000-of-00001")
92      self.assertTrue(os.path.exists(expected_checkpoint))
93      _clear_flags()
94      tf.reset_default_graph()
95      infer_script = imp.load_source("seq2seq.test.infer_bin",
96                                     os.path.join(BIN_FOLDER, "infer.py"))
97      attention_dir = os.path.join(self.output_dir, "att")
98      tf.app.flags.FLAGS.model_dir = self.output_dir
99      tf.app.flags.FLAGS.input_pipeline = .format(sources_dev.name, targets_dev.name)
100      tf.app.flags.FLAGS.batch_size = 2
101      tf.app.flags.FLAGS.checkpoint_path = os.path.join(self.output_dir,
102                                                        "model.ckpt-50")
<span onclick='openModal()' class='match'>103      tf.app.flags.FLAGS.tasks = .format(attention_dir)
104      infer_script.main([])
105      self.assertTrue(
106          os.path.exists(os.path.join(attention_dir, "attention_scores.npz")))
</span>107      self.assertTrue(os.path.exists(os.path.join(attention_dir, "00002.png")))
108      scores = np.load(os.path.join(attention_dir, "attention_scores.npz"))
109      self.assertIn("arr_0", scores)
110      self.assertEqual(scores["arr_0"].shape[1], 3)
111      self.assertIn("arr_1", scores)
112      self.assertEqual(scores["arr_1"].shape[1], 3)
113      self.assertIn("arr_2", scores)
114      self.assertEqual(scores["arr_2"].shape[1], 4)
115      self.assertIn("arr_3", scores)
116      self.assertEqual(scores["arr_3"].shape[1], 4)
117      _clear_flags()
118      tf.reset_default_graph()
119      infer_script = imp.load_source("seq2seq.test.infer_bin",
120                                     os.path.join(BIN_FOLDER, "infer.py"))
121      tf.app.flags.FLAGS.model_dir = self.output_dir
122      tf.app.flags.FLAGS.input_pipeline = .format(sources_dev.name, targets_dev.name)
123      tf.app.flags.FLAGS.batch_size = 2
124      tf.app.flags.FLAGS.checkpoint_path = os.path.join(self.output_dir,
125                                                        "model.ckpt-50")
126      tf.app.flags.FLAGS.model_params = 
127      tf.app.flags.FLAGS.tasks = .format(os.path.join(self.output_dir, "beams.npz"))
128      infer_script.main([])
129      self.assertTrue(os.path.exists(os.path.join(self.output_dir, "beams.npz")))
130  if __name__ == "__main__":
131    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-dump_attention.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-pipeline_test.py</div>
                </div>
                <div class="column column_space"><pre><code>63          _create_figure(fetches)
64          plt.savefig(output_path)
65          plt.close()
66          tf.logging.info("Wrote %s", output_path)
67          self._idx += 1
</pre></code></div>
                <div class="column column_space"><pre><code>103      tf.app.flags.FLAGS.tasks = .format(attention_dir)
104      infer_script.main([])
105      self.assertTrue(
106          os.path.exists(os.path.join(attention_dir, "attention_scores.npz")))
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    