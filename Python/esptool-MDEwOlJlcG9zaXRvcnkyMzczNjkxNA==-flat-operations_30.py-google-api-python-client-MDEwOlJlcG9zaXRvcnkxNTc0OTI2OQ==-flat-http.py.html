
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 2.53994264645637%, Tokens: 10</h2>
        <div class="column">
            <h3>esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-operations_30.py</h3>
            <pre><code>1  import argparse
2  import os  # noqa: F401. It is used in IDF scripts
3  import traceback
4  import espsecure
5  import esptool
6  from . import fields
7  from .. import util
8  from ..base_operations import (
9      add_common_commands,
10      add_force_write_always,
11      add_show_sensitive_info_option,
12      burn_bit,
13      burn_block_data,
14      burn_efuse,
15      check_error,
16      dump,
17      read_protect_efuse,
18      summary,
19      write_protect_efuse,
20  )
21  def protect_options(p):
22      p.add_argument(
23          "--no-write-protect",
24          help="Disable write-protecting of the key. The key remains writable. "
25          "(The keys use the RS coding scheme that does not support "
26          "post-write data changes. Forced write can damage RS encoding bits.) "
27          "The write-protecting of keypurposes does not depend on the option, "
28          "it will be set anyway.",
29          action="store_true",
30      )
31      p.add_argument(
32          "--no-read-protect",
33          help="Disable read-protecting of the key. The key remains readable software."
34          "The key with keypurpose[USER, RESERVED and *_DIGEST] "
35          "will remain readable anyway. For the rest keypurposes the read-protection "
36          "will be defined the option (Read-protect by default).",
37          action="store_true",
38      )
39  def add_commands(subparsers, efuses):
40      add_common_commands(subparsers, efuses)
41      burn_key = subparsers.add_parser(
42          "burn_key", help="Burn the key block with the specified name"
43      )
44      protect_options(burn_key)
45      add_force_write_always(burn_key)
46      add_show_sensitive_info_option(burn_key)
47      burn_key.add_argument(
48          "block",
49          help="Key block to burn",
50          action="append",
51          choices=efuses.BLOCKS_FOR_KEYS,
52      )
53      burn_key.add_argument(
54          "keyfile",
55          help="File containing 256 bits of binary key data. For the ECDSA_KEY purpose use PEM file.",
56          action="append",
57          type=argparse.FileType("rb"),
58      )
59      burn_key.add_argument(
60          "keypurpose",
61          help="Purpose to set.",
62          action="append",
63          choices=fields.EfuseKeyPurposeField.KEY_PURPOSES_NAME,
64      )
65      for _ in efuses.BLOCKS_FOR_KEYS:
66          burn_key.add_argument(
67              "block",
68              help="Key block to burn",
69              nargs="?",
70              action="append",
71              metavar="BLOCK",
72              choices=efuses.BLOCKS_FOR_KEYS,
73          )
74          burn_key.add_argument(
75              "keyfile",
76              help="File containing 256 bits of binary key data. For the ECDSA_KEY purpose use PEM file.",
77              nargs="?",
78              action="append",
79              metavar="KEYFILE",
80              type=argparse.FileType("rb"),
81          )
82          burn_key.add_argument(
83              "keypurpose",
84              help="Purpose to set.",
85              nargs="?",
86              action="append",
87              metavar="KEYPURPOSE",
88              choices=fields.EfuseKeyPurposeField.KEY_PURPOSES_NAME,
89          )
90      burn_key_digest = subparsers.add_parser(
91          "burn_key_digest",
92          help="Parse a RSA public key and burn the digest to key efuse block",
93      )
94      protect_options(burn_key_digest)
95      add_force_write_always(burn_key_digest)
96      add_show_sensitive_info_option(burn_key_digest)
97      burn_key_digest.add_argument(
98          "block",
99          help="Key block to burn",
100          action="append",
101          choices=efuses.BLOCKS_FOR_KEYS,
102      )
103      burn_key_digest.add_argument(
104          "keyfile",
105          help="Key file to digest (PEM format)",
106          action="append",
107          type=argparse.FileType("rb"),
108      )
109      burn_key_digest.add_argument(
110          "keypurpose",
111          help="Purpose to set.",
112          action="append",
113          choices=fields.EfuseKeyPurposeField.DIGEST_KEY_PURPOSES,
114      )
115      for _ in efuses.BLOCKS_FOR_KEYS:
116          burn_key_digest.add_argument(
117              "block",
118              help="Key block to burn",
119              nargs="?",
120              action="append",
121              metavar="BLOCK",
122              choices=efuses.BLOCKS_FOR_KEYS,
123          )
124          burn_key_digest.add_argument(
125              "keyfile",
126              help="Key file to digest (PEM format)",
127              nargs="?",
128              action="append",
129              metavar="KEYFILE",
130              type=argparse.FileType("rb"),
131          )
132          burn_key_digest.add_argument(
133              "keypurpose",
134              help="Purpose to set.",
135              nargs="?",
136              action="append",
137              metavar="KEYPURPOSE",
138              choices=fields.EfuseKeyPurposeField.DIGEST_KEY_PURPOSES,
139          )
140      p = subparsers.add_parser(
141          "set_flash_voltage",
142          help="Permanently set the internal flash voltage regulator "
143          "to either 1.8V, 3.3V or OFF. This means GPIO45 can be high or low "
144          "at reset without changing the flash voltage.",
145      )
146      p.add_argument("voltage", help="Voltage selection", choices=["1.8V", "3.3V", "OFF"])
147      p = subparsers.add_parser(
148          "burn_custom_mac", help="Burn a 48-bit Custom MAC Address to EFUSE BLOCK3."
149      )
150      p.add_argument(
151          "mac",
152          help="Custom MAC Address to burn given in hexadecimal format with bytes "
153          "separated by colons (e.g. AA:CD:EF:01:02:03). "
154          "Final CUSTOM_MAC = CUSTOM_MAC[48] + MAC_EXT[16]",
155          type=fields.base_fields.CheckArgValue(efuses, "CUSTOM_MAC"),
156      )
157      add_force_write_always(p)
158      p = subparsers.add_parser("get_custom_mac", help="Prints the Custom MAC Address.")
159  def burn_custom_mac(esp, efuses, args):
160      efuses["CUSTOM_MAC"].save(args.mac)
161      if not efuses.burn_all(check_batch_mode=True):
162          return
163      get_custom_mac(esp, efuses, args)
164      print("Successful")
165  def get_custom_mac(esp, efuses, args):
166      print("Custom MAC Address: {}".format(efuses["CUSTOM_MAC"].get()))
167  def set_flash_voltage(esp, efuses, args):
168      raise esptool.FatalError("set_flash_voltage is not supported!")
169  def adc_info(esp, efuses, args):
170      print("")
171      if efuses["BLK_VERSION_MAJOR"].get() == 1:
172          print("Temperature Sensor Calibration = {}C".format(efuses["TEMP_SENSOR_CAL"].get()))
173          print("")
174          print("ADC1 readings stored in efuse BLOCK2:")
175          print("    MODE0 D1 reading  (250mV):  {}".format(efuses["ADC1_MODE0_D1"].get()))
176          print("    MODE0 D2 reading  (600mV):  {}".format(efuses["ADC1_MODE0_D2"].get()))
177          print("    MODE1 D1 reading  (250mV):  {}".format(efuses["ADC1_MODE1_D1"].get()))
178          print("    MODE1 D2 reading  (800mV):  {}".format(efuses["ADC1_MODE1_D2"].get()))
179          print("    MODE2 D1 reading  (250mV):  {}".format(efuses["ADC1_MODE2_D1"].get()))
180          print("    MODE2 D2 reading  (1000mV): {}".format(efuses["ADC1_MODE2_D2"].get()))
181          print("    MODE3 D1 reading  (250mV):  {}".format(efuses["ADC1_MODE3_D1"].get()))
182          print("    MODE3 D2 reading  (2000mV): {}".format(efuses["ADC1_MODE3_D2"].get()))
183          print("")
184          print("ADC2 readings stored in efuse BLOCK2:")
185          print("    MODE0 D1 reading  (250mV):  {}".format(efuses["ADC2_MODE0_D1"].get()))
186          print("    MODE0 D2 reading  (600mV):  {}".format(efuses["ADC2_MODE0_D2"].get()))
187          print("    MODE1 D1 reading  (250mV):  {}".format(efuses["ADC2_MODE1_D1"].get()))
188          print("    MODE1 D2 reading  (800mV):  {}".format(efuses["ADC2_MODE1_D2"].get()))
189          print("    MODE2 D1 reading  (250mV):  {}".format(efuses["ADC2_MODE2_D1"].get()))
190          print("    MODE2 D2 reading  (1000mV): {}".format(efuses["ADC2_MODE2_D2"].get()))
191          print("    MODE3 D1 reading  (250mV):  {}".format(efuses["ADC2_MODE3_D1"].get()))
192          print("    MODE3 D2 reading  (2000mV): {}".format(efuses["ADC2_MODE3_D2"].get()))
193      else:
194          print("BLK_VERSION_MAJOR = {}".format(efuses["BLK_VERSION_MAJOR"].get_meaning()))
195  def burn_key(esp, efuses, args, digest=None):
196      if digest is None:
197          datafile_list = args.keyfile[
198              0 : len([name for name in args.keyfile if name is not None]) :
199          ]
200      else:
201          datafile_list = digest[0 : len([name for name in digest if name is not None]) :]
202      efuses.force_write_always = args.force_write_always
203      block_name_list = args.block[
204          0 : len([name for name in args.block if name is not None]) :
205      ]
206      keypurpose_list = args.keypurpose[
207          0 : len([name for name in args.keypurpose if name is not None]) :
208      ]
209      util.check_duplicate_name_in_list(block_name_list)
210      if len(block_name_list) != len(datafile_list) or len(block_name_list) != len(
211          keypurpose_list
212      ):
213          raise esptool.FatalError(
214              "The number of blocks (%d), datafile (%d) and keypurpose (%d) "
215              "should be the same."
216              % (len(block_name_list), len(datafile_list), len(keypurpose_list))
217          )
218      print("Burn keys to blocks:")
219      for block_name, datafile, keypurpose in zip(
220          block_name_list, datafile_list, keypurpose_list
221      ):
222          efuse = None
223          for block in efuses.blocks:
224              if block_name == block.name or block_name in block.alias:
225                  efuse = efuses[block.name]
226          if efuse is None:
227              raise esptool.FatalError("Unknown block name - %s" % (block_name))
228          num_bytes = efuse.bit_len // 8
229          block_num = efuses.get_index_block_by_name(block_name)
230          block = efuses.blocks[block_num]
231          if digest is None:
232              if keypurpose == "ECDSA_KEY":
233                  sk = espsecure.load_ecdsa_signing_key(datafile)
234                  data = sk.to_string()
235                  if len(data) == 24:
236                      data = b"\x00" * 8 + data
237              else:
238                  data = datafile.read()
239          else:
240              data = datafile
241          print(" - %s" % (efuse.name), end=" ")
242          revers_msg = None
243          if efuses[block.key_purpose_name].need_reverse(keypurpose):
244              revers_msg = f"\tReversing byte order for {keypurpose} hardware peripheral"
245              data = data[::-1]
246          print(
247              "-> [{}]".format(
248                  util.hexify(data, " ")
249                  if args.show_sensitive_info
250                  else " ".join(["??"] * len(data))
251              )
252          )
253          if revers_msg:
254              print(revers_msg)
255          if len(data) != num_bytes:
256              raise esptool.FatalError(
257                  "Incorrect key file size %d. Key file must be %d bytes (%d bits) "
258                  "of raw binary key data." % (len(data), num_bytes, num_bytes * 8)
259              )
260          if efuses[block.key_purpose_name].need_rd_protect(keypurpose):
261              read_protect = False if args.no_read_protect else True
262          else:
263              read_protect = False
264          write_protect = not args.no_write_protect
265          efuse.save(data)
266          disable_wr_protect_key_purpose = False
267          if efuses[block.key_purpose_name].get() != keypurpose:
268              if efuses[block.key_purpose_name].is_writeable():
269                  print(
270                      "\t'%s': '%s' -> '%s'."
271                      % (
272                          block.key_purpose_name,
273                          efuses[block.key_purpose_name].get(),
274                          keypurpose,
275                      )
276                  )
277                  efuses[block.key_purpose_name].save(keypurpose)
278                  disable_wr_protect_key_purpose = True
279              else:
280                  raise esptool.FatalError(
281                      "It is not possible to change '%s' to '%s' "
282                      "because write protection bit is set."
283                      % (block.key_purpose_name, keypurpose)
284                  )
285          else:
286              print("\t'%s' is already '%s'." % (block.key_purpose_name, keypurpose))
287              if efuses[block.key_purpose_name].is_writeable():
288                  disable_wr_protect_key_purpose = True
289          if disable_wr_protect_key_purpose:
290              print("\tDisabling write to '%s'." % block.key_purpose_name)
291              efuses[block.key_purpose_name].disable_write()
292          if read_protect:
293              print("\tDisabling read to key block")
294              efuse.disable_read()
295          if write_protect:
296              print("\tDisabling write to key block")
297              efuse.disable_write()
298          print("")
299      if not write_protect:
300          print("Keys will remain writeable (due to --no-write-protect)")
301      if args.no_read_protect:
302          print("Keys will remain readable (due to --no-read-protect)")
303      if not efuses.burn_all(check_batch_mode=True):
304          return
305      print("Successful")
<span onclick='openModal()' class='match'>306  def burn_key_digest(esp, efuses, args):
307      digest_list = []
308      datafile_list = args.keyfile[
309          0 : len([name for name in args.keyfile if name is not None]) :
310      ]
311      block_list = args.block[
</span>312          0 : len([block for block in args.block if block is not None]) :
313      ]
314      for block_name, datafile in zip(block_list, datafile_list):
315          efuse = None
316          for block in efuses.blocks:
317              if block_name == block.name or block_name in block.alias:
318                  efuse = efuses[block.name]
319          if efuse is None:
320              raise esptool.FatalError("Unknown block name - %s" % (block_name))
321          num_bytes = efuse.bit_len // 8
322          digest = espsecure._digest_sbv2_public_key(datafile)
323          if len(digest) != num_bytes:
324              raise esptool.FatalError(
325                  "Incorrect digest size %d. Digest must be %d bytes (%d bits) "
326                  "of raw binary key data." % (len(digest), num_bytes, num_bytes * 8)
327              )
328          digest_list.append(digest)
329      burn_key(esp, efuses, args, digest=digest_list)
330  def espefuse(esp, efuses, args, command):
331      parser = argparse.ArgumentParser()
332      subparsers = parser.add_subparsers(dest="operation")
333      add_commands(subparsers, efuses)
334      try:
335          cmd_line_args = parser.parse_args(command.split())
336      except SystemExit:
337          traceback.print_stack()
338          raise esptool.FatalError('"{}" - incorrect command'.format(command))
339      if cmd_line_args.operation == "execute_scripts":
340          configfiles = cmd_line_args.configfiles
341          index = cmd_line_args.index
342      vars(cmd_line_args).update(vars(args))
343      if cmd_line_args.operation == "execute_scripts":
344          cmd_line_args.configfiles = configfiles
345          cmd_line_args.index = index
346      if cmd_line_args.operation is None:
347          parser.print_help()
348          parser.exit(1)
349      operation_func = globals()[cmd_line_args.operation]
350      operation_func(esp, efuses, cmd_line_args)
351  def execute_scripts(esp, efuses, args):
352      efuses.batch_mode_cnt += 1
353      del args.operation
354      scripts = args.scripts
355      del args.scripts
356      for file in scripts:
357          with open(file.name, "r") as file:
358              exec(compile(file.read(), file.name, "exec"))
359      if args.debug:
360          for block in efuses.blocks:
361              data = block.get_bitstring(from_read=False)
362              block.print_block(data, "regs_for_burn", args.debug)
363      efuses.batch_mode_cnt -= 1
364      if not efuses.burn_all(check_batch_mode=True):
365          return
366      print("Successful")
</code></pre>
        </div>
        <div class="column">
            <h3>google-api-python-client-MDEwOlJlcG9zaXRvcnkxNTc0OTI2OQ==-flat-http.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  __author__ = "jcgregorio@google.com (Joe Gregorio)"
3  import copy
4  import http.client as http_client
5  import io
6  import json
7  import logging
8  import mimetypes
9  import os
10  import random
11  import socket
12  import time
13  import urllib
14  import uuid
15  import httplib2
16  try:
17      import ssl
18  except ImportError:
19      _ssl_SSLError = object()
20  else:
21      _ssl_SSLError = ssl.SSLError
22  from email.generator import Generator
23  from email.mime.multipart import MIMEMultipart
24  from email.mime.nonmultipart import MIMENonMultipart
25  from email.parser import FeedParser
26  from googleapiclient import _auth
27  from googleapiclient import _helpers as util
28  from googleapiclient.errors import (
29      BatchError,
30      HttpError,
31      InvalidChunkSizeError,
32      ResumableUploadError,
33      UnexpectedBodyError,
34      UnexpectedMethodError,
35  )
36  from googleapiclient.model import JsonModel
37  LOGGER = logging.getLogger(__name__)
38  DEFAULT_CHUNK_SIZE = 100 * 1024 * 1024
39  MAX_URI_LENGTH = 2048
40  MAX_BATCH_LIMIT = 1000
41  _TOO_MANY_REQUESTS = 429
42  DEFAULT_HTTP_TIMEOUT_SEC = 60
43  _LEGACY_BATCH_URI = "https://www.googleapis.com/batch"
44  def _should_retry_response(resp_status, content):
45      reason = None
46      if resp_status >= 500:
47          return True
48      if resp_status == _TOO_MANY_REQUESTS:
49          return True
50      if resp_status == http_client.FORBIDDEN:
51          if not content:
52              return False
53          try:
54              data = json.loads(content.decode("utf-8"))
55              if isinstance(data, dict):
56                  error_detail_keyword = next(
57                      (
58                          kw
59                          for kw in ["errors", "status", "message"]
60                          if kw in data["error"]
61                      ),
62                      "",
63                  )
64                  if error_detail_keyword:
65                      reason = data["error"][error_detail_keyword]
66                      if isinstance(reason, list) and len(reason) > 0:
67                          reason = reason[0]
68                          if "reason" in reason:
69                              reason = reason["reason"]
70              else:
71                  reason = data[0]["error"]["errors"]["reason"]
72          except (UnicodeDecodeError, ValueError, KeyError):
73              LOGGER.warning("Invalid JSON content from response: %s", content)
74              return False
75          LOGGER.warning('Encountered 403 Forbidden with reason "%s"', reason)
76          if reason in ("userRateLimitExceeded", "rateLimitExceeded"):
77              return True
78      return False
79  def _retry_request(
80      http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs
81  ):
82      resp = None
83      content = None
84      exception = None
85      for retry_num in range(num_retries + 1):
86          if retry_num > 0:
87              sleep_time = rand() * 2**retry_num
88              LOGGER.warning(
89                  "Sleeping %.2f seconds before retry %d of %d for %s: %s %s, after %s",
90                  sleep_time,
91                  retry_num,
92                  num_retries,
93                  req_type,
94                  method,
95                  uri,
96                  resp.status if resp else exception,
97              )
98              sleep(sleep_time)
99          try:
100              exception = None
101              resp, content = http.request(uri, method, *args, **kwargs)
102          except _ssl_SSLError as ssl_error:
103              exception = ssl_error
104          except socket.timeout as socket_timeout:
105              exception = socket_timeout
106          except ConnectionError as connection_error:
107              exception = connection_error
108          except OSError as socket_error:
109              if socket.errno.errorcode.get(socket_error.errno) not in {
110                  "WSAETIMEDOUT",
111                  "ETIMEDOUT",
112                  "EPIPE",
113                  "ECONNABORTED",
114                  "ECONNREFUSED",
115                  "ECONNRESET",
116              }:
117                  raise
118              exception = socket_error
119          except httplib2.ServerNotFoundError as server_not_found_error:
120              exception = server_not_found_error
121          if exception:
122              if retry_num == num_retries:
123                  raise exception
124              else:
125                  continue
126          if not _should_retry_response(resp.status, content):
127              break
128      return resp, content
129  class MediaUploadProgress(object):
130      def __init__(self, resumable_progress, total_size):
131          self.resumable_progress = resumable_progress
132          self.total_size = total_size
133      def progress(self):
134          if self.total_size is not None and self.total_size != 0:
135              return float(self.resumable_progress) / float(self.total_size)
136          else:
137              return 0.0
138  class MediaDownloadProgress(object):
139      def __init__(self, resumable_progress, total_size):
140          self.resumable_progress = resumable_progress
141          self.total_size = total_size
142      def progress(self):
143          if self.total_size is not None and self.total_size != 0:
144              return float(self.resumable_progress) / float(self.total_size)
145          else:
146              return 0.0
147  class MediaUpload(object):
148      def chunksize(self):
149          raise NotImplementedError()
150      def mimetype(self):
151          return "application/octet-stream"
152      def size(self):
153          return None
154      def resumable(self):
155          return False
156      def getbytes(self, begin, end):
157          raise NotImplementedError()
158      def has_stream(self):
159          return False
160      def stream(self):
161          raise NotImplementedError()
162      @util.positional(1)
163      def _to_json(self, strip=None):
164          t = type(self)
165          d = copy.copy(self.__dict__)
166          if strip is not None:
167              for member in strip:
168                  del d[member]
169          d["_class"] = t.__name__
170          d["_module"] = t.__module__
171          return json.dumps(d)
172      def to_json(self):
173          return self._to_json()
174      @classmethod
175      def new_from_json(cls, s):
176          data = json.loads(s)
177          module = data["_module"]
178          m = __import__(module, fromlist=module.split(".")[:-1])
179          kls = getattr(m, data["_class"])
180          from_json = getattr(kls, "from_json")
181          return from_json(s)
182  class MediaIoBaseUpload(MediaUpload):
183      @util.positional(3)
184      def __init__(self, fd, mimetype, chunksize=DEFAULT_CHUNK_SIZE, resumable=False):
185          super(MediaIoBaseUpload, self).__init__()
186          self._fd = fd
187          self._mimetype = mimetype
188          if not (chunksize == -1 or chunksize > 0):
189              raise InvalidChunkSizeError()
190          self._chunksize = chunksize
191          self._resumable = resumable
192          self._fd.seek(0, os.SEEK_END)
193          self._size = self._fd.tell()
194      def chunksize(self):
195          return self._chunksize
196      def mimetype(self):
197          return self._mimetype
198      def size(self):
199          return self._size
200      def resumable(self):
201          return self._resumable
202      def getbytes(self, begin, length):
203          self._fd.seek(begin)
204          return self._fd.read(length)
205      def has_stream(self):
206          return True
207      def stream(self):
208          return self._fd
209      def to_json(self):
210          raise NotImplementedError("MediaIoBaseUpload is not serializable.")
211  class MediaFileUpload(MediaIoBaseUpload):
212      @util.positional(2)
213      def __init__(
214          self, filename, mimetype=None, chunksize=DEFAULT_CHUNK_SIZE, resumable=False
215      ):
216          self._fd = None
217          self._filename = filename
218          self._fd = open(self._filename, "rb")
219          if mimetype is None:
220              mimetype, _ = mimetypes.guess_type(filename)
221              if mimetype is None:
222                  mimetype = "application/octet-stream"
223          super(MediaFileUpload, self).__init__(
224              self._fd, mimetype, chunksize=chunksize, resumable=resumable
225          )
226      def __del__(self):
227          if self._fd:
228              self._fd.close()
229      def to_json(self):
230          return self._to_json(strip=["_fd"])
231      @staticmethod
232      def from_json(s):
233          d = json.loads(s)
234          return MediaFileUpload(
235              d["_filename"],
236              mimetype=d["_mimetype"],
237              chunksize=d["_chunksize"],
238              resumable=d["_resumable"],
239          )
240  class MediaInMemoryUpload(MediaIoBaseUpload):
241      @util.positional(2)
242      def __init__(
243          self,
244          body,
245          mimetype="application/octet-stream",
246          chunksize=DEFAULT_CHUNK_SIZE,
247          resumable=False,
248      ):
249          fd = io.BytesIO(body)
250          super(MediaInMemoryUpload, self).__init__(
251              fd, mimetype, chunksize=chunksize, resumable=resumable
252          )
253  class MediaIoBaseDownload(object):
254      @util.positional(3)
255      def __init__(self, fd, request, chunksize=DEFAULT_CHUNK_SIZE):
256          self._fd = fd
257          self._request = request
258          self._uri = request.uri
259          self._chunksize = chunksize
260          self._progress = 0
261          self._total_size = None
262          self._done = False
263          self._sleep = time.sleep
264          self._rand = random.random
265          self._headers = {}
266          for k, v in request.headers.items():
267              if not k.lower() in ("accept", "accept-encoding", "user-agent"):
268                  self._headers[k] = v
269      @util.positional(1)
<span onclick='openModal()' class='match'>270      def next_chunk(self, num_retries=0):
271          headers = self._headers.copy()
272          headers["range"] = "bytes=%d-%d" % (
273              self._progress,
</span>274              self._progress + self._chunksize - 1,
275          )
276          http = self._request.http
277          resp, content = _retry_request(
278              http,
279              num_retries,
280              "media download",
281              self._sleep,
282              self._rand,
283              self._uri,
284              "GET",
285              headers=headers,
286          )
287          if resp.status in [200, 206]:
288              if "content-location" in resp and resp["content-location"] != self._uri:
289                  self._uri = resp["content-location"]
290              self._progress += len(content)
291              self._fd.write(content)
292              if "content-range" in resp:
293                  content_range = resp["content-range"]
294                  length = content_range.rsplit("/", 1)[1]
295                  self._total_size = int(length)
296              elif "content-length" in resp:
297                  self._total_size = int(resp["content-length"])
298              if self._total_size is None or self._progress == self._total_size:
299                  self._done = True
300              return MediaDownloadProgress(self._progress, self._total_size), self._done
301          elif resp.status == 416:
302              content_range = resp["content-range"]
303              length = content_range.rsplit("/", 1)[1]
304              self._total_size = int(length)
305              if self._total_size == 0:
306                  self._done = True
307                  return (
308                      MediaDownloadProgress(self._progress, self._total_size),
309                      self._done,
310                  )
311          raise HttpError(resp, content, uri=self._uri)
312  class _StreamSlice(object):
313      def __init__(self, stream, begin, chunksize):
314          self._stream = stream
315          self._begin = begin
316          self._chunksize = chunksize
317          self._stream.seek(begin)
318      def read(self, n=-1):
319          cur = self._stream.tell()
320          end = self._begin + self._chunksize
321          if n == -1 or cur + n > end:
322              n = end - cur
323          return self._stream.read(n)
324  class HttpRequest(object):
325      @util.positional(4)
326      def __init__(
327          self,
328          http,
329          postproc,
330          uri,
331          method="GET",
332          body=None,
333          headers=None,
334          methodId=None,
335          resumable=None,
336      ):
337          self.uri = uri
338          self.method = method
339          self.body = body
340          self.headers = headers or {}
341          self.methodId = methodId
342          self.http = http
343          self.postproc = postproc
344          self.resumable = resumable
345          self.response_callbacks = []
346          self._in_error_state = False
347          self.body_size = len(self.body or "")
348          self.resumable_uri = None
349          self.resumable_progress = 0
350          self._rand = random.random
351          self._sleep = time.sleep
352      @util.positional(1)
353      def execute(self, http=None, num_retries=0):
354          if http is None:
355              http = self.http
356          if self.resumable:
357              body = None
358              while body is None:
359                  _, body = self.next_chunk(http=http, num_retries=num_retries)
360              return body
361          if "content-length" not in self.headers:
362              self.headers["content-length"] = str(self.body_size)
363          if len(self.uri) > MAX_URI_LENGTH and self.method == "GET":
364              self.method = "POST"
365              self.headers["x-http-method-override"] = "GET"
366              self.headers["content-type"] = "application/x-www-form-urlencoded"
367              parsed = urllib.parse.urlparse(self.uri)
368              self.uri = urllib.parse.urlunparse(
369                  (parsed.scheme, parsed.netloc, parsed.path, parsed.params, None, None)
370              )
371              self.body = parsed.query
372              self.headers["content-length"] = str(len(self.body))
373          resp, content = _retry_request(
374              http,
375              num_retries,
376              "request",
377              self._sleep,
378              self._rand,
379              str(self.uri),
380              method=str(self.method),
381              body=self.body,
382              headers=self.headers,
383          )
384          for callback in self.response_callbacks:
385              callback(resp)
386          if resp.status >= 300:
387              raise HttpError(resp, content, uri=self.uri)
388          return self.postproc(resp, content)
389      @util.positional(2)
390      def add_response_callback(self, cb):
391          self.response_callbacks.append(cb)
392      @util.positional(1)
393      def next_chunk(self, http=None, num_retries=0):
394          if http is None:
395              http = self.http
396          if self.resumable.size() is None:
397              size = "*"
398          else:
399              size = str(self.resumable.size())
400          if self.resumable_uri is None:
401              start_headers = copy.copy(self.headers)
402              start_headers["X-Upload-Content-Type"] = self.resumable.mimetype()
403              if size != "*":
404                  start_headers["X-Upload-Content-Length"] = size
405              start_headers["content-length"] = str(self.body_size)
406              resp, content = _retry_request(
407                  http,
408                  num_retries,
409                  "resumable URI request",
410                  self._sleep,
411                  self._rand,
412                  self.uri,
413                  method=self.method,
414                  body=self.body,
415                  headers=start_headers,
416              )
417              if resp.status == 200 and "location" in resp:
418                  self.resumable_uri = resp["location"]
419              else:
420                  raise ResumableUploadError(resp, content)
421          elif self._in_error_state:
422              resp, content = http.request(self.resumable_uri, "PUT", headers=headers)
423              status, body = self._process_response(resp, content)
424              if body:
425                  return (status, body)
426          if self.resumable.has_stream():
427              data = self.resumable.stream()
428              if self.resumable.chunksize() == -1:
429                  data.seek(self.resumable_progress)
430                  chunk_end = self.resumable.size() - self.resumable_progress - 1
431              else:
432                  data = _StreamSlice(
433                      data, self.resumable_progress, self.resumable.chunksize()
434                  )
435                  chunk_end = min(
436                      self.resumable_progress + self.resumable.chunksize() - 1,
437                      self.resumable.size() - 1,
438                  )
439          else:
440              data = self.resumable.getbytes(
441                  self.resumable_progress, self.resumable.chunksize()
442              )
443              if len(data) < self.resumable.chunksize():
444                  size = str(self.resumable_progress + len(data))
445              chunk_end = self.resumable_progress + len(data) - 1
446          headers = {
447              "Content-Length": str(chunk_end - self.resumable_progress + 1),
448          }
449          if chunk_end != -1:
450              headers["Content-Range"] = "bytes %d-%d/%s" % (
451                  self.resumable_progress,
452                  chunk_end,
453                  size,
454              )
455          for retry_num in range(num_retries + 1):
456              if retry_num > 0:
457                  self._sleep(self._rand() * 2**retry_num)
458                  LOGGER.warning(
459                      "Retry #%d for media upload: %s %s, following status: %d"
460                      % (retry_num, self.method, self.uri, resp.status)
461                  )
462              try:
463                  resp, content = http.request(
464                      self.resumable_uri, method="PUT", body=data, headers=headers
465                  )
466              except:
467                  self._in_error_state = True
468                  raise
469              if not _should_retry_response(resp.status, content):
470                  break
471          return self._process_response(resp, content)
472      def _process_response(self, resp, content):
473          if resp.status in [200, 201]:
474              self._in_error_state = False
475              return None, self.postproc(resp, content)
476          elif resp.status == 308:
477              self._in_error_state = False
478              try:
479                  self.resumable_progress = int(resp["range"].split("-")[1]) + 1
480              except KeyError:
481                  self.resumable_progress = 0
482              if "location" in resp:
483                  self.resumable_uri = resp["location"]
484          else:
485              self._in_error_state = True
486              raise HttpError(resp, content, uri=self.uri)
487          return (
488              MediaUploadProgress(self.resumable_progress, self.resumable.size()),
489              None,
490          )
491      def to_json(self):
492          d = copy.copy(self.__dict__)
493          if d["resumable"] is not None:
494              d["resumable"] = self.resumable.to_json()
495          del d["http"]
496          del d["postproc"]
497          del d["_sleep"]
498          del d["_rand"]
499          return json.dumps(d)
500      @staticmethod
501      def from_json(s, http, postproc):
502          d = json.loads(s)
503          if d["resumable"] is not None:
504              d["resumable"] = MediaUpload.new_from_json(d["resumable"])
505          return HttpRequest(
506              http,
507              postproc,
508              uri=d["uri"],
509              method=d["method"],
510              body=d["body"],
511              headers=d["headers"],
512              methodId=d["methodId"],
513              resumable=d["resumable"],
514          )
515      @staticmethod
516      def null_postproc(resp, contents):
517          return resp, contents
518  class BatchHttpRequest(object):
519      @util.positional(1)
520      def __init__(self, callback=None, batch_uri=None):
521          if batch_uri is None:
522              batch_uri = _LEGACY_BATCH_URI
523          if batch_uri == _LEGACY_BATCH_URI:
524              LOGGER.warning(
525                  "You have constructed a BatchHttpRequest using the legacy batch "
526                  "endpoint %s. This endpoint will be turned down on August 12, 2020. "
527                  "Please provide the API-specific endpoint or use "
528                  "service.new_batch_http_request(). For more details see "
529                  "https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html"
530                  "and https://developers.google.com/api-client-library/python/guide/batch.",
531                  _LEGACY_BATCH_URI,
532              )
533          self._batch_uri = batch_uri
534          self._callback = callback
535          self._requests = {}
536          self._callbacks = {}
537          self._order = []
538          self._last_auto_id = 0
539          self._base_id = None
540          self._responses = {}
541          self._refreshed_credentials = {}
542      def _refresh_and_apply_credentials(self, request, http):
543          creds = None
544          request_credentials = False
545          if request.http is not None:
546              creds = _auth.get_credentials_from_http(request.http)
547              request_credentials = True
548          if creds is None and http is not None:
549              creds = _auth.get_credentials_from_http(http)
550          if creds is not None:
551              if id(creds) not in self._refreshed_credentials:
552                  _auth.refresh_credentials(creds)
553                  self._refreshed_credentials[id(creds)] = 1
554          if request.http is None or not request_credentials:
555              _auth.apply_credentials(creds, request.headers)
556      def _id_to_header(self, id_):
557          if self._base_id is None:
558              self._base_id = uuid.uuid4()
559          return "<%s + %s>" % (self._base_id, urllib.parse.quote(id_))
560      def _header_to_id(self, header):
561          if header[0] != "<" or header[-1] != ">":
562              raise BatchError("Invalid value for Content-ID: %s" % header)
563          if "+" not in header:
564              raise BatchError("Invalid value for Content-ID: %s" % header)
565          base, id_ = header[1:-1].split(" + ", 1)
566          return urllib.parse.unquote(id_)
567      def _serialize_request(self, request):
568          parsed = urllib.parse.urlparse(request.uri)
569          request_line = urllib.parse.urlunparse(
570              ("", "", parsed.path, parsed.params, parsed.query, "")
571          )
572          status_line = request.method + " " + request_line + " HTTP/1.1\n"
573          major, minor = request.headers.get("content-type", "application/json").split(
574              "/"
575          )
576          msg = MIMENonMultipart(major, minor)
577          headers = request.headers.copy()
578          if request.http is not None:
579              credentials = _auth.get_credentials_from_http(request.http)
580              if credentials is not None:
581                  _auth.apply_credentials(credentials, headers)
582          if "content-type" in headers:
583              del headers["content-type"]
584          for key, value in headers.items():
585              msg[key] = value
586          msg["Host"] = parsed.netloc
587          msg.set_unixfrom(None)
588          if request.body is not None:
589              msg.set_payload(request.body)
590              msg["content-length"] = str(len(request.body))
591          fp = io.StringIO()
592          g = Generator(fp, maxheaderlen=0)
593          g.flatten(msg, unixfrom=False)
594          body = fp.getvalue()
595          return status_line + body
596      def _deserialize_response(self, payload):
597          status_line, payload = payload.split("\n", 1)
598          protocol, status, reason = status_line.split(" ", 2)
599          parser = FeedParser()
600          parser.feed(payload)
601          msg = parser.close()
602          msg["status"] = status
603          resp = httplib2.Response(msg)
604          resp.reason = reason
605          resp.version = int(protocol.split("/", 1)[1].replace(".", ""))
606          content = payload.split("\r\n\r\n", 1)[1]
607          return resp, content
608      def _new_id(self):
609          self._last_auto_id += 1
610          while str(self._last_auto_id) in self._requests:
611              self._last_auto_id += 1
612          return str(self._last_auto_id)
613      @util.positional(2)
614      def add(self, request, callback=None, request_id=None):
615          if len(self._order) >= MAX_BATCH_LIMIT:
616              raise BatchError(
617                  "Exceeded the maximum calls(%d) in a single batch request."
618                  % MAX_BATCH_LIMIT
619              )
620          if request_id is None:
621              request_id = self._new_id()
622          if request.resumable is not None:
623              raise BatchError("Media requests cannot be used in a batch request.")
624          if request_id in self._requests:
625              raise KeyError("A request with this ID already exists: %s" % request_id)
626          self._requests[request_id] = request
627          self._callbacks[request_id] = callback
628          self._order.append(request_id)
629      def _execute(self, http, order, requests):
630          message = MIMEMultipart("mixed")
631          setattr(message, "_write_headers", lambda self: None)
632          for request_id in order:
633              request = requests[request_id]
634              msg = MIMENonMultipart("application", "http")
635              msg["Content-Transfer-Encoding"] = "binary"
636              msg["Content-ID"] = self._id_to_header(request_id)
637              body = self._serialize_request(request)
638              msg.set_payload(body)
639              message.attach(msg)
640          fp = io.StringIO()
641          g = Generator(fp, mangle_from_=False)
642          g.flatten(message, unixfrom=False)
643          body = fp.getvalue()
644          headers = {}
645          headers["content-type"] = (
646              "multipart/mixed; " 'boundary="%s"'
647          ) % message.get_boundary()
648          resp, content = http.request(
649              self._batch_uri, method="POST", body=body, headers=headers
650          )
651          if resp.status >= 300:
652              raise HttpError(resp, content, uri=self._batch_uri)
653          header = "content-type: %s\r\n\r\n" % resp["content-type"]
654          content = content.decode("utf-8")
655          for_parser = header + content
656          parser = FeedParser()
657          parser.feed(for_parser)
658          mime_response = parser.close()
659          if not mime_response.is_multipart():
660              raise BatchError(
661                  "Response not in multipart/mixed format.", resp=resp, content=content
662              )
663          for part in mime_response.get_payload():
664              request_id = self._header_to_id(part["Content-ID"])
665              response, content = self._deserialize_response(part.get_payload())
666              if isinstance(content, str):
667                  content = content.encode("utf-8")
668              self._responses[request_id] = (response, content)
669      @util.positional(1)
670      def execute(self, http=None):
671          if len(self._order) == 0:
672              return None
673          if http is None:
674              for request_id in self._order:
675                  request = self._requests[request_id]
676                  if request is not None:
677                      http = request.http
678                      break
679          if http is None:
680              raise ValueError("Missing a valid http object.")
681          creds = _auth.get_credentials_from_http(http)
682          if creds is not None:
683              if not _auth.is_valid(creds):
684                  LOGGER.info("Attempting refresh to obtain initial access_token")
685                  _auth.refresh_credentials(creds)
686          self._execute(http, self._order, self._requests)
687          redo_requests = {}
688          redo_order = []
689          for request_id in self._order:
690              resp, content = self._responses[request_id]
691              if resp["status"] == "401":
692                  redo_order.append(request_id)
693                  request = self._requests[request_id]
694                  self._refresh_and_apply_credentials(request, http)
695                  redo_requests[request_id] = request
696          if redo_requests:
697              self._execute(http, redo_order, redo_requests)
698          for request_id in self._order:
699              resp, content = self._responses[request_id]
700              request = self._requests[request_id]
701              callback = self._callbacks[request_id]
702              response = None
703              exception = None
704              try:
705                  if resp.status >= 300:
706                      raise HttpError(resp, content, uri=request.uri)
707                  response = request.postproc(resp, content)
708              except HttpError as e:
709                  exception = e
710              if callback is not None:
711                  callback(request_id, response, exception)
712              if self._callback is not None:
713                  self._callback(request_id, response, exception)
714  class HttpRequestMock(object):
715      def __init__(self, resp, content, postproc):
716          self.resp = resp
717          self.content = content
718          self.postproc = postproc
719          if resp is None:
720              self.resp = httplib2.Response({"status": 200, "reason": "OK"})
721          if "reason" in self.resp:
722              self.resp.reason = self.resp["reason"]
723      def execute(self, http=None):
724          return self.postproc(self.resp, self.content)
725  class RequestMockBuilder(object):
726      def __init__(self, responses, check_unexpected=False):
727          self.responses = responses
728          self.check_unexpected = check_unexpected
729      def __call__(
730          self,
731          http,
732          postproc,
733          uri,
734          method="GET",
735          body=None,
736          headers=None,
737          methodId=None,
738          resumable=None,
739      ):
740          if methodId in self.responses:
741              response = self.responses[methodId]
742              resp, content = response[:2]
743              if len(response) > 2:
744                  expected_body = response[2]
745                  if bool(expected_body) != bool(body):
746                      raise UnexpectedBodyError(expected_body, body)
747                  if isinstance(expected_body, str):
748                      expected_body = json.loads(expected_body)
749                  body = json.loads(body)
750                  if body != expected_body:
751                      raise UnexpectedBodyError(expected_body, body)
752              return HttpRequestMock(resp, content, postproc)
753          elif self.check_unexpected:
754              raise UnexpectedMethodError(methodId=methodId)
755          else:
756              model = JsonModel(False)
757              return HttpRequestMock(None, "{}", model.response)
758  class HttpMock(object):
759      def __init__(self, filename=None, headers=None):
760          if headers is None:
761              headers = {"status": "200"}
762          if filename:
763              with open(filename, "rb") as f:
764                  self.data = f.read()
765          else:
766              self.data = None
767          self.response_headers = headers
768          self.headers = None
769          self.uri = None
770          self.method = None
771          self.body = None
772          self.headers = None
773      def request(
774          self,
775          uri,
776          method="GET",
777          body=None,
778          headers=None,
779          redirections=1,
780          connection_type=None,
781      ):
782          self.uri = uri
783          self.method = method
784          self.body = body
785          self.headers = headers
786          return httplib2.Response(self.response_headers), self.data
787      def close(self):
788          return None
789  class HttpMockSequence(object):
790      def __init__(self, iterable):
791          self._iterable = iterable
792          self.follow_redirects = True
793          self.request_sequence = list()
794      def request(
795          self,
796          uri,
797          method="GET",
798          body=None,
799          headers=None,
800          redirections=1,
801          connection_type=None,
802      ):
803          self.request_sequence.append((uri, method, body, headers))
804          resp, content = self._iterable.pop(0)
805          if isinstance(content, str):
806              content = content.encode("utf-8")
807          if content == b"echo_request_headers":
808              content = headers
809          elif content == b"echo_request_headers_as_json":
810              content = json.dumps(headers)
811          elif content == b"echo_request_body":
812              if hasattr(body, "read"):
813                  content = body.read()
814              else:
815                  content = body
816          elif content == b"echo_request_uri":
817              content = uri
818          if isinstance(content, str):
819              content = content.encode("utf-8")
820          return httplib2.Response(resp), content
821  def set_user_agent(http, user_agent):
822      request_orig = http.request
823      def new_request(
824          uri,
825          method="GET",
826          body=None,
827          headers=None,
828          redirections=httplib2.DEFAULT_MAX_REDIRECTS,
829          connection_type=None,
830      ):
831          if headers is None:
832              headers = {}
833          if "user-agent" in headers:
834              headers["user-agent"] = user_agent + " " + headers["user-agent"]
835          else:
836              headers["user-agent"] = user_agent
837          resp, content = request_orig(
838              uri,
839              method=method,
840              body=body,
841              headers=headers,
842              redirections=redirections,
843              connection_type=connection_type,
844          )
845          return resp, content
846      http.request = new_request
847      return http
848  def tunnel_patch(http):
849      request_orig = http.request
850      def new_request(
851          uri,
852          method="GET",
853          body=None,
854          headers=None,
855          redirections=httplib2.DEFAULT_MAX_REDIRECTS,
856          connection_type=None,
857      ):
858          if headers is None:
859              headers = {}
860          if method == "PATCH":
861              if "oauth_token" in headers.get("authorization", ""):
862                  LOGGER.warning(
863                      "OAuth 1.0 request made with Credentials after tunnel_patch."
864                  )
865              headers["x-http-method-override"] = "PATCH"
866              method = "POST"
867          resp, content = request_orig(
868              uri,
869              method=method,
870              body=body,
871              headers=headers,
872              redirections=redirections,
873              connection_type=connection_type,
874          )
875          return resp, content
876      http.request = new_request
877      return http
878  def build_http():
879      if socket.getdefaulttimeout() is not None:
880          http_timeout = socket.getdefaulttimeout()
881      else:
882          http_timeout = DEFAULT_HTTP_TIMEOUT_SEC
883      http = httplib2.Http(timeout=http_timeout)
884      try:
885          http.redirect_codes = http.redirect_codes - {308}
886      except AttributeError:
887          pass
888      return http
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-operations_30.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from google-api-python-client-MDEwOlJlcG9zaXRvcnkxNTc0OTI2OQ==-flat-http.py</div>
                </div>
                <div class="column column_space"><pre><code>306  def burn_key_digest(esp, efuses, args):
307      digest_list = []
308      datafile_list = args.keyfile[
309          0 : len([name for name in args.keyfile if name is not None]) :
310      ]
311      block_list = args.block[
</pre></code></div>
                <div class="column column_space"><pre><code>270      def next_chunk(self, num_retries=0):
271          headers = self._headers.copy()
272          headers["range"] = "bytes=%d-%d" % (
273              self._progress,
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    