<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for master.py &amp; test_output.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for master.py &amp; test_output.py
      </h3>
<h1 align="center">
        0.6%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>master.py (0.33888733%)<th>test_output.py (5.714286%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(249-252)<td><a href="#" name="0">(107-110)</a><td align="center"><font color="#ff0000">12</font>
</td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>master.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import collections
2 import copy
3 import ctypes
4 import functools
5 import logging
6 import multiprocessing
7 import os
8 import re
9 import signal
10 import stat
11 import sys
12 import threading
13 import time
14 import salt.acl
15 import salt.auth
16 import salt.channel.server
17 import salt.client
18 import salt.client.ssh.client
19 import salt.crypt
20 import salt.daemons.masterapi
21 import salt.defaults.exitcodes
22 import salt.engines
23 import salt.exceptions
24 import salt.ext.tornado.gen
25 import salt.key
26 import salt.minion
27 import salt.payload
28 import salt.pillar
29 import salt.runner
30 import salt.serializers.msgpack
31 import salt.state
32 import salt.utils.args
33 import salt.utils.atomicfile
34 import salt.utils.crypt
35 import salt.utils.event
36 import salt.utils.files
37 import salt.utils.gitfs
38 import salt.utils.gzip_util
39 import salt.utils.jid
40 import salt.utils.job
41 import salt.utils.master
42 import salt.utils.minions
43 import salt.utils.platform
44 import salt.utils.process
45 import salt.utils.schedule
46 import salt.utils.ssdp
47 import salt.utils.stringutils
48 import salt.utils.user
49 import salt.utils.verify
50 import salt.utils.zeromq
51 import salt.wheel
52 from salt.config import DEFAULT_INTERVAL
53 from salt.defaults import DEFAULT_TARGET_DELIM
54 from salt.ext.tornado.stack_context import StackContext
55 from salt.transport import TRANSPORTS
56 from salt.utils.channel import iter_transport_opts
57 from salt.utils.ctx import RequestContext
58 from salt.utils.debug import (
59     enable_sigusr1_handler,
60     enable_sigusr2_handler,
61     inspect_stack,
62 )
63 from salt.utils.event import tagify
64 from salt.utils.odict import OrderedDict
65 from salt.utils.zeromq import ZMQ_VERSION_INFO, zmq
66 try:
67     import resource
68     HAS_RESOURCE = True
69 except ImportError:
70     HAS_RESOURCE = False
71 log = logging.getLogger(__name__)
72 class SMaster:
73     secrets = (
74         {}
75     )  # mapping of key -&gt; {'secret': multiprocessing type, 'reload': FUNCTION}
76     def __init__(self, opts):
77         self.opts = opts
78         self.master_key = salt.crypt.MasterKeys(self.opts)
79         self.key = self.__prep_key()
80     def __setstate__(self, state):
81         super().__setstate__(state)
82         self.master_key = state["master_key"]
83         self.key = state["key"]
84         SMaster.secrets = state["secrets"]
85     def __getstate__(self):
86         state = super().__getstate__()
87         state.update(
88             {
89                 "key": self.key,
90                 "master_key": self.master_key,
91                 "secrets": SMaster.secrets,
92             }
93         )
94         return state
95     def __prep_key(self):
96         return salt.daemons.masterapi.access_keys(self.opts)
97 class Maintenance(salt.utils.process.SignalHandlingProcess):
98     def __init__(self, opts, **kwargs):
99         super().__init__(**kwargs)
100         self.opts = opts
101         self.loop_interval = int(self.opts["loop_interval"])
102         self.rotate = int(time.time())
103     def _post_fork_init(self):
104         ropts = dict(self.opts)
105         ropts["quiet"] = True
106         runner_client = salt.runner.RunnerClient(ropts)
107         self.returners = salt.loader.returners(self.opts, {})
108         self.schedule = salt.utils.schedule.Schedule(
109             self.opts, runner_client.functions_dict(), returners=self.returners
110         )
111         self.ckminions = salt.utils.minions.CkMinions(self.opts)
112         self.event = salt.utils.event.get_master_event(
113             self.opts, self.opts["sock_dir"], listen=False
114         )
115         self.git_pillar = salt.daemons.masterapi.init_git_pillar(self.opts)
116         if self.opts["maintenance_niceness"] and not salt.utils.platform.is_windows():
117             log.info(
118                 "setting Maintenance niceness to %d", self.opts["maintenance_niceness"]
119             )
120             os.nice(self.opts["maintenance_niceness"])
121         self.presence_events = False
122         if self.opts.get("presence_events", False):
123             tcp_only = True
124             for transport, _ in iter_transport_opts(self.opts):
125                 if transport != "tcp":
126                     tcp_only = False
127             if not tcp_only:
128                 self.presence_events = True
129     def run(self):
130         self._post_fork_init()
131         last = int(time.time())
132         last_git_pillar_update = 0
133         git_pillar_update_interval = self.opts.get("git_pillar_update_interval", 0)
134         old_present = set()
135         while True:
136             now = int(time.time())
137             if (now - last) &gt;= self.loop_interval:
138                 salt.daemons.masterapi.clean_old_jobs(self.opts)
139                 salt.daemons.masterapi.clean_expired_tokens(self.opts)
140                 salt.daemons.masterapi.clean_pub_auth(self.opts)
141             if (now - last_git_pillar_update) &gt;= git_pillar_update_interval:
142                 last_git_pillar_update = now
143                 self.handle_git_pillar()
144             self.handle_schedule()
145             self.handle_key_cache()
146             self.handle_presence(old_present)
147             self.handle_key_rotate(now)
148             salt.utils.verify.check_max_open_files(self.opts)
149             last = now
150             time.sleep(self.loop_interval)
151     def handle_key_cache(self):
152         if self.opts["key_cache"] == "sched":
153             keys = []
154             if self.opts["transport"] in TRANSPORTS:
155                 acc = "minions"
156             else:
157                 acc = "accepted"
158             for fn_ in os.listdir(os.path.join(self.opts["pki_dir"], acc)):
159                 if not fn_.startswith(".") and os.path.isfile(
160                     os.path.join(self.opts["pki_dir"], acc, fn_)
161                 ):
162 <a name="0"></a>                    keys.append(fn_)
163             log.debug("Writing master key cache")
164             with salt.utils<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.atomicfile.atomic_open(
165                 os.path.join(self.opts["pki_dir"], acc, ".key_cache"), mode="wb"
166             ) as cache_file:
167                 salt.payload.dump(</b></font>keys, cache_file)
168     def handle_key_rotate(self, now):
169         to_rotate = False
170         dfn = os.path.join(self.opts["cachedir"], ".dfn")
171         try:
172             stats = os.stat(dfn)
173             if salt.utils.platform.is_windows() and not os.access(dfn, os.W_OK):
174                 to_rotate = True
175                 os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)
176             elif stats.st_mode == 0o100400:
177                 to_rotate = True
178             else:
179                 log.error("Found dropfile with incorrect permissions, ignoring...")
180             os.remove(dfn)
181         except os.error:
182             pass
183         if self.opts.get("publish_session"):
184             if now - self.rotate &gt;= self.opts["publish_session"]:
185                 to_rotate = True
186         if to_rotate:
187             log.info("Rotating master AES key")
188             for secret_key, secret_map in SMaster.secrets.items():
189                 with secret_map["secret"].get_lock():
190                     secret_map["secret"].value = salt.utils.stringutils.to_bytes(
191                         secret_map["reload"]()
192                     )
193                 self.event.fire_event(
194                     {"rotate_{}_key".format(secret_key): True}, tag="key"
195                 )
196             self.rotate = now
197             if self.opts.get("ping_on_rotate"):
198                 log.debug("Pinging all connected minions due to key rotation")
199                 salt.utils.master.ping_all_connected_minions(self.opts)
200     def handle_git_pillar(self):
201         try:
202             for pillar in self.git_pillar:
203                 pillar.fetch_remotes()
204         except Exception as exc:  # pylint: disable=broad-except
205             log.error("Exception caught while updating git_pillar", exc_info=True)
206     def handle_schedule(self):
207         try:
208             self.schedule.eval()
209             if self.schedule.loop_interval &lt; self.loop_interval:
210                 self.loop_interval = self.schedule.loop_interval
211         except Exception as exc:  # pylint: disable=broad-except
212             log.error("Exception %s occurred in scheduled job", exc)
213         self.schedule.cleanup_subprocesses()
214     def handle_presence(self, old_present):
215         if self.presence_events and self.event.connect_pull(timeout=3):
216             present = self.ckminions.connected_ids()
217             new = present.difference(old_present)
218             lost = old_present.difference(present)
219             if new or lost:
220                 data = {"new": list(new), "lost": list(lost)}
221                 self.event.fire_event(data, tagify("change", "presence"))
222             data = {"present": list(present)}
223             self.event.fire_event(data, tagify("present", "presence"))
224             old_present.clear()
225             old_present.update(present)
226 class FileserverUpdate(salt.utils.process.SignalHandlingProcess):
227     def __init__(self, opts, **kwargs):
228         super().__init__(**kwargs)
229         self.opts = opts
230         self.update_threads = {}
231         import salt.fileserver
232         self.fileserver = salt.fileserver.Fileserver(self.opts)
233         self.fill_buckets()
234     def fill_buckets(self):
235         update_intervals = self.fileserver.update_intervals()
236         self.buckets = {}
237         for backend in self.fileserver.backends():
238             fstr = "{}.update".format(backend)
239             try:
240                 update_func = self.fileserver.servers[fstr]
241             except KeyError:
242                 log.debug("No update function for the %s filserver backend", backend)
243                 continue
244             if backend in update_intervals:
245                 for id_, interval in update_intervals[backend].items():
246                     if not interval:
247                         interval = DEFAULT_INTERVAL
248                         log.debug(
249                             "An update_interval of 0 is not supported, "
250                             "falling back to %s",
251                             interval,
252                         )
253                     i_ptr = self.buckets.setdefault(interval, OrderedDict())
254                     i_ptr.setdefault((backend, update_func), []).append(id_)
255             else:
256                 try:
257                     interval_key = "{}_update_interval".format(backend)
258                     interval = self.opts[interval_key]
259                 except KeyError:
260                     interval = DEFAULT_INTERVAL
261                     log.warning(
262                         "%s key missing from configuration. Falling back to "
263                         "default interval of %d seconds",
264                         interval_key,
265                         interval,
266                     )
267                 self.buckets.setdefault(interval, OrderedDict())[
268                     (backend, update_func)
269                 ] = None
270     @staticmethod
271     def _do_update(backends):
272         for backend, update_args in backends.items():
273             backend_name, update_func = backend
274             try:
275                 if update_args:
276                     log.debug(
277                         "Updating %s fileserver cache for the following targets: %s",
278                         backend_name,
279                         update_args,
280                     )
281                     args = (update_args,)
282                 else:
283                     log.debug("Updating %s fileserver cache", backend_name)
284                     args = ()
285                 update_func(*args)
286             except Exception as exc:  # pylint: disable=broad-except
287                 log.exception(
288                     "Uncaught exception while updating %s fileserver cache",
289                     backend_name,
290                 )
291     @classmethod
292     def update(cls, interval, backends, timeout=300):
293         start = time.time()
294         condition = threading.Condition()
295         while time.time() - start &lt; timeout:
296             log.debug(
297                 "Performing fileserver updates for items with an update interval of %d",
298                 interval,
299             )
300             cls._do_update(backends)
301             log.debug(
302                 "Completed fileserver updates for items with an update "
303                 "interval of %d, waiting %d seconds",
304                 interval,
305                 interval,
306             )
307             with condition:
308                 condition.wait(interval)
309     def run(self):
310         if (
311             self.opts["fileserver_update_niceness"]
312             and not salt.utils.platform.is_windows()
313         ):
314             log.info(
315                 "setting FileServerUpdate niceness to %d",
316                 self.opts["fileserver_update_niceness"],
317             )
318             os.nice(self.opts["fileserver_update_niceness"])
319         salt.daemons.masterapi.clean_fsbackend(self.opts)
320         for interval in self.buckets:
321             self.update_threads[interval] = threading.Thread(
322                 target=self.update,
323                 args=(interval, self.buckets[interval]),
324             )
325             self.update_threads[interval].start()
326         while self.update_threads:
327             for name, thread in list(self.update_threads.items()):
328                 thread.join(1)
329                 if not thread.is_alive():
330                     self.update_threads.pop(name)
331 class Master(SMaster):
332     def __init__(self, opts):
333         if zmq and ZMQ_VERSION_INFO &lt; (3, 2):
334             log.warning(
335                 "You have a version of ZMQ less than ZMQ 3.2! There are "
336                 "known connection keep-alive issues with ZMQ &lt; 3.2 which "
337                 "may result in loss of contact with minions. Please "
338                 "upgrade your ZMQ!"
339             )
340         SMaster.__init__(self, opts)
341     def __set_max_open_files(self):
342         if not HAS_RESOURCE:
343             return
344         mof_s, mof_h = resource.getrlimit(resource.RLIMIT_NOFILE)
345         if mof_h == resource.RLIM_INFINITY:
346             mof_h = mof_s
347         log.info(
348             "Current values for max open files soft/hard setting: %s/%s", mof_s, mof_h
349         )
350         mof_c = self.opts["max_open_files"]
351         if mof_c &gt; mof_h:
352             log.info(
353                 "The value for the 'max_open_files' setting, %s, is higher "
354                 "than the highest value the user running salt is allowed to "
355                 "set (%s). Defaulting to %s.",
356                 mof_c,
357                 mof_h,
358                 mof_h,
359             )
360             mof_c = mof_h
361         if mof_s &lt; mof_c:
362             log.info("Raising max open files value to %s", mof_c)
363             resource.setrlimit(resource.RLIMIT_NOFILE, (mof_c, mof_h))
364             try:
365                 mof_s, mof_h = resource.getrlimit(resource.RLIMIT_NOFILE)
366                 log.info(
367                     "New values for max open files soft/hard values: %s/%s",
368                     mof_s,
369                     mof_h,
370                 )
371             except ValueError:
372                 log.critical(
373                     "Failed to raise max open files setting to %s. If this "
374                     "value is too low, the salt-master will most likely fail "
375                     "to run properly.",
376                     mof_c,
377                 )
378     def _pre_flight(self):
379         errors = []
380         critical_errors = []
381         try:
382             os.chdir("/")
383         except OSError as err:
384             errors.append("Cannot change to root directory ({})".format(err))
385         if self.opts.get("fileserver_verify_config", True):
386             import salt.fileserver
387             fileserver = salt.fileserver.Fileserver(self.opts)
388             if not fileserver.servers:
389                 errors.append(
390                     "Failed to load fileserver backends, the configured backends "
391                     "are: {}".format(", ".join(self.opts["fileserver_backend"]))
392                 )
393             else:
394                 try:
395                     fileserver.init()
396                 except salt.exceptions.FileserverConfigError as exc:
397                     critical_errors.append("{}".format(exc))
398         if not self.opts["fileserver_backend"]:
399             errors.append("No fileserver backends are configured")
400         if self.opts["pillar_cache"] and not os.path.isdir(
401             os.path.join(self.opts["cachedir"], "pillar_cache")
402         ):
403             try:
404                 with salt.utils.files.set_umask(0o077):
405                     os.mkdir(os.path.join(self.opts["cachedir"], "pillar_cache"))
406             except OSError:
407                 pass
408         if self.opts.get("git_pillar_verify_config", True):
409             try:
410                 git_pillars = [
411                     x
412                     for x in self.opts.get("ext_pillar", [])
413                     if "git" in x and not isinstance(x["git"], str)
414                 ]
415             except TypeError:
416                 git_pillars = []
417                 critical_errors.append(
418                     "Invalid ext_pillar configuration. It is likely that the "
419                     "external pillar type was not specified for one or more "
420                     "external pillars."
421                 )
422             if git_pillars:
423                 try:
424                     new_opts = copy.deepcopy(self.opts)
425                     import salt.pillar.git_pillar
426                     for repo in git_pillars:
427                         new_opts["ext_pillar"] = [repo]
428                         try:
429                             git_pillar = salt.utils.gitfs.GitPillar(
430                                 new_opts,
431                                 repo["git"],
432                                 per_remote_overrides=salt.pillar.git_pillar.PER_REMOTE_OVERRIDES,
433                                 per_remote_only=salt.pillar.git_pillar.PER_REMOTE_ONLY,
434                                 global_only=salt.pillar.git_pillar.GLOBAL_ONLY,
435                             )
436                         except salt.exceptions.FileserverConfigError as exc:
437                             critical_errors.append(exc.strerror)
438                 finally:
439                     del new_opts
440         if errors or critical_errors:
441             for error in errors:
442                 log.error(error)
443             for error in critical_errors:
444                 log.critical(error)
445             log.critical("Master failed pre flight checks, exiting\n")
446             sys.exit(salt.defaults.exitcodes.EX_GENERIC)
447     def start(self):
448         self._pre_flight()
449         log.info("salt-master is starting as user '%s'", salt.utils.user.get_user())
450         enable_sigusr1_handler()
451         enable_sigusr2_handler()
452         self.__set_max_open_files()
453         with salt.utils.process.default_signals(signal.SIGINT, signal.SIGTERM):
454             SMaster.secrets["aes"] = {
455                 "secret": multiprocessing.Array(
456                     ctypes.c_char,
457                     salt.utils.stringutils.to_bytes(
458                         salt.crypt.Crypticle.generate_key_string()
459                     ),
460                 ),
461                 "reload": salt.crypt.Crypticle.generate_key_string,
462             }
463             log.info("Creating master process manager")
464             self.process_manager = salt.utils.process.ProcessManager(wait_for_kill=5)
465             pub_channels = []
466             log.info("Creating master publisher process")
467             for _, opts in iter_transport_opts(self.opts):
468                 chan = salt.channel.server.PubServerChannel.factory(opts)
469                 chan.pre_fork(self.process_manager)
470                 pub_channels.append(chan)
471             log.info("Creating master event publisher process")
472             self.process_manager.add_process(
473                 salt.utils.event.EventPublisher,
474                 args=(self.opts,),
475                 name="EventPublisher",
476             )
477             if self.opts.get("reactor"):
478                 if isinstance(self.opts["engines"], list):
479                     rine = False
480                     for item in self.opts["engines"]:
481                         if "reactor" in item:
482                             rine = True
483                             break
484                     if not rine:
485                         self.opts["engines"].append({"reactor": {}})
486                 else:
487                     if "reactor" not in self.opts["engines"]:
488                         log.info("Enabling the reactor engine")
489                         self.opts["engines"]["reactor"] = {}
490             salt.engines.start_engines(self.opts, self.process_manager)
491             log.info("Creating master maintenance process")
492             self.process_manager.add_process(
493                 Maintenance, args=(self.opts,), name="Maintenance"
494             )
495             if self.opts.get("event_return"):
496                 log.info("Creating master event return process")
497                 self.process_manager.add_process(
498                     salt.utils.event.EventReturn, args=(self.opts,), name="EventReturn"
499                 )
500             ext_procs = self.opts.get("ext_processes", [])
501             for proc in ext_procs:
502                 log.info("Creating ext_processes process: %s", proc)
503                 try:
504                     mod = ".".join(proc.split(".")[:-1])
505                     cls = proc.split(".")[-1]
506                     _tmp = __import__(mod, globals(), locals(), [cls], -1)
507                     cls = _tmp.__getattribute__(cls)
508                     name = "ExtProcess({})".format(cls.__qualname__)
509                     self.process_manager.add_process(cls, args=(self.opts,), name=name)
510                 except Exception:  # pylint: disable=broad-except
511                     log.error("Error creating ext_processes process: %s", proc)
512             if self.opts["con_cache"]:
513                 log.info("Creating master concache process")
514                 self.process_manager.add_process(
515                     salt.utils.master.ConnectedCache,
516                     args=(self.opts,),
517                     name="ConnectedCache",
518                 )
519                 log.debug("Sleeping for two seconds to let concache rest")
520                 time.sleep(2)
521             log.info("Creating master request server process")
522             kwargs = {}
523             if salt.utils.platform.spawning_platform():
524                 kwargs["secrets"] = SMaster.secrets
525             self.process_manager.add_process(
526                 ReqServer,
527                 args=(self.opts, self.key, self.master_key),
528                 kwargs=kwargs,
529                 name="ReqServer",
530             )
531             self.process_manager.add_process(
532                 FileserverUpdate, args=(self.opts,), name="FileServerUpdate"
533             )
534             if self.opts["discovery"]:
535                 if salt.utils.ssdp.SSDPDiscoveryServer.is_available():
536                     self.process_manager.add_process(
537                         salt.utils.ssdp.SSDPDiscoveryServer(
538                             port=self.opts["discovery"]["port"],
539                             listen_ip=self.opts["interface"],
540                             answer={
541                                 "mapping": self.opts["discovery"].get("mapping", {})
542                             },
543                         ).run,
544                         name="SSDPDiscoveryServer",
545                     )
546                 else:
547                     log.error("Unable to load SSDP: asynchronous IO is not available.")
548                     if sys.version_info.major == 2:
549                         log.error(
550                             'You are using Python 2, please install "trollius" module'
551                             " to enable SSDP discovery."
552                         )
553         if signal.getsignal(signal.SIGINT) is signal.SIG_DFL:
554             signal.signal(signal.SIGINT, self._handle_signals)
555         if signal.getsignal(signal.SIGTERM) is signal.SIG_DFL:
556             signal.signal(signal.SIGTERM, self._handle_signals)
557         self.process_manager.run()
558     def _handle_signals(self, signum, sigframe):
559         self.process_manager._handle_signals(signum, sigframe)
560         time.sleep(1)
561         sys.exit(0)
562 class ReqServer(salt.utils.process.SignalHandlingProcess):
563     def __init__(self, opts, key, mkey, secrets=None, **kwargs):
564         super().__init__(**kwargs)
565         self.opts = opts
566         self.master_key = mkey
567         self.key = key
568         self.secrets = secrets
569     def _handle_signals(self, signum, sigframe):  # pylint: disable=unused-argument
570         self.destroy(signum)
571         super()._handle_signals(signum, sigframe)
572     def __bind(self):
573         if self.secrets is not None:
574             SMaster.secrets = self.secrets
575         dfn = os.path.join(self.opts["cachedir"], ".dfn")
576         if os.path.isfile(dfn):
577             try:
578                 if salt.utils.platform.is_windows() and not os.access(dfn, os.W_OK):
579                     os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)
580                 os.remove(dfn)
581             except os.error:
582                 pass
583         self.process_manager = salt.utils.process.ProcessManager(
584             name="ReqServer_ProcessManager", wait_for_kill=1
585         )
586         req_channels = []
587         tcp_only = True
588         for transport, opts in iter_transport_opts(self.opts):
589             chan = salt.channel.server.ReqServerChannel.factory(opts)
590             chan.pre_fork(self.process_manager)
591             req_channels.append(chan)
592             if transport != "tcp":
593                 tcp_only = False
594         if self.opts["req_server_niceness"] and not salt.utils.platform.is_windows():
595             log.info(
596                 "setting ReqServer_ProcessManager niceness to %d",
597                 self.opts["req_server_niceness"],
598             )
599             os.nice(self.opts["req_server_niceness"])
600         with salt.utils.process.default_signals(signal.SIGINT, signal.SIGTERM):
601             for ind in range(int(self.opts["worker_threads"])):
602                 name = "MWorker-{}".format(ind)
603                 self.process_manager.add_process(
604                     MWorker,
605                     args=(self.opts, self.master_key, self.key, req_channels),
606                     name=name,
607                 )
608         self.process_manager.run()
609     def run(self):
610         self.__bind()
611     def destroy(self, signum=signal.SIGTERM):
612         if hasattr(self, "process_manager"):
613             self.process_manager.stop_restarting()
614             self.process_manager.send_signal_to_processes(signum)
615             self.process_manager.kill_children()
616     def __del__(self):
617         self.destroy()
618 class MWorker(salt.utils.process.SignalHandlingProcess):
619     def __init__(self, opts, mkey, key, req_channels, **kwargs):
620         super().__init__(**kwargs)
621         self.opts = opts
622         self.req_channels = req_channels
623         self.mkey = mkey
624         self.key = key
625         self.k_mtime = 0
626         self.stats = collections.defaultdict(lambda: {"mean": 0, "runs": 0})
627         self.stat_clock = time.time()
628     def __setstate__(self, state):
629         super().__setstate__(state)
630         self.k_mtime = state["k_mtime"]
631         SMaster.secrets = state["secrets"]
632     def __getstate__(self):
633         state = super().__getstate__()
634         state.update({"k_mtime": self.k_mtime, "secrets": SMaster.secrets})
635         return state
636     def _handle_signals(self, signum, sigframe):
637         for channel in getattr(self, "req_channels", ()):
638             channel.close()
639         self.clear_funcs.destroy()
640         super()._handle_signals(signum, sigframe)
641     def __bind(self):
642         self.io_loop = salt.ext.tornado.ioloop.IOLoop()
643         self.io_loop.make_current()
644         for req_channel in self.req_channels:
645             req_channel.post_fork(
646                 self._handle_payload, io_loop=self.io_loop
647             )  # TODO: cleaner? Maybe lazily?
648         try:
649             self.io_loop.start()
650         except (KeyboardInterrupt, SystemExit):
651             pass
652     @salt.ext.tornado.gen.coroutine
653     def _handle_payload(self, payload):
654         key = payload["enc"]
655         load = payload["load"]
656         ret = {"aes": self._handle_aes, "clear": self._handle_clear}[key](load)
657         raise salt.ext.tornado.gen.Return(ret)
658     def _post_stats(self, start, cmd):
659         end = time.time()
660         duration = end - start
661         self.stats[cmd]["mean"] = (
662             self.stats[cmd]["mean"] * (self.stats[cmd]["runs"] - 1) + duration
663         ) / self.stats[cmd]["runs"]
664         if end - self.stat_clock &gt; self.opts["master_stats_event_iter"]:
665             self.aes_funcs.event.fire_event(
666                 {
667                     "time": end - self.stat_clock,
668                     "worker": self.name,
669                     "stats": self.stats,
670                 },
671                 tagify(self.name, "stats"),
672             )
673             self.stats = collections.defaultdict(lambda: {"mean": 0, "runs": 0})
674             self.stat_clock = end
675     def _handle_clear(self, load):
676         log.trace("Clear payload received with command %s", load["cmd"])
677         cmd = load["cmd"]
678         method = self.clear_funcs.get_method(cmd)
679         if not method:
680             return {}, {"fun": "send_clear"}
681         if self.opts["master_stats"]:
682             start = time.time()
683             self.stats[cmd]["runs"] += 1
684         ret = method(load), {"fun": "send_clear"}
685         if self.opts["master_stats"]:
686             self._post_stats(start, cmd)
687         return ret
688     def _handle_aes(self, data):
689         if "cmd" not in data:
690             log.error("Received malformed command %s", data)
691             return {}
692         cmd = data["cmd"]
693         log.trace("AES payload received with command %s", data["cmd"])
694         method = self.aes_funcs.get_method(cmd)
695         if not method:
696             return {}, {"fun": "send"}
697         if self.opts["master_stats"]:
698             start = time.time()
699             self.stats[cmd]["runs"] += 1
700         def run_func(data):
701             return self.aes_funcs.run_func(data["cmd"], data)
702         with StackContext(
703             functools.partial(RequestContext, {"data": data, "opts": self.opts})
704         ):
705             ret = run_func(data)
706         if self.opts["master_stats"]:
707             self._post_stats(start, cmd)
708         return ret
709     def run(self):
710         if not salt.utils.platform.is_windows():
711             enforce_mworker_niceness = True
712             if self.opts["req_server_niceness"]:
713                 if salt.utils.user.get_user() == "root":
714                     log.info(
715                         "%s decrementing inherited ReqServer niceness to 0", self.name
716                     )
717                     log.info(os.nice())
718                     os.nice(-1 * self.opts["req_server_niceness"])
719                 else:
720                     log.error(
721                         "%s unable to decrement niceness for MWorker, not running as"
722                         " root",
723                         self.name,
724                     )
725                     enforce_mworker_niceness = False
726             if enforce_mworker_niceness and self.opts["mworker_niceness"]:
727                 log.info(
728                     "setting %s niceness to %i",
729                     self.name,
730                     self.opts["mworker_niceness"],
731                 )
732                 os.nice(self.opts["mworker_niceness"])
733         self.clear_funcs = ClearFuncs(
734             self.opts,
735             self.key,
736         )
737         self.clear_funcs.connect()
738         self.aes_funcs = AESFuncs(self.opts)
739         salt.utils.crypt.reinit_crypto()
740         self.__bind()
741 class TransportMethods:
742     expose_methods = ()
743     def get_method(self, name):
744         if name in self.expose_methods:
745             try:
746                 return getattr(self, name)
747             except AttributeError:
748                 log.error("Requested method not exposed: %s", name)
749         else:
750             log.error("Requested method not exposed: %s", name)
751 class AESFuncs(TransportMethods):
752     expose_methods = (
753         "verify_minion",
754         "_master_tops",
755         "_master_opts",
756         "_mine_get",
757         "_mine",
758         "_mine_delete",
759         "_mine_flush",
760         "_file_recv",
761         "_pillar",
762         "_minion_event",
763         "_handle_minion_event",
764         "_return",
765         "_syndic_return",
766         "minion_runner",
767         "pub_ret",
768         "minion_pub",
769         "minion_publish",
770         "revoke_auth",
771         "_serve_file",
772         "_file_find",
773         "_file_hash",
774         "_file_hash_and_stat",
775         "_file_list",
776         "_file_list_emptydirs",
777         "_dir_list",
778         "_symlink_list",
779         "_file_envs",
780         "_ext_nodes",  # To be removed in 3006 (Sulfur) #60980
781     )
782     def __init__(self, opts):
783         self.opts = opts
784         self.event = salt.utils.event.get_master_event(
785             self.opts, self.opts["sock_dir"], listen=False
786         )
787         self.ckminions = salt.utils.minions.CkMinions(opts)
788         self.local = salt.client.get_local_client(self.opts["conf_file"])
789         self.mminion = salt.minion.MasterMinion(
790             self.opts, states=False, rend=False, ignore_config_errors=True
791         )
792         self.__setup_fileserver()
793         self.masterapi = salt.daemons.masterapi.RemoteFuncs(opts)
794     def __setup_fileserver(self):
795         import salt.fileserver
796         self.fs_ = salt.fileserver.Fileserver(self.opts)
797         self._serve_file = self.fs_.serve_file
798         self._file_find = self.fs_._find_file
799         self._file_hash = self.fs_.file_hash
800         self._file_hash_and_stat = self.fs_.file_hash_and_stat
801         self._file_list = self.fs_.file_list
802         self._file_list_emptydirs = self.fs_.file_list_emptydirs
803         self._dir_list = self.fs_.dir_list
804         self._symlink_list = self.fs_.symlink_list
805         self._file_envs = self.fs_.file_envs
806     def __verify_minion(self, id_, token):
807         if not salt.utils.verify.valid_id(self.opts, id_):
808             return False
809         pub_path = os.path.join(self.opts["pki_dir"], "minions", id_)
810         try:
811             pub = salt.crypt.get_rsa_pub_key(pub_path)
812         except OSError:
813             log.warning(
814                 "Salt minion claiming to be %s attempted to communicate with "
815                 "master, but key could not be read and verification was denied.",
816                 id_,
817             )
818             return False
819         except (ValueError, IndexError, TypeError) as err:
820             log.error('Unable to load public key "%s": %s', pub_path, err)
821         try:
822             if salt.crypt.public_decrypt(pub, token) == b"salt":
823                 return True
824         except ValueError as err:
825             log.error("Unable to decrypt token: %s", err)
826         log.error(
827             "Salt minion claiming to be %s has attempted to communicate with "
828             "the master and could not be verified",
829             id_,
830         )
831         return False
832     def verify_minion(self, id_, token):
833         return self.__verify_minion(id_, token)
834     def __verify_minion_publish(self, clear_load):
835         if "peer" not in self.opts:
836             return False
837         if not isinstance(self.opts["peer"], dict):
838             return False
839         if any(
840             key not in clear_load for key in ("fun", "arg", "tgt", "ret", "tok", "id")
841         ):
842             return False
843         if clear_load["fun"].startswith("publish."):
844             return False
845         if not self.__verify_minion(clear_load["id"], clear_load["tok"]):
846             log.warning(
847                 "Minion id %s is not who it says it is and is attempting "
848                 "to issue a peer command",
849                 clear_load["id"],
850             )
851             return False
852         clear_load.pop("tok")
853         perms = []
854         for match in self.opts["peer"]:
855             if re.match(match, clear_load["id"]):
856                 if isinstance(self.opts["peer"][match], list):
857                     perms.extend(self.opts["peer"][match])
858         if "," in clear_load["fun"]:
859             clear_load["fun"] = clear_load["fun"].split(",")
860             arg_ = []
861             for arg in clear_load["arg"]:
862                 arg_.append(arg.split())
863             clear_load["arg"] = arg_
864         return self.ckminions.auth_check(
865             perms,
866             clear_load["fun"],
867             clear_load["arg"],
868             clear_load["tgt"],
869             clear_load.get("tgt_type", "glob"),
870             publish_validate=True,
871         )
872     def __verify_load(self, load, verify_keys):
873         if any(key not in load for key in verify_keys):
874             return False
875         if "tok" not in load:
876             log.error(
877                 "Received incomplete call from %s for '%s', missing '%s'",
878                 load["id"],
879                 inspect_stack()["co_name"],
880                 "tok",
881             )
882             return False
883         if not self.__verify_minion(load["id"], load["tok"]):
884             log.warning("Minion id %s is not who it says it is!", load["id"])
885             return False
886         if "tok" in load:
887             load.pop("tok")
888         return load
889     def _master_tops(self, load):
890         load = self.__verify_load(load, ("id", "tok"))
891         if load is False:
892             return {}
893         return self.masterapi._master_tops(load, skip_verify=True)
894     _ext_nodes = _master_tops
895     def _master_opts(self, load):
896         mopts = {}
897         file_roots = {}
898         envs = self._file_envs()
899         for saltenv in envs:
900             if saltenv not in file_roots:
901                 file_roots[saltenv] = []
902         mopts["file_roots"] = file_roots
903         mopts["top_file_merging_strategy"] = self.opts["top_file_merging_strategy"]
904         mopts["env_order"] = self.opts["env_order"]
905         mopts["default_top"] = self.opts["default_top"]
906         if load.get("env_only"):
907             return mopts
908         mopts["renderer"] = self.opts["renderer"]
909         mopts["failhard"] = self.opts["failhard"]
910         mopts["state_top"] = self.opts["state_top"]
911         mopts["state_top_saltenv"] = self.opts["state_top_saltenv"]
912         mopts["nodegroups"] = self.opts["nodegroups"]
913         mopts["state_auto_order"] = self.opts["state_auto_order"]
914         mopts["state_events"] = self.opts["state_events"]
915         mopts["state_aggregate"] = self.opts["state_aggregate"]
916         mopts["jinja_env"] = self.opts["jinja_env"]
917         mopts["jinja_sls_env"] = self.opts["jinja_sls_env"]
918         mopts["jinja_lstrip_blocks"] = self.opts["jinja_lstrip_blocks"]
919         mopts["jinja_trim_blocks"] = self.opts["jinja_trim_blocks"]
920         return mopts
921     def _mine_get(self, load):
922         load = self.__verify_load(load, ("id", "tgt", "fun", "tok"))
923         if load is False:
924             return {}
925         else:
926             return self.masterapi._mine_get(load, skip_verify=True)
927     def _mine(self, load):
928         load = self.__verify_load(load, ("id", "data", "tok"))
929         if load is False:
930             return {}
931         return self.masterapi._mine(load, skip_verify=True)
932     def _mine_delete(self, load):
933         load = self.__verify_load(load, ("id", "fun", "tok"))
934         if load is False:
935             return {}
936         else:
937             return self.masterapi._mine_delete(load)
938     def _mine_flush(self, load):
939         load = self.__verify_load(load, ("id", "tok"))
940         if load is False:
941             return {}
942         else:
943             return self.masterapi._mine_flush(load, skip_verify=True)
944     def _file_recv(self, load):
945         if any(key not in load for key in ("id", "path", "loc")):
946             return False
947         if not isinstance(load["path"], list):
948             return False
949         if not self.opts["file_recv"]:
950             return False
951         if not salt.utils.verify.valid_id(self.opts, load["id"]):
952             return False
953         file_recv_max_size = 1024 * 1024 * self.opts["file_recv_max_size"]
954         if "loc" in load and load["loc"] &lt; 0:
955             log.error("Invalid file pointer: load[loc] &lt; 0")
956             return False
957         if len(load["data"]) + load.get("loc", 0) &gt; file_recv_max_size:
958             log.error(
959                 "file_recv_max_size limit of %d MB exceeded! %s will be "
960                 "truncated. To successfully push this file, adjust "
961                 "file_recv_max_size to an integer (in MB) large enough to "
962                 "accommodate it.",
963                 file_recv_max_size,
964                 load["path"],
965             )
966             return False
967         if "tok" not in load:
968             log.error(
969                 "Received incomplete call from %s for '%s', missing '%s'",
970                 load["id"],
971                 inspect_stack()["co_name"],
972                 "tok",
973             )
974             return False
975         if not self.__verify_minion(load["id"], load["tok"]):
976             log.warning("Minion id %s is not who it says it is!", load["id"])
977             return {}
978         load.pop("tok")
979         sep_path = os.sep.join(load["path"])
980         normpath = os.path.normpath(sep_path)
981         if os.path.isabs(normpath) or "../" in load["path"]:
982             return False
983         cpath = os.path.join(
984             self.opts["cachedir"], "minions", load["id"], "files", normpath
985         )
986         if not os.path.normpath(cpath).startswith(self.opts["cachedir"]):
987             log.warning(
988                 "Attempt to write received file outside of master cache "
989                 "directory! Requested path: %s. Access denied.",
990                 cpath,
991             )
992             return False
993         cdir = os.path.dirname(cpath)
994         if not os.path.isdir(cdir):
995             try:
996                 os.makedirs(cdir)
997             except os.error:
998                 pass
999         if os.path.isfile(cpath) and load["loc"] != 0:
1000             mode = "ab"
1001         else:
1002             mode = "wb"
1003         with salt.utils.files.fopen(cpath, mode) as fp_:
1004             if load["loc"]:
1005                 fp_.seek(load["loc"])
1006             fp_.write(salt.utils.stringutils.to_bytes(load["data"]))
1007         return True
1008     def _pillar(self, load):
1009         if any(key not in load for key in ("id", "grains")):
1010             return False
1011         if not salt.utils.verify.valid_id(self.opts, load["id"]):
1012             return False
1013         load["grains"]["id"] = load["id"]
1014         pillar = salt.pillar.get_pillar(
1015             self.opts,
1016             load["grains"],
1017             load["id"],
1018             load.get("saltenv", load.get("env")),
1019             ext=load.get("ext"),
1020             pillar_override=load.get("pillar_override", {}),
1021             pillarenv=load.get("pillarenv"),
1022             extra_minion_data=load.get("extra_minion_data"),
1023             clean_cache=load.get("clean_cache"),
1024         )
1025         data = pillar.compile_pillar()
1026         self.fs_.update_opts()
1027         if self.opts.get("minion_data_cache", False):
1028             self.masterapi.cache.store(
1029                 "minions/{}".format(load["id"]),
1030                 "data",
1031                 {"grains": load["grains"], "pillar": data},
1032             )
1033             if self.opts.get("minion_data_cache_events") is True:
1034                 self.event.fire_event(
1035                     {"Minion data cache refresh": load["id"]},
1036                     tagify(load["id"], "refresh", "minion"),
1037                 )
1038         return data
1039     def _minion_event(self, load):
1040         load = self.__verify_load(load, ("id", "tok"))
1041         if load is False:
1042             return {}
1043         self.masterapi._minion_event(load)
1044         self._handle_minion_event(load)
1045     def _handle_minion_event(self, load):
1046         id_ = load["id"]
1047         if load.get("tag", "") == "_salt_error":
1048             log.error(
1049                 "Received minion error from [%s]: %s", id_, load["data"]["message"]
1050             )
1051         for event in load.get("events", []):
1052             event_data = event.get("data", {})
1053             if "minions" in event_data:
1054                 jid = event_data.get("jid")
1055                 if not jid:
1056                     continue
1057                 minions = event_data["minions"]
1058                 try:
1059                     salt.utils.job.store_minions(
1060                         self.opts, jid, minions, mminion=self.mminion, syndic_id=id_
1061                     )
1062                 except (KeyError, salt.exceptions.SaltCacheError) as exc:
1063                     log.error(
1064                         "Could not add minion(s) %s for job %s: %s", minions, jid, exc
1065                     )
1066     def _return(self, load):
1067         if self.opts["require_minion_sign_messages"] and "sig" not in load:
1068             log.critical(
1069                 "_return: Master is requiring minions to sign their "
1070                 "messages, but there is no signature in this payload from "
1071                 "%s.",
1072                 load["id"],
1073             )
1074             return False
1075         if "sig" in load:
1076             log.trace("Verifying signed event publish from minion")
1077             sig = load.pop("sig")
1078             this_minion_pubkey = os.path.join(
1079                 self.opts["pki_dir"], "minions/{}".format(load["id"])
1080             )
1081             serialized_load = salt.serializers.msgpack.serialize(load)
1082             if not salt.crypt.verify_signature(
1083                 this_minion_pubkey, serialized_load, sig
1084             ):
1085                 log.info("Failed to verify event signature from minion %s.", load["id"])
1086                 if self.opts["drop_messages_signature_fail"]:
1087                     log.critical(
1088                         "drop_messages_signature_fail is enabled, dropping "
1089                         "message from %s",
1090                         load["id"],
1091                     )
1092                     return False
1093                 else:
1094                     log.info(
1095                         "But 'drop_message_signature_fail' is disabled, so message is"
1096                         " still accepted."
1097                     )
1098             load["sig"] = sig
1099         try:
1100             salt.utils.job.store_job(
1101                 self.opts, load, event=self.event, mminion=self.mminion
1102             )
1103         except salt.exceptions.SaltCacheError:
1104             log.error("Could not store job information for load: %s", load)
1105     def _syndic_return(self, load):
1106         loads = load.get("load")
1107         if not isinstance(loads, list):
1108             loads = [load]  # support old syndics not aggregating returns
1109         for load in loads:
1110             if any(key not in load for key in ("return", "jid", "id")):
1111                 continue
1112             if load.get("load"):
1113                 fstr = "{}.save_load".format(self.opts["master_job_cache"])
1114                 self.mminion.returners[fstr](load["jid"], load["load"])
1115             syndic_cache_path = os.path.join(
1116                 self.opts["cachedir"], "syndics", load["id"]
1117             )
1118             if not os.path.exists(syndic_cache_path):
1119                 path_name = os.path.split(syndic_cache_path)[0]
1120                 if not os.path.exists(path_name):
1121                     os.makedirs(path_name)
1122                 with salt.utils.files.fopen(syndic_cache_path, "w") as wfh:
1123                     wfh.write("")
1124             for key, item in load["return"].items():
1125                 ret = {"jid": load["jid"], "id": key}
1126                 ret.update(item)
1127                 if "master_id" in load:
1128                     ret["master_id"] = load["master_id"]
1129                 if "fun" in load:
1130                     ret["fun"] = load["fun"]
1131                 if "arg" in load:
1132                     ret["fun_args"] = load["arg"]
1133                 if "out" in load:
1134                     ret["out"] = load["out"]
1135                 if "sig" in load:
1136                     ret["sig"] = load["sig"]
1137                 self._return(ret)
1138     def minion_runner(self, clear_load):
1139         load = self.__verify_load(clear_load, ("fun", "arg", "id", "tok"))
1140         if load is False:
1141             return {}
1142         else:
1143             return self.masterapi.minion_runner(clear_load)
1144     def pub_ret(self, load):
1145         load = self.__verify_load(load, ("jid", "id", "tok"))
1146         if load is False:
1147             return {}
1148         auth_cache = os.path.join(self.opts["cachedir"], "publish_auth")
1149         if not os.path.isdir(auth_cache):
1150             os.makedirs(auth_cache)
1151         jid_fn = os.path.join(auth_cache, str(load["jid"]))
1152         with salt.utils.files.fopen(jid_fn, "r") as fp_:
1153             if not load["id"] == fp_.read():
1154                 return {}
1155         return self.local.get_cache_returns(load["jid"])
1156     def minion_pub(self, clear_load):
1157         if not self.__verify_minion_publish(clear_load):
1158             return {}
1159         else:
1160             return self.masterapi.minion_pub(clear_load)
1161     def minion_publish(self, clear_load):
1162         if not self.__verify_minion_publish(clear_load):
1163             return {}
1164         else:
1165             return self.masterapi.minion_publish(clear_load)
1166     def revoke_auth(self, load):
1167         load = self.__verify_load(load, ("id", "tok"))
1168         if not self.opts.get("allow_minion_key_revoke", False):
1169             log.warning(
1170                 "Minion %s requested key revoke, but allow_minion_key_revoke "
1171                 "is set to False",
1172                 load["id"],
1173             )
1174             return load
1175         if load is False:
1176             return load
1177         else:
1178             return self.masterapi.revoke_auth(load)
1179     def run_func(self, func, load):
1180         if func.startswith("__"):
1181             return {}, {"fun": "send"}
1182         if hasattr(self, func):
1183             try:
1184                 start = time.time()
1185                 ret = getattr(self, func)(load)
1186                 log.trace(
1187                     "Master function call %s took %s seconds", func, time.time() - start
1188                 )
1189             except Exception:  # pylint: disable=broad-except
1190                 ret = ""
1191                 log.error("Error in function %s:\n", func, exc_info=True)
1192         else:
1193             log.error(
1194                 "Received function %s which is unavailable on the master, "
1195                 "returning False",
1196                 func,
1197             )
1198             return False, {"fun": "send"}
1199         if func == "_return":
1200             return ret, {"fun": "send"}
1201         if func == "_pillar" and "id" in load:
1202             if load.get("ver") != "2" and self.opts["pillar_version"] == 1:
1203                 return ret, {"fun": "send"}
1204             return ret, {"fun": "send_private", "key": "pillar", "tgt": load["id"]}
1205         return ret, {"fun": "send"}
1206     def destroy(self):
1207         self.masterapi.destroy()
1208         if self.local is not None:
1209             self.local.destroy()
1210             self.local = None
1211 class ClearFuncs(TransportMethods):
1212     expose_methods = (
1213         "ping",
1214         "publish",
1215         "get_token",
1216         "mk_token",
1217         "wheel",
1218         "runner",
1219     )
1220     def __init__(self, opts, key):
1221         self.opts = opts
1222         self.key = key
1223         self.event = salt.utils.event.get_master_event(
1224             self.opts, self.opts["sock_dir"], listen=False
1225         )
1226         self.local = salt.client.get_local_client(self.opts["conf_file"])
1227         self.ckminions = salt.utils.minions.CkMinions(opts)
1228         self.loadauth = salt.auth.LoadAuth(opts)
1229         self.mminion = salt.minion.MasterMinion(
1230             self.opts, states=False, rend=False, ignore_config_errors=True
1231         )
1232         self.wheel_ = salt.wheel.Wheel(opts)
1233         self.masterapi = salt.daemons.masterapi.LocalFuncs(opts, key)
1234         self.channels = []
1235     def runner(self, clear_load):
1236         auth_type, err_name, key, sensitive_load_keys = self._prep_auth_info(clear_load)
1237         auth_check = self.loadauth.check_authentication(clear_load, auth_type, key=key)
1238         error = auth_check.get("error")
1239         if error:
1240             return {"error": error}
1241         username = auth_check.get("username")
1242         if auth_type != "user":
1243             runner_check = self.ckminions.runner_check(
1244                 auth_check.get("auth_list", []),
1245                 clear_load["fun"],
1246                 clear_load.get("kwarg", {}),
1247             )
1248             if not runner_check:
1249                 return {
1250                     "error": {
1251                         "name": err_name,
1252                         "message": (
1253                             'Authentication failure of type "{}" occurred for '
1254                             "user {}.".format(auth_type, username)
1255                         ),
1256                     }
1257                 }
1258             elif isinstance(runner_check, dict) and "error" in runner_check:
1259                 return runner_check
1260             for item in sensitive_load_keys:
1261                 clear_load.pop(item, None)
1262         else:
1263             if "user" in clear_load:
1264                 username = clear_load["user"]
1265                 if salt.auth.AuthUser(username).is_sudo():
1266                     username = self.opts.get("user", "root")
1267             else:
1268                 username = salt.utils.user.get_user()
1269         try:
1270             fun = clear_load.pop("fun")
1271             runner_client = salt.runner.RunnerClient(self.opts)
1272             return runner_client.asynchronous(
1273                 fun, clear_load.get("kwarg", {}), username, local=True
1274             )
1275         except Exception as exc:  # pylint: disable=broad-except
1276             log.error("Exception occurred while introspecting %s: %s", fun, exc)
1277             return {
1278                 "error": {
1279                     "name": exc.__class__.__name__,
1280                     "args": exc.args,
1281                     "message": str(exc),
1282                 }
1283             }
1284     def wheel(self, clear_load):
1285         auth_type, err_name, key, sensitive_load_keys = self._prep_auth_info(clear_load)
1286         auth_check = self.loadauth.check_authentication(clear_load, auth_type, key=key)
1287         error = auth_check.get("error")
1288         if error:
1289             return {"error": error}
1290         username = auth_check.get("username")
1291         if auth_type != "user":
1292             wheel_check = self.ckminions.wheel_check(
1293                 auth_check.get("auth_list", []),
1294                 clear_load["fun"],
1295                 clear_load.get("kwarg", {}),
1296             )
1297             if not wheel_check:
1298                 return {
1299                     "error": {
1300                         "name": err_name,
1301                         "message": (
1302                             'Authentication failure of type "{}" occurred for '
1303                             "user {}.".format(auth_type, username)
1304                         ),
1305                     }
1306                 }
1307             elif isinstance(wheel_check, dict) and "error" in wheel_check:
1308                 return wheel_check
1309             for item in sensitive_load_keys:
1310                 clear_load.pop(item, None)
1311         else:
1312             if "user" in clear_load:
1313                 username = clear_load["user"]
1314                 if salt.auth.AuthUser(username).is_sudo():
1315                     username = self.opts.get("user", "root")
1316             else:
1317                 username = salt.utils.user.get_user()
1318         try:
1319             jid = salt.utils.jid.gen_jid(self.opts)
1320             fun = clear_load.pop("fun")
1321             tag = tagify(jid, prefix="wheel")
1322             data = {
1323                 "fun": "wheel.{}".format(fun),
1324                 "jid": jid,
1325                 "tag": tag,
1326                 "user": username,
1327             }
1328             self.event.fire_event(data, tagify([jid, "new"], "wheel"))
1329             ret = self.wheel_.call_func(fun, full_return=True, **clear_load)
1330             data["return"] = ret["return"]
1331             data["success"] = ret["success"]
1332             self.event.fire_event(data, tagify([jid, "ret"], "wheel"))
1333             return {"tag": tag, "data": data}
1334         except Exception as exc:  # pylint: disable=broad-except
1335             log.error("Exception occurred while introspecting %s: %s", fun, exc)
1336             data["return"] = "Exception occurred in wheel {}: {}: {}".format(
1337                 fun,
1338                 exc.__class__.__name__,
1339                 exc,
1340             )
1341             data["success"] = False
1342             self.event.fire_event(data, tagify([jid, "ret"], "wheel"))
1343             return {"tag": tag, "data": data}
1344     def mk_token(self, clear_load):
1345         token = self.loadauth.mk_token(clear_load)
1346         if not token:
1347             log.warning('Authentication failure of type "eauth" occurred.')
1348             return ""
1349         return token
1350     def get_token(self, clear_load):
1351         if "token" not in clear_load:
1352             return False
1353         return self.loadauth.get_tok(clear_load["token"])
1354     def publish(self, clear_load):
1355         extra = clear_load.get("kwargs", {})
1356         publisher_acl = salt.acl.PublisherACL(self.opts["publisher_acl_blacklist"])
1357         if publisher_acl.user_is_blacklisted(
1358             clear_load["user"]
1359         ) or publisher_acl.cmd_is_blacklisted(clear_load["fun"]):
1360             log.error(
1361                 "%s does not have permissions to run %s. Please contact "
1362                 "your local administrator if you believe this is in "
1363                 "error.\n",
1364                 clear_load["user"],
1365                 clear_load["fun"],
1366             )
1367             return {
1368                 "error": {
1369                     "name": "AuthorizationError",
1370                     "message": "Authorization error occurred.",
1371                 }
1372             }
1373         delimiter = clear_load.get("kwargs", {}).get("delimiter", DEFAULT_TARGET_DELIM)
1374         _res = self.ckminions.check_minions(
1375             clear_load["tgt"], clear_load.get("tgt_type", "glob"), delimiter
1376         )
1377         minions = _res.get("minions", list())
1378         missing = _res.get("missing", list())
1379         ssh_minions = _res.get("ssh_minions", False)
1380         auth_type, err_name, key, sensitive_load_keys = self._prep_auth_info(extra)
1381         if auth_type == "user":
1382             auth_check = self.loadauth.check_authentication(
1383                 clear_load, auth_type, key=key
1384             )
1385         else:
1386             auth_check = self.loadauth.check_authentication(extra, auth_type)
1387         auth_list = auth_check.get("auth_list", [])
1388         err_msg = 'Authentication failure of type "{}" occurred.'.format(auth_type)
1389         if auth_check.get("error"):
1390             log.warning(err_msg)
1391             return {
1392                 "error": {
1393                     "name": "AuthenticationError",
1394                     "message": "Authentication error occurred.",
1395                 }
1396             }
1397         if auth_type != "user" or (auth_type == "user" and auth_list):
1398             authorized = self.ckminions.auth_check(
1399                 auth_list,
1400                 clear_load["fun"],
1401                 clear_load["arg"],
1402                 clear_load["tgt"],
1403                 clear_load.get("tgt_type", "glob"),
1404                 minions=minions,
1405                 whitelist=["saltutil.find_job"],
1406             )
1407             if not authorized:
1408                 if (
1409                     auth_type == "eauth"
1410                     and not auth_list
1411                     and "username" in extra
1412                     and "eauth" in extra
1413                 ):
1414                     log.debug(
1415                         'Auth configuration for eauth "%s" and user "%s" is empty',
1416                         extra["eauth"],
1417                         extra["username"],
1418                     )
1419                 log.warning(err_msg)
1420                 return {
1421                     "error": {
1422                         "name": "AuthorizationError",
1423                         "message": "Authorization error occurred.",
1424                     }
1425                 }
1426             if auth_type == "token":
1427                 username = auth_check.get("username")
1428                 clear_load["user"] = username
1429                 log.debug('Minion tokenized user = "%s"', username)
1430             elif auth_type == "eauth":
1431                 clear_load["user"] = self.loadauth.load_name(extra)
1432         if not self.opts.get("order_masters"):
1433             if not minions:
1434                 return {
1435                     "enc": "clear",
1436                     "load": {
1437                         "jid": None,
1438                         "minions": minions,
1439                         "error": (
1440                             "Master could not resolve minions for target {}".format(
1441                                 clear_load["tgt"]
1442                             )
1443                         ),
1444                     },
1445                 }
1446         jid = self._prep_jid(clear_load, extra)
1447         if jid is None:
1448             return {"enc": "clear", "load": {"error": "Master failed to assign jid"}}
1449         payload = self._prep_pub(minions, jid, clear_load, extra, missing)
1450         self._send_ssh_pub(payload, ssh_minions=ssh_minions)
1451         self._send_pub(payload)
1452         return {
1453             "enc": "clear",
1454             "load": {"jid": clear_load["jid"], "minions": minions, "missing": missing},
1455         }
1456     def _prep_auth_info(self, clear_load):
1457         sensitive_load_keys = []
1458         key = None
1459         if "token" in clear_load:
1460             auth_type = "token"
1461             err_name = "TokenAuthenticationError"
1462             sensitive_load_keys = ["token"]
1463         elif "eauth" in clear_load:
1464             auth_type = "eauth"
1465             err_name = "EauthAuthenticationError"
1466             sensitive_load_keys = ["username", "password"]
1467         else:
1468             auth_type = "user"
1469             err_name = "UserAuthenticationError"
1470             key = self.key
1471         return auth_type, err_name, key, sensitive_load_keys
1472     def _prep_jid(self, clear_load, extra):
1473         passed_jid = clear_load["jid"] if clear_load.get("jid") else None
1474         nocache = extra.get("nocache", False)
1475         fstr = "{}.prep_jid".format(self.opts["master_job_cache"])
1476         try:
1477             jid = self.mminion.returners[fstr](nocache=nocache, passed_jid=passed_jid)
1478         except (KeyError, TypeError):
1479             msg = (
1480                 "Failed to allocate a jid. The requested returner '{}' "
1481                 "could not be loaded.".format(fstr.split(".")[0])
1482             )
1483             log.error(msg)
1484             return {"error": msg}
1485         return jid
1486     def _send_pub(self, load):
1487         if not self.channels:
1488             for transport, opts in iter_transport_opts(self.opts):
1489                 chan = salt.channel.server.PubServerChannel.factory(opts)
1490                 self.channels.append(chan)
1491         for chan in self.channels:
1492             chan.publish(load)
1493     @property
1494     def ssh_client(self):
1495         if not hasattr(self, "_ssh_client"):
1496             self._ssh_client = salt.client.ssh.client.SSHClient(mopts=self.opts)
1497         return self._ssh_client
1498     def _send_ssh_pub(self, load, ssh_minions=False):
1499         if self.opts["enable_ssh_minions"] is True and ssh_minions is True:
1500             log.debug("Send payload to ssh minions")
1501             threading.Thread(target=self.ssh_client.cmd, kwargs=load).start()
1502     def _prep_pub(self, minions, jid, clear_load, extra, missing):
1503         clear_load["jid"] = jid
1504         delimiter = clear_load.get("kwargs", {}).get("delimiter", DEFAULT_TARGET_DELIM)
1505         self.event.fire_event({"minions": minions}, clear_load["jid"])
1506         new_job_load = {
1507             "jid": clear_load["jid"],
1508             "tgt_type": clear_load["tgt_type"],
1509             "tgt": clear_load["tgt"],
1510             "user": clear_load["user"],
1511             "fun": clear_load["fun"],
1512             "arg": clear_load["arg"],
1513             "minions": minions,
1514             "missing": missing,
1515         }
1516         self.event.fire_event(new_job_load, tagify([clear_load["jid"], "new"], "job"))
1517         if self.opts["ext_job_cache"]:
1518             fstr = "{}.save_load".format(self.opts["ext_job_cache"])
1519             save_load_func = True
1520             try:
1521                 arg_spec = salt.utils.args.get_function_argspec(
1522                     self.mminion.returners[fstr]
1523                 )
1524                 if "minions" not in arg_spec.args:
1525                     log.critical(
1526                         "The specified returner used for the external job cache "
1527                         "'%s' does not have a 'minions' kwarg in the returner's "
1528                         "save_load function.",
1529                         self.opts["ext_job_cache"],
1530                     )
1531             except (AttributeError, KeyError):
1532                 save_load_func = False
1533                 log.critical(
1534                     "The specified returner used for the external job cache "
1535                     '"%s" does not have a save_load function!',
1536                     self.opts["ext_job_cache"],
1537                 )
1538             if save_load_func:
1539                 try:
1540                     self.mminion.returners[fstr](
1541                         clear_load["jid"], clear_load, minions=minions
1542                     )
1543                 except Exception:  # pylint: disable=broad-except
1544                     log.critical(
1545                         "The specified returner threw a stack trace:\n", exc_info=True
1546                     )
1547         try:
1548             fstr = "{}.save_load".format(self.opts["master_job_cache"])
1549             self.mminion.returners[fstr](clear_load["jid"], clear_load, minions)
1550         except KeyError:
1551             log.critical(
1552                 "The specified returner used for the master job cache "
1553                 '"%s" does not have a save_load function!',
1554                 self.opts["master_job_cache"],
1555             )
1556         except Exception:  # pylint: disable=broad-except
1557             log.critical("The specified returner threw a stack trace:\n", exc_info=True)
1558         payload = {"enc": "aes"}
1559         load = {
1560             "fun": clear_load["fun"],
1561             "arg": clear_load["arg"],
1562             "tgt": clear_load["tgt"],
1563             "jid": clear_load["jid"],
1564             "ret": clear_load["ret"],
1565         }
1566         if "master_id" in self.opts:
1567             load["master_id"] = self.opts["master_id"]
1568         if "master_id" in extra:
1569             load["master_id"] = extra["master_id"]
1570         if delimiter != DEFAULT_TARGET_DELIM:
1571             load["delimiter"] = delimiter
1572         if "id" in extra:
1573             load["id"] = extra["id"]
1574         if "tgt_type" in clear_load:
1575             load["tgt_type"] = clear_load["tgt_type"]
1576         if "to" in clear_load:
1577             load["to"] = clear_load["to"]
1578         if "kwargs" in clear_load:
1579             if "ret_config" in clear_load["kwargs"]:
1580                 load["ret_config"] = clear_load["kwargs"].get("ret_config")
1581             if "metadata" in clear_load["kwargs"]:
1582                 load["metadata"] = clear_load["kwargs"].get("metadata")
1583             if "module_executors" in clear_load["kwargs"]:
1584                 load["module_executors"] = clear_load["kwargs"].get("module_executors")
1585             if "executor_opts" in clear_load["kwargs"]:
1586                 load["executor_opts"] = clear_load["kwargs"].get("executor_opts")
1587             if "ret_kwargs" in clear_load["kwargs"]:
1588                 load["ret_kwargs"] = clear_load["kwargs"].get("ret_kwargs")
1589         if "user" in clear_load:
1590             log.info(
1591                 "User %s Published command %s with jid %s",
1592                 clear_load["user"],
1593                 clear_load["fun"],
1594                 clear_load["jid"],
1595             )
1596             load["user"] = clear_load["user"]
1597         else:
1598             log.info(
1599                 "Published command %s with jid %s", clear_load["fun"], clear_load["jid"]
1600             )
1601         log.debug("Published command details %s", load)
1602         return load
1603     def ping(self, clear_load):
1604         return clear_load
1605     def destroy(self):
1606         if self.masterapi is not None:
1607             self.masterapi.destroy()
1608             self.masterapi = None
1609         if self.local is not None:
1610             self.local.destroy()
1611             self.local = None
1612         while self.channels:
1613             chan = self.channels.pop()
1614             chan.close()
1615     def connect(self):
1616         if self.channels:
1617             return
1618         for transport, opts in iter_transport_opts(self.opts):
1619             chan = salt.channel.server.PubServerChannel.factory(opts)
1620             self.channels.append(chan)
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_output.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import os
2 import traceback
3 import pytest
4 import salt.config
5 import salt.utils.yaml
6 from salt.output import display_output
7 from saltfactories.utils.tempfiles import temp_file
8 from tests.support.case import ShellCase
9 from tests.support.mixins import RUNTIME_VARS
10 class OutputReturnTest(ShellCase):
11     @pytest.mark.slow_test
12     def test_output_json(self):
13         ret = self.run_call("test.ping --out=json")
14         self.assertIn("{", ret)
15         self.assertIn('"local": true', "".join(ret))
16         self.assertIn("}", "".join(ret))
17     @pytest.mark.slow_test
18     def test_output_nested(self):
19         expected = ["local:", "    True"]
20         ret = self.run_call("test.ping --out=nested")
21         self.assertEqual(ret, expected)
22     @pytest.mark.slow_test
23     def test_output_quiet(self):
24         expected = []
25         ret = self.run_call("test.ping --out=quiet")
26         self.assertEqual(ret, expected)
27     @pytest.mark.slow_test
28     def test_output_pprint(self):
29         expected = ["{'local': True}"]
30         ret = self.run_call("test.ping --out=pprint")
31         self.assertEqual(ret, expected)
32     @pytest.mark.slow_test
33     def test_output_raw(self):
34         expected = ["{'local': True}"]
35         ret = self.run_call("test.ping --out=raw")
36         self.assertEqual(ret, expected)
37     @pytest.mark.slow_test
38     def test_output_txt(self):
39         expected = ["local: True"]
40         ret = self.run_call("test.ping --out=txt")
41         self.assertEqual(ret, expected)
42     @pytest.mark.slow_test
43     def test_output_yaml(self):
44         expected = ["local: true"]
45         ret = self.run_call("test.ping --out=yaml")
46         self.assertEqual(ret, expected)
47     @pytest.mark.slow_test
48     def test_output_yaml_namespaced_dict_wrapper(self):
49         dumped_yaml = "\n".join(self.run_call("grains.items --out=yaml"))
50         loaded_yaml = salt.utils.yaml.safe_load(dumped_yaml)
51         assert isinstance(loaded_yaml, dict)
52         assert list(loaded_yaml) == ["local"]
53     def test_output_unicodebad(self):
54 <a name="0"></a>        """
55         Tests outputter reliability with utf8
56         opts = salt<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.config.minion_config(
57             os.path.join(RUNTIME_VARS.TMP_CONF_DIR, "minion")
58         )
59         opts["output_file"] = os.path.join(</b></font>RUNTIME_VARS.TMP, "outputtest")
60         data = {"foo": {"result": False, "aaa": "azerzaeréééé", "comment": "ééééàààà"}}
61         try:
62             display_output(data, opts=opts)
63         except Exception:  # pylint: disable=broad-except
64             trace = traceback.format_exc()
65             sentinel = object()
66             old_max_diff = getattr(self, "maxDiff", sentinel)
67             try:
68                 self.maxDiff = None
69                 self.assertEqual(trace, "")
70             finally:
71                 if old_max_diff is sentinel:
72                     delattr(self, "maxDiff")
73                 else:
74                     self.maxDiff = old_max_diff
75     @pytest.mark.slow_test
76     def test_output_highstate(self):
77         simple_ping_sls = """
78         simple-ping:
79           module.run:
80             - name: test.ping
81         Tests outputter when passing --out=highstate with a non-state call. This should
82         fall back to "nested" output.
83         Tests passing the --static option with a basic test.ping command. This
84         should be the "nested" output.
85         """
86         expected = ["minion:", "    True"]
87         ret = self.run_salt('"minion" test.ping --static')
88         self.assertEqual(ret, expected)
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
