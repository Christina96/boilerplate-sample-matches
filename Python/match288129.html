<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for master.py &amp; test_output.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for master.py &amp; test_output.py
      </h3>
<h1 align="center">
        0.6%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>master.py (0.33888733%)<th>test_output.py (5.714286%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(249-252)<td><a href="#" name="0">(107-110)</a><td align="center"><font color="#ff0000">12</font>
</td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>master.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import collections
2 import copy
3 import ctypes
4 import functools
5 import logging
6 import multiprocessing
7 import os
8 import re
9 import signal
10 import stat
11 import sys
12 import threading
13 import time
14 import salt.acl
15 import salt.auth
16 import salt.channel.server
17 import salt.client
18 import salt.client.ssh.client
19 import salt.crypt
20 import salt.daemons.masterapi
21 import salt.defaults.exitcodes
22 import salt.engines
23 import salt.exceptions
24 import salt.ext.tornado.gen
25 import salt.key
26 import salt.minion
27 import salt.payload
28 import salt.pillar
29 import salt.runner
30 import salt.serializers.msgpack
31 import salt.state
32 import salt.utils.args
33 import salt.utils.atomicfile
34 import salt.utils.crypt
35 import salt.utils.event
36 import salt.utils.files
37 import salt.utils.gitfs
38 import salt.utils.gzip_util
39 import salt.utils.jid
40 import salt.utils.job
41 import salt.utils.master
42 import salt.utils.minions
43 import salt.utils.platform
44 import salt.utils.process
45 import salt.utils.schedule
46 import salt.utils.ssdp
47 import salt.utils.stringutils
48 import salt.utils.user
49 import salt.utils.verify
50 import salt.utils.zeromq
51 import salt.wheel
52 from salt.config import DEFAULT_INTERVAL
53 from salt.defaults import DEFAULT_TARGET_DELIM
54 from salt.ext.tornado.stack_context import StackContext
55 from salt.transport import TRANSPORTS
56 from salt.utils.channel import iter_transport_opts
57 from salt.utils.ctx import RequestContext
58 from salt.utils.debug import (
59     enable_sigusr1_handler,
60     enable_sigusr2_handler,
61     inspect_stack,
62 )
63 from salt.utils.event import tagify
64 from salt.utils.odict import OrderedDict
65 from salt.utils.zeromq import ZMQ_VERSION_INFO, zmq
66 try:
67     import resource
68     HAS_RESOURCE = True
69 except ImportError:
70     HAS_RESOURCE = False
71 log = logging.getLogger(__name__)
72 class SMaster:
73     secrets = (
74         {}
75     )  # mapping of key -&gt; {'secret': multiprocessing type, 'reload': FUNCTION}
76     def __init__(self, opts):
77         self.opts = opts
78         self.master_key = salt.crypt.MasterKeys(self.opts)
79         self.key = self.__prep_key()
80     def __setstate__(self, state):
81         super().__setstate__(state)
82         self.master_key = state["master_key"]
83         self.key = state["key"]
84         SMaster.secrets = state["secrets"]
85     def __getstate__(self):
86         state = super().__getstate__()
87         state.update(
88             {
89                 "key": self.key,
90                 "master_key": self.master_key,
91                 "secrets": SMaster.secrets,
92             }
93         )
94         return state
95     def __prep_key(self):
96         return salt.daemons.masterapi.access_keys(self.opts)
97 class Maintenance(salt.utils.process.SignalHandlingProcess):
98     def __init__(self, opts, **kwargs):
99         super().__init__(**kwargs)
100         self.opts = opts
101         self.loop_interval = int(self.opts["loop_interval"])
102         self.rotate = int(time.time())
103     def _post_fork_init(self):
104         ropts = dict(self.opts)
105         ropts["quiet"] = True
106         runner_client = salt.runner.RunnerClient(ropts)
107         self.returners = salt.loader.returners(self.opts, {})
108         self.schedule = salt.utils.schedule.Schedule(
109             self.opts, runner_client.functions_dict(), returners=self.returners
110         )
111         self.ckminions = salt.utils.minions.CkMinions(self.opts)
112         self.event = salt.utils.event.get_master_event(
113             self.opts, self.opts["sock_dir"], listen=False
114         )
115         self.git_pillar = salt.daemons.masterapi.init_git_pillar(self.opts)
116         if self.opts["maintenance_niceness"] and not salt.utils.platform.is_windows():
117             log.info(
118                 "setting Maintenance niceness to %d", self.opts["maintenance_niceness"]
119             )
120             os.nice(self.opts["maintenance_niceness"])
121         self.presence_events = False
122         if self.opts.get("presence_events", False):
123             tcp_only = True
124             for transport, _ in iter_transport_opts(self.opts):
125                 if transport != "tcp":
126                     tcp_only = False
127             if not tcp_only:
128                 self.presence_events = True
129     def run(self):
130         self._post_fork_init()
131         last = int(time.time())
132         last_git_pillar_update = 0
133         git_pillar_update_interval = self.opts.get("git_pillar_update_interval", 0)
134         old_present = set()
135         while True:
136             now = int(time.time())
137             if (now - last) &gt;= self.loop_interval:
138                 salt.daemons.masterapi.clean_old_jobs(self.opts)
139                 salt.daemons.masterapi.clean_expired_tokens(self.opts)
140                 salt.daemons.masterapi.clean_pub_auth(self.opts)
141             if (now - last_git_pillar_update) &gt;= git_pillar_update_interval:
142                 last_git_pillar_update = now
143                 self.handle_git_pillar()
144             self.handle_schedule()
145             self.handle_key_cache()
146             self.handle_presence(old_present)
147             self.handle_key_rotate(now)
148             salt.utils.verify.check_max_open_files(self.opts)
149             last = now
150             time.sleep(self.loop_interval)
151     def handle_key_cache(self):
152         if self.opts["key_cache"] == "sched":
153             keys = []
154             if self.opts["transport"] in TRANSPORTS:
155                 acc = "minions"
156             else:
157                 acc = "accepted"
158             for fn_ in os.listdir(os.path.join(self.opts["pki_dir"], acc)):
159                 if not fn_.startswith(".") and os.path.isfile(
160                     os.path.join(self.opts["pki_dir"], acc, fn_)
161                 ):
162             log.debug("Writing master key cache")
163             with salt.utils<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.atomicfile.atomic_open(
164                 os.path.join(self.opts["pki_dir"], acc, ".key_cache"), mode="wb"
165             ) as cache_file:
166                 salt.payload.dump(</b></font>keys, cache_file)
167     def handle_key_rotate(self, now):
168         to_rotate = False
169         dfn = os.path.join(self.opts["cachedir"], ".dfn")
170         try:
171             stats = os.stat(dfn)
172             if salt.utils.platform.is_windows() and not os.access(dfn, os.W_OK):
173                 to_rotate = True
174                 os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)
175             elif stats.st_mode == 0o100400:
176                 to_rotate = True
177             else:
178                 log.error("Found dropfile with incorrect permissions, ignoring...")
179             os.remove(dfn)
180         except os.error:
181             pass
182         if self.opts.get("publish_session"):
183             if now - self.rotate &gt;= self.opts["publish_session"]:
184                 to_rotate = True
185         if to_rotate:
186             log.info("Rotating master AES key")
187             for secret_key, secret_map in SMaster.secrets.items():
188                 with secret_map["secret"].get_lock():
189                     secret_map["secret"].value = salt.utils.stringutils.to_bytes(
190                         secret_map["reload"]()
191                     )
192                 self.event.fire_event(
193                     {"rotate_{}_key".format(secret_key): True}, tag="key"
194                 )
195             self.rotate = now
196             if self.opts.get("ping_on_rotate"):
197                 log.debug("Pinging all connected minions due to key rotation")
198                 salt.utils.master.ping_all_connected_minions(self.opts)
199     def handle_git_pillar(self):
200         try:
201             for pillar in self.git_pillar:
202                 pillar.fetch_remotes()
203         except Exception as exc:  # pylint: disable=broad-except
204             log.error("Exception caught while updating git_pillar", exc_info=True)
205     def handle_schedule(self):
206         try:
207             self.schedule.eval()
208             if self.schedule.loop_interval &lt; self.loop_interval:
209                 self.loop_interval = self.schedule.loop_interval
210         except Exception as exc:  # pylint: disable=broad-except
211             log.error("Exception %s occurred in scheduled job", exc)
212         self.schedule.cleanup_subprocesses()
213     def handle_presence(self, old_present):
214         if self.presence_events and self.event.connect_pull(timeout=3):
215             present = self.ckminions.connected_ids()
216             new = present.difference(old_present)
217             lost = old_present.difference(present)
218             if new or lost:
219                 data = {"new": list(new), "lost": list(lost)}
220                 self.event.fire_event(data, tagify("change", "presence"))
221             data = {"present": list(present)}
222             self.event.fire_event(data, tagify("present", "presence"))
223             old_present.clear()
224             old_present.update(present)
225 class FileserverUpdate(salt.utils.process.SignalHandlingProcess):
226     def __init__(self, opts, **kwargs):
227         super().__init__(**kwargs)
228         self.opts = opts
229         self.update_threads = {}
230         import salt.fileserver
231         self.fileserver = salt.fileserver.Fileserver(self.opts)
232         self.fill_buckets()
233     def fill_buckets(self):
234         update_intervals = self.fileserver.update_intervals()
235         self.buckets = {}
236         for backend in self.fileserver.backends():
237             fstr = "{}.update".format(backend)
238             try:
239                 update_func = self.fileserver.servers[fstr]
240             except KeyError:
241                 log.debug("No update function for the %s filserver backend", backend)
242                 continue
243             if backend in update_intervals:
244                 for id_, interval in update_intervals[backend].items():
245                     if not interval:
246                         interval = DEFAULT_INTERVAL
247                         log.debug(
248                             "An update_interval of 0 is not supported, "
249                             "falling back to %s",
250                             interval,
251                         )
252                     i_ptr = self.buckets.setdefault(interval, OrderedDict())
253                     i_ptr.setdefault((backend, update_func), []).append(id_)
254             else:
255                 try:
256                     interval_key = "{}_update_interval".format(backend)
257                     interval = self.opts[interval_key]
258                 except KeyError:
259                     interval = DEFAULT_INTERVAL
260                     log.warning(
261                         "%s key missing from configuration. Falling back to "
262                         "default interval of %d seconds",
263                         interval_key,
264                         interval,
265                     )
266                 self.buckets.setdefault(interval, OrderedDict())[
267                     (backend, update_func)
268                 ] = None
269     @staticmethod
270     def _do_update(backends):
271         for backend, update_args in backends.items():
272             backend_name, update_func = backend
273             try:
274                 if update_args:
275                     log.debug(
276                         "Updating %s fileserver cache for the following targets: %s",
277                         backend_name,
278                         update_args,
279                     )
280                     args = (update_args,)
281                 else:
282                     log.debug("Updating %s fileserver cache", backend_name)
283                     args = ()
284                 update_func(*args)
285             except Exception as exc:  # pylint: disable=broad-except
286                 log.exception(
287                     "Uncaught exception while updating %s fileserver cache",
288                     backend_name,
289                 )
290     @classmethod
291     def update(cls, interval, backends, timeout=300):
292         start = time.time()
293         condition = threading.Condition()
294         while time.time() - start &lt; timeout:
295             log.debug(
296                 "Performing fileserver updates for items with an update interval of %d",
297                 interval,
298             )
299             cls._do_update(backends)
300             log.debug(
301                 "Completed fileserver updates for items with an update "
302                 "interval of %d, waiting %d seconds",
303                 interval,
304                 interval,
305             )
306             with condition:
307                 condition.wait(interval)
308     def run(self):
309         if (
310             self.opts["fileserver_update_niceness"]
311             and not salt.utils.platform.is_windows()
312         ):
313             log.info(
314                 "setting FileServerUpdate niceness to %d",
315                 self.opts["fileserver_update_niceness"],
316             )
317             os.nice(self.opts["fileserver_update_niceness"])
318         salt.daemons.masterapi.clean_fsbackend(self.opts)
319         for interval in self.buckets:
320             self.update_threads[interval] = threading.Thread(
321                 target=self.update,
322                 args=(interval, self.buckets[interval]),
323             )
324             self.update_threads[interval].start()
325         while self.update_threads:
326             for name, thread in list(self.update_threads.items()):
327                 thread.join(1)
328                 if not thread.is_alive():
329                     self.update_threads.pop(name)
330 class Master(SMaster):
331     def __init__(self, opts):
332         if zmq and ZMQ_VERSION_INFO &lt; (3, 2):
333             log.warning(
334                 "You have a version of ZMQ less than ZMQ 3.2! There are "
335                 "known connection keep-alive issues with ZMQ &lt; 3.2 which "
336                 "may result in loss of contact with minions. Please "
337                 "upgrade your ZMQ!"
338             )
339         SMaster.__init__(self, opts)
340     def __set_max_open_files(self):
341         if not HAS_RESOURCE:
342             return
343         mof_s, mof_h = resource.getrlimit(resource.RLIMIT_NOFILE)
344         if mof_h == resource.RLIM_INFINITY:
345             mof_h = mof_s
346         log.info(
347             "Current values for max open files soft/hard setting: %s/%s", mof_s, mof_h
348         )
349         mof_c = self.opts["max_open_files"]
350         if mof_c &gt; mof_h:
351             log.info(
352                 "The value for the 'max_open_files' setting, %s, is higher "
353                 "than the highest value the user running salt is allowed to "
354                 "set (%s). Defaulting to %s.",
355                 mof_c,
356                 mof_h,
357                 mof_h,
358             )
359             mof_c = mof_h
360         if mof_s &lt; mof_c:
361             log.info("Raising max open files value to %s", mof_c)
362             resource.setrlimit(resource.RLIMIT_NOFILE, (mof_c, mof_h))
363             try:
364                 mof_s, mof_h = resource.getrlimit(resource.RLIMIT_NOFILE)
365                 log.info(
366                     "New values for max open files soft/hard values: %s/%s",
367                     mof_s,
368                     mof_h,
369                 )
370             except ValueError:
371                 log.critical(
372                     "Failed to raise max open files setting to %s. If this "
373                     "value is too low, the salt-master will most likely fail "
374                     "to run properly.",
375                     mof_c,
376                 )
377     def _pre_flight(self):
378         errors = []
379         critical_errors = []
380         try:
381             os.chdir("/")
382         except OSError as err:
383             errors.append("Cannot change to root directory ({})".format(err))
384         if self.opts.get("fileserver_verify_config", True):
385             import salt.fileserver
386             fileserver = salt.fileserver.Fileserver(self.opts)
387             if not fileserver.servers:
388                 errors.append(
389                     "Failed to load fileserver backends, the configured backends "
390                     "are: {}".format(", ".join(self.opts["fileserver_backend"]))
391                 )
392             else:
393                 try:
394                     fileserver.init()
395                 except salt.exceptions.FileserverConfigError as exc:
396                     critical_errors.append("{}".format(exc))
397         if not self.opts["fileserver_backend"]:
398             errors.append("No fileserver backends are configured")
399         if self.opts["pillar_cache"] and not os.path.isdir(
400             os.path.join(self.opts["cachedir"], "pillar_cache")
401         ):
402             try:
403                 with salt.utils.files.set_umask(0o077):
404                     os.mkdir(os.path.join(self.opts["cachedir"], "pillar_cache"))
405             except OSError:
406                 pass
407         if self.opts.get("git_pillar_verify_config", True):
408             try:
409                 git_pillars = [
410                     x
411                     for x in self.opts.get("ext_pillar", [])
412                     if "git" in x and not isinstance(x["git"], str)
413                 ]
414             except TypeError:
415                 git_pillars = []
416                 critical_errors.append(
417                     "Invalid ext_pillar configuration. It is likely that the "
418                     "external pillar type was not specified for one or more "
419                     "external pillars."
420                 )
421             if git_pillars:
422                 try:
423                     new_opts = copy.deepcopy(self.opts)
424                     import salt.pillar.git_pillar
425                     for repo in git_pillars:
426                         new_opts["ext_pillar"] = [repo]
427                         try:
428                             git_pillar = salt.utils.gitfs.GitPillar(
429                                 new_opts,
430                                 repo["git"],
431                                 per_remote_overrides=salt.pillar.git_pillar.PER_REMOTE_OVERRIDES,
432                                 per_remote_only=salt.pillar.git_pillar.PER_REMOTE_ONLY,
433                                 global_only=salt.pillar.git_pillar.GLOBAL_ONLY,
434                             )
435                         except salt.exceptions.FileserverConfigError as exc:
436                             critical_errors.append(exc.strerror)
437                 finally:
438                     del new_opts
439         if errors or critical_errors:
440             for error in errors:
441                 log.error(error)
442             for error in critical_errors:
443                 log.critical(error)
444             log.critical("Master failed pre flight checks, exiting\n")
445             sys.exit(salt.defaults.exitcodes.EX_GENERIC)
446     def start(self):
447         self._pre_flight()
448         log.info("salt-master is starting as user '%s'", salt.utils.user.get_user())
449         enable_sigusr1_handler()
450         enable_sigusr2_handler()
451         self.__set_max_open_files()
452         with salt.utils.process.default_signals(signal.SIGINT, signal.SIGTERM):
453             SMaster.secrets["aes"] = {
454                 "secret": multiprocessing.Array(
455                     ctypes.c_char,
456                     salt.utils.stringutils.to_bytes(
457                         salt.crypt.Crypticle.generate_key_string()
458                     ),
459                 ),
460                 "reload": salt.crypt.Crypticle.generate_key_string,
461             }
462             log.info("Creating master process manager")
463             self.process_manager = salt.utils.process.ProcessManager(wait_for_kill=5)
464             pub_channels = []
465             log.info("Creating master publisher process")
466             for _, opts in iter_transport_opts(self.opts):
467                 chan = salt.channel.server.PubServerChannel.factory(opts)
468                 chan.pre_fork(self.process_manager)
469                 pub_channels.append(chan)
470             log.info("Creating master event publisher process")
471             self.process_manager.add_process(
472                 salt.utils.event.EventPublisher,
473                 args=(self.opts,),
474                 name="EventPublisher",
475             )
476             if self.opts.get("reactor"):
477                 if isinstance(self.opts["engines"], list):
478                     rine = False
479                     for item in self.opts["engines"]:
480                         if "reactor" in item:
481                             rine = True
482                             break
483                     if not rine:
484                         self.opts["engines"].append({"reactor": {}})
485                 else:
486                     if "reactor" not in self.opts["engines"]:
487                         log.info("Enabling the reactor engine")
488                         self.opts["engines"]["reactor"] = {}
489             salt.engines.start_engines(self.opts, self.process_manager)
490             log.info("Creating master maintenance process")
491             self.process_manager.add_process(
492                 Maintenance, args=(self.opts,), name="Maintenance"
493             )
494             if self.opts.get("event_return"):
495                 log.info("Creating master event return process")
496                 self.process_manager.add_process(
497                     salt.utils.event.EventReturn, args=(self.opts,), name="EventReturn"
498                 )
499             ext_procs = self.opts.get("ext_processes", [])
500             for proc in ext_procs:
501                 log.info("Creating ext_processes process: %s", proc)
502                 try:
503                     mod = ".".join(proc.split(".")[:-1])
504                     cls = proc.split(".")[-1]
505                     _tmp = __import__(mod, globals(), locals(), [cls], -1)
506                     cls = _tmp.__getattribute__(cls)
507                     name = "ExtProcess({})".format(cls.__qualname__)
508                     self.process_manager.add_process(cls, args=(self.opts,), name=name)
509                 except Exception:  # pylint: disable=broad-except
510                     log.error("Error creating ext_processes process: %s", proc)
511             if self.opts["con_cache"]:
512                 log.info("Creating master concache process")
513                 self.process_manager.add_process(
514                     salt.utils.master.ConnectedCache,
515                     args=(self.opts,),
516                     name="ConnectedCache",
517                 )
518                 log.debug("Sleeping for two seconds to let concache rest")
519                 time.sleep(2)
520             log.info("Creating master request server process")
521             kwargs = {}
522             if salt.utils.platform.spawning_platform():
523                 kwargs["secrets"] = SMaster.secrets
524             self.process_manager.add_process(
525                 ReqServer,
526                 args=(self.opts, self.key, self.master_key),
527                 kwargs=kwargs,
528                 name="ReqServer",
529             )
530             self.process_manager.add_process(
531                 FileserverUpdate, args=(self.opts,), name="FileServerUpdate"
532             )
533             if self.opts["discovery"]:
534                 if salt.utils.ssdp.SSDPDiscoveryServer.is_available():
535                     self.process_manager.add_process(
536                         salt.utils.ssdp.SSDPDiscoveryServer(
537                             port=self.opts["discovery"]["port"],
538                             listen_ip=self.opts["interface"],
539                             answer={
540                                 "mapping": self.opts["discovery"].get("mapping", {})
541                             },
542                         ).run,
543                         name="SSDPDiscoveryServer",
544                     )
545                 else:
546                     log.error("Unable to load SSDP: asynchronous IO is not available.")
547                     if sys.version_info.major == 2:
548                         log.error(
549                             'You are using Python 2, please install "trollius" module'
550                             " to enable SSDP discovery."
551                         )
552         if signal.getsignal(signal.SIGINT) is signal.SIG_DFL:
553             signal.signal(signal.SIGINT, self._handle_signals)
554         if signal.getsignal(signal.SIGTERM) is signal.SIG_DFL:
555             signal.signal(signal.SIGTERM, self._handle_signals)
556         self.process_manager.run()
557     def _handle_signals(self, signum, sigframe):
558         self.process_manager._handle_signals(signum, sigframe)
559         time.sleep(1)
560         sys.exit(0)
561 class ReqServer(salt.utils.process.SignalHandlingProcess):
562     def __init__(self, opts, key, mkey, secrets=None, **kwargs):
563         super().__init__(**kwargs)
564         self.opts = opts
565         self.master_key = mkey
566         self.key = key
567         self.secrets = secrets
568     def _handle_signals(self, signum, sigframe):  # pylint: disable=unused-argument
569         self.destroy(signum)
570         super()._handle_signals(signum, sigframe)
571     def __bind(self):
572         if self.secrets is not None:
573             SMaster.secrets = self.secrets
574         dfn = os.path.join(self.opts["cachedir"], ".dfn")
575         if os.path.isfile(dfn):
576             try:
577                 if salt.utils.platform.is_windows() and not os.access(dfn, os.W_OK):
578                     os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)
579                 os.remove(dfn)
580             except os.error:
581                 pass
582         self.process_manager = salt.utils.process.ProcessManager(
583             name="ReqServer_ProcessManager", wait_for_kill=1
584         )
585         req_channels = []
586         tcp_only = True
587         for transport, opts in iter_transport_opts(self.opts):
588             chan = salt.channel.server.ReqServerChannel.factory(opts)
589             chan.pre_fork(self.process_manager)
590             req_channels.append(chan)
591             if transport != "tcp":
592                 tcp_only = False
593         if self.opts["req_server_niceness"] and not salt.utils.platform.is_windows():
594             log.info(
595                 "setting ReqServer_ProcessManager niceness to %d",
596                 self.opts["req_server_niceness"],
597             )
598             os.nice(self.opts["req_server_niceness"])
599         with salt.utils.process.default_signals(signal.SIGINT, signal.SIGTERM):
600             for ind in range(int(self.opts["worker_threads"])):
601                 name = "MWorker-{}".format(ind)
602                 self.process_manager.add_process(
603                     MWorker,
604                     args=(self.opts, self.master_key, self.key, req_channels),
605                     name=name,
606                 )
607         self.process_manager.run()
608     def run(self):
609         self.__bind()
610     def destroy(self, signum=signal.SIGTERM):
611         if hasattr(self, "process_manager"):
612             self.process_manager.stop_restarting()
613             self.process_manager.send_signal_to_processes(signum)
614             self.process_manager.kill_children()
615     def __del__(self):
616         self.destroy()
617 class MWorker(salt.utils.process.SignalHandlingProcess):
618     def __init__(self, opts, mkey, key, req_channels, **kwargs):
619         super().__init__(**kwargs)
620         self.opts = opts
621         self.req_channels = req_channels
622         self.mkey = mkey
623         self.key = key
624         self.k_mtime = 0
625         self.stats = collections.defaultdict(lambda: {"mean": 0, "runs": 0})
626         self.stat_clock = time.time()
627     def __setstate__(self, state):
628         super().__setstate__(state)
629         self.k_mtime = state["k_mtime"]
630         SMaster.secrets = state["secrets"]
631     def __getstate__(self):
632         state = super().__getstate__()
633         state.update({"k_mtime": self.k_mtime, "secrets": SMaster.secrets})
634         return state
635     def _handle_signals(self, signum, sigframe):
636         for channel in getattr(self, "req_channels", ()):
637             channel.close()
638         self.clear_funcs.destroy()
639         super()._handle_signals(signum, sigframe)
640     def __bind(self):
641         self.io_loop = salt.ext.tornado.ioloop.IOLoop()
642         self.io_loop.make_current()
643         for req_channel in self.req_channels:
644             req_channel.post_fork(
645                 self._handle_payload, io_loop=self.io_loop
646             )  # TODO: cleaner? Maybe lazily?
647         try:
648             self.io_loop.start()
649         except (KeyboardInterrupt, SystemExit):
650             pass
651     @salt.ext.tornado.gen.coroutine
652     def _handle_payload(self, payload):
653         key = payload["enc"]
654         load = payload["load"]
655         ret = {"aes": self._handle_aes, "clear": self._handle_clear}[key](load)
656         raise salt.ext.tornado.gen.Return(ret)
657     def _post_stats(self, start, cmd):
658         end = time.time()
659         duration = end - start
660         self.stats[cmd]["mean"] = (
661             self.stats[cmd]["mean"] * (self.stats[cmd]["runs"] - 1) + duration
662         ) / self.stats[cmd]["runs"]
663         if end - self.stat_clock &gt; self.opts["master_stats_event_iter"]:
664             self.aes_funcs.event.fire_event(
665                 {
666                     "time": end - self.stat_clock,
667                     "worker": self.name,
668                     "stats": self.stats,
669                 },
670                 tagify(self.name, "stats"),
671             )
672             self.stats = collections.defaultdict(lambda: {"mean": 0, "runs": 0})
673             self.stat_clock = end
674     def _handle_clear(self, load):
675         log.trace("Clear payload received with command %s", load["cmd"])
676         cmd = load["cmd"]
677         method = self.clear_funcs.get_method(cmd)
678         if not method:
679             return {}, {"fun": "send_clear"}
680         if self.opts["master_stats"]:
681             start = time.time()
682             self.stats[cmd]["runs"] += 1
683         ret = method(load), {"fun": "send_clear"}
684         if self.opts["master_stats"]:
685             self._post_stats(start, cmd)
686         return ret
687     def _handle_aes(self, data):
688         if "cmd" not in data:
689             log.error("Received malformed command %s", data)
690             return {}
691         cmd = data["cmd"]
692         log.trace("AES payload received with command %s", data["cmd"])
693         method = self.aes_funcs.get_method(cmd)
694         if not method:
695             return {}, {"fun": "send"}
696         if self.opts["master_stats"]:
697             start = time.time()
698             self.stats[cmd]["runs"] += 1
699         def run_func(data):
700             return self.aes_funcs.run_func(data["cmd"], data)
701         with StackContext(
702             functools.partial(RequestContext, {"data": data, "opts": self.opts})
703         ):
704             ret = run_func(data)
705         if self.opts["master_stats"]:
706             self._post_stats(start, cmd)
707         return ret
708     def run(self):
709         if not salt.utils.platform.is_windows():
710             enforce_mworker_niceness = True
711             if self.opts["req_server_niceness"]:
712                 if salt.utils.user.get_user() == "root":
713                     log.info(
714                         "%s decrementing inherited ReqServer niceness to 0", self.name
715                     )
716                     log.info(os.nice())
717                     os.nice(-1 * self.opts["req_server_niceness"])
718                 else:
719                     log.error(
720                         "%s unable to decrement niceness for MWorker, not running as"
721                         " root",
722                         self.name,
723                     )
724                     enforce_mworker_niceness = False
725             if enforce_mworker_niceness and self.opts["mworker_niceness"]:
726                 log.info(
727                     "setting %s niceness to %i",
728                     self.name,
729                     self.opts["mworker_niceness"],
730                 )
731                 os.nice(self.opts["mworker_niceness"])
732         self.clear_funcs = ClearFuncs(
733             self.opts,
734             self.key,
735         )
736         self.clear_funcs.connect()
737         self.aes_funcs = AESFuncs(self.opts)
738         salt.utils.crypt.reinit_crypto()
739         self.__bind()
740 class TransportMethods:
741     expose_methods = ()
742     def get_method(self, name):
743         if name in self.expose_methods:
744             try:
745                 return getattr(self, name)
746             except AttributeError:
747                 log.error("Requested method not exposed: %s", name)
748         else:
749             log.error("Requested method not exposed: %s", name)
750 class AESFuncs(TransportMethods):
751     expose_methods = (
752         "verify_minion",
753         "_master_tops",
754         "_master_opts",
755         "_mine_get",
756         "_mine",
757         "_mine_delete",
758         "_mine_flush",
759         "_file_recv",
760         "_pillar",
761         "_minion_event",
762         "_handle_minion_event",
763         "_return",
764         "_syndic_return",
765         "minion_runner",
766         "pub_ret",
767         "minion_pub",
768         "minion_publish",
769         "revoke_auth",
770         "_serve_file",
771         "_file_find",
772         "_file_hash",
773         "_file_hash_and_stat",
774         "_file_list",
775         "_file_list_emptydirs",
776         "_dir_list",
777         "_symlink_list",
778         "_file_envs",
779         "_ext_nodes",  # To be removed in 3006 (Sulfur) #60980
780     )
781     def __init__(self, opts):
782         self.opts = opts
783         self.event = salt.utils.event.get_master_event(
784             self.opts, self.opts["sock_dir"], listen=False
785         )
786         self.ckminions = salt.utils.minions.CkMinions(opts)
787         self.local = salt.client.get_local_client(self.opts["conf_file"])
788         self.mminion = salt.minion.MasterMinion(
789             self.opts, states=False, rend=False, ignore_config_errors=True
790         )
791         self.__setup_fileserver()
792         self.masterapi = salt.daemons.masterapi.RemoteFuncs(opts)
793     def __setup_fileserver(self):
794         import salt.fileserver
795         self.fs_ = salt.fileserver.Fileserver(self.opts)
796         self._serve_file = self.fs_.serve_file
797         self._file_find = self.fs_._find_file
798         self._file_hash = self.fs_.file_hash
799         self._file_hash_and_stat = self.fs_.file_hash_and_stat
800         self._file_list = self.fs_.file_list
801         self._file_list_emptydirs = self.fs_.file_list_emptydirs
802         self._dir_list = self.fs_.dir_list
803         self._symlink_list = self.fs_.symlink_list
804         self._file_envs = self.fs_.file_envs
805     def __verify_minion(self, id_, token):
806         if not salt.utils.verify.valid_id(self.opts, id_):
807             return False
808         pub_path = os.path.join(self.opts["pki_dir"], "minions", id_)
809         try:
810             pub = salt.crypt.get_rsa_pub_key(pub_path)
811         except OSError:
812             log.warning(
813                 "Salt minion claiming to be %s attempted to communicate with "
814                 "master, but key could not be read and verification was denied.",
815                 id_,
816             )
817             return False
818         except (ValueError, IndexError, TypeError) as err:
819             log.error('Unable to load public key "%s": %s', pub_path, err)
820         try:
821             if salt.crypt.public_decrypt(pub, token) == b"salt":
822                 return True
823         except ValueError as err:
824             log.error("Unable to decrypt token: %s", err)
825         log.error(
826             "Salt minion claiming to be %s has attempted to communicate with "
827             "the master and could not be verified",
828             id_,
829         )
830         return False
831     def verify_minion(self, id_, token):
832         return self.__verify_minion(id_, token)
833     def __verify_minion_publish(self, clear_load):
834         if "peer" not in self.opts:
835             return False
836         if not isinstance(self.opts["peer"], dict):
837             return False
838         if any(
839             key not in clear_load for key in ("fun", "arg", "tgt", "ret", "tok", "id")
840         ):
841             return False
842         if clear_load["fun"].startswith("publish."):
843             return False
844         if not self.__verify_minion(clear_load["id"], clear_load["tok"]):
845             log.warning(
846                 "Minion id %s is not who it says it is and is attempting "
847                 "to issue a peer command",
848                 clear_load["id"],
849             )
850             return False
851         clear_load.pop("tok")
852         perms = []
853         for match in self.opts["peer"]:
854             if re.match(match, clear_load["id"]):
855                 if isinstance(self.opts["peer"][match], list):
856                     perms.extend(self.opts["peer"][match])
857         if "," in clear_load["fun"]:
858             clear_load["fun"] = clear_load["fun"].split(",")
859             arg_ = []
860             for arg in clear_load["arg"]:
861                 arg_.append(arg.split())
862             clear_load["arg"] = arg_
863         return self.ckminions.auth_check(
864             perms,
865             clear_load["fun"],
866             clear_load["arg"],
867             clear_load["tgt"],
868             clear_load.get("tgt_type", "glob"),
869             publish_validate=True,
870         )
871     def __verify_load(self, load, verify_keys):
872         if any(key not in load for key in verify_keys):
873             return False
874         if "tok" not in load:
875             log.error(
876                 "Received incomplete call from %s for '%s', missing '%s'",
877                 load["id"],
878                 inspect_stack()["co_name"],
879                 "tok",
880             )
881             return False
882         if not self.__verify_minion(load["id"], load["tok"]):
883             log.warning("Minion id %s is not who it says it is!", load["id"])
884             return False
885         if "tok" in load:
886             load.pop("tok")
887         return load
888     def _master_tops(self, load):
889         load = self.__verify_load(load, ("id", "tok"))
890         if load is False:
891             return {}
892         return self.masterapi._master_tops(load, skip_verify=True)
893     _ext_nodes = _master_tops
894     def _master_opts(self, load):
895         mopts = {}
896         file_roots = {}
897         envs = self._file_envs()
898         for saltenv in envs:
899             if saltenv not in file_roots:
900                 file_roots[saltenv] = []
901         mopts["file_roots"] = file_roots
902         mopts["top_file_merging_strategy"] = self.opts["top_file_merging_strategy"]
903         mopts["env_order"] = self.opts["env_order"]
904         mopts["default_top"] = self.opts["default_top"]
905         if load.get("env_only"):
906             return mopts
907         mopts["renderer"] = self.opts["renderer"]
908         mopts["failhard"] = self.opts["failhard"]
909         mopts["state_top"] = self.opts["state_top"]
910         mopts["state_top_saltenv"] = self.opts["state_top_saltenv"]
911         mopts["nodegroups"] = self.opts["nodegroups"]
912         mopts["state_auto_order"] = self.opts["state_auto_order"]
913         mopts["state_events"] = self.opts["state_events"]
914         mopts["state_aggregate"] = self.opts["state_aggregate"]
915         mopts["jinja_env"] = self.opts["jinja_env"]
916         mopts["jinja_sls_env"] = self.opts["jinja_sls_env"]
917         mopts["jinja_lstrip_blocks"] = self.opts["jinja_lstrip_blocks"]
918         mopts["jinja_trim_blocks"] = self.opts["jinja_trim_blocks"]
919         return mopts
920     def _mine_get(self, load):
921         load = self.__verify_load(load, ("id", "tgt", "fun", "tok"))
922         if load is False:
923             return {}
924         else:
925             return self.masterapi._mine_get(load, skip_verify=True)
926     def _mine(self, load):
927         load = self.__verify_load(load, ("id", "data", "tok"))
928         if load is False:
929             return {}
930         return self.masterapi._mine(load, skip_verify=True)
931     def _mine_delete(self, load):
932         load = self.__verify_load(load, ("id", "fun", "tok"))
933         if load is False:
934             return {}
935         else:
936             return self.masterapi._mine_delete(load)
937     def _mine_flush(self, load):
938         load = self.__verify_load(load, ("id", "tok"))
939         if load is False:
940             return {}
941         else:
942             return self.masterapi._mine_flush(load, skip_verify=True)
943     def _file_recv(self, load):
944         if any(key not in load for key in ("id", "path", "loc")):
945             return False
946         if not isinstance(load["path"], list):
947             return False
948         if not self.opts["file_recv"]:
949             return False
950         if not salt.utils.verify.valid_id(self.opts, load["id"]):
951             return False
952         file_recv_max_size = 1024 * 1024 * self.opts["file_recv_max_size"]
953         if "loc" in load and load["loc"] &lt; 0:
954             log.error("Invalid file pointer: load[loc] &lt; 0")
955             return False
956         if len(load["data"]) + load.get("loc", 0) &gt; file_recv_max_size:
957             log.error(
958                 "file_recv_max_size limit of %d MB exceeded! %s will be "
959                 "truncated. To successfully push this file, adjust "
960                 "file_recv_max_size to an integer (in MB) large enough to "
961                 "accommodate it.",
962                 file_recv_max_size,
963                 load["path"],
964             )
965             return False
966         if "tok" not in load:
967             log.error(
968                 "Received incomplete call from %s for '%s', missing '%s'",
969                 load["id"],
970                 inspect_stack()["co_name"],
971                 "tok",
972             )
973             return False
974         if not self.__verify_minion(load["id"], load["tok"]):
975             log.warning("Minion id %s is not who it says it is!", load["id"])
976             return {}
977         load.pop("tok")
978         sep_path = os.sep.join(load["path"])
979         normpath = os.path.normpath(sep_path)
980         if os.path.isabs(normpath) or "../" in load["path"]:
981             return False
982         cpath = os.path.join(
983             self.opts["cachedir"], "minions", load["id"], "files", normpath
984         )
985         if not os.path.normpath(cpath).startswith(self.opts["cachedir"]):
986             log.warning(
987                 "Attempt to write received file outside of master cache "
988                 "directory! Requested path: %s. Access denied.",
989                 cpath,
990             )
991             return False
992         cdir = os.path.dirname(cpath)
993         if not os.path.isdir(cdir):
994             try:
995                 os.makedirs(cdir)
996             except os.error:
997                 pass
998         if os.path.isfile(cpath) and load["loc"] != 0:
999             mode = "ab"
1000         else:
1001             mode = "wb"
1002         with salt.utils.files.fopen(cpath, mode) as fp_:
1003             if load["loc"]:
1004                 fp_.seek(load["loc"])
1005             fp_.write(salt.utils.stringutils.to_bytes(load["data"]))
1006         return True
1007     def _pillar(self, load):
1008         if any(key not in load for key in ("id", "grains")):
1009             return False
1010         if not salt.utils.verify.valid_id(self.opts, load["id"]):
1011             return False
1012         load["grains"]["id"] = load["id"]
1013         pillar = salt.pillar.get_pillar(
1014             self.opts,
1015             load["grains"],
1016             load["id"],
1017             load.get("saltenv", load.get("env")),
1018             ext=load.get("ext"),
1019             pillar_override=load.get("pillar_override", {}),
1020             pillarenv=load.get("pillarenv"),
1021             extra_minion_data=load.get("extra_minion_data"),
1022             clean_cache=load.get("clean_cache"),
1023         )
1024         data = pillar.compile_pillar()
1025         self.fs_.update_opts()
1026         if self.opts.get("minion_data_cache", False):
1027             self.masterapi.cache.store(
1028                 "minions/{}".format(load["id"]),
1029                 "data",
1030                 {"grains": load["grains"], "pillar": data},
1031             )
1032             if self.opts.get("minion_data_cache_events") is True:
1033                 self.event.fire_event(
1034                     {"Minion data cache refresh": load["id"]},
1035                     tagify(load["id"], "refresh", "minion"),
1036                 )
1037         return data
1038     def _minion_event(self, load):
1039         load = self.__verify_load(load, ("id", "tok"))
1040         if load is False:
1041             return {}
1042         self.masterapi._minion_event(load)
1043         self._handle_minion_event(load)
1044     def _handle_minion_event(self, load):
1045         id_ = load["id"]
1046         if load.get("tag", "") == "_salt_error":
1047             log.error(
1048                 "Received minion error from [%s]: %s", id_, load["data"]["message"]
1049             )
1050         for event in load.get("events", []):
1051             event_data = event.get("data", {})
1052             if "minions" in event_data:
1053                 jid = event_data.get("jid")
1054                 if not jid:
1055                     continue
1056                 minions = event_data["minions"]
1057                 try:
1058                     salt.utils.job.store_minions(
1059                         self.opts, jid, minions, mminion=self.mminion, syndic_id=id_
1060                     )
1061                 except (KeyError, salt.exceptions.SaltCacheError) as exc:
1062                     log.error(
1063                         "Could not add minion(s) %s for job %s: %s", minions, jid, exc
1064                     )
1065     def _return(self, load):
1066         if self.opts["require_minion_sign_messages"] and "sig" not in load:
1067             log.critical(
1068                 "_return: Master is requiring minions to sign their "
1069                 "messages, but there is no signature in this payload from "
1070                 "%s.",
1071                 load["id"],
1072             )
1073             return False
1074         if "sig" in load:
1075             log.trace("Verifying signed event publish from minion")
1076             sig = load.pop("sig")
1077             this_minion_pubkey = os.path.join(
1078                 self.opts["pki_dir"], "minions/{}".format(load["id"])
1079             )
1080             serialized_load = salt.serializers.msgpack.serialize(load)
1081             if not salt.crypt.verify_signature(
1082                 this_minion_pubkey, serialized_load, sig
1083             ):
1084                 log.info("Failed to verify event signature from minion %s.", load["id"])
1085                 if self.opts["drop_messages_signature_fail"]:
1086                     log.critical(
1087                         "drop_messages_signature_fail is enabled, dropping "
1088                         "message from %s",
1089                         load["id"],
1090                     )
1091                     return False
1092                 else:
1093                     log.info(
1094                         "But 'drop_message_signature_fail' is disabled, so message is"
1095                         " still accepted."
1096                     )
1097             load["sig"] = sig
1098         try:
1099             salt.utils.job.store_job(
1100                 self.opts, load, event=self.event, mminion=self.mminion
1101             )
1102         except salt.exceptions.SaltCacheError:
1103             log.error("Could not store job information for load: %s", load)
1104     def _syndic_return(self, load):
1105         loads = load.get("load")
1106         if not isinstance(loads, list):
1107             loads = [load]  # support old syndics not aggregating returns
1108         for load in loads:
1109             if any(key not in load for key in ("return", "jid", "id")):
1110                 continue
1111             if load.get("load"):
1112                 fstr = "{}.save_load".format(self.opts["master_job_cache"])
1113                 self.mminion.returners[fstr](load["jid"], load["load"])
1114             syndic_cache_path = os.path.join(
1115                 self.opts["cachedir"], "syndics", load["id"]
1116             )
1117             if not os.path.exists(syndic_cache_path):
1118                 path_name = os.path.split(syndic_cache_path)[0]
1119                 if not os.path.exists(path_name):
1120                     os.makedirs(path_name)
1121                 with salt.utils.files.fopen(syndic_cache_path, "w") as wfh:
1122                     wfh.write("")
1123             for key, item in load["return"].items():
1124                 ret = {"jid": load["jid"], "id": key}
1125                 ret.update(item)
1126                 if "master_id" in load:
1127                     ret["master_id"] = load["master_id"]
1128                 if "fun" in load:
1129                     ret["fun"] = load["fun"]
1130                 if "arg" in load:
1131                     ret["fun_args"] = load["arg"]
1132                 if "out" in load:
1133                     ret["out"] = load["out"]
1134                 if "sig" in load:
1135                     ret["sig"] = load["sig"]
1136                 self._return(ret)
1137     def minion_runner(self, clear_load):
1138         load = self.__verify_load(clear_load, ("fun", "arg", "id", "tok"))
1139         if load is False:
1140             return {}
1141         else:
1142             return self.masterapi.minion_runner(clear_load)
1143     def pub_ret(self, load):
1144         load = self.__verify_load(load, ("jid", "id", "tok"))
1145         if load is False:
1146             return {}
1147         auth_cache = os.path.join(self.opts["cachedir"], "publish_auth")
1148         if not os.path.isdir(auth_cache):
1149             os.makedirs(auth_cache)
1150         jid_fn = os.path.join(auth_cache, str(load["jid"]))
1151         with salt.utils.files.fopen(jid_fn, "r") as fp_:
1152             if not load["id"] == fp_.read():
1153                 return {}
1154         return self.local.get_cache_returns(load["jid"])
1155     def minion_pub(self, clear_load):
1156         if not self.__verify_minion_publish(clear_load):
1157             return {}
1158         else:
1159             return self.masterapi.minion_pub(clear_load)
1160     def minion_publish(self, clear_load):
1161         if not self.__verify_minion_publish(clear_load):
1162             return {}
1163         else:
1164             return self.masterapi.minion_publish(clear_load)
1165     def revoke_auth(self, load):
1166         load = self.__verify_load(load, ("id", "tok"))
1167         if not self.opts.get("allow_minion_key_revoke", False):
1168             log.warning(
1169                 "Minion %s requested key revoke, but allow_minion_key_revoke "
1170                 "is set to False",
1171                 load["id"],
1172             )
1173             return load
1174         if load is False:
1175             return load
1176         else:
1177             return self.masterapi.revoke_auth(load)
1178     def run_func(self, func, load):
1179         if func.startswith("__"):
1180             return {}, {"fun": "send"}
1181         if hasattr(self, func):
1182             try:
1183                 start = time.time()
1184                 ret = getattr(self, func)(load)
1185                 log.trace(
1186                     "Master function call %s took %s seconds", func, time.time() - start
1187                 )
1188             except Exception:  # pylint: disable=broad-except
1189                 ret = ""
1190                 log.error("Error in function %s:\n", func, exc_info=True)
1191         else:
1192             log.error(
1193                 "Received function %s which is unavailable on the master, "
1194                 "returning False",
1195                 func,
1196             )
1197             return False, {"fun": "send"}
1198         if func == "_return":
1199             return ret, {"fun": "send"}
1200         if func == "_pillar" and "id" in load:
1201             if load.get("ver") != "2" and self.opts["pillar_version"] == 1:
1202                 return ret, {"fun": "send"}
1203             return ret, {"fun": "send_private", "key": "pillar", "tgt": load["id"]}
1204         return ret, {"fun": "send"}
1205     def destroy(self):
1206         self.masterapi.destroy()
1207         if self.local is not None:
1208             self.local.destroy()
1209             self.local = None
1210 class ClearFuncs(TransportMethods):
1211     expose_methods = (
1212         "ping",
1213         "publish",
1214         "get_token",
1215         "mk_token",
1216         "wheel",
1217         "runner",
1218     )
1219     def __init__(self, opts, key):
1220         self.opts = opts
1221         self.key = key
1222         self.event = salt.utils.event.get_master_event(
1223             self.opts, self.opts["sock_dir"], listen=False
1224         )
1225         self.local = salt.client.get_local_client(self.opts["conf_file"])
1226         self.ckminions = salt.utils.minions.CkMinions(opts)
1227         self.loadauth = salt.auth.LoadAuth(opts)
1228         self.mminion = salt.minion.MasterMinion(
1229             self.opts, states=False, rend=False, ignore_config_errors=True
1230         )
1231         self.wheel_ = salt.wheel.Wheel(opts)
1232         self.masterapi = salt.daemons.masterapi.LocalFuncs(opts, key)
1233         self.channels = []
1234     def runner(self, clear_load):
1235         auth_type, err_name, key, sensitive_load_keys = self._prep_auth_info(clear_load)
1236         auth_check = self.loadauth.check_authentication(clear_load, auth_type, key=key)
1237         error = auth_check.get("error")
1238         if error:
1239             return {"error": error}
1240         username = auth_check.get("username")
1241         if auth_type != "user":
1242             runner_check = self.ckminions.runner_check(
1243                 auth_check.get("auth_list", []),
1244                 clear_load["fun"],
1245                 clear_load.get("kwarg", {}),
1246             )
1247             if not runner_check:
1248                 return {
1249                     "error": {
1250                         "name": err_name,
1251                         "message": (
1252                             'Authentication failure of type "{}" occurred for '
1253                             "user {}.".format(auth_type, username)
1254                         ),
1255                     }
1256                 }
1257             elif isinstance(runner_check, dict) and "error" in runner_check:
1258                 return runner_check
1259             for item in sensitive_load_keys:
1260                 clear_load.pop(item, None)
1261         else:
1262             if "user" in clear_load:
1263                 username = clear_load["user"]
1264                 if salt.auth.AuthUser(username).is_sudo():
1265                     username = self.opts.get("user", "root")
1266             else:
1267                 username = salt.utils.user.get_user()
1268         try:
1269             fun = clear_load.pop("fun")
1270             runner_client = salt.runner.RunnerClient(self.opts)
1271             return runner_client.asynchronous(
1272                 fun, clear_load.get("kwarg", {}), username, local=True
1273             )
1274         except Exception as exc:  # pylint: disable=broad-except
1275             log.error("Exception occurred while introspecting %s: %s", fun, exc)
1276             return {
1277                 "error": {
1278                     "name": exc.__class__.__name__,
1279                     "args": exc.args,
1280                     "message": str(exc),
1281                 }
1282             }
1283     def wheel(self, clear_load):
1284         auth_type, err_name, key, sensitive_load_keys = self._prep_auth_info(clear_load)
1285         auth_check = self.loadauth.check_authentication(clear_load, auth_type, key=key)
1286         error = auth_check.get("error")
1287         if error:
1288             return {"error": error}
1289         username = auth_check.get("username")
1290         if auth_type != "user":
1291             wheel_check = self.ckminions.wheel_check(
1292                 auth_check.get("auth_list", []),
1293                 clear_load["fun"],
1294                 clear_load.get("kwarg", {}),
1295             )
1296             if not wheel_check:
1297                 return {
1298                     "error": {
1299                         "name": err_name,
1300                         "message": (
1301                             'Authentication failure of type "{}" occurred for '
1302                             "user {}.".format(auth_type, username)
1303                         ),
1304                     }
1305                 }
1306             elif isinstance(wheel_check, dict) and "error" in wheel_check:
1307                 return wheel_check
1308             for item in sensitive_load_keys:
1309                 clear_load.pop(item, None)
1310         else:
1311             if "user" in clear_load:
1312                 username = clear_load["user"]
1313                 if salt.auth.AuthUser(username).is_sudo():
1314                     username = self.opts.get("user", "root")
1315             else:
1316                 username = salt.utils.user.get_user()
1317         try:
1318             jid = salt.utils.jid.gen_jid(self.opts)
1319             fun = clear_load.pop("fun")
1320             tag = tagify(jid, prefix="wheel")
1321             data = {
1322                 "fun": "wheel.{}".format(fun),
1323                 "jid": jid,
1324                 "tag": tag,
1325                 "user": username,
1326             }
1327             self.event.fire_event(data, tagify([jid, "new"], "wheel"))
1328             ret = self.wheel_.call_func(fun, full_return=True, **clear_load)
1329             data["return"] = ret["return"]
1330             data["success"] = ret["success"]
1331             self.event.fire_event(data, tagify([jid, "ret"], "wheel"))
1332             return {"tag": tag, "data": data}
1333         except Exception as exc:  # pylint: disable=broad-except
1334             log.error("Exception occurred while introspecting %s: %s", fun, exc)
1335             data["return"] = "Exception occurred in wheel {}: {}: {}".format(
1336                 fun,
1337                 exc.__class__.__name__,
1338                 exc,
1339             )
1340             data["success"] = False
1341             self.event.fire_event(data, tagify([jid, "ret"], "wheel"))
1342             return {"tag": tag, "data": data}
1343     def mk_token(self, clear_load):
1344         token = self.loadauth.mk_token(clear_load)
1345         if not token:
1346             log.warning('Authentication failure of type "eauth" occurred.')
1347             return ""
1348         return token
1349     def get_token(self, clear_load):
1350         if "token" not in clear_load:
1351             return False
1352         return self.loadauth.get_tok(clear_load["token"])
1353     def publish(self, clear_load):
1354         extra = clear_load.get("kwargs", {})
1355         publisher_acl = salt.acl.PublisherACL(self.opts["publisher_acl_blacklist"])
1356         if publisher_acl.user_is_blacklisted(
1357             clear_load["user"]
1358         ) or publisher_acl.cmd_is_blacklisted(clear_load["fun"]):
1359             log.error(
1360                 "%s does not have permissions to run %s. Please contact "
1361                 "your local administrator if you believe this is in "
1362                 "error.\n",
1363                 clear_load["user"],
1364                 clear_load["fun"],
1365             )
1366             return {
1367                 "error": {
1368                     "name": "AuthorizationError",
1369                     "message": "Authorization error occurred.",
1370                 }
1371             }
1372         delimiter = clear_load.get("kwargs", {}).get("delimiter", DEFAULT_TARGET_DELIM)
1373         _res = self.ckminions.check_minions(
1374             clear_load["tgt"], clear_load.get("tgt_type", "glob"), delimiter
1375         )
1376         minions = _res.get("minions", list())
1377         missing = _res.get("missing", list())
1378         ssh_minions = _res.get("ssh_minions", False)
1379         auth_type, err_name, key, sensitive_load_keys = self._prep_auth_info(extra)
1380         if auth_type == "user":
1381             auth_check = self.loadauth.check_authentication(
1382                 clear_load, auth_type, key=key
1383             )
1384         else:
1385             auth_check = self.loadauth.check_authentication(extra, auth_type)
1386         auth_list = auth_check.get("auth_list", [])
1387         err_msg = 'Authentication failure of type "{}" occurred.'.format(auth_type)
1388         if auth_check.get("error"):
1389             log.warning(err_msg)
1390             return {
1391                 "error": {
1392                     "name": "AuthenticationError",
1393                     "message": "Authentication error occurred.",
1394                 }
1395             }
1396         if auth_type != "user" or (auth_type == "user" and auth_list):
1397             authorized = self.ckminions.auth_check(
1398                 auth_list,
1399                 clear_load["fun"],
1400                 clear_load["arg"],
1401                 clear_load["tgt"],
1402                 clear_load.get("tgt_type", "glob"),
1403                 minions=minions,
1404                 whitelist=["saltutil.find_job"],
1405             )
1406             if not authorized:
1407                 if (
1408                     auth_type == "eauth"
1409                     and not auth_list
1410                     and "username" in extra
1411                     and "eauth" in extra
1412                 ):
1413                     log.debug(
1414                         'Auth configuration for eauth "%s" and user "%s" is empty',
1415                         extra["eauth"],
1416                         extra["username"],
1417                     )
1418                 log.warning(err_msg)
1419                 return {
1420                     "error": {
1421                         "name": "AuthorizationError",
1422                         "message": "Authorization error occurred.",
1423                     }
1424                 }
1425             if auth_type == "token":
1426                 username = auth_check.get("username")
1427                 clear_load["user"] = username
1428                 log.debug('Minion tokenized user = "%s"', username)
1429             elif auth_type == "eauth":
1430                 clear_load["user"] = self.loadauth.load_name(extra)
1431         if not self.opts.get("order_masters"):
1432             if not minions:
1433                 return {
1434                     "enc": "clear",
1435                     "load": {
1436                         "jid": None,
1437                         "minions": minions,
1438                         "error": (
1439                             "Master could not resolve minions for target {}".format(
1440                                 clear_load["tgt"]
1441                             )
1442                         ),
1443                     },
1444                 }
1445         jid = self._prep_jid(clear_load, extra)
1446         if jid is None:
1447             return {"enc": "clear", "load": {"error": "Master failed to assign jid"}}
1448         payload = self._prep_pub(minions, jid, clear_load, extra, missing)
1449         self._send_ssh_pub(payload, ssh_minions=ssh_minions)
1450         self._send_pub(payload)
1451         return {
1452             "enc": "clear",
1453             "load": {"jid": clear_load["jid"], "minions": minions, "missing": missing},
1454         }
1455     def _prep_auth_info(self, clear_load):
1456         sensitive_load_keys = []
1457         key = None
1458         if "token" in clear_load:
1459             auth_type = "token"
1460             err_name = "TokenAuthenticationError"
1461             sensitive_load_keys = ["token"]
1462         elif "eauth" in clear_load:
1463             auth_type = "eauth"
1464             err_name = "EauthAuthenticationError"
1465             sensitive_load_keys = ["username", "password"]
1466         else:
1467             auth_type = "user"
1468             err_name = "UserAuthenticationError"
1469             key = self.key
1470         return auth_type, err_name, key, sensitive_load_keys
1471     def _prep_jid(self, clear_load, extra):
1472         passed_jid = clear_load["jid"] if clear_load.get("jid") else None
1473         nocache = extra.get("nocache", False)
1474         fstr = "{}.prep_jid".format(self.opts["master_job_cache"])
1475         try:
1476             jid = self.mminion.returners[fstr](nocache=nocache, passed_jid=passed_jid)
1477         except (KeyError, TypeError):
1478             msg = (
1479                 "Failed to allocate a jid. The requested returner '{}' "
1480                 "could not be loaded.".format(fstr.split(".")[0])
1481             )
1482             log.error(msg)
1483             return {"error": msg}
1484         return jid
1485     def _send_pub(self, load):
1486         if not self.channels:
1487             for transport, opts in iter_transport_opts(self.opts):
1488                 chan = salt.channel.server.PubServerChannel.factory(opts)
1489                 self.channels.append(chan)
1490         for chan in self.channels:
1491             chan.publish(load)
1492     @property
1493     def ssh_client(self):
1494         if not hasattr(self, "_ssh_client"):
1495             self._ssh_client = salt.client.ssh.client.SSHClient(mopts=self.opts)
1496         return self._ssh_client
1497     def _send_ssh_pub(self, load, ssh_minions=False):
1498         if self.opts["enable_ssh_minions"] is True and ssh_minions is True:
1499             log.debug("Send payload to ssh minions")
1500             threading.Thread(target=self.ssh_client.cmd, kwargs=load).start()
1501     def _prep_pub(self, minions, jid, clear_load, extra, missing):
1502         clear_load["jid"] = jid
1503         delimiter = clear_load.get("kwargs", {}).get("delimiter", DEFAULT_TARGET_DELIM)
1504         self.event.fire_event({"minions": minions}, clear_load["jid"])
1505         new_job_load = {
1506             "jid": clear_load["jid"],
1507             "tgt_type": clear_load["tgt_type"],
1508             "tgt": clear_load["tgt"],
1509             "user": clear_load["user"],
1510             "fun": clear_load["fun"],
1511             "arg": clear_load["arg"],
1512             "minions": minions,
1513             "missing": missing,
1514         }
1515         self.event.fire_event(new_job_load, tagify([clear_load["jid"], "new"], "job"))
1516         if self.opts["ext_job_cache"]:
1517             fstr = "{}.save_load".format(self.opts["ext_job_cache"])
1518             save_load_func = True
1519             try:
1520                 arg_spec = salt.utils.args.get_function_argspec(
1521                     self.mminion.returners[fstr]
1522                 )
1523                 if "minions" not in arg_spec.args:
1524                     log.critical(
1525                         "The specified returner used for the external job cache "
1526                         "'%s' does not have a 'minions' kwarg in the returner's "
1527                         "save_load function.",
1528                         self.opts["ext_job_cache"],
1529                     )
1530             except (AttributeError, KeyError):
1531                 save_load_func = False
1532                 log.critical(
1533                     "The specified returner used for the external job cache "
1534                     '"%s" does not have a save_load function!',
1535                     self.opts["ext_job_cache"],
1536                 )
1537             if save_load_func:
1538                 try:
1539                     self.mminion.returners[fstr](
1540                         clear_load["jid"], clear_load, minions=minions
1541                     )
1542                 except Exception:  # pylint: disable=broad-except
1543                     log.critical(
1544                         "The specified returner threw a stack trace:\n", exc_info=True
1545                     )
1546         try:
1547             fstr = "{}.save_load".format(self.opts["master_job_cache"])
1548             self.mminion.returners[fstr](clear_load["jid"], clear_load, minions)
1549         except KeyError:
1550             log.critical(
1551                 "The specified returner used for the master job cache "
1552                 '"%s" does not have a save_load function!',
1553                 self.opts["master_job_cache"],
1554             )
1555         except Exception:  # pylint: disable=broad-except
1556             log.critical("The specified returner threw a stack trace:\n", exc_info=True)
1557         payload = {"enc": "aes"}
1558         load = {
1559             "fun": clear_load["fun"],
1560             "arg": clear_load["arg"],
1561             "tgt": clear_load["tgt"],
1562             "jid": clear_load["jid"],
1563             "ret": clear_load["ret"],
1564         }
1565         if "master_id" in self.opts:
1566             load["master_id"] = self.opts["master_id"]
1567         if "master_id" in extra:
1568             load["master_id"] = extra["master_id"]
1569         if delimiter != DEFAULT_TARGET_DELIM:
1570             load["delimiter"] = delimiter
1571         if "id" in extra:
1572             load["id"] = extra["id"]
1573         if "tgt_type" in clear_load:
1574             load["tgt_type"] = clear_load["tgt_type"]
1575         if "to" in clear_load:
1576             load["to"] = clear_load["to"]
1577         if "kwargs" in clear_load:
1578             if "ret_config" in clear_load["kwargs"]:
1579                 load["ret_config"] = clear_load["kwargs"].get("ret_config")
1580             if "metadata" in clear_load["kwargs"]:
1581                 load["metadata"] = clear_load["kwargs"].get("metadata")
1582             if "module_executors" in clear_load["kwargs"]:
1583                 load["module_executors"] = clear_load["kwargs"].get("module_executors")
1584             if "executor_opts" in clear_load["kwargs"]:
1585                 load["executor_opts"] = clear_load["kwargs"].get("executor_opts")
1586             if "ret_kwargs" in clear_load["kwargs"]:
1587                 load["ret_kwargs"] = clear_load["kwargs"].get("ret_kwargs")
1588         if "user" in clear_load:
1589             log.info(
1590                 "User %s Published command %s with jid %s",
1591                 clear_load["user"],
1592                 clear_load["fun"],
1593                 clear_load["jid"],
1594             )
1595             load["user"] = clear_load["user"]
1596         else:
1597             log.info(
1598                 "Published command %s with jid %s", clear_load["fun"], clear_load["jid"]
1599             )
1600         log.debug("Published command details %s", load)
1601         return load
1602     def ping(self, clear_load):
1603         return clear_load
1604     def destroy(self):
1605         if self.masterapi is not None:
1606             self.masterapi.destroy()
1607             self.masterapi = None
1608         if self.local is not None:
1609             self.local.destroy()
1610             self.local = None
1611         while self.channels:
1612             chan = self.channels.pop()
1613             chan.close()
1614     def connect(self):
1615         if self.channels:
1616             return
1617         for transport, opts in iter_transport_opts(self.opts):
1618             chan = salt.channel.server.PubServerChannel.factory(opts)
1619             self.channels.append(chan)
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_output.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import os
2 import traceback
3 import pytest
4 import salt.config
5 import salt.utils.yaml
6 from salt.output import display_output
7 from saltfactories.utils.tempfiles import temp_file
8 from tests.support.case import ShellCase
9 from tests.support.mixins import RUNTIME_VARS
10 class OutputReturnTest(ShellCase):
11     @pytest.mark.slow_test
12     def test_output_json(self):
13         ret = self.run_call("test.ping --out=json")
14         self.assertIn("{", ret)
15         self.assertIn('"local": true', "".join(ret))
16         self.assertIn("}", "".join(ret))
17     @pytest.mark.slow_test
18     def test_output_nested(self):
19         expected = ["local:", "    True"]
20         ret = self.run_call("test.ping --out=nested")
21         self.assertEqual(ret, expected)
22     @pytest.mark.slow_test
23     def test_output_quiet(self):
24         expected = []
25         ret = self.run_call("test.ping --out=quiet")
26         self.assertEqual(ret, expected)
27     @pytest.mark.slow_test
28     def test_output_pprint(self):
29         expected = ["{'local': True}"]
30         ret = self.run_call("test.ping --out=pprint")
31         self.assertEqual(ret, expected)
32     @pytest.mark.slow_test
33     def test_output_raw(self):
34         expected = ["{'local': True}"]
35         ret = self.run_call("test.ping --out=raw")
36         self.assertEqual(ret, expected)
37     @pytest.mark.slow_test
38     def test_output_txt(self):
39         expected = ["local: True"]
40         ret = self.run_call("test.ping --out=txt")
41         self.assertEqual(ret, expected)
42     @pytest.mark.slow_test
43     def test_output_yaml(self):
44         expected = ["local: true"]
45         ret = self.run_call("test.ping --out=yaml")
46         self.assertEqual(ret, expected)
47     @pytest.mark.slow_test
48     def test_output_yaml_namespaced_dict_wrapper(self):
49         dumped_yaml = "\n".join(self.run_call("grains.items --out=yaml"))
50         loaded_yaml = salt.utils.yaml.safe_load(dumped_yaml)
51         assert isinstance(loaded_yaml, dict)
52         assert list(loaded_yaml) == ["local"]
53     def test_output_unicodebad(self):
54         Tests outputter reliability with utf8
55         """
56         opts = salt<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.config.minion_config(
57             os.path.join(RUNTIME_VARS.TMP_CONF_DIR, "minion")
58         )
59         opts["output_file"] = os.path.join(</b></font>RUNTIME_VARS.TMP, "outputtest")
60         data = {"foo": {"result": False, "aaa": "azerzaeréééé", "comment": "ééééàààà"}}
61         try:
62             display_output(data, opts=opts)
63         except Exception:  # pylint: disable=broad-except
64             trace = traceback.format_exc()
65             sentinel = object()
66             old_max_diff = getattr(self, "maxDiff", sentinel)
67             try:
68                 self.maxDiff = None
69                 self.assertEqual(trace, "")
70             finally:
71                 if old_max_diff is sentinel:
72                     delattr(self, "maxDiff")
73                 else:
74                     self.maxDiff = old_max_diff
75     @pytest.mark.slow_test
76     def test_output_highstate(self):
77         """
78         Regression tests for the highstate outputter. Calls a basic state with various
79         flags. Each comparison should be identical when successful.
80         """
81         simple_ping_sls = """
82         simple-ping:
83           module.run:
84             - name: test.ping
85         """
86         with temp_file(
87             "simple-ping.sls", simple_ping_sls, RUNTIME_VARS.TMP_BASEENV_STATE_TREE
88         ):
89             expected = [
90                 "minion:",
91                 "          ID: simple-ping",
92                 "    Function: module.run",
93                 "        Name: test.ping",
94                 "      Result: True",
95                 "     Comment: Module function test.ping executed",
96                 "     Changes:   ",
97                 "              ret:",
98                 "                  True",
99                 "Summary for minion",
100                 "Succeeded: 1 (changed=1)",
101                 "Failed:    0",
102                 "Total states run:     1",
103             ]
104             state_run = self.run_salt('"minion" state.sls simple-ping')
105             for expected_item in expected:
106                 self.assertIn(expected_item, state_run)
107             state_run = self.run_salt('"minion" state.sls simple-ping --out=highstate')
108             for expected_item in expected:
109                 self.assertIn(expected_item, state_run)
110             state_run = self.run_salt('"minion" state.sls simple-ping --static')
111             for expected_item in expected:
112                 self.assertIn(expected_item, state_run)
113             state_run = self.run_salt(
114                 '"minion" state.sls simple-ping --static --out=highstate'
115             )
116             for expected_item in expected:
117                 self.assertIn(expected_item, state_run)
118     @pytest.mark.slow_test
119     def test_output_highstate_falls_back_nested(self):
120         """
121         Tests outputter when passing --out=highstate with a non-state call. This should
122         fall back to "nested" output.
123         """
124         expected = ["minion:", "    True"]
125         ret = self.run_salt('"minion" test.ping --out=highstate')
126         self.assertEqual(ret, expected)
127     @pytest.mark.slow_test
128     def test_static_simple(self):
129         """
130         Tests passing the --static option with a basic test.ping command. This
131         should be the "nested" output.
132         """
133         expected = ["minion:", "    True"]
134         ret = self.run_salt('"minion" test.ping --static')
135         self.assertEqual(ret, expected)
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
