
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 16, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-fields_15.py</h3>
            <pre><code>1  import binascii
2  import struct
3  import time
4  from bitstring import BitArray
5  import esptool
6  import reedsolo
7  from .mem_definition import EfuseDefineBlocks, EfuseDefineFields, EfuseDefineRegisters
8  from .. import base_fields
9  from .. import util
10  class EfuseBlock(base_fields.EfuseBlockBase):
11      def len_of_burn_unit(self):
12          return 8 * 4
13      def __init__(self, parent, param, skip_read=False):
14          parent.read_coding_scheme()
15          super(EfuseBlock, self).__init__(parent, param, skip_read=skip_read)
16      def apply_coding_scheme(self):
17          data = self.get_raw(from_read=False)[::-1]
18          if len(data) &lt; self.len_of_burn_unit():
19              add_empty_bytes = self.len_of_burn_unit() - len(data)
20              data = data + (b&quot;\x00&quot; * add_empty_bytes)
21          if self.get_coding_scheme() == self.parent.REGS.CODING_SCHEME_RS:
22              rs = reedsolo.RSCodec(12)
23              encoded_data = rs.encode([x for x in data])
24              words = struct.unpack(&quot;&lt;&quot; + &quot;I&quot; * 11, encoded_data)
25          else:
26              words = struct.unpack(&quot;&lt;&quot; + (&quot;I&quot; * (len(data) // 4)), data)
27          return words
28  class EspEfuses(base_fields.EspEfusesBase):
29      debug = False
30      do_not_confirm = False
31      def __init__(self, esp, skip_connect=False, debug=False, do_not_confirm=False):
32          self.Blocks = EfuseDefineBlocks()
33          self.Fields = EfuseDefineFields()
34          self.REGS = EfuseDefineRegisters
35          self.BURN_BLOCK_DATA_NAMES = self.Blocks.get_burn_block_data_names()
36          self.BLOCKS_FOR_KEYS = self.Blocks.get_blocks_for_keys()
37          self._esp = esp
38          self.debug = debug
39          self.do_not_confirm = do_not_confirm
40          if esp.CHIP_NAME != &quot;ESP32-C6&quot;:
41              raise esptool.FatalError(
42                  &quot;Expected the &#x27;esp&#x27; param for ESP32-C6 chip but got for &#x27;%s&#x27;.&quot;
43                  % (esp.CHIP_NAME)
44              )
45          if not skip_connect:
46              flags = self._esp.get_security_info()[&quot;flags&quot;]
47              GET_SECURITY_INFO_FLAG_SECURE_DOWNLOAD_ENABLE = 1 &lt;&lt; 2
48              if flags &amp; GET_SECURITY_INFO_FLAG_SECURE_DOWNLOAD_ENABLE:
49                  raise esptool.FatalError(
50                      &quot;Secure Download Mode is enabled. The tool can not read eFuses.&quot;
51                  )
52          self.blocks = [
53              EfuseBlock(self, self.Blocks.get(block), skip_read=skip_connect)
54              for block in self.Blocks.BLOCKS
55          ]
56          if not skip_connect:
57              self.get_coding_scheme_warnings()
58          self.efuses = [EfuseField.convert(self, efuse) for efuse in self.Fields.EFUSES]
59          self.efuses += [
60              EfuseField.convert(self, efuse) for efuse in self.Fields.KEYBLOCKS
61          ]
62          if skip_connect:
63              self.efuses += [
64                  EfuseField.convert(self, efuse)
65                  for efuse in self.Fields.BLOCK2_CALIBRATION_EFUSES
66              ]
67          else:
68              if self[&quot;BLK_VERSION_MINOR&quot;].get() == 1:
69                  self.efuses += [
70                      EfuseField.convert(self, efuse)
71                      for efuse in self.Fields.BLOCK2_CALIBRATION_EFUSES
72                  ]
73              self.efuses += [
74                  EfuseField.convert(self, efuse) for efuse in self.Fields.CALC
75              ]
76      def __getitem__(self, efuse_name):
77          for e in self.efuses:
78              if efuse_name == e.name or any(x == efuse_name for x in e.alt_names):
79                  return e
80          new_fields = False
81          for efuse in self.Fields.BLOCK2_CALIBRATION_EFUSES:
82              if efuse.name == efuse_name or any(
83                  x == efuse_name for x in efuse.alt_names
84              ):
85                  self.efuses += [
86                      EfuseField.convert(self, efuse)
87                      for efuse in self.Fields.BLOCK2_CALIBRATION_EFUSES
88                  ]
89                  new_fields = True
90          if new_fields:
91              for e in self.efuses:
92                  if efuse_name == e.name or any(x == efuse_name for x in e.alt_names):
93                      return e
94          raise KeyError
95      def read_coding_scheme(self):
96          self.coding_scheme = self.REGS.CODING_SCHEME_RS
97      def print_status_regs(self):
98          print(&quot;&quot;)
99          self.blocks[0].print_block(self.blocks[0].err_bitarray, &quot;err__regs&quot;, debug=True)
100          print(
101              &quot;{:27} 0x{:08x}&quot;.format(
102                  &quot;EFUSE_RD_RS_ERR0_REG&quot;, self.read_reg(self.REGS.EFUSE_RD_RS_ERR0_REG)
103              )
104          )
105          print(
106              &quot;{:27} 0x{:08x}&quot;.format(
107                  &quot;EFUSE_RD_RS_ERR1_REG&quot;, self.read_reg(self.REGS.EFUSE_RD_RS_ERR1_REG)
108              )
109          )
110      def efuse_controller_setup(self):
111          self.set_efuse_timing()
112          self.clear_pgm_registers()
113          self.wait_efuse_idle()
114      def write_efuses(self, block):
115          self.efuse_program(block)
116          return self.get_coding_scheme_warnings(silent=True)
117      def clear_pgm_registers(self):
118          self.wait_efuse_idle()
119          for r in range(
120              self.REGS.EFUSE_PGM_DATA0_REG, self.REGS.EFUSE_PGM_DATA0_REG + 32, 4
121          ):
122              self.write_reg(r, 0)
123      def wait_efuse_idle(self):
124          deadline = time.time() + self.REGS.EFUSE_BURN_TIMEOUT
125          while time.time() &lt; deadline:
126              if self.read_reg(self.REGS.EFUSE_STATUS_REG) &amp; 0x7 == 1:
127                  return
128          raise esptool.FatalError(
129              &quot;Timed out waiting for Efuse controller command to complete&quot;
130          )
131      def efuse_program(self, block):
132          self.wait_efuse_idle()
133          self.write_reg(self.REGS.EFUSE_CONF_REG, self.REGS.EFUSE_WRITE_OP_CODE)
134          self.write_reg(self.REGS.EFUSE_CMD_REG, self.REGS.EFUSE_PGM_CMD | (block &lt;&lt; 2))
135          self.wait_efuse_idle()
136          self.clear_pgm_registers()
137          self.efuse_read()
138      def efuse_read(self):
139          self.wait_efuse_idle()
140          self.write_reg(self.REGS.EFUSE_CONF_REG, self.REGS.EFUSE_READ_OP_CODE)
141          try:
142              self.write_reg(
143                  self.REGS.EFUSE_CMD_REG, self.REGS.EFUSE_READ_CMD, delay_after_us=1000
144              )
145              self.wait_efuse_idle()
146          except esptool.FatalError:
147              secure_download_mode_before = self._esp.secure_download_mode
148              try:
149                  self._esp = self.reconnect_chip(self._esp)
150              except esptool.FatalError:
151                  print(&quot;Can not re-connect to the chip&quot;)
152                  if not self[&quot;DIS_DOWNLOAD_MODE&quot;].get() and self[
153                      &quot;DIS_DOWNLOAD_MODE&quot;
154                  ].get(from_read=False):
155                      print(
156                          &quot;This is the correct behavior as we are actually burning &quot;
157                          &quot;DIS_DOWNLOAD_MODE which disables the connection to the chip&quot;
158                      )
159                      print(&quot;DIS_DOWNLOAD_MODE is enabled&quot;)
160                      print(&quot;Successful&quot;)
161                      exit(0)  # finish without errors
162                  raise
163              print(&quot;Established a connection with the chip&quot;)
164              if self._esp.secure_download_mode and not secure_download_mode_before:
165                  print(&quot;Secure download mode is enabled&quot;)
166                  if not self[&quot;ENABLE_SECURITY_DOWNLOAD&quot;].get() and self[
167                      &quot;ENABLE_SECURITY_DOWNLOAD&quot;
168                  ].get(from_read=False):
169                      print(
170                          &quot;espefuse tool can not continue to work in Secure download mode&quot;
171                      )
172                      print(&quot;ENABLE_SECURITY_DOWNLOAD is enabled&quot;)
173                      print(&quot;Successful&quot;)
174                      exit(0)  # finish without errors
175              raise
176      def set_efuse_timing(self):
177          apb_freq = self.get_crystal_freq()
178          if apb_freq != 40:
179              raise esptool.FatalError(
180                  &quot;The eFuse supports only xtal=40M (xtal was %d)&quot; % apb_freq
181              )
182          self.update_reg(self.REGS.EFUSE_DAC_CONF_REG, self.REGS.EFUSE_DAC_NUM_M, 0xFF)
183          self.update_reg(
184              self.REGS.EFUSE_DAC_CONF_REG, self.REGS.EFUSE_DAC_CLK_DIV_M, 0x28
185          )
186          self.update_reg(
187              self.REGS.EFUSE_WR_TIM_CONF1_REG, self.REGS.EFUSE_PWR_ON_NUM_M, 0x3000
188          )
189          self.update_reg(
190              self.REGS.EFUSE_WR_TIM_CONF2_REG, self.REGS.EFUSE_PWR_OFF_NUM_M, 0x190
191          )
192      def get_coding_scheme_warnings(self, silent=False):
193          old_addr_reg = 0
194          reg_value = 0
195          ret_fail = False
196          for block in self.blocks:
197              if block.id == 0:
198                  words = [
199                      self.read_reg(self.REGS.EFUSE_RD_REPEAT_ERR0_REG + offs * 4)
200                      for offs in range(5)
201                  ]
202                  block.err_bitarray.pos = 0
203                  for word in reversed(words):
204                      block.err_bitarray.overwrite(BitArray(&quot;uint:32=%d&quot; % word))
205                  block.num_errors = block.err_bitarray.count(True)
206                  block.fail = block.num_errors != 0
207              else:
208                  addr_reg, err_num_mask, err_num_offs, fail_bit = self.REGS.BLOCK_ERRORS[
209                      block.id
210                  ]
211                  if err_num_mask is None or err_num_offs is None or fail_bit is None:
212                      continue
213                  if addr_reg != old_addr_reg:
214                      old_addr_reg = addr_reg
215                      reg_value = self.read_reg(addr_reg)
216                  block.fail = reg_value &amp; (1 &lt;&lt; fail_bit) != 0
217                  block.num_errors = (reg_value &gt;&gt; err_num_offs) &amp; err_num_mask
218              ret_fail |= block.fail
219              if not silent and (block.fail or block.num_errors):
220                  print(
221                      &quot;Error(s) in BLOCK%d [ERRORS:%d FAIL:%d]&quot;
222                      % (block.id, block.num_errors, block.fail)
223                  )
224          if (self.debug or ret_fail) and not silent:
225              self.print_status_regs()
226          return ret_fail
227      def summary(self):
228          return &quot;&quot;
229  class EfuseField(base_fields.EfuseFieldBase):
230      @staticmethod
231      def convert(parent, efuse):
232          return {
233              &quot;mac&quot;: EfuseMacField,
234              &quot;keypurpose&quot;: EfuseKeyPurposeField,
235              &quot;t_sensor&quot;: EfuseTempSensor,
236              &quot;adc_tp&quot;: EfuseAdcPointCalibration,
237              &quot;wafer&quot;: EfuseWafer,
238          }.get(efuse.class_type, EfuseField)(parent, efuse)
239  class EfuseWafer(EfuseField):
240      def get(self, from_read=True):
241          hi_bits = self.parent[&quot;WAFER_VERSION_MINOR_HI&quot;].get(from_read)
242          assert self.parent[&quot;WAFER_VERSION_MINOR_HI&quot;].bit_len == 1
243          lo_bits = self.parent[&quot;WAFER_VERSION_MINOR_LO&quot;].get(from_read)
244          assert self.parent[&quot;WAFER_VERSION_MINOR_LO&quot;].bit_len == 3
245          return (hi_bits &lt;&lt; 3) + lo_bits
246      def save(self, new_value):
247          raise esptool.FatalError(&quot;Burning %s is not supported&quot; % self.name)
248  class EfuseTempSensor(EfuseField):
249      def get(self, from_read=True):
250          value = self.get_bitstring(from_read)
251          sig = -1 if value[0] else 1
252          return sig * value[1:].uint * 0.1
253  class EfuseAdcPointCalibration(EfuseField):
254      def get(self, from_read=True):
255          STEP_SIZE = 4
256          value = self.get_bitstring(from_read)
257          sig = -1 if value[0] else 1
258          return sig * value[1:].uint * STEP_SIZE
259  class EfuseMacField(EfuseField):
260      def check_format(self, new_value_str):
261          if new_value_str is None:
262              raise esptool.FatalError(
263                  &quot;Required MAC Address in AA:CD:EF:01:02:03 format!&quot;
264              )
265          num_bytes = 8 if self.name == &quot;MAC_EUI64&quot; else 6
266          if new_value_str.count(&quot;:&quot;) != num_bytes - 1:
267              raise esptool.FatalError(
268                  f&quot;MAC Address needs to be a {num_bytes}-byte hexadecimal format &quot;
269                  &quot;separated by colons (:)!&quot;
270              )
271          hexad = new_value_str.replace(&quot;:&quot;, &quot;&quot;).split(&quot; &quot;, 1)[0]
272          hexad = hexad.split(&quot; &quot;, 1)[0] if self.is_field_calculated() else hexad
273          if len(hexad) != num_bytes * 2:
274              raise esptool.FatalError(
275                  f&quot;MAC Address needs to be a {num_bytes}-byte hexadecimal number &quot;
276                  f&quot;({num_bytes * 2} hexadecimal characters)!&quot;
277              )
<span onclick='openModal()' class='match'>278          bindata = binascii.unhexlify(hexad)
279          if not self.is_field_calculated():
280              if esptool.util.byte(bindata, 0) &amp; 0x01:
</span>281                  raise esptool.FatalError(&quot;Custom MAC must be a unicast MAC!&quot;)
282          return bindata
283      def check(self):
284          errs, fail = self.parent.get_block_errors(self.block)
285          if errs != 0 or fail:
286              output = &quot;Block%d has ERRORS:%d FAIL:%d&quot; % (self.block, errs, fail)
287          else:
288              output = &quot;OK&quot;
289          return &quot;(&quot; + output + &quot;)&quot;
290      def get(self, from_read=True):
291          if self.name == &quot;CUSTOM_MAC&quot;:
292              mac = self.get_raw(from_read)[::-1]
293          elif self.name == &quot;MAC&quot;:
294              mac = self.get_raw(from_read)
295          elif self.name == &quot;MAC_EUI64&quot;:
296              mac = self.parent[&quot;MAC&quot;].get_bitstring(from_read).copy()
297              mac_ext = self.parent[&quot;MAC_EXT&quot;].get_bitstring(from_read)
298              mac.insert(mac_ext, 24)
299              mac = mac.bytes
300          else:
301              mac = self.get_raw(from_read)
302          return &quot;%s %s&quot; % (util.hexify(mac, &quot;:&quot;), self.check())
303      def save(self, new_value):
304          def print_field(e, new_value):
305              print(
306                  &quot;    - &#x27;{}&#x27; ({}) {} -&gt; {}&quot;.format(
307                      e.name, e.description, e.get_bitstring(), new_value
308                  )
309              )
310          if self.name == &quot;CUSTOM_MAC&quot;:
311              bitarray_mac = self.convert_to_bitstring(new_value)
312              print_field(self, bitarray_mac)
313              super(EfuseMacField, self).save(new_value)
314          else:
315              raise esptool.FatalError(f&quot;Burning {self.name} is not supported&quot;)
316  class EfuseKeyPurposeField(EfuseField):
317      KEY_PURPOSES = [
318          (&quot;USER&quot;,                         0,  None,       None,      &quot;no_need_rd_protect&quot;),   # User purposes (software-only use)
319          (&quot;RESERVED&quot;,                     1,  None,       None,      &quot;no_need_rd_protect&quot;),   # Reserved
320          (&quot;XTS_AES_128_KEY&quot;,              4,  None,       &quot;Reverse&quot;, &quot;need_rd_protect&quot;),      # XTS_AES_128_KEY (flash/PSRAM encryption)
321          (&quot;HMAC_DOWN_ALL&quot;,                5,  None,       None,      &quot;need_rd_protect&quot;),      # HMAC Downstream mode
322          (&quot;HMAC_DOWN_JTAG&quot;,               6,  None,       None,      &quot;need_rd_protect&quot;),      # JTAG soft enable key (uses HMAC Downstream mode)
323          (&quot;HMAC_DOWN_DIGITAL_SIGNATURE&quot;,  7,  None,       None,      &quot;need_rd_protect&quot;),      # Digital Signature peripheral key (uses HMAC Downstream mode)
324          (&quot;HMAC_UP&quot;,                      8,  None,       None,      &quot;need_rd_protect&quot;),      # HMAC Upstream mode
325          (&quot;SECURE_BOOT_DIGEST0&quot;,          9,  &quot;DIGEST&quot;,   None,      &quot;no_need_rd_protect&quot;),   # SECURE_BOOT_DIGEST0 (Secure Boot key digest)
326          (&quot;SECURE_BOOT_DIGEST1&quot;,          10, &quot;DIGEST&quot;,   None,      &quot;no_need_rd_protect&quot;),   # SECURE_BOOT_DIGEST1 (Secure Boot key digest)
327          (&quot;SECURE_BOOT_DIGEST2&quot;,          11, &quot;DIGEST&quot;,   None,      &quot;no_need_rd_protect&quot;),   # SECURE_BOOT_DIGEST2 (Secure Boot key digest)
328      ]
329      KEY_PURPOSES_NAME = [name[0] for name in KEY_PURPOSES]
330      DIGEST_KEY_PURPOSES = [name[0] for name in KEY_PURPOSES if name[2] == &quot;DIGEST&quot;]
331      def check_format(self, new_value_str):
332          raw_val = new_value_str
333          for purpose_name in self.KEY_PURPOSES:
334              if purpose_name[0] == new_value_str:
335                  raw_val = str(purpose_name[1])
336                  break
337          if raw_val.isdigit():
338              if int(raw_val) not in [p[1] for p in self.KEY_PURPOSES if p[1] &gt; 0]:
339                  raise esptool.FatalError(&quot;&#x27;%s&#x27; can not be set (value out of range)&quot; % raw_val)
340          else:
341              raise esptool.FatalError(&quot;&#x27;%s&#x27; unknown name&quot; % raw_val)
342          return raw_val
343      def need_reverse(self, new_key_purpose):
344          for key in self.KEY_PURPOSES:
345              if key[0] == new_key_purpose:
346                  return key[3] == &quot;Reverse&quot;
347      def need_rd_protect(self, new_key_purpose):
348          for key in self.KEY_PURPOSES:
349              if key[0] == new_key_purpose:
350                  return key[4] == &quot;need_rd_protect&quot;
351      def get(self, from_read=True):
352          for p in self.KEY_PURPOSES:
353              if p[1] == self.get_raw(from_read):
354                  return p[0]
355          return &quot;FORBIDDEN_STATE&quot;
356      def get_name(self, raw_val):
357          for key in self.KEY_PURPOSES:
358              if key[1] == raw_val:
359                  return key[0]
360      def save(self, new_value):
361          raw_val = int(self.check_format(str(new_value)))
362          str_new_value = self.get_name(raw_val)
363          if self.name == &quot;KEY_PURPOSE_5&quot; and str_new_value.startswith(&quot;XTS_AES&quot;):
364              raise esptool.FatalError(f&quot;{self.name} can not have {str_new_value} key due to a hardware bug (please see TRM for more details)&quot;)
365          return super(EfuseKeyPurposeField, self).save(raw_val)
</code></pre>
        </div>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-eval.py</h3>
            <pre><code>1  from data import COCODetection, get_label_map, MEANS, COLORS
2  from yolact import Yolact
3  from utils.augmentations import BaseTransform, FastBaseTransform, Resize
4  from utils.functions import MovingAverage, ProgressBar
5  from layers.box_utils import jaccard, center_size, mask_iou
6  from utils import timer
7  from utils.functions import SavePath
8  from layers.output_utils import postprocess, undo_image_transformation
9  import pycocotools
10  from data import cfg, set_cfg, set_dataset
11  import numpy as np
12  import torch
13  import torch.backends.cudnn as cudnn
14  from torch.autograd import Variable
15  import argparse
16  import time
17  import random
18  import cProfile
19  import pickle
20  import json
21  import os
22  from collections import defaultdict
23  from pathlib import Path
24  from collections import OrderedDict
25  from PIL import Image
26  import matplotlib.pyplot as plt
27  import cv2
28  def str2bool(v):
29      if v.lower() in (&#x27;yes&#x27;, &#x27;true&#x27;, &#x27;t&#x27;, &#x27;y&#x27;, &#x27;1&#x27;):
30          return True
31      elif v.lower() in (&#x27;no&#x27;, &#x27;false&#x27;, &#x27;f&#x27;, &#x27;n&#x27;, &#x27;0&#x27;):
32          return False
33      else:
34          raise argparse.ArgumentTypeError(&#x27;Boolean value expected.&#x27;)
35  def parse_args(argv=None):
36      parser = argparse.ArgumentParser(
37          description=&#x27;YOLACT COCO Evaluation&#x27;)
38      parser.add_argument(&#x27;--trained_model&#x27;,
39                          default=&#x27;weights/ssd300_mAP_77.43_v2.pth&#x27;, type=str,
40                          help=&#x27;Trained state_dict file path to open. If &quot;interrupt&quot;, this will open the interrupt file.&#x27;)
41      parser.add_argument(&#x27;--top_k&#x27;, default=5, type=int,
42                          help=&#x27;Further restrict the number of predictions to parse&#x27;)
43      parser.add_argument(&#x27;--cuda&#x27;, default=True, type=str2bool,
44                          help=&#x27;Use cuda to evaulate model&#x27;)
45      parser.add_argument(&#x27;--fast_nms&#x27;, default=True, type=str2bool,
46                          help=&#x27;Whether to use a faster, but not entirely correct version of NMS.&#x27;)
47      parser.add_argument(&#x27;--cross_class_nms&#x27;, default=False, type=str2bool,
48                          help=&#x27;Whether compute NMS cross-class or per-class.&#x27;)
49      parser.add_argument(&#x27;--display_masks&#x27;, default=True, type=str2bool,
50                          help=&#x27;Whether or not to display masks over bounding boxes&#x27;)
51      parser.add_argument(&#x27;--display_bboxes&#x27;, default=True, type=str2bool,
52                          help=&#x27;Whether or not to display bboxes around masks&#x27;)
53      parser.add_argument(&#x27;--display_text&#x27;, default=True, type=str2bool,
54                          help=&#x27;Whether or not to display text (class [score])&#x27;)
55      parser.add_argument(&#x27;--display_scores&#x27;, default=True, type=str2bool,
56                          help=&#x27;Whether or not to display scores in addition to classes&#x27;)
57      parser.add_argument(&#x27;--display&#x27;, dest=&#x27;display&#x27;, action=&#x27;store_true&#x27;,
58                          help=&#x27;Display qualitative results instead of quantitative ones.&#x27;)
59      parser.add_argument(&#x27;--shuffle&#x27;, dest=&#x27;shuffle&#x27;, action=&#x27;store_true&#x27;,
60                          help=&#x27;Shuffles the images when displaying them. Doesn\&#x27;t have much of an effect when display is off though.&#x27;)
61      parser.add_argument(&#x27;--ap_data_file&#x27;, default=&#x27;results/ap_data.pkl&#x27;, type=str,
62                          help=&#x27;In quantitative mode, the file to save detections before calculating mAP.&#x27;)
63      parser.add_argument(&#x27;--resume&#x27;, dest=&#x27;resume&#x27;, action=&#x27;store_true&#x27;,
64                          help=&#x27;If display not set, this resumes mAP calculations from the ap_data_file.&#x27;)
65      parser.add_argument(&#x27;--max_images&#x27;, default=-1, type=int,
66                          help=&#x27;The maximum number of images from the dataset to consider. Use -1 for all.&#x27;)
67      parser.add_argument(&#x27;--output_coco_json&#x27;, dest=&#x27;output_coco_json&#x27;, action=&#x27;store_true&#x27;,
68                          help=&#x27;If display is not set, instead of processing IoU values, this just dumps detections into the coco json file.&#x27;)
69      parser.add_argument(&#x27;--bbox_det_file&#x27;, default=&#x27;results/bbox_detections.json&#x27;, type=str,
70                          help=&#x27;The output file for coco bbox results if --coco_results is set.&#x27;)
71      parser.add_argument(&#x27;--mask_det_file&#x27;, default=&#x27;results/mask_detections.json&#x27;, type=str,
72                          help=&#x27;The output file for coco mask results if --coco_results is set.&#x27;)
73      parser.add_argument(&#x27;--config&#x27;, default=None,
74                          help=&#x27;The config object to use.&#x27;)
75      parser.add_argument(&#x27;--output_web_json&#x27;, dest=&#x27;output_web_json&#x27;, action=&#x27;store_true&#x27;,
76                          help=&#x27;If display is not set, instead of processing IoU values, this dumps detections for usage with the detections viewer web thingy.&#x27;)
77      parser.add_argument(&#x27;--web_det_path&#x27;, default=&#x27;web/dets/&#x27;, type=str,
78                          help=&#x27;If output_web_json is set, this is the path to dump detections into.&#x27;)
79      parser.add_argument(&#x27;--no_bar&#x27;, dest=&#x27;no_bar&#x27;, action=&#x27;store_true&#x27;,
80                          help=&#x27;Do not output the status bar. This is useful for when piping to a file.&#x27;)
81      parser.add_argument(&#x27;--display_lincomb&#x27;, default=False, type=str2bool,
82                          help=&#x27;If the config uses lincomb masks, output a visualization of how those masks are created.&#x27;)
83      parser.add_argument(&#x27;--benchmark&#x27;, default=False, dest=&#x27;benchmark&#x27;, action=&#x27;store_true&#x27;,
84                          help=&#x27;Equivalent to running display mode but without displaying an image.&#x27;)
85      parser.add_argument(&#x27;--no_sort&#x27;, default=False, dest=&#x27;no_sort&#x27;, action=&#x27;store_true&#x27;,
86                          help=&#x27;Do not sort images by hashed image ID.&#x27;)
87      parser.add_argument(&#x27;--seed&#x27;, default=None, type=int,
88                          help=&#x27;The seed to pass into random.seed. Note: this is only really for the shuffle and does not (I think) affect cuda stuff.&#x27;)
89      parser.add_argument(&#x27;--mask_proto_debug&#x27;, default=False, dest=&#x27;mask_proto_debug&#x27;, action=&#x27;store_true&#x27;,
90                          help=&#x27;Outputs stuff for scripts/compute_mask.py.&#x27;)
91      parser.add_argument(&#x27;--no_crop&#x27;, default=False, dest=&#x27;crop&#x27;, action=&#x27;store_false&#x27;,
92                          help=&#x27;Do not crop output masks with the predicted bounding box.&#x27;)
93      parser.add_argument(&#x27;--image&#x27;, default=None, type=str,
94                          help=&#x27;A path to an image to use for display.&#x27;)
95      parser.add_argument(&#x27;--images&#x27;, default=None, type=str,
96                          help=&#x27;An input folder of images and output folder to save detected images. Should be in the format input-&gt;output.&#x27;)
97      parser.add_argument(&#x27;--video&#x27;, default=None, type=str,
98                          help=&#x27;A path to a video to evaluate on. Passing in a number will use that index webcam.&#x27;)
99      parser.add_argument(&#x27;--video_multiframe&#x27;, default=1, type=int,
100                          help=&#x27;The number of frames to evaluate in parallel to make videos play at higher fps.&#x27;)
101      parser.add_argument(&#x27;--score_threshold&#x27;, default=0, type=float,
102                          help=&#x27;Detections with a score under this threshold will not be considered. This currently only works in display mode.&#x27;)
103      parser.add_argument(&#x27;--dataset&#x27;, default=None, type=str,
104                          help=&#x27;If specified, override the dataset specified in the config with this one (example: coco2017_dataset).&#x27;)
105      parser.add_argument(&#x27;--detect&#x27;, default=False, dest=&#x27;detect&#x27;, action=&#x27;store_true&#x27;,
106                          help=&#x27;Don\&#x27;t evauluate the mask branch at all and only do object detection. This only works for --display and --benchmark.&#x27;)
107      parser.add_argument(&#x27;--display_fps&#x27;, default=False, dest=&#x27;display_fps&#x27;, action=&#x27;store_true&#x27;,
108                          help=&#x27;When displaying / saving video, draw the FPS on the frame&#x27;)
109      parser.add_argument(&#x27;--emulate_playback&#x27;, default=False, dest=&#x27;emulate_playback&#x27;, action=&#x27;store_true&#x27;,
110                          help=&#x27;When saving a video, emulate the framerate that you\&#x27;d get running in real-time mode.&#x27;)
111      parser.set_defaults(no_bar=False, display=False, resume=False, output_coco_json=False, output_web_json=False, shuffle=False,
112                          benchmark=False, no_sort=False, no_hash=False, mask_proto_debug=False, crop=True, detect=False, display_fps=False,
113                          emulate_playback=False)
114      global args
115      args = parser.parse_args(argv)
116      if args.output_web_json:
117          args.output_coco_json = True
118      if args.seed is not None:
119          random.seed(args.seed)
120  iou_thresholds = [x / 100 for x in range(50, 100, 5)]
121  coco_cats = {} # Call prep_coco_cats to fill this
122  coco_cats_inv = {}
123  color_cache = defaultdict(lambda: {})
124  def prep_display(dets_out, img, h, w, undo_transform=True, class_color=False, mask_alpha=0.45, fps_str=&#x27;&#x27;):
125      if undo_transform:
126          img_numpy = undo_image_transformation(img, w, h)
127          img_gpu = torch.Tensor(img_numpy).cuda()
128      else:
129          img_gpu = img / 255.0
130          h, w, _ = img.shape
131      with timer.env(&#x27;Postprocess&#x27;):
132          save = cfg.rescore_bbox
133          cfg.rescore_bbox = True
134          t = postprocess(dets_out, w, h, visualize_lincomb = args.display_lincomb,
135                                          crop_masks        = args.crop,
136                                          score_threshold   = args.score_threshold)
137          cfg.rescore_bbox = save
138      with timer.env(&#x27;Copy&#x27;):
139          idx = t[1].argsort(0, descending=True)[:args.top_k]
140          if cfg.eval_mask_branch:
141              masks = t[3][idx]
142          classes, scores, boxes = [x[idx].cpu().numpy() for x in t[:3]]
143      num_dets_to_consider = min(args.top_k, classes.shape[0])
144      for j in range(num_dets_to_consider):
145          if scores[j] &lt; args.score_threshold:
146              num_dets_to_consider = j
147              break
148      def get_color(j, on_gpu=None):
149          global color_cache
150          color_idx = (classes[j] * 5 if class_color else j * 5) % len(COLORS)
151          if on_gpu is not None and color_idx in color_cache[on_gpu]:
152              return color_cache[on_gpu][color_idx]
153          else:
154              color = COLORS[color_idx]
155              if not undo_transform:
156                  color = (color[2], color[1], color[0])
157              if on_gpu is not None:
158                  color = torch.Tensor(color).to(on_gpu).float() / 255.
159                  color_cache[on_gpu][color_idx] = color
160              return color
161      if args.display_masks and cfg.eval_mask_branch and num_dets_to_consider &gt; 0:
162          masks = masks[:num_dets_to_consider, :, :, None]
163          colors = torch.cat([get_color(j, on_gpu=img_gpu.device.index).view(1, 1, 1, 3) for j in range(num_dets_to_consider)], dim=0)
164          masks_color = masks.repeat(1, 1, 1, 3) * colors * mask_alpha
165          inv_alph_masks = masks * (-mask_alpha) + 1
166          masks_color_summand = masks_color[0]
167          if num_dets_to_consider &gt; 1:
168              inv_alph_cumul = inv_alph_masks[:(num_dets_to_consider-1)].cumprod(dim=0)
169              masks_color_cumul = masks_color[1:] * inv_alph_cumul
170              masks_color_summand += masks_color_cumul.sum(dim=0)
171          img_gpu = img_gpu * inv_alph_masks.prod(dim=0) + masks_color_summand
172      if args.display_fps:
173          font_face = cv2.FONT_HERSHEY_DUPLEX
174          font_scale = 0.6
175          font_thickness = 1
176          text_w, text_h = cv2.getTextSize(fps_str, font_face, font_scale, font_thickness)[0]
177          img_gpu[0:text_h+8, 0:text_w+8] *= 0.6 # 1 - Box alpha
178      img_numpy = (img_gpu * 255).byte().cpu().numpy()
179      if args.display_fps:
180          text_pt = (4, text_h + 2)
181          text_color = [255, 255, 255]
182          cv2.putText(img_numpy, fps_str, text_pt, font_face, font_scale, text_color, font_thickness, cv2.LINE_AA)
183      if num_dets_to_consider == 0:
184          return img_numpy
185      if args.display_text or args.display_bboxes:
186          for j in reversed(range(num_dets_to_consider)):
187              x1, y1, x2, y2 = boxes[j, :]
188              color = get_color(j)
189              score = scores[j]
190              if args.display_bboxes:
191                  cv2.rectangle(img_numpy, (x1, y1), (x2, y2), color, 1)
192              if args.display_text:
193                  _class = cfg.dataset.class_names[classes[j]]
194                  text_str = &#x27;%s: %.2f&#x27; % (_class, score) if args.display_scores else _class
195                  font_face = cv2.FONT_HERSHEY_DUPLEX
196                  font_scale = 0.6
197                  font_thickness = 1
198                  text_w, text_h = cv2.getTextSize(text_str, font_face, font_scale, font_thickness)[0]
199                  text_pt = (x1, y1 - 3)
200                  text_color = [255, 255, 255]
201                  cv2.rectangle(img_numpy, (x1, y1), (x1 + text_w, y1 - text_h - 4), color, -1)
202                  cv2.putText(img_numpy, text_str, text_pt, font_face, font_scale, text_color, font_thickness, cv2.LINE_AA)
203      return img_numpy
204  def prep_benchmark(dets_out, h, w):
205      with timer.env(&#x27;Postprocess&#x27;):
206          t = postprocess(dets_out, w, h, crop_masks=args.crop, score_threshold=args.score_threshold)
207      with timer.env(&#x27;Copy&#x27;):
208          classes, scores, boxes, masks = [x[:args.top_k] for x in t]
209          if isinstance(scores, list):
210              box_scores = scores[0].cpu().numpy()
211              mask_scores = scores[1].cpu().numpy()
212          else:
213              scores = scores.cpu().numpy()
214          classes = classes.cpu().numpy()
215          boxes = boxes.cpu().numpy()
216          masks = masks.cpu().numpy()
217      with timer.env(&#x27;Sync&#x27;):
218          torch.cuda.synchronize()
219  def prep_coco_cats():
220      for coco_cat_id, transformed_cat_id_p1 in get_label_map().items():
221          transformed_cat_id = transformed_cat_id_p1 - 1
222          coco_cats[transformed_cat_id] = coco_cat_id
223          coco_cats_inv[coco_cat_id] = transformed_cat_id
224  def get_coco_cat(transformed_cat_id):
225      return coco_cats[transformed_cat_id]
226  def get_transformed_cat(coco_cat_id):
227      return coco_cats_inv[coco_cat_id]
228  class Detections:
229      def __init__(self):
230          self.bbox_data = []
231          self.mask_data = []
232      def add_bbox(self, image_id:int, category_id:int, bbox:list, score:float):
233          bbox = [bbox[0], bbox[1], bbox[2]-bbox[0], bbox[3]-bbox[1]]
234          bbox = [round(float(x)*10)/10 for x in bbox]
235          self.bbox_data.append({
236              &#x27;image_id&#x27;: int(image_id),
237              &#x27;category_id&#x27;: get_coco_cat(int(category_id)),
238              &#x27;bbox&#x27;: bbox,
239              &#x27;score&#x27;: float(score)
240          })
241      def add_mask(self, image_id:int, category_id:int, segmentation:np.ndarray, score:float):
242          rle = pycocotools.mask.encode(np.asfortranarray(segmentation.astype(np.uint8)))
243          rle[&#x27;counts&#x27;] = rle[&#x27;counts&#x27;].decode(&#x27;ascii&#x27;) # json.dump doesn&#x27;t like bytes strings
244          self.mask_data.append({
245              &#x27;image_id&#x27;: int(image_id),
246              &#x27;category_id&#x27;: get_coco_cat(int(category_id)),
247              &#x27;segmentation&#x27;: rle,
248              &#x27;score&#x27;: float(score)
249          })
250      def dump(self):
251          dump_arguments = [
252              (self.bbox_data, args.bbox_det_file),
253              (self.mask_data, args.mask_det_file)
254          ]
255          for data, path in dump_arguments:
256              with open(path, &#x27;w&#x27;) as f:
257                  json.dump(data, f)
258      def dump_web(self):
259          config_outs = [&#x27;preserve_aspect_ratio&#x27;, &#x27;use_prediction_module&#x27;,
260                          &#x27;use_yolo_regressors&#x27;, &#x27;use_prediction_matching&#x27;,
261                          &#x27;train_masks&#x27;]
262          output = {
263              &#x27;info&#x27; : {
264                  &#x27;Config&#x27;: {key: getattr(cfg, key) for key in config_outs},
265              }
266          }
267          image_ids = list(set([x[&#x27;image_id&#x27;] for x in self.bbox_data]))
268          image_ids.sort()
269          image_lookup = {_id: idx for idx, _id in enumerate(image_ids)}
270          output[&#x27;images&#x27;] = [{&#x27;image_id&#x27;: image_id, &#x27;dets&#x27;: []} for image_id in image_ids]
271          for bbox, mask in zip(self.bbox_data, self.mask_data):
272              image_obj = output[&#x27;images&#x27;][image_lookup[bbox[&#x27;image_id&#x27;]]]
273              image_obj[&#x27;dets&#x27;].append({
274                  &#x27;score&#x27;: bbox[&#x27;score&#x27;],
275                  &#x27;bbox&#x27;: bbox[&#x27;bbox&#x27;],
276                  &#x27;category&#x27;: cfg.dataset.class_names[get_transformed_cat(bbox[&#x27;category_id&#x27;])],
277                  &#x27;mask&#x27;: mask[&#x27;segmentation&#x27;],
278              })
279          with open(os.path.join(args.web_det_path, &#x27;%s.json&#x27; % cfg.name), &#x27;w&#x27;) as f:
280              json.dump(output, f)
281  def _mask_iou(mask1, mask2, iscrowd=False):
282      with timer.env(&#x27;Mask IoU&#x27;):
283          ret = mask_iou(mask1, mask2, iscrowd)
284      return ret.cpu()
285  def _bbox_iou(bbox1, bbox2, iscrowd=False):
286      with timer.env(&#x27;BBox IoU&#x27;):
287          ret = jaccard(bbox1, bbox2, iscrowd)
288      return ret.cpu()
289  def prep_metrics(ap_data, dets, img, gt, gt_masks, h, w, num_crowd, image_id, detections:Detections=None):
290      if not args.output_coco_json:
291          with timer.env(&#x27;Prepare gt&#x27;):
292              gt_boxes = torch.Tensor(gt[:, :4])
293              gt_boxes[:, [0, 2]] *= w
294              gt_boxes[:, [1, 3]] *= h
295              gt_classes = list(gt[:, 4].astype(int))
296              gt_masks = torch.Tensor(gt_masks).view(-1, h*w)
297              if num_crowd &gt; 0:
298                  split = lambda x: (x[-num_crowd:], x[:-num_crowd])
299                  crowd_boxes  , gt_boxes   = split(gt_boxes)
300                  crowd_masks  , gt_masks   = split(gt_masks)
301                  crowd_classes, gt_classes = split(gt_classes)
302      with timer.env(&#x27;Postprocess&#x27;):
303          classes, scores, boxes, masks = postprocess(dets, w, h, crop_masks=args.crop, score_threshold=args.score_threshold)
304          if classes.size(0) == 0:
305              return
306          classes = list(classes.cpu().numpy().astype(int))
307          if isinstance(scores, list):
308              box_scores = list(scores[0].cpu().numpy().astype(float))
309              mask_scores = list(scores[1].cpu().numpy().astype(float))
310          else:
311              scores = list(scores.cpu().numpy().astype(float))
312              box_scores = scores
313              mask_scores = scores
314          masks = masks.view(-1, h*w).cuda()
315          boxes = boxes.cuda()
316      if args.output_coco_json:
317          with timer.env(&#x27;JSON Output&#x27;):
318              boxes = boxes.cpu().numpy()
319              masks = masks.view(-1, h, w).cpu().numpy()
320              for i in range(masks.shape[0]):
321                  if (boxes[i, 3] - boxes[i, 1]) * (boxes[i, 2] - boxes[i, 0]) &gt; 0:
322                      detections.add_bbox(image_id, classes[i], boxes[i,:],   box_scores[i])
323                      detections.add_mask(image_id, classes[i], masks[i,:,:], mask_scores[i])
324              return
325      with timer.env(&#x27;Eval Setup&#x27;):
326          num_pred = len(classes)
327          num_gt   = len(gt_classes)
328          mask_iou_cache = _mask_iou(masks, gt_masks)
329          bbox_iou_cache = _bbox_iou(boxes.float(), gt_boxes.float())
330          if num_crowd &gt; 0:
331              crowd_mask_iou_cache = _mask_iou(masks, crowd_masks, iscrowd=True)
332              crowd_bbox_iou_cache = _bbox_iou(boxes.float(), crowd_boxes.float(), iscrowd=True)
333          else:
334              crowd_mask_iou_cache = None
335              crowd_bbox_iou_cache = None
336          box_indices = sorted(range(num_pred), key=lambda i: -box_scores[i])
337          mask_indices = sorted(box_indices, key=lambda i: -mask_scores[i])
338          iou_types = [
339              (&#x27;box&#x27;,  lambda i,j: bbox_iou_cache[i, j].item(),
340                       lambda i,j: crowd_bbox_iou_cache[i,j].item(),
341                       lambda i: box_scores[i], box_indices),
342              (&#x27;mask&#x27;, lambda i,j: mask_iou_cache[i, j].item(),
343                       lambda i,j: crowd_mask_iou_cache[i,j].item(),
344                       lambda i: mask_scores[i], mask_indices)
345          ]
346      timer.start(&#x27;Main loop&#x27;)
347      for _class in set(classes + gt_classes):
348          ap_per_iou = []
349          num_gt_for_class = sum([1 for x in gt_classes if x == _class])
350          for iouIdx in range(len(iou_thresholds)):
351              iou_threshold = iou_thresholds[iouIdx]
352              for iou_type, iou_func, crowd_func, score_func, indices in iou_types:
353                  gt_used = [False] * len(gt_classes)
354                  ap_obj = ap_data[iou_type][iouIdx][_class]
355                  ap_obj.add_gt_positives(num_gt_for_class)
356                  for i in indices:
357                      if classes[i] != _class:
358                          continue
359                      max_iou_found = iou_threshold
360                      max_match_idx = -1
361                      for j in range(num_gt):
362                          if gt_used[j] or gt_classes[j] != _class:
363                              continue
364                          iou = iou_func(i, j)
365                          if iou &gt; max_iou_found:
366                              max_iou_found = iou
367                              max_match_idx = j
368                      if max_match_idx &gt;= 0:
369                          gt_used[max_match_idx] = True
370                          ap_obj.push(score_func(i), True)
371                      else:
372                          matched_crowd = False
373                          if num_crowd &gt; 0:
374                              for j in range(len(crowd_classes)):
375                                  if crowd_classes[j] != _class:
376                                      continue
377                                  iou = crowd_func(i, j)
378                                  if iou &gt; iou_threshold:
379                                      matched_crowd = True
380                                      break
381                          if not matched_crowd:
382                              ap_obj.push(score_func(i), False)
383      timer.stop(&#x27;Main loop&#x27;)
384  class APDataObject:
385      def __init__(self):
386          self.data_points = []
387          self.num_gt_positives = 0
388      def push(self, score:float, is_true:bool):
389          self.data_points.append((score, is_true))
390      def add_gt_positives(self, num_positives:int):
391          self.num_gt_positives += num_positives
392      def is_empty(self) -&gt; bool:
393          return len(self.data_points) == 0 and self.num_gt_positives == 0
394      def get_ap(self) -&gt; float:
395          if self.num_gt_positives == 0:
396              return 0
397          self.data_points.sort(key=lambda x: -x[0])
398          precisions = []
399          recalls    = []
400          num_true  = 0
401          num_false = 0
402          for datum in self.data_points:
403              if datum[1]: num_true += 1
404              else: num_false += 1
405              precision = num_true / (num_true + num_false)
406              recall    = num_true / self.num_gt_positives
407              precisions.append(precision)
408              recalls.append(recall)
409          for i in range(len(precisions)-1, 0, -1):
410              if precisions[i] &gt; precisions[i-1]:
411                  precisions[i-1] = precisions[i]
412          y_range = [0] * 101 # idx 0 is recall == 0.0 and idx 100 is recall == 1.00
413          x_range = np.array([x / 100 for x in range(101)])
414          recalls = np.array(recalls)
415          indices = np.searchsorted(recalls, x_range, side=&#x27;left&#x27;)
416          for bar_idx, precision_idx in enumerate(indices):
417              if precision_idx &lt; len(precisions):
418                  y_range[bar_idx] = precisions[precision_idx]
419          return sum(y_range) / len(y_range)
420  def badhash(x):
421      x = (((x &gt;&gt; 16) ^ x) * 0x045d9f3b) &amp; 0xFFFFFFFF
422      x = (((x &gt;&gt; 16) ^ x) * 0x045d9f3b) &amp; 0xFFFFFFFF
423      x =  ((x &gt;&gt; 16) ^ x) &amp; 0xFFFFFFFF
424      return x
425  def evalimage(net:Yolact, path:str, save_path:str=None):
426      frame = torch.from_numpy(cv2.imread(path)).cuda().float()
427      batch = FastBaseTransform()(frame.unsqueeze(0))
428      preds = net(batch)
429      img_numpy = prep_display(preds, frame, None, None, undo_transform=False)
430      if save_path is None:
431          img_numpy = img_numpy[:, :, (2, 1, 0)]
432      if save_path is None:
433          plt.imshow(img_numpy)
434          plt.title(path)
435          plt.show()
436      else:
437          cv2.imwrite(save_path, img_numpy)
438  def evalimages(net:Yolact, input_folder:str, output_folder:str):
439      if not os.path.exists(output_folder):
440          os.mkdir(output_folder)
441      print()
442      for p in Path(input_folder).glob(&#x27;*&#x27;): 
443          path = str(p)
444          name = os.path.basename(path)
445          name = &#x27;.&#x27;.join(name.split(&#x27;.&#x27;)[:-1]) + &#x27;.png&#x27;
446          out_path = os.path.join(output_folder, name)
447          evalimage(net, path, out_path)
448          print(path + &#x27; -&gt; &#x27; + out_path)
449      print(&#x27;Done.&#x27;)
450  from multiprocessing.pool import ThreadPool
451  from queue import Queue
452  class CustomDataParallel(torch.nn.DataParallel):
453      def gather(self, outputs, output_device):
454          return sum(outputs, [])
455  def evalvideo(net:Yolact, path:str, out_path:str=None):
456      is_webcam = path.isdigit()
457      cudnn.benchmark = True
458      if is_webcam:
459          vid = cv2.VideoCapture(int(path))
460      else:
<span onclick='openModal()' class='match'>461          vid = cv2.VideoCapture(path)
462      if not vid.isOpened():
463          print(&#x27;Could not open video &quot;%s&quot;&#x27; % path)
</span>464          exit(-1)
465      target_fps   = round(vid.get(cv2.CAP_PROP_FPS))
466      frame_width  = round(vid.get(cv2.CAP_PROP_FRAME_WIDTH))
467      frame_height = round(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
468      if is_webcam:
469          num_frames = float(&#x27;inf&#x27;)
470      else:
471          num_frames = round(vid.get(cv2.CAP_PROP_FRAME_COUNT))
472      net = CustomDataParallel(net).cuda()
473      transform = torch.nn.DataParallel(FastBaseTransform()).cuda()
474      frame_times = MovingAverage(100)
475      fps = 0
476      frame_time_target = 1 / target_fps
477      running = True
478      fps_str = &#x27;&#x27;
479      vid_done = False
480      frames_displayed = 0
481      if out_path is not None:
482          out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*&quot;mp4v&quot;), target_fps, (frame_width, frame_height))
483      def cleanup_and_exit():
484          print()
485          pool.terminate()
486          vid.release()
487          if out_path is not None:
488              out.release()
489          cv2.destroyAllWindows()
490          exit()
491      def get_next_frame(vid):
492          frames = []
493          for idx in range(args.video_multiframe):
494              frame = vid.read()[1]
495              if frame is None:
496                  return frames
497              frames.append(frame)
498          return frames
499      def transform_frame(frames):
500          with torch.no_grad():
501              frames = [torch.from_numpy(frame).cuda().float() for frame in frames]
502              return frames, transform(torch.stack(frames, 0))
503      def eval_network(inp):
504          with torch.no_grad():
505              frames, imgs = inp
506              num_extra = 0
507              while imgs.size(0) &lt; args.video_multiframe:
508                  imgs = torch.cat([imgs, imgs[0].unsqueeze(0)], dim=0)
509                  num_extra += 1
510              out = net(imgs)
511              if num_extra &gt; 0:
512                  out = out[:-num_extra]
513              return frames, out
514      def prep_frame(inp, fps_str):
515          with torch.no_grad():
516              frame, preds = inp
517              return prep_display(preds, frame, None, None, undo_transform=False, class_color=True, fps_str=fps_str)
518      frame_buffer = Queue()
519      video_fps = 0
520      def play_video():
521          try:
522              nonlocal frame_buffer, running, video_fps, is_webcam, num_frames, frames_displayed, vid_done
523              video_frame_times = MovingAverage(100)
524              frame_time_stabilizer = frame_time_target
525              last_time = None
526              stabilizer_step = 0.0005
527              progress_bar = ProgressBar(30, num_frames)
528              while running:
529                  frame_time_start = time.time()
530                  if not frame_buffer.empty():
531                      next_time = time.time()
532                      if last_time is not None:
533                          video_frame_times.add(next_time - last_time)
534                          video_fps = 1 / video_frame_times.get_avg()
535                      if out_path is None:
536                          cv2.imshow(path, frame_buffer.get())
537                      else:
538                          out.write(frame_buffer.get())
539                      frames_displayed += 1
540                      last_time = next_time
541                      if out_path is not None:
542                          if video_frame_times.get_avg() == 0:
543                              fps = 0
544                          else:
545                              fps = 1 / video_frame_times.get_avg()
546                          progress = frames_displayed / num_frames * 100
547                          progress_bar.set_val(frames_displayed)
548                          print(&#x27;\rProcessing Frames  %s %6d / %6d (%5.2f%%)    %5.2f fps        &#x27;
549                              % (repr(progress_bar), frames_displayed, num_frames, progress, fps), end=&#x27;&#x27;)
550                  if out_path is None and cv2.waitKey(1) == 27:
551                      running = False
552                  if not (frames_displayed &lt; num_frames):
553                      running = False
554                  if not vid_done:
555                      buffer_size = frame_buffer.qsize()
556                      if buffer_size &lt; args.video_multiframe:
557                          frame_time_stabilizer += stabilizer_step
558                      elif buffer_size &gt; args.video_multiframe:
559                          frame_time_stabilizer -= stabilizer_step
560                          if frame_time_stabilizer &lt; 0:
561                              frame_time_stabilizer = 0
562                      new_target = frame_time_stabilizer if is_webcam else max(frame_time_stabilizer, frame_time_target)
563                  else:
564                      new_target = frame_time_target
565                  next_frame_target = max(2 * new_target - video_frame_times.get_avg(), 0)
566                  target_time = frame_time_start + next_frame_target - 0.001 # Let&#x27;s just subtract a millisecond to be safe
567                  if out_path is None or args.emulate_playback:
568                      while time.time() &lt; target_time:
569                          time.sleep(0.001)
570                  else:
571                      time.sleep(0.001)
572          except:
573              import traceback
574              traceback.print_exc()
575      extract_frame = lambda x, i: (x[0][i] if x[1][i][&#x27;detection&#x27;] is None else x[0][i].to(x[1][i][&#x27;detection&#x27;][&#x27;box&#x27;].device), [x[1][i]])
576      print(&#x27;Initializing model... &#x27;, end=&#x27;&#x27;)
577      first_batch = eval_network(transform_frame(get_next_frame(vid)))
578      print(&#x27;Done.&#x27;)
579      sequence = [prep_frame, eval_network, transform_frame]
580      pool = ThreadPool(processes=len(sequence) + args.video_multiframe + 2)
581      pool.apply_async(play_video)
582      active_frames = [{&#x27;value&#x27;: extract_frame(first_batch, i), &#x27;idx&#x27;: 0} for i in range(len(first_batch[0]))]
583      print()
584      if out_path is None: print(&#x27;Press Escape to close.&#x27;)
585      try:
586          while vid.isOpened() and running:
587              while frame_buffer.qsize() &gt; 100:
588                  time.sleep(0.001)
589              start_time = time.time()
590              if not vid_done:
591                  next_frames = pool.apply_async(get_next_frame, args=(vid,))
592              else:
593                  next_frames = None
594              if not (vid_done and len(active_frames) == 0):
595                  for frame in active_frames:
596                      _args =  [frame[&#x27;value&#x27;]]
597                      if frame[&#x27;idx&#x27;] == 0:
598                          _args.append(fps_str)
599                      frame[&#x27;value&#x27;] = pool.apply_async(sequence[frame[&#x27;idx&#x27;]], args=_args)
600                  for frame in active_frames:
601                      if frame[&#x27;idx&#x27;] == 0:
602                          frame_buffer.put(frame[&#x27;value&#x27;].get())
603                  active_frames = [x for x in active_frames if x[&#x27;idx&#x27;] &gt; 0]
604                  for frame in list(reversed(active_frames)):
605                      frame[&#x27;value&#x27;] = frame[&#x27;value&#x27;].get()
606                      frame[&#x27;idx&#x27;] -= 1
607                      if frame[&#x27;idx&#x27;] == 0:
608                          active_frames += [{&#x27;value&#x27;: extract_frame(frame[&#x27;value&#x27;], i), &#x27;idx&#x27;: 0} for i in range(1, len(frame[&#x27;value&#x27;][0]))]
609                          frame[&#x27;value&#x27;] = extract_frame(frame[&#x27;value&#x27;], 0)
610                  if next_frames is not None:
611                      frames = next_frames.get()
612                      if len(frames) == 0:
613                          vid_done = True
614                      else:
615                          active_frames.append({&#x27;value&#x27;: frames, &#x27;idx&#x27;: len(sequence)-1})
616                  frame_times.add(time.time() - start_time)
617                  fps = args.video_multiframe / frame_times.get_avg()
618              else:
619                  fps = 0
620              fps_str = &#x27;Processing FPS: %.2f | Video Playback FPS: %.2f | Frames in Buffer: %d&#x27; % (fps, video_fps, frame_buffer.qsize())
621              if not args.display_fps:
622                  print(&#x27;\r&#x27; + fps_str + &#x27;    &#x27;, end=&#x27;&#x27;)
623      except KeyboardInterrupt:
624          print(&#x27;\nStopping...&#x27;)
625      cleanup_and_exit()
626  def evaluate(net:Yolact, dataset, train_mode=False):
627      net.detect.use_fast_nms = args.fast_nms
628      net.detect.use_cross_class_nms = args.cross_class_nms
629      cfg.mask_proto_debug = args.mask_proto_debug
630      if args.image is not None:
631          if &#x27;:&#x27; in args.image:
632              inp, out = args.image.split(&#x27;:&#x27;)
633              evalimage(net, inp, out)
634          else:
635              evalimage(net, args.image)
636          return
637      elif args.images is not None:
638          inp, out = args.images.split(&#x27;:&#x27;)
639          evalimages(net, inp, out)
640          return
641      elif args.video is not None:
642          if &#x27;:&#x27; in args.video:
643              inp, out = args.video.split(&#x27;:&#x27;)
644              evalvideo(net, inp, out)
645          else:
646              evalvideo(net, args.video)
647          return
648      frame_times = MovingAverage()
649      dataset_size = len(dataset) if args.max_images &lt; 0 else min(args.max_images, len(dataset))
650      progress_bar = ProgressBar(30, dataset_size)
651      print()
652      if not args.display and not args.benchmark:
653          ap_data = {
654              &#x27;box&#x27; : [[APDataObject() for _ in cfg.dataset.class_names] for _ in iou_thresholds],
655              &#x27;mask&#x27;: [[APDataObject() for _ in cfg.dataset.class_names] for _ in iou_thresholds]
656          }
657          detections = Detections()
658      else:
659          timer.disable(&#x27;Load Data&#x27;)
660      dataset_indices = list(range(len(dataset)))
661      if args.shuffle:
662          random.shuffle(dataset_indices)
663      elif not args.no_sort:
664          hashed = [badhash(x) for x in dataset.ids]
665          dataset_indices.sort(key=lambda x: hashed[x])
666      dataset_indices = dataset_indices[:dataset_size]
667      try:
668          for it, image_idx in enumerate(dataset_indices):
669              timer.reset()
670              with timer.env(&#x27;Load Data&#x27;):
671                  img, gt, gt_masks, h, w, num_crowd = dataset.pull_item(image_idx)
672                  if cfg.mask_proto_debug:
673                      with open(&#x27;scripts/info.txt&#x27;, &#x27;w&#x27;) as f:
674                          f.write(str(dataset.ids[image_idx]))
675                      np.save(&#x27;scripts/gt.npy&#x27;, gt_masks)
676                  batch = Variable(img.unsqueeze(0))
677                  if args.cuda:
678                      batch = batch.cuda()
679              with timer.env(&#x27;Network Extra&#x27;):
680                  preds = net(batch)
681              if args.display:
682                  img_numpy = prep_display(preds, img, h, w)
683              elif args.benchmark:
684                  prep_benchmark(preds, h, w)
685              else:
686                  prep_metrics(ap_data, preds, img, gt, gt_masks, h, w, num_crowd, dataset.ids[image_idx], detections)
687              if it &gt; 1:
688                  frame_times.add(timer.total_time())
689              if args.display:
690                  if it &gt; 1:
691                      print(&#x27;Avg FPS: %.4f&#x27; % (1 / frame_times.get_avg()))
692                  plt.imshow(img_numpy)
693                  plt.title(str(dataset.ids[image_idx]))
694                  plt.show()
695              elif not args.no_bar:
696                  if it &gt; 1: fps = 1 / frame_times.get_avg()
697                  else: fps = 0
698                  progress = (it+1) / dataset_size * 100
699                  progress_bar.set_val(it+1)
700                  print(&#x27;\rProcessing Images  %s %6d / %6d (%5.2f%%)    %5.2f fps        &#x27;
701                      % (repr(progress_bar), it+1, dataset_size, progress, fps), end=&#x27;&#x27;)
702          if not args.display and not args.benchmark:
703              print()
704              if args.output_coco_json:
705                  print(&#x27;Dumping detections...&#x27;)
706                  if args.output_web_json:
707                      detections.dump_web()
708                  else:
709                      detections.dump()
710              else:
711                  if not train_mode:
712                      print(&#x27;Saving data...&#x27;)
713                      with open(args.ap_data_file, &#x27;wb&#x27;) as f:
714                          pickle.dump(ap_data, f)
715                  return calc_map(ap_data)
716          elif args.benchmark:
717              print()
718              print()
719              print(&#x27;Stats for the last frame:&#x27;)
720              timer.print_stats()
721              avg_seconds = frame_times.get_avg()
722              print(&#x27;Average: %5.2f fps, %5.2f ms&#x27; % (1 / frame_times.get_avg(), 1000*avg_seconds))
723      except KeyboardInterrupt:
724          print(&#x27;Stopping...&#x27;)
725  def calc_map(ap_data):
726      print(&#x27;Calculating mAP...&#x27;)
727      aps = [{&#x27;box&#x27;: [], &#x27;mask&#x27;: []} for _ in iou_thresholds]
728      for _class in range(len(cfg.dataset.class_names)):
729          for iou_idx in range(len(iou_thresholds)):
730              for iou_type in (&#x27;box&#x27;, &#x27;mask&#x27;):
731                  ap_obj = ap_data[iou_type][iou_idx][_class]
732                  if not ap_obj.is_empty():
733                      aps[iou_idx][iou_type].append(ap_obj.get_ap())
734      all_maps = {&#x27;box&#x27;: OrderedDict(), &#x27;mask&#x27;: OrderedDict()}
735      for iou_type in (&#x27;box&#x27;, &#x27;mask&#x27;):
736          all_maps[iou_type][&#x27;all&#x27;] = 0 # Make this first in the ordereddict
737          for i, threshold in enumerate(iou_thresholds):
738              mAP = sum(aps[i][iou_type]) / len(aps[i][iou_type]) * 100 if len(aps[i][iou_type]) &gt; 0 else 0
739              all_maps[iou_type][int(threshold*100)] = mAP
740          all_maps[iou_type][&#x27;all&#x27;] = (sum(all_maps[iou_type].values()) / (len(all_maps[iou_type].values())-1))
741      print_maps(all_maps)
742      all_maps = {k: {j: round(u, 2) for j, u in v.items()} for k, v in all_maps.items()}
743      return all_maps
744  def print_maps(all_maps):
745      make_row = lambda vals: (&#x27; %5s |&#x27; * len(vals)) % tuple(vals)
746      make_sep = lambda n:  (&#x27;-------+&#x27; * n)
747      print()
748      print(make_row([&#x27;&#x27;] + [(&#x27;.%d &#x27; % x if isinstance(x, int) else x + &#x27; &#x27;) for x in all_maps[&#x27;box&#x27;].keys()]))
749      print(make_sep(len(all_maps[&#x27;box&#x27;]) + 1))
750      for iou_type in (&#x27;box&#x27;, &#x27;mask&#x27;):
751          print(make_row([iou_type] + [&#x27;%.2f&#x27; % x if x &lt; 100 else &#x27;%.1f&#x27; % x for x in all_maps[iou_type].values()]))
752      print(make_sep(len(all_maps[&#x27;box&#x27;]) + 1))
753      print()
754  if __name__ == &#x27;__main__&#x27;:
755      parse_args()
756      if args.config is not None:
757          set_cfg(args.config)
758      if args.trained_model == &#x27;interrupt&#x27;:
759          args.trained_model = SavePath.get_interrupt(&#x27;weights/&#x27;)
760      elif args.trained_model == &#x27;latest&#x27;:
761          args.trained_model = SavePath.get_latest(&#x27;weights/&#x27;, cfg.name)
762      if args.config is None:
763          model_path = SavePath.from_str(args.trained_model)
764          args.config = model_path.model_name + &#x27;_config&#x27;
765          print(&#x27;Config not specified. Parsed %s from the file name.\n&#x27; % args.config)
766          set_cfg(args.config)
767      if args.detect:
768          cfg.eval_mask_branch = False
769      if args.dataset is not None:
770          set_dataset(args.dataset)
771      with torch.no_grad():
772          if not os.path.exists(&#x27;results&#x27;):
773              os.makedirs(&#x27;results&#x27;)
774          if args.cuda:
775              cudnn.fastest = True
776              torch.set_default_tensor_type(&#x27;torch.cuda.FloatTensor&#x27;)
777          else:
778              torch.set_default_tensor_type(&#x27;torch.FloatTensor&#x27;)
779          if args.resume and not args.display:
780              with open(args.ap_data_file, &#x27;rb&#x27;) as f:
781                  ap_data = pickle.load(f)
782              calc_map(ap_data)
783              exit()
784          if args.image is None and args.video is None and args.images is None:
785              dataset = COCODetection(cfg.dataset.valid_images, cfg.dataset.valid_info,
786                                      transform=BaseTransform(), has_gt=cfg.dataset.has_gt)
787              prep_coco_cats()
788          else:
789              dataset = None        
790          print(&#x27;Loading model...&#x27;, end=&#x27;&#x27;)
791          net = Yolact()
792          net.load_weights(args.trained_model)
793          net.eval()
794          print(&#x27; Done.&#x27;)
795          if args.cuda:
796              net = net.cuda()
797          evaluate(net, dataset)
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-fields_15.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-eval.py</div>
                </div>
                <div class="column column_space"><pre><code>278          bindata = binascii.unhexlify(hexad)
279          if not self.is_field_calculated():
280              if esptool.util.byte(bindata, 0) &amp; 0x01:
</pre></code></div>
                <div class="column column_space"><pre><code>461          vid = cv2.VideoCapture(path)
462      if not vid.isOpened():
463          print(&#x27;Could not open video &quot;%s&quot;&#x27; % path)
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    