
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 3.6072144288577155%, Tokens: 9</h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-beam_search_decoder.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  from collections import namedtuple
6  import tensorflow as tf
7  from tensorflow.python.util import nest  # pylint: disable=E0611
8  from seq2seq.inference import beam_search
9  from seq2seq.decoders.rnn_decoder import RNNDecoder
10  class FinalBeamDecoderOutput(
11      namedtuple("FinalBeamDecoderOutput",
12                 ["predicted_ids", "beam_search_output"])):
13    pass
14  class BeamDecoderOutput(
15      namedtuple("BeamDecoderOutput", [
16          "logits", "predicted_ids", "log_probs", "scores", "beam_parent_ids",
17          "original_outputs"
18      ])):
19    pass
20  class BeamSearchDecoder(RNNDecoder):
21    def __init__(self, decoder, config):
22      super(BeamSearchDecoder, self).__init__(decoder.params, decoder.mode,
23                                              decoder.name)
24      self.decoder = decoder
25      self.config = config
26    def __call__(self, *args, **kwargs):
27      with self.decoder.variable_scope():
28        return self._build(*args, **kwargs)
29    @property
30    def output_size(self):
31      return BeamDecoderOutput(
32          logits=self.decoder.vocab_size,
<span onclick='openModal()' class='match'>33          predicted_ids=tf.TensorShape([]),
34          log_probs=tf.TensorShape([]),
35          scores=tf.TensorShape([]),
</span>36          beam_parent_ids=tf.TensorShape([]),
37          original_outputs=self.decoder.output_size)
38    @property
39    def output_dtype(self):
40      return BeamDecoderOutput(
41          logits=tf.float32,
42          predicted_ids=tf.int32,
43          log_probs=tf.float32,
44          scores=tf.float32,
45          beam_parent_ids=tf.int32,
46          original_outputs=self.decoder.output_dtype)
47    @property
48    def batch_size(self):
49      return self.config.beam_width
50    def initialize(self, name=None):
51      finished, first_inputs, initial_state = self.decoder.initialize()
52      beam_state = beam_search.create_initial_beam_state(config=self.config)
53      return finished, first_inputs, (initial_state, beam_state)
54    def finalize(self, outputs, final_state):
55      predicted_ids = beam_search.gather_tree(outputs.predicted_ids,
56                                              outputs.beam_parent_ids)
57      outputs = nest.map_structure(lambda x: tf.expand_dims(x, 1), outputs)
58      final_outputs = FinalBeamDecoderOutput(
59          predicted_ids=tf.expand_dims(predicted_ids, 1),
60          beam_search_output=outputs)
61      return final_outputs, final_state
62    def _build(self, initial_state, helper):
63      initial_state = nest.map_structure(
64          lambda x: tf.tile(x, [self.batch_size, 1]), initial_state)
65      self.decoder._setup(initial_state, helper)  #pylint: disable=W0212
66      return super(BeamSearchDecoder, self)._build(self.decoder.initial_state,
67                                                   self.decoder.helper)
68    def step(self, time_, inputs, state, name=None):
69      decoder_state, beam_state = state
70      (decoder_output, decoder_state, _, _) = self.decoder.step(time_, inputs,
71                                                                decoder_state)
72      bs_output, beam_state = beam_search.beam_search_step(
73          time_=time_,
74          logits=decoder_output.logits,
75          beam_state=beam_state,
76          config=self.config)
77      decoder_state = nest.map_structure(
78          lambda x: tf.gather(x, bs_output.beam_parent_ids), decoder_state)
79      decoder_output = nest.map_structure(
80          lambda x: tf.gather(x, bs_output.beam_parent_ids), decoder_output)
81      next_state = (decoder_state, beam_state)
82      outputs = BeamDecoderOutput(
83          logits=tf.zeros([self.config.beam_width, self.config.vocab_size]),
84          predicted_ids=bs_output.predicted_ids,
85          log_probs=beam_state.log_probs,
86          scores=bs_output.scores,
87          beam_parent_ids=bs_output.beam_parent_ids,
88          original_outputs=decoder_output)
89      finished, next_inputs, next_state = self.decoder.helper.next_inputs(
90          time=time_,
91          outputs=decoder_output,
92          state=next_state,
93          sample_ids=bs_output.predicted_ids)
94      next_inputs.set_shape([self.batch_size, None])
95      return (outputs, next_state, next_inputs, finished)
</code></pre>
        </div>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-bbox_recall.py</h3>
            <pre><code>1  import os.path as osp
2  import json, pickle
3  import sys
4  from math import sqrt
5  from itertools import product
6  import torch
7  import random
8  import numpy as np
9  dump_file = 'weights/bboxes.pkl'
10  aug_file  = 'weights/bboxes_aug.pkl'
11  use_augmented_boxes = True
12  def intersect(box_a, box_b):
<span onclick='openModal()' class='match'>13      A = box_a.size(0)
14      B = box_b.size(0)
15      max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),
</span>16                         box_b[:, 2:].unsqueeze(0).expand(A, B, 2))
17      min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),
18                         box_b[:, :2].unsqueeze(0).expand(A, B, 2))
19      inter = torch.clamp((max_xy - min_xy), min=0)
20      return inter[:, :, 0] * inter[:, :, 1]
21  def jaccard(box_a, box_b, iscrowd=False):
22      inter = intersect(box_a, box_b)
23      area_a = ((box_a[:, 2]-box_a[:, 0]) *
24                (box_a[:, 3]-box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]
25      area_b = ((box_b[:, 2]-box_b[:, 0]) *
26                (box_b[:, 3]-box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]
27      union = area_a + area_b - inter
28      if iscrowd:
29          return inter / area_a
30      else:
31          return inter / union  # [A,B]
32  def to_relative(bboxes):
33      return np.concatenate((bboxes[:, 2:4] / bboxes[:, :2], (bboxes[:, 2:4] + bboxes[:, 4:]) / bboxes[:, :2]), axis=1)
34  def make_priors(conv_size, scales, aspect_ratios):
35      prior_data = []
36      conv_h = conv_size[0]
37      conv_w = conv_size[1]
38      for j, i in product(range(conv_h), range(conv_w)):
39          x = (i + 0.5) / conv_w
40          y = (j + 0.5) / conv_h
41          for scale, ars in zip(scales, aspect_ratios):
42              for ar in ars:
43                  w = scale * ar / conv_w
44                  h = scale / ar / conv_h
45                  prior_data += [x - w/2, y - h/2, x + w/2, y + h/2]
46      return np.array(prior_data).reshape(-1, 4)
47  scales = [[1.68, 2.91],
48            [2.95, 2.22, 0.84],
49            [2.23, 2.17, 3.12],
50            [0.76, 1.94, 2.72],
51            [2.10, 2.65],
52            [1.80, 1.92]]
53  aspect_ratios = [[[0.72, 0.96], [0.68, 1.17]],
54                   [[1.28, 0.66], [0.63, 1.23], [0.89, 1.40]],
55                   [[2.05, 1.24], [0.57, 0.83], [0.61, 1.15]],
56                   [[1.00, 2.21], [0.47, 1.60], [1.44, 0.79]],
57                   [[1.00, 1.41, 0.71, 1.73, 0.58], [1.08]],
58                   [[1.00, 1.41, 0.71, 1.73, 0.58], [1.00]]]
59  conv_sizes = [(35, 35), (18, 18), (9, 9), (5, 5), (3, 3), (2, 2)]
60  SMALL = 0
61  MEDIUM = 1
62  LARGE = 2
63  if __name__ == '__main__':
64      with open(dump_file, 'rb') as f:
65          bboxes = pickle.load(f)
66      sizes = []
67      smalls = []
68      for i in range(len(bboxes)):
69          area = bboxes[i][4] * bboxes[i][5]
70          if area < 32 ** 2:
71              sizes.append(SMALL)
72              smalls.append(area)
73          elif area < 96 ** 2:
74              sizes.append(MEDIUM)
75          else:
76              sizes.append(LARGE)
77      if use_augmented_boxes:
78          with open(aug_file, 'rb') as f:
79              bboxes_rel = pickle.load(f)
80      else:
81          bboxes_rel = to_relative(np.array(bboxes))
82      with torch.no_grad():
83          sizes = torch.Tensor(sizes)
84          anchors = [make_priors(cs, s, ar) for cs, s, ar in zip(conv_sizes, scales, aspect_ratios)]
85          anchors = np.concatenate(anchors, axis=0)
86          anchors = torch.Tensor(anchors).cuda()
87          bboxes_rel = torch.Tensor(bboxes_rel).cuda()
88          perGTAnchorMax = torch.zeros(bboxes_rel.shape[0]).cuda()
89          chunk_size = 1000
90          for i in range((bboxes_rel.size(0) // chunk_size) + 1):
91              start = i * chunk_size
92              end   = min((i + 1) * chunk_size, bboxes_rel.size(0))
93              ious = jaccard(bboxes_rel[start:end, :], anchors)
94              maxes, maxidx = torch.max(ious, dim=1)
95              perGTAnchorMax[start:end] = maxes
96          hits = (perGTAnchorMax > 0.5).float()
97          print('Total recall: %.2f' % (torch.sum(hits) / hits.size(0) * 100))
98          print()
99          for i, metric in zip(range(3), ('small', 'medium', 'large')):
100              _hits = hits[sizes == i]
101              _size = (1 if _hits.size(0) == 0 else _hits.size(0))
102              print(metric + ' recall: %.2f' % ((torch.sum(_hits) / _size) * 100))
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-beam_search_decoder.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-bbox_recall.py</div>
                </div>
                <div class="column column_space"><pre><code>33          predicted_ids=tf.TensorShape([]),
34          log_probs=tf.TensorShape([]),
35          scores=tf.TensorShape([]),
</pre></code></div>
                <div class="column column_space"><pre><code>13      A = box_a.size(0)
14      B = box_b.size(0)
15      max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    