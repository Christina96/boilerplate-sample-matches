
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 11.213850088530396%, Tokens: 9</h2>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-multibox_loss.py</h3>
            <pre><code>1  import torch
2  import torch.nn as nn
3  import torch.nn.functional as F
4  from torch.autograd import Variable
5  from ..box_utils import match, log_sum_exp, decode, center_size, crop, elemwise_mask_iou, elemwise_box_iou
6  from data import cfg, mask_type, activation_func
7  class MultiBoxLoss(nn.Module):
8      def __init__(self, num_classes, pos_threshold, neg_threshold, negpos_ratio):
9          super(MultiBoxLoss, self).__init__()
10          self.num_classes = num_classes
11          self.pos_threshold = pos_threshold
12          self.neg_threshold = neg_threshold
13          self.negpos_ratio = negpos_ratio
14          self.l1_expected_area = 20*20/70/70
15          self.l1_alpha = 0.1
16          if cfg.use_class_balanced_conf:
17              self.class_instances = None
18              self.total_instances = 0
19      def forward(self, net, predictions, targets, masks, num_crowds):
20          loc_data  = predictions['loc']
21          conf_data = predictions['conf']
22          mask_data = predictions['mask']
23          priors    = predictions['priors']
24          if cfg.mask_type == mask_type.lincomb:
25              proto_data = predictions['proto']
26          score_data = predictions['score'] if cfg.use_mask_scoring   else None   
27          inst_data  = predictions['inst']  if cfg.use_instance_coeff else None
28          labels = [None] * len(targets) # Used in sem segm loss
29          batch_size = loc_data.size(0)
30          num_priors = priors.size(0)
31          num_classes = self.num_classes
32          loc_t = loc_data.new(batch_size, num_priors, 4)
33          gt_box_t = loc_data.new(batch_size, num_priors, 4)
34          conf_t = loc_data.new(batch_size, num_priors).long()
35          idx_t = loc_data.new(batch_size, num_priors).long()
36          if cfg.use_class_existence_loss:
37              class_existence_t = loc_data.new(batch_size, num_classes-1)
38          for idx in range(batch_size):
39              truths      = targets[idx][:, :-1].data
40              labels[idx] = targets[idx][:, -1].data.long()
41              if cfg.use_class_existence_loss:
42                  class_existence_t[idx, :] = torch.eye(num_classes-1, device=conf_t.get_device())[labels[idx]].max(dim=0)[0]
43              cur_crowds = num_crowds[idx]
44              if cur_crowds > 0:
45                  split = lambda x: (x[-cur_crowds:], x[:-cur_crowds])
46                  crowd_boxes, truths = split(truths)
47                  _, labels[idx] = split(labels[idx])
48                  _, masks[idx]  = split(masks[idx])
49              else:
50                  crowd_boxes = None
51              match(self.pos_threshold, self.neg_threshold,
52                    truths, priors.data, labels[idx], crowd_boxes,
53                    loc_t, conf_t, idx_t, idx, loc_data[idx])
54              gt_box_t[idx, :, :] = truths[idx_t[idx]]
55          loc_t = Variable(loc_t, requires_grad=False)
56          conf_t = Variable(conf_t, requires_grad=False)
57          idx_t = Variable(idx_t, requires_grad=False)
58          pos = conf_t > 0
59          num_pos = pos.sum(dim=1, keepdim=True)
60          pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)
61          losses = {}
62          if cfg.train_boxes:
63              loc_p = loc_data[pos_idx].view(-1, 4)
64              loc_t = loc_t[pos_idx].view(-1, 4)
65              losses['B'] = F.smooth_l1_loss(loc_p, loc_t, reduction='sum') * cfg.bbox_alpha
66          if cfg.train_masks:
67              if cfg.mask_type == mask_type.direct:
68                  if cfg.use_gt_bboxes:
69                      pos_masks = []
70                      for idx in range(batch_size):
71                          pos_masks.append(masks[idx][idx_t[idx, pos[idx]]])
72                      masks_t = torch.cat(pos_masks, 0)
73                      masks_p = mask_data[pos, :].view(-1, cfg.mask_dim)
74                      losses['M'] = F.binary_cross_entropy(torch.clamp(masks_p, 0, 1), masks_t, reduction='sum') * cfg.mask_alpha
75                  else:
76                      losses['M'] = self.direct_mask_loss(pos_idx, idx_t, loc_data, mask_data, priors, masks)
77              elif cfg.mask_type == mask_type.lincomb:
78                  ret = self.lincomb_mask_loss(pos, idx_t, loc_data, mask_data, priors, proto_data, masks, gt_box_t, score_data, inst_data, labels)
79                  if cfg.use_maskiou:
80                      loss, maskiou_targets = ret
81                  else:
82                      loss = ret
83                  losses.update(loss)
84                  if cfg.mask_proto_loss is not None:
85                      if cfg.mask_proto_loss == 'l1':
86                          losses['P'] = torch.mean(torch.abs(proto_data)) / self.l1_expected_area * self.l1_alpha
87                      elif cfg.mask_proto_loss == 'disj':
88                          losses['P'] = -torch.mean(torch.max(F.log_softmax(proto_data, dim=-1), dim=-1)[0])
89          if cfg.use_focal_loss:
90              if cfg.use_sigmoid_focal_loss:
91                  losses['C'] = self.focal_conf_sigmoid_loss(conf_data, conf_t)
92              elif cfg.use_objectness_score:
93                  losses['C'] = self.focal_conf_objectness_loss(conf_data, conf_t)
94              else:
95                  losses['C'] = self.focal_conf_loss(conf_data, conf_t)
96          else:
97              if cfg.use_objectness_score:
98                  losses['C'] = self.conf_objectness_loss(conf_data, conf_t, batch_size, loc_p, loc_t, priors)
99              else:
100                  losses['C'] = self.ohem_conf_loss(conf_data, conf_t, pos, batch_size)
101          if cfg.use_maskiou and maskiou_targets is not None:
102              losses['I'] = self.mask_iou_loss(net, maskiou_targets)
103          if cfg.use_class_existence_loss:
104              losses['E'] = self.class_existence_loss(predictions['classes'], class_existence_t)
105          if cfg.use_semantic_segmentation_loss:
106              losses['S'] = self.semantic_segmentation_loss(predictions['segm'], masks, labels)
107          total_num_pos = num_pos.data.sum().float()
108          for k in losses:
109              if k not in ('P', 'E', 'S'):
110                  losses[k] /= total_num_pos
111              else:
112                  losses[k] /= batch_size
113          return losses
114      def class_existence_loss(self, class_data, class_existence_t):
115          return cfg.class_existence_alpha * F.binary_cross_entropy_with_logits(class_data, class_existence_t, reduction='sum')
116      def semantic_segmentation_loss(self, segment_data, mask_t, class_t, interpolation_mode='bilinear'):
117          batch_size, num_classes, mask_h, mask_w = segment_data.size()
118          loss_s = 0
119          for idx in range(batch_size):
120              cur_segment = segment_data[idx]
121              cur_class_t = class_t[idx]
122              with torch.no_grad():
123                  downsampled_masks = F.interpolate(mask_t[idx].unsqueeze(0), (mask_h, mask_w),
124                                                    mode=interpolation_mode, align_corners=False).squeeze(0)
125                  downsampled_masks = downsampled_masks.gt(0.5).float()
126                  segment_t = torch.zeros_like(cur_segment, requires_grad=False)
127                  for obj_idx in range(downsampled_masks.size(0)):
128                      segment_t[cur_class_t[obj_idx]] = torch.max(segment_t[cur_class_t[obj_idx]], downsampled_masks[obj_idx])
129              loss_s += F.binary_cross_entropy_with_logits(cur_segment, segment_t, reduction='sum')
130          return loss_s / mask_h / mask_w * cfg.semantic_segmentation_alpha
131      def ohem_conf_loss(self, conf_data, conf_t, pos, num):
132          batch_conf = conf_data.view(-1, self.num_classes)
133          if cfg.ohem_use_most_confident:
134              batch_conf = F.softmax(batch_conf, dim=1)
135              loss_c, _ = batch_conf[:, 1:].max(dim=1)
136          else:
137              loss_c = log_sum_exp(batch_conf) - batch_conf[:, 0]
138          loss_c = loss_c.view(num, -1)
139          loss_c[pos]        = 0 # filter out pos boxes
140          loss_c[conf_t < 0] = 0 # filter out neutrals (conf_t = -1)
141          _, loss_idx = loss_c.sort(1, descending=True)
142          _, idx_rank = loss_idx.sort(1)
143          num_pos = pos.long().sum(1, keepdim=True)
144          num_neg = torch.clamp(self.negpos_ratio*num_pos, max=pos.size(1)-1)
145          neg = idx_rank < num_neg.expand_as(idx_rank)
146          neg[pos]        = 0
147          neg[conf_t < 0] = 0 # Filter out neutrals
148          pos_idx = pos.unsqueeze(2).expand_as(conf_data)
149          neg_idx = neg.unsqueeze(2).expand_as(conf_data)
150          conf_p = conf_data[(pos_idx+neg_idx).gt(0)].view(-1, self.num_classes)
151          targets_weighted = conf_t[(pos+neg).gt(0)]
152          loss_c = F.cross_entropy(conf_p, targets_weighted, reduction='none')
153          if cfg.use_class_balanced_conf:
154              if self.class_instances is None:
155                  self.class_instances = torch.zeros(self.num_classes, device=targets_weighted.device)
156              classes, counts = targets_weighted.unique(return_counts=True)
157              for _cls, _cnt in zip(classes.cpu().numpy(), counts.cpu().numpy()):
158                  self.class_instances[_cls] += _cnt
<span onclick='openModal()' class='match'>159              self.total_instances += targets_weighted.size(0)
160              weighting = 1 - (self.class_instances[targets_weighted] / self.total_instances)
161              weighting = torch.clamp(weighting, min=1/self.num_classes)
</span>162              avg_weight = (self.num_classes - 1) / self.num_classes
163              loss_c = (loss_c * weighting).sum() / avg_weight
164          else:
165              loss_c = loss_c.sum()
166          return cfg.conf_alpha * loss_c
167      def focal_conf_loss(self, conf_data, conf_t):
168          conf_t = conf_t.view(-1) # [batch_size*num_priors]
169          conf_data = conf_data.view(-1, conf_data.size(-1)) # [batch_size*num_priors, num_classes]
170          keep = (conf_t >= 0).float()
171          conf_t[conf_t < 0] = 0 # so that gather doesn't drum up a fuss
172          logpt = F.log_softmax(conf_data, dim=-1)
173          logpt = logpt.gather(1, conf_t.unsqueeze(-1))
174          logpt = logpt.view(-1)
175          pt    = logpt.exp()
176          background = (conf_t == 0).float()
177          at = (1 - cfg.focal_loss_alpha) * background + cfg.focal_loss_alpha * (1 - background)
178          loss = -at * (1 - pt) ** cfg.focal_loss_gamma * logpt
179          return cfg.conf_alpha * (loss * keep).sum()
180      def focal_conf_sigmoid_loss(self, conf_data, conf_t):
181          num_classes = conf_data.size(-1)
182          conf_t = conf_t.view(-1) # [batch_size*num_priors]
183          conf_data = conf_data.view(-1, num_classes) # [batch_size*num_priors, num_classes]
184          keep = (conf_t >= 0).float()
185          conf_t[conf_t < 0] = 0 # can't mask with -1, so filter that out
186          conf_one_t = torch.eye(num_classes, device=conf_t.get_device())[conf_t]
187          conf_pm_t  = conf_one_t * 2 - 1 # -1 if background, +1 if forground for specific class
188          logpt = F.logsigmoid(conf_data * conf_pm_t) # note: 1 - sigmoid(x) = sigmoid(-x)
189          pt    = logpt.exp()
190          at = cfg.focal_loss_alpha * conf_one_t + (1 - cfg.focal_loss_alpha) * (1 - conf_one_t)
191          at[..., 0] = 0 # Set alpha for the background class to 0 because sigmoid focal loss doesn't use it
192          loss = -at * (1 - pt) ** cfg.focal_loss_gamma * logpt
193          loss = keep * loss.sum(dim=-1)
194          return cfg.conf_alpha * loss.sum()
195      def focal_conf_objectness_loss(self, conf_data, conf_t):
196          conf_t = conf_t.view(-1) # [batch_size*num_priors]
197          conf_data = conf_data.view(-1, conf_data.size(-1)) # [batch_size*num_priors, num_classes]
198          keep = (conf_t >= 0).float()
199          conf_t[conf_t < 0] = 0 # so that gather doesn't drum up a fuss
200          background = (conf_t == 0).float()
201          at = (1 - cfg.focal_loss_alpha) * background + cfg.focal_loss_alpha * (1 - background)
202          logpt = F.logsigmoid(conf_data[:, 0]) * (1 - background) + F.logsigmoid(-conf_data[:, 0]) * background
203          pt    = logpt.exp()
204          obj_loss = -at * (1 - pt) ** cfg.focal_loss_gamma * logpt
205          pos_mask = conf_t > 0
206          conf_data_pos = (conf_data[:, 1:])[pos_mask] # Now this has just 80 classes
207          conf_t_pos    = conf_t[pos_mask] - 1         # So subtract 1 here
208          class_loss = F.cross_entropy(conf_data_pos, conf_t_pos, reduction='sum')
209          return cfg.conf_alpha * (class_loss + (obj_loss * keep).sum())
210      def conf_objectness_loss(self, conf_data, conf_t, batch_size, loc_p, loc_t, priors):
211          conf_t = conf_t.view(-1) # [batch_size*num_priors]
212          conf_data = conf_data.view(-1, conf_data.size(-1)) # [batch_size*num_priors, num_classes]
213          pos_mask = (conf_t > 0)
214          neg_mask = (conf_t == 0)
215          obj_data = conf_data[:, 0]
216          obj_data_pos = obj_data[pos_mask]
217          obj_data_neg = obj_data[neg_mask]
218          obj_neg_loss = - F.logsigmoid(-obj_data_neg).sum()
219          with torch.no_grad():
220              pos_priors = priors.unsqueeze(0).expand(batch_size, -1, -1).reshape(-1, 4)[pos_mask, :]
221              boxes_pred = decode(loc_p, pos_priors, cfg.use_yolo_regressors)
222              boxes_targ = decode(loc_t, pos_priors, cfg.use_yolo_regressors)
223              iou_targets = elemwise_box_iou(boxes_pred, boxes_targ)
224          obj_pos_loss = - iou_targets * F.logsigmoid(obj_data_pos) - (1 - iou_targets) * F.logsigmoid(-obj_data_pos)
225          obj_pos_loss = obj_pos_loss.sum()
226          conf_data_pos = (conf_data[:, 1:])[pos_mask] # Now this has just 80 classes
227          conf_t_pos    = conf_t[pos_mask] - 1         # So subtract 1 here
228          class_loss = F.cross_entropy(conf_data_pos, conf_t_pos, reduction='sum')
229          return cfg.conf_alpha * (class_loss + obj_pos_loss + obj_neg_loss)
230      def direct_mask_loss(self, pos_idx, idx_t, loc_data, mask_data, priors, masks):
231          loss_m = 0
232          for idx in range(mask_data.size(0)):
233              with torch.no_grad():
234                  cur_pos_idx = pos_idx[idx, :, :]
235                  cur_pos_idx_squeezed = cur_pos_idx[:, 1]
236                  pos_bboxes = decode(loc_data[idx, :, :], priors.data, cfg.use_yolo_regressors)
237                  pos_bboxes = pos_bboxes[cur_pos_idx].view(-1, 4).clamp(0, 1)
238                  pos_lookup = idx_t[idx, cur_pos_idx_squeezed]
239                  cur_masks = masks[idx]
240                  pos_masks = cur_masks[pos_lookup, :, :]
241                  num_pos, img_height, img_width = pos_masks.size()
242                  x1, x2 = sanitize_coordinates(pos_bboxes[:, 0], pos_bboxes[:, 2], img_width)
243                  y1, y2 = sanitize_coordinates(pos_bboxes[:, 1], pos_bboxes[:, 3], img_height)
244                  scaled_masks = []
245                  for jdx in range(num_pos):
246                      tmp_mask = pos_masks[jdx, y1[jdx]:y2[jdx], x1[jdx]:x2[jdx]]
247                      while tmp_mask.dim() < 2:
248                          tmp_mask = tmp_mask.unsqueeze(0)
249                      new_mask = F.adaptive_avg_pool2d(tmp_mask.unsqueeze(0), cfg.mask_size)
250                      scaled_masks.append(new_mask.view(1, -1))
251                  mask_t = torch.cat(scaled_masks, 0).gt(0.5).float() # Threshold downsampled mask
252              pos_mask_data = mask_data[idx, cur_pos_idx_squeezed, :]
253              loss_m += F.binary_cross_entropy(torch.clamp(pos_mask_data, 0, 1), mask_t, reduction='sum') * cfg.mask_alpha
254          return loss_m
255      def coeff_diversity_loss(self, coeffs, instance_t):
256          num_pos = coeffs.size(0)
257          instance_t = instance_t.view(-1) # juuuust to make sure
258          coeffs_norm = F.normalize(coeffs, dim=1)
259          cos_sim = coeffs_norm @ coeffs_norm.t()
260          inst_eq = (instance_t[:, None].expand_as(cos_sim) == instance_t[None, :].expand_as(cos_sim)).float()
261          cos_sim = (cos_sim + 1) / 2
262          loss = (1 - cos_sim) * inst_eq + cos_sim * (1 - inst_eq)
263          return cfg.mask_proto_coeff_diversity_alpha * loss.sum() / num_pos
264      def lincomb_mask_loss(self, pos, idx_t, loc_data, mask_data, priors, proto_data, masks, gt_box_t, score_data, inst_data, labels, interpolation_mode='bilinear'):
265          mask_h = proto_data.size(1)
266          mask_w = proto_data.size(2)
267          process_gt_bboxes = cfg.mask_proto_normalize_emulate_roi_pooling or cfg.mask_proto_crop
268          if cfg.mask_proto_remove_empty_masks:
269              pos = pos.clone()
270          loss_m = 0
271          loss_d = 0 # Coefficient diversity loss
272          maskiou_t_list = []
273          maskiou_net_input_list = []
274          label_t_list = []
275          for idx in range(mask_data.size(0)):
276              with torch.no_grad():
277                  downsampled_masks = F.interpolate(masks[idx].unsqueeze(0), (mask_h, mask_w),
278                                                    mode=interpolation_mode, align_corners=False).squeeze(0)
279                  downsampled_masks = downsampled_masks.permute(1, 2, 0).contiguous()
280                  if cfg.mask_proto_binarize_downsampled_gt:
281                      downsampled_masks = downsampled_masks.gt(0.5).float()
282                  if cfg.mask_proto_remove_empty_masks:
283                      very_small_masks = (downsampled_masks.sum(dim=(0,1)) <= 0.0001)
284                      for i in range(very_small_masks.size(0)):
285                          if very_small_masks[i]:
286                              pos[idx, idx_t[idx] == i] = 0
287                  if cfg.mask_proto_reweight_mask_loss:
288                      if not cfg.mask_proto_binarize_downsampled_gt:
289                          bin_gt = downsampled_masks.gt(0.5).float()
290                      else:
291                          bin_gt = downsampled_masks
292                      gt_foreground_norm = bin_gt     / (torch.sum(bin_gt,   dim=(0,1), keepdim=True) + 0.0001)
293                      gt_background_norm = (1-bin_gt) / (torch.sum(1-bin_gt, dim=(0,1), keepdim=True) + 0.0001)
294                      mask_reweighting   = gt_foreground_norm * cfg.mask_proto_reweight_coeff + gt_background_norm
295                      mask_reweighting  *= mask_h * mask_w
296              cur_pos = pos[idx]
297              pos_idx_t = idx_t[idx, cur_pos]
298              if process_gt_bboxes:
299                  if cfg.mask_proto_crop_with_pred_box:
300                      pos_gt_box_t = decode(loc_data[idx, :, :], priors.data, cfg.use_yolo_regressors)[cur_pos]
301                  else:
302                      pos_gt_box_t = gt_box_t[idx, cur_pos]
303              if pos_idx_t.size(0) == 0:
304                  continue
305              proto_masks = proto_data[idx]
306              proto_coef  = mask_data[idx, cur_pos, :]
307              if cfg.use_mask_scoring:
308                  mask_scores = score_data[idx, cur_pos, :]
309              if cfg.mask_proto_coeff_diversity_loss:
310                  if inst_data is not None:
311                      div_coeffs = inst_data[idx, cur_pos, :]
312                  else:
313                      div_coeffs = proto_coef
314                  loss_d += self.coeff_diversity_loss(div_coeffs, pos_idx_t)
315              old_num_pos = proto_coef.size(0)
316              if old_num_pos > cfg.masks_to_train:
317                  perm = torch.randperm(proto_coef.size(0))
318                  select = perm[:cfg.masks_to_train]
319                  proto_coef = proto_coef[select, :]
320                  pos_idx_t  = pos_idx_t[select]
321                  if process_gt_bboxes:
322                      pos_gt_box_t = pos_gt_box_t[select, :]
323                  if cfg.use_mask_scoring:
324                      mask_scores = mask_scores[select, :]
325              num_pos = proto_coef.size(0)
326              mask_t = downsampled_masks[:, :, pos_idx_t]     
327              label_t = labels[idx][pos_idx_t]     
328              pred_masks = proto_masks @ proto_coef.t()
329              pred_masks = cfg.mask_proto_mask_activation(pred_masks)
330              if cfg.mask_proto_double_loss:
331                  if cfg.mask_proto_mask_activation == activation_func.sigmoid:
332                      pre_loss = F.binary_cross_entropy(torch.clamp(pred_masks, 0, 1), mask_t, reduction='sum')
333                  else:
334                      pre_loss = F.smooth_l1_loss(pred_masks, mask_t, reduction='sum')
335                  loss_m += cfg.mask_proto_double_loss_alpha * pre_loss
336              if cfg.mask_proto_crop:
337                  pred_masks = crop(pred_masks, pos_gt_box_t)
338              if cfg.mask_proto_mask_activation == activation_func.sigmoid:
339                  pre_loss = F.binary_cross_entropy(torch.clamp(pred_masks, 0, 1), mask_t, reduction='none')
340              else:
341                  pre_loss = F.smooth_l1_loss(pred_masks, mask_t, reduction='none')
342              if cfg.mask_proto_normalize_mask_loss_by_sqrt_area:
343                  gt_area  = torch.sum(mask_t, dim=(0, 1), keepdim=True)
344                  pre_loss = pre_loss / (torch.sqrt(gt_area) + 0.0001)
345              if cfg.mask_proto_reweight_mask_loss:
346                  pre_loss = pre_loss * mask_reweighting[:, :, pos_idx_t]
347              if cfg.mask_proto_normalize_emulate_roi_pooling:
348                  weight = mask_h * mask_w if cfg.mask_proto_crop else 1
349                  pos_gt_csize = center_size(pos_gt_box_t)
350                  gt_box_width  = pos_gt_csize[:, 2] * mask_w
351                  gt_box_height = pos_gt_csize[:, 3] * mask_h
352                  pre_loss = pre_loss.sum(dim=(0, 1)) / gt_box_width / gt_box_height * weight
353              if old_num_pos > num_pos:
354                  pre_loss *= old_num_pos / num_pos
355              loss_m += torch.sum(pre_loss)
356              if cfg.use_maskiou:
357                  if cfg.discard_mask_area > 0:
358                      gt_mask_area = torch.sum(mask_t, dim=(0, 1))
359                      select = gt_mask_area > cfg.discard_mask_area
360                      if torch.sum(select) < 1:
361                          continue
362                      pos_gt_box_t = pos_gt_box_t[select, :]
363                      pred_masks = pred_masks[:, :, select]
364                      mask_t = mask_t[:, :, select]
365                      label_t = label_t[select]
366                  maskiou_net_input = pred_masks.permute(2, 0, 1).contiguous().unsqueeze(1)
367                  pred_masks = pred_masks.gt(0.5).float()                
368                  maskiou_t = self._mask_iou(pred_masks, mask_t)
369                  maskiou_net_input_list.append(maskiou_net_input)
370                  maskiou_t_list.append(maskiou_t)
371                  label_t_list.append(label_t)
372          losses = {'M': loss_m * cfg.mask_alpha / mask_h / mask_w}
373          if cfg.mask_proto_coeff_diversity_loss:
374              losses['D'] = loss_d
375          if cfg.use_maskiou:
376              if len(maskiou_t_list) == 0:
377                  return losses, None
378              maskiou_t = torch.cat(maskiou_t_list)
379              label_t = torch.cat(label_t_list)
380              maskiou_net_input = torch.cat(maskiou_net_input_list)
381              num_samples = maskiou_t.size(0)
382              if cfg.maskious_to_train > 0 and num_samples > cfg.maskious_to_train:
383                  perm = torch.randperm(num_samples)
384                  select = perm[:cfg.masks_to_train]
385                  maskiou_t = maskiou_t[select]
386                  label_t = label_t[select]
387                  maskiou_net_input = maskiou_net_input[select]
388              return losses, [maskiou_net_input, maskiou_t, label_t]
389          return losses
390      def _mask_iou(self, mask1, mask2):
391          intersection = torch.sum(mask1*mask2, dim=(0, 1))
392          area1 = torch.sum(mask1, dim=(0, 1))
393          area2 = torch.sum(mask2, dim=(0, 1))
394          union = (area1 + area2) - intersection
395          ret = intersection / union
396          return ret
397      def mask_iou_loss(self, net, maskiou_targets):
398          maskiou_net_input, maskiou_t, label_t = maskiou_targets
399          maskiou_p = net.maskiou_net(maskiou_net_input)
400          label_t = label_t[:, None]
401          maskiou_p = torch.gather(maskiou_p, dim=1, index=label_t).view(-1)
402          loss_i = F.smooth_l1_loss(maskiou_p, maskiou_t, reduction='sum')
403          return loss_i * cfg.maskiou_alpha
</code></pre>
        </div>
        <div class="column">
            <h3>google-api-python-client-MDEwOlJlcG9zaXRvcnkxNTc0OTI2OQ==-flat-test_discovery.py</h3>
            <pre><code>1  #!/usr/bin/env python
2  from __future__ import absolute_import
3  __author__ = "jcgregorio@google.com (Joe Gregorio)"
4  from collections import defaultdict
5  import copy
6  import datetime
7  import io
8  import itertools
9  import json
10  import os
11  import pickle
12  import re
13  import sys
14  import unittest
15  from unittest import mock
16  import urllib
17  import google.api_core.exceptions
18  import google.auth.credentials
19  from google.auth.exceptions import MutualTLSChannelError
20  import google_auth_httplib2
21  import httplib2
22  from parameterized import parameterized
23  import uritemplate
24  try:
25      from oauth2client import GOOGLE_TOKEN_URI
26      from oauth2client.client import GoogleCredentials, OAuth2Credentials
27      HAS_OAUTH2CLIENT = True
28  except ImportError:
29      HAS_OAUTH2CLIENT = False
30  from googleapiclient import _helpers as util
31  from googleapiclient.discovery import (
32      DISCOVERY_URI,
33      MEDIA_BODY_PARAMETER_DEFAULT_VALUE,
34      MEDIA_MIME_TYPE_PARAMETER_DEFAULT_VALUE,
35      STACK_QUERY_PARAMETER_DEFAULT_VALUE,
36      STACK_QUERY_PARAMETERS,
37      V1_DISCOVERY_URI,
38      V2_DISCOVERY_URI,
39      ResourceMethodParameters,
40      _fix_up_media_path_base_url,
41      _fix_up_media_upload,
42      _fix_up_method_description,
43      _fix_up_parameters,
44      _urljoin,
45      build,
46      build_from_document,
47      key2param,
48  )
49  from googleapiclient.discovery_cache import DISCOVERY_DOC_MAX_AGE
50  from googleapiclient.discovery_cache.base import Cache
51  from googleapiclient.errors import (
52      HttpError,
53      InvalidJsonError,
54      MediaUploadSizeError,
55      ResumableUploadError,
56      UnacceptableMimeTypeError,
57      UnknownApiNameOrVersion,
58      UnknownFileType,
59  )
60  from googleapiclient.http import (
61      HttpMock,
62      HttpMockSequence,
63      MediaFileUpload,
64      MediaIoBaseUpload,
65      MediaUpload,
66      MediaUploadProgress,
67      build_http,
68      tunnel_patch,
69  )
70  from googleapiclient.model import JsonModel
71  from googleapiclient.schema import Schemas
72  DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
73  def assertUrisEqual(testcase, expected, actual):
74      expected = urllib.parse.urlparse(expected)
75      actual = urllib.parse.urlparse(actual)
76      testcase.assertEqual(expected.scheme, actual.scheme)
77      testcase.assertEqual(expected.netloc, actual.netloc)
78      testcase.assertEqual(expected.path, actual.path)
79      testcase.assertEqual(expected.params, actual.params)
80      testcase.assertEqual(expected.fragment, actual.fragment)
81      expected_query = urllib.parse.parse_qs(expected.query)
82      actual_query = urllib.parse.parse_qs(actual.query)
83      for name in list(expected_query.keys()):
84          testcase.assertEqual(expected_query[name], actual_query[name])
85      for name in list(actual_query.keys()):
86          testcase.assertEqual(expected_query[name], actual_query[name])
87  def assert_discovery_uri(testcase, actual, service_name, version, discovery):
88      params = {"api": service_name, "apiVersion": version}
89      expanded_requested_uri = uritemplate.expand(discovery, params)
90      assertUrisEqual(testcase, expanded_requested_uri, actual)
91  def validate_discovery_requests(testcase, http_mock, service_name, version, discovery):
92      testcase.assertTrue(len(http_mock.request_sequence) > 0)
93      if len(http_mock.request_sequence) > 0:
94          actual_uri = http_mock.request_sequence[-1][0]
95          assert_discovery_uri(testcase, actual_uri, service_name, version, discovery)
96  def datafile(filename):
97      return os.path.join(DATA_DIR, filename)
98  def read_datafile(filename, mode="r"):
99      with open(datafile(filename), mode=mode) as f:
100          return f.read()
101  class SetupHttplib2(unittest.TestCase):
102      def test_retries(self):
103          self.assertEqual(1, httplib2.RETRIES)
104  class Utilities(unittest.TestCase):
105      def setUp(self):
106          self.zoo_root_desc = json.loads(read_datafile("zoo.json", "r"))
107          self.zoo_get_method_desc = self.zoo_root_desc["methods"]["query"]
108          self.zoo_animals_resource = self.zoo_root_desc["resources"]["animals"]
109          self.zoo_insert_method_desc = self.zoo_animals_resource["methods"]["insert"]
110          self.zoo_schema = Schemas(self.zoo_root_desc)
111      def test_key2param(self):
112          self.assertEqual("max_results", key2param("max-results"))
113          self.assertEqual("x007_bond", key2param("007-bond"))
114      def _base_fix_up_parameters_test(self, method_desc, http_method, root_desc, schema):
115          self.assertEqual(method_desc["httpMethod"], http_method)
116          method_desc_copy = copy.deepcopy(method_desc)
117          self.assertEqual(method_desc, method_desc_copy)
118          parameters = _fix_up_parameters(
119              method_desc_copy, root_desc, http_method, schema
120          )
121          self.assertNotEqual(method_desc, method_desc_copy)
122          for param_name in STACK_QUERY_PARAMETERS:
123              self.assertEqual(
124                  STACK_QUERY_PARAMETER_DEFAULT_VALUE, parameters[param_name]
125              )
126          for param_name, value in root_desc.get("parameters", {}).items():
127              self.assertEqual(value, parameters[param_name])
128          return parameters
129      def test_fix_up_parameters_get(self):
130          parameters = self._base_fix_up_parameters_test(
131              self.zoo_get_method_desc, "GET", self.zoo_root_desc, self.zoo_schema
132          )
133          self.assertFalse("body" in parameters)
134      def test_fix_up_parameters_insert(self):
135          parameters = self._base_fix_up_parameters_test(
136              self.zoo_insert_method_desc, "POST", self.zoo_root_desc, self.zoo_schema
137          )
138          body = {"description": "The request body.", "type": "object", "$ref": "Animal"}
139          self.assertEqual(parameters["body"], body)
140      def test_fix_up_parameters_check_body(self):
141          dummy_root_desc = {}
142          dummy_schema = {
143              "Request": {
144                  "properties": {
145                      "description": "Required. Dummy parameter.",
146                      "type": "string",
147                  }
148              }
149          }
150          no_payload_http_method = "DELETE"
151          with_payload_http_method = "PUT"
152          invalid_method_desc = {"response": "Who cares"}
153          valid_method_desc = {
154              "request": {"key1": "value1", "key2": "value2", "$ref": "Request"}
155          }
156          parameters = _fix_up_parameters(
157              invalid_method_desc, dummy_root_desc, no_payload_http_method, dummy_schema
158          )
159          self.assertFalse("body" in parameters)
160          parameters = _fix_up_parameters(
161              valid_method_desc, dummy_root_desc, no_payload_http_method, dummy_schema
162          )
163          self.assertFalse("body" in parameters)
164          parameters = _fix_up_parameters(
165              invalid_method_desc, dummy_root_desc, with_payload_http_method, dummy_schema
166          )
167          self.assertFalse("body" in parameters)
168          parameters = _fix_up_parameters(
169              valid_method_desc, dummy_root_desc, with_payload_http_method, dummy_schema
170          )
171          body = {
172              "description": "The request body.",
173              "type": "object",
174              "$ref": "Request",
175              "key1": "value1",
176              "key2": "value2",
177          }
178          self.assertEqual(parameters["body"], body)
179      def test_fix_up_parameters_optional_body(self):
180          dummy_schema = {"Request": {"properties": {}}}
181          method_desc = {"request": {"$ref": "Request"}}
182          parameters = _fix_up_parameters(method_desc, {}, "POST", dummy_schema)
183      def _base_fix_up_method_description_test(
184          self,
185          method_desc,
186          initial_parameters,
187          final_parameters,
188          final_accept,
189          final_max_size,
190          final_media_path_url,
191      ):
192          fake_root_desc = {
193              "rootUrl": "http://root/",
194              "servicePath": "fake/",
195              "mtlsRootUrl": "http://root/",
196          }
197          fake_path_url = "fake-path/"
198          accept, max_size, media_path_url = _fix_up_media_upload(
199              method_desc, fake_root_desc, fake_path_url, initial_parameters
200          )
201          self.assertEqual(accept, final_accept)
202          self.assertEqual(max_size, final_max_size)
203          self.assertEqual(media_path_url, final_media_path_url)
204          self.assertEqual(initial_parameters, final_parameters)
205      def test_fix_up_media_upload_no_initial_invalid(self):
206          invalid_method_desc = {"response": "Who cares"}
207          self._base_fix_up_method_description_test(
208              invalid_method_desc, {}, {}, [], 0, None
209          )
210      def test_fix_up_media_upload_no_initial_valid_minimal(self):
211          valid_method_desc = {"mediaUpload": {"accept": []}}
212          final_parameters = {
213              "media_body": MEDIA_BODY_PARAMETER_DEFAULT_VALUE,
214              "media_mime_type": MEDIA_MIME_TYPE_PARAMETER_DEFAULT_VALUE,
215          }
216          self._base_fix_up_method_description_test(
217              valid_method_desc,
218              {},
219              final_parameters,
220              [],
221              0,
222              "http://root/upload/fake/fake-path/",
223          )
224      def test_fix_up_media_upload_no_initial_valid_full(self):
225          final_parameters = {
226              "media_body": MEDIA_BODY_PARAMETER_DEFAULT_VALUE,
227              "media_mime_type": MEDIA_MIME_TYPE_PARAMETER_DEFAULT_VALUE,
228          }
229          ten_gb = 10 * 2**30
230          self._base_fix_up_method_description_test(
231              valid_method_desc,
232              {},
233              final_parameters,
234              ten_gb,
235              "http://root/upload/fake/fake-path/",
236          )
237      def test_fix_up_media_upload_with_initial_invalid(self):
238          invalid_method_desc = {"response": "Who cares"}
239          initial_parameters = {"body": {}}
240          self._base_fix_up_method_description_test(
241              invalid_method_desc, initial_parameters, initial_parameters, [], 0, None
242          )
243      def test_fix_up_media_upload_with_initial_valid_minimal(self):
244          valid_method_desc = {"mediaUpload": {"accept": []}}
245          initial_parameters = {"body": {}}
246          final_parameters = {
247              "body": {},
248              "media_body": MEDIA_BODY_PARAMETER_DEFAULT_VALUE,
249              "media_mime_type": MEDIA_MIME_TYPE_PARAMETER_DEFAULT_VALUE,
250          }
251          self._base_fix_up_method_description_test(
252              valid_method_desc,
253              initial_parameters,
254              final_parameters,
255              [],
256              0,
257              "http://root/upload/fake/fake-path/",
258          )
259      def test_fix_up_media_upload_with_initial_valid_full(self):
260          initial_parameters = {"body": {}}
261          final_parameters = {
262              "body": {},
263              "media_body": MEDIA_BODY_PARAMETER_DEFAULT_VALUE,
264              "media_mime_type": MEDIA_MIME_TYPE_PARAMETER_DEFAULT_VALUE,
265          }
266          ten_gb = 10 * 2**30
267          self._base_fix_up_method_description_test(
268              valid_method_desc,
269              initial_parameters,
270              final_parameters,
271              ten_gb,
272              "http://root/upload/fake/fake-path/",
273          )
274      def test_fix_up_method_description_get(self):
275          result = _fix_up_method_description(
276              self.zoo_get_method_desc, self.zoo_root_desc, self.zoo_schema
277          )
278          path_url = "query"
279          http_method = "GET"
280          method_id = "bigquery.query"
281          accept = []
282          max_size = 0
283          media_path_url = None
284          self.assertEqual(
285              result, (path_url, http_method, method_id, accept, max_size, media_path_url)
286          )
287      def test_fix_up_method_description_insert(self):
288          result = _fix_up_method_description(
289              self.zoo_insert_method_desc, self.zoo_root_desc, self.zoo_schema
290          )
291          path_url = "animals"
292          http_method = "POST"
293          method_id = "zoo.animals.insert"
294          accept = ["image/png"]
295          max_size = 1024
296          media_path_url = "https://www.googleapis.com/upload/zoo/v1/animals"
297          self.assertEqual(
298              result, (path_url, http_method, method_id, accept, max_size, media_path_url)
299          )
300      def test_fix_up_media_path_base_url_same_netloc(self):
301          result = _fix_up_media_path_base_url(
302              "https://www.googleapis.com/upload/foo",
303              "https://www.googleapis.com/upload/bar",
304          )
305          self.assertEqual(result, "https://www.googleapis.com/upload/foo")
306      def test_fix_up_media_path_base_url_different_netloc(self):
307          result = _fix_up_media_path_base_url(
308              "https://www.googleapis.com/upload/foo",
309              "https://www.example.com/upload/bar",
310          )
311          self.assertEqual(result, "https://www.example.com/upload/foo")
312      def test_urljoin(self):
313          simple_bases = ["https://www.googleapis.com", "https://www.googleapis.com/"]
314          long_urls = ["foo/v1/bar:custom?alt=json", "/foo/v1/bar:custom?alt=json"]
315          long_bases = [
316              "https://www.googleapis.com/foo/v1",
317              "https://www.googleapis.com/foo/v1/",
318          ]
319          simple_urls = ["bar:custom?alt=json", "/bar:custom?alt=json"]
320          final_url = "https://www.googleapis.com/foo/v1/bar:custom?alt=json"
321          for base, url in itertools.product(simple_bases, long_urls):
322              self.assertEqual(final_url, _urljoin(base, url))
323          for base, url in itertools.product(long_bases, simple_urls):
324              self.assertEqual(final_url, _urljoin(base, url))
325      def test_ResourceMethodParameters_zoo_get(self):
326          parameters = ResourceMethodParameters(self.zoo_get_method_desc)
327          param_types = {
328              "a": "any",
329              "b": "boolean",
330              "e": "string",
331              "er": "string",
332              "i": "integer",
333              "n": "number",
334              "o": "object",
335              "q": "string",
336              "rr": "string",
337          }
338          keys = list(param_types.keys())
339          self.assertEqual(parameters.argmap, dict((key, key) for key in keys))
340          self.assertEqual(parameters.required_params, [])
341          self.assertEqual(sorted(parameters.repeated_params), ["er", "rr"])
342          self.assertEqual(parameters.pattern_params, {"rr": "[a-z]+"})
343          self.assertEqual(
344              sorted(parameters.query_params),
345              ["a", "b", "e", "er", "i", "n", "o", "q", "rr"],
346          )
347          self.assertEqual(parameters.path_params, set())
348          self.assertEqual(parameters.param_types, param_types)
349          enum_params = {"e": ["foo", "bar"], "er": ["one", "two", "three"]}
350          self.assertEqual(parameters.enum_params, enum_params)
351      def test_ResourceMethodParameters_zoo_animals_patch(self):
352          method_desc = self.zoo_animals_resource["methods"]["patch"]
353          parameters = ResourceMethodParameters(method_desc)
354          param_types = {"name": "string"}
355          keys = list(param_types.keys())
356          self.assertEqual(parameters.argmap, dict((key, key) for key in keys))
357          self.assertEqual(parameters.required_params, ["name"])
358          self.assertEqual(parameters.repeated_params, [])
359          self.assertEqual(parameters.pattern_params, {})
360          self.assertEqual(parameters.query_params, [])
361          self.assertEqual(parameters.path_params, set(["name"]))
362          self.assertEqual(parameters.param_types, param_types)
363          self.assertEqual(parameters.enum_params, {})
364  class Discovery(unittest.TestCase):
365      def test_discovery_http_is_closed(self):
366          http = HttpMock(datafile("malformed.json"), {"status": "200"})
367          service = build("plus", "v1", credentials=mock.sentinel.credentials)
368          http.close.assert_called_once()
369  class DiscoveryErrors(unittest.TestCase):
370      def test_tests_should_be_run_with_strict_positional_enforcement(self):
371          try:
372              plus = build("plus", "v1", None, static_discovery=False)
373              self.fail("should have raised a TypeError exception over missing http=.")
374          except TypeError:
375              pass
376      def test_failed_to_parse_discovery_json(self):
377          self.http = HttpMock(datafile("malformed.json"), {"status": "200"})
378          try:
379              plus = build(
380                  "plus",
381                  "v1",
382                  http=self.http,
383                  cache_discovery=False,
384                  static_discovery=False,
385              )
386              self.fail("should have raised an exception over malformed JSON.")
387          except InvalidJsonError:
388              pass
389      def test_unknown_api_name_or_version(self):
390          http = HttpMockSequence(
391              [
392                  ({"status": "404"}, read_datafile("zoo.json", "rb")),
393                  ({"status": "404"}, read_datafile("zoo.json", "rb")),
394              ]
395          )
396          with self.assertRaises(UnknownApiNameOrVersion):
397              plus = build("plus", "v1", http=http, cache_discovery=False)
398      def test_credentials_and_http_mutually_exclusive(self):
399          http = HttpMock(datafile("plus.json"), {"status": "200"})
400          with self.assertRaises(ValueError):
401              build(
402                  "plus",
403                  "v1",
404                  http=http,
405                  credentials=mock.sentinel.credentials,
406                  static_discovery=False,
407              )
408      def test_credentials_file_and_http_mutually_exclusive(self):
409          http = HttpMock(datafile("plus.json"), {"status": "200"})
410          with self.assertRaises(ValueError):
411              build(
412                  "plus",
413                  "v1",
414                  http=http,
415                  client_options=google.api_core.client_options.ClientOptions(
416                      credentials_file="credentials.json"
417                  ),
418                  static_discovery=False,
419              )
420      def test_credentials_and_credentials_file_mutually_exclusive(self):
421          with self.assertRaises(google.api_core.exceptions.DuplicateCredentialArgs):
422              build(
423                  "plus",
424                  "v1",
425                  credentials=mock.sentinel.credentials,
426                  client_options=google.api_core.client_options.ClientOptions(
427                      credentials_file="credentials.json"
428                  ),
429                  static_discovery=False,
430              )
431  class DiscoveryFromDocument(unittest.TestCase):
432      MOCK_CREDENTIALS = mock.Mock(spec=google.auth.credentials.Credentials)
433      def test_can_build_from_local_document(self):
434          discovery = read_datafile("plus.json")
435          plus = build_from_document(
436              discovery,
437              base="https://www.googleapis.com/",
438              credentials=self.MOCK_CREDENTIALS,
439          )
440          self.assertIsNotNone(plus)
441          self.assertTrue(hasattr(plus, "activities"))
442      def test_can_build_from_local_deserialized_document(self):
443          discovery = read_datafile("plus.json")
444          discovery = json.loads(discovery)
445          plus = build_from_document(
446              discovery,
447              base="https://www.googleapis.com/",
448              credentials=self.MOCK_CREDENTIALS,
449          )
450          self.assertIsNotNone(plus)
451          self.assertTrue(hasattr(plus, "activities"))
452      def test_building_with_base_remembers_base(self):
453          discovery = read_datafile("plus.json")
454          base = "https://www.example.com/"
455          plus = build_from_document(
456              discovery, base=base, credentials=self.MOCK_CREDENTIALS
457          )
458          self.assertEqual("https://www.googleapis.com/plus/v1/", plus._baseUrl)
459      def test_building_with_optional_http_with_authorization(self):
460          discovery = read_datafile("plus.json")
461          plus = build_from_document(
462              discovery,
463              base="https://www.googleapis.com/",
464              credentials=self.MOCK_CREDENTIALS,
465          )
466          self.assertIsInstance(plus._http, google_auth_httplib2.AuthorizedHttp)
467          self.assertIsInstance(plus._http.http, httplib2.Http)
468          self.assertIsInstance(plus._http.http.timeout, int)
469          self.assertGreater(plus._http.http.timeout, 0)
470      def test_building_with_optional_http_with_no_authorization(self):
471          discovery = read_datafile("plus.json")
472          discovery = json.loads(discovery)
473          discovery["auth"] = {}
474          discovery = json.dumps(discovery)
475          plus = build_from_document(
476              discovery, base="https://www.googleapis.com/", credentials=None
477          )
478          self.assertIsInstance(plus._http, httplib2.Http)
479          self.assertIsInstance(plus._http.timeout, int)
480          self.assertGreater(plus._http.timeout, 0)
481      def test_building_with_explicit_http(self):
482          http = HttpMock()
483          discovery = read_datafile("plus.json")
484          plus = build_from_document(
485              discovery, base="https://www.googleapis.com/", http=http
486          )
487          self.assertEqual(plus._http, http)
488      def test_building_with_developer_key_skips_adc(self):
489          discovery = read_datafile("plus.json")
490          plus = build_from_document(
491              discovery, base="https://www.googleapis.com/", developerKey="123"
492          )
493          self.assertIsInstance(plus._http, httplib2.Http)
494          self.assertNotIsInstance(plus._http, google_auth_httplib2.AuthorizedHttp)
495      def test_building_with_context_manager(self):
496          discovery = read_datafile("plus.json")
497          with mock.patch("httplib2.Http") as http:
498              with build_from_document(
499                  discovery,
500                  base="https://www.googleapis.com/",
501                  credentials=self.MOCK_CREDENTIALS,
502              ) as plus:
503                  self.assertIsNotNone(plus)
504                  self.assertTrue(hasattr(plus, "activities"))
505              plus._http.http.close.assert_called_once()
506      def test_resource_close(self):
507          discovery = read_datafile("plus.json")
508          with mock.patch("httplib2.Http", autospec=True) as httplib2_http:
509              http = httplib2_http()
510              plus = build_from_document(
511                  discovery,
512                  base="https://www.googleapis.com/",
513                  http=http,
514              )
515              plus.close()
516              http.close.assert_called_once()
517      def test_resource_close_authorized_http(self):
518          discovery = read_datafile("plus.json")
519          with mock.patch("google_auth_httplib2.AuthorizedHttp", autospec=True):
520              plus = build_from_document(
521                  discovery,
522                  base="https://www.googleapis.com/",
523                  credentials=self.MOCK_CREDENTIALS,
524              )
525              plus.close()
526              plus._http.close.assert_called_once()
527      def test_api_endpoint_override_from_client_options(self):
528          discovery = read_datafile("plus.json")
529          api_endpoint = "https://foo.googleapis.com/"
530          options = google.api_core.client_options.ClientOptions(
531              api_endpoint=api_endpoint
532          )
533          plus = build_from_document(
534              discovery, client_options=options, credentials=self.MOCK_CREDENTIALS
535          )
536          self.assertEqual(plus._baseUrl, api_endpoint)
537      def test_api_endpoint_override_from_client_options_mapping_object(self):
538          discovery = read_datafile("plus.json")
539          api_endpoint = "https://foo.googleapis.com/"
540          mapping_object = defaultdict(str)
541          mapping_object["api_endpoint"] = api_endpoint
542          plus = build_from_document(
543              discovery, client_options=mapping_object, credentials=self.MOCK_CREDENTIALS
544          )
545          self.assertEqual(plus._baseUrl, api_endpoint)
546      def test_api_endpoint_override_from_client_options_dict(self):
547          discovery = read_datafile("plus.json")
548          api_endpoint = "https://foo.googleapis.com/"
549          plus = build_from_document(
550              discovery,
551              client_options={"api_endpoint": api_endpoint},
552              credentials=self.MOCK_CREDENTIALS,
553          )
554          self.assertEqual(plus._baseUrl, api_endpoint)
555      def test_scopes_from_client_options(self):
556          discovery = read_datafile("plus.json")
557          with mock.patch("googleapiclient._auth.default_credentials") as default:
558              plus = build_from_document(
559                  discovery,
560                  client_options={"scopes": ["1", "2"]},
561              )
562          default.assert_called_once_with(scopes=["1", "2"], quota_project_id=None)
563      def test_quota_project_from_client_options(self):
564          discovery = read_datafile("plus.json")
565          with mock.patch("googleapiclient._auth.default_credentials") as default:
566              plus = build_from_document(
567                  discovery,
568                  client_options=google.api_core.client_options.ClientOptions(
569                      quota_project_id="my-project"
570                  ),
571              )
572          default.assert_called_once_with(scopes=None, quota_project_id="my-project")
573      def test_credentials_file_from_client_options(self):
574          discovery = read_datafile("plus.json")
575          with mock.patch("googleapiclient._auth.credentials_from_file") as default:
576              plus = build_from_document(
577                  discovery,
578                  client_options=google.api_core.client_options.ClientOptions(
579                      credentials_file="credentials.json"
580                  ),
581              )
582          default.assert_called_once_with(
583              "credentials.json", scopes=None, quota_project_id=None
584          )
585      def test_self_signed_jwt_enabled(self):
586          service_account_file_path = os.path.join(DATA_DIR, "service_account.json")
587          creds = google.oauth2.service_account.Credentials.from_service_account_file(
588              service_account_file_path
589          )
590          discovery = read_datafile("logging.json")
591          with mock.patch(
592              "google.oauth2.service_account.Credentials._create_self_signed_jwt"
593          ) as _create_self_signed_jwt:
594              build_from_document(
595                  discovery,
596                  credentials=creds,
597                  always_use_jwt_access=True,
598              )
599              _create_self_signed_jwt.assert_called_with(
600                  "https://logging.googleapis.com/"
601              )
602      def test_self_signed_jwt_disabled(self):
603          service_account_file_path = os.path.join(DATA_DIR, "service_account.json")
604          creds = google.oauth2.service_account.Credentials.from_service_account_file(
605              service_account_file_path
606          )
607          discovery = read_datafile("logging.json")
608          with mock.patch(
609              "google.oauth2.service_account.Credentials._create_self_signed_jwt"
610          ) as _create_self_signed_jwt:
611              build_from_document(
612                  discovery,
613                  credentials=creds,
614              )
615              _create_self_signed_jwt.assert_not_called()
616  REGULAR_ENDPOINT = "https://www.googleapis.com/plus/v1/"
617  MTLS_ENDPOINT = "https://www.mtls.googleapis.com/plus/v1/"
<span onclick='openModal()' class='match'>618  class DiscoveryFromDocumentMutualTLS(unittest.TestCase):
619      MOCK_CREDENTIALS = mock.Mock(spec=google.auth.credentials.Credentials)
620      ADC_CERT_PATH = "adc_cert_path"
</span>621      ADC_KEY_PATH = "adc_key_path"
622      ADC_PASSPHRASE = "adc_passphrase"
623      def check_http_client_cert(self, resource, has_client_cert="false"):
624          if isinstance(resource._http, google_auth_httplib2.AuthorizedHttp):
625              certs = list(resource._http.http.certificates.iter(""))
626          else:
627              certs = list(resource._http.certificates.iter(""))
628          if has_client_cert == "true":
629              self.assertEqual(len(certs), 1)
630              self.assertEqual(
631                  certs[0], (self.ADC_KEY_PATH, self.ADC_CERT_PATH, self.ADC_PASSPHRASE)
632              )
633          else:
634              self.assertEqual(len(certs), 0)
635      def client_encrypted_cert_source(self):
636          return self.ADC_CERT_PATH, self.ADC_KEY_PATH, self.ADC_PASSPHRASE
637      @parameterized.expand(
638          [
639              ("never", "true"),
640              ("auto", "true"),
641              ("always", "true"),
642              ("never", "false"),
643              ("auto", "false"),
644              ("always", "false"),
645          ]
646      )
647      def test_mtls_not_trigger_if_http_provided(self, use_mtls_env, use_client_cert):
648          discovery = read_datafile("plus.json")
649          with mock.patch.dict(
650              "os.environ", {"GOOGLE_API_USE_MTLS_ENDPOINT": use_mtls_env}
651          ):
652              with mock.patch.dict(
653                  "os.environ", {"GOOGLE_API_USE_CLIENT_CERTIFICATE": use_client_cert}
654              ):
655                  plus = build_from_document(discovery, http=httplib2.Http())
656                  self.assertIsNotNone(plus)
657                  self.assertEqual(plus._baseUrl, REGULAR_ENDPOINT)
658                  self.check_http_client_cert(plus, has_client_cert="false")
659      @parameterized.expand(
660          [
661              ("never", "true"),
662              ("auto", "true"),
663              ("always", "true"),
664              ("never", "false"),
665              ("auto", "false"),
666              ("always", "false"),
667          ]
668      )
669      def test_exception_with_client_cert_source(self, use_mtls_env, use_client_cert):
670          discovery = read_datafile("plus.json")
671          with mock.patch.dict(
672              "os.environ", {"GOOGLE_API_USE_MTLS_ENDPOINT": use_mtls_env}
673          ):
674              with mock.patch.dict(
675                  "os.environ", {"GOOGLE_API_USE_CLIENT_CERTIFICATE": use_client_cert}
676              ):
677                  with self.assertRaises(MutualTLSChannelError):
678                      build_from_document(
679                          discovery,
680                          credentials=self.MOCK_CREDENTIALS,
681                          client_options={"client_cert_source": mock.Mock()},
682                      )
683      @parameterized.expand(
684          [
685              ("never", "true", REGULAR_ENDPOINT),
686              ("auto", "true", MTLS_ENDPOINT),
687              ("always", "true", MTLS_ENDPOINT),
688              ("never", "false", REGULAR_ENDPOINT),
689              ("auto", "false", REGULAR_ENDPOINT),
690              ("always", "false", MTLS_ENDPOINT),
691          ]
692      )
693      def test_mtls_with_provided_client_cert(
694          self, use_mtls_env, use_client_cert, base_url
695      ):
696          discovery = read_datafile("plus.json")
697          with mock.patch.dict(
698              "os.environ", {"GOOGLE_API_USE_MTLS_ENDPOINT": use_mtls_env}
699          ):
700              with mock.patch.dict(
701                  "os.environ", {"GOOGLE_API_USE_CLIENT_CERTIFICATE": use_client_cert}
702              ):
703                  plus = build_from_document(
704                      discovery,
705                      credentials=self.MOCK_CREDENTIALS,
706                      client_options={
707                          "client_encrypted_cert_source": self.client_encrypted_cert_source
708                      },
709                  )
710                  self.assertIsNotNone(plus)
711                  self.check_http_client_cert(plus, has_client_cert=use_client_cert)
712                  self.assertEqual(plus._baseUrl, base_url)
713      @parameterized.expand(
714          [
715              ("never", "true"),
716              ("auto", "true"),
717              ("always", "true"),
718              ("never", "false"),
719              ("auto", "false"),
720              ("always", "false"),
721          ]
722      )
723      def test_endpoint_not_switch(self, use_mtls_env, use_client_cert):
724          discovery = read_datafile("plus.json")
725          with mock.patch.dict(
726              "os.environ", {"GOOGLE_API_USE_MTLS_ENDPOINT": use_mtls_env}
727          ):
728              with mock.patch.dict(
729                  "os.environ", {"GOOGLE_API_USE_CLIENT_CERTIFICATE": use_client_cert}
730              ):
731                  plus = build_from_document(
732                      discovery,
733                      credentials=self.MOCK_CREDENTIALS,
734                      client_options={
735                          "api_endpoint": "https://foo.googleapis.com",
736                          "client_encrypted_cert_source": self.client_encrypted_cert_source,
737                      },
738                  )
739                  self.assertIsNotNone(plus)
740                  self.check_http_client_cert(plus, has_client_cert=use_client_cert)
741                  self.assertEqual(plus._baseUrl, "https://foo.googleapis.com")
742      @parameterized.expand(
743          [
744              ("never", "true", REGULAR_ENDPOINT),
745              ("auto", "true", MTLS_ENDPOINT),
746              ("always", "true", MTLS_ENDPOINT),
747              ("never", "false", REGULAR_ENDPOINT),
748              ("auto", "false", REGULAR_ENDPOINT),
749              ("always", "false", MTLS_ENDPOINT),
750          ]
751      )
752      @mock.patch(
753          "google.auth.transport.mtls.has_default_client_cert_source", autospec=True
754      )
755      @mock.patch(
756          "google.auth.transport.mtls.default_client_encrypted_cert_source", autospec=True
757      )
758      def test_mtls_with_default_client_cert(
759          self,
760          use_mtls_env,
761          use_client_cert,
762          base_url,
763          default_client_encrypted_cert_source,
764          has_default_client_cert_source,
765      ):
766          has_default_client_cert_source.return_value = True
767          default_client_encrypted_cert_source.return_value = (
768              self.client_encrypted_cert_source
769          )
770          discovery = read_datafile("plus.json")
771          with mock.patch.dict(
772              "os.environ", {"GOOGLE_API_USE_MTLS_ENDPOINT": use_mtls_env}
773          ):
774              with mock.patch.dict(
775                  "os.environ", {"GOOGLE_API_USE_CLIENT_CERTIFICATE": use_client_cert}
776              ):
777                  plus = build_from_document(
778                      discovery,
779                      credentials=self.MOCK_CREDENTIALS,
780                      adc_cert_path=self.ADC_CERT_PATH,
781                      adc_key_path=self.ADC_KEY_PATH,
782                  )
783                  self.assertIsNotNone(plus)
784                  self.check_http_client_cert(plus, has_client_cert=use_client_cert)
785                  self.assertEqual(plus._baseUrl, base_url)
786      @parameterized.expand(
787          [
788              ("never", "true", REGULAR_ENDPOINT),
789              ("auto", "true", REGULAR_ENDPOINT),
790              ("always", "true", MTLS_ENDPOINT),
791              ("never", "false", REGULAR_ENDPOINT),
792              ("auto", "false", REGULAR_ENDPOINT),
793              ("always", "false", MTLS_ENDPOINT),
794          ]
795      )
796      @mock.patch(
797          "google.auth.transport.mtls.has_default_client_cert_source", autospec=True
798      )
799      def test_mtls_with_no_client_cert(
800          self, use_mtls_env, use_client_cert, base_url, has_default_client_cert_source
801      ):
802          has_default_client_cert_source.return_value = False
803          discovery = read_datafile("plus.json")
804          with mock.patch.dict(
805              "os.environ", {"GOOGLE_API_USE_MTLS_ENDPOINT": use_mtls_env}
806          ):
807              with mock.patch.dict(
808                  "os.environ", {"GOOGLE_API_USE_CLIENT_CERTIFICATE": use_client_cert}
809              ):
810                  plus = build_from_document(
811                      discovery,
812                      credentials=self.MOCK_CREDENTIALS,
813                      adc_cert_path=self.ADC_CERT_PATH,
814                      adc_key_path=self.ADC_KEY_PATH,
815                  )
816                  self.assertIsNotNone(plus)
817                  self.check_http_client_cert(plus, has_client_cert="false")
818                  self.assertEqual(plus._baseUrl, base_url)
819  class DiscoveryFromHttp(unittest.TestCase):
820      def setUp(self):
821          self.old_environ = os.environ.copy()
822      def tearDown(self):
823          os.environ = self.old_environ
824      def test_userip_is_added_to_discovery_uri(self):
825          os.environ["REMOTE_ADDR"] = "10.0.0.1"
826          try:
827              http = HttpMockSequence(
828                  [({"status": "400"}, read_datafile("zoo.json", "rb"))]
829              )
830              zoo = build(
831                  "zoo",
832                  "v1",
833                  http=http,
834                  developerKey=None,
835                  discoveryServiceUrl="http://example.com",
836              )
837              self.fail("Should have raised an exception.")
838          except HttpError as e:
839              self.assertEqual(e.uri, "http://example.com?userIp=10.0.0.1")
840      def test_userip_missing_is_not_added_to_discovery_uri(self):
841          try:
842              http = HttpMockSequence(
843                  [({"status": "400"}, read_datafile("zoo.json", "rb"))]
844              )
845              zoo = build(
846                  "zoo",
847                  "v1",
848                  http=http,
849                  developerKey=None,
850                  discoveryServiceUrl="http://example.com",
851              )
852              self.fail("Should have raised an exception.")
853          except HttpError as e:
854              self.assertEqual(e.uri, "http://example.com")
855      def test_key_is_added_to_discovery_uri(self):
856          try:
857              http = HttpMockSequence(
858                  [({"status": "400"}, read_datafile("zoo.json", "rb"))]
859              )
860              zoo = build(
861                  "zoo",
862                  "v1",
863                  http=http,
864                  developerKey="foo",
865                  discoveryServiceUrl="http://example.com",
866                  static_discovery=False,
867              )
868              self.fail("Should have raised an exception.")
869          except HttpError as e:
870              self.assertEqual(e.uri, "http://example.com?key=foo")
871      def test_discovery_loading_from_v2_discovery_uri(self):
872          http = HttpMockSequence(
873              [
874                  ({"status": "404"}, "Not found"),
875                  ({"status": "200"}, read_datafile("zoo.json", "rb")),
876              ]
877          )
878          zoo = build(
879              "zoo", "v1", http=http, cache_discovery=False, static_discovery=False
880          )
881          self.assertTrue(hasattr(zoo, "animals"))
882      def test_api_endpoint_override_from_client_options(self):
883          http = HttpMockSequence(
884              [
885                  ({"status": "404"}, "Not found"),
886                  ({"status": "200"}, read_datafile("zoo.json", "rb")),
887              ]
888          )
889          api_endpoint = "https://foo.googleapis.com/"
890          options = google.api_core.client_options.ClientOptions(
891              api_endpoint=api_endpoint
892          )
893          zoo = build(
894              "zoo",
895              "v1",
896              http=http,
897              cache_discovery=False,
898              client_options=options,
899              static_discovery=False,
900          )
901          self.assertEqual(zoo._baseUrl, api_endpoint)
902      def test_api_endpoint_override_from_client_options_dict(self):
903          http = HttpMockSequence(
904              [
905                  ({"status": "404"}, "Not found"),
906                  ({"status": "200"}, read_datafile("zoo.json", "rb")),
907              ]
908          )
909          api_endpoint = "https://foo.googleapis.com/"
910          zoo = build(
911              "zoo",
912              "v1",
913              http=http,
914              cache_discovery=False,
915              client_options={"api_endpoint": api_endpoint},
916              static_discovery=False,
917          )
918          self.assertEqual(zoo._baseUrl, api_endpoint)
919      def test_discovery_with_empty_version_uses_v2(self):
920          http = HttpMockSequence(
921              [
922                  ({"status": "200"}, read_datafile("zoo.json", "rb")),
923              ]
924          )
925          build(
926              "zoo",
927              version=None,
928              http=http,
929              cache_discovery=False,
930              static_discovery=False,
931          )
932          validate_discovery_requests(self, http, "zoo", None, V2_DISCOVERY_URI)
933      def test_discovery_with_empty_version_preserves_custom_uri(self):
934          http = HttpMockSequence(
935              [
936                  ({"status": "200"}, read_datafile("zoo.json", "rb")),
937              ]
938          )
939          custom_discovery_uri = "https://foo.bar/$discovery"
940          build(
941              "zoo",
942              version=None,
943              http=http,
944              cache_discovery=False,
945              discoveryServiceUrl=custom_discovery_uri,
946              static_discovery=False,
947          )
948          validate_discovery_requests(self, http, "zoo", None, custom_discovery_uri)
949      def test_discovery_with_valid_version_uses_v1(self):
950          http = HttpMockSequence(
951              [
952                  ({"status": "200"}, read_datafile("zoo.json", "rb")),
953              ]
954          )
955          build(
956              "zoo",
957              version="v123",
958              http=http,
959              cache_discovery=False,
960              static_discovery=False,
961          )
962          validate_discovery_requests(self, http, "zoo", "v123", V1_DISCOVERY_URI)
963  class DiscoveryRetryFromHttp(unittest.TestCase):
964      def test_repeated_500_retries_and_fails(self):
965          http = HttpMockSequence(
966              [
967                  ({"status": "500"}, read_datafile("500.json", "rb")),
968                  ({"status": "503"}, read_datafile("503.json", "rb")),
969              ]
970          )
971          with self.assertRaises(HttpError):
972              with mock.patch("time.sleep") as mocked_sleep:
973                  build(
974                      "zoo",
975                      "v1",
976                      http=http,
977                      cache_discovery=False,
978                      static_discovery=False,
979                  )
980          mocked_sleep.assert_called_once()
981          validate_discovery_requests(self, http, "zoo", "v1", V1_DISCOVERY_URI)
982      def test_v2_repeated_500_retries_and_fails(self):
983          http = HttpMockSequence(
984              [
985                  ({"status": "404"}, "Not found"),  # last v1 discovery call
986                  ({"status": "500"}, read_datafile("500.json", "rb")),
987                  ({"status": "503"}, read_datafile("503.json", "rb")),
988              ]
989          )
990          with self.assertRaises(HttpError):
991              with mock.patch("time.sleep") as mocked_sleep:
992                  build(
993                      "zoo",
994                      "v1",
995                      http=http,
996                      cache_discovery=False,
997                      static_discovery=False,
998                  )
999          mocked_sleep.assert_called_once()
1000          validate_discovery_requests(self, http, "zoo", "v1", V2_DISCOVERY_URI)
1001      def test_single_500_retries_and_succeeds(self):
1002          http = HttpMockSequence(
1003              [
1004                  ({"status": "500"}, read_datafile("500.json", "rb")),
1005                  ({"status": "200"}, read_datafile("zoo.json", "rb")),
1006              ]
1007          )
1008          with mock.patch("time.sleep") as mocked_sleep:
1009              zoo = build(
1010                  "zoo", "v1", http=http, cache_discovery=False, static_discovery=False
1011              )
1012          self.assertTrue(hasattr(zoo, "animals"))
1013          mocked_sleep.assert_called_once()
1014          validate_discovery_requests(self, http, "zoo", "v1", V1_DISCOVERY_URI)
1015      def test_single_500_then_404_retries_and_succeeds(self):
1016          http = HttpMockSequence(
1017              [
1018                  ({"status": "500"}, read_datafile("500.json", "rb")),
1019                  ({"status": "404"}, "Not found"),  # last v1 discovery call
1020                  ({"status": "200"}, read_datafile("zoo.json", "rb")),
1021              ]
1022          )
1023          with mock.patch("time.sleep") as mocked_sleep:
1024              zoo = build(
1025                  "zoo", "v1", http=http, cache_discovery=False, static_discovery=False
1026              )
1027          self.assertTrue(hasattr(zoo, "animals"))
1028          mocked_sleep.assert_called_once()
1029          validate_discovery_requests(self, http, "zoo", "v1", V2_DISCOVERY_URI)
1030  class DiscoveryFromAppEngineCache(unittest.TestCase):
1031      def setUp(self):
1032          self.old_environ = os.environ.copy()
1033          os.environ["GAE_ENV"] = "standard"
1034      def tearDown(self):
1035          os.environ = self.old_environ
1036      def test_appengine_memcache(self):
1037          self.orig_import = __import__
1038          self.mocked_api = mock.MagicMock()
1039          def import_mock(name, *args, **kwargs):
1040              if name == "google.appengine.api":
1041                  return self.mocked_api
1042              return self.orig_import(name, *args, **kwargs)
1043          import_fullname = "__builtin__.__import__"
1044          if sys.version_info[0] >= 3:
1045              import_fullname = "builtins.__import__"
1046          with mock.patch(import_fullname, side_effect=import_mock):
1047              namespace = "google-api-client"
1048              self.http = HttpMock(datafile("plus.json"), {"status": "200"})
1049              self.mocked_api.memcache.get.return_value = None
1050              plus = build("plus", "v1", http=self.http, static_discovery=False)
1051              url = "https://www.googleapis.com/discovery/v1/apis/plus/v1/rest"
1052              self.mocked_api.memcache.get.assert_called_once_with(
1053                  url, namespace=namespace
1054              )
1055              content = read_datafile("plus.json")
1056              self.mocked_api.memcache.set.assert_called_once_with(
1057                  url, content, time=DISCOVERY_DOC_MAX_AGE, namespace=namespace
1058              )
1059              self.mocked_api.memcache.get.return_value = content
1060              self.http = HttpMock(None, {"status": "200"})
1061              plus = build("plus", "v1", http=self.http, static_discovery=False)
1062              self.mocked_api.memcache.get.assert_has_calls(
1063                  [
1064                      mock.call(url, namespace=namespace),
1065                      mock.call(url, namespace=namespace),
1066                  ]
1067              )
1068              self.mocked_api.memcache.set.assert_called_once_with(
1069                  url, content, time=DISCOVERY_DOC_MAX_AGE, namespace=namespace
1070              )
1071  class DiscoveryFromStaticDocument(unittest.TestCase):
1072      def test_retrieve_from_local_when_static_discovery_true(self):
1073          http = HttpMockSequence([({"status": "400"}, "")])
1074          drive = build(
1075              "drive", "v3", http=http, cache_discovery=False, static_discovery=True
1076          )
1077          self.assertIsNotNone(drive)
1078          self.assertTrue(hasattr(drive, "files"))
1079      def test_retrieve_from_internet_when_static_discovery_false(self):
1080          http = HttpMockSequence([({"status": "400"}, "")])
1081          with self.assertRaises(HttpError):
1082              build(
1083                  "drive", "v3", http=http, cache_discovery=False, static_discovery=False
1084              )
1085      def test_unknown_api_when_static_discovery_true(self):
1086          with self.assertRaises(UnknownApiNameOrVersion):
1087              build("doesnotexist", "v3", cache_discovery=False, static_discovery=True)
1088  class DictCache(Cache):
1089      def __init__(self):
1090          self.d = {}
1091      def get(self, url):
1092          return self.d.get(url, None)
1093      def set(self, url, content):
1094          self.d[url] = content
1095      def contains(self, url):
1096          return url in self.d
1097  class DiscoveryFromFileCache(unittest.TestCase):
1098      def test_file_based_cache(self):
1099          cache = mock.Mock(wraps=DictCache())
1100          with mock.patch(
1101              "googleapiclient.discovery_cache.autodetect", return_value=cache
1102          ):
1103              self.http = HttpMock(datafile("plus.json"), {"status": "200"})
1104              plus = build("plus", "v1", http=self.http, static_discovery=False)
1105              url = "https://www.googleapis.com/discovery/v1/apis/plus/v1/rest"
1106              cache.get.assert_called_once_with(url)
1107              content = read_datafile("plus.json")
1108              cache.set.assert_called_once_with(url, content)
1109              self.assertTrue(cache.contains(url))
1110              self.http = HttpMock(None, {"status": "200"})
1111              plus = build("plus", "v1", http=self.http, static_discovery=False)
1112              cache.get.assert_has_calls([mock.call(url), mock.call(url)])
1113              cache.set.assert_called_once_with(url, content)
1114  class Discovery(unittest.TestCase):
1115      def test_method_error_checking(self):
1116          self.http = HttpMock(datafile("plus.json"), {"status": "200"})
1117          plus = build("plus", "v1", http=self.http, static_discovery=False)
1118          try:
1119              plus.activities().list()
1120              self.fail()
1121          except TypeError as e:
1122              self.assertTrue("Missing" in str(e))
1123          try:
1124              plus.activities().list(collection=None, userId=None)
1125              self.fail()
1126          except TypeError as e:
1127              self.assertTrue("Missing" in str(e))
1128          try:
1129              plus.activities().list(collection="not_a_collection_name", userId="me")
1130              self.fail()
1131          except TypeError as e:
1132              self.assertTrue("not an allowed value" in str(e))
1133          try:
1134              plus.activities().list(flubber=12)
1135              self.fail()
1136          except TypeError as e:
1137              self.assertTrue("unexpected" in str(e))
1138      def _check_query_types(self, request):
1139          parsed = urllib.parse.urlparse(request.uri)
1140          q = urllib.parse.parse_qs(parsed.query)
1141          self.assertEqual(q["q"], ["foo"])
1142          self.assertEqual(q["i"], ["1"])
1143          self.assertEqual(q["n"], ["1.0"])
1144          self.assertEqual(q["b"], ["false"])
1145          self.assertEqual(q["a"], ["[1, 2, 3]"])
1146          self.assertEqual(q["o"], ["{'a': 1}"])
1147          self.assertEqual(q["e"], ["bar"])
1148      def test_type_coercion(self):
1149          http = HttpMock(datafile("zoo.json"), {"status": "200"})
1150          zoo = build("zoo", "v1", http=http, static_discovery=False)
1151          request = zoo.query(
1152              q="foo", i=1.0, n=1.0, b=0, a=[1, 2, 3], o={"a": 1}, e="bar"
1153          )
1154          self._check_query_types(request)
1155          request = zoo.query(
1156              q="foo", i=1, n=1, b=False, a=[1, 2, 3], o={"a": 1}, e="bar"
1157          )
1158          self._check_query_types(request)
1159          request = zoo.query(
1160              q="foo", i="1", n="1", b="", a=[1, 2, 3], o={"a": 1}, e="bar", er="two"
1161          )
1162          request = zoo.query(
1163              q="foo",
1164              i="1",
1165              n="1",
1166              b="",
1167              a=[1, 2, 3],
1168              o={"a": 1},
1169              e="bar",
1170              er=["one", "three"],
1171              rr=["foo", "bar"],
1172          )
1173          self._check_query_types(request)
1174          self.assertRaises(TypeError, zoo.query, er=["one", "five"])
1175      def test_optional_stack_query_parameters(self):
1176          http = HttpMock(datafile("zoo.json"), {"status": "200"})
1177          zoo = build("zoo", "v1", http=http, static_discovery=False)
1178          request = zoo.query(trace="html", fields="description")
1179          parsed = urllib.parse.urlparse(request.uri)
1180          q = urllib.parse.parse_qs(parsed.query)
1181          self.assertEqual(q["trace"], ["html"])
1182          self.assertEqual(q["fields"], ["description"])
1183      def test_string_params_value_of_none_get_dropped(self):
1184          http = HttpMock(datafile("zoo.json"), {"status": "200"})
1185          zoo = build("zoo", "v1", http=http, static_discovery=False)
1186          request = zoo.query(trace=None, fields="description")
1187          parsed = urllib.parse.urlparse(request.uri)
1188          q = urllib.parse.parse_qs(parsed.query)
1189          self.assertFalse("trace" in q)
1190      def test_model_added_query_parameters(self):
1191          http = HttpMock(datafile("zoo.json"), {"status": "200"})
1192          zoo = build("zoo", "v1", http=http, static_discovery=False)
1193          request = zoo.animals().get(name="Lion")
1194          parsed = urllib.parse.urlparse(request.uri)
1195          q = urllib.parse.parse_qs(parsed.query)
1196          self.assertEqual(q["alt"], ["json"])
1197          self.assertEqual(request.headers["accept"], "application/json")
1198      def test_fallback_to_raw_model(self):
1199          http = HttpMock(datafile("zoo.json"), {"status": "200"})
1200          zoo = build("zoo", "v1", http=http, static_discovery=False)
1201          request = zoo.animals().getmedia(name="Lion")
1202          parsed = urllib.parse.urlparse(request.uri)
1203          q = urllib.parse.parse_qs(parsed.query)
1204          self.assertTrue("alt" not in q)
1205      def test_patch(self):
1206          http = HttpMock(datafile("zoo.json"), {"status": "200"})
1207          zoo = build("zoo", "v1", http=http, static_discovery=False)
1208          request = zoo.animals().patch(name="lion", body='{"description": "foo"}')
1209          self.assertEqual(request.method, "PATCH")
1210      def test_batch_request_from_discovery(self):
1211          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1212          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1213          batch_request = zoo.new_batch_http_request()
1214          self.assertEqual(
1215              batch_request._batch_uri, "https://www.googleapis.com/batchZoo"
1216          )
1217      def test_batch_request_from_default(self):
1218          self.http = HttpMock(datafile("plus.json"), {"status": "200"})
1219          plus = build(
1220              "plus", "v1", http=self.http, cache_discovery=False, static_discovery=False
1221          )
1222          batch_request = plus.new_batch_http_request()
1223          self.assertEqual(batch_request._batch_uri, "https://www.googleapis.com/batch")
1224      def test_tunnel_patch(self):
1225          http = HttpMockSequence(
1226              [
1227                  ({"status": "200"}, read_datafile("zoo.json", "rb")),
1228                  ({"status": "200"}, "echo_request_headers_as_json"),
1229              ]
1230          )
1231          http = tunnel_patch(http)
1232          zoo = build(
1233              "zoo", "v1", http=http, cache_discovery=False, static_discovery=False
1234          )
1235          resp = zoo.animals().patch(name="lion", body='{"description": "foo"}').execute()
1236          self.assertTrue("x-http-method-override" in resp)
1237      def test_plus_resources(self):
1238          self.http = HttpMock(datafile("plus.json"), {"status": "200"})
1239          plus = build("plus", "v1", http=self.http, static_discovery=False)
1240          self.assertTrue(getattr(plus, "activities"))
1241          self.assertTrue(getattr(plus, "people"))
1242      @unittest.skipIf(not HAS_OAUTH2CLIENT, "oauth2client unavailable.")
1243      def test_oauth2client_credentials(self):
1244          credentials = mock.Mock(spec=GoogleCredentials)
1245          credentials.create_scoped_required.return_value = False
1246          discovery = read_datafile("plus.json")
1247          service = build_from_document(discovery, credentials=credentials)
1248          self.assertEqual(service._http, credentials.authorize.return_value)
1249      def test_google_auth_credentials(self):
1250          credentials = mock.Mock(spec=google.auth.credentials.Credentials)
1251          discovery = read_datafile("plus.json")
1252          service = build_from_document(discovery, credentials=credentials)
1253          self.assertIsInstance(service._http, google_auth_httplib2.AuthorizedHttp)
1254          self.assertEqual(service._http.credentials, credentials)
1255      def test_no_scopes_no_credentials(self):
1256          discovery = read_datafile("zoo.json")
1257          service = build_from_document(discovery)
1258          self.assertIsInstance(service._http, httplib2.Http)
1259      def test_full_featured(self):
1260          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1261          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1262          self.assertTrue(getattr(zoo, "animals"))
1263          request = zoo.animals().list(name="bat", projection="full")
1264          parsed = urllib.parse.urlparse(request.uri)
1265          q = urllib.parse.parse_qs(parsed.query)
1266          self.assertEqual(q["name"], ["bat"])
1267          self.assertEqual(q["projection"], ["full"])
1268      def test_nested_resources(self):
1269          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1270          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1271          self.assertTrue(getattr(zoo, "animals"))
1272          request = zoo.my().favorites().list(max_results="5")
1273          parsed = urllib.parse.urlparse(request.uri)
1274          q = urllib.parse.parse_qs(parsed.query)
1275          self.assertEqual(q["max-results"], ["5"])
1276      def test_top_level_functions(self):
1277          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1278          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1279          self.assertTrue(getattr(zoo, "query"))
1280          request = zoo.query(q="foo")
1281          parsed = urllib.parse.urlparse(request.uri)
1282          q = urllib.parse.parse_qs(parsed.query)
1283          self.assertEqual(q["q"], ["foo"])
1284      def test_simple_media_uploads(self):
1285          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1286          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1287          doc = getattr(zoo.animals().insert, "__doc__")
1288          self.assertTrue("media_body" in doc)
1289      def test_simple_media_upload_no_max_size_provided(self):
1290          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1291          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1292          request = zoo.animals().crossbreed(media_body=datafile("small.png"))
1293          self.assertEqual("image/png", request.headers["content-type"])
1294          self.assertEqual(b"PNG", request.body[1:4])
1295      def test_simple_media_raise_correct_exceptions(self):
1296          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1297          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1298          try:
1299              zoo.animals().insert(media_body=datafile("smiley.png"))
1300              self.fail("should throw exception if media is too large.")
1301          except MediaUploadSizeError:
1302              pass
1303          try:
1304              zoo.animals().insert(media_body=datafile("small.jpg"))
1305              self.fail("should throw exception if mimetype is unacceptable.")
1306          except UnacceptableMimeTypeError:
1307              pass
1308      def test_simple_media_good_upload(self):
1309          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1310          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1311          request = zoo.animals().insert(media_body=datafile("small.png"))
1312          self.assertEqual("image/png", request.headers["content-type"])
1313          self.assertEqual(b"PNG", request.body[1:4])
1314          assertUrisEqual(
1315              self,
1316              "https://www.googleapis.com/upload/zoo/v1/animals?uploadType=media&alt=json",
1317              request.uri,
1318          )
1319      def test_simple_media_unknown_mimetype(self):
1320          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1321          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1322          try:
1323              zoo.animals().insert(media_body=datafile("small-png"))
1324              self.fail("should throw exception if mimetype is unknown.")
1325          except UnknownFileType:
1326              pass
1327          request = zoo.animals().insert(
1328              media_body=datafile("small-png"), media_mime_type="image/png"
1329          )
1330          self.assertEqual("image/png", request.headers["content-type"])
1331          self.assertEqual(b"PNG", request.body[1:4])
1332          assertUrisEqual(
1333              self,
1334              "https://www.googleapis.com/upload/zoo/v1/animals?uploadType=media&alt=json",
1335              request.uri,
1336          )
1337      def test_multipart_media_raise_correct_exceptions(self):
1338          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1339          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1340          try:
1341              zoo.animals().insert(media_body=datafile("smiley.png"), body={})
1342              self.fail("should throw exception if media is too large.")
1343          except MediaUploadSizeError:
1344              pass
1345          try:
1346              zoo.animals().insert(media_body=datafile("small.jpg"), body={})
1347              self.fail("should throw exception if mimetype is unacceptable.")
1348          except UnacceptableMimeTypeError:
1349              pass
1350      def test_multipart_media_good_upload(self, static_discovery=False):
1351          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1352          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1353          request = zoo.animals().insert(media_body=datafile("small.png"), body={})
1354          self.assertTrue(request.headers["content-type"].startswith("multipart/related"))
1355          contents = read_datafile("small.png", "rb")
1356          boundary = re.match(b"--=+([^=]+)", request.body).group(1)
1357          self.assertEqual(
1358              request.body.rstrip(b"\n"),  # Python 2.6 does not add a trailing \n
1359              b"--==============="
1360              + boundary
1361              + b"==\n"
1362              + b"Content-Type: application/json\n"
1363              + b"MIME-Version: 1.0\n\n"
1364              + b'{"data": {}}\n'
1365              + b"--==============="
1366              + boundary
1367              + b"==\n"
1368              + b"Content-Type: image/png\n"
1369              + b"MIME-Version: 1.0\n"
1370              + b"Content-Transfer-Encoding: binary\n\n"
1371              + contents
1372              + b"\n--==============="
1373              + boundary
1374              + b"==--",
1375          )
1376          assertUrisEqual(
1377              self,
1378              "https://www.googleapis.com/upload/zoo/v1/animals?uploadType=multipart&alt=json",
1379              request.uri,
1380          )
1381      def test_media_capable_method_without_media(self):
1382          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1383          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1384          request = zoo.animals().insert(body={})
1385          self.assertTrue(request.headers["content-type"], "application/json")
1386      def test_resumable_multipart_media_good_upload(self):
1387          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1388          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1389          media_upload = MediaFileUpload(datafile("small.png"), resumable=True)
1390          request = zoo.animals().insert(media_body=media_upload, body={})
1391          self.assertTrue(request.headers["content-type"].startswith("application/json"))
1392          self.assertEqual('{"data": {}}', request.body)
1393          self.assertEqual(media_upload, request.resumable)
1394          self.assertEqual("image/png", request.resumable.mimetype())
1395          self.assertNotEqual(request.body, None)
1396          self.assertEqual(request.resumable_uri, None)
1397          http = HttpMockSequence(
1398              [
1399                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1400                  ({"status": "308", "location": "http://upload.example.com/2"}, ""),
1401                  (
1402                      {
1403                          "status": "308",
1404                          "location": "http://upload.example.com/3",
1405                          "range": "0-12",
1406                      },
1407                      "",
1408                  ),
1409                  (
1410                      {
1411                          "status": "308",
1412                          "location": "http://upload.example.com/4",
1413                          "range": "0-%d" % (media_upload.size() - 2),
1414                      },
1415                      "",
1416                  ),
1417                  ({"status": "200"}, '{"foo": "bar"}'),
1418              ]
1419          )
1420          status, body = request.next_chunk(http=http)
1421          self.assertEqual(None, body)
1422          self.assertTrue(isinstance(status, MediaUploadProgress))
1423          self.assertEqual(0, status.resumable_progress)
1424          self.assertEqual(request.resumable_uri, "http://upload.example.com/2")
1425          self.assertEqual(media_upload, request.resumable)
1426          self.assertEqual(0, request.resumable_progress)
1427          status, body = request.next_chunk(http=http)
1428          self.assertEqual(request.resumable_uri, "http://upload.example.com/3")
1429          self.assertEqual(media_upload, request.resumable)
1430          self.assertEqual(13, request.resumable_progress)
1431          status, body = request.next_chunk(http=http)
1432          self.assertEqual(request.resumable_uri, "http://upload.example.com/4")
1433          self.assertEqual(media_upload.size() - 1, request.resumable_progress)
1434          self.assertEqual('{"data": {}}', request.body)
1435          status, body = request.next_chunk(http=http)
1436          self.assertEqual(body, {"foo": "bar"})
1437          self.assertEqual(status, None)
1438      def test_resumable_media_good_upload(self):
1439          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1440          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1441          media_upload = MediaFileUpload(datafile("small.png"), resumable=True)
1442          request = zoo.animals().insert(media_body=media_upload, body=None)
1443          self.assertEqual(media_upload, request.resumable)
1444          self.assertEqual("image/png", request.resumable.mimetype())
1445          self.assertEqual(request.body, None)
1446          self.assertEqual(request.resumable_uri, None)
1447          http = HttpMockSequence(
1448              [
1449                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1450                  (
1451                      {
1452                          "status": "308",
1453                          "location": "http://upload.example.com/2",
1454                          "range": "0-12",
1455                      },
1456                      "",
1457                  ),
1458                  (
1459                      {
1460                          "status": "308",
1461                          "location": "http://upload.example.com/3",
1462                          "range": "0-%d" % (media_upload.size() - 2),
1463                      },
1464                      "",
1465                  ),
1466                  ({"status": "200"}, '{"foo": "bar"}'),
1467              ]
1468          )
1469          status, body = request.next_chunk(http=http)
1470          self.assertEqual(None, body)
1471          self.assertTrue(isinstance(status, MediaUploadProgress))
1472          self.assertEqual(13, status.resumable_progress)
1473          self.assertEqual(request.resumable_uri, "http://upload.example.com/2")
1474          self.assertEqual(media_upload, request.resumable)
1475          self.assertEqual(13, request.resumable_progress)
1476          status, body = request.next_chunk(http=http)
1477          self.assertEqual(request.resumable_uri, "http://upload.example.com/3")
1478          self.assertEqual(media_upload.size() - 1, request.resumable_progress)
1479          self.assertEqual(request.body, None)
1480          status, body = request.next_chunk(http=http)
1481          self.assertEqual(body, {"foo": "bar"})
1482          self.assertEqual(status, None)
1483      def test_resumable_media_good_upload_from_execute(self):
1484          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1485          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1486          media_upload = MediaFileUpload(datafile("small.png"), resumable=True)
1487          request = zoo.animals().insert(media_body=media_upload, body=None)
1488          assertUrisEqual(
1489              self,
1490              "https://www.googleapis.com/upload/zoo/v1/animals?uploadType=resumable&alt=json",
1491              request.uri,
1492          )
1493          http = HttpMockSequence(
1494              [
1495                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1496                  (
1497                      {
1498                          "status": "308",
1499                          "location": "http://upload.example.com/2",
1500                          "range": "0-12",
1501                      },
1502                      "",
1503                  ),
1504                  (
1505                      {
1506                          "status": "308",
1507                          "location": "http://upload.example.com/3",
1508                          "range": "0-%d" % media_upload.size(),
1509                      },
1510                      "",
1511                  ),
1512                  ({"status": "200"}, '{"foo": "bar"}'),
1513              ]
1514          )
1515          body = request.execute(http=http)
1516          self.assertEqual(body, {"foo": "bar"})
1517      def test_resumable_media_fail_unknown_response_code_first_request(self):
1518          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1519          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1520          media_upload = MediaFileUpload(datafile("small.png"), resumable=True)
1521          request = zoo.animals().insert(media_body=media_upload, body=None)
1522          http = HttpMockSequence(
1523              [({"status": "400", "location": "http://upload.example.com"}, "")]
1524          )
1525          try:
1526              request.execute(http=http)
1527              self.fail("Should have raised ResumableUploadError.")
1528          except ResumableUploadError as e:
1529              self.assertEqual(400, e.resp.status)
1530      def test_resumable_media_fail_unknown_response_code_subsequent_request(self):
1531          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1532          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1533          media_upload = MediaFileUpload(datafile("small.png"), resumable=True)
1534          request = zoo.animals().insert(media_body=media_upload, body=None)
1535          http = HttpMockSequence(
1536              [
1537                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1538                  ({"status": "400"}, ""),
1539              ]
1540          )
1541          self.assertRaises(HttpError, request.execute, http=http)
1542          self.assertTrue(request._in_error_state)
1543          http = HttpMockSequence(
1544              [
1545                  ({"status": "308", "range": "0-5"}, ""),
1546                  ({"status": "308", "range": "0-6"}, ""),
1547              ]
1548          )
1549          status, body = request.next_chunk(http=http)
1550          self.assertEqual(
1551              status.resumable_progress,
1552              7,
1553              "Should have first checked length and then tried to PUT more.",
1554          )
1555          self.assertFalse(request._in_error_state)
1556          http = HttpMockSequence([({"status": "400"}, "")])
1557          self.assertRaises(HttpError, request.execute, http=http)
1558          self.assertTrue(request._in_error_state)
1559          http = HttpMockSequence([({"status": "200"}, '{"foo": "bar"}')])
1560          status, body = request.next_chunk(http=http)
1561          self.assertEqual(body, {"foo": "bar"})
1562      def test_media_io_base_stream_unlimited_chunksize_resume(self):
1563          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1564          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1565          fd = io.BytesIO(b'01234"56789"')
1566          media_upload = MediaIoBaseUpload(
1567              fd=fd, mimetype="text/plain", chunksize=-1, resumable=True
1568          )
1569          request = zoo.animals().insert(media_body=media_upload, body=None)
1570          http = HttpMockSequence(
1571              [
1572                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1573                  (
1574                      {
1575                          "status": "308",
1576                          "location": "http://upload.example.com/2",
1577                          "range": "0-4",
1578                      },
1579                      "",
1580                  ),
1581                  ({"status": "200"}, "echo_request_body"),
1582              ]
1583          )
1584          body = request.execute(http=http)
1585          self.assertEqual("56789", body)
1586      def test_media_io_base_stream_chunksize_resume(self):
1587          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1588          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1589          fd = io.BytesIO(b"0123456789")
1590          media_upload = MediaIoBaseUpload(
1591              fd=fd, mimetype="text/plain", chunksize=5, resumable=True
1592          )
1593          request = zoo.animals().insert(media_body=media_upload, body=None)
1594          http = HttpMockSequence(
1595              [
1596                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1597                  ({"status": "400"}, "echo_request_body"),
1598              ]
1599          )
1600          try:
1601              body = request.execute(http=http)
1602          except HttpError as e:
1603              self.assertEqual(b"01234", e.content)
1604      def test_resumable_media_handle_uploads_of_unknown_size(self):
1605          http = HttpMockSequence(
1606              [
1607                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1608                  ({"status": "200"}, "echo_request_headers_as_json"),
1609              ]
1610          )
1611          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1612          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1613          class IoBaseUnknownLength(MediaUpload):
1614              def chunksize(self):
1615                  return 10
1616              def mimetype(self):
1617                  return "image/png"
1618              def size(self):
1619                  return None
1620              def resumable(self):
1621                  return True
1622              def getbytes(self, begin, length):
1623                  return "0123456789"
1624          upload = IoBaseUnknownLength()
1625          request = zoo.animals().insert(media_body=upload, body=None)
1626          status, body = request.next_chunk(http=http)
1627      def test_resumable_media_no_streaming_on_unsupported_platforms(self):
1628          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1629          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1630          class IoBaseHasStream(MediaUpload):
1631              def chunksize(self):
1632                  return 10
1633              def mimetype(self):
1634                  return "image/png"
1635              def size(self):
1636                  return None
1637              def resumable(self):
1638                  return True
1639              def getbytes(self, begin, length):
1640                  return "0123456789"
1641              def has_stream(self):
1642                  return True
1643              def stream(self):
1644                  raise NotImplementedError()
1645          upload = IoBaseHasStream()
1646          orig_version = sys.version_info
1647          sys.version_info = (2, 6, 5, "final", 0)
1648          request = zoo.animals().insert(media_body=upload, body=None)
1649          http = HttpMockSequence(
1650              [
1651                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1652                  ({"status": "200"}, "echo_request_headers_as_json"),
1653              ]
1654          )
1655          self.assertRaises(NotImplementedError, request.next_chunk, http=http)
1656          sys.version_info = orig_version
1657      def test_resumable_media_handle_uploads_of_unknown_size_eof(self):
1658          http = HttpMockSequence(
1659              [
1660                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1661                  ({"status": "200"}, "echo_request_headers_as_json"),
1662              ]
1663          )
1664          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1665          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1666          fd = io.BytesIO(b"data goes here")
1667          upload = MediaIoBaseUpload(
1668              fd=fd, mimetype="image/png", chunksize=15, resumable=True
1669          )
1670          request = zoo.animals().insert(media_body=upload, body=None)
1671          status, body = request.next_chunk(http=http)
1672          self.assertEqual(
1673              body, {"Content-Range": "bytes 0-13/14", "Content-Length": "14"}
1674          )
1675      def test_resumable_media_handle_resume_of_upload_of_unknown_size(self):
1676          http = HttpMockSequence(
1677              [
1678                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1679                  ({"status": "400"}, ""),
1680              ]
1681          )
1682          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1683          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1684          fd = io.BytesIO(b"data goes here")
1685          upload = MediaIoBaseUpload(
1686              fd=fd, mimetype="image/png", chunksize=500, resumable=True
1687          )
1688          request = zoo.animals().insert(media_body=upload, body=None)
1689          self.assertRaises(HttpError, request.next_chunk, http=http)
1690          http = HttpMockSequence(
1691              [({"status": "400", "range": "0-5"}, "echo_request_headers_as_json")]
1692          )
1693          try:
1694              request.next_chunk(http=http)
1695          except HttpError as e:
1696              self.assertEqual(
1697                  expected,
1698                  json.loads(e.content.decode("utf-8")),
1699                  "Should send an empty body when requesting the current upload status.",
1700              )
1701      def test_pickle(self):
1702          sorted_resource_keys = [
1703              "_baseUrl",
1704              "_developerKey",
1705              "_dynamic_attrs",
1706              "_http",
1707              "_model",
1708              "_requestBuilder",
1709              "_resourceDesc",
1710              "_rootDesc",
1711              "_schema",
1712              "animals",
1713              "global_",
1714              "load",
1715              "loadNoTemplate",
1716              "my",
1717              "new_batch_http_request",
1718              "query",
1719              "scopedAnimals",
1720          ]
1721          http = HttpMock(datafile("zoo.json"), {"status": "200"})
1722          zoo = build("zoo", "v1", http=http, static_discovery=False)
1723          self.assertEqual(sorted(zoo.__dict__.keys()), sorted_resource_keys)
1724          pickled_zoo = pickle.dumps(zoo)
1725          new_zoo = pickle.loads(pickled_zoo)
1726          self.assertEqual(sorted(new_zoo.__dict__.keys()), sorted_resource_keys)
1727          self.assertTrue(hasattr(new_zoo, "animals"))
1728          self.assertTrue(callable(new_zoo.animals))
1729          self.assertTrue(hasattr(new_zoo, "global_"))
1730          self.assertTrue(callable(new_zoo.global_))
1731          self.assertTrue(hasattr(new_zoo, "load"))
1732          self.assertTrue(callable(new_zoo.load))
1733          self.assertTrue(hasattr(new_zoo, "loadNoTemplate"))
1734          self.assertTrue(callable(new_zoo.loadNoTemplate))
1735          self.assertTrue(hasattr(new_zoo, "my"))
1736          self.assertTrue(callable(new_zoo.my))
1737          self.assertTrue(hasattr(new_zoo, "query"))
1738          self.assertTrue(callable(new_zoo.query))
1739          self.assertTrue(hasattr(new_zoo, "scopedAnimals"))
1740          self.assertTrue(callable(new_zoo.scopedAnimals))
1741          self.assertEqual(sorted(zoo._dynamic_attrs), sorted(new_zoo._dynamic_attrs))
1742          self.assertEqual(zoo._baseUrl, new_zoo._baseUrl)
1743          self.assertEqual(zoo._developerKey, new_zoo._developerKey)
1744          self.assertEqual(zoo._requestBuilder, new_zoo._requestBuilder)
1745          self.assertEqual(zoo._resourceDesc, new_zoo._resourceDesc)
1746          self.assertEqual(zoo._rootDesc, new_zoo._rootDesc)
1747      def _dummy_zoo_request(self):
1748          zoo_contents = read_datafile("zoo.json")
1749          zoo_uri = uritemplate.expand(DISCOVERY_URI, {"api": "zoo", "apiVersion": "v1"})
1750          if "REMOTE_ADDR" in os.environ:
1751              zoo_uri = util._add_query_parameter(
1752                  zoo_uri, "userIp", os.environ["REMOTE_ADDR"]
1753              )
1754          http = build_http()
1755          original_request = http.request
1756          def wrapped_request(uri, method="GET", *args, **kwargs):
1757              if uri == zoo_uri:
1758                  return httplib2.Response({"status": "200"}), zoo_contents
1759              return original_request(uri, method=method, *args, **kwargs)
1760          http.request = wrapped_request
1761          return http
1762      def _dummy_token(self):
1763          access_token = "foo"
1764          client_id = "some_client_id"
1765          client_secret = "cOuDdkfjxxnv+"
1766          refresh_token = "1/0/a.df219fjls0"
1767          token_expiry = datetime.datetime.utcnow()
1768          user_agent = "refresh_checker/1.0"
1769          return OAuth2Credentials(
1770              access_token,
1771              client_id,
1772              client_secret,
1773              refresh_token,
1774              token_expiry,
1775              GOOGLE_TOKEN_URI,
1776              user_agent,
1777          )
1778      @unittest.skipIf(not HAS_OAUTH2CLIENT, "oauth2client unavailable.")
1779      def test_pickle_with_credentials(self):
1780          credentials = self._dummy_token()
1781          http = self._dummy_zoo_request()
1782          http = credentials.authorize(http)
1783          self.assertTrue(hasattr(http.request, "credentials"))
1784          zoo = build("zoo", "v1", http=http, static_discovery=False)
1785          pickled_zoo = pickle.dumps(zoo)
1786          new_zoo = pickle.loads(pickled_zoo)
1787          self.assertEqual(sorted(zoo.__dict__.keys()), sorted(new_zoo.__dict__.keys()))
1788          new_http = new_zoo._http
1789          self.assertFalse(hasattr(new_http.request, "credentials"))
1790      def test_resumable_media_upload_no_content(self):
1791          self.http = HttpMock(datafile("zoo.json"), {"status": "200"})
1792          zoo = build("zoo", "v1", http=self.http, static_discovery=False)
1793          media_upload = MediaFileUpload(datafile("empty"), resumable=True)
1794          request = zoo.animals().insert(media_body=media_upload, body=None)
1795          self.assertEqual(media_upload, request.resumable)
1796          self.assertEqual(request.body, None)
1797          self.assertEqual(request.resumable_uri, None)
1798          http = HttpMockSequence(
1799              [
1800                  ({"status": "200", "location": "http://upload.example.com"}, ""),
1801                  (
1802                      {
1803                          "status": "308",
1804                          "location": "http://upload.example.com/2",
1805                          "range": "0-0",
1806                      },
1807                      "",
1808                  ),
1809              ]
1810          )
1811          status, body = request.next_chunk(http=http)
1812          self.assertEqual(None, body)
1813          self.assertTrue(isinstance(status, MediaUploadProgress))
1814          self.assertEqual(0, status.progress())
1815  class Next(unittest.TestCase):
1816      def test_next_successful_none_on_no_next_page_token(self):
1817          self.http = HttpMock(datafile("tasks.json"), {"status": "200"})
1818          tasks = build("tasks", "v1", http=self.http)
1819          request = tasks.tasklists().list()
1820          self.assertEqual(None, tasks.tasklists().list_next(request, {}))
1821      def test_next_successful_none_on_empty_page_token(self):
1822          self.http = HttpMock(datafile("tasks.json"), {"status": "200"})
1823          tasks = build("tasks", "v1", http=self.http)
1824          request = tasks.tasklists().list()
1825          next_request = tasks.tasklists().list_next(request, {"nextPageToken": ""})
1826          self.assertEqual(None, next_request)
1827      def test_next_successful_with_next_page_token(self):
1828          self.http = HttpMock(datafile("tasks.json"), {"status": "200"})
1829          tasks = build("tasks", "v1", http=self.http)
1830          request = tasks.tasklists().list()
1831          next_request = tasks.tasklists().list_next(request, {"nextPageToken": "123abc"})
1832          parsed = urllib.parse.urlparse(next_request.uri)
1833          q = urllib.parse.parse_qs(parsed.query)
1834          self.assertEqual(q["pageToken"][0], "123abc")
1835      def test_next_successful_with_next_page_token_alternate_name(self):
1836          self.http = HttpMock(datafile("bigquery.json"), {"status": "200"})
1837          bigquery = build("bigquery", "v2", http=self.http)
1838          request = bigquery.tabledata().list(datasetId="", projectId="", tableId="")
1839          next_request = bigquery.tabledata().list_next(request, {"pageToken": "123abc"})
1840          parsed = urllib.parse.urlparse(next_request.uri)
1841          q = urllib.parse.parse_qs(parsed.query)
1842          self.assertEqual(q["pageToken"][0], "123abc")
1843      def test_next_successful_with_next_page_token_in_body(self):
1844          self.http = HttpMock(datafile("logging.json"), {"status": "200"})
1845          logging = build("logging", "v2", http=self.http)
1846          request = logging.entries().list(body={})
1847          next_request = logging.entries().list_next(request, {"nextPageToken": "123abc"})
1848          body = JsonModel().deserialize(next_request.body)
1849          self.assertEqual(body["pageToken"], "123abc")
1850          self.assertEqual(next_request.body_size, len(next_request.body))
1851      def test_next_with_method_with_no_properties(self):
1852          self.http = HttpMock(datafile("latitude.json"), {"status": "200"})
1853          service = build("latitude", "v1", http=self.http, static_discovery=False)
1854          service.currentLocation().get()
1855      def test_next_nonexistent_with_no_next_page_token(self):
1856          self.http = HttpMock(datafile("drive.json"), {"status": "200"})
1857          drive = build("drive", "v3", http=self.http)
1858          drive.changes().watch(body={})
1859          self.assertFalse(callable(getattr(drive.changes(), "watch_next", None)))
1860      def test_next_successful_with_next_page_token_required(self):
1861          self.http = HttpMock(datafile("drive.json"), {"status": "200"})
1862          drive = build("drive", "v3", http=self.http)
1863          request = drive.changes().list(pageToken="startPageToken")
1864          next_request = drive.changes().list_next(request, {"nextPageToken": "123abc"})
1865          parsed = urllib.parse.urlparse(next_request.uri)
1866          q = urllib.parse.parse_qs(parsed.query)
1867          self.assertEqual(q["pageToken"][0], "123abc")
1868  class MediaGet(unittest.TestCase):
1869      def test_get_media(self):
1870          http = HttpMock(datafile("zoo.json"), {"status": "200"})
1871          zoo = build("zoo", "v1", http=http, static_discovery=False)
1872          request = zoo.animals().get_media(name="Lion")
1873          parsed = urllib.parse.urlparse(request.uri)
1874          q = urllib.parse.parse_qs(parsed.query)
1875          self.assertEqual(q["alt"], ["media"])
1876          http = HttpMockSequence([({"status": "200"}, "standing in for media")])
1877          response = request.execute(http=http)
1878          self.assertEqual(b"standing in for media", response)
1879  if __name__ == "__main__":
1880      unittest.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-multibox_loss.py</div>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from google-api-python-client-MDEwOlJlcG9zaXRvcnkxNTc0OTI2OQ==-flat-test_discovery.py</div>
                <div class="column column_space"><pre><code>159              self.total_instances += targets_weighted.size(0)
160              weighting = 1 - (self.class_instances[targets_weighted] / self.total_instances)
161              weighting = torch.clamp(weighting, min=1/self.num_classes)
</pre></code></div>
                <div class="column column_space"><pre><code>618  class DiscoveryFromDocumentMutualTLS(unittest.TestCase):
619      MOCK_CREDENTIALS = mock.Mock(spec=google.auth.credentials.Credentials)
620      ADC_CERT_PATH = "adc_cert_path"
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    