
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 65, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-decoder_test.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import tensorflow as tf
6  import numpy as np
7  from seq2seq.decoders import BasicDecoder, AttentionDecoder, AttentionLayerDot
8  from seq2seq.decoders import beam_search_decoder
9  from seq2seq.inference import beam_search
10  from seq2seq.contrib.seq2seq import helper as decode_helper
11  class DecoderTests(object):
12    def __init__(self):
13      self.batch_size = 4
14      self.sequence_length = 16
15      self.input_depth = 10
16      self.vocab_size = 100
17      self.max_decode_length = 20
18    def create_decoder(self, helper, mode):
19      raise NotImplementedError
20    def test_with_fixed_inputs(self):
21      inputs = tf.random_normal(
22          [self.batch_size, self.sequence_length, self.input_depth])
23      seq_length = tf.ones(self.batch_size, dtype=tf.int32) * self.sequence_length
24      helper = decode_helper.TrainingHelper(
25          inputs=inputs, sequence_length=seq_length)
26      decoder_fn = self.create_decoder(
27          helper=helper, mode=tf.contrib.learn.ModeKeys.TRAIN)
28      initial_state = decoder_fn.cell.zero_state(
29          self.batch_size, dtype=tf.float32)
30      decoder_output, _ = decoder_fn(initial_state, helper)
31      with self.test_session() as sess:
32        sess.run(tf.global_variables_initializer())
33        decoder_output_ = sess.run(decoder_output)
34      np.testing.assert_array_equal(
35          decoder_output_.logits.shape,
36          [self.sequence_length, self.batch_size, self.vocab_size])
37      np.testing.assert_array_equal(decoder_output_.predicted_ids.shape,
38                                    [self.sequence_length, self.batch_size])
39      return decoder_output_
40    def test_gradients(self):
41      inputs = tf.random_normal(
42          [self.batch_size, self.sequence_length, self.input_depth])
43      seq_length = tf.ones(self.batch_size, dtype=tf.int32) * self.sequence_length
44      labels = np.random.randint(0, self.vocab_size,
45                                 [self.batch_size, self.sequence_length])
46      helper = decode_helper.TrainingHelper(
47          inputs=inputs, sequence_length=seq_length)
48      decoder_fn = self.create_decoder(
49          helper=helper, mode=tf.contrib.learn.ModeKeys.TRAIN)
50      initial_state = decoder_fn.cell.zero_state(
51          self.batch_size, dtype=tf.float32)
52      decoder_output, _ = decoder_fn(initial_state, helper)
53      losses = tf.nn.sparse_softmax_cross_entropy_with_logits(
54          logits=decoder_output.logits, labels=labels)
55      optimizer = tf.train.AdamOptimizer(learning_rate=0.001)
56      grads_and_vars = optimizer.compute_gradients(tf.reduce_mean(losses))
57      with self.test_session() as sess:
58        sess.run(tf.global_variables_initializer())
59        grads_and_vars_ = sess.run(grads_and_vars)
60      for grad, _ in grads_and_vars_:
61        self.assertFalse(np.isnan(grad).any())
62      return grads_and_vars_
63    def test_with_dynamic_inputs(self):
<span onclick='openModal()' class='match'>64      embeddings = tf.get_variable("W_embed", [self.vocab_size, self.input_depth])
65      helper = decode_helper.GreedyEmbeddingHelper(
66          embedding=embeddings, start_tokens=[0] * self.batch_size, end_token=-1)
67      decoder_fn = self.create_decoder(
68          helper=helper, mode=tf.contrib.learn.ModeKeys.INFER)
69      initial_state = decoder_fn.cell.zero_state(
</span>70          self.batch_size, dtype=tf.float32)
71      decoder_output, _ = decoder_fn(initial_state, helper)
72      with self.test_session() as sess:
73        sess.run(tf.global_variables_initializer())
74        decoder_output_ = sess.run(decoder_output)
75      np.testing.assert_array_equal(
76          decoder_output_.logits.shape,
77          [self.max_decode_length, self.batch_size, self.vocab_size])
78      np.testing.assert_array_equal(decoder_output_.predicted_ids.shape,
79                                    [self.max_decode_length, self.batch_size])
80    def test_with_beam_search(self):
81      self.batch_size = 1
82      config = beam_search.BeamSearchConfig(
83          beam_width=10,
84          vocab_size=self.vocab_size,
85          eos_token=self.vocab_size - 2,
86          length_penalty_weight=0.6,
87          choose_successors_fn=beam_search.choose_top_k)
88      embeddings = tf.get_variable("W_embed", [self.vocab_size, self.input_depth])
89      helper = decode_helper.GreedyEmbeddingHelper(
90          embedding=embeddings,
91          start_tokens=[0] * config.beam_width,
92          end_token=-1)
93      decoder_fn = self.create_decoder(
94          helper=helper, mode=tf.contrib.learn.ModeKeys.INFER)
95      decoder_fn = beam_search_decoder.BeamSearchDecoder(
96          decoder=decoder_fn, config=config)
97      initial_state = decoder_fn.cell.zero_state(
98          self.batch_size, dtype=tf.float32)
99      decoder_output, _ = decoder_fn(initial_state, helper)
100      with self.test_session() as sess:
101        sess.run(tf.global_variables_initializer())
102        decoder_output_ = sess.run(decoder_output)
103      np.testing.assert_array_equal(
104          decoder_output_.predicted_ids.shape,
105          [self.max_decode_length, 1, config.beam_width])
106      np.testing.assert_array_equal(
107          decoder_output_.beam_search_output.beam_parent_ids.shape,
108          [self.max_decode_length, 1, config.beam_width])
109      np.testing.assert_array_equal(
110          decoder_output_.beam_search_output.scores.shape,
111          [self.max_decode_length, 1, config.beam_width])
112      np.testing.assert_array_equal(
113          decoder_output_.beam_search_output.original_outputs.predicted_ids.shape,
114          [self.max_decode_length, 1, config.beam_width])
115      np.testing.assert_array_equal(
116          decoder_output_.beam_search_output.original_outputs.logits.shape,
117          [self.max_decode_length, 1, config.beam_width, self.vocab_size])
118      return decoder_output
119  class BasicDecoderTest(tf.test.TestCase, DecoderTests):
120    def setUp(self):
121      tf.test.TestCase.setUp(self)
122      tf.logging.set_verbosity(tf.logging.INFO)
123      DecoderTests.__init__(self)
124    def create_decoder(self, helper, mode):
125      params = BasicDecoder.default_params()
126      params["max_decode_length"] = self.max_decode_length
127      decoder = BasicDecoder(params=params, mode=mode, vocab_size=self.vocab_size)
128      return decoder
129  class AttentionDecoderTest(tf.test.TestCase, DecoderTests):
130    def setUp(self):
131      tf.test.TestCase.setUp(self)
132      tf.logging.set_verbosity(tf.logging.INFO)
133      DecoderTests.__init__(self)
134      self.attention_dim = 64
135      self.input_seq_len = 10
136    def create_decoder(self, helper, mode):
137      attention_fn = AttentionLayerDot(
138          params={"num_units": self.attention_dim},
139          mode=tf.contrib.learn.ModeKeys.TRAIN)
140      attention_values = tf.convert_to_tensor(
141          np.random.randn(self.batch_size, self.input_seq_len, 32),
142          dtype=tf.float32)
143      attention_keys = tf.convert_to_tensor(
144          np.random.randn(self.batch_size, self.input_seq_len, 32),
145          dtype=tf.float32)
146      params = AttentionDecoder.default_params()
147      params["max_decode_length"] = self.max_decode_length
148      return AttentionDecoder(
149          params=params,
150          mode=mode,
151          vocab_size=self.vocab_size,
152          attention_keys=attention_keys,
153          attention_values=attention_values,
154          attention_values_length=np.arange(self.batch_size) + 1,
155          attention_fn=attention_fn)
156    def test_attention_scores(self):
157      decoder_output_ = self.test_with_fixed_inputs()
158      np.testing.assert_array_equal(
159          decoder_output_.attention_scores.shape,
160          [self.sequence_length, self.batch_size, self.input_seq_len])
161      scores_sum = np.sum(decoder_output_.attention_scores, axis=2)
162      np.testing.assert_array_almost_equal(
163          scores_sum, np.ones([self.sequence_length, self.batch_size]))
164  if __name__ == "__main__":
165    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-decoder_test.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import tensorflow as tf
6  import numpy as np
7  from seq2seq.decoders import BasicDecoder, AttentionDecoder, AttentionLayerDot
8  from seq2seq.decoders import beam_search_decoder
9  from seq2seq.inference import beam_search
10  from seq2seq.contrib.seq2seq import helper as decode_helper
11  class DecoderTests(object):
12    def __init__(self):
13      self.batch_size = 4
14      self.sequence_length = 16
15      self.input_depth = 10
16      self.vocab_size = 100
17      self.max_decode_length = 20
18    def create_decoder(self, helper, mode):
19      raise NotImplementedError
20    def test_with_fixed_inputs(self):
21      inputs = tf.random_normal(
22          [self.batch_size, self.sequence_length, self.input_depth])
23      seq_length = tf.ones(self.batch_size, dtype=tf.int32) * self.sequence_length
24      helper = decode_helper.TrainingHelper(
25          inputs=inputs, sequence_length=seq_length)
26      decoder_fn = self.create_decoder(
27          helper=helper, mode=tf.contrib.learn.ModeKeys.TRAIN)
28      initial_state = decoder_fn.cell.zero_state(
29          self.batch_size, dtype=tf.float32)
30      decoder_output, _ = decoder_fn(initial_state, helper)
31      with self.test_session() as sess:
32        sess.run(tf.global_variables_initializer())
33        decoder_output_ = sess.run(decoder_output)
34      np.testing.assert_array_equal(
35          decoder_output_.logits.shape,
36          [self.sequence_length, self.batch_size, self.vocab_size])
37      np.testing.assert_array_equal(decoder_output_.predicted_ids.shape,
38                                    [self.sequence_length, self.batch_size])
39      return decoder_output_
40    def test_gradients(self):
41      inputs = tf.random_normal(
42          [self.batch_size, self.sequence_length, self.input_depth])
43      seq_length = tf.ones(self.batch_size, dtype=tf.int32) * self.sequence_length
44      labels = np.random.randint(0, self.vocab_size,
45                                 [self.batch_size, self.sequence_length])
46      helper = decode_helper.TrainingHelper(
47          inputs=inputs, sequence_length=seq_length)
48      decoder_fn = self.create_decoder(
49          helper=helper, mode=tf.contrib.learn.ModeKeys.TRAIN)
50      initial_state = decoder_fn.cell.zero_state(
51          self.batch_size, dtype=tf.float32)
52      decoder_output, _ = decoder_fn(initial_state, helper)
53      losses = tf.nn.sparse_softmax_cross_entropy_with_logits(
54          logits=decoder_output.logits, labels=labels)
55      optimizer = tf.train.AdamOptimizer(learning_rate=0.001)
56      grads_and_vars = optimizer.compute_gradients(tf.reduce_mean(losses))
57      with self.test_session() as sess:
58        sess.run(tf.global_variables_initializer())
59        grads_and_vars_ = sess.run(grads_and_vars)
60      for grad, _ in grads_and_vars_:
61        self.assertFalse(np.isnan(grad).any())
62      return grads_and_vars_
63    def test_with_dynamic_inputs(self):
64      embeddings = tf.get_variable("W_embed", [self.vocab_size, self.input_depth])
65      helper = decode_helper.GreedyEmbeddingHelper(
66          embedding=embeddings, start_tokens=[0] * self.batch_size, end_token=-1)
67      decoder_fn = self.create_decoder(
68          helper=helper, mode=tf.contrib.learn.ModeKeys.INFER)
69      initial_state = decoder_fn.cell.zero_state(
70          self.batch_size, dtype=tf.float32)
71      decoder_output, _ = decoder_fn(initial_state, helper)
72      with self.test_session() as sess:
73        sess.run(tf.global_variables_initializer())
74        decoder_output_ = sess.run(decoder_output)
75      np.testing.assert_array_equal(
76          decoder_output_.logits.shape,
77          [self.max_decode_length, self.batch_size, self.vocab_size])
78      np.testing.assert_array_equal(decoder_output_.predicted_ids.shape,
79                                    [self.max_decode_length, self.batch_size])
80    def test_with_beam_search(self):
81      self.batch_size = 1
82      config = beam_search.BeamSearchConfig(
83          beam_width=10,
84          vocab_size=self.vocab_size,
85          eos_token=self.vocab_size - 2,
86          length_penalty_weight=0.6,
87          choose_successors_fn=beam_search.choose_top_k)
<span onclick='openModal()' class='match'>88      embeddings = tf.get_variable("W_embed", [self.vocab_size, self.input_depth])
89      helper = decode_helper.GreedyEmbeddingHelper(
90          embedding=embeddings,
91          start_tokens=[0] * config.beam_width,
92          end_token=-1)
93      decoder_fn = self.create_decoder(
94          helper=helper, mode=tf.contrib.learn.ModeKeys.INFER)
95      decoder_fn = beam_search_decoder.BeamSearchDecoder(
</span>96          decoder=decoder_fn, config=config)
97      initial_state = decoder_fn.cell.zero_state(
98          self.batch_size, dtype=tf.float32)
99      decoder_output, _ = decoder_fn(initial_state, helper)
100      with self.test_session() as sess:
101        sess.run(tf.global_variables_initializer())
102        decoder_output_ = sess.run(decoder_output)
103      np.testing.assert_array_equal(
104          decoder_output_.predicted_ids.shape,
105          [self.max_decode_length, 1, config.beam_width])
106      np.testing.assert_array_equal(
107          decoder_output_.beam_search_output.beam_parent_ids.shape,
108          [self.max_decode_length, 1, config.beam_width])
109      np.testing.assert_array_equal(
110          decoder_output_.beam_search_output.scores.shape,
111          [self.max_decode_length, 1, config.beam_width])
112      np.testing.assert_array_equal(
113          decoder_output_.beam_search_output.original_outputs.predicted_ids.shape,
114          [self.max_decode_length, 1, config.beam_width])
115      np.testing.assert_array_equal(
116          decoder_output_.beam_search_output.original_outputs.logits.shape,
117          [self.max_decode_length, 1, config.beam_width, self.vocab_size])
118      return decoder_output
119  class BasicDecoderTest(tf.test.TestCase, DecoderTests):
120    def setUp(self):
121      tf.test.TestCase.setUp(self)
122      tf.logging.set_verbosity(tf.logging.INFO)
123      DecoderTests.__init__(self)
124    def create_decoder(self, helper, mode):
125      params = BasicDecoder.default_params()
126      params["max_decode_length"] = self.max_decode_length
127      decoder = BasicDecoder(params=params, mode=mode, vocab_size=self.vocab_size)
128      return decoder
129  class AttentionDecoderTest(tf.test.TestCase, DecoderTests):
130    def setUp(self):
131      tf.test.TestCase.setUp(self)
132      tf.logging.set_verbosity(tf.logging.INFO)
133      DecoderTests.__init__(self)
134      self.attention_dim = 64
135      self.input_seq_len = 10
136    def create_decoder(self, helper, mode):
137      attention_fn = AttentionLayerDot(
138          params={"num_units": self.attention_dim},
139          mode=tf.contrib.learn.ModeKeys.TRAIN)
140      attention_values = tf.convert_to_tensor(
141          np.random.randn(self.batch_size, self.input_seq_len, 32),
142          dtype=tf.float32)
143      attention_keys = tf.convert_to_tensor(
144          np.random.randn(self.batch_size, self.input_seq_len, 32),
145          dtype=tf.float32)
146      params = AttentionDecoder.default_params()
147      params["max_decode_length"] = self.max_decode_length
148      return AttentionDecoder(
149          params=params,
150          mode=mode,
151          vocab_size=self.vocab_size,
152          attention_keys=attention_keys,
153          attention_values=attention_values,
154          attention_values_length=np.arange(self.batch_size) + 1,
155          attention_fn=attention_fn)
156    def test_attention_scores(self):
157      decoder_output_ = self.test_with_fixed_inputs()
158      np.testing.assert_array_equal(
159          decoder_output_.attention_scores.shape,
160          [self.sequence_length, self.batch_size, self.input_seq_len])
161      scores_sum = np.sum(decoder_output_.attention_scores, axis=2)
162      np.testing.assert_array_almost_equal(
163          scores_sum, np.ones([self.sequence_length, self.batch_size]))
164  if __name__ == "__main__":
165    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-decoder_test.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-decoder_test.py</div>
                </div>
                <div class="column column_space"><pre><code>64      embeddings = tf.get_variable("W_embed", [self.vocab_size, self.input_depth])
65      helper = decode_helper.GreedyEmbeddingHelper(
66          embedding=embeddings, start_tokens=[0] * self.batch_size, end_token=-1)
67      decoder_fn = self.create_decoder(
68          helper=helper, mode=tf.contrib.learn.ModeKeys.INFER)
69      initial_state = decoder_fn.cell.zero_state(
</pre></code></div>
                <div class="column column_space"><pre><code>88      embeddings = tf.get_variable("W_embed", [self.vocab_size, self.input_depth])
89      helper = decode_helper.GreedyEmbeddingHelper(
90          embedding=embeddings,
91          start_tokens=[0] * config.beam_width,
92          end_token=-1)
93      decoder_fn = self.create_decoder(
94          helper=helper, mode=tf.contrib.learn.ModeKeys.INFER)
95      decoder_fn = beam_search_decoder.BeamSearchDecoder(
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    