
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 16, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-rmsprop_test.py</h3>
            <pre><code>1  from sonnet.src import test_utils
2  from sonnet.src.optimizers import optimizer_tests
3  from sonnet.src.optimizers import rmsprop
4  import tensorflow as tf
5  CONFIGS = optimizer_tests.named_product(learning_rate=(0.01, 0.001),
<span onclick='openModal()' class='match'>6                                          decay=(0.8, 0.9),
7                                          momentum=(0.0, 0.5),
8                                          epsilon=(1e-7, 1e-8),
</span>9                                          centered=(False, True),
10                                          seed=(28, 2, 90))
11  class ComparisonTest(optimizer_tests.AbstractFuzzTest):
12    def _make_tf(self, learning_rate, decay, momentum, epsilon, centered):
13      optimizer = tf.optimizers.RMSprop(learning_rate=learning_rate,
14                                        rho=decay,
15                                        momentum=momentum,
16                                        epsilon=epsilon,
17                                        centered=centered)
18      return lambda g, p: optimizer.apply_gradients(zip(g, p))
19    def _make_snt(self, learning_rate, decay, momentum, epsilon, centered):
20      optimizer = rmsprop.RMSProp(learning_rate=learning_rate,
21                                  decay=decay,
22                                  momentum=momentum,
23                                  epsilon=epsilon,
24                                  centered=centered)
25      return optimizer.apply
26    @test_utils.combined_named_parameters(CONFIGS)
27    def testComparingSonnetAndTensorFlow(self, config):
28      seed = config.pop("seed")
29      self.assertParametersRemainClose(seed, config, atol=1e-2)
30  class RMSPropTest(optimizer_tests.OptimizerTestBase):
31    def make_optimizer(self, **kwargs):
32      if "learning_rate" not in kwargs:
33        kwargs["learning_rate"] = 0.1
34      return rmsprop.RMSProp(**kwargs)
35    def testDense(self):
36      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
37      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
38      optimizer = self.make_optimizer(learning_rate=0.1)
39      optimizer.apply(updates, parameters)
40      self.assertAllClose([[0.683772, 1.683772], [2.683772, 3.683772]],
41                          [x.numpy() for x in parameters])
42      optimizer.apply(updates, parameters)
43      self.assertAllClose([[0.454357, 1.454357], [2.454357, 3.454357]],
44                          [x.numpy() for x in parameters])
45      optimizer.apply(updates, parameters)
46      self.assertAllClose([[0.262262, 1.262262], [2.262262, 3.262262]],
47                          [x.numpy() for x in parameters])
48    def testDenseCentered(self):
49      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
50      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
51      optimizer = self.make_optimizer(learning_rate=0.1, centered=True)
52      optimizer.apply(updates, parameters)
53      self.assertAllClose([[0.666667, 1.666667], [2.666667, 3.666667]],
54                          [x.numpy() for x in parameters])
55      optimizer.apply(updates, parameters)
56      self.assertAllClose([[0.41176, 1.41176], [2.41176, 3.41176]],
57                          [x.numpy() for x in parameters])
58      optimizer.apply(updates, parameters)
59      self.assertAllClose([[0.186776, 1.186776], [2.186776, 3.186776]],
60                          [x.numpy() for x in parameters])
61    def testSparse(self):
62      if self.primary_device in ("GPU", "TPU"):
63        self.skipTest("IndexedSlices not supported on {}.".format(
64            self.primary_device))
65      parameters = [tf.Variable([[1.], [2.]]), tf.Variable([[3.], [4.]])]
66      updates = [
67          tf.IndexedSlices(
68              tf.constant([0.1], shape=[1, 1]), tf.constant([0]),
69              tf.constant([2, 1])),
70          tf.IndexedSlices(
71              tf.constant([0.01], shape=[1, 1]), tf.constant([1]),
72              tf.constant([2, 1]))
73      ]
74      optimizer = self.make_optimizer(learning_rate=3.)
75      optimizer.apply(updates, parameters)
76      self.assertAllClose([[-8.486831], [2.0]], parameters[0].numpy(), rtol=1e-4)
77      self.assertAllClose([[3.0], [-5.486784]], parameters[1].numpy(), rtol=1e-4)
78      optimizer.apply(updates, parameters)
79      self.assertAllClose([[-15.369301], [2.0]], parameters[0].numpy(), rtol=1e-4)
80      self.assertAllClose([[3.0], [-12.369237]], parameters[1].numpy(), rtol=1e-4)
81      optimizer.apply(updates, parameters)
82      self.assertAllClose([[-21.132141], [2.0]], parameters[0].numpy(), rtol=1e-4)
83      self.assertAllClose([[3.0], [-18.132067]], parameters[1].numpy(), rtol=1e-4)
84    def testSparseCentered(self):
85      if self.primary_device in ("GPU", "TPU"):
86        self.skipTest("IndexedSlices not supported on {}.".format(
87            self.primary_device))
88      parameters = [tf.Variable([[1.], [2.]]), tf.Variable([[3.], [4.]])]
89      updates = [
90          tf.IndexedSlices(
91              tf.constant([0.1], shape=[1, 1]), tf.constant([0]),
92              tf.constant([2, 1])),
93          tf.IndexedSlices(
94              tf.constant([0.01], shape=[1, 1]), tf.constant([1]),
95              tf.constant([2, 1]))
96      ]
97      optimizer = self.make_optimizer(learning_rate=3., centered=True)
98      optimizer.apply(updates, parameters)
99      self.assertAllClose([[-8.999999], [2.0]], parameters[0].numpy(), rtol=1e-4)
100      self.assertAllClose([[3.0], [-5.999944]], parameters[1].numpy(), rtol=1e-4)
101      optimizer.apply(updates, parameters)
102      self.assertAllClose([[-16.64719], [2.0]], parameters[0].numpy(), rtol=1e-4)
103      self.assertAllClose([[3.0], [-13.647109]], parameters[1].numpy(), rtol=1e-4)
104      optimizer.apply(updates, parameters)
105      self.assertAllClose([[-23.396709], [2.0]], parameters[0].numpy(), rtol=1e-4)
106      self.assertAllClose([[3.0], [-20.39661]], parameters[1].numpy(), rtol=1e-4)
107    def testVariableHyperParams(self):
108      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
109      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
110      learning_rate = tf.Variable(0.1)
111      optimizer = self.make_optimizer(learning_rate=learning_rate)
112      optimizer.apply(updates, parameters)
113      self.assertAllClose([[0.683772, 1.683772], [2.683772, 3.683772]],
114                          [x.numpy() for x in parameters])
115      learning_rate.assign(0.01)
116      self.assertAlmostEqual(0.01, optimizer.learning_rate.numpy())
117      optimizer.apply(updates, parameters)
118      self.assertAllClose([[0.660831, 1.660831], [2.660831, 3.660831]],
119                          [x.numpy() for x in parameters])
120    def testHyperParamDTypeConversion(self):
121      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
122      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
123      dtype = tf.float32 if self.primary_device == "TPU" else tf.float64
124      learning_rate = tf.Variable(0.1, dtype=dtype)
125      decay = tf.Variable(0.9, dtype=dtype)
126      momentum = tf.Variable(0.0, dtype=dtype)
127      epsilon = tf.Variable(1e-7, dtype=dtype)
128      optimizer = self.make_optimizer(
129          learning_rate=learning_rate,
130          decay=decay,
131          momentum=momentum,
132          epsilon=epsilon)
133      if optimizer_tests.is_tf_optimizer(optimizer):
134        self.skipTest("TF optimizers don't support automatic casting.")
135      optimizer.apply(updates, parameters)
136      self.assertAllClose([[0.683772, 1.683772], [2.683772, 3.683772]],
137                          [x.numpy() for x in parameters])
138    def testAuxVariablesColocatedWithOriginal(self):
139      optimizer = self.make_optimizer(learning_rate=0.1)
140      if optimizer_tests.is_tf_optimizer(optimizer):
141        self.skipTest("Aux vars are in a different location for TF optimizers.")
142      with tf.device("CPU:0"):
143        var = tf.Variable(1.0)
144      optimizer.apply([tf.constant(0.1)], [var])
145      self.assertEqual(optimizer.mom[0].device, var.device)
146      self.assertEqual(optimizer.ms[0].device, var.device)
147  class ReferenceRMSPropTest(RMSPropTest):
148    def make_optimizer(self, **kwargs):
149      if "learning_rate" not in kwargs:
150        kwargs["learning_rate"] = 0.1
151      kwargs["rho"] = kwargs.pop("decay", 0.9)
152      if hasattr(tf.keras.optimizers, "legacy"):
153        return optimizer_tests.WrappedTFOptimizer(
154            tf.keras.optimizers.legacy.RMSprop(**kwargs))
155      return optimizer_tests.WrappedTFOptimizer(
156          tf.keras.optimizers.RMSprop(**kwargs))
157  if __name__ == "__main__":
158    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-test.py</h3>
            <pre><code>1  #!/usr/bin/env python
2  from __future__ import absolute_import
3  from __future__ import print_function
4  from __future__ import division
5  import time
6  import torch
7  import torch.nn as nn
8  from torch.autograd import gradcheck
9  from dcn_v2 import dcn_v2_conv, DCNv2, DCN
10  from dcn_v2 import dcn_v2_pooling, DCNv2Pooling, DCNPooling
11  deformable_groups = 1
12  N, inC, inH, inW = 2, 2, 4, 4
13  outC = 2
14  kH, kW = 3, 3
15  def conv_identify(weight, bias):
16      weight.data.zero_()
17      bias.data.zero_()
18      o, i, h, w = weight.shape
19      y = h//2
20      x = w//2
21      for p in range(i):
22          for q in range(o):
23              if p == q:
24                  weight.data[q, p, y, x] = 1.0
25  def check_zero_offset():
26      conv_offset = nn.Conv2d(inC, deformable_groups * 2 * kH * kW,
27                              kernel_size=(kH, kW),
28                              stride=(1, 1),
29                              padding=(1, 1),
30                              bias=True).cuda()
31      conv_mask = nn.Conv2d(inC, deformable_groups * 1 * kH * kW,
32                            kernel_size=(kH, kW),
<span onclick='openModal()' class='match'>33                            stride=(1, 1),
34                            padding=(1, 1),
35                            bias=True).cuda()
</span>36      dcn_v2 = DCNv2(inC, outC, (kH, kW),
37                     stride=1, padding=1, dilation=1,
38                     deformable_groups=deformable_groups).cuda()
39      conv_offset.weight.data.zero_()
40      conv_offset.bias.data.zero_()
41      conv_mask.weight.data.zero_()
42      conv_mask.bias.data.zero_()
43      conv_identify(dcn_v2.weight, dcn_v2.bias)
44      input = torch.randn(N, inC, inH, inW).cuda()
45      offset = conv_offset(input)
46      mask = conv_mask(input)
47      mask = torch.sigmoid(mask)
48      output = dcn_v2(input, offset, mask)
49      output *= 2
50      d = (input - output).abs().max()
51      if d < 1e-10:
52          print('Zero offset passed')
53      else:
54          print('Zero offset failed')
55          print(input)
56          print(output)
57  def check_gradient_dconv():
58      input = torch.rand(N, inC, inH, inW).cuda() * 0.01
59      input.requires_grad = True
60      offset = torch.randn(N, deformable_groups * 2 * kW * kH, inH, inW).cuda() * 2
61      offset.requires_grad = True
62      mask = torch.rand(N, deformable_groups * 1 * kW * kH, inH, inW).cuda()
63      mask.requires_grad = True
64      mask = torch.sigmoid(mask)
65      weight = torch.randn(outC, inC, kH, kW).cuda()
66      weight.requires_grad = True
67      bias = torch.rand(outC).cuda()
68      bias.requires_grad = True
69      stride = 1
70      padding = 1
71      dilation = 1
72      print('check_gradient_dconv: ',
73            gradcheck(dcn_v2_conv, (input, offset, mask, weight, bias,
74                      stride, padding, dilation, deformable_groups),
75                      eps=1e-3, atol=1e-4, rtol=1e-2))
76  def check_pooling_zero_offset():
77      input = torch.randn(2, 16, 64, 64).cuda().zero_()
78      input[0, :, 16:26, 16:26] = 1.
79      input[1, :, 10:20, 20:30] = 2.
80      rois = torch.tensor([
81          [0, 65, 65, 103, 103],
82          [1, 81, 41, 119, 79],
83      ]).cuda().float()
84      pooling = DCNv2Pooling(spatial_scale=1.0 / 4,
85                             pooled_size=7,
86                             output_dim=16,
87                             no_trans=True,
88                             group_size=1,
89                             trans_std=0.0).cuda()
90      out = pooling(input, rois, input.new())
91      s = ', '.join(['%f' % out[i, :, :, :].mean().item()
92                     for i in range(rois.shape[0])])
93      print(s)
94      dpooling = DCNv2Pooling(spatial_scale=1.0 / 4,
95                              pooled_size=7,
96                              output_dim=16,
97                              no_trans=False,
98                              group_size=1,
99                              trans_std=0.0).cuda()
100      offset = torch.randn(20, 2, 7, 7).cuda().zero_()
101      dout = dpooling(input, rois, offset)
102      s = ', '.join(['%f' % dout[i, :, :, :].mean().item()
103                     for i in range(rois.shape[0])])
104      print(s)
105  def check_gradient_dpooling():
106      input = torch.randn(2, 3, 5, 5).cuda() * 0.01
107      N = 4
108      batch_inds = torch.randint(2, (N, 1)).cuda().float()
109      x = torch.rand((N, 1)).cuda().float() * 15
110      y = torch.rand((N, 1)).cuda().float() * 15
111      w = torch.rand((N, 1)).cuda().float() * 10
112      h = torch.rand((N, 1)).cuda().float() * 10
113      rois = torch.cat((batch_inds, x, y, x + w, y + h), dim=1)
114      offset = torch.randn(N, 2, 3, 3).cuda()
115      input.requires_grad = True
116      offset.requires_grad = True
117      spatial_scale = 1.0 / 4
118      pooled_size = 3
119      output_dim = 3
120      no_trans = 0
121      group_size = 1
122      trans_std = 0.0
123      sample_per_part = 4
124      part_size = pooled_size
125      print('check_gradient_dpooling:',
126            gradcheck(dcn_v2_pooling, (input, rois, offset,
127                                       spatial_scale,
128                                       pooled_size,
129                                       output_dim,
130                                       no_trans,
131                                       group_size,
132                                       part_size,
133                                       sample_per_part,
134                                       trans_std),
135                      eps=1e-4))
136  def example_dconv():
137      input = torch.randn(2, 64, 128, 128).cuda()
138      dcn = DCN(64, 64, kernel_size=(3, 3), stride=1,
139                padding=1, deformable_groups=2).cuda()
140      output = dcn(input)
141      targert = output.new(*output.size())
142      targert.data.uniform_(-0.01, 0.01)
143      error = (targert - output).mean()
144      error.backward()
145      print(output.shape)
146  def example_dpooling():
147      input = torch.randn(2, 32, 64, 64).cuda()
148      batch_inds = torch.randint(2, (20, 1)).cuda().float()
149      x = torch.randint(256, (20, 1)).cuda().float()
150      y = torch.randint(256, (20, 1)).cuda().float()
151      w = torch.randint(64, (20, 1)).cuda().float()
152      h = torch.randint(64, (20, 1)).cuda().float()
153      rois = torch.cat((batch_inds, x, y, x + w, y + h), dim=1)
154      offset = torch.randn(20, 2, 7, 7).cuda()
155      input.requires_grad = True
156      offset.requires_grad = True
157      pooling = DCNv2Pooling(spatial_scale=1.0 / 4,
158                             pooled_size=7,
159                             output_dim=32,
160                             no_trans=True,
161                             group_size=1,
162                             trans_std=0.1).cuda()
163      dpooling = DCNv2Pooling(spatial_scale=1.0 / 4,
164                              pooled_size=7,
165                              output_dim=32,
166                              no_trans=False,
167                              group_size=1,
168                              trans_std=0.1).cuda()
169      out = pooling(input, rois, offset)
170      dout = dpooling(input, rois, offset)
171      print(out.shape)
172      print(dout.shape)
173      target_out = out.new(*out.size())
174      target_out.data.uniform_(-0.01, 0.01)
175      target_dout = dout.new(*dout.size())
176      target_dout.data.uniform_(-0.01, 0.01)
177      e = (target_out - out).mean()
178      e.backward()
179      e = (target_dout - dout).mean()
180      e.backward()
181  def example_mdpooling():
182      input = torch.randn(2, 32, 64, 64).cuda()
183      input.requires_grad = True
184      batch_inds = torch.randint(2, (20, 1)).cuda().float()
185      x = torch.randint(256, (20, 1)).cuda().float()
186      y = torch.randint(256, (20, 1)).cuda().float()
187      w = torch.randint(64, (20, 1)).cuda().float()
188      h = torch.randint(64, (20, 1)).cuda().float()
189      rois = torch.cat((batch_inds, x, y, x + w, y + h), dim=1)
190      dpooling = DCNPooling(spatial_scale=1.0 / 4,
191                            pooled_size=7,
192                            output_dim=32,
193                            no_trans=False,
194                            group_size=1,
195                            trans_std=0.1,
196                            deform_fc_dim=1024).cuda()
197      dout = dpooling(input, rois)
198      target = dout.new(*dout.size())
199      target.data.uniform_(-0.1, 0.1)
200      error = (target - dout).mean()
201      error.backward()
202      print(dout.shape)
203  if __name__ == '__main__':
204      example_dconv()
205      example_dpooling()
206      example_mdpooling()
207      check_pooling_zero_offset()
208      if inC == outC:
209          check_zero_offset()
210      check_gradient_dpooling()
211      check_gradient_dconv()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-rmsprop_test.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-test.py</div>
                </div>
                <div class="column column_space"><pre><code>6                                          decay=(0.8, 0.9),
7                                          momentum=(0.0, 0.5),
8                                          epsilon=(1e-7, 1e-8),
</pre></code></div>
                <div class="column column_space"><pre><code>33                            stride=(1, 1),
34                            padding=(1, 1),
35                            bias=True).cuda()
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    