
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 16, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-coco.py</h3>
            <pre><code>1  import os
2  import os.path as osp
3  import sys
4  import torch
5  import torch.utils.data as data
6  import torch.nn.functional as F
7  import cv2
8  import numpy as np
9  from .config import cfg
10  from pycocotools import mask as maskUtils
11  import random
12  def get_label_map():
13      if cfg.dataset.label_map is None:
14          return {x+1: x+1 for x in range(len(cfg.dataset.class_names))}
15      else:
16          return cfg.dataset.label_map 
17  class COCOAnnotationTransform(object):
18      def __init__(self):
19          self.label_map = get_label_map()
20      def __call__(self, target, width, height):
21          scale = np.array([width, height, width, height])
22          res = []
23          for obj in target:
24              if &#x27;bbox&#x27; in obj:
25                  bbox = obj[&#x27;bbox&#x27;]
26                  label_idx = obj[&#x27;category_id&#x27;]
27                  if label_idx &gt;= 0:
28                      label_idx = self.label_map[label_idx] - 1
29                  final_box = list(np.array([bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]])/scale)
30                  final_box.append(label_idx)
31                  res += [final_box]  # [xmin, ymin, xmax, ymax, label_idx]
32              else:
33                  print(&quot;No bbox found for object &quot;, obj)
34          return res
35  class COCODetection(data.Dataset):
36      def __init__(self, image_path, info_file, transform=None,
37                   target_transform=None,
38                   dataset_name=&#x27;MS COCO&#x27;, has_gt=True):
39          from pycocotools.coco import COCO
40          if target_transform is None:
41              target_transform = COCOAnnotationTransform()
42          self.root = image_path
43          self.coco = COCO(info_file)
44          self.ids = list(self.coco.imgToAnns.keys())
45          if len(self.ids) == 0 or not has_gt:
46              self.ids = list(self.coco.imgs.keys())
47          self.transform = transform
48          self.target_transform = COCOAnnotationTransform()
49          self.name = dataset_name
50          self.has_gt = has_gt
51      def __getitem__(self, index):
52          im, gt, masks, h, w, num_crowds = self.pull_item(index)
53          return im, (gt, masks, num_crowds)
54      def __len__(self):
55          return len(self.ids)
56      def pull_item(self, index):
57          img_id = self.ids[index]
58          if self.has_gt:
59              ann_ids = self.coco.getAnnIds(imgIds=img_id)
60              target = [x for x in self.coco.loadAnns(ann_ids) if x[&#x27;image_id&#x27;] == img_id]
61          else:
62              target = []
63          crowd  = [x for x in target if     (&#x27;iscrowd&#x27; in x and x[&#x27;iscrowd&#x27;])]
64          target = [x for x in target if not (&#x27;iscrowd&#x27; in x and x[&#x27;iscrowd&#x27;])]
65          num_crowds = len(crowd)
66          for x in crowd:
67              x[&#x27;category_id&#x27;] = -1
68          target += crowd
69          file_name = self.coco.loadImgs(img_id)[0][&#x27;file_name&#x27;]
70          if file_name.startswith(&#x27;COCO&#x27;):
71              file_name = file_name.split(&#x27;_&#x27;)[-1]
72          path = osp.join(self.root, file_name)
73          assert osp.exists(path), &#x27;Image path does not exist: {}&#x27;.format(path)
74          img = cv2.imread(path)
75          height, width, _ = img.shape
76          if len(target) &gt; 0:
77              masks = [self.coco.annToMask(obj).reshape(-1) for obj in target]
78              masks = np.vstack(masks)
79              masks = masks.reshape(-1, height, width)
80          if self.target_transform is not None and len(target) &gt; 0:
81              target = self.target_transform(target, width, height)
82          if self.transform is not None:
83              if len(target) &gt; 0:
84                  target = np.array(target)
85                  img, masks, boxes, labels = self.transform(img, masks, target[:, :4],
86                      {&#x27;num_crowds&#x27;: num_crowds, &#x27;labels&#x27;: target[:, 4]})
87                  num_crowds = labels[&#x27;num_crowds&#x27;]
88                  labels     = labels[&#x27;labels&#x27;]
89                  target = np.hstack((boxes, np.expand_dims(labels, axis=1)))
90              else:
91                  img, _, _, _ = self.transform(img, np.zeros((1, height, width), dtype=np.float), np.array([[0, 0, 1, 1]]),
92                      {&#x27;num_crowds&#x27;: 0, &#x27;labels&#x27;: np.array([0])})
93                  masks = None
94                  target = None
95          if target.shape[0] == 0:
96              print(&#x27;Warning: Augmentation output an example with no ground truth. Resampling...&#x27;)
97              return self.pull_item(random.randint(0, len(self.ids)-1))
98          return torch.from_numpy(img).permute(2, 0, 1), target, masks, height, width, num_crowds
99      def pull_image(self, index):
100          img_id = self.ids[index]
101          path = self.coco.loadImgs(img_id)[0][&#x27;file_name&#x27;]
102          return cv2.imread(osp.join(self.root, path), cv2.IMREAD_COLOR)
103      def pull_anno(self, index):
104          img_id = self.ids[index]
105          ann_ids = self.coco.getAnnIds(imgIds=img_id)
106          return self.coco.loadAnns(ann_ids)
107      def __repr__(self):
108          fmt_str = &#x27;Dataset &#x27; + self.__class__.__name__ + &#x27;\n&#x27;
109          fmt_str += &#x27;    Number of datapoints: {}\n&#x27;.format(self.__len__())
110          fmt_str += &#x27;    Root Location: {}\n&#x27;.format(self.root)
111          tmp = &#x27;    Transforms (if any): &#x27;
112          fmt_str += &#x27;{0}{1}\n&#x27;.format(tmp, self.transform.__repr__().replace(&#x27;\n&#x27;, &#x27;\n&#x27; + &#x27; &#x27; * len(tmp)))
113          tmp = &#x27;    Target Transforms (if any): &#x27;
114          fmt_str += &#x27;{0}{1}&#x27;.format(tmp, self.target_transform.__repr__().replace(&#x27;\n&#x27;, &#x27;\n&#x27; + &#x27; &#x27; * len(tmp)))
115          return fmt_str
116  def enforce_size(img, targets, masks, num_crowds, new_w, new_h):
117      with torch.no_grad():
118          _, h, w = img.size()
119          if h == new_h and w == new_w:
120              return img, targets, masks, num_crowds
121          w_prime = new_w
122          h_prime = h * new_w / w
123          if h_prime &gt; new_h:
124              w_prime *= new_h / h_prime
125              h_prime = new_h
126          w_prime = int(w_prime)
127          h_prime = int(h_prime)
128          img = F.interpolate(img.unsqueeze(0), (h_prime, w_prime), mode=&#x27;bilinear&#x27;, align_corners=False)
129          img.squeeze_(0)
130          masks = F.interpolate(masks.unsqueeze(0), (h_prime, w_prime), mode=&#x27;bilinear&#x27;, align_corners=False)
131          masks.squeeze_(0)
132          targets[:, [0, 2]] *= (w_prime / new_w)
<span onclick='openModal()' class='match'>133          targets[:, [1, 3]] *= (h_prime / new_h)
134          pad_dims = (0, new_w - w_prime, 0, new_h - h_prime)
</span>135          img   = F.pad(  img, pad_dims, mode=&#x27;constant&#x27;, value=0)
136          masks = F.pad(masks, pad_dims, mode=&#x27;constant&#x27;, value=0)
137          return img, targets, masks, num_crowds
138  def detection_collate(batch):
139      targets = []
140      imgs = []
141      masks = []
142      num_crowds = []
143      for sample in batch:
144          imgs.append(sample[0])
145          targets.append(torch.FloatTensor(sample[1][0]))
146          masks.append(torch.FloatTensor(sample[1][1]))
147          num_crowds.append(sample[1][2])
148      return imgs, (targets, masks, num_crowds)
</code></pre>
        </div>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-coco.py</h3>
            <pre><code>1  import os
2  import os.path as osp
3  import sys
4  import torch
5  import torch.utils.data as data
6  import torch.nn.functional as F
7  import cv2
8  import numpy as np
9  from .config import cfg
10  from pycocotools import mask as maskUtils
11  import random
12  def get_label_map():
13      if cfg.dataset.label_map is None:
14          return {x+1: x+1 for x in range(len(cfg.dataset.class_names))}
15      else:
16          return cfg.dataset.label_map 
17  class COCOAnnotationTransform(object):
18      def __init__(self):
19          self.label_map = get_label_map()
20      def __call__(self, target, width, height):
21          scale = np.array([width, height, width, height])
22          res = []
23          for obj in target:
24              if &#x27;bbox&#x27; in obj:
25                  bbox = obj[&#x27;bbox&#x27;]
26                  label_idx = obj[&#x27;category_id&#x27;]
27                  if label_idx &gt;= 0:
28                      label_idx = self.label_map[label_idx] - 1
29                  final_box = list(np.array([bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]])/scale)
30                  final_box.append(label_idx)
31                  res += [final_box]  # [xmin, ymin, xmax, ymax, label_idx]
32              else:
33                  print(&quot;No bbox found for object &quot;, obj)
34          return res
35  class COCODetection(data.Dataset):
36      def __init__(self, image_path, info_file, transform=None,
37                   target_transform=None,
38                   dataset_name=&#x27;MS COCO&#x27;, has_gt=True):
39          from pycocotools.coco import COCO
40          if target_transform is None:
41              target_transform = COCOAnnotationTransform()
42          self.root = image_path
43          self.coco = COCO(info_file)
44          self.ids = list(self.coco.imgToAnns.keys())
45          if len(self.ids) == 0 or not has_gt:
46              self.ids = list(self.coco.imgs.keys())
47          self.transform = transform
48          self.target_transform = COCOAnnotationTransform()
49          self.name = dataset_name
50          self.has_gt = has_gt
51      def __getitem__(self, index):
52          im, gt, masks, h, w, num_crowds = self.pull_item(index)
53          return im, (gt, masks, num_crowds)
54      def __len__(self):
55          return len(self.ids)
56      def pull_item(self, index):
57          img_id = self.ids[index]
58          if self.has_gt:
59              ann_ids = self.coco.getAnnIds(imgIds=img_id)
60              target = [x for x in self.coco.loadAnns(ann_ids) if x[&#x27;image_id&#x27;] == img_id]
61          else:
62              target = []
63          crowd  = [x for x in target if     (&#x27;iscrowd&#x27; in x and x[&#x27;iscrowd&#x27;])]
64          target = [x for x in target if not (&#x27;iscrowd&#x27; in x and x[&#x27;iscrowd&#x27;])]
65          num_crowds = len(crowd)
66          for x in crowd:
67              x[&#x27;category_id&#x27;] = -1
68          target += crowd
69          file_name = self.coco.loadImgs(img_id)[0][&#x27;file_name&#x27;]
70          if file_name.startswith(&#x27;COCO&#x27;):
71              file_name = file_name.split(&#x27;_&#x27;)[-1]
72          path = osp.join(self.root, file_name)
73          assert osp.exists(path), &#x27;Image path does not exist: {}&#x27;.format(path)
74          img = cv2.imread(path)
75          height, width, _ = img.shape
76          if len(target) &gt; 0:
77              masks = [self.coco.annToMask(obj).reshape(-1) for obj in target]
78              masks = np.vstack(masks)
79              masks = masks.reshape(-1, height, width)
80          if self.target_transform is not None and len(target) &gt; 0:
81              target = self.target_transform(target, width, height)
82          if self.transform is not None:
83              if len(target) &gt; 0:
84                  target = np.array(target)
85                  img, masks, boxes, labels = self.transform(img, masks, target[:, :4],
86                      {&#x27;num_crowds&#x27;: num_crowds, &#x27;labels&#x27;: target[:, 4]})
87                  num_crowds = labels[&#x27;num_crowds&#x27;]
88                  labels     = labels[&#x27;labels&#x27;]
89                  target = np.hstack((boxes, np.expand_dims(labels, axis=1)))
90              else:
91                  img, _, _, _ = self.transform(img, np.zeros((1, height, width), dtype=np.float), np.array([[0, 0, 1, 1]]),
92                      {&#x27;num_crowds&#x27;: 0, &#x27;labels&#x27;: np.array([0])})
93                  masks = None
94                  target = None
95          if target.shape[0] == 0:
96              print(&#x27;Warning: Augmentation output an example with no ground truth. Resampling...&#x27;)
97              return self.pull_item(random.randint(0, len(self.ids)-1))
98          return torch.from_numpy(img).permute(2, 0, 1), target, masks, height, width, num_crowds
99      def pull_image(self, index):
100          img_id = self.ids[index]
101          path = self.coco.loadImgs(img_id)[0][&#x27;file_name&#x27;]
102          return cv2.imread(osp.join(self.root, path), cv2.IMREAD_COLOR)
103      def pull_anno(self, index):
104          img_id = self.ids[index]
105          ann_ids = self.coco.getAnnIds(imgIds=img_id)
106          return self.coco.loadAnns(ann_ids)
107      def __repr__(self):
108          fmt_str = &#x27;Dataset &#x27; + self.__class__.__name__ + &#x27;\n&#x27;
109          fmt_str += &#x27;    Number of datapoints: {}\n&#x27;.format(self.__len__())
110          fmt_str += &#x27;    Root Location: {}\n&#x27;.format(self.root)
111          tmp = &#x27;    Transforms (if any): &#x27;
112          fmt_str += &#x27;{0}{1}\n&#x27;.format(tmp, self.transform.__repr__().replace(&#x27;\n&#x27;, &#x27;\n&#x27; + &#x27; &#x27; * len(tmp)))
113          tmp = &#x27;    Target Transforms (if any): &#x27;
114          fmt_str += &#x27;{0}{1}&#x27;.format(tmp, self.target_transform.__repr__().replace(&#x27;\n&#x27;, &#x27;\n&#x27; + &#x27; &#x27; * len(tmp)))
115          return fmt_str
116  def enforce_size(img, targets, masks, num_crowds, new_w, new_h):
117      with torch.no_grad():
118          _, h, w = img.size()
119          if h == new_h and w == new_w:
120              return img, targets, masks, num_crowds
121          w_prime = new_w
122          h_prime = h * new_w / w
123          if h_prime &gt; new_h:
124              w_prime *= new_h / h_prime
125              h_prime = new_h
126          w_prime = int(w_prime)
127          h_prime = int(h_prime)
128          img = F.interpolate(img.unsqueeze(0), (h_prime, w_prime), mode=&#x27;bilinear&#x27;, align_corners=False)
129          img.squeeze_(0)
130          masks = F.interpolate(masks.unsqueeze(0), (h_prime, w_prime), mode=&#x27;bilinear&#x27;, align_corners=False)
131          masks.squeeze_(0)
<span onclick='openModal()' class='match'>132          targets[:, [0, 2]] *= (w_prime / new_w)
133          targets[:, [1, 3]] *= (h_prime / new_h)
</span>134          pad_dims = (0, new_w - w_prime, 0, new_h - h_prime)
135          img   = F.pad(  img, pad_dims, mode=&#x27;constant&#x27;, value=0)
136          masks = F.pad(masks, pad_dims, mode=&#x27;constant&#x27;, value=0)
137          return img, targets, masks, num_crowds
138  def detection_collate(batch):
139      targets = []
140      imgs = []
141      masks = []
142      num_crowds = []
143      for sample in batch:
144          imgs.append(sample[0])
145          targets.append(torch.FloatTensor(sample[1][0]))
146          masks.append(torch.FloatTensor(sample[1][1]))
147          num_crowds.append(sample[1][2])
148      return imgs, (targets, masks, num_crowds)
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-coco.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-coco.py</div>
                </div>
                <div class="column column_space"><pre><code>133          targets[:, [1, 3]] *= (h_prime / new_h)
134          pad_dims = (0, new_w - w_prime, 0, new_h - h_prime)
</pre></code></div>
                <div class="column column_space"><pre><code>132          targets[:, [0, 2]] *= (w_prime / new_w)
133          targets[:, [1, 3]] *= (h_prime / new_h)
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    