
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 5.086285195277021%, Tokens: 10, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-test_merge_bin.py</h3>
            <pre><code>1  import itertools
2  import os
3  import os.path
4  import subprocess
5  import sys
6  import tempfile
7  IMAGES_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), "images")
8  from conftest import need_to_install_package_err
9  import pytest
10  try:
11      from esptool.util import byte
12  except ImportError:
13      need_to_install_package_err()
14  def read_image(filename):
15      with open(os.path.join(IMAGES_DIR, filename), "rb") as f:
16          return f.read()
17  @pytest.mark.host_test
18  class TestMergeBin:
19      def run_merge_bin(self, chip, offsets_names, options=[]):
20          output_file = tempfile.NamedTemporaryFile(delete=False)
21          try:
22              output_file.close()
23              cmd = [
24                  sys.executable,
25                  "-m",
26                  "esptool",
27                  "--chip",
28                  chip,
29                  "merge_bin",
30                  "-o",
31                  output_file.name,
32              ] + options
33              for offset, name in offsets_names:
34                  cmd += [hex(offset), name]
35              print("\nExecuting {}".format(" ".join(cmd)))
36              output = subprocess.check_output(
37                  cmd, cwd=IMAGES_DIR, stderr=subprocess.STDOUT
38              )
39              output = output.decode("utf-8")
40              print(output)
41              assert (
42                  "warning" not in output.lower()
43              ), "merge_bin should not output warnings"
44              with open(output_file.name, "rb") as f:
45                  return f.read()
46          except subprocess.CalledProcessError as e:
47              print(e.output)
48              raise
49          finally:
50              os.unlink(output_file.name)
51      def assertAllFF(self, some_bytes):
52          assert b"\xFF" * len(some_bytes) == some_bytes
53      def test_simple_merge(self):
54          merged = self.run_merge_bin(
55              "esp8266",
56              [(0x0, "one_kb.bin"), (0x1000, "one_kb.bin"), (0x10000, "one_kb.bin")],
57          )
58          one_kb = read_image("one_kb.bin")
59          assert len(one_kb) == 0x400
60          assert len(merged) == 0x10400
61          assert merged[:0x400] == one_kb
62          assert merged[0x1000:0x1400] == one_kb
63          assert merged[0x10000:] == one_kb
64          self.assertAllFF(merged[0x400:0x1000])
65          self.assertAllFF(merged[0x1400:0x10000])
66      def test_args_out_of_order(self):
67          args = [(0x0, "one_kb.bin"), (0x1000, "one_kb.bin"), (0x10000, "one_kb.bin")]
68          merged_orders = [
69              self.run_merge_bin("esp8266", perm_args)
70              for perm_args in itertools.permutations(args)
71          ]
72          for m in merged_orders:
73              assert m == merged_orders[0]
74      def test_error_overlap(self, capsys):
75          args = [(0x1000, "one_mb.bin"), (0x20000, "one_kb.bin")]
76          for perm_args in itertools.permutations(args):
77              with pytest.raises(subprocess.CalledProcessError):
78                  self.run_merge_bin("esp32", perm_args)
79              output = capsys.readouterr().out
80              assert "overlap" in output
81      def test_leading_padding(self):
82          merged = self.run_merge_bin("esp32c3", [(0x100000, "one_mb.bin")])
83          self.assertAllFF(merged[:0x100000])
84          assert read_image("one_mb.bin") == merged[0x100000:]
85      def test_update_bootloader_params(self):
<span onclick='openModal()' class='match'>86          merged = self.run_merge_bin(
87              "esp32",
88              [
89                  (0x1000, "bootloader_esp32.bin"),
90                  (0x10000, "ram_helloworld/helloworld-esp32.bin"),
91              ],
92              ["--flash_size", "2MB", "--flash_mode", "dout"],
93          )
94          self.assertAllFF(merged[:0x1000])
95          bootloader = read_image("bootloader_esp32.bin")
</span>96          helloworld = read_image("ram_helloworld/helloworld-esp32.bin")
97          assert merged[0x1010 : 0x1000 + len(bootloader)] == bootloader[0x10:]
98          merged_hdr = merged[0x1000:0x1010]
99          bootloader_hdr = bootloader[:0x10]
100          assert bootloader_hdr[:2] == merged_hdr[:2]
101          assert byte(merged_hdr, 2) == 3  # flash mode dout
102          assert byte(merged_hdr, 3) & 0xF0 == 0x10  # flash size 2MB (ESP32)
103          assert byte(bootloader_hdr, 3) & 0x0F == byte(merged_hdr, 3) & 0x0F
104          assert bootloader_hdr[4:] == merged_hdr[4:]  # remaining field are unchanged
105          self.assertAllFF(merged[0x1000 + len(bootloader) : 0x10000])
106          assert merged[0x10000 : 0x10000 + len(helloworld)], helloworld
107      def test_target_offset(self):
108          merged = self.run_merge_bin(
109              "esp32",
110              [
111                  (0x1000, "bootloader_esp32.bin"),
112                  (0x10000, "ram_helloworld/helloworld-esp32.bin"),
113              ],
114              ["--target-offset", "0x1000"],
115          )
116          bootloader = read_image("bootloader_esp32.bin")
117          helloworld = read_image("ram_helloworld/helloworld-esp32.bin")
118          assert bootloader == merged[: len(bootloader)]
119          assert helloworld == merged[0xF000 : 0xF000 + len(helloworld)]
120          self.assertAllFF(merged[0x1000 + len(bootloader) : 0xF000])
121      def test_fill_flash_size(self):
122          merged = self.run_merge_bin(
123              "esp32c3", [(0x0, "bootloader_esp32c3.bin")], ["--fill-flash-size", "4MB"]
124          )
125          bootloader = read_image("bootloader_esp32c3.bin")
126          assert len(merged) == 0x400000
127          assert bootloader == merged[: len(bootloader)]
128          self.assertAllFF(merged[len(bootloader) :])
129      def test_fill_flash_size_w_target_offset(self):
130          merged = self.run_merge_bin(
131              "esp32",
132              [
133                  (0x1000, "bootloader_esp32.bin"),
134                  (0x10000, "ram_helloworld/helloworld-esp32.bin"),
135              ],
136              ["--target-offset", "0x1000", "--fill-flash-size", "2MB"],
137          )
138          assert len(merged) == 0x200000 - 0x1000
139          bootloader = read_image("bootloader_esp32.bin")
140          helloworld = read_image("ram_helloworld/helloworld-esp32.bin")
141          assert bootloader == merged[: len(bootloader)]
142          assert helloworld == merged[0xF000 : 0xF000 + len(helloworld)]
143          self.assertAllFF(merged[0xF000 + len(helloworld) :])
</code></pre>
        </div>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-backbone.py</h3>
            <pre><code>1  import torch
2  import torch.nn as nn
3  import pickle
4  from collections import OrderedDict
5  try:
6      from dcn_v2 import DCN
7  except ImportError:
8      def DCN(*args, **kwdargs):
9          raise Exception('DCN could not be imported. If you want to use YOLACT++ models, compile DCN. Check the README for instructions.')
10  class Bottleneck(nn.Module):
11      expansion = 4
12      def __init__(self, inplanes, planes, stride=1, downsample=None, norm_layer=nn.BatchNorm2d, dilation=1, use_dcn=False):
13          super(Bottleneck, self).__init__()
14          self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False, dilation=dilation)
15          self.bn1 = norm_layer(planes)
16          if use_dcn:
17              self.conv2 = DCN(planes, planes, kernel_size=3, stride=stride,
18                                  padding=dilation, dilation=dilation, deformable_groups=1)
19              self.conv2.bias.data.zero_()
<span onclick='openModal()' class='match'>20              self.conv2.conv_offset_mask.weight.data.zero_()
21              self.conv2.conv_offset_mask.bias.data.zero_()
22          else:
23              self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
</span>24                                  padding=dilation, bias=False, dilation=dilation)
25          self.bn2 = norm_layer(planes)
26          self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False, dilation=dilation)
27          self.bn3 = norm_layer(planes * 4)
28          self.relu = nn.ReLU(inplace=True)
29          self.downsample = downsample
30          self.stride = stride
31      def forward(self, x):
32          residual = x
33          out = self.conv1(x)
34          out = self.bn1(out)
35          out = self.relu(out)
36          out = self.conv2(out)
37          out = self.bn2(out)
38          out = self.relu(out)
39          out = self.conv3(out)
40          out = self.bn3(out)
41          if self.downsample is not None:
42              residual = self.downsample(x)
43          out += residual
44          out = self.relu(out)
45          return out
46  class ResNetBackbone(nn.Module):
47      def __init__(self, layers, dcn_layers=[0, 0, 0, 0], dcn_interval=1, atrous_layers=[], block=Bottleneck, norm_layer=nn.BatchNorm2d):
48          super().__init__()
49          self.num_base_layers = len(layers)
50          self.layers = nn.ModuleList()
51          self.channels = []
52          self.norm_layer = norm_layer
53          self.dilation = 1
54          self.atrous_layers = atrous_layers
55          self.inplanes = 64
56          self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
57          self.bn1 = norm_layer(64)
58          self.relu = nn.ReLU(inplace=True)
59          self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
60          self._make_layer(block, 64, layers[0], dcn_layers=dcn_layers[0], dcn_interval=dcn_interval)
61          self._make_layer(block, 128, layers[1], stride=2, dcn_layers=dcn_layers[1], dcn_interval=dcn_interval)
62          self._make_layer(block, 256, layers[2], stride=2, dcn_layers=dcn_layers[2], dcn_interval=dcn_interval)
63          self._make_layer(block, 512, layers[3], stride=2, dcn_layers=dcn_layers[3], dcn_interval=dcn_interval)
64          self.backbone_modules = [m for m in self.modules() if isinstance(m, nn.Conv2d)]
65      def _make_layer(self, block, planes, blocks, stride=1, dcn_layers=0, dcn_interval=1):
66          downsample = None
67          if stride != 1 or self.inplanes != planes * block.expansion:
68              if len(self.layers) in self.atrous_layers:
69                  self.dilation += 1
70                  stride = 1
71              downsample = nn.Sequential(
72                  nn.Conv2d(self.inplanes, planes * block.expansion,
73                            kernel_size=1, stride=stride, bias=False,
74                            dilation=self.dilation),
75                  self.norm_layer(planes * block.expansion),
76              )
77          layers = []
78          use_dcn = (dcn_layers >= blocks)
79          layers.append(block(self.inplanes, planes, stride, downsample, self.norm_layer, self.dilation, use_dcn=use_dcn))
80          self.inplanes = planes * block.expansion
81          for i in range(1, blocks):
82              use_dcn = ((i+dcn_layers) >= blocks) and (i % dcn_interval == 0)
83              layers.append(block(self.inplanes, planes, norm_layer=self.norm_layer, use_dcn=use_dcn))
84          layer = nn.Sequential(*layers)
85          self.channels.append(planes * block.expansion)
86          self.layers.append(layer)
87          return layer
88      def forward(self, x):
89          x = self.conv1(x)
90          x = self.bn1(x)
91          x = self.relu(x)
92          x = self.maxpool(x)
93          outs = []
94          for layer in self.layers:
95              x = layer(x)
96              outs.append(x)
97          return tuple(outs)
98      def init_backbone(self, path):
99          state_dict = torch.load(path)
100          keys = list(state_dict)
101          for key in keys:
102              if key.startswith('layer'):
103                  idx = int(key[5])
104                  new_key = 'layers.' + str(idx-1) + key[6:]
105                  state_dict[new_key] = state_dict.pop(key)
106          self.load_state_dict(state_dict, strict=False)
107      def add_layer(self, conv_channels=1024, downsample=2, depth=1, block=Bottleneck):
108          self._make_layer(block, conv_channels // block.expansion, blocks=depth, stride=downsample)
109  class ResNetBackboneGN(ResNetBackbone):
110      def __init__(self, layers, num_groups=32):
111          super().__init__(layers, norm_layer=lambda x: nn.GroupNorm(num_groups, x))
112      def init_backbone(self, path):
113          with open(path, 'rb') as f:
114              state_dict = pickle.load(f, encoding='latin1') # From the detectron source
115              state_dict = state_dict['blobs']
116          our_state_dict_keys = list(self.state_dict().keys())
117          new_state_dict = {}
118          gn_trans     = lambda x: ('gn_s' if x == 'weight' else 'gn_b')
119          layeridx2res = lambda x: 'res' + str(int(x)+2)
120          block2branch = lambda x: 'branch2' + ('a', 'b', 'c')[int(x[-1:])-1]
121          for key in our_state_dict_keys:
122              parts = key.split('.')
123              transcribed_key = ''
124              if (parts[0] == 'conv1'):
125                  transcribed_key = 'conv1_w'
126              elif (parts[0] == 'bn1'):
127                  transcribed_key = 'conv1_' + gn_trans(parts[1])
128              elif (parts[0] == 'layers'):
129                  if int(parts[1]) >= self.num_base_layers: continue
130                  transcribed_key = layeridx2res(parts[1])
131                  transcribed_key += '_' + parts[2] + '_'
132                  if parts[3] == 'downsample':
133                      transcribed_key += 'branch1_'
134                      if parts[4] == '0':
135                          transcribed_key += 'w'
136                      else:
137                          transcribed_key += gn_trans(parts[5])
138                  else:
139                      transcribed_key += block2branch(parts[3]) + '_'
140                      if 'conv' in parts[3]:
141                          transcribed_key += 'w'
142                      else:
143                          transcribed_key += gn_trans(parts[4])
144              new_state_dict[key] = torch.Tensor(state_dict[transcribed_key])
145          self.load_state_dict(new_state_dict, strict=False)
146  def darknetconvlayer(in_channels, out_channels, *args, **kwdargs):
147      return nn.Sequential(
148          nn.Conv2d(in_channels, out_channels, *args, **kwdargs, bias=False),
149          nn.BatchNorm2d(out_channels),
150          nn.LeakyReLU(0.1, inplace=True)
151      )
152  class DarkNetBlock(nn.Module):
153      expansion = 2
154      def __init__(self, in_channels, channels):
155          super().__init__()
156          self.conv1 = darknetconvlayer(in_channels, channels,                  kernel_size=1)
157          self.conv2 = darknetconvlayer(channels,    channels * self.expansion, kernel_size=3, padding=1)
158      def forward(self, x):
159          return self.conv2(self.conv1(x)) + x
160  class DarkNetBackbone(nn.Module):
161      def __init__(self, layers=[1, 2, 8, 8, 4], block=DarkNetBlock):
162          super().__init__()
163          self.num_base_layers = len(layers)
164          self.layers = nn.ModuleList()
165          self.channels = []
166          self._preconv = darknetconvlayer(3, 32, kernel_size=3, padding=1)
167          self.in_channels = 32
168          self._make_layer(block, 32,  layers[0])
169          self._make_layer(block, 64,  layers[1])
170          self._make_layer(block, 128, layers[2])
171          self._make_layer(block, 256, layers[3])
172          self._make_layer(block, 512, layers[4])
173          self.backbone_modules = [m for m in self.modules() if isinstance(m, nn.Conv2d)]
174      def _make_layer(self, block, channels, num_blocks, stride=2):
175          layer_list = []
176          layer_list.append(
177              darknetconvlayer(self.in_channels, channels * block.expansion,
178                               kernel_size=3, padding=1, stride=stride))
179          self.in_channels = channels * block.expansion
180          layer_list += [block(self.in_channels, channels) for _ in range(num_blocks)]
181          self.channels.append(self.in_channels)
182          self.layers.append(nn.Sequential(*layer_list))
183      def forward(self, x):
184          x = self._preconv(x)
185          outs = []
186          for layer in self.layers:
187              x = layer(x)
188              outs.append(x)
189          return tuple(outs)
190      def add_layer(self, conv_channels=1024, stride=2, depth=1, block=DarkNetBlock):
191          self._make_layer(block, conv_channels // block.expansion, num_blocks=depth, stride=stride)
192      def init_backbone(self, path):
193          self.load_state_dict(torch.load(path), strict=False)
194  class VGGBackbone(nn.Module):
195      def __init__(self, cfg, extra_args=[], norm_layers=[]):
196          super().__init__()
197          self.channels = []
198          self.layers = nn.ModuleList()
199          self.in_channels = 3
200          self.extra_args = list(reversed(extra_args)) # So I can use it as a stack
201          self.total_layer_count = 0
202          self.state_dict_lookup = {}
203          for idx, layer_cfg in enumerate(cfg):
204              self._make_layer(layer_cfg)
205          self.norms = nn.ModuleList([nn.BatchNorm2d(self.channels[l]) for l in norm_layers])
206          self.norm_lookup = {l: idx for idx, l in enumerate(norm_layers)}
207          self.backbone_modules = [m for m in self.modules() if isinstance(m, nn.Conv2d)]
208      def _make_layer(self, cfg):
209          layers = []
210          for v in cfg:
211              args = None
212              if isinstance(v, tuple):
213                  args = v[1]
214                  v = v[0]
215              if v == 'M':
216                  if args is None:
217                      args = {'kernel_size': 2, 'stride': 2}
218                  layers.append(nn.MaxPool2d(**args))
219              else:
220                  cur_layer_idx = self.total_layer_count + len(layers)
221                  self.state_dict_lookup[cur_layer_idx] = '%d.%d' % (len(self.layers), len(layers))
222                  if args is None:
223                      args = {'kernel_size': 3, 'padding': 1}
224                  layers.append(nn.Conv2d(self.in_channels, v, **args))
225                  layers.append(nn.ReLU(inplace=True))
226                  self.in_channels = v
227          self.total_layer_count += len(layers)
228          self.channels.append(self.in_channels)
229          self.layers.append(nn.Sequential(*layers))
230      def forward(self, x):
231          outs = []
232          for idx, layer in enumerate(self.layers):
233              x = layer(x)
234              if idx in self.norm_lookup:
235                  x = self.norms[self.norm_lookup[idx]](x)
236              outs.append(x)
237          return tuple(outs)
238      def transform_key(self, k):
239          vals = k.split('.')
240          layerIdx = self.state_dict_lookup[int(vals[0])]
241          return 'layers.%s.%s' % (layerIdx, vals[1])
242      def init_backbone(self, path):
243          state_dict = torch.load(path)
244          state_dict = OrderedDict([(self.transform_key(k), v) for k,v in state_dict.items()])
245          self.load_state_dict(state_dict, strict=False)
246      def add_layer(self, conv_channels=128, downsample=2):
247          if len(self.extra_args) > 0:
248              conv_channels, downsample = self.extra_args.pop()
249          padding = 1 if downsample > 1 else 0
250          layer = nn.Sequential(
251              nn.Conv2d(self.in_channels, conv_channels, kernel_size=1),
252              nn.ReLU(inplace=True),
253              nn.Conv2d(conv_channels, conv_channels*2, kernel_size=3, stride=downsample, padding=padding),
254              nn.ReLU(inplace=True)
255          )
256          self.in_channels = conv_channels*2
257          self.channels.append(self.in_channels)
258          self.layers.append(layer)
259  def construct_backbone(cfg):
260      backbone = cfg.type(*cfg.args)
261      num_layers = max(cfg.selected_layers) + 1
262      while len(backbone.layers) < num_layers:
263          backbone.add_layer()
264      return backbone
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-test_merge_bin.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-backbone.py</div>
                </div>
                <div class="column column_space"><pre><code>86          merged = self.run_merge_bin(
87              "esp32",
88              [
89                  (0x1000, "bootloader_esp32.bin"),
90                  (0x10000, "ram_helloworld/helloworld-esp32.bin"),
91              ],
92              ["--flash_size", "2MB", "--flash_mode", "dout"],
93          )
94          self.assertAllFF(merged[:0x1000])
95          bootloader = read_image("bootloader_esp32.bin")
</pre></code></div>
                <div class="column column_space"><pre><code>20              self.conv2.conv_offset_mask.weight.data.zero_()
21              self.conv2.conv_offset_mask.bias.data.zero_()
22          else:
23              self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    