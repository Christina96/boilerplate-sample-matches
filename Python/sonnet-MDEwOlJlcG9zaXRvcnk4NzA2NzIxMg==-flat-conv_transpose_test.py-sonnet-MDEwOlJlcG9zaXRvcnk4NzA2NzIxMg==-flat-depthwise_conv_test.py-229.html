
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 105, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-conv_transpose_test.py</h3>
            <pre><code>1  import itertools
2  from absl.testing import parameterized
3  import numpy as np
4  from sonnet.src import conv_transpose
5  from sonnet.src import initializers as lib_initializers
6  from sonnet.src import test_utils
7  import tensorflow as tf
8  def create_constant_initializers(w, b, with_bias):
9    if with_bias:
10      return {
11          &quot;w_init&quot;: lib_initializers.Constant(w),
12          &quot;b_init&quot;: lib_initializers.Constant(b)
13      }
14    else:
15      return {&quot;w_init&quot;: lib_initializers.Constant(w)}
16  class ConvTransposeTest(test_utils.TestCase, parameterized.TestCase):
17    @parameterized.parameters(0, 4)
18    def testIncorrectN(self, n):
19      with self.assertRaisesRegex(
20          ValueError,
21          &quot;only support transpose convolution operations for num_spatial_dims&quot;):
22        conv_transpose.ConvNDTranspose(
23            num_spatial_dims=n,
24            output_channels=1,
25            output_shape=None,
26            kernel_shape=3,
27            data_format=&quot;NHWC&quot;)
28    def testIncorrectPadding(self):
29      with self.assertRaisesRegex(
30          TypeError,
31          &quot;ConvNDTranspose only takes string padding, please provide either&quot;):
32        conv_transpose.ConvNDTranspose(
33            2, output_channels=1, kernel_shape=3, padding=None)
34    def testBiasInitNoBias(self):
35      with self.assertRaisesRegex(
36          ValueError, &quot;When not using a bias the b_init must be None.&quot;):
37        conv_transpose.ConvNDTranspose(
38            2, output_channels=1, kernel_shape=3, with_bias=False,
39            b_init=lib_initializers.Ones(), data_format=&quot;NHWC&quot;)
40    def testIncorrectOutputShape(self):
41      c = conv_transpose.ConvNDTranspose(
42          num_spatial_dims=2,
43          output_channels=3,
44          kernel_shape=2,
45          output_shape=[1],
46          data_format=&quot;NHWC&quot;)
47      with self.assertRaisesRegex(
48          ValueError, &quot;The output_shape must be of length 2 but instead was 1.&quot;):
49        c(tf.ones([3, 5, 5, 3]))
50    @parameterized.parameters(*itertools.product(
51        [True, False],  # with_bias
52        [&quot;SAME&quot;, &quot;VALID&quot;]))  # padding
53    def testGraphConv(self, with_bias, padding):
54      conv1 = conv_transpose.ConvNDTranspose(
55          num_spatial_dims=2,
56          output_channels=1,
57          output_shape=None,
58          kernel_shape=3,
59          stride=1,
60          padding=padding,
61          with_bias=with_bias,
62          data_format=&quot;NHWC&quot;,
63          **create_constant_initializers(1.0, 1.0, with_bias))
64      conv2 = conv_transpose.ConvNDTranspose(
65          num_spatial_dims=2,
66          output_channels=1,
67          output_shape=None,
68          kernel_shape=3,
69          stride=1,
70          padding=padding,
71          with_bias=with_bias,
72          data_format=&quot;NHWC&quot;,
73          **create_constant_initializers(1.0, 1.0, with_bias))
74      defun_conv = tf.function(conv2)
<span onclick='openModal()' class='match'>75      iterations = 5
76      for _ in range(iterations):
77        x = tf.random.uniform([1, 3, 3, 1])
78        y1 = conv1(x)
79        y2 = defun_conv(x)
80        self.assertAllClose(self.evaluate(y1), self.evaluate(y2), atol=1e-4)
81    def testUnknownBatchSizeNHWC(self):
82      x = tf.TensorSpec([None, 5, 5, 3], dtype=tf.float32)
83      c = conv_transpose.ConvNDTranspose(
84          num_spatial_dims=2,
85          output_channels=2,
86          kernel_shape=3,
</span>87          data_format=&quot;NHWC&quot;)
88      defun_conv = tf.function(c).get_concrete_function(x)
89      out1 = defun_conv(tf.ones([3, 5, 5, 3]))
90      self.assertEqual(out1.shape, [3, 5, 5, 2])
91      out2 = defun_conv(tf.ones([5, 5, 5, 3]))
92      self.assertEqual(out2.shape, [5, 5, 5, 2])
93    def testUnknownBatchSizeNCHW(self):
94      if self.primary_device == &quot;CPU&quot;:
95        self.skipTest(&quot;NCHW not supported on CPU&quot;)
96      x = tf.TensorSpec([None, 3, 5, 5], dtype=tf.float32)
97      c = conv_transpose.ConvNDTranspose(
98          num_spatial_dims=2,
99          output_channels=2,
100          kernel_shape=3,
101          data_format=&quot;NCHW&quot;)
102      defun_conv = tf.function(c).get_concrete_function(x)
103      out1 = defun_conv(tf.ones([3, 3, 5, 5]))
104      self.assertEqual(out1.shape, [3, 2, 5, 5])
105      out2 = defun_conv(tf.ones([5, 3, 5, 5]))
106      self.assertEqual(out2.shape, [5, 2, 5, 5])
107    def testUnknownShapeDims(self):
108      x = tf.TensorSpec([3, None, None, 3], dtype=tf.float32)
109      c = conv_transpose.ConvNDTranspose(
110          num_spatial_dims=2,
111          output_channels=2,
112          kernel_shape=3,
113          data_format=&quot;NHWC&quot;)
114      defun_conv = tf.function(c).get_concrete_function(x)
115      out1 = defun_conv(tf.ones([3, 5, 5, 3]))
116      self.assertEqual(out1.shape, [3, 5, 5, 2])
117      out1 = defun_conv(tf.ones([3, 3, 3, 3]))
118      self.assertEqual(out1.shape, [3, 3, 3, 2])
119    def testGivenOutputShape(self):
120      c = conv_transpose.ConvNDTranspose(
121          num_spatial_dims=2,
122          output_channels=2,
123          kernel_shape=3,
124          output_shape=[5, 5],
125          data_format=&quot;NHWC&quot;)
126      out1 = c(tf.ones([3, 5, 5, 3]))
127      self.assertEqual(out1.shape, [3, 5, 5, 2])
128    @parameterized.parameters(True, False)
129    def testUnknownChannels(self, autograph):
130      x = tf.TensorSpec([3, 3, 3, None], dtype=tf.float32)
131      c = conv_transpose.ConvNDTranspose(
132          num_spatial_dims=2,
133          output_channels=1,
134          kernel_shape=3,
135          data_format=&quot;NHWC&quot;)
136      defun_conv = tf.function(c, autograph=autograph)
137      with self.assertRaisesRegex(ValueError,
138                                  &quot;The number of input channels must be known&quot;):
139        defun_conv.get_concrete_function(x)
140    @parameterized.parameters(
141        (1, (3,), 128, 5, &quot;NWC&quot;),
142        (2, (4, 4), 64, 3, &quot;NHWC&quot;),
143        (3, (4, 4, 4), 64, 3, &quot;NDHWC&quot;))
144    def testInitializerVariance(self, num_spatial_dims, kernel_shape,
145                                in_channels, output_channels, data_format):
146      inputs = tf.random.uniform([16] + ([32] * num_spatial_dims) + [in_channels])
147      c = conv_transpose.ConvNDTranspose(
148          num_spatial_dims=num_spatial_dims,
149          kernel_shape=kernel_shape,
150          output_channels=output_channels,
151          data_format=data_format)
152      c(inputs)
153      actual_std = c.w.numpy().std()
154      expected_std = 1 / (np.sqrt(np.prod(kernel_shape + (in_channels,))))
155      rel_diff = np.abs(actual_std - expected_std) / expected_std
156      self.assertLess(rel_diff, 0.5)
157  class Conv2DTransposeTest(test_utils.TestCase, parameterized.TestCase):
158    @parameterized.parameters(True, False)
159    def testComputationPaddingSame(self, with_bias):
160      expected_out = [[4, 6, 4], [6, 9, 6], [4, 6, 4]]
161      expected_out = np.asarray(expected_out, dtype=np.float32)
162      if with_bias:
163        expected_out += 1
164      conv_transpose1 = conv_transpose.Conv2DTranspose(
165          output_channels=1,
166          output_shape=None,
167          kernel_shape=3,
168          stride=1,
169          padding=&quot;SAME&quot;,
170          with_bias=with_bias,
171          **create_constant_initializers(1.0, 1.0, with_bias))
172      out = conv_transpose1(tf.ones([1, 3, 3, 1], dtype=tf.float32))
173      self.assertEqual(out.shape, [1, 3, 3, 1])
174      out = tf.squeeze(out, axis=(0, 3))
175      self.assertAllClose(self.evaluate(out), expected_out)
176    @parameterized.parameters(True, False)
177    def testComputationPaddingValid(self, with_bias):
178      expected_out = [[1, 2, 3, 2, 1], [2, 4, 6, 4, 2], [3, 6, 9, 6, 3],
179                      [2, 4, 6, 4, 2], [1, 2, 3, 2, 1]]
180      expected_out = np.asarray(expected_out, dtype=np.float32)
181      if with_bias:
182        expected_out += 1
183      conv1 = conv_transpose.Conv2DTranspose(
184          output_channels=1,
185          output_shape=None,
186          kernel_shape=3,
187          stride=1,
188          padding=&quot;VALID&quot;,
189          with_bias=with_bias,
190          **create_constant_initializers(1.0, 1.0, with_bias))
191      out = conv1(tf.ones([1, 3, 3, 1], dtype=tf.float32))
192      self.assertEqual(out.shape, [1, 5, 5, 1])
193      out = tf.squeeze(out, axis=(0, 3))
194      self.assertAllClose(self.evaluate(out), expected_out)
195    def testShapeDilated(self):
196      if &quot;CPU&quot; == self.primary_device:
197        self.skipTest(&quot;Not supported on CPU&quot;)
198      conv1 = conv_transpose.Conv2DTranspose(
199          output_channels=1,
200          output_shape=None,
201          kernel_shape=3,
202          rate=2,
203          padding=&quot;VALID&quot;)
204      out = conv1(tf.ones([1, 3, 3, 1]))
205      self.assertEqual(out.shape, [1, 7, 7, 1])
206  class Conv1DTransposeTest(test_utils.TestCase, parameterized.TestCase):
207    @parameterized.parameters(True, False)
208    def testComputationPaddingSame(self, with_bias):
209      expected_out = [2, 3, 2]
210      expected_out = np.asarray(expected_out, dtype=np.float32)
211      if with_bias:
212        expected_out += 1
213      conv1 = conv_transpose.Conv1DTranspose(
214          output_channels=1,
215          output_shape=None,
216          kernel_shape=3,
217          stride=1,
218          padding=&quot;SAME&quot;,
219          with_bias=with_bias,
220          **create_constant_initializers(1.0, 1.0, with_bias))
221      out = conv1(tf.ones([1, 3, 1], dtype=tf.float32))
222      self.assertEqual(out.shape, [1, 3, 1])
223      out = tf.squeeze(out, axis=(0, 2))
224      self.assertAllClose(self.evaluate(out), expected_out)
225    @parameterized.parameters(True, False)
226    def testComputationPaddingValid(self, with_bias):
227      expected_out = [1, 2, 3, 2, 1]
228      expected_out = np.asarray(expected_out, dtype=np.float32)
229      if with_bias:
230        expected_out += 1
231      conv1 = conv_transpose.Conv1DTranspose(
232          output_channels=1,
233          output_shape=None,
234          kernel_shape=3,
235          stride=1,
236          padding=&quot;VALID&quot;,
237          with_bias=with_bias,
238          **create_constant_initializers(1.0, 1.0, with_bias))
239      out = conv1(tf.ones([1, 3, 1], dtype=tf.float32))
240      self.assertEqual(out.shape, [1, 5, 1])
241      out = tf.squeeze(out, axis=(0, 2))
242      self.assertAllClose(self.evaluate(out), expected_out)
243  class Conv3DTransposeTest(test_utils.TestCase, parameterized.TestCase):
244    @parameterized.parameters(True, False)
245    def testComputationPaddingSame(self, with_bias):
246      expected_out = np.asarray([
247          8, 12, 8, 12, 18, 12, 8, 12, 8, 12, 18, 12, 18, 27, 18, 12, 18, 12, 8,
248          12, 8, 12, 18, 12, 8, 12, 8
249      ]).reshape((3, 3, 3))
250      if with_bias:
251        expected_out += 1
252      conv_transpose1 = conv_transpose.Conv3DTranspose(
253          output_channels=1,
254          output_shape=None,
255          kernel_shape=3,
256          stride=1,
257          padding=&quot;SAME&quot;,
258          with_bias=with_bias,
259          **create_constant_initializers(1.0, 1.0, with_bias))
260      out = conv_transpose1(tf.ones([1, 3, 3, 3, 1], dtype=tf.float32))
261      self.assertEqual(out.shape, [1, 3, 3, 3, 1])
262      out = tf.squeeze(out, axis=(0, 4))
263      self.assertAllClose(self.evaluate(out), expected_out)
264    @parameterized.parameters(True, False)
265    def testComputationPaddingValid(self, with_bias):
266      expected_out = np.asarray([
267          1, 2, 3, 2, 1, 2, 4, 6, 4, 2, 3, 6, 9, 6, 3, 2, 4, 6, 4, 2, 1, 2, 3, 2,
268          1, 2, 4, 6, 4, 2, 4, 8, 12, 8, 4, 6, 12, 18, 12, 6, 4, 8, 12, 8, 4, 2,
269          4, 6, 4, 2, 3, 6, 9, 6, 3, 6, 12, 18, 12, 6, 9, 18, 27, 18, 9, 6, 12,
270          18, 12, 6, 3, 6, 9, 6, 3, 2, 4, 6, 4, 2, 4, 8, 12, 8, 4, 6, 12, 18, 12,
271          6, 4, 8, 12, 8, 4, 2, 4, 6, 4, 2, 1, 2, 3, 2, 1, 2, 4, 6, 4, 2, 3, 6, 9,
272          6, 3, 2, 4, 6, 4, 2, 1, 2, 3, 2, 1.
273      ]).reshape((5, 5, 5))
274      if with_bias:
275        expected_out += 1
276      conv1 = conv_transpose.Conv3DTranspose(
277          output_channels=1,
278          output_shape=None,
279          kernel_shape=3,
280          stride=1,
281          padding=&quot;VALID&quot;,
282          with_bias=with_bias,
283          **create_constant_initializers(1.0, 1.0, with_bias))
284      out = conv1(tf.ones([1, 3, 3, 3, 1], dtype=tf.float32))
285      self.assertEqual(out.shape, [1, 5, 5, 5, 1])
286      out = tf.squeeze(out, axis=(0, 4))
287      self.assertAllClose(self.evaluate(out), expected_out)
288  if __name__ == &quot;__main__&quot;:
289    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-depthwise_conv_test.py</h3>
            <pre><code>1  from absl.testing import parameterized
2  import numpy as np
3  from sonnet.src import depthwise_conv
4  from sonnet.src import initializers
5  from sonnet.src import test_utils
6  import tensorflow as tf
7  def create_constant_initializers(w, b, with_bias):
8    if with_bias:
9      return {
10          &quot;w_init&quot;: initializers.Constant(w),
11          &quot;b_init&quot;: initializers.Constant(b)
12      }
13    else:
14      return {&quot;w_init&quot;: initializers.Constant(w)}
15  class DepthwiseConvTest(test_utils.TestCase, parameterized.TestCase):
16    def testInitializerKeysInvalidWithoutBias(self):
17      with self.assertRaisesRegex(ValueError, &quot;b_init must be None&quot;):
18        depthwise_conv.DepthwiseConv2D(
19            channel_multiplier=1,
20            kernel_shape=3,
21            data_format=&quot;NHWC&quot;,
22            with_bias=False,
23            b_init=tf.zeros_initializer())
24    @parameterized.parameters(tf.float32, tf.float64)
25    def testDefaultInitializers(self, dtype):
26      if &quot;TPU&quot; in self.device_types and dtype == tf.float64:
27        self.skipTest(&quot;Double precision not supported on TPU.&quot;)
28      conv1 = depthwise_conv.DepthwiseConv2D(
29          kernel_shape=16, stride=1, padding=&quot;VALID&quot;, data_format=&quot;NHWC&quot;)
30      out = conv1(tf.random.normal([8, 64, 64, 1], dtype=dtype))
31      self.assertAllEqual(out.shape, [8, 49, 49, 1])
32      self.assertEqual(out.dtype, dtype)
33      err = 0.2 if self.primary_device == &quot;TPU&quot; else 0.1
34      self.assertNear(out.numpy().std(), 0.87, err=err)
35    @parameterized.named_parameters((&quot;SamePaddingUseBias&quot;, True, &quot;SAME&quot;),
36                                    (&quot;SamePaddingNoBias&quot;, False, &quot;SAME&quot;),
37                                    (&quot;ValidPaddingNoBias&quot;, False, &quot;VALID&quot;),
38                                    (&quot;ValidPaddingUseBias&quot;, True, &quot;VALID&quot;))
39    def testFunction(self, with_bias, padding):
40      conv1 = depthwise_conv.DepthwiseConv2D(
41          channel_multiplier=1,
42          kernel_shape=3,
43          stride=1,
44          padding=padding,
45          with_bias=with_bias,
46          data_format=&quot;NHWC&quot;,
47          **create_constant_initializers(1.0, 1.0, with_bias))
48      conv2 = depthwise_conv.DepthwiseConv2D(
49          channel_multiplier=1,
50          kernel_shape=3,
51          stride=1,
52          padding=padding,
53          with_bias=with_bias,
54          data_format=&quot;NHWC&quot;,
55          **create_constant_initializers(1.0, 1.0, with_bias))
56      defun_conv = tf.function(conv2)
<span onclick='openModal()' class='match'>57      iterations = 5
58      for _ in range(iterations):
59        x = tf.random.uniform([1, 5, 5, 1])
60        y1 = conv1(x)
61        y2 = defun_conv(x)
62        self.assertAllClose(self.evaluate(y1), self.evaluate(y2), atol=1e-4)
63    def testUnknownBatchSizeNHWC(self):
64      x = tf.TensorSpec([None, 5, 5, 3], dtype=tf.float32)
65      c = depthwise_conv.DepthwiseConv2D(
66          channel_multiplier=1, kernel_shape=3, data_format=&quot;NHWC&quot;)
</span>67      defun_conv = tf.function(c).get_concrete_function(x)
68      out1 = defun_conv(tf.ones([3, 5, 5, 3]))
69      self.assertEqual(out1.shape, [3, 5, 5, 3])
70      out2 = defun_conv(tf.ones([5, 5, 5, 3]))
71      self.assertEqual(out2.shape, [5, 5, 5, 3])
72    def testUnknownBatchSizeNCHW(self):
73      if self.primary_device == &quot;CPU&quot;:
74        self.skipTest(&quot;NCHW not supported on CPU&quot;)
75      x = tf.TensorSpec([None, 3, 5, 5], dtype=tf.float32)
76      c = depthwise_conv.DepthwiseConv2D(
77          channel_multiplier=1, kernel_shape=3, data_format=&quot;NCHW&quot;)
78      defun_conv = tf.function(c).get_concrete_function(x)
79      out1 = defun_conv(tf.ones([3, 3, 5, 5]))
80      self.assertEqual(out1.shape, [3, 3, 5, 5])
81      out2 = defun_conv(tf.ones([5, 3, 5, 5]))
82      self.assertEqual(out2.shape, [5, 3, 5, 5])
83    def testUnknownSpatialDims(self):
84      x = tf.TensorSpec([3, None, None, 3], dtype=tf.float32)
85      c = depthwise_conv.DepthwiseConv2D(
86          channel_multiplier=1, kernel_shape=3, data_format=&quot;NHWC&quot;)
87      defun_conv = tf.function(c).get_concrete_function(x)
88      out = defun_conv(tf.ones([3, 5, 5, 3]))
89      expected_out = c(tf.ones([3, 5, 5, 3]))
90      self.assertEqual(out.shape, [3, 5, 5, 3])
91      self.assertAllEqual(self.evaluate(out), self.evaluate(expected_out))
92      out = defun_conv(tf.ones([3, 4, 4, 3]))
93      expected_out = c(tf.ones([3, 4, 4, 3]))
94      self.assertEqual(out.shape, [3, 4, 4, 3])
95      self.assertAllEqual(self.evaluate(out), self.evaluate(expected_out))
96    @parameterized.parameters(True, False)
97    def testUnknownChannels(self, autograph):
98      x = tf.TensorSpec([3, 3, 3, None], dtype=tf.float32)
99      c = depthwise_conv.DepthwiseConv2D(
100          channel_multiplier=1, kernel_shape=3, data_format=&quot;NHWC&quot;)
101      defun_conv = tf.function(c, autograph=autograph)
102      with self.assertRaisesRegex(ValueError,
103                                  &quot;The number of input channels must be known&quot;):
104        defun_conv.get_concrete_function(x)
105    @parameterized.named_parameters((&quot;WithBias&quot;, True), (&quot;WithoutBias&quot;, False))
106    def testComputationSame(self, with_bias):
107      conv1 = depthwise_conv.DepthwiseConv2D(
108          channel_multiplier=1,
109          kernel_shape=[3, 3],
110          stride=1,
111          padding=&quot;SAME&quot;,
112          with_bias=with_bias,
113          **create_constant_initializers(1.0, 1.0, with_bias))
114      out = conv1(tf.ones([1, 5, 5, 1]))
115      expected_out = np.array([[5, 7, 7, 7, 5], [7, 10, 10, 10, 7],
116                               [7, 10, 10, 10, 7], [7, 10, 10, 10, 7],
117                               [5, 7, 7, 7, 5]])
118      if not with_bias:
119        expected_out -= 1
120      self.assertEqual(out.shape, [1, 5, 5, 1])
121      self.assertAllClose(np.reshape(out.numpy(), [5, 5]), expected_out)
122    @parameterized.named_parameters((&quot;WithBias&quot;, True), (&quot;WithoutBias&quot;, False))
123    def testComputationValid(self, with_bias):
124      conv1 = depthwise_conv.DepthwiseConv2D(
125          channel_multiplier=1,
126          kernel_shape=[3, 3],
127          stride=1,
128          padding=&quot;VALID&quot;,
129          with_bias=with_bias,
130          **create_constant_initializers(1.0, 1.0, with_bias))
131      out = conv1(tf.ones([1, 5, 5, 1]))
132      expected_out = np.array([[10, 10, 10], [10, 10, 10], [10, 10, 10]])
133      if not with_bias:
134        expected_out -= 1
135      self.assertEqual(out.shape, [1, 3, 3, 1])
136      self.assertAllClose(np.reshape(out.numpy(), [3, 3]), expected_out)
137    @parameterized.named_parameters((&quot;WithBias&quot;, True), (&quot;WithoutBias&quot;, False))
138    def testComputationValidMultiChannel(self, with_bias):
139      conv1 = depthwise_conv.DepthwiseConv2D(
140          channel_multiplier=1,
141          kernel_shape=[3, 3],
142          stride=1,
143          padding=&quot;VALID&quot;,
144          with_bias=with_bias,
145          **create_constant_initializers(1.0, 1.0, with_bias))
146      out = conv1(tf.ones([1, 5, 5, 3]))
147      expected_out = np.array([[[10] * 3] * 3] * 3)
148      if not with_bias:
149        expected_out -= 1
150      self.assertAllClose(np.reshape(out.numpy(), [3, 3, 3]), expected_out)
151    @parameterized.named_parameters((&quot;WithBias&quot;, True), (&quot;WithoutBias&quot;, False))
152    def testSharing(self, with_bias):
153      conv1 = depthwise_conv.DepthwiseConv2D(
154          channel_multiplier=3,
155          kernel_shape=3,
156          stride=1,
157          padding=&quot;SAME&quot;,
158          with_bias=with_bias)
159      x = np.random.randn(1, 5, 5, 1)
160      x1 = tf.constant(x, dtype=np.float32)
161      x2 = tf.constant(x, dtype=np.float32)
162      self.assertAllClose(conv1(x1), conv1(x2))
163      w = np.random.randn(3, 3, 1, 3)  # Now change the weights.
164      conv1.w.assign(w)
165      self.assertAllClose(conv1(x1), conv1(x2))
166  if __name__ == &quot;__main__&quot;:
167    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-conv_transpose_test.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-depthwise_conv_test.py</div>
                </div>
                <div class="column column_space"><pre><code>75      iterations = 5
76      for _ in range(iterations):
77        x = tf.random.uniform([1, 3, 3, 1])
78        y1 = conv1(x)
79        y2 = defun_conv(x)
80        self.assertAllClose(self.evaluate(y1), self.evaluate(y2), atol=1e-4)
81    def testUnknownBatchSizeNHWC(self):
82      x = tf.TensorSpec([None, 5, 5, 3], dtype=tf.float32)
83      c = conv_transpose.ConvNDTranspose(
84          num_spatial_dims=2,
85          output_channels=2,
86          kernel_shape=3,
</pre></code></div>
                <div class="column column_space"><pre><code>57      iterations = 5
58      for _ in range(iterations):
59        x = tf.random.uniform([1, 5, 5, 1])
60        y1 = conv1(x)
61        y2 = defun_conv(x)
62        self.assertAllClose(self.evaluate(y1), self.evaluate(y2), atol=1e-4)
63    def testUnknownBatchSizeNHWC(self):
64      x = tf.TensorSpec([None, 5, 5, 3], dtype=tf.float32)
65      c = depthwise_conv.DepthwiseConv2D(
66          channel_multiplier=1, kernel_shape=3, data_format=&quot;NHWC&quot;)
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    