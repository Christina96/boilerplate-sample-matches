<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for test_hgfs.py &amp; gce.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for test_hgfs.py &amp; gce.py
      </h3>
<h1 align="center">
        1.3%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>test_hgfs.py (2.8503563%)<th>gce.py (0.89053804%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(295-299)<td><a href="#" name="0">(2352-2362)</a><td align="center"><font color="#ff0000">12</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(50-53)<td><a href="#" name="1">(1332-1336)</a><td align="center"><font color="#ff0000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_hgfs.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import shutil
2 import tempfile
3 from pathlib import Path
4 import psutil  # pylint: disable=3rd-party-module-not-gated
5 import pytest
6 import salt.config
7 import salt.fileserver.hgfs as hgfs
8 from saltfactories.utils.processes import terminate_process
9 from tests.support.mock import patch
10 try:
11     import hglib
12     HAS_HG = True
13 except ImportError:
14     HAS_HG = False
15 @pytest.fixture(scope="module")
16 def configure_loader_modules():
17     opts = salt.config.DEFAULT_MASTER_OPTS.copy()
18     cache = tempfile.TemporaryDirectory(dir="/tmp")
19     opts["cachedir"] = cache.name
20     opts["fileserver_backend"] = ["hgfs"]
21     yield {hgfs: {"__opts__": opts}}
22     cache.cleanup()
23 @pytest.fixture
24 def hgfs_setup_and_teardown():
25     initial_child_processes = psutil.Process().children()
26     source_dir = Path(__file__).resolve().parent.joinpath("files")
27     tempdir = tempfile.TemporaryDirectory()
28     tempsubdir = tempdir.name / Path("subdir/")
29     tempsubdir.mkdir()
30     tempdirPath = Path(tempdir.name)
31     for file in source_dir.iterdir():
32         to_file = tempdirPath / file.name
33         to_file2 = tempsubdir / file.name
34         shutil.copy(file.as_posix(), to_file.as_posix())
35         shutil.copy(file.as_posix(), to_file2.as_posix())
36 <a name="1"></a>    client = hglib.init(bytes(tempdirPath.as_posix(), encoding="utf8"))
37     client.close()
38     with hglib.open(bytes(tempdirPath.as_posix(), encoding="utf8")) as repo:
39         repo.add(bytes<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(tempdirPath.as_posix(), encoding="utf8"))
40         repo.commit(b"init commit", user="test")
41         repo.tag(b"test", user="test")
42         repo.branch(</b></font>b"test")
43         repo.commit(b"create test branch", user="test")
44         repo.bookmark(b"bookmark_test")
45     try:
46         yield tempdirPath.as_uri()
47     finally:
48         tempdir.cleanup()
49         for child in psutil.Process().children():
50             if child not in initial_child_processes:
51                 terminate_process(process=child, kill_children=True)
52 @pytest.mark.slow_test
53 @pytest.mark.skip_on_windows(reason="testing break in windows")
54 def test_fix_58852(hgfs_setup_and_teardown):
55     with patch.dict(
56         hgfs.__opts__,
57         {
58             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
59         },
60     ):
61         repo = hgfs.init()
62         assert isinstance(repo, list)
63         if isinstance(repo, list):
64             for value in repo:
65                 assert isinstance(value, dict)
66                 for key, value in value.items():
67                     if key != "repo":
68                         assert isinstance(value, str)
69 @pytest.mark.slow_test
70 @pytest.mark.skip_on_windows(reason="testing break in windows")
71 def test_all_branches(hgfs_setup_and_teardown):
72     with patch.dict(
73         hgfs.__opts__,
74         {
75             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
76         },
77     ):
78         repos = hgfs.init()
79         hgfs.update()
80         for repo in repos:
81             repo["repo"].open()
82             branches = hgfs._all_branches(repo["repo"])
83             assert isinstance(branches, list)
84             if isinstance(branches, list):
85                 for value in branches:
86                     assert isinstance(value, tuple)
87                     assert len(value) == 3
88                     assert value[0] in ["default", "test"]
89                     assert isinstance(value[1], int)
90                     assert isinstance(value[2], str)
91 @pytest.mark.slow_test
92 @pytest.mark.skip_on_windows(reason="testing break in windows")
93 def test_get_branch(hgfs_setup_and_teardown):
94     with patch.dict(
95         hgfs.__opts__,
96         {
97             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
98         },
99     ):
100         repo = hgfs.init()
101         hgfs.update()
102         repo[0]["repo"].open()
103         branch = hgfs._get_branch(repo[0]["repo"], "test")
104         assert isinstance(branch, tuple)
105         assert len(branch) == 3
106         assert branch[0] in "test"
107         assert branch[1] == 2
108         assert isinstance(branch[2], str)
109         branch = hgfs._get_branch(repo[0]["repo"], "fake")
110         assert branch is False
111 @pytest.mark.slow_test
112 @pytest.mark.skip_on_windows(reason="testing break in windows")
113 def test_all_bookmarks(hgfs_setup_and_teardown):
114     with patch.dict(
115         hgfs.__opts__,
116         {
117             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
118         },
119     ):
120         repos = hgfs.init()
121         hgfs.update()
122         for repo in repos:
123             repo["repo"].open()
124             bookmarks = hgfs._all_bookmarks(repo["repo"])
125             assert isinstance(bookmarks, list)
126             if isinstance(bookmarks, list):
127                 for value in bookmarks:
128                     assert isinstance(value, tuple)
129                     assert len(value) == 3
130                     assert value[0] in ["bookmark_test"]
131                     assert value[1] == 2
132                     assert isinstance(value[2], str)
133 @pytest.mark.slow_test
134 @pytest.mark.skip_on_windows(reason="testing break in windows")
135 def test_get_bookmark(hgfs_setup_and_teardown):
136     with patch.dict(
137         hgfs.__opts__,
138         {
139             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
140         },
141     ):
142         repo = hgfs.init()
143         hgfs.update()
144         repo[0]["repo"].open()
145         bookmark = hgfs._get_bookmark(repo[0]["repo"], "bookmark_test")
146         assert isinstance(bookmark, tuple)
147         assert len(bookmark) == 3
148         assert bookmark[0] in "bookmark_test"
149         assert bookmark[1] == 2
150         assert isinstance(bookmark[2], str)
151         bookmark = hgfs._get_bookmark(repo[0]["repo"], "fake")
152         assert bookmark is False
153 @pytest.mark.slow_test
154 @pytest.mark.skip_on_windows(reason="testing break in windows")
155 def test_all_tags(hgfs_setup_and_teardown):
156     with patch.dict(
157         hgfs.__opts__,
158         {
159             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
160         },
161     ):
162         repos = hgfs.init()
163         hgfs.update()
164         for repo in repos:
165             repo["repo"].open()
166             tags = hgfs._all_tags(repo["repo"])
167             assert isinstance(tags, list)
168             if isinstance(tags, list):
169                 for value in tags:
170                     assert isinstance(value, tuple)
171                     assert len(value) == 4
172                     assert value[0] in ["test"]
173                     assert value[0] not in ["tip"]
174                     assert value[1] == 0
175                     assert isinstance(value[2], str)
176                     assert value[3] is False
177 @pytest.mark.slow_test
178 @pytest.mark.skip_on_windows(reason="testing break in windows")
179 def test_get_tag(hgfs_setup_and_teardown):
180     with patch.dict(
181         hgfs.__opts__,
182         {
183             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
184         },
185     ):
186         repo = hgfs.init()
187         hgfs.update()
188         repo[0]["repo"].open()
189         tag = hgfs._get_tag(repo[0]["repo"], "test")
190         assert isinstance(tag, tuple)
191         assert len(tag) == 4
192         assert tag[0] in "test"
193         assert tag[1] == 0
194         assert isinstance(tag[2], str)
195         tag = hgfs._get_tag(repo[0]["repo"], "fake")
196         assert tag is False
197         tag = hgfs._get_tag(repo[0]["repo"], "tip")
198         assert tag is False
199 @pytest.mark.slow_test
200 @pytest.mark.skip_on_windows(reason="testing break in windows")
201 def test_get_ref(hgfs_setup_and_teardown):
202     with patch.dict(
203         hgfs.__opts__,
204         {
205             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
206         },
207     ):
208         repo = hgfs.init()[0]
209         hgfs.update()
210         repo["repo"].open()
211         ref = hgfs._get_ref(repo, "base")
212         assert isinstance(ref, tuple)
213         assert len(ref) == 3
214         assert ref[0] == "default"
215         assert ref[1] == 1
216         assert isinstance(ref[2], str)
217     with patch.dict(
218         hgfs.__opts__,
219         {
220             "hgfs_remotes": [
221                 {str(hgfs_setup_and_teardown): [{"base": "bookmark_test"}]}
222             ],
223             "hgfs_branch_method": "bookmarks",
224         },
225     ):
226         repo = hgfs.init()[0]
227         hgfs.update()
228         repo["repo"].open()
229         ref = hgfs._get_ref(repo, "base")
230         assert isinstance(ref, tuple)
231         assert len(ref) == 3
232         assert ref[0] in "bookmark_test"
233         assert ref[1] == 2
234         assert isinstance(ref[2], str)
235     with patch.dict(
236         hgfs.__opts__,
237         {
238             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
239         },
240     ):
241         repo = hgfs.init()[0]
242         hgfs.update()
243         repo["repo"].open()
244         ref = hgfs._get_ref(repo, "fake")
245         assert ref is False
246 @pytest.mark.slow_test
247 @pytest.mark.skip_on_windows(reason="testing break in windows")
248 def test_get_manifest(hgfs_setup_and_teardown):
249     with patch.dict(
250         hgfs.__opts__,
251         {
252 <a name="0"></a>            "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
253         },
254     ):
255         repo = hgfs.init()<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>[0]
256         hgfs.update()
257         repo["repo"].open()
258         ref = hgfs._get_ref(repo, "base")
259         manifest = hgfs._get_manifest(</b></font>repo["repo"], ref=ref)
260         assert isinstance(manifest, list)
261         for value in manifest:
262             assert len(value) == 5
263             assert isinstance(value[0], str)
264             assert value[1] == "644"
265             assert value[2] is False
266             assert value[3] is False
267             assert value[4] in [
268                 "test.sls",
269                 "test2.sls",
270                 ".hgtags",
271                 "subdir/test.sls",
272                 "subdir/test2.sls",
273             ]
274 @pytest.mark.slow_test
275 @pytest.mark.skip_on_windows(reason="testing break in windows")
276 def test_envs(hgfs_setup_and_teardown):
277     with patch.dict(
278         hgfs.__opts__,
279         {
280             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
281             "hgfs_branch_method": "branches",
282         },
283     ):
284         hgfs.init()
285         hgfs.update()
286         envs = hgfs.envs(ignore_cache=True)
287         assert isinstance(envs, list)
288         assert envs == ["base", "test"]
289     with patch.dict(
290         hgfs.__opts__,
291         {
292             "hgfs_remotes": [
293                 {str(hgfs_setup_and_teardown): [{"base": "bookmark_test"}]}
294             ],
295             "hgfs_branch_method": "bookmarks",
296         },
297     ):
298         hgfs.init()
299         hgfs.update()
300         envs = hgfs.envs(ignore_cache=True)
301         assert isinstance(envs, list)
302         assert envs == ["base", "test"]
303 @pytest.mark.skip_on_windows(reason="testing break in windows")
304 def test_env_is_exposed_blacklist():
305     with patch.dict(
306         hgfs.__opts__,
307         {"hgfs_saltenv_whitelist": "", "hgfs_saltenv_blacklist": "test"},
308     ):
309         hgfs.init()
310         hgfs.update()
311         assert hgfs._env_is_exposed("base") is True
312         assert hgfs._env_is_exposed("test") is False
313         assert hgfs._env_is_exposed("unset") is True
314 @pytest.mark.skip_on_windows(reason="testing break in windows")
315 def test_env_is_exposed_whitelist():
316     with patch.dict(
317         hgfs.__opts__,
318         {"hgfs_saltenv_whitelist": "base", "hgfs_saltenv_blacklist": ""},
319     ):
320         hgfs.init()
321         hgfs.update()
322         assert hgfs._env_is_exposed("base") is True
323         assert hgfs._env_is_exposed("test") is False
324         assert hgfs._env_is_exposed("unset") is False
325 @pytest.mark.slow_test
326 @pytest.mark.skip_on_windows(reason="testing break in windows")
327 def test_find_file(hgfs_setup_and_teardown):
328     with patch.dict(
329         hgfs.__opts__,
330         {
331             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
332         },
333     ):
334         hgfs.init()
335         hgfs.update()
336         file = hgfs.find_file(path="test.sls", tgt_env="base")
337         assert file["path"] == hgfs.__opts__["cachedir"] + "/hgfs/refs/base/test.sls"
338         assert file["rel"] == "test.sls"
339         assert isinstance(file["stat"], list)
340         for i in file["stat"]:
341             assert isinstance(i, int)
342 @pytest.mark.slow_test
343 @pytest.mark.skip_on_windows(reason="testing break in windows")
344 def test_serve_file(hgfs_setup_and_teardown):
345     with patch.dict(
346         hgfs.__opts__,
347         {
348             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
349         },
350     ):
351         hgfs.init()
352         hgfs.update()
353         file = hgfs.find_file(path="test.sls", tgt_env="base")
354         load = {"saltenv": "base", "loc": 0, "path": "test.sls"}
355         data = hgfs.serve_file(load, file)
356         assert data == {
357             "data": "always-passes:\n  test.succeed_without_changes:\n    - name: foo\n",
358             "dest": "test.sls",
359         }
360 @pytest.mark.slow_test
361 @pytest.mark.skip_on_windows(reason="testing break in windows")
362 def test_file_hash(hgfs_setup_and_teardown):
363     with patch.dict(
364         hgfs.__opts__,
365         {
366             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
367         },
368     ):
369         hgfs.init()
370         hgfs.update()
371         file = hgfs.find_file(path="test.sls", tgt_env="base")
372         load = {"saltenv": "base", "loc": 0, "path": "test.sls"}
373         data = hgfs.file_hash(load, file)
374         assert data == {
375             "hash_type": "sha256",
376             "hsum": "a6a48d90dce9c9b580efb2ed308af100a8328913dcf9441705125866551c7d8d",
377         }
378 @pytest.mark.slow_test
379 @pytest.mark.skip_on_windows(reason="testing break in windows")
380 def test_file_list(hgfs_setup_and_teardown):
381     with patch.dict(
382         hgfs.__opts__,
383         {
384             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
385         },
386     ):
387         hgfs.init()
388         hgfs.update()
389         load = {"saltenv": "base", "loc": 0, "path": "test.sls"}
390         data = hgfs.file_list(load)
391         assert data == [
392             ".hgtags",
393             "subdir/test.sls",
394             "subdir/test2.sls",
395             "test.sls",
396             "test2.sls",
397         ]
398 @pytest.mark.slow_test
399 @pytest.mark.skip_on_windows(reason="testing break in windows")
400 def test_dir_list(hgfs_setup_and_teardown):
401     with patch.dict(
402         hgfs.__opts__,
403         {
404             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
405         },
406     ):
407         hgfs.init()
408         hgfs.update()
409         load = {"saltenv": "base", "loc": 0, "path": "test.sls"}
410         data = hgfs.dir_list(load)
411         assert data == ["subdir"]
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>gce.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import logging
2 import os
3 import pprint
4 import re
5 import sys
6 from ast import literal_eval
7 import salt.config as config
8 import salt.utils.cloud
9 import salt.utils.files
10 import salt.utils.http
11 import salt.utils.msgpack
12 from salt.cloud.libcloudfuncs import *  # pylint: disable=redefined-builtin,wildcard-import,unused-wildcard-import
13 from salt.exceptions import SaltCloudSystemExit
14 from salt.utils.functools import namespaced_function
15 from salt.utils.versions import LooseVersion as _LooseVersion
16 LIBCLOUD_IMPORT_ERROR = None
17 try:
18     import libcloud
19     from libcloud.compute.types import Provider
20     from libcloud.compute.providers import get_driver
21     from libcloud.loadbalancer.types import Provider as Provider_lb
22     from libcloud.loadbalancer.providers import get_driver as get_driver_lb
23     from libcloud.common.google import (
24         ResourceInUseError,
25         ResourceNotFoundError,
26     )
27     HAS_LIBCLOUD = True
28 except ImportError:
29     LIBCLOUD_IMPORT_ERROR = sys.exc_info()
30     HAS_LIBCLOUD = False
31 log = logging.getLogger(__name__)
32 __virtualname__ = "gce"
33 _UA_PRODUCT = "salt-cloud"
34 _UA_VERSION = "0.2.0"
35 avail_locations = namespaced_function(avail_locations, globals())
36 script = namespaced_function(script, globals())
37 destroy = namespaced_function(destroy, globals())
38 list_nodes = namespaced_function(list_nodes, globals())
39 list_nodes_full = namespaced_function(list_nodes_full, globals())
40 list_nodes_select = namespaced_function(list_nodes_select, globals())
41 GCE_VM_NAME_REGEX = re.compile(r"^(?:[a-z](?:[-a-z0-9]{0,61}[a-z0-9])?)$")
42 def __virtual__():
43     if not HAS_LIBCLOUD:
44         return False, "apache-libcloud is not installed"
45     if _LooseVersion(libcloud.__version__) &lt; _LooseVersion("2.5.0"):
46         return False, "The salt-cloud GCE driver requires apache-libcloud&gt;=2.5.0"
47     if get_configured_provider() is False:
48         return False
49     if get_dependencies() is False:
50         return False
51     for provider, details in __opts__["providers"].items():
52         if "gce" not in details:
53             continue
54         parameters = details["gce"]
55         pathname = os.path.expanduser(parameters["service_account_private_key"])
56         if (
57             pathname
58             and salt.utils.cloud.check_key_path_and_mode(provider, pathname) is False
59         ):
60             return False
61     return __virtualname__
62 def _get_active_provider_name():
63     try:
64         return __active_provider_name__.value()
65     except AttributeError:
66         return __active_provider_name__
67 def get_configured_provider():
68     return config.is_provider_configured(
69         __opts__,
70         _get_active_provider_name() or "gce",
71         ("project", "service_account_email_address", "service_account_private_key"),
72     )
73 def get_dependencies():
74     if LIBCLOUD_IMPORT_ERROR:
75         log.error("Failure when importing LibCloud: ", exc_info=LIBCLOUD_IMPORT_ERROR)
76         log.error(
77             "Note: The libcloud dependency is called 'apache-libcloud' on PyPi/pip."
78         )
79     return config.check_driver_dependencies(__virtualname__, {"libcloud": HAS_LIBCLOUD})
80 def get_lb_conn(gce_driver=None):
81     if not gce_driver:
82         raise SaltCloudSystemExit("Missing gce_driver for get_lb_conn method.")
83     return get_driver_lb(Provider_lb.GCE)(gce_driver=gce_driver)
84 def get_conn():
85     driver = get_driver(Provider.GCE)
86     provider = get_configured_provider()
87     project = config.get_cloud_config_value("project", provider, __opts__)
88     email = config.get_cloud_config_value(
89         "service_account_email_address", provider, __opts__
90     )
91     private_key = config.get_cloud_config_value(
92         "service_account_private_key", provider, __opts__
93     )
94     gce = driver(email, private_key, project=project)
95     gce.connection.user_agent_append("{}/{}".format(_UA_PRODUCT, _UA_VERSION))
96     return gce
97 def _expand_item(item):
98     ret = {}
99     ret.update(item.__dict__)
100     return ret
101 def _expand_node(node):
102     ret = {}
103     ret.update(node.__dict__)
104     try:
105         del ret["extra"]["boot_disk"]
106     except Exception:  # pylint: disable=W0703
107         pass
108     zone = ret["extra"]["zone"]
109     ret["extra"]["zone"] = {}
110     ret["extra"]["zone"].update(zone.__dict__)
111     if "driver" in ret:
112         del ret["driver"]
113     if "driver" in ret["extra"]["zone"]:
114         del ret["extra"]["zone"]["driver"]
115     return ret
116 def _expand_disk(disk):
117     ret = {}
118     ret.update(disk.__dict__)
119     zone = ret["extra"]["zone"]
120     ret["extra"]["zone"] = {}
121     ret["extra"]["zone"].update(zone.__dict__)
122     return ret
123 def _expand_address(addy):
124     ret = {}
125     ret.update(addy.__dict__)
126     ret["extra"]["zone"] = addy.region.name
127     return ret
128 def _expand_balancer(lb):
129     ret = {}
130     ret.update(lb.__dict__)
131     hc = ret["extra"]["healthchecks"]
132     ret["extra"]["healthchecks"] = []
133     for item in hc:
134         ret["extra"]["healthchecks"].append(_expand_item(item))
135     fwr = ret["extra"]["forwarding_rule"]
136     tp = ret["extra"]["forwarding_rule"].targetpool
137     reg = ret["extra"]["forwarding_rule"].region
138     ret["extra"]["forwarding_rule"] = {}
139     ret["extra"]["forwarding_rule"].update(fwr.__dict__)
140     ret["extra"]["forwarding_rule"]["targetpool"] = tp.name
141     ret["extra"]["forwarding_rule"]["region"] = reg.name
142     tp = ret["extra"]["targetpool"]
143     hc = ret["extra"]["targetpool"].healthchecks
144     nodes = ret["extra"]["targetpool"].nodes
145     region = ret["extra"]["targetpool"].region
146     zones = ret["extra"]["targetpool"].region.zones
147     ret["extra"]["targetpool"] = {}
148     ret["extra"]["targetpool"].update(tp.__dict__)
149     ret["extra"]["targetpool"]["region"] = _expand_item(region)
150     ret["extra"]["targetpool"]["nodes"] = []
151     for n in nodes:
152         ret["extra"]["targetpool"]["nodes"].append(_expand_node(n))
153     ret["extra"]["targetpool"]["healthchecks"] = []
154     for hci in hc:
155         ret["extra"]["targetpool"]["healthchecks"].append(hci.name)
156     ret["extra"]["targetpool"]["region"]["zones"] = []
157     for z in zones:
158         ret["extra"]["targetpool"]["region"]["zones"].append(z.name)
159     return ret
160 def show_instance(vm_name, call=None):
161     if call != "action":
162         raise SaltCloudSystemExit(
163             "The show_instance action must be called with -a or --action."
164         )
165     conn = get_conn()
166     node = _expand_node(conn.ex_get_node(vm_name))
167     __utils__["cloud.cache_node"](node, _get_active_provider_name(), __opts__)
168     return node
169 def avail_sizes(conn=None):
170     if not conn:
171         conn = get_conn()
172     raw_sizes = conn.list_sizes("all")  # get *all* the machine types!
173     sizes = []
174     for size in raw_sizes:
175         zone = size.extra["zone"]
176         size.extra["zone"] = {}
177         size.extra["zone"].update(zone.__dict__)
178         mtype = {}
179         mtype.update(size.__dict__)
180         sizes.append(mtype)
181     return sizes
182 def avail_images(conn=None):
183     if not conn:
184         conn = get_conn()
185     all_images = []
186     public_image_projects = (
187         "centos-cloud",
188         "coreos-cloud",
189         "debian-cloud",
190         "google-containers",
191         "opensuse-cloud",
192         "rhel-cloud",
193         "suse-cloud",
194         "ubuntu-os-cloud",
195         "windows-cloud",
196     )
197     for project in public_image_projects:
198         all_images.extend(conn.list_images(project))
199     all_images.extend(conn.list_images())
200     ret = {}
201     for img in all_images:
202         ret[img.name] = {}
203         for attr in dir(img):
204             if attr.startswith("_"):
205                 continue
206             ret[img.name][attr] = getattr(img, attr)
207     return ret
208 def __get_image(conn, vm_):
209     img = config.get_cloud_config_value(
210         "image", vm_, __opts__, default="debian-7", search_global=False
211     )
212     return conn.ex_get_image(img)
213 def __get_location(conn, vm_):
214     location = config.get_cloud_config_value("location", vm_, __opts__)
215     return conn.ex_get_zone(location)
216 def __get_size(conn, vm_):
217     size = config.get_cloud_config_value(
218         "size", vm_, __opts__, default="n1-standard-1", search_global=False
219     )
220     return conn.ex_get_size(size, __get_location(conn, vm_))
221 def __get_tags(vm_):
222     t = config.get_cloud_config_value(
223         "tags", vm_, __opts__, default="[]", search_global=False
224     )
225     try:
226         tags = literal_eval(t)
227     except Exception:  # pylint: disable=W0703
228         tags = None
229     if not tags or not isinstance(tags, list):
230         tags = None
231     return tags
232 def __get_metadata(vm_):
233     md = config.get_cloud_config_value(
234         "metadata", vm_, __opts__, default="{}", search_global=False
235     )
236     try:
237         metadata = literal_eval(md)
238     except Exception:  # pylint: disable=W0703
239         metadata = None
240     if not metadata or not isinstance(metadata, dict):
241         metadata = {"items": [{"key": "salt-cloud-profile", "value": vm_["profile"]}]}
242     else:
243         metadata["salt-cloud-profile"] = vm_["profile"]
244         items = []
245         for k, v in metadata.items():
246             items.append({"key": k, "value": v})
247         metadata = {"items": items}
248     return metadata
249 def __get_host(node, vm_):
250     if __get_ssh_interface(vm_) == "private_ips" or vm_["external_ip"] is None:
251         ip_address = node.private_ips[0]
252         log.info("Salt node data. Private_ip: %s", ip_address)
253     else:
254         ip_address = node.public_ips[0]
255         log.info("Salt node data. Public_ip: %s", ip_address)
256     if ip_address:
257         return ip_address
258     return node.name
259 def __get_network(conn, vm_):
260     network = config.get_cloud_config_value(
261         "network", vm_, __opts__, default="default", search_global=False
262     )
263     return conn.ex_get_network(network)
264 def __get_subnetwork(vm_):
265     ex_subnetwork = config.get_cloud_config_value(
266         "subnetwork", vm_, __opts__, search_global=False
267     )
268     return ex_subnetwork
269 def __get_region(conn, vm_):
270     location = __get_location(conn, vm_)
271     region = "-".join(location.name.split("-")[:2])
272     return conn.ex_get_region(region)
273 def __get_ssh_interface(vm_):
274     return config.get_cloud_config_value(
275         "ssh_interface", vm_, __opts__, default="public_ips", search_global=False
276     )
277 def __create_orget_address(conn, name, region):
278     try:
279         addy = conn.ex_get_address(name, region)
280     except ResourceNotFoundError:  # pylint: disable=W0703
281         addr_kwargs = {"name": name, "region": region}
282         new_addy = create_address(addr_kwargs, "function")
283         addy = conn.ex_get_address(new_addy["name"], new_addy["region"])
284     return addy
285 def _parse_allow(allow):
286     seen_protos = {}
287     allow_dict = []
288     protocols = allow.split(",")
289     for p in protocols:
290         pairs = p.split(":")
291         if pairs[0].lower() not in ["tcp", "udp", "icmp"]:
292             raise SaltCloudSystemExit(
293                 "Unsupported protocol {}. Must be tcp, udp, or icmp.".format(pairs[0])
294             )
295         if len(pairs) == 1 or pairs[0].lower() == "icmp":
296             seen_protos[pairs[0]] = []
297         else:
298             if pairs[0] not in seen_protos:
299                 seen_protos[pairs[0]] = [pairs[1]]
300             else:
301                 seen_protos[pairs[0]].append(pairs[1])
302     for k in seen_protos:
303         d = {"IPProtocol": k}
304         if seen_protos[k]:
305             d["ports"] = seen_protos[k]
306         allow_dict.append(d)
307     log.debug("firewall allowed protocols/ports: %s", allow_dict)
308     return allow_dict
309 def __get_ssh_credentials(vm_):
310     ssh_user = config.get_cloud_config_value(
311         "ssh_username", vm_, __opts__, default=os.getenv("USER")
312     )
313     ssh_key = config.get_cloud_config_value(
314         "ssh_keyfile",
315         vm_,
316         __opts__,
317         default=os.path.expanduser("~/.ssh/google_compute_engine"),
318     )
319     return ssh_user, ssh_key
320 def create_network(kwargs=None, call=None):
321     if call != "function":
322         raise SaltCloudSystemExit(
323             "The create_network function must be called with -f or --function."
324         )
325     if not kwargs or "name" not in kwargs:
326         log.error("A name must be specified when creating a network.")
327         return False
328     mode = kwargs.get("mode", "legacy")
329     cidr = kwargs.get("cidr", None)
330     if cidr is None and mode == "legacy":
331         log.error(
332             "A network CIDR range must be specified when creating a legacy network."
333         )
334         return False
335     name = kwargs["name"]
336     desc = kwargs.get("description", None)
337     conn = get_conn()
338     __utils__["cloud.fire_event"](
339         "event",
340         "creating network",
341         "salt/cloud/net/creating",
342         args={"name": name, "cidr": cidr, "description": desc, "mode": mode},
343         sock_dir=__opts__["sock_dir"],
344         transport=__opts__["transport"],
345     )
346     network = conn.ex_create_network(name, cidr, desc, mode)
347     __utils__["cloud.fire_event"](
348         "event",
349         "created network",
350         "salt/cloud/net/created",
351         args={"name": name, "cidr": cidr, "description": desc, "mode": mode},
352         sock_dir=__opts__["sock_dir"],
353         transport=__opts__["transport"],
354     )
355     return _expand_item(network)
356 def delete_network(kwargs=None, call=None):
357     if call != "function":
358         raise SaltCloudSystemExit(
359             "The delete_network function must be called with -f or --function."
360         )
361     if not kwargs or "name" not in kwargs:
362         log.error("A name must be specified when deleting a network.")
363         return False
364     name = kwargs["name"]
365     conn = get_conn()
366     __utils__["cloud.fire_event"](
367         "event",
368         "deleting network",
369         "salt/cloud/net/deleting",
370         args={"name": name},
371         sock_dir=__opts__["sock_dir"],
372         transport=__opts__["transport"],
373     )
374     try:
375         result = conn.ex_destroy_network(conn.ex_get_network(name))
376     except ResourceNotFoundError as exc:
377         log.error(
378             "Nework %s was not found. Exception was: %s",
379             name,
380             exc,
381             exc_info_on_loglevel=logging.DEBUG,
382         )
383         return False
384     __utils__["cloud.fire_event"](
385         "event",
386         "deleted network",
387         "salt/cloud/net/deleted",
388         args={"name": name},
389         sock_dir=__opts__["sock_dir"],
390         transport=__opts__["transport"],
391     )
392     return result
393 def show_network(kwargs=None, call=None):
394     if call != "function":
395         raise SaltCloudSystemExit(
396             "The show_network function must be called with -f or --function."
397         )
398     if not kwargs or "name" not in kwargs:
399         log.error("Must specify name of network.")
400         return False
401     conn = get_conn()
402     return _expand_item(conn.ex_get_network(kwargs["name"]))
403 def create_subnetwork(kwargs=None, call=None):
404     if call != "function":
405         raise SaltCloudSystemExit(
406             "The create_subnetwork function must be called with -f or --function."
407         )
408     if not kwargs or "name" not in kwargs:
409         log.error("Must specify name of subnet.")
410         return False
411     if "network" not in kwargs:
412         log.errror("Must specify name of network to create subnet under.")
413         return False
414     if "cidr" not in kwargs:
415         log.errror("A network CIDR range must be specified when creating a subnet.")
416         return False
417     if "region" not in kwargs:
418         log.error("A region must be specified when creating a subnetwork.")
419         return False
420     name = kwargs["name"]
421     cidr = kwargs["cidr"]
422     network = kwargs["network"]
423     region = kwargs["region"]
424     desc = kwargs.get("description", None)
425     conn = get_conn()
426     __utils__["cloud.fire_event"](
427         "event",
428         "create subnetwork",
429         "salt/cloud/subnet/creating",
430         args={
431             "name": name,
432             "network": network,
433             "cidr": cidr,
434             "region": region,
435             "description": desc,
436         },
437         sock_dir=__opts__["sock_dir"],
438         transport=__opts__["transport"],
439     )
440     subnet = conn.ex_create_subnetwork(name, cidr, network, region, desc)
441     __utils__["cloud.fire_event"](
442         "event",
443         "created subnetwork",
444         "salt/cloud/subnet/created",
445         args={
446             "name": name,
447             "network": network,
448             "cidr": cidr,
449             "region": region,
450             "description": desc,
451         },
452         sock_dir=__opts__["sock_dir"],
453         transport=__opts__["transport"],
454     )
455     return _expand_item(subnet)
456 def delete_subnetwork(kwargs=None, call=None):
457     if call != "function":
458         raise SaltCloudSystemExit(
459             "The delete_subnet function must be called with -f or --function."
460         )
461     if not kwargs or "name" not in kwargs:
462         log.error("Must specify name of subnet.")
463         return False
464     if "region" not in kwargs:
465         log.error("Must specify region of subnet.")
466         return False
467     name = kwargs["name"]
468     region = kwargs["region"]
469     conn = get_conn()
470     __utils__["cloud.fire_event"](
471         "event",
472         "deleting subnetwork",
473         "salt/cloud/subnet/deleting",
474         args={"name": name, "region": region},
475         sock_dir=__opts__["sock_dir"],
476         transport=__opts__["transport"],
477     )
478     try:
479         result = conn.ex_destroy_subnetwork(name, region)
480     except ResourceNotFoundError as exc:
481         log.error(
482             "Subnetwork %s was not found. Exception was: %s",
483             name,
484             exc,
485             exc_info_on_loglevel=logging.DEBUG,
486         )
487         return False
488     __utils__["cloud.fire_event"](
489         "event",
490         "deleted subnetwork",
491         "salt/cloud/subnet/deleted",
492         args={"name": name, "region": region},
493         sock_dir=__opts__["sock_dir"],
494         transport=__opts__["transport"],
495     )
496     return result
497 def show_subnetwork(kwargs=None, call=None):
498     if call != "function":
499         raise SaltCloudSystemExit(
500             "The show_subnetwork function must be called with -f or --function."
501         )
502     if not kwargs or "name" not in kwargs:
503         log.error("Must specify name of subnet.")
504         return False
505     if "region" not in kwargs:
506         log.error("Must specify region of subnet.")
507         return False
508     name = kwargs["name"]
509     region = kwargs["region"]
510     conn = get_conn()
511     return _expand_item(conn.ex_get_subnetwork(name, region))
512 def create_fwrule(kwargs=None, call=None):
513     if call != "function":
514         raise SaltCloudSystemExit(
515             "The create_fwrule function must be called with -f or --function."
516         )
517     if not kwargs or "name" not in kwargs:
518         log.error("A name must be specified when creating a firewall rule.")
519         return False
520     if "allow" not in kwargs:
521         log.error('Must use "allow" to specify allowed protocols/ports.')
522         return False
523     name = kwargs["name"]
524     network_name = kwargs.get("network", "default")
525     allow = _parse_allow(kwargs["allow"])
526     src_range = kwargs.get("src_range", "0.0.0.0/0")
527     src_tags = kwargs.get("src_tags", None)
528     dst_tags = kwargs.get("dst_tags", None)
529     if src_range:
530         src_range = src_range.split(",")
531     if src_tags:
532         src_tags = src_tags.split(",")
533     if dst_tags:
534         dst_tags = dst_tags.split(",")
535     conn = get_conn()
536     __utils__["cloud.fire_event"](
537         "event",
538         "create firewall",
539         "salt/cloud/firewall/creating",
540         args={"name": name, "network": network_name, "allow": kwargs["allow"]},
541         sock_dir=__opts__["sock_dir"],
542         transport=__opts__["transport"],
543     )
544     fwrule = conn.ex_create_firewall(
545         name,
546         allow,
547         network=network_name,
548         source_ranges=src_range,
549         source_tags=src_tags,
550         target_tags=dst_tags,
551     )
552     __utils__["cloud.fire_event"](
553         "event",
554         "created firewall",
555         "salt/cloud/firewall/created",
556         args={"name": name, "network": network_name, "allow": kwargs["allow"]},
557         sock_dir=__opts__["sock_dir"],
558         transport=__opts__["transport"],
559     )
560     return _expand_item(fwrule)
561 def delete_fwrule(kwargs=None, call=None):
562     if call != "function":
563         raise SaltCloudSystemExit(
564             "The delete_fwrule function must be called with -f or --function."
565         )
566     if not kwargs or "name" not in kwargs:
567         log.error("A name must be specified when deleting a firewall rule.")
568         return False
569     name = kwargs["name"]
570     conn = get_conn()
571     __utils__["cloud.fire_event"](
572         "event",
573         "delete firewall",
574         "salt/cloud/firewall/deleting",
575         args={"name": name},
576         sock_dir=__opts__["sock_dir"],
577         transport=__opts__["transport"],
578     )
579     try:
580         result = conn.ex_destroy_firewall(conn.ex_get_firewall(name))
581     except ResourceNotFoundError as exc:
582         log.error(
583             "Rule %s was not found. Exception was: %s",
584             name,
585             exc,
586             exc_info_on_loglevel=logging.DEBUG,
587         )
588         return False
589     __utils__["cloud.fire_event"](
590         "event",
591         "deleted firewall",
592         "salt/cloud/firewall/deleted",
593         args={"name": name},
594         sock_dir=__opts__["sock_dir"],
595         transport=__opts__["transport"],
596     )
597     return result
598 def show_fwrule(kwargs=None, call=None):
599     if call != "function":
600         raise SaltCloudSystemExit(
601             "The show_fwrule function must be called with -f or --function."
602         )
603     if not kwargs or "name" not in kwargs:
604         log.error("Must specify name of network.")
605         return False
606     conn = get_conn()
607     return _expand_item(conn.ex_get_firewall(kwargs["name"]))
608 def create_hc(kwargs=None, call=None):
609     if call != "function":
610         raise SaltCloudSystemExit(
611             "The create_hc function must be called with -f or --function."
612         )
613     if not kwargs or "name" not in kwargs:
614         log.error("A name must be specified when creating a health check.")
615         return False
616     name = kwargs["name"]
617     host = kwargs.get("host", None)
618     path = kwargs.get("path", None)
619     port = kwargs.get("port", None)
620     interval = kwargs.get("interval", None)
621     timeout = kwargs.get("timeout", None)
622     unhealthy_threshold = kwargs.get("unhealthy_threshold", None)
623     healthy_threshold = kwargs.get("healthy_threshold", None)
624     conn = get_conn()
625     __utils__["cloud.fire_event"](
626         "event",
627         "create health_check",
628         "salt/cloud/healthcheck/creating",
629         args={
630             "name": name,
631             "host": host,
632             "path": path,
633             "port": port,
634             "interval": interval,
635             "timeout": timeout,
636             "unhealthy_threshold": unhealthy_threshold,
637             "healthy_threshold": healthy_threshold,
638         },
639         sock_dir=__opts__["sock_dir"],
640         transport=__opts__["transport"],
641     )
642     hc = conn.ex_create_healthcheck(
643         name,
644         host=host,
645         path=path,
646         port=port,
647         interval=interval,
648         timeout=timeout,
649         unhealthy_threshold=unhealthy_threshold,
650         healthy_threshold=healthy_threshold,
651     )
652     __utils__["cloud.fire_event"](
653         "event",
654         "created health_check",
655         "salt/cloud/healthcheck/created",
656         args={
657             "name": name,
658             "host": host,
659             "path": path,
660             "port": port,
661             "interval": interval,
662             "timeout": timeout,
663             "unhealthy_threshold": unhealthy_threshold,
664             "healthy_threshold": healthy_threshold,
665         },
666         sock_dir=__opts__["sock_dir"],
667         transport=__opts__["transport"],
668     )
669     return _expand_item(hc)
670 def delete_hc(kwargs=None, call=None):
671     if call != "function":
672         raise SaltCloudSystemExit(
673             "The delete_hc function must be called with -f or --function."
674         )
675     if not kwargs or "name" not in kwargs:
676         log.error("A name must be specified when deleting a health check.")
677         return False
678     name = kwargs["name"]
679     conn = get_conn()
680     __utils__["cloud.fire_event"](
681         "event",
682         "delete health_check",
683         "salt/cloud/healthcheck/deleting",
684         args={"name": name},
685         sock_dir=__opts__["sock_dir"],
686         transport=__opts__["transport"],
687     )
688     try:
689         result = conn.ex_destroy_healthcheck(conn.ex_get_healthcheck(name))
690     except ResourceNotFoundError as exc:
691         log.error(
692             "Health check %s was not found. Exception was: %s",
693             name,
694             exc,
695             exc_info_on_loglevel=logging.DEBUG,
696         )
697         return False
698     __utils__["cloud.fire_event"](
699         "event",
700         "deleted health_check",
701         "salt/cloud/healthcheck/deleted",
702         args={"name": name},
703         sock_dir=__opts__["sock_dir"],
704         transport=__opts__["transport"],
705     )
706     return result
707 def show_hc(kwargs=None, call=None):
708     if call != "function":
709         raise SaltCloudSystemExit(
710             "The show_hc function must be called with -f or --function."
711         )
712     if not kwargs or "name" not in kwargs:
713         log.error("Must specify name of health check.")
714         return False
715     conn = get_conn()
716     return _expand_item(conn.ex_get_healthcheck(kwargs["name"]))
717 def create_address(kwargs=None, call=None):
718     if call != "function":
719         raise SaltCloudSystemExit(
720             "The create_address function must be called with -f or --function."
721         )
722     if not kwargs or "name" not in kwargs:
723         log.error("A name must be specified when creating an address.")
724         return False
725     if "region" not in kwargs:
726         log.error("A region must be specified for the address.")
727         return False
728     name = kwargs["name"]
729     ex_region = kwargs["region"]
730     ex_address = kwargs.get("address", None)
731     kwargs["region"] = {"name": ex_region.name}
732     conn = get_conn()
733     __utils__["cloud.fire_event"](
734         "event",
735         "create address",
736         "salt/cloud/address/creating",
737         args=salt.utils.data.simple_types_filter(kwargs),
738         sock_dir=__opts__["sock_dir"],
739         transport=__opts__["transport"],
740     )
741     addy = conn.ex_create_address(name, ex_region, ex_address)
742     __utils__["cloud.fire_event"](
743         "event",
744         "created address",
745         "salt/cloud/address/created",
746         args=salt.utils.data.simple_types_filter(kwargs),
747         sock_dir=__opts__["sock_dir"],
748         transport=__opts__["transport"],
749     )
750     log.info("Created GCE Address %s", name)
751     return _expand_address(addy)
752 def delete_address(kwargs=None, call=None):
753     if call != "function":
754         raise SaltCloudSystemExit(
755             "The delete_address function must be called with -f or --function."
756         )
757     if not kwargs or "name" not in kwargs:
758         log.error("A name must be specified when deleting an address.")
759         return False
760     if not kwargs or "region" not in kwargs:
761         log.error("A region must be specified when deleting an address.")
762         return False
763     name = kwargs["name"]
764     ex_region = kwargs["region"]
765     conn = get_conn()
766     __utils__["cloud.fire_event"](
767         "event",
768         "delete address",
769         "salt/cloud/address/deleting",
770         args={"name": name},
771         sock_dir=__opts__["sock_dir"],
772         transport=__opts__["transport"],
773     )
774     try:
775         result = conn.ex_destroy_address(conn.ex_get_address(name, ex_region))
776     except ResourceNotFoundError as exc:
777         log.error(
778             "Address %s in region %s was not found. Exception was: %s",
779             name,
780             ex_region,
781             exc,
782             exc_info_on_loglevel=logging.DEBUG,
783         )
784         return False
785     __utils__["cloud.fire_event"](
786         "event",
787         "deleted address",
788         "salt/cloud/address/deleted",
789         args={"name": name},
790         sock_dir=__opts__["sock_dir"],
791         transport=__opts__["transport"],
792     )
793     log.info("Deleted GCE Address %s", name)
794     return result
795 def show_address(kwargs=None, call=None):
796     if call != "function":
797         raise SaltCloudSystemExit(
798             "The show_snapshot function must be called with -f or --function."
799         )
800     if not kwargs or "name" not in kwargs:
801         log.error("Must specify name.")
802         return False
803     if not kwargs or "region" not in kwargs:
804         log.error("Must specify region.")
805         return False
806     conn = get_conn()
807     return _expand_address(conn.ex_get_address(kwargs["name"], kwargs["region"]))
808 def create_lb(kwargs=None, call=None):
809     if call != "function":
810         raise SaltCloudSystemExit(
811             "The create_lb function must be called with -f or --function."
812         )
813     if not kwargs or "name" not in kwargs:
814         log.error("A name must be specified when creating a health check.")
815         return False
816     if "ports" not in kwargs:
817         log.error("A port or port-range must be specified for the load-balancer.")
818         return False
819     if "region" not in kwargs:
820         log.error("A region must be specified for the load-balancer.")
821         return False
822     if "members" not in kwargs:
823         log.error("A comma-separated list of members must be specified.")
824         return False
825 <a name="1"></a>    name = kwargs["name"]
826     ports = kwargs["ports"]
827     ex_region = kwargs["region"]
828     members = kwargs.get<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>("members").split(",")
829     protocol = kwargs.get("protocol", "tcp")
830     algorithm = kwargs.get("algorithm", None)
831     ex_healthchecks = kwargs.get(</b></font>"healthchecks", None)
832     conn = get_conn()
833     lb_conn = get_lb_conn(conn)
834     ex_address = kwargs.get("address", None)
835     if ex_address is not None:
836         ex_address = __create_orget_address(conn, ex_address, ex_region)
837     if ex_healthchecks:
838         ex_healthchecks = ex_healthchecks.split(",")
839     __utils__["cloud.fire_event"](
840         "event",
841         "create load_balancer",
842         "salt/cloud/loadbalancer/creating",
843         args=kwargs,
844         sock_dir=__opts__["sock_dir"],
845         transport=__opts__["transport"],
846     )
847     lb = lb_conn.create_balancer(
848         name,
849         ports,
850         protocol,
851         algorithm,
852         members,
853         ex_region=ex_region,
854         ex_healthchecks=ex_healthchecks,
855         ex_address=ex_address,
856     )
857     __utils__["cloud.fire_event"](
858         "event",
859         "created load_balancer",
860         "salt/cloud/loadbalancer/created",
861         args=kwargs,
862         sock_dir=__opts__["sock_dir"],
863         transport=__opts__["transport"],
864     )
865     return _expand_balancer(lb)
866 def delete_lb(kwargs=None, call=None):
867     if call != "function":
868         raise SaltCloudSystemExit(
869             "The delete_hc function must be called with -f or --function."
870         )
871     if not kwargs or "name" not in kwargs:
872         log.error("A name must be specified when deleting a health check.")
873         return False
874     name = kwargs["name"]
875     lb_conn = get_lb_conn(get_conn())
876     __utils__["cloud.fire_event"](
877         "event",
878         "delete load_balancer",
879         "salt/cloud/loadbalancer/deleting",
880         args={"name": name},
881         sock_dir=__opts__["sock_dir"],
882         transport=__opts__["transport"],
883     )
884     try:
885         result = lb_conn.destroy_balancer(lb_conn.get_balancer(name))
886     except ResourceNotFoundError as exc:
887         log.error(
888             "Load balancer %s was not found. Exception was: %s",
889             name,
890             exc,
891             exc_info_on_loglevel=logging.DEBUG,
892         )
893         return False
894     __utils__["cloud.fire_event"](
895         "event",
896         "deleted load_balancer",
897         "salt/cloud/loadbalancer/deleted",
898         args={"name": name},
899         sock_dir=__opts__["sock_dir"],
900         transport=__opts__["transport"],
901     )
902     return result
903 def show_lb(kwargs=None, call=None):
904     if call != "function":
905         raise SaltCloudSystemExit(
906             "The show_lb function must be called with -f or --function."
907         )
908     if not kwargs or "name" not in kwargs:
909         log.error("Must specify name of load-balancer.")
910         return False
911     lb_conn = get_lb_conn(get_conn())
912     return _expand_balancer(lb_conn.get_balancer(kwargs["name"]))
913 def attach_lb(kwargs=None, call=None):
914     if call != "function":
915         raise SaltCloudSystemExit(
916             "The attach_lb function must be called with -f or --function."
917         )
918     if not kwargs or "name" not in kwargs:
919         log.error("A load-balancer name must be specified.")
920         return False
921     if "member" not in kwargs:
922         log.error("A node name name must be specified.")
923         return False
924     conn = get_conn()
925     node = conn.ex_get_node(kwargs["member"])
926     lb_conn = get_lb_conn(conn)
927     lb = lb_conn.get_balancer(kwargs["name"])
928     __utils__["cloud.fire_event"](
929         "event",
930         "attach load_balancer",
931         "salt/cloud/loadbalancer/attaching",
932         args=kwargs,
933         sock_dir=__opts__["sock_dir"],
934         transport=__opts__["transport"],
935     )
936     result = lb_conn.balancer_attach_compute_node(lb, node)
937     __utils__["cloud.fire_event"](
938         "event",
939         "attached load_balancer",
940         "salt/cloud/loadbalancer/attached",
941         args=kwargs,
942         sock_dir=__opts__["sock_dir"],
943         transport=__opts__["transport"],
944     )
945     return _expand_item(result)
946 def detach_lb(kwargs=None, call=None):
947     if call != "function":
948         raise SaltCloudSystemExit(
949             "The detach_lb function must be called with -f or --function."
950         )
951     if not kwargs or "name" not in kwargs:
952         log.error("A load-balancer name must be specified.")
953         return False
954     if "member" not in kwargs:
955         log.error("A node name name must be specified.")
956         return False
957     conn = get_conn()
958     lb_conn = get_lb_conn(conn)
959     lb = lb_conn.get_balancer(kwargs["name"])
960     member_list = lb_conn.balancer_list_members(lb)
961     remove_member = None
962     for member in member_list:
963         if member.id == kwargs["member"]:
964             remove_member = member
965             break
966     if not remove_member:
967         log.error(
968             "The specified member %s was not a member of LB %s.",
969             kwargs["member"],
970             kwargs["name"],
971         )
972         return False
973     __utils__["cloud.fire_event"](
974         "event",
975         "detach load_balancer",
976         "salt/cloud/loadbalancer/detaching",
977         args=kwargs,
978         sock_dir=__opts__["sock_dir"],
979         transport=__opts__["transport"],
980     )
981     result = lb_conn.balancer_detach_member(lb, remove_member)
982     __utils__["cloud.fire_event"](
983         "event",
984         "detached load_balancer",
985         "salt/cloud/loadbalancer/detached",
986         args=kwargs,
987         sock_dir=__opts__["sock_dir"],
988         transport=__opts__["transport"],
989     )
990     return result
991 def delete_snapshot(kwargs=None, call=None):
992     if call != "function":
993         raise SaltCloudSystemExit(
994             "The delete_snapshot function must be called with -f or --function."
995         )
996     if not kwargs or "name" not in kwargs:
997         log.error("A name must be specified when deleting a snapshot.")
998         return False
999     name = kwargs["name"]
1000     conn = get_conn()
1001     __utils__["cloud.fire_event"](
1002         "event",
1003         "delete snapshot",
1004         "salt/cloud/snapshot/deleting",
1005         args={"name": name},
1006         sock_dir=__opts__["sock_dir"],
1007         transport=__opts__["transport"],
1008     )
1009     try:
1010         result = conn.destroy_volume_snapshot(conn.ex_get_snapshot(name))
1011     except ResourceNotFoundError as exc:
1012         log.error(
1013             "Snapshot %s was not found. Exception was: %s",
1014             name,
1015             exc,
1016             exc_info_on_loglevel=logging.DEBUG,
1017         )
1018         return False
1019     __utils__["cloud.fire_event"](
1020         "event",
1021         "deleted snapshot",
1022         "salt/cloud/snapshot/deleted",
1023         args={"name": name},
1024         sock_dir=__opts__["sock_dir"],
1025         transport=__opts__["transport"],
1026     )
1027     return result
1028 def delete_disk(kwargs=None, call=None):
1029     if call != "function":
1030         raise SaltCloudSystemExit(
1031             "The delete_disk function must be called with -f or --function."
1032         )
1033     if not kwargs or "disk_name" not in kwargs:
1034         log.error("A disk_name must be specified when deleting a disk.")
1035         return False
1036     conn = get_conn()
1037     disk = conn.ex_get_volume(kwargs.get("disk_name"))
1038     __utils__["cloud.fire_event"](
1039         "event",
1040         "delete disk",
1041         "salt/cloud/disk/deleting",
1042         args={
1043             "name": disk.name,
1044             "location": disk.extra["zone"].name,
1045             "size": disk.size,
1046         },
1047         sock_dir=__opts__["sock_dir"],
1048         transport=__opts__["transport"],
1049     )
1050     try:
1051         result = conn.destroy_volume(disk)
1052     except ResourceInUseError as exc:
1053         log.error(
1054             "Disk %s is in use and must be detached before deleting.\n"
1055             "The following exception was thrown by libcloud:\n%s",
1056             disk.name,
1057             exc,
1058             exc_info_on_loglevel=logging.DEBUG,
1059         )
1060         return False
1061     __utils__["cloud.fire_event"](
1062         "event",
1063         "deleted disk",
1064         "salt/cloud/disk/deleted",
1065         args={
1066             "name": disk.name,
1067             "location": disk.extra["zone"].name,
1068             "size": disk.size,
1069         },
1070         sock_dir=__opts__["sock_dir"],
1071         transport=__opts__["transport"],
1072     )
1073     return result
1074 def create_disk(kwargs=None, call=None):
1075     if call != "function":
1076         raise SaltCloudSystemExit(
1077             "The create_disk function must be called with -f or --function."
1078         )
1079     if kwargs is None:
1080         kwargs = {}
1081     name = kwargs.get("disk_name", None)
1082     image = kwargs.get("image", None)
1083     location = kwargs.get("location", None)
1084     size = kwargs.get("size", None)
1085     snapshot = kwargs.get("snapshot", None)
1086     disk_type = kwargs.get("type", "pd-standard")
1087     if location is None:
1088         log.error("A location (zone) must be specified when creating a disk.")
1089         return False
1090     if name is None:
1091         log.error("A disk_name must be specified when creating a disk.")
1092         return False
1093     if size is None and image is None and snapshot is None:
1094         log.error("Must specify image, snapshot, or size.")
1095         return False
1096     conn = get_conn()
1097     location = conn.ex_get_zone(kwargs["location"])
1098     use_existing = True
1099     __utils__["cloud.fire_event"](
1100         "event",
1101         "create disk",
1102         "salt/cloud/disk/creating",
1103         args={
1104             "name": name,
1105             "location": location.name,
1106             "image": image,
1107             "snapshot": snapshot,
1108         },
1109         sock_dir=__opts__["sock_dir"],
1110         transport=__opts__["transport"],
1111     )
1112     disk = conn.create_volume(
1113         size, name, location, snapshot, image, use_existing, disk_type
1114     )
1115     __utils__["cloud.fire_event"](
1116         "event",
1117         "created disk",
1118         "salt/cloud/disk/created",
1119         args={
1120             "name": name,
1121             "location": location.name,
1122             "image": image,
1123             "snapshot": snapshot,
1124         },
1125         sock_dir=__opts__["sock_dir"],
1126         transport=__opts__["transport"],
1127     )
1128     return _expand_disk(disk)
1129 def create_snapshot(kwargs=None, call=None):
1130     if call != "function":
1131         raise SaltCloudSystemExit(
1132             "The create_snapshot function must be called with -f or --function."
1133         )
1134     if not kwargs or "name" not in kwargs:
1135         log.error("A name must be specified when creating a snapshot.")
1136         return False
1137     if "disk_name" not in kwargs:
1138         log.error("A disk_name must be specified when creating a snapshot.")
1139         return False
1140     conn = get_conn()
1141     name = kwargs.get("name")
1142     disk_name = kwargs.get("disk_name")
1143     try:
1144         disk = conn.ex_get_volume(disk_name)
1145     except ResourceNotFoundError as exc:
1146         log.error(
1147             "Disk %s was not found. Exception was: %s",
1148             disk_name,
1149             exc,
1150             exc_info_on_loglevel=logging.DEBUG,
1151         )
1152         return False
1153     __utils__["cloud.fire_event"](
1154         "event",
1155         "create snapshot",
1156         "salt/cloud/snapshot/creating",
1157         args={"name": name, "disk_name": disk_name},
1158         sock_dir=__opts__["sock_dir"],
1159         transport=__opts__["transport"],
1160     )
1161     snapshot = conn.create_volume_snapshot(disk, name)
1162     __utils__["cloud.fire_event"](
1163         "event",
1164         "created snapshot",
1165         "salt/cloud/snapshot/created",
1166         args={"name": name, "disk_name": disk_name},
1167         sock_dir=__opts__["sock_dir"],
1168         transport=__opts__["transport"],
1169     )
1170     return _expand_item(snapshot)
1171 def show_disk(name=None, kwargs=None, call=None):  # pylint: disable=W0613
1172     if not kwargs or "disk_name" not in kwargs:
1173         log.error("Must specify disk_name.")
1174         return False
1175     conn = get_conn()
1176     return _expand_disk(conn.ex_get_volume(kwargs["disk_name"]))
1177 def show_snapshot(kwargs=None, call=None):
1178     if call != "function":
1179         raise SaltCloudSystemExit(
1180             "The show_snapshot function must be called with -f or --function."
1181         )
1182     if not kwargs or "name" not in kwargs:
1183         log.error("Must specify name.")
1184         return False
1185     conn = get_conn()
1186     return _expand_item(conn.ex_get_snapshot(kwargs["name"]))
1187 def detach_disk(name=None, kwargs=None, call=None):
1188     if call != "action":
1189         raise SaltCloudSystemExit(
1190             "The detach_Disk action must be called with -a or --action."
1191         )
1192     if not name:
1193         log.error("Must specify an instance name.")
1194         return False
1195     if not kwargs or "disk_name" not in kwargs:
1196         log.error("Must specify a disk_name to detach.")
1197         return False
1198     node_name = name
1199     disk_name = kwargs["disk_name"]
1200     conn = get_conn()
1201     node = conn.ex_get_node(node_name)
1202     disk = conn.ex_get_volume(disk_name)
1203     __utils__["cloud.fire_event"](
1204         "event",
1205         "detach disk",
1206         "salt/cloud/disk/detaching",
1207         args={"name": node_name, "disk_name": disk_name},
1208         sock_dir=__opts__["sock_dir"],
1209         transport=__opts__["transport"],
1210     )
1211     result = conn.detach_volume(disk, node)
1212     __utils__["cloud.fire_event"](
1213         "event",
1214         "detached disk",
1215         "salt/cloud/disk/detached",
1216         args={"name": node_name, "disk_name": disk_name},
1217         sock_dir=__opts__["sock_dir"],
1218         transport=__opts__["transport"],
1219     )
1220     return result
1221 def attach_disk(name=None, kwargs=None, call=None):
1222     if call != "action":
1223         raise SaltCloudSystemExit(
1224             "The attach_disk action must be called with -a or --action."
1225         )
1226     if not name:
1227         log.error("Must specify an instance name.")
1228         return False
1229     if not kwargs or "disk_name" not in kwargs:
1230         log.error("Must specify a disk_name to attach.")
1231         return False
1232     node_name = name
1233     disk_name = kwargs["disk_name"]
1234     mode = kwargs.get("mode", "READ_WRITE").upper()
1235     boot = kwargs.get("boot", False)
1236     auto_delete = kwargs.get("auto_delete", False)
1237     if boot and boot.lower() in ["true", "yes", "enabled"]:
1238         boot = True
1239     else:
1240         boot = False
1241     if mode not in ["READ_WRITE", "READ_ONLY"]:
1242         log.error("Mode must be either READ_ONLY or (default) READ_WRITE.")
1243         return False
1244     conn = get_conn()
1245     node = conn.ex_get_node(node_name)
1246     disk = conn.ex_get_volume(disk_name)
1247     __utils__["cloud.fire_event"](
1248         "event",
1249         "attach disk",
1250         "salt/cloud/disk/attaching",
1251         args={"name": node_name, "disk_name": disk_name, "mode": mode, "boot": boot},
1252         sock_dir=__opts__["sock_dir"],
1253         transport=__opts__["transport"],
1254     )
1255     result = conn.attach_volume(
1256         node, disk, ex_mode=mode, ex_boot=boot, ex_auto_delete=auto_delete
1257     )
1258     __utils__["cloud.fire_event"](
1259         "event",
1260         "attached disk",
1261         "salt/cloud/disk/attached",
1262         args={"name": node_name, "disk_name": disk_name, "mode": mode, "boot": boot},
1263         sock_dir=__opts__["sock_dir"],
1264         transport=__opts__["transport"],
1265     )
1266     return result
1267 def reboot(vm_name, call=None):
1268     if call != "action":
1269         raise SaltCloudSystemExit(
1270             "The reboot action must be called with -a or --action."
1271         )
1272     conn = get_conn()
1273     __utils__["cloud.fire_event"](
1274         "event",
1275         "reboot instance",
1276         "salt/cloud/{}/rebooting".format(vm_name),
1277         args={"name": vm_name},
1278         sock_dir=__opts__["sock_dir"],
1279         transport=__opts__["transport"],
1280     )
1281     result = conn.reboot_node(conn.ex_get_node(vm_name))
1282     __utils__["cloud.fire_event"](
1283         "event",
1284         "reboot instance",
1285         "salt/cloud/{}/rebooted".format(vm_name),
1286         args={"name": vm_name},
1287         sock_dir=__opts__["sock_dir"],
1288         transport=__opts__["transport"],
1289     )
1290     return result
1291 def start(vm_name, call=None):
1292     if call != "action":
1293         raise SaltCloudSystemExit(
1294             "The start action must be called with -a or --action."
1295         )
1296     conn = get_conn()
1297     __utils__["cloud.fire_event"](
1298         "event",
1299         "start instance",
1300         "salt/cloud/{}/starting".format(vm_name),
1301         args={"name": vm_name},
1302         sock_dir=__opts__["sock_dir"],
1303         transport=__opts__["transport"],
1304     )
1305     result = conn.ex_start_node(conn.ex_get_node(vm_name))
1306     __utils__["cloud.fire_event"](
1307         "event",
1308         "start instance",
1309         "salt/cloud/{}/started".format(vm_name),
1310         args={"name": vm_name},
1311         sock_dir=__opts__["sock_dir"],
1312         transport=__opts__["transport"],
1313     )
1314     return result
1315 def stop(vm_name, call=None):
1316     if call != "action":
1317         raise SaltCloudSystemExit("The stop action must be called with -a or --action.")
1318     conn = get_conn()
1319     __utils__["cloud.fire_event"](
1320         "event",
1321         "stop instance",
1322         "salt/cloud/{}/stopping".format(vm_name),
1323         args={"name": vm_name},
1324         sock_dir=__opts__["sock_dir"],
1325         transport=__opts__["transport"],
1326     )
1327     result = conn.ex_stop_node(conn.ex_get_node(vm_name))
1328     __utils__["cloud.fire_event"](
1329         "event",
1330         "stop instance",
1331         "salt/cloud/{}/stopped".format(vm_name),
1332         args={"name": vm_name},
1333         sock_dir=__opts__["sock_dir"],
1334         transport=__opts__["transport"],
1335     )
1336     return result
1337 def destroy(vm_name, call=None):
1338     if call and call != "action":
1339         raise SaltCloudSystemExit(
1340             'The destroy action must be called with -d or "-a destroy".'
1341         )
1342     conn = get_conn()
1343     try:
1344         node = conn.ex_get_node(vm_name)
1345     except Exception as exc:  # pylint: disable=W0703
1346         log.error(
1347             "Could not locate instance %s\n\n"
1348             "The following exception was thrown by libcloud when trying to "
1349             "run the initial deployment: \n%s",
1350             vm_name,
1351             exc,
1352             exc_info_on_loglevel=logging.DEBUG,
1353         )
1354         raise SaltCloudSystemExit("Could not find instance {}.".format(vm_name))
1355     __utils__["cloud.fire_event"](
1356         "event",
1357         "delete instance",
1358         "salt/cloud/{}/deleting".format(vm_name),
1359         args={"name": vm_name},
1360         sock_dir=__opts__["sock_dir"],
1361         transport=__opts__["transport"],
1362     )
1363     profile = None
1364     if node.extra["metadata"] and "items" in node.extra["metadata"]:
1365         for md in node.extra["metadata"]["items"]:
1366             if md["key"] == "salt-cloud-profile":
1367                 profile = md["value"]
1368     vm_ = get_configured_provider()
1369     delete_boot_pd = False
1370     if (
1371         profile
1372         and profile in vm_["profiles"]
1373         and "delete_boot_pd" in vm_["profiles"][profile]
1374     ):
1375         delete_boot_pd = vm_["profiles"][profile]["delete_boot_pd"]
1376     try:
1377         inst_deleted = conn.destroy_node(node)
1378     except Exception as exc:  # pylint: disable=W0703
1379         log.error(
1380             "Could not destroy instance %s\n\n"
1381             "The following exception was thrown by libcloud when trying to "
1382             "run the initial deployment: \n%s",
1383             vm_name,
1384             exc,
1385             exc_info_on_loglevel=logging.DEBUG,
1386         )
1387         raise SaltCloudSystemExit("Could not destroy instance {}.".format(vm_name))
1388     __utils__["cloud.fire_event"](
1389         "event",
1390         "delete instance",
1391         "salt/cloud/{}/deleted".format(vm_name),
1392         args={"name": vm_name},
1393         sock_dir=__opts__["sock_dir"],
1394         transport=__opts__["transport"],
1395     )
1396     if delete_boot_pd:
1397         log.info(
1398             "delete_boot_pd is enabled for the instance profile, "
1399             "attempting to delete disk"
1400         )
1401         __utils__["cloud.fire_event"](
1402             "event",
1403             "delete disk",
1404             "salt/cloud/disk/deleting",
1405             args={"name": vm_name},
1406             sock_dir=__opts__["sock_dir"],
1407             transport=__opts__["transport"],
1408         )
1409         try:
1410             conn.destroy_volume(conn.ex_get_volume(vm_name))
1411         except Exception as exc:  # pylint: disable=W0703
1412             log.error(
1413                 "Could not destroy disk %s\n\n"
1414                 "The following exception was thrown by libcloud when trying "
1415                 "to run the initial deployment: \n%s",
1416                 vm_name,
1417                 exc,
1418                 exc_info_on_loglevel=logging.DEBUG,
1419             )
1420         __utils__["cloud.fire_event"](
1421             "event",
1422             "deleted disk",
1423             "salt/cloud/disk/deleted",
1424             args={"name": vm_name},
1425             sock_dir=__opts__["sock_dir"],
1426             transport=__opts__["transport"],
1427         )
1428     if __opts__.get("update_cachedir", False) is True:
1429         __utils__["cloud.delete_minion_cachedir"](
1430             vm_name, _get_active_provider_name().split(":")[0], __opts__
1431         )
1432     return inst_deleted
1433 def create_attach_volumes(name, kwargs, call=None):
1434     if call != "action":
1435         raise SaltCloudSystemExit(
1436             "The create_attach_volumes action must be called with -a or --action."
1437         )
1438     volumes = literal_eval(kwargs["volumes"])
1439     node = kwargs["node"]
1440     conn = get_conn()
1441     node_data = _expand_node(conn.ex_get_node(node))
1442     letter = ord("a") - 1
1443     for idx, volume in enumerate(volumes):
1444         volume_name = "{}-sd{}".format(name, chr(letter + 2 + idx))
1445         volume_dict = {
1446             "disk_name": volume_name,
1447             "location": node_data["extra"]["zone"]["name"],
1448             "size": volume["size"],
1449             "type": volume.get("type", "pd-standard"),
1450             "image": volume.get("image", None),
1451             "snapshot": volume.get("snapshot", None),
1452             "auto_delete": volume.get("auto_delete", False),
1453         }
1454         create_disk(volume_dict, "function")
1455         attach_disk(name, volume_dict, "action")
1456 def request_instance(vm_):
1457     if not GCE_VM_NAME_REGEX.match(vm_["name"]):
1458         raise SaltCloudSystemExit(
1459             "VM names must start with a letter, only contain letters, numbers, or"
1460             " dashes and cannot end in a dash."
1461         )
1462     try:
1463         if (
1464             vm_["profile"]
1465             and config.is_profile_configured(
1466                 __opts__, _get_active_provider_name() or "gce", vm_["profile"], vm_=vm_
1467             )
1468             is False
1469         ):
1470             return False
1471     except AttributeError:
1472         pass
1473     __utils__["cloud.fire_event"](
1474         "event",
1475         "create instance",
1476         "salt/cloud/{}/creating".format(vm_["name"]),
1477         args=__utils__["cloud.filter_event"](
1478             "creating", vm_, ["name", "profile", "provider", "driver"]
1479         ),
1480         sock_dir=__opts__["sock_dir"],
1481         transport=__opts__["transport"],
1482     )
1483     conn = get_conn()
1484     kwargs = {
1485         "name": vm_["name"],
1486         "size": __get_size(conn, vm_),
1487         "image": __get_image(conn, vm_),
1488         "location": __get_location(conn, vm_),
1489         "ex_network": __get_network(conn, vm_),
1490         "ex_subnetwork": __get_subnetwork(vm_),
1491         "ex_tags": __get_tags(vm_),
1492         "ex_metadata": __get_metadata(vm_),
1493     }
1494     external_ip = config.get_cloud_config_value(
1495         "external_ip", vm_, __opts__, default="ephemeral"
1496     )
1497     if external_ip.lower() == "ephemeral":
1498         external_ip = "ephemeral"
1499         vm_["external_ip"] = external_ip
1500     elif external_ip == "None":
1501         external_ip = None
1502         vm_["external_ip"] = external_ip
1503     else:
1504         region = __get_region(conn, vm_)
1505         external_ip = __create_orget_address(conn, external_ip, region)
1506         vm_["external_ip"] = {
1507             "name": external_ip.name,
1508             "address": external_ip.address,
1509             "region": external_ip.region.name,
1510 <a name="0"></a>        }
1511     kwargs["external_ip"] = external_ip
1512     if LIBCLOUD_VERSION_INFO &gt; (<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>0, 15, 1):
1513         kwargs.update(
1514             {
1515                 "ex_disk_type": config.get_cloud_config_value(
1516                     "ex_disk_type", vm_, __opts__, default="pd-standard"
1517                 ),
1518                 "ex_disk_auto_delete": config.get_cloud_config_value(
1519                     "ex_disk_auto_delete", vm_, __opts__, default=True
1520                 ),
1521                 "ex_disks_gce_struct": config.get_cloud_config_value(</b></font>
1522                     "ex_disks_gce_struct", vm_, __opts__, default=None
1523                 ),
1524                 "ex_service_accounts": config.get_cloud_config_value(
1525                     "ex_service_accounts", vm_, __opts__, default=None
1526                 ),
1527                 "ex_can_ip_forward": config.get_cloud_config_value(
1528                     "ip_forwarding", vm_, __opts__, default=False
1529                 ),
1530                 "ex_preemptible": config.get_cloud_config_value(
1531                     "preemptible", vm_, __opts__, default=False
1532                 ),
1533             }
1534         )
1535         if kwargs.get("ex_disk_type") not in ("pd-standard", "pd-ssd"):
1536             raise SaltCloudSystemExit(
1537                 "The value of 'ex_disk_type' needs to be one of: "
1538                 "'pd-standard', 'pd-ssd'"
1539             )
1540     if LIBCLOUD_VERSION_INFO &gt;= (2, 3, 0):
1541         kwargs.update(
1542             {
1543                 "ex_accelerator_type": config.get_cloud_config_value(
1544                     "ex_accelerator_type", vm_, __opts__, default=None
1545                 ),
1546                 "ex_accelerator_count": config.get_cloud_config_value(
1547                     "ex_accelerator_count", vm_, __opts__, default=None
1548                 ),
1549             }
1550         )
1551         if kwargs.get("ex_accelerator_type"):
1552             log.warning(
1553                 "An accelerator is being attached to this instance, "
1554                 "the ex_on_host_maintenance setting is being set to "
1555                 "'TERMINATE' as a result"
1556             )
1557             kwargs.update({"ex_on_host_maintenance": "TERMINATE"})
1558     log.info("Creating GCE instance %s in %s", vm_["name"], kwargs["location"].name)
1559     log.debug("Create instance kwargs %s", kwargs)
1560     __utils__["cloud.fire_event"](
1561         "event",
1562         "requesting instance",
1563         "salt/cloud/{}/requesting".format(vm_["name"]),
1564         args=__utils__["cloud.filter_event"](
1565             "requesting", vm_, ["name", "profile", "provider", "driver"]
1566         ),
1567         sock_dir=__opts__["sock_dir"],
1568         transport=__opts__["transport"],
1569     )
1570     try:
1571         node_data = conn.create_node(**kwargs)
1572     except Exception as exc:  # pylint: disable=W0703
1573         log.error(
1574             "Error creating %s on GCE\n\n"
1575             "The following exception was thrown by libcloud when trying to "
1576             "run the initial deployment: \n%s",
1577             vm_["name"],
1578             exc,
1579             exc_info_on_loglevel=logging.DEBUG,
1580         )
1581         return False
1582     volumes = config.get_cloud_config_value(
1583         "volumes", vm_, __opts__, search_global=True
1584     )
1585     if volumes:
1586         __utils__["cloud.fire_event"](
1587             "event",
1588             "attaching volumes",
1589             "salt/cloud/{}/attaching_volumes".format(vm_["name"]),
1590             args={"volumes": volumes},
1591             sock_dir=__opts__["sock_dir"],
1592             transport=__opts__["transport"],
1593         )
1594         log.info("Create and attach volumes to node %s", vm_["name"])
1595         create_attach_volumes(
1596             vm_["name"], {"volumes": volumes, "node": node_data}, call="action"
1597         )
1598     try:
1599         node_dict = show_instance(node_data["name"], "action")
1600     except TypeError:
1601         node_dict = show_instance(node_data.name, "action")
1602     return node_dict, node_data
1603 def create(vm_=None, call=None):
1604     if call:
1605         raise SaltCloudSystemExit("You cannot create an instance with -a or -f.")
1606     node_info = request_instance(vm_)
1607     if isinstance(node_info, bool):
1608         raise SaltCloudSystemExit("There was an error creating the GCE instance.")
1609     node_dict = node_info[0]
1610     node_data = node_info[1]
1611     ssh_user, ssh_key = __get_ssh_credentials(vm_)
1612     vm_["ssh_host"] = __get_host(node_data, vm_)
1613     vm_["key_filename"] = ssh_key
1614     ret = __utils__["cloud.bootstrap"](vm_, __opts__)
1615     ret.update(node_dict)
1616     log.info("Created Cloud VM '%s'", vm_["name"])
1617     log.trace("'%s' VM creation details:\n%s", vm_["name"], pprint.pformat(node_dict))
1618     __utils__["cloud.fire_event"](
1619         "event",
1620         "created instance",
1621         "salt/cloud/{}/created".format(vm_["name"]),
1622         args=__utils__["cloud.filter_event"](
1623             "created", vm_, ["name", "profile", "provider", "driver"]
1624         ),
1625         sock_dir=__opts__["sock_dir"],
1626         transport=__opts__["transport"],
1627     )
1628     return ret
1629 def update_pricing(kwargs=None, call=None):
1630     url = "https://cloudpricingcalculator.appspot.com/static/data/pricelist.json"
1631     price_json = salt.utils.http.query(url, decode=True, decode_type="json")
1632     outfile = os.path.join(__opts__["cachedir"], "gce-pricing.p")
1633     with salt.utils.files.fopen(outfile, "w") as fho:
1634         salt.utils.msgpack.dump(price_json["dict"], fho)
1635     return True
1636 def show_pricing(kwargs=None, call=None):
1637     profile = __opts__["profiles"].get(kwargs["profile"], {})
1638     if not profile:
1639         return {"Error": "The requested profile was not found"}
1640     provider = profile.get("provider", "0:0")
1641     comps = provider.split(":")
1642     if len(comps) &lt; 2 or comps[1] != "gce":
1643         return {"Error": "The requested profile does not belong to GCE"}
1644     comps = profile.get("location", "us").split("-")
1645     region = comps[0]
1646     size = "CP-COMPUTEENGINE-VMIMAGE-{}".format(profile["size"].upper())
1647     pricefile = os.path.join(__opts__["cachedir"], "gce-pricing.p")
1648     if not os.path.exists(pricefile):
1649         update_pricing()
1650     with salt.utils.files.fopen(pricefile, "r") as fho:
1651         sizes = salt.utils.msgpack.load(fho)
1652     per_hour = float(sizes["gcp_price_list"][size][region])
1653     week1_discount = float(sizes["gcp_price_list"]["sustained_use_tiers"]["0.25"])
1654     week2_discount = float(sizes["gcp_price_list"]["sustained_use_tiers"]["0.50"])
1655     week3_discount = float(sizes["gcp_price_list"]["sustained_use_tiers"]["0.75"])
1656     week4_discount = float(sizes["gcp_price_list"]["sustained_use_tiers"]["1.0"])
1657     week1 = per_hour * (730 / 4) * week1_discount
1658     week2 = per_hour * (730 / 4) * week2_discount
1659     week3 = per_hour * (730 / 4) * week3_discount
1660     week4 = per_hour * (730 / 4) * week4_discount
1661     raw = sizes
1662     ret = {}
1663     ret["per_hour"] = per_hour
1664     ret["per_day"] = ret["per_hour"] * 24
1665     ret["per_week"] = ret["per_day"] * 7
1666     ret["per_month"] = week1 + week2 + week3 + week4
1667     ret["per_year"] = ret["per_month"] * 12
1668     if kwargs.get("raw", False):
1669         ret["_raw"] = raw
1670     return {profile["profile"]: ret}
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
