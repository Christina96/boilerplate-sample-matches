<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for test_hgfs.py &amp; gce.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for test_hgfs.py &amp; gce.py
      </h3>
<h1 align="center">
        1.3%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>test_hgfs.py (2.8503563%)<th>gce.py (0.89053804%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(295-299)<td><a href="#" name="0">(2352-2362)</a><td align="center"><font color="#ff0000">12</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(50-53)<td><a href="#" name="1">(1332-1336)</a><td align="center"><font color="#ff0000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_hgfs.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import shutil
2 import tempfile
3 from pathlib import Path
4 import psutil  # pylint: disable=3rd-party-module-not-gated
5 import pytest
6 import salt.config
7 import salt.fileserver.hgfs as hgfs
8 from saltfactories.utils.processes import terminate_process
9 from tests.support.mock import patch
10 try:
11     import hglib
12     HAS_HG = True
13 except ImportError:
14     HAS_HG = False
15 @pytest.fixture(scope="module")
16 def configure_loader_modules():
17     opts = salt.config.DEFAULT_MASTER_OPTS.copy()
18     cache = tempfile.TemporaryDirectory(dir="/tmp")
19     opts["cachedir"] = cache.name
20     opts["fileserver_backend"] = ["hgfs"]
21     yield {hgfs: {"__opts__": opts}}
22     cache.cleanup()
23 @pytest.fixture
24 def hgfs_setup_and_teardown():
25     initial_child_processes = psutil.Process().children()
26     source_dir = Path(__file__).resolve().parent.joinpath("files")
27     tempdir = tempfile.TemporaryDirectory()
28     tempsubdir = tempdir.name / Path("subdir/")
29     tempsubdir.mkdir()
30     tempdirPath = Path(tempdir.name)
31     for file in source_dir.iterdir():
32         to_file = tempdirPath / file.name
33         to_file2 = tempsubdir / file.name
34         shutil.copy(file.as_posix(), to_file.as_posix())
35         shutil.copy(file.as_posix(), to_file2.as_posix())
36     client.close()
37     with hglib.open(bytes(tempdirPath.as_posix(), encoding="utf8")) as repo:
38         repo.add(bytes<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(tempdirPath.as_posix(), encoding="utf8"))
39         repo.commit(b"init commit", user="test")
40         repo.tag(b"test", user="test")
41         repo.branch(</b></font>b"test")
42         repo.commit(b"create test branch", user="test")
43         repo.bookmark(b"bookmark_test")
44     try:
45         yield tempdirPath.as_uri()
46     finally:
47         tempdir.cleanup()
48         for child in psutil.Process().children():
49             if child not in initial_child_processes:
50                 terminate_process(process=child, kill_children=True)
51 @pytest.mark.slow_test
52 @pytest.mark.skip_on_windows(reason="testing break in windows")
53 def test_fix_58852(hgfs_setup_and_teardown):
54     with patch.dict(
55         hgfs.__opts__,
56         {
57             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
58         },
59     ):
60         repo = hgfs.init()
61         assert isinstance(repo, list)
62         if isinstance(repo, list):
63             for value in repo:
64                 assert isinstance(value, dict)
65                 for key, value in value.items():
66                     if key != "repo":
67                         assert isinstance(value, str)
68 @pytest.mark.slow_test
69 @pytest.mark.skip_on_windows(reason="testing break in windows")
70 def test_all_branches(hgfs_setup_and_teardown):
71     with patch.dict(
72         hgfs.__opts__,
73         {
74             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
75         },
76     ):
77         repos = hgfs.init()
78         hgfs.update()
79         for repo in repos:
80             repo["repo"].open()
81             branches = hgfs._all_branches(repo["repo"])
82             assert isinstance(branches, list)
83             if isinstance(branches, list):
84                 for value in branches:
85                     assert isinstance(value, tuple)
86                     assert len(value) == 3
87                     assert value[0] in ["default", "test"]
88                     assert isinstance(value[1], int)
89                     assert isinstance(value[2], str)
90 @pytest.mark.slow_test
91 @pytest.mark.skip_on_windows(reason="testing break in windows")
92 def test_get_branch(hgfs_setup_and_teardown):
93     with patch.dict(
94         hgfs.__opts__,
95         {
96             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
97         },
98     ):
99         repo = hgfs.init()
100         hgfs.update()
101         repo[0]["repo"].open()
102         branch = hgfs._get_branch(repo[0]["repo"], "test")
103         assert isinstance(branch, tuple)
104         assert len(branch) == 3
105         assert branch[0] in "test"
106         assert branch[1] == 2
107         assert isinstance(branch[2], str)
108         branch = hgfs._get_branch(repo[0]["repo"], "fake")
109         assert branch is False
110 @pytest.mark.slow_test
111 @pytest.mark.skip_on_windows(reason="testing break in windows")
112 def test_all_bookmarks(hgfs_setup_and_teardown):
113     with patch.dict(
114         hgfs.__opts__,
115         {
116             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
117         },
118     ):
119         repos = hgfs.init()
120         hgfs.update()
121         for repo in repos:
122             repo["repo"].open()
123             bookmarks = hgfs._all_bookmarks(repo["repo"])
124             assert isinstance(bookmarks, list)
125             if isinstance(bookmarks, list):
126                 for value in bookmarks:
127                     assert isinstance(value, tuple)
128                     assert len(value) == 3
129                     assert value[0] in ["bookmark_test"]
130                     assert value[1] == 2
131                     assert isinstance(value[2], str)
132 @pytest.mark.slow_test
133 @pytest.mark.skip_on_windows(reason="testing break in windows")
134 def test_get_bookmark(hgfs_setup_and_teardown):
135     with patch.dict(
136         hgfs.__opts__,
137         {
138             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
139         },
140     ):
141         repo = hgfs.init()
142         hgfs.update()
143         repo[0]["repo"].open()
144         bookmark = hgfs._get_bookmark(repo[0]["repo"], "bookmark_test")
145         assert isinstance(bookmark, tuple)
146         assert len(bookmark) == 3
147         assert bookmark[0] in "bookmark_test"
148         assert bookmark[1] == 2
149         assert isinstance(bookmark[2], str)
150         bookmark = hgfs._get_bookmark(repo[0]["repo"], "fake")
151         assert bookmark is False
152 @pytest.mark.slow_test
153 @pytest.mark.skip_on_windows(reason="testing break in windows")
154 def test_all_tags(hgfs_setup_and_teardown):
155     with patch.dict(
156         hgfs.__opts__,
157         {
158             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
159         },
160     ):
161         repos = hgfs.init()
162         hgfs.update()
163         for repo in repos:
164             repo["repo"].open()
165             tags = hgfs._all_tags(repo["repo"])
166             assert isinstance(tags, list)
167             if isinstance(tags, list):
168                 for value in tags:
169                     assert isinstance(value, tuple)
170                     assert len(value) == 4
171                     assert value[0] in ["test"]
172                     assert value[0] not in ["tip"]
173                     assert value[1] == 0
174                     assert isinstance(value[2], str)
175                     assert value[3] is False
176 @pytest.mark.slow_test
177 @pytest.mark.skip_on_windows(reason="testing break in windows")
178 def test_get_tag(hgfs_setup_and_teardown):
179     with patch.dict(
180         hgfs.__opts__,
181         {
182             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
183         },
184     ):
185         repo = hgfs.init()
186         hgfs.update()
187         repo[0]["repo"].open()
188         tag = hgfs._get_tag(repo[0]["repo"], "test")
189         assert isinstance(tag, tuple)
190         assert len(tag) == 4
191         assert tag[0] in "test"
192         assert tag[1] == 0
193         assert isinstance(tag[2], str)
194         tag = hgfs._get_tag(repo[0]["repo"], "fake")
195         assert tag is False
196         tag = hgfs._get_tag(repo[0]["repo"], "tip")
197         assert tag is False
198 @pytest.mark.slow_test
199 @pytest.mark.skip_on_windows(reason="testing break in windows")
200 def test_get_ref(hgfs_setup_and_teardown):
201     with patch.dict(
202         hgfs.__opts__,
203         {
204             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
205         },
206     ):
207         repo = hgfs.init()[0]
208         hgfs.update()
209         repo["repo"].open()
210         ref = hgfs._get_ref(repo, "base")
211         assert isinstance(ref, tuple)
212         assert len(ref) == 3
213         assert ref[0] == "default"
214         assert ref[1] == 1
215         assert isinstance(ref[2], str)
216     with patch.dict(
217         hgfs.__opts__,
218         {
219             "hgfs_remotes": [
220                 {str(hgfs_setup_and_teardown): [{"base": "bookmark_test"}]}
221             ],
222             "hgfs_branch_method": "bookmarks",
223         },
224     ):
225         repo = hgfs.init()[0]
226         hgfs.update()
227         repo["repo"].open()
228         ref = hgfs._get_ref(repo, "base")
229         assert isinstance(ref, tuple)
230         assert len(ref) == 3
231         assert ref[0] in "bookmark_test"
232         assert ref[1] == 2
233         assert isinstance(ref[2], str)
234     with patch.dict(
235         hgfs.__opts__,
236         {
237             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
238         },
239     ):
240         repo = hgfs.init()[0]
241         hgfs.update()
242         repo["repo"].open()
243         ref = hgfs._get_ref(repo, "fake")
244         assert ref is False
245 @pytest.mark.slow_test
246 @pytest.mark.skip_on_windows(reason="testing break in windows")
247 def test_get_manifest(hgfs_setup_and_teardown):
248     with patch.dict(
249         hgfs.__opts__,
250         {
251         },
252     ):
253         repo = hgfs.init()<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>[0]
254         hgfs.update()
255         repo["repo"].open()
256         ref = hgfs._get_ref(repo, "base")
257         manifest = hgfs._get_manifest(</b></font>repo["repo"], ref=ref)
258         assert isinstance(manifest, list)
259         for value in manifest:
260             assert len(value) == 5
261             assert isinstance(value[0], str)
262             assert value[1] == "644"
263             assert value[2] is False
264             assert value[3] is False
265             assert value[4] in [
266                 "test.sls",
267                 "test2.sls",
268                 ".hgtags",
269                 "subdir/test.sls",
270                 "subdir/test2.sls",
271             ]
272 @pytest.mark.slow_test
273 @pytest.mark.skip_on_windows(reason="testing break in windows")
274 def test_envs(hgfs_setup_and_teardown):
275     with patch.dict(
276         hgfs.__opts__,
277         {
278             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
279             "hgfs_branch_method": "branches",
280         },
281     ):
282         hgfs.init()
283         hgfs.update()
284         envs = hgfs.envs(ignore_cache=True)
285         assert isinstance(envs, list)
286         assert envs == ["base", "test"]
287     with patch.dict(
288         hgfs.__opts__,
289         {
290             "hgfs_remotes": [
291                 {str(hgfs_setup_and_teardown): [{"base": "bookmark_test"}]}
292             ],
293             "hgfs_branch_method": "bookmarks",
294         },
295     ):
296         hgfs.init()
297         hgfs.update()
298         envs = hgfs.envs(ignore_cache=True)
299         assert isinstance(envs, list)
300         assert envs == ["base", "test"]
301 @pytest.mark.skip_on_windows(reason="testing break in windows")
302 def test_env_is_exposed_blacklist():
303     with patch.dict(
304         hgfs.__opts__,
305         {"hgfs_saltenv_whitelist": "", "hgfs_saltenv_blacklist": "test"},
306     ):
307         hgfs.init()
308         hgfs.update()
309         assert hgfs._env_is_exposed("base") is True
310         assert hgfs._env_is_exposed("test") is False
311         assert hgfs._env_is_exposed("unset") is True
312 @pytest.mark.skip_on_windows(reason="testing break in windows")
313 def test_env_is_exposed_whitelist():
314     with patch.dict(
315         hgfs.__opts__,
316         {"hgfs_saltenv_whitelist": "base", "hgfs_saltenv_blacklist": ""},
317     ):
318         hgfs.init()
319         hgfs.update()
320         assert hgfs._env_is_exposed("base") is True
321         assert hgfs._env_is_exposed("test") is False
322         assert hgfs._env_is_exposed("unset") is False
323 @pytest.mark.slow_test
324 @pytest.mark.skip_on_windows(reason="testing break in windows")
325 def test_find_file(hgfs_setup_and_teardown):
326     with patch.dict(
327         hgfs.__opts__,
328         {
329             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
330         },
331     ):
332         hgfs.init()
333         hgfs.update()
334         file = hgfs.find_file(path="test.sls", tgt_env="base")
335         assert file["path"] == hgfs.__opts__["cachedir"] + "/hgfs/refs/base/test.sls"
336         assert file["rel"] == "test.sls"
337         assert isinstance(file["stat"], list)
338         for i in file["stat"]:
339             assert isinstance(i, int)
340 @pytest.mark.slow_test
341 @pytest.mark.skip_on_windows(reason="testing break in windows")
342 def test_serve_file(hgfs_setup_and_teardown):
343     with patch.dict(
344         hgfs.__opts__,
345         {
346             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
347         },
348     ):
349         hgfs.init()
350         hgfs.update()
351         file = hgfs.find_file(path="test.sls", tgt_env="base")
352         load = {"saltenv": "base", "loc": 0, "path": "test.sls"}
353         data = hgfs.serve_file(load, file)
354         assert data == {
355             "data": "always-passes:\n  test.succeed_without_changes:\n    - name: foo\n",
356             "dest": "test.sls",
357         }
358 @pytest.mark.slow_test
359 @pytest.mark.skip_on_windows(reason="testing break in windows")
360 def test_file_hash(hgfs_setup_and_teardown):
361     with patch.dict(
362         hgfs.__opts__,
363         {
364             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
365         },
366     ):
367         hgfs.init()
368         hgfs.update()
369         file = hgfs.find_file(path="test.sls", tgt_env="base")
370         load = {"saltenv": "base", "loc": 0, "path": "test.sls"}
371         data = hgfs.file_hash(load, file)
372         assert data == {
373             "hash_type": "sha256",
374             "hsum": "a6a48d90dce9c9b580efb2ed308af100a8328913dcf9441705125866551c7d8d",
375         }
376 @pytest.mark.slow_test
377 @pytest.mark.skip_on_windows(reason="testing break in windows")
378 def test_file_list(hgfs_setup_and_teardown):
379     with patch.dict(
380         hgfs.__opts__,
381         {
382             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
383         },
384     ):
385         hgfs.init()
386         hgfs.update()
387         load = {"saltenv": "base", "loc": 0, "path": "test.sls"}
388         data = hgfs.file_list(load)
389         assert data == [
390             ".hgtags",
391             "subdir/test.sls",
392             "subdir/test2.sls",
393             "test.sls",
394             "test2.sls",
395         ]
396 @pytest.mark.slow_test
397 @pytest.mark.skip_on_windows(reason="testing break in windows")
398 def test_dir_list(hgfs_setup_and_teardown):
399     with patch.dict(
400         hgfs.__opts__,
401         {
402             "hgfs_remotes": [{str(hgfs_setup_and_teardown): [{"base": "default"}]}],
403         },
404     ):
405         hgfs.init()
406         hgfs.update()
407         load = {"saltenv": "base", "loc": 0, "path": "test.sls"}
408         data = hgfs.dir_list(load)
409         assert data == ["subdir"]
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>gce.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 import logging
2 import os
3 import pprint
4 import re
5 import sys
6 from ast import literal_eval
7 import salt.config as config
8 import salt.utils.cloud
9 import salt.utils.files
10 import salt.utils.http
11 import salt.utils.msgpack
12 from salt.cloud.libcloudfuncs import *  # pylint: disable=redefined-builtin,wildcard-import,unused-wildcard-import
13 from salt.exceptions import SaltCloudSystemExit
14 from salt.utils.functools import namespaced_function
15 from salt.utils.versions import LooseVersion as _LooseVersion
16 LIBCLOUD_IMPORT_ERROR = None
17 try:
18     import libcloud
19     from libcloud.compute.types import Provider
20     from libcloud.compute.providers import get_driver
21     from libcloud.loadbalancer.types import Provider as Provider_lb
22     from libcloud.loadbalancer.providers import get_driver as get_driver_lb
23     from libcloud.common.google import (
24         ResourceInUseError,
25         ResourceNotFoundError,
26     )
27     HAS_LIBCLOUD = True
28 except ImportError:
29     LIBCLOUD_IMPORT_ERROR = sys.exc_info()
30     HAS_LIBCLOUD = False
31 log = logging.getLogger(__name__)
32 __virtualname__ = "gce"
33 _UA_PRODUCT = "salt-cloud"
34 _UA_VERSION = "0.2.0"
35 avail_locations = namespaced_function(avail_locations, globals())
36 script = namespaced_function(script, globals())
37 destroy = namespaced_function(destroy, globals())
38 list_nodes = namespaced_function(list_nodes, globals())
39 list_nodes_full = namespaced_function(list_nodes_full, globals())
40 list_nodes_select = namespaced_function(list_nodes_select, globals())
41 GCE_VM_NAME_REGEX = re.compile(r"^(?:[a-z](?:[-a-z0-9]{0,61}[a-z0-9])?)$")
42 def __virtual__():
43     if not HAS_LIBCLOUD:
44         return False, "apache-libcloud is not installed"
45     if _LooseVersion(libcloud.__version__) &lt; _LooseVersion("2.5.0"):
46         return False, "The salt-cloud GCE driver requires apache-libcloud&gt;=2.5.0"
47     if get_configured_provider() is False:
48         return False
49     if get_dependencies() is False:
50         return False
51     for provider, details in __opts__["providers"].items():
52         if "gce" not in details:
53             continue
54         parameters = details["gce"]
55         pathname = os.path.expanduser(parameters["service_account_private_key"])
56         if (
57             pathname
58             and salt.utils.cloud.check_key_path_and_mode(provider, pathname) is False
59         ):
60             return False
61     return __virtualname__
62 def _get_active_provider_name():
63     try:
64         return __active_provider_name__.value()
65     except AttributeError:
66         return __active_provider_name__
67 def get_configured_provider():
68     return config.is_provider_configured(
69         __opts__,
70         _get_active_provider_name() or "gce",
71         ("project", "service_account_email_address", "service_account_private_key"),
72     )
73 def get_dependencies():
74     if LIBCLOUD_IMPORT_ERROR:
75         log.error("Failure when importing LibCloud: ", exc_info=LIBCLOUD_IMPORT_ERROR)
76         log.error(
77             "Note: The libcloud dependency is called 'apache-libcloud' on PyPi/pip."
78         )
79     return config.check_driver_dependencies(__virtualname__, {"libcloud": HAS_LIBCLOUD})
80 def get_lb_conn(gce_driver=None):
81     if not gce_driver:
82         raise SaltCloudSystemExit("Missing gce_driver for get_lb_conn method.")
83     return get_driver_lb(Provider_lb.GCE)(gce_driver=gce_driver)
84 def get_conn():
85     driver = get_driver(Provider.GCE)
86     provider = get_configured_provider()
87     project = config.get_cloud_config_value("project", provider, __opts__)
88     email = config.get_cloud_config_value(
89         "service_account_email_address", provider, __opts__
90     )
91     private_key = config.get_cloud_config_value(
92         "service_account_private_key", provider, __opts__
93     )
94     gce = driver(email, private_key, project=project)
95     gce.connection.user_agent_append("{}/{}".format(_UA_PRODUCT, _UA_VERSION))
96     return gce
97 def _expand_item(item):
98     ret = {}
99     ret.update(item.__dict__)
100     return ret
101 def _expand_node(node):
102     ret = {}
103     ret.update(node.__dict__)
104     try:
105         del ret["extra"]["boot_disk"]
106     except Exception:  # pylint: disable=W0703
107         pass
108     zone = ret["extra"]["zone"]
109     ret["extra"]["zone"] = {}
110     ret["extra"]["zone"].update(zone.__dict__)
111     if "driver" in ret:
112         del ret["driver"]
113     if "driver" in ret["extra"]["zone"]:
114         del ret["extra"]["zone"]["driver"]
115     return ret
116 def _expand_disk(disk):
117     ret = {}
118     ret.update(disk.__dict__)
119     zone = ret["extra"]["zone"]
120     ret["extra"]["zone"] = {}
121     ret["extra"]["zone"].update(zone.__dict__)
122     return ret
123 def _expand_address(addy):
124     ret = {}
125     ret.update(addy.__dict__)
126     ret["extra"]["zone"] = addy.region.name
127     return ret
128 def _expand_balancer(lb):
129     ret = {}
130     ret.update(lb.__dict__)
131     hc = ret["extra"]["healthchecks"]
132     ret["extra"]["healthchecks"] = []
133     for item in hc:
134         ret["extra"]["healthchecks"].append(_expand_item(item))
135     fwr = ret["extra"]["forwarding_rule"]
136     tp = ret["extra"]["forwarding_rule"].targetpool
137     reg = ret["extra"]["forwarding_rule"].region
138     ret["extra"]["forwarding_rule"] = {}
139     ret["extra"]["forwarding_rule"].update(fwr.__dict__)
140     ret["extra"]["forwarding_rule"]["targetpool"] = tp.name
141     ret["extra"]["forwarding_rule"]["region"] = reg.name
142     tp = ret["extra"]["targetpool"]
143     hc = ret["extra"]["targetpool"].healthchecks
144     nodes = ret["extra"]["targetpool"].nodes
145     region = ret["extra"]["targetpool"].region
146     zones = ret["extra"]["targetpool"].region.zones
147     ret["extra"]["targetpool"] = {}
148     ret["extra"]["targetpool"].update(tp.__dict__)
149     ret["extra"]["targetpool"]["region"] = _expand_item(region)
150     ret["extra"]["targetpool"]["nodes"] = []
151     for n in nodes:
152         ret["extra"]["targetpool"]["nodes"].append(_expand_node(n))
153     ret["extra"]["targetpool"]["healthchecks"] = []
154     for hci in hc:
155         ret["extra"]["targetpool"]["healthchecks"].append(hci.name)
156     ret["extra"]["targetpool"]["region"]["zones"] = []
157     for z in zones:
158         ret["extra"]["targetpool"]["region"]["zones"].append(z.name)
159     return ret
160 def show_instance(vm_name, call=None):
161     if call != "action":
162         raise SaltCloudSystemExit(
163             "The show_instance action must be called with -a or --action."
164         )
165     conn = get_conn()
166     node = _expand_node(conn.ex_get_node(vm_name))
167     __utils__["cloud.cache_node"](node, _get_active_provider_name(), __opts__)
168     return node
169 def avail_sizes(conn=None):
170     if not conn:
171         conn = get_conn()
172     raw_sizes = conn.list_sizes("all")  # get *all* the machine types!
173     sizes = []
174     for size in raw_sizes:
175         zone = size.extra["zone"]
176         size.extra["zone"] = {}
177         size.extra["zone"].update(zone.__dict__)
178         mtype = {}
179         mtype.update(size.__dict__)
180         sizes.append(mtype)
181     return sizes
182 def avail_images(conn=None):
183     if not conn:
184         conn = get_conn()
185     all_images = []
186     public_image_projects = (
187         "centos-cloud",
188         "coreos-cloud",
189         "debian-cloud",
190         "google-containers",
191         "opensuse-cloud",
192         "rhel-cloud",
193         "suse-cloud",
194         "ubuntu-os-cloud",
195         "windows-cloud",
196     )
197     for project in public_image_projects:
198         all_images.extend(conn.list_images(project))
199     all_images.extend(conn.list_images())
200     ret = {}
201     for img in all_images:
202         ret[img.name] = {}
203         for attr in dir(img):
204             if attr.startswith("_"):
205                 continue
206             ret[img.name][attr] = getattr(img, attr)
207     return ret
208 def __get_image(conn, vm_):
209     img = config.get_cloud_config_value(
210         "image", vm_, __opts__, default="debian-7", search_global=False
211     )
212     return conn.ex_get_image(img)
213 def __get_location(conn, vm_):
214     location = config.get_cloud_config_value("location", vm_, __opts__)
215     return conn.ex_get_zone(location)
216 def __get_size(conn, vm_):
217     size = config.get_cloud_config_value(
218         "size", vm_, __opts__, default="n1-standard-1", search_global=False
219     )
220     return conn.ex_get_size(size, __get_location(conn, vm_))
221 def __get_tags(vm_):
222     t = config.get_cloud_config_value(
223         "tags", vm_, __opts__, default="[]", search_global=False
224     )
225     try:
226         tags = literal_eval(t)
227     except Exception:  # pylint: disable=W0703
228         tags = None
229     if not tags or not isinstance(tags, list):
230         tags = None
231     return tags
232 def __get_metadata(vm_):
233     md = config.get_cloud_config_value(
234         "metadata", vm_, __opts__, default="{}", search_global=False
235     )
236     try:
237         metadata = literal_eval(md)
238     except Exception:  # pylint: disable=W0703
239         metadata = None
240     if not metadata or not isinstance(metadata, dict):
241         metadata = {"items": [{"key": "salt-cloud-profile", "value": vm_["profile"]}]}
242     else:
243         metadata["salt-cloud-profile"] = vm_["profile"]
244         items = []
245         for k, v in metadata.items():
246             items.append({"key": k, "value": v})
247         metadata = {"items": items}
248     return metadata
249 def __get_host(node, vm_):
250     if __get_ssh_interface(vm_) == "private_ips" or vm_["external_ip"] is None:
251         ip_address = node.private_ips[0]
252         log.info("Salt node data. Private_ip: %s", ip_address)
253     else:
254         ip_address = node.public_ips[0]
255         log.info("Salt node data. Public_ip: %s", ip_address)
256     if ip_address:
257         return ip_address
258     return node.name
259 def __get_network(conn, vm_):
260     network = config.get_cloud_config_value(
261         "network", vm_, __opts__, default="default", search_global=False
262     )
263     return conn.ex_get_network(network)
264 def __get_subnetwork(vm_):
265     ex_subnetwork = config.get_cloud_config_value(
266         "subnetwork", vm_, __opts__, search_global=False
267     )
268     return ex_subnetwork
269 def __get_region(conn, vm_):
270     location = __get_location(conn, vm_)
271     region = "-".join(location.name.split("-")[:2])
272     return conn.ex_get_region(region)
273 def __get_ssh_interface(vm_):
274     return config.get_cloud_config_value(
275         "ssh_interface", vm_, __opts__, default="public_ips", search_global=False
276     )
277 def __create_orget_address(conn, name, region):
278     try:
279         addy = conn.ex_get_address(name, region)
280     except ResourceNotFoundError:  # pylint: disable=W0703
281         addr_kwargs = {"name": name, "region": region}
282         new_addy = create_address(addr_kwargs, "function")
283         addy = conn.ex_get_address(new_addy["name"], new_addy["region"])
284     return addy
285 def _parse_allow(allow):
286     seen_protos = {}
287     allow_dict = []
288     protocols = allow.split(",")
289     for p in protocols:
290         pairs = p.split(":")
291         if pairs[0].lower() not in ["tcp", "udp", "icmp"]:
292             raise SaltCloudSystemExit(
293                 "Unsupported protocol {}. Must be tcp, udp, or icmp.".format(pairs[0])
294             )
295         if len(pairs) == 1 or pairs[0].lower() == "icmp":
296             seen_protos[pairs[0]] = []
297         else:
298             if pairs[0] not in seen_protos:
299                 seen_protos[pairs[0]] = [pairs[1]]
300             else:
301                 seen_protos[pairs[0]].append(pairs[1])
302     for k in seen_protos:
303         d = {"IPProtocol": k}
304         if seen_protos[k]:
305             d["ports"] = seen_protos[k]
306         allow_dict.append(d)
307     log.debug("firewall allowed protocols/ports: %s", allow_dict)
308     return allow_dict
309 def __get_ssh_credentials(vm_):
310     ssh_user = config.get_cloud_config_value(
311         "ssh_username", vm_, __opts__, default=os.getenv("USER")
312     )
313     ssh_key = config.get_cloud_config_value(
314         "ssh_keyfile",
315         vm_,
316         __opts__,
317         default=os.path.expanduser("~/.ssh/google_compute_engine"),
318     )
319     return ssh_user, ssh_key
320 def create_network(kwargs=None, call=None):
321     if call != "function":
322         raise SaltCloudSystemExit(
323             "The create_network function must be called with -f or --function."
324         )
325     if not kwargs or "name" not in kwargs:
326         log.error("A name must be specified when creating a network.")
327         return False
328     mode = kwargs.get("mode", "legacy")
329     cidr = kwargs.get("cidr", None)
330     if cidr is None and mode == "legacy":
331         log.error(
332             "A network CIDR range must be specified when creating a legacy network."
333         )
334         return False
335     name = kwargs["name"]
336     desc = kwargs.get("description", None)
337     conn = get_conn()
338     __utils__["cloud.fire_event"](
339         "event",
340         "creating network",
341         "salt/cloud/net/creating",
342         args={"name": name, "cidr": cidr, "description": desc, "mode": mode},
343         sock_dir=__opts__["sock_dir"],
344         transport=__opts__["transport"],
345     )
346     network = conn.ex_create_network(name, cidr, desc, mode)
347     __utils__["cloud.fire_event"](
348         "event",
349         "created network",
350         "salt/cloud/net/created",
351         args={"name": name, "cidr": cidr, "description": desc, "mode": mode},
352         sock_dir=__opts__["sock_dir"],
353         transport=__opts__["transport"],
354     )
355     return _expand_item(network)
356 def delete_network(kwargs=None, call=None):
357     if call != "function":
358         raise SaltCloudSystemExit(
359             "The delete_network function must be called with -f or --function."
360         )
361     if not kwargs or "name" not in kwargs:
362         log.error("A name must be specified when deleting a network.")
363         return False
364     name = kwargs["name"]
365     conn = get_conn()
366     __utils__["cloud.fire_event"](
367         "event",
368         "deleting network",
369         "salt/cloud/net/deleting",
370         args={"name": name},
371         sock_dir=__opts__["sock_dir"],
372         transport=__opts__["transport"],
373     )
374     try:
375         result = conn.ex_destroy_network(conn.ex_get_network(name))
376     except ResourceNotFoundError as exc:
377         log.error(
378             "Nework %s was not found. Exception was: %s",
379             name,
380             exc,
381             exc_info_on_loglevel=logging.DEBUG,
382         )
383         return False
384     __utils__["cloud.fire_event"](
385         "event",
386         "deleted network",
387         "salt/cloud/net/deleted",
388         args={"name": name},
389         sock_dir=__opts__["sock_dir"],
390         transport=__opts__["transport"],
391     )
392     return result
393 def show_network(kwargs=None, call=None):
394     if call != "function":
395         raise SaltCloudSystemExit(
396             "The show_network function must be called with -f or --function."
397         )
398     if not kwargs or "name" not in kwargs:
399         log.error("Must specify name of network.")
400         return False
401     conn = get_conn()
402     return _expand_item(conn.ex_get_network(kwargs["name"]))
403 def create_subnetwork(kwargs=None, call=None):
404     if call != "function":
405         raise SaltCloudSystemExit(
406             "The create_subnetwork function must be called with -f or --function."
407         )
408     if not kwargs or "name" not in kwargs:
409         log.error("Must specify name of subnet.")
410         return False
411     if "network" not in kwargs:
412         log.errror("Must specify name of network to create subnet under.")
413         return False
414     if "cidr" not in kwargs:
415         log.errror("A network CIDR range must be specified when creating a subnet.")
416         return False
417     if "region" not in kwargs:
418         log.error("A region must be specified when creating a subnetwork.")
419         return False
420     name = kwargs["name"]
421     cidr = kwargs["cidr"]
422     network = kwargs["network"]
423     region = kwargs["region"]
424     desc = kwargs.get("description", None)
425     conn = get_conn()
426     __utils__["cloud.fire_event"](
427         "event",
428         "create subnetwork",
429         "salt/cloud/subnet/creating",
430         args={
431             "name": name,
432             "network": network,
433             "cidr": cidr,
434             "region": region,
435             "description": desc,
436         },
437         sock_dir=__opts__["sock_dir"],
438         transport=__opts__["transport"],
439     )
440     subnet = conn.ex_create_subnetwork(name, cidr, network, region, desc)
441     __utils__["cloud.fire_event"](
442         "event",
443         "created subnetwork",
444         "salt/cloud/subnet/created",
445         args={
446             "name": name,
447             "network": network,
448             "cidr": cidr,
449             "region": region,
450             "description": desc,
451         },
452         sock_dir=__opts__["sock_dir"],
453         transport=__opts__["transport"],
454     )
455     return _expand_item(subnet)
456 def delete_subnetwork(kwargs=None, call=None):
457     if call != "function":
458         raise SaltCloudSystemExit(
459             "The delete_subnet function must be called with -f or --function."
460         )
461     if not kwargs or "name" not in kwargs:
462         log.error("Must specify name of subnet.")
463         return False
464     if "region" not in kwargs:
465         log.error("Must specify region of subnet.")
466         return False
467     name = kwargs["name"]
468     region = kwargs["region"]
469     conn = get_conn()
470     __utils__["cloud.fire_event"](
471         "event",
472         "deleting subnetwork",
473         "salt/cloud/subnet/deleting",
474         args={"name": name, "region": region},
475         sock_dir=__opts__["sock_dir"],
476         transport=__opts__["transport"],
477     )
478     try:
479         result = conn.ex_destroy_subnetwork(name, region)
480     except ResourceNotFoundError as exc:
481         log.error(
482             "Subnetwork %s was not found. Exception was: %s",
483             name,
484             exc,
485             exc_info_on_loglevel=logging.DEBUG,
486         )
487         return False
488     __utils__["cloud.fire_event"](
489         "event",
490         "deleted subnetwork",
491         "salt/cloud/subnet/deleted",
492         args={"name": name, "region": region},
493         sock_dir=__opts__["sock_dir"],
494         transport=__opts__["transport"],
495     )
496     return result
497 def show_subnetwork(kwargs=None, call=None):
498     if call != "function":
499         raise SaltCloudSystemExit(
500             "The show_subnetwork function must be called with -f or --function."
501         )
502     if not kwargs or "name" not in kwargs:
503         log.error("Must specify name of subnet.")
504         return False
505     if "region" not in kwargs:
506         log.error("Must specify region of subnet.")
507         return False
508     name = kwargs["name"]
509     region = kwargs["region"]
510     conn = get_conn()
511     return _expand_item(conn.ex_get_subnetwork(name, region))
512 def create_fwrule(kwargs=None, call=None):
513     if call != "function":
514         raise SaltCloudSystemExit(
515             "The create_fwrule function must be called with -f or --function."
516         )
517     if not kwargs or "name" not in kwargs:
518         log.error("A name must be specified when creating a firewall rule.")
519         return False
520     if "allow" not in kwargs:
521         log.error('Must use "allow" to specify allowed protocols/ports.')
522         return False
523     name = kwargs["name"]
524     network_name = kwargs.get("network", "default")
525     allow = _parse_allow(kwargs["allow"])
526     src_range = kwargs.get("src_range", "0.0.0.0/0")
527     src_tags = kwargs.get("src_tags", None)
528     dst_tags = kwargs.get("dst_tags", None)
529     if src_range:
530         src_range = src_range.split(",")
531     if src_tags:
532         src_tags = src_tags.split(",")
533     if dst_tags:
534         dst_tags = dst_tags.split(",")
535     conn = get_conn()
536     __utils__["cloud.fire_event"](
537         "event",
538         "create firewall",
539         "salt/cloud/firewall/creating",
540         args={"name": name, "network": network_name, "allow": kwargs["allow"]},
541         sock_dir=__opts__["sock_dir"],
542         transport=__opts__["transport"],
543     )
544     fwrule = conn.ex_create_firewall(
545         name,
546         allow,
547         network=network_name,
548         source_ranges=src_range,
549         source_tags=src_tags,
550         target_tags=dst_tags,
551     )
552     __utils__["cloud.fire_event"](
553         "event",
554         "created firewall",
555         "salt/cloud/firewall/created",
556         args={"name": name, "network": network_name, "allow": kwargs["allow"]},
557         sock_dir=__opts__["sock_dir"],
558         transport=__opts__["transport"],
559     )
560     return _expand_item(fwrule)
561 def delete_fwrule(kwargs=None, call=None):
562     if call != "function":
563         raise SaltCloudSystemExit(
564             "The delete_fwrule function must be called with -f or --function."
565         )
566     if not kwargs or "name" not in kwargs:
567         log.error("A name must be specified when deleting a firewall rule.")
568         return False
569     name = kwargs["name"]
570     conn = get_conn()
571     __utils__["cloud.fire_event"](
572         "event",
573         "delete firewall",
574         "salt/cloud/firewall/deleting",
575         args={"name": name},
576         sock_dir=__opts__["sock_dir"],
577         transport=__opts__["transport"],
578     )
579     try:
580         result = conn.ex_destroy_firewall(conn.ex_get_firewall(name))
581     except ResourceNotFoundError as exc:
582         log.error(
583             "Rule %s was not found. Exception was: %s",
584             name,
585             exc,
586             exc_info_on_loglevel=logging.DEBUG,
587         )
588         return False
589     __utils__["cloud.fire_event"](
590         "event",
591         "deleted firewall",
592         "salt/cloud/firewall/deleted",
593         args={"name": name},
594         sock_dir=__opts__["sock_dir"],
595         transport=__opts__["transport"],
596     )
597     return result
598 def show_fwrule(kwargs=None, call=None):
599     if call != "function":
600         raise SaltCloudSystemExit(
601             "The show_fwrule function must be called with -f or --function."
602         )
603     if not kwargs or "name" not in kwargs:
604         log.error("Must specify name of network.")
605         return False
606     conn = get_conn()
607     return _expand_item(conn.ex_get_firewall(kwargs["name"]))
608 def create_hc(kwargs=None, call=None):
609     if call != "function":
610         raise SaltCloudSystemExit(
611             "The create_hc function must be called with -f or --function."
612         )
613     if not kwargs or "name" not in kwargs:
614         log.error("A name must be specified when creating a health check.")
615         return False
616     name = kwargs["name"]
617     host = kwargs.get("host", None)
618     path = kwargs.get("path", None)
619     port = kwargs.get("port", None)
620     interval = kwargs.get("interval", None)
621     timeout = kwargs.get("timeout", None)
622     unhealthy_threshold = kwargs.get("unhealthy_threshold", None)
623     healthy_threshold = kwargs.get("healthy_threshold", None)
624     conn = get_conn()
625     __utils__["cloud.fire_event"](
626         "event",
627         "create health_check",
628         "salt/cloud/healthcheck/creating",
629         args={
630             "name": name,
631             "host": host,
632             "path": path,
633             "port": port,
634             "interval": interval,
635             "timeout": timeout,
636             "unhealthy_threshold": unhealthy_threshold,
637             "healthy_threshold": healthy_threshold,
638         },
639         sock_dir=__opts__["sock_dir"],
640         transport=__opts__["transport"],
641     )
642     hc = conn.ex_create_healthcheck(
643         name,
644         host=host,
645         path=path,
646         port=port,
647         interval=interval,
648         timeout=timeout,
649         unhealthy_threshold=unhealthy_threshold,
650         healthy_threshold=healthy_threshold,
651     )
652     __utils__["cloud.fire_event"](
653         "event",
654         "created health_check",
655         "salt/cloud/healthcheck/created",
656         args={
657             "name": name,
658             "host": host,
659             "path": path,
660             "port": port,
661             "interval": interval,
662             "timeout": timeout,
663             "unhealthy_threshold": unhealthy_threshold,
664             "healthy_threshold": healthy_threshold,
665         },
666         sock_dir=__opts__["sock_dir"],
667         transport=__opts__["transport"],
668     )
669     return _expand_item(hc)
670 def delete_hc(kwargs=None, call=None):
671     if call != "function":
672         raise SaltCloudSystemExit(
673             "The delete_hc function must be called with -f or --function."
674         )
675     if not kwargs or "name" not in kwargs:
676         log.error("A name must be specified when deleting a health check.")
677         return False
678     name = kwargs["name"]
679     conn = get_conn()
680     __utils__["cloud.fire_event"](
681         "event",
682         "delete health_check",
683         "salt/cloud/healthcheck/deleting",
684         args={"name": name},
685         sock_dir=__opts__["sock_dir"],
686         transport=__opts__["transport"],
687     )
688     try:
689         result = conn.ex_destroy_healthcheck(conn.ex_get_healthcheck(name))
690     except ResourceNotFoundError as exc:
691         log.error(
692             "Health check %s was not found. Exception was: %s",
693             name,
694             exc,
695             exc_info_on_loglevel=logging.DEBUG,
696         )
697         return False
698     __utils__["cloud.fire_event"](
699         "event",
700         "deleted health_check",
701         "salt/cloud/healthcheck/deleted",
702         args={"name": name},
703         sock_dir=__opts__["sock_dir"],
704         transport=__opts__["transport"],
705     )
706     return result
707 def show_hc(kwargs=None, call=None):
708     if call != "function":
709         raise SaltCloudSystemExit(
710             "The show_hc function must be called with -f or --function."
711         )
712     if not kwargs or "name" not in kwargs:
713         log.error("Must specify name of health check.")
714         return False
715     conn = get_conn()
716     return _expand_item(conn.ex_get_healthcheck(kwargs["name"]))
717 def create_address(kwargs=None, call=None):
718     if call != "function":
719         raise SaltCloudSystemExit(
720             "The create_address function must be called with -f or --function."
721         )
722     if not kwargs or "name" not in kwargs:
723         log.error("A name must be specified when creating an address.")
724         return False
725     if "region" not in kwargs:
726         log.error("A region must be specified for the address.")
727         return False
728     name = kwargs["name"]
729     ex_region = kwargs["region"]
730     ex_address = kwargs.get("address", None)
731     kwargs["region"] = {"name": ex_region.name}
732     conn = get_conn()
733     __utils__["cloud.fire_event"](
734         "event",
735         "create address",
736         "salt/cloud/address/creating",
737         args=salt.utils.data.simple_types_filter(kwargs),
738         sock_dir=__opts__["sock_dir"],
739         transport=__opts__["transport"],
740     )
741     addy = conn.ex_create_address(name, ex_region, ex_address)
742     __utils__["cloud.fire_event"](
743         "event",
744         "created address",
745         "salt/cloud/address/created",
746         args=salt.utils.data.simple_types_filter(kwargs),
747         sock_dir=__opts__["sock_dir"],
748         transport=__opts__["transport"],
749     )
750     log.info("Created GCE Address %s", name)
751     return _expand_address(addy)
752 def delete_address(kwargs=None, call=None):
753     if call != "function":
754         raise SaltCloudSystemExit(
755             "The delete_address function must be called with -f or --function."
756         )
757     if not kwargs or "name" not in kwargs:
758         log.error("A name must be specified when deleting an address.")
759         return False
760     if not kwargs or "region" not in kwargs:
761         log.error("A region must be specified when deleting an address.")
762         return False
763     name = kwargs["name"]
764     ex_region = kwargs["region"]
765     conn = get_conn()
766     __utils__["cloud.fire_event"](
767         "event",
768         "delete address",
769         "salt/cloud/address/deleting",
770         args={"name": name},
771         sock_dir=__opts__["sock_dir"],
772         transport=__opts__["transport"],
773     )
774     try:
775         result = conn.ex_destroy_address(conn.ex_get_address(name, ex_region))
776     except ResourceNotFoundError as exc:
777         log.error(
778             "Address %s in region %s was not found. Exception was: %s",
779             name,
780             ex_region,
781             exc,
782             exc_info_on_loglevel=logging.DEBUG,
783         )
784         return False
785     __utils__["cloud.fire_event"](
786         "event",
787         "deleted address",
788         "salt/cloud/address/deleted",
789         args={"name": name},
790         sock_dir=__opts__["sock_dir"],
791         transport=__opts__["transport"],
792     )
793     log.info("Deleted GCE Address %s", name)
794     return result
795 def show_address(kwargs=None, call=None):
796     if call != "function":
797         raise SaltCloudSystemExit(
798             "The show_snapshot function must be called with -f or --function."
799         )
800     if not kwargs or "name" not in kwargs:
801         log.error("Must specify name.")
802         return False
803     if not kwargs or "region" not in kwargs:
804         log.error("Must specify region.")
805         return False
806     conn = get_conn()
807     return _expand_address(conn.ex_get_address(kwargs["name"], kwargs["region"]))
808 def create_lb(kwargs=None, call=None):
809     if call != "function":
810         raise SaltCloudSystemExit(
811             "The create_lb function must be called with -f or --function."
812         )
813     if not kwargs or "name" not in kwargs:
814         log.error("A name must be specified when creating a health check.")
815         return False
816     if "ports" not in kwargs:
817         log.error("A port or port-range must be specified for the load-balancer.")
818         return False
819     if "region" not in kwargs:
820         log.error("A region must be specified for the load-balancer.")
821         return False
822     if "members" not in kwargs:
823         log.error("A comma-separated list of members must be specified.")
824         return False
825     ports = kwargs["ports"]
826     ex_region = kwargs["region"]
827     members = kwargs.get<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>("members").split(",")
828     protocol = kwargs.get("protocol", "tcp")
829     algorithm = kwargs.get("algorithm", None)
830     ex_healthchecks = kwargs.get(</b></font>"healthchecks", None)
831     conn = get_conn()
832     lb_conn = get_lb_conn(conn)
833     ex_address = kwargs.get("address", None)
834     if ex_address is not None:
835         ex_address = __create_orget_address(conn, ex_address, ex_region)
836     if ex_healthchecks:
837         ex_healthchecks = ex_healthchecks.split(",")
838     __utils__["cloud.fire_event"](
839         "event",
840         "create load_balancer",
841         "salt/cloud/loadbalancer/creating",
842         args=kwargs,
843         sock_dir=__opts__["sock_dir"],
844         transport=__opts__["transport"],
845     )
846     lb = lb_conn.create_balancer(
847         name,
848         ports,
849         protocol,
850         algorithm,
851         members,
852         ex_region=ex_region,
853         ex_healthchecks=ex_healthchecks,
854         ex_address=ex_address,
855     )
856     __utils__["cloud.fire_event"](
857         "event",
858         "created load_balancer",
859         "salt/cloud/loadbalancer/created",
860         args=kwargs,
861         sock_dir=__opts__["sock_dir"],
862         transport=__opts__["transport"],
863     )
864     return _expand_balancer(lb)
865 def delete_lb(kwargs=None, call=None):
866     if call != "function":
867         raise SaltCloudSystemExit(
868             "The delete_hc function must be called with -f or --function."
869         )
870     if not kwargs or "name" not in kwargs:
871         log.error("A name must be specified when deleting a health check.")
872         return False
873     name = kwargs["name"]
874     lb_conn = get_lb_conn(get_conn())
875     __utils__["cloud.fire_event"](
876         "event",
877         "delete load_balancer",
878         "salt/cloud/loadbalancer/deleting",
879         args={"name": name},
880         sock_dir=__opts__["sock_dir"],
881         transport=__opts__["transport"],
882     )
883     try:
884         result = lb_conn.destroy_balancer(lb_conn.get_balancer(name))
885     except ResourceNotFoundError as exc:
886         log.error(
887             "Load balancer %s was not found. Exception was: %s",
888             name,
889             exc,
890             exc_info_on_loglevel=logging.DEBUG,
891         )
892         return False
893     __utils__["cloud.fire_event"](
894         "event",
895         "deleted load_balancer",
896         "salt/cloud/loadbalancer/deleted",
897         args={"name": name},
898         sock_dir=__opts__["sock_dir"],
899         transport=__opts__["transport"],
900     )
901     return result
902 def show_lb(kwargs=None, call=None):
903     if call != "function":
904         raise SaltCloudSystemExit(
905             "The show_lb function must be called with -f or --function."
906         )
907     if not kwargs or "name" not in kwargs:
908         log.error("Must specify name of load-balancer.")
909         return False
910     lb_conn = get_lb_conn(get_conn())
911     return _expand_balancer(lb_conn.get_balancer(kwargs["name"]))
912 def attach_lb(kwargs=None, call=None):
913     if call != "function":
914         raise SaltCloudSystemExit(
915             "The attach_lb function must be called with -f or --function."
916         )
917     if not kwargs or "name" not in kwargs:
918         log.error("A load-balancer name must be specified.")
919         return False
920     if "member" not in kwargs:
921         log.error("A node name name must be specified.")
922         return False
923     conn = get_conn()
924     node = conn.ex_get_node(kwargs["member"])
925     lb_conn = get_lb_conn(conn)
926     lb = lb_conn.get_balancer(kwargs["name"])
927     __utils__["cloud.fire_event"](
928         "event",
929         "attach load_balancer",
930         "salt/cloud/loadbalancer/attaching",
931         args=kwargs,
932         sock_dir=__opts__["sock_dir"],
933         transport=__opts__["transport"],
934     )
935     result = lb_conn.balancer_attach_compute_node(lb, node)
936     __utils__["cloud.fire_event"](
937         "event",
938         "attached load_balancer",
939         "salt/cloud/loadbalancer/attached",
940         args=kwargs,
941         sock_dir=__opts__["sock_dir"],
942         transport=__opts__["transport"],
943     )
944     return _expand_item(result)
945 def detach_lb(kwargs=None, call=None):
946     if call != "function":
947         raise SaltCloudSystemExit(
948             "The detach_lb function must be called with -f or --function."
949         )
950     if not kwargs or "name" not in kwargs:
951         log.error("A load-balancer name must be specified.")
952         return False
953     if "member" not in kwargs:
954         log.error("A node name name must be specified.")
955         return False
956     conn = get_conn()
957     lb_conn = get_lb_conn(conn)
958     lb = lb_conn.get_balancer(kwargs["name"])
959     member_list = lb_conn.balancer_list_members(lb)
960     remove_member = None
961     for member in member_list:
962         if member.id == kwargs["member"]:
963             remove_member = member
964             break
965     if not remove_member:
966         log.error(
967             "The specified member %s was not a member of LB %s.",
968             kwargs["member"],
969             kwargs["name"],
970         )
971         return False
972     __utils__["cloud.fire_event"](
973         "event",
974         "detach load_balancer",
975         "salt/cloud/loadbalancer/detaching",
976         args=kwargs,
977         sock_dir=__opts__["sock_dir"],
978         transport=__opts__["transport"],
979     )
980     result = lb_conn.balancer_detach_member(lb, remove_member)
981     __utils__["cloud.fire_event"](
982         "event",
983         "detached load_balancer",
984         "salt/cloud/loadbalancer/detached",
985         args=kwargs,
986         sock_dir=__opts__["sock_dir"],
987         transport=__opts__["transport"],
988     )
989     return result
990 def delete_snapshot(kwargs=None, call=None):
991     if call != "function":
992         raise SaltCloudSystemExit(
993             "The delete_snapshot function must be called with -f or --function."
994         )
995     if not kwargs or "name" not in kwargs:
996         log.error("A name must be specified when deleting a snapshot.")
997         return False
998     name = kwargs["name"]
999     conn = get_conn()
1000     __utils__["cloud.fire_event"](
1001         "event",
1002         "delete snapshot",
1003         "salt/cloud/snapshot/deleting",
1004         args={"name": name},
1005         sock_dir=__opts__["sock_dir"],
1006         transport=__opts__["transport"],
1007     )
1008     try:
1009         result = conn.destroy_volume_snapshot(conn.ex_get_snapshot(name))
1010     except ResourceNotFoundError as exc:
1011         log.error(
1012             "Snapshot %s was not found. Exception was: %s",
1013             name,
1014             exc,
1015             exc_info_on_loglevel=logging.DEBUG,
1016         )
1017         return False
1018     __utils__["cloud.fire_event"](
1019         "event",
1020         "deleted snapshot",
1021         "salt/cloud/snapshot/deleted",
1022         args={"name": name},
1023         sock_dir=__opts__["sock_dir"],
1024         transport=__opts__["transport"],
1025     )
1026     return result
1027 def delete_disk(kwargs=None, call=None):
1028     if call != "function":
1029         raise SaltCloudSystemExit(
1030             "The delete_disk function must be called with -f or --function."
1031         )
1032     if not kwargs or "disk_name" not in kwargs:
1033         log.error("A disk_name must be specified when deleting a disk.")
1034         return False
1035     conn = get_conn()
1036     disk = conn.ex_get_volume(kwargs.get("disk_name"))
1037     __utils__["cloud.fire_event"](
1038         "event",
1039         "delete disk",
1040         "salt/cloud/disk/deleting",
1041         args={
1042             "name": disk.name,
1043             "location": disk.extra["zone"].name,
1044             "size": disk.size,
1045         },
1046         sock_dir=__opts__["sock_dir"],
1047         transport=__opts__["transport"],
1048     )
1049     try:
1050         result = conn.destroy_volume(disk)
1051     except ResourceInUseError as exc:
1052         log.error(
1053             "Disk %s is in use and must be detached before deleting.\n"
1054             "The following exception was thrown by libcloud:\n%s",
1055             disk.name,
1056             exc,
1057             exc_info_on_loglevel=logging.DEBUG,
1058         )
1059         return False
1060     __utils__["cloud.fire_event"](
1061         "event",
1062         "deleted disk",
1063         "salt/cloud/disk/deleted",
1064         args={
1065             "name": disk.name,
1066             "location": disk.extra["zone"].name,
1067             "size": disk.size,
1068         },
1069         sock_dir=__opts__["sock_dir"],
1070         transport=__opts__["transport"],
1071     )
1072     return result
1073 def create_disk(kwargs=None, call=None):
1074     if call != "function":
1075         raise SaltCloudSystemExit(
1076             "The create_disk function must be called with -f or --function."
1077         )
1078     if kwargs is None:
1079         kwargs = {}
1080     name = kwargs.get("disk_name", None)
1081     image = kwargs.get("image", None)
1082     location = kwargs.get("location", None)
1083     size = kwargs.get("size", None)
1084     snapshot = kwargs.get("snapshot", None)
1085     disk_type = kwargs.get("type", "pd-standard")
1086     if location is None:
1087         log.error("A location (zone) must be specified when creating a disk.")
1088         return False
1089     if name is None:
1090         log.error("A disk_name must be specified when creating a disk.")
1091         return False
1092     if size is None and image is None and snapshot is None:
1093         log.error("Must specify image, snapshot, or size.")
1094         return False
1095     conn = get_conn()
1096     location = conn.ex_get_zone(kwargs["location"])
1097     use_existing = True
1098     __utils__["cloud.fire_event"](
1099         "event",
1100         "create disk",
1101         "salt/cloud/disk/creating",
1102         args={
1103             "name": name,
1104             "location": location.name,
1105             "image": image,
1106             "snapshot": snapshot,
1107         },
1108         sock_dir=__opts__["sock_dir"],
1109         transport=__opts__["transport"],
1110     )
1111     disk = conn.create_volume(
1112         size, name, location, snapshot, image, use_existing, disk_type
1113     )
1114     __utils__["cloud.fire_event"](
1115         "event",
1116         "created disk",
1117         "salt/cloud/disk/created",
1118         args={
1119             "name": name,
1120             "location": location.name,
1121             "image": image,
1122             "snapshot": snapshot,
1123         },
1124         sock_dir=__opts__["sock_dir"],
1125         transport=__opts__["transport"],
1126     )
1127     return _expand_disk(disk)
1128 def create_snapshot(kwargs=None, call=None):
1129     if call != "function":
1130         raise SaltCloudSystemExit(
1131             "The create_snapshot function must be called with -f or --function."
1132         )
1133     if not kwargs or "name" not in kwargs:
1134         log.error("A name must be specified when creating a snapshot.")
1135         return False
1136     if "disk_name" not in kwargs:
1137         log.error("A disk_name must be specified when creating a snapshot.")
1138         return False
1139     conn = get_conn()
1140     name = kwargs.get("name")
1141     disk_name = kwargs.get("disk_name")
1142     try:
1143         disk = conn.ex_get_volume(disk_name)
1144     except ResourceNotFoundError as exc:
1145         log.error(
1146             "Disk %s was not found. Exception was: %s",
1147             disk_name,
1148             exc,
1149             exc_info_on_loglevel=logging.DEBUG,
1150         )
1151         return False
1152     __utils__["cloud.fire_event"](
1153         "event",
1154         "create snapshot",
1155         "salt/cloud/snapshot/creating",
1156         args={"name": name, "disk_name": disk_name},
1157         sock_dir=__opts__["sock_dir"],
1158         transport=__opts__["transport"],
1159     )
1160     snapshot = conn.create_volume_snapshot(disk, name)
1161     __utils__["cloud.fire_event"](
1162         "event",
1163         "created snapshot",
1164         "salt/cloud/snapshot/created",
1165         args={"name": name, "disk_name": disk_name},
1166         sock_dir=__opts__["sock_dir"],
1167         transport=__opts__["transport"],
1168     )
1169     return _expand_item(snapshot)
1170 def show_disk(name=None, kwargs=None, call=None):  # pylint: disable=W0613
1171     if not kwargs or "disk_name" not in kwargs:
1172         log.error("Must specify disk_name.")
1173         return False
1174     conn = get_conn()
1175     return _expand_disk(conn.ex_get_volume(kwargs["disk_name"]))
1176 def show_snapshot(kwargs=None, call=None):
1177     if call != "function":
1178         raise SaltCloudSystemExit(
1179             "The show_snapshot function must be called with -f or --function."
1180         )
1181     if not kwargs or "name" not in kwargs:
1182         log.error("Must specify name.")
1183         return False
1184     conn = get_conn()
1185     return _expand_item(conn.ex_get_snapshot(kwargs["name"]))
1186 def detach_disk(name=None, kwargs=None, call=None):
1187     if call != "action":
1188         raise SaltCloudSystemExit(
1189             "The detach_Disk action must be called with -a or --action."
1190         )
1191     if not name:
1192         log.error("Must specify an instance name.")
1193         return False
1194     if not kwargs or "disk_name" not in kwargs:
1195         log.error("Must specify a disk_name to detach.")
1196         return False
1197     node_name = name
1198     disk_name = kwargs["disk_name"]
1199     conn = get_conn()
1200     node = conn.ex_get_node(node_name)
1201     disk = conn.ex_get_volume(disk_name)
1202     __utils__["cloud.fire_event"](
1203         "event",
1204         "detach disk",
1205         "salt/cloud/disk/detaching",
1206         args={"name": node_name, "disk_name": disk_name},
1207         sock_dir=__opts__["sock_dir"],
1208         transport=__opts__["transport"],
1209     )
1210     result = conn.detach_volume(disk, node)
1211     __utils__["cloud.fire_event"](
1212         "event",
1213         "detached disk",
1214         "salt/cloud/disk/detached",
1215         args={"name": node_name, "disk_name": disk_name},
1216         sock_dir=__opts__["sock_dir"],
1217         transport=__opts__["transport"],
1218     )
1219     return result
1220 def attach_disk(name=None, kwargs=None, call=None):
1221     if call != "action":
1222         raise SaltCloudSystemExit(
1223             "The attach_disk action must be called with -a or --action."
1224         )
1225     if not name:
1226         log.error("Must specify an instance name.")
1227         return False
1228     if not kwargs or "disk_name" not in kwargs:
1229         log.error("Must specify a disk_name to attach.")
1230         return False
1231     node_name = name
1232     disk_name = kwargs["disk_name"]
1233     mode = kwargs.get("mode", "READ_WRITE").upper()
1234     boot = kwargs.get("boot", False)
1235     auto_delete = kwargs.get("auto_delete", False)
1236     if boot and boot.lower() in ["true", "yes", "enabled"]:
1237         boot = True
1238     else:
1239         boot = False
1240     if mode not in ["READ_WRITE", "READ_ONLY"]:
1241         log.error("Mode must be either READ_ONLY or (default) READ_WRITE.")
1242         return False
1243     conn = get_conn()
1244     node = conn.ex_get_node(node_name)
1245     disk = conn.ex_get_volume(disk_name)
1246     __utils__["cloud.fire_event"](
1247         "event",
1248         "attach disk",
1249         "salt/cloud/disk/attaching",
1250         args={"name": node_name, "disk_name": disk_name, "mode": mode, "boot": boot},
1251         sock_dir=__opts__["sock_dir"],
1252         transport=__opts__["transport"],
1253     )
1254     result = conn.attach_volume(
1255         node, disk, ex_mode=mode, ex_boot=boot, ex_auto_delete=auto_delete
1256     )
1257     __utils__["cloud.fire_event"](
1258         "event",
1259         "attached disk",
1260         "salt/cloud/disk/attached",
1261         args={"name": node_name, "disk_name": disk_name, "mode": mode, "boot": boot},
1262         sock_dir=__opts__["sock_dir"],
1263         transport=__opts__["transport"],
1264     )
1265     return result
1266 def reboot(vm_name, call=None):
1267     if call != "action":
1268         raise SaltCloudSystemExit(
1269             "The reboot action must be called with -a or --action."
1270         )
1271     conn = get_conn()
1272     __utils__["cloud.fire_event"](
1273         "event",
1274         "reboot instance",
1275         "salt/cloud/{}/rebooting".format(vm_name),
1276         args={"name": vm_name},
1277         sock_dir=__opts__["sock_dir"],
1278         transport=__opts__["transport"],
1279     )
1280     result = conn.reboot_node(conn.ex_get_node(vm_name))
1281     __utils__["cloud.fire_event"](
1282         "event",
1283         "reboot instance",
1284         "salt/cloud/{}/rebooted".format(vm_name),
1285         args={"name": vm_name},
1286         sock_dir=__opts__["sock_dir"],
1287         transport=__opts__["transport"],
1288     )
1289     return result
1290 def start(vm_name, call=None):
1291     if call != "action":
1292         raise SaltCloudSystemExit(
1293             "The start action must be called with -a or --action."
1294         )
1295     conn = get_conn()
1296     __utils__["cloud.fire_event"](
1297         "event",
1298         "start instance",
1299         "salt/cloud/{}/starting".format(vm_name),
1300         args={"name": vm_name},
1301         sock_dir=__opts__["sock_dir"],
1302         transport=__opts__["transport"],
1303     )
1304     result = conn.ex_start_node(conn.ex_get_node(vm_name))
1305     __utils__["cloud.fire_event"](
1306         "event",
1307         "start instance",
1308         "salt/cloud/{}/started".format(vm_name),
1309         args={"name": vm_name},
1310         sock_dir=__opts__["sock_dir"],
1311         transport=__opts__["transport"],
1312     )
1313     return result
1314 def stop(vm_name, call=None):
1315     if call != "action":
1316         raise SaltCloudSystemExit("The stop action must be called with -a or --action.")
1317     conn = get_conn()
1318     __utils__["cloud.fire_event"](
1319         "event",
1320         "stop instance",
1321         "salt/cloud/{}/stopping".format(vm_name),
1322         args={"name": vm_name},
1323         sock_dir=__opts__["sock_dir"],
1324         transport=__opts__["transport"],
1325     )
1326     result = conn.ex_stop_node(conn.ex_get_node(vm_name))
1327     __utils__["cloud.fire_event"](
1328         "event",
1329         "stop instance",
1330         "salt/cloud/{}/stopped".format(vm_name),
1331         args={"name": vm_name},
1332         sock_dir=__opts__["sock_dir"],
1333         transport=__opts__["transport"],
1334     )
1335     return result
1336 def destroy(vm_name, call=None):
1337     if call and call != "action":
1338         raise SaltCloudSystemExit(
1339             'The destroy action must be called with -d or "-a destroy".'
1340         )
1341     conn = get_conn()
1342     try:
1343         node = conn.ex_get_node(vm_name)
1344     except Exception as exc:  # pylint: disable=W0703
1345         log.error(
1346             "Could not locate instance %s\n\n"
1347             "The following exception was thrown by libcloud when trying to "
1348             "run the initial deployment: \n%s",
1349             vm_name,
1350             exc,
1351             exc_info_on_loglevel=logging.DEBUG,
1352         )
1353         raise SaltCloudSystemExit("Could not find instance {}.".format(vm_name))
1354     __utils__["cloud.fire_event"](
1355         "event",
1356         "delete instance",
1357         "salt/cloud/{}/deleting".format(vm_name),
1358         args={"name": vm_name},
1359         sock_dir=__opts__["sock_dir"],
1360         transport=__opts__["transport"],
1361     )
1362     profile = None
1363     if node.extra["metadata"] and "items" in node.extra["metadata"]:
1364         for md in node.extra["metadata"]["items"]:
1365             if md["key"] == "salt-cloud-profile":
1366                 profile = md["value"]
1367     vm_ = get_configured_provider()
1368     delete_boot_pd = False
1369     if (
1370         profile
1371         and profile in vm_["profiles"]
1372         and "delete_boot_pd" in vm_["profiles"][profile]
1373     ):
1374         delete_boot_pd = vm_["profiles"][profile]["delete_boot_pd"]
1375     try:
1376         inst_deleted = conn.destroy_node(node)
1377     except Exception as exc:  # pylint: disable=W0703
1378         log.error(
1379             "Could not destroy instance %s\n\n"
1380             "The following exception was thrown by libcloud when trying to "
1381             "run the initial deployment: \n%s",
1382             vm_name,
1383             exc,
1384             exc_info_on_loglevel=logging.DEBUG,
1385         )
1386         raise SaltCloudSystemExit("Could not destroy instance {}.".format(vm_name))
1387     __utils__["cloud.fire_event"](
1388         "event",
1389         "delete instance",
1390         "salt/cloud/{}/deleted".format(vm_name),
1391         args={"name": vm_name},
1392         sock_dir=__opts__["sock_dir"],
1393         transport=__opts__["transport"],
1394     )
1395     if delete_boot_pd:
1396         log.info(
1397             "delete_boot_pd is enabled for the instance profile, "
1398             "attempting to delete disk"
1399         )
1400         __utils__["cloud.fire_event"](
1401             "event",
1402             "delete disk",
1403             "salt/cloud/disk/deleting",
1404             args={"name": vm_name},
1405             sock_dir=__opts__["sock_dir"],
1406             transport=__opts__["transport"],
1407         )
1408         try:
1409             conn.destroy_volume(conn.ex_get_volume(vm_name))
1410         except Exception as exc:  # pylint: disable=W0703
1411             log.error(
1412                 "Could not destroy disk %s\n\n"
1413                 "The following exception was thrown by libcloud when trying "
1414                 "to run the initial deployment: \n%s",
1415                 vm_name,
1416                 exc,
1417                 exc_info_on_loglevel=logging.DEBUG,
1418             )
1419         __utils__["cloud.fire_event"](
1420             "event",
1421             "deleted disk",
1422             "salt/cloud/disk/deleted",
1423             args={"name": vm_name},
1424             sock_dir=__opts__["sock_dir"],
1425             transport=__opts__["transport"],
1426         )
1427     if __opts__.get("update_cachedir", False) is True:
1428         __utils__["cloud.delete_minion_cachedir"](
1429             vm_name, _get_active_provider_name().split(":")[0], __opts__
1430         )
1431     return inst_deleted
1432 def create_attach_volumes(name, kwargs, call=None):
1433     if call != "action":
1434         raise SaltCloudSystemExit(
1435             "The create_attach_volumes action must be called with -a or --action."
1436         )
1437     volumes = literal_eval(kwargs["volumes"])
1438     node = kwargs["node"]
1439     conn = get_conn()
1440     node_data = _expand_node(conn.ex_get_node(node))
1441     letter = ord("a") - 1
1442     for idx, volume in enumerate(volumes):
1443         volume_name = "{}-sd{}".format(name, chr(letter + 2 + idx))
1444         volume_dict = {
1445             "disk_name": volume_name,
1446             "location": node_data["extra"]["zone"]["name"],
1447             "size": volume["size"],
1448             "type": volume.get("type", "pd-standard"),
1449             "image": volume.get("image", None),
1450             "snapshot": volume.get("snapshot", None),
1451             "auto_delete": volume.get("auto_delete", False),
1452         }
1453         create_disk(volume_dict, "function")
1454         attach_disk(name, volume_dict, "action")
1455 def request_instance(vm_):
1456     if not GCE_VM_NAME_REGEX.match(vm_["name"]):
1457         raise SaltCloudSystemExit(
1458             "VM names must start with a letter, only contain letters, numbers, or"
1459             " dashes and cannot end in a dash."
1460         )
1461     try:
1462         if (
1463             vm_["profile"]
1464             and config.is_profile_configured(
1465                 __opts__, _get_active_provider_name() or "gce", vm_["profile"], vm_=vm_
1466             )
1467             is False
1468         ):
1469             return False
1470     except AttributeError:
1471         pass
1472     __utils__["cloud.fire_event"](
1473         "event",
1474         "create instance",
1475         "salt/cloud/{}/creating".format(vm_["name"]),
1476         args=__utils__["cloud.filter_event"](
1477             "creating", vm_, ["name", "profile", "provider", "driver"]
1478         ),
1479         sock_dir=__opts__["sock_dir"],
1480         transport=__opts__["transport"],
1481     )
1482     conn = get_conn()
1483     kwargs = {
1484         "name": vm_["name"],
1485         "size": __get_size(conn, vm_),
1486         "image": __get_image(conn, vm_),
1487         "location": __get_location(conn, vm_),
1488         "ex_network": __get_network(conn, vm_),
1489         "ex_subnetwork": __get_subnetwork(vm_),
1490         "ex_tags": __get_tags(vm_),
1491         "ex_metadata": __get_metadata(vm_),
1492     }
1493     external_ip = config.get_cloud_config_value(
1494         "external_ip", vm_, __opts__, default="ephemeral"
1495     )
1496     if external_ip.lower() == "ephemeral":
1497         external_ip = "ephemeral"
1498         vm_["external_ip"] = external_ip
1499     elif external_ip == "None":
1500         external_ip = None
1501         vm_["external_ip"] = external_ip
1502     else:
1503         region = __get_region(conn, vm_)
1504         external_ip = __create_orget_address(conn, external_ip, region)
1505         vm_["external_ip"] = {
1506             "name": external_ip.name,
1507             "address": external_ip.address,
1508             "region": external_ip.region.name,
1509     kwargs["external_ip"] = external_ip
1510     if LIBCLOUD_VERSION_INFO &gt; (<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>0, 15, 1):
1511         kwargs.update(
1512             {
1513                 "ex_disk_type": config.get_cloud_config_value(
1514                     "ex_disk_type", vm_, __opts__, default="pd-standard"
1515                 ),
1516                 "ex_disk_auto_delete": config.get_cloud_config_value(
1517                     "ex_disk_auto_delete", vm_, __opts__, default=True
1518                 ),
1519                 "ex_disks_gce_struct": config.get_cloud_config_value(</b></font>
1520                     "ex_disks_gce_struct", vm_, __opts__, default=None
1521                 ),
1522                 "ex_service_accounts": config.get_cloud_config_value(
1523                     "ex_service_accounts", vm_, __opts__, default=None
1524                 ),
1525                 "ex_can_ip_forward": config.get_cloud_config_value(
1526                     "ip_forwarding", vm_, __opts__, default=False
1527                 ),
1528                 "ex_preemptible": config.get_cloud_config_value(
1529                     "preemptible", vm_, __opts__, default=False
1530                 ),
1531             }
1532         )
1533         if kwargs.get("ex_disk_type") not in ("pd-standard", "pd-ssd"):
1534             raise SaltCloudSystemExit(
1535                 "The value of 'ex_disk_type' needs to be one of: "
1536                 "'pd-standard', 'pd-ssd'"
1537             )
1538     if LIBCLOUD_VERSION_INFO &gt;= (2, 3, 0):
1539         kwargs.update(
1540             {
1541                 "ex_accelerator_type": config.get_cloud_config_value(
1542                     "ex_accelerator_type", vm_, __opts__, default=None
1543                 ),
1544                 "ex_accelerator_count": config.get_cloud_config_value(
1545                     "ex_accelerator_count", vm_, __opts__, default=None
1546                 ),
1547             }
1548         )
1549         if kwargs.get("ex_accelerator_type"):
1550             log.warning(
1551                 "An accelerator is being attached to this instance, "
1552                 "the ex_on_host_maintenance setting is being set to "
1553                 "'TERMINATE' as a result"
1554             )
1555             kwargs.update({"ex_on_host_maintenance": "TERMINATE"})
1556     log.info("Creating GCE instance %s in %s", vm_["name"], kwargs["location"].name)
1557     log.debug("Create instance kwargs %s", kwargs)
1558     __utils__["cloud.fire_event"](
1559         "event",
1560         "requesting instance",
1561         "salt/cloud/{}/requesting".format(vm_["name"]),
1562         args=__utils__["cloud.filter_event"](
1563             "requesting", vm_, ["name", "profile", "provider", "driver"]
1564         ),
1565         sock_dir=__opts__["sock_dir"],
1566         transport=__opts__["transport"],
1567     )
1568     try:
1569         node_data = conn.create_node(**kwargs)
1570     except Exception as exc:  # pylint: disable=W0703
1571         log.error(
1572             "Error creating %s on GCE\n\n"
1573             "The following exception was thrown by libcloud when trying to "
1574             "run the initial deployment: \n%s",
1575             vm_["name"],
1576             exc,
1577             exc_info_on_loglevel=logging.DEBUG,
1578         )
1579         return False
1580     volumes = config.get_cloud_config_value(
1581         "volumes", vm_, __opts__, search_global=True
1582     )
1583     if volumes:
1584         __utils__["cloud.fire_event"](
1585             "event",
1586             "attaching volumes",
1587             "salt/cloud/{}/attaching_volumes".format(vm_["name"]),
1588             args={"volumes": volumes},
1589             sock_dir=__opts__["sock_dir"],
1590             transport=__opts__["transport"],
1591         )
1592         log.info("Create and attach volumes to node %s", vm_["name"])
1593         create_attach_volumes(
1594             vm_["name"], {"volumes": volumes, "node": node_data}, call="action"
1595         )
1596     try:
1597         node_dict = show_instance(node_data["name"], "action")
1598     except TypeError:
1599         node_dict = show_instance(node_data.name, "action")
1600     return node_dict, node_data
1601 def create(vm_=None, call=None):
1602     if call:
1603         raise SaltCloudSystemExit("You cannot create an instance with -a or -f.")
1604     node_info = request_instance(vm_)
1605     if isinstance(node_info, bool):
1606         raise SaltCloudSystemExit("There was an error creating the GCE instance.")
1607     node_dict = node_info[0]
1608     node_data = node_info[1]
1609     ssh_user, ssh_key = __get_ssh_credentials(vm_)
1610     vm_["ssh_host"] = __get_host(node_data, vm_)
1611     vm_["key_filename"] = ssh_key
1612     ret = __utils__["cloud.bootstrap"](vm_, __opts__)
1613     ret.update(node_dict)
1614     log.info("Created Cloud VM '%s'", vm_["name"])
1615     log.trace("'%s' VM creation details:\n%s", vm_["name"], pprint.pformat(node_dict))
1616     __utils__["cloud.fire_event"](
1617         "event",
1618         "created instance",
1619         "salt/cloud/{}/created".format(vm_["name"]),
1620         args=__utils__["cloud.filter_event"](
1621             "created", vm_, ["name", "profile", "provider", "driver"]
1622         ),
1623         sock_dir=__opts__["sock_dir"],
1624         transport=__opts__["transport"],
1625     )
1626     return ret
1627 def update_pricing(kwargs=None, call=None):
1628     url = "https://cloudpricingcalculator.appspot.com/static/data/pricelist.json"
1629     price_json = salt.utils.http.query(url, decode=True, decode_type="json")
1630     outfile = os.path.join(__opts__["cachedir"], "gce-pricing.p")
1631     with salt.utils.files.fopen(outfile, "w") as fho:
1632         salt.utils.msgpack.dump(price_json["dict"], fho)
1633     return True
1634 def show_pricing(kwargs=None, call=None):
1635     profile = __opts__["profiles"].get(kwargs["profile"], {})
1636     if not profile:
1637         return {"Error": "The requested profile was not found"}
1638     provider = profile.get("provider", "0:0")
1639     comps = provider.split(":")
1640     if len(comps) &lt; 2 or comps[1] != "gce":
1641         return {"Error": "The requested profile does not belong to GCE"}
1642     comps = profile.get("location", "us").split("-")
1643     region = comps[0]
1644     size = "CP-COMPUTEENGINE-VMIMAGE-{}".format(profile["size"].upper())
1645     pricefile = os.path.join(__opts__["cachedir"], "gce-pricing.p")
1646     if not os.path.exists(pricefile):
1647         update_pricing()
1648     with salt.utils.files.fopen(pricefile, "r") as fho:
1649         sizes = salt.utils.msgpack.load(fho)
1650     per_hour = float(sizes["gcp_price_list"][size][region])
1651     week1_discount = float(sizes["gcp_price_list"]["sustained_use_tiers"]["0.25"])
1652     week2_discount = float(sizes["gcp_price_list"]["sustained_use_tiers"]["0.50"])
1653     week3_discount = float(sizes["gcp_price_list"]["sustained_use_tiers"]["0.75"])
1654     week4_discount = float(sizes["gcp_price_list"]["sustained_use_tiers"]["1.0"])
1655     week1 = per_hour * (730 / 4) * week1_discount
1656     week2 = per_hour * (730 / 4) * week2_discount
1657     week3 = per_hour * (730 / 4) * week3_discount
1658     week4 = per_hour * (730 / 4) * week4_discount
1659     raw = sizes
1660     ret = {}
1661     ret["per_hour"] = per_hour
1662     ret["per_day"] = ret["per_hour"] * 24
1663     ret["per_week"] = ret["per_day"] * 7
1664     ret["per_month"] = week1 + week2 + week3 + week4
1665     ret["per_year"] = ret["per_month"] * 12
1666     if kwargs.get("raw", False):
1667         ret["_raw"] = raw
1668     return {profile["profile"]: ret}
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
