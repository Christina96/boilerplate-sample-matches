<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for labelarray.py &amp; hdf5_daily_bars.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for labelarray.py &amp; hdf5_daily_bars.py
      </h3>
<h1 align="center">
        1.4%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>labelarray.py (1.5706806%)<th>hdf5_daily_bars.py (1.4101057%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(4-17)<td><a href="#" name="0">(101-119)</a><td align="center"><font color="#ff0000">12</font>
</td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>labelarray.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
<a name="0"></a>"""
An ndarray subclass for working with arrays of strings.
<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>from functools import partial, total_ordering
from operator import eq, ne
import re
import numpy as np
from numpy import ndarray
import pandas as pd
from toolz import compose
from zipline.utils.compat import unicode
from zipline.utils.functional import instance
from zipline.utils.preprocess import preprocess
from zipline.utils.sentinel import sentinel
from</b></font> zipline.utils.input_validation import (
    coerce,
    expect_kinds,
    expect_types,
    optional,
)
from zipline.utils.numpy_utils import (
    bool_dtype,
    unsigned_int_dtype_with_size_in_bytes,
    is_object,
    object_dtype,
)
from zipline.utils.pandas_utils import ignore_pandas_nan_categorical_warning
from ._factorize import (
    factorize_strings,
    factorize_strings_known_categories,
    smallest_uint_that_can_hold,
)
def compare_arrays(left, right):
    "Eq check with a short-circuit for identical objects."
    return (
        left is right
        or ((left.shape == right.shape) and (left == right).all())
    )
def _make_unsupported_method(name):
    def method(*args, **kwargs):
        raise NotImplementedError(
            "Method %s is not supported on LabelArrays." % name
        )
    method.__name__ = name
    method.__doc__ = "Unsupported LabelArray Method: %s" % name
    return method
class MissingValueMismatch(ValueError):
    def __init__(self, left, right):
        super(MissingValueMismatch, self).__init__(
            "LabelArray missing_values don't match:"
            " left={}, right={}".format(left, right)
        )
class CategoryMismatch(ValueError):
    def __init__(self, left, right):
        (mismatches,) = np.where(left != right)
        assert len(mismatches), "Not actually a mismatch!"
        super(CategoryMismatch, self).__init__(
            "LabelArray categories don't match:\n"
            "Mismatched Indices: {mismatches}\n"
            "Left: {left}\n"
            "Right: {right}".format(
                mismatches=mismatches,
                left=left[mismatches],
                right=right[mismatches],
            )
        )
_NotPassed = sentinel('_NotPassed')
class LabelArray(ndarray):
    SUPPORTED_SCALAR_TYPES = (bytes, unicode, type(None))
    SUPPORTED_NON_NONE_SCALAR_TYPES = (bytes, unicode)
    @preprocess(
        values=coerce(list, partial(np.asarray, dtype=object)),
        categories=coerce((list, np.ndarray, set), list),
    )
    @expect_types(
        values=np.ndarray,
        missing_value=SUPPORTED_SCALAR_TYPES,
        categories=optional(list),
    )
    @expect_kinds(values=("O", "S", "U"))
    def __new__(cls,
                values,
                missing_value,
                categories=None,
                sort=True):
        if not is_object(values):
            values = values.astype(object)
        if values.flags.f_contiguous:
            ravel_order = 'F'
        else:
            ravel_order = 'C'
        if categories is None:
            codes, categories, reverse_categories = factorize_strings(
                values.ravel(ravel_order),
                missing_value=missing_value,
                sort=sort,
            )
        else:
            codes, categories, reverse_categories = (
                factorize_strings_known_categories(
                    values.ravel(ravel_order),
                    categories=categories,
                    missing_value=missing_value,
                    sort=sort,
                )
            )
        categories.setflags(write=False)
        return cls.from_codes_and_metadata(
            codes=codes.reshape(values.shape, order=ravel_order),
            categories=categories,
            reverse_categories=reverse_categories,
            missing_value=missing_value,
        )
    @classmethod
    def from_codes_and_metadata(cls,
                                codes,
                                categories,
                                reverse_categories,
                                missing_value):
        ret = codes.view(type=cls, dtype=np.void)
        ret._categories = categories
        ret._reverse_categories = reverse_categories
        ret._missing_value = missing_value
        return ret
    @classmethod
    def from_categorical(cls, categorical, missing_value=None):
        return LabelArray(
            categorical,
            missing_value,
            categorical.categories,
        )
    @property
    def categories(self):
        return self._categories
    @property
    def reverse_categories(self):
        return self._reverse_categories
    @property
    def missing_value(self):
        return self._missing_value
    @property
    def missing_value_code(self):
        return self.reverse_categories[self.missing_value]
    def has_label(self, value):
        return value in self.reverse_categories
    def __array_finalize__(self, obj):
        if obj is None:
            raise TypeError(
                "Direct construction of LabelArrays is not supported."
            )
        self._categories = getattr(obj, 'categories', None)
        self._reverse_categories = getattr(obj, 'reverse_categories', None)
        self._missing_value = getattr(obj, 'missing_value', None)
    def as_int_array(self):
        return self.view(
            type=ndarray,
            dtype=unsigned_int_dtype_with_size_in_bytes(self.itemsize),
        )
    def as_string_array(self):
        return self.categories[self.as_int_array()]
    def as_categorical(self):
        if len(self.shape) &gt; 1:
            raise ValueError("Can't convert a 2D array to a categorical.")
        with ignore_pandas_nan_categorical_warning():
            return pd.Categorical.from_codes(
                self.as_int_array(),
                self.categories.copy(),
                ordered=False,
            )
    def as_categorical_frame(self, index, columns, name=None):
        if len(self.shape) != 2:
            raise ValueError(
                "Can't convert a non-2D LabelArray into a DataFrame."
            )
        expected_shape = (len(index), len(columns))
        if expected_shape != self.shape:
            raise ValueError(
                "Can't construct a DataFrame with provided indices:\n\n"
                "LabelArray shape is {actual}, but index and columns imply "
                "that shape should be {expected}.".format(
                    actual=self.shape,
                    expected=expected_shape,
                )
            )
        return pd.Series(
            index=pd.MultiIndex.from_product([index, columns]),
            data=self.ravel().as_categorical(),
            name=name,
        ).unstack()
    def __setitem__(self, indexer, value):
        self_categories = self.categories
        if isinstance(value, self.SUPPORTED_SCALAR_TYPES):
            value_code = self.reverse_categories.get(value, None)
            if value_code is None:
                raise ValueError("%r is not in LabelArray categories." % value)
            self.as_int_array()[indexer] = value_code
        elif isinstance(value, LabelArray):
            value_categories = value.categories
            if compare_arrays(self_categories, value_categories):
                return super(LabelArray, self).__setitem__(indexer, value)
            elif (self.missing_value == value.missing_value and
                  set(value.categories) &lt;= set(self.categories)):
                rhs = LabelArray.from_codes_and_metadata(
                    *factorize_strings_known_categories(
                        value.as_string_array().ravel(),
                        list(self.categories),
                        self.missing_value,
                        False,
                    ),
                    missing_value=self.missing_value
                ).reshape(value.shape)
                super(LabelArray, self).__setitem__(indexer, rhs)
            else:
                raise CategoryMismatch(self_categories, value_categories)
        else:
            raise NotImplementedError(
                "Setting into a LabelArray with a value of "
                "type {type} is not yet supported.".format(
                    type=type(value).__name__,
                ),
            )
    def set_scalar(self, indexer, value):
        try:
            value_code = self.reverse_categories[value]
        except KeyError:
            raise ValueError("%r is not in LabelArray categories." % value)
        self.as_int_array()[indexer] = value_code
    def __setslice__(self, i, j, sequence):
        self.__setitem__(slice(i, j), sequence)
    def __getitem__(self, indexer):
        result = super(LabelArray, self).__getitem__(indexer)
        if result.ndim:
            return result
        index = result.view(
            unsigned_int_dtype_with_size_in_bytes(self.itemsize),
        )
        return self.categories[index]
    def is_missing(self):
        return (
            self.as_int_array() == self.reverse_categories[self.missing_value]
        )
    def not_missing(self):
        return (
            self.as_int_array() != self.reverse_categories[self.missing_value]
        )
    def _equality_check(op):
        def method(self, other):
            if isinstance(other, LabelArray):
                self_mv = self.missing_value
                other_mv = other.missing_value
                if self_mv != other_mv:
                    raise MissingValueMismatch(self_mv, other_mv)
                self_categories = self.categories
                other_categories = other.categories
                if not compare_arrays(self_categories, other_categories):
                    raise CategoryMismatch(self_categories, other_categories)
                return (
                    op(self.as_int_array(), other.as_int_array())
                    &amp; self.not_missing()
                    &amp; other.not_missing()
                )
            elif isinstance(other, ndarray):
                return op(self.as_string_array(), other) &amp; self.not_missing()
            elif isinstance(other, self.SUPPORTED_SCALAR_TYPES):
                i = self._reverse_categories.get(other, -1)
                return op(self.as_int_array(), i) &amp; self.not_missing()
            return op(super(LabelArray, self), other)
        return method
    __eq__ = _equality_check(eq)
    __ne__ = _equality_check(ne)
    del _equality_check
    def view(self, dtype=_NotPassed, type=_NotPassed):
        if type is _NotPassed and dtype not in (_NotPassed, self.dtype):
            raise TypeError("Can't view LabelArray as another dtype.")
        kwargs = {}
        if dtype is not _NotPassed:
            kwargs['dtype'] = dtype
        if type is not _NotPassed:
            kwargs['type'] = type
        return super(LabelArray, self).view(**kwargs)
    def astype(self,
               dtype,
               order='K',
               casting='unsafe',
               subok=True,
               copy=True):
        if dtype == self.dtype:
            if not subok:
                array = self.view(type=np.ndarray)
            else:
                array = self
            if copy:
                return array.copy()
            return array
        if dtype == object_dtype:
            return self.as_string_array()
        if dtype.kind == 'S':
            return self.as_string_array().astype(
                dtype,
                order=order,
                casting=casting,
                subok=subok,
                copy=copy,
            )
        raise TypeError(
            '%s can only be converted into object, string, or void,'
            ' got: %r' % (
                type(self).__name__,
                dtype,
            ),
        )
    SUPPORTED_NDARRAY_METHODS = frozenset([
        'astype',
        'base',
        'compress',
        'copy',
        'data',
        'diagonal',
        'dtype',
        'flat',
        'flatten',
        'item',
        'itemset',
        'itemsize',
        'nbytes',
        'ndim',
        'ravel',
        'repeat',
        'reshape',
        'resize',
        'setflags',
        'shape',
        'size',
        'squeeze',
        'strides',
        'swapaxes',
        'take',
        'trace',
        'transpose',
        'view'
    ])
    PUBLIC_NDARRAY_METHODS = frozenset([
        s for s in dir(ndarray) if not s.startswith('_')
    ])
    locals().update(
        {
            method: _make_unsupported_method(method)
            for method in PUBLIC_NDARRAY_METHODS - SUPPORTED_NDARRAY_METHODS
        }
    )
    def __repr__(self):
        repr_lines = repr(self.as_string_array()).splitlines()
        repr_lines[0] = repr_lines[0].replace('array(', 'LabelArray(', 1)
        repr_lines[-1] = repr_lines[-1].rsplit(',', 1)[0] + ')'
        return '\n     '.join(repr_lines)
    def empty_like(self, shape):
        return type(self).from_codes_and_metadata(
            codes=np.full(
                shape,
                self.reverse_categories[self.missing_value],
                dtype=unsigned_int_dtype_with_size_in_bytes(self.itemsize),
            ),
            categories=self.categories,
            reverse_categories=self.reverse_categories,
            missing_value=self.missing_value,
        )
    def map_predicate(self, f):
        if self.missing_value is None:
            def f_to_use(x):
                return False if x is None else f(x)
        else:
            f_to_use = f
        results = np.vectorize(f_to_use, otypes=[bool_dtype])(self.categories)
        results[self.reverse_categories[self.missing_value]] = False
        return results[self.as_int_array()]
    def map(self, f):
        if self.missing_value is None:
            allowed_outtypes = self.SUPPORTED_SCALAR_TYPES
        else:
            allowed_outtypes = self.SUPPORTED_NON_NONE_SCALAR_TYPES
        def f_to_use(x,
                     missing_value=self.missing_value,
                     otypes=allowed_outtypes):
            if x == missing_value:
                return _sortable_sentinel
            ret = f(x)
            if not isinstance(ret, otypes):
                raise TypeError(
                    "LabelArray.map expected function {f} to return a string"
                    " or None, but got {type} instead.\n"
                    "Value was {value}.".format(
                        f=f.__name__,
                        type=type(ret).__name__,
                        value=ret,
                    )
                )
            if ret == missing_value:
                return _sortable_sentinel
            return ret
        new_categories_with_duplicates = (
            np.vectorize(f_to_use, otypes=[object])(self.categories)
        )
        new_categories, bloated_inverse_index = np.unique(
            new_categories_with_duplicates,
            return_inverse=True
        )
        if new_categories[0] is _sortable_sentinel:
            new_categories[0] = self.missing_value
        reverse_index = bloated_inverse_index.astype(
            smallest_uint_that_can_hold(len(new_categories))
        )
        new_codes = np.take(reverse_index, self.as_int_array())
        return self.from_codes_and_metadata(
            new_codes,
            new_categories,
            dict(zip(new_categories, range(len(new_categories)))),
            missing_value=self.missing_value,
        )
    def startswith(self, prefix):
        return self.map_predicate(lambda elem: elem.startswith(prefix))
    def endswith(self, suffix):
        return self.map_predicate(lambda elem: elem.endswith(suffix))
    def has_substring(self, substring):
        return self.map_predicate(lambda elem: substring in elem)
    @preprocess(pattern=coerce(from_=(bytes, unicode), to=re.compile))
    def matches(self, pattern):
        return self.map_predicate(compose(bool, pattern.match))
    @preprocess(container=coerce((list, tuple, np.ndarray), set))
    def element_of(self, container):
        return self.map_predicate(container.__contains__)
@instance  # This makes _sortable_sentinel a singleton instance.
@total_ordering
class _sortable_sentinel(object):
    def __eq__(self, other):
        return self is other
    def __lt__(self, other):
        return True
@expect_types(trues=LabelArray, falses=LabelArray)
def labelarray_where(cond, trues, falses):
    if trues.missing_value != falses.missing_value:
        raise ValueError(
            "Can't compute where on arrays with different missing values."
        )
    strs = np.where(cond, trues.as_string_array(), falses.as_string_array())
    return LabelArray(strs, missing_value=trues.missing_value)
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>hdf5_daily_bars.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>from functools import partial
import h5py
import logbook
import numpy as np
import pandas as pd
from six import iteritems, raise_from, viewkeys
from six.moves import reduce
from zipline.data.bar_reader import (
    NoDataAfterDate,
    NoDataBeforeDate,
    NoDataForSid,
    NoDataOnDate,
)
from zipline.data.session_bars import CurrencyAwareSessionBarReader
from zipline.utils.memoize import lazyval
from zipline.utils.numpy_utils import bytes_array_to_native_str_object_array
from</b></font> zipline.utils.pandas_utils import check_indexes_all_same
log = logbook.Logger('HDF5DailyBars')
VERSION = 0
DATA = 'data'
INDEX = 'index'
LIFETIMES = 'lifetimes'
CURRENCY = 'currency'
CODE = 'code'
SCALING_FACTOR = 'scaling_factor'
OPEN = 'open'
HIGH = 'high'
LOW = 'low'
CLOSE = 'close'
VOLUME = 'volume'
FIELDS = (OPEN, HIGH, LOW, CLOSE, VOLUME)
DAY = 'day'
SID = 'sid'
START_DATE = 'start_date'
END_DATE = 'end_date'
MISSING_CURRENCY = 'XXX'
DEFAULT_SCALING_FACTORS = {
    OPEN: 1000,
    HIGH: 1000,
    LOW: 1000,
    CLOSE: 1000,
    VOLUME: 1,
}
def coerce_to_uint32(a, scaling_factor):
    return (a * scaling_factor).round().astype('uint32')
def days_and_sids_for_frames(frames):
    if not frames:
        days = np.array([], dtype='datetime64[ns]')
        sids = np.array([], dtype='int64')
        return days, sids
    check_indexes_all_same(
        [frame.index for frame in frames],
        message='Frames have mismatched days.',
    )
    check_indexes_all_same(
        [frame.columns for frame in frames],
        message='Frames have mismatched sids.',
    )
    return frames[0].index.values, frames[0].columns.values
class HDF5DailyBarWriter(object):
    def __init__(self, filename, date_chunk_size):
        self._filename = filename
        self._date_chunk_size = date_chunk_size
    def h5_file(self, mode):
        return h5py.File(self._filename, mode)
    def write(self,
              country_code,
              frames,
              currency_codes=None,
              scaling_factors=None):
        if scaling_factors is None:
            scaling_factors = DEFAULT_SCALING_FACTORS
        days, sids = days_and_sids_for_frames(list(frames.values()))
        if currency_codes is None:
            currency_codes = pd.Series(index=sids, data=MISSING_CURRENCY)
        check_sids_arrays_match(
            sids,
            currency_codes.index.values,
            message="currency_codes sids do not match data sids:",
        )
        start_date_ixs, end_date_ixs = compute_asset_lifetimes(frames)
        if len(sids):
            chunks = (len(sids), min(self._date_chunk_size, len(days)))
        else:
            chunks = None
        with self.h5_file(mode='a') as h5_file:
            h5_file.attrs['version'] = VERSION
            country_group = h5_file.create_group(country_code)
            self._write_index_group(country_group, days, sids)
            self._write_lifetimes_group(
                country_group,
                start_date_ixs,
                end_date_ixs,
            )
            self._write_currency_group(country_group, currency_codes)
            self._write_data_group(
                country_group,
                frames,
                scaling_factors,
                chunks,
            )
    def write_from_sid_df_pairs(self,
                                country_code,
                                data,
                                currency_codes=None,
                                scaling_factors=None):
        data = list(data)
        if not data:
            empty_frame = pd.DataFrame(
                data=None,
                index=np.array([], dtype='datetime64[ns]'),
                columns=np.array([], dtype='int64'),
            )
            return self.write(
                country_code,
                {f: empty_frame.copy() for f in FIELDS},
                scaling_factors,
            )
        sids, frames = zip(*data)
        ohlcv_frame = pd.concat(frames)
        sid_ix = np.repeat(sids, [len(f) for f in frames])
        ohlcv_frame.set_index(sid_ix, append=True, inplace=True)
        frames = {
            field: ohlcv_frame[field].unstack()
            for field in FIELDS
        }
        return self.write(
            country_code=country_code,
            frames=frames,
            scaling_factors=scaling_factors,
            currency_codes=currency_codes
        )
    def _write_index_group(self, country_group, days, sids):
        index_group = country_group.create_group(INDEX)
        self._log_writing_dataset(index_group)
        index_group.create_dataset(SID, data=sids)
        index_group.create_dataset(DAY, data=days.astype(np.int64))
    def _write_lifetimes_group(self,
                               country_group,
                               start_date_ixs,
                               end_date_ixs):
        lifetimes_group = country_group.create_group(LIFETIMES)
        self._log_writing_dataset(lifetimes_group)
        lifetimes_group.create_dataset(START_DATE, data=start_date_ixs)
        lifetimes_group.create_dataset(END_DATE, data=end_date_ixs)
    def _write_currency_group(self, country_group, currencies):
        currency_group = country_group.create_group(CURRENCY)
        self._log_writing_dataset(currency_group)
        currency_group.create_dataset(
            CODE,
            data=currencies.values.astype(dtype='S3'),
        )
    def _write_data_group(self,
                          country_group,
                          frames,
                          scaling_factors,
                          chunks):
        data_group = country_group.create_group(DATA)
        self._log_writing_dataset(data_group)
        for field in FIELDS:
            frame = frames[field]
            frame.sort_index(inplace=True)
            frame.sort_index(axis='columns', inplace=True)
            data = coerce_to_uint32(
                frame.T.fillna(0).values,
                scaling_factors[field],
            )
            dataset = data_group.create_dataset(
                field,
                compression='lzf',
                shuffle=True,
                data=data,
                chunks=chunks,
            )
            self._log_writing_dataset(dataset)
            dataset.attrs[SCALING_FACTOR] = scaling_factors[field]
            log.debug(
                'Writing dataset {} to file {}',
                dataset.name, self._filename
            )
    def _log_writing_dataset(self, dataset):
        log.debug("Writing {} to file {}", dataset.name, self._filename)
def compute_asset_lifetimes(frames):
    is_null_matrix = np.logical_and.reduce(
        [frames[field].isnull().values for field in FIELDS],
    )
    if not is_null_matrix.size:
        empty = np.array([], dtype='int64')
        return empty, empty.copy()
    start_date_ixs = is_null_matrix.argmin(axis=0)
    end_offsets = is_null_matrix[::-1].argmin(axis=0)
    end_date_ixs = is_null_matrix.shape[0] - end_offsets - 1
    return start_date_ixs, end_date_ixs
def convert_price_with_scaling_factor(a, scaling_factor):
    conversion_factor = (1.0 / scaling_factor)
    zeroes = (a == 0)
    return np.where(zeroes, np.nan, a.astype('float64')) * conversion_factor
class HDF5DailyBarReader(CurrencyAwareSessionBarReader):
    def __init__(self, country_group):
        self._country_group = country_group
        self._postprocessors = {
            OPEN: partial(convert_price_with_scaling_factor,
                          scaling_factor=self._read_scaling_factor(OPEN)),
            HIGH: partial(convert_price_with_scaling_factor,
                          scaling_factor=self._read_scaling_factor(HIGH)),
            LOW: partial(convert_price_with_scaling_factor,
                         scaling_factor=self._read_scaling_factor(LOW)),
            CLOSE: partial(convert_price_with_scaling_factor,
                           scaling_factor=self._read_scaling_factor(CLOSE)),
            VOLUME: lambda a: a,
        }
    @classmethod
    def from_file(cls, h5_file, country_code):
        if h5_file.attrs['version'] != VERSION:
            raise ValueError(
                'mismatched version: file is of version %s, expected %s' % (
                    h5_file.attrs['version'],
                    VERSION,
                ),
            )
        return cls(h5_file[country_code])
    @classmethod
    def from_path(cls, path, country_code):
        return cls.from_file(h5py.File(path), country_code)
    def _read_scaling_factor(self, field):
        return self._country_group[DATA][field].attrs[SCALING_FACTOR]
    def load_raw_arrays(self,
                        columns,
                        start_date,
                        end_date,
                        assets):
        self._validate_timestamp(start_date)
        self._validate_timestamp(end_date)
        start = start_date.asm8
        end = end_date.asm8
        date_slice = self._compute_date_range_slice(start, end)
        n_dates = date_slice.stop - date_slice.start
        full_buf = np.zeros((len(self.sids) + 1, n_dates), dtype=np.uint32)
        mutable_buf = full_buf[:-1]
        sid_selector = self._make_sid_selector(assets)
        out = []
        for column in columns:
            mutable_buf.fill(0)
            dataset = self._country_group[DATA][column]
            dataset.read_direct(
                mutable_buf,
                np.s_[:, date_slice],
            )
            out.append(self._postprocessors[column](full_buf[sid_selector].T))
        return out
    def _make_sid_selector(self, assets):
        assets = np.array(assets)
        sid_selector = self.sids.searchsorted(assets)
        unknown = np.in1d(assets, self.sids, invert=True)
        sid_selector[unknown] = -1
        return sid_selector
    def _compute_date_range_slice(self, start_date, end_date):
        start_ix = self.dates.searchsorted(start_date)
        end_ix = self.dates.searchsorted(end_date, side='right')
        return slice(start_ix, end_ix)
    def _validate_assets(self, assets):
        missing_sids = np.setdiff1d(assets, self.sids)
        if len(missing_sids):
            raise NoDataForSid(
                'Assets not contained in daily pricing file: {}'.format(
                    missing_sids
                )
            )
    def _validate_timestamp(self, ts):
        if ts.asm8 not in self.dates:
            raise NoDataOnDate(ts)
    @lazyval
    def dates(self):
        return self._country_group[INDEX][DAY][:].astype('datetime64[ns]')
    @lazyval
    def sids(self):
        return self._country_group[INDEX][SID][:].astype('int64', copy=False)
    @lazyval
    def asset_start_dates(self):
        return self.dates[self._country_group[LIFETIMES][START_DATE][:]]
    @lazyval
    def asset_end_dates(self):
        return self.dates[self._country_group[LIFETIMES][END_DATE][:]]
    @lazyval
    def _currency_codes(self):
        bytes_array = self._country_group[CURRENCY][CODE][:]
        return bytes_array_to_native_str_object_array(bytes_array)
    def currency_codes(self, sids):
        ixs = self.sids.searchsorted(sids, side='left')
        result = self._currency_codes[ixs]
        not_found = (self.sids[ixs] != sids)
        result[not_found] = None
        return result
    @property
    def last_available_dt(self):
        return pd.Timestamp(self.dates[-1], tz='UTC')
    @property
    def trading_calendar(self):
        raise NotImplementedError(
            'HDF5 pricing does not yet support trading calendars.'
        )
    @property
    def first_trading_day(self):
        return pd.Timestamp(self.dates[0], tz='UTC')
    @lazyval
    def sessions(self):
        return pd.to_datetime(self.dates, utc=True)
    def get_value(self, sid, dt, field):
        self._validate_assets([sid])
        self._validate_timestamp(dt)
        sid_ix = self.sids.searchsorted(sid)
        dt_ix = self.dates.searchsorted(dt.asm8)
        value = self._postprocessors[field](
            self._country_group[DATA][field][sid_ix, dt_ix]
        )
        if np.isnan(value):
            if dt.asm8 &lt; self.asset_start_dates[sid_ix]:
                raise NoDataBeforeDate()
            if dt.asm8 &gt; self.asset_end_dates[sid_ix]:
                raise NoDataAfterDate()
        return value
    def get_last_traded_dt(self, asset, dt):
        sid_ix = self.sids.searchsorted(asset.sid)
        dt_limit_ix = self.dates.searchsorted(dt.asm8, side='right')
        nonzero_volume_ixs = np.ravel(
            np.nonzero(self._country_group[DATA][VOLUME][sid_ix, :dt_limit_ix])
        )
        if len(nonzero_volume_ixs) == 0:
            return pd.NaT
        return pd.Timestamp(self.dates[nonzero_volume_ixs][-1], tz='UTC')
class MultiCountryDailyBarReader(CurrencyAwareSessionBarReader):
    def __init__(self, readers):
        self._readers = readers
        self._country_map = pd.concat([
            pd.Series(index=reader.sids, data=country_code)
            for country_code, reader in iteritems(readers)
        ])
    @classmethod
    def from_file(cls, h5_file):
        return cls({
            country: HDF5DailyBarReader.from_file(h5_file, country)
            for country in h5_file.keys()
        })
    @classmethod
    def from_path(cls, path):
        return cls.from_file(h5py.File(path))
    @property
    def countries(self):
        return viewkeys(self._readers)
    def _country_code_for_assets(self, assets):
        country_codes = self._country_map.get(assets)
        if country_codes is not None:
            unique_country_codes = country_codes.dropna().unique()
            num_countries = len(unique_country_codes)
        else:
            num_countries = 0
        if num_countries == 0:
            raise ValueError('At least one valid asset id is required.')
        elif num_countries &gt; 1:
            raise NotImplementedError(
                (
                    'Assets were requested from multiple countries ({}),'
                    ' but multi-country reads are not yet supported.'
                ).format(list(unique_country_codes))
            )
        return np.asscalar(unique_country_codes)
    def load_raw_arrays(self,
                        columns,
                        start_date,
                        end_date,
                        assets):
        country_code = self._country_code_for_assets(assets)
        return self._readers[country_code].load_raw_arrays(
            columns,
            start_date,
            end_date,
            assets,
        )
    @property
    def last_available_dt(self):
        return max(
            reader.last_available_dt for reader in self._readers.values()
        )
    @property
    def trading_calendar(self):
        raise NotImplementedError(
            'HDF5 pricing does not yet support trading calendars.'
        )
    @property
    def first_trading_day(self):
        return min(
            reader.first_trading_day for reader in self._readers.values()
        )
    @property
    def sessions(self):
        return pd.to_datetime(
            reduce(
                np.union1d,
                (reader.dates for reader in self._readers.values()),
            ),
            utc=True,
        )
    def get_value(self, sid, dt, field):
        try:
            country_code = self._country_code_for_assets([sid])
        except ValueError as exc:
            raise_from(
                NoDataForSid(
                    'Asset not contained in daily pricing file: {}'.format(sid)
                ),
                exc
            )
        return self._readers[country_code].get_value(sid, dt, field)
    def get_last_traded_dt(self, asset, dt):
        country_code = self._country_code_for_assets([asset.sid])
        return self._readers[country_code].get_last_traded_dt(asset, dt)
    def currency_codes(self, sids):
        country_code = self._country_code_for_assets(sids)
        return self._readers[country_code].currency_codes(sids)
def check_sids_arrays_match(left, right, message):
    if len(left) != len(right):
        raise ValueError(
            "{}:\nlen(left) ({}) != len(right) ({})".format(
                message, len(left), len(right)
            )
        )
    diff = (left != right)
    if diff.any():
        (bad_locs,) = np.where(diff)
        raise ValueError(
            "{}:\n Indices with differences: {}".format(message, bad_locs)
        )
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
