<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for boto_apigateway.py &amp; junos_1.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for boto_apigateway.py &amp; junos_1.py
      </h3>
<h1 align="center">
        0.4%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>boto_apigateway.py (0.4743083%)<th>junos_1.py (0.45300114%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(2076-2083)<td><a href="#" name="0">(1719-1726)</a><td align="center"><font color="#ff0000">12</font>
</td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>boto_apigateway.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
"""
Manage Apigateway Rest APIs
===========================
.. versionadded:: 2016.11.0
:depends:
  - boto &gt;= 2.8.0
  - boto3 &gt;= 1.2.1
  - botocore &gt;= 1.4.49
Create and destroy rest apis depending on a swagger version 2 definition file.
Be aware that this interacts with Amazon's services, and so may incur charges.
This module uses ``boto3``, which can be installed via package, or pip.
This module accepts explicit vpc credentials but can also utilize
IAM roles assigned to the instance through Instance Profiles. Dynamic
credentials are then automatically obtained from AWS API and no further
configuration is necessary. More information available `here
&lt;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html&gt;`_.
If IAM roles are not used you need to specify them either in a pillar file or
in the minion's config file:
.. code-block:: yaml
    vpc.keyid: GKTADJGHEIQSXMKKRBJ08H
    vpc.key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
It's also possible to specify ``key``, ``keyid`` and ``region`` via a profile,
either passed in as a dict, or as a string to pull from pillars or minion
config:
.. code-block:: yaml
    myprofile:
      keyid: GKTADJGHEIQSXMKKRBJ08H
      key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
      region: us-east-1
.. code-block:: yaml
    Ensure Apigateway API exists:
      boto_apigateway.present:
        - name: myfunction
        - region: us-east-1
        - keyid: GKTADJGHEIQSXMKKRBJ08H
        - key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
"""
import hashlib
import logging
import os
import re
import salt.utils.files
import salt.utils.json
import salt.utils.yaml
log = logging.getLogger(__name__)
def __virtual__():
    """
    Only load if boto is available.
    """
    if "boto_apigateway.describe_apis" in __salt__:
        return "boto_apigateway"
    return (False, "boto_apigateway module could not be loaded")
def present(
    name,
    api_name,
    swagger_file,
    stage_name,
    api_key_required,
    lambda_integration_role,
    lambda_region=None,
    stage_variables=None,
    region=None,
    key=None,
    keyid=None,
    profile=None,
    lambda_funcname_format="{stage}_{api}_{resource}_{method}",
    authorization_type="NONE",
    error_response_template=None,
    response_template=None,
):
    """
    Ensure the spcified api_name with the corresponding swaggerfile is deployed to the
    given stage_name in AWS ApiGateway.
    this state currently only supports ApiGateway integration with AWS Lambda, and CORS support is
    handled through a Mock integration.
    There may be multiple deployments for the API object, each deployment is tagged with a description
    (i.e. unique label) in pretty printed json format consisting of the following key/values.
    .. code-block:: text
        {
            "api_name": api_name,
            "swagger_file": basename_of_swagger_file
            "swagger_file_md5sum": md5sum_of_swagger_file,
            "swagger_info_object": info_object_content_in_swagger_file
        }
    Please note that the name of the lambda function to be integrated will be derived
    via the provided lambda_funcname_format parameters:
    - the default lambda_funcname_format is a string with the following
      substitutable keys: "{stage}_{api}_{resource}_{method}".  The user can
      choose to reorder the known keys.
    - the stage key corresponds to the stage_name passed in.
    - the api key corresponds to the api_name passed in.
    - the resource corresponds to the resource path defined in the passed swagger file.
    - the method corresponds to the method for a resource path defined in the passed swagger file.
    For the default lambda_funcname_format, given the following input:
    .. code-block:: python
        api_name = '  Test    Service'
        stage_name = 'alpha'
        basePath = '/api'
        path = '/a/{b}/c'
        method = 'POST'
    We will end up with the following Lambda Function Name that will be looked
    up: 'test_service_alpha_a_b_c_post'
    The canconicalization of these input parameters is done in the following order:
    1. lambda_funcname_format is formatted with the input parameters as passed,
    2. resulting string is stripped for leading/trailing spaces,
    3. path parameter's curly braces are removed from the resource path,
    4. consecutive spaces and forward slashes in the paths are replaced with '_'
    5. consecutive '_' are replaced with '_'
    Please note that for error response handling, the swagger file must have an error response model
    with the following schema.  The lambda functions should throw exceptions for any non successful responses.
    An optional pattern field can be specified in errorMessage field to aid the response mapping from Lambda
    to the proper error return status codes.
    .. code-block:: yaml
        Error:
          type: object
          properties:
            stackTrace:
              type: array
              items:
                type: array
                items:
                  type: string
              description: call stack
          errorType:
            type: string
            description: error type
          errorMessage:
            type: string
            description: |
              Error message, will be matched based on pattern.
              If no pattern is specified, the default pattern used for response mapping will be +*.
    name
        The name of the state definition
    api_name
        The name of the rest api that we want to ensure exists in AWS API Gateway
    swagger_file
        Name of the location of the swagger rest api definition file in YAML format.
    stage_name
        Name of the stage we want to be associated with the given api_name and swagger_file
        definition
    api_key_required
        True or False - whether the API Key is required to call API methods
    lambda_integration_role
        The name or ARN of the IAM role that the AWS ApiGateway assumes when it
        executes your lambda function to handle incoming requests
    lambda_region
        The region where we expect to find the lambda functions.  This is used to
        determine the region where we should look for the Lambda Function for
        integration purposes.  The region determination is based on the following
        priority:
        1. lambda_region as passed in (is not None)
        2. if lambda_region is None, use the region as if a boto_lambda
           function were executed without explicitly specifying lambda region.
        3. if region determined in (2) is different than the region used by
           boto_apigateway functions, a final lookup will be attempted using
           the boto_apigateway region.
    stage_variables
        A dict with variables and their values, or a pillar key (string) that
        contains a dict with variables and their values.
        key and values in the dict must be strings.  {'string': 'string'}
    region
        Region to connect to.
    key
        Secret key to be used.
    keyid
        Access key to be used.
    profile
        A dict with region, key and keyid, or a pillar key (string) that
        contains a dict with region, key and keyid.
    lambda_funcname_format
        Please review the earlier example for the usage.  The only substituable keys in the funcname
        format are {stage}, {api}, {resource}, {method}.
        Any other keys or positional substitution parameters will be flagged as an invalid input.
    authorization_type
        This field can be either 'NONE', or 'AWS_IAM'.  This will be applied to all methods in the given
        swagger spec file.  Default is set to 'NONE'
    error_response_template
        String value that defines the response template mapping that should be applied in cases error occurs.
        Refer to AWS documentation for details: http://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-mapping-template-reference.html
        If set to None, the following default value is used:
        .. code-block:: text
            '#set($inputRoot = $input.path(\'$\'))\\n'
            '{\\n'
            '  "errorMessage" : "$inputRoot.errorMessage",\\n'
            '  "errorType" : "$inputRoot.errorType",\\n'
            '  "stackTrace" : [\\n'
            '#foreach($stackTrace in $inputRoot.stackTrace)\\n'
            '    [\\n'
            '#foreach($elem in $stackTrace)\\n'
            '      "$elem"\\n'
            '#if($foreach.hasNext),#end\\n'
            '#end\\n'
            '    ]\\n'
            '#if($foreach.hasNext),#end\\n'
            '#end\\n'
            '  ]\\n'
        .. versionadded:: 2017.7.0
    response_template
        String value that defines the response template mapping applied in case
        of success (including OPTIONS method) If set to None, empty ({})
        template is assumed, which will transfer response from the lambda
        function as is.
        .. versionadded:: 2017.7.0
    """
    ret = {"name": name, "result": True, "comment": "", "changes": {}}
    try:
        common_args = dict(
            [("region", region), ("key", key), ("keyid", keyid), ("profile", profile)]
        )
        swagger = _Swagger(
            api_name,
            stage_name,
            lambda_funcname_format,
            swagger_file,
            error_response_template,
            response_template,
            common_args,
        )
        stage_vars = _get_stage_variables(stage_variables)
        ret = swagger.verify_api(ret)
        if ret.get("publish"):
            if __opts__["test"]:
                ret["comment"] = (
                    "[stage: {}] will be reassociated to an already available "
                    "deployment that matched the given [api_name: {}] "
                    "and [swagger_file: {}].\n"
                    "Stage variables will be set "
                    "to {}.".format(stage_name, api_name, swagger_file, stage_vars)
                )
                ret["result"] = None
                return ret
            return swagger.publish_api(ret, stage_vars)
        if ret.get("current"):
            if __opts__["test"]:
                ret["comment"] = (
                    "[stage: {}] is already at desired state with an associated "
                    "deployment matching the given [api_name: {}] "
                    "and [swagger_file: {}].\n"
                    "Stage variables will be set "
                    "to {}.".format(stage_name, api_name, swagger_file, stage_vars)
                )
                ret["result"] = None
            return swagger.overwrite_stage_variables(ret, stage_vars)
        if __opts__["test"]:
            ret["comment"] = (
                "There is no deployment matching the given [api_name: {}] "
                "and [swagger_file: {}].  A new deployment will be "
                "created and the [stage_name: {}] will then be associated "
                "to the newly created deployment.\n"
                "Stage variables will be set "
                "to {}.".format(api_name, swagger_file, stage_name, stage_vars)
            )
            ret["result"] = None
            return ret
        ret = swagger.deploy_api(ret)
        if ret.get("abort"):
            return ret
        ret = swagger.deploy_models(ret)
        if ret.get("abort"):
            return ret
        ret = swagger.deploy_resources(
            ret,
            api_key_required=api_key_required,
            lambda_integration_role=lambda_integration_role,
            lambda_region=lambda_region,
            authorization_type=authorization_type,
        )
        if ret.get("abort"):
            return ret
        ret = swagger.publish_api(ret, stage_vars)
    except (ValueError, OSError) as e:
        ret["result"] = False
        ret["comment"] = "{}".format(e.args)
    return ret
def _get_stage_variables(stage_variables):
    """
    Helper function to retrieve stage variables from pillars/options, if the
    input is a string
    """
    ret = dict()
    if stage_variables is None:
        return ret
    if isinstance(stage_variables, str):
        if stage_variables in __opts__:
            ret = __opts__[stage_variables]
        master_opts = __pillar__.get("master", {})
        if stage_variables in master_opts:
            ret = master_opts[stage_variables]
        if stage_variables in __pillar__:
            ret = __pillar__[stage_variables]
    elif isinstance(stage_variables, dict):
        ret = stage_variables
    if not isinstance(ret, dict):
        ret = dict()
    return ret
def absent(
    name,
    api_name,
    stage_name,
    nuke_api=False,
    region=None,
    key=None,
    keyid=None,
    profile=None,
):
    """
    Ensure the stage_name associated with the given api_name deployed by boto_apigateway's
    present state is removed.  If the currently associated deployment to the given stage_name has
    no other stages associated with it, the deployment will also be removed.
    name
        Name of the swagger file in YAML format
    api_name
        Name of the rest api on AWS ApiGateway to ensure is absent.
    stage_name
        Name of the stage to be removed irrespective of the swagger file content.
        If the current deployment associated with the stage_name has no other stages associated
        with it, the deployment will also be removed.
    nuke_api
        If True, removes the API itself only if there are no other stages associated with any other
        deployments once the given stage_name is removed.
    region
        Region to connect to.
    key
        Secret key to be used.
    keyid
        Access key to be used.
    profile
        A dict with region, key and keyid, or a pillar key (string) that
        contains a dict with region, key and keyid.
    """
    ret = {"name": name, "result": True, "comment": "", "changes": {}}
    try:
        common_args = dict(
            [("region", region), ("key", key), ("keyid", keyid), ("profile", profile)]
        )
        swagger = _Swagger(api_name, stage_name, "", None, None, None, common_args)
        if not swagger.restApiId:
            ret["comment"] = "[Rest API: {}] does not exist.".format(api_name)
            return ret
        if __opts__["test"]:
            if nuke_api:
                ret["comment"] = (
                    "[stage: {}] will be deleted, if there are no other "
                    "active stages, the [api: {} will also be "
                    "deleted.".format(stage_name, api_name)
                )
            else:
                ret["comment"] = "[stage: {}] will be deleted.".format(stage_name)
            ret["result"] = None
            return ret
        ret = swagger.delete_stage(ret)
        if ret.get("abort"):
            return ret
        if nuke_api and swagger.no_more_deployments_remain():
            ret = swagger.delete_api(ret)
    except (ValueError, OSError) as e:
        ret["result"] = False
        ret["comment"] = "{}".format(e.args)
    return ret
def _gen_md5_filehash(fname, *args):
    """
    helper function to generate a md5 hash of the swagger definition file
    any extra argument passed to the function is converted to a string
    and participates in the hash calculation
    """
    _hash = hashlib.md5()
    with salt.utils.files.fopen(fname, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            _hash.update(chunk)
    for extra_arg in args:
        _hash.update(str(extra_arg).encode())
    return _hash.hexdigest()
def _dict_to_json_pretty(d, sort_keys=True):
    """
    helper function to generate pretty printed json output
    """
    return salt.utils.json.dumps(
        d, indent=4, separators=(",", ": "), sort_keys=sort_keys
    )
def _name_matches(name, matches):
    """
    Helper function to see if given name has any of the patterns in given matches
    """
    for m in matches:
        if name.endswith(m):
            return True
        if name.lower().endswith("_" + m.lower()):
            return True
        if name.lower() == m.lower():
            return True
    return False
def _object_reducer(
    o,
    names=(
        "id",
        "name",
        "path",
        "httpMethod",
        "statusCode",
        "Created",
        "Deleted",
        "Updated",
        "Flushed",
        "Associated",
        "Disassociated",
    ),
):
    """
    Helper function to reduce the amount of information that will be kept in the change log
    for API GW related return values
    """
    result = {}
    if isinstance(o, dict):
        for k, v in o.items():
            if isinstance(v, dict):
                reduced = v if k == "variables" else _object_reducer(v, names)
                if reduced or _name_matches(k, names):
                    result[k] = reduced
            elif isinstance(v, list):
                newlist = []
                for val in v:
                    reduced = _object_reducer(val, names)
                    if reduced or _name_matches(k, names):
                        newlist.append(reduced)
                if newlist:
                    result[k] = newlist
            else:
                if _name_matches(k, names):
                    result[k] = v
    return result
def _log_changes(ret, changekey, changevalue):
    """
    For logging create/update/delete operations to AWS ApiGateway
    """
    cl = ret["changes"].get("new", [])
    cl.append({changekey: _object_reducer(changevalue)})
    ret["changes"]["new"] = cl
    return ret
def _log_error_and_abort(ret, obj):
    """
    helper function to update errors in the return structure
    """
    ret["result"] = False
    ret["abort"] = True
    if "error" in obj:
        ret["comment"] = "{}".format(obj.get("error"))
    return ret
class _Swagger:
    """
    this is a helper class that holds the swagger definition file and the associated logic
    related to how to interpret the file and apply it to AWS Api Gateway.
    The main interface to the outside world is in deploy_api, deploy_models, and deploy_resources
    methods.
    """
    SWAGGER_OBJ_V2_FIELDS = (
        "swagger",
        "info",
        "host",
        "basePath",
        "schemes",
        "consumes",
        "produces",
        "paths",
        "definitions",
        "parameters",
        "responses",
        "securityDefinitions",
        "security",
        "tags",
        "externalDocs",
    )
    SWAGGER_OBJ_V2_FIELDS_REQUIRED = (
        "swagger",
        "info",
        "basePath",
        "schemes",
        "paths",
        "definitions",
    )
    SWAGGER_OPERATION_NAMES = (
        "get",
        "put",
        "post",
        "delete",
        "options",
        "head",
        "patch",
    )
    SWAGGER_VERSIONS_SUPPORTED = ("2.0",)
    VENDOR_EXT_PATTERN = re.compile("^x-")
    JSON_SCHEMA_DRAFT_4 = "http://json-schema.org/draft-04/schema#"
    REQUEST_TEMPLATE = {
        "application/json": (
            "#set($inputRoot = $input.path('$'))\n{\n\"header_params\" : {\n#set ($map"
            " = $input.params().header)\n#foreach( $param in $map.entrySet()"
            ' )\n"$param.key" : "$param.value" #if( $foreach.hasNext ),'
            ' #end\n#end\n},\n"query_params" : {\n#set ($map ='
            " $input.params().querystring)\n#foreach( $param in $map.entrySet()"
            ' )\n"$param.key" : "$param.value" #if( $foreach.hasNext ),'
            ' #end\n#end\n},\n"path_params" : {\n#set ($map ='
            " $input.params().path)\n#foreach( $param in $map.entrySet()"
            ' )\n"$param.key" : "$param.value" #if( $foreach.hasNext ),'
            ' #end\n#end\n},\n"apigw_context" : {\n"apiId":'
            ' "$context.apiId",\n"httpMethod": "$context.httpMethod",\n"requestId":'
            ' "$context.requestId",\n"resourceId":'
            ' "$context.resourceId",\n"resourcePath":'
            ' "$context.resourcePath",\n"stage": "$context.stage",\n"identity": {\n '
            ' "user":"$context.identity.user",\n '
            ' "userArn":"$context.identity.userArn",\n '
            ' "userAgent":"$context.identity.userAgent",\n '
            ' "sourceIp":"$context.identity.sourceIp",\n '
            ' "cognitoIdentityId":"$context.identity.cognitoIdentityId",\n '
            ' "cognitoIdentityPoolId":"$context.identity.cognitoIdentityPoolId",\n '
            ' "cognitoAuthenticationType":"$context.identity.cognitoAuthenticationType",\n'
            '  "cognitoAuthenticationProvider":["$util.escapeJavaScript($context.identity.cognitoAuthenticationProvider)"],\n'
            '  "caller":"$context.identity.caller",\n '
            ' "apiKey":"$context.identity.apiKey",\n '
            ' "accountId":"$context.identity.accountId"\n}\n},\n"body_params" :'
            " $input.json('$'),\n\"stage_variables\": {\n#foreach($variable in"
            ' $stageVariables.keySet())\n"$variable":'
            ' "$util.escapeJavaScript($stageVariables.get($variable))"\n#if($foreach.hasNext),'
            " #end\n#end\n}\n}"
        )
    }
    REQUEST_OPTION_TEMPLATE = {"application/json": '{"statusCode": 200}'}
    RESPONSE_TEMPLATE = {
        "application/json": (
            "#set($inputRoot = $input.path('$'))\n"
            "{\n"
            '  "errorMessage" : "$inputRoot.errorMessage",\n'
            '  "errorType" : "$inputRoot.errorType",\n'
            '  "stackTrace" : [\n'
            "#foreach($stackTrace in $inputRoot.stackTrace)\n"
            "    [\n"
            "#foreach($elem in $stackTrace)\n"
            '      "$elem"\n'
            "#if($foreach.hasNext),#end\n"
            "#end\n"
            "    ]\n"
            "#if($foreach.hasNext),#end\n"
            "#end\n"
            "  ]\n"
            "}"
        )
    }
    RESPONSE_OPTION_TEMPLATE = {}
    AWS_API_DESCRIPTION = _dict_to_json_pretty(
        {
            "provisioned_by": "Salt boto_apigateway.present State",
            "context": "See deployment or stage description",
        }
    )
    class SwaggerParameter:
        """
        This is a helper class for the Swagger Parameter Object
        """
        LOCATIONS = ("body", "query", "header", "path")
        def __init__(self, paramdict):
            self._paramdict = paramdict
        @property
        def location(self):
            """
            returns location in the swagger parameter object
            """
            _location = self._paramdict.get("in")
            if _location in _Swagger.SwaggerParameter.LOCATIONS:
                return _location
            raise ValueError(
                "Unsupported parameter location: {} in Parameter Object".format(
                    _location
                )
            )
        @property
        def name(self):
            """
            returns parameter name in the swagger parameter object
            """
            _name = self._paramdict.get("name")
            if _name:
                if self.location == "header":
                    return "method.request.header.{}".format(_name)
                elif self.location == "query":
                    return "method.request.querystring.{}".format(_name)
                elif self.location == "path":
                    return "method.request.path.{}".format(_name)
                return None
            raise ValueError(
                "Parameter must have a name: {}".format(
                    _dict_to_json_pretty(self._paramdict)
                )
            )
        @property
        def schema(self):
            """
            returns the name of the schema given the reference in the swagger parameter object
            """
            if self.location == "body":
                _schema = self._paramdict.get("schema")
                if _schema:
                    if "$ref" in _schema:
                        schema_name = _schema.get("$ref").split("/")[-1]
                        return schema_name
                    raise ValueError(
                        "Body parameter must have a JSON reference "
                        "to the schema definition due to Amazon API restrictions: {}".format(
                            self.name
                        )
                    )
                raise ValueError(
                    "Body parameter must have a schema: {}".format(self.name)
                )
            return None
    class SwaggerMethodResponse:
        """
        Helper class for Swagger Method Response Object
        """
        def __init__(self, r):
            self._r = r
        @property
        def schema(self):
            """
            returns the name of the schema given the reference in the swagger method response object
            """
            _schema = self._r.get("schema")
            if _schema:
                if "$ref" in _schema:
                    return _schema.get("$ref").split("/")[-1]
                raise ValueError(
                    "Method response must have a JSON reference "
                    "to the schema definition: {}".format(_schema)
                )
            return None
        @property
        def headers(self):
            """
            returns the headers dictionary in the method response object
            """
            _headers = self._r.get("headers", {})
            return _headers
    def __init__(
        self,
        api_name,
        stage_name,
        lambda_funcname_format,
        swagger_file_path,
        error_response_template,
        response_template,
        common_aws_args,
    ):
        self._api_name = api_name
        self._stage_name = stage_name
        self._lambda_funcname_format = lambda_funcname_format
        self._common_aws_args = common_aws_args
        self._restApiId = ""
        self._deploymentId = ""
        self._error_response_template = error_response_template
        self._response_template = response_template
        if swagger_file_path is not None:
            if os.path.exists(swagger_file_path) and os.path.isfile(swagger_file_path):
                self._swagger_file = swagger_file_path
                self._md5_filehash = _gen_md5_filehash(
                    self._swagger_file, error_response_template, response_template
                )
                with salt.utils.files.fopen(self._swagger_file, "rb") as sf:
                    self._cfg = salt.utils.yaml.safe_load(sf)
                self._swagger_version = ""
            else:
                raise OSError("Invalid swagger file path, {}".format(swagger_file_path))
            self._validate_swagger_file()
        self._validate_lambda_funcname_format()
        self._resolve_api_id()
    def _is_http_error_rescode(self, code):
        """
        Helper function to determine if the passed code is in the 400~599 range of http error
        codes
        """
        return bool(re.match(r"^\s*[45]\d\d\s*$", code))
    def _validate_error_response_model(self, paths, mods):
        """
        Helper function to help validate the convention established in the swagger file on how
        to handle response code mapping/integration
        """
        for path, ops in paths:
            for opname, opobj in ops.items():
                if opname not in _Swagger.SWAGGER_OPERATION_NAMES:
                    continue
                if "responses" not in opobj:
                    raise ValueError(
                        "missing mandatory responses field in path item object"
                    )
                for rescode, resobj in opobj.get("responses").items():
                    if not self._is_http_error_rescode(str(rescode)):
                        continue
                    if "schema" not in resobj:
                        raise ValueError(
                            "missing schema field in path {}, "
                            "op {}, response {}".format(path, opname, rescode)
                        )
                    schemaobj = resobj.get("schema")
                    if "$ref" not in schemaobj:
                        raise ValueError(
                            "missing $ref field under schema in "
                            "path {}, op {}, response {}".format(path, opname, rescode)
                        )
                    schemaobjref = schemaobj.get("$ref", "/")
                    modelname = schemaobjref.split("/")[-1]
                    if modelname not in mods:
                        raise ValueError(
                            "model schema {} reference not found "
                            "under /definitions".format(schemaobjref)
                        )
                    model = mods.get(modelname)
                    if model.get("type") != "object":
                        raise ValueError(
                            "model schema {} must be type object".format(modelname)
                        )
                    if "properties" not in model:
                        raise ValueError(
                            "model schema {} must have properties fields".format(
                                modelname
                            )
                        )
                    modelprops = model.get("properties")
                    if "errorMessage" not in modelprops:
                        raise ValueError(
                            "model schema {} must have errorMessage as a property to "
                            "match AWS convention. If pattern is not set, .+ will "
                            "be used".format(modelname)
                        )
    def _validate_lambda_funcname_format(self):
        """
        Checks if the lambda function name format contains only known elements
        :return: True on success, ValueError raised on error
        """
        try:
            if self._lambda_funcname_format:
                known_kwargs = dict(stage="", api="", resource="", method="")
                self._lambda_funcname_format.format(**known_kwargs)
            return True
        except Exception:  # pylint: disable=broad-except
            raise ValueError(
                "Invalid lambda_funcname_format {}.  Please review "
                "documentation for known substitutable keys".format(
                    self._lambda_funcname_format
                )
            )
    def _validate_swagger_file(self):
        """
        High level check/validation of the input swagger file based on
        https://github.com/swagger-api/swagger-spec/blob/master/versions/2.0.md
        This is not a full schema compliance check, but rather make sure that the input file (YAML or
        JSON) can be read into a dictionary, and we check for the content of the Swagger Object for version
        and info.
        """
        for field in self._cfg:
            if (
                field not in _Swagger.SWAGGER_OBJ_V2_FIELDS
                and not _Swagger.VENDOR_EXT_PATTERN.match(field)
            ):
                raise ValueError("Invalid Swagger Object Field: {}".format(field))
        for field in _Swagger.SWAGGER_OBJ_V2_FIELDS_REQUIRED:
            if field not in self._cfg:
                raise ValueError("Missing Swagger Object Field: {}".format(field))
        self._swagger_version = self._cfg.get("swagger")
        if self._swagger_version not in _Swagger.SWAGGER_VERSIONS_SUPPORTED:
            raise ValueError(
                "Unsupported Swagger version: {},Supported versions are {}".format(
                    self._swagger_version, _Swagger.SWAGGER_VERSIONS_SUPPORTED
                )
            )
        log.info(type(self._models))
        self._validate_error_response_model(self.paths, self._models())
    @property
    def md5_filehash(self):
        """
        returns md5 hash for the swagger file
        """
        return self._md5_filehash
    @property
    def info(self):
        """
        returns the swagger info object as a dictionary
        """
        info = self._cfg.get("info")
        if not info:
            raise ValueError("Info Object has no values")
        return info
    @property
    def info_json(self):
        """
        returns the swagger info object as a pretty printed json string.
        """
        return _dict_to_json_pretty(self.info)
    @property
    def rest_api_name(self):
        """
        returns the name of the api
        """
        return self._api_name
    @property
    def rest_api_version(self):
        """
        returns the version field in the swagger info object
        """
        version = self.info.get("version")
        if not version:
            raise ValueError("Missing version value in Info Object")
        return version
    def _models(self):
        """
        returns an iterator for the models specified in the swagger file
        """
        models = self._cfg.get("definitions")
        if not models:
            raise ValueError(
                "Definitions Object has no values, You need to define them in your"
                " swagger file"
            )
        return models
    def models(self):
        """
        generator to return the tuple of model and its schema to create on aws.
        """
        model_dict = self._build_all_dependencies()
        while True:
            model = self._get_model_without_dependencies(model_dict)
            if not model:
                break
            yield (model, self._models().get(model))
    @property
    def paths(self):
        """
        returns an iterator for the relative resource paths specified in the swagger file
        """
        paths = self._cfg.get("paths")
        if not paths:
            raise ValueError(
                "Paths Object has no values, You need to define them in your swagger"
                " file"
            )
        for path in paths:
            if not path.startswith("/"):
                raise ValueError(
                    "Path object {} should start with /. Please fix it".format(path)
                )
        return paths.items()
    @property
    def basePath(self):
        """
        returns the base path field as defined in the swagger file
        """
        basePath = self._cfg.get("basePath", "")
        return basePath
    @property
    def restApiId(self):
        """
        returns the rest api id as returned by AWS on creation of the rest api
        """
        return self._restApiId
    @restApiId.setter
    def restApiId(self, restApiId):
        """
        allows the assignment of the rest api id on creation of the rest api
        """
        self._restApiId = restApiId
    @property
    def deployment_label_json(self):
        """
        this property returns the unique description in pretty printed json for
        a particular api deployment
        """
        return _dict_to_json_pretty(self.deployment_label)
    @property
    def deployment_label(self):
        """
        this property returns the deployment label dictionary (mainly used by
        stage description)
        """
        label = dict()
        label["swagger_info_object"] = self.info
        label["api_name"] = self.rest_api_name
        label["swagger_file"] = os.path.basename(self._swagger_file)
        label["swagger_file_md5sum"] = self.md5_filehash
        return label
    def _one_or_more_stages_remain(self, deploymentId):
        """
        Helper function to find whether there are other stages still associated with a deployment
        """
        stages = __salt__["boto_apigateway.describe_api_stages"](
            restApiId=self.restApiId, deploymentId=deploymentId, **self._common_aws_args
        ).get("stages")
        return bool(stages)
    def no_more_deployments_remain(self):
        """
        Helper function to find whether there are deployments left with stages associated
        """
        no_more_deployments = True
        deployments = __salt__["boto_apigateway.describe_api_deployments"](
            restApiId=self.restApiId, **self._common_aws_args
        ).get("deployments")
        if deployments:
            for deployment in deployments:
                deploymentId = deployment.get("id")
                stages = __salt__["boto_apigateway.describe_api_stages"](
                    restApiId=self.restApiId,
                    deploymentId=deploymentId,
                    **self._common_aws_args
                ).get("stages")
                if stages:
                    no_more_deployments = False
                    break
        return no_more_deployments
    def _get_current_deployment_id(self):
        """
        Helper method to find the deployment id that the stage name is currently assocaited with.
        """
        deploymentId = ""
        stage = __salt__["boto_apigateway.describe_api_stage"](
            restApiId=self.restApiId,
            stageName=self._stage_name,
            **self._common_aws_args
        ).get("stage")
        if stage:
            deploymentId = stage.get("deploymentId")
        return deploymentId
    def _get_current_deployment_label(self):
        """
        Helper method to find the deployment label that the stage_name is currently associated with.
        """
        deploymentId = self._get_current_deployment_id()
        deployment = __salt__["boto_apigateway.describe_api_deployment"](
            restApiId=self.restApiId, deploymentId=deploymentId, **self._common_aws_args
        ).get("deployment")
        if deployment:
            return deployment.get("description")
        return None
    def _get_desired_deployment_id(self):
        """
        Helper method to return the deployment id matching the desired deployment label for
        this Swagger object based on the given api_name, swagger_file
        """
        deployments = __salt__["boto_apigateway.describe_api_deployments"](
            restApiId=self.restApiId, **self._common_aws_args
        ).get("deployments")
        if deployments:
            for deployment in deployments:
                if deployment.get("description") == self.deployment_label_json:
                    return deployment.get("id")
        return ""
    def overwrite_stage_variables(self, ret, stage_variables):
        """
        overwrite the given stage_name's stage variables with the given stage_variables
        """
        res = __salt__["boto_apigateway.overwrite_api_stage_variables"](
            restApiId=self.restApiId,
            stageName=self._stage_name,
            variables=stage_variables,
            **self._common_aws_args
        )
        if not res.get("overwrite"):
            ret["result"] = False
            ret["abort"] = True
            ret["comment"] = res.get("error")
        else:
            ret = _log_changes(ret, "overwrite_stage_variables", res.get("stage"))
        return ret
    def _set_current_deployment(self, stage_desc_json, stage_variables):
        """
        Helper method to associate the stage_name to the given deploymentId and make this current
        """
        stage = __salt__["boto_apigateway.describe_api_stage"](
            restApiId=self.restApiId,
            stageName=self._stage_name,
            **self._common_aws_args
        ).get("stage")
        if not stage:
            stage = __salt__["boto_apigateway.create_api_stage"](
                restApiId=self.restApiId,
                stageName=self._stage_name,
                deploymentId=self._deploymentId,
                description=stage_desc_json,
                variables=stage_variables,
                **self._common_aws_args
            )
            if not stage.get("stage"):
                return {"set": False, "error": stage.get("error")}
        else:
            overwrite = __salt__["boto_apigateway.overwrite_api_stage_variables"](
                restApiId=self.restApiId,
                stageName=self._stage_name,
                variables=stage_variables,
                **self._common_aws_args
            )
            if not overwrite.get("stage"):
                return {"set": False, "error": overwrite.get("error")}
        return __salt__["boto_apigateway.activate_api_deployment"](
            restApiId=self.restApiId,
            stageName=self._stage_name,
            deploymentId=self._deploymentId,
            **self._common_aws_args
        )
    def _resolve_api_id(self):
        """
        returns an Api Id that matches the given api_name and the hardcoded _Swagger.AWS_API_DESCRIPTION
        as the api description
        """
        apis = __salt__["boto_apigateway.describe_apis"](
            name=self.rest_api_name,
            description=_Swagger.AWS_API_DESCRIPTION,
            **self._common_aws_args
        ).get("restapi")
        if apis:
            if len(apis) == 1:
                self.restApiId = apis[0].get("id")
            else:
                raise ValueError(
                    "Multiple APIs matching given name {} and description {}".format(
                        self.rest_api_name, self.info_json
                    )
                )
    def delete_stage(self, ret):
        """
        Method to delete the given stage_name.  If the current deployment tied to the given
        stage_name has no other stages associated with it, the deployment will be removed
        as well
        """
        deploymentId = self._get_current_deployment_id()
        if deploymentId:
            result = __salt__["boto_apigateway.delete_api_stage"](
                restApiId=self.restApiId,
                stageName=self._stage_name,
                **self._common_aws_args
            )
            if not result.get("deleted"):
                ret["abort"] = True
                ret["result"] = False
                ret["comment"] = "delete_stage delete_api_stage, {}".format(
                    result.get("error")
                )
            else:
                if not self._one_or_more_stages_remain(deploymentId):
                    result = __salt__["boto_apigateway.delete_api_deployment"](
                        restApiId=self.restApiId,
                        deploymentId=deploymentId,
                        **self._common_aws_args
                    )
                    if not result.get("deleted"):
                        ret["abort"] = True
                        ret["result"] = False
                        ret[
                            "comment"
                        ] = "delete_stage delete_api_deployment, {}".format(
                            result.get("error")
                        )
                else:
                    ret["comment"] = "stage {} has been deleted.\n".format(
                        self._stage_name
                    )
        else:
            ret["comment"] = "stage {} does not exist".format(self._stage_name)
        return ret
    def verify_api(self, ret):
        """
        this method helps determine if the given stage_name is already on a deployment
        label matching the input api_name, swagger_file.
        If yes, returns abort with comment indicating already at desired state.
        If not and there is previous deployment labels in AWS matching the given input api_name and
        swagger file, indicate to the caller that we only need to reassociate stage_name to the
        previously existing deployment label.
        """
        if self.restApiId:
            deployed_label_json = self._get_current_deployment_label()
            if deployed_label_json == self.deployment_label_json:
                ret["comment"] = (
                    "Already at desired state, the stage {} is already at the desired "
                    "deployment label:\n{}".format(
                        self._stage_name, deployed_label_json
                    )
                )
                ret["current"] = True
                return ret
            else:
                self._deploymentId = self._get_desired_deployment_id()
                if self._deploymentId:
                    ret["publish"] = True
        return ret
    def publish_api(self, ret, stage_variables):
        """
        this method tie the given stage_name to a deployment matching the given swagger_file
        """
        stage_desc = dict()
        stage_desc["current_deployment_label"] = self.deployment_label
        stage_desc_json = _dict_to_json_pretty(stage_desc)
        if self._deploymentId:
            res = self._set_current_deployment(stage_desc_json, stage_variables)
            if not res.get("set"):
                ret["abort"] = True
                ret["result"] = False
                ret["comment"] = res.get("error")
            else:
                ret = _log_changes(
                    ret,
                    "publish_api (reassociate deployment, set stage_variables)",
                    res.get("response"),
                )
        else:
            res = __salt__["boto_apigateway.create_api_deployment"](
                restApiId=self.restApiId,
                stageName=self._stage_name,
                stageDescription=stage_desc_json,
                description=self.deployment_label_json,
                variables=stage_variables,
                **self._common_aws_args
            )
            if not res.get("created"):
                ret["abort"] = True
                ret["result"] = False
                ret["comment"] = res.get("error")
            else:
                ret = _log_changes(
                    ret, "publish_api (new deployment)", res.get("deployment")
                )
        return ret
    def _cleanup_api(self):
        """
        Helper method to clean up resources and models if we detected a change in the swagger file
        for a stage
        """
        resources = __salt__["boto_apigateway.describe_api_resources"](
            restApiId=self.restApiId, **self._common_aws_args
        )
        if resources.get("resources"):
            res = resources.get("resources")[1:]
            res.reverse()
            for resource in res:
                delres = __salt__["boto_apigateway.delete_api_resources"](
                    restApiId=self.restApiId,
                    path=resource.get("path"),
                    **self._common_aws_args
                )
                if not delres.get("deleted"):
                    return delres
        models = __salt__["boto_apigateway.describe_api_models"](
            restApiId=self.restApiId, **self._common_aws_args
        )
        if models.get("models"):
            for model in models.get("models"):
                delres = __salt__["boto_apigateway.delete_api_model"](
                    restApiId=self.restApiId,
                    modelName=model.get("name"),
                    **self._common_aws_args
                )
                if not delres.get("deleted"):
                    return delres
        return {"deleted": True}
    def deploy_api(self, ret):
        """
        this method create the top level rest api in AWS apigateway
        """
        if self.restApiId:
            res = self._cleanup_api()
            if not res.get("deleted"):
                ret["comment"] = "Failed to cleanup restAreId {}".format(self.restApiId)
                ret["abort"] = True
                ret["result"] = False
                return ret
            return ret
        response = __salt__["boto_apigateway.create_api"](
            name=self.rest_api_name,
            description=_Swagger.AWS_API_DESCRIPTION,
            **self._common_aws_args
        )
        if not response.get("created"):
            ret["result"] = False
            ret["abort"] = True
            if "error" in response:
                ret["comment"] = "Failed to create rest api: {}.".format(
                    response["error"]["message"]
                )
            return ret
        self.restApiId = response.get("restapi", {}).get("id")
        return _log_changes(ret, "deploy_api", response.get("restapi"))
    def delete_api(self, ret):
        """
        Method to delete a Rest Api named defined in the swagger file's Info Object's title value.
        ret
            a dictionary for returning status to Saltstack
        """
        exists_response = __salt__["boto_apigateway.api_exists"](
            name=self.rest_api_name,
            description=_Swagger.AWS_API_DESCRIPTION,
            **self._common_aws_args
        )
        if exists_response.get("exists"):
            if __opts__["test"]:
                ret["comment"] = "Rest API named {} is set to be deleted.".format(
                    self.rest_api_name
                )
                ret["result"] = None
                ret["abort"] = True
                return ret
            delete_api_response = __salt__["boto_apigateway.delete_api"](
                name=self.rest_api_name,
                description=_Swagger.AWS_API_DESCRIPTION,
                **self._common_aws_args
            )
            if not delete_api_response.get("deleted"):
                ret["result"] = False
                ret["abort"] = True
                if "error" in delete_api_response:
                    ret["comment"] = "Failed to delete rest api: {}.".format(
                        delete_api_response["error"]["message"]
                    )
                return ret
            ret = _log_changes(ret, "delete_api", delete_api_response)
        else:
            ret["comment"] = "api already absent for swagger file: {}, desc: {}".format(
                self.rest_api_name, self.info_json
            )
        return ret
    def _aws_model_ref_from_swagger_ref(self, r):
        """
        Helper function to reference models created on aws apigw
        """
        model_name = r.split("/")[-1]
        return "https://apigateway.amazonaws.com/restapis/{}/models/{}".format(
            self.restApiId, model_name
        )
    def _update_schema_to_aws_notation(self, schema):
        """
        Helper function to map model schema to aws notation
        """
        result = {}
        for k, v in schema.items():
            if k == "$ref":
                v = self._aws_model_ref_from_swagger_ref(v)
            if isinstance(v, dict):
                v = self._update_schema_to_aws_notation(v)
            result[k] = v
        return result
    def _build_dependent_model_list(self, obj_schema):
        """
        Helper function to build the list of models the given object schema is referencing.
        """
        dep_models_list = []
        if obj_schema:
            obj_schema["type"] = obj_schema.get("type", "object")
        if obj_schema["type"] == "array":
            dep_models_list.extend(
                self._build_dependent_model_list(obj_schema.get("items", {}))
            )
        else:
            ref = obj_schema.get("$ref")
            if ref:
                ref_obj_model = ref.split("/")[-1]
                ref_obj_schema = self._models().get(ref_obj_model)
                dep_models_list.extend(self._build_dependent_model_list(ref_obj_schema))
                dep_models_list.extend([ref_obj_model])
            else:
                properties = obj_schema.get("properties")
                if properties:
                    for _, prop_obj_schema in properties.items():
                        dep_models_list.extend(
                            self._build_dependent_model_list(prop_obj_schema)
                        )
        return list(set(dep_models_list))
    def _build_all_dependencies(self):
        """
        Helper function to build a map of model to their list of model reference dependencies
        """
        ret = {}
        for model, schema in self._models().items():
            dep_list = self._build_dependent_model_list(schema)
            ret[model] = dep_list
        return ret
    def _get_model_without_dependencies(self, models_dict):
        """
        Helper function to find the next model that should be created
        """
        next_model = None
        if not models_dict:
            return next_model
        for model, dependencies in models_dict.items():
            if dependencies == []:
                next_model = model
                break
        if next_model is None:
            raise ValueError(
                "incomplete model definitions, models in dependency "
                "list not defined: {}".format(models_dict)
            )
        models_dict.pop(next_model)
        for model, dep_list in models_dict.items():
            if next_model in dep_list:
                dep_list.remove(next_model)
        return next_model
    def deploy_models(self, ret):
        """
        Method to deploy swagger file's definition objects and associated schema to AWS Apigateway as Models
        ret
            a dictionary for returning status to Saltstack
        """
        for model, schema in self.models():
            _schema = self._update_schema_to_aws_notation(schema)
            _schema.update(
                {
                    "$schema": _Swagger.JSON_SCHEMA_DRAFT_4,
                    "title": "{} Schema".format(model),
                }
            )
            model_exists_response = __salt__["boto_apigateway.api_model_exists"](
                restApiId=self.restApiId, modelName=model, **self._common_aws_args
            )
            if model_exists_response.get("exists"):
                update_model_schema_response = __salt__[
                    "boto_apigateway.update_api_model_schema"
                ](
                    restApiId=self.restApiId,
                    modelName=model,
                    schema=_dict_to_json_pretty(_schema),
                    **self._common_aws_args
                )
                if not update_model_schema_response.get("updated"):
                    ret["result"] = False
                    ret["abort"] = True
                    if "error" in update_model_schema_response:
                        ret[
                            "comment"
                        ] = "Failed to update existing model {} with schema {}, " "error: {}".format(
                            model,
                            _dict_to_json_pretty(schema),
                            update_model_schema_response["error"]["message"],
                        )
                    return ret
                ret = _log_changes(ret, "deploy_models", update_model_schema_response)
            else:
                create_model_response = __salt__["boto_apigateway.create_api_model"](
                    restApiId=self.restApiId,
                    modelName=model,
                    modelDescription=model,
                    schema=_dict_to_json_pretty(_schema),
                    contentType="application/json",
                    **self._common_aws_args
                )
                if not create_model_response.get("created"):
                    ret["result"] = False
                    ret["abort"] = True
                    if "error" in create_model_response:
                        ret[
                            "comment"
                        ] = "Failed to create model {}, schema {}, error: {}".format(
                            model,
                            _dict_to_json_pretty(schema),
                            create_model_response["error"]["message"],
                        )
                    return ret
                ret = _log_changes(ret, "deploy_models", create_model_response)
        return ret
    def _lambda_name(self, resourcePath, httpMethod):
        """
        Helper method to construct lambda name based on the rule specified in doc string of
        boto_apigateway.api_present function
        """
        lambda_name = self._lambda_funcname_format.format(
            stage=self._stage_name,
            api=self.rest_api_name,
            resource=resourcePath,
            method=httpMethod,
        )
        lambda_name = lambda_name.strip()
        lambda_name = re.sub(r"{|}", "", lambda_name)
        lambda_name = re.sub(r"\s+|/", "_", lambda_name).lower()
        return re.sub(r"_+", "_", lambda_name)
    def _lambda_uri(self, lambda_name, lambda_region):
        """
        Helper Method to construct the lambda uri for use in method integration
        """
        profile = self._common_aws_args.get("profile")
        region = self._common_aws_args.get("region")
        lambda_region = __utils__["boto3.get_region"]("lambda", lambda_region, profile)
        apigw_region = __utils__["boto3.get_region"]("apigateway", region, profile)
        lambda_desc = __salt__["boto_lambda.describe_function"](
            lambda_name, **self._common_aws_args
        )
        if lambda_region != apigw_region:
            if not lambda_desc.get("function"):
                lambda_desc = __salt__["boto_lambda.describe_function"](
                    lambda_name, **self._common_aws_args
                )
        if not lambda_desc.get("function"):
            raise ValueError(
                "Could not find lambda function {} in regions [{}, {}].".format(
                    lambda_name, lambda_region, apigw_region
                )
            )
        lambda_arn = lambda_desc.get("function").get("FunctionArn")
        lambda_uri = (
            "arn:aws:apigateway:{}:lambda:path/2015-03-31"
            "/functions/{}/invocations".format(apigw_region, lambda_arn)
        )
        return lambda_uri
    def _parse_method_data(self, method_name, method_data):
        """
        Helper function to construct the method request params, models, request_templates and
        integration_type values needed to configure method request integration/mappings.
        """
        method_params = {}
        method_models = {}
        if "parameters" in method_data:
            for param in method_data["parameters"]:
                p = _Swagger.SwaggerParameter(param)
                if p.name:
                    method_params[p.name] = True
                if p.schema:
                    method_models["application/json"] = p.schema
        request_templates = (
            _Swagger.REQUEST_OPTION_TEMPLATE
            if method_name == "options"
            else _Swagger.REQUEST_TEMPLATE
        )
        integration_type = "MOCK" if method_name == "options" else "AWS"
        return {
            "params": method_params,
            "models": method_models,
            "request_templates": request_templates,
            "integration_type": integration_type,
        }
    def _find_patterns(self, o):
        result = []
        if isinstance(o, dict):
            for k, v in o.items():
                if isinstance(v, dict):
                    result.extend(self._find_patterns(v))
                else:
                    if k == "pattern":
                        result.append(v)
        return result
    def _get_pattern_for_schema(self, schema_name, httpStatus):
        """
        returns the pattern specified in a response schema
        """
        defaultPattern = ".+" if self._is_http_error_rescode(httpStatus) else ".*"
        model = self._models().get(schema_name)
        patterns = self._find_patterns(model)
        return patterns[0] if patterns else defaultPattern
    def _get_response_template(self, method_name, http_status):
        if method_name == "options" or not self._is_http_error_rescode(http_status):
            response_templates = (
                {"application/json": self._response_template}
                if self._response_template
                else self.RESPONSE_OPTION_TEMPLATE
            )
        else:
            response_templates = (
                {"application/json": self._error_response_template}
                if self._error_response_template
                else self.RESPONSE_TEMPLATE
            )
        return response_templates
    def _parse_method_response(self, method_name, method_response, httpStatus):
        """
        Helper function to construct the method response params, models, and integration_params
        values needed to configure method response integration/mappings.
        """
        method_response_models = {}
        method_response_pattern = ".*"
        if method_response.schema:
            method_response_models["application/json"] = method_response.schema
            method_response_pattern = self._get_pattern_for_schema(
                method_response.schema, httpStatus
            )
        method_response_params = {}
        method_integration_response_params = {}
        for header in method_response.headers:
            response_header = "method.response.header.{}".format(header)
            method_response_params[response_header] = False
            header_data = method_response.headers.get(header)
            method_integration_response_params[response_header] = (
                "'{}'".format(header_data.get("default"))
                if "default" in header_data
                else "'*'"
            )
        response_templates = self._get_response_template(method_name, httpStatus)
        return {
            "params": method_response_params,
            "models": method_response_models,
            "integration_params": method_integration_response_params,
            "pattern": method_response_pattern,
            "response_templates": response_templates,
        }
    def _deploy_method(
        self,
        ret,
        resource_path,
        method_name,
        method_data,
        api_key_required,
        lambda_integration_role,
        lambda_region,
        authorization_type,
    ):
        """
        Method to create a method for the given resource path, along with its associated
        request and response integrations.
        ret
            a dictionary for returning status to Saltstack
        resource_path
            the full resource path where the named method_name will be associated with.
        method_name
            a string that is one of the following values: 'delete', 'get', 'head', 'options',
            'patch', 'post', 'put'
        method_data
            the value dictionary for this method in the swagger definition file.
        api_key_required
            True or False, whether api key is required to access this method.
        lambda_integration_role
            name of the IAM role or IAM role arn that Api Gateway will assume when executing
            the associated lambda function
        lambda_region
            the region for the lambda function that Api Gateway will integrate to.
        authorization_type
            'NONE' or 'AWS_IAM'
        """
        method = self._parse_method_data(method_name.lower(), method_data)
        if method_name.lower() == "options":
            api_key_required = False
            authorization_type = "NONE"
        m = __salt__["boto_apigateway.create_api_method"](
            restApiId=self.restApiId,
            resourcePath=resource_path,
            httpMethod=method_name.upper(),
            authorizationType=authorization_type,
            apiKeyRequired=api_key_required,
            requestParameters=method.get("params"),
            requestModels=method.get("models"),
            **self._common_aws_args
        )
        if not m.get("created"):
            ret = _log_error_and_abort(ret, m)
            return ret
        ret = _log_changes(ret, "_deploy_method.create_api_method", m)
        lambda_uri = ""
        if method_name.lower() != "options":
            lambda_uri = self._lambda_uri(
                self._lambda_name(resource_path, method_name),
                lambda_region=lambda_region,
            )
        integration = __salt__["boto_apigateway.create_api_integration"](
            restApiId=self.restApiId,
            resourcePath=resource_path,
            httpMethod=method_name.upper(),
            integrationType=method.get("integration_type"),
            integrationHttpMethod="POST",
            uri=lambda_uri,
            credentials=lambda_integration_role,
            requestTemplates=method.get("request_templates"),
            **self._common_aws_args
        )
        if not integration.get("created"):
            ret = _log_error_and_abort(ret, integration)
            return ret
        ret = _log_changes(ret, "_deploy_method.create_api_integration", integration)
        if "responses" in method_data:
            for response, response_data in method_data["responses"].items():
                httpStatus = str(response)
                method_response = self._parse_method_response(
                    method_name.lower(),
                    _Swagger.SwaggerMethodResponse(response_data),
                    httpStatus,
                )
                mr = __salt__["boto_apigateway.create_api_method_response"](
                    restApiId=self.restApiId,
                    resourcePath=resource_path,
                    httpMethod=method_name.upper(),
                    statusCode=httpStatus,
                    responseParameters=method_response.get("params"),
                    responseModels=method_response.get("models"),
                    **self._common_aws_args
                )
                if not mr.get("created"):
                    ret = _log_error_and_abort(ret, mr)
                    return ret
                ret = _log_changes(ret, "_deploy_method.create_api_method_response", mr)
                mir = __salt__["boto_apigateway.create_api_integration_response"](
                    restApiId=self.restApiId,
                    resourcePath=resource_path,
                    httpMethod=method_name.upper(),
                    statusCode=httpStatus,
                    selectionPattern=method_response.get("pattern"),
                    responseParameters=method_response.get("integration_params"),
                    responseTemplates=method_response.get("response_templates"),
                    **self._common_aws_args
                )
                if not mir.get("created"):
                    ret = _log_error_and_abort(ret, mir)
                    return ret
                ret = _log_changes(
                    ret, "_deploy_method.create_api_integration_response", mir
                )
        else:
            raise ValueError(
                "No responses specified for {} {}".format(resource_path, method_name)
            )
        return ret
    def deploy_resources(
        self,
        ret,
        api_key_required,
        lambda_integration_role,
        lambda_region,
        authorization_type,
    ):
        """
        Method to deploy resources defined in the swagger file.
        ret
            a dictionary for returning status to Saltstack
        api_key_required
            True or False, whether api key is required to access this method.
        lambda_integration_role
            name of the IAM role or IAM role arn that Api Gateway will assume when executing
            the associated lambda function
        lambda_region
            the region for the lambda function that Api Gateway will integrate to.
        authorization_type
            'NONE' or 'AWS_IAM'
        """
        for path, pathData in self.paths:
            resource = __salt__["boto_apigateway.create_api_resources"](
                restApiId=self.restApiId, path=path, **self._common_aws_args
            )
            if not resource.get("created"):
                ret = _log_error_and_abort(ret, resource)
                return ret
            ret = _log_changes(ret, "deploy_resources", resource)
            for method, method_data in pathData.items():
                if method in _Swagger.SWAGGER_OPERATION_NAMES:
                    ret = self._deploy_method(
                        ret,
                        path,
                        method,
                        method_data,
                        api_key_required,
                        lambda_integration_role,
                        lambda_region,
                        authorization_type,
                    )
        return ret
def usage_plan_present(
    name,
    plan_name,
    description=None,
    throttle=None,
    quota=None,
    region=None,
    key=None,
    keyid=None,
    profile=None,
):
    """
    Ensure the spcifieda usage plan with the corresponding metrics is deployed
    .. versionadded:: 2017.7.0
    name
        name of the state
    plan_name
        [Required] name of the usage plan
    throttle
        [Optional] throttling parameters expressed as a dictionary.
        If provided, at least one of the throttling parameters must be present
        rateLimit
            rate per second at which capacity bucket is populated
        burstLimit
            maximum rate allowed
    quota
        [Optional] quota on the number of api calls permitted by the plan.
        If provided, limit and period must be present
        limit
            [Required] number of calls permitted per quota period
        offset
            [Optional] number of calls to be subtracted from the limit at the beginning of the period
        period
            [Required] period to which quota applies. Must be DAY, WEEK or MONTH
    .. code-block:: yaml
        UsagePlanPresent:
          boto_apigateway.usage_plan_present:
            - plan_name: my_usage_plan
            - throttle:
                rateLimit: 70
                burstLimit: 100
            - quota:
                limit: 1000
                offset: 0
                period: DAY
            - profile: my_profile
    """
    func_params = locals()
    ret = {"name": name, "result": True, "comment": "", "changes": {}}
    try:
        common_args = dict(
            [("region", region), ("key", key), ("keyid", keyid), ("profile", profile)]
        )
        existing = __salt__["boto_apigateway.describe_usage_plans"](
            name=plan_name, **common_args
        )
        if "error" in existing:
            ret["result"] = False
            ret["comment"] = "Failed to describe existing usage plans"
            return ret
        if not existing["plans"]:
            if __opts__["test"]:
                ret["comment"] = "a new usage plan {} would be created".format(
                    plan_name
                )
                ret["result"] = None
                return ret
            result = __salt__["boto_apigateway.create_usage_plan"](
                name=plan_name,
                description=description,
                throttle=throttle,
                quota=quota,
                **common_args
            )
            if "error" in result:
                ret["result"] = False
                ret["comment"] = "Failed to create a usage plan {}, {}".format(
                    plan_name, result["error"]
                )
                return ret
            ret["changes"]["old"] = {"plan": None}
            ret["comment"] = "A new usage plan {} has been created".format(plan_name)
        else:
            plan = existing["plans"][0]
            needs_updating = False
            modifiable_params = (
                ("throttle", ("rateLimit", "burstLimit")),
                ("quota", ("limit", "offset", "period")),
            )
            for p, fields in modifiable_params:
                for f in fields:
                    actual_param = (
                        {} if func_params.get(p) is None else func_params.get(p)
                    )
                    if plan.get(p, {}).get(f, None) != actual_param.get(f, None):
                        needs_updating = True
            if not needs_updating:
                ret<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>["comment"] = "usage plan {} is already in a correct state".format(
                    plan_name
                )
                ret["result"] = True
                return ret
            if __opts__["test"]:
                ret["comment"] =</b></font> "a new usage plan {} would be updated".format(
                    plan_name
                )
                ret["result"] = None
                return ret
            result = __salt__["boto_apigateway.update_usage_plan"](
                plan["id"], throttle=throttle, quota=quota, **common_args
            )
            if "error" in result:
                ret["result"] = False
                ret["comment"] = "Failed to update a usage plan {}, {}".format(
                    plan_name, result["error"]
                )
                return ret
            ret["changes"]["old"] = {"plan": plan}
            ret["comment"] = "usage plan {} has been updated".format(plan_name)
        newstate = __salt__["boto_apigateway.describe_usage_plans"](
            name=plan_name, **common_args
        )
        if "error" in existing:
            ret["result"] = False
            ret["comment"] = "Failed to describe existing usage plans after updates"
            return ret
        ret["changes"]["new"] = {"plan": newstate["plans"][0]}
    except (ValueError, OSError) as e:
        ret["result"] = False
        ret["comment"] = "{}".format(e.args)
    return ret
def usage_plan_absent(name, plan_name, region=None, key=None, keyid=None, profile=None):
    """
    Ensures usage plan identified by name is no longer present
    .. versionadded:: 2017.7.0
    name
        name of the state
    plan_name
        name of the plan to remove
    .. code-block:: yaml
        usage plan absent:
          boto_apigateway.usage_plan_absent:
            - plan_name: my_usage_plan
            - profile: my_profile
    """
    ret = {"name": name, "result": True, "comment": "", "changes": {}}
    try:
        common_args = dict(
            [("region", region), ("key", key), ("keyid", keyid), ("profile", profile)]
        )
        existing = __salt__["boto_apigateway.describe_usage_plans"](
            name=plan_name, **common_args
        )
        if "error" in existing:
            ret["result"] = False
            ret["comment"] = "Failed to describe existing usage plans"
            return ret
        if not existing["plans"]:
            ret["comment"] = "Usage plan {} does not exist already".format(plan_name)
            return ret
        if __opts__["test"]:
            ret["comment"] = "Usage plan {} exists and would be deleted".format(
                plan_name
            )
            ret["result"] = None
            return ret
        plan_id = existing["plans"][0]["id"]
        result = __salt__["boto_apigateway.delete_usage_plan"](plan_id, **common_args)
        if "error" in result:
            ret["result"] = False
            ret["comment"] = "Failed to delete usage plan {}, {}".format(
                plan_name, result
            )
            return ret
        ret["comment"] = "Usage plan {} has been deleted".format(plan_name)
        ret["changes"]["old"] = {"plan": existing["plans"][0]}
        ret["changes"]["new"] = {"plan": None}
    except (ValueError, OSError) as e:
        ret["result"] = False
        ret["comment"] = "{}".format(e.args)
    return ret
def usage_plan_association_present(
    name, plan_name, api_stages, region=None, key=None, keyid=None, profile=None
):
    """
    Ensures usage plan identified by name is added to provided api_stages
    .. versionadded:: 2017.7.0
    name
        name of the state
    plan_name
        name of the plan to use
    api_stages
        list of dictionaries, where each dictionary consists of the following keys:
        apiId
            apiId of the api to attach usage plan to
        stage
            stage name of the api to attach usage plan to
    .. code-block:: yaml
        UsagePlanAssociationPresent:
          boto_apigateway.usage_plan_association_present:
            - plan_name: my_plan
            - api_stages:
              - apiId: 9kb0404ec0
                stage: my_stage
              - apiId: l9v7o2aj90
                stage: my_stage
            - profile: my_profile
    """
    ret = {"name": name, "result": True, "comment": "", "changes": {}}
    try:
        common_args = dict(
            [("region", region), ("key", key), ("keyid", keyid), ("profile", profile)]
        )
        existing = __salt__["boto_apigateway.describe_usage_plans"](
            name=plan_name, **common_args
        )
        if "error" in existing:
            ret["result"] = False
            ret["comment"] = "Failed to describe existing usage plans"
            return ret
        if not existing["plans"]:
            ret["comment"] = "Usage plan {} does not exist".format(plan_name)
            ret["result"] = False
            return ret
        if len(existing["plans"]) != 1:
            ret["comment"] = (
                "There are multiple usage plans with the same name - it is not"
                " supported"
            )
            ret["result"] = False
            return ret
        plan = existing["plans"][0]
        plan_id = plan["id"]
        plan_stages = plan.get("apiStages", [])
        stages_to_add = []
        for api in api_stages:
            if api not in plan_stages:
                stages_to_add.append(api)
        if not stages_to_add:
            ret["comment"] = "Usage plan is already asssociated to all api stages"
            return ret
        result = __salt__["boto_apigateway.attach_usage_plan_to_apis"](
            plan_id, stages_to_add, **common_args
        )
        if "error" in result:
            ret[
                "comment"
            ] = "Failed to associate a usage plan {} to the apis {}, {}".format(
                plan_name, stages_to_add, result["error"]
            )
            ret["result"] = False
            return ret
        ret["comment"] = "successfully associated usage plan to apis"
        ret["changes"]["old"] = plan_stages
        ret["changes"]["new"] = result.get("result", {}).get("apiStages", [])
    except (ValueError, OSError) as e:
        ret["result"] = False
        ret["comment"] = "{}".format(e.args)
    return ret
def usage_plan_association_absent(
    name, plan_name, api_stages, region=None, key=None, keyid=None, profile=None
):
    """
    Ensures usage plan identified by name is removed from provided api_stages
    If a plan is associated to stages not listed in api_stages parameter,
    those associations remain intact.
    .. versionadded:: 2017.7.0
    name
        name of the state
    plan_name
        name of the plan to use
    api_stages
        list of dictionaries, where each dictionary consists of the following keys:
        apiId
            apiId of the api to detach usage plan from
        stage
            stage name of the api to detach usage plan from
    .. code-block:: yaml
        UsagePlanAssociationAbsent:
          boto_apigateway.usage_plan_association_absent:
            - plan_name: my_plan
            - api_stages:
              - apiId: 9kb0404ec0
                stage: my_stage
              - apiId: l9v7o2aj90
                stage: my_stage
            - profile: my_profile
    """
    ret = {"name": name, "result": True, "comment": "", "changes": {}}
    try:
        common_args = dict(
            [("region", region), ("key", key), ("keyid", keyid), ("profile", profile)]
        )
        existing = __salt__["boto_apigateway.describe_usage_plans"](
            name=plan_name, **common_args
        )
        if "error" in existing:
            ret["result"] = False
            ret["comment"] = "Failed to describe existing usage plans"
            return ret
        if not existing["plans"]:
            ret["comment"] = "Usage plan {} does not exist".format(plan_name)
            ret["result"] = False
            return ret
        if len(existing["plans"]) != 1:
            ret["comment"] = (
                "There are multiple usage plans with the same name - it is not"
                " supported"
            )
            ret["result"] = False
            return ret
        plan = existing["plans"][0]
        plan_id = plan["id"]
        plan_stages = plan.get("apiStages", [])
        if not plan_stages:
            ret["comment"] = "Usage plan {} has no associated stages already".format(
                plan_name
            )
            return ret
        stages_to_remove = []
        for api in api_stages:
            if api in plan_stages:
                stages_to_remove.append(api)
        if not stages_to_remove:
            ret["comment"] = "Usage plan is already not asssociated to any api stages"
            return ret
        result = __salt__["boto_apigateway.detach_usage_plan_from_apis"](
            plan_id, stages_to_remove, **common_args
        )
        if "error" in result:
            ret[
                "comment"
            ] = "Failed to disassociate a usage plan {} from the apis {}, {}".format(
                plan_name, stages_to_remove, result["error"]
            )
            ret["result"] = False
            return ret
        ret["comment"] = "successfully disassociated usage plan from apis"
        ret["changes"]["old"] = plan_stages
        ret["changes"]["new"] = result.get("result", {}).get("apiStages", [])
    except (ValueError, OSError) as e:
        ret["result"] = False
        ret["comment"] = "{}".format(e.args)
    return ret
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>junos_1.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
"""
Module to interact with Junos devices.
:maturity: new
:dependencies: junos-eznc, jxmlease
.. note::
    Those who wish to use junos-eznc (PyEZ) version &gt;= 2.1.0, must
    use the latest salt code from github until the next release.
Refer to :mod:`junos &lt;salt.proxy.junos&gt;` for information on connecting to junos proxy.
"""
import copy
import json
import logging
import os
import re
from functools import wraps
import salt.utils.args
import salt.utils.files
import salt.utils.json
import salt.utils.path
import salt.utils.platform
import salt.utils.stringutils
import yaml
try:
    from lxml import etree
except ImportError:
    import xml.etree.ElementTree as etree
try:
    import jnpr.junos.cfg
    import jnpr.junos.op as tables_dir
    import jnpr.junos.utils
    import jxmlease
    import yamlordereddictloader
    from jnpr.junos import Device
    from jnpr.junos.exception import (
        ConnectClosedError,
        LockError,
        RpcTimeoutError,
        UnlockError,
    )
    from jnpr.junos.factory.cfgtable import CfgTable
    from jnpr.junos.factory.factory_loader import FactoryLoader
    from jnpr.junos.factory.optable import OpTable
    from jnpr.junos.utils.config import Config
    from jnpr.junos.utils.scp import SCP
    from jnpr.junos.utils.sw import SW
    HAS_JUNOS = True
except ImportError:
    HAS_JUNOS = False
log = logging.getLogger(__name__)
__virtualname__ = "junos"
__proxyenabled__ = ["junos"]
def __virtual__():
    """
    We need the Junos adapter libraries for this
    module to work.  We also need a proxymodule entry in __opts__
    in the opts dictionary
    """
    if HAS_JUNOS and "proxy" in __opts__:
        return __virtualname__
    else:
        return (
            False,
            "The junos or dependent module could not be loaded: "
            "junos-eznc or jxmlease or yamlordereddictloader or "
            "proxy could not be loaded.",
        )
class HandleFileCopy:
    """
    To figure out proper path either from proxy local file system
    or proxy cache or on master. If required, then only copy from
    master to proxy
    """
    def __init__(self, path, **kwargs):
        self._file_path = path
        self._cached_folder = None
        self._cached_file = None
        self._kwargs = kwargs
    def __enter__(self):
        if self._file_path.startswith("salt://"):
            local_cache_path = __salt__["cp.is_cached"](self._file_path)
            if local_cache_path:
                master_hash = __salt__["cp.hash_file"](self._file_path)
                proxy_hash = __salt__["file.get_hash"](local_cache_path)
                if master_hash.get("hsum") == proxy_hash:
                    self._cached_file = salt.utils.files.mkstemp()
                    with salt.utils.files.fopen(self._cached_file, "w") as fp:
                        template_string = __salt__["slsutil.renderer"](
                            path=local_cache_path,
                            default_renderer="jinja",
                            **self._kwargs,
                        )
                        fp.write(template_string)
                    return self._cached_file
            self._cached_file = salt.utils.files.mkstemp()
            __salt__["cp.get_template"](
                self._file_path, self._cached_file, **self._kwargs
            )
            if self._cached_file != "":
                return self._cached_file
        else:
            if __salt__["file.file_exists"](self._file_path):
                self._cached_file = salt.utils.files.mkstemp()
                with salt.utils.files.fopen(self._cached_file, "w") as fp:
                    template_string = __salt__["slsutil.renderer"](
                        path=self._file_path, default_renderer="jinja", **self._kwargs
                    )
                    fp.write(template_string)
                return self._cached_file
    def __exit__(self, exc_type, exc_value, exc_traceback):
        if self._cached_file is not None:
            salt.utils.files.safe_rm(self._cached_file)
            log.debug("Deleted cached file: %s", self._cached_file)
        if self._cached_folder is not None:
            __salt__["file.rmdir"](self._cached_folder)
            log.debug("Deleted cached folder: %s", self._cached_folder)
def _timeout_decorator(function):
    @wraps(function)
    def wrapper(*args, **kwargs):
        if "dev_timeout" in kwargs or "timeout" in kwargs:
            ldev_timeout = max(kwargs.pop("dev_timeout", 0), kwargs.pop("timeout", 0))
            conn = __proxy__["junos.conn"]()
            restore_timeout = conn.timeout
            conn.timeout = ldev_timeout
            try:
                result = function(*args, **kwargs)
                conn.timeout = restore_timeout
                return result
            except Exception:  # pylint: disable=broad-except
                conn.timeout = restore_timeout
                raise
        else:
            return function(*args, **kwargs)
    return wrapper
def _timeout_decorator_cleankwargs(function):
    @wraps(function)
    def wrapper(*args, **kwargs):
        if "dev_timeout" in kwargs or "timeout" in kwargs:
            ldev_timeout = max(kwargs.pop("dev_timeout", 0), kwargs.pop("timeout", 0))
            conn = __proxy__["junos.conn"]()
            restore_timeout = conn.timeout
            conn.timeout = ldev_timeout
            try:
                restore_kwargs = False
                del_list = []
                op = {}
                op.update(kwargs)
                for keychk in kwargs:
                    if keychk.startswith("__pub"):
                        del_list.append(keychk)
                if del_list:
                    restore_kwargs = True
                    for delkey in del_list:
                        kwargs.pop(delkey)
                result = function(*args, **kwargs)
                if restore_kwargs:
                    kwargs.update(op)
                conn.timeout = restore_timeout
                return result
            except Exception:  # pylint: disable=broad-except
                conn.timeout = restore_timeout
                raise
        else:
            restore_kwargs = False
            del_list = []
            op = {}
            op.update(kwargs)
            for keychk in kwargs:
                if keychk.startswith("__pub"):
                    del_list.append(keychk)
            if del_list:
                restore_kwargs = True
                for delkey in del_list:
                    kwargs.pop(delkey)
            ret = function(*args, **kwargs)
            if restore_kwargs:
                kwargs.update(op)
            return ret
    return wrapper
def _restart_connection():
    minion_id = __opts__.get("proxyid", "") or __opts__.get("id", "")
    log.info(
        "Junos exception occurred %s (junos proxy) is down. Restarting.", minion_id
    )
    __salt__["event.fire_master"](
        {}, "junos/proxy/{}/stop".format(__opts__["proxy"]["host"])
    )
    __proxy__["junos.shutdown"](__opts__)  # safely close connection
    __proxy__["junos.init"](__opts__)  # reopen connection
    log.debug("Junos exception occurred, restarted %s (junos proxy)!", minion_id)
@_timeout_decorator_cleankwargs
def facts_refresh():
    """
    Reload the facts dictionary from the device. Usually only needed if,
    the device configuration is changed by some other actor.
    This function will also refresh the facts stored in the salt grains.
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.facts_refresh
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    try:
        conn.facts_refresh()
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Execution failed due to "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
        return ret
    ret["facts"] = __proxy__["junos.get_serialized_facts"]()
    try:
        __salt__["saltutil.sync_grains"]()
    except Exception as exception:  # pylint: disable=broad-except
        log.error('Grains could not be updated due to "%s"', exception)
    return ret
def facts():
    """
    Displays the facts gathered during the connection.
    These facts are also stored in Salt grains.
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.facts
    """
    ret = {}
    try:
        ret["facts"] = __proxy__["junos.get_serialized_facts"]()
        ret["out"] = True
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Could not display facts due to "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
    return ret
@_timeout_decorator
def rpc(cmd=None, dest=None, **kwargs):
    """
    This function executes the RPC provided as arguments on the junos device.
    The returned data can be stored in a file.
    cmd
        The RPC to be executed
    dest
        Destination file where the RPC output is stored. Note that the file
        will be stored on the proxy minion. To push the files to the master use
        :py:func:`cp.push &lt;salt.modules.cp.push&gt;`.
    format : xml
        The format in which the RPC reply is received from the device
    dev_timeout : 30
        The NETCONF RPC timeout (in seconds)
    filter
        Used with the ``get-config`` RPC to get specific configuration
    terse : False
        Amount of information you want
    interface_name
      Name of the interface to query
    CLI Example:
    .. code-block:: bash
        salt 'device' junos.rpc get_config dest=/var/log/config.txt format=text filter='&lt;configuration&gt;&lt;system/&gt;&lt;/configuration&gt;'
        salt 'device' junos.rpc get-interface-information dest=/home/user/interface.xml interface_name='lo0' terse=True
        salt 'device' junos.rpc get-chassis-inventory
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    op = dict()
    if "__pub_arg" in kwargs:
        if kwargs["__pub_arg"]:
            if isinstance(kwargs["__pub_arg"][-1], dict):
                op.update(kwargs["__pub_arg"][-1])
    elif "__pub_schedule" in kwargs:
        for key, value in kwargs.items():
            if not key.startswith("__pub_"):
                op[key] = value
    else:
        op.update(kwargs)
    if cmd is None:
        ret["message"] = "Please provide the rpc to execute."
        ret["out"] = False
        return ret
    format_ = op.pop("format", "xml")
    op.pop("dest", dest)
    if cmd in ["get-config", "get_config"]:
        filter_reply = None
        if "filter" in op:
            try:
                filter_reply = etree.XML(op["filter"])
            except etree.XMLSyntaxError as ex:
                ret["message"] = "Invalid filter: {}".format(str(ex))
                ret["out"] = False
                return ret
            del op["filter"]
        op.update({"format": format_})
        try:
            reply = getattr(conn.rpc, cmd.replace("-", "_"))(filter_reply, options=op)
        except Exception as exception:  # pylint: disable=broad-except
            ret["message"] = 'RPC execution failed due to "{}"'.format(exception)
            ret["out"] = False
            _restart_connection()
            return ret
    else:
        if "filter" in op:
            log.warning('Filter ignored as it is only used with "get-config" rpc')
        if "dest" in op:
            log.warning("dest in op, rpc may reject this for cmd '%s'", cmd)
        try:
            reply = getattr(conn.rpc, cmd.replace("-", "_"))({"format": format_}, **op)
        except Exception as exception:  # pylint: disable=broad-except
            ret["message"] = 'RPC execution failed due to "{}"'.format(exception)
            ret["out"] = False
            _restart_connection()
            return ret
    if format_ == "text":
        ret["rpc_reply"] = reply.text
    elif format_ == "json":
        ret["rpc_reply"] = reply
    else:
        ret["rpc_reply"] = jxmlease.parse(etree.tostring(reply))
    if dest:
        if format_ == "text":
            write_response = reply.text
        elif format_ == "json":
            write_response = salt.utils.json.dumps(reply, indent=1)
        else:
            write_response = etree.tostring(reply)
        with salt.utils.files.fopen(dest, "w") as fp:
            fp.write(salt.utils.stringutils.to_str(write_response))
    return ret
@_timeout_decorator
def set_hostname(hostname=None, **kwargs):
    """
    Set the device's hostname
    hostname
        The name to be set
    comment
        Provide a comment to the commit
    dev_timeout : 30
        The NETCONF RPC timeout (in seconds)
    confirm
      Provide time in minutes for commit confirmation. If this option is
      specified, the commit will be rolled back in the specified amount of time
      unless the commit is confirmed.
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.set_hostname salt-device
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    if hostname is None:
        ret["message"] = "Please provide the hostname."
        ret["out"] = False
        return ret
    op = dict()
    if "__pub_arg" in kwargs:
        if kwargs["__pub_arg"]:
            if isinstance(kwargs["__pub_arg"][-1], dict):
                op.update(kwargs["__pub_arg"][-1])
    else:
        op.update(kwargs)
    set_string = "set system host-name {}".format(hostname)
    try:
        conn.cu.load(set_string, format="set")
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Could not load configuration due to error "{}"'.format(
            exception
        )
        ret["out"] = False
        _restart_connection()
        return ret
    try:
        commit_ok = conn.cu.commit_check()
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Could not commit check due to error "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
        return ret
    if commit_ok:
        try:
            conn.cu.commit(**op)
            ret["message"] = "Successfully changed hostname."
            ret["out"] = True
        except Exception as exception:  # pylint: disable=broad-except
            ret["out"] = False
            ret[
                "message"
            ] = 'Successfully loaded host-name but commit failed with "{}"'.format(
                exception
            )
            _restart_connection()
            return ret
    else:
        ret["out"] = False
        ret["message"] = "Successfully loaded host-name but pre-commit check failed."
        try:
            conn.cu.rollback()
        except Exception as exception:  # pylint: disable=broad-except
            ret["out"] = False
            ret[
                "message"
            ] = 'Successfully loaded host-name but rollback before exit failed "{}"'.format(
                exception
            )
            _restart_connection()
    return ret
@_timeout_decorator
def commit(**kwargs):
    """
    To commit the changes loaded in the candidate configuration.
    dev_timeout : 30
        The NETCONF RPC timeout (in seconds)
    comment
      Provide a comment for the commit
    confirm
      Provide time in minutes for commit confirmation. If this option is
      specified, the commit will be rolled back in the specified amount of time
      unless the commit is confirmed.
    sync : False
      When ``True``, on dual control plane systems, requests that the candidate
      configuration on one control plane be copied to the other control plane,
      checked for correct syntax, and committed on both Routing Engines.
    force_sync : False
      When ``True``, on dual control plane systems, force the candidate
      configuration on one control plane to be copied to the other control
      plane.
    full
      When ``True``, requires all the daemons to check and evaluate the new
      configuration.
    detail
      When ``True``, return commit detail
    CLI Examples:
    .. code-block:: bash
        salt 'device_name' junos.commit comment='Commiting via saltstack' detail=True
        salt 'device_name' junos.commit dev_timeout=60 confirm=10
        salt 'device_name' junos.commit sync=True dev_timeout=90
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    op = dict()
    if "__pub_arg" in kwargs:
        if kwargs["__pub_arg"]:
            if isinstance(kwargs["__pub_arg"][-1], dict):
                op.update(kwargs["__pub_arg"][-1])
    else:
        op.update(kwargs)
    op["detail"] = op.get("detail", False)
    try:
        commit_ok = conn.cu.commit_check()
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Could not perform commit check due to "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
        return ret
    if commit_ok:
        try:
            commit = conn.cu.commit(**op)
            ret["out"] = True
            if commit:
                if op["detail"]:
                    ret["message"] = jxmlease.parse(etree.tostring(commit))
                else:
                    ret["message"] = "Commit Successful."
            else:
                ret["message"] = "Commit failed."
                ret["out"] = False
        except Exception as exception:  # pylint: disable=broad-except
            ret["out"] = False
            ret[
                "message"
            ] = 'Commit check succeeded but actual commit failed with "{}"'.format(
                exception
            )
            _restart_connection()
    else:
        ret["out"] = False
        ret["message"] = "Pre-commit check failed."
        try:
            conn.cu.rollback()
        except Exception as exception:  # pylint: disable=broad-except
            ret["out"] = False
            ret[
                "message"
            ] = 'Pre-commit check failed, and exception during rollback "{}"'.format(
                exception
            )
            _restart_connection()
    return ret
@_timeout_decorator
def rollback(**kwargs):
    """
    Roll back the last committed configuration changes and commit
    id : 0
        The rollback ID value (0-49)
    d_id : 0
        The rollback ID value (0-49)
    dev_timeout : 30
        The NETCONF RPC timeout (in seconds)
    comment
      Provide a comment for the commit
    confirm
      Provide time in minutes for commit confirmation. If this option is
      specified, the commit will be rolled back in the specified amount of time
      unless the commit is confirmed.
    diffs_file
      Path to the file where the diff (difference in old configuration and the
      committed configuration) will be stored. Note that the file will be
      stored on the proxy minion. To push the files to the master use
      :py:func:`cp.push &lt;salt.modules.cp.push&gt;`.
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.rollback 10
    NOTE: Because of historical reasons and the internals of the Salt state
    compiler, there are three possible sources of the rollback ID--the
    positional argument, and the `id` and `d_id` kwargs.  The precedence of
    the arguments are `id` (positional), `id` (kwarg), `d_id` (kwarg).  In
    other words, if all three are passed, only the positional argument
    will be used.  A warning is logged if more than one is passed.
    """
    ids_passed = 0
    id_ = 0
    if "d_id" in kwargs:
        id_ = kwargs.pop("d_id")
        ids_passed = ids_passed + 1
    if "id" in kwargs:
        id_ = kwargs.pop("id", 0)
        ids_passed = ids_passed + 1
    if ids_passed &gt; 1:
        log.warning(
            "junos.rollback called with more than one possible ID. "
            "Use only one of the positional argument, `id`, or `d_id` kwargs"
        )
    ret = {}
    conn = __proxy__["junos.conn"]()
    op = dict()
    if "__pub_arg" in kwargs:
        if kwargs["__pub_arg"]:
            if isinstance(kwargs["__pub_arg"][-1], dict):
                op.update(kwargs["__pub_arg"][-1])
    else:
        op.update(kwargs)
    try:
        ret["out"] = conn.cu.rollback(id_)
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Rollback failed due to "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
        return ret
    if ret["out"]:
        ret["message"] = "Rollback successful"
    else:
        ret["message"] = "Rollback failed"
        return ret
    if "diffs_file" in op and op["diffs_file"] is not None:
        diff = conn.cu.diff()
        if diff is not None:
            with salt.utils.files.fopen(op["diffs_file"], "w") as fp:
                fp.write(salt.utils.stringutils.to_str(diff))
        else:
            log.info(
                "No diff between current configuration and "
                "rollbacked configuration, so no diff file created"
            )
    try:
        commit_ok = conn.cu.commit_check()
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Could not commit check due to "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
        return ret
    if commit_ok:
        try:
            conn.cu.commit(**op)
            ret["out"] = True
        except Exception as exception:  # pylint: disable=broad-except
            ret["out"] = False
            ret[
                "message"
            ] = 'Rollback successful but commit failed with error "{}"'.format(
                exception
            )
            _restart_connection()
            return ret
    else:
        ret["message"] = "Rollback successful but pre-commit check failed."
        ret["out"] = False
    return ret
@_timeout_decorator
def diff(**kwargs):
    """
    Returns the difference between the candidate and the current configuration
    id : 0
        The rollback ID value (0-49)
    d_id : 0
        The rollback ID value (0-49)
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.diff d_id=3
    NOTE: Because of historical reasons and the internals of the Salt state
    compiler, there are three possible sources of the rollback ID--the
    positional argument, and the `id` and `d_id` kwargs.  The precedence of
    the arguments are `id` (positional), `id` (kwarg), `d_id` (kwarg).  In
    other words, if all three are passed, only the positional argument
    will be used.  A warning is logged if more than one is passed.
    """
    kwargs = salt.utils.args.clean_kwargs(**kwargs)
    ids_passed = 0
    id_ = 0
    if "d_id" in kwargs:
        id_ = kwargs.pop("d_id")
        ids_passed = ids_passed + 1
    if "id" in kwargs:
        id_ = kwargs.pop("id", 0)
        ids_passed = ids_passed + 1
    if ids_passed &gt; 1:
        log.warning(
            "junos.rollback called with more than one possible ID. "
            "Use only one of the positional argument, `id`, or `d_id` kwargs"
        )
    if kwargs:
        salt.utils.args.invalid_kwargs(kwargs)
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    try:
        ret["message"] = conn.cu.diff(rb_id=id_)
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Could not get diff with error "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
    return ret
@_timeout_decorator
def ping(dest_ip=None, **kwargs):
    """
    Send a ping RPC to a device
    dest_ip
      The IP of the device to ping
    dev_timeout : 30
        The NETCONF RPC timeout (in seconds)
    rapid : False
        When ``True``, executes ping at 100pps instead of 1pps
    ttl
        Maximum number of IP routers (IP hops) allowed between source and
        destination
    routing_instance
      Name of the routing instance to use to send the ping
    interface
      Interface used to send traffic
    count : 5
      Number of packets to send
    CLI Examples:
    .. code-block:: bash
        salt 'device_name' junos.ping '8.8.8.8' count=5
        salt 'device_name' junos.ping '8.8.8.8' ttl=1 rapid=True
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    if dest_ip is None:
        ret["message"] = "Please specify the destination ip to ping."
        ret["out"] = False
        return ret
    op = {"host": dest_ip}
    if "__pub_arg" in kwargs:
        if kwargs["__pub_arg"]:
            if isinstance(kwargs["__pub_arg"][-1], dict):
                op.update(kwargs["__pub_arg"][-1])
    else:
        op.update(kwargs)
    op["count"] = str(op.pop("count", 5))
    if "ttl" in op:
        op["ttl"] = str(op["ttl"])
    ret["out"] = True
    try:
        ret["message"] = jxmlease.parse(etree.tostring(conn.rpc.ping(**op)))
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Execution failed due to "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
    return ret
@_timeout_decorator
def cli(command=None, **kwargs):
    """
    Executes the CLI commands and returns the output in specified format. \
    (default is text) The output can also be stored in a file.
    command (required)
        The command to execute on the Junos CLI
    format : text
        Format in which to get the CLI output (either ``text`` or ``xml``)
    dev_timeout : 30
        The NETCONF RPC timeout (in seconds)
    dest
        Destination file where the RPC output is stored. Note that the file
        will be stored on the proxy minion. To push the files to the master use
        :py:func:`cp.push &lt;salt.modules.cp.push&gt;`.
    CLI Examples:
    .. code-block:: bash
        salt 'device_name' junos.cli 'show system commit'
        salt 'device_name' junos.cli 'show system alarms' format=xml dest=/home/user/cli_output.txt
    """
    conn = __proxy__["junos.conn"]()
    format_ = kwargs.pop("format", "text")
    if not format_:
        format_ = "text"
    ret = {}
    if command is None:
        ret["message"] = "Please provide the CLI command to be executed."
        ret["out"] = False
        return ret
    op = dict()
    if "__pub_arg" in kwargs:
        if kwargs["__pub_arg"]:
            if isinstance(kwargs["__pub_arg"][-1], dict):
                op.update(kwargs["__pub_arg"][-1])
    else:
        op.update(kwargs)
    try:
        result = conn.cli(command, format_, warning=False)
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Execution failed due to "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
        return ret
    if format_ == "text":
        ret["message"] = result
    else:
        result = etree.tostring(result)
        ret["message"] = jxmlease.parse(result)
    if "dest" in op and op["dest"] is not None:
        try:
            with salt.utils.files.fopen(op["dest"], "w") as fp:
                fp.write(salt.utils.stringutils.to_str(result))
        except OSError:
            ret["message"] = 'Unable to open "{}" to write'.format(op["dest"])
            ret["out"] = False
            return ret
    ret["out"] = True
    return ret
@_timeout_decorator
def shutdown(**kwargs):
    """
    Shut down (power off) or reboot a device running Junos OS. This includes
    all Routing Engines in a Virtual Chassis or a dual Routing Engine system.
      .. note::
          One of ``shutdown`` or ``reboot`` must be set to ``True`` or no
          action will be taken.
    shutdown : False
      Set this to ``True`` if you want to shutdown the machine. This is a
      safety mechanism so that the user does not accidentally shutdown the
      junos device.
    reboot : False
      If ``True``, reboot instead of shutting down
    at
      Used when rebooting, to specify the date and time the reboot should take
      place. The value of this option must match the JunOS CLI reboot syntax.
    in_min
        Used when shutting down. Specify the delay (in minutes) before the
        device will be shut down.
    CLI Examples:
    .. code-block:: bash
        salt 'device_name' junos.shutdown reboot=True
        salt 'device_name' junos.shutdown shutdown=True in_min=10
        salt 'device_name' junos.shutdown shutdown=True
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    sw = SW(conn)
    op = {}
    if "__pub_arg" in kwargs:
        if kwargs["__pub_arg"]:
            if isinstance(kwargs["__pub_arg"][-1], dict):
                op.update(kwargs["__pub_arg"][-1])
    else:
        op.update(kwargs)
    if "shutdown" not in op and "reboot" not in op:
        ret["message"] = "Provide either one of the arguments: shutdown or reboot."
        ret["out"] = False
        return ret
    try:
        if "reboot" in op and op["reboot"]:
            shut = sw.reboot
        elif "shutdown" in op and op["shutdown"]:
            shut = sw.poweroff
        else:
            ret["message"] = "Nothing to be done."
            ret["out"] = False
            return ret
        if "in_min" in op:
            shut(in_min=op["in_min"])
        elif "at" in op:
            shut(at=op["at"])
        else:
            shut()
        ret["message"] = "Successfully powered off/rebooted."
        ret["out"] = True
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Could not poweroff/reboot because "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
    return ret
@_timeout_decorator
def install_config(path=None, **kwargs):
    """
    Installs the given configuration file into the candidate configuration.
    Commits the changes if the commit checks or throws an error.
    path (required)
        Path where the configuration/template file is present. If the file has
        a ``.conf`` extension, the content is treated as text format. If the
        file has a ``.xml`` extension, the content is treated as XML format. If
        the file has a ``.set`` extension, the content is treated as Junos OS
        ``set`` commands.
    mode : exclusive
        The mode in which the configuration is locked. Can be one of
        ``private``, ``dynamic``, ``batch``, ``exclusive``, ``ephemeral``
    dev_timeout : 30
        Set NETCONF RPC timeout. Can be used for commands which take a while to
        execute.
    overwrite : False
        Set to ``True`` if you want this file is to completely replace the
        configuration file. Sets action to override
        .. note:: This option cannot be used if **format** is "set".
    replace : False
        Specify whether the configuration file uses ``replace:`` statements. If
        ``True``, only those statements under the ``replace`` tag will be
        changed.
    merge : False
        If set to ``True`` will set the load-config action to merge.
        the default load-config action is 'replace' for xml/json/text config
    format
        Determines the format of the contents
    update : False
        Compare a complete loaded configuration against the candidate
        configuration. For each hierarchy level or configuration object that is
        different in the two configurations, the version in the loaded
        configuration replaces the version in the candidate configuration. When
        the configuration is later committed, only system processes that are
        affected by the changed configuration elements parse the new
        configuration. This action is supported from PyEZ 2.1.
    comment
      Provide a comment for the commit
    confirm
      Provide time in minutes for commit confirmation. If this option is
      specified, the commit will be rolled back in the specified amount of time
      unless the commit is confirmed.
    diffs_file
      Path to the file where the diff (difference in old configuration and the
      committed configuration) will be stored. Note that the file will be
      stored on the proxy minion. To push the files to the master use:
        py:func:`cp.push &lt;salt.modules.cp.push&gt;`.
    template_vars
      Variables to be passed into the template processing engine in addition to
      those present in pillar, the minion configuration, grains, etc.  You may
      reference these variables in your template like so:
      .. code-block:: jinja
          {{ template_vars["var_name"] }}
    CLI Examples:
    .. code-block:: bash
        salt 'device_name' junos.install_config 'salt://production/network/routers/config.set'
        salt 'device_name' junos.install_config 'salt://templates/replace_config.conf' replace=True comment='Committed via SaltStack'
        salt 'device_name' junos.install_config 'salt://my_new_configuration.conf' dev_timeout=300 diffs_file='/salt/confs/old_config.conf' overwrite=True
        salt 'device_name' junos.install_config 'salt://syslog_template.conf' template_vars='{"syslog_host": "10.180.222.7"}'
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    if path is None:
        ret[
            "message"
        ] = "Please provide the salt path where the configuration is present"
        ret["out"] = False
        return ret
    op = {}
    if "__pub_arg" in kwargs:
        if kwargs["__pub_arg"]:
            if isinstance(kwargs["__pub_arg"][-1], dict):
                op.update(kwargs["__pub_arg"][-1])
    else:
        op.update(kwargs)
    test = op.pop("test", False)
    kwargs = {}
    if "template_vars" in op:
        kwargs.update({"template_vars": op["template_vars"]})
    with HandleFileCopy(path, **kwargs) as template_cached_path:
        if template_cached_path is None:
            ret["message"] = "Invalid file path."
            ret["out"] = False
            return ret
        if os.path.getsize(template_cached_path) == 0:
            ret["message"] = "Template failed to render"
            ret["out"] = False
            return ret
        write_diff = ""
        if "diffs_file" in op and op["diffs_file"] is not None:
            write_diff = op["diffs_file"]
            del op["diffs_file"]
        op["path"] = template_cached_path
        if "format" not in op:
            if path.endswith("set"):
                template_format = "set"
            elif path.endswith("xml"):
                template_format = "xml"
            elif path.endswith("json"):
                template_format = "json"
            else:
                template_format = "text"
            op["format"] = template_format
        if "replace" in op and op["replace"]:
            op["merge"] = False
            del op["replace"]
        elif "overwrite" in op and op["overwrite"]:
            op["overwrite"] = True
        elif "overwrite" in op and not op["overwrite"]:
            op["merge"] = True
            del op["overwrite"]
        db_mode = op.pop("mode", "exclusive")
        if write_diff and db_mode in ["dynamic", "ephemeral"]:
            ret[
                "message"
            ] = "Write diff is not supported with dynamic/ephemeral configuration mode"
            ret["out"] = False
            return ret
        config_params = {}
        if "ephemeral_instance" in op:
            config_params["ephemeral_instance"] = op.pop("ephemeral_instance")
        try:
            with Config(conn, mode=db_mode, **config_params) as cu:
                try:
                    cu.load(**op)
                except Exception as exception:  # pylint: disable=broad-except
                    ret[
                        "message"
                    ] = 'Could not load configuration due to : "{}"'.format(exception)
                    ret["format"] = op["format"]
                    ret["out"] = False
                    _restart_connection()
                    return ret
                config_diff = None
                if db_mode in ["dynamic", "ephemeral"]:
                    log.warning("diff is not supported for dynamic and ephemeral")
                else:
                    config_diff = cu.diff()
                    if config_diff is None:
                        ret["message"] = "Configuration already applied!"
                        ret["out"] = True
                        return ret
                commit_params = {}
                if "confirm" in op:
                    commit_params["confirm"] = op["confirm"]
                if "comment" in op:
                    commit_params["comment"] = op["comment"]
                check = True
                if db_mode in ["dynamic", "ephemeral"]:
                    log.warning("commit check not supported for dynamic and ephemeral")
                else:
                    try:
                        check = cu.commit_check()
                    except Exception as exception:  # pylint: disable=broad-except
                        ret[
                            "message"
                        ] = 'Commit check threw the following exception: "{}"'.format(
                            exception
                        )
                        ret["out"] = False
                        _restart_connection()
                        return ret
                if check and not test:
                    try:
                        cu.commit(**commit_params)
                        ret["message"] = "Successfully loaded and committed!"
                    except Exception as exception:  # pylint: disable=broad-except
                        ret[
                            "message"
                        ] = 'Commit check successful but commit failed with "{}"'.format(
                            exception
                        )
                        ret["out"] = False
                        _restart_connection()
                        return ret
                elif not check:
                    try:
                        cu.rollback()
                        ret["message"] = (
                            "Loaded configuration but commit check failed, hence"
                            " rolling back configuration."
                        )
                    except Exception as exception:  # pylint: disable=broad-except
                        ret["message"] = (
                            "Loaded configuration but commit check failed, and"
                            ' exception occurred during rolling back configuration "{}"'.format(
                                exception
                            )
                        )
                        _restart_connection()
                    ret["out"] = False
                else:
                    try:
                        cu.rollback()
                        ret["message"] = (
                            "Commit check passed, but skipping commit for dry-run and"
                            " rolling back configuration."
                        )
                        ret["out"] = True
                    except Exception as exception:  # pylint: disable=broad-except
                        ret["message"] = (
                            "Commit check passed, but skipping commit for dry-run and"
                            ' while rolling back configuration exception occurred "{}"'.format(
                                exception
                            )
                        )
                        ret["out"] = False
                        _restart_connection()
                try:
                    if write_diff and config_diff is not None:
                        with salt.utils.files.fopen(write_diff, "w") as fp:
                            fp.write(salt.utils.stringutils.to_str(config_diff))
                except Exception as exception:  # pylint: disable=broad-except
                    ret[
                        "message"
                    ] = "Could not write into diffs_file due to: '{}'".format(exception)
                    ret["out"] = False
        except ValueError as ex:
            message = "install_config failed due to: {}".format(str(ex))
            log.error(message)
            ret["message"] = message
            ret["out"] = False
        except LockError as ex:
            log.error("Configuration database is locked")
            ret["message"] = ex.message
            ret["out"] = False
        except RpcTimeoutError as ex:
            message = "install_config failed due to timeout error : {}".format(str(ex))
            log.error(message)
            ret["message"] = message
            ret["out"] = False
        except Exception as exc:  # pylint: disable=broad-except
            ret["message"] = "install_config failed due to exception: '{}'".format(exc)
            ret["out"] = False
        return ret
@_timeout_decorator_cleankwargs
def zeroize():
    """
    Resets the device to default factory settings
    .. note::
        In case of non-root user, proxy_reconnect will not be able
        to re-connect to the device as zeroize will delete the local
        user's configuration.
        For more details on zeroize functionality, please refer
        https://www.juniper.net/documentation/en_US/junos/topics/reference/command-summary/request-system-zeroize.html
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.zeroize
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    try:
        conn.cli("request system zeroize")
        ret["message"] = "Completed zeroize and rebooted"
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = 'Could not zeroize due to : "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
    return ret
@_timeout_decorator
def install_os(path=None, **kwargs):
    """
    Installs the given image on the device. After the installation is complete
    the device is rebooted, if reboot=True is given as a keyworded argument.
    path (required)
        Path where the image file is present on the proxy minion
    remote_path : /var/tmp
        If the value of path  is a file path on the local
        (Salt host's) filesystem, then the image is copied from the local
        filesystem to the :remote_path: directory on the target Junos
        device. The default is ``/var/tmp``. If the value of :path: or
        is a URL, then the value of :remote_path: is unused.
    dev_timeout : 1800
        The NETCONF RPC timeout (in seconds). This argument was added since most of
        the time the "package add" RPC takes a significant amount of time.
        So this :timeout: value will be used in the context of the SW installation
        process.  Defaults to 30 minutes (30*60=1800 seconds)
    timeout : 1800
        Alias to dev_timeout for backward compatibility
    reboot : False
        Whether to reboot after installation
    no_copy : False
        If ``True`` the software package will not be SCP’d to the device
    bool validate:
        When ``True`` this method will perform a config validation against
        the new image
    bool issu: False
        When ``True`` allows unified in-service software upgrade
        (ISSU) feature enables you to upgrade between two different Junos OS
        releases with no disruption on the control plane and with minimal
        disruption of traffic.
    bool nssu: False
        When ``True`` allows nonstop software upgrade (NSSU)
        enables you to upgrade the software running on a Juniper Networks
        EX Series Virtual Chassis or a Juniper Networks EX Series Ethernet
        Switch with redundant Routing Engines with a single command and
        minimal disruption to network traffic.
    bool all_re: True
        When True (default), executes the software install on all Routing Engines of the Junos
        device. When False, execute the software install only on the current Routing Engine.
        .. versionadded:: 3001
    .. note::
        Any additional keyword arguments specified are passed down to PyEZ sw.install() as is.
        Please refer to below URl for PyEZ sw.install() documentation:
        https://pyez.readthedocs.io/en/latest/jnpr.junos.utils.html#jnpr.junos.utils.sw.SW.install
    CLI Examples:
    .. code-block:: bash
        salt 'device_name' junos.install_os 'salt://images/junos_image.tgz' reboot=True
        salt 'device_name' junos.install_os 'salt://junos_16_1.tgz' dev_timeout=300
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    op = {}
    if "__pub_arg" in kwargs:
        if kwargs["__pub_arg"]:
            if isinstance(kwargs["__pub_arg"][-1], dict):
                op.update(kwargs["__pub_arg"][-1])
    else:
        op.update(kwargs)
    dev_timeout = max(op.pop("dev_timeout", 0), op.pop("timeout", 0))
    timeout = max(1800, conn.timeout, dev_timeout)
    reboot = op.pop("reboot", False)
    no_copy_ = op.get("no_copy", False)
    if path is None:
        ret[
            "message"
        ] = "Please provide the salt path where the junos image is present."
        ret["out"] = False
        return ret
    if reboot:
        __proxy__["junos.reboot_active"]()
    install_status = False
    if not no_copy_:
        with HandleFileCopy(path) as image_path:
            if image_path is None:
                ret["message"] = "Invalid path. Please provide a valid image path"
                ret["out"] = False
                __proxy__["junos.reboot_clear"]()
                return ret
            if salt.utils.platform.is_junos():
                tmp_absfile = image_path
                op["no_copy"] = True
                op["remote_path"] = os.path.dirname(tmp_absfile)
                image_path = os.path.basename(tmp_absfile)
            try:
                install_status, install_message = conn.sw.install(
                    image_path, progress=True, timeout=timeout, **op
                )
            except Exception as exception:  # pylint: disable=broad-except
                ret["message"] = 'Installation failed due to: "{}"'.format(exception)
                ret["out"] = False
                __proxy__["junos.reboot_clear"]()
                _restart_connection()
                return ret
    else:
        try:
            install_status, install_message = conn.sw.install(
                path, progress=True, timeout=timeout, **op
            )
        except Exception as exception:  # pylint: disable=broad-except
            ret["message"] = 'Installation failed due to: "{}"'.format(exception)
            ret["out"] = False
            __proxy__["junos.reboot_clear"]()
            _restart_connection()
            return ret
    if install_status is True:
        ret["out"] = True
        ret["message"] = "Installed the os."
    else:
        ret["message"] = "Installation failed. Reason: {}".format(install_message)
        ret["out"] = False
        __proxy__["junos.reboot_clear"]()
        return ret
    if reboot is True:
        reboot_kwargs = {}
        if "vmhost" in op and op.get("vmhost") is True:
            reboot_kwargs["vmhost"] = True
        if "all_re" in op:
            reboot_kwargs["all_re"] = op.get("all_re")
        try:
            __proxy__["junos.reboot_active"]()
            conn.sw.reboot(**reboot_kwargs)
        except Exception as exception:  # pylint: disable=broad-except
            __proxy__["junos.reboot_clear"]()
            ret[
                "message"
            ] = 'Installation successful but reboot failed due to : "{}"'.format(
                exception
            )
            ret["out"] = False
            _restart_connection()
            return ret
        __proxy__["junos.reboot_clear"]()
        ret["out"] = True
        ret["message"] = "Successfully installed and rebooted!"
    return ret
@_timeout_decorator_cleankwargs
def file_copy(src, dest):
    """
    Copies the file from the local device to the junos device
    .. note::
        This function does not work on Juniper native minions
    src
        The source path where the file is kept.
    dest
        The destination path on the where the file will be copied
    .. versionadded:: 3001
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.file_copy /home/m2/info.txt info_copy.txt
    """
    if salt.utils.platform.is_junos():
        return {
            "success": False,
            "message": "This method is unsupported on the current operating system!",
        }
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    with HandleFileCopy(src) as fp:
        if fp is None:
            ret["message"] = "Invalid source file path {}".format(src)
            ret["out"] = False
            return ret
        try:
            with SCP(conn, progress=True) as scp:
                scp.put(fp, dest)
            ret["message"] = "Successfully copied file from {} to {}".format(src, dest)
        except Exception as exception:  # pylint: disable=broad-except
            ret["message"] = 'Could not copy file : "{}"'.format(exception)
            ret["out"] = False
        return ret
@_timeout_decorator_cleankwargs
def lock():
    """
    Attempts an exclusive lock on the candidate configuration. This
    is a non-blocking call.
    .. note::
        When locking, it is important to remember to call
        :py:func:`junos.unlock &lt;salt.modules.junos.unlock&gt;` once finished. If
        locking during orchestration, remember to include a step in the
        orchestration job to unlock.
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.lock
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    try:
        conn.cu.lock()
        ret["message"] = "Successfully locked the configuration."
    except RpcTimeoutError as exception:
        ret["message"] = 'Could not gain lock due to : "{}"'.format(exception)
        ret["out"] = False
        _restart_connection()
    except LockError as exception:
        ret["message"] = 'Could not gain lock due to : "{}"'.format(exception)
        ret["out"] = False
    return ret
@_timeout_decorator_cleankwargs
def unlock():
    """
    Unlocks the candidate configuration.
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.unlock
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    try:
        conn.cu.unlock()
        ret["message"] = "Successfully unlocked the configuration."
    except RpcTimeoutError as exception:
        ret["message"] = 'Could not unlock configuration due to : "{}"'.format(
            exception
        )
        ret["out"] = False
        _restart_connection()
    except UnlockError as exception:
        ret["message"] = 'Could not unlock configuration due to : "{}"'.format(
            exception
        )
        ret["out"] = False
    return ret
@_timeout_decorator
def load(path=None, **kwargs):
    """
    Loads the configuration from the file provided onto the device.
    path (required)
        Path where the configuration/template file is present. If the file has
        a ``.conf`` extension, the content is treated as text format. If the
        file has a ``.xml`` extension, the content is treated as XML format. If
        the file has a ``.set`` extension, the content is treated as Junos OS
        ``set`` commands.
    overwrite : False
        Set to ``True`` if you want this file is to completely replace the
        configuration file. Sets action to override
        .. note:: This option cannot be used if **format** is "set".
    replace : False
        Specify whether the configuration file uses ``replace:`` statements. If
        ``True``, only those statements under the ``replace`` tag will be
        changed.
    merge : False
        If set to ``True`` will set the load-config action to merge.
        the default load-config action is 'replace' for xml/json/text config
    update : False
        Compare a complete loaded configuration against the candidate
        configuration. For each hierarchy level or configuration object that is
        different in the two configurations, the version in the loaded
        configuration replaces the version in the candidate configuration. When
        the configuration is later committed, only system processes that are
        affected by the changed configuration elements parse the new
        configuration. This action is supported from PyEZ 2.1.
    format
        Determines the format of the contents
    template_vars
      Variables to be passed into the template processing engine in addition to
      those present in pillar, the minion configuration, grains, etc.  You may
      reference these variables in your template like so:
      .. code-block:: jinja
          {{ template_vars["var_name"] }}
    CLI Examples:
    .. code-block:: bash
        salt 'device_name' junos.load 'salt://production/network/routers/config.set'
        salt 'device_name' junos.load 'salt://templates/replace_config.conf' replace=True
        salt 'device_name' junos.load 'salt://my_new_configuration.conf' overwrite=True
        salt 'device_name' junos.load 'salt://syslog_template.conf' template_vars='{"syslog_host": "10.180.222.7"}'
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    if path is None:
        ret[
            "message"
        ] = "Please provide the salt path where the configuration is present"
        ret["out"] = False
        return ret
    op = {}
    if "__pub_arg" in kwargs:
        if kwargs["__pub_arg"]:
            if isinstance(kwargs["__pub_arg"][-1], dict):
                op.update(kwargs["__pub_arg"][-1])
    else:
        op.update(kwargs)
    kwargs = {}
    if "template_vars" in op:
        kwargs.update({"template_vars": op["template_vars"]})
    with HandleFileCopy(path, **kwargs) as template_cached_path:
        if template_cached_path is None:
            ret["message"] = "Invalid file path."
            ret["out"] = False
            return ret
        if os.path.getsize(template_cached_path) == 0:
            ret["message"] = "Template failed to render"
            ret["out"] = False
            return ret
        op["path"] = template_cached_path
        if "format" not in op:
            if path.endswith("set"):
                template_format = "set"
            elif path.endswith("xml"):
                template_format = "xml"
            elif path.endswith("json"):
                template_format = "json"
            else:
                template_format = "text"
            op["format"] = template_format
        actions = [
            item
            for item in ("overwrite", "replace", "update", "merge")
        ]
        if len(list(actions)) &gt; 1:
            ret<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>["message"] = "Only one config_action is allowed. Provided: {}".format(
                actions
            )
            ret["out"] = False
            return ret
        if "replace" in op and op["replace"]:
            op["merge"] =</b></font> False
            del op["replace"]
        elif "overwrite" in op and op["overwrite"]:
            op["overwrite"] = True
        elif "merge" in op and op["merge"]:
            op["merge"] = True
        elif "overwrite" in op and not op["overwrite"]:
            op["merge"] = True
            del op["overwrite"]
        try:
            conn.cu.load(**op)
            ret["message"] = "Successfully loaded the configuration."
        except Exception as exception:  # pylint: disable=broad-except
            ret["message"] = 'Could not load configuration due to : "{}"'.format(
                exception
            )
            ret["format"] = op["format"]
            ret["out"] = False
            _restart_connection()
            return ret
        return ret
@_timeout_decorator_cleankwargs
def commit_check():
    """
    Perform a commit check on the configuration
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.commit_check
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    try:
        conn.cu.commit_check()
        ret["message"] = "Commit check succeeded."
    except Exception as exception:  # pylint: disable=broad-except
        ret["message"] = "Commit check failed with {}".format(exception)
        ret["out"] = False
        _restart_connection()
    return ret
@_timeout_decorator_cleankwargs
def get_table(
    table,
    table_file,
    path=None,
    target=None,
    key=None,
    key_items=None,
    filters=None,
    table_args=None,
):
    """
    .. versionadded:: 3001
    Retrieve data from a Junos device using Tables/Views
    table (required)
        Name of PyEZ Table
    table_file (required)
        YAML file that has the table specified in table parameter
    path:
        Path of location of the YAML file.
        defaults to op directory in jnpr.junos.op
    target:
        if command need to run on FPC, can specify fpc target
    key:
        To overwrite key provided in YAML
    key_items:
        To select only given key items
    filters:
        To select only filter for the dictionary from columns
    table_args:
        key/value pair which should render Jinja template command
        or are passed as args to rpc call in op table
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.get_table RouteTable routes.yml
        salt 'device_name' junos.get_table EthPortTable ethport.yml table_args='{"interface_name": "ge-3/2/2"}'
        salt 'device_name' junos.get_table EthPortTable ethport.yml salt://tables
    """
    conn = __proxy__["junos.conn"]()
    ret = {}
    ret["out"] = True
    ret["hostname"] = conn._hostname
    ret["tablename"] = table
    get_kvargs = {}
    if target is not None:
        get_kvargs["target"] = target
    if key is not None:
        get_kvargs["key"] = key
    if key_items is not None:
        get_kvargs["key_items"] = key_items
    if filters is not None:
        get_kvargs["filters"] = filters
    if table_args is not None and isinstance(table_args, dict):
        get_kvargs["args"] = table_args
    pyez_tables_path = os.path.dirname(os.path.abspath(tables_dir.__file__))
    try:
        if path is not None:
            file_path = os.path.join(path, "{}".format(table_file))
        else:
            file_path = os.path.join(pyez_tables_path, "{}".format(table_file))
        with HandleFileCopy(file_path) as file_loc:
            if file_loc is None:
                ret["message"] = "Given table file {} cannot be located".format(
                    table_file
                )
                ret["out"] = False
                return ret
            try:
                with salt.utils.files.fopen(file_loc) as fp:
                    ret["table"] = yaml.load(
                        fp.read(), Loader=yamlordereddictloader.Loader
                    )
                    globals().update(FactoryLoader().load(ret["table"]))
            except OSError as err:
                ret[
                    "message"
                ] = "Uncaught exception during YAML Load - please report: {}".format(
                    str(err)
                )
                ret["out"] = False
                return ret
            try:
                data = globals()[table](conn)
                data.get(**get_kvargs)
            except KeyError as err:
                ret[
                    "message"
                ] = "Uncaught exception during get API call - please report: {}".format(
                    str(err)
                )
                ret["out"] = False
                return ret
            except ConnectClosedError:
                ret[
                    "message"
                ] = "Got ConnectClosedError exception. Connection lost with {}".format(
                    conn
                )
                ret["out"] = False
                _restart_connection()
                return ret
            ret["reply"] = json.loads(data.to_json())
            if data.__class__.__bases__[0] in [OpTable, CfgTable]:
                if ret["table"][table].get("key") is None:
                    ret["table"][table]["key"] = data.ITEM_NAME_XPATH
                if key is not None:
                    ret["table"][table]["key"] = data.KEY
                if table_args is not None:
                    args = copy.copy(data.GET_ARGS)
                    args.update(table_args)
                    ret["table"][table]["args"] = args
            else:
                if target is not None:
                    ret["table"][table]["target"] = data.TARGET
                if key is not None:
                    ret["table"][table]["key"] = data.KEY
                if key_items is not None:
                    ret["table"][table]["key_items"] = data.KEY_ITEMS
                if table_args is not None:
                    args = copy.copy(data.CMD_ARGS)
                    args.update(table_args)
                    ret["table"][table]["args"] = args
                    ret["table"][table]["command"] = data.GET_CMD
    except ConnectClosedError:
        ret[
            "message"
        ] = "Got ConnectClosedError exception. Connection lost with {}".format(
            str(conn)
        )
        ret["out"] = False
        _restart_connection()
        return ret
    except Exception as err:  # pylint: disable=broad-except
        ret["message"] = "Uncaught exception - please report: {}".format(str(err))
        ret["out"] = False
        _restart_connection()
        return ret
    return ret
def _recursive_dict(node):
    """
    Convert an lxml.etree node tree into a dict.
    """
    result = {}
    for element in node.iterchildren():
        key = element.tag.split("}")[1] if "}" in element.tag else element.tag
        if element.text and element.text.strip():
            value = element.text
        else:
            value = _recursive_dict(element)
        if key in result:
            if type(result[key]) is list:
                result[key].append(value)
            else:
                tempvalue = result[key].copy()
                result[key] = [tempvalue, value]
        else:
            result[key] = value
    return result
@_timeout_decorator
def rpc_file_list(path, **kwargs):
    """
    Use the Junos RPC interface to get a list of files and return
    them as a structure dictionary.
    .. versionadded:: 3003
    CLI Example:
    .. code-block:: bash
        salt junos-router junos.rpc_file_list /var/local/salt/etc
        junos-router:
            files:
                directory:
                    directory-name:
                        /var/local/salt/etc
                    file-information:
                        |_
                          file-directory:
                              file-name:
                                  pki
                        |_
                          file-name:
                              proxy
                        |_
                          file-directory:
                              file-name:
                                  proxy.d
                total-file-blocks:
                    10
                total-files:
                    1
        success:
            True
    """
    kwargs = salt.utils.args.clean_kwargs(**kwargs)
    conn = __proxy__["junos.conn"]()
    if conn._conn is None:
        return False
    results = conn.rpc.file_list(path=path)
    ret = {}
    ret["files"] = _recursive_dict(results)
    ret["success"] = True
    return ret
def _strip_newlines(str):
    stripped = str.replace("\n", "")
    return stripped
def _make_source_list(dir):
    dir_list = []
    if not dir:
        return
    base = rpc_file_list(dir)["files"]["directory"]
    if "file-information" not in base:
        if "directory_name" not in base:
            return None
        return [os.path.join(_strip_newlines(base.get("directory-name", None))) + "/"]
    if isinstance(base["file-information"], dict):
        dirname = os.path.join(
            dir, _strip_newlines(base["file-information"]["file-name"])
        )
        if "file-directory" in base["file-information"]:
            new_list = _make_source_list(os.path.join(dir, dirname))
            return new_list
        else:
            return [dirname]
    for entry in base["file-information"]:
        if "file-directory" in entry:
            new_list = _make_source_list(
                os.path.join(dir, _strip_newlines(entry["file-name"]))
            )
            if new_list:
                dir_list.extend(new_list)
        else:
            dir_list.append(os.path.join(dir, _strip_newlines(entry["file-name"])))
    return dir_list
@_timeout_decorator
def file_compare(file1, file2, **kwargs):
    """
    Compare two files and return a dictionary indicating if they
    are different.
    Dictionary includes `success` key.  If False, one or more files do not
    exist or some other error occurred.
    Under the hood, this uses the junos CLI command `file compare files ...`
    .. note::
        This function only works on Juniper native minions
    .. versionadded:: 3003
    CLI Example:
    .. code-block:: bash
        salt junos-router junos.file_compare /var/tmp/backup1/cmt.script /var/tmp/backup2/cmt.script
        junos-router:
            identical:
                False
            success:
                True
    """
    if not salt.utils.platform.is_junos():
        return {
            "success": False,
            "message": "This method is unsupported on the current operating system!",
        }
    ret = {"message": "", "identical": False, "success": True}
    junos_cli = salt.utils.path.which("cli")
    if not junos_cli:
        return {"success": False, "message": "Cannot find Junos cli command"}
    cliret = __salt__["cmd.run"](
        "{} file compare files {} {} ".format(junos_cli, file1, file2)
    )
    clilines = cliret.splitlines()
    for r in clilines:
        if r.strip() != "":
            if "No such file" in r:
                ret["identical"] = False
                ret["success"] = False
                return ret
            ret["identical"] = False
            ret["success"] = True
            return ret
    ret["identical"] = True
    ret["success"] = True
    return ret
@_timeout_decorator
def fsentry_exists(dir, **kwargs):
    """
    Returns a dictionary indicating if `dir` refers to a file
    or a non-file (generally a directory) in the file system,
    or if there is no file by that name.
    .. note::
        This function only works on Juniper native minions
    .. versionadded:: 3003
    CLI Example:
    .. code-block:: bash
        salt junos-router junos.fsentry_exists /var/log
        junos-router:
            is_dir:
                True
            exists:
                True
    """
    if not salt.utils.platform.is_junos():
        return {
            "success": False,
            "message": "This method is unsupported on the current operating system!",
        }
    junos_cli = salt.utils.path.which("cli")
    if not junos_cli:
        return {"success": False, "message": "Cannot find Junos cli command"}
    ret = __salt__["cmd.run"]("{} file show {}".format(junos_cli, dir))
    retlines = ret.splitlines()
    exists = True
    is_dir = False
    status = {"is_dir": False, "exists": True}
    for r in retlines:
        if "could not resolve" in r or "error: Could not connect" in r:
            status["is_dir"] = False
            status["exists"] = False
        if "is not a regular file" in r:
            status["is_dir"] = True
            status["exists"] = True
    return status
def _find_routing_engines():
    junos_cli = salt.utils.path.which("cli")
    if not junos_cli:
        return {"success": False, "message": "Cannot find Junos cli command"}
    re_check = __salt__["cmd.run"]("{} show chassis routing-engine".format(junos_cli))
    engine_present = True
    engine = {}
    current_engine = None
    status = None
    for l in re_check.splitlines():
        if "Slot" in l:
            mat = re.search(".*(\\d+):.*", l)
            if mat:
                current_engine = "re" + str(mat.group(1)) + ":"
        if "Current state" in l:
            if "Master" in l:
                status = "Master"
            if "Disabled" in l:
                status = "Disabled"
            if "Backup" in l:
                status = "Backup"
        if current_engine and status:
            engine[current_engine] = status
            current_engine = None
            status = None
    if not engine:
        return {
            "success": False,
            "message": "Junos cli command returned no information",
        }
    engine["success"] = True
    return engine
@_timeout_decorator
def routing_engine(**kwargs):
    """
    Returns a dictionary containing the routing engines on the device and
    their status (Master, Disabled, Backup).
    Under the hood parses the result of `show chassis routing-engine`
    .. versionadded:: 3003
    CLI Example:
    .. code-block:: bash
        salt junos-router junos.routing_engine
        junos-router:
            backup:
              - re1:
            master:
              re0:
            success:
              True
    Returns `success: False` if the device does not appear to have multiple routing engines.
    """
    engine_status = _find_routing_engines()
    if not engine_status["success"]:
        return {"success": False}
    master = None
    backup = []
    for k, v in engine_status.items():
        if v == "Master":
            master = k
        if v == "Backup" or v == "Disabled":
            backup.append(k)
    if master:
        ret = {"master": master, "backup": backup, "success": True}
    else:
        ret = {"master": master, "backup": backup, "success": False}
    log.debug(ret)
    return ret
@_timeout_decorator
def dir_copy(source, dest, force=False, **kwargs):
    """
    Copy a directory and recursively its contents from source to dest.
    .. note::
        This function only works on the Juniper native minion
    Parameters:
    source : Directory to use as the source
    dest : Directory in which to place the source and its contents.
    force : This function will not copy identical files unless `force` is `True`
    .. versionadded:: 3003
    CLI Example:
    .. code-block:: bash
        salt 'device_name' junos.dir_copy /etc/salt/pki re1:/
    This will take the `pki` directory, its absolute path and copy it and its
    contents to routing engine 1 root directory. The result will be
    `re1:/etc/salt/pki/&lt;files and dirs in /etc/salt/pki`.
    """
    if not salt.utils.platform.is_junos():
        return {
            "success": False,
            "message": "This method is unsupported on the current operating system!",
        }
    junos_cli = salt.utils.path.which("cli")
    if not junos_cli:
        return {"success": False, "message": "Cannot find Junos cli command"}
    ret = {}
    ret_messages = ""
    if not source.startswith("/"):
        ret["message"] = "Source directory must be a fully qualified path."
        ret["success"] = False
        return ret
    if not (dest.endswith(":") or dest.startswith("/")):
        ret["message"] = (
            "Destination must be a routing engine reference (e.g. re1:) or a fully"
            " qualified path."
        )
        ret["success"] = False
        return ret
    check_source = fsentry_exists(source)
    if not check_source["exists"]:
        ret["message"] = "Source does not exist"
        ret["success"] = False
        return ret
    if not check_source["is_dir"]:
        ret["message"] = "Source is not a directory."
        ret["success"] = False
        return ret
    filelist = _make_source_list(source)
    dirops = []
    for f in filelist:
        splitpath = os.path.split(f)[0]
        fullpath = "/"
        for component in splitpath.split("/"):
            fullpath = os.path.join(fullpath, component)
            if fullpath not in dirops:
                dirops.append(fullpath)
    for d in dirops:
        target = dest + d
        status = fsentry_exists(target)
        if not status["exists"]:
            ret = __salt__["cmd.run"](
                "{} file make-directory {}".format(junos_cli, target)
            )
            ret = ret_messages + ret
        else:
            ret_messages = ret_messages + "Directory " + target + " already exists.\n"
    for f in filelist:
        if not f.endswith("/"):
            target = dest + f
            comp_result = file_compare(f, target)
            if not comp_result["identical"] or force:
                ret = __salt__["cmd.run"](
                    "{} file copy {} {}".format(junos_cli, f, target)
                )
                ret = ret_messages + ret
            else:
                ret_messages = (
                    ret_messages
                    + "Files {} and {} are identical, not copying.\n".format(f, target)
                )
    return ret_messages
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
