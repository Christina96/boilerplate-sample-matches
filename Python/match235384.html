<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for btrfs.py &amp; hgfs.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for btrfs.py &amp; hgfs.py
      </h3>
<h1 align="center">
        1.2%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>btrfs.py (2.7842228%)<th>hgfs.py (0.8174387%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(367-370)<td><a href="#" name="0">(866-867)</a><td align="center"><font color="#ff0000">12</font>
</td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>btrfs.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
import functools
import logging
import os.path
import tempfile
from salt.exceptions import CommandExecutionError
log = logging.getLogger(__name__)
__virtualname__ = "btrfs"
def _mount(device, use_default):
    opts = "defaults" if use_default else "subvol=/"
    dest = tempfile.mkdtemp()
    res = __states__["mount.mounted"](
        dest, device=device, fstype="btrfs", opts=opts, persist=False
    )
    if not res["result"]:
        log.error("Cannot mount device %s in %s", device, dest)
        _umount(dest)
        return None
    return dest
def _umount(path):
    __states__["mount.unmounted"](path)
    __utils__["files.rm_rf"](path)
def _is_default(path, dest, name):
    subvol_id = __salt__["btrfs.subvolume_show"](path)[name]["subvolume id"]
    def_id = __salt__["btrfs.subvolume_get_default"](dest)["id"]
    return subvol_id == def_id
def _set_default(path, dest, name):
    subvol_id = __salt__["btrfs.subvolume_show"](path)[name]["subvolume id"]
    return __salt__["btrfs.subvolume_set_default"](subvol_id, dest)
def _is_cow(path):
    dirname = os.path.dirname(path)
    return "C" not in __salt__["file.lsattr"](dirname)[path]
def _unset_cow(path):
    return __salt__["file.chattr"](path, operator="add", attributes="C")
def __mount_device(action):
    @functools.wraps(action)
    def wrapper(*args, **kwargs):
        name = kwargs.get("name", args[0] if args else None)
        device = kwargs.get("device", args[1] if len(args) &gt; 1 else None)
        use_default = kwargs.get("use_default", False)
        ret = {
            "name": name,
            "result": False,
            "changes": {},
            "comment": ["Some error happends during the operation."],
        }
        try:
            if device:
                dest = _mount(device, use_default)
                if not dest:
                    msg = "Device {} cannot be mounted".format(device)
                    ret["comment"].append(msg)
                kwargs["__dest"] = dest
            ret = action(*args, **kwargs)
        except Exception as exc:  # pylint: disable=broad-except
            log.error("Exception raised while mounting device: %s", exc, exc_info=True)
            ret["comment"].append(exc)
        finally:
            if device:
                _umount(dest)
        return ret
    return wrapper
@__mount_device
def subvolume_created(
    name,
    device,
    qgroupids=None,
    set_default=False,
    copy_on_write=True,
    force_set_default=True,
    __dest=None,
):
    ret = {
        "name": name,
        "result": False,
        "changes": {},
        "comment": [],
    }
    path = os.path.join(__dest, name)
    exists = __salt__["btrfs.subvolume_exists"](path)
    if exists:
        ret["comment"].append("Subvolume {} already present".format(name))
    if __opts__["test"]:
        ret["result"] = None
        if not exists:
            ret["changes"][name] = "Subvolume {} will be created".format(name)
        return ret
    if not exists:
        _path = os.path.dirname(path)
        res = __states__["file.directory"](_path, makedirs=True)
        if not res["result"]:
            ret["comment"].append("Error creating {} directory".format(_path))
            return ret
        try:
            __salt__["btrfs.subvolume_create"](name, dest=__dest, qgroupids=qgroupids)
        except CommandExecutionError:
            ret["comment"].append("Error creating subvolume {}".format(name))
            return ret
        ret["changes"][name] = "Created subvolume {}".format(name)
    if (
        (not exists or (exists and force_set_default))
        and set_default
        and not _is_default(path, __dest, name)
    ):
        ret["changes"][name + "_default"] = _set_default(path, __dest, name)
    if not copy_on_write and _is_cow(path):
        ret["changes"][name + "_no_cow"] = _unset_cow(path)
    ret["result"] = True
    return ret
@__mount_device
def subvolume_deleted(name, device, commit=False, __dest=None):
    ret = {
        "name": name,
        "result": False,
        "changes": {},
        "comment": [],
    }
    path = os.path.join(__dest, name)
    exists = __salt__["btrfs.subvolume_exists"](path)
    if not exists:
        ret["comment"].append("Subvolume {} already missing".format(name))
    if __opts__["test"]:
        ret["result"] = None
        if exists:
            ret["changes"][name] = "Subvolume {} will be removed".format(name)
        return ret
    commit = "after" if commit else None
    if not exists:
        try:
            __salt__["btrfs.subvolume_delete"](path, commit=commit)
        except CommandExecutionError:
            ret["comment"].append("Error removing subvolume {}".format(name))
            return ret
        ret["changes"][name] = "Removed subvolume {}".format(name)
    ret["result"] = True
    return ret
def _diff_properties(expected, current):
    difference = {}
    for _property, value in expected.items():
        current_value = current[_property]["value"]
        if value is False and current_value == "N/A":
            needs_update = False
        elif value != current_value:
            needs_update = True
        else:
            needs_update = False
        if needs_update:
            difference[_property] = value
    return difference
@__mount_device
def properties(name, device, use_default=False, __dest=None, **properties):
    ret = {
        "name": name,
        "result": False,
        "changes": {},
        "comment": [],
    }
    if device:
        if os.path.isabs(name):
            path = os.path.join(__dest, os.path.relpath(name, os.path.sep))
        else:
            path = os.path.join(__dest, name)
    else:
        path = name
    if not os.path.exists(path):
        ret["comment"].append("Object {} not found".format(name))
        return ret
    properties = {
        k: v if type(v) is not bool else str(v).lower() for k, v in properties.items()
    }
    current_properties = {}
    try:
        current_properties = __salt__["btrfs.properties"](path)
    except CommandExecutionError as e:
        ret["comment"].append("Error reading properties from {}".format(name))
        ret["comment"].append("Current error {}".format(e))
        return ret
    try:
        properties_to_set = _diff_properties(properties, current_properties)
    except KeyError:
        ret["comment"].append("Some property not found in {}".format(name))
        return ret
    if __opts__["test"]:
        ret["result"] = None
        if properties_to_set:
            ret["changes"] = properties_to_set
        else:
            msg = "No properties will be changed in {}".format(name)
            ret["comment"].append(msg)
        return ret
    if properties_to_set:
        _properties = ",".join(
            "{}={}".format(k, v) for k, v in properties_to_set.items()
        )
        __salt__["btrfs.properties"](path, set=_properties)
        current_properties = __salt__["btrfs.properties"](path)
        properties_failed = _diff_properties(properties, current_properties)
        if properties_failed:
            msg = "Properties {} failed to be changed in {}".format(
                properties_failed, name
            )
<a name="0"></a>            ret["comment"].append(msg)
            return ret
        ret<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>["comment"].append("Properties changed in {}".format(name))
        ret["changes"] = properties_to_set
    else:
        ret["comment"].append("Properties not changed in {}".format(</b></font>name))
    ret["result"] = True
    return ret
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>hgfs.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
import copy
import errno
import fnmatch
import glob
import hashlib
import logging
import os
import shutil
from datetime import datetime
import salt.fileserver
import salt.utils.data
import salt.utils.files
import salt.utils.gzip_util
import salt.utils.hashutils
import salt.utils.stringutils
import salt.utils.url
import salt.utils.versions
from salt.exceptions import FileserverConfigError
from salt.utils.event import tagify
VALID_BRANCH_METHODS = ("branches", "bookmarks", "mixed")
PER_REMOTE_OVERRIDES = ("base", "branch_method", "mountpoint", "root")
try:
    import hglib
    HAS_HG = True
except ImportError:
    HAS_HG = False
log = logging.getLogger(__name__)
__virtualname__ = "hgfs"
__virtual_aliases__ = ("hg",)
def __virtual__():
    if __virtualname__ not in __opts__["fileserver_backend"]:
        return False
    if not HAS_HG:
        log.error(
            "Mercurial fileserver backend is enabled in configuration "
            "but could not be loaded, is hglib installed?"
        )
        return False
    if __opts__["hgfs_branch_method"] not in VALID_BRANCH_METHODS:
        log.error(
            "Invalid hgfs_branch_method '%s'. Valid methods are: %s",
            __opts__["hgfs_branch_method"],
            VALID_BRANCH_METHODS,
        )
        return False
    if salt.utils.path.which("hg") is None:
        log.error("hgfs requested but hg executable is not available.")
        return False
    return __virtualname__
def _all_branches(repo):
    branches = [
        (salt.utils.stringutils.to_str(x[0]), x[1], salt.utils.stringutils.to_str(x[2]))
        for x in repo.branches()
    ]
    return branches
def _get_branch(repo, name):
    try:
        return [x for x in _all_branches(repo) if x[0] == name][0]
    except IndexError:
        return False
def _all_bookmarks(repo):
    bookmarks = [
        (salt.utils.stringutils.to_str(x[0]), x[1], salt.utils.stringutils.to_str(x[2]))
        for x in repo.bookmarks()[0]
    ]
    return bookmarks
def _get_bookmark(repo, name):
    try:
        return [x for x in _all_bookmarks(repo) if x[0] == name][0]
    except IndexError:
        return False
def _all_tags(repo):
    return [
        (
            salt.utils.stringutils.to_str(x[0]),
            x[1],
            salt.utils.stringutils.to_str(x[2]),
            x[3],
        )
        for x in repo.tags()
        if salt.utils.stringutils.to_str(x[0]) != "tip"
    ]
def _get_tag(repo, name):
    try:
        return [x for x in _all_tags(repo) if x[0] == name][0]
    except IndexError:
        return False
def _get_ref(repo, name):
    if name == "base":
        name = repo["base"]
    if name == repo["base"] or name in envs():
        if repo["branch_method"] == "branches":
            return _get_branch(repo["repo"], name) or _get_tag(repo["repo"], name)
        elif repo["branch_method"] == "bookmarks":
            return _get_bookmark(repo["repo"], name) or _get_tag(repo["repo"], name)
        elif repo["branch_method"] == "mixed":
            return (
                _get_branch(repo["repo"], name)
                or _get_bookmark(repo["repo"], name)
                or _get_tag(repo["repo"], name)
            )
    return False
def _get_manifest(repo, ref):
    manifest = [
        (
            salt.utils.stringutils.to_str(x[0]),
            salt.utils.stringutils.to_str(x[1]),
            x[2],
            x[3],
            salt.utils.stringutils.to_str(x[4]),
        )
        for x in repo.manifest(rev=ref[1])
    ]
    return manifest
def _failhard():
    raise FileserverConfigError("Failed to load hg fileserver backend")
def init():
    bp_ = os.path.join(__opts__["cachedir"], "hgfs")
    new_remote = False
    repos = []
    per_remote_defaults = {}
    for param in PER_REMOTE_OVERRIDES:
        per_remote_defaults[param] = str(__opts__["hgfs_{}".format(param)])
    for remote in __opts__["hgfs_remotes"]:
        repo_conf = copy.deepcopy(per_remote_defaults)
        if isinstance(remote, dict):
            repo_url = next(iter(remote))
            per_remote_conf = {
                key: str(val)
                for key, val in salt.utils.data.repack_dictlist(
                    remote[repo_url]
                ).items()
            }
            if not per_remote_conf:
                log.error(
                    "Invalid per-remote configuration for hgfs remote %s. If "
                    "no per-remote parameters are being specified, there may "
                    "be a trailing colon after the URL, which should be "
                    "removed. Check the master configuration file.",
                    repo_url,
                )
                _failhard()
            branch_method = per_remote_conf.get(
                "branch_method", per_remote_defaults["branch_method"]
            )
            if branch_method not in VALID_BRANCH_METHODS:
                log.error(
                    "Invalid branch_method '%s' for remote %s. Valid "
                    "branch methods are: %s. This remote will be ignored.",
                    branch_method,
                    repo_url,
                    ", ".join(VALID_BRANCH_METHODS),
                )
                _failhard()
            per_remote_errors = False
            for param in (x for x in per_remote_conf if x not in PER_REMOTE_OVERRIDES):
                log.error(
                    "Invalid configuration parameter '%s' for remote %s. "
                    "Valid parameters are: %s. See the documentation for "
                    "further information.",
                    param,
                    repo_url,
                    ", ".join(PER_REMOTE_OVERRIDES),
                )
                per_remote_errors = True
            if per_remote_errors:
                _failhard()
            repo_conf.update(per_remote_conf)
        else:
            repo_url = remote
        if not isinstance(repo_url, str):
            log.error(
                "Invalid hgfs remote %s. Remotes must be strings, you may "
                "need to enclose the URL in quotes",
                repo_url,
            )
            _failhard()
        try:
            repo_conf["mountpoint"] = salt.utils.url.strip_proto(
                repo_conf["mountpoint"]
            )
        except TypeError:
            pass
        hash_type = getattr(hashlib, __opts__.get("hash_type", "md5"))
        repo_hash = hash_type(repo_url.encode("utf-8")).hexdigest()
        rp_ = os.path.join(bp_, repo_hash)
        if not os.path.isdir(rp_):
            os.makedirs(rp_)
        if not os.listdir(rp_):
            client = hglib.init(rp_)
            client.close()
            new_remote = True
        repo = None
        try:
            try:
                repo = hglib.open(rp_)
            except hglib.error.ServerError:
                log.error(
                    "Cache path %s (corresponding remote: %s) exists but is not "
                    "a valid mercurial repository. You will need to manually "
                    "delete this directory on the master to continue to use this "
                    "hgfs remote.",
                    rp_,
                    repo_url,
                )
                _failhard()
            except Exception as exc:  # pylint: disable=broad-except
                log.error(
                    "Exception '%s' encountered while initializing hgfs remote %s",
                    exc,
                    repo_url,
                )
                _failhard()
            try:
                refs = repo.config(names=b"paths")
            except hglib.error.CommandError:
                refs = None
            if not refs:
                hgconfpath = os.path.join(rp_, ".hg", "hgrc")
                with salt.utils.files.fopen(hgconfpath, "w+") as hgconfig:
                    hgconfig.write("[paths]\n")
                    hgconfig.write(
                        salt.utils.stringutils.to_str("default = {}\n".format(repo_url))
                    )
            repo_conf.update(
                {
                    "repo": repo,
                    "url": repo_url,
                    "hash": repo_hash,
                    "cachedir": rp_,
                    "lockfile": os.path.join(
                        __opts__["cachedir"], "hgfs", "{}.update.lk".format(repo_hash)
                    ),
                }
            )
            repos.append(repo_conf)
        finally:
            if repo:
                repo.close()
    if new_remote:
        remote_map = os.path.join(__opts__["cachedir"], "hgfs/remote_map.txt")
        try:
            with salt.utils.files.fopen(remote_map, "w+") as fp_:
                timestamp = datetime.now().strftime("%d %b %Y %H:%M:%S.%f")
                fp_.write("# hgfs_remote map as of {}\n".format(timestamp))
                for repo in repos:
                    fp_.write(
                        salt.utils.stringutils.to_str(
                            "{} = {}\n".format(repo["hash"], repo["url"])
                        )
                    )
        except OSError:
            pass
        else:
            log.info("Wrote new hgfs_remote map to %s", remote_map)
    return repos
def _clear_old_remotes():
    bp_ = os.path.join(__opts__["cachedir"], "hgfs")
    try:
        cachedir_ls = os.listdir(bp_)
    except OSError:
        cachedir_ls = []
    repos = init()
    for repo in repos:
        try:
            cachedir_ls.remove(repo["hash"])
        except ValueError:
            pass
    to_remove = []
    for item in cachedir_ls:
        if item in ("hash", "refs"):
            continue
        path = os.path.join(bp_, item)
        if os.path.isdir(path):
            to_remove.append(path)
    failed = []
    if to_remove:
        for rdir in to_remove:
            try:
                shutil.rmtree(rdir)
            except OSError as exc:
                log.error("Unable to remove old hgfs remote cachedir %s: %s", rdir, exc)
                failed.append(rdir)
            else:
                log.debug("hgfs removed old cachedir %s", rdir)
    for fdir in failed:
        to_remove.remove(fdir)
    return bool(to_remove), repos
def clear_cache():
    fsb_cachedir = os.path.join(__opts__["cachedir"], "hgfs")
    list_cachedir = os.path.join(__opts__["cachedir"], "file_lists/hgfs")
    errors = []
    for rdir in (fsb_cachedir, list_cachedir):
        if os.path.exists(rdir):
            try:
                shutil.rmtree(rdir)
            except OSError as exc:
                errors.append("Unable to delete {}: {}".format(rdir, exc))
    return errors
def clear_lock(remote=None):
    def _do_clear_lock(repo):
        def _add_error(errlist, repo, exc):
            msg = "Unable to remove update lock for {} ({}): {} ".format(
                repo["url"], repo["lockfile"], exc
            )
            log.debug(msg)
            errlist.append(msg)
        success = []
        failed = []
        if os.path.exists(repo["lockfile"]):
            try:
                os.remove(repo["lockfile"])
            except OSError as exc:
                if exc.errno == errno.EISDIR:
                    try:
                        shutil.rmtree(repo["lockfile"])
                    except OSError as exc:
                        _add_error(failed, repo, exc)
                else:
                    _add_error(failed, repo, exc)
            else:
                msg = "Removed lock for {}".format(repo["url"])
                log.debug(msg)
                success.append(msg)
        return success, failed
    if isinstance(remote, dict):
        return _do_clear_lock(remote)
    cleared = []
    errors = []
    for repo in init():
        try:
            if remote:
                try:
                    if not fnmatch.fnmatch(repo["url"], remote):
                        continue
                except TypeError:
                    if not fnmatch.fnmatch(repo["url"], str(remote)):
                        continue
            success, failed = _do_clear_lock(repo)
            cleared.extend(success)
            errors.extend(failed)
        finally:
            repo["repo"].close()
    return cleared, errors
def lock(remote=None):
    def _do_lock(repo):
        success = []
        failed = []
        if not os.path.exists(repo["lockfile"]):
            try:
                with salt.utils.files.fopen(repo["lockfile"], "w"):
                    pass
            except OSError as exc:
                msg = "Unable to set update lock for {} ({}): {} ".format(
                    repo["url"], repo["lockfile"], exc
                )
                log.debug(msg)
                failed.append(msg)
            else:
                msg = "Set lock for {}".format(repo["url"])
                log.debug(msg)
                success.append(msg)
        return success, failed
    if isinstance(remote, dict):
        return _do_lock(remote)
    locked = []
    errors = []
    for repo in init():
        try:
            if remote:
                try:
                    if not fnmatch.fnmatch(repo["url"], remote):
                        continue
                except TypeError:
                    if not fnmatch.fnmatch(repo["url"], str(remote)):
                        continue
            success, failed = _do_lock(repo)
            locked.extend(success)
            errors.extend(failed)
        finally:
            repo["repo"].close()
    return locked, errors
def update():
    data = {"changed": False, "backend": "hgfs"}
    data["changed"], repos = _clear_old_remotes()
    for repo in repos:
        try:
            if os.path.exists(repo["lockfile"]):
                log.warning(
                    "Update lockfile is present for hgfs remote %s, skipping. "
                    "If this warning persists, it is possible that the update "
                    "process was interrupted. Removing %s or running "
                    "'salt-run fileserver.clear_lock hgfs' will allow updates "
                    "to continue for this remote.",
                    repo["url"],
                    repo["lockfile"],
                )
                continue
            _, errors = lock(repo)
            if errors:
                log.error(
                    "Unable to set update lock for hgfs remote %s, skipping.",
                    repo["url"],
                )
                continue
            log.debug("hgfs is fetching from %s", repo["url"])
            repo["repo"].open()
            curtip = repo["repo"].tip()
            try:
                repo["repo"].pull()
            except Exception as exc:  # pylint: disable=broad-except
                log.error(
                    "Exception %s caught while updating hgfs remote %s",
                    exc,
                    repo["url"],
                    exc_info_on_loglevel=logging.DEBUG,
                )
            else:
                newtip = repo["repo"].tip()
                if curtip[1] != newtip[1]:
                    data["changed"] = True
        finally:
            repo["repo"].close()
        clear_lock(repo)
    env_cache = os.path.join(__opts__["cachedir"], "hgfs/envs.p")
    if data.get("changed", False) is True or not os.path.isfile(env_cache):
        env_cachedir = os.path.dirname(env_cache)
        if not os.path.exists(env_cachedir):
            os.makedirs(env_cachedir)
        new_envs = envs(ignore_cache=True)
        with salt.utils.files.fopen(env_cache, "wb+") as fp_:
            fp_.write(salt.payload.dumps(new_envs))
            log.trace("Wrote env cache data to %s", env_cache)
    if __opts__.get("fileserver_events", False):
        with salt.utils.event.get_event(
            "master",
            __opts__["sock_dir"],
            opts=__opts__,
            listen=False,
        ) as event:
            event.fire_event(data, tagify(["hgfs", "update"], prefix="fileserver"))
    try:
        salt.fileserver.reap_fileserver_cache_dir(
            os.path.join(__opts__["cachedir"], "hgfs/hash"), find_file
        )
    except OSError:
        pass
def _env_is_exposed(env):
    return salt.utils.stringutils.check_whitelist_blacklist(
        env,
        whitelist=__opts__["hgfs_saltenv_whitelist"],
        blacklist=__opts__["hgfs_saltenv_blacklist"],
    )
def envs(ignore_cache=False):
    if not ignore_cache:
        env_cache = os.path.join(__opts__["cachedir"], "hgfs/envs.p")
        cache_match = salt.fileserver.check_env_cache(__opts__, env_cache)
        if cache_match is not None:
            return cache_match
    ret = set()
    for repo in init():
        try:
            repo["repo"].open()
            if repo["branch_method"] in ("branches", "mixed"):
                for branch in _all_branches(repo["repo"]):
                    branch_name = branch[0]
                    if branch_name == repo["base"]:
                        branch_name = "base"
                    ret.add(branch_name)
            if repo["branch_method"] in ("bookmarks", "mixed"):
                for bookmark in _all_bookmarks(repo["repo"]):
                    bookmark_name = bookmark[0]
                    if bookmark_name == repo["base"]:
                        bookmark_name = "base"
                    ret.add(bookmark_name)
            ret.update([x[0] for x in _all_tags(repo["repo"])])
        finally:
            repo["repo"].close()
    return [x for x in sorted(ret) if _env_is_exposed(x)]
def find_file(path, tgt_env="base", **kwargs):  # pylint: disable=W0613
    fnd = {"path": "", "rel": ""}
    if os.path.isabs(path) or tgt_env not in envs():
        return fnd
    dest = os.path.join(__opts__["cachedir"], "hgfs/refs", tgt_env, path)
    hashes_glob = os.path.join(
        __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.hash.*".format(path)
    )
    blobshadest = os.path.join(
        __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.hash.blob_sha1".format(path)
    )
    lk_fn = os.path.join(
        __opts__["cachedir"], "hgfs/hash", tgt_env, "{}.lk".format(path)
    )
    destdir = os.path.dirname(dest)
    hashdir = os.path.dirname(blobshadest)
    if not os.path.isdir(destdir):
        try:
            os.makedirs(destdir)
        except OSError:
            os.remove(destdir)
            os.makedirs(destdir)
    if not os.path.isdir(hashdir):
        try:
            os.makedirs(hashdir)
        except OSError:
            os.remove(hashdir)
            os.makedirs(hashdir)
    for repo in init():
        try:
            if repo["mountpoint"] and not path.startswith(
                repo["mountpoint"] + os.path.sep
            ):
                continue
            repo_path = path[len(repo["mountpoint"]) :].lstrip(os.path.sep)
            if repo["root"]:
                repo_path = os.path.join(repo["root"], repo_path)
            repo["repo"].open()
            ref = _get_ref(repo, tgt_env)
            if not ref:
                repo["repo"].close()
                continue
            salt.fileserver.wait_lock(lk_fn, dest)
            if os.path.isfile(blobshadest) and os.path.isfile(dest):
                with salt.utils.files.fopen(blobshadest, "r") as fp_:
                    sha = fp_.read()
                    if sha == ref[2]:
                        fnd["rel"] = path
                        fnd["path"] = dest
                        repo["repo"].close()
                        return fnd
            try:
                repo["repo"].cat(
                    [salt.utils.stringutils.to_bytes("path:{}".format(repo_path))],
                    rev=ref[2],
                    output=dest,
                )
            except hglib.error.CommandError:
                repo["repo"].close()
                continue
            with salt.utils.files.fopen(lk_fn, "w"):
                pass
            for filename in glob.glob(hashes_glob):
                try:
                    os.remove(filename)
                except Exception:  # pylint: disable=broad-except
                    pass
            with salt.utils.files.fopen(blobshadest, "w+") as fp_:
                fp_.write(salt.utils.stringutils.to_str(ref[2]))
            try:
                os.remove(lk_fn)
            except OSError:
                pass
            fnd["rel"] = path
            fnd["path"] = dest
            try:
                fnd["stat"] = list(os.stat(dest))
            except Exception:  # pylint: disable=broad-except
                pass
        finally:
            repo["repo"].close()
        return fnd
    return fnd
def serve_file(load, fnd):
    if "env" in load:
        load.pop("env")
    ret = {"data": "", "dest": ""}
    if not all(x in load for x in ("path", "loc", "saltenv")):
        return ret
    if not fnd["path"]:
        return ret
    ret["dest"] = fnd["rel"]
    gzip = load.get("gzip", None)
    fpath = os.path.normpath(fnd["path"])
    with salt.utils.files.fopen(fpath, "rb") as fp_:
        fp_.seek(load["loc"])
        data = fp_.read(__opts__["file_buffer_size"])
        if data and not salt.utils.files.is_binary(fpath):
            data = data.decode(__salt_system_encoding__)
        if gzip and data:
            data = salt.utils.gzip_util.compress(data, gzip)
            ret["gzip"] = gzip
        ret["data"] = data
    return ret
def file_hash(load, fnd):
    if "env" in load:
        load.pop("env")
    if not all(x in load for x in ("path", "saltenv")):
        return ""
    ret = {"hash_type": __opts__["hash_type"]}
    relpath = fnd["rel"]
    path = fnd["path"]
    hashdest = os.path.join(
        __opts__["cachedir"],
        "hgfs/hash",
        load["saltenv"],
        "{}.hash.{}".format(relpath, __opts__["hash_type"]),
    )
    if not os.path.isfile(hashdest):
        ret["hsum"] = salt.utils.hashutils.get_hash(path, __opts__["hash_type"])
        with salt.utils.files.fopen(hashdest, "w+") as fp_:
            fp_.write(ret["hsum"])
        return ret
    else:
        with salt.utils.files.fopen(hashdest, "rb") as fp_:
            ret["hsum"] = salt.utils.stringutils.to_unicode(fp_.read())
        return ret
def _file_lists(load, form):
    if "env" in load:
        load.pop("env")
    list_cachedir = os.path.join(__opts__["cachedir"], "file_lists/hgfs")
    if not os.path.isdir(list_cachedir):
        try:
            os.makedirs(list_cachedir)
<a name="0"></a>        except os.error:
            log.critical("Unable to make cachedir %s", list_cachedir)
            return []
    list_cache = os<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.path.join(list_cachedir, "{}.p".format(load["saltenv"]))
    w_lock = os.path.join(list_cachedir, ".{}.w".format(</b></font>load["saltenv"]))
    cache_match, refresh_cache, save_cache = salt.fileserver.check_file_list_cache(
        __opts__, form, list_cache, w_lock
    )
    if cache_match is not None:
        return cache_match
    if refresh_cache:
        ret = {}
        ret["files"] = _get_file_list(load)
        ret["dirs"] = _get_dir_list(load)
        if save_cache:
            salt.fileserver.write_file_list_cache(__opts__, ret, list_cache, w_lock)
        return ret.get(form, [])
    return []
def file_list(load):
    return _file_lists(load, "files")
def _get_file_list(load):
    if "env" in load:
        load.pop("env")
    if "saltenv" not in load or load["saltenv"] not in envs():
        return []
    ret = set()
    for repo in init():
        try:
            repo["repo"].open()
            ref = _get_ref(repo, load["saltenv"])
            if ref:
                manifest = _get_manifest(repo["repo"], ref=ref)
                for tup in manifest:
                    relpath = os.path.relpath(tup[4], repo["root"])
                    if not relpath.startswith("../"):
                        ret.add(os.path.join(repo["mountpoint"], relpath))
        finally:
            repo["repo"].close()
    return sorted(ret)
def file_list_emptydirs(load):  # pylint: disable=W0613
    return []
def dir_list(load):
    return _file_lists(load, "dirs")
def _get_dir_list(load):
    if "env" in load:
        load.pop("env")
    if "saltenv" not in load or load["saltenv"] not in envs():
        return []
    ret = set()
    for repo in init():
        try:
            repo["repo"].open()
            ref = _get_ref(repo, load["saltenv"])
            if ref:
                manifest = _get_manifest(repo["repo"], ref=ref)
                for tup in manifest:
                    filepath = tup[4]
                    split = filepath.rsplit("/", 1)
                    while len(split) &gt; 1:
                        relpath = os.path.relpath(split[0], repo["root"])
                        if relpath != ".":
                            if not relpath.startswith("../"):
                                ret.add(os.path.join(repo["mountpoint"], relpath))
                        split = split[0].rsplit("/", 1)
        finally:
            repo["repo"].close()
    if repo["mountpoint"]:
        ret.add(repo["mountpoint"])
    return sorted(ret)
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
