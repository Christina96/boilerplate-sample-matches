
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 16.753022452504318%, Tokens: 9</h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-momentum_test.py</h3>
            <pre><code>1  from sonnet.src import test_utils
2  from sonnet.src.optimizers import momentum as momentum_lib
3  from sonnet.src.optimizers import optimizer_tests
4  import tensorflow as tf
5  CONFIGS = optimizer_tests.named_product(learning_rate=(0.1, 0.01, 0.001),
6                                          momentum=(0.9, 0.5, 0.2),
7                                          use_nesterov=(True, False),
8                                          seed=(28, 2, 90))
9  class ComparisonTest(optimizer_tests.AbstractFuzzTest):
10    def _make_tf(self, learning_rate, momentum, use_nesterov):
11      optimizer = tf.optimizers.SGD(learning_rate=learning_rate,
12                                    momentum=momentum,
13                                    nesterov=use_nesterov)
14      return lambda g, p: optimizer.apply_gradients(zip(g, p))
15    def _make_snt(self, learning_rate, momentum, use_nesterov):
16      optimizer = momentum_lib.Momentum(learning_rate=learning_rate,
17                                        momentum=momentum,
18                                        use_nesterov=use_nesterov)
19      return optimizer.apply
20    @test_utils.combined_named_parameters(CONFIGS)
21    def testComparingSonnetAndTensorFlow(self, config):
22      seed = config.pop("seed")
23      self.assertParametersRemainClose(seed, config)
24  class MomentumTest(optimizer_tests.OptimizerTestBase):
25    def make_optimizer(self, **kwargs):
26      if "learning_rate" not in kwargs:
27        kwargs["learning_rate"] = 0.1
28      if "momentum" not in kwargs:
29        kwargs["momentum"] = 0.9
30      return momentum_lib.Momentum(**kwargs)
31    def testDense(self):
32      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
33      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
34      optimizer = self.make_optimizer(learning_rate=0.1, momentum=0.9)
35      optimizer.apply(updates, parameters)
36      self.assertAllClose([[0.5, 1.5], [2.7, 3.7]],
37                          [x.numpy() for x in parameters])
38      optimizer.apply(updates, parameters)
39      self.assertAllClose([[-0.45, 0.55], [2.13, 3.13]],
40                          [x.numpy() for x in parameters])
41      optimizer.apply(updates, parameters)
42      self.assertAllClose([[-1.805, -0.805], [1.317, 2.317]],
43                          [x.numpy() for x in parameters])
44    def testDenseNesterov(self):
45      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
46      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
47      optimizer = self.make_optimizer(
48          learning_rate=0.1, momentum=0.9, use_nesterov=True)
49      optimizer.apply(updates, parameters)
50      self.assertAllClose([[0.05, 1.05], [2.43, 3.43]],
51                          [x.numpy() for x in parameters])
52      optimizer.apply(updates, parameters)
53      self.assertAllClose([[-1.305, -0.305], [1.617, 2.617]],
54                          [x.numpy() for x in parameters])
55      optimizer.apply(updates, parameters)
56      self.assertAllClose([[-3.0245, -2.0245], [0.5853, 1.5853]],
57                          [x.numpy() for x in parameters])
58    def testSparse(self):
59      if self.primary_device in ("GPU", "TPU"):
60        self.skipTest("IndexedSlices not supported on {}.".format(
61            self.primary_device))
62      parameters = [tf.Variable([[1.], [2.]]), tf.Variable([[3.], [4.]])]
63      updates = [
64          tf.IndexedSlices(
65              tf.constant([0.1], shape=[1, 1]), tf.constant([0]),
66              tf.constant([2, 1])),
67          tf.IndexedSlices(
68              tf.constant([0.01], shape=[1, 1]), tf.constant([1]),
69              tf.constant([2, 1]))
70      ]
71      optimizer = self.make_optimizer(learning_rate=3., momentum=0.9)
72      optimizer.apply(updates, parameters)
73      self.assertAllClose([[1.0 - 3.0 * 0.1], [2.0]], parameters[0].numpy())
74      self.assertAllClose([[3.0], [4.0 - 3.0 * 0.01]], parameters[1].numpy())
75      optimizer.apply(updates, parameters)
76      self.assertAllClose([[0.7 - 3.0 * 0.19], [2.0]], parameters[0].numpy())
77      self.assertAllClose([[3.0], [3.97 - 3.0 * 0.019]], parameters[1].numpy())
78      optimizer.apply(updates, parameters)
79      self.assertAllClose([[0.13 - 3.0 * 0.271], [2.0]], parameters[0].numpy())
80      self.assertAllClose([[3.0], [3.913 - 3.0 * 0.0271]], parameters[1].numpy())
81    def testSparseNesterov(self):
82      if self.primary_device in ("GPU", "TPU"):
83        self.skipTest("IndexedSlices not supported on {}.".format(
84            self.primary_device))
85      parameters = [tf.Variable([[1.], [2.]]), tf.Variable([[3.], [4.]])]
86      updates = [
87          tf.IndexedSlices(
88              tf.constant([0.1], shape=[1, 1]), tf.constant([0]),
89              tf.constant([2, 1])),
90          tf.IndexedSlices(
91              tf.constant([0.01], shape=[1, 1]), tf.constant([1]),
92              tf.constant([2, 1]))
93      ]
94      optimizer = self.make_optimizer(
95          learning_rate=3., momentum=0.9, use_nesterov=True)
96      optimizer.apply(updates, parameters)
97      self.assertAllClose([[0.43], [2.0]], parameters[0].numpy())
98      self.assertAllClose([[3.0], [3.943]], parameters[1].numpy())
99      optimizer.apply(updates, parameters)
100      self.assertAllClose([[-0.383], [2.0]], parameters[0].numpy())
101      self.assertAllClose([[3.0], [3.8617]], parameters[1].numpy())
102      optimizer.apply(updates, parameters)
103      self.assertAllClose([[-1.4147], [2.0]], parameters[0].numpy())
104      self.assertAllClose([[3.0], [3.75853]], parameters[1].numpy())
105    def testVariableHyperParams(self):
106      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
107      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
<span onclick='openModal()' class='match'>108      learning_rate = tf.Variable(0.1)
109      momentum_coeff = tf.Variable(0.9)
110      optimizer = self.make_optimizer(
</span>111          learning_rate=learning_rate, momentum=momentum_coeff)
112      if optimizer_tests.is_tf_optimizer(optimizer):
113        self.skipTest("TF SGD optimizer doesn't support variable learning rate.")
114      optimizer.apply(updates, parameters)
115      self.assertAllClose([[0.5, 1.5], [2.7, 3.7]],
116                          [x.numpy() for x in parameters])
117      learning_rate.assign(0.01)
118      momentum_coeff.assign(0.09)
119      self.assertAlmostEqual(0.01, optimizer.learning_rate.numpy())
120      self.assertAlmostEqual(0.09, optimizer.momentum.numpy())
121      optimizer.apply(updates, parameters)
122      self.assertAllClose([[0.4455, 1.4455], [2.6673, 3.6673]],
123                          [x.numpy() for x in parameters])
124    def testHyperParamDTypeConversion(self):
125      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
126      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
127      dtype = tf.float32 if self.primary_device == "TPU" else tf.float64
128      learning_rate = tf.Variable(0.1, dtype=dtype)
129      momentum_coeff = tf.Variable(0.9, dtype=dtype)
130      optimizer = self.make_optimizer(
131          learning_rate=learning_rate, momentum=momentum_coeff)
132      optimizer.apply(updates, parameters)
133      self.assertAllClose([[0.5, 1.5], [2.7, 3.7]],
134                          [x.numpy() for x in parameters])
135    def testAuxVariablesColocatedWithOriginal(self):
136      optimizer = self.make_optimizer(learning_rate=0.1, momentum=0.9)
137      if optimizer_tests.is_tf_optimizer(optimizer):
138        self.skipTest("TF slot variables are in a different location.")
139      with tf.device("CPU:0"):
140        var = tf.Variable(1.0)
141      optimizer.apply([tf.constant(0.1)], [var])
142      self.assertEqual(optimizer.accumulated_momentum[0].device, var.device)
143  class ReferenceMomentumTest(MomentumTest):
144    def make_optimizer(self, **kwargs):
145      if "learning_rate" not in kwargs:
146        kwargs["learning_rate"] = 0.1
147      if "momentum" not in kwargs:
148        kwargs["momentum"] = 0.9
149      if "use_nesterov" in kwargs:
150        kwargs["nesterov"] = kwargs["use_nesterov"]
151        del kwargs["use_nesterov"]
152      if hasattr(tf.keras.optimizers, "legacy"):
153        return optimizer_tests.WrappedTFOptimizer(
154            tf.keras.optimizers.legacy.SGD(**kwargs))
155      return optimizer_tests.WrappedTFOptimizer(tf.keras.optimizers.SGD(**kwargs))
156  if __name__ == "__main__":
157    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-reshape_test.py</h3>
            <pre><code>1  from absl.testing import parameterized
2  import numpy as np
3  from sonnet.src import reshape
4  from sonnet.src import test_utils
5  import tensorflow as tf
6  B, H, W, C, D = 2, 3, 4, 5, 6
7  class ReshapeTest(test_utils.TestCase, parameterized.TestCase):
8    @parameterized.parameters(
9        (1, [B, H * W * C, D]),
10        (2, [B, H, W * C, D]),
11        (3, [B, H, W, C, D]),
12        (4, [B, H, W, C, 1, D]),
13    )
14    def testReshape(self, preserve_dims, expected_output_shape):
15      mod = reshape.Reshape(output_shape=(-1, D), preserve_dims=preserve_dims)
16      outputs = mod(tf.ones([B, H, W, C, D]))
17      self.assertEqual(outputs.shape, expected_output_shape)
18    def testInvalid_multipleWildcard(self):
19      mod = reshape.Reshape(output_shape=[-1, -1])
20      with self.assertRaises(tf.errors.InvalidArgumentError):
21        mod(tf.ones([1, 2, 3]))
22    def testInvalid_negativeSize(self):
23      mod = reshape.Reshape(output_shape=[1, -2])
24      with self.assertRaisesRegex(tf.errors.InvalidArgumentError,
25                                  "[Ss]ize 2 must be non-negative, not -2"):
26        mod(tf.ones([1, 2, 3]))
27    def testInvalid_type(self):
28      mod = reshape.Reshape(output_shape=[7, "string"])
29      with self.assertRaises(ValueError):
30        mod(tf.ones([1, 2, 3]))
31    def testIncompatibleShape(self):
32      mod = reshape.Reshape(output_shape=[2 * 3, 4])
33      input_size = 8 * 2 * 2 * 4
34      output_size = 8 * 2 * 3 * 4
35      msg = ("Input to reshape is a tensor with %d values, "
36             "but the requested shape has %d" % (input_size, output_size))
37      with self.assertRaisesRegex(tf.errors.InvalidArgumentError, msg):
38        mod(tf.ones([8, 2, 2, 4]))
39    def testInferShape(self):
40      batch_size = 10
41      out_size = [2, -1, 5]
42      mod = reshape.Reshape(output_shape=out_size)
43      output = mod(tf.ones([batch_size, 2, 3, 4, 5]))
44      self.assertEqual(output.shape, [batch_size, 2, 3 * 4, 5])
45    def testAddDimensions(self):
46      batch_size = 10
47      mod = reshape.Reshape(output_shape=[1, 1])
48      inputs = tf.ones([batch_size])
49      output = mod(inputs)
50      self.assertEqual(output.shape, [batch_size, 1, 1])
51      mod_t = mod.reversed()
52      t_output = mod_t(output)
53      self.assertEqual(t_output.shape, [batch_size])
54    def testFlatten(self):
55      batch_size = 10
56      inputs = tf.ones([batch_size, 2, 3, 4, 5])
57      mod = reshape.Reshape(output_shape=[-1])
58      output = mod(inputs)
59      self.assertEqual(output.shape, [batch_size, 2 * 3 * 4 * 5])
60    def testUnknownBatchSize(self):
61      mod = reshape.Reshape(output_shape=[-1])
62      input_spec = tf.TensorSpec([None, 2, 3, 4, 5], tf.float32)
63      cf = tf.function(mod).get_concrete_function(input_spec)
64      output, = cf.outputs
65      self.assertEqual(output.shape.as_list(), [None, 2 * 3 * 4 * 5])
66    def testReverse(self):
67      batch_size = 10
68      input_shape = [batch_size, 2, 3, 4, 5]
69      expected_output_shape = [batch_size, 2, 3 * 4, 5]
70      inputs = tf.random.normal(input_shape)
71      mod = reshape.Reshape(output_shape=[2, -1, 5])
72      output = mod(inputs)
73      self.assertEqual(output.shape, expected_output_shape)
74      mod_r = mod.reversed()
75      output_r = mod_r(output)
76      self.assertEqual(output_r.shape, input_shape)
77      mod_r_r = mod_r.reversed()
78      output_r_r = mod_r_r(output)
79      self.assertEqual(output_r_r.shape, expected_output_shape)
80      input_np, output_r_np = self.evaluate([inputs, output_r])
81      self.assertAllClose(output_r_np, input_np)
82    def testReverse_name(self):
83      mod = reshape.Reshape(output_shape=[2, -1, 5])
84      mod(tf.ones([1, 2, 3, 4, 5]))
85      mod_r = mod.reversed()
86      self.assertEqual(mod_r.name, "%s_reversed" % mod.name)
87    def testInvalidPreserveDimsError(self):
88      with self.assertRaisesRegex(ValueError, "preserve_dims"):
89        reshape.Reshape((-1,), preserve_dims=0)
90    def testBuildDimError(self):
91      mod = reshape.Reshape((-1,), preserve_dims=2)
92      input_tensor = tf.ones([50])
93      with self.assertRaisesRegex(ValueError, "preserve_dims"):
94        mod(input_tensor)
95    @parameterized.named_parameters(
96        ("Preserve1", (1,)),
97        ("Preserve24", (2, 4)),
98        ("Preserve?", (None,)),
99        ("Preserve?5", (None, 5)),
100        ("Preserve5?", (5, None)),
101        ("Preserve??", (None, None)),
102    )
103    def testPreserve(self, preserve):
104      shape = list(preserve) + [13, 84, 3, 2]
105      output_shape = [13, 21, 3, 8]
106      preserve_dims = len(preserve)
107      input_spec = tf.TensorSpec(shape, tf.float32)
108      mod = reshape.Reshape(
109          output_shape=output_shape, preserve_dims=preserve_dims)
110      cf = tf.function(mod).get_concrete_function(input_spec)
111      output, = cf.outputs
112      self.assertEqual(output.shape.as_list(), list(preserve) + output_shape)
113    @parameterized.named_parameters(
114        ("Session1", (1,), (2, 3), (-1,)),
115        ("Session2", (1, 7), (2, 3), (-1,)),
116        ("Session3", (None,), (2, 3), (-1,)),
117        ("Session4", (None, 5, None), (2, 3, 4), (4, 6)),
118        ("Session5", (None, None, None), (2, 3, 4), (-1,)),
119        ("Session6", (5, None, None), (1, 3, 1), (-1,)),
120        ("Session7", (1,), (4, 3), (2, 2, 1, 3)),
121        ("Session8", (None,), (4, 3), (2, 2, 1, 3)),
122        ("Session9", (1, None, 5, None), (4, 3), (2, 2, -1, 3)),
123    )
124    def testRun(self, preserve, trailing_in, trailing_out):
125      rng = np.random.RandomState(0)
126      input_shape = preserve + trailing_in
127      output_shape = preserve + np.zeros(trailing_in).reshape(trailing_out).shape
128      input_spec = tf.TensorSpec(input_shape, tf.float32)
129      mod = reshape.Reshape(
130          output_shape=trailing_out, preserve_dims=len(preserve))
131      cf = tf.function(mod).get_concrete_function(input_spec)
132      output, = cf.outputs
133      self.assertEqual(output.shape.as_list(), list(output_shape))
134      actual_input_shape = [13 if i is None else i for i in input_shape]
135      expected_output_shape = [13 if i is None else i for i in output_shape]
136      actual_input = rng.rand(*actual_input_shape).astype(np.float32)
137      expected_output = actual_input.reshape(expected_output_shape)
138      actual_output = cf(tf.convert_to_tensor(actual_input))
139      self.assertAllEqual(actual_output, expected_output)
140  class FlattenTest(test_utils.TestCase, parameterized.TestCase):
141    @parameterized.parameters([1, 10])
142    def testFlatten(self, batch_size):
143      in_shape = [2, 3, 4, 5]
144      inputs = tf.ones([batch_size] + in_shape)
145      mod = reshape.Flatten()
146      output = mod(inputs)
147      flattened_size = np.prod(in_shape, dtype=int)
148      self.assertEqual(output.shape, [batch_size, flattened_size])
149    def testFlatten_unknownBatchSize(self):
<span onclick='openModal()' class='match'>150      mod = reshape.Flatten()
151      f = tf.function(mod)
152      inputs = tf.TensorSpec([None, 1, 2, 3], tf.float32)
</span>153      cf = f.get_concrete_function(inputs)
154      self.assertEqual(cf.outputs[0].shape.as_list(), [None, 1 * 2 * 3])
155      flat = cf(tf.ones([8, 1, 2, 3]))
156      self.assertEqual(flat.shape, [8, 1 * 2 * 3])
157    def testFlatten_unknownNonBatchSize(self):
158      mod = reshape.Flatten()
159      f = tf.function(mod)
160      inputs = tf.TensorSpec([8, None, None, 3], tf.float32)
161      cf = f.get_concrete_function(inputs)
162      self.assertEqual(cf.outputs[0].shape.as_list(), [8, None])
163      flat = cf(tf.ones([8, 1, 2, 3]))
164      self.assertEqual(flat.shape, [8, 1 * 2 * 3])
165    @parameterized.parameters(1, 2, 3, 4)
166    def testPreserveDimsOk(self, preserve_dims):
167      in_shape = [10, 2, 3, 4]
168      inputs = tf.ones(in_shape)
169      mod = reshape.Flatten(preserve_dims=preserve_dims)
170      output = mod(inputs)
171      flattened_shape = (
172          in_shape[:preserve_dims] +
173          [np.prod(in_shape[preserve_dims:], dtype=int)])
174      self.assertEqual(output.shape, flattened_shape)
175    @parameterized.parameters(5, 6, 7, 10)
176    def testPreserveDimsError(self, preserve_dims):
177      in_shape = [10, 2, 3, 4]
178      inputs = tf.ones(in_shape)
179      mod = reshape.Flatten(preserve_dims=preserve_dims)
180      with self.assertRaisesRegex(ValueError, "Input tensor has 4 dimensions"):
181        _ = mod(inputs)
182    def testFlattenWithZeroDim(self):
183      inputs = tf.ones([1, 0])
184      output = reshape.Flatten()(inputs)
185      self.assertEqual(output.shape, [1, 0])
186    def testInvalidFlattenFromError(self):
187      with self.assertRaisesRegex(ValueError, "preserve_dims"):
188        reshape.Flatten(preserve_dims=0)
189    def testBuildDimError(self):
190      mod = reshape.Flatten(preserve_dims=2)
191      input_tensor = tf.ones([50])
192      with self.assertRaisesRegex(ValueError, "should have at least as many as"):
193        mod(input_tensor)
194    @parameterized.parameters([1, 8])
195    def testReverse(self, batch_size):
196      mod = reshape.Flatten(preserve_dims=4)
197      inputs = tf.ones([batch_size, 5, 84, 84, 3, 2])
198      output = mod(inputs)
199      self.assertEqual(output.shape, inputs.shape.as_list()[:4] + [6])
200      mod_r = mod.reversed()
201      output_r = mod_r(output)
202      self.assertEqual(output_r.shape, inputs.shape)
203  if __name__ == "__main__":
204    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-momentum_test.py</div>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-reshape_test.py</div>
                <div class="column column_space"><pre><code>108      learning_rate = tf.Variable(0.1)
109      momentum_coeff = tf.Variable(0.9)
110      optimizer = self.make_optimizer(
</pre></code></div>
                <div class="column column_space"><pre><code>150      mod = reshape.Flatten()
151      f = tf.function(mod)
152      inputs = tf.TensorSpec([None, 1, 2, 3], tf.float32)
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    