
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 16.846652267818573%, Tokens: 10, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-pooling_encoder_test.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import tensorflow as tf
6  import numpy as np
7  from seq2seq.encoders import PoolingEncoder
<span onclick='openModal()' class='match'>8  class PoolingEncoderTest(tf.test.TestCase):
9    def setUp(self):
10      super(PoolingEncoderTest, self).setUp()
11      self.batch_size = 4
12      self.sequence_length = 16
</span>13      self.input_depth = 10
14      self.mode = tf.contrib.learn.ModeKeys.TRAIN
15    def _test_with_params(self, params):
16      inputs = tf.random_normal(
17          [self.batch_size, self.sequence_length, self.input_depth])
18      example_length = tf.ones(
19          self.batch_size, dtype=tf.int32) * self.sequence_length
20      encode_fn = PoolingEncoder(params, self.mode)
21      encoder_output = encode_fn(inputs, example_length)
22      with self.test_session() as sess:
23        sess.run(tf.global_variables_initializer())
24        encoder_output_ = sess.run(encoder_output)
25      np.testing.assert_array_equal(
26          encoder_output_.outputs.shape,
27          [self.batch_size, self.sequence_length, self.input_depth])
28      np.testing.assert_array_equal(
29          encoder_output_.attention_values.shape,
30          [self.batch_size, self.sequence_length, self.input_depth])
31      np.testing.assert_array_equal(encoder_output_.final_state.shape,
32                                    [self.batch_size, self.input_depth])
33    def test_encode_with_pos(self):
34      self._test_with_params({
35          "position_embeddings.enable": True,
36          "position_embeddings.num_positions": self.sequence_length
37      })
38    def test_encode_without_pos(self):
39      self._test_with_params({
40          "position_embeddings.enable": False,
41          "position_embeddings.num_positions": 0
42      })
43  if __name__ == "__main__":
44    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-pipeline_test.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import argparse
6  import imp
7  import os
8  import shutil
9  import tempfile
10  import yaml
11  import numpy as np
12  import tensorflow as tf
13  from tensorflow import gfile
14  from seq2seq.test import utils as test_utils
15  BIN_FOLDER = os.path.abspath(
16      os.path.join(os.path.dirname(__file__), "../../bin"))
17  def _clear_flags():
18    tf.app.flags.FLAGS = tf.app.flags._FlagValues()
19    tf.app.flags._global_parser = argparse.ArgumentParser()
<span onclick='openModal()' class='match'>20  class PipelineTest(tf.test.TestCase):
21    def setUp(self):
22      super(PipelineTest, self).setUp()
23      self.output_dir = tempfile.mkdtemp()
</span>24      self.bin_folder = os.path.abspath(
25          os.path.join(os.path.dirname(__file__), "../../bin"))
26      tf.contrib.framework.get_or_create_global_step()
27    def tearDown(self):
28      shutil.rmtree(self.output_dir, ignore_errors=True)
29      super(PipelineTest, self).tearDown()
30    def test_train_infer(self):
31      sources_train, targets_train = test_utils.create_temp_parallel_data(
32          sources=["a a a a", "b b b b", "c c c c", "笑 笑 笑 笑"],
33          targets=["b b b b", "a a a a", "c c c c", "泣 泣 泣 泣"])
34      sources_dev, targets_dev = test_utils.create_temp_parallel_data(
35          sources=["a a", "b b", "c c c", "笑 笑 笑"],
36          targets=["b b", "a a", "c c c", "泣 泣 泣"])
37      vocab_source = test_utils.create_temporary_vocab_file(["a", "b", "c", "笑"])
38      vocab_target = test_utils.create_temporary_vocab_file(["a", "b", "c", "泣"])
39      _clear_flags()
40      tf.reset_default_graph()
41      train_script = imp.load_source("seq2seq.test.train_bin",
42                                     os.path.join(BIN_FOLDER, "train.py"))
43      tf.app.flags.FLAGS.output_dir = self.output_dir
44      tf.app.flags.FLAGS.hooks = 
45      tf.app.flags.FLAGS.metrics = 
46      tf.app.flags.FLAGS.model = "AttentionSeq2Seq"
47      tf.app.flags.FLAGS.model_params = .format(vocab_source.name, vocab_target.name)
48      tf.app.flags.FLAGS.batch_size = 2
49      config_path = os.path.join(self.output_dir, "train_config.yml")
50      with gfile.GFile(config_path, "w") as config_file:
51        yaml.dump({
52            "input_pipeline_train": {
53                "class": "ParallelTextInputPipeline",
54                "params": {
55                    "source_files": [sources_train.name],
56                    "target_files": [targets_train.name],
57                }
58            },
59            "input_pipeline_dev": {
60                "class": "ParallelTextInputPipeline",
61                "params": {
62                    "source_files": [sources_dev.name],
63                    "target_files": [targets_dev.name],
64                }
65            },
66            "train_steps": 50,
67            "model_params": {
68                "embedding.dim": 10,
69                "decoder.params": {
70                    "rnn_cell": {
71                        "cell_class": "GRUCell",
72                        "cell_params": {
73                            "num_units": 8
74                        }
75                    }
76                },
77                "encoder.params": {
78                    "rnn_cell": {
79                        "cell_class": "GRUCell",
80                        "cell_params": {
81                            "num_units": 8
82                        }
83                    }
84                }
85            }
86        }, config_file)
87      tf.app.flags.FLAGS.config_paths = config_path
88      tf.logging.set_verbosity(tf.logging.INFO)
89      train_script.main([])
90      expected_checkpoint = os.path.join(self.output_dir,
91                                         "model.ckpt-50.data-00000-of-00001")
92      self.assertTrue(os.path.exists(expected_checkpoint))
93      _clear_flags()
94      tf.reset_default_graph()
95      infer_script = imp.load_source("seq2seq.test.infer_bin",
96                                     os.path.join(BIN_FOLDER, "infer.py"))
97      attention_dir = os.path.join(self.output_dir, "att")
98      tf.app.flags.FLAGS.model_dir = self.output_dir
99      tf.app.flags.FLAGS.input_pipeline = .format(sources_dev.name, targets_dev.name)
100      tf.app.flags.FLAGS.batch_size = 2
101      tf.app.flags.FLAGS.checkpoint_path = os.path.join(self.output_dir,
102                                                        "model.ckpt-50")
103      tf.app.flags.FLAGS.tasks = .format(attention_dir)
104      infer_script.main([])
105      self.assertTrue(
106          os.path.exists(os.path.join(attention_dir, "attention_scores.npz")))
107      self.assertTrue(os.path.exists(os.path.join(attention_dir, "00002.png")))
108      scores = np.load(os.path.join(attention_dir, "attention_scores.npz"))
109      self.assertIn("arr_0", scores)
110      self.assertEqual(scores["arr_0"].shape[1], 3)
111      self.assertIn("arr_1", scores)
112      self.assertEqual(scores["arr_1"].shape[1], 3)
113      self.assertIn("arr_2", scores)
114      self.assertEqual(scores["arr_2"].shape[1], 4)
115      self.assertIn("arr_3", scores)
116      self.assertEqual(scores["arr_3"].shape[1], 4)
117      _clear_flags()
118      tf.reset_default_graph()
119      infer_script = imp.load_source("seq2seq.test.infer_bin",
120                                     os.path.join(BIN_FOLDER, "infer.py"))
121      tf.app.flags.FLAGS.model_dir = self.output_dir
122      tf.app.flags.FLAGS.input_pipeline = .format(sources_dev.name, targets_dev.name)
123      tf.app.flags.FLAGS.batch_size = 2
124      tf.app.flags.FLAGS.checkpoint_path = os.path.join(self.output_dir,
125                                                        "model.ckpt-50")
126      tf.app.flags.FLAGS.model_params = 
127      tf.app.flags.FLAGS.tasks = .format(os.path.join(self.output_dir, "beams.npz"))
128      infer_script.main([])
129      self.assertTrue(os.path.exists(os.path.join(self.output_dir, "beams.npz")))
130  if __name__ == "__main__":
131    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-pooling_encoder_test.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-pipeline_test.py</div>
                </div>
                <div class="column column_space"><pre><code>8  class PoolingEncoderTest(tf.test.TestCase):
9    def setUp(self):
10      super(PoolingEncoderTest, self).setUp()
11      self.batch_size = 4
12      self.sequence_length = 16
</pre></code></div>
                <div class="column column_space"><pre><code>20  class PipelineTest(tf.test.TestCase):
21    def setUp(self):
22      super(PipelineTest, self).setUp()
23      self.output_dir = tempfile.mkdtemp()
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    