
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 12, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-hooks.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import abc
6  import os
7  import numpy as np
8  import six
9  import yaml
10  import tensorflow as tf
11  from tensorflow.python.training.basic_session_run_hooks import SecondOrStepTimer  # pylint: disable=E0611
12  from tensorflow.python.training import session_manager # pylint: disable=E0611
13  from tensorflow.python.client import timeline  # pylint: disable=E0611
14  from tensorflow import gfile
15  from seq2seq.configurable import Configurable, abstractstaticmethod
16  from seq2seq import graph_utils, global_vars
17  FLAGS = tf.flags.FLAGS
18  @six.add_metaclass(abc.ABCMeta)
19  class TrainingHook(tf.train.SessionRunHook, Configurable):
20    def __init__(self, params, model_dir, run_config):
21      tf.train.SessionRunHook.__init__(self)
22      Configurable.__init__(self, params, tf.contrib.learn.ModeKeys.TRAIN)
23      self._model_dir = model_dir
24      self._run_config = run_config
25    @property
26    def model_dir(self):
27      return os.path.abspath(self._model_dir)
28    @property
29    def is_chief(self):
30      return self._run_config.is_chief
31    @abstractstaticmethod
32    def default_params():
33      raise NotImplementedError()
34  class MetadataCaptureHook(TrainingHook):
35    def __init__(self, params, model_dir, run_config):
36      super(MetadataCaptureHook, self).__init__(params, model_dir, run_config)
37      self._active = False
38      self._done = False
39      self._global_step = None
40      self._output_dir = os.path.abspath(self.model_dir)
41    @staticmethod
42    def default_params():
43      return {"step": 10}
44    def begin(self):
45      self._global_step = tf.train.get_global_step()
46    def before_run(self, _run_context):
47      if not self.is_chief or self._done:
48        return
49      if not self._active:
50        return tf.train.SessionRunArgs(self._global_step)
51      else:
52        tf.logging.info("Performing full trace on next step.")
53        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE) #pylint: disable=E1101
54        return tf.train.SessionRunArgs(self._global_step, options=run_options)
55    def after_run(self, _run_context, run_values):
56      if not self.is_chief or self._done:
57        return
58      step_done = run_values.results
59      if self._active:
60        tf.logging.info("Captured full trace at step %s", step_done)
61        gfile.MakeDirs(self._output_dir)
62        trace_path = os.path.join(self._output_dir, "run_meta")
63        with gfile.GFile(trace_path, "wb") as trace_file:
64          trace_file.write(run_values.run_metadata.SerializeToString())
65          tf.logging.info("Saved run_metadata to %s", trace_path)
66        timeline_path = os.path.join(self._output_dir, "timeline.json")
67        with gfile.GFile(timeline_path, "w") as timeline_file:
68          tl_info = timeline.Timeline(run_values.run_metadata.step_stats)
69          tl_chrome = tl_info.generate_chrome_trace_format(show_memory=True)
70          timeline_file.write(tl_chrome)
71          tf.logging.info("Saved timeline to %s", timeline_path)
72        tf.contrib.tfprof.tfprof_logger.write_op_log(
73            graph=tf.get_default_graph(),
74            log_dir=self._output_dir,
75            run_meta=run_values.run_metadata)
<span onclick='openModal()' class='match'>76        tf.logging.info("Saved op log to %s", self._output_dir)
77        self._active = False
</span>78        self._done = True
79      self._active = (step_done >= self.params["step"])
80  class TrainSampleHook(TrainingHook):
81    def __init__(self, params, model_dir, run_config):
82      super(TrainSampleHook, self).__init__(params, model_dir, run_config)
83      self._sample_dir = os.path.join(self.model_dir, "samples")
84      self._timer = SecondOrStepTimer(
85          every_secs=self.params["every_n_secs"],
86          every_steps=self.params["every_n_steps"])
87      self._pred_dict = {}
88      self._should_trigger = False
89      self._iter_count = 0
90      self._global_step = None
91      self._source_delimiter = self.params["source_delimiter"]
92      self._target_delimiter = self.params["target_delimiter"]
93    @staticmethod
94    def default_params():
95      return {
96          "every_n_secs": None,
97          "every_n_steps": 1000,
98          "source_delimiter": " ",
99          "target_delimiter": " "
100      }
101    def begin(self):
102      self._iter_count = 0
103      self._global_step = tf.train.get_global_step()
104      self._pred_dict = graph_utils.get_dict_from_collection("predictions")
105      if self._sample_dir is not None:
106        gfile.MakeDirs(self._sample_dir)
107    def before_run(self, _run_context):
108      self._should_trigger = self._timer.should_trigger_for_step(self._iter_count)
109      if self._should_trigger:
110        fetches = {
111            "predicted_tokens": self._pred_dict["predicted_tokens"],
112            "target_words": self._pred_dict["labels.target_tokens"],
113            "target_len": self._pred_dict["labels.target_len"]
114        }
115        return tf.train.SessionRunArgs([fetches, self._global_step])
116      return tf.train.SessionRunArgs([{}, self._global_step])
117    def after_run(self, _run_context, run_values):
118      result_dict, step = run_values.results
119      self._iter_count = step
120      if not self._should_trigger:
121        return None
122      result_dicts = [
123          dict(zip(result_dict, t)) for t in zip(*result_dict.values())
124      ]
125      result_str = ""
126      result_str += "Prediction followed by Target @ Step {}\n".format(step)
127      result_str += ("=" * 100) + "\n"
128      for result in result_dicts:
129        target_len = result["target_len"]
130        predicted_slice = result["predicted_tokens"][:target_len - 1]
131        target_slice = result["target_words"][1:target_len]
132        result_str += self._target_delimiter.encode("utf-8").join(
133            predicted_slice).decode("utf-8") + "\n"
134        result_str += self._target_delimiter.encode("utf-8").join(
135            target_slice).decode("utf-8") + "\n\n"
136      result_str += ("=" * 100) + "\n\n"
137      tf.logging.info(result_str)
138      if self._sample_dir:
139        filepath = os.path.join(self._sample_dir,
140                                "samples_{:06d}.txt".format(step))
141        with gfile.GFile(filepath, "w") as file:
142          file.write(result_str)
143      self._timer.update_last_triggered_step(self._iter_count - 1)
144  class PrintModelAnalysisHook(TrainingHook):
145    def __init__(self, params, model_dir, run_config):
146      super(PrintModelAnalysisHook, self).__init__(params, model_dir, run_config)
147      self._filename = os.path.join(self.model_dir, "model_analysis.txt")
148    @staticmethod
149    def default_params():
150      return {}
151    def begin(self):
152      if self.is_chief:
153        opts = tf.contrib.tfprof.model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS
154        opts['dump_to_file'] = os.path.abspath(self._filename)
155        tf.contrib.tfprof.model_analyzer.print_model_analysis(
156            tf.get_default_graph(), tfprof_options=opts)
157      with gfile.GFile(self._filename) as file:
158        tf.logging.info(file.read())
159  class VariableRestoreHook(TrainingHook):
160    def __init__(self, params, model_dir, run_config):
161      super(VariableRestoreHook, self).__init__(params, model_dir, run_config)
162      self._saver = None
163    @staticmethod
164    def default_params():
165      return {"prefix": "", "checkpoint_path": ""}
166    def begin(self):
167      variables = tf.contrib.framework.get_variables(scope=self.params["prefix"])
168      def varname_in_checkpoint(name):
169        prefix_parts = self.params["prefix"].split("/")
170        checkpoint_prefix = "/".join(prefix_parts[:-1])
171        return name.replace(checkpoint_prefix + "/", "")
172      target_names = [varname_in_checkpoint(_.op.name) for _ in variables]
173      restore_map = {k: v for k, v in zip(target_names, variables)}
174      tf.logging.info("Restoring variables: \n%s",
175                      yaml.dump({k: v.op.name
176                                 for k, v in restore_map.items()}))
177      self._saver = tf.train.Saver(restore_map)
178    def after_create_session(self, session, coord):
179      self._saver.restore(session, self.params["checkpoint_path"])
180      tf.logging.info("Successfully restored all variables")
181  class DelayStartHook(TrainingHook, tf.train.GlobalStepWaiterHook):
182    def __init__(self, params, model_dir, run_config):
183      TrainingHook.__init__(self, params, model_dir, run_config)
184      self._task_id = self._run_config.task_id
185      self._delay_k = self.params["delay_k"]
186      self._wait_until_step = int(self._delay_k * self._task_id)
187      tf.train.GlobalStepWaiterHook.__init__(self, self._wait_until_step)
188    @staticmethod
189    def default_params():
190      return {"delay_k": 500}
191  class SyncReplicasOptimizerHook(TrainingHook):
192    def __init__(self, params, model_dir, run_config):
193      super(SyncReplicasOptimizerHook, self).__init__(
194          params, model_dir, run_config)
195      self._sync_optimizer = None
196      self._num_tokens = -1
197      self._local_init_op = None
198      self._ready_for_local_init_op = None
199      self._q_runner = None
200      self._init_tokens_op = None
201    @staticmethod
202    def default_params():
203      return {}
204    def begin(self):
205      if global_vars.SYNC_REPLICAS_OPTIMIZER is not None:
206        self._sync_optimizer = global_vars.SYNC_REPLICAS_OPTIMIZER
207      else:
208        return
209      if self._sync_optimizer._gradients_applied is False:  # pylint: disable=protected-access
210        raise ValueError(
211            "SyncReplicasOptimizer.apply_gradient should be called before using "
212            "the hook.")
213      if self.is_chief:
214        self._local_init_op = self._sync_optimizer.chief_init_op
215        self._ready_for_local_init_op = (
216            self._sync_optimizer.ready_for_local_init_op)
217        self._q_runner = self._sync_optimizer.get_chief_queue_runner()
218        self._init_tokens_op = self._sync_optimizer.get_init_tokens_op(
219            self._num_tokens)
220      else:
221        self._local_init_op = self._sync_optimizer.local_step_init_op
222        self._ready_for_local_init_op = (
223            self._sync_optimizer.ready_for_local_init_op)
224        self._q_runner = None
225        self._init_tokens_op = None
226    def after_create_session(self, session, coord):
227      if not self._sync_optimizer:
228        return
229      tf.logging.info("Found SyncReplicasOptimizer. Initializing.")
230      local_init_success, msg = session_manager._ready(  # pylint: disable=protected-access
231          self._ready_for_local_init_op, session,
232          "Model is not ready for SyncReplicasOptimizer local init.")
233      if not local_init_success:
234        raise RuntimeError(
235            "Init operations did not make model ready for SyncReplicasOptimizer "
236            "local_init. Init op: %s, error: %s" %
237            (self._local_init_op.name, msg))
238      session.run(self._local_init_op)
239      if self._init_tokens_op is not None:
240        session.run(self._init_tokens_op)
241      if self._q_runner is not None:
242        self._q_runner.create_threads(
243            session, coord=coord, daemon=True, start=True)
</code></pre>
        </div>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-train.py</h3>
            <pre><code>1  #! /usr/bin/env python
2  from __future__ import absolute_import
3  from __future__ import division
4  from __future__ import print_function
5  from __future__ import unicode_literals
6  import os
7  import tempfile
8  import yaml
9  import tensorflow as tf
10  from tensorflow.contrib.learn.python.learn import learn_runner
11  from tensorflow.contrib.learn.python.learn.estimators import run_config
12  from tensorflow import gfile
13  from seq2seq import models
14  from seq2seq.contrib.experiment import Experiment as PatchedExperiment
15  from seq2seq.configurable import _maybe_load_yaml, _create_from_dict
16  from seq2seq.configurable import _deep_merge_dict
17  from seq2seq.data import input_pipeline
18  from seq2seq.metrics import metric_specs
19  from seq2seq.training import hooks
20  from seq2seq.training import utils as training_utils
21  tf.flags.DEFINE_string("config_paths", "",
22                         )
23  tf.flags.DEFINE_string("hooks", "[]",
24                         )
25  tf.flags.DEFINE_string("metrics", "[]",
26                         )
27  tf.flags.DEFINE_string("model", "",
28                         )
29  tf.flags.DEFINE_string("model_params", "{}",
30                         )
31  tf.flags.DEFINE_string("input_pipeline_train", "{}",
32                         )
33  tf.flags.DEFINE_string("input_pipeline_dev", "{}",
34                         )
35  tf.flags.DEFINE_string("buckets", None,
36                         )
37  tf.flags.DEFINE_integer("batch_size", 16,
38                          )
39  tf.flags.DEFINE_string("output_dir", None,
40                         )
41  tf.flags.DEFINE_string("schedule", "continuous_train_and_eval",
42                         )
43  tf.flags.DEFINE_integer("train_steps", None,
44                          )
45  tf.flags.DEFINE_integer("eval_every_n_steps", 1000,
46                          "Run evaluation on validation data every N steps.")
47  tf.flags.DEFINE_integer("tf_random_seed", None,
48                          )
49  tf.flags.DEFINE_integer("save_checkpoints_secs", None,
50                          )
51  tf.flags.DEFINE_integer("save_checkpoints_steps", None,
52                          )
53  tf.flags.DEFINE_integer("keep_checkpoint_max", 5,
54                          )
55  tf.flags.DEFINE_integer("keep_checkpoint_every_n_hours", 4,
56                          )
57  tf.flags.DEFINE_float("gpu_memory_fraction", 1.0,
58                        )
59  tf.flags.DEFINE_boolean("gpu_allow_growth", False,
60                          )
61  tf.flags.DEFINE_boolean("log_device_placement", False,
62                          )
63  FLAGS = tf.flags.FLAGS
64  def create_experiment(output_dir):
65    config = run_config.RunConfig(
66        tf_random_seed=FLAGS.tf_random_seed,
67        save_checkpoints_secs=FLAGS.save_checkpoints_secs,
68        save_checkpoints_steps=FLAGS.save_checkpoints_steps,
69        keep_checkpoint_max=FLAGS.keep_checkpoint_max,
70        keep_checkpoint_every_n_hours=FLAGS.keep_checkpoint_every_n_hours,
71        gpu_memory_fraction=FLAGS.gpu_memory_fraction)
72    config.tf_config.gpu_options.allow_growth = FLAGS.gpu_allow_growth
73    config.tf_config.log_device_placement = FLAGS.log_device_placement
74    train_options = training_utils.TrainOptions(
75        model_class=FLAGS.model,
76        model_params=FLAGS.model_params)
77    if config.is_chief:
78      gfile.MakeDirs(output_dir)
79      train_options.dump(output_dir)
80    bucket_boundaries = None
81    if FLAGS.buckets:
82      bucket_boundaries = list(map(int, FLAGS.buckets.split(",")))
83    train_input_pipeline = input_pipeline.make_input_pipeline_from_def(
84        def_dict=FLAGS.input_pipeline_train,
85        mode=tf.contrib.learn.ModeKeys.TRAIN)
86    train_input_fn = training_utils.create_input_fn(
87        pipeline=train_input_pipeline,
88        batch_size=FLAGS.batch_size,
89        bucket_boundaries=bucket_boundaries,
90        scope="train_input_fn")
91    dev_input_pipeline = input_pipeline.make_input_pipeline_from_def(
92        def_dict=FLAGS.input_pipeline_dev,
93        mode=tf.contrib.learn.ModeKeys.EVAL,
94        shuffle=False, num_epochs=1)
95    eval_input_fn = training_utils.create_input_fn(
96        pipeline=dev_input_pipeline,
97        batch_size=FLAGS.batch_size,
98        allow_smaller_final_batch=True,
99        scope="dev_input_fn")
100    def model_fn(features, labels, params, mode):
101      model = _create_from_dict({
102          "class": train_options.model_class,
103          "params": train_options.model_params
104      }, models, mode=mode)
105      return model(features, labels, params)
106    estimator = tf.contrib.learn.Estimator(
107        model_fn=model_fn,
108        model_dir=output_dir,
109        config=config,
110        params=FLAGS.model_params)
111    train_hooks = []
112    for dict_ in FLAGS.hooks:
113      hook = _create_from_dict(
114          dict_, hooks,
115          model_dir=estimator.model_dir,
116          run_config=config)
117      train_hooks.append(hook)
118    eval_metrics = {}
119    for dict_ in FLAGS.metrics:
120      metric = _create_from_dict(dict_, metric_specs)
121      eval_metrics[metric.name] = metric
122    experiment = PatchedExperiment(
123        estimator=estimator,
124        train_input_fn=train_input_fn,
125        eval_input_fn=eval_input_fn,
126        min_eval_frequency=FLAGS.eval_every_n_steps,
127        train_steps=FLAGS.train_steps,
128        eval_steps=None,
129        eval_metrics=eval_metrics,
130        train_monitors=train_hooks)
131    return experiment
132  def main(_argv):
133    FLAGS.hooks = _maybe_load_yaml(FLAGS.hooks)
134    FLAGS.metrics = _maybe_load_yaml(FLAGS.metrics)
135    FLAGS.model_params = _maybe_load_yaml(FLAGS.model_params)
136    FLAGS.input_pipeline_train = _maybe_load_yaml(FLAGS.input_pipeline_train)
137    FLAGS.input_pipeline_dev = _maybe_load_yaml(FLAGS.input_pipeline_dev)
138    final_config = {}
139    if FLAGS.config_paths:
140      for config_path in FLAGS.config_paths.split(","):
141        config_path = config_path.strip()
142        if not config_path:
143          continue
144        config_path = os.path.abspath(config_path)
145        tf.logging.info("Loading config from %s", config_path)
146        with gfile.GFile(config_path.strip()) as config_file:
147          config_flags = yaml.load(config_file)
148          final_config = _deep_merge_dict(final_config, config_flags)
149    tf.logging.info("Final Config:\n%s", yaml.dump(final_config))
150    for flag_key, flag_value in final_config.items():
151      if hasattr(FLAGS, flag_key) and isinstance(getattr(FLAGS, flag_key), dict):
152        merged_value = _deep_merge_dict(flag_value, getattr(FLAGS, flag_key))
153        setattr(FLAGS, flag_key, merged_value)
154      elif hasattr(FLAGS, flag_key):
155        setattr(FLAGS, flag_key, flag_value)
156      else:
157        tf.logging.warning("Ignoring config flag: %s", flag_key)
158    if FLAGS.save_checkpoints_secs is None \
159      and FLAGS.save_checkpoints_steps is None:
160      FLAGS.save_checkpoints_secs = 600
<span onclick='openModal()' class='match'>161      tf.logging.info("Setting save_checkpoints_secs to %d",
162                      FLAGS.save_checkpoints_secs)
163    if not FLAGS.output_dir:
</span>164      FLAGS.output_dir = tempfile.mkdtemp()
165    if not FLAGS.input_pipeline_train:
166      raise ValueError("You must specify input_pipeline_train")
167    if not FLAGS.input_pipeline_dev:
168      raise ValueError("You must specify input_pipeline_dev")
169    learn_runner.run(
170        experiment_fn=create_experiment,
171        output_dir=FLAGS.output_dir,
172        schedule=FLAGS.schedule)
173  if __name__ == "__main__":
174    tf.logging.set_verbosity(tf.logging.INFO)
175    tf.app.run()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-hooks.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-train.py</div>
                </div>
                <div class="column column_space"><pre><code>76        tf.logging.info("Saved op log to %s", self._output_dir)
77        self._active = False
</pre></code></div>
                <div class="column column_space"><pre><code>161      tf.logging.info("Setting save_checkpoints_secs to %d",
162                      FLAGS.save_checkpoints_secs)
163    if not FLAGS.output_dir:
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    