
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 9.36058009228741%, Tokens: 9</h2>
        <div class="column">
            <h3>google-api-python-client-MDEwOlJlcG9zaXRvcnkxNTc0OTI2OQ==-flat-discovery.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  __author__ = "jcgregorio@google.com (Joe Gregorio)"
3  __all__ = ["build", "build_from_document", "fix_method_name", "key2param"]
4  from collections import OrderedDict
5  import collections.abc
6  import copy
7  from email.generator import BytesGenerator
8  from email.mime.multipart import MIMEMultipart
9  from email.mime.nonmultipart import MIMENonMultipart
10  import http.client as http_client
11  import io
12  import json
13  import keyword
14  import logging
15  import mimetypes
16  import os
17  import re
18  import urllib
19  import google.api_core.client_options
20  from google.auth.exceptions import MutualTLSChannelError
21  from google.auth.transport import mtls
22  from google.oauth2 import service_account
23  import httplib2
24  import uritemplate
25  try:
26      import google_auth_httplib2
27  except ImportError:  # pragma: NO COVER
28      google_auth_httplib2 = None
29  from googleapiclient import _auth, mimeparse
30  from googleapiclient._helpers import _add_query_parameter, positional
31  from googleapiclient.errors import (
32      HttpError,
33      InvalidJsonError,
34      MediaUploadSizeError,
35      UnacceptableMimeTypeError,
36      UnknownApiNameOrVersion,
37      UnknownFileType,
38  )
39  from googleapiclient.http import (
40      BatchHttpRequest,
41      HttpMock,
42      HttpMockSequence,
43      HttpRequest,
44      MediaFileUpload,
45      MediaUpload,
46      build_http,
47  )
48  from googleapiclient.model import JsonModel, MediaModel, RawModel
49  from googleapiclient.schema import Schemas
50  httplib2.RETRIES = 1
51  logger = logging.getLogger(__name__)
52  URITEMPLATE = re.compile("{[^}]*}")
53  VARNAME = re.compile("[a-zA-Z0-9_-]+")
54  DISCOVERY_URI = (
55      "https://www.googleapis.com/discovery/v1/apis/" "{api}/{apiVersion}/rest"
56  )
57  V1_DISCOVERY_URI = DISCOVERY_URI
58  V2_DISCOVERY_URI = (
59      "https://{api}.googleapis.com/$discovery/rest?" "version={apiVersion}"
60  )
61  DEFAULT_METHOD_DOC = "A description of how to use this function"
62  HTTP_PAYLOAD_METHODS = frozenset(["PUT", "POST", "PATCH"])
63  _MEDIA_SIZE_BIT_SHIFTS = {"KB": 10, "MB": 20, "GB": 30, "TB": 40}
64  BODY_PARAMETER_DEFAULT_VALUE = {"description": "The request body.", "type": "object"}
65  MEDIA_BODY_PARAMETER_DEFAULT_VALUE = {
66      "description": (
67          "The filename of the media request body, or an instance "
68          "of a MediaUpload object."
69      ),
70      "type": "string",
71      "required": False,
72  }
73  MEDIA_MIME_TYPE_PARAMETER_DEFAULT_VALUE = {
74      "description": (
75          "The MIME type of the media request body, or an instance "
76          "of a MediaUpload object."
77      ),
78      "type": "string",
79      "required": False,
80  }
81  _PAGE_TOKEN_NAMES = ("pageToken", "nextPageToken")
82  GOOGLE_API_USE_CLIENT_CERTIFICATE = "GOOGLE_API_USE_CLIENT_CERTIFICATE"
83  GOOGLE_API_USE_MTLS_ENDPOINT = "GOOGLE_API_USE_MTLS_ENDPOINT"
84  STACK_QUERY_PARAMETERS = frozenset(["trace", "pp", "userip", "strict"])
85  STACK_QUERY_PARAMETER_DEFAULT_VALUE = {"type": "string", "location": "query"}
86  RESERVED_WORDS = frozenset(["body"])
87  class _BytesGenerator(BytesGenerator):
88      _write_lines = BytesGenerator.write
89  def fix_method_name(name):
90      name = name.replace("$", "_").replace("-", "_")
91      if keyword.iskeyword(name) or name in RESERVED_WORDS:
92          return name + "_"
93      else:
94          return name
95  def key2param(key):
96      result = []
97      key = list(key)
98      if not key[0].isalpha():
99          result.append("x")
100      for c in key:
101          if c.isalnum():
102              result.append(c)
103          else:
104              result.append("_")
105      return "".join(result)
106  @positional(2)
107  def build(
108      serviceName,
109      version,
110      http=None,
111      discoveryServiceUrl=None,
112      developerKey=None,
113      model=None,
114      requestBuilder=HttpRequest,
115      credentials=None,
116      cache_discovery=True,
117      cache=None,
118      client_options=None,
119      adc_cert_path=None,
120      adc_key_path=None,
121      num_retries=1,
122      static_discovery=None,
123      always_use_jwt_access=False,
124  ):
125      params = {"api": serviceName, "apiVersion": version}
126      if static_discovery is None:
127          if discoveryServiceUrl is None:
128              static_discovery = True
129          else:
130              static_discovery = False
131      if http is None:
132          discovery_http = build_http()
133      else:
134          discovery_http = http
135      service = None
136      for discovery_url in _discovery_service_uri_options(discoveryServiceUrl, version):
137          requested_url = uritemplate.expand(discovery_url, params)
138          try:
139              content = _retrieve_discovery_doc(
140                  requested_url,
141                  discovery_http,
142                  cache_discovery,
143                  serviceName,
144                  version,
145                  cache,
146                  developerKey,
147                  num_retries=num_retries,
148                  static_discovery=static_discovery,
149              )
150              service = build_from_document(
151                  content,
152                  base=discovery_url,
153                  http=http,
154                  developerKey=developerKey,
155                  model=model,
156                  requestBuilder=requestBuilder,
157                  credentials=credentials,
158                  client_options=client_options,
159                  adc_cert_path=adc_cert_path,
160                  adc_key_path=adc_key_path,
161                  always_use_jwt_access=always_use_jwt_access,
162              )
163              break  # exit if a service was created
164          except HttpError as e:
165              if e.resp.status == http_client.NOT_FOUND:
166                  continue
167              else:
168                  raise e
169      if http is None:
170          discovery_http.close()
171      if service is None:
172          raise UnknownApiNameOrVersion("name: %s  version: %s" % (serviceName, version))
173      else:
174          return service
175  def _discovery_service_uri_options(discoveryServiceUrl, version):
176      if discoveryServiceUrl is not None:
177          return [discoveryServiceUrl]
178      if version is None:
179          logger.warning(
180              "Discovery V1 does not support empty versions. Defaulting to V2..."
181          )
182          return [V2_DISCOVERY_URI]
183      else:
184          return [DISCOVERY_URI, V2_DISCOVERY_URI]
185  def _retrieve_discovery_doc(
186      url,
187      http,
188      cache_discovery,
189      serviceName,
190      version,
191      cache=None,
192      developerKey=None,
193      num_retries=1,
194      static_discovery=True,
195  ):
196      from . import discovery_cache
197      if cache_discovery:
198          if cache is None:
199              cache = discovery_cache.autodetect()
200          if cache:
201              content = cache.get(url)
202              if content:
203                  return content
204      if static_discovery:
205          content = discovery_cache.get_static_doc(serviceName, version)
206          if content:
207              return content
208          else:
209              raise UnknownApiNameOrVersion(
210                  "name: %s  version: %s" % (serviceName, version)
211              )
212      actual_url = url
213      if "REMOTE_ADDR" in os.environ:
214          actual_url = _add_query_parameter(url, "userIp", os.environ["REMOTE_ADDR"])
215      if developerKey:
216          actual_url = _add_query_parameter(url, "key", developerKey)
217      logger.debug("URL being requested: GET %s", actual_url)
218      req = HttpRequest(http, HttpRequest.null_postproc, actual_url)
219      resp, content = req.execute(num_retries=num_retries)
220      try:
221          content = content.decode("utf-8")
222      except AttributeError:
223          pass
224      try:
225          service = json.loads(content)
226      except ValueError as e:
227          logger.error("Failed to parse as JSON: " + content)
228          raise InvalidJsonError()
229      if cache_discovery and cache:
230          cache.set(url, content)
231      return content
232  @positional(1)
233  def build_from_document(
234      service,
235      base=None,
236      future=None,
237      http=None,
238      developerKey=None,
239      model=None,
240      requestBuilder=HttpRequest,
241      credentials=None,
242      client_options=None,
243      adc_cert_path=None,
244      adc_key_path=None,
245      always_use_jwt_access=False,
246  ):
247      if client_options is None:
248          client_options = google.api_core.client_options.ClientOptions()
249      if isinstance(client_options, collections.abc.Mapping):
250          client_options = google.api_core.client_options.from_dict(client_options)
251      if http is not None:
252          banned_options = [
253              (credentials, "credentials"),
254              (client_options.credentials_file, "client_options.credentials_file"),
255          ]
256          for option, name in banned_options:
257              if option is not None:
258                  raise ValueError(
259                      "Arguments http and {} are mutually exclusive".format(name)
260                  )
261      if isinstance(service, str):
262          service = json.loads(service)
263      elif isinstance(service, bytes):
264          service = json.loads(service.decode("utf-8"))
265      if "rootUrl" not in service and isinstance(http, (HttpMock, HttpMockSequence)):
266          logger.error(
267              "You are using HttpMock or HttpMockSequence without"
268              + "having the service discovery doc in cache. Try calling "
269              + "build() without mocking once first to populate the "
270              + "cache."
271          )
272          raise InvalidJsonError()
273      base = urllib.parse.urljoin(service["rootUrl"], service["servicePath"])
274      audience_for_self_signed_jwt = base
275      if client_options.api_endpoint:
276          base = client_options.api_endpoint
277      schema = Schemas(service)
278      if http is None:
<span onclick='openModal()' class='match'>279          scopes = list(
280              service.get("auth", {}).get("oauth2", {}).get("scopes", {}).keys()
</span>281          )
282          if scopes and not developerKey:
283              if client_options.credentials_file and credentials:
284                  raise google.api_core.exceptions.DuplicateCredentialArgs(
285                      "client_options.credentials_file and credentials are mutually exclusive."
286                  )
287              if client_options.credentials_file:
288                  credentials = _auth.credentials_from_file(
289                      client_options.credentials_file,
290                      scopes=client_options.scopes,
291                      quota_project_id=client_options.quota_project_id,
292                  )
293              if credentials is None:
294                  credentials = _auth.default_credentials(
295                      scopes=client_options.scopes,
296                      quota_project_id=client_options.quota_project_id,
297                  )
298              if not client_options.scopes:
299                  credentials = _auth.with_scopes(credentials, scopes)
300          if (
301              credentials
302              and isinstance(credentials, service_account.Credentials)
303              and always_use_jwt_access
304              and hasattr(service_account.Credentials, "with_always_use_jwt_access")
305          ):
306              credentials = credentials.with_always_use_jwt_access(always_use_jwt_access)
307              credentials._create_self_signed_jwt(audience_for_self_signed_jwt)
308          if credentials:
309              http = _auth.authorized_http(credentials)
310          else:
311              http = build_http()
312          client_cert_to_use = None
313          use_client_cert = os.getenv(GOOGLE_API_USE_CLIENT_CERTIFICATE, "false")
314          if not use_client_cert in ("true", "false"):
315              raise MutualTLSChannelError(
316                  "Unsupported GOOGLE_API_USE_CLIENT_CERTIFICATE value. Accepted values: true, false"
317              )
318          if client_options and client_options.client_cert_source:
319              raise MutualTLSChannelError(
320                  "ClientOptions.client_cert_source is not supported, please use ClientOptions.client_encrypted_cert_source."
321              )
322          if use_client_cert == "true":
323              if (
324                  client_options
325                  and hasattr(client_options, "client_encrypted_cert_source")
326                  and client_options.client_encrypted_cert_source
327              ):
328                  client_cert_to_use = client_options.client_encrypted_cert_source
329              elif (
330                  adc_cert_path and adc_key_path and mtls.has_default_client_cert_source()
331              ):
332                  client_cert_to_use = mtls.default_client_encrypted_cert_source(
333                      adc_cert_path, adc_key_path
334                  )
335          if client_cert_to_use:
336              cert_path, key_path, passphrase = client_cert_to_use()
337              http_channel = (
338                  http.http
339                  if google_auth_httplib2
340                  and isinstance(http, google_auth_httplib2.AuthorizedHttp)
341                  else http
342              )
343              http_channel.add_certificate(key_path, cert_path, "", passphrase)
344          if "mtlsRootUrl" in service and (
345              not client_options or not client_options.api_endpoint
346          ):
347              mtls_endpoint = urllib.parse.urljoin(
348                  service["mtlsRootUrl"], service["servicePath"]
349              )
350              use_mtls_endpoint = os.getenv(GOOGLE_API_USE_MTLS_ENDPOINT, "auto")
351              if not use_mtls_endpoint in ("never", "auto", "always"):
352                  raise MutualTLSChannelError(
353                      "Unsupported GOOGLE_API_USE_MTLS_ENDPOINT value. Accepted values: never, auto, always"
354                  )
355              if use_mtls_endpoint == "always" or (
356                  use_mtls_endpoint == "auto" and client_cert_to_use
357              ):
358                  base = mtls_endpoint
359      if model is None:
360          features = service.get("features", [])
361          model = JsonModel("dataWrapper" in features)
362      return Resource(
363          http=http,
364          baseUrl=base,
365          model=model,
366          developerKey=developerKey,
367          requestBuilder=requestBuilder,
368          resourceDesc=service,
369          rootDesc=service,
370          schema=schema,
371      )
372  def _cast(value, schema_type):
373      if schema_type == "string":
374          if type(value) == type("") or type(value) == type(""):
375              return value
376          else:
377              return str(value)
378      elif schema_type == "integer":
379          return str(int(value))
380      elif schema_type == "number":
381          return str(float(value))
382      elif schema_type == "boolean":
383          return str(bool(value)).lower()
384      else:
385          if type(value) == type("") or type(value) == type(""):
386              return value
387          else:
388              return str(value)
389  def _media_size_to_long(maxSize):
390      if len(maxSize) < 2:
391          return 0
392      units = maxSize[-2:].upper()
393      bit_shift = _MEDIA_SIZE_BIT_SHIFTS.get(units)
394      if bit_shift is not None:
395          return int(maxSize[:-2]) << bit_shift
396      else:
397          return int(maxSize)
398  def _media_path_url_from_info(root_desc, path_url):
399      return "%(root)supload/%(service_path)s%(path)s" % {
400          "root": root_desc["rootUrl"],
401          "service_path": root_desc["servicePath"],
402          "path": path_url,
403      }
404  def _fix_up_parameters(method_desc, root_desc, http_method, schema):
405      parameters = method_desc.setdefault("parameters", {})
406      for name, description in root_desc.get("parameters", {}).items():
407          parameters[name] = description
408      for name in STACK_QUERY_PARAMETERS:
409          parameters[name] = STACK_QUERY_PARAMETER_DEFAULT_VALUE.copy()
410      if http_method in HTTP_PAYLOAD_METHODS and "request" in method_desc:
411          body = BODY_PARAMETER_DEFAULT_VALUE.copy()
412          body.update(method_desc["request"])
413          parameters["body"] = body
414      return parameters
415  def _fix_up_media_upload(method_desc, root_desc, path_url, parameters):
416      media_upload = method_desc.get("mediaUpload", {})
417      accept = media_upload.get("accept", [])
418      max_size = _media_size_to_long(media_upload.get("maxSize", ""))
419      media_path_url = None
420      if media_upload:
421          media_path_url = _media_path_url_from_info(root_desc, path_url)
422          parameters["media_body"] = MEDIA_BODY_PARAMETER_DEFAULT_VALUE.copy()
423          parameters["media_mime_type"] = MEDIA_MIME_TYPE_PARAMETER_DEFAULT_VALUE.copy()
424      return accept, max_size, media_path_url
425  def _fix_up_method_description(method_desc, root_desc, schema):
426      path_url = method_desc["path"]
427      http_method = method_desc["httpMethod"]
428      method_id = method_desc["id"]
429      parameters = _fix_up_parameters(method_desc, root_desc, http_method, schema)
430      accept, max_size, media_path_url = _fix_up_media_upload(
431          method_desc, root_desc, path_url, parameters
432      )
433      return path_url, http_method, method_id, accept, max_size, media_path_url
434  def _fix_up_media_path_base_url(media_path_url, base_url):
435      parsed_media_url = urllib.parse.urlparse(media_path_url)
436      parsed_base_url = urllib.parse.urlparse(base_url)
437      if parsed_media_url.netloc == parsed_base_url.netloc:
438          return media_path_url
439      return urllib.parse.urlunparse(
440          parsed_media_url._replace(netloc=parsed_base_url.netloc)
441      )
442  def _urljoin(base, url):
443      if url.startswith("http://") or url.startswith("https://"):
444          return urllib.parse.urljoin(base, url)
445      new_base = base if base.endswith("/") else base + "/"
446      new_url = url[1:] if url.startswith("/") else url
447      return new_base + new_url
448  class ResourceMethodParameters(object):
449      def __init__(self, method_desc):
450          self.argmap = {}
451          self.required_params = []
452          self.repeated_params = []
453          self.pattern_params = {}
454          self.query_params = []
455          self.path_params = set()
456          self.param_types = {}
457          self.enum_params = {}
458          self.set_parameters(method_desc)
459      def set_parameters(self, method_desc):
460          parameters = method_desc.get("parameters", {})
461          sorted_parameters = OrderedDict(sorted(parameters.items()))
462          for arg, desc in sorted_parameters.items():
463              param = key2param(arg)
464              self.argmap[param] = arg
465              if desc.get("pattern"):
466                  self.pattern_params[param] = desc["pattern"]
467              if desc.get("enum"):
468                  self.enum_params[param] = desc["enum"]
469              if desc.get("required"):
470                  self.required_params.append(param)
471              if desc.get("repeated"):
472                  self.repeated_params.append(param)
473              if desc.get("location") == "query":
474                  self.query_params.append(param)
475              if desc.get("location") == "path":
476                  self.path_params.add(param)
477              self.param_types[param] = desc.get("type", "string")
478          for match in URITEMPLATE.finditer(method_desc["path"]):
479              for namematch in VARNAME.finditer(match.group(0)):
480                  name = key2param(namematch.group(0))
481                  self.path_params.add(name)
482                  if name in self.query_params:
483                      self.query_params.remove(name)
484  def createMethod(methodName, methodDesc, rootDesc, schema):
485      methodName = fix_method_name(methodName)
486      (
487          pathUrl,
488          httpMethod,
489          methodId,
490          accept,
491          maxSize,
492          mediaPathUrl,
493      ) = _fix_up_method_description(methodDesc, rootDesc, schema)
494      parameters = ResourceMethodParameters(methodDesc)
495      def method(self, **kwargs):
496          for name in kwargs:
497              if name not in parameters.argmap:
498                  raise TypeError("Got an unexpected keyword argument {}".format(name))
499          keys = list(kwargs.keys())
500          for name in keys:
501              if kwargs[name] is None:
502                  del kwargs[name]
503          for name in parameters.required_params:
504              if name not in kwargs:
505                  if name not in _PAGE_TOKEN_NAMES or _findPageTokenName(
506                      _methodProperties(methodDesc, schema, "response")
507                  ):
508                      raise TypeError('Missing required parameter "%s"' % name)
509          for name, regex in parameters.pattern_params.items():
510              if name in kwargs:
511                  if isinstance(kwargs[name], str):
512                      pvalues = [kwargs[name]]
513                  else:
514                      pvalues = kwargs[name]
515                  for pvalue in pvalues:
516                      if re.match(regex, pvalue) is None:
517                          raise TypeError(
518                              'Parameter "%s" value "%s" does not match the pattern "%s"'
519                              % (name, pvalue, regex)
520                          )
521          for name, enums in parameters.enum_params.items():
522              if name in kwargs:
523                  if name in parameters.repeated_params and not isinstance(
524                      kwargs[name], str
525                  ):
526                      values = kwargs[name]
527                  else:
528                      values = [kwargs[name]]
529                  for value in values:
530                      if value not in enums:
531                          raise TypeError(
532                              'Parameter "%s" value "%s" is not an allowed value in "%s"'
533                              % (name, value, str(enums))
534                          )
535          actual_query_params = {}
536          actual_path_params = {}
537          for key, value in kwargs.items():
538              to_type = parameters.param_types.get(key, "string")
539              if key in parameters.repeated_params and type(value) == type([]):
540                  cast_value = [_cast(x, to_type) for x in value]
541              else:
542                  cast_value = _cast(value, to_type)
543              if key in parameters.query_params:
544                  actual_query_params[parameters.argmap[key]] = cast_value
545              if key in parameters.path_params:
546                  actual_path_params[parameters.argmap[key]] = cast_value
547          body_value = kwargs.get("body", None)
548          media_filename = kwargs.get("media_body", None)
549          media_mime_type = kwargs.get("media_mime_type", None)
550          if self._developerKey:
551              actual_query_params["key"] = self._developerKey
552          model = self._model
553          if methodName.endswith("_media"):
554              model = MediaModel()
555          elif "response" not in methodDesc:
556              model = RawModel()
557          headers = {}
558          headers, params, query, body = model.request(
559              headers, actual_path_params, actual_query_params, body_value
560          )
561          expanded_url = uritemplate.expand(pathUrl, params)
562          url = _urljoin(self._baseUrl, expanded_url + query)
563          resumable = None
564          multipart_boundary = ""
565          if media_filename:
566              if isinstance(media_filename, str):
567                  if media_mime_type is None:
568                      logger.warning(
569                          "media_mime_type argument not specified: trying to auto-detect for %s",
570                          media_filename,
571                      )
572                      media_mime_type, _ = mimetypes.guess_type(media_filename)
573                  if media_mime_type is None:
574                      raise UnknownFileType(media_filename)
575                  if not mimeparse.best_match([media_mime_type], ",".join(accept)):
576                      raise UnacceptableMimeTypeError(media_mime_type)
577                  media_upload = MediaFileUpload(media_filename, mimetype=media_mime_type)
578              elif isinstance(media_filename, MediaUpload):
579                  media_upload = media_filename
580              else:
581                  raise TypeError("media_filename must be str or MediaUpload.")
582              if media_upload.size() is not None and media_upload.size() > maxSize > 0:
583                  raise MediaUploadSizeError("Media larger than: %s" % maxSize)
584              expanded_url = uritemplate.expand(mediaPathUrl, params)
585              url = _urljoin(self._baseUrl, expanded_url + query)
586              url = _fix_up_media_path_base_url(url, self._baseUrl)
587              if media_upload.resumable():
588                  url = _add_query_parameter(url, "uploadType", "resumable")
589              if media_upload.resumable():
590                  resumable = media_upload
591              else:
592                  if body is None:
593                      headers["content-type"] = media_upload.mimetype()
594                      body = media_upload.getbytes(0, media_upload.size())
595                      url = _add_query_parameter(url, "uploadType", "media")
596                  else:
597                      msgRoot = MIMEMultipart("related")
598                      setattr(msgRoot, "_write_headers", lambda self: None)
599                      msg = MIMENonMultipart(*headers["content-type"].split("/"))
600                      msg.set_payload(body)
601                      msgRoot.attach(msg)
602                      msg = MIMENonMultipart(*media_upload.mimetype().split("/"))
603                      msg["Content-Transfer-Encoding"] = "binary"
604                      payload = media_upload.getbytes(0, media_upload.size())
605                      msg.set_payload(payload)
606                      msgRoot.attach(msg)
607                      fp = io.BytesIO()
608                      g = _BytesGenerator(fp, mangle_from_=False)
609                      g.flatten(msgRoot, unixfrom=False)
610                      body = fp.getvalue()
611                      multipart_boundary = msgRoot.get_boundary()
612                      headers["content-type"] = (
613                          "multipart/related; " 'boundary="%s"'
614                      ) % multipart_boundary
615                      url = _add_query_parameter(url, "uploadType", "multipart")
616          logger.debug("URL being requested: %s %s" % (httpMethod, url))
617          return self._requestBuilder(
618              self._http,
619              model.response,
620              url,
621              method=httpMethod,
622              body=body,
623              headers=headers,
624              methodId=methodId,
625              resumable=resumable,
626          )
627      docs = [methodDesc.get("description", DEFAULT_METHOD_DOC), "\n\n"]
628      if len(parameters.argmap) > 0:
629          docs.append("Args:\n")
630      skip_parameters = list(rootDesc.get("parameters", {}).keys())
631      skip_parameters.extend(STACK_QUERY_PARAMETERS)
632      all_args = list(parameters.argmap.keys())
633      args_ordered = [key2param(s) for s in methodDesc.get("parameterOrder", [])]
634      if "body" in all_args:
635          args_ordered.append("body")
636      for name in sorted(all_args):
637          if name not in args_ordered:
638              args_ordered.append(name)
639      for arg in args_ordered:
640          if arg in skip_parameters:
641              continue
642          repeated = ""
643          if arg in parameters.repeated_params:
644              repeated = " (repeated)"
645          required = ""
646          if arg in parameters.required_params:
647              required = " (required)"
648          paramdesc = methodDesc["parameters"][parameters.argmap[arg]]
649          paramdoc = paramdesc.get("description", "A parameter")
650          if "$ref" in paramdesc:
651              docs.append(
652                  ("  %s: object, %s%s%s\n    The object takes the form of:\n\n%s\n\n")
653                  % (
654                      arg,
655                      paramdoc,
656                      required,
657                      repeated,
658                      schema.prettyPrintByName(paramdesc["$ref"]),
659                  )
660              )
661          else:
662              paramtype = paramdesc.get("type", "string")
663              docs.append(
664                  "  %s: %s, %s%s%s\n" % (arg, paramtype, paramdoc, required, repeated)
665              )
666          enum = paramdesc.get("enum", [])
667          enumDesc = paramdesc.get("enumDescriptions", [])
668          if enum and enumDesc:
669              docs.append("    Allowed values\n")
670              for (name, desc) in zip(enum, enumDesc):
671                  docs.append("      %s - %s\n" % (name, desc))
672      if "response" in methodDesc:
673          if methodName.endswith("_media"):
674              docs.append("\nReturns:\n  The media object as a string.\n\n    ")
675          else:
676              docs.append("\nReturns:\n  An object of the form:\n\n    ")
677              docs.append(schema.prettyPrintSchema(methodDesc["response"]))
678      setattr(method, "__doc__", "".join(docs))
679      return (methodName, method)
680  def createNextMethod(
681      methodName,
682      pageTokenName="pageToken",
683      nextPageTokenName="nextPageToken",
684      isPageTokenParameter=True,
685  ):
686      methodName = fix_method_name(methodName)
687      def methodNext(self, previous_request, previous_response):
688          nextPageToken = previous_response.get(nextPageTokenName, None)
689          if not nextPageToken:
690              return None
691          request = copy.copy(previous_request)
692          if isPageTokenParameter:
693              request.uri = _add_query_parameter(
694                  request.uri, pageTokenName, nextPageToken
695              )
696              logger.debug("Next page request URL: %s %s" % (methodName, request.uri))
697          else:
698              model = self._model
699              body = model.deserialize(request.body)
700              body[pageTokenName] = nextPageToken
701              request.body = model.serialize(body)
702              request.body_size = len(request.body)
703              if "content-length" in request.headers:
704                  del request.headers["content-length"]
705              logger.debug("Next page request body: %s %s" % (methodName, body))
706          return request
707      return (methodName, methodNext)
708  class Resource(object):
709      def __init__(
710          self,
711          http,
712          baseUrl,
713          model,
714          requestBuilder,
715          developerKey,
716          resourceDesc,
717          rootDesc,
718          schema,
719      ):
720          self._dynamic_attrs = []
721          self._http = http
722          self._baseUrl = baseUrl
723          self._model = model
724          self._developerKey = developerKey
725          self._requestBuilder = requestBuilder
726          self._resourceDesc = resourceDesc
727          self._rootDesc = rootDesc
728          self._schema = schema
729          self._set_service_methods()
730      def _set_dynamic_attr(self, attr_name, value):
731          self._dynamic_attrs.append(attr_name)
732          self.__dict__[attr_name] = value
733      def __getstate__(self):
734          state_dict = copy.copy(self.__dict__)
735          for dynamic_attr in self._dynamic_attrs:
736              del state_dict[dynamic_attr]
737          del state_dict["_dynamic_attrs"]
738          return state_dict
739      def __setstate__(self, state):
740          self.__dict__.update(state)
741          self._dynamic_attrs = []
742          self._set_service_methods()
743      def __enter__(self):
744          return self
745      def __exit__(self, exc_type, exc, exc_tb):
746          self.close()
747      def close(self):
748          self._http.close()
749      def _set_service_methods(self):
750          self._add_basic_methods(self._resourceDesc, self._rootDesc, self._schema)
751          self._add_nested_resources(self._resourceDesc, self._rootDesc, self._schema)
752          self._add_next_methods(self._resourceDesc, self._schema)
753      def _add_basic_methods(self, resourceDesc, rootDesc, schema):
754          if resourceDesc == rootDesc:
755              batch_uri = "%s%s" % (
756                  rootDesc["rootUrl"],
757                  rootDesc.get("batchPath", "batch"),
758              )
759              def new_batch_http_request(callback=None):
760                  return BatchHttpRequest(callback=callback, batch_uri=batch_uri)
761              self._set_dynamic_attr("new_batch_http_request", new_batch_http_request)
762          if "methods" in resourceDesc:
763              for methodName, methodDesc in resourceDesc["methods"].items():
764                  fixedMethodName, method = createMethod(
765                      methodName, methodDesc, rootDesc, schema
766                  )
767                  self._set_dynamic_attr(
768                      fixedMethodName, method.__get__(self, self.__class__)
769                  )
770                  if methodDesc.get("supportsMediaDownload", False):
771                      fixedMethodName, method = createMethod(
772                          methodName + "_media", methodDesc, rootDesc, schema
773                      )
774                      self._set_dynamic_attr(
775                          fixedMethodName, method.__get__(self, self.__class__)
776                      )
777      def _add_nested_resources(self, resourceDesc, rootDesc, schema):
778          if "resources" in resourceDesc:
779              def createResourceMethod(methodName, methodDesc):
780                  methodName = fix_method_name(methodName)
781                  def methodResource(self):
782                      return Resource(
783                          http=self._http,
784                          baseUrl=self._baseUrl,
785                          model=self._model,
786                          developerKey=self._developerKey,
787                          requestBuilder=self._requestBuilder,
788                          resourceDesc=methodDesc,
789                          rootDesc=rootDesc,
790                          schema=schema,
791                      )
792                  setattr(methodResource, "__doc__", "A collection resource.")
793                  setattr(methodResource, "__is_resource__", True)
794                  return (methodName, methodResource)
795              for methodName, methodDesc in resourceDesc["resources"].items():
796                  fixedMethodName, method = createResourceMethod(methodName, methodDesc)
797                  self._set_dynamic_attr(
798                      fixedMethodName, method.__get__(self, self.__class__)
799                  )
800      def _add_next_methods(self, resourceDesc, schema):
801          if "methods" not in resourceDesc:
802              return
803          for methodName, methodDesc in resourceDesc["methods"].items():
804              nextPageTokenName = _findPageTokenName(
805                  _methodProperties(methodDesc, schema, "response")
806              )
807              if not nextPageTokenName:
808                  continue
809              isPageTokenParameter = True
810              pageTokenName = _findPageTokenName(methodDesc.get("parameters", {}))
811              if not pageTokenName:
812                  isPageTokenParameter = False
813                  pageTokenName = _findPageTokenName(
814                      _methodProperties(methodDesc, schema, "request")
815                  )
816              if not pageTokenName:
817                  continue
818              fixedMethodName, method = createNextMethod(
819                  methodName + "_next",
820                  pageTokenName,
821                  nextPageTokenName,
822                  isPageTokenParameter,
823              )
824              self._set_dynamic_attr(
825                  fixedMethodName, method.__get__(self, self.__class__)
826              )
827  def _findPageTokenName(fields):
828      return next(
829          (tokenName for tokenName in _PAGE_TOKEN_NAMES if tokenName in fields), None
830      )
831  def _methodProperties(methodDesc, schema, name):
832      desc = methodDesc.get(name, {})
833      if "$ref" in desc:
834          desc = schema.get(desc["$ref"], {})
835      return desc.get("properties", {})
</code></pre>
        </div>
        <div class="column">
            <h3>esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-bin_image.py</h3>
            <pre><code>1  import binascii
2  import copy
3  import hashlib
4  import io
5  import os
6  import re
7  import struct
8  from .loader import ESPLoader
9  from .targets import (
10      ESP32C2ROM,
11      ESP32C3ROM,
12      ESP32C6BETAROM,
13      ESP32C6ROM,
14      ESP32H2BETA1ROM,
15      ESP32H2BETA2ROM,
16      ESP32H2ROM,
17      ESP32ROM,
18      ESP32S2ROM,
19      ESP32S3BETA2ROM,
20      ESP32S3ROM,
21      ESP8266ROM,
22  )
23  from .util import FatalError, byte, pad_to
24  def align_file_position(f, size):
25      align = (size - 1) - (f.tell() % size)
26      f.seek(align, 1)
27  def LoadFirmwareImage(chip, image_file):
28      def select_image_class(f, chip):
29          chip = re.sub(r"[-()]", "", chip.lower())
30          if chip != "esp8266":
31              return {
32                  "esp32": ESP32FirmwareImage,
33                  "esp32s2": ESP32S2FirmwareImage,
34                  "esp32s3beta2": ESP32S3BETA2FirmwareImage,
35                  "esp32s3": ESP32S3FirmwareImage,
36                  "esp32c3": ESP32C3FirmwareImage,
37                  "esp32c6beta": ESP32C6BETAFirmwareImage,
38                  "esp32h2beta1": ESP32H2BETA1FirmwareImage,
39                  "esp32h2beta2": ESP32H2BETA2FirmwareImage,
40                  "esp32c2": ESP32C2FirmwareImage,
41                  "esp32c6": ESP32C6FirmwareImage,
42                  "esp32h2": ESP32H2FirmwareImage,
43              }[chip](f)
44          else:  # Otherwise, ESP8266 so look at magic to determine the image type
45              magic = ord(f.read(1))
46              f.seek(0)
47              if magic == ESPLoader.ESP_IMAGE_MAGIC:
48                  return ESP8266ROMFirmwareImage(f)
49              elif magic == ESP8266V2FirmwareImage.IMAGE_V2_MAGIC:
50                  return ESP8266V2FirmwareImage(f)
51              else:
52                  raise FatalError("Invalid image magic number: %d" % magic)
53      if isinstance(image_file, str):
54          with open(image_file, "rb") as f:
55              return select_image_class(f, chip)
56      return select_image_class(image_file, chip)
57  class ImageSegment(object):
58      def __init__(self, addr, data, file_offs=None):
59          self.addr = addr
60          self.data = data
61          self.file_offs = file_offs
62          self.include_in_checksum = True
63          if self.addr != 0:
64              self.pad_to_alignment(
65                  4
66              )  # pad all "real" ImageSegments 4 byte aligned length
67      def copy_with_new_addr(self, new_addr):
68          return ImageSegment(new_addr, self.data, 0)
69      def split_image(self, split_len):
70          result = copy.copy(self)
71          result.data = self.data[:split_len]
72          self.data = self.data[split_len:]
73          self.addr += split_len
74          self.file_offs = None
75          result.file_offs = None
76          return result
77      def __repr__(self):
78          r = "len 0x%05x load 0x%08x" % (len(self.data), self.addr)
79          if self.file_offs is not None:
80              r += " file_offs 0x%08x" % (self.file_offs)
81          return r
82      def get_memory_type(self, image):
83          return [
84              map_range[2]
85              for map_range in image.ROM_LOADER.MEMORY_MAP
86              if map_range[0] <= self.addr < map_range[1]
87          ]
88      def pad_to_alignment(self, alignment):
89          self.data = pad_to(self.data, alignment, b"\x00")
90  class ELFSection(ImageSegment):
91      def __init__(self, name, addr, data):
92          super(ELFSection, self).__init__(addr, data)
93          self.name = name.decode("utf-8")
94      def __repr__(self):
95          return "%s %s" % (self.name, super(ELFSection, self).__repr__())
96  class BaseFirmwareImage(object):
97      SEG_HEADER_LEN = 8
98      SHA256_DIGEST_LEN = 32
99      def __init__(self):
100          self.segments = []
101          self.entrypoint = 0
102          self.elf_sha256 = None
103          self.elf_sha256_offset = 0
104          self.pad_to_size = 0
105      def load_common_header(self, load_file, expected_magic):
106          (
107              magic,
108              segments,
109              self.flash_mode,
110              self.flash_size_freq,
111              self.entrypoint,
112          ) = struct.unpack("<BBBBI", load_file.read(8))
113          if magic != expected_magic:
114              raise FatalError("Invalid firmware image magic=0x%x" % (magic))
115          return segments
116      def verify(self):
117          if len(self.segments) > 16:
118              raise FatalError(
119                  "Invalid segment count %d (max 16). "
120                  "Usually this indicates a linker script problem." % len(self.segments)
121              )
122      def load_segment(self, f, is_irom_segment=False):
123          file_offs = f.tell()
124          (offset, size) = struct.unpack("<II", f.read(8))
125          self.warn_if_unusual_segment(offset, size, is_irom_segment)
126          segment_data = f.read(size)
127          if len(segment_data) < size:
128              raise FatalError(
129                  "End of file reading segment 0x%x, length %d (actual length %d)"
130                  % (offset, size, len(segment_data))
131              )
132          segment = ImageSegment(offset, segment_data, file_offs)
133          self.segments.append(segment)
134          return segment
135      def warn_if_unusual_segment(self, offset, size, is_irom_segment):
136          if not is_irom_segment:
137              if offset > 0x40200000 or offset < 0x3FFE0000 or size > 65536:
138                  print("WARNING: Suspicious segment 0x%x, length %d" % (offset, size))
139      def maybe_patch_segment_data(self, f, segment_data):
140          segment_len = len(segment_data)
141          file_pos = f.tell()  # file_pos is position in the .bin file
142          if (
143              self.elf_sha256_offset >= file_pos
144              and self.elf_sha256_offset < file_pos + segment_len
145          ):
146              patch_offset = self.elf_sha256_offset - file_pos
147              if (
148                  patch_offset < self.SEG_HEADER_LEN
149                  or patch_offset + self.SHA256_DIGEST_LEN > segment_len
150              ):
151                  raise FatalError(
152                      "Cannot place SHA256 digest on segment boundary"
153                      "(elf_sha256_offset=%d, file_pos=%d, segment_size=%d)"
154                      % (self.elf_sha256_offset, file_pos, segment_len)
155                  )
156              patch_offset -= self.SEG_HEADER_LEN
157              if (
158                  segment_data[patch_offset : patch_offset + self.SHA256_DIGEST_LEN]
159                  != b"\x00" * self.SHA256_DIGEST_LEN
160              ):
161                  raise FatalError(
162                      "Contents of segment at SHA256 digest offset 0x%x are not all zero."
163                      " Refusing to overwrite." % self.elf_sha256_offset
164                  )
165              assert len(self.elf_sha256) == self.SHA256_DIGEST_LEN
166              segment_data = (
167                  segment_data[0:patch_offset]
168                  + self.elf_sha256
169                  + segment_data[patch_offset + self.SHA256_DIGEST_LEN :]
170              )
171          return segment_data
172      def save_segment(self, f, segment, checksum=None):
173          segment_data = self.maybe_patch_segment_data(f, segment.data)
174          f.write(struct.pack("<II", segment.addr, len(segment_data)))
175          f.write(segment_data)
176          if checksum is not None:
177              return ESPLoader.checksum(segment_data, checksum)
178      def read_checksum(self, f):
179          align_file_position(f, 16)
180          return ord(f.read(1))
181      def calculate_checksum(self):
182          checksum = ESPLoader.ESP_CHECKSUM_MAGIC
183          for seg in self.segments:
184              if seg.include_in_checksum:
185                  checksum = ESPLoader.checksum(seg.data, checksum)
186          return checksum
187      def append_checksum(self, f, checksum):
188          align_file_position(f, 16)
189          f.write(struct.pack(b"B", checksum))
190      def write_common_header(self, f, segments):
191          f.write(
192              struct.pack(
193                  "<BBBBI",
194                  ESPLoader.ESP_IMAGE_MAGIC,
195                  len(segments),
196                  self.flash_mode,
197                  self.flash_size_freq,
198                  self.entrypoint,
199              )
200          )
201      def is_irom_addr(self, addr):
202          return ESP8266ROM.IROM_MAP_START <= addr < ESP8266ROM.IROM_MAP_END
203      def get_irom_segment(self):
204          irom_segments = [s for s in self.segments if self.is_irom_addr(s.addr)]
205          if len(irom_segments) > 0:
206              if len(irom_segments) != 1:
207                  raise FatalError(
208                      "Found %d segments that could be irom0. Bad ELF file?"
209                      % len(irom_segments)
210                  )
211              return irom_segments[0]
212          return None
213      def get_non_irom_segments(self):
214          irom_segment = self.get_irom_segment()
215          return [s for s in self.segments if s != irom_segment]
216      def merge_adjacent_segments(self):
217          if not self.segments:
218              return  # nothing to merge
219          segments = []
220          for i in range(len(self.segments) - 1, 0, -1):
221              elem = self.segments[i - 1]
222              next_elem = self.segments[i]
223              if all(
224                  (
225                      elem.get_memory_type(self) == next_elem.get_memory_type(self),
226                      elem.include_in_checksum == next_elem.include_in_checksum,
227                      next_elem.addr == elem.addr + len(elem.data),
228                  )
229              ):
230                  elem.data += next_elem.data
231              else:
232                  segments.insert(0, next_elem)
233          segments.insert(0, self.segments[0])
234          self.segments = segments
235      def set_mmu_page_size(self, size):
236          print(
237              "WARNING: Changing MMU page size is not supported on {}! "
238              "Defaulting to 64KB.".format(self.ROM_LOADER.CHIP_NAME)
239          )
240  class ESP8266ROMFirmwareImage(BaseFirmwareImage):
241      ROM_LOADER = ESP8266ROM
242      def __init__(self, load_file=None):
243          super(ESP8266ROMFirmwareImage, self).__init__()
244          self.flash_mode = 0
245          self.flash_size_freq = 0
246          self.version = 1
247          if load_file is not None:
248              segments = self.load_common_header(load_file, ESPLoader.ESP_IMAGE_MAGIC)
249              for _ in range(segments):
250                  self.load_segment(load_file)
251              self.checksum = self.read_checksum(load_file)
252              self.verify()
253      def default_output_name(self, input_file):
254          return input_file + "-"
255      def save(self, basename):
256          irom_segment = self.get_irom_segment()
257          if irom_segment is not None:
258              with open(
259                  "%s0x%05x.bin"
260                  % (basename, irom_segment.addr - ESP8266ROM.IROM_MAP_START),
261                  "wb",
262              ) as f:
263                  f.write(irom_segment.data)
264          normal_segments = self.get_non_irom_segments()
265          with open("%s0x00000.bin" % basename, "wb") as f:
266              self.write_common_header(f, normal_segments)
267              checksum = ESPLoader.ESP_CHECKSUM_MAGIC
268              for segment in normal_segments:
269                  checksum = self.save_segment(f, segment, checksum)
270              self.append_checksum(f, checksum)
271  ESP8266ROM.BOOTLOADER_IMAGE = ESP8266ROMFirmwareImage
272  class ESP8266V2FirmwareImage(BaseFirmwareImage):
273      ROM_LOADER = ESP8266ROM
274      IMAGE_V2_MAGIC = 0xEA
275      IMAGE_V2_SEGMENT = 4
276      def __init__(self, load_file=None):
277          super(ESP8266V2FirmwareImage, self).__init__()
278          self.version = 2
279          if load_file is not None:
280              segments = self.load_common_header(load_file, self.IMAGE_V2_MAGIC)
281              if segments != self.IMAGE_V2_SEGMENT:
282                  print(
283                      'Warning: V2 header has unexpected "segment" count %d (usually 4)'
284                      % segments
285                  )
286              irom_segment = self.load_segment(load_file, True)
287              irom_segment.addr = 0
288              irom_segment.include_in_checksum = False
289              first_flash_mode = self.flash_mode
290              first_flash_size_freq = self.flash_size_freq
291              first_entrypoint = self.entrypoint
292              segments = self.load_common_header(load_file, ESPLoader.ESP_IMAGE_MAGIC)
293              if first_flash_mode != self.flash_mode:
294                  print(
295                      "WARNING: Flash mode value in first header (0x%02x) disagrees "
296                      "with second (0x%02x). Using second value."
297                      % (first_flash_mode, self.flash_mode)
298                  )
299              if first_flash_size_freq != self.flash_size_freq:
300                  print(
301                      "WARNING: Flash size/freq value in first header (0x%02x) disagrees "
302                      "with second (0x%02x). Using second value."
303                      % (first_flash_size_freq, self.flash_size_freq)
304                  )
305              if first_entrypoint != self.entrypoint:
306                  print(
307                      "WARNING: Entrypoint address in first header (0x%08x) disagrees "
308                      "with second header (0x%08x). Using second value."
309                      % (first_entrypoint, self.entrypoint)
310                  )
311              for _ in range(segments):
312                  self.load_segment(load_file)
313              self.checksum = self.read_checksum(load_file)
314              self.verify()
315      def default_output_name(self, input_file):
316          irom_segment = self.get_irom_segment()
317          if irom_segment is not None:
318              irom_offs = irom_segment.addr - ESP8266ROM.IROM_MAP_START
319          else:
320              irom_offs = 0
321          return "%s-0x%05x.bin" % (
322              os.path.splitext(input_file)[0],
323              irom_offs & ~(ESPLoader.FLASH_SECTOR_SIZE - 1),
324          )
325      def save(self, filename):
326          with open(filename, "wb") as f:
327              f.write(
328                  struct.pack(
329                      b"<BBBBI",
330                      self.IMAGE_V2_MAGIC,
331                      self.IMAGE_V2_SEGMENT,
332                      self.flash_mode,
333                      self.flash_size_freq,
334                      self.entrypoint,
335                  )
336              )
337              irom_segment = self.get_irom_segment()
338              if irom_segment is not None:
339                  irom_segment = irom_segment.copy_with_new_addr(0)
340                  irom_segment.pad_to_alignment(
341                      16
342                  )  # irom_segment must end on a 16 byte boundary
343                  self.save_segment(f, irom_segment)
344              normal_segments = self.get_non_irom_segments()
345              self.write_common_header(f, normal_segments)
346              checksum = ESPLoader.ESP_CHECKSUM_MAGIC
347              for segment in normal_segments:
348                  checksum = self.save_segment(f, segment, checksum)
349              self.append_checksum(f, checksum)
350          with open(filename, "rb") as f:
351              crc = esp8266_crc32(f.read())
352          with open(filename, "ab") as f:
353              f.write(struct.pack(b"<I", crc))
354  def esp8266_crc32(data):
355      crc = binascii.crc32(data, 0) & 0xFFFFFFFF
356      if crc & 0x80000000:
357          return crc ^ 0xFFFFFFFF
358      else:
359          return crc + 1
360  class ESP32FirmwareImage(BaseFirmwareImage):
361      ROM_LOADER = ESP32ROM
362      WP_PIN_DISABLED = 0xEE
363      EXTENDED_HEADER_STRUCT_FMT = "<BBBBHBHH" + ("B" * 4) + "B"
364      IROM_ALIGN = 65536
365      def __init__(self, load_file=None, append_digest=True):
366          super(ESP32FirmwareImage, self).__init__()
367          self.secure_pad = None
368          self.flash_mode = 0
369          self.flash_size_freq = 0
370          self.version = 1
371          self.wp_pin = self.WP_PIN_DISABLED
372          self.clk_drv = 0
373          self.q_drv = 0
374          self.d_drv = 0
375          self.cs_drv = 0
376          self.hd_drv = 0
377          self.wp_drv = 0
378          self.chip_id = 0
379          self.min_rev = 0
380          self.min_rev_full = 0
381          self.max_rev_full = 0
382          self.append_digest = append_digest
383          if load_file is not None:
384              start = load_file.tell()
385              segments = self.load_common_header(load_file, ESPLoader.ESP_IMAGE_MAGIC)
386              self.load_extended_header(load_file)
387              for _ in range(segments):
388                  self.load_segment(load_file)
389              self.checksum = self.read_checksum(load_file)
390              if self.append_digest:
391                  end = load_file.tell()
392                  self.stored_digest = load_file.read(32)
393                  load_file.seek(start)
394                  calc_digest = hashlib.sha256()
395                  calc_digest.update(load_file.read(end - start))
396                  self.calc_digest = calc_digest.digest()  # TODO: decide what to do here?
397              self.verify()
398      def is_flash_addr(self, addr):
399          return (
400              self.ROM_LOADER.IROM_MAP_START <= addr < self.ROM_LOADER.IROM_MAP_END
401          ) or (self.ROM_LOADER.DROM_MAP_START <= addr < self.ROM_LOADER.DROM_MAP_END)
402      def default_output_name(self, input_file):
403          return "%s.bin" % (os.path.splitext(input_file)[0])
404      def warn_if_unusual_segment(self, offset, size, is_irom_segment):
405          pass  # TODO: add warnings for wrong ESP32 segment offset/size combinations
406      def save(self, filename):
407          total_segments = 0
408          with io.BytesIO() as f:  # write file to memory first
409              self.write_common_header(f, self.segments)
410              self.save_extended_header(f)
411              checksum = ESPLoader.ESP_CHECKSUM_MAGIC
412              flash_segments = [
413                  copy.deepcopy(s)
414                  for s in sorted(self.segments, key=lambda s: s.addr)
415                  if self.is_flash_addr(s.addr)
416              ]
417              ram_segments = [
418                  copy.deepcopy(s)
419                  for s in sorted(self.segments, key=lambda s: s.addr)
420                  if not self.is_flash_addr(s.addr)
421              ]
422              for segment in flash_segments:
423                  if segment.name == ".flash.appdesc":
424                      flash_segments.remove(segment)
425                      flash_segments.insert(0, segment)
426                      break
427              for segment in ram_segments:
428                  if segment.name == ".dram0.bootdesc":
429                      ram_segments.remove(segment)
430                      ram_segments.insert(0, segment)
431                      break
432              if len(flash_segments) > 0:
433                  last_addr = flash_segments[0].addr
434                  for segment in flash_segments[1:]:
435                      if segment.addr // self.IROM_ALIGN == last_addr // self.IROM_ALIGN:
436                          raise FatalError(
437                              "Segment loaded at 0x%08x lands in same 64KB flash mapping "
438                              "as segment loaded at 0x%08x. Can't generate binary. "
439                              "Suggest changing linker script or ELF to merge sections."
440                              % (segment.addr, last_addr)
441                          )
442                      last_addr = segment.addr
443              def get_alignment_data_needed(segment):
444                  align_past = (segment.addr % self.IROM_ALIGN) - self.SEG_HEADER_LEN
445                  pad_len = (self.IROM_ALIGN - (f.tell() % self.IROM_ALIGN)) + align_past
446                  if pad_len == 0 or pad_len == self.IROM_ALIGN:
447                      return 0  # already aligned
448                  pad_len -= self.SEG_HEADER_LEN
449                  if pad_len < 0:
450                      pad_len += self.IROM_ALIGN
451                  return pad_len
452              while len(flash_segments) > 0:
453                  segment = flash_segments[0]
454                  pad_len = get_alignment_data_needed(segment)
455                  if pad_len > 0:  # need to pad
456                      if len(ram_segments) > 0 and pad_len > self.SEG_HEADER_LEN:
457                          pad_segment = ram_segments[0].split_image(pad_len)
458                          if len(ram_segments[0].data) == 0:
459                              ram_segments.pop(0)
460                      else:
461                          pad_segment = ImageSegment(0, b"\x00" * pad_len, f.tell())
462                      checksum = self.save_segment(f, pad_segment, checksum)
463                      total_segments += 1
464                  else:
465                      assert (
466                          f.tell() + 8
467                      ) % self.IROM_ALIGN == segment.addr % self.IROM_ALIGN
468                      checksum = self.save_flash_segment(f, segment, checksum)
469                      flash_segments.pop(0)
470                      total_segments += 1
471              for segment in ram_segments:
472                  checksum = self.save_segment(f, segment, checksum)
473                  total_segments += 1
474              if self.secure_pad:
475                  if not self.append_digest:
476                      raise FatalError(
477                          "secure_pad only applies if a SHA-256 digest "
478                          "is also appended to the image"
479                      )
480                  align_past = (f.tell() + self.SEG_HEADER_LEN) % self.IROM_ALIGN
481                  checksum_space = 16
482                  if self.secure_pad == "1":
483                      space_after_checksum = 32 + 4 + 64 + 12
484                  elif self.secure_pad == "2":  # Secure Boot V2
485                      space_after_checksum = 32
486                  pad_len = (
487                      self.IROM_ALIGN - align_past - checksum_space - space_after_checksum
488                  ) % self.IROM_ALIGN
489                  pad_segment = ImageSegment(0, b"\x00" * pad_len, f.tell())
490                  checksum = self.save_segment(f, pad_segment, checksum)
491                  total_segments += 1
492              self.append_checksum(f, checksum)
493              image_length = f.tell()
494              if self.secure_pad:
495                  assert ((image_length + space_after_checksum) % self.IROM_ALIGN) == 0
496              f.seek(1)
497              f.write(bytes([total_segments]))
498              if self.append_digest:
499                  f.seek(0)
500                  digest = hashlib.sha256()
501                  digest.update(f.read(image_length))
502                  f.write(digest.digest())
503              if self.pad_to_size:
504                  image_length = f.tell()
505                  if image_length % self.pad_to_size != 0:
506                      pad_by = self.pad_to_size - (image_length % self.pad_to_size)
507                      f.write(b"\xff" * pad_by)
508              with open(filename, "wb") as real_file:
509                  real_file.write(f.getvalue())
510      def save_flash_segment(self, f, segment, checksum=None):
511          segment_end_pos = f.tell() + len(segment.data) + self.SEG_HEADER_LEN
512          segment_len_remainder = segment_end_pos % self.IROM_ALIGN
513          if segment_len_remainder < 0x24:
514              segment.data += b"\x00" * (0x24 - segment_len_remainder)
515          return self.save_segment(f, segment, checksum)
516      def load_extended_header(self, load_file):
517          def split_byte(n):
518              return (n & 0x0F, (n >> 4) & 0x0F)
519          fields = list(
520              struct.unpack(self.EXTENDED_HEADER_STRUCT_FMT, load_file.read(16))
521          )
522          self.wp_pin = fields[0]
523          self.clk_drv, self.q_drv = split_byte(fields[1])
524          self.d_drv, self.cs_drv = split_byte(fields[2])
525          self.hd_drv, self.wp_drv = split_byte(fields[3])
526          self.chip_id = fields[4]
527          if self.chip_id != self.ROM_LOADER.IMAGE_CHIP_ID:
528              print(
529                  (
530                      "Unexpected chip id in image. Expected %d but value was %d. "
531                      "Is this image for a different chip model?"
532                  )
533                  % (self.ROM_LOADER.IMAGE_CHIP_ID, self.chip_id)
534              )
535          self.min_rev = fields[5]
536          self.min_rev_full = fields[6]
537          self.max_rev_full = fields[7]
538          append_digest = fields[-1]  # last byte is append_digest
539          if append_digest in [0, 1]:
540              self.append_digest = append_digest == 1
541          else:
542              raise RuntimeError(
543                  "Invalid value for append_digest field (0x%02x). Should be 0 or 1.",
544                  append_digest,
545              )
546      def save_extended_header(self, save_file):
547          def join_byte(ln, hn):
548              return (ln & 0x0F) + ((hn & 0x0F) << 4)
549          append_digest = 1 if self.append_digest else 0
550          fields = [
551              self.wp_pin,
552              join_byte(self.clk_drv, self.q_drv),
553              join_byte(self.d_drv, self.cs_drv),
554              join_byte(self.hd_drv, self.wp_drv),
555              self.ROM_LOADER.IMAGE_CHIP_ID,
556              self.min_rev,
557              self.min_rev_full,
558              self.max_rev_full,
559          ]
560          fields += [0] * 4  # padding
561          fields += [append_digest]
562          packed = struct.pack(self.EXTENDED_HEADER_STRUCT_FMT, *fields)
563          save_file.write(packed)
564  class ESP8266V3FirmwareImage(ESP32FirmwareImage):
565      EXTENDED_HEADER_STRUCT_FMT = "B" * 16
566      def is_flash_addr(self, addr):
567          return addr > ESP8266ROM.IROM_MAP_START
568      def save(self, filename):
569          total_segments = 0
570          with io.BytesIO() as f:  # write file to memory first
571              self.write_common_header(f, self.segments)
572              checksum = ESPLoader.ESP_CHECKSUM_MAGIC
573              flash_segments = [
574                  copy.deepcopy(s)
575                  for s in sorted(self.segments, key=lambda s: s.addr)
576                  if self.is_flash_addr(s.addr) and len(s.data)
577              ]
578              ram_segments = [
579                  copy.deepcopy(s)
580                  for s in sorted(self.segments, key=lambda s: s.addr)
581                  if not self.is_flash_addr(s.addr) and len(s.data)
582              ]
583              if len(flash_segments) > 0:
584                  last_addr = flash_segments[0].addr
585                  for segment in flash_segments[1:]:
586                      if segment.addr // self.IROM_ALIGN == last_addr // self.IROM_ALIGN:
587                          raise FatalError(
588                              "Segment loaded at 0x%08x lands in same 64KB flash mapping "
589                              "as segment loaded at 0x%08x. Can't generate binary. "
590                              "Suggest changing linker script or ELF to merge sections."
591                              % (segment.addr, last_addr)
592                          )
593                      last_addr = segment.addr
594              while len(flash_segments) > 0:
595                  segment = flash_segments[0]
596                  if segment.name == ".flash.rodata":
597                      segment.data = segment.data[8:]
598                  checksum = self.save_segment(f, segment, checksum)
599                  flash_segments.pop(0)
600                  total_segments += 1
601              for segment in ram_segments:
602                  checksum = self.save_segment(f, segment, checksum)
603                  total_segments += 1
604              self.append_checksum(f, checksum)
605              image_length = f.tell()
606              f.seek(1)
607              f.write(bytes([total_segments]))
608              if self.append_digest:
609                  f.seek(0)
<span onclick='openModal()' class='match'>610                  digest = hashlib.sha256()
611                  digest.update(f.read(image_length))
612                  f.write(digest.digest())
</span>613              with open(filename, "wb") as real_file:
614                  real_file.write(f.getvalue())
615      def load_extended_header(self, load_file):
616          def split_byte(n):
617              return (n & 0x0F, (n >> 4) & 0x0F)
618          fields = list(
619              struct.unpack(self.EXTENDED_HEADER_STRUCT_FMT, load_file.read(16))
620          )
621          self.wp_pin = fields[0]
622          self.clk_drv, self.q_drv = split_byte(fields[1])
623          self.d_drv, self.cs_drv = split_byte(fields[2])
624          self.hd_drv, self.wp_drv = split_byte(fields[3])
625          if fields[15] in [0, 1]:
626              self.append_digest = fields[15] == 1
627          else:
628              raise RuntimeError(
629                  "Invalid value for append_digest field (0x%02x). Should be 0 or 1.",
630                  fields[15],
631              )
632          if any(f for f in fields[4:15] if f != 0):
633              print(
634                  "Warning: some reserved header fields have non-zero values. "
635                  "This image may be from a newer esptool.py?"
636              )
637  ESP32ROM.BOOTLOADER_IMAGE = ESP32FirmwareImage
638  class ESP32S2FirmwareImage(ESP32FirmwareImage):
639      ROM_LOADER = ESP32S2ROM
640  ESP32S2ROM.BOOTLOADER_IMAGE = ESP32S2FirmwareImage
641  class ESP32S3BETA2FirmwareImage(ESP32FirmwareImage):
642      ROM_LOADER = ESP32S3BETA2ROM
643  ESP32S3BETA2ROM.BOOTLOADER_IMAGE = ESP32S3BETA2FirmwareImage
644  class ESP32S3FirmwareImage(ESP32FirmwareImage):
645      ROM_LOADER = ESP32S3ROM
646  ESP32S3ROM.BOOTLOADER_IMAGE = ESP32S3FirmwareImage
647  class ESP32C3FirmwareImage(ESP32FirmwareImage):
648      ROM_LOADER = ESP32C3ROM
649  ESP32C3ROM.BOOTLOADER_IMAGE = ESP32C3FirmwareImage
650  class ESP32C6BETAFirmwareImage(ESP32FirmwareImage):
651      ROM_LOADER = ESP32C6BETAROM
652  ESP32C6BETAROM.BOOTLOADER_IMAGE = ESP32C6BETAFirmwareImage
653  class ESP32H2BETA1FirmwareImage(ESP32FirmwareImage):
654      ROM_LOADER = ESP32H2BETA1ROM
655  ESP32H2BETA1ROM.BOOTLOADER_IMAGE = ESP32H2BETA1FirmwareImage
656  class ESP32H2BETA2FirmwareImage(ESP32FirmwareImage):
657      ROM_LOADER = ESP32H2BETA2ROM
658  ESP32H2BETA2ROM.BOOTLOADER_IMAGE = ESP32H2BETA2FirmwareImage
659  class ESP32C2FirmwareImage(ESP32FirmwareImage):
660      ROM_LOADER = ESP32C2ROM
661      def set_mmu_page_size(self, size):
662          if size not in [16384, 32768, 65536]:
663              raise FatalError(
664                  "{} bytes is not a valid ESP32-C2 page size, "
665                  "select from 64KB, 32KB, 16KB.".format(size)
666              )
667          self.IROM_ALIGN = size
668  ESP32C2ROM.BOOTLOADER_IMAGE = ESP32C2FirmwareImage
669  class ESP32C6FirmwareImage(ESP32FirmwareImage):
670      ROM_LOADER = ESP32C6ROM
671      def set_mmu_page_size(self, size):
672          if size not in [8192, 16384, 32768, 65536]:
673              raise FatalError(
674                  "{} bytes is not a valid ESP32-C6 page size, "
675                  "select from 64KB, 32KB, 16KB, 8KB.".format(size)
676              )
677          self.IROM_ALIGN = size
678  ESP32C6ROM.BOOTLOADER_IMAGE = ESP32C6FirmwareImage
679  class ESP32H2FirmwareImage(ESP32C6FirmwareImage):
680      ROM_LOADER = ESP32H2ROM
681  ESP32H2ROM.BOOTLOADER_IMAGE = ESP32H2FirmwareImage
682  class ELFFile(object):
683      SEC_TYPE_PROGBITS = 0x01
684      SEC_TYPE_STRTAB = 0x03
685      SEC_TYPE_INITARRAY = 0x0E
686      SEC_TYPE_FINIARRAY = 0x0F
687      PROG_SEC_TYPES = (SEC_TYPE_PROGBITS, SEC_TYPE_INITARRAY, SEC_TYPE_FINIARRAY)
688      LEN_SEC_HEADER = 0x28
689      SEG_TYPE_LOAD = 0x01
690      LEN_SEG_HEADER = 0x20
691      def __init__(self, name):
692          self.name = name
693          with open(self.name, "rb") as f:
694              self._read_elf_file(f)
695      def get_section(self, section_name):
696          for s in self.sections:
697              if s.name == section_name:
698                  return s
699          raise ValueError("No section %s in ELF file" % section_name)
700      def _read_elf_file(self, f):
701          LEN_FILE_HEADER = 0x34
702          try:
703              (
704                  ident,
705                  _type,
706                  machine,
707                  _version,
708                  self.entrypoint,
709                  _phoff,
710                  shoff,
711                  _flags,
712                  _ehsize,
713                  _phentsize,
714                  _phnum,
715                  shentsize,
716                  shnum,
717                  shstrndx,
718              ) = struct.unpack("<16sHHLLLLLHHHHHH", f.read(LEN_FILE_HEADER))
719          except struct.error as e:
720              raise FatalError(
721                  "Failed to read a valid ELF header from %s: %s" % (self.name, e)
722              )
723          if byte(ident, 0) != 0x7F or ident[1:4] != b"ELF":
724              raise FatalError("%s has invalid ELF magic header" % self.name)
725          if machine not in [0x5E, 0xF3]:
726              raise FatalError(
727                  "%s does not appear to be an Xtensa or an RISCV ELF file. "
728                  "e_machine=%04x" % (self.name, machine)
729              )
730          if shentsize != self.LEN_SEC_HEADER:
731              raise FatalError(
732                  "%s has unexpected section header entry size 0x%x (not 0x%x)"
733                  % (self.name, shentsize, self.LEN_SEC_HEADER)
734              )
735          if shnum == 0:
736              raise FatalError("%s has 0 section headers" % (self.name))
737          self._read_sections(f, shoff, shnum, shstrndx)
738          self._read_segments(f, _phoff, _phnum, shstrndx)
739      def _read_sections(self, f, section_header_offs, section_header_count, shstrndx):
740          f.seek(section_header_offs)
741          len_bytes = section_header_count * self.LEN_SEC_HEADER
742          section_header = f.read(len_bytes)
743          if len(section_header) == 0:
744              raise FatalError(
745                  "No section header found at offset %04x in ELF file."
746                  % section_header_offs
747              )
748          if len(section_header) != (len_bytes):
749              raise FatalError(
750                  "Only read 0x%x bytes from section header (expected 0x%x.) "
751                  "Truncated ELF file?" % (len(section_header), len_bytes)
752              )
753          section_header_offsets = range(0, len(section_header), self.LEN_SEC_HEADER)
754          def read_section_header(offs):
755              name_offs, sec_type, _flags, lma, sec_offs, size = struct.unpack_from(
756                  "<LLLLLL", section_header[offs:]
757              )
758              return (name_offs, sec_type, lma, size, sec_offs)
759          all_sections = [read_section_header(offs) for offs in section_header_offsets]
760          prog_sections = [s for s in all_sections if s[1] in ELFFile.PROG_SEC_TYPES]
761          if not (shstrndx * self.LEN_SEC_HEADER) in section_header_offsets:
762              raise FatalError("ELF file has no STRTAB section at shstrndx %d" % shstrndx)
763          _, sec_type, _, sec_size, sec_offs = read_section_header(
764              shstrndx * self.LEN_SEC_HEADER
765          )
766          if sec_type != ELFFile.SEC_TYPE_STRTAB:
767              print(
768                  "WARNING: ELF file has incorrect STRTAB section type 0x%02x" % sec_type
769              )
770          f.seek(sec_offs)
771          string_table = f.read(sec_size)
772          def lookup_string(offs):
773              raw = string_table[offs:]
774              return raw[: raw.index(b"\x00")]
775          def read_data(offs, size):
776              f.seek(offs)
777              return f.read(size)
778          prog_sections = [
779              ELFSection(lookup_string(n_offs), lma, read_data(offs, size))
780              for (n_offs, _type, lma, size, offs) in prog_sections
781              if lma != 0 and size > 0
782          ]
783          self.sections = prog_sections
784      def _read_segments(self, f, segment_header_offs, segment_header_count, shstrndx):
785          f.seek(segment_header_offs)
786          len_bytes = segment_header_count * self.LEN_SEG_HEADER
787          segment_header = f.read(len_bytes)
788          if len(segment_header) == 0:
789              raise FatalError(
790                  "No segment header found at offset %04x in ELF file."
791                  % segment_header_offs
792              )
793          if len(segment_header) != (len_bytes):
794              raise FatalError(
795                  "Only read 0x%x bytes from segment header (expected 0x%x.) "
796                  "Truncated ELF file?" % (len(segment_header), len_bytes)
797              )
798          segment_header_offsets = range(0, len(segment_header), self.LEN_SEG_HEADER)
799          def read_segment_header(offs):
800              (
801                  seg_type,
802                  seg_offs,
803                  _vaddr,
804                  lma,
805                  size,
806                  _memsize,
807                  _flags,
808                  _align,
809              ) = struct.unpack_from("<LLLLLLLL", segment_header[offs:])
810              return (seg_type, lma, size, seg_offs)
811          all_segments = [read_segment_header(offs) for offs in segment_header_offsets]
812          prog_segments = [s for s in all_segments if s[0] == ELFFile.SEG_TYPE_LOAD]
813          def read_data(offs, size):
814              f.seek(offs)
815              return f.read(size)
816          prog_segments = [
817              ELFSection(b"PHDR", lma, read_data(offs, size))
818              for (_type, lma, size, offs) in prog_segments
819              if lma != 0 and size > 0
820          ]
821          self.segments = prog_segments
822      def sha256(self):
823          sha256 = hashlib.sha256()
824          with open(self.name, "rb") as f:
825              sha256.update(f.read())
826          return sha256.digest()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from google-api-python-client-MDEwOlJlcG9zaXRvcnkxNTc0OTI2OQ==-flat-discovery.py</div>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-bin_image.py</div>
                <div class="column column_space"><pre><code>279          scopes = list(
280              service.get("auth", {}).get("oauth2", {}).get("scopes", {}).keys()
</pre></code></div>
                <div class="column column_space"><pre><code>610                  digest = hashlib.sha256()
611                  digest.update(f.read(image_length))
612                  f.write(digest.digest())
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    