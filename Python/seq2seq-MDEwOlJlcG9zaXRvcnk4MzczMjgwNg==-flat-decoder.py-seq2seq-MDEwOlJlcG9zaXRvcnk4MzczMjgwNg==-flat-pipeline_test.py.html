
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 13.273001508295627%, Tokens: 10</h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-decoder.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  import abc
5  import six
6  from tensorflow.python.framework import constant_op
7  from tensorflow.python.framework import dtypes
8  from tensorflow.python.framework import ops
9  from tensorflow.python.framework import tensor_shape
10  from tensorflow.python.framework import tensor_util
11  from tensorflow.python.ops import array_ops
12  from tensorflow.python.ops import control_flow_ops
13  from tensorflow.python.ops import math_ops
14  from tensorflow.python.ops import tensor_array_ops
15  from tensorflow.python.ops import variable_scope
16  from tensorflow.python.util import nest
17  __all__ = ["Decoder", "dynamic_decode"]
18  def _transpose_batch_time(x):
19    x_static_shape = x.get_shape()
20    if x_static_shape.ndims is not None and x_static_shape.ndims < 2:
21      raise ValueError(
22          "Expected input tensor %s to have rank at least 2, but saw shape: %s" %
23          (x, x_static_shape))
24    x_rank = array_ops.rank(x)
25    x_t = array_ops.transpose(
26        x, array_ops.concat(
27            ([1, 0], math_ops.range(2, x_rank)), axis=0))
<span onclick='openModal()' class='match'>28    x_t.set_shape(
29        tensor_shape.TensorShape([
30            x_static_shape[1].value, x_static_shape[0].value
31        ]).concatenate(x_static_shape[2:]))
</span>32    return x_t
33  @six.add_metaclass(abc.ABCMeta)
34  class Decoder(object):
35    @property
36    def batch_size(self):
37      raise NotImplementedError
38    @property
39    def output_size(self):
40      raise NotImplementedError
41    @property
42    def output_dtype(self):
43      raise NotImplementedError
44    @abc.abstractmethod
45    def initialize(self, name=None):
46      raise NotImplementedError
47    @abc.abstractmethod
48    def step(self, time, inputs, state, name=None):
49      raise NotImplementedError
50  def _create_zero_outputs(size, dtype, batch_size):
51    def _t(s):
52      return (s if isinstance(s, ops.Tensor) else constant_op.constant(
53          tensor_shape.TensorShape(s).as_list(),
54          dtype=dtypes.int32,
55          name="zero_suffix_shape"))
56    def _create(s, d):
57      return array_ops.zeros(
58          array_ops.concat(
59              ([batch_size], _t(s)), axis=0), dtype=d)
60    return nest.map_structure(_create, size, dtype)
61  def dynamic_decode(decoder,
62                     output_time_major=False,
63                     impute_finished=False,
64                     maximum_iterations=None,
65                     parallel_iterations=32,
66                     swap_memory=False,
67                     scope=None):
68    if not isinstance(decoder, Decoder):
69      raise TypeError("Expected decoder to be type Decoder, but saw: %s" %
70                      type(decoder))
71    with variable_scope.variable_scope(scope or "decoder") as varscope:
72      if varscope.caching_device is None:
73        varscope.set_caching_device(lambda op: op.device)
74      if maximum_iterations is not None:
75        maximum_iterations = ops.convert_to_tensor(
76            maximum_iterations, dtype=dtypes.int32, name="maximum_iterations")
77        if maximum_iterations.get_shape().ndims != 0:
78          raise ValueError("maximum_iterations must be a scalar")
79      initial_finished, initial_inputs, initial_state = decoder.initialize()
80      zero_outputs = _create_zero_outputs(decoder.output_size,
81                                          decoder.output_dtype,
82                                          decoder.batch_size)
83      if maximum_iterations is not None:
84        initial_finished = math_ops.logical_or(
85            initial_finished, 0 >= maximum_iterations)
86      initial_time = constant_op.constant(0, dtype=dtypes.int32)
87      def _shape(batch_size, from_shape):
88        if not isinstance(from_shape, tensor_shape.TensorShape):
89          return tensor_shape.TensorShape(None)
90        else:
91          batch_size = tensor_util.constant_value(
92              ops.convert_to_tensor(
93                  batch_size, name="batch_size"))
94          return tensor_shape.TensorShape([batch_size]).concatenate(from_shape)
95      def _create_ta(s, d):
96        return tensor_array_ops.TensorArray(
97            dtype=d,
98            size=0,
99            dynamic_size=True,
100            element_shape=_shape(decoder.batch_size, s))
101      initial_outputs_ta = nest.map_structure(_create_ta, decoder.output_size,
102                                              decoder.output_dtype)
103      def condition(unused_time, unused_outputs_ta, unused_state, unused_inputs,
104                    finished):
105        return math_ops.logical_not(math_ops.reduce_all(finished))
106      def body(time, outputs_ta, state, inputs, finished):
107        (next_outputs, decoder_state, next_inputs,
108         decoder_finished) = decoder.step(time, inputs, state)
109        next_finished = math_ops.logical_or(decoder_finished, finished)
110        if maximum_iterations is not None:
111          next_finished = math_ops.logical_or(
112              next_finished, time + 1 >= maximum_iterations)
113        nest.assert_same_structure(state, decoder_state)
114        nest.assert_same_structure(outputs_ta, next_outputs)
115        nest.assert_same_structure(inputs, next_inputs)
116        if impute_finished:
117          emit = nest.map_structure(
118              lambda out, zero: array_ops.where(finished, zero, out),
119              next_outputs,
120              zero_outputs)
121        else:
122          emit = next_outputs
123        def _maybe_copy_state(new, cur):
124          if isinstance(cur, tensor_array_ops.TensorArray):
125            pass_through = True
126          else:
127            new.set_shape(cur.shape)
128            pass_through = (new.shape.ndims == 0)
129          return new if pass_through else array_ops.where(finished, cur, new)
130        if impute_finished:
131          next_state = nest.map_structure(
132              _maybe_copy_state, decoder_state, state)
133        else:
134          next_state = decoder_state
135        outputs_ta = nest.map_structure(lambda ta, out: ta.write(time, out),
136                                        outputs_ta, emit)
137        return (time + 1, outputs_ta, next_state, next_inputs, next_finished)
138      res = control_flow_ops.while_loop(
139          condition,
140          body,
141          loop_vars=[
142              initial_time, initial_outputs_ta, initial_state, initial_inputs,
143              initial_finished
144          ],
145          parallel_iterations=parallel_iterations,
146          swap_memory=swap_memory)
147      final_outputs_ta = res[1]
148      final_state = res[2]
149      final_outputs = nest.map_structure(lambda ta: ta.stack(), final_outputs_ta)
150      if not output_time_major:
151        final_outputs = nest.map_structure(_transpose_batch_time, final_outputs)
152    return final_outputs, final_state
</code></pre>
        </div>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-pipeline_test.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import argparse
6  import imp
7  import os
8  import shutil
9  import tempfile
10  import yaml
11  import numpy as np
12  import tensorflow as tf
13  from tensorflow import gfile
14  from seq2seq.test import utils as test_utils
15  BIN_FOLDER = os.path.abspath(
16      os.path.join(os.path.dirname(__file__), "../../bin"))
17  def _clear_flags():
18    tf.app.flags.FLAGS = tf.app.flags._FlagValues()
19    tf.app.flags._global_parser = argparse.ArgumentParser()
20  class PipelineTest(tf.test.TestCase):
21    def setUp(self):
22      super(PipelineTest, self).setUp()
23      self.output_dir = tempfile.mkdtemp()
24      self.bin_folder = os.path.abspath(
25          os.path.join(os.path.dirname(__file__), "../../bin"))
26      tf.contrib.framework.get_or_create_global_step()
27    def tearDown(self):
28      shutil.rmtree(self.output_dir, ignore_errors=True)
29      super(PipelineTest, self).tearDown()
30    def test_train_infer(self):
31      sources_train, targets_train = test_utils.create_temp_parallel_data(
32          sources=["a a a a", "b b b b", "c c c c", "笑 笑 笑 笑"],
33          targets=["b b b b", "a a a a", "c c c c", "泣 泣 泣 泣"])
34      sources_dev, targets_dev = test_utils.create_temp_parallel_data(
35          sources=["a a", "b b", "c c c", "笑 笑 笑"],
36          targets=["b b", "a a", "c c c", "泣 泣 泣"])
37      vocab_source = test_utils.create_temporary_vocab_file(["a", "b", "c", "笑"])
38      vocab_target = test_utils.create_temporary_vocab_file(["a", "b", "c", "泣"])
39      _clear_flags()
40      tf.reset_default_graph()
41      train_script = imp.load_source("seq2seq.test.train_bin",
42                                     os.path.join(BIN_FOLDER, "train.py"))
43      tf.app.flags.FLAGS.output_dir = self.output_dir
44      tf.app.flags.FLAGS.hooks = 
45      tf.app.flags.FLAGS.metrics = 
46      tf.app.flags.FLAGS.model = "AttentionSeq2Seq"
47      tf.app.flags.FLAGS.model_params = .format(vocab_source.name, vocab_target.name)
48      tf.app.flags.FLAGS.batch_size = 2
49      config_path = os.path.join(self.output_dir, "train_config.yml")
<span onclick='openModal()' class='match'>50      with gfile.GFile(config_path, "w") as config_file:
51        yaml.dump({
52            "input_pipeline_train": {
53                "class": "ParallelTextInputPipeline",
54                "params": {
55                    "source_files": [sources_train.name],
56                    "target_files": [targets_train.name],
57                }
58            },
59            "input_pipeline_dev": {
60                "class": "ParallelTextInputPipeline",
</span>61                "params": {
62                    "source_files": [sources_dev.name],
63                    "target_files": [targets_dev.name],
64                }
65            },
66            "train_steps": 50,
67            "model_params": {
68                "embedding.dim": 10,
69                "decoder.params": {
70                    "rnn_cell": {
71                        "cell_class": "GRUCell",
72                        "cell_params": {
73                            "num_units": 8
74                        }
75                    }
76                },
77                "encoder.params": {
78                    "rnn_cell": {
79                        "cell_class": "GRUCell",
80                        "cell_params": {
81                            "num_units": 8
82                        }
83                    }
84                }
85            }
86        }, config_file)
87      tf.app.flags.FLAGS.config_paths = config_path
88      tf.logging.set_verbosity(tf.logging.INFO)
89      train_script.main([])
90      expected_checkpoint = os.path.join(self.output_dir,
91                                         "model.ckpt-50.data-00000-of-00001")
92      self.assertTrue(os.path.exists(expected_checkpoint))
93      _clear_flags()
94      tf.reset_default_graph()
95      infer_script = imp.load_source("seq2seq.test.infer_bin",
96                                     os.path.join(BIN_FOLDER, "infer.py"))
97      attention_dir = os.path.join(self.output_dir, "att")
98      tf.app.flags.FLAGS.model_dir = self.output_dir
99      tf.app.flags.FLAGS.input_pipeline = .format(sources_dev.name, targets_dev.name)
100      tf.app.flags.FLAGS.batch_size = 2
101      tf.app.flags.FLAGS.checkpoint_path = os.path.join(self.output_dir,
102                                                        "model.ckpt-50")
103      tf.app.flags.FLAGS.tasks = .format(attention_dir)
104      infer_script.main([])
105      self.assertTrue(
106          os.path.exists(os.path.join(attention_dir, "attention_scores.npz")))
107      self.assertTrue(os.path.exists(os.path.join(attention_dir, "00002.png")))
108      scores = np.load(os.path.join(attention_dir, "attention_scores.npz"))
109      self.assertIn("arr_0", scores)
110      self.assertEqual(scores["arr_0"].shape[1], 3)
111      self.assertIn("arr_1", scores)
112      self.assertEqual(scores["arr_1"].shape[1], 3)
113      self.assertIn("arr_2", scores)
114      self.assertEqual(scores["arr_2"].shape[1], 4)
115      self.assertIn("arr_3", scores)
116      self.assertEqual(scores["arr_3"].shape[1], 4)
117      _clear_flags()
118      tf.reset_default_graph()
119      infer_script = imp.load_source("seq2seq.test.infer_bin",
120                                     os.path.join(BIN_FOLDER, "infer.py"))
121      tf.app.flags.FLAGS.model_dir = self.output_dir
122      tf.app.flags.FLAGS.input_pipeline = .format(sources_dev.name, targets_dev.name)
123      tf.app.flags.FLAGS.batch_size = 2
124      tf.app.flags.FLAGS.checkpoint_path = os.path.join(self.output_dir,
125                                                        "model.ckpt-50")
126      tf.app.flags.FLAGS.model_params = 
127      tf.app.flags.FLAGS.tasks = .format(os.path.join(self.output_dir, "beams.npz"))
128      infer_script.main([])
129      self.assertTrue(os.path.exists(os.path.join(self.output_dir, "beams.npz")))
130  if __name__ == "__main__":
131    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-decoder.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-pipeline_test.py</div>
                </div>
                <div class="column column_space"><pre><code>28    x_t.set_shape(
29        tensor_shape.TensorShape([
30            x_static_shape[1].value, x_static_shape[0].value
31        ]).concatenate(x_static_shape[2:]))
</pre></code></div>
                <div class="column column_space"><pre><code>50      with gfile.GFile(config_path, "w") as config_file:
51        yaml.dump({
52            "input_pipeline_train": {
53                "class": "ParallelTextInputPipeline",
54                "params": {
55                    "source_files": [sources_train.name],
56                    "target_files": [targets_train.name],
57                }
58            },
59            "input_pipeline_dev": {
60                "class": "ParallelTextInputPipeline",
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    