<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html><head><title>Matches for archive.py &amp; network_4.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for archive.py &amp; network_4.py
      </h3>
<h1 align="center">
        1.2%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>archive.py (1.8971848%)<th>network_4.py (0.97822654%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(7-24)<td><a href="#" name="0">(7-24)</a><td align="center"><font color="#ff0000">17</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(1367-1369)<td><a href="#" name="1">(168-173)</a><td align="center"><font color="#d20000">14</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>archive.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
"""
Extract an archive

<a name="0"></a>.. versionadded:: 2014.1.0
"""

<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>import errno
import logging
import os
import re
import shlex
import stat
import string
import tarfile
from contextlib import closing
from urllib.parse import urlparse

import salt.utils.args
import salt.utils.files
import salt.utils.hashutils
import salt.utils.path
import salt.utils.platform
import salt.utils.url
from</b></font> salt.exceptions import CommandExecutionError, CommandNotFoundError

log = logging.getLogger(__name__)


def _path_is_abs(path):
    """
    Return a bool telling whether or ``path`` is absolute. If ``path`` is None,
    return ``True``. This function is designed to validate variables which
    optionally contain a file path.
    """
    if path is None:
        return True
    try:
        return os.path.isabs(path)
    except AttributeError:
        # Non-string data passed
        return False


def _add_explanation(ret, source_hash_trigger, contents_missing):
    """
    Common code to add additional explanation to the state's comment field,
    both when test=True and not
    """
    if source_hash_trigger:
        ret["comment"] += ", due to source_hash update"
    elif contents_missing:
        ret["comment"] += ", due to absence of one or more files/dirs"


def _gen_checksum(path):
    return {
        "hsum": salt.utils.hashutils.get_hash(path, form=__opts__["hash_type"]),
        "hash_type": __opts__["hash_type"],
    }


def _checksum_file_path(path):
    try:
        relpath = ".".join((os.path.relpath(path, __opts__["cachedir"]), "hash"))
        if re.match(r"..[/\\]", relpath):
            # path is a local file
            relpath = salt.utils.path.join(
                "local",
                os.path.splitdrive(path)[-1].lstrip("/\\"),
            )
    except ValueError as exc:
        # The path is on a different drive (Windows)
        if str(exc).startswith("path is on"):
            drive, path = os.path.splitdrive(path)
            relpath = salt.utils.path.join(
                "local",
                drive.rstrip(":"),
                path.lstrip("/\\"),
            )
        elif str(exc).startswith("Cannot mix UNC"):
            relpath = salt.utils.path.join("unc", path)
        else:
            raise
    ret = salt.utils.path.join(__opts__["cachedir"], "archive_hash", relpath)
    log.debug("Using checksum file %s for cached archive file %s", ret, path)
    return ret


def _update_checksum(path):
    checksum_file = _checksum_file_path(path)
    checksum_dir = os.path.dirname(checksum_file)
    if not os.path.isdir(checksum_dir):
        os.makedirs(checksum_dir)
    source_sum = _gen_checksum(path)
    hash_type = source_sum.get("hash_type")
    hsum = source_sum.get("hsum")
    if hash_type and hsum:
        lines = []
        try:
            try:
                with salt.utils.files.fopen(checksum_file, "r") as fp_:
                    for line in fp_:
                        try:
                            lines.append(line.rstrip("\n").split(":", 1))
                        except ValueError:
                            continue
            except OSError as exc:
                if exc.errno != errno.ENOENT:
                    raise

            with salt.utils.files.fopen(checksum_file, "w") as fp_:
                for line in lines:
                    if line[0] == hash_type:
                        line[1] = hsum
                    fp_.write("{}:{}\n".format(*line))
                if hash_type not in [x[0] for x in lines]:
                    fp_.write("{}:{}\n".format(hash_type, hsum))
        except OSError as exc:
            log.warning(
                "Failed to update checksum for %s: %s",
                path,
                exc.__str__(),
                exc_info=True,
            )


def _read_cached_checksum(path, form=None):
    if form is None:
        form = __opts__["hash_type"]
    checksum_file = _checksum_file_path(path)
    try:
        with salt.utils.files.fopen(checksum_file, "r") as fp_:
            for line in fp_:
                # Should only be one line in this file but just in case it
                # isn't, read only a single line to avoid overuse of memory.
                hash_type, hsum = line.rstrip("\n").split(":", 1)
                if hash_type == form:
                    break
            else:
                return None
    except (OSError, ValueError):
        return None
    else:
        return {"hash_type": hash_type, "hsum": hsum}


def _compare_checksum(cached, source_sum):
    cached_sum = _read_cached_checksum(
        cached, form=source_sum.get("hash_type", __opts__["hash_type"])
    )
    return source_sum == cached_sum


def _is_bsdtar():
    return "bsdtar" in __salt__["cmd.run"](["tar", "--version"], python_shell=False)


def _cleanup_destdir(name):
    """
    Attempt to remove the specified directory
    """
    try:
        os.rmdir(name)
    except OSError:
        pass


def extracted(
    name,
    source,
    source_hash=None,
    source_hash_name=None,
    source_hash_update=False,
    skip_files_list_verify=False,
    skip_verify=False,
    password=None,
    options=None,
    list_options=None,
    force=False,
    overwrite=False,
    clean=False,
    clean_parent=False,
    user=None,
    group=None,
    if_missing=None,
    trim_output=False,
    use_cmd_unzip=None,
    extract_perms=True,
    enforce_toplevel=True,
    enforce_ownership_on=None,
    archive_format=None,
    use_etag=False,
    **kwargs
):
    """
    .. versionadded:: 2014.1.0
    .. versionchanged:: 2016.11.0,3005
        This state has been rewritten. Some arguments are new to this release
        and will not be available in the 2016.3 release cycle (and earlier).
        Additionally, the **ZIP Archive Handling** section below applies
        specifically to the 2016.11.0 release (and newer).

    Ensure that an archive is extracted to a specific directory.

    .. important::
        **Changes for 2016.11.0**

        In earlier releases, this state would rely on the ``if_missing``
        argument to determine whether or not the archive needed to be
        extracted. When this argument was not passed, then the state would just
        assume ``if_missing`` is the same as the ``name`` argument (i.e. the
        parent directory into which the archive would be extracted).

        This caused a number of annoyances. One such annoyance was the need to
        know beforehand a path that would result from the extraction of the
        archive, and setting ``if_missing`` to that directory, like so:

        .. code-block:: yaml

            extract_myapp:
              archive.extracted:
                - name: /var/www
                - source: salt://apps/src/myapp-16.2.4.tar.gz
                - user: www
                - group: www
                - if_missing: /var/www/myapp-16.2.4

        If ``/var/www`` already existed, this would effectively make
        ``if_missing`` a required argument, just to get Salt to extract the
        archive.

        Some users worked around this by adding the top-level directory of the
        archive to the end of the ``name`` argument, and then used ``--strip``
        or ``--strip-components`` to remove that top-level dir when extracting:

        .. code-block:: yaml

            extract_myapp:
              archive.extracted:
                - name: /var/www/myapp-16.2.4
                - source: salt://apps/src/myapp-16.2.4.tar.gz
                - user: www
                - group: www

        With the rewrite for 2016.11.0, these workarounds are no longer
        necessary. ``if_missing`` is still a supported argument, but it is no
        longer required. The equivalent SLS in 2016.11.0 would be:

        .. code-block:: yaml

            extract_myapp:
              archive.extracted:
                - name: /var/www
                - source: salt://apps/src/myapp-16.2.4.tar.gz
                - user: www
                - group: www

        Salt now uses a function called :py:func:`archive.list
        &lt;salt.modules.archive.list&gt;` to get a list of files/directories in the
        archive. Using this information, the state can now check the minion to
        see if any paths are missing, and know whether or not the archive needs
        to be extracted. This makes the ``if_missing`` argument unnecessary in
        most use cases.

    .. important::
        **ZIP Archive Handling**

        *Note: this information applies to 2016.11.0 and later.*

        Salt has two different functions for extracting ZIP archives:

        1. :py:func:`archive.unzip &lt;salt.modules.archive.unzip&gt;`, which uses
           Python's zipfile_ module to extract ZIP files.
        2. :py:func:`archive.cmd_unzip &lt;salt.modules.archive.cmd_unzip&gt;`, which
           uses the ``unzip`` CLI command to extract ZIP files.

        Salt will prefer the use of :py:func:`archive.cmd_unzip
        &lt;salt.modules.archive.cmd_unzip&gt;` when CLI options are specified (via
        the ``options`` argument), and will otherwise prefer the
        :py:func:`archive.unzip &lt;salt.modules.archive.unzip&gt;` function. Use
        of :py:func:`archive.cmd_unzip &lt;salt.modules.archive.cmd_unzip&gt;` can be
        forced however by setting the ``use_cmd_unzip`` argument to ``True``.
        By contrast, setting this argument to ``False`` will force usage of
        :py:func:`archive.unzip &lt;salt.modules.archive.unzip&gt;`. For example:

        .. code-block:: yaml

            /var/www:
              archive.extracted:
                - source: salt://foo/bar/myapp.zip
                - use_cmd_unzip: True

        When ``use_cmd_unzip`` is omitted, Salt will choose which extraction
        function to use based on the source archive and the arguments passed to
        the state. When in doubt, simply do not set this argument; it is
        provided as a means of overriding the logic Salt uses to decide which
        function to use.

        There are differences in the features available in both extraction
        functions. These are detailed below.

        - *Command-line options* (only supported by :py:func:`archive.cmd_unzip
          &lt;salt.modules.archive.cmd_unzip&gt;`) - When the ``options`` argument is
          used, :py:func:`archive.cmd_unzip &lt;salt.modules.archive.cmd_unzip&gt;`
          is the only function that can be used to extract the archive.
          Therefore, if ``use_cmd_unzip`` is specified and set to ``False``,
          and ``options`` is also set, the state will not proceed.

        - *Permissions* - Due to an `upstream bug in Python`_, permissions are
          not preserved when the zipfile_ module is used to extract an archive.
          As of the 2016.11.0 release, :py:func:`archive.unzip
          &lt;salt.modules.archive.unzip&gt;` (as well as this state) has an
          ``extract_perms`` argument which, when set to ``True`` (the default),
          will attempt to match the permissions of the extracted
          files/directories to those defined within the archive. To disable
          this functionality and have the state not attempt to preserve the
          permissions from the ZIP archive, set ``extract_perms`` to ``False``:

          .. code-block:: yaml

              /var/www:
                archive.extracted:
                  - source: salt://foo/bar/myapp.zip
                  - extract_perms: False

    .. _`upstream bug in Python`: https://bugs.python.org/issue15795

    name
        Directory into which the archive should be extracted

    source
        Archive to be extracted

        .. note::
            This argument uses the same syntax as its counterpart in the
            :py:func:`file.managed &lt;salt.states.file.managed&gt;` state.

    source_hash
        Hash of source file, or file with list of hash-to-file mappings

        .. note::
            This argument uses the same syntax as its counterpart in the
            :py:func:`file.managed &lt;salt.states.file.managed&gt;` state.

        .. versionchanged:: 2016.11.0
            If this argument specifies the hash itself, instead of a URI to a
            file containing hashes, the hash type can now be omitted and Salt
            will determine the hash type based on the length of the hash. For
            example, both of the below states are now valid, while before only
            the second one would be:

        .. code-block:: yaml

            foo_app:
              archive.extracted:
                - name: /var/www
                - source: https://mydomain.tld/foo.tar.gz
                - source_hash: 3360db35e682f1c5f9c58aa307de16d41361618c

            bar_app:
              archive.extracted:
                - name: /var/www
                - source: https://mydomain.tld/bar.tar.gz
                - source_hash: sha1=5edb7d584b82ddcbf76e311601f5d4442974aaa5

    source_hash_name
        When ``source_hash`` refers to a hash file, Salt will try to find the
        correct hash by matching the filename part of the ``source`` URI. When
        managing a file with a ``source`` of ``salt://files/foo.tar.gz``, then
        the following line in a hash file would match:

        .. code-block:: text

            acbd18db4cc2f85cedef654fccc4a4d8    foo.tar.gz

        This line would also match:

        .. code-block:: text

            acbd18db4cc2f85cedef654fccc4a4d8    ./dir1/foo.tar.gz

        However, sometimes a hash file will include multiple similar paths:

        .. code-block:: text

            37b51d194a7513e45b56f6524f2d51f2    ./dir1/foo.txt
            acbd18db4cc2f85cedef654fccc4a4d8    ./dir2/foo.txt
            73feffa4b7f6bb68e44cf984c85f6e88    ./dir3/foo.txt

        In cases like this, Salt may match the incorrect hash. This argument
        can be used to tell Salt which filename to match, to ensure that the
        correct hash is identified. For example:

        .. code-block:: yaml

            /var/www:
              archive.extracted:
                - source: https://mydomain.tld/dir2/foo.tar.gz
                - source_hash: https://mydomain.tld/hashes
                - source_hash_name: ./dir2/foo.tar.gz

        .. note::
            This argument must contain the full filename entry from the
            checksum file, as this argument is meant to disambiguate matches
            for multiple files that have the same basename. So, in the
            example above, simply using ``foo.txt`` would not match.

        .. versionadded:: 2016.11.0

    source_hash_update : False
        Set this to ``True`` if archive should be extracted if source_hash has
        changed and there is a difference between the archive and the local files.
        This would extract regardless of the ``if_missing`` parameter.

        Note that this is only checked if the ``source`` value has not changed.
        If it has (e.g. to increment a version number in the path) then the
        archive will not be extracted even if the hash has changed.

        .. note::
            Setting this to ``True`` along with ``keep_source`` set to ``False``
            will result the ``source`` re-download to do a archive file list check.
            If it's not desirable please consider the ``skip_files_list_verify``
            argument.

        .. versionadded:: 2016.3.0

    skip_files_list_verify : False
        Set this to ``True`` if archive should be extracted if ``source_hash`` has
        changed but only checksums of the archive will be checked to determine if
        the extraction is required.

        It will try to find a local cache of the ``source`` and check its hash against
        the ``source_hash``. If there is no local cache available, for example if you
        set the ``keep_source`` to ``False``,  it will try to find a cached source hash
        file in the Minion archives cache directory.

        .. note::
            The current limitation of this logic is that you have to set
            minions ``hash_type`` config option to the same one that you're going
            to pass via ``source_hash`` argument.

        .. warning::
            With this argument set to ``True`` Salt will only check for the ``source_hash``
            against the local hash of the ``sourse``. So if you, for example, remove extracted
            files without clearing the Salt Minion cache next time you execute the state Salt
            will not notice that extraction is required if the hashes are still match.

        .. versionadded:: 3000

    skip_verify : False
        If ``True``, hash verification of remote file sources (``http://``,
        ``https://``, ``ftp://``) will be skipped, and the ``source_hash``
        argument will be ignored.

        .. versionadded:: 2016.3.4

    keep_source : True
        For ``source`` archives not local to the minion (i.e. from the Salt
        fileserver or a remote source such as ``http(s)`` or ``ftp``), Salt
        will need to download the archive to the minion cache before they can
        be extracted. To remove the downloaded archive after extraction, set
        this argument to ``False``.

        .. versionadded:: 2017.7.3

    keep : True
        Same as ``keep_source``, kept for backward-compatibility.

        .. note::
            If both ``keep_source`` and ``keep`` are used, ``keep`` will be
            ignored.

    password
        **For ZIP archives only.** Password used for extraction.

        .. versionadded:: 2016.3.0
        .. versionchanged:: 2016.11.0
          The newly-added :py:func:`archive.is_encrypted
          &lt;salt.modules.archive.is_encrypted&gt;` function will be used to
          determine if the archive is password-protected. If it is, then the
          ``password`` argument will be required for the state to proceed.

    options
        **For tar and zip archives only.**  This option can be used to specify
        a string of additional arguments to pass to the tar/zip command.

        If this argument is not used, then the minion will attempt to use
        Python's native tarfile_/zipfile_ support to extract it. For zip
        archives, this argument is mostly used to overwrite existing files with
        ``o``.

        Using this argument means that the ``tar`` or ``unzip`` command will be
        used, which is less platform-independent, so keep this in mind when
        using this option; the CLI options must be valid options for the
        ``tar``/``unzip`` implementation on the minion's OS.

        .. versionadded:: 2016.11.0
        .. versionchanged:: 2015.8.11,2016.3.2
            XZ-compressed tar archives no longer require ``J`` to manually be
            set in the ``options``, they are now detected automatically and
            decompressed using the xz_ CLI command and extracted using ``tar
            xvf``. This is a more platform-independent solution, as not all tar
            implementations support the ``J`` argument for extracting archives.

        .. note::
            For tar archives, main operators like ``-x``, ``--extract``,
            ``--get``, ``-c`` and ``-f``/``--file`` should *not* be used here.

    list_options
        **For tar archives only.** This state uses :py:func:`archive.list
        &lt;salt.modules.archive.list_&gt;` to discover the contents of the source
        archive so that it knows which file paths should exist on the minion if
        the archive has already been extracted. For the vast majority of tar
        archives, :py:func:`archive.list &lt;salt.modules.archive.list_&gt;` "just
        works". Archives compressed using gzip, bzip2, and xz/lzma (with the
        help of the xz_ CLI command) are supported automatically. However, for
        archives compressed using other compression types, CLI options must be
        passed to :py:func:`archive.list &lt;salt.modules.archive.list_&gt;`.

        This argument will be passed through to :py:func:`archive.list
        &lt;salt.modules.archive.list_&gt;` as its ``options`` argument, to allow it
        to successfully list the archive's contents. For the vast majority of
        archives, this argument should not need to be used, it should only be
        needed in cases where the state fails with an error stating that the
        archive's contents could not be listed.

        .. versionadded:: 2016.11.0

    force : False
        If a path that should be occupied by a file in the extracted result is
        instead a directory (or vice-versa), the state will fail. Set this
        argument to ``True`` to force these paths to be removed in order to
        allow the archive to be extracted.

        .. warning::
            Use this option *very* carefully.

        .. versionadded:: 2016.11.0

    overwrite : False
        Set this to ``True`` to force the archive to be extracted. This is
        useful for cases where the filenames/directories have not changed, but
        the content of the files have.

        .. versionadded:: 2016.11.1

    clean : False
        Set this to ``True`` to remove any top-level files and recursively
        remove any top-level directory paths before extracting.

        .. note::
            Files will only be cleaned first if extracting the archive is
            deemed necessary, either by paths missing on the minion, or if
            ``overwrite`` is set to ``True``.

        .. versionadded:: 2016.11.1

    clean_parent : False
        If ``True``, and the archive is extracted, delete the parent
        directory (i.e. the directory into which the archive is extracted), and
        then re-create that directory before extracting. Note that ``clean``
        and ``clean_parent`` are mutually exclusive.

        .. versionadded:: 3000

    user
        The user to own each extracted file. Not available on Windows.

        .. versionadded:: 2015.8.0
        .. versionchanged:: 2016.3.0
            When used in combination with ``if_missing``, ownership will only
            be enforced if ``if_missing`` is a directory.
        .. versionchanged:: 2016.11.0
            Ownership will be enforced only on the file/directory paths found
            by running :py:func:`archive.list &lt;salt.modules.archive.list_&gt;` on
            the source archive. An alternative root directory on which to
            enforce ownership can be specified using the
            ``enforce_ownership_on`` argument.

    group
        The group to own each extracted file. Not available on Windows.

        .. versionadded:: 2015.8.0
        .. versionchanged:: 2016.3.0
            When used in combination with ``if_missing``, ownership will only
            be enforced if ``if_missing`` is a directory.
        .. versionchanged:: 2016.11.0
            Ownership will be enforced only on the file/directory paths found
            by running :py:func:`archive.list &lt;salt.modules.archive.list_&gt;` on
            the source archive. An alternative root directory on which to
            enforce ownership can be specified using the
            ``enforce_ownership_on`` argument.

    if_missing
        If specified, this path will be checked, and if it exists then the
        archive will not be extracted. This path can be either a directory or a
        file, so this option can also be used to check for a semaphore file and
        conditionally skip extraction.

        .. versionchanged:: 2016.3.0
            When used in combination with either ``user`` or ``group``,
            ownership will only be enforced when ``if_missing`` is a directory.
        .. versionchanged:: 2016.11.0
            Ownership enforcement is no longer tied to this argument, it is
            simply checked for existence and extraction will be skipped if
            if is present.

    trim_output : False
        Useful for archives with many files in them. This can either be set to
        ``True`` (in which case only the first 100 files extracted will be
        in the state results), or it can be set to an integer for more exact
        control over the max number of files to include in the state results.

        .. versionadded:: 2016.3.0

    use_cmd_unzip : False
        Set to ``True`` for zip files to force usage of the
        :py:func:`archive.cmd_unzip &lt;salt.modules.archive.cmd_unzip&gt;` function
        to extract.

        .. versionadded:: 2016.11.0

    extract_perms : True
        **For ZIP archives only.** When using :py:func:`archive.unzip
        &lt;salt.modules.archive.unzip&gt;` to extract ZIP archives, Salt works
        around an `upstream bug in Python`_ to set the permissions on extracted
        files/directories to match those encoded into the ZIP archive. Set this
        argument to ``False`` to skip this workaround.

        .. versionadded:: 2016.11.0

    enforce_toplevel : True
        This option will enforce a single directory at the top level of the
        source archive, to prevent extracting a 'tar-bomb'. Set this argument
        to ``False`` to allow archives with files (or multiple directories) at
        the top level to be extracted.

        .. versionadded:: 2016.11.0

    enforce_ownership_on
        When ``user`` or ``group`` is specified, Salt will default to enforcing
        permissions on the file/directory paths detected by running
        :py:func:`archive.list &lt;salt.modules.archive.list_&gt;` on the source
        archive. Use this argument to specify an alternate directory on which
        ownership should be enforced.

        .. note::
            This path must be within the path specified by the ``name``
            argument.

        .. versionadded:: 2016.11.0

    archive_format
        One of ``tar``, ``zip``, or ``rar``.

        .. versionchanged:: 2016.11.0
            If omitted, the archive format will be guessed based on the value
            of the ``source`` argument. If the minion is running a release
            older than 2016.11.0, this option is required.

    .. _tarfile: https://docs.python.org/2/library/tarfile.html
    .. _zipfile: https://docs.python.org/2/library/zipfile.html
    .. _xz: http://tukaani.org/xz/

    use_etag
        If ``True``, remote http/https file sources will attempt to use the
        ETag header to determine if the remote file needs to be downloaded.
        This provides a lightweight mechanism for promptly refreshing files
        changed on a web server without requiring a full hash comparison via
        the ``source_hash`` parameter.

        .. versionadded:: 3005

    **Examples**

    1. tar with lmza (i.e. xz) compression:

       .. code-block:: yaml

           graylog2-server:
             archive.extracted:
               - name: /opt/
               - source: https://github.com/downloads/Graylog2/graylog2-server/graylog2-server-0.9.6p1.tar.lzma
               - source_hash: md5=499ae16dcae71eeb7c3a30c75ea7a1a6

    2. tar archive with flag for verbose output, and enforcement of user/group
       ownership:

       .. code-block:: yaml

           graylog2-server:
             archive.extracted:
               - name: /opt/
               - source: https://github.com/downloads/Graylog2/graylog2-server/graylog2-server-0.9.6p1.tar.gz
               - source_hash: md5=499ae16dcae71eeb7c3a30c75ea7a1a6
               - options: v
               - user: foo
               - group: foo

    3. tar archive, with ``source_hash_update`` set to ``True`` to prevent
       state from attempting extraction unless the ``source_hash`` differs
       from the previous time the archive was extracted:

       .. code-block:: yaml

           graylog2-server:
             archive.extracted:
               - name: /opt/
               - source: https://github.com/downloads/Graylog2/graylog2-server/graylog2-server-0.9.6p1.tar.lzma
               - source_hash: md5=499ae16dcae71eeb7c3a30c75ea7a1a6
               - source_hash_update: True
    """
    ret = {"name": name, "result": False, "changes": {}, "comment": ""}

    # Remove pub kwargs as they're irrelevant here.
    kwargs = salt.utils.args.clean_kwargs(**kwargs)

    if skip_files_list_verify and skip_verify:
        ret[
            "comment"
        ] = 'Only one of "skip_files_list_verify" and "skip_verify" can be set to True'
        return ret

    if "keep_source" in kwargs and "keep" in kwargs:
        ret.setdefault("warnings", []).append(
            "Both 'keep_source' and 'keep' were used. Since these both "
            "do the same thing, 'keep' was ignored."
        )
        keep_source = bool(kwargs.pop("keep_source"))
        kwargs.pop("keep")
    elif "keep_source" in kwargs:
        keep_source = bool(kwargs.pop("keep_source"))
    elif "keep" in kwargs:
        keep_source = bool(kwargs.pop("keep"))
    else:
        # Neither was passed, default is True
        keep_source = True

    if not _path_is_abs(name):
        ret["comment"] = "{} is not an absolute path".format(name)
        return ret
    else:
        if not name:
            # Empty name, like None, '' etc.
            ret["comment"] = "Name of the directory path needs to be specified"
            return ret
        # os.path.isfile() returns False when there is a trailing slash, hence
        # our need for first stripping the slash and then adding it back later.
        # Otherwise, we can't properly check if the extraction location both a)
        # exists and b) is a file.
        #
        # &gt;&gt;&gt; os.path.isfile('/tmp/foo.txt')
        # True
        # &gt;&gt;&gt; os.path.isfile('/tmp/foo.txt/')
        # False
        name = name.rstrip(os.sep)
        if os.path.isfile(name):
            ret["comment"] = "{} exists and is not a directory".format(name)
            return ret
        # Add back the slash so that file.makedirs properly creates the
        # destdir if it needs to be created. file.makedirs expects a trailing
        # slash in the directory path.
        name += os.sep
    if not _path_is_abs(if_missing):
        ret["comment"] = "Value for 'if_missing' is not an absolute path"
        return ret
    if not _path_is_abs(enforce_ownership_on):
        ret["comment"] = "Value for 'enforce_ownership_on' is not an absolute path"
        return ret
    else:
        if enforce_ownership_on is not None:
            try:
                not_rel = os.path.relpath(enforce_ownership_on, name).startswith(
                    ".." + os.sep
                )
            except Exception:  # pylint: disable=broad-except
                # A ValueError is raised on Windows when the paths passed to
                # os.path.relpath are not on the same drive letter. Using a
                # generic Exception here to keep other possible exception types
                # from making this state blow up with a traceback.
                not_rel = True
            if not_rel:
                ret[
                    "comment"
                ] = "Value for 'enforce_ownership_on' must be within {}".format(name)
                return ret

    if if_missing is not None and os.path.exists(if_missing):
        ret["result"] = True
        ret["comment"] = "Path {} exists".format(if_missing)
        return ret

    if user or group:
        if salt.utils.platform.is_windows():
            ret[
                "comment"
            ] = "User/group ownership cannot be enforced on Windows minions"
            return ret

        if user:
            uid = __salt__["file.user_to_uid"](user)
            if uid == "":
                ret["comment"] = "User {} does not exist".format(user)
                return ret
        else:
            uid = -1

        if group:
            gid = __salt__["file.group_to_gid"](group)
            if gid == "":
                ret["comment"] = "Group {} does not exist".format(group)
                return ret
        else:
            gid = -1
    else:
        # We should never hit the ownership enforcement code unless user or
        # group was specified, but just in case, set uid/gid to -1 to make the
        # os.chown() a no-op and avoid a NameError.
        uid = gid = -1

    if source_hash_update and not source_hash:
        ret.setdefault("warnings", []).append(
            "The 'source_hash_update' argument is ignored when "
            "'source_hash' is not also specified."
        )

    try:
        source_match = __salt__["file.source_list"](source, source_hash, __env__)[0]
    except CommandExecutionError as exc:
        ret["result"] = False
        ret["comment"] = exc.strerror
        return ret

    if not source_match:
        ret["result"] = False
        ret["comment"] = 'Invalid source "{}"'.format(source)
        return ret

    urlparsed_source = urlparse(source_match)
    urlparsed_scheme = urlparsed_source.scheme
    urlparsed_path = os.path.join(
        urlparsed_source.netloc, urlparsed_source.path
    ).rstrip(os.sep)

    # urlparsed_scheme will be the drive letter if this is a Windows file path
    # This checks for a drive letter as the scheme and changes it to file
    if urlparsed_scheme and urlparsed_scheme.lower() in string.ascii_lowercase:
        urlparsed_path = ":".join([urlparsed_scheme, urlparsed_path])
        urlparsed_scheme = "file"

    source_hash_basename = urlparsed_path or urlparsed_source.netloc

    source_is_local = urlparsed_scheme in salt.utils.files.LOCAL_PROTOS
    if source_is_local:
        # Get rid of "file://" from start of source_match
        source_match = os.path.realpath(os.path.expanduser(urlparsed_path))
        if not os.path.isfile(source_match):
            ret["comment"] = "Source file '{}' does not exist".format(
                salt.utils.url.redact_http_basic_auth(source_match)
            )
            return ret

    valid_archive_formats = ("tar", "rar", "zip")
    if not archive_format:
        archive_format = salt.utils.files.guess_archive_type(source_hash_basename)
        if archive_format is None:
            ret["comment"] = (
                "Could not guess archive_format from the value of the "
                "'source' argument. Please set this archive_format to one "
                "of the following: {}".format(", ".join(valid_archive_formats))
            )
            return ret
    try:
        archive_format = archive_format.lower()
    except AttributeError:
        pass
    if archive_format not in valid_archive_formats:
        ret["comment"] = (
            "Invalid archive_format '{}'. Either set it to a supported "
            "value ({}) or remove this argument and the archive format will "
            "be guessed based on file extension.".format(
                archive_format,
                ", ".join(valid_archive_formats),
            )
        )
        return ret

    if options is not None and not isinstance(options, str):
        options = str(options)

    strip_components = None
    if options and archive_format == "tar":
        try:
            strip_components = int(
                re.search(
                    r"""--strip(?:-components)?(?:\s+|=)["']?(\d+)["']?""", options
                ).group(1)
            )
        except (AttributeError, ValueError):
            pass

    if archive_format == "zip":
        if options:
            if use_cmd_unzip is None:
                log.info(
                    "Presence of CLI options in archive.extracted state for "
                    "'%s' implies that use_cmd_unzip is set to True.",
                    name,
                )
                use_cmd_unzip = True
            elif not use_cmd_unzip:
                # use_cmd_unzip explicitly disabled
                ret["comment"] = (
                    "'use_cmd_unzip' cannot be set to False if CLI options "
                    "are being specified (via the 'options' argument). "
                    "Either remove 'use_cmd_unzip', or set it to True."
                )
                return ret
            if use_cmd_unzip:
                if "archive.cmd_unzip" not in __salt__:
                    ret["comment"] = (
                        "archive.cmd_unzip function not available, unzip might "
                        "not be installed on minion"
                    )
                    return ret
        if password:
            if use_cmd_unzip is None:
                log.info(
                    "Presence of a password in archive.extracted state for "
                    "'%s' implies that use_cmd_unzip is set to False.",
                    name,
                )
                use_cmd_unzip = False
            elif use_cmd_unzip:
                ret.setdefault("warnings", []).append(
                    "Using a password in combination with setting "
                    "'use_cmd_unzip' to True is considered insecure. It is "
                    "recommended to remove the 'use_cmd_unzip' argument (or "
                    "set it to False) and allow Salt to extract the archive "
                    "using Python's built-in ZIP file support."
                )
    else:
        if password:
            ret[
                "comment"
            ] = "The 'password' argument is only supported for zip archives"
            return ret

    if archive_format == "rar":
        if "archive.unrar" not in __salt__:
            ret["comment"] = (
                "archive.unrar function not available, rar/unrar might "
                "not be installed on minion"
            )
            return ret

    supports_options = ("tar", "zip")
    if options and archive_format not in supports_options:
        ret["comment"] = (
            "The 'options' argument is only compatible with the following "
            "archive formats: {}".format(", ".join(supports_options))
        )
        return ret

    if trim_output:
        if trim_output is True:
            trim_output = 100
        elif not isinstance(trim_output, (bool, int)):
            try:
                # Try to handle cases where trim_output was passed as a
                # string-ified integer.
                trim_output = int(trim_output)
            except TypeError:
                ret[
                    "comment"
                ] = "Invalid value for trim_output, must be True/False or an integer"
                return ret

    if source_hash:
        try:
            source_sum = __salt__["file.get_source_sum"](
                source=source_match,
                source_hash=source_hash,
                source_hash_name=source_hash_name,
                saltenv=__env__,
            )
        except CommandExecutionError as exc:
            ret["comment"] = exc.strerror
            return ret
    else:
        source_sum = {}

    if skip_files_list_verify:
        if source_is_local:
            cached = source_match
        else:
            cached = __salt__["cp.is_cached"](source_match, saltenv=__env__)

        # If file was already cached we can just re-generate its hash.
        if cached:
            existing_cached_source_sum = _read_cached_checksum(cached)
            log.debug(
                'Existing source sum is: "%s". Expected source sum is "%s"',
                existing_cached_source_sum,
                source_sum,
            )

        # If file was not cached we still could have a pre-existing hash file which would be
        # generated if update_source was set to True.
        else:
            parsed = urlparse(source_match)
            # This path would be generated if this file would be cached by file.cached state
            # We have to mimic it due to questionable logic in the _checksum_file_path function
            expected_cached_path = salt.utils.path.join(
                __opts__["cachedir"], "extrn_files", __env__, parsed.netloc, parsed.path
            )
            existing_cached_source_sum = _read_cached_checksum(expected_cached_path)

        if source_sum and existing_cached_source_sum:
            if existing_cached_source_sum["hsum"] == source_sum["hsum"]:
                ret["result"] = None if __opts__["test"] else True
                ret["comment"] = (
                    "Archive {} existing source sum is the same as the "
                    "expected one and skip_files_list_verify argument was set "
                    "to True. Extraction is not needed".format(
                        salt.utils.url.redact_http_basic_auth(source_match)
                    )
                )
                return ret
        else:
            log.debug("There is no cached source %s available on minion", source_match)

    if source_is_local:
        cached = source_match
    else:
        if __opts__["test"]:
            ret["result"] = None
            ret["comment"] = (
                "Archive {} would be cached (if necessary) and checked to "
                "discover if extraction is needed".format(
                    salt.utils.url.redact_http_basic_auth(source_match)
                )
            )
            return ret

        if "file.cached" not in __states__:
            # Shouldn't happen unless there is a traceback keeping
            # salt/states/file.py from being processed through the loader. If
            # that is the case, we have much more important problems as _all_
            # file states would be unavailable.
            ret[
                "comment"
            ] = "Unable to cache {}, file.cached state not available".format(
                salt.utils.url.redact_http_basic_auth(source_match)
            )
            return ret

        try:
            result = __states__["file.cached"](
                source_match,
                source_hash=source_hash,
                source_hash_name=source_hash_name,
                skip_verify=skip_verify,
                saltenv=__env__,
                use_etag=use_etag,
            )
        except Exception as exc:  # pylint: disable=broad-except
            msg = "Failed to cache {}: {}".format(
                salt.utils.url.redact_http_basic_auth(source_match), exc.__str__()
            )
            log.exception(msg)
            ret["comment"] = msg
            return ret
        else:
            log.debug("file.cached: %s", result)

        if result["result"]:
            # Get the path of the file in the minion cache
            cached = __salt__["cp.is_cached"](source_match, saltenv=__env__)
        else:
            log.debug(
                "failed to download %s",
                salt.utils.url.redact_http_basic_auth(source_match),
            )
            return result

    existing_cached_source_sum = _read_cached_checksum(cached)

    if source_hash and source_hash_update and not skip_verify:
        # Create local hash sum file if we're going to track sum update
        _update_checksum(cached)

    if archive_format == "zip" and not password:
        log.debug("Checking %s to see if it is password-protected", source_match)
        # Either use_cmd_unzip was explicitly set to True, or was
        # implicitly enabled by setting the "options" argument.
        try:
            encrypted_zip = __salt__["archive.is_encrypted"](
                cached, clean=False, saltenv=__env__, use_etag=use_etag
            )
        except CommandExecutionError:
            # This would happen if archive_format=zip and the source archive is
            # not actually a zip file.
            pass
        else:
            if encrypted_zip:
                ret["comment"] = (
                    "Archive {} is password-protected, but no password was "
                    "specified. Please set the 'password' argument.".format(
                        salt.utils.url.redact_http_basic_auth(source_match)
                    )
                )
                return ret

    try:
        contents = __salt__["archive.list"](
            cached,
            archive_format=archive_format,
            options=list_options,
            strip_components=strip_components,
            clean=False,
            verbose=True,
            use_etag=use_etag,
        )
    except CommandExecutionError as exc:
        contents = None
        errors = []
        if not if_missing:
            errors.append("'if_missing' must be set")
        if not enforce_ownership_on and (user or group):
            errors.append(
                "Ownership cannot be managed without setting 'enforce_ownership_on'."
            )
        msg = exc.strerror
        if errors:
            msg += "\n\n"
            if archive_format == "tar":
                msg += (
                    "If the source archive is a tar archive compressed using "
                    "a compression type not natively supported by the tar "
                    "command, then setting the 'list_options' argument may "
                    "allow the contents to be listed. Otherwise, if Salt is "
                    "unable to determine the files/directories in the "
                    "archive, the following workaround(s) would need to be "
                    "used for this state to proceed"
                )
            else:
                msg += (
                    "The following workarounds must be used for this state to proceed"
                )
            msg += " (assuming the source file is a valid {} archive):\n".format(
                archive_format
            )

            for error in errors:
                msg += "\n- {}".format(error)
        ret["comment"] = msg
        return ret

    if (
        enforce_toplevel
        and contents is not None
        and (
            len(contents["top_level_dirs"]) &gt; 1 or len(contents["top_level_files"]) &gt; 0
        )
    ):
        ret["comment"] = (
            "Archive does not have a single top-level directory. "
            "To allow this archive to be extracted, set "
            "'enforce_toplevel' to False. To avoid a "
            "'{}-bomb' it may also be advisable to set a "
            "top-level directory by adding it to the 'name' "
            "value (for example, setting 'name' to {} "
            "instead of {}).".format(
                archive_format,
                os.path.join(name, "some_dir"),
                name,
            )
        )
        return ret

    if clean and clean_parent:
        ret["comment"] = "Only one of 'clean' and 'clean_parent' can be set to True"
        ret["result"] = False
        return ret

    extraction_needed = overwrite
    contents_missing = False

    # Check to see if we need to extract the archive. Using os.lstat() in a
    # try/except is considerably faster than using os.path.exists(), and we
    # already need to catch an OSError to cover edge cases where the minion is
    # running as a non-privileged user and is trying to check for the existence
    # of a path to which it does not have permission.
    try:
        if_missing_path_exists = os.path.exists(if_missing)
    except TypeError:
        if_missing_path_exists = False

    if not if_missing_path_exists:
        if contents is None:
            try:
                os.lstat(if_missing)
                extraction_needed = False
            except OSError as exc:
                if exc.errno == errno.ENOENT:
                    extraction_needed = True
                else:
                    ret["comment"] = (
                        "Failed to check for existence of if_missing path "
                        "({}): {}".format(if_missing, exc.__str__())
                    )
                    return ret
        else:
            incorrect_type = []
            for path_list, func in (
                (contents["dirs"], stat.S_ISDIR),
                (
                    contents["files"],
                    lambda x: not stat.S_ISLNK(x) and not stat.S_ISDIR(x),
                ),
                (contents["links"], stat.S_ISLNK),
            ):
                for path in path_list:
                    full_path = salt.utils.path.join(name, path)
                    try:
                        path_mode = os.lstat(full_path.rstrip(os.sep)).st_mode
                        if not func(path_mode):
                            incorrect_type.append(path)
                    except OSError as exc:
                        if exc.errno == errno.ENOENT:
                            extraction_needed = True
                            contents_missing = True
                        elif exc.errno != errno.ENOTDIR:
                            # In cases where a directory path was occupied by a
                            # file instead, all os.lstat() calls to files within
                            # that dir will raise an ENOTDIR OSError. So we
                            # expect these and will only abort here if the
                            # error code is something else.
                            ret["comment"] = exc.__str__()
                            return ret

            if incorrect_type:
                incorrect_paths = "\n\n" + "\n".join(
                    ["- {}".format(x) for x in incorrect_type]
                )
                ret["comment"] = (
                    "The below paths (relative to {}) exist, but are the "
                    "incorrect type (file instead of directory, symlink "
                    "instead of file, etc.).".format(name)
                )
                if __opts__["test"] and clean and contents is not None:
                    ret["result"] = None
                    ret["comment"] += (
                        " Since the 'clean' option is enabled, the "
                        "destination paths would be cleared and the "
                        "archive would be extracted.{}".format(incorrect_paths)
                    )
                    return ret
                if __opts__["test"] and clean_parent and contents is not None:
                    ret["result"] = None
                    ret["comment"] += (
                        " Since the 'clean_parent' option is enabled, the "
                        "destination parent directory would be removed first "
                        "and then re-created and the archive would be "
                        "extracted"
                    )
                    return ret

                # Skip notices of incorrect types if we're cleaning
                if not (clean and contents is not None):
                    if not force:
                        ret["comment"] += (
                            " To proceed with extraction, set 'force' to "
                            "True. Note that this will remove these paths "
                            "before extracting.{}".format(incorrect_paths)
                        )
                        return ret
                    else:
                        errors = []
                        for path in incorrect_type:
                            full_path = os.path.join(name, path)
                            try:
                                salt.utils.files.rm_rf(full_path.rstrip(os.sep))
                                ret["changes"].setdefault("removed", []).append(
                                    full_path
                                )
                                extraction_needed = True
                            except OSError as exc:
                                if exc.errno != errno.ENOENT:
                                    errors.append(exc.__str__())
                        if errors:
                            msg = (
                                "One or more paths existed by were the incorrect "
                                "type (i.e. file instead of directory or "
                                "vice-versa), but could not be removed. The "
                                "following errors were observed:\n"
                            )
                            for error in errors:
                                msg += "\n- {}".format(error)
                            ret["comment"] = msg
                            return ret

    if (
        not extraction_needed
        and source_hash_update
        and existing_cached_source_sum is not None
        and not _compare_checksum(cached, existing_cached_source_sum)
    ):
        extraction_needed = True
        source_hash_trigger = True
    else:
        source_hash_trigger = False

    created_destdir = False

    if extraction_needed:
        if source_is_local and source_hash and not skip_verify:
            ret["result"] = __salt__["file.check_hash"](
                source_match, source_sum["hsum"]
            )
            if not ret["result"]:
                ret["comment"] = "{} does not match the desired source_hash {}".format(
                    salt.utils.url.redact_http_basic_auth(source_match),
                    source_sum["hsum"],
                )
                return ret

        if __opts__["test"]:
            ret["result"] = None
            ret["comment"] = "Archive {} would be extracted to {}".format(
                salt.utils.url.redact_http_basic_auth(source_match), name
            )
            if clean and contents is not None:
                ret["comment"] += ", after cleaning destination path(s)"
            _add_explanation(ret, source_hash_trigger, contents_missing)
            return ret

        if clean_parent and contents is not None:
            errors = []
            log.debug("Removing directory %s due to clean_parent set to True", name)
            try:
                salt.utils.files.rm_rf(name.rstrip(os.sep))
                ret["changes"].setdefault(
                    "removed",
                    "Directory {} was removed prior to the extraction".format(name),
                )
            except OSError as exc:
                if exc.errno != errno.ENOENT:
                    errors.append(str(exc))
            if errors:
                msg = (
                    "Unable to remove the directory {}. The following "
                    "errors were observed:\n".format(name)
                )
                for error in errors:
                    msg += "\n- {}".format(error)
                ret["comment"] = msg
                return ret

        if clean and contents is not None:
            errors = []
            log.debug("Cleaning archive paths from within %s", name)
<a name="1"></a>            for path in contents["top_level_dirs"] + contents["top_level_files"]:
                full_path = os.path.join(name, path)
                try:
                    log<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.debug("Removing %s", full_path)
                    salt.utils.files.rm_rf(full_path.rstrip(os.sep))
                    ret["changes"].setdefault("removed", []).append(</b></font>full_path)
                except OSError as exc:
                    if exc.errno != errno.ENOENT:
                        errors.append(exc.__str__())

            if errors:
                msg = (
                    "One or more paths could not be cleaned. The following "
                    "errors were observed:\n"
                )
                for error in errors:
                    msg += "\n- {}".format(error)
                ret["comment"] = msg
                return ret

        if not os.path.isdir(name):
            __states__["file.directory"](name, user=user, makedirs=True)
            created_destdir = True

        log.debug("Extracting %s to %s", cached, name)
        try:
            if archive_format == "zip":
                if use_cmd_unzip:
                    try:
                        files = __salt__["archive.cmd_unzip"](
                            cached,
                            name,
                            options=options,
                            trim_output=trim_output,
                            password=password,
                            **kwargs
                        )
                    except (CommandExecutionError, CommandNotFoundError) as exc:
                        ret["comment"] = exc.strerror
                        return ret
                else:
                    files = __salt__["archive.unzip"](
                        cached,
                        name,
                        options=options,
                        trim_output=trim_output,
                        password=password,
                        extract_perms=extract_perms,
                        **kwargs
                    )
            elif archive_format == "rar":
                try:
                    files = __salt__["archive.unrar"](
                        cached, name, trim_output=trim_output, **kwargs
                    )
                except (CommandExecutionError, CommandNotFoundError) as exc:
                    ret["comment"] = exc.strerror
                    return ret
            else:
                if options is None:
                    try:
                        with closing(tarfile.open(cached, "r")) as tar:
                            tar.extractall(salt.utils.stringutils.to_str(name))
                            files = tar.getnames()
                            if trim_output:
                                files = files[:trim_output]
                    except tarfile.ReadError:
                        if salt.utils.path.which("xz"):
                            if (
                                __salt__["cmd.retcode"](
                                    ["xz", "-t", cached],
                                    python_shell=False,
                                    ignore_retcode=True,
                                )
                                == 0
                            ):
                                # XZ-compressed data
                                log.debug(
                                    "Tar file is XZ-compressed, attempting "
                                    "decompression and extraction using XZ Utils "
                                    "and the tar command"
                                )
                                # Must use python_shell=True here because not
                                # all tar implementations support the -J flag
                                # for decompressing XZ-compressed data. We need
                                # to dump the decompressed data to stdout and
                                # pipe it to tar for extraction.
                                cmd = "xz --decompress --stdout {0} | tar xvf -"
                                results = __salt__["cmd.run_all"](
                                    cmd.format(shlex.quote(cached)),
                                    cwd=name,
                                    python_shell=True,
                                )
                                if results["retcode"] != 0:
                                    if created_destdir:
                                        _cleanup_destdir(name)
                                    ret["result"] = False
                                    ret["changes"] = results
                                    return ret
                                if _is_bsdtar():
                                    files = results["stderr"]
                                else:
                                    files = results["stdout"]
                            else:
                                # Failed to open tar archive and it is not
                                # XZ-compressed, gracefully fail the state
                                if created_destdir:
                                    _cleanup_destdir(name)
                                ret["result"] = False
                                ret["comment"] = (
                                    "Failed to read from tar archive using "
                                    "Python's native tar file support. If "
                                    "archive is compressed using something "
                                    "other than gzip or bzip2, the "
                                    "'options' argument may be required to "
                                    "pass the correct options to the tar "
                                    "command in order to extract the archive."
                                )
                                return ret
                        else:
                            if created_destdir:
                                _cleanup_destdir(name)
                            ret["result"] = False
                            ret["comment"] = (
                                "Failed to read from tar archive. If it is "
                                "XZ-compressed, install xz-utils to attempt "
                                "extraction."
                            )
                            return ret
                else:
                    if not salt.utils.path.which("tar"):
                        ret["comment"] = (
                            "tar command not available, it might not be "
                            "installed on minion"
                        )
                        return ret

                    # Ignore verbose file list options as we are already using
                    # "v" below in tar_shortopts
                    tar_opts = [
                        x
                        for x in shlex.split(options)
                        if x not in ("v", "-v", "--verbose")
                    ]

                    tar_cmd = ["tar"]
                    tar_shortopts = "xv"
                    tar_longopts = []

                    for position, opt in enumerate(tar_opts):
                        if opt.startswith("-"):
                            tar_longopts.append(opt)
                        else:
                            if position &gt; 0:
                                tar_longopts.append(opt)
                            else:
                                append_opt = opt
                                append_opt = append_opt.replace("x", "")
                                append_opt = append_opt.replace("f", "")
                                tar_shortopts = tar_shortopts + append_opt

                    if __grains__["os"].lower() == "openbsd":
                        tar_shortopts = "-" + tar_shortopts

                    tar_cmd.append(tar_shortopts)
                    tar_cmd.extend(tar_longopts)
                    tar_cmd.extend(["-f", cached])

                    results = __salt__["cmd.run_all"](
                        tar_cmd, cwd=name, python_shell=False
                    )
                    if results["retcode"] != 0:
                        ret["result"] = False
                        ret["changes"] = results
                        return ret
                    if _is_bsdtar():
                        files = results["stderr"].splitlines()
                        if trim_output:
                            files = files[:trim_output]
                    else:
                        files = results["stdout"].splitlines()
                        if trim_output:
                            files = files[:trim_output]
                    if not files:
                        files = "no tar output so far"
        except CommandExecutionError as exc:
            ret["comment"] = exc.strerror
            return ret

    # Recursively set user and group ownership of files
    enforce_missing = []
    enforce_failed = []
    if user or group:
        if enforce_ownership_on:
            if os.path.isdir(enforce_ownership_on):
                enforce_dirs = [enforce_ownership_on]
                enforce_files = []
                enforce_links = []
            else:
                enforce_dirs = []
                enforce_files = [enforce_ownership_on]
                enforce_links = []
        else:
            if contents is not None:
                enforce_dirs = contents["top_level_dirs"]
                enforce_files = contents["top_level_files"]
                enforce_links = contents["top_level_links"]

        recurse = []
        if user:
            recurse.append("user")
        if group:
            recurse.append("group")
        recurse_str = ", ".join(recurse)

        owner_changes = {x: y for x, y in (("user", user), ("group", group)) if y}
        for dirname in enforce_dirs:
            full_path = os.path.join(name, dirname)
            if not os.path.isdir(full_path):
                if not __opts__["test"]:
                    enforce_missing.append(full_path)
            else:
                log.debug(
                    "Enforcing %s ownership on %s using a file.directory state%s",
                    recurse_str,
                    dirname,
                    " (dry-run only)" if __opts__["test"] else "",
                )
                dir_result = __states__["file.directory"](
                    full_path, user=user, group=group, recurse=recurse
                )
                log.debug("file.directory: %s", dir_result)

                if dir_result.get("changes"):
                    ret["changes"]["updated ownership"] = True
                try:
                    if not dir_result["result"]:
                        enforce_failed.append(full_path)
                except (KeyError, TypeError):
                    log.warning(
                        "Bad state return %s for file.directory state on %s",
                        dir_result,
                        dirname,
                    )

        for filename in enforce_files + enforce_links:
            full_path = os.path.join(name, filename)
            try:
                # Using os.lstat instead of calling out to
                # __salt__['file.stats'], since we may be doing this for a lot
                # of files, and simply calling os.lstat directly will speed
                # things up a bit.
                file_stat = os.lstat(full_path)
            except OSError as exc:
                if not __opts__["test"]:
                    if exc.errno == errno.ENOENT:
                        enforce_missing.append(full_path)
                    enforce_failed.append(full_path)
            else:
                # Earlier we set uid, gid to -1 if we're not enforcing
                # ownership on user, group, as passing -1 to os.chown will tell
                # it not to change that ownership. Since we've done that, we
                # can selectively compare the uid/gid from the values in
                # file_stat, _only if_ the "desired" uid/gid is something other
                # than -1.
                if (uid != -1 and uid != file_stat.st_uid) or (
                    gid != -1 and gid != file_stat.st_gid
                ):
                    if __opts__["test"]:
                        ret["changes"]["updated ownership"] = True
                    else:
                        try:
                            os.lchown(full_path, uid, gid)
                            ret["changes"]["updated ownership"] = True
                        except OSError:
                            enforce_failed.append(filename)

    if extraction_needed:
        if len(files) &gt; 0:
            if created_destdir:
                ret["changes"]["directories_created"] = [name]
            ret["changes"]["extracted_files"] = files
            ret["comment"] = "{} extracted to {}".format(
                salt.utils.url.redact_http_basic_auth(source_match),
                name,
            )
            _add_explanation(ret, source_hash_trigger, contents_missing)
            ret["comment"] += ". Output was trimmed to {} number of lines".format(
                trim_output
            )
            ret["result"] = True

        else:
            ret["result"] = False
            ret["comment"] = "No files were extracted from {}".format(
                salt.utils.url.redact_http_basic_auth(source_match)
            )
    else:
        ret["result"] = True
        if if_missing_path_exists:
            ret["comment"] = "{} exists".format(if_missing)
        else:
            ret["comment"] = "All files in archive are already present"
        if __opts__["test"]:
            if ret["changes"].get("updated ownership"):
                ret["result"] = None
                ret[
                    "comment"
                ] += ". Ownership would be updated on one or more files/directories."

    if enforce_missing:
        if not if_missing:
            # If is_missing was used, and both a) the archive had never been
            # extracted, and b) the path referred to by if_missing exists, then
            # enforce_missing would contain paths of top_level dirs/files that
            # _would_ have been extracted. Since if_missing can be used as a
            # semaphore to conditionally extract, we don't want to make this a
            # case where the state fails, so we only fail the state if
            # is_missing is not used.
            ret["result"] = False
        ret["comment"] += (
            "\n\nWhile trying to enforce user/group ownership, the following "
            "paths were missing:\n"
        )
        for item in enforce_missing:
            ret["comment"] += "\n- {}".format(item)

    if enforce_failed:
        ret["result"] = False
        ret["comment"] += (
            "\n\nWhile trying to enforce user/group ownership, Salt was "
            "unable to change ownership on the following paths:\n"
        )
        for item in enforce_failed:
            ret["comment"] += "\n- {}".format(item)

    if not source_is_local:
        if keep_source:
            log.debug("Keeping cached source file %s", cached)
        else:
            log.debug("Cleaning cached source file %s", cached)
            result = __states__["file.not_cached"](source_match, saltenv=__env__)
            if not result["result"]:
                # Don't let failure to delete cached file cause the state
                # itself to fail, just drop it in the warnings.
                ret.setdefault("warnings", []).append(result["comment"])

    return ret
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>network_4.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
# pylint: disable=invalid-name
"""
Define some generic socket functions for network modules
<a name="0"></a>"""


<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>import fnmatch
import itertools
import logging
import os
import platform
import random
import re
import socket
import subprocess
import types
from collections.abc import Mapping, Sequence
from string import ascii_letters, digits

import salt.utils.args
import salt.utils.files
import salt.utils.path
import salt.utils.platform
import</b></font> salt.utils.stringutils
import salt.utils.zeromq
from salt._compat import ipaddress
from salt.exceptions import SaltClientError, SaltSystemExit
from salt.utils.decorators.jinja import jinja_filter
from salt.utils.versions import LooseVersion

try:
    import salt.utils.win_network

    WIN_NETWORK_LOADED = True
except ImportError:
    WIN_NETWORK_LOADED = False

log = logging.getLogger(__name__)

try:
    import ctypes
    import ctypes.util

    LIBC = ctypes.cdll.LoadLibrary(ctypes.util.find_library("c"))
    RES_INIT = LIBC.__res_init
except (ImportError, OSError, AttributeError, TypeError):
    pass


class Interfaces:
    __slots__ = ("interfaces",)

    def __init__(self, interfaces=None):
        if interfaces is None:
            interfaces = {}
        self.interfaces = interfaces

    def __call__(self, *args, **kwargs):
        if not self.interfaces:
            self.interfaces = interfaces()
        return self.interfaces

    def clear(self):
        self.interfaces = {}


_get_interfaces = Interfaces()
_clear_interfaces = _get_interfaces.clear


def sanitize_host(host):
    """
    Sanitize host string.
    https://tools.ietf.org/html/rfc1123#section-2.1
    """
    RFC952_characters = ascii_letters + digits + ".-_"
    return "".join([c for c in host[0:255] if c in RFC952_characters])


def isportopen(host, port):
    """
    Return status of a port
    """

    if not 1 &lt;= int(port) &lt;= 65535:
        return False

    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    out = sock.connect_ex((sanitize_host(host), int(port)))

    return out


def host_to_ips(host):
    """
    Returns a list of IP addresses of a given hostname or None if not found.
    """
    ips = []
    try:
        for family, socktype, proto, canonname, sockaddr in socket.getaddrinfo(
            host, 0, socket.AF_UNSPEC, socket.SOCK_STREAM
        ):
            if family == socket.AF_INET:
                ip, port = sockaddr
            elif family == socket.AF_INET6:
                ip, port, flow_info, scope_id = sockaddr
            ips.append(ip)
        if not ips:
            ips = None
    except Exception:  # pylint: disable=broad-except
        ips = None
    return ips


def _generate_minion_id():
    """
    Get list of possible host names and convention names.

    :return:
    """
    # There are three types of hostnames:
    # 1. Network names. How host is accessed from the network.
    # 2. Host aliases. They might be not available in all the network or only locally (/etc/hosts)
    # 3. Convention names, an internal nodename.

    class DistinctList(list):
        """
        List, which allows one to append only distinct objects.
        Needs to work on Python 2.6, because of collections.OrderedDict only since 2.7 version.
        Override 'filter()' for custom filtering.
        """

        localhost_matchers = [
            r"localhost.*",
            r"ip6-.*",
            r"127[.]\d",
            r"0\.0\.0\.0",
            r"::1.*",
            r"ipv6-.*",
            r"fe00::.*",
            r"fe02::.*",
            r"1.0.0.*.ip6.arpa",
        ]

        def append(self, p_object):
            if p_object and p_object not in self and not self.filter(p_object):
                super().append(p_object)
            return self

        def extend(self, iterable):
            for obj in iterable:
                self.append(obj)
            return self

        def filter(self, element):
            "Returns True if element needs to be filtered"
            for rgx in self.localhost_matchers:
                if re.match(rgx, element):
                    return True

        def first(self):
            return self and self[0] or None

    hostname = socket.gethostname()
<a name="1"></a>
    hosts = (
        DistinctList()
        <font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.append(
            salt.utils.stringutils.to_unicode(
                socket.getfqdn(salt.utils.stringutils.to_bytes(hostname))
            )
        )
        .append(</b></font>platform.node())
        .append(hostname)
    )
    if not hosts:
        try:
            for a_nfo in socket.getaddrinfo(
                hosts.first() or "localhost",
                None,
                socket.AF_INET,
                socket.SOCK_RAW,
                socket.IPPROTO_IP,
                socket.AI_CANONNAME,
            ):
                if len(a_nfo) &gt; 3:
                    hosts.append(a_nfo[3])
        except socket.gaierror:
            log.warning(
                "Cannot resolve address %s info via socket: %s",
                hosts.first() or "localhost (N/A)",
                socket.gaierror,
            )
    # Universal method for everywhere (Linux, Slowlaris, Windows etc)
    for f_name in (
        "/etc/hostname",
        "/etc/nodename",
        "/etc/hosts",
        r"{win}\system32\drivers\etc\hosts".format(win=os.getenv("WINDIR")),
    ):
        try:
            with salt.utils.files.fopen(f_name) as f_hdl:
                for line in f_hdl:
                    line = salt.utils.stringutils.to_unicode(line)
                    hst = line.strip().split("#")[0].strip().split()
                    if hst:
                        if hst[0][:4] in ("127.", "::1") or len(hst) == 1:
                            hosts.extend(hst)
        except OSError:
            pass

    # include public and private ipaddresses
    return hosts.extend(
        [addr for addr in ip_addrs() if not ipaddress.ip_address(addr).is_loopback]
    )


def generate_minion_id():
    """
    Return only first element of the hostname from all possible list.

    :return:
    """
    try:
        ret = salt.utils.stringutils.to_unicode(_generate_minion_id().first())
    except TypeError:
        ret = None
    return ret or "localhost"


def get_socket(addr, type=socket.SOCK_STREAM, proto=0):
    """
    Return a socket object for the addr
    IP-version agnostic
    """

    version = ipaddress.ip_address(addr).version
    if version == 4:
        family = socket.AF_INET
    elif version == 6:
        family = socket.AF_INET6
    return socket.socket(family, type, proto)


def get_fqhostname():
    """
    Returns the fully qualified hostname
    """
    l = [socket.getfqdn()]

    # try socket.getaddrinfo
    try:
        addrinfo = socket.getaddrinfo(
            socket.gethostname(),
            0,
            socket.AF_UNSPEC,
            socket.SOCK_STREAM,
            socket.SOL_TCP,
            socket.AI_CANONNAME,
        )
        for info in addrinfo:
            # info struct [family, socktype, proto, canonname, sockaddr]
            # On Windows `canonname` can be an empty string
            # This can cause the function to return `None`
            if len(info) &gt;= 4 and info[3]:
                l = [info[3]]
    except socket.gaierror:
        pass

    return l and l[0] or None


def ip_to_host(ip):
    """
    Returns the hostname of a given IP
    """
    try:
        hostname, aliaslist, ipaddrlist = socket.gethostbyaddr(ip)
    except Exception as exc:  # pylint: disable=broad-except
        log.debug("salt.utils.network.ip_to_host(%r) failed: %s", ip, exc)
        hostname = None
    return hostname


def is_reachable_host(entity_name):
    """
    Returns a bool telling if the entity name is a reachable host (IPv4/IPv6/FQDN/etc).
    :param hostname:
    :return:
    """
    try:
        assert type(socket.getaddrinfo(entity_name, 0, 0, 0, 0)) == list
        ret = True
    except socket.gaierror:
        ret = False

    return ret


def is_ip(ip_addr):
    """
    Returns a bool telling if the passed IP is a valid IPv4 or IPv6 address.
    """
    return is_ipv4(ip_addr) or is_ipv6(ip_addr)


def is_ipv4(ip_addr):
    """
    Returns a bool telling if the value passed to it was a valid IPv4 address
    """
    try:
        return ipaddress.ip_address(ip_addr).version == 4
    except ValueError:
        return False


def is_ipv6(ip_addr):
    """
    Returns a bool telling if the value passed to it was a valid IPv6 address
    """
    try:
        return ipaddress.ip_address(ip_addr).version == 6
    except ValueError:
        return False


def is_subnet(cidr):
    """
    Returns a bool telling if the passed string is an IPv4 or IPv6 subnet
    """
    return is_ipv4_subnet(cidr) or is_ipv6_subnet(cidr)


def is_ipv4_subnet(cidr):
    """
    Returns a bool telling if the passed string is an IPv4 subnet
    """
    try:
        return "/" in cidr and bool(ipaddress.IPv4Network(cidr))
    except Exception:  # pylint: disable=broad-except
        return False


def is_ipv6_subnet(cidr):
    """
    Returns a bool telling if the passed string is an IPv6 subnet
    """
    try:
        return "/" in cidr and bool(ipaddress.IPv6Network(cidr))
    except Exception:  # pylint: disable=broad-except
        return False


@jinja_filter("is_ip")
def is_ip_filter(ip_addr, options=None):
    """
    Returns a bool telling if the passed IP is a valid IPv4 or IPv6 address.
    """
    return is_ipv4_filter(ip_addr, options=options) or is_ipv6_filter(
        ip_addr, options=options
    )


def _ip_options_global(ip_obj, version):
    return not ip_obj.is_private


def _ip_options_multicast(ip_obj, version):
    return ip_obj.is_multicast


def _ip_options_loopback(ip_obj, version):
    return ip_obj.is_loopback


def _ip_options_link_local(ip_obj, version):
    return ip_obj.is_link_local


def _ip_options_private(ip_obj, version):
    return ip_obj.is_private


def _ip_options_reserved(ip_obj, version):
    return ip_obj.is_reserved


def _ip_options_site_local(ip_obj, version):
    if version == 6:
        return ip_obj.is_site_local
    return False


def _ip_options_unspecified(ip_obj, version):
    return ip_obj.is_unspecified


def _ip_options(ip_obj, version, options=None):

    # will process and IP options
    options_fun_map = {
        "global": _ip_options_global,
        "link-local": _ip_options_link_local,
        "linklocal": _ip_options_link_local,
        "ll": _ip_options_link_local,
        "link_local": _ip_options_link_local,
        "loopback": _ip_options_loopback,
        "lo": _ip_options_loopback,
        "multicast": _ip_options_multicast,
        "private": _ip_options_private,
        "public": _ip_options_global,
        "reserved": _ip_options_reserved,
        "site-local": _ip_options_site_local,
        "sl": _ip_options_site_local,
        "site_local": _ip_options_site_local,
        "unspecified": _ip_options_unspecified,
    }

    if not options:
        return str(ip_obj)  # IP version already checked

    options_list = [option.strip() for option in options.split(",")]

    for option, fun in options_fun_map.items():
        if option in options_list:
            fun_res = fun(ip_obj, version)
            if not fun_res:
                return None
                # stop at first failed test
            # else continue
    return str(ip_obj)


def _is_ipv(ip_addr, version, options=None):

    if not version:
        version = 4

    if version not in (4, 6):
        return None

    try:
        ip_obj = ipaddress.ip_address(ip_addr)
    except ValueError:
        # maybe it is an IP network
        try:
            ip_obj = ipaddress.ip_interface(ip_addr)
        except ValueError:
            # nope, still not :(
            return None

    if not ip_obj.version == version:
        return None

    # has the right version, let's move on
    return _ip_options(ip_obj, version, options=options)


@jinja_filter("is_ipv4")
def is_ipv4_filter(ip_addr, options=None):
    """
    Returns a bool telling if the value passed to it was a valid IPv4 address.

    ip
        The IP address.

    net: False
        Consider IP addresses followed by netmask.

    options
        CSV of options regarding the nature of the IP address. E.g.: loopback, multicast, private etc.
    """
    _is_ipv4 = _is_ipv(ip_addr, 4, options=options)
    return isinstance(_is_ipv4, str)


@jinja_filter("is_ipv6")
def is_ipv6_filter(ip_addr, options=None):
    """
    Returns a bool telling if the value passed to it was a valid IPv6 address.

    ip
        The IP address.

    net: False
        Consider IP addresses followed by netmask.

    options
        CSV of options regarding the nature of the IP address. E.g.: loopback, multicast, private etc.
    """
    _is_ipv6 = _is_ipv(ip_addr, 6, options=options)
    return isinstance(_is_ipv6, str)


def _ipv_filter(value, version, options=None):

    if version not in (4, 6):
        return

    if isinstance(value, (str, bytes)):
        return _is_ipv(
            value, version, options=options
        )  # calls is_ipv4 or is_ipv6 for `value`
    elif isinstance(value, (list, tuple, types.GeneratorType)):
        # calls is_ipv4 or is_ipv6 for each element in the list
        # os it filters and returns only those elements having the desired IP version
        return [
            _is_ipv(addr, version, options=options)
            for addr in value
            if _is_ipv(addr, version, options=options) is not None
        ]
    return None


@jinja_filter("ipv4")
def ipv4(value, options=None):
    """
    Filters a list and returns IPv4 values only.
    """
    return _ipv_filter(value, 4, options=options)


@jinja_filter("ipv6")
def ipv6(value, options=None):
    """
    Filters a list and returns IPv6 values only.
    """
    return _ipv_filter(value, 6, options=options)


@jinja_filter("ipaddr")
def ipaddr(value, options=None):
    """
    Filters and returns only valid IP objects.
    """
    ipv4_obj = ipv4(value, options=options)
    ipv6_obj = ipv6(value, options=options)
    if ipv4_obj is None or ipv6_obj is None:
        # an IP address can be either IPv4 either IPv6
        # therefofe if the value passed as arg is not a list, at least one of the calls above will return None
        # if one of them is none, means that we should return only one of them
        return ipv4_obj or ipv6_obj  # one of them
    else:
        return ipv4_obj + ipv6_obj  # extend lists


def _filter_ipaddr(value, options, version=None):
    ipaddr_filter_out = None
    if version:
        if version == 4:
            ipaddr_filter_out = ipv4(value, options)
        elif version == 6:
            ipaddr_filter_out = ipv6(value, options)
    else:
        ipaddr_filter_out = ipaddr(value, options)
    if not ipaddr_filter_out:
        return
    if not isinstance(ipaddr_filter_out, (list, tuple, types.GeneratorType)):
        ipaddr_filter_out = [ipaddr_filter_out]
    return ipaddr_filter_out


@jinja_filter("ip_host")
def ip_host(value, options=None, version=None):
    """
    Returns the interfaces IP address, e.g.: 192.168.0.1/28.
    """
    ipaddr_filter_out = _filter_ipaddr(value, options=options, version=version)
    if not ipaddr_filter_out:
        return
    if not isinstance(value, (list, tuple, types.GeneratorType)):
        return str(ipaddress.ip_interface(ipaddr_filter_out[0]))
    return [str(ipaddress.ip_interface(ip_a)) for ip_a in ipaddr_filter_out]


def _network_hosts(ip_addr_entry):
    return [
        str(host) for host in ipaddress.ip_network(ip_addr_entry, strict=False).hosts()
    ]


@jinja_filter("network_hosts")
def network_hosts(value, options=None, version=None):
    """
    Return the list of hosts within a network.

    .. note::

        When running this command with a large IPv6 network, the command will
        take a long time to gather all of the hosts.
    """
    ipaddr_filter_out = _filter_ipaddr(value, options=options, version=version)
    if not ipaddr_filter_out:
        return
    if not isinstance(value, (list, tuple, types.GeneratorType)):
        return _network_hosts(ipaddr_filter_out[0])
    return [_network_hosts(ip_a) for ip_a in ipaddr_filter_out]


def _network_size(ip_addr_entry):
    return ipaddress.ip_network(ip_addr_entry, strict=False).num_addresses


@jinja_filter("network_size")
def network_size(value, options=None, version=None):
    """
    Get the size of a network.
    """
    ipaddr_filter_out = _filter_ipaddr(value, options=options, version=version)
    if not ipaddr_filter_out:
        return
    if not isinstance(value, (list, tuple, types.GeneratorType)):
        return _network_size(ipaddr_filter_out[0])
    return [_network_size(ip_a) for ip_a in ipaddr_filter_out]


def natural_ipv4_netmask(ip_addr, fmt="prefixlen"):
    """
    Returns the "natural" mask of an IPv4 address
    """
    bits = _ipv4_to_bits(ip_addr)

    if bits.startswith("11"):
        mask = "24"
    elif bits.startswith("1"):
        mask = "16"
    else:
        mask = "8"

    if fmt == "netmask":
        return cidr_to_ipv4_netmask(mask)
    else:
        return "/" + mask


def rpad_ipv4_network(ip_addr):
    """
    Returns an IP network address padded with zeros.

    Ex: '192.168.3' -&gt; '192.168.3.0'
        '10.209' -&gt; '10.209.0.0'
    """
    return ".".join(itertools.islice(itertools.chain(ip_addr.split("."), "0000"), 0, 4))


def cidr_to_ipv4_netmask(cidr_bits):
    """
    Returns an IPv4 netmask
    """
    try:
        cidr_bits = int(cidr_bits)
        if not 1 &lt;= cidr_bits &lt;= 32:
            return ""
    except ValueError:
        return ""

    netmask = ""
    for idx in range(4):
        if idx:
            netmask += "."
        if cidr_bits &gt;= 8:
            netmask += "255"
            cidr_bits -= 8
        else:
            netmask += "{:d}".format(256 - (2 ** (8 - cidr_bits)))
            cidr_bits = 0
    return netmask


def _number_of_set_bits_to_ipv4_netmask(set_bits):
    """
    Returns an IPv4 netmask from the integer representation of that mask.

    Ex. 0xffffff00 -&gt; '255.255.255.0'
    """
    return cidr_to_ipv4_netmask(_number_of_set_bits(set_bits))


def _number_of_set_bits(x):
    """
    Returns the number of bits that are set in a 32bit int
    """
    # Taken from http://stackoverflow.com/a/4912729. Many thanks!
    x -= (x &gt;&gt; 1) &amp; 0x55555555
    x = ((x &gt;&gt; 2) &amp; 0x33333333) + (x &amp; 0x33333333)
    x = ((x &gt;&gt; 4) + x) &amp; 0x0F0F0F0F
    x += x &gt;&gt; 8
    x += x &gt;&gt; 16
    return x &amp; 0x0000003F


def _interfaces_ip(out):
    """
    Uses ip to return a dictionary of interfaces with various information about
    each (up/down state, ip address, netmask, and hwaddr)
    """
    ret = dict()

    def parse_network(value, cols):
        """
        Return a tuple of ip, netmask, broadcast
        based on the current set of cols
        """
        brd = None
        scope = None
        if "/" in value:  # we have a CIDR in this address
            ip, cidr = value.split("/")
        else:
            ip = value
            cidr = 32

        if type_ == "inet":
            mask = cidr_to_ipv4_netmask(int(cidr))
            if "brd" in cols:
                brd = cols[cols.index("brd") + 1]
        elif type_ == "inet6":
            mask = cidr
            if "scope" in cols:
                scope = cols[cols.index("scope") + 1]
        return (ip, mask, brd, scope)

    groups = re.compile("\r?\n\\d").split(out)
    for group in groups:
        iface = None
        data = dict()

        for line in group.splitlines():
            if " " not in line:
                continue
            match = re.match(r"^\d*:\s+([\w.\-]+)(?:@)?([\w.\-]+)?:\s+&lt;(.+)&gt;", line)
            if match:
                iface, parent, attrs = match.groups()
                if "UP" in attrs.split(","):
                    data["up"] = True
                else:
                    data["up"] = False
                if parent:
                    data["parent"] = parent
                continue

            cols = line.split()
            if len(cols) &gt;= 2:
                type_, value = tuple(cols[0:2])
                iflabel = cols[-1:][0]
                if type_ in ("inet", "inet6"):
                    ipaddr, netmask, broadcast, scope = parse_network(value, cols)
                    addr_obj = dict()
                    if "secondary" not in cols:
                        if type_ == "inet":
                            if "inet" not in data:
                                data["inet"] = list()
                            addr_obj["address"] = ipaddr
                            addr_obj["netmask"] = netmask
                            addr_obj["broadcast"] = broadcast
                            addr_obj["label"] = iflabel
                            data["inet"].append(addr_obj)
                        elif type_ == "inet6":
                            if "inet6" not in data:
                                data["inet6"] = list()
                            addr_obj["address"] = ipaddr
                            addr_obj["prefixlen"] = netmask
                            addr_obj["scope"] = scope
                            data["inet6"].append(addr_obj)
                    else:
                        if type_ == "inet":
                            if "secondary" not in data:
                                data["secondary"] = list()
                            addr_obj["type"] = type_
                            addr_obj["address"] = ipaddr
                            addr_obj["netmask"] = netmask
                            addr_obj["broadcast"] = broadcast
                            addr_obj["label"] = iflabel
                            data["secondary"].append(addr_obj)
                        elif type_ == "inet6":
                            if "secondary" not in data:
                                data["secondary"] = list()
                            addr_obj["type"] = type_
                            addr_obj["address"] = ipaddr
                            addr_obj["prefixlen"] = netmask
                            addr_obj["scope"] = scope
                            data["secondary"].append(addr_obj)
                elif type_.startswith("link"):
                    data["hwaddr"] = value
        if iface:
            ret[iface] = data
            del iface, data
    return ret


def _interfaces_ifconfig(out):
    """
    Uses ifconfig to return a dictionary of interfaces with various information
    about each (up/down state, ip address, netmask, and hwaddr)
    """
    ret = dict()

    piface = re.compile(r"^([^\s:]+)")
    pmac = re.compile(".*?(?:HWaddr|ether|address:|lladdr) ([0-9a-fA-F:]+)")
    if salt.utils.platform.is_sunos():
        pip = re.compile(r".*?(?:inet\s+)([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)(.*)")
        pip6 = re.compile(".*?(?:inet6 )([0-9a-fA-F:]+)")
        pmask6 = re.compile(r".*?(?:inet6 [0-9a-fA-F:]+/(\d+)).*")
    else:
        pip = re.compile(r".*?(?:inet addr:|inet [^\d]*)(.*?)\s")
        pip6 = re.compile(".*?(?:inet6 addr: (.*?)/|inet6 )([0-9a-fA-F:]+)")
        pmask6 = re.compile(
            r".*?(?:inet6 addr: [0-9a-fA-F:]+/(\d+)|prefixlen (\d+))(?:"
            r" Scope:([a-zA-Z]+)| scopeid (0x[0-9a-fA-F]))?"
        )
    pmask = re.compile(r".*?(?:Mask:|netmask )(?:((?:0x)?[0-9a-fA-F]{8})|([\d\.]+))")
    pupdown = re.compile("UP")
    pbcast = re.compile(r".*?(?:Bcast:|broadcast )([\d\.]+)")

    groups = re.compile("\r?\n(?=\\S)").split(out)
    for group in groups:
        data = dict()
        iface = ""
        updown = False
        for line in group.splitlines():
            miface = piface.match(line)
            mmac = pmac.match(line)
            mip = pip.match(line)
            mip6 = pip6.match(line)
            mupdown = pupdown.search(line)
            if miface:
                iface = miface.group(1)
            if mmac:
                data["hwaddr"] = mmac.group(1)
                if salt.utils.platform.is_sunos():
                    expand_mac = []
                    for chunk in data["hwaddr"].split(":"):
                        expand_mac.append(
                            "0{}".format(chunk)
                            if len(chunk) &lt; 2
                            else "{}".format(chunk)
                        )
                    data["hwaddr"] = ":".join(expand_mac)
            if mip:
                if "inet" not in data:
                    data["inet"] = list()
                addr_obj = dict()
                addr_obj["address"] = mip.group(1)
                mmask = pmask.match(line)
                if mmask:
                    if mmask.group(1):
                        mmask = _number_of_set_bits_to_ipv4_netmask(
                            int(mmask.group(1), 16)
                        )
                    else:
                        mmask = mmask.group(2)
                    addr_obj["netmask"] = mmask
                mbcast = pbcast.match(line)
                if mbcast:
                    addr_obj["broadcast"] = mbcast.group(1)
                data["inet"].append(addr_obj)
            if mupdown:
                updown = True
            if mip6:
                if "inet6" not in data:
                    data["inet6"] = list()
                addr_obj = dict()
                addr_obj["address"] = mip6.group(1) or mip6.group(2)
                mmask6 = pmask6.match(line)
                if mmask6:
                    addr_obj["prefixlen"] = mmask6.group(1) or mmask6.group(2)
                    if not salt.utils.platform.is_sunos():
                        ipv6scope = mmask6.group(3) or mmask6.group(4)
                        addr_obj["scope"] = (
                            ipv6scope.lower() if ipv6scope is not None else ipv6scope
                        )
                # SunOS sometimes has ::/0 as inet6 addr when using addrconf
                if (
                    not salt.utils.platform.is_sunos()
                    or addr_obj["address"] != "::"
                    and addr_obj["prefixlen"] != 0
                ):
                    data["inet6"].append(addr_obj)
        data["up"] = updown
        if iface in ret:
            # SunOS optimization, where interfaces occur twice in 'ifconfig -a'
            # output with the same name: for ipv4 and then for ipv6 addr family.
            # Every instance has its own 'UP' status and we assume that ipv4
            # status determines global interface status.
            #
            # merge items with higher priority for older values
            # after that merge the inet and inet6 sub items for both
            ret[iface] = dict(list(data.items()) + list(ret[iface].items()))
            if "inet" in data:
                ret[iface]["inet"].extend(
                    x for x in data["inet"] if x not in ret[iface]["inet"]
                )
            if "inet6" in data:
                ret[iface]["inet6"].extend(
                    x for x in data["inet6"] if x not in ret[iface]["inet6"]
                )
        else:
            ret[iface] = data
        del data
    return ret


def linux_interfaces():
    """
    Obtain interface information for *NIX/BSD variants
    """
    ifaces = dict()
    ip_path = salt.utils.path.which("ip")
    ifconfig_path = None if ip_path else salt.utils.path.which("ifconfig")
    if ip_path:
        cmd1 = subprocess.Popen(
            [ip_path, "link", "show"],
            close_fds=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
        ).communicate()[0]
        cmd2 = subprocess.Popen(
            [ip_path, "addr", "show"],
            close_fds=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
        ).communicate()[0]
        ifaces = _interfaces_ip(
            "{}\n{}".format(
                salt.utils.stringutils.to_str(cmd1), salt.utils.stringutils.to_str(cmd2)
            )
        )
    elif ifconfig_path:
        cmd = subprocess.Popen(
            [ifconfig_path, "-a"],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
        ).communicate()[0]
        ifaces = _interfaces_ifconfig(salt.utils.stringutils.to_str(cmd))
    return ifaces


def _netbsd_interfaces_ifconfig(out):
    """
    Uses ifconfig to return a dictionary of interfaces with various information
    about each (up/down state, ip address, netmask, and hwaddr)
    """
    ret = dict()

    piface = re.compile(r"^([^\s:]+)")
    pmac = re.compile(".*?address: ([0-9a-f:]+)")

    pip = re.compile(r".*?inet [^\d]*(.*?)/([\d]*)\s")
    pip6 = re.compile(r".*?inet6 ([0-9a-f:]+)%([a-zA-Z0-9]*)/([\d]*)\s")

    pupdown = re.compile("UP")
    pbcast = re.compile(r".*?broadcast ([\d\.]+)")

    groups = re.compile("\r?\n(?=\\S)").split(out)
    for group in groups:
        data = dict()
        iface = ""
        updown = False
        for line in group.splitlines():
            miface = piface.match(line)
            mmac = pmac.match(line)
            mip = pip.match(line)
            mip6 = pip6.match(line)
            mupdown = pupdown.search(line)
            if miface:
                iface = miface.group(1)
            if mmac:
                data["hwaddr"] = mmac.group(1)
            if mip:
                if "inet" not in data:
                    data["inet"] = list()
                addr_obj = dict()
                addr_obj["address"] = mip.group(1)
                mmask = mip.group(2)
                if mip.group(2):
                    addr_obj["netmask"] = cidr_to_ipv4_netmask(mip.group(2))
                mbcast = pbcast.match(line)
                if mbcast:
                    addr_obj["broadcast"] = mbcast.group(1)
                data["inet"].append(addr_obj)
            if mupdown:
                updown = True
            if mip6:
                if "inet6" not in data:
                    data["inet6"] = list()
                addr_obj = dict()
                addr_obj["address"] = mip6.group(1)
                mmask6 = mip6.group(3)
                addr_obj["scope"] = mip6.group(2)
                addr_obj["prefixlen"] = mip6.group(3)
                data["inet6"].append(addr_obj)
        data["up"] = updown
        ret[iface] = data
        del data
    return ret


def _junos_interfaces_ifconfig(out):
    """
    Uses ifconfig to return a dictionary of interfaces with various information
    about each (up/down state, ip address, netmask, and hwaddr)
    """
    ret = dict()

    piface = re.compile(r"^([^\s:]+)")
    pmac = re.compile("curr media .*? ([0-9a-f:]+)")

    pip = re.compile(
        r".*?inet\s*(primary)*\s+mtu"
        r" (\d+)\s+local=[^\d]*(.*?)\s+dest=[^\d]*(.*?)\/([\d]*)\s+bcast=((?:[0-9]{1,3}\.){3}[0-9]{1,3})"
    )
    pip6 = re.compile(
        r".*?inet6 mtu [^\d]+\s+local=([0-9a-f:]+)%([a-zA-Z0-9]*)/([\d]*)\s"
    )

    pupdown = re.compile("UP")
    pbcast = re.compile(r".*?broadcast ([\d\.]+)")

    groups = re.compile("\r?\n(?=\\S)").split(out)
    for group in groups:
        data = dict()
        iface = ""
        updown = False
        primary = False
        for line in group.splitlines():
            miface = piface.match(line)
            mmac = pmac.match(line)
            mip = pip.match(line)
            mip6 = pip6.match(line)
            mupdown = pupdown.search(line)
            if miface:
                iface = miface.group(1)
            if mmac:
                data["hwaddr"] = mmac.group(1)
            if mip:
                if "primary" in data:
                    primary = True
                if "inet" not in data:
                    data["inet"] = list()
                if mip.group(2):
                    data["mtu"] = int(mip.group(2))
                addr_obj = dict()
                addr_obj["address"] = mip.group(3)
                mmask = mip.group(5)
                if mip.group(5):
                    addr_obj["netmask"] = cidr_to_ipv4_netmask(mip.group(5))
                mbcast = pbcast.match(line)
                if mbcast:
                    addr_obj["broadcast"] = mbcast.group(1)
                data["inet"].append(addr_obj)
            if mupdown:
                updown = True
            if mip6:
                if "inet6" not in data:
                    data["inet6"] = list()
                addr_obj = dict()
                addr_obj["address"] = mip6.group(1)
                mmask6 = mip6.group(3)
                addr_obj["scope"] = mip6.group(2)
                addr_obj["prefixlen"] = mip6.group(3)
                data["inet6"].append(addr_obj)
        data["up"] = updown
        ret[iface] = data
        del data
    return ret


def junos_interfaces():
    """
    Obtain interface information for Junos; ifconfig
    output diverged from other BSD variants (Netmask is now part of the
    address)
    """
    ifconfig_path = salt.utils.path.which("ifconfig")
    cmd = subprocess.Popen(
        [ifconfig_path, "-a"],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
    ).communicate()[0]
    return _junos_interfaces_ifconfig(salt.utils.stringutils.to_str(cmd))


def netbsd_interfaces():
    """
    Obtain interface information for NetBSD &gt;= 8 where the ifconfig
    output diverged from other BSD variants (Netmask is now part of the
    address)
    """
    # NetBSD versions prior to 8.0 can still use linux_interfaces()
    if LooseVersion(os.uname()[2]) &lt; LooseVersion("8.0"):
        return linux_interfaces()

    ifconfig_path = salt.utils.path.which("ifconfig")
    cmd = subprocess.Popen(
        [ifconfig_path, "-a"],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
    ).communicate()[0]
    return _netbsd_interfaces_ifconfig(salt.utils.stringutils.to_str(cmd))


def _interfaces_ipconfig(out):
    """
    Returns a dictionary of interfaces with various information about each
    (up/down state, ip address, netmask, and hwaddr)

    NOTE: This is not used by any function and may be able to be removed in the
    future.
    """
    ifaces = dict()
    iface = None
    addr = None
    adapter_iface_regex = re.compile(r"adapter (\S.+):$")

    for line in out.splitlines():
        if not line:
            continue
        # TODO what does Windows call Infiniband and 10/40gige adapters
        if line.startswith("Ethernet"):
            iface = ifaces[adapter_iface_regex.search(line).group(1)]
            iface["up"] = True
            addr = {}
            continue
        if iface:
            key, val = line.split(",", 1)
            key = key.strip(" .")
            val = val.strip()
            if addr and key == "Subnet Mask":
                addr["netmask"] = val
            elif key in ("IP Address", "IPv4 Address"):
                if "inet" not in iface:
                    iface["inet"] = list()
                addr = {
                    "address": val.rstrip("(Preferred)"),
                    "netmask": None,
                    "broadcast": None,
                }  # TODO find the broadcast
                iface["inet"].append(addr)
            elif "IPv6 Address" in key:
                if "inet6" not in iface:
                    iface["inet"] = list()
                # XXX What is the prefixlen!?
                addr = {"address": val.rstrip("(Preferred)"), "prefixlen": None}
                iface["inet6"].append(addr)
            elif key == "Physical Address":
                iface["hwaddr"] = val
            elif key == "Media State":
                # XXX seen used for tunnel adaptors
                # might be useful
                iface["up"] = val != "Media disconnected"


def win_interfaces():
    """
    Obtain interface information for Windows systems
    """
    if WIN_NETWORK_LOADED is False:
        # Let's throw the ImportException again
        import salt.utils.win_network as _
    return salt.utils.win_network.get_interface_info()


def interfaces():
    """
    Return a dictionary of information about all the interfaces on the minion
    """
    if salt.utils.platform.is_windows():
        return win_interfaces()
    elif salt.utils.platform.is_junos():
        return junos_interfaces()
    elif salt.utils.platform.is_netbsd():
        return netbsd_interfaces()
    else:
        return linux_interfaces()


def get_net_start(ipaddr, netmask):
    """
    Return the address of the network
    """
    net = ipaddress.ip_network("{}/{}".format(ipaddr, netmask), strict=False)
    return str(net.network_address)


def get_net_size(mask):
    """
    Turns an IPv4 netmask into its corresponding prefix length
    (255.255.255.0 -&gt; 24 as in 192.168.1.10/24).
    """
    binary_str = ""
    for octet in mask.split("."):
        binary_str += bin(int(octet))[2:].zfill(8)
    return len(binary_str.rstrip("0"))


def calc_net(ipaddr, netmask=None):
    """
    Takes IP (CIDR notation supported) and optionally netmask
    and returns the network in CIDR-notation.
    (The IP can be any IP inside the subnet)
    """
    if netmask is not None:
        ipaddr = "{}/{}".format(ipaddr, netmask)

    return str(ipaddress.ip_network(ipaddr, strict=False))


def _ipv4_to_bits(ipaddr):
    """
    Accepts an IPv4 dotted quad and returns a string representing its binary
    counterpart
    """
    return "".join([bin(int(x))[2:].rjust(8, "0") for x in ipaddr.split(".")])


def _get_iface_info(iface):
    """
    If `iface` is available, return interface info and no error, otherwise
    return no info and log and return an error
    """
    iface_info = interfaces()

    if iface in iface_info.keys():
        return iface_info, False
    else:
        error_msg = 'Interface "{}" not in available interfaces: "{}"'.format(
            iface, '", "'.join(iface_info.keys())
        )
        log.error(error_msg)
        return None, error_msg


def _hw_addr_aix(iface):
    """
    Return the hardware address (a.k.a. MAC address) for a given interface on AIX
    MAC address not available in through interfaces
    """
    cmd = subprocess.Popen(
        ["grep", "Hardware Address"],
        stdin=subprocess.Popen(
            ["entstat", "-d", iface],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
        ).stdout,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
    ).communicate()[0]

    if cmd:
        comps = cmd.split(" ")
        if len(comps) == 3:
            mac_addr = comps[2].strip("'").strip()
            return mac_addr

    error_msg = 'Interface "{}" either not available or does not contain a hardware address'.format(
        iface
    )
    log.error(error_msg)
    return error_msg


def hw_addr(iface):
    """
    Return the hardware address (a.k.a. MAC address) for a given interface

    .. versionchanged:: 2016.11.4
        Added support for AIX

    """
    if salt.utils.platform.is_aix():
        return _hw_addr_aix

    iface_info, error = _get_iface_info(iface)

    if error is False:
        return iface_info.get(iface, {}).get("hwaddr", "")
    else:
        return error


def interface(iface):
    """
    Return the details of `iface` or an error if it does not exist
    """
    iface_info, error = _get_iface_info(iface)

    if error is False:
        return iface_info.get(iface, {}).get("inet", "")
    else:
        return error


def interface_ip(iface):
    """
    Return `iface` IPv4 addr or an error if `iface` does not exist
    """
    iface_info, error = _get_iface_info(iface)

    if error is False:
        inet = iface_info.get(iface, {}).get("inet", None)
        return inet[0].get("address", "") if inet else ""
    else:
        return error


def _subnets(proto="inet", interfaces_=None):
    """
    Returns a list of subnets to which the host belongs
    """
    if interfaces_ is None:
        ifaces = interfaces()
    elif isinstance(interfaces_, list):
        ifaces = {}
        for key, value in interfaces().items():
            if key in interfaces_:
                ifaces[key] = value
    else:
        ifaces = {interfaces_: interfaces().get(interfaces_, {})}

    ret = set()

    if proto == "inet":
        subnet = "netmask"
        dflt_cidr = 32
    elif proto == "inet6":
        subnet = "prefixlen"
        dflt_cidr = 128
    else:
        log.error("Invalid proto %s calling subnets()", proto)
        return

    for ip_info in ifaces.values():
        addrs = ip_info.get(proto, [])
        addrs.extend(
            [addr for addr in ip_info.get("secondary", []) if addr.get("type") == proto]
        )

        for intf in addrs:
            if subnet in intf:
                intf = ipaddress.ip_interface(
                    "{}/{}".format(intf["address"], intf[subnet])
                )
            else:
                intf = ipaddress.ip_interface(
                    "{}/{}".format(intf["address"], dflt_cidr)
                )
            if not intf.is_loopback:
                ret.add(intf.network)
    return [str(net) for net in sorted(ret)]


def subnets(interfaces=None):
    """
    Returns a list of IPv4 subnets to which the host belongs
    """
    return _subnets("inet", interfaces_=interfaces)


def subnets6():
    """
    Returns a list of IPv6 subnets to which the host belongs
    """
    return _subnets("inet6")


def in_subnet(cidr, addr=None):
    """
    Returns True if host or (any of) addrs is within specified subnet, otherwise False
    """
    try:
        cidr = ipaddress.ip_network(cidr)
    except ValueError:
        log.error("Invalid CIDR '%s'", cidr)
        return False

    if addr is None:
        addr = ip_addrs()
        addr.extend(ip_addrs6())
    elif not isinstance(addr, (list, tuple)):
        addr = (addr,)

    return any(ipaddress.ip_address(item) in cidr for item in addr)


def _get_ips(ifaces, proto="inet"):
    """
    Accepts a dict of interface data and returns a list of dictionaries
    """
    ret = []
    for ip_info in ifaces.values():
        ret.extend(ip_info.get(proto, []))
        ret.extend(
            [addr for addr in ip_info.get("secondary", []) if addr.get("type") == proto]
        )
    return ret


def _filter_interfaces(interface=None, interface_data=None):
    """
    Gather interface data if not passed in, and optionally filter by the
    specified interface name.
    """
    ifaces = interface_data if isinstance(interface_data, dict) else interfaces()
    if interface is None:
        ret = ifaces
    else:
        interface = salt.utils.args.split_input(interface)
        # pylint: disable=not-an-iterable
        ret = {
            k: v
            for k, v in ifaces.items()
            if any(fnmatch.fnmatch(k, pat) for pat in interface)
        }
        # pylint: enable=not-an-iterable
    return ret


def _ip_addrs(
    interface=None, include_loopback=False, interface_data=None, proto="inet"
):
    """
    Return the full list of IP adresses matching the criteria

    proto = inet|inet6
    """
    addrs = _get_ips(_filter_interfaces(interface, interface_data), proto=proto)

    ret = set()
    for addr in addrs:
        addr = ipaddress.ip_address(addr.get("address"))
        if not addr.is_loopback or include_loopback:
            ret.add(addr)

    return [str(addr) for addr in sorted(ret)]


def ip_addrs(interface=None, include_loopback=False, interface_data=None):
    """
    Returns a list of IPv4 addresses assigned to the host. 127.0.0.1 is
    ignored, unless 'include_loopback=True' is indicated. If 'interface' is
    provided, then only IP addresses from that interface will be returned.
    """
    return _ip_addrs(interface, include_loopback, interface_data, "inet")


def ip_addrs6(interface=None, include_loopback=False, interface_data=None):
    """
    Returns a list of IPv6 addresses assigned to the host. ::1 is ignored,
    unless 'include_loopback=True' is indicated. If 'interface' is provided,
    then only IP addresses from that interface will be returned.
    """
    return _ip_addrs(interface, include_loopback, interface_data, "inet6")


def _ip_networks(
    interface=None,
    include_loopback=False,
    verbose=False,
    interface_data=None,
    proto="inet",
):
    """
    Returns a list of networks to which the minion belongs. The results can be
    restricted to a single interface using the ``interface`` argument.
    """
    addrs = _get_ips(_filter_interfaces(interface, interface_data), proto=proto)

    ret = set()
    for addr in addrs:
        _ip = addr.get("address")
        _net = addr.get("netmask" if proto == "inet" else "prefixlen")
        if _ip and _net:
            try:
                ip_net = ipaddress.ip_network("{}/{}".format(_ip, _net), strict=False)
            except Exception:  # pylint: disable=broad-except
                continue
            if not ip_net.is_loopback or include_loopback:
                ret.add(ip_net)

    if not verbose:
        return [str(addr) for addr in sorted(ret)]

    verbose_ret = {
        str(x): {
            "address": str(x.network_address),
            "netmask": str(x.netmask),
            "num_addresses": x.num_addresses,
            "prefixlen": x.prefixlen,
        }
        for x in ret
    }
    return verbose_ret


def ip_networks(
    interface=None, include_loopback=False, verbose=False, interface_data=None
):
    """
    Returns the IPv4 networks to which the minion belongs. Networks will be
    returned as a list of network/prefixlen. To get more information about a
    each network, use verbose=True and a dictionary with more information will
    be returned.
    """
    return _ip_networks(
        interface=interface,
        include_loopback=include_loopback,
        verbose=verbose,
        interface_data=interface_data,
        proto="inet",
    )


def ip_networks6(
    interface=None, include_loopback=False, verbose=False, interface_data=None
):
    """
    Returns the IPv6 networks to which the minion belongs. Networks will be
    returned as a list of network/prefixlen. To get more information about a
    each network, use verbose=True and a dictionary with more information will
    be returned.
    """
    return _ip_networks(
        interface=interface,
        include_loopback=include_loopback,
        verbose=verbose,
        interface_data=interface_data,
        proto="inet6",
    )


def hex2ip(hex_ip, invert=False):
    """
    Convert a hex string to an ip, if a failure occurs the original hex is
    returned. If 'invert=True' assume that ip from /proc/net/&lt;proto&gt;
    """
    if len(hex_ip) == 32:  # ipv6
        ip_addr = []
        for i in range(0, 32, 8):
            ip_part = hex_ip[i : i + 8]
            ip_part = [ip_part[x : x + 2] for x in range(0, 8, 2)]
            if invert:
                ip_addr.append("{0[3]}{0[2]}:{0[1]}{0[0]}".format(ip_part))
            else:
                ip_addr.append("{0[0]}{0[1]}:{0[2]}{0[3]}".format(ip_part))
        try:
            address = ipaddress.IPv6Address(":".join(ip_addr))
            if address.ipv4_mapped:
                return str(address.ipv4_mapped)
            else:
                return address.compressed
        except ipaddress.AddressValueError as ex:
            log.error("hex2ip - ipv6 address error: %s", ex)
            return hex_ip

    try:
        hip = int(hex_ip, 16)
    except ValueError:
        return hex_ip
    if invert:
        return "{3}.{2}.{1}.{0}".format(
            hip &gt;&gt; 24 &amp; 255, hip &gt;&gt; 16 &amp; 255, hip &gt;&gt; 8 &amp; 255, hip &amp; 255
        )
    return "{}.{}.{}.{}".format(
        hip &gt;&gt; 24 &amp; 255, hip &gt;&gt; 16 &amp; 255, hip &gt;&gt; 8 &amp; 255, hip &amp; 255
    )


def mac2eui64(mac, prefix=None):
    """
    Convert a MAC address to a EUI64 identifier
    or, with prefix provided, a full IPv6 address
    """
    # http://tools.ietf.org/html/rfc4291#section-2.5.1
    eui64 = re.sub(r"[.:-]", "", mac).lower()
    eui64 = eui64[0:6] + "fffe" + eui64[6:]
    eui64 = hex(int(eui64[0:2], 16) | 2)[2:].zfill(2) + eui64[2:]

    if prefix is None:
        return ":".join(re.findall(r".{4}", eui64))
    else:
        try:
            net = ipaddress.ip_network(prefix, strict=False)
            euil = int("0x{}".format(eui64), 16)
            return "{}/{}".format(net[euil], net.prefixlen)
        except Exception:  # pylint: disable=broad-except
            return


def active_tcp():
    """
    Return a dict describing all active tcp connections as quickly as possible
    """
    ret = {}
    for statf in ["/proc/net/tcp", "/proc/net/tcp6"]:
        if not os.path.isfile(statf):
            continue
        with salt.utils.files.fopen(statf, "rb") as fp_:
            for line in fp_:
                line = salt.utils.stringutils.to_unicode(line)
                if line.strip().startswith("sl"):
                    continue
                iret = _parse_tcp_line(line)
                slot = next(iter(iret))
                if iret[slot]["state"] == 1:  # 1 is ESTABLISHED
                    del iret[slot]["state"]
                    ret[len(ret)] = iret[slot]
    return ret


def local_port_tcp(port):
    """
    Return a set of remote ip addrs attached to the specified local port
    """
    ret = _remotes_on(port, "local_port")
    return ret


def remote_port_tcp(port):
    """
    Return a set of ip addrs the current host is connected to on given port
    """
    ret = _remotes_on(port, "remote_port")
    return ret


def _remotes_on(port, which_end):
    """
    Return a set of ip addrs active tcp connections
    """
    port = int(port)

    ret = _netlink_tool_remote_on(port, which_end)
    if ret is not None:
        return ret

    ret = set()
    proc_available = False
    for statf in ["/proc/net/tcp", "/proc/net/tcp6"]:
        if not os.path.isfile(statf):
            continue
        proc_available = True
        with salt.utils.files.fopen(statf, "r") as fp_:
            for line in fp_:
                line = salt.utils.stringutils.to_unicode(line)
                if line.strip().startswith("sl"):
                    continue
                iret = _parse_tcp_line(line)
                slot = next(iter(iret))
                if (
                    iret[slot][which_end] == port and iret[slot]["state"] == 1
                ):  # 1 is ESTABLISHED
                    ret.add(iret[slot]["remote_addr"])

    if not proc_available:  # Fallback to use OS specific tools
        if salt.utils.platform.is_sunos():
            return _sunos_remotes_on(port, which_end)
        if salt.utils.platform.is_freebsd():
            return _freebsd_remotes_on(port, which_end)
        if salt.utils.platform.is_netbsd():
            return _netbsd_remotes_on(port, which_end)
        if salt.utils.platform.is_openbsd():
            return _openbsd_remotes_on(port, which_end)
        if salt.utils.platform.is_windows():
            return _windows_remotes_on(port, which_end)
        if salt.utils.platform.is_aix():
            return _aix_remotes_on(port, which_end)

        return _linux_remotes_on(port, which_end)

    return ret


def _parse_tcp_line(line):
    """
    Parse a single line from the contents of /proc/net/tcp or /proc/net/tcp6
    """
    ret = {}
    comps = line.strip().split()
    slot = comps[0].rstrip(":")
    ret[slot] = {}
    l_addr, l_port = comps[1].split(":")
    r_addr, r_port = comps[2].split(":")
    ret[slot]["local_addr"] = hex2ip(l_addr, True)
    ret[slot]["local_port"] = int(l_port, 16)
    ret[slot]["remote_addr"] = hex2ip(r_addr, True)
    ret[slot]["remote_port"] = int(r_port, 16)
    ret[slot]["state"] = int(comps[3], 16)
    return ret


def _netlink_tool_remote_on(port, which_end):
    """
    Returns set of IPv4/IPv6 host addresses of remote established connections
    on local or remote tcp port.

    Parses output of shell 'ss' to get connections

    [root@salt-master ~]# ss -ant
    State      Recv-Q Send-Q               Local Address:Port                 Peer Address:Port
    LISTEN     0      511                              *:80                              *:*
    LISTEN     0      128                              *:22                              *:*
    ESTAB      0      0                      127.0.0.1:56726                  127.0.0.1:4505
    ESTAB      0      0             [::ffff:127.0.0.1]:41323         [::ffff:127.0.0.1]:4505
    """
    remotes = set()
    valid = False
    tcp_end = "dst" if which_end == "remote_port" else "src"
    try:
        data = subprocess.check_output(
            ["ss", "-ant", tcp_end, ":{}".format(port)]
        )  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError:
        log.error("Failed ss")
        raise
    except OSError:  # not command "No such file or directory"
        return None

    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        if "Address:Port" in line:  # ss tools may not be valid
            valid = True
            continue
        elif "ESTAB" not in line:
            continue
        chunks = line.split()
        remote_host, remote_port = chunks[4].rsplit(":", 1)

        remotes.add(remote_host.strip("[]"))

    if valid is False:
        remotes = None
    return remotes


def _sunos_remotes_on(port, which_end):
    """
    SunOS specific helper function.
    Returns set of ipv4 host addresses of remote established connections
    on local or remote tcp port.

    Parses output of shell 'netstat' to get connections

    [root@salt-master ~]# netstat -f inet -n
    TCP: IPv4
       Local Address        Remote Address    Swind Send-Q Rwind Recv-Q    State
       -------------------- -------------------- ----- ------ ----- ------ -----------
       10.0.0.101.4505      10.0.0.1.45329       1064800      0 1055864      0 ESTABLISHED
       10.0.0.101.4505      10.0.0.100.50798     1064800      0 1055864      0 ESTABLISHED
    """
    remotes = set()
    try:
        data = subprocess.check_output(
            ["netstat", "-f", "inet", "-n"]
        )  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError:
        log.error("Failed netstat")
        raise

    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        if "ESTABLISHED" not in line:
            continue
        chunks = line.split()
        local_host, local_port = chunks[0].rsplit(".", 1)
        remote_host, remote_port = chunks[1].rsplit(".", 1)

        if which_end == "remote_port" and int(remote_port) != port:
            continue
        if which_end == "local_port" and int(local_port) != port:
            continue
        remotes.add(remote_host)
    return remotes


def _freebsd_remotes_on(port, which_end):
    """
    Returns set of ipv4 host addresses of remote established connections
    on local tcp port port.

    Parses output of shell 'sockstat' (FreeBSD)
    to get connections

    $ sudo sockstat -4
    USER    COMMAND     PID     FD  PROTO  LOCAL ADDRESS    FOREIGN ADDRESS
    root    python2.7   1456    29  tcp4   *:4505           *:*
    root    python2.7   1445    17  tcp4   *:4506           *:*
    root    python2.7   1294    14  tcp4   127.0.0.1:11813  127.0.0.1:4505
    root    python2.7   1294    41  tcp4   127.0.0.1:61115  127.0.0.1:4506

    $ sudo sockstat -4 -c -p 4506
    USER    COMMAND     PID     FD  PROTO  LOCAL ADDRESS    FOREIGN ADDRESS
    root    python2.7   1294    41  tcp4   127.0.0.1:61115  127.0.0.1:4506
    """

    port = int(port)
    remotes = set()

    try:
        cmd = salt.utils.args.shlex_split("sockstat -4 -c -p {}".format(port))
        data = subprocess.check_output(cmd)  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError as ex:
        log.error('Failed "sockstat" with returncode = %s', ex.returncode)
        raise

    lines = salt.utils.stringutils.to_str(data).split("\n")

    for line in lines:
        chunks = line.split()
        if not chunks:
            continue
        # ['root', 'python2.7', '1456', '37', 'tcp4',
        #  '127.0.0.1:4505-', '127.0.0.1:55703']
        # print chunks
        if "COMMAND" in chunks[1]:
            continue  # ignore header
        if len(chunks) &lt; 2:
            continue
        # sockstat -4 -c -p 4506 does this with high PIDs:
        # USER     COMMAND    PID   FD PROTO  LOCAL ADDRESS         FOREIGN ADDRESS
        # salt-master python2.781106 35 tcp4  192.168.12.34:4506    192.168.12.45:60143
        local = chunks[-2]
        remote = chunks[-1]
        lhost, lport = local.split(":")
        rhost, rport = remote.split(":")
        if which_end == "local" and int(lport) != port:  # ignore if local port not port
            continue
        if (
            which_end == "remote" and int(rport) != port
        ):  # ignore if remote port not port
            continue

        remotes.add(rhost)

    return remotes


def _netbsd_remotes_on(port, which_end):
    """
    Returns set of ipv4 host addresses of remote established connections
    on local tcp port port.

    Parses output of shell 'sockstat' (NetBSD)
    to get connections

    $ sudo sockstat -4 -n
    USER    COMMAND     PID     FD  PROTO  LOCAL ADDRESS    FOREIGN ADDRESS
    root    python2.7   1456    29  tcp    *.4505           *.*
    root    python2.7   1445    17  tcp    *.4506           *.*
    root    python2.7   1294    14  tcp    127.0.0.1.11813  127.0.0.1.4505
    root    python2.7   1294    41  tcp    127.0.0.1.61115  127.0.0.1.4506

    $ sudo sockstat -4 -c -n -p 4506
    USER    COMMAND     PID     FD  PROTO  LOCAL ADDRESS    FOREIGN ADDRESS
    root    python2.7   1294    41  tcp    127.0.0.1.61115  127.0.0.1.4506
    """

    port = int(port)
    remotes = set()

    try:
        cmd = salt.utils.args.shlex_split("sockstat -4 -c -n -p {}".format(port))
        data = subprocess.check_output(cmd)  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError as ex:
        log.error('Failed "sockstat" with returncode = %s', ex.returncode)
        raise

    lines = salt.utils.stringutils.to_str(data).split("\n")

    for line in lines:
        chunks = line.split()
        if not chunks:
            continue
        # ['root', 'python2.7', '1456', '37', 'tcp',
        #  '127.0.0.1.4505-', '127.0.0.1.55703']
        # print chunks
        if "COMMAND" in chunks[1]:
            continue  # ignore header
        if len(chunks) &lt; 2:
            continue
        local = chunks[5].split(".")
        lport = local.pop()
        lhost = ".".join(local)
        remote = chunks[6].split(".")
        rport = remote.pop()
        rhost = ".".join(remote)
        if which_end == "local" and int(lport) != port:  # ignore if local port not port
            continue
        if (
            which_end == "remote" and int(rport) != port
        ):  # ignore if remote port not port
            continue

        remotes.add(rhost)

    return remotes


def _openbsd_remotes_on(port, which_end):
    """
    OpenBSD specific helper function.
    Returns set of ipv4 host addresses of remote established connections
    on local or remote tcp port.

    Parses output of shell 'netstat' to get connections

    $ netstat -nf inet
    Active Internet connections
    Proto   Recv-Q Send-Q  Local Address          Foreign Address        (state)
    tcp          0      0  10.0.0.101.4505        10.0.0.1.45329         ESTABLISHED
    tcp          0      0  10.0.0.101.4505        10.0.0.100.50798       ESTABLISHED
    """
    remotes = set()
    try:
        data = subprocess.check_output(
            ["netstat", "-nf", "inet"]
        )  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError:
        log.error("Failed netstat")
        raise

    lines = data.split("\n")
    for line in lines:
        if "ESTABLISHED" not in line:
            continue
        chunks = line.split()
        local_host, local_port = chunks[3].rsplit(".", 1)
        remote_host, remote_port = chunks[4].rsplit(".", 1)

        if which_end == "remote_port" and int(remote_port) != port:
            continue
        if which_end == "local_port" and int(local_port) != port:
            continue
        remotes.add(remote_host)
    return remotes


def _windows_remotes_on(port, which_end):
    r"""
    Windows specific helper function.
    Returns set of ipv4 host addresses of remote established connections
    on local or remote tcp port.

    Parses output of shell 'netstat' to get connections

    C:\&gt;netstat -n

    Active Connections

       Proto  Local Address          Foreign Address        State
       TCP    10.2.33.17:3007        130.164.12.233:10123   ESTABLISHED
       TCP    10.2.33.17:3389        130.164.30.5:10378     ESTABLISHED
    """
    remotes = set()
    try:
        data = subprocess.check_output(
            ["netstat", "-n"]
        )  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError:
        log.error("Failed netstat")
        raise

    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        if "ESTABLISHED" not in line:
            continue
        chunks = line.split()
        local_host, local_port = chunks[1].rsplit(":", 1)
        remote_host, remote_port = chunks[2].rsplit(":", 1)
        if which_end == "remote_port" and int(remote_port) != port:
            continue
        if which_end == "local_port" and int(local_port) != port:
            continue
        remotes.add(remote_host)
    return remotes


def _linux_remotes_on(port, which_end):
    """
    Linux specific helper function.
    Returns set of ip host addresses of remote established connections
    on local tcp port port.

    Parses output of shell 'lsof'
    to get connections

    $ sudo lsof -iTCP:4505 -n
    COMMAND   PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
    Python   9971 root   35u  IPv4 0x18a8464a29ca329d      0t0  TCP *:4505 (LISTEN)
    Python   9971 root   37u  IPv4 0x18a8464a29b2b29d      0t0  TCP 127.0.0.1:4505-&gt;127.0.0.1:55703 (ESTABLISHED)
    Python  10152 root   22u  IPv4 0x18a8464a29c8cab5      0t0  TCP 127.0.0.1:55703-&gt;127.0.0.1:4505 (ESTABLISHED)
    Python  10153 root   22u  IPv4 0x18a8464a29c8cab5      0t0  TCP [fe80::249a]:4505-&gt;[fe80::150]:59367 (ESTABLISHED)

    """
    remotes = set()

    try:
        data = subprocess.check_output(
            [
                "lsof",
                "-iTCP:{:d}".format(port),
                "-n",
                "-P",
            ]  # pylint: disable=minimum-python-version
        )
    except subprocess.CalledProcessError as ex:
        if ex.returncode == 1:
            # Lsof return 1 if any error was detected, including the failure
            # to locate Internet addresses, and it is not an error in this case.
            log.warning('"lsof" returncode = 1, likely no active TCP sessions.')
            return remotes
        log.error('Failed "lsof" with returncode = %s', ex.returncode)
        raise

    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        chunks = line.split()
        if not chunks:
            continue
        # ['Python', '9971', 'root', '37u', 'IPv4', '0x18a8464a29b2b29d', '0t0',
        # 'TCP', '127.0.0.1:4505-&gt;127.0.0.1:55703', '(ESTABLISHED)']
        # print chunks
        if "COMMAND" in chunks[0]:
            continue  # ignore header
        if "ESTABLISHED" not in chunks[-1]:
            continue  # ignore if not ESTABLISHED
        # '127.0.0.1:4505-&gt;127.0.0.1:55703'
        local, remote = chunks[8].split("-&gt;")
        _, lport = local.rsplit(":", 1)
        rhost, rport = remote.rsplit(":", 1)
        if which_end == "remote_port" and int(rport) != port:
            continue
        if which_end == "local_port" and int(lport) != port:
            continue
        remotes.add(rhost.strip("[]"))

    return remotes


def _aix_remotes_on(port, which_end):
    """
    AIX specific helper function.
    Returns set of ipv4 host addresses of remote established connections
    on local or remote tcp port.

    Parses output of shell 'netstat' to get connections

    root@la68pp002_pub:/opt/salt/lib/python2.7/site-packages/salt/modules# netstat -f inet -n
    Active Internet connections
    Proto Recv-Q Send-Q  Local Address          Foreign Address        (state)
    tcp4       0      0  172.29.149.95.50093    209.41.78.13.4505      ESTABLISHED
    tcp4       0      0  127.0.0.1.9514         *.*                    LISTEN
    tcp4       0      0  127.0.0.1.9515         *.*                    LISTEN
    tcp4       0      0  127.0.0.1.199          127.0.0.1.32779        ESTABLISHED
    tcp4       0      0  127.0.0.1.32779        127.0.0.1.199          ESTABLISHED
    tcp4       0     40  172.29.149.95.22       172.29.96.83.41022     ESTABLISHED
    tcp4       0      0  172.29.149.95.22       172.29.96.83.41032     ESTABLISHED
    tcp4       0      0  127.0.0.1.32771        127.0.0.1.32775        ESTABLISHED
    tcp        0      0  127.0.0.1.32775        127.0.0.1.32771        ESTABLISHED
    tcp4       0      0  127.0.0.1.32771        127.0.0.1.32776        ESTABLISHED
    tcp        0      0  127.0.0.1.32776        127.0.0.1.32771        ESTABLISHED
    tcp4       0      0  127.0.0.1.32771        127.0.0.1.32777        ESTABLISHED
    tcp        0      0  127.0.0.1.32777        127.0.0.1.32771        ESTABLISHED
    tcp4       0      0  127.0.0.1.32771        127.0.0.1.32778        ESTABLISHED
    tcp        0      0  127.0.0.1.32778        127.0.0.1.32771        ESTABLISHED
    """
    remotes = set()
    try:
        data = subprocess.check_output(
            ["netstat", "-f", "inet", "-n"]
        )  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError:
        log.error("Failed netstat")
        raise

    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        if "ESTABLISHED" not in line:
            continue
        chunks = line.split()
        local_host, local_port = chunks[3].rsplit(".", 1)
        remote_host, remote_port = chunks[4].rsplit(".", 1)

        if which_end == "remote_port" and int(remote_port) != port:
            continue
        if which_end == "local_port" and int(local_port) != port:
            continue
        remotes.add(remote_host)
    return remotes


@jinja_filter("gen_mac")
def gen_mac(prefix="AC:DE:48"):
    """
    Generates a MAC address with the defined OUI prefix.

    Common prefixes:

     - ``00:16:3E`` -- Xen
     - ``00:18:51`` -- OpenVZ
     - ``00:50:56`` -- VMware (manually generated)
     - ``52:54:00`` -- QEMU/KVM
     - ``AC:DE:48`` -- PRIVATE

    References:

     - http://standards.ieee.org/develop/regauth/oui/oui.txt
     - https://www.wireshark.org/tools/oui-lookup.html
     - https://en.wikipedia.org/wiki/MAC_address
    """
    return "{}:{:02X}:{:02X}:{:02X}".format(
        prefix,
        random.randint(0, 0xFF),
        random.randint(0, 0xFF),
        random.randint(0, 0xFF),
    )


@jinja_filter("mac_str_to_bytes")
def mac_str_to_bytes(mac_str):
    """
    Convert a MAC address string into bytes. Works with or without separators:

    b1 = mac_str_to_bytes('08:00:27:13:69:77')
    b2 = mac_str_to_bytes('080027136977')
    assert b1 == b2
    assert isinstance(b1, bytes)
    """
    if len(mac_str) == 12:
        pass
    elif len(mac_str) == 17:
        sep = mac_str[2]
        mac_str = mac_str.replace(sep, "")
    else:
        raise ValueError("Invalid MAC address")
    chars = (int(mac_str[s : s + 2], 16) for s in range(0, 12, 2))
    return bytes(chars)


def refresh_dns():
    """
    issue #21397: force glibc to re-read resolv.conf
    """
    try:
        RES_INIT()
    except NameError:
        # Exception raised loading the library, thus RES_INIT is not defined
        pass


@jinja_filter("dns_check")
def dns_check(addr, port, safe=False, ipv6=None):
    """
    Return an ip address resolved by dns in a format usable in URLs (ipv6 in brackets).
    Obeys system preference for IPv4/6 address resolution - this can be overridden by
    the ipv6 flag. Tries to connect to the address before considering it useful. If no
    address can be reached, the first one resolved is used as a fallback.
    Does not exit on failure, raises an exception.
    """
    ip_addrs = []
    family = (
        socket.AF_INET6
        if ipv6
        else socket.AF_INET
        if ipv6 is False
        else socket.AF_UNSPEC
    )
    socket_error = False
    try:
        refresh_dns()
        addrinfo = socket.getaddrinfo(addr, port, family, socket.SOCK_STREAM)
        ip_addrs = _test_addrs(addrinfo, port)
    except TypeError:
        raise SaltSystemExit(
            code=42,
            msg=(
                "Attempt to resolve address '{}' failed. Invalid or unresolveable"
                " address".format(addr)
            ),
        )
    except OSError:
        socket_error = True

    # If ipv6 is set to True, attempt another lookup using the IPv4 family,
    # just in case we're attempting to lookup an IPv4 IP
    # as an IPv6 hostname.
    if socket_error and ipv6:
        try:
            refresh_dns()
            addrinfo = socket.getaddrinfo(
                addr, port, socket.AF_INET, socket.SOCK_STREAM
            )
            ip_addrs = _test_addrs(addrinfo, port)
        except TypeError:
            raise SaltSystemExit(
                code=42,
                msg=(
                    "Attempt to resolve address '{}' failed. Invalid or unresolveable"
                    " address".format(addr)
                ),
            )
        except OSError:
            error = True

    if not ip_addrs:
        err = "DNS lookup or connection check of '{}' failed.".format(addr)
        if safe:
            if salt.log.is_console_configured():
                # If logging is not configured it also means that either
                # the master or minion instance calling this hasn't even
                # started running
                log.error(err)
            raise SaltClientError()
        raise SaltSystemExit(code=42, msg=err)

    return salt.utils.zeromq.ip_bracket(ip_addrs[0])


def _test_addrs(addrinfo, port):
    """
    Attempt to connect to all addresses, return one if it succeeds.
    Otherwise, return all addrs.
    """
    ip_addrs = []
    # test for connectivity, short circuit on success
    for a in addrinfo:
        ip_family = a[0]
        ip_addr = a[4][0]
        if ip_addr in ip_addrs:
            continue
        ip_addrs.append(ip_addr)

        try:
            s = socket.socket(ip_family, socket.SOCK_STREAM)
            s.settimeout(2)
            s.connect((ip_addr, port))
            s.close()

            ip_addrs = [ip_addr]
            break
        except OSError:
            pass
    return ip_addrs


def parse_host_port(host_port):
    """
    Takes a string argument specifying host or host:port.

    Returns a (hostname, port) or (ip_address, port) tuple. If no port is given,
    the second (port) element of the returned tuple will be None.

    host:port argument, for example, is accepted in the forms of:
      - hostname
      - hostname:1234
      - hostname.domain.tld
      - hostname.domain.tld:5678
      - [1234::5]:5678
      - 1234::5
      - 10.11.12.13:4567
      - 10.11.12.13
    """
    host, port = None, None  # default

    _s_ = host_port[:]
    if _s_[0] == "[":
        if "]" in host_port:
            host, _s_ = _s_.lstrip("[").rsplit("]", 1)
            host = ipaddress.IPv6Address(host).compressed
            if _s_[0] == ":":
                port = int(_s_.lstrip(":"))
            else:
                if len(_s_) &gt; 1:
                    raise ValueError(
                        'found ambiguous "{}" port in "{}"'.format(_s_, host_port)
                    )
    else:
        if _s_.count(":") == 1:
            host, _hostport_separator_, port = _s_.partition(":")
            try:
                port = int(port)
            except ValueError as _e_:
                errmsg = 'host_port "{}" port value "{}" is not an integer.'.format(
                    host_port, port
                )
                log.error(errmsg)
                raise ValueError(errmsg)
        else:
            host = _s_
    try:
        if not isinstance(host, ipaddress._BaseAddress):
            host_ip = ipaddress.ip_address(host).compressed
            host = host_ip
    except ValueError:
        log.debug('"%s" Not an IP address? Assuming it is a hostname.', host)
        if host != sanitize_host(host):
            log.error('bad hostname: "%s"', host)
            raise ValueError('bad hostname: "{}"'.format(host))

    return host, port


@jinja_filter("filter_by_networks")
def filter_by_networks(values, networks):
    """
    Returns the list of IPs filtered by the network list.
    If the network list is an empty sequence, no IPs are returned.
    If the network list is None, all IPs are returned.

    {% set networks = ['192.168.0.0/24', 'fe80::/64'] %}
    {{ grains['ip_interfaces'] | filter_by_networks(networks) }}
    {{ grains['ipv6'] | filter_by_networks(networks) }}
    {{ grains['ipv4'] | filter_by_networks(networks) }}
    """

    _filter = lambda ips, networks: [
        ip for ip in ips for net in networks if ipaddress.ip_address(ip) in net
    ]

    if networks is not None:
        networks = [ipaddress.ip_network(network) for network in networks]
        if isinstance(values, Mapping):
            return {
                interface: _filter(values[interface], networks) for interface in values
            }
        elif isinstance(values, Sequence):
            return _filter(values, networks)
        else:
            raise ValueError("Do not know how to filter a {}".format(type(values)))
    else:
        return values
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerHTML.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
