<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for archive.py &amp; network_4.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for archive.py &amp; network_4.py
      </h3>
<h1 align="center">
        1.2%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>archive.py (1.8971848%)<th>network_4.py (0.97822654%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(7-24)<td><a href="#" name="0">(7-24)</a><td align="center"><font color="#ff0000">17</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(1367-1369)<td><a href="#" name="1">(168-173)</a><td align="center"><font color="#d20000">14</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>archive.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>import errno
import logging
import os
import re
import shlex
import stat
import string
import tarfile
from contextlib import closing
from urllib.parse import urlparse
import salt.utils.args
import salt.utils.files
import salt.utils.hashutils
import salt.utils.path
import salt.utils.platform
import salt.utils.url
from</b></font> salt.exceptions import CommandExecutionError, CommandNotFoundError
log = logging.getLogger(__name__)
def _path_is_abs(path):
    if path is None:
        return True
    try:
        return os.path.isabs(path)
    except AttributeError:
        return False
def _add_explanation(ret, source_hash_trigger, contents_missing):
    if source_hash_trigger:
        ret["comment"] += ", due to source_hash update"
    elif contents_missing:
        ret["comment"] += ", due to absence of one or more files/dirs"
def _gen_checksum(path):
    return {
        "hsum": salt.utils.hashutils.get_hash(path, form=__opts__["hash_type"]),
        "hash_type": __opts__["hash_type"],
    }
def _checksum_file_path(path):
    try:
        relpath = ".".join((os.path.relpath(path, __opts__["cachedir"]), "hash"))
        if re.match(r"..[/\\]", relpath):
            relpath = salt.utils.path.join(
                "local",
                os.path.splitdrive(path)[-1].lstrip("/\\"),
            )
    except ValueError as exc:
        if str(exc).startswith("path is on"):
            drive, path = os.path.splitdrive(path)
            relpath = salt.utils.path.join(
                "local",
                drive.rstrip(":"),
                path.lstrip("/\\"),
            )
        elif str(exc).startswith("Cannot mix UNC"):
            relpath = salt.utils.path.join("unc", path)
        else:
            raise
    ret = salt.utils.path.join(__opts__["cachedir"], "archive_hash", relpath)
    log.debug("Using checksum file %s for cached archive file %s", ret, path)
    return ret
def _update_checksum(path):
    checksum_file = _checksum_file_path(path)
    checksum_dir = os.path.dirname(checksum_file)
    if not os.path.isdir(checksum_dir):
        os.makedirs(checksum_dir)
    source_sum = _gen_checksum(path)
    hash_type = source_sum.get("hash_type")
    hsum = source_sum.get("hsum")
    if hash_type and hsum:
        lines = []
        try:
            try:
                with salt.utils.files.fopen(checksum_file, "r") as fp_:
                    for line in fp_:
                        try:
                            lines.append(line.rstrip("\n").split(":", 1))
                        except ValueError:
                            continue
            except OSError as exc:
                if exc.errno != errno.ENOENT:
                    raise
            with salt.utils.files.fopen(checksum_file, "w") as fp_:
                for line in lines:
                    if line[0] == hash_type:
                        line[1] = hsum
                    fp_.write("{}:{}\n".format(*line))
                if hash_type not in [x[0] for x in lines]:
                    fp_.write("{}:{}\n".format(hash_type, hsum))
        except OSError as exc:
            log.warning(
                "Failed to update checksum for %s: %s",
                path,
                exc.__str__(),
                exc_info=True,
            )
def _read_cached_checksum(path, form=None):
    if form is None:
        form = __opts__["hash_type"]
    checksum_file = _checksum_file_path(path)
    try:
        with salt.utils.files.fopen(checksum_file, "r") as fp_:
            for line in fp_:
                hash_type, hsum = line.rstrip("\n").split(":", 1)
                if hash_type == form:
                    break
            else:
                return None
    except (OSError, ValueError):
        return None
    else:
        return {"hash_type": hash_type, "hsum": hsum}
def _compare_checksum(cached, source_sum):
    cached_sum = _read_cached_checksum(
        cached, form=source_sum.get("hash_type", __opts__["hash_type"])
    )
    return source_sum == cached_sum
def _is_bsdtar():
    return "bsdtar" in __salt__["cmd.run"](["tar", "--version"], python_shell=False)
def _cleanup_destdir(name):
    try:
        os.rmdir(name)
    except OSError:
        pass
def extracted(
    name,
    source,
    source_hash=None,
    source_hash_name=None,
    source_hash_update=False,
    skip_files_list_verify=False,
    skip_verify=False,
    password=None,
    options=None,
    list_options=None,
    force=False,
    overwrite=False,
    clean=False,
    clean_parent=False,
    user=None,
    group=None,
    if_missing=None,
    trim_output=False,
    use_cmd_unzip=None,
    extract_perms=True,
    enforce_toplevel=True,
    enforce_ownership_on=None,
    archive_format=None,
    use_etag=False,
    **kwargs
):
    ret = {"name": name, "result": False, "changes": {}, "comment": ""}
    kwargs = salt.utils.args.clean_kwargs(**kwargs)
    if skip_files_list_verify and skip_verify:
        ret[
            "comment"
        ] = 'Only one of "skip_files_list_verify" and "skip_verify" can be set to True'
        return ret
    if "keep_source" in kwargs and "keep" in kwargs:
        ret.setdefault("warnings", []).append(
            "Both 'keep_source' and 'keep' were used. Since these both "
            "do the same thing, 'keep' was ignored."
        )
        keep_source = bool(kwargs.pop("keep_source"))
        kwargs.pop("keep")
    elif "keep_source" in kwargs:
        keep_source = bool(kwargs.pop("keep_source"))
    elif "keep" in kwargs:
        keep_source = bool(kwargs.pop("keep"))
    else:
        keep_source = True
    if not _path_is_abs(name):
        ret["comment"] = "{} is not an absolute path".format(name)
        return ret
    else:
        if not name:
            ret["comment"] = "Name of the directory path needs to be specified"
            return ret
        name = name.rstrip(os.sep)
        if os.path.isfile(name):
            ret["comment"] = "{} exists and is not a directory".format(name)
            return ret
        name += os.sep
    if not _path_is_abs(if_missing):
        ret["comment"] = "Value for 'if_missing' is not an absolute path"
        return ret
    if not _path_is_abs(enforce_ownership_on):
        ret["comment"] = "Value for 'enforce_ownership_on' is not an absolute path"
        return ret
    else:
        if enforce_ownership_on is not None:
            try:
                not_rel = os.path.relpath(enforce_ownership_on, name).startswith(
                    ".." + os.sep
                )
            except Exception:  # pylint: disable=broad-except
                not_rel = True
            if not_rel:
                ret[
                    "comment"
                ] = "Value for 'enforce_ownership_on' must be within {}".format(name)
                return ret
    if if_missing is not None and os.path.exists(if_missing):
        ret["result"] = True
        ret["comment"] = "Path {} exists".format(if_missing)
        return ret
    if user or group:
        if salt.utils.platform.is_windows():
            ret[
                "comment"
            ] = "User/group ownership cannot be enforced on Windows minions"
            return ret
        if user:
            uid = __salt__["file.user_to_uid"](user)
            if uid == "":
                ret["comment"] = "User {} does not exist".format(user)
                return ret
        else:
            uid = -1
        if group:
            gid = __salt__["file.group_to_gid"](group)
            if gid == "":
                ret["comment"] = "Group {} does not exist".format(group)
                return ret
        else:
            gid = -1
    else:
        uid = gid = -1
    if source_hash_update and not source_hash:
        ret.setdefault("warnings", []).append(
            "The 'source_hash_update' argument is ignored when "
            "'source_hash' is not also specified."
        )
    try:
        source_match = __salt__["file.source_list"](source, source_hash, __env__)[0]
    except CommandExecutionError as exc:
        ret["result"] = False
        ret["comment"] = exc.strerror
        return ret
    if not source_match:
        ret["result"] = False
        ret["comment"] = 'Invalid source "{}"'.format(source)
        return ret
    urlparsed_source = urlparse(source_match)
    urlparsed_scheme = urlparsed_source.scheme
    urlparsed_path = os.path.join(
        urlparsed_source.netloc, urlparsed_source.path
    ).rstrip(os.sep)
    if urlparsed_scheme and urlparsed_scheme.lower() in string.ascii_lowercase:
        urlparsed_path = ":".join([urlparsed_scheme, urlparsed_path])
        urlparsed_scheme = "file"
    source_hash_basename = urlparsed_path or urlparsed_source.netloc
    source_is_local = urlparsed_scheme in salt.utils.files.LOCAL_PROTOS
    if source_is_local:
        source_match = os.path.realpath(os.path.expanduser(urlparsed_path))
        if not os.path.isfile(source_match):
            ret["comment"] = "Source file '{}' does not exist".format(
                salt.utils.url.redact_http_basic_auth(source_match)
            )
            return ret
    valid_archive_formats = ("tar", "rar", "zip")
    if not archive_format:
        archive_format = salt.utils.files.guess_archive_type(source_hash_basename)
        if archive_format is None:
            ret["comment"] = (
                "Could not guess archive_format from the value of the "
                "'source' argument. Please set this archive_format to one "
                "of the following: {}".format(", ".join(valid_archive_formats))
            )
            return ret
    try:
        archive_format = archive_format.lower()
    except AttributeError:
        pass
    if archive_format not in valid_archive_formats:
        ret["comment"] = (
            "Invalid archive_format '{}'. Either set it to a supported "
            "value ({}) or remove this argument and the archive format will "
            "be guessed based on file extension.".format(
                archive_format,
                ", ".join(valid_archive_formats),
            )
        )
        return ret
    if options is not None and not isinstance(options, str):
        options = str(options)
    strip_components = None
    if options and archive_format == "tar":
        try:
            strip_components = int(
                re.search(
                    r"""--strip(?:-components)?(?:\s+|=)["']?(\d+)["']?""", options
                ).group(1)
            )
        except (AttributeError, ValueError):
            pass
    if archive_format == "zip":
        if options:
            if use_cmd_unzip is None:
                log.info(
                    "Presence of CLI options in archive.extracted state for "
                    "'%s' implies that use_cmd_unzip is set to True.",
                    name,
                )
                use_cmd_unzip = True
            elif not use_cmd_unzip:
                ret["comment"] = (
                    "'use_cmd_unzip' cannot be set to False if CLI options "
                    "are being specified (via the 'options' argument). "
                    "Either remove 'use_cmd_unzip', or set it to True."
                )
                return ret
            if use_cmd_unzip:
                if "archive.cmd_unzip" not in __salt__:
                    ret["comment"] = (
                        "archive.cmd_unzip function not available, unzip might "
                        "not be installed on minion"
                    )
                    return ret
        if password:
            if use_cmd_unzip is None:
                log.info(
                    "Presence of a password in archive.extracted state for "
                    "'%s' implies that use_cmd_unzip is set to False.",
                    name,
                )
                use_cmd_unzip = False
            elif use_cmd_unzip:
                ret.setdefault("warnings", []).append(
                    "Using a password in combination with setting "
                    "'use_cmd_unzip' to True is considered insecure. It is "
                    "recommended to remove the 'use_cmd_unzip' argument (or "
                    "set it to False) and allow Salt to extract the archive "
                    "using Python's built-in ZIP file support."
                )
    else:
        if password:
            ret[
                "comment"
            ] = "The 'password' argument is only supported for zip archives"
            return ret
    if archive_format == "rar":
        if "archive.unrar" not in __salt__:
            ret["comment"] = (
                "archive.unrar function not available, rar/unrar might "
                "not be installed on minion"
            )
            return ret
    supports_options = ("tar", "zip")
    if options and archive_format not in supports_options:
        ret["comment"] = (
            "The 'options' argument is only compatible with the following "
            "archive formats: {}".format(", ".join(supports_options))
        )
        return ret
    if trim_output:
        if trim_output is True:
            trim_output = 100
        elif not isinstance(trim_output, (bool, int)):
            try:
                trim_output = int(trim_output)
            except TypeError:
                ret[
                    "comment"
                ] = "Invalid value for trim_output, must be True/False or an integer"
                return ret
    if source_hash:
        try:
            source_sum = __salt__["file.get_source_sum"](
                source=source_match,
                source_hash=source_hash,
                source_hash_name=source_hash_name,
                saltenv=__env__,
            )
        except CommandExecutionError as exc:
            ret["comment"] = exc.strerror
            return ret
    else:
        source_sum = {}
    if skip_files_list_verify:
        if source_is_local:
            cached = source_match
        else:
            cached = __salt__["cp.is_cached"](source_match, saltenv=__env__)
        if cached:
            existing_cached_source_sum = _read_cached_checksum(cached)
            log.debug(
                'Existing source sum is: "%s". Expected source sum is "%s"',
                existing_cached_source_sum,
                source_sum,
            )
        else:
            parsed = urlparse(source_match)
            expected_cached_path = salt.utils.path.join(
                __opts__["cachedir"], "extrn_files", __env__, parsed.netloc, parsed.path
            )
            existing_cached_source_sum = _read_cached_checksum(expected_cached_path)
        if source_sum and existing_cached_source_sum:
            if existing_cached_source_sum["hsum"] == source_sum["hsum"]:
                ret["result"] = None if __opts__["test"] else True
                ret["comment"] = (
                    "Archive {} existing source sum is the same as the "
                    "expected one and skip_files_list_verify argument was set "
                    "to True. Extraction is not needed".format(
                        salt.utils.url.redact_http_basic_auth(source_match)
                    )
                )
                return ret
        else:
            log.debug("There is no cached source %s available on minion", source_match)
    if source_is_local:
        cached = source_match
    else:
        if __opts__["test"]:
            ret["result"] = None
            ret["comment"] = (
                "Archive {} would be cached (if necessary) and checked to "
                "discover if extraction is needed".format(
                    salt.utils.url.redact_http_basic_auth(source_match)
                )
            )
            return ret
        if "file.cached" not in __states__:
            ret[
                "comment"
            ] = "Unable to cache {}, file.cached state not available".format(
                salt.utils.url.redact_http_basic_auth(source_match)
            )
            return ret
        try:
            result = __states__["file.cached"](
                source_match,
                source_hash=source_hash,
                source_hash_name=source_hash_name,
                skip_verify=skip_verify,
                saltenv=__env__,
                use_etag=use_etag,
            )
        except Exception as exc:  # pylint: disable=broad-except
            msg = "Failed to cache {}: {}".format(
                salt.utils.url.redact_http_basic_auth(source_match), exc.__str__()
            )
            log.exception(msg)
            ret["comment"] = msg
            return ret
        else:
            log.debug("file.cached: %s", result)
        if result["result"]:
            cached = __salt__["cp.is_cached"](source_match, saltenv=__env__)
        else:
            log.debug(
                "failed to download %s",
                salt.utils.url.redact_http_basic_auth(source_match),
            )
            return result
    existing_cached_source_sum = _read_cached_checksum(cached)
    if source_hash and source_hash_update and not skip_verify:
        _update_checksum(cached)
    if archive_format == "zip" and not password:
        log.debug("Checking %s to see if it is password-protected", source_match)
        try:
            encrypted_zip = __salt__["archive.is_encrypted"](
                cached, clean=False, saltenv=__env__, use_etag=use_etag
            )
        except CommandExecutionError:
            pass
        else:
            if encrypted_zip:
                ret["comment"] = (
                    "Archive {} is password-protected, but no password was "
                    "specified. Please set the 'password' argument.".format(
                        salt.utils.url.redact_http_basic_auth(source_match)
                    )
                )
                return ret
    try:
        contents = __salt__["archive.list"](
            cached,
            archive_format=archive_format,
            options=list_options,
            strip_components=strip_components,
            clean=False,
            verbose=True,
            use_etag=use_etag,
        )
    except CommandExecutionError as exc:
        contents = None
        errors = []
        if not if_missing:
            errors.append("'if_missing' must be set")
        if not enforce_ownership_on and (user or group):
            errors.append(
                "Ownership cannot be managed without setting 'enforce_ownership_on'."
            )
        msg = exc.strerror
        if errors:
            msg += "\n\n"
            if archive_format == "tar":
                msg += (
                    "If the source archive is a tar archive compressed using "
                    "a compression type not natively supported by the tar "
                    "command, then setting the 'list_options' argument may "
                    "allow the contents to be listed. Otherwise, if Salt is "
                    "unable to determine the files/directories in the "
                    "archive, the following workaround(s) would need to be "
                    "used for this state to proceed"
                )
            else:
                msg += (
                    "The following workarounds must be used for this state to proceed"
                )
            msg += " (assuming the source file is a valid {} archive):\n".format(
                archive_format
            )
            for error in errors:
                msg += "\n- {}".format(error)
        ret["comment"] = msg
        return ret
    if (
        enforce_toplevel
        and contents is not None
        and (
            len(contents["top_level_dirs"]) &gt; 1 or len(contents["top_level_files"]) &gt; 0
        )
    ):
        ret["comment"] = (
            "Archive does not have a single top-level directory. "
            "To allow this archive to be extracted, set "
            "'enforce_toplevel' to False. To avoid a "
            "'{}-bomb' it may also be advisable to set a "
            "top-level directory by adding it to the 'name' "
            "value (for example, setting 'name' to {} "
            "instead of {}).".format(
                archive_format,
                os.path.join(name, "some_dir"),
                name,
            )
        )
        return ret
    if clean and clean_parent:
        ret["comment"] = "Only one of 'clean' and 'clean_parent' can be set to True"
        ret["result"] = False
        return ret
    extraction_needed = overwrite
    contents_missing = False
    try:
        if_missing_path_exists = os.path.exists(if_missing)
    except TypeError:
        if_missing_path_exists = False
    if not if_missing_path_exists:
        if contents is None:
            try:
                os.lstat(if_missing)
                extraction_needed = False
            except OSError as exc:
                if exc.errno == errno.ENOENT:
                    extraction_needed = True
                else:
                    ret["comment"] = (
                        "Failed to check for existence of if_missing path "
                        "({}): {}".format(if_missing, exc.__str__())
                    )
                    return ret
        else:
            incorrect_type = []
            for path_list, func in (
                (contents["dirs"], stat.S_ISDIR),
                (
                    contents["files"],
                    lambda x: not stat.S_ISLNK(x) and not stat.S_ISDIR(x),
                ),
                (contents["links"], stat.S_ISLNK),
            ):
                for path in path_list:
                    full_path = salt.utils.path.join(name, path)
                    try:
                        path_mode = os.lstat(full_path.rstrip(os.sep)).st_mode
                        if not func(path_mode):
                            incorrect_type.append(path)
                    except OSError as exc:
                        if exc.errno == errno.ENOENT:
                            extraction_needed = True
                            contents_missing = True
                        elif exc.errno != errno.ENOTDIR:
                            ret["comment"] = exc.__str__()
                            return ret
            if incorrect_type:
                incorrect_paths = "\n\n" + "\n".join(
                    ["- {}".format(x) for x in incorrect_type]
                )
                ret["comment"] = (
                    "The below paths (relative to {}) exist, but are the "
                    "incorrect type (file instead of directory, symlink "
                    "instead of file, etc.).".format(name)
                )
                if __opts__["test"] and clean and contents is not None:
                    ret["result"] = None
                    ret["comment"] += (
                        " Since the 'clean' option is enabled, the "
                        "destination paths would be cleared and the "
                        "archive would be extracted.{}".format(incorrect_paths)
                    )
                    return ret
                if __opts__["test"] and clean_parent and contents is not None:
                    ret["result"] = None
                    ret["comment"] += (
                        " Since the 'clean_parent' option is enabled, the "
                        "destination parent directory would be removed first "
                        "and then re-created and the archive would be "
                        "extracted"
                    )
                    return ret
                if not (clean and contents is not None):
                    if not force:
                        ret["comment"] += (
                            " To proceed with extraction, set 'force' to "
                            "True. Note that this will remove these paths "
                            "before extracting.{}".format(incorrect_paths)
                        )
                        return ret
                    else:
                        errors = []
                        for path in incorrect_type:
                            full_path = os.path.join(name, path)
                            try:
                                salt.utils.files.rm_rf(full_path.rstrip(os.sep))
                                ret["changes"].setdefault("removed", []).append(
                                    full_path
                                )
                                extraction_needed = True
                            except OSError as exc:
                                if exc.errno != errno.ENOENT:
                                    errors.append(exc.__str__())
                        if errors:
                            msg = (
                                "One or more paths existed by were the incorrect "
                                "type (i.e. file instead of directory or "
                                "vice-versa), but could not be removed. The "
                                "following errors were observed:\n"
                            )
                            for error in errors:
                                msg += "\n- {}".format(error)
                            ret["comment"] = msg
                            return ret
    if (
        not extraction_needed
        and source_hash_update
        and existing_cached_source_sum is not None
        and not _compare_checksum(cached, existing_cached_source_sum)
    ):
        extraction_needed = True
        source_hash_trigger = True
    else:
        source_hash_trigger = False
    created_destdir = False
    if extraction_needed:
        if source_is_local and source_hash and not skip_verify:
            ret["result"] = __salt__["file.check_hash"](
                source_match, source_sum["hsum"]
            )
            if not ret["result"]:
                ret["comment"] = "{} does not match the desired source_hash {}".format(
                    salt.utils.url.redact_http_basic_auth(source_match),
                    source_sum["hsum"],
                )
                return ret
        if __opts__["test"]:
            ret["result"] = None
            ret["comment"] = "Archive {} would be extracted to {}".format(
                salt.utils.url.redact_http_basic_auth(source_match), name
            )
            if clean and contents is not None:
                ret["comment"] += ", after cleaning destination path(s)"
            _add_explanation(ret, source_hash_trigger, contents_missing)
            return ret
        if clean_parent and contents is not None:
            errors = []
            log.debug("Removing directory %s due to clean_parent set to True", name)
            try:
                salt.utils.files.rm_rf(name.rstrip(os.sep))
                ret["changes"].setdefault(
                    "removed",
                    "Directory {} was removed prior to the extraction".format(name),
                )
            except OSError as exc:
                if exc.errno != errno.ENOENT:
                    errors.append(str(exc))
            if errors:
                msg = (
                    "Unable to remove the directory {}. The following "
                    "errors were observed:\n".format(name)
                )
                for error in errors:
                    msg += "\n- {}".format(error)
                ret["comment"] = msg
                return ret
        if clean and contents is not None:
            errors = []
            log.debug("Cleaning archive paths from within %s", name)
<a name="1"></a>            for path in contents["top_level_dirs"] + contents["top_level_files"]:
                full_path = os.path.join(name, path)
                try:
                    log<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.debug("Removing %s", full_path)
                    salt.utils.files.rm_rf(full_path.rstrip(os.sep))
                    ret["changes"].setdefault("removed", []).append(</b></font>full_path)
                except OSError as exc:
                    if exc.errno != errno.ENOENT:
                        errors.append(exc.__str__())
            if errors:
                msg = (
                    "One or more paths could not be cleaned. The following "
                    "errors were observed:\n"
                )
                for error in errors:
                    msg += "\n- {}".format(error)
                ret["comment"] = msg
                return ret
        if not os.path.isdir(name):
            __states__["file.directory"](name, user=user, makedirs=True)
            created_destdir = True
        log.debug("Extracting %s to %s", cached, name)
        try:
            if archive_format == "zip":
                if use_cmd_unzip:
                    try:
                        files = __salt__["archive.cmd_unzip"](
                            cached,
                            name,
                            options=options,
                            trim_output=trim_output,
                            password=password,
                            **kwargs
                        )
                    except (CommandExecutionError, CommandNotFoundError) as exc:
                        ret["comment"] = exc.strerror
                        return ret
                else:
                    files = __salt__["archive.unzip"](
                        cached,
                        name,
                        options=options,
                        trim_output=trim_output,
                        password=password,
                        extract_perms=extract_perms,
                        **kwargs
                    )
            elif archive_format == "rar":
                try:
                    files = __salt__["archive.unrar"](
                        cached, name, trim_output=trim_output, **kwargs
                    )
                except (CommandExecutionError, CommandNotFoundError) as exc:
                    ret["comment"] = exc.strerror
                    return ret
            else:
                if options is None:
                    try:
                        with closing(tarfile.open(cached, "r")) as tar:
                            tar.extractall(salt.utils.stringutils.to_str(name))
                            files = tar.getnames()
                            if trim_output:
                                files = files[:trim_output]
                    except tarfile.ReadError:
                        if salt.utils.path.which("xz"):
                            if (
                                __salt__["cmd.retcode"](
                                    ["xz", "-t", cached],
                                    python_shell=False,
                                    ignore_retcode=True,
                                )
                                == 0
                            ):
                                log.debug(
                                    "Tar file is XZ-compressed, attempting "
                                    "decompression and extraction using XZ Utils "
                                    "and the tar command"
                                )
                                cmd = "xz --decompress --stdout {0} | tar xvf -"
                                results = __salt__["cmd.run_all"](
                                    cmd.format(shlex.quote(cached)),
                                    cwd=name,
                                    python_shell=True,
                                )
                                if results["retcode"] != 0:
                                    if created_destdir:
                                        _cleanup_destdir(name)
                                    ret["result"] = False
                                    ret["changes"] = results
                                    return ret
                                if _is_bsdtar():
                                    files = results["stderr"]
                                else:
                                    files = results["stdout"]
                            else:
                                if created_destdir:
                                    _cleanup_destdir(name)
                                ret["result"] = False
                                ret["comment"] = (
                                    "Failed to read from tar archive using "
                                    "Python's native tar file support. If "
                                    "archive is compressed using something "
                                    "other than gzip or bzip2, the "
                                    "'options' argument may be required to "
                                    "pass the correct options to the tar "
                                    "command in order to extract the archive."
                                )
                                return ret
                        else:
                            if created_destdir:
                                _cleanup_destdir(name)
                            ret["result"] = False
                            ret["comment"] = (
                                "Failed to read from tar archive. If it is "
                                "XZ-compressed, install xz-utils to attempt "
                                "extraction."
                            )
                            return ret
                else:
                    if not salt.utils.path.which("tar"):
                        ret["comment"] = (
                            "tar command not available, it might not be "
                            "installed on minion"
                        )
                        return ret
                    tar_opts = [
                        x
                        for x in shlex.split(options)
                        if x not in ("v", "-v", "--verbose")
                    ]
                    tar_cmd = ["tar"]
                    tar_shortopts = "xv"
                    tar_longopts = []
                    for position, opt in enumerate(tar_opts):
                        if opt.startswith("-"):
                            tar_longopts.append(opt)
                        else:
                            if position &gt; 0:
                                tar_longopts.append(opt)
                            else:
                                append_opt = opt
                                append_opt = append_opt.replace("x", "")
                                append_opt = append_opt.replace("f", "")
                                tar_shortopts = tar_shortopts + append_opt
                    if __grains__["os"].lower() == "openbsd":
                        tar_shortopts = "-" + tar_shortopts
                    tar_cmd.append(tar_shortopts)
                    tar_cmd.extend(tar_longopts)
                    tar_cmd.extend(["-f", cached])
                    results = __salt__["cmd.run_all"](
                        tar_cmd, cwd=name, python_shell=False
                    )
                    if results["retcode"] != 0:
                        ret["result"] = False
                        ret["changes"] = results
                        return ret
                    if _is_bsdtar():
                        files = results["stderr"].splitlines()
                        if trim_output:
                            files = files[:trim_output]
                    else:
                        files = results["stdout"].splitlines()
                        if trim_output:
                            files = files[:trim_output]
                    if not files:
                        files = "no tar output so far"
        except CommandExecutionError as exc:
            ret["comment"] = exc.strerror
            return ret
    enforce_missing = []
    enforce_failed = []
    if user or group:
        if enforce_ownership_on:
            if os.path.isdir(enforce_ownership_on):
                enforce_dirs = [enforce_ownership_on]
                enforce_files = []
                enforce_links = []
            else:
                enforce_dirs = []
                enforce_files = [enforce_ownership_on]
                enforce_links = []
        else:
            if contents is not None:
                enforce_dirs = contents["top_level_dirs"]
                enforce_files = contents["top_level_files"]
                enforce_links = contents["top_level_links"]
        recurse = []
        if user:
            recurse.append("user")
        if group:
            recurse.append("group")
        recurse_str = ", ".join(recurse)
        owner_changes = {x: y for x, y in (("user", user), ("group", group)) if y}
        for dirname in enforce_dirs:
            full_path = os.path.join(name, dirname)
            if not os.path.isdir(full_path):
                if not __opts__["test"]:
                    enforce_missing.append(full_path)
            else:
                log.debug(
                    "Enforcing %s ownership on %s using a file.directory state%s",
                    recurse_str,
                    dirname,
                    " (dry-run only)" if __opts__["test"] else "",
                )
                dir_result = __states__["file.directory"](
                    full_path, user=user, group=group, recurse=recurse
                )
                log.debug("file.directory: %s", dir_result)
                if dir_result.get("changes"):
                    ret["changes"]["updated ownership"] = True
                try:
                    if not dir_result["result"]:
                        enforce_failed.append(full_path)
                except (KeyError, TypeError):
                    log.warning(
                        "Bad state return %s for file.directory state on %s",
                        dir_result,
                        dirname,
                    )
        for filename in enforce_files + enforce_links:
            full_path = os.path.join(name, filename)
            try:
                file_stat = os.lstat(full_path)
            except OSError as exc:
                if not __opts__["test"]:
                    if exc.errno == errno.ENOENT:
                        enforce_missing.append(full_path)
                    enforce_failed.append(full_path)
            else:
                if (uid != -1 and uid != file_stat.st_uid) or (
                    gid != -1 and gid != file_stat.st_gid
                ):
                    if __opts__["test"]:
                        ret["changes"]["updated ownership"] = True
                    else:
                        try:
                            os.lchown(full_path, uid, gid)
                            ret["changes"]["updated ownership"] = True
                        except OSError:
                            enforce_failed.append(filename)
    if extraction_needed:
        if len(files) &gt; 0:
            if created_destdir:
                ret["changes"]["directories_created"] = [name]
            ret["changes"]["extracted_files"] = files
            ret["comment"] = "{} extracted to {}".format(
                salt.utils.url.redact_http_basic_auth(source_match),
                name,
            )
            _add_explanation(ret, source_hash_trigger, contents_missing)
            ret["comment"] += ". Output was trimmed to {} number of lines".format(
                trim_output
            )
            ret["result"] = True
        else:
            ret["result"] = False
            ret["comment"] = "No files were extracted from {}".format(
                salt.utils.url.redact_http_basic_auth(source_match)
            )
    else:
        ret["result"] = True
        if if_missing_path_exists:
            ret["comment"] = "{} exists".format(if_missing)
        else:
            ret["comment"] = "All files in archive are already present"
        if __opts__["test"]:
            if ret["changes"].get("updated ownership"):
                ret["result"] = None
                ret[
                    "comment"
                ] += ". Ownership would be updated on one or more files/directories."
    if enforce_missing:
        if not if_missing:
            ret["result"] = False
        ret["comment"] += (
            "\n\nWhile trying to enforce user/group ownership, the following "
            "paths were missing:\n"
        )
        for item in enforce_missing:
            ret["comment"] += "\n- {}".format(item)
    if enforce_failed:
        ret["result"] = False
        ret["comment"] += (
            "\n\nWhile trying to enforce user/group ownership, Salt was "
            "unable to change ownership on the following paths:\n"
        )
        for item in enforce_failed:
            ret["comment"] += "\n- {}".format(item)
    if not source_is_local:
        if keep_source:
            log.debug("Keeping cached source file %s", cached)
        else:
            log.debug("Cleaning cached source file %s", cached)
            result = __states__["file.not_cached"](source_match, saltenv=__env__)
            if not result["result"]:
                ret.setdefault("warnings", []).append(result["comment"])
    return ret
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>network_4.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>import fnmatch
import itertools
import logging
import os
import platform
import random
import re
import socket
import subprocess
import types
from collections.abc import Mapping, Sequence
from string import ascii_letters, digits
import salt.utils.args
import salt.utils.files
import salt.utils.path
import salt.utils.platform
import</b></font> salt.utils.stringutils
import salt.utils.zeromq
from salt._compat import ipaddress
from salt.exceptions import SaltClientError, SaltSystemExit
from salt.utils.decorators.jinja import jinja_filter
from salt.utils.versions import LooseVersion
try:
    import salt.utils.win_network
    WIN_NETWORK_LOADED = True
except ImportError:
    WIN_NETWORK_LOADED = False
log = logging.getLogger(__name__)
try:
    import ctypes
    import ctypes.util
    LIBC = ctypes.cdll.LoadLibrary(ctypes.util.find_library("c"))
    RES_INIT = LIBC.__res_init
except (ImportError, OSError, AttributeError, TypeError):
    pass
class Interfaces:
    __slots__ = ("interfaces",)
    def __init__(self, interfaces=None):
        if interfaces is None:
            interfaces = {}
        self.interfaces = interfaces
    def __call__(self, *args, **kwargs):
        if not self.interfaces:
            self.interfaces = interfaces()
        return self.interfaces
    def clear(self):
        self.interfaces = {}
_get_interfaces = Interfaces()
_clear_interfaces = _get_interfaces.clear
def sanitize_host(host):
    RFC952_characters = ascii_letters + digits + ".-_"
    return "".join([c for c in host[0:255] if c in RFC952_characters])
def isportopen(host, port):
    if not 1 &lt;= int(port) &lt;= 65535:
        return False
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    out = sock.connect_ex((sanitize_host(host), int(port)))
    return out
def host_to_ips(host):
    ips = []
    try:
        for family, socktype, proto, canonname, sockaddr in socket.getaddrinfo(
            host, 0, socket.AF_UNSPEC, socket.SOCK_STREAM
        ):
            if family == socket.AF_INET:
                ip, port = sockaddr
            elif family == socket.AF_INET6:
                ip, port, flow_info, scope_id = sockaddr
            ips.append(ip)
        if not ips:
            ips = None
    except Exception:  # pylint: disable=broad-except
        ips = None
    return ips
def _generate_minion_id():
    class DistinctList(list):
        localhost_matchers = [
            r"localhost.*",
            r"ip6-.*",
            r"127[.]\d",
            r"0\.0\.0\.0",
            r"::1.*",
            r"ipv6-.*",
            r"fe00::.*",
            r"fe02::.*",
            r"1.0.0.*.ip6.arpa",
        ]
        def append(self, p_object):
            if p_object and p_object not in self and not self.filter(p_object):
                super().append(p_object)
            return self
        def extend(self, iterable):
            for obj in iterable:
                self.append(obj)
            return self
        def filter(self, element):
            "Returns True if element needs to be filtered"
            for rgx in self.localhost_matchers:
                if re.match(rgx, element):
                    return True
        def first(self):
            return self and self[0] or None
    hostname = socket.gethostname()
<a name="1"></a>
    hosts = (
        DistinctList()
        <font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.append(
            salt.utils.stringutils.to_unicode(
                socket.getfqdn(salt.utils.stringutils.to_bytes(hostname))
            )
        )
        .append(</b></font>platform.node())
        .append(hostname)
    )
    if not hosts:
        try:
            for a_nfo in socket.getaddrinfo(
                hosts.first() or "localhost",
                None,
                socket.AF_INET,
                socket.SOCK_RAW,
                socket.IPPROTO_IP,
                socket.AI_CANONNAME,
            ):
                if len(a_nfo) &gt; 3:
                    hosts.append(a_nfo[3])
        except socket.gaierror:
            log.warning(
                "Cannot resolve address %s info via socket: %s",
                hosts.first() or "localhost (N/A)",
                socket.gaierror,
            )
    for f_name in (
        "/etc/hostname",
        "/etc/nodename",
        "/etc/hosts",
        r"{win}\system32\drivers\etc\hosts".format(win=os.getenv("WINDIR")),
    ):
        try:
            with salt.utils.files.fopen(f_name) as f_hdl:
                for line in f_hdl:
                    line = salt.utils.stringutils.to_unicode(line)
                    hst = line.strip().split("#")[0].strip().split()
                    if hst:
                        if hst[0][:4] in ("127.", "::1") or len(hst) == 1:
                            hosts.extend(hst)
        except OSError:
            pass
    return hosts.extend(
        [addr for addr in ip_addrs() if not ipaddress.ip_address(addr).is_loopback]
    )
def generate_minion_id():
    try:
        ret = salt.utils.stringutils.to_unicode(_generate_minion_id().first())
    except TypeError:
        ret = None
    return ret or "localhost"
def get_socket(addr, type=socket.SOCK_STREAM, proto=0):
    version = ipaddress.ip_address(addr).version
    if version == 4:
        family = socket.AF_INET
    elif version == 6:
        family = socket.AF_INET6
    return socket.socket(family, type, proto)
def get_fqhostname():
    l = [socket.getfqdn()]
    try:
        addrinfo = socket.getaddrinfo(
            socket.gethostname(),
            0,
            socket.AF_UNSPEC,
            socket.SOCK_STREAM,
            socket.SOL_TCP,
            socket.AI_CANONNAME,
        )
        for info in addrinfo:
            if len(info) &gt;= 4 and info[3]:
                l = [info[3]]
    except socket.gaierror:
        pass
    return l and l[0] or None
def ip_to_host(ip):
    try:
        hostname, aliaslist, ipaddrlist = socket.gethostbyaddr(ip)
    except Exception as exc:  # pylint: disable=broad-except
        log.debug("salt.utils.network.ip_to_host(%r) failed: %s", ip, exc)
        hostname = None
    return hostname
def is_reachable_host(entity_name):
    try:
        assert type(socket.getaddrinfo(entity_name, 0, 0, 0, 0)) == list
        ret = True
    except socket.gaierror:
        ret = False
    return ret
def is_ip(ip_addr):
    return is_ipv4(ip_addr) or is_ipv6(ip_addr)
def is_ipv4(ip_addr):
    try:
        return ipaddress.ip_address(ip_addr).version == 4
    except ValueError:
        return False
def is_ipv6(ip_addr):
    try:
        return ipaddress.ip_address(ip_addr).version == 6
    except ValueError:
        return False
def is_subnet(cidr):
    return is_ipv4_subnet(cidr) or is_ipv6_subnet(cidr)
def is_ipv4_subnet(cidr):
    try:
        return "/" in cidr and bool(ipaddress.IPv4Network(cidr))
    except Exception:  # pylint: disable=broad-except
        return False
def is_ipv6_subnet(cidr):
    try:
        return "/" in cidr and bool(ipaddress.IPv6Network(cidr))
    except Exception:  # pylint: disable=broad-except
        return False
@jinja_filter("is_ip")
def is_ip_filter(ip_addr, options=None):
    return is_ipv4_filter(ip_addr, options=options) or is_ipv6_filter(
        ip_addr, options=options
    )
def _ip_options_global(ip_obj, version):
    return not ip_obj.is_private
def _ip_options_multicast(ip_obj, version):
    return ip_obj.is_multicast
def _ip_options_loopback(ip_obj, version):
    return ip_obj.is_loopback
def _ip_options_link_local(ip_obj, version):
    return ip_obj.is_link_local
def _ip_options_private(ip_obj, version):
    return ip_obj.is_private
def _ip_options_reserved(ip_obj, version):
    return ip_obj.is_reserved
def _ip_options_site_local(ip_obj, version):
    if version == 6:
        return ip_obj.is_site_local
    return False
def _ip_options_unspecified(ip_obj, version):
    return ip_obj.is_unspecified
def _ip_options(ip_obj, version, options=None):
    options_fun_map = {
        "global": _ip_options_global,
        "link-local": _ip_options_link_local,
        "linklocal": _ip_options_link_local,
        "ll": _ip_options_link_local,
        "link_local": _ip_options_link_local,
        "loopback": _ip_options_loopback,
        "lo": _ip_options_loopback,
        "multicast": _ip_options_multicast,
        "private": _ip_options_private,
        "public": _ip_options_global,
        "reserved": _ip_options_reserved,
        "site-local": _ip_options_site_local,
        "sl": _ip_options_site_local,
        "site_local": _ip_options_site_local,
        "unspecified": _ip_options_unspecified,
    }
    if not options:
        return str(ip_obj)  # IP version already checked
    options_list = [option.strip() for option in options.split(",")]
    for option, fun in options_fun_map.items():
        if option in options_list:
            fun_res = fun(ip_obj, version)
            if not fun_res:
                return None
    return str(ip_obj)
def _is_ipv(ip_addr, version, options=None):
    if not version:
        version = 4
    if version not in (4, 6):
        return None
    try:
        ip_obj = ipaddress.ip_address(ip_addr)
    except ValueError:
        try:
            ip_obj = ipaddress.ip_interface(ip_addr)
        except ValueError:
            return None
    if not ip_obj.version == version:
        return None
    return _ip_options(ip_obj, version, options=options)
@jinja_filter("is_ipv4")
def is_ipv4_filter(ip_addr, options=None):
    _is_ipv4 = _is_ipv(ip_addr, 4, options=options)
    return isinstance(_is_ipv4, str)
@jinja_filter("is_ipv6")
def is_ipv6_filter(ip_addr, options=None):
    _is_ipv6 = _is_ipv(ip_addr, 6, options=options)
    return isinstance(_is_ipv6, str)
def _ipv_filter(value, version, options=None):
    if version not in (4, 6):
        return
    if isinstance(value, (str, bytes)):
        return _is_ipv(
            value, version, options=options
        )  # calls is_ipv4 or is_ipv6 for `value`
    elif isinstance(value, (list, tuple, types.GeneratorType)):
        return [
            _is_ipv(addr, version, options=options)
            for addr in value
            if _is_ipv(addr, version, options=options) is not None
        ]
    return None
@jinja_filter("ipv4")
def ipv4(value, options=None):
    return _ipv_filter(value, 4, options=options)
@jinja_filter("ipv6")
def ipv6(value, options=None):
    return _ipv_filter(value, 6, options=options)
@jinja_filter("ipaddr")
def ipaddr(value, options=None):
    ipv4_obj = ipv4(value, options=options)
    ipv6_obj = ipv6(value, options=options)
    if ipv4_obj is None or ipv6_obj is None:
        return ipv4_obj or ipv6_obj  # one of them
    else:
        return ipv4_obj + ipv6_obj  # extend lists
def _filter_ipaddr(value, options, version=None):
    ipaddr_filter_out = None
    if version:
        if version == 4:
            ipaddr_filter_out = ipv4(value, options)
        elif version == 6:
            ipaddr_filter_out = ipv6(value, options)
    else:
        ipaddr_filter_out = ipaddr(value, options)
    if not ipaddr_filter_out:
        return
    if not isinstance(ipaddr_filter_out, (list, tuple, types.GeneratorType)):
        ipaddr_filter_out = [ipaddr_filter_out]
    return ipaddr_filter_out
@jinja_filter("ip_host")
def ip_host(value, options=None, version=None):
    ipaddr_filter_out = _filter_ipaddr(value, options=options, version=version)
    if not ipaddr_filter_out:
        return
    if not isinstance(value, (list, tuple, types.GeneratorType)):
        return str(ipaddress.ip_interface(ipaddr_filter_out[0]))
    return [str(ipaddress.ip_interface(ip_a)) for ip_a in ipaddr_filter_out]
def _network_hosts(ip_addr_entry):
    return [
        str(host) for host in ipaddress.ip_network(ip_addr_entry, strict=False).hosts()
    ]
@jinja_filter("network_hosts")
def network_hosts(value, options=None, version=None):
    ipaddr_filter_out = _filter_ipaddr(value, options=options, version=version)
    if not ipaddr_filter_out:
        return
    if not isinstance(value, (list, tuple, types.GeneratorType)):
        return _network_hosts(ipaddr_filter_out[0])
    return [_network_hosts(ip_a) for ip_a in ipaddr_filter_out]
def _network_size(ip_addr_entry):
    return ipaddress.ip_network(ip_addr_entry, strict=False).num_addresses
@jinja_filter("network_size")
def network_size(value, options=None, version=None):
    ipaddr_filter_out = _filter_ipaddr(value, options=options, version=version)
    if not ipaddr_filter_out:
        return
    if not isinstance(value, (list, tuple, types.GeneratorType)):
        return _network_size(ipaddr_filter_out[0])
    return [_network_size(ip_a) for ip_a in ipaddr_filter_out]
def natural_ipv4_netmask(ip_addr, fmt="prefixlen"):
    bits = _ipv4_to_bits(ip_addr)
    if bits.startswith("11"):
        mask = "24"
    elif bits.startswith("1"):
        mask = "16"
    else:
        mask = "8"
    if fmt == "netmask":
        return cidr_to_ipv4_netmask(mask)
    else:
        return "/" + mask
def rpad_ipv4_network(ip_addr):
    return ".".join(itertools.islice(itertools.chain(ip_addr.split("."), "0000"), 0, 4))
def cidr_to_ipv4_netmask(cidr_bits):
    try:
        cidr_bits = int(cidr_bits)
        if not 1 &lt;= cidr_bits &lt;= 32:
            return ""
    except ValueError:
        return ""
    netmask = ""
    for idx in range(4):
        if idx:
            netmask += "."
        if cidr_bits &gt;= 8:
            netmask += "255"
            cidr_bits -= 8
        else:
            netmask += "{:d}".format(256 - (2 ** (8 - cidr_bits)))
            cidr_bits = 0
    return netmask
def _number_of_set_bits_to_ipv4_netmask(set_bits):
    return cidr_to_ipv4_netmask(_number_of_set_bits(set_bits))
def _number_of_set_bits(x):
    x -= (x &gt;&gt; 1) &amp; 0x55555555
    x = ((x &gt;&gt; 2) &amp; 0x33333333) + (x &amp; 0x33333333)
    x = ((x &gt;&gt; 4) + x) &amp; 0x0F0F0F0F
    x += x &gt;&gt; 8
    x += x &gt;&gt; 16
    return x &amp; 0x0000003F
def _interfaces_ip(out):
    ret = dict()
    def parse_network(value, cols):
        brd = None
        scope = None
        if "/" in value:  # we have a CIDR in this address
            ip, cidr = value.split("/")
        else:
            ip = value
            cidr = 32
        if type_ == "inet":
            mask = cidr_to_ipv4_netmask(int(cidr))
            if "brd" in cols:
                brd = cols[cols.index("brd") + 1]
        elif type_ == "inet6":
            mask = cidr
            if "scope" in cols:
                scope = cols[cols.index("scope") + 1]
        return (ip, mask, brd, scope)
    groups = re.compile("\r?\n\\d").split(out)
    for group in groups:
        iface = None
        data = dict()
        for line in group.splitlines():
            if " " not in line:
                continue
            match = re.match(r"^\d*:\s+([\w.\-]+)(?:@)?([\w.\-]+)?:\s+&lt;(.+)&gt;", line)
            if match:
                iface, parent, attrs = match.groups()
                if "UP" in attrs.split(","):
                    data["up"] = True
                else:
                    data["up"] = False
                if parent:
                    data["parent"] = parent
                continue
            cols = line.split()
            if len(cols) &gt;= 2:
                type_, value = tuple(cols[0:2])
                iflabel = cols[-1:][0]
                if type_ in ("inet", "inet6"):
                    ipaddr, netmask, broadcast, scope = parse_network(value, cols)
                    addr_obj = dict()
                    if "secondary" not in cols:
                        if type_ == "inet":
                            if "inet" not in data:
                                data["inet"] = list()
                            addr_obj["address"] = ipaddr
                            addr_obj["netmask"] = netmask
                            addr_obj["broadcast"] = broadcast
                            addr_obj["label"] = iflabel
                            data["inet"].append(addr_obj)
                        elif type_ == "inet6":
                            if "inet6" not in data:
                                data["inet6"] = list()
                            addr_obj["address"] = ipaddr
                            addr_obj["prefixlen"] = netmask
                            addr_obj["scope"] = scope
                            data["inet6"].append(addr_obj)
                    else:
                        if type_ == "inet":
                            if "secondary" not in data:
                                data["secondary"] = list()
                            addr_obj["type"] = type_
                            addr_obj["address"] = ipaddr
                            addr_obj["netmask"] = netmask
                            addr_obj["broadcast"] = broadcast
                            addr_obj["label"] = iflabel
                            data["secondary"].append(addr_obj)
                        elif type_ == "inet6":
                            if "secondary" not in data:
                                data["secondary"] = list()
                            addr_obj["type"] = type_
                            addr_obj["address"] = ipaddr
                            addr_obj["prefixlen"] = netmask
                            addr_obj["scope"] = scope
                            data["secondary"].append(addr_obj)
                elif type_.startswith("link"):
                    data["hwaddr"] = value
        if iface:
            ret[iface] = data
            del iface, data
    return ret
def _interfaces_ifconfig(out):
    ret = dict()
    piface = re.compile(r"^([^\s:]+)")
    pmac = re.compile(".*?(?:HWaddr|ether|address:|lladdr) ([0-9a-fA-F:]+)")
    if salt.utils.platform.is_sunos():
        pip = re.compile(r".*?(?:inet\s+)([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)(.*)")
        pip6 = re.compile(".*?(?:inet6 )([0-9a-fA-F:]+)")
        pmask6 = re.compile(r".*?(?:inet6 [0-9a-fA-F:]+/(\d+)).*")
    else:
        pip = re.compile(r".*?(?:inet addr:|inet [^\d]*)(.*?)\s")
        pip6 = re.compile(".*?(?:inet6 addr: (.*?)/|inet6 )([0-9a-fA-F:]+)")
        pmask6 = re.compile(
            r".*?(?:inet6 addr: [0-9a-fA-F:]+/(\d+)|prefixlen (\d+))(?:"
            r" Scope:([a-zA-Z]+)| scopeid (0x[0-9a-fA-F]))?"
        )
    pmask = re.compile(r".*?(?:Mask:|netmask )(?:((?:0x)?[0-9a-fA-F]{8})|([\d\.]+))")
    pupdown = re.compile("UP")
    pbcast = re.compile(r".*?(?:Bcast:|broadcast )([\d\.]+)")
    groups = re.compile("\r?\n(?=\\S)").split(out)
    for group in groups:
        data = dict()
        iface = ""
        updown = False
        for line in group.splitlines():
            miface = piface.match(line)
            mmac = pmac.match(line)
            mip = pip.match(line)
            mip6 = pip6.match(line)
            mupdown = pupdown.search(line)
            if miface:
                iface = miface.group(1)
            if mmac:
                data["hwaddr"] = mmac.group(1)
                if salt.utils.platform.is_sunos():
                    expand_mac = []
                    for chunk in data["hwaddr"].split(":"):
                        expand_mac.append(
                            "0{}".format(chunk)
                            if len(chunk) &lt; 2
                            else "{}".format(chunk)
                        )
                    data["hwaddr"] = ":".join(expand_mac)
            if mip:
                if "inet" not in data:
                    data["inet"] = list()
                addr_obj = dict()
                addr_obj["address"] = mip.group(1)
                mmask = pmask.match(line)
                if mmask:
                    if mmask.group(1):
                        mmask = _number_of_set_bits_to_ipv4_netmask(
                            int(mmask.group(1), 16)
                        )
                    else:
                        mmask = mmask.group(2)
                    addr_obj["netmask"] = mmask
                mbcast = pbcast.match(line)
                if mbcast:
                    addr_obj["broadcast"] = mbcast.group(1)
                data["inet"].append(addr_obj)
            if mupdown:
                updown = True
            if mip6:
                if "inet6" not in data:
                    data["inet6"] = list()
                addr_obj = dict()
                addr_obj["address"] = mip6.group(1) or mip6.group(2)
                mmask6 = pmask6.match(line)
                if mmask6:
                    addr_obj["prefixlen"] = mmask6.group(1) or mmask6.group(2)
                    if not salt.utils.platform.is_sunos():
                        ipv6scope = mmask6.group(3) or mmask6.group(4)
                        addr_obj["scope"] = (
                            ipv6scope.lower() if ipv6scope is not None else ipv6scope
                        )
                if (
                    not salt.utils.platform.is_sunos()
                    or addr_obj["address"] != "::"
                    and addr_obj["prefixlen"] != 0
                ):
                    data["inet6"].append(addr_obj)
        data["up"] = updown
        if iface in ret:
            ret[iface] = dict(list(data.items()) + list(ret[iface].items()))
            if "inet" in data:
                ret[iface]["inet"].extend(
                    x for x in data["inet"] if x not in ret[iface]["inet"]
                )
            if "inet6" in data:
                ret[iface]["inet6"].extend(
                    x for x in data["inet6"] if x not in ret[iface]["inet6"]
                )
        else:
            ret[iface] = data
        del data
    return ret
def linux_interfaces():
    ifaces = dict()
    ip_path = salt.utils.path.which("ip")
    ifconfig_path = None if ip_path else salt.utils.path.which("ifconfig")
    if ip_path:
        cmd1 = subprocess.Popen(
            [ip_path, "link", "show"],
            close_fds=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
        ).communicate()[0]
        cmd2 = subprocess.Popen(
            [ip_path, "addr", "show"],
            close_fds=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
        ).communicate()[0]
        ifaces = _interfaces_ip(
            "{}\n{}".format(
                salt.utils.stringutils.to_str(cmd1), salt.utils.stringutils.to_str(cmd2)
            )
        )
    elif ifconfig_path:
        cmd = subprocess.Popen(
            [ifconfig_path, "-a"],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
        ).communicate()[0]
        ifaces = _interfaces_ifconfig(salt.utils.stringutils.to_str(cmd))
    return ifaces
def _netbsd_interfaces_ifconfig(out):
    ret = dict()
    piface = re.compile(r"^([^\s:]+)")
    pmac = re.compile(".*?address: ([0-9a-f:]+)")
    pip = re.compile(r".*?inet [^\d]*(.*?)/([\d]*)\s")
    pip6 = re.compile(r".*?inet6 ([0-9a-f:]+)%([a-zA-Z0-9]*)/([\d]*)\s")
    pupdown = re.compile("UP")
    pbcast = re.compile(r".*?broadcast ([\d\.]+)")
    groups = re.compile("\r?\n(?=\\S)").split(out)
    for group in groups:
        data = dict()
        iface = ""
        updown = False
        for line in group.splitlines():
            miface = piface.match(line)
            mmac = pmac.match(line)
            mip = pip.match(line)
            mip6 = pip6.match(line)
            mupdown = pupdown.search(line)
            if miface:
                iface = miface.group(1)
            if mmac:
                data["hwaddr"] = mmac.group(1)
            if mip:
                if "inet" not in data:
                    data["inet"] = list()
                addr_obj = dict()
                addr_obj["address"] = mip.group(1)
                mmask = mip.group(2)
                if mip.group(2):
                    addr_obj["netmask"] = cidr_to_ipv4_netmask(mip.group(2))
                mbcast = pbcast.match(line)
                if mbcast:
                    addr_obj["broadcast"] = mbcast.group(1)
                data["inet"].append(addr_obj)
            if mupdown:
                updown = True
            if mip6:
                if "inet6" not in data:
                    data["inet6"] = list()
                addr_obj = dict()
                addr_obj["address"] = mip6.group(1)
                mmask6 = mip6.group(3)
                addr_obj["scope"] = mip6.group(2)
                addr_obj["prefixlen"] = mip6.group(3)
                data["inet6"].append(addr_obj)
        data["up"] = updown
        ret[iface] = data
        del data
    return ret
def _junos_interfaces_ifconfig(out):
    ret = dict()
    piface = re.compile(r"^([^\s:]+)")
    pmac = re.compile("curr media .*? ([0-9a-f:]+)")
    pip = re.compile(
        r".*?inet\s*(primary)*\s+mtu"
        r" (\d+)\s+local=[^\d]*(.*?)\s+dest=[^\d]*(.*?)\/([\d]*)\s+bcast=((?:[0-9]{1,3}\.){3}[0-9]{1,3})"
    )
    pip6 = re.compile(
        r".*?inet6 mtu [^\d]+\s+local=([0-9a-f:]+)%([a-zA-Z0-9]*)/([\d]*)\s"
    )
    pupdown = re.compile("UP")
    pbcast = re.compile(r".*?broadcast ([\d\.]+)")
    groups = re.compile("\r?\n(?=\\S)").split(out)
    for group in groups:
        data = dict()
        iface = ""
        updown = False
        primary = False
        for line in group.splitlines():
            miface = piface.match(line)
            mmac = pmac.match(line)
            mip = pip.match(line)
            mip6 = pip6.match(line)
            mupdown = pupdown.search(line)
            if miface:
                iface = miface.group(1)
            if mmac:
                data["hwaddr"] = mmac.group(1)
            if mip:
                if "primary" in data:
                    primary = True
                if "inet" not in data:
                    data["inet"] = list()
                if mip.group(2):
                    data["mtu"] = int(mip.group(2))
                addr_obj = dict()
                addr_obj["address"] = mip.group(3)
                mmask = mip.group(5)
                if mip.group(5):
                    addr_obj["netmask"] = cidr_to_ipv4_netmask(mip.group(5))
                mbcast = pbcast.match(line)
                if mbcast:
                    addr_obj["broadcast"] = mbcast.group(1)
                data["inet"].append(addr_obj)
            if mupdown:
                updown = True
            if mip6:
                if "inet6" not in data:
                    data["inet6"] = list()
                addr_obj = dict()
                addr_obj["address"] = mip6.group(1)
                mmask6 = mip6.group(3)
                addr_obj["scope"] = mip6.group(2)
                addr_obj["prefixlen"] = mip6.group(3)
                data["inet6"].append(addr_obj)
        data["up"] = updown
        ret[iface] = data
        del data
    return ret
def junos_interfaces():
    ifconfig_path = salt.utils.path.which("ifconfig")
    cmd = subprocess.Popen(
        [ifconfig_path, "-a"],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
    ).communicate()[0]
    return _junos_interfaces_ifconfig(salt.utils.stringutils.to_str(cmd))
def netbsd_interfaces():
    if LooseVersion(os.uname()[2]) &lt; LooseVersion("8.0"):
        return linux_interfaces()
    ifconfig_path = salt.utils.path.which("ifconfig")
    cmd = subprocess.Popen(
        [ifconfig_path, "-a"],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
    ).communicate()[0]
    return _netbsd_interfaces_ifconfig(salt.utils.stringutils.to_str(cmd))
def _interfaces_ipconfig(out):
    ifaces = dict()
    iface = None
    addr = None
    adapter_iface_regex = re.compile(r"adapter (\S.+):$")
    for line in out.splitlines():
        if not line:
            continue
        if line.startswith("Ethernet"):
            iface = ifaces[adapter_iface_regex.search(line).group(1)]
            iface["up"] = True
            addr = {}
            continue
        if iface:
            key, val = line.split(",", 1)
            key = key.strip(" .")
            val = val.strip()
            if addr and key == "Subnet Mask":
                addr["netmask"] = val
            elif key in ("IP Address", "IPv4 Address"):
                if "inet" not in iface:
                    iface["inet"] = list()
                addr = {
                    "address": val.rstrip("(Preferred)"),
                    "netmask": None,
                    "broadcast": None,
                }  # TODO find the broadcast
                iface["inet"].append(addr)
            elif "IPv6 Address" in key:
                if "inet6" not in iface:
                    iface["inet"] = list()
                addr = {"address": val.rstrip("(Preferred)"), "prefixlen": None}
                iface["inet6"].append(addr)
            elif key == "Physical Address":
                iface["hwaddr"] = val
            elif key == "Media State":
                iface["up"] = val != "Media disconnected"
def win_interfaces():
    if WIN_NETWORK_LOADED is False:
        import salt.utils.win_network as _
    return salt.utils.win_network.get_interface_info()
def interfaces():
    if salt.utils.platform.is_windows():
        return win_interfaces()
    elif salt.utils.platform.is_junos():
        return junos_interfaces()
    elif salt.utils.platform.is_netbsd():
        return netbsd_interfaces()
    else:
        return linux_interfaces()
def get_net_start(ipaddr, netmask):
    net = ipaddress.ip_network("{}/{}".format(ipaddr, netmask), strict=False)
    return str(net.network_address)
def get_net_size(mask):
    binary_str = ""
    for octet in mask.split("."):
        binary_str += bin(int(octet))[2:].zfill(8)
    return len(binary_str.rstrip("0"))
def calc_net(ipaddr, netmask=None):
    if netmask is not None:
        ipaddr = "{}/{}".format(ipaddr, netmask)
    return str(ipaddress.ip_network(ipaddr, strict=False))
def _ipv4_to_bits(ipaddr):
    return "".join([bin(int(x))[2:].rjust(8, "0") for x in ipaddr.split(".")])
def _get_iface_info(iface):
    iface_info = interfaces()
    if iface in iface_info.keys():
        return iface_info, False
    else:
        error_msg = 'Interface "{}" not in available interfaces: "{}"'.format(
            iface, '", "'.join(iface_info.keys())
        )
        log.error(error_msg)
        return None, error_msg
def _hw_addr_aix(iface):
    cmd = subprocess.Popen(
        ["grep", "Hardware Address"],
        stdin=subprocess.Popen(
            ["entstat", "-d", iface],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
        ).stdout,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
    ).communicate()[0]
    if cmd:
        comps = cmd.split(" ")
        if len(comps) == 3:
            mac_addr = comps[2].strip("'").strip()
            return mac_addr
    error_msg = 'Interface "{}" either not available or does not contain a hardware address'.format(
        iface
    )
    log.error(error_msg)
    return error_msg
def hw_addr(iface):
    if salt.utils.platform.is_aix():
        return _hw_addr_aix
    iface_info, error = _get_iface_info(iface)
    if error is False:
        return iface_info.get(iface, {}).get("hwaddr", "")
    else:
        return error
def interface(iface):
    iface_info, error = _get_iface_info(iface)
    if error is False:
        return iface_info.get(iface, {}).get("inet", "")
    else:
        return error
def interface_ip(iface):
    iface_info, error = _get_iface_info(iface)
    if error is False:
        inet = iface_info.get(iface, {}).get("inet", None)
        return inet[0].get("address", "") if inet else ""
    else:
        return error
def _subnets(proto="inet", interfaces_=None):
    if interfaces_ is None:
        ifaces = interfaces()
    elif isinstance(interfaces_, list):
        ifaces = {}
        for key, value in interfaces().items():
            if key in interfaces_:
                ifaces[key] = value
    else:
        ifaces = {interfaces_: interfaces().get(interfaces_, {})}
    ret = set()
    if proto == "inet":
        subnet = "netmask"
        dflt_cidr = 32
    elif proto == "inet6":
        subnet = "prefixlen"
        dflt_cidr = 128
    else:
        log.error("Invalid proto %s calling subnets()", proto)
        return
    for ip_info in ifaces.values():
        addrs = ip_info.get(proto, [])
        addrs.extend(
            [addr for addr in ip_info.get("secondary", []) if addr.get("type") == proto]
        )
        for intf in addrs:
            if subnet in intf:
                intf = ipaddress.ip_interface(
                    "{}/{}".format(intf["address"], intf[subnet])
                )
            else:
                intf = ipaddress.ip_interface(
                    "{}/{}".format(intf["address"], dflt_cidr)
                )
            if not intf.is_loopback:
                ret.add(intf.network)
    return [str(net) for net in sorted(ret)]
def subnets(interfaces=None):
    return _subnets("inet", interfaces_=interfaces)
def subnets6():
    return _subnets("inet6")
def in_subnet(cidr, addr=None):
    try:
        cidr = ipaddress.ip_network(cidr)
    except ValueError:
        log.error("Invalid CIDR '%s'", cidr)
        return False
    if addr is None:
        addr = ip_addrs()
        addr.extend(ip_addrs6())
    elif not isinstance(addr, (list, tuple)):
        addr = (addr,)
    return any(ipaddress.ip_address(item) in cidr for item in addr)
def _get_ips(ifaces, proto="inet"):
    ret = []
    for ip_info in ifaces.values():
        ret.extend(ip_info.get(proto, []))
        ret.extend(
            [addr for addr in ip_info.get("secondary", []) if addr.get("type") == proto]
        )
    return ret
def _filter_interfaces(interface=None, interface_data=None):
    ifaces = interface_data if isinstance(interface_data, dict) else interfaces()
    if interface is None:
        ret = ifaces
    else:
        interface = salt.utils.args.split_input(interface)
        ret = {
            k: v
            for k, v in ifaces.items()
            if any(fnmatch.fnmatch(k, pat) for pat in interface)
        }
    return ret
def _ip_addrs(
    interface=None, include_loopback=False, interface_data=None, proto="inet"
):
    addrs = _get_ips(_filter_interfaces(interface, interface_data), proto=proto)
    ret = set()
    for addr in addrs:
        addr = ipaddress.ip_address(addr.get("address"))
        if not addr.is_loopback or include_loopback:
            ret.add(addr)
    return [str(addr) for addr in sorted(ret)]
def ip_addrs(interface=None, include_loopback=False, interface_data=None):
    return _ip_addrs(interface, include_loopback, interface_data, "inet")
def ip_addrs6(interface=None, include_loopback=False, interface_data=None):
    return _ip_addrs(interface, include_loopback, interface_data, "inet6")
def _ip_networks(
    interface=None,
    include_loopback=False,
    verbose=False,
    interface_data=None,
    proto="inet",
):
    addrs = _get_ips(_filter_interfaces(interface, interface_data), proto=proto)
    ret = set()
    for addr in addrs:
        _ip = addr.get("address")
        _net = addr.get("netmask" if proto == "inet" else "prefixlen")
        if _ip and _net:
            try:
                ip_net = ipaddress.ip_network("{}/{}".format(_ip, _net), strict=False)
            except Exception:  # pylint: disable=broad-except
                continue
            if not ip_net.is_loopback or include_loopback:
                ret.add(ip_net)
    if not verbose:
        return [str(addr) for addr in sorted(ret)]
    verbose_ret = {
        str(x): {
            "address": str(x.network_address),
            "netmask": str(x.netmask),
            "num_addresses": x.num_addresses,
            "prefixlen": x.prefixlen,
        }
        for x in ret
    }
    return verbose_ret
def ip_networks(
    interface=None, include_loopback=False, verbose=False, interface_data=None
):
    return _ip_networks(
        interface=interface,
        include_loopback=include_loopback,
        verbose=verbose,
        interface_data=interface_data,
        proto="inet",
    )
def ip_networks6(
    interface=None, include_loopback=False, verbose=False, interface_data=None
):
    return _ip_networks(
        interface=interface,
        include_loopback=include_loopback,
        verbose=verbose,
        interface_data=interface_data,
        proto="inet6",
    )
def hex2ip(hex_ip, invert=False):
    if len(hex_ip) == 32:  # ipv6
        ip_addr = []
        for i in range(0, 32, 8):
            ip_part = hex_ip[i : i + 8]
            ip_part = [ip_part[x : x + 2] for x in range(0, 8, 2)]
            if invert:
                ip_addr.append("{0[3]}{0[2]}:{0[1]}{0[0]}".format(ip_part))
            else:
                ip_addr.append("{0[0]}{0[1]}:{0[2]}{0[3]}".format(ip_part))
        try:
            address = ipaddress.IPv6Address(":".join(ip_addr))
            if address.ipv4_mapped:
                return str(address.ipv4_mapped)
            else:
                return address.compressed
        except ipaddress.AddressValueError as ex:
            log.error("hex2ip - ipv6 address error: %s", ex)
            return hex_ip
    try:
        hip = int(hex_ip, 16)
    except ValueError:
        return hex_ip
    if invert:
        return "{3}.{2}.{1}.{0}".format(
            hip &gt;&gt; 24 &amp; 255, hip &gt;&gt; 16 &amp; 255, hip &gt;&gt; 8 &amp; 255, hip &amp; 255
        )
    return "{}.{}.{}.{}".format(
        hip &gt;&gt; 24 &amp; 255, hip &gt;&gt; 16 &amp; 255, hip &gt;&gt; 8 &amp; 255, hip &amp; 255
    )
def mac2eui64(mac, prefix=None):
    eui64 = re.sub(r"[.:-]", "", mac).lower()
    eui64 = eui64[0:6] + "fffe" + eui64[6:]
    eui64 = hex(int(eui64[0:2], 16) | 2)[2:].zfill(2) + eui64[2:]
    if prefix is None:
        return ":".join(re.findall(r".{4}", eui64))
    else:
        try:
            net = ipaddress.ip_network(prefix, strict=False)
            euil = int("0x{}".format(eui64), 16)
            return "{}/{}".format(net[euil], net.prefixlen)
        except Exception:  # pylint: disable=broad-except
            return
def active_tcp():
    ret = {}
    for statf in ["/proc/net/tcp", "/proc/net/tcp6"]:
        if not os.path.isfile(statf):
            continue
        with salt.utils.files.fopen(statf, "rb") as fp_:
            for line in fp_:
                line = salt.utils.stringutils.to_unicode(line)
                if line.strip().startswith("sl"):
                    continue
                iret = _parse_tcp_line(line)
                slot = next(iter(iret))
                if iret[slot]["state"] == 1:  # 1 is ESTABLISHED
                    del iret[slot]["state"]
                    ret[len(ret)] = iret[slot]
    return ret
def local_port_tcp(port):
    ret = _remotes_on(port, "local_port")
    return ret
def remote_port_tcp(port):
    ret = _remotes_on(port, "remote_port")
    return ret
def _remotes_on(port, which_end):
    port = int(port)
    ret = _netlink_tool_remote_on(port, which_end)
    if ret is not None:
        return ret
    ret = set()
    proc_available = False
    for statf in ["/proc/net/tcp", "/proc/net/tcp6"]:
        if not os.path.isfile(statf):
            continue
        proc_available = True
        with salt.utils.files.fopen(statf, "r") as fp_:
            for line in fp_:
                line = salt.utils.stringutils.to_unicode(line)
                if line.strip().startswith("sl"):
                    continue
                iret = _parse_tcp_line(line)
                slot = next(iter(iret))
                if (
                    iret[slot][which_end] == port and iret[slot]["state"] == 1
                ):  # 1 is ESTABLISHED
                    ret.add(iret[slot]["remote_addr"])
    if not proc_available:  # Fallback to use OS specific tools
        if salt.utils.platform.is_sunos():
            return _sunos_remotes_on(port, which_end)
        if salt.utils.platform.is_freebsd():
            return _freebsd_remotes_on(port, which_end)
        if salt.utils.platform.is_netbsd():
            return _netbsd_remotes_on(port, which_end)
        if salt.utils.platform.is_openbsd():
            return _openbsd_remotes_on(port, which_end)
        if salt.utils.platform.is_windows():
            return _windows_remotes_on(port, which_end)
        if salt.utils.platform.is_aix():
            return _aix_remotes_on(port, which_end)
        return _linux_remotes_on(port, which_end)
    return ret
def _parse_tcp_line(line):
    ret = {}
    comps = line.strip().split()
    slot = comps[0].rstrip(":")
    ret[slot] = {}
    l_addr, l_port = comps[1].split(":")
    r_addr, r_port = comps[2].split(":")
    ret[slot]["local_addr"] = hex2ip(l_addr, True)
    ret[slot]["local_port"] = int(l_port, 16)
    ret[slot]["remote_addr"] = hex2ip(r_addr, True)
    ret[slot]["remote_port"] = int(r_port, 16)
    ret[slot]["state"] = int(comps[3], 16)
    return ret
def _netlink_tool_remote_on(port, which_end):
    remotes = set()
    valid = False
    tcp_end = "dst" if which_end == "remote_port" else "src"
    try:
        data = subprocess.check_output(
            ["ss", "-ant", tcp_end, ":{}".format(port)]
        )  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError:
        log.error("Failed ss")
        raise
    except OSError:  # not command "No such file or directory"
        return None
    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        if "Address:Port" in line:  # ss tools may not be valid
            valid = True
            continue
        elif "ESTAB" not in line:
            continue
        chunks = line.split()
        remote_host, remote_port = chunks[4].rsplit(":", 1)
        remotes.add(remote_host.strip("[]"))
    if valid is False:
        remotes = None
    return remotes
def _sunos_remotes_on(port, which_end):
    remotes = set()
    try:
        data = subprocess.check_output(
            ["netstat", "-f", "inet", "-n"]
        )  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError:
        log.error("Failed netstat")
        raise
    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        if "ESTABLISHED" not in line:
            continue
        chunks = line.split()
        local_host, local_port = chunks[0].rsplit(".", 1)
        remote_host, remote_port = chunks[1].rsplit(".", 1)
        if which_end == "remote_port" and int(remote_port) != port:
            continue
        if which_end == "local_port" and int(local_port) != port:
            continue
        remotes.add(remote_host)
    return remotes
def _freebsd_remotes_on(port, which_end):
    port = int(port)
    remotes = set()
    try:
        cmd = salt.utils.args.shlex_split("sockstat -4 -c -p {}".format(port))
        data = subprocess.check_output(cmd)  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError as ex:
        log.error('Failed "sockstat" with returncode = %s', ex.returncode)
        raise
    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        chunks = line.split()
        if not chunks:
            continue
        if "COMMAND" in chunks[1]:
            continue  # ignore header
        if len(chunks) &lt; 2:
            continue
        local = chunks[-2]
        remote = chunks[-1]
        lhost, lport = local.split(":")
        rhost, rport = remote.split(":")
        if which_end == "local" and int(lport) != port:  # ignore if local port not port
            continue
        if (
            which_end == "remote" and int(rport) != port
        ):  # ignore if remote port not port
            continue
        remotes.add(rhost)
    return remotes
def _netbsd_remotes_on(port, which_end):
    port = int(port)
    remotes = set()
    try:
        cmd = salt.utils.args.shlex_split("sockstat -4 -c -n -p {}".format(port))
        data = subprocess.check_output(cmd)  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError as ex:
        log.error('Failed "sockstat" with returncode = %s', ex.returncode)
        raise
    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        chunks = line.split()
        if not chunks:
            continue
        if "COMMAND" in chunks[1]:
            continue  # ignore header
        if len(chunks) &lt; 2:
            continue
        local = chunks[5].split(".")
        lport = local.pop()
        lhost = ".".join(local)
        remote = chunks[6].split(".")
        rport = remote.pop()
        rhost = ".".join(remote)
        if which_end == "local" and int(lport) != port:  # ignore if local port not port
            continue
        if (
            which_end == "remote" and int(rport) != port
        ):  # ignore if remote port not port
            continue
        remotes.add(rhost)
    return remotes
def _openbsd_remotes_on(port, which_end):
    remotes = set()
    try:
        data = subprocess.check_output(
            ["netstat", "-nf", "inet"]
        )  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError:
        log.error("Failed netstat")
        raise
    lines = data.split("\n")
    for line in lines:
        if "ESTABLISHED" not in line:
            continue
        chunks = line.split()
        local_host, local_port = chunks[3].rsplit(".", 1)
        remote_host, remote_port = chunks[4].rsplit(".", 1)
        if which_end == "remote_port" and int(remote_port) != port:
            continue
        if which_end == "local_port" and int(local_port) != port:
            continue
        remotes.add(remote_host)
    return remotes
def _windows_remotes_on(port, which_end):
    r"""
    Windows specific helper function.
    Returns set of ipv4 host addresses of remote established connections
    on local or remote tcp port.
    Parses output of shell 'netstat' to get connections
    C:\&gt;netstat -n
    Active Connections
       Proto  Local Address          Foreign Address        State
       TCP    10.2.33.17:3007        130.164.12.233:10123   ESTABLISHED
       TCP    10.2.33.17:3389        130.164.30.5:10378     ESTABLISHED
    Linux specific helper function.
    Returns set of ip host addresses of remote established connections
    on local tcp port port.
    Parses output of shell 'lsof'
    to get connections
    $ sudo lsof -iTCP:4505 -n
    COMMAND   PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
    Python   9971 root   35u  IPv4 0x18a8464a29ca329d      0t0  TCP *:4505 (LISTEN)
    Python   9971 root   37u  IPv4 0x18a8464a29b2b29d      0t0  TCP 127.0.0.1:4505-&gt;127.0.0.1:55703 (ESTABLISHED)
    Python  10152 root   22u  IPv4 0x18a8464a29c8cab5      0t0  TCP 127.0.0.1:55703-&gt;127.0.0.1:4505 (ESTABLISHED)
    Python  10153 root   22u  IPv4 0x18a8464a29c8cab5      0t0  TCP [fe80::249a]:4505-&gt;[fe80::150]:59367 (ESTABLISHED)
    """
    remotes = set()
    try:
        data = subprocess.check_output(
            [
                "lsof",
                "-iTCP:{:d}".format(port),
                "-n",
                "-P",
            ]  # pylint: disable=minimum-python-version
        )
    except subprocess.CalledProcessError as ex:
        if ex.returncode == 1:
            log.warning('"lsof" returncode = 1, likely no active TCP sessions.')
            return remotes
        log.error('Failed "lsof" with returncode = %s', ex.returncode)
        raise
    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        chunks = line.split()
        if not chunks:
            continue
        if "COMMAND" in chunks[0]:
            continue  # ignore header
        if "ESTABLISHED" not in chunks[-1]:
            continue  # ignore if not ESTABLISHED
        local, remote = chunks[8].split("-&gt;")
        _, lport = local.rsplit(":", 1)
        rhost, rport = remote.rsplit(":", 1)
        if which_end == "remote_port" and int(rport) != port:
            continue
        if which_end == "local_port" and int(lport) != port:
            continue
        remotes.add(rhost.strip("[]"))
    return remotes
def _aix_remotes_on(port, which_end):
    remotes = set()
    try:
        data = subprocess.check_output(
            ["netstat", "-f", "inet", "-n"]
        )  # pylint: disable=minimum-python-version
    except subprocess.CalledProcessError:
        log.error("Failed netstat")
        raise
    lines = salt.utils.stringutils.to_str(data).split("\n")
    for line in lines:
        if "ESTABLISHED" not in line:
            continue
        chunks = line.split()
        local_host, local_port = chunks[3].rsplit(".", 1)
        remote_host, remote_port = chunks[4].rsplit(".", 1)
        if which_end == "remote_port" and int(remote_port) != port:
            continue
        if which_end == "local_port" and int(local_port) != port:
            continue
        remotes.add(remote_host)
    return remotes
@jinja_filter("gen_mac")
def gen_mac(prefix="AC:DE:48"):
    return "{}:{:02X}:{:02X}:{:02X}".format(
        prefix,
        random.randint(0, 0xFF),
        random.randint(0, 0xFF),
        random.randint(0, 0xFF),
    )
@jinja_filter("mac_str_to_bytes")
def mac_str_to_bytes(mac_str):
    if len(mac_str) == 12:
        pass
    elif len(mac_str) == 17:
        sep = mac_str[2]
        mac_str = mac_str.replace(sep, "")
    else:
        raise ValueError("Invalid MAC address")
    chars = (int(mac_str[s : s + 2], 16) for s in range(0, 12, 2))
    return bytes(chars)
def refresh_dns():
    try:
        RES_INIT()
    except NameError:
        pass
@jinja_filter("dns_check")
def dns_check(addr, port, safe=False, ipv6=None):
    ip_addrs = []
    family = (
        socket.AF_INET6
        if ipv6
        else socket.AF_INET
        if ipv6 is False
        else socket.AF_UNSPEC
    )
    socket_error = False
    try:
        refresh_dns()
        addrinfo = socket.getaddrinfo(addr, port, family, socket.SOCK_STREAM)
        ip_addrs = _test_addrs(addrinfo, port)
    except TypeError:
        raise SaltSystemExit(
            code=42,
            msg=(
                "Attempt to resolve address '{}' failed. Invalid or unresolveable"
                " address".format(addr)
            ),
        )
    except OSError:
        socket_error = True
    if socket_error and ipv6:
        try:
            refresh_dns()
            addrinfo = socket.getaddrinfo(
                addr, port, socket.AF_INET, socket.SOCK_STREAM
            )
            ip_addrs = _test_addrs(addrinfo, port)
        except TypeError:
            raise SaltSystemExit(
                code=42,
                msg=(
                    "Attempt to resolve address '{}' failed. Invalid or unresolveable"
                    " address".format(addr)
                ),
            )
        except OSError:
            error = True
    if not ip_addrs:
        err = "DNS lookup or connection check of '{}' failed.".format(addr)
        if safe:
            if salt.log.is_console_configured():
                log.error(err)
            raise SaltClientError()
        raise SaltSystemExit(code=42, msg=err)
    return salt.utils.zeromq.ip_bracket(ip_addrs[0])
def _test_addrs(addrinfo, port):
    ip_addrs = []
    for a in addrinfo:
        ip_family = a[0]
        ip_addr = a[4][0]
        if ip_addr in ip_addrs:
            continue
        ip_addrs.append(ip_addr)
        try:
            s = socket.socket(ip_family, socket.SOCK_STREAM)
            s.settimeout(2)
            s.connect((ip_addr, port))
            s.close()
            ip_addrs = [ip_addr]
            break
        except OSError:
            pass
    return ip_addrs
def parse_host_port(host_port):
    host, port = None, None  # default
    _s_ = host_port[:]
    if _s_[0] == "[":
        if "]" in host_port:
            host, _s_ = _s_.lstrip("[").rsplit("]", 1)
            host = ipaddress.IPv6Address(host).compressed
            if _s_[0] == ":":
                port = int(_s_.lstrip(":"))
            else:
                if len(_s_) &gt; 1:
                    raise ValueError(
                        'found ambiguous "{}" port in "{}"'.format(_s_, host_port)
                    )
    else:
        if _s_.count(":") == 1:
            host, _hostport_separator_, port = _s_.partition(":")
            try:
                port = int(port)
            except ValueError as _e_:
                errmsg = 'host_port "{}" port value "{}" is not an integer.'.format(
                    host_port, port
                )
                log.error(errmsg)
                raise ValueError(errmsg)
        else:
            host = _s_
    try:
        if not isinstance(host, ipaddress._BaseAddress):
            host_ip = ipaddress.ip_address(host).compressed
            host = host_ip
    except ValueError:
        log.debug('"%s" Not an IP address? Assuming it is a hostname.', host)
        if host != sanitize_host(host):
            log.error('bad hostname: "%s"', host)
            raise ValueError('bad hostname: "{}"'.format(host))
    return host, port
@jinja_filter("filter_by_networks")
def filter_by_networks(values, networks):
    _filter = lambda ips, networks: [
        ip for ip in ips for net in networks if ipaddress.ip_address(ip) in net
    ]
    if networks is not None:
        networks = [ipaddress.ip_network(network) for network in networks]
        if isinstance(values, Mapping):
            return {
                interface: _filter(values[interface], networks) for interface in values
            }
        elif isinstance(values, Sequence):
            return _filter(values, networks)
        else:
            raise ValueError("Do not know how to filter a {}".format(type(values)))
    else:
        return values
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
