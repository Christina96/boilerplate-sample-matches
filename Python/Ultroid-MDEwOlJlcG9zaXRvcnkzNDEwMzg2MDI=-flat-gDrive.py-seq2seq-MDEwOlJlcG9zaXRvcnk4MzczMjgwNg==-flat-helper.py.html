
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 6.621392190152801%, Tokens: 9</h2>
        <div class="column">
            <h3>Ultroid-MDEwOlJlcG9zaXRvcnkzNDEwMzg2MDI=-flat-gDrive.py</h3>
            <pre><code>1  import time
2  from io import FileIO
3  from logging import WARNING
4  from mimetypes import guess_type
5  from apiclient.http import LOGGER, MediaFileUpload, MediaIoBaseDownload
6  from googleapiclient.discovery import build, logger
7  from httplib2 import Http
8  from oauth2client.client import OOB_CALLBACK_URN, OAuth2WebServerFlow
9  from oauth2client.client import logger as _logger
10  from oauth2client.file import Storage
11  from .. import udB
12  from .helper import humanbytes, time_formatter
13  for log in [LOGGER, logger, _logger]:
14      log.setLevel(WARNING)
15  class GDriveManager:
16      def __init__(self):
17          self._flow = {}
18          self.gdrive_creds = {
19              "oauth_scope": [
20                  "https://www.googleapis.com/auth/drive",
21                  "https://www.googleapis.com/auth/drive.file",
22                  "https://www.googleapis.com/auth/drive.metadata",
23              ],
24              "dir_mimetype": "application/vnd.google-apps.folder",
25              "redirect_uri": OOB_CALLBACK_URN,
26          }
27          self.auth_token = udB.get_key("GDRIVE_AUTH_TOKEN")
28          self.folder_id = udB.get_key("GDRIVE_FOLDER_ID")
29          self.token_file = "resources/auth/gdrive_creds.json"
30      @staticmethod
31      def _create_download_link(fileId: str):
32          return f"https://drive.google.com/uc?id={fileId}&export=download"
33      @staticmethod
34      def _create_folder_link(folderId: str):
35          return f"https://drive.google.com/folderview?id={folderId}"
36      def _create_token_file(self, code: str = None):
37          if code and self._flow:
38              _auth_flow = self._flow["_"]
39              credentials = _auth_flow.step2_exchange(code)
40              Storage(self.token_file).put(credentials)
41              return udB.set_key("GDRIVE_AUTH_TOKEN", str(open(self.token_file).read()))
42          try:
43              _auth_flow = OAuth2WebServerFlow(
44                  udB.get_key("GDRIVE_CLIENT_ID")
45                  or "458306970678-jhfbv6o5sf1ar63o1ohp4c0grblp8qba.apps.googleusercontent.com",
46                  udB.get_key("GDRIVE_CLIENT_SECRET")
47                  or "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",
48                  self.gdrive_creds["oauth_scope"],
49                  redirect_uri=self.gdrive_creds["redirect_uri"],
50              )
51              self._flow["_"] = _auth_flow
52          except KeyError:
53              return "Fill GDRIVE client credentials"
54          return _auth_flow.step1_get_authorize_url()
55      @property
56      def _http(self):
57          storage = Storage(self.token_file)
58          creds = storage.get()
59          http = Http()
60          http.redirect_codes = http.redirect_codes - {308}
61          creds.refresh(http)
62          return creds.authorize(http)
63      @property
64      def _build(self):
65          return build("drive", "v2", http=self._http, cache_discovery=False)
66      def _set_permissions(self, fileId: str):
67          _permissions = {
68              "role": "reader",
69              "type": "anyone",
70              "value": None,
71              "withLink": True,
72          }
73          self._build.permissions().insert(
74              fileId=fileId, body=_permissions, supportsAllDrives=True
75          ).execute(http=self._http)
76      async def _upload_file(
77          self, event, path: str, filename: str = None, folder_id: str = None
78      ):
79          last_txt = ""
80          if not filename:
81              filename = path.split("/")[-1]
82          mime_type = guess_type(path)[0] or "application/octet-stream"
83          media_body = MediaFileUpload(path, mimetype=mime_type, resumable=True)
84          body = {
85              "title": filename,
86              "description": "Uploaded using Ultroid Userbot",
87              "mimeType": mime_type,
88          }
89          if folder_id:
90              body["parents"] = [{"id": folder_id}]
91          elif self.folder_id:
92              body["parents"] = [{"id": self.folder_id}]
93          upload = self._build.files().insert(
94              body=body, media_body=media_body, supportsAllDrives=True
95          )
96          start = time.time()
97          _status = None
98          while not _status:
99              _progress, _status = upload.next_chunk(num_retries=3)
100              if _progress:
101                  diff = time.time() - start
102                  completed = _progress.resumable_progress
103                  total_size = _progress.total_size
104                  percentage = round((completed / total_size) * 100, 2)
105                  speed = round(completed / diff, 2)
106                  eta = round((total_size - completed) / speed, 2) * 1000
107                  crnt_txt = (
108                      f"`Uploading {filename} to GDrive...\n\n"
109                      + f"Status: {humanbytes(completed)}/{humanbytes(total_size)} »» {percentage}%\n"
110                      + f"Speed: {humanbytes(speed)}/s\n"
111                      + f"ETA: {time_formatter(eta)}`"
112                  )
113                  if round((diff % 10.00) == 0) or last_txt != crnt_txt:
114                      await event.edit(crnt_txt)
115                      last_txt = crnt_txt
116          fileId = _status.get("id")
117          try:
118              self._set_permissions(fileId=fileId)
119          except BaseException:
120              pass
121          _url = self._build.files().get(fileId=fileId, supportsAllDrives=True).execute()
122          return _url.get("webContentLink")
123      async def _download_file(self, event, fileId: str, filename: str = None):
124          last_txt = ""
125          if fileId.startswith("http"):
126              if "=download" in fileId:
127                  fileId = fileId.split("=")[1][:-7]
128              elif "/view" in fileId:
129                  fileId = fileId.split("/")[::-1][1]
130          try:
131              if not filename:
132                  filename = (
133                      self._build.files()
134                      .get(fileId=fileId, supportsAllDrives=True)
135                      .execute()["title"]
136                  )
137              downloader = self._build.files().get_media(
138                  fileId=fileId, supportsAllDrives=True
139              )
140          except Exception as ex:
141              return False, str(ex)
142          with FileIO(filename, "wb") as file:
143              start = time.time()
144              download = MediaIoBaseDownload(file, downloader)
145              _status = None
146              while not _status:
147                  _progress, _status = download.next_chunk(num_retries=3)
148                  if _progress:
149                      diff = time.time() - start
150                      completed = _progress.resumable_progress
151                      total_size = _progress.total_size
152                      percentage = round((completed / total_size) * 100, 2)
153                      speed = round(completed / diff, 2)
154                      eta = round((total_size - completed) / speed, 2) * 1000
155                      crnt_txt = (
156                          f"`Downloading {filename} from GDrive...\n\n"
157                          + f"Status: {humanbytes(completed)}/{humanbytes(total_size)} »» {percentage}%\n"
158                          + f"Speed: {humanbytes(speed)}/s\n"
159                          + f"ETA: {time_formatter(eta)}`"
160                      )
161                      if round((diff % 10.00) == 0) or last_txt != crnt_txt:
162                          await event.edit(crnt_txt)
163                          last_txt = crnt_txt
164          return True, filename
165      @property
166      def _list_files(self):
167          _items = (
<span onclick='openModal()' class='match'>168              self._build.files()
169              .list(
170                  supportsTeamDrives=True,
171                  includeTeamDriveItems=True,
172                  spaces="drive",
173                  fields="nextPageToken, items(id, title, mimeType)",
174                  pageToken=None,
</span>175              )
176              .execute()
177          )
178          _files = {}
179          for files in _items["items"]:
180              if files["mimeType"] == self.gdrive_creds["dir_mimetype"]:
181                  _files[self._create_folder_link(files["id"])] = files["title"]
182              else:
183                  _files[self._create_download_link(files["id"])] = files["title"]
184          return _files
185      def create_directory(self, directory):
186          body = {
187              "title": directory,
188              "mimeType": self.gdrive_creds["dir_mimetype"],
189          }
190          if self.folder_id:
191              body["parents"] = [{"id": self.folder_id}]
192          file = self._build.files().insert(body=body, supportsAllDrives=True).execute()
193          fileId = file.get("id")
194          self._set_permissions(fileId=fileId)
195          return fileId
196      def search(self, title):
197          query = f"title contains '{title}'"
198          if self.folder_id:
199              query = f"'{self.folder_id}' in parents and (title contains '{title}')"
200          _items = (
201              self._build.files()
202              .list(
203                  supportsTeamDrives=True,
204                  includeTeamDriveItems=True,
205                  q=query,
206                  spaces="drive",
207                  fields="nextPageToken, items(id, title, mimeType)",
208                  pageToken=None,
209              )
210              .execute()
211          )
212          _files = {}
213          for files in _items["items"]:
214              _files[self._create_download_link(files["id"])] = files["title"]
215          return _files
</code></pre>
        </div>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-helper.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  import abc
5  import six
6  from tensorflow.contrib.distributions.python.ops import bernoulli
7  from tensorflow.contrib.distributions.python.ops import categorical
8  from tensorflow.python.framework import dtypes
9  from tensorflow.python.framework import ops
10  from tensorflow.python.layers import base as layers_base
11  from tensorflow.python.ops import array_ops
12  from tensorflow.python.ops import control_flow_ops
13  from tensorflow.python.ops import embedding_ops
14  from tensorflow.python.ops import math_ops
15  from tensorflow.python.ops import random_ops
16  from tensorflow.python.ops import tensor_array_ops
17  from tensorflow.python.util import nest
18  from seq2seq.contrib.seq2seq import decoder
19  __all__ = [
20      "Helper",
21      "TrainingHelper",
22      "GreedyEmbeddingHelper",
23      "CustomHelper",
24      "ScheduledEmbeddingTrainingHelper",
25      "ScheduledOutputTrainingHelper",
26  ]
27  _transpose_batch_time = decoder._transpose_batch_time  # pylint: disable=protected-access
28  def _unstack_ta(inp):
29    return tensor_array_ops.TensorArray(
30        dtype=inp.dtype, size=array_ops.shape(inp)[0],
31        element_shape=inp.get_shape()[1:]).unstack(inp)
32  @six.add_metaclass(abc.ABCMeta)
33  class Helper(object):
34    @abc.abstractproperty
35    def batch_size(self):
36      raise NotImplementedError("batch_size has not been implemented")
37    @abc.abstractmethod
38    def initialize(self, name=None):
39      pass
40    @abc.abstractmethod
41    def sample(self, time, outputs, state, name=None):
42      pass
43    @abc.abstractmethod
44    def next_inputs(self, time, outputs, state, sample_ids, name=None):
45      pass
46  class CustomHelper(Helper):
47    def __init__(self, initialize_fn, sample_fn, next_inputs_fn):
48      self._initialize_fn = initialize_fn
49      self._sample_fn = sample_fn
50      self._next_inputs_fn = next_inputs_fn
51      self._batch_size = None
52    @property
53    def batch_size(self):
54      if self._batch_size is None:
55        raise ValueError("batch_size accessed before initialize was called")
56      return self._batch_size
57    def initialize(self, name=None):
58      with ops.name_scope(name, "%sInitialize" % type(self).__name__):
59        (finished, next_inputs) = self._initialize_fn()
60        if self._batch_size is None:
61          self._batch_size = array_ops.size(finished)
62      return (finished, next_inputs)
63    def sample(self, time, outputs, state, name=None):
64      with ops.name_scope(
65          name, "%sSample" % type(self).__name__, (time, outputs, state)):
66        return self._sample_fn(time=time, outputs=outputs, state=state)
67    def next_inputs(self, time, outputs, state, sample_ids, name=None):
68      with ops.name_scope(
69          name, "%sNextInputs" % type(self).__name__, (time, outputs, state)):
70        return self._next_inputs_fn(
71            time=time, outputs=outputs, state=state, sample_ids=sample_ids)
72  class TrainingHelper(Helper):
73    def __init__(self, inputs, sequence_length, time_major=False, name=None):
74      with ops.name_scope(name, "TrainingHelper", [inputs, sequence_length]):
75        inputs = ops.convert_to_tensor(inputs, name="inputs")
76        if not time_major:
77          inputs = nest.map_structure(_transpose_batch_time, inputs)
78        self._input_tas = nest.map_structure(_unstack_ta, inputs)
79        self._sequence_length = ops.convert_to_tensor(
80            sequence_length, name="sequence_length")
81        if self._sequence_length.get_shape().ndims != 1:
82          raise ValueError(
83              "Expected sequence_length to be a vector, but received shape: %s" %
84              self._sequence_length.get_shape())
85        self._zero_inputs = nest.map_structure(
86            lambda inp: array_ops.zeros_like(inp[0, :]), inputs)
87        self._batch_size = array_ops.size(sequence_length)
88    @property
89    def batch_size(self):
90      return self._batch_size
91    def initialize(self, name=None):
92      with ops.name_scope(name, "TrainingHelperInitialize"):
93        finished = math_ops.equal(0, self._sequence_length)
94        all_finished = math_ops.reduce_all(finished)
95        next_inputs = control_flow_ops.cond(
96            all_finished, lambda: self._zero_inputs,
97            lambda: nest.map_structure(lambda inp: inp.read(0), self._input_tas))
98        return (finished, next_inputs)
99    def sample(self, time, outputs, name=None, **unused_kwargs):
100      with ops.name_scope(name, "TrainingHelperSample", [time, outputs]):
101        sample_ids = math_ops.cast(
102            math_ops.argmax(outputs, axis=-1), dtypes.int32)
103        return sample_ids
104    def next_inputs(self, time, outputs, state, name=None, **unused_kwargs):
105      with ops.name_scope(name, "TrainingHelperNextInputs",
106                          [time, outputs, state]):
107        next_time = time + 1
108        finished = (next_time >= self._sequence_length)
109        all_finished = math_ops.reduce_all(finished)
110        def read_from_ta(inp):
111          return inp.read(next_time)
112        next_inputs = control_flow_ops.cond(
113            all_finished, lambda: self._zero_inputs,
114            lambda: nest.map_structure(read_from_ta, self._input_tas))
115        return (finished, next_inputs, state)
116  class ScheduledEmbeddingTrainingHelper(TrainingHelper):
117    def __init__(self, inputs, sequence_length, embedding, sampling_probability,
118                 time_major=False, seed=None, scheduling_seed=None, name=None):
119      with ops.name_scope(name, "ScheduledEmbeddingSamplingWrapper",
120                          [embedding, sampling_probability]):
121        if callable(embedding):
122          self._embedding_fn = embedding
123        else:
124          self._embedding_fn = (
125              lambda ids: embedding_ops.embedding_lookup(embedding, ids))
126        self._sampling_probability = ops.convert_to_tensor(
127            sampling_probability, name="sampling_probability")
128        if self._sampling_probability.get_shape().ndims not in (0, 1):
129          raise ValueError(
130              "sampling_probability must be either a scalar or a vector. "
131              "saw shape: %s" % (self._sampling_probability.get_shape()))
132        self._seed = seed
133        self._scheduling_seed = scheduling_seed
134        super(ScheduledEmbeddingTrainingHelper, self).__init__(
135            inputs=inputs,
136            sequence_length=sequence_length,
137            time_major=time_major,
138            name=name)
139    def initialize(self, name=None):
140      return super(ScheduledEmbeddingTrainingHelper, self).initialize(name=name)
141    def sample(self, time, outputs, state, name=None):
142      with ops.name_scope(name, "ScheduledEmbeddingTrainingHelperSample",
143                          [time, outputs, state]):
144        select_sample_noise = random_ops.random_uniform(
145            [self.batch_size], seed=self._scheduling_seed)
146        select_sample = (self._sampling_probability > select_sample_noise)
147        sample_id_sampler = categorical.Categorical(logits=outputs)
148        return array_ops.where(
149            select_sample,
150            sample_id_sampler.sample(seed=self._seed),
151            array_ops.tile([-1], [self.batch_size]))
152    def next_inputs(self, time, outputs, state, sample_ids, name=None):
153      with ops.name_scope(name, "ScheduledEmbeddingTrainingHelperSample",
154                          [time, outputs, state, sample_ids]):
155        (finished, base_next_inputs, state) = (
<span onclick='openModal()' class='match'>156            super(ScheduledEmbeddingTrainingHelper, self).next_inputs(
157                time=time,
158                outputs=outputs,
159                state=state,
160                sample_ids=sample_ids,
161                name=name))
</span>162        def maybe_sample():
163          where_sampling = math_ops.cast(
164              array_ops.where(sample_ids > -1), dtypes.int32)
165          where_not_sampling = math_ops.cast(
166              array_ops.where(sample_ids <= -1), dtypes.int32)
167          where_sampling_flat = array_ops.reshape(where_sampling, [-1])
168          where_not_sampling_flat = array_ops.reshape(where_not_sampling, [-1])
169          sample_ids_sampling = array_ops.gather(sample_ids, where_sampling_flat)
170          inputs_not_sampling = array_ops.gather(
171              base_next_inputs, where_not_sampling_flat)
172          sampled_next_inputs = self._embedding_fn(sample_ids_sampling)
173          base_shape = array_ops.shape(base_next_inputs)
174          return (array_ops.scatter_nd(indices=where_sampling,
175                                       updates=sampled_next_inputs,
176                                       shape=base_shape)
177                  + array_ops.scatter_nd(indices=where_not_sampling,
178                                         updates=inputs_not_sampling,
179                                         shape=base_shape))
180        all_finished = math_ops.reduce_all(finished)
181        next_inputs = control_flow_ops.cond(
182            all_finished, lambda: base_next_inputs, maybe_sample)
183        return (finished, next_inputs, state)
184  class ScheduledOutputTrainingHelper(TrainingHelper):
185    def __init__(self, inputs, sequence_length, sampling_probability,
186                 time_major=False, seed=None, next_input_layer=None,
187                 auxiliary_inputs=None, name=None):
188      with ops.name_scope(name, "ScheduledOutputTrainingHelper",
189                          [inputs, auxiliary_inputs, sampling_probability]):
190        self._sampling_probability = ops.convert_to_tensor(
191            sampling_probability, name="sampling_probability")
192        if self._sampling_probability.get_shape().ndims not in (0, 1):
193          raise ValueError(
194              "sampling_probability must be either a scalar or a vector. "
195              "saw shape: %s" % (self._sampling_probability.get_shape()))
196        if auxiliary_inputs is None:
197          maybe_concatenated_inputs = inputs
198        else:
199          inputs = ops.convert_to_tensor(inputs, name="inputs")
200          auxiliary_inputs = ops.convert_to_tensor(
201              auxiliary_inputs, name="auxiliary_inputs")
202          maybe_concatenated_inputs = nest.map_structure(
203              lambda x, y: array_ops.concat((x, y), -1),
204              inputs, auxiliary_inputs)
205          if not time_major:
206            auxiliary_inputs = nest.map_structure(
207                _transpose_batch_time, auxiliary_inputs)
208        self._auxiliary_input_tas = (
209            nest.map_structure(_unstack_ta, auxiliary_inputs)
210            if auxiliary_inputs is not None else None)
211        self._seed = seed
212        if (next_input_layer is not None and not isinstance(next_input_layer,
213                                                            layers_base._Layer)):  # pylint: disable=protected-access
214          raise TypeError("next_input_layer must be a Layer, received: %s" %
215                          type(next_input_layer))
216        self._next_input_layer = next_input_layer
217        super(ScheduledOutputTrainingHelper, self).__init__(
218            inputs=maybe_concatenated_inputs,
219            sequence_length=sequence_length,
220            time_major=time_major,
221            name=name)
222    def initialize(self, name=None):
223      return super(ScheduledOutputTrainingHelper, self).initialize(name=name)
224    def sample(self, time, outputs, state, name=None):
225      with ops.name_scope(name, "ScheduledOutputTrainingHelperSample",
226                          [time, outputs, state]):
227        sampler = bernoulli.Bernoulli(probs=self._sampling_probability)
228        return math_ops.cast(
229            sampler.sample(sample_shape=self.batch_size, seed=self._seed),
230            dtypes.bool)
231    def next_inputs(self, time, outputs, state, sample_ids, name=None):
232      with ops.name_scope(name, "ScheduledOutputTrainingHelperNextInputs",
233                          [time, outputs, state, sample_ids]):
234        (finished, base_next_inputs, state) = (
235            super(ScheduledOutputTrainingHelper, self).next_inputs(
236                time=time,
237                outputs=outputs,
238                state=state,
239                sample_ids=sample_ids,
240                name=name))
241        def maybe_sample():
242          def maybe_concatenate_auxiliary_inputs(outputs_, indices=None):
243            if self._auxiliary_input_tas is None:
244              return outputs_
245            next_time = time + 1
246            auxiliary_inputs = nest.map_structure(
247                lambda ta: ta.read(next_time), self._auxiliary_input_tas)
248            if indices is not None:
249              auxiliary_inputs = array_ops.gather_nd(auxiliary_inputs, indices)
250            return nest.map_structure(
251                lambda x, y: array_ops.concat((x, y), -1),
252                outputs_, auxiliary_inputs)
253          if self._next_input_layer is None:
254            return array_ops.where(
255                sample_ids, maybe_concatenate_auxiliary_inputs(outputs),
256                base_next_inputs)
257          where_sampling = math_ops.cast(
258              array_ops.where(sample_ids), dtypes.int32)
259          where_not_sampling = math_ops.cast(
260              array_ops.where(math_ops.logical_not(sample_ids)), dtypes.int32)
261          outputs_sampling = array_ops.gather_nd(outputs, where_sampling)
262          inputs_not_sampling = array_ops.gather_nd(base_next_inputs,
263                                                    where_not_sampling)
264          sampled_next_inputs = maybe_concatenate_auxiliary_inputs(
265              self._next_input_layer(outputs_sampling), where_sampling)
266          base_shape = array_ops.shape(base_next_inputs)
267          return (array_ops.scatter_nd(indices=where_sampling,
268                                       updates=sampled_next_inputs,
269                                       shape=base_shape)
270                  + array_ops.scatter_nd(indices=where_not_sampling,
271                                         updates=inputs_not_sampling,
272                                         shape=base_shape))
273        all_finished = math_ops.reduce_all(finished)
274        next_inputs = control_flow_ops.cond(
275            all_finished, lambda: base_next_inputs, maybe_sample)
276        return (finished, next_inputs, state)
277  class GreedyEmbeddingHelper(Helper):
278    def __init__(self, embedding, start_tokens, end_token):
279      if callable(embedding):
280        self._embedding_fn = embedding
281      else:
282        self._embedding_fn = (
283            lambda ids: embedding_ops.embedding_lookup(embedding, ids))
284      self._start_tokens = ops.convert_to_tensor(
285          start_tokens, dtype=dtypes.int32, name="start_tokens")
286      self._end_token = ops.convert_to_tensor(
287          end_token, dtype=dtypes.int32, name="end_token")
288      if self._start_tokens.get_shape().ndims != 1:
289        raise ValueError("start_tokens must be a vector")
290      self._batch_size = array_ops.size(start_tokens)
291      if self._end_token.get_shape().ndims != 0:
292        raise ValueError("end_token must be a scalar")
293      self._start_inputs = self._embedding_fn(self._start_tokens)
294    @property
295    def batch_size(self):
296      return self._batch_size
297    def initialize(self, name=None):
298      finished = array_ops.tile([False], [self._batch_size])
299      return (finished, self._start_inputs)
300    def sample(self, time, outputs, state, name=None):
301      del time, state  # unused by sample_fn
302      if not isinstance(outputs, ops.Tensor):
303        raise TypeError("Expected outputs to be a single Tensor, got: %s" %
304                        type(outputs))
305      sample_ids = math_ops.cast(
306          math_ops.argmax(outputs, axis=-1), dtypes.int32)
307      return sample_ids
308    def next_inputs(self, time, outputs, state, sample_ids, name=None):
309      del time, outputs  # unused by next_inputs_fn
310      finished = math_ops.equal(sample_ids, self._end_token)
311      all_finished = math_ops.reduce_all(finished)
312      next_inputs = control_flow_ops.cond(
313          all_finished,
314          lambda: self._start_inputs,
315          lambda: self._embedding_fn(sample_ids))
316      return (finished, next_inputs, state)
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from Ultroid-MDEwOlJlcG9zaXRvcnkzNDEwMzg2MDI=-flat-gDrive.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-helper.py</div>
                </div>
                <div class="column column_space"><pre><code>168              self._build.files()
169              .list(
170                  supportsTeamDrives=True,
171                  includeTeamDriveItems=True,
172                  spaces="drive",
173                  fields="nextPageToken, items(id, title, mimeType)",
174                  pageToken=None,
</pre></code></div>
                <div class="column column_space"><pre><code>156            super(ScheduledEmbeddingTrainingHelper, self).next_inputs(
157                time=time,
158                outputs=outputs,
159                state=state,
160                sample_ids=sample_ids,
161                name=name))
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    