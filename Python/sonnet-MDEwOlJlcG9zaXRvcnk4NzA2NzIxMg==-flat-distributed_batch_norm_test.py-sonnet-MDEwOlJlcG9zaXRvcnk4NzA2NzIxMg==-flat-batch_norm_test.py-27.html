
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 83, <button onclick='openModal()' class='match'>CODE CLONE</button></h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-distributed_batch_norm_test.py</h3>
            <pre><code>1  from absl import logging
2  from absl.testing import parameterized
3  from sonnet.src import test_utils
4  from sonnet.src.distribute import distributed_batch_norm as batch_norm
5  from sonnet.src.distribute import replicator
6  import tensorflow as tf
7  class CrossReplicaBatchNormTest(test_utils.TestCase, parameterized.TestCase):
8    ENTER_PRIMARY_DEVICE = False
9    def testDefaultReplicaContext(self):
10      layer = batch_norm.CrossReplicaBatchNorm(False, False, TestMetric(),
11                                               TestMetric())
12      inputs = tf.ones([2, 3, 3, 5])
13      scale = tf.constant(0.5, shape=(5,))
14      offset = tf.constant(2.0, shape=(5,))
15      outputs = layer(inputs, True, scale=scale, offset=offset).numpy()
16      self.assertAllEqual(outputs, tf.fill(inputs.shape, 2.0))
17    def testWithMultipleDevicesMirrored(self):
18      if self.primary_device == &quot;CPU&quot;:
19        self.skipTest(&quot;No devices to mirror across.&quot;)
20      elif self.primary_device == &quot;GPU&quot;:
21        devices = tf.config.experimental.list_logical_devices(&quot;GPU&quot;)
22      else:
23        devices = tf.config.experimental.list_logical_devices(&quot;TPU&quot;)
24      strategy = replicator.Replicator([device.name for device in devices])
25      with strategy.scope():
26        mean_metric = TestMetric()
27        var_metric = TestMetric()
28        layer = batch_norm.CrossReplicaBatchNorm(False, False, mean_metric,
29                                                 var_metric)
30      scale = tf.constant(0.5, shape=(5,))
31      offset = tf.constant(2.0, shape=(5,))
32      def foo():
33        inputs = tf.random.normal([2, 3, 3, 5])
34        outputs = layer(inputs, True, False, scale, offset)
35        return inputs, outputs
36      inputs, outputs = strategy.run(foo)
37      local_mean_metric = strategy.experimental_local_results(mean_metric.value)
38      local_var_metric = strategy.experimental_local_results(var_metric.value)
39      self.assertAllEqual(local_mean_metric[0].numpy(),
40                          local_mean_metric[1].numpy())
41      self.assertAllEqual(local_var_metric[0].numpy(),
42                          local_var_metric[1].numpy())
43      mean = local_mean_metric[0]
44      var = local_var_metric[0]
45      for inp, out in zip(
46          strategy.experimental_local_results(inputs),
47          strategy.experimental_local_results(outputs)):
48        expected_out = (inp - mean) * tf.math.rsqrt(var + 1e-5) * scale + offset
49        self.assertAllClose(out, expected_out)
50    def testWithTpuStrategy(self):
51      if self.primary_device != &quot;TPU&quot;:
52        self.skipTest(&quot;TPU strategy only runs on TPU&#x27;s&quot;)
53      strategy = replicator.TpuReplicator()
54      with strategy.scope():
55        mean_metric = TestMetric()
56        var_metric = TestMetric()
57        layer = batch_norm.CrossReplicaBatchNorm(False, False,
58                                                 mean_metric, var_metric)
59      scale = tf.constant(0.5, shape=(5,))
60      offset = tf.constant(2.0, shape=(5,))
61      @tf.function
62      def run():
63        def compute():
64          inputs = tf.ones([2, 3, 3, 5])
65          outputs = layer(inputs, True, False, scale, offset)
66          return inputs, outputs
67        return strategy.run(compute)
68      inputs, outputs = run()
69      local_mean_metric = strategy.experimental_local_results(mean_metric.value)
70      local_var_metric = strategy.experimental_local_results(var_metric.value)
71      self.assertAllEqual(local_mean_metric[0].numpy(),
72                          local_mean_metric[1].numpy())
73      self.assertAllEqual(local_var_metric[0].numpy(),
74                          local_var_metric[1].numpy())
75      mean = local_mean_metric[0]
76      var = local_var_metric[0]
77      for inp, out in zip(
78          strategy.experimental_local_results(inputs),
79          strategy.experimental_local_results(outputs)):
80        expected_out = (inp - mean) * tf.math.rsqrt(var + 1e-5) * scale + offset
81        self.assertAllClose(out, expected_out)
82  class TestMetric:
83    def __init__(self):
<span onclick='openModal()' class='match'>84      self._foo = None
85      self._built = False
86    def update(self, x):
87      if self._built:
88        self._foo.assign(x)
89      else:
90        self._foo = tf.Variable(x)
91        self._built = True
92    @property
93    def value(self):
94      return self._foo
95    def initialize(self, x):
96      self._foo = tf.Variable(x)
97      self._built = True
98  def setUpModule():
</span>99    gpus = tf.config.experimental.list_physical_devices(device_type=&quot;GPU&quot;)
100    if len(gpus) == 1:
101      logging.info(&quot;Splitting one physical GPU into two logical GPUs.&quot;)
102      tf.config.experimental.set_virtual_device_configuration(
103          gpus[0], [
104              tf.config.experimental.VirtualDeviceConfiguration(
105                  memory_limit=1024),
106              tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)
107          ])
108  if __name__ == &quot;__main__&quot;:
109    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-batch_norm_test.py</h3>
            <pre><code>1  import itertools
2  from absl.testing import parameterized
3  import numpy as np
4  from sonnet.src import batch_norm
5  from sonnet.src import initializers
6  from sonnet.src import test_utils
7  import tensorflow as tf
8  class BaseBatchNormTest(test_utils.TestCase, parameterized.TestCase):
9    def testSimpleTraining(self):
10      layer = batch_norm.BaseBatchNorm(
11          moving_mean=TestMetric(),
12          moving_variance=TestMetric(),
13          create_scale=False,
14          create_offset=False)
15      inputs = tf.ones([2, 3, 3, 5])
16      scale = tf.constant(0.5, shape=(5,))
17      offset = tf.constant(2.0, shape=(5,))
18      outputs = layer(inputs, True, scale=scale, offset=offset).numpy()
19      self.assertAllEqual(outputs, tf.fill(inputs.shape, 2.0))
20      self.assertEqual((0, 1, 2), layer._axis)
21    def testSimpleTrainingNCHW(self):
22      layer = batch_norm.BaseBatchNorm(
23          moving_mean=TestMetric(),
24          moving_variance=TestMetric(),
25          create_scale=False,
26          create_offset=False,
27          data_format=&quot;NCHW&quot;)
28      inputs = tf.ones([2, 5, 3, 3])
29      scale = tf.constant(0.5, shape=(5, 1, 1))
30      offset = tf.constant(2.0, shape=(5, 1, 1))
31      outputs = layer(inputs, True, scale=scale, offset=offset).numpy()
32      self.assertAllEqual(outputs, tf.fill(inputs.shape, 2.0))
33      self.assertEqual((0, 2, 3), layer._axis)
34    def testSimpleTraining3D(self):
35      layer = batch_norm.BaseBatchNorm(
36          moving_mean=TestMetric(),
37          moving_variance=TestMetric(),
38          create_scale=False,
39          create_offset=False)
40      inputs = tf.ones([2, 3, 3, 3, 5])
41      scale = tf.constant(0.5, shape=(5,))
42      offset = tf.constant(2.0, shape=(5,))
43      outputs = layer(inputs, True, scale=scale, offset=offset).numpy()
44      self.assertAllEqual(outputs, tf.fill(inputs.shape, 2.0))
45      self.assertEqual((0, 1, 2, 3), layer._axis)
46    def testSimpleTraining3DNCDHW(self):
47      layer = batch_norm.BaseBatchNorm(
48          moving_mean=TestMetric(),
49          moving_variance=TestMetric(),
50          create_scale=False,
51          create_offset=False,
52          data_format=&quot;NCDHW&quot;)
53      inputs = tf.ones([2, 5, 3, 3, 3])
54      scale = tf.constant(0.5, shape=(5, 1, 1, 1))
55      offset = tf.constant(2.0, shape=(5, 1, 1, 1))
56      outputs = layer(inputs, True, scale=scale, offset=offset).numpy()
57      self.assertAllEqual(outputs, tf.fill(inputs.shape, 2.0))
58      self.assertEqual((0, 2, 3, 4), layer._axis)
59    def testNoScaleAndOffset(self):
60      layer = batch_norm.BaseBatchNorm(
61          moving_mean=TestMetric(),
62          moving_variance=TestMetric(),
63          create_scale=False,
64          create_offset=False,
65          data_format=&quot;NHWC&quot;)
66      inputs = tf.ones([2, 5, 3, 3, 3])
67      outputs = layer(inputs, True)
68      self.assertAllEqual(outputs, tf.zeros_like(inputs))
69    def testSingleBatchInference(self):
70      layer = batch_norm.BaseBatchNorm(
71          moving_mean=TestMetric(),
72          moving_variance=TestMetric(),
73          create_scale=True,
74          create_offset=True)
75      inputs = tf.ones([1, 1, 1, 1])
76      outputs = layer(inputs, False)
77      self.assertAllEqual(outputs, tf.zeros_like(inputs))
78    @parameterized.parameters(True, False)
79    def testWithTfFunction(self, autograph):
80      if &quot;TPU&quot; in self.device_types:
81        self.skipTest(&quot;Test not working on TPU&quot;)
82      layer = batch_norm.BaseBatchNorm(
83          moving_mean=TestMetric(),
84          moving_variance=TestMetric(),
85          create_scale=False,
86          create_offset=False,
87          data_format=&quot;NHWC&quot;)
88      layer = tf.function(layer, autograph=autograph)
89      inputs = tf.ones([2, 5, 3, 3, 3])
90      scale = tf.constant(0.5, shape=(5, 1, 1, 1))
91      offset = tf.constant(2.0, shape=(5, 1, 1, 1))
92      expected1 = tf.zeros_like(inputs)
93      expected2 = tf.fill(inputs.shape, 2.0)
94      for is_training, use_batch_stats in itertools.product((True, False),
95                                                            (True, False)):
96        outputs = layer(inputs, is_training, use_batch_stats)
97        self.assertAllEqual(outputs, expected1)
98        outputs = layer(
99            inputs, is_training, use_batch_stats, scale=scale, offset=offset)
100        self.assertAllEqual(outputs, expected2)
101    @parameterized.parameters(True, False)
102    def testWithTfFunctionTfArgs(self, autograph):
103      if &quot;TPU&quot; in self.device_types:
104        self.skipTest(&quot;Test not working on TPU&quot;)
105      layer = batch_norm.BaseBatchNorm(
106          moving_mean=TestMetric(),
107          moving_variance=TestMetric(),
108          create_scale=False,
109          create_offset=False,
110          data_format=&quot;NHWC&quot;)
111      layer = tf.function(layer, autograph=autograph)
112      inputs = tf.ones([2, 5, 3, 3, 3])
113      expected = tf.zeros_like(inputs)
114      for is_training, use_batch_stats in itertools.product((True, False),
115                                                            (True, False)):
116        outputs = layer(inputs, tf.constant(is_training),
117                        tf.constant(use_batch_stats))
118        self.assertAllEqual(outputs, expected)
119    def testUsingTestStats(self):
120      layer = batch_norm.BaseBatchNorm(
121          moving_mean=TestMetric(),
122          moving_variance=TestMetric(),
123          create_scale=False,
124          create_offset=False)
125      inputs = tf.ones([2, 3, 3, 5])
126      scale = tf.constant(0.5, shape=(5,))
127      offset = tf.constant(2.0, shape=(5,))
128      outputs = layer(inputs, True, scale=scale, offset=offset).numpy()
129      self.assertAllEqual(outputs, tf.fill(inputs.shape, 2.0))
130      outputs = layer(inputs, False, scale=scale, offset=offset).numpy()
131      for x in np.nditer(outputs):
132        self.assertAllClose(x, 2.0, rtol=1e-5, atol=1e-3)
133    def testIsTrainingFalseFirstCall(self):
134      layer = batch_norm.BaseBatchNorm(
135          moving_mean=TestMetric(),
136          moving_variance=TestMetric(),
137          create_scale=False,
138          create_offset=False)
139      inputs = tf.ones([2, 3, 3, 5])
140      outputs = layer(inputs, False)
141      self.assertAllEqual(outputs, tf.fill(inputs.shape, 0.0))
142    @parameterized.parameters(&quot;NHW&quot;, &quot;HWC&quot;, &quot;channel_last&quot;)
143    def testInvalidDataFormat(self, data_format):
144      with self.assertRaisesRegex(
145          ValueError,
146          &quot;Unable to extract channel information from &#x27;{}&#x27;&quot;.format(data_format)):
147        batch_norm.BaseBatchNorm(
148            moving_mean=TestMetric(),
149            moving_variance=TestMetric(),
150            create_scale=False,
151            create_offset=False,
152            data_format=data_format)
153    @parameterized.parameters(&quot;NCHW&quot;, &quot;NCW&quot;, &quot;channels_first&quot;)
154    def testValidDataFormatChannelsFirst(self, data_format):
155      test = batch_norm.BaseBatchNorm(
156          moving_mean=TestMetric(),
157          moving_variance=TestMetric(),
158          create_scale=False,
159          create_offset=False,
160          data_format=data_format)
161      self.assertEqual(test._channel_index, 1)
162    @parameterized.parameters(&quot;NHWC&quot;, &quot;NWC&quot;, &quot;channels_last&quot;)
163    def testValidDataFormatChannelsLast(self, data_format):
164      test = batch_norm.BaseBatchNorm(
165          moving_mean=TestMetric(),
166          moving_variance=TestMetric(),
167          create_scale=False,
168          create_offset=False,
169          data_format=data_format)
170      self.assertEqual(test._channel_index, -1)
171    def testNoScaleAndInitProvided(self):
172      with self.assertRaisesRegex(
173          ValueError, &quot;Cannot set `scale_init` if `create_scale=False`&quot;):
174        batch_norm.BaseBatchNorm(
175            moving_mean=TestMetric(),
176            moving_variance=TestMetric(),
177            create_scale=False,
178            create_offset=True,
179            scale_init=initializers.Ones())
180    def testNoOffsetBetaInitProvided(self):
181      with self.assertRaisesRegex(
182          ValueError, &quot;Cannot set `offset_init` if `create_offset=False`&quot;):
183        batch_norm.BaseBatchNorm(
184            moving_mean=TestMetric(),
185            moving_variance=TestMetric(),
186            create_scale=True,
187            create_offset=False,
188            offset_init=initializers.Zeros())
189  class BatchNormTest(test_utils.TestCase, parameterized.TestCase):
190    def testSimple(self):
191      layer = batch_norm.BatchNorm(False, False)
192      inputs = tf.ones([2, 3, 3, 5])
193      scale = tf.constant(0.5, shape=(5,))
194      offset = tf.constant(2.0, shape=(5,))
195      outputs = layer(inputs, True, scale=scale, offset=offset).numpy()
196      self.assertAllEqual(outputs, tf.fill(inputs.shape, 2.0))
197  class TestMetric:
198    def __init__(self):
<span onclick='openModal()' class='match'>199      self._foo = None
200      self._built = False
201    def update(self, x):
202      if self._built:
203        self._foo.assign(x)
204      else:
205        self._foo = tf.Variable(x)
206        self._built = True
207    @property
208    def value(self):
209      return self._foo
210    def initialize(self, x):
211      self._foo = tf.Variable(x)
212      self._built = True
213  if __name__ == &quot;__main__&quot;:
</span>214    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-distributed_batch_norm_test.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-batch_norm_test.py</div>
                </div>
                <div class="column column_space"><pre><code>84      self._foo = None
85      self._built = False
86    def update(self, x):
87      if self._built:
88        self._foo.assign(x)
89      else:
90        self._foo = tf.Variable(x)
91        self._built = True
92    @property
93    def value(self):
94      return self._foo
95    def initialize(self, x):
96      self._foo = tf.Variable(x)
97      self._built = True
98  def setUpModule():
</pre></code></div>
                <div class="column column_space"><pre><code>199      self._foo = None
200      self._built = False
201    def update(self, x):
202      if self._built:
203        self._foo.assign(x)
204      else:
205        self._foo = tf.Variable(x)
206        self._built = True
207    @property
208    def value(self):
209      return self._foo
210    def initialize(self, x):
211      self._foo = tf.Variable(x)
212      self._built = True
213  if __name__ == &quot;__main__&quot;:
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    