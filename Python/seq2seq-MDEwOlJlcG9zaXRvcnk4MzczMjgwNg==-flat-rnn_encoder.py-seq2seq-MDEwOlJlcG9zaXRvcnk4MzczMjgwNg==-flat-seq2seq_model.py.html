
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 14.85884101040119%, Tokens: 9</h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-rnn_encoder.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  import copy
5  import tensorflow as tf
6  from tensorflow.contrib.rnn.python.ops import rnn
7  from seq2seq.encoders.encoder import Encoder, EncoderOutput
8  from seq2seq.training import utils as training_utils
9  def _unpack_cell(cell):
10    if isinstance(cell, tf.contrib.rnn.MultiRNNCell):
11      return cell._cells  #pylint: disable=W0212
12    else:
13      return [cell]
14  def _default_rnn_cell_params():
15    return {
16        "cell_class": "BasicLSTMCell",
17        "cell_params": {
18            "num_units": 128
19        },
20        "dropout_input_keep_prob": 1.0,
21        "dropout_output_keep_prob": 1.0,
22        "num_layers": 1,
23        "residual_connections": False,
24        "residual_combiner": "add",
25        "residual_dense": False
26    }
27  def _toggle_dropout(cell_params, mode):
28    cell_params = copy.deepcopy(cell_params)
29    if mode != tf.contrib.learn.ModeKeys.TRAIN:
30      cell_params["dropout_input_keep_prob"] = 1.0
31      cell_params["dropout_output_keep_prob"] = 1.0
32    return cell_params
33  class UnidirectionalRNNEncoder(Encoder):
34    def __init__(self, params, mode, name="forward_rnn_encoder"):
35      super(UnidirectionalRNNEncoder, self).__init__(params, mode, name)
36      self.params["rnn_cell"] = _toggle_dropout(self.params["rnn_cell"], mode)
37    @staticmethod
38    def default_params():
39      return {
40          "rnn_cell": _default_rnn_cell_params(),
41          "init_scale": 0.04,
42      }
43    def encode(self, inputs, sequence_length, **kwargs):
44      scope = tf.get_variable_scope()
45      scope.set_initializer(tf.random_uniform_initializer(
<span onclick='openModal()' class='match'>46          -self.params["init_scale"],
47          self.params["init_scale"]))
48      cell = training_utils.get_rnn_cell(**self.params["rnn_cell"])
</span>49      outputs, state = tf.nn.dynamic_rnn(
50          cell=cell,
51          inputs=inputs,
52          sequence_length=sequence_length,
53          dtype=tf.float32,
54          **kwargs)
55      return EncoderOutput(
56          outputs=outputs,
57          final_state=state,
58          attention_values=outputs,
59          attention_values_length=sequence_length)
60  class BidirectionalRNNEncoder(Encoder):
61    def __init__(self, params, mode, name="bidi_rnn_encoder"):
62      super(BidirectionalRNNEncoder, self).__init__(params, mode, name)
63      self.params["rnn_cell"] = _toggle_dropout(self.params["rnn_cell"], mode)
64    @staticmethod
65    def default_params():
66      return {
67          "rnn_cell": _default_rnn_cell_params(),
68          "init_scale": 0.04,
69      }
70    def encode(self, inputs, sequence_length, **kwargs):
71      scope = tf.get_variable_scope()
72      scope.set_initializer(tf.random_uniform_initializer(
73          -self.params["init_scale"],
74          self.params["init_scale"]))
75      cell_fw = training_utils.get_rnn_cell(**self.params["rnn_cell"])
76      cell_bw = training_utils.get_rnn_cell(**self.params["rnn_cell"])
77      outputs, states = tf.nn.bidirectional_dynamic_rnn(
78          cell_fw=cell_fw,
79          cell_bw=cell_bw,
80          inputs=inputs,
81          sequence_length=sequence_length,
82          dtype=tf.float32,
83          **kwargs)
84      outputs_concat = tf.concat(outputs, 2)
85      return EncoderOutput(
86          outputs=outputs_concat,
87          final_state=states,
88          attention_values=outputs_concat,
89          attention_values_length=sequence_length)
90  class StackBidirectionalRNNEncoder(Encoder):
91    def __init__(self, params, mode, name="stacked_bidi_rnn_encoder"):
92      super(StackBidirectionalRNNEncoder, self).__init__(params, mode, name)
93      self.params["rnn_cell"] = _toggle_dropout(self.params["rnn_cell"], mode)
94    @staticmethod
95    def default_params():
96      return {
97          "rnn_cell": _default_rnn_cell_params(),
98          "init_scale": 0.04,
99      }
100    def encode(self, inputs, sequence_length, **kwargs):
101      scope = tf.get_variable_scope()
102      scope.set_initializer(tf.random_uniform_initializer(
103          -self.params["init_scale"],
104          self.params["init_scale"]))
105      cell_fw = training_utils.get_rnn_cell(**self.params["rnn_cell"])
106      cell_bw = training_utils.get_rnn_cell(**self.params["rnn_cell"])
107      cells_fw = _unpack_cell(cell_fw)
108      cells_bw = _unpack_cell(cell_bw)
109      result = rnn.stack_bidirectional_dynamic_rnn(
110          cells_fw=cells_fw,
111          cells_bw=cells_bw,
112          inputs=inputs,
113          dtype=tf.float32,
114          sequence_length=sequence_length,
115          **kwargs)
116      outputs_concat, _output_state_fw, _output_state_bw = result
117      final_state = (_output_state_fw, _output_state_bw)
118      return EncoderOutput(
119          outputs=outputs_concat,
120          final_state=final_state,
121          attention_values=outputs_concat,
122          attention_values_length=sequence_length)
</code></pre>
        </div>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-seq2seq_model.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import collections
6  import tensorflow as tf
7  from seq2seq import graph_utils
8  from seq2seq import losses as seq2seq_losses
9  from seq2seq.contrib.seq2seq.decoder import _transpose_batch_time
10  from seq2seq.data import vocab
11  from seq2seq.graph_utils import templatemethod
12  from seq2seq.decoders.beam_search_decoder import BeamSearchDecoder
13  from seq2seq.inference import beam_search
14  from seq2seq.models.model_base import ModelBase, _flatten_dict
15  class Seq2SeqModel(ModelBase):
16    def __init__(self, params, mode, name):
17      super(Seq2SeqModel, self).__init__(params, mode, name)
18      self.source_vocab_info = None
<span onclick='openModal()' class='match'>19      if "vocab_source" in self.params and self.params["vocab_source"]:
20        self.source_vocab_info = vocab.get_vocab_info(self.params["vocab_source"])
</span>21      self.target_vocab_info = None
22      if "vocab_target" in self.params and self.params["vocab_target"]:
23        self.target_vocab_info = vocab.get_vocab_info(self.params["vocab_target"])
24    @staticmethod
25    def default_params():
26      params = ModelBase.default_params()
27      params.update({
28          "source.max_seq_len": 50,
29          "source.reverse": True,
30          "target.max_seq_len": 50,
31          "embedding.dim": 100,
32          "embedding.init_scale": 0.04,
33          "embedding.share": False,
34          "inference.beam_search.beam_width": 0,
35          "inference.beam_search.length_penalty_weight": 0.0,
36          "inference.beam_search.choose_successors_fn": "choose_top_k",
37          "optimizer.clip_embed_gradients": 0.1,
38          "vocab_source": "",
39          "vocab_target": "",
40      })
41      return params
42    def _clip_gradients(self, grads_and_vars):
43      grads_and_vars = super(Seq2SeqModel, self)._clip_gradients(grads_and_vars)
44      clipped_gradients = []
45      variables = []
46      for gradient, variable in grads_and_vars:
47        if "embedding" in variable.name:
48          tmp = tf.clip_by_norm(
49              gradient.values, self.params["optimizer.clip_embed_gradients"])
50          gradient = tf.IndexedSlices(tmp, gradient.indices, gradient.dense_shape)
51        clipped_gradients.append(gradient)
52        variables.append(variable)
53      return list(zip(clipped_gradients, variables))
54    def _create_predictions(self, decoder_output, features, labels, losses=None):
55      predictions = {}
56      predictions.update(_flatten_dict({"features": features}))
57      if labels is not None:
58        predictions.update(_flatten_dict({"labels": labels}))
59      if losses is not None:
60        predictions["losses"] = _transpose_batch_time(losses)
61      output_dict = collections.OrderedDict(
62          zip(decoder_output._fields, decoder_output))
63      decoder_output_flat = _flatten_dict(output_dict)
64      decoder_output_flat = {
65          k: _transpose_batch_time(v)
66          for k, v in decoder_output_flat.items()
67      }
68      predictions.update(decoder_output_flat)
69      if "predicted_ids" in predictions.keys():
70        vocab_tables = graph_utils.get_dict_from_collection("vocab_tables")
71        target_id_to_vocab = vocab_tables["target_id_to_vocab"]
72        predicted_tokens = target_id_to_vocab.lookup(
73            tf.to_int64(predictions["predicted_ids"]))
74        predictions["predicted_tokens"] = predicted_tokens
75      return predictions
76    def batch_size(self, features, labels):
77      return tf.shape(features["source_ids"])[0]
78    @property
79    @templatemethod("source_embedding")
80    def source_embedding(self):
81      return tf.get_variable(
82          name="W",
83          shape=[self.source_vocab_info.total_size, self.params["embedding.dim"]],
84          initializer=tf.random_uniform_initializer(
85              -self.params["embedding.init_scale"],
86              self.params["embedding.init_scale"]))
87    @property
88    @templatemethod("target_embedding")
89    def target_embedding(self):
90      if self.params["embedding.share"]:
91        return self.source_embedding
92      return tf.get_variable(
93          name="W",
94          shape=[self.target_vocab_info.total_size, self.params["embedding.dim"]],
95          initializer=tf.random_uniform_initializer(
96              -self.params["embedding.init_scale"],
97              self.params["embedding.init_scale"]))
98    @templatemethod("encode")
99    def encode(self, features, labels):
100      raise NotImplementedError()
101    @templatemethod("decode")
102    def decode(self, encoder_output, features, labels):
103      raise NotImplementedError()
104    def _get_beam_search_decoder(self, decoder):
105      config = beam_search.BeamSearchConfig(
106          beam_width=self.params["inference.beam_search.beam_width"],
107          vocab_size=self.target_vocab_info.total_size,
108          eos_token=self.target_vocab_info.special_vocab.SEQUENCE_END,
109          length_penalty_weight=self.params[
110              "inference.beam_search.length_penalty_weight"],
111          choose_successors_fn=getattr(
112              beam_search,
113              self.params["inference.beam_search.choose_successors_fn"]))
114      return BeamSearchDecoder(decoder=decoder, config=config)
115    @property
116    def use_beam_search(self):
117      return self.params["inference.beam_search.beam_width"] > 1
118    def _preprocess(self, features, labels):
119      source_vocab_to_id, source_id_to_vocab, source_word_to_count, _ = \
120        vocab.create_vocabulary_lookup_table(self.source_vocab_info.path)
121      target_vocab_to_id, target_id_to_vocab, target_word_to_count, _ = \
122        vocab.create_vocabulary_lookup_table(self.target_vocab_info.path)
123      graph_utils.add_dict_to_collection({
124          "source_vocab_to_id": source_vocab_to_id,
125          "source_id_to_vocab": source_id_to_vocab,
126          "source_word_to_count": source_word_to_count,
127          "target_vocab_to_id": target_vocab_to_id,
128          "target_id_to_vocab": target_id_to_vocab,
129          "target_word_to_count": target_word_to_count
130      }, "vocab_tables")
131      if self.params["source.max_seq_len"] is not None:
132        features["source_tokens"] = features["source_tokens"][:, :self.params[
133            "source.max_seq_len"]]
134        features["source_len"] = tf.minimum(features["source_len"],
135                                            self.params["source.max_seq_len"])
136      features["source_ids"] = source_vocab_to_id.lookup(features[
137          "source_tokens"])
138      if self.params["source.reverse"] is True:
139        features["source_ids"] = tf.reverse_sequence(
140            input=features["source_ids"],
141            seq_lengths=features["source_len"],
142            seq_dim=1,
143            batch_dim=0,
144            name=None)
145      features["source_len"] = tf.to_int32(features["source_len"])
146      tf.summary.histogram("source_len", tf.to_float(features["source_len"]))
147      if labels is None:
148        return features, None
149      labels = labels.copy()
150      if self.params["target.max_seq_len"] is not None:
151        labels["target_tokens"] = labels["target_tokens"][:, :self.params[
152            "target.max_seq_len"]]
153        labels["target_len"] = tf.minimum(labels["target_len"],
154                                          self.params["target.max_seq_len"])
155      labels["target_ids"] = target_vocab_to_id.lookup(labels["target_tokens"])
156      labels["target_len"] = tf.to_int32(labels["target_len"])
157      tf.summary.histogram("target_len", tf.to_float(labels["target_len"]))
158      num_tokens = tf.reduce_sum(labels["target_len"])
159      num_tokens += tf.reduce_sum(features["source_len"])
160      token_counter_var = tf.Variable(0, "tokens_counter")
161      total_tokens = tf.assign_add(token_counter_var, num_tokens)
162      tf.summary.scalar("num_tokens", total_tokens)
163      with tf.control_dependencies([total_tokens]):
164        features["source_tokens"] = tf.identity(features["source_tokens"])
165      graph_utils.add_dict_to_collection(features, "features")
166      if labels:
167        graph_utils.add_dict_to_collection(labels, "labels")
168      return features, labels
169    def compute_loss(self, decoder_output, _features, labels):
170      losses = seq2seq_losses.cross_entropy_sequence_loss(
171          logits=decoder_output.logits[:, :, :],
172          targets=tf.transpose(labels["target_ids"][:, 1:], [1, 0]),
173          sequence_length=labels["target_len"] - 1)
174      loss = tf.reduce_sum(losses) / tf.to_float(
175          tf.reduce_sum(labels["target_len"] - 1))
176      return losses, loss
177    def _build(self, features, labels, params):
178      features, labels = self._preprocess(features, labels)
179      encoder_output = self.encode(features, labels)
180      decoder_output, _, = self.decode(encoder_output, features, labels)
181      if self.mode == tf.contrib.learn.ModeKeys.INFER:
182        predictions = self._create_predictions(
183            decoder_output=decoder_output, features=features, labels=labels)
184        loss = None
185        train_op = None
186      else:
187        losses, loss = self.compute_loss(decoder_output, features, labels)
188        train_op = None
189        if self.mode == tf.contrib.learn.ModeKeys.TRAIN:
190          train_op = self._build_train_op(loss)
191        predictions = self._create_predictions(
192            decoder_output=decoder_output,
193            features=features,
194            labels=labels,
195            losses=losses)
196      graph_utils.add_dict_to_collection(predictions, "predictions")
197      return predictions, loss, train_op
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-rnn_encoder.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-seq2seq_model.py</div>
                </div>
                <div class="column column_space"><pre><code>46          -self.params["init_scale"],
47          self.params["init_scale"]))
48      cell = training_utils.get_rnn_cell(**self.params["rnn_cell"])
</pre></code></div>
                <div class="column column_space"><pre><code>19      if "vocab_source" in self.params and self.params["vocab_source"]:
20        self.source_vocab_info = vocab.get_vocab_info(self.params["vocab_source"])
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    