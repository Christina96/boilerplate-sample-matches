<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for theplatform.py &amp; youtube.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for theplatform.py &amp; youtube.py
      </h3>
<h1 align="center">
        1.2%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>theplatform.py (4.787234%)<th>youtube.py (0.71428573%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(128-196)<td><a href="#" name="0">(506-593)</a><td align="center"><font color="#ff0000">15</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(87-89)<td><a href="#" name="1">(2041-2042)</a><td align="center"><font color="#cc0000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>theplatform.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 from __future__ import unicode_literals
2 import re
3 import time
4 import hmac
5 import binascii
6 import hashlib
7 from .once import OnceIE
8 from .adobepass import AdobePassIE
9 from ..compat import (
10     compat_parse_qs,
11     compat_urllib_parse_urlparse,
12 )
13 from ..utils import (
14     determine_ext,
15     ExtractorError,
16     float_or_none,
17     int_or_none,
18     sanitized_Request,
19     unsmuggle_url,
20     update_url_query,
21     xpath_with_ns,
22     mimetype2ext,
23     find_xpath_attr,
24 )
25 default_ns = 'http://www.w3.org/2005/SMIL21/Language'
26 _x = lambda p: xpath_with_ns(p, {'smil': default_ns})
27 class ThePlatformBaseIE(OnceIE):
28     _TP_TLD = 'com'
29     def _extract_theplatform_smil(self, smil_url, video_id, note='Downloading SMIL data'):
30         meta = self._download_xml(
31             smil_url, video_id, note=note, query={'format': 'SMIL'},
32             headers=self.geo_verification_headers())
33         error_element = find_xpath_attr(meta, _x('.//smil:ref'), 'src')
34         if error_element is not None:
35             exception = find_xpath_attr(
36                 error_element, _x('.//smil:param'), 'name', 'exception')
37             if exception is not None:
38                 if exception.get('value') == 'GeoLocationBlocked':
39                     self.raise_geo_restricted(error_element.attrib['abstract'])
40                 elif error_element.attrib['src'].startswith(
41                         'http://link.theplatform.%s/s/errorFiles/Unavailable.'
42                         % self._TP_TLD):
43                     raise ExtractorError(
44                         error_element.attrib['abstract'], expected=True)
45         smil_formats = self._parse_smil_formats(
46             meta, smil_url, video_id, namespace=default_ns,
47             f4m_params={'g': 'UXWGVKRWHFSP', 'hdcore': '3.0.3'},
48             transform_rtmp_url=lambda streamer, src: (streamer, 'mp4:' + src))
49         formats = []
50         for _format in smil_formats:
51             if OnceIE.suitable(_format['url']):
52                 formats.extend(self._extract_once_formats(_format['url']))
53             else:
54                 media_url = _format['url']
55                 if determine_ext(media_url) == 'm3u8':
56                     hdnea2 = self._get_cookies(media_url).get('hdnea2')
57                     if hdnea2:
58                         _format['url'] = update_url_query(media_url, {'hdnea3': hdnea2.value})
59                 formats.append(_format)
60         subtitles = self._parse_smil_subtitles(meta, default_ns)
61         return formats, subtitles
62     def _download_theplatform_metadata(self, path, video_id):
63         info_url = 'http://link.theplatform.%s/s/%s?format=preview' % (self._TP_TLD, path)
64         return self._download_json(info_url, video_id)
65     def _parse_theplatform_metadata(self, info):
66         subtitles = {}
67         if isinstance(captions, list):
68             for caption in captions:
69                 lang, src, mime = caption<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.get('lang', 'en'), caption.get('src'), caption.get('type')
70                 subtitles.setdefault(lang, []).append({
71                     'ext': mimetype2ext(</b></font>mime),
72                     'url': src,
73                 })
74         duration = info.get('duration')
75         tp_chapters = info.get('chapters', [])
76         chapters = []
77         if tp_chapters:
78             def _add_chapter(start_time, end_time):
79                 start_time = float_or_none(start_time, 1000)
80                 end_time = float_or_none(end_time, 1000)
81                 if start_time is None or end_time is None:
82                     return
83                 chapters.append({
84                     'start_time': start_time,
85                     'end_time': end_time,
86                 })
87             for chapter in tp_chapters[:-1]:
88                 _add_chapter(chapter.get('startTime'), chapter.get('endTime'))
89             _add_chapter(tp_chapters[-1].get('startTime'), tp_chapters[-1].get('endTime') or duration)
90         return {
91             'title': info['title'],
92             'subtitles': subtitles,
93             'description': info['description'],
94             'thumbnail': info['defaultThumbnailUrl'],
95             'duration': float_or_none(duration, 1000),
96             'timestamp': int_or_none(info.get('pubDate'), 1000) or None,
97             'uploader': info.get('billingCode'),
98             'chapters': chapters,
99         }
100     def _extract_theplatform_metadata(self, path, video_id):
101         info = self._download_theplatform_metadata(path, video_id)
102         return self._parse_theplatform_metadata(info)
103 class ThePlatformIE(ThePlatformBaseIE, AdobePassIE):
104     _VALID_URL <font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>= r'''(?x)
105         (?:https?://(?:link|player)\.theplatform\.com/[sp]/(?P&lt;provider_id&gt;[^/]+)/
106            (?:(?:(?:[^/]+/)+select/)?(?P&lt;media&gt;media/(?:guid/\d+/)?)?|(?P&lt;config&gt;(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
107          |theplatform:)(?P&lt;id&gt;[^/\?&amp;]+)'''
108     _TESTS = [{
109         'url': 'http://link.theplatform.com/s/dJ5BDC/e9I_cZgTgIPd/meta.smil?format=smil&amp;Tracking=true&amp;mbr=true',
110         'info_dict': {
111             'id': 'e9I_cZgTgIPd',
112             'ext': 'flv',
113             'title': 'Blackberry\'s big, bold Z30',
114             'description': 'The Z30 is Blackberry\'s biggest, baddest mobile messaging device yet.',
115             'duration': 247,
116             'timestamp': 1383239700,
117             'upload_date': '20131031',
118             'uploader': 'CBSI-NEW',
119         },
120         'params': {
121             'skip_download': True,
122         },
123         'skip': '404 Not Found',
124     }, {
125         'url': 'http://link.theplatform.com/s/kYEXFC/22d_qsQ6MIRT',
126         'info_dict': {
127             'id': '22d_qsQ6MIRT',
128             'ext': 'flv',
129             'description': 'md5:ac330c9258c04f9d7512cf26b9595409',
130             'title': 'Tesla Model S: A second step towards a cleaner motoring future',
131             'timestamp': 1426176191,
132             'upload_date': '20150312',
133             'uploader': 'CBSI-NEW',
134         },
135         'params': {
136             'skip_download': True,
137         }
138     }, {
139         'url': 'https://player.theplatform.com/p/D6x-PC/pulse_preview/embed/select/media/yMBg9E8KFxZD',
140         'info_dict': {
141             'id': 'yMBg9E8KFxZD',
142             'ext': 'mp4',
143             'description': 'md5:644ad9188d655b742f942bf2e06b002d',
144             'title': 'HIGHLIGHTS: USA bag first ever series Cup win',
145             'uploader': 'EGSM',
146         }
147     }, {
148         'url': 'http://player.theplatform.com/p/NnzsPC/widget/select/media/4Y0TlYUr_ZT7',
149         'only_matching': True,
150     }, {
151         'url': 'http://player.theplatform.com/p/2E2eJC/nbcNewsOffsite?guid=tdy_or_siri_150701',
152         'md5': 'fb96bb3d85118930a5b055783a3bd992',
153         'info_dict': {
154             'id': 'tdy_or_siri_150701',
155             'ext': 'mp4',
156             'title': 'iPhone Siri‚Äôs sassy response to a math question has people talking',
157             'description': 'md5:a565d1deadd5086f3331d57298ec6333',
158             'duration': 83.0,
159             'thumbnail': r're:^https?://.*\.jpg$',
160             'timestamp': 1435752600,
161             'upload_date': '20150701',
162             'uploader': 'NBCU-NEWS',
163         },
164     }, {
165         'url'</b></font>: 'http://player.theplatform.com/p/NnzsPC/onsite_universal/select/media/guid/2410887629/2928790?fwsitesection=nbc_the_blacklist_video_library&amp;autoPlay=true&amp;carouselID=137781',
166         'only_matching': True,
167     }]
168     @classmethod
169     def _extract_urls(cls, webpage):
170         m = re.search(
171             r'''(?x)
172                     &lt;meta\s+
173                         property=(["'])(?:og:video(?::(?:secure_)?url)?|twitter:player)\1\s+
174                         content=(["'])(?P&lt;url&gt;https?://player\.theplatform\.com/p/.+?)\2
175             ''', webpage)
176         if m:
177             return [m.group('url')]
178         matches = re.findall(
179             r'(?s)&lt;(?:iframe|script)[^&gt;]+src=(["\'])((?:https?:)?//player\.theplatform\.com/p/.+?)\1', webpage)
180         if matches:
181             return [re.sub(r'\s', '', list(zip(*matches))[1][0])]
182     @staticmethod
183     def _sign_url(url, sig_key, sig_secret, life=600, include_qs=False):
184         flags = '10' if include_qs else '00'
185         expiration_date = '%x' % (int(time.time()) + life)
186         def str_to_hex(str):
187             return binascii.b2a_hex(str.encode('ascii')).decode('ascii')
188         def hex_to_bytes(hex):
189             return binascii.a2b_hex(hex.encode('ascii'))
190         relative_path = re.match(r'https?://link\.theplatform\.com/s/([^?]+)', url).group(1)
191         clear_text = hex_to_bytes(flags + expiration_date + str_to_hex(relative_path))
192         checksum = hmac.new(sig_key.encode('ascii'), clear_text, hashlib.sha1).hexdigest()
193         sig = flags + expiration_date + checksum + str_to_hex(sig_secret)
194         return '%s&amp;sig=%s' % (url, sig)
195     def _real_extract(self, url):
196         url, smuggled_data = unsmuggle_url(url, {})
197         self._initialize_geo_bypass({
198             'countries': smuggled_data.get('geo_countries'),
199         })
200         mobj = re.match(self._VALID_URL, url)
201         provider_id = mobj.group('provider_id')
202         video_id = mobj.group('id')
203         if not provider_id:
204             provider_id = 'dJ5BDC'
205         path = provider_id + '/'
206         if mobj.group('media'):
207             path += mobj.group('media')
208         path += video_id
209         qs_dict = compat_parse_qs(compat_urllib_parse_urlparse(url).query)
210         if 'guid' in qs_dict:
211             webpage = self._download_webpage(url, video_id)
212             scripts = re.findall(r'&lt;script[^&gt;]+src="([^"]+)"', webpage)
213             feed_id = None
214             for script in reversed(scripts):
215                 feed_script = self._download_webpage(
216                     self._proto_relative_url(script, 'http:'),
217                     video_id, 'Downloading feed script')
218                 feed_id = self._search_regex(
219                     r'defaultFeedId\s*:\s*"([^"]+)"', feed_script,
220                     'default feed id', default=None)
221                 if feed_id is not None:
222                     break
223             if feed_id is None:
224                 raise ExtractorError('Unable to find feed id')
225             return self.url_result('http://feed.theplatform.com/f/%s/%s?byGuid=%s' % (
226                 provider_id, feed_id, qs_dict['guid'][0]))
227         if smuggled_data.get('force_smil_url', False):
228             smil_url = url
229         elif '/guid/' in url:
230             headers = {}
231             source_url = smuggled_data.get('source_url')
232             if source_url:
233                 headers['Referer'] = source_url
234             request = sanitized_Request(url, headers=headers)
235             webpage = self._download_webpage(request, video_id)
236             smil_url = self._search_regex(
237                 r'&lt;link[^&gt;]+href=(["\'])(?P&lt;url&gt;.+?)\1[^&gt;]+type=["\']application/smil\+xml',
238                 webpage, 'smil url', group='url')
239             path = self._search_regex(
240                 r'link\.theplatform\.com/s/((?:[^/?#&amp;]+/)+[^/?#&amp;]+)', smil_url, 'path')
241             smil_url += '?' if '?' not in smil_url else '&amp;' + 'formats=m3u,mpeg4'
242         elif mobj.group('config'):
243             config_url = url + '&amp;form=json'
244             config_url = config_url.replace('swf/', 'config/')
245             config_url = config_url.replace('onsite/', 'onsite/config/')
246             config = self._download_json(config_url, video_id, 'Downloading config')
247             if 'releaseUrl' in config:
248                 release_url = config['releaseUrl']
249             else:
250                 release_url = 'http://link.theplatform.com/s/%s?mbr=true' % path
251             smil_url = release_url + '&amp;formats=MPEG4&amp;manifest=f4m'
252         else:
253             smil_url = 'http://link.theplatform.com/s/%s?mbr=true' % path
254         sig = smuggled_data.get('sig')
255         if sig:
256             smil_url = self._sign_url(smil_url, sig['key'], sig['secret'])
257         formats, subtitles = self._extract_theplatform_smil(smil_url, video_id)
258         self._sort_formats(formats)
259         ret = self._extract_theplatform_metadata(path, video_id)
260         combined_subtitles = self._merge_subtitles(ret.get('subtitles', {}), subtitles)
261         ret.update({
262             'id': video_id,
263             'formats': formats,
264             'subtitles': combined_subtitles,
265         })
266         return ret
267 class ThePlatformFeedIE(ThePlatformBaseIE):
268     _URL_TEMPLATE = '%s//feed.theplatform.com/f/%s/%s?form=json&amp;%s'
269     _VALID_URL = r'https?://feed\.theplatform\.com/f/(?P&lt;provider_id&gt;[^/]+)/(?P&lt;feed_id&gt;[^?/]+)\?(?:[^&amp;]+&amp;)*(?P&lt;filter&gt;by(?:Gui|I)d=(?P&lt;id&gt;[^&amp;]+))'
270     _TESTS = [{
271         'url': 'http://feed.theplatform.com/f/7wvmTC/msnbc_video-p-test?form=json&amp;pretty=true&amp;range=-40&amp;byGuid=n_hardball_5biden_140207',
272         'md5': '6e32495b5073ab414471b615c5ded394',
273         'info_dict': {
274             'id': 'n_hardball_5biden_140207',
275             'ext': 'mp4',
276             'title': 'The Biden factor: will Joe run in 2016?',
277             'description': 'Could Vice President Joe Biden be preparing a 2016 campaign? Mark Halperin and Sam Stein weigh in.',
278             'thumbnail': r're:^https?://.*\.jpg$',
279             'upload_date': '20140208',
280             'timestamp': 1391824260,
281             'duration': 467.0,
282             'categories': ['MSNBC/Issues/Democrats', 'MSNBC/Issues/Elections/Election 2016'],
283             'uploader': 'NBCU-NEWS',
284         },
285     }, {
286         'url': 'http://feed.theplatform.com/f/2E2eJC/nnd_NBCNews?byGuid=nn_netcast_180306.Copy.01',
287         'only_matching': True,
288     }]
289     def _extract_feed_info(self, provider_id, feed_id, filter_query, video_id, custom_fields=None, asset_types_query={}, account_id=None):
290         real_url = self._URL_TEMPLATE % (self.http_scheme(), provider_id, feed_id, filter_query)
291         entry = self._download_json(real_url, video_id)['entries'][0]
292         main_smil_url = 'http://link.theplatform.com/s/%s/media/guid/%d/%s' % (provider_id, account_id, entry['guid']) if account_id else entry.get('plmedia$publicUrl')
293         formats = []
294         subtitles = {}
295         first_video_id = None
296         duration = None
297         asset_types = []
298         for item in entry['media$content']:
299             smil_url = item['plfile$url']
300             cur_video_id = ThePlatformIE._match_id(smil_url)
301             if first_video_id is None:
302                 first_video_id = cur_video_id
303                 duration = float_or_none(item.get('plfile$duration'))
304             file_asset_types = item.get('plfile$assetTypes') or compat_parse_qs(compat_urllib_parse_urlparse(smil_url).query)['assetTypes']
305             for asset_type in file_asset_types:
306                 if asset_type in asset_types:
307                     continue
308                 asset_types.append(asset_type)
309                 query = {
310                     'mbr': 'true',
311                     'formats': item['plfile$format'],
312                     'assetTypes': asset_type,
313                 }
314                 if asset_type in asset_types_query:
315                     query.update(asset_types_query[asset_type])
316                 cur_formats, cur_subtitles = self._extract_theplatform_smil(update_url_query(
317                     main_smil_url or smil_url, query), video_id, 'Downloading SMIL data for %s' % asset_type)
318                 formats.extend(cur_formats)
319                 subtitles = self._merge_subtitles(subtitles, cur_subtitles)
320         self._sort_formats(formats)
321         thumbnails = [{
322             'url': thumbnail['plfile$url'],
323             'width': int_or_none(thumbnail.get('plfile$width')),
324             'height': int_or_none(thumbnail.get('plfile$height')),
325         } for thumbnail in entry.get('media$thumbnails', [])]
326         timestamp = int_or_none(entry.get('media$availableDate'), scale=1000)
327         categories = [item['media$name'] for item in entry.get('media$categories', [])]
328         ret = self._extract_theplatform_metadata('%s/%s' % (provider_id, first_video_id), video_id)
329         subtitles = self._merge_subtitles(subtitles, ret['subtitles'])
330         ret.update({
331             'id': video_id,
332             'formats': formats,
333             'subtitles': subtitles,
334             'thumbnails': thumbnails,
335             'duration': duration,
336             'timestamp': timestamp,
337             'categories': categories,
338         })
339         if custom_fields:
340             ret.update(custom_fields(entry))
341         return ret
342     def _real_extract(self, url):
343         mobj = re.match(self._VALID_URL, url)
344         video_id = mobj.group('id')
345         provider_id = mobj.group('provider_id')
346         feed_id = mobj.group('feed_id')
347         filter_query = mobj.group('filter')
348         return self._extract_feed_info(provider_id, feed_id, filter_query, video_id)
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>youtube.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 from __future__ import unicode_literals
2 import itertools
3 import json
4 import os.path
5 import random
6 import re
7 import traceback
8 from .common import InfoExtractor, SearchInfoExtractor
9 from ..compat import (
10     compat_chr,
11     compat_HTTPError,
12     compat_map as map,
13     compat_parse_qs,
14     compat_str,
15     compat_urllib_parse_unquote_plus,
16     compat_urllib_parse_urlencode,
17     compat_urllib_parse_urlparse,
18     compat_urlparse,
19 )
20 from ..jsinterp import JSInterpreter
21 from ..utils import (
22     ExtractorError,
23     clean_html,
24     dict_get,
25     error_to_compat_str,
26     float_or_none,
27     int_or_none,
28     js_to_json,
29     mimetype2ext,
30     parse_codecs,
31     parse_duration,
32     qualities,
33     remove_start,
34     smuggle_url,
35     str_or_none,
36     str_to_int,
37     try_get,
38     unescapeHTML,
39     unified_strdate,
40     unsmuggle_url,
41     update_url_query,
42     url_or_none,
43     urlencode_postdata,
44     urljoin,
45 )
46 def parse_qs(url):
47     return compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)
48 class YoutubeBaseInfoExtractor(InfoExtractor):
49     _LOGIN_URL = 'https://accounts.google.com/ServiceLogin'
50     _TWOFACTOR_URL = 'https://accounts.google.com/signin/challenge'
51     _LOOKUP_URL = 'https://accounts.google.com/_/signin/sl/lookup'
52     _CHALLENGE_URL = 'https://accounts.google.com/_/signin/sl/challenge'
53     _TFA_URL = 'https://accounts.google.com/_/signin/challenge?hl=en&amp;TL={0}'
54     _NETRC_MACHINE = 'youtube'
55     _LOGIN_REQUIRED = False
56     _PLAYLIST_ID_RE = r'(?:(?:PL|LL|EC|UU|FL|RD|UL|TL|PU|OLAK5uy_)[0-9A-Za-z-_]{10,}|RDMM)'
57     def _login(self):
58         username, password = self._get_login_info()
59         if username is None:
60             if self._LOGIN_REQUIRED and self._downloader.params.get('cookiefile') is None:
61                 raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)
62             return True
63         login_page = self._download_webpage(
64             self._LOGIN_URL, None,
65             note='Downloading login page',
66             errnote='unable to fetch login page', fatal=False)
67         if login_page is False:
68             return
69         login_form = self._hidden_inputs(login_page)
70         def req(url, f_req, note, errnote):
71             data = login_form.copy()
72             data.update({
73                 'pstMsg': 1,
74                 'checkConnection': 'youtube',
75                 'checkedDomains': 'youtube',
76                 'hl': 'en',
77                 'deviceinfo': '[null,null,null,[],null,"US",null,null,[],"GlifWebSignIn",null,[null,null,[]]]',
78                 'f.req': json.dumps(f_req),
79                 'flowName': 'GlifWebSignIn',
80                 'flowEntry': 'ServiceLogin',
81                 'bgRequest': '["identifier",""]',
82             })
83             return self._download_json(
84                 url, None, note=note, errnote=errnote,
85                 transform_source=lambda s: re.sub(r'^[^[]*', '', s),
86                 fatal=False,
87                 data=urlencode_postdata(data), headers={
88                     'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8',
89                     'Google-Accounts-XSRF': 1,
90                 })
91         def warn(message):
92             self._downloader.report_warning(message)
93         lookup_req = [
94             username,
95             None, [], None, 'US', None, None, 2, False, True,
96             [
97                 None, None,
98                 [2, 1, None, 1,
99                  'https://accounts.google.com/ServiceLogin?passive=true&amp;continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Fnext%3D%252F%26action_handle_signin%3Dtrue%26hl%3Den%26app%3Ddesktop%26feature%3Dsign_in_button&amp;hl=en&amp;service=youtube&amp;uilel=3&amp;requestPath=%2FServiceLogin&amp;Page=PasswordSeparationSignIn',
100                  None, [], 4],
101                 1, [None, None, []], None, None, None, True
102             ],
103             username,
104         ]
105         lookup_results = req(
106             self._LOOKUP_URL, lookup_req,
107             'Looking up account info', 'Unable to look up account info')
108         if lookup_results is False:
109             return False
110         user_hash = try_get(lookup_results, lambda x: x[0][2], compat_str)
111         if not user_hash:
112             warn('Unable to extract user hash')
113             return False
114         challenge_req = [
115             user_hash,
116             None, 1, None, [1, None, None, None, [password, None, True]],
117             [
118                 None, None, [2, 1, None, 1, 'https://accounts.google.com/ServiceLogin?passive=true&amp;continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Fnext%3D%252F%26action_handle_signin%3Dtrue%26hl%3Den%26app%3Ddesktop%26feature%3Dsign_in_button&amp;hl=en&amp;service=youtube&amp;uilel=3&amp;requestPath=%2FServiceLogin&amp;Page=PasswordSeparationSignIn', None, [], 4],
119                 1, [None, None, []], None, None, None, True
120             ]]
121         challenge_results = req(
122             self._CHALLENGE_URL, challenge_req,
123             'Logging in', 'Unable to log in')
124         if challenge_results is False:
125             return
126         login_res = try_get(challenge_results, lambda x: x[0][5], list)
127         if login_res:
128             login_msg = try_get(login_res, lambda x: x[5], compat_str)
129             warn(
130                 'Unable to login: %s' % 'Invalid password'
131                 if login_msg == 'INCORRECT_ANSWER_ENTERED' else login_msg)
132             return False
133         res = try_get(challenge_results, lambda x: x[0][-1], list)
134         if not res:
135             warn('Unable to extract result entry')
136             return False
137         login_challenge = try_get(res, lambda x: x[0][0], list)
138         if login_challenge:
139             challenge_str = try_get(login_challenge, lambda x: x[2], compat_str)
140             if challenge_str == 'TWO_STEP_VERIFICATION':
141                 status = try_get(login_challenge, lambda x: x[5], compat_str)
142                 if status == 'QUOTA_EXCEEDED':
143                     warn('Exceeded the limit of TFA codes, try later')
144                     return False
145                 tl = try_get(challenge_results, lambda x: x[1][2], compat_str)
146                 if not tl:
147                     warn('Unable to extract TL')
148                     return False
149                 tfa_code = self._get_tfa_info('2-step verification code')
150                 if not tfa_code:
151                     warn(
152                         'Two-factor authentication required. Provide it either interactively or with --twofactor &lt;code&gt;'
153                         '(Note that only TOTP (Google Authenticator App) codes work at this time.)')
154                     return False
155                 tfa_code = remove_start(tfa_code, 'G-')
156                 tfa_req = [
157                     user_hash, None, 2, None,
158                     [
159                         9, None, None, None, None, None, None, None,
160                         [None, tfa_code, True, 2]
161                     ]]
162                 tfa_results = req(
163                     self._TFA_URL.format(tl), tfa_req,
164                     'Submitting TFA code', 'Unable to submit TFA code')
165                 if tfa_results is False:
166                     return False
167                 tfa_res = try_get(tfa_results, lambda x: x[0][5], list)
168                 if tfa_res:
169                     tfa_msg = try_get(tfa_res, lambda x: x[5], compat_str)
170                     warn(
171                         'Unable to finish TFA: %s' % 'Invalid TFA code'
172                         if tfa_msg == 'INCORRECT_ANSWER_ENTERED' else tfa_msg)
173                     return False
174                 check_cookie_url = try_get(
175                     tfa_results, lambda x: x[0][-1][2], compat_str)
176             else:
177                 CHALLENGES = {
178                     'LOGIN_CHALLENGE': "This device isn't recognized. For your security, Google wants to make sure it's really you.",
179                     'USERNAME_RECOVERY': 'Please provide additional information to aid in the recovery process.',
180                     'REAUTH': "There is something unusual about your activity. For your security, Google wants to make sure it's really you.",
181                 }
182                 challenge = CHALLENGES.get(
183                     challenge_str,
184                     '%s returned error %s.' % (self.IE_NAME, challenge_str))
185                 warn('%s\nGo to https://accounts.google.com/, login and solve a challenge.' % challenge)
186                 return False
187         else:
188             check_cookie_url = try_get(res, lambda x: x[2], compat_str)
189         if not check_cookie_url:
190             warn('Unable to extract CheckCookie URL')
191             return False
192         check_cookie_results = self._download_webpage(
193             check_cookie_url, None, 'Checking cookie', fatal=False)
194         if check_cookie_results is False:
195             return False
196         if 'https://myaccount.google.com/' not in check_cookie_results:
197             warn('Unable to log in')
198             return False
199         return True
200     def _initialize_consent(self):
201         cookies = self._get_cookies('https://www.youtube.com/')
202         if cookies.get('__Secure-3PSID'):
203             return
204         consent_id = None
205         consent = cookies.get('CONSENT')
206         if consent:
207             if 'YES' in consent.value:
208                 return
209             consent_id = self._search_regex(
210                 r'PENDING\+(\d+)', consent.value, 'consent', default=None)
211         if not consent_id:
212             consent_id = random.randint(100, 999)
213         self._set_cookie('.youtube.com', 'CONSENT', 'YES+cb.20210328-17-p0.en+FX+%s' % consent_id)
214     def _real_initialize(self):
215         self._initialize_consent()
216         if self._downloader is None:
217             return
218         if not self._login():
219             return
220     _DEFAULT_API_DATA = {
221         'context': {
222             'client': {
223                 'clientName': 'WEB',
224                 'clientVersion': '2.20201021.03.00',
225             }
226         },
227     }
228     _YT_INITIAL_DATA_RE = r'(?:window\s*\[\s*["\']ytInitialData["\']\s*\]|ytInitialData)\s*=\s*({.+?})\s*;'
229     _YT_INITIAL_PLAYER_RESPONSE_RE = r'ytInitialPlayerResponse\s*=\s*({.+?})\s*;'
230     _YT_INITIAL_BOUNDARY_RE = r'(?:var\s+meta|&lt;/script|\n)'
231     def _call_api(self, ep, query, video_id, fatal=True):
232         data = self._DEFAULT_API_DATA.copy()
233         data.update(query)
234         return self._download_json(
235             'https://www.youtube.com/youtubei/v1/%s' % ep, video_id=video_id,
236             note='Downloading API JSON', errnote='Unable to download API page',
237             data=json.dumps(data).encode('utf8'), fatal=fatal,
238             headers={'content-type': 'application/json'},
239             query={'key': 'AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8'})
240     def _extract_yt_initial_data(self, video_id, webpage):
241         return self._parse_json(
242             self._search_regex(
243                 (r'%s\s*%s' % (self._YT_INITIAL_DATA_RE, self._YT_INITIAL_BOUNDARY_RE),
244                  self._YT_INITIAL_DATA_RE), webpage, 'yt initial data'),
245             video_id)
246     def _extract_ytcfg(self, video_id, webpage):
247         return self._parse_json(
248             self._search_regex(
249                 r'ytcfg\.set\s*\(\s*({.+?})\s*\)\s*;', webpage, 'ytcfg',
250                 default='{}'), video_id, fatal=False) or {}
251     def _extract_video(self, renderer):
252         video_id = renderer['videoId']
253         title = try_get(
254             renderer,
255             (lambda x: x['title']['runs'][0]['text'],
256              lambda x: x['title']['simpleText']), compat_str)
257         description = try_get(
258             renderer, lambda x: x['descriptionSnippet']['runs'][0]['text'],
259             compat_str)
260         duration = parse_duration(try_get(
261             renderer, lambda x: x['lengthText']['simpleText'], compat_str))
262         view_count_text = try_get(
263             renderer, lambda x: x['viewCountText']['simpleText'], compat_str) or ''
264         view_count = str_to_int(self._search_regex(
265             r'^([\d,]+)', re.sub(r'\s', '', view_count_text),
266             'view count', default=None))
267         uploader = try_get(
268             renderer,
269             (lambda x: x['ownerText']['runs'][0]['text'],
270              lambda x: x['shortBylineText']['runs'][0]['text']), compat_str)
271         return {
272             '_type': 'url',
273             'ie_key': YoutubeIE.ie_key(),
274             'id': video_id,
275             'url': video_id,
276             'title': title,
277             'description': description,
278             'duration': duration,
279             'view_count': view_count,
280             'uploader': uploader,
281         }
282     def _search_results(self, query, params):
283         data = {
284             'context': {
285                 'client': {
286                     'clientName': 'WEB',
287                     'clientVersion': '2.20201021.03.00',
288                 }
289             },
290             'query': query,
291         }
292         if params:
293             data['params'] = params
294         for page_num in itertools.count(1):
295             search = self._download_json(
296                 'https://www.youtube.com/youtubei/v1/search?key=AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8',
297                 video_id='query "%s"' % query,
298                 note='Downloading page %s' % page_num,
299                 errnote='Unable to download API page', fatal=False,
300                 data=json.dumps(data).encode('utf8'),
301                 headers={'content-type': 'application/json'})
302             if not search:
303                 break
304             slr_contents = try_get(
305                 search,
306                 (lambda x: x['contents']['twoColumnSearchResultsRenderer']['primaryContents']['sectionListRenderer']['contents'],
307                  lambda x: x['onResponseReceivedCommands'][0]['appendContinuationItemsAction']['continuationItems']),
308                 list)
309             if not slr_contents:
310                 break
311             for slr_content in slr_contents:
312                 isr_contents = try_get(
313                     slr_content,
314                     lambda x: x['itemSectionRenderer']['contents'],
315                     list)
316                 if not isr_contents:
317                     continue
318                 for content in isr_contents:
319                     if not isinstance(content, dict):
320                         continue
321                     video = content.get('videoRenderer')
322                     if not isinstance(video, dict):
323                         continue
324                     video_id = video.get('videoId')
325                     if not video_id:
326                         continue
327                     yield self._extract_video(video)
328             token = try_get(
329                 slr_contents,
330                 lambda x: x[-1]['continuationItemRenderer']['continuationEndpoint']['continuationCommand']['token'],
331                 compat_str)
332             if not token:
333                 break
334             data['continuation'] = token
335 class YoutubeIE(YoutubeBaseInfoExtractor):
336     IE_DESC = 'YouTube.com'
337     _INVIDIOUS_SITES = (
338         r'(?:www\.)?redirect\.invidious\.io',
339         r'(?:(?:www|dev)\.)?invidio\.us',
340         r'(?:(?:www|no)\.)?invidiou\.sh',
341         r'(?:(?:www|fi)\.)?invidious\.snopyta\.org',
342         r'(?:www\.)?invidious\.kabi\.tk',
343         r'(?:www\.)?invidious\.13ad\.de',
344         r'(?:www\.)?invidious\.mastodon\.host',
345         r'(?:www\.)?invidious\.zapashcanon\.fr',
346         r'(?:www\.)?(?:invidious(?:-us)?|piped)\.kavin\.rocks',
347         r'(?:www\.)?invidious\.tinfoil-hat\.net',
348         r'(?:www\.)?invidious\.himiko\.cloud',
349         r'(?:www\.)?invidious\.reallyancient\.tech',
350         r'(?:www\.)?invidious\.tube',
351         r'(?:www\.)?invidiou\.site',
352         r'(?:www\.)?invidious\.site',
353         r'(?:www\.)?invidious\.xyz',
354         r'(?:www\.)?invidious\.nixnet\.xyz',
355         r'(?:www\.)?invidious\.048596\.xyz',
356         r'(?:www\.)?invidious\.drycat\.fr',
357         r'(?:www\.)?inv\.skyn3t\.in',
358         r'(?:www\.)?tube\.poal\.co',
359         r'(?:www\.)?tube\.connect\.cafe',
360         r'(?:www\.)?vid\.wxzm\.sx',
361         r'(?:www\.)?vid\.mint\.lgbt',
362         r'(?:www\.)?vid\.puffyan\.us',
363         r'(?:www\.)?yewtu\.be',
364         r'(?:www\.)?yt\.elukerio\.org',
365         r'(?:www\.)?yt\.lelux\.fi',
366         r'(?:www\.)?invidious\.ggc-project\.de',
367         r'(?:www\.)?yt\.maisputain\.ovh',
368         r'(?:www\.)?ytprivate\.com',
369         r'(?:www\.)?invidious\.13ad\.de',
370         r'(?:www\.)?invidious\.toot\.koeln',
371         r'(?:www\.)?invidious\.fdn\.fr',
372         r'(?:www\.)?watch\.nettohikari\.com',
373         r'(?:www\.)?invidious\.namazso\.eu',
374         r'(?:www\.)?invidious\.silkky\.cloud',
375         r'(?:www\.)?invidious\.exonip\.de',
376         r'(?:www\.)?invidious\.riverside\.rocks',
377         r'(?:www\.)?invidious\.blamefran\.net',
378         r'(?:www\.)?invidious\.moomoo\.de',
379         r'(?:www\.)?ytb\.trom\.tf',
380         r'(?:www\.)?yt\.cyberhost\.uk',
381         r'(?:www\.)?kgg2m7yk5aybusll\.onion',
382         r'(?:www\.)?qklhadlycap4cnod\.onion',
383         r'(?:www\.)?axqzx4s6s54s32yentfqojs3x5i7faxza6xo3ehd4bzzsg2ii4fv2iid\.onion',
384         r'(?:www\.)?c7hqkpkpemu6e7emz5b4vyz7idjgdvgaaa3dyimmeojqbgpea3xqjoid\.onion',
385         r'(?:www\.)?fz253lmuao3strwbfbmx46yu7acac2jz27iwtorgmbqlkurlclmancad\.onion',
386         r'(?:www\.)?invidious\.l4qlywnpwqsluw65ts7md3khrivpirse744un3x7mlskqauz5pyuzgqd\.onion',
387         r'(?:www\.)?owxfohz4kjyv25fvlqilyxast7inivgiktls3th44jhk3ej3i7ya\.b32\.i2p',
388         r'(?:www\.)?4l2dgddgsrkf2ous66i6seeyi6etzfgrue332grh2n7madpwopotugyd\.onion',
389         r'(?:www\.)?w6ijuptxiku4xpnnaetxvnkc5vqcdu7mgns2u77qefoixi63vbvnpnqd\.onion',
390         r'(?:www\.)?kbjggqkzv65ivcqj6bumvp337z6264huv5kpkwuv6gu5yjiskvan7fad\.onion',
391         r'(?:www\.)?grwp24hodrefzvjjuccrkw3mjq4tzhaaq32amf33dzpmuxe7ilepcmad\.onion',
392         r'(?:www\.)?hpniueoejy4opn7bc4ftgazyqjoeqwlvh2uiku2xqku6zpoa4bf5ruid\.onion',
393     )
394     _VALID_URL = r"""(?x)^
395                      (
396                          (?:https?://|//)                                    # http(s):// or protocol-independent URL
397                          (?:(?:(?:(?:\w+\.)?[yY][oO][uU][tT][uU][bB][eE](?:-nocookie|kids)?\.com|
398                             (?:www\.)?deturl\.com/www\.youtube\.com|
399                             (?:www\.)?pwnyoutube\.com|
400                             (?:www\.)?hooktube\.com|
401                             (?:www\.)?yourepeat\.com|
402                             tube\.majestyc\.net|
403                             %(invidious)s|
404                             youtube\.googleapis\.com)/                        # the various hostnames, with wildcard subdomains
405                          (?:.*?\#/)?                                          # handle anchor (#/) redirect urls
406                          (?:                                                  # the various things that can precede the ID:
407                              (?:(?:v|embed|e)/(?!videoseries))                # v/ or embed/ or e/
408                              |shorts/
409                              |(?:                                             # or the v= param in all its forms
410                                  (?:(?:watch|movie)(?:_popup)?(?:\.php)?/?)?  # preceding watch(_popup|.php) or nothing (like /?v=xxxx)
411                                  (?:\?|\#!?)                                  # the params delimiter ? or # or #!
412                                  (?:.*?[&amp;;])??                                # any other preceding param (like /?s=tuff&amp;v=xxxx or ?s=tuff&amp;amp;v=V36LpHqtcDY)
413                                  v=
414                              )
415                          ))
416                          |(?:
417                             youtu\.be|                                        # just youtu.be/xxxx
418                             vid\.plus|                                        # or vid.plus/xxxx
419                             zwearz\.com/watch|                                # or zwearz.com/watch/xxxx
420                             %(invidious)s
421                          )/
422                          |(?:www\.)?cleanvideosearch\.com/media/action/yt/watch\?videoId=
423                          )
424                      )?                                                       # all until now is optional -&gt; you can pass the naked ID
425                      (?P&lt;id&gt;[0-9A-Za-z_-]{11})                                # here is it! the YouTube video ID
426                      (?(1).+)?                                                # if we found the ID, everything can follow
427                      $""" % {
428         'invidious': '|'.join(_INVIDIOUS_SITES),
429     }
430     _PLAYER_INFO_RE = (
431         r'/s/player/(?P&lt;id&gt;[a-zA-Z0-9_-]{8,})/player',
432         r'/(?P&lt;id&gt;[a-zA-Z0-9_-]{8,})/player(?:_ias\.vflset(?:/[a-zA-Z]{2,3}_[a-zA-Z]{2,3})?|-plasma-ias-(?:phone|tablet)-[a-z]{2}_[A-Z]{2}\.vflset)/base\.js$',
433         r'\b(?P&lt;id&gt;vfl[a-zA-Z0-9_-]+)\b.*?\.js$',
434     )
435     _SUBTITLE_FORMATS = ('srv1', 'srv2', 'srv3', 'ttml', 'vtt')
436     _GEO_BYPASS = False
437     IE_NAME <font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= 'youtube'
438     _TESTS = [
439         {
440             'url': 'https://www.youtube.com/watch?v=BaW_jenozKc&amp;t=1s&amp;end=9',
441             'info_dict': {
442                 'id': 'BaW_jenozKc',
443                 'ext': 'mp4',
444                 'title': 'youtube-dl test video "\'/\\√§‚Ü≠ùïê',
445                 'uploader': 'Philipp Hagemeister',
446                 'uploader_id': 'phihag',
447                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/phihag',
448                 'channel_id': 'UCLqxVugv74EIW3VWh2NOa3Q',
449                 'channel_url': r're:https?://(?:www\.)?youtube\.com/channel/UCLqxVugv74EIW3VWh2NOa3Q',
450                 'upload_date': '20121002',
451                 'description': 'test chars:  "\'/\\√§‚Ü≠ùïê\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\n\nThis is a test video for youtube-dl.\n\nFor more information, contact phihag@phihag.de .',
452                 'categories': ['Science &amp; Technology'],
453                 'tags': ['youtube-dl'],
454                 'duration': 10,
455                 'view_count': int,
456                 'like_count': int,
457                 'dislike_count': int,
458                 'start_time': 1,
459                 'end_time': 9,
460             }
461         },
462         {
463             'url': '//www.YouTube.com/watch?v=yZIXLfi8CZQ',
464             'note': 'Embed-only video (#1746)',
465             'info_dict': {
466                 'id': 'yZIXLfi8CZQ',
467                 'ext': 'mp4',
468                 'upload_date': '20120608',
469                 'title': 'Principal Sexually Assaults A Teacher - Episode 117 - 8th June 2012',
470                 'description': 'md5:09b78bd971f1e3e289601dfba15ca4f7',
471                 'uploader': 'SET India',
472                 'uploader_id': 'setindia',
473                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/setindia',
474                 'age_limit': 18,
475             },
476             'skip': 'Private video',
477         },
478         {
479             'url': 'https://www.youtube.com/watch?v=BaW_jenozKc&amp;v=yZIXLfi8CZQ',
480             'note': 'Use the first video ID in the URL',
481             'info_dict': {
482                 'id': 'BaW_jenozKc',
483                 'ext': 'mp4',
484                 'title': 'youtube-dl test video "\'/\\√§‚Ü≠ùïê',
485                 'uploader': 'Philipp Hagemeister',
486                 'uploader_id': 'phihag',
487                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/phihag',
488                 'upload_date': '20121002',
489                 'description': 'test chars:  "\'/\\√§‚Ü≠ùïê\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\n\nThis is a test video for youtube-dl.\n\nFor more information, contact phihag@phihag.de .',
490                 'categories': ['Science &amp; Technology'],
491                 'tags': ['youtube-dl'],
492                 'duration': 10,
493                 'view_count': int,
494                 'like_count': int,
495                 'dislike_count': int,
496             },
497             'params': {
498                 'skip_download': True,
499             },
500         },
501         {
502             'url': 'https://www.youtube.com/watch?v=a9LDPn-MO4I',
503             'note': '256k DASH audio (format 141) via DASH manifest',
504             'info_dict': {
505                 'id': 'a9LDPn-MO4I',
506                 'ext': 'm4a',
507                 'upload_date': '20121002',
508                 'uploader_id': '8KVIDEO',
509                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/8KVIDEO',
510                 'description': '',
511                 'uploader': '8KVIDEO',
512                 'title': 'UHDTV TEST 8K VIDEO.mp4'
513             },
514             'params': {
515                 'youtube_include_dash_manifest': True,
516                 'format': '141',
517             },
518             'skip': 'format 141 not served anymore',
519         },
520         {
521             'url': 'https://www.youtube.com/watch?v=IB3lcPjvWLA',
522             'info_dict': {
523                 'id'</b></font>: 'IB3lcPjvWLA',
524                 'ext': 'm4a',
525                 'title': 'Afrojack, Spree Wilson - The Spark (Official Music Video) ft. Spree Wilson',
526                 'description': 'md5:8f5e2b82460520b619ccac1f509d43bf',
527                 'duration': 244,
528                 'uploader': 'AfrojackVEVO',
529                 'uploader_id': 'AfrojackVEVO',
530                 'upload_date': '20131011',
531                 'abr': 129.495,
532             },
533             'params': {
534                 'youtube_include_dash_manifest': True,
535                 'format': '141/bestaudio[ext=m4a]',
536             },
537         },
538         {
539             'url': 'https://www.youtube.com/watch?v=T4XJQO3qol8',
540             'info_dict': {
541                 'id': 'T4XJQO3qol8',
542                 'ext': 'mp4',
543                 'duration': 219,
544                 'upload_date': '20100909',
545                 'uploader': 'Amazing Atheist',
546                 'uploader_id': 'TheAmazingAtheist',
547                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/TheAmazingAtheist',
548                 'title': 'Burning Everyone\'s Koran',
549                 'description': 'SUBSCRIBE: http://www.youtube.com/saturninefilms \r\n\r\nEven Obama has taken a stand against freedom on this issue: http://www.huffingtonpost.com/2010/09/09/obama-gma-interview-quran_n_710282.html',
550             }
551         },
552         {
553             'url': 'https://youtube.com/watch?v=HtVdAasjOgU',
554             'info_dict': {
555                 'id': 'HtVdAasjOgU',
556                 'ext': 'mp4',
557                 'title': 'The Witcher 3: Wild Hunt - The Sword Of Destiny Trailer',
558                 'description': r're:(?s).{100,}About the Game\n.*?The Witcher 3: Wild Hunt.{100,}',
559                 'duration': 142,
560                 'uploader': 'The Witcher',
561                 'uploader_id': 'WitcherGame',
562                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/WitcherGame',
563                 'upload_date': '20140605',
564                 'age_limit': 18,
565             },
566         },
567         {
568             'url': 'XgnwCQzjau8',
569             'only_matching': True,
570         },
571         {
572             'url': '__2ABJjxzNo',
573             'info_dict': {
574                 'id': '__2ABJjxzNo',
575                 'ext': 'mp4',
576                 'duration': 266,
577                 'upload_date': '20100430',
578                 'uploader_id': 'deadmau5',
579                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/deadmau5',
580                 'creator': 'deadmau5',
581                 'description': 'md5:6cbcd3a92ce1bc676fc4d6ab4ace2336',
582                 'uploader': 'deadmau5',
583                 'title': 'Deadmau5 - Some Chords (HD)',
584                 'alt_title': 'Some Chords',
585             },
586             'expected_warnings': [
587                 'DASH manifest missing',
588             ]
589         },
590         {
591             'url': 'lqQg6PlCWgI',
592             'info_dict': {
593                 'id': 'lqQg6PlCWgI',
594                 'ext': 'mp4',
595                 'duration': 6085,
596                 'upload_date': '20150827',
597                 'uploader_id': 'olympic',
598                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/olympic',
599                 'description': 'HO09  - Women -  GER-AUS - Hockey - 31 July 2012 - London 2012 Olympic Games',
600                 'uploader': 'Olympic',
601                 'title': 'Hockey - Women -  GER-AUS - London 2012 Olympic Games',
602             },
603             'params': {
604                 'skip_download': 'requires avconv',
605             }
606         },
607         {
608             'url': 'https://www.youtube.com/watch?v=_b-2C3KPAM0',
609             'info_dict': {
610                 'id': '_b-2C3KPAM0',
611                 'ext': 'mp4',
612                 'stretched_ratio': 16 / 9.,
613                 'duration': 85,
614                 'upload_date': '20110310',
615                 'uploader_id': 'AllenMeow',
616                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/AllenMeow',
617                 'description': 'made by Wacom from Korea | Â≠óÂπï&amp;Âä†Ê≤πÊ∑ªÈÜã by TY\'s Allen | ÊÑüË¨ùheylisa00cavey1001ÂêåÂ≠∏ÁÜ±ÊÉÖÊèê‰æõÊ¢óÂèäÁøªË≠Ø',
618                 'uploader': 'Â≠´·Ñã·ÑÖ',
619                 'title': '[A-made] ËÆäÊÖãÂ¶çÂ≠óÂπïÁâà Â§™Â¶ç ÊàëÂ∞±ÊòØÈÄôÊ®£ÁöÑ‰∫∫',
620             },
621         },
622         {
623             'url': 'qEJwOuvDf7I',
624             'info_dict': {
625                 'id': 'qEJwOuvDf7I',
626                 'ext': 'webm',
627                 'title': '–û–±—Å—É–∂–¥–µ–Ω–∏–µ —Å—É–¥–µ–±–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–∏ –ø–æ –≤—ã–±–æ—Ä–∞–º 14 —Å–µ–Ω—Ç—è–±—Ä—è 2014 –≥–æ–¥–∞ –≤ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ',
628                 'description': '',
629                 'upload_date': '20150404',
630                 'uploader_id': 'spbelect',
631                 'uploader': '–ù–∞–±–ª—é–¥–∞—Ç–µ–ª–∏ –ü–µ—Ç–µ—Ä–±—É—Ä–≥–∞',
632             },
633             'params': {
634                 'skip_download': 'requires avconv',
635             },
636             'skip': 'This live event has ended.',
637         },
638         {
639             'url': 'https://www.youtube.com/watch?v=FIl7x6_3R5Y',
640             'info_dict': {
641                 'id': 'FIl7x6_3R5Y',
642                 'ext': 'webm',
643                 'title': 'md5:7b81415841e02ecd4313668cde88737a',
644                 'description': 'md5:116377fd2963b81ec4ce64b542173306',
645                 'duration': 220,
646                 'upload_date': '20150625',
647                 'uploader_id': 'dorappi2000',
648                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/dorappi2000',
649                 'uploader': 'dorappi2000',
650                 'formats': 'mincount:31',
651             },
652             'skip': 'not actual anymore',
653         },
654         {
655             'url': 'https://www.youtube.com/embed/CsmdDsKjzN8',
656             'md5': '8ce563a1d667b599d21064e982ab9e31',
657             'info_dict': {
658                 'id': 'CsmdDsKjzN8',
659                 'ext': 'mp4',
660                 'upload_date': '20150501',  # According to '&lt;meta itemprop="datePublished"', but in other places it's 20150510
661                 'uploader': 'Airtek',
662                 'description': 'Retransmisi√≥n en directo de la XVIII media marat√≥n de Zaragoza.',
663                 'uploader_id': 'UCzTzUmjXxxacNnL8I3m4LnQ',
664                 'title': 'Retransmisi√≥n XVIII Media marat√≥n Zaragoza 2015',
665             },
666             'params': {
667                 'youtube_include_dash_manifest': True,
668                 'format': '135',  # bestvideo
669             },
670             'skip': 'This live event has ended.',
671         },
672         {
673             'url': 'https://www.youtube.com/watch?v=jvGDaLqkpTg',
674             'info_dict': {
675                 'id': 'jvGDaLqkpTg',
676                 'title': 'Tom Clancy Free Weekend Rainbow Whatever',
677                 'description': 'md5:e03b909557865076822aa169218d6a5d',
678             },
679             'playlist': [{
680                 'info_dict': {
681                     'id': 'jvGDaLqkpTg',
682                     'ext': 'mp4',
683                     'title': 'Tom Clancy Free Weekend Rainbow Whatever (Main Camera)',
684                     'description': 'md5:e03b909557865076822aa169218d6a5d',
685                     'duration': 10643,
686                     'upload_date': '20161111',
687                     'uploader': 'Team PGP',
688                     'uploader_id': 'UChORY56LMMETTuGjXaJXvLg',
689                     'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UChORY56LMMETTuGjXaJXvLg',
690                 },
691             }, {
692                 'info_dict': {
693                     'id': '3AKt1R1aDnw',
694                     'ext': 'mp4',
695                     'title': 'Tom Clancy Free Weekend Rainbow Whatever (Camera 2)',
696                     'description': 'md5:e03b909557865076822aa169218d6a5d',
697                     'duration': 10991,
698                     'upload_date': '20161111',
699                     'uploader': 'Team PGP',
700                     'uploader_id': 'UChORY56LMMETTuGjXaJXvLg',
701                     'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UChORY56LMMETTuGjXaJXvLg',
702                 },
703             }, {
704                 'info_dict': {
705                     'id': 'RtAMM00gpVc',
706                     'ext': 'mp4',
707                     'title': 'Tom Clancy Free Weekend Rainbow Whatever (Camera 3)',
708                     'description': 'md5:e03b909557865076822aa169218d6a5d',
709                     'duration': 10995,
710                     'upload_date': '20161111',
711                     'uploader': 'Team PGP',
712                     'uploader_id': 'UChORY56LMMETTuGjXaJXvLg',
713                     'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UChORY56LMMETTuGjXaJXvLg',
714                 },
715             }, {
716                 'info_dict': {
717                     'id': '6N2fdlP3C5U',
718                     'ext': 'mp4',
719                     'title': 'Tom Clancy Free Weekend Rainbow Whatever (Camera 4)',
720                     'description': 'md5:e03b909557865076822aa169218d6a5d',
721                     'duration': 10990,
722                     'upload_date': '20161111',
723                     'uploader': 'Team PGP',
724                     'uploader_id': 'UChORY56LMMETTuGjXaJXvLg',
725                     'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UChORY56LMMETTuGjXaJXvLg',
726                 },
727             }],
728             'params': {
729                 'skip_download': True,
730             },
731         },
732         {
733             'url': 'https://www.youtube.com/watch?v=gVfLd0zydlo',
734             'info_dict': {
735                 'id': 'gVfLd0zydlo',
736                 'title': 'DevConf.cz 2016 Day 2 Workshops 1 14:00 - 15:30',
737             },
738             'playlist_count': 2,
739             'skip': 'Not multifeed anymore',
740         },
741         {
742             'url': 'https://vid.plus/FlRa-iH7PGw',
743             'only_matching': True,
744         },
745         {
746             'url': 'https://zwearz.com/watch/9lWxNJF-ufM/electra-woman-dyna-girl-official-trailer-grace-helbig.html',
747             'only_matching': True,
748         },
749         {
750             'url': 'https://www.youtube.com/watch?v=lsguqyKfVQg',
751             'info_dict': {
752                 'id': 'lsguqyKfVQg',
753                 'ext': 'mp4',
754                 'title': '{dark walk}; Loki/AC/Dishonored; collab w/Elflover21',
755                 'alt_title': 'Dark Walk - Position Music',
756                 'description': 'md5:8085699c11dc3f597ce0410b0dcbb34a',
757                 'duration': 133,
758                 'upload_date': '20151119',
759                 'uploader_id': 'IronSoulElf',
760                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/IronSoulElf',
761                 'uploader': 'IronSoulElf',
762                 'creator': 'Todd Haberman,  Daniel Law Heath and Aaron Kaplan',
763                 'track': 'Dark Walk - Position Music',
764                 'artist': 'Todd Haberman,  Daniel Law Heath and Aaron Kaplan',
765                 'album': 'Position Music - Production Music Vol. 143 - Dark Walk',
766             },
767             'params': {
768                 'skip_download': True,
769             },
770         },
771         {
772             'url': 'https://www.youtube.com/watch?v=Ms7iBXnlUO8',
773             'only_matching': True,
774         },
775         {
776             'url': 'https://www.youtube.com/watch?v=Q39EVAstoRM',
777             'info_dict': {
778                 'id': 'Q39EVAstoRM',
779                 'ext': 'mp4',
780                 'title': 'Clash Of Clans#14 Dicas De Ataque Para CV 4',
781                 'description': 'md5:ee18a25c350637c8faff806845bddee9',
782                 'upload_date': '20151107',
783                 'uploader_id': 'UCCr7TALkRbo3EtFzETQF1LA',
784                 'uploader': 'CH GAMER DROID',
785             },
786             'params': {
787                 'skip_download': True,
788             },
789             'skip': 'This video does not exist.',
790         },
791         {
792             'url': 'https://www.youtube.com/watch?v=FRhJzUSJbGI',
793             'only_matching': True,
794         },
795         {
796             'url': 'https://www.youtube.com/watch?v=M4gD1WSo5mA',
797             'info_dict': {
798                 'id': 'M4gD1WSo5mA',
799                 'ext': 'mp4',
800                 'title': 'md5:e41008789470fc2533a3252216f1c1d1',
801                 'description': 'md5:a677553cf0840649b731a3024aeff4cc',
802                 'duration': 721,
803                 'upload_date': '20150127',
804                 'uploader_id': 'BerkmanCenter',
805                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/BerkmanCenter',
806                 'uploader': 'The Berkman Klein Center for Internet &amp; Society',
807                 'license': 'Creative Commons Attribution license (reuse allowed)',
808             },
809             'params': {
810                 'skip_download': True,
811             },
812         },
813         {
814             'url': 'https://www.youtube.com/watch?v=eQcmzGIKrzg',
815             'info_dict': {
816                 'id': 'eQcmzGIKrzg',
817                 'ext': 'mp4',
818                 'title': 'Democratic Socialism and Foreign Policy | Bernie Sanders',
819                 'description': 'md5:13a2503d7b5904ef4b223aa101628f39',
820                 'duration': 4060,
821                 'upload_date': '20151119',
822                 'uploader': 'Bernie Sanders',
823                 'uploader_id': 'UCH1dpzjCEiGAt8CXkryhkZg',
824                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCH1dpzjCEiGAt8CXkryhkZg',
825                 'license': 'Creative Commons Attribution license (reuse allowed)',
826             },
827             'params': {
828                 'skip_download': True,
829             },
830         },
831         {
832             'url': 'https://www.youtube.com/watch?feature=player_embedded&amp;amp;amp;v=V36LpHqtcDY',
833             'only_matching': True,
834         },
835         {
836             'url': 'https://www.youtube.com/watch?v=i1Ko8UG-Tdo',
837             'only_matching': True,
838         },
839         {
840             'url': 'https://www.youtube.com/watch?v=yYr8q0y5Jfg',
841             'info_dict': {
842                 'id': 'uGpuVWrhIzE',
843                 'ext': 'mp4',
844                 'title': 'Piku - Trailer',
845                 'description': 'md5:c36bd60c3fd6f1954086c083c72092eb',
846                 'upload_date': '20150811',
847                 'uploader': 'FlixMatrix',
848                 'uploader_id': 'FlixMatrixKaravan',
849                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/FlixMatrixKaravan',
850                 'license': 'Standard YouTube License',
851             },
852             'params': {
853                 'skip_download': True,
854             },
855             'skip': 'This video is not available.',
856         },
857         {
858             'url': 'https://www.youtube.com/watch?v=iqKdEhx-dD4',
859             'info_dict': {
860                 'id': 'iqKdEhx-dD4',
861                 'ext': 'mp4',
862                 'title': 'Isolation - Mind Field (Ep 1)',
863                 'description': 'md5:f540112edec5d09fc8cc752d3d4ba3cd',
864                 'duration': 2085,
865                 'upload_date': '20170118',
866                 'uploader': 'Vsauce',
867                 'uploader_id': 'Vsauce',
868                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/Vsauce',
869                 'series': 'Mind Field',
870                 'season_number': 1,
871                 'episode_number': 1,
872             },
873             'params': {
874                 'skip_download': True,
875             },
876             'expected_warnings': [
877                 'Skipping DASH manifest',
878             ],
879         },
880         {
881             'url': 'https://www.youtube.com/watch?v=6SJNVb0GnPI',
882             'info_dict': {
883                 'id': '6SJNVb0GnPI',
884                 'ext': 'mp4',
885                 'title': 'Race Differences in Intelligence',
886                 'description': 'md5:5d161533167390427a1f8ee89a1fc6f1',
887                 'duration': 965,
888                 'upload_date': '20140124',
889                 'uploader': 'New Century Foundation',
890                 'uploader_id': 'UCEJYpZGqgUob0zVVEaLhvVg',
891                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCEJYpZGqgUob0zVVEaLhvVg',
892             },
893             'params': {
894                 'skip_download': True,
895             },
896             'skip': 'This video has been removed for violating YouTube\'s policy on hate speech.',
897         },
898         {
899             'url': '1t24XAntNCY',
900             'only_matching': True,
901         },
902         {
903             'url': 'sJL6WA-aGkQ',
904             'only_matching': True,
905         },
906         {
907             'url': 'https://invidio.us/watch?v=BaW_jenozKc',
908             'only_matching': True,
909         },
910         {
911             'url': 'https://redirect.invidious.io/watch?v=BaW_jenozKc',
912             'only_matching': True,
913         },
914         {
915             'url': 'https://redirect.invidious.io/Yh0AhrY9GjA',
916             'only_matching': True,
917         },
918         {
919             'url': 'https://www.youtube.com/watch?v=s7_qI6_mIXc',
920             'only_matching': True,
921         },
922         {
923             'url': 'https://www.youtube.com/watch?v=Z4Vy8R84T1U',
924             'info_dict': {
925                 'id': 'Z4Vy8R84T1U',
926                 'ext': 'mp4',
927                 'title': 'saman SMAN 53 Jakarta(Sancety) opening COFFEE4th at SMAN 53 Jakarta',
928                 'description': 'md5:d41d8cd98f00b204e9800998ecf8427e',
929                 'duration': 433,
930                 'upload_date': '20130923',
931                 'uploader': 'Amelia Putri Harwita',
932                 'uploader_id': 'UCpOxM49HJxmC1qCalXyB3_Q',
933                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCpOxM49HJxmC1qCalXyB3_Q',
934                 'formats': 'maxcount:10',
935             },
936             'params': {
937                 'skip_download': True,
938                 'youtube_include_dash_manifest': False,
939             },
940             'skip': 'not actual anymore',
941         },
942         {
943             'url': 'https://music.youtube.com/watch?v=MgNrAu2pzNs',
944             'info_dict': {
945                 'id': 'MgNrAu2pzNs',
946                 'ext': 'mp4',
947                 'title': 'Voyeur Girl',
948                 'description': 'md5:7ae382a65843d6df2685993e90a8628f',
949                 'upload_date': '20190312',
950                 'uploader': 'Stephen - Topic',
951                 'uploader_id': 'UC-pWHpBjdGG69N9mM2auIAA',
952                 'artist': 'Stephen',
953                 'track': 'Voyeur Girl',
954                 'album': 'it\'s too much love to know my dear',
955                 'release_date': '20190313',
956                 'release_year': 2019,
957             },
958             'params': {
959                 'skip_download': True,
960             },
961         },
962         {
963             'url': 'https://www.youtubekids.com/watch?v=3b8nCWDgZ6Q',
964             'only_matching': True,
965         },
966         {
967             'url': 'DJztXj2GPfl',
968             'info_dict': {
969                 'id': 'DJztXj2GPfk',
970                 'ext': 'mp4',
971                 'title': 'Panjabi MC - Mundian To Bach Ke (The Dictator Soundtrack)',
972                 'description': 'md5:bf577a41da97918e94fa9798d9228825',
973                 'upload_date': '20090125',
974                 'uploader': 'Prochorowka',
975                 'uploader_id': 'Prochorowka',
976                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/Prochorowka',
977                 'artist': 'Panjabi MC',
978                 'track': 'Beware of the Boys (Mundian to Bach Ke) - Motivo Hi-Lectro Remix',
979                 'album': 'Beware of the Boys (Mundian To Bach Ke)',
980             },
981             'params': {
982                 'skip_download': True,
983             },
984             'skip': 'Video unavailable',
985         },
986         {
987             'url': 'https://www.youtube.com/watch?v=x41yOUIvK2k',
988             'info_dict': {
989                 'id': 'x41yOUIvK2k',
990                 'ext': 'mp4',
991                 'title': 'IMG 3456',
992                 'description': '',
993                 'upload_date': '20170613',
994                 'uploader_id': 'ElevageOrVert',
995                 'uploader': 'ElevageOrVert',
996             },
997             'params': {
998                 'skip_download': True,
999             },
1000         },
1001         {
1002             'url': 'https://www.youtube.com/watch?v=CHqg6qOn4no',
1003             'info_dict': {
1004                 'id': 'CHqg6qOn4no',
1005                 'ext': 'mp4',
1006                 'title': 'Part 77   Sort a list of simple types in c#',
1007                 'description': 'md5:b8746fa52e10cdbf47997903f13b20dc',
1008                 'upload_date': '20130831',
1009                 'uploader_id': 'kudvenkat',
1010                 'uploader': 'kudvenkat',
1011             },
1012             'params': {
1013                 'skip_download': True,
1014             },
1015         },
1016         {
1017             'url': 'https://www.youtube.com/watch?v=gVfgbahppCY',
1018             'only_matching': True,
1019         },
1020         {
1021             'url': 'https://www.youtube.com/watch_popup?v=63RmMXCd_bQ',
1022             'only_matching': True,
1023         },
1024         {
1025             'url': 'OtqTfy26tG0',
1026             'info_dict': {
1027                 'id': 'OtqTfy26tG0',
1028                 'ext': 'mp4',
1029                 'title': 'Burn Out',
1030                 'description': 'md5:8d07b84dcbcbfb34bc12a56d968b6131',
1031                 'upload_date': '20141120',
1032                 'uploader': 'The Cinematic Orchestra - Topic',
1033                 'uploader_id': 'UCIzsJBIyo8hhpFm1NK0uLgw',
1034                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCIzsJBIyo8hhpFm1NK0uLgw',
1035                 'artist': 'The Cinematic Orchestra',
1036                 'track': 'Burn Out',
1037                 'album': 'Every Day',
1038                 'release_data': None,
1039                 'release_year': None,
1040             },
1041             'params': {
1042                 'skip_download': True,
1043             },
1044         },
1045         {
1046             'url': 'https://www.youtube.com/watch?v=nGC3D_FkCmg',
1047             'only_matching': True,
1048         },
1049         {
1050             'url': 'cBvYw8_A0vQ',
1051             'info_dict': {
1052                 'id': 'cBvYw8_A0vQ',
1053                 'ext': 'mp4',
1054                 'title': '4K Ueno Okachimachi  Street  Scenes  ‰∏äÈáéÂæ°ÂæíÁî∫Ê≠©„Åç',
1055                 'description': 'md5:ea770e474b7cd6722b4c95b833c03630',
1056                 'upload_date': '20201120',
1057                 'uploader': 'Walk around Japan',
1058                 'uploader_id': 'UC3o_t8PzBmXf5S9b7GLx1Mw',
1059                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UC3o_t8PzBmXf5S9b7GLx1Mw',
1060             },
1061             'params': {
1062                 'skip_download': True,
1063             },
1064         },
1065         {
1066             'url': 'https://youtube.com/shorts/4L2J27mJ3Dc',
1067             'info_dict': {
1068                 'id': '4L2J27mJ3Dc',
1069                 'ext': 'mp4',
1070                 'upload_date': '20211025',
1071                 'uploader': 'Charlie Berens',
1072                 'description': 'md5:976512b8a29269b93bbd8a61edc45a6d',
1073                 'uploader_id': 'fivedlrmilkshake',
1074                 'title': 'Midwest Squid Game #Shorts',
1075             },
1076             'params': {
1077                 'skip_download': True,
1078             },
1079         },
1080     ]
1081     _formats = {
1082         '5': {'ext': 'flv', 'width': 400, 'height': 240, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263'},
1083         '6': {'ext': 'flv', 'width': 450, 'height': 270, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263'},
1084         '13': {'ext': '3gp', 'acodec': 'aac', 'vcodec': 'mp4v'},
1085         '17': {'ext': '3gp', 'width': 176, 'height': 144, 'acodec': 'aac', 'abr': 24, 'vcodec': 'mp4v'},
1086         '18': {'ext': 'mp4', 'width': 640, 'height': 360, 'acodec': 'aac', 'abr': 96, 'vcodec': 'h264'},
1087         '22': {'ext': 'mp4', 'width': 1280, 'height': 720, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},
1088         '34': {'ext': 'flv', 'width': 640, 'height': 360, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
1089         '35': {'ext': 'flv', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
1090         '36': {'ext': '3gp', 'width': 320, 'acodec': 'aac', 'vcodec': 'mp4v'},
1091         '37': {'ext': 'mp4', 'width': 1920, 'height': 1080, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},
1092         '38': {'ext': 'mp4', 'width': 4096, 'height': 3072, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},
1093         '43': {'ext': 'webm', 'width': 640, 'height': 360, 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8'},
1094         '44': {'ext': 'webm', 'width': 854, 'height': 480, 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8'},
1095         '45': {'ext': 'webm', 'width': 1280, 'height': 720, 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8'},
1096         '46': {'ext': 'webm', 'width': 1920, 'height': 1080, 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8'},
1097         '59': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
1098         '78': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
1099         '82': {'ext': 'mp4', 'height': 360, 'format_note': '3D', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -20},
1100         '83': {'ext': 'mp4', 'height': 480, 'format_note': '3D', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -20},
1101         '84': {'ext': 'mp4', 'height': 720, 'format_note': '3D', 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264', 'preference': -20},
1102         '85': {'ext': 'mp4', 'height': 1080, 'format_note': '3D', 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264', 'preference': -20},
1103         '100': {'ext': 'webm', 'height': 360, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8', 'preference': -20},
1104         '101': {'ext': 'webm', 'height': 480, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8', 'preference': -20},
1105         '102': {'ext': 'webm', 'height': 720, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8', 'preference': -20},
1106         '91': {'ext': 'mp4', 'height': 144, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},
1107         '92': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},
1108         '93': {'ext': 'mp4', 'height': 360, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -10},
1109         '94': {'ext': 'mp4', 'height': 480, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -10},
1110         '95': {'ext': 'mp4', 'height': 720, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 256, 'vcodec': 'h264', 'preference': -10},
1111         '96': {'ext': 'mp4', 'height': 1080, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 256, 'vcodec': 'h264', 'preference': -10},
1112         '132': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},
1113         '151': {'ext': 'mp4', 'height': 72, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 24, 'vcodec': 'h264', 'preference': -10},
1114         '133': {'ext': 'mp4', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'h264'},
1115         '134': {'ext': 'mp4', 'height': 360, 'format_note': 'DASH video', 'vcodec': 'h264'},
1116         '135': {'ext': 'mp4', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'h264'},
1117         '136': {'ext': 'mp4', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'h264'},
1118         '137': {'ext': 'mp4', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'h264'},
1119         '138': {'ext': 'mp4', 'format_note': 'DASH video', 'vcodec': 'h264'},  # Height can vary (https://github.com/ytdl-org/youtube-dl/issues/4559)
1120         '160': {'ext': 'mp4', 'height': 144, 'format_note': 'DASH video', 'vcodec': 'h264'},
1121         '212': {'ext': 'mp4', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'h264'},
1122         '264': {'ext': 'mp4', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'h264'},
1123         '298': {'ext': 'mp4', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'h264', 'fps': 60},
1124         '299': {'ext': 'mp4', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'h264', 'fps': 60},
1125         '266': {'ext': 'mp4', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'h264'},
1126         '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 48, 'container': 'm4a_dash'},
1127         '140': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 128, 'container': 'm4a_dash'},
1128         '141': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 256, 'container': 'm4a_dash'},
1129         '256': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'container': 'm4a_dash'},
1130         '258': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'container': 'm4a_dash'},
1131         '325': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'dtse', 'container': 'm4a_dash'},
1132         '328': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'ec-3', 'container': 'm4a_dash'},
1133         '167': {'ext': 'webm', 'height': 360, 'width': 640, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1134         '168': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1135         '169': {'ext': 'webm', 'height': 720, 'width': 1280, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1136         '170': {'ext': 'webm', 'height': 1080, 'width': 1920, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1137         '218': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1138         '219': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1139         '278': {'ext': 'webm', 'height': 144, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp9'},
1140         '242': {'ext': 'webm', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1141         '243': {'ext': 'webm', 'height': 360, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1142         '244': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1143         '245': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1144         '246': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1145         '247': {'ext': 'webm', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1146         '248': {'ext': 'webm', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1147         '271': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1148         '272': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1149         '302': {'ext': 'webm', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},
1150         '303': {'ext': 'webm', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},
1151         '308': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},
1152         '313': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1153         '315': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},
1154         '171': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 128},
1155         '172': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 256},
1156         '249': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 50},
1157         '250': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 70},
1158         '251': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 160},
1159         '_rtmp': {'protocol': 'rtmp'},
1160         '394': {'acodec': 'none', 'vcodec': 'av01.0.05M.08'},
1161         '395': {'acodec': 'none', 'vcodec': 'av01.0.05M.08'},
1162         '396': {'acodec': 'none', 'vcodec': 'av01.0.05M.08'},
1163         '397': {'acodec': 'none', 'vcodec': 'av01.0.05M.08'},
1164     }
1165     @classmethod
1166     def suitable(cls, url):
1167         from .youtube import parse_qs
1168         qs = parse_qs(url)
1169         if qs.get('list', [None])[0]:
1170             return False
1171         return super(YoutubeIE, cls).suitable(url)
1172     def __init__(self, *args, **kwargs):
1173         super(YoutubeIE, self).__init__(*args, **kwargs)
1174         self._code_cache = {}
1175         self._player_cache = {}
1176     def _signature_cache_id(self, example_sig):
1177         return '.'.join(compat_str(len(part)) for part in example_sig.split('.'))
1178     @classmethod
1179     def _extract_player_info(cls, player_url):
1180         for player_re in cls._PLAYER_INFO_RE:
1181             id_m = re.search(player_re, player_url)
1182             if id_m:
1183                 break
1184         else:
1185             raise ExtractorError('Cannot identify player %r' % player_url)
1186         return id_m.group('id')
1187     def _get_player_code(self, video_id, player_url, player_id=None):
1188         if not player_id:
1189             player_id = self._extract_player_info(player_url)
1190         if player_id not in self._code_cache:
1191             self._code_cache[player_id] = self._download_webpage(
1192                 player_url, video_id,
1193                 note='Downloading player ' + player_id,
1194                 errnote='Download of %s failed' % player_url)
1195         return self._code_cache[player_id]
1196     def _extract_signature_function(self, video_id, player_url, example_sig):
1197         player_id = self._extract_player_info(player_url)
1198         func_id = 'js_%s_%s' % (
1199             player_id, self._signature_cache_id(example_sig))
1200         assert os.path.basename(func_id) == func_id
1201         cache_spec = self._downloader.cache.load('youtube-sigfuncs', func_id)
1202         if cache_spec is not None:
1203             return lambda s: ''.join(s[i] for i in cache_spec)
1204         code = self._get_player_code(video_id, player_url, player_id)
1205         res = self._parse_sig_js(code)
1206         test_string = ''.join(map(compat_chr, range(len(example_sig))))
1207         cache_res = res(test_string)
1208         cache_spec = [ord(c) for c in cache_res]
1209         self._downloader.cache.store('youtube-sigfuncs', func_id, cache_spec)
1210         return res
1211     def _print_sig_code(self, func, example_sig):
1212         def gen_sig_code(idxs):
1213             def _genslice(start, end, step):
1214                 starts = '' if start == 0 else str(start)
1215                 ends = (':%d' % (end + step)) if end + step &gt;= 0 else ':'
1216                 steps = '' if step == 1 else (':%d' % step)
1217                 return 's[%s%s%s]' % (starts, ends, steps)
1218             step = None
1219             start = '(Never used)'
1220             for i, prev in zip(idxs[1:], idxs[:-1]):
1221                 if step is not None:
1222                     if i - prev == step:
1223                         continue
1224                     yield _genslice(start, prev, step)
1225                     step = None
1226                     continue
1227                 if i - prev in [-1, 1]:
1228                     step = i - prev
1229                     start = prev
1230                     continue
1231                 else:
1232                     yield 's[%d]' % prev
1233             if step is None:
1234                 yield 's[%d]' % i
1235             else:
1236                 yield _genslice(start, i, step)
1237         test_string = ''.join(map(compat_chr, range(len(example_sig))))
1238         cache_res = func(test_string)
1239         cache_spec = [ord(c) for c in cache_res]
1240         expr_code = ' + '.join(gen_sig_code(cache_spec))
1241         signature_id_tuple = '(%s)' % (
1242             ', '.join(compat_str(len(p)) for p in example_sig.split('.')))
1243         code = ('if tuple(len(p) for p in s.split(\'.\')) == %s:\n'
1244                 '    return %s\n') % (signature_id_tuple, expr_code)
1245         self.to_screen('Extracted signature function:\n' + code)
1246     def _parse_sig_js(self, jscode):
1247         funcname = self._search_regex(
1248             (r'\b[cs]\s*&amp;&amp;\s*[adf]\.set\([^,]+\s*,\s*encodeURIComponent\s*\(\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1249              r'\b[a-zA-Z0-9]+\s*&amp;&amp;\s*[a-zA-Z0-9]+\.set\([^,]+\s*,\s*encodeURIComponent\s*\(\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1250              r'\bm=(?P&lt;sig&gt;[a-zA-Z0-9$]{2,})\(decodeURIComponent\(h\.s\)\)',
1251              r'\bc&amp;&amp;\(c=(?P&lt;sig&gt;[a-zA-Z0-9$]{2,})\(decodeURIComponent\(c\)\)',
1252              r'(?:\b|[^a-zA-Z0-9$])(?P&lt;sig&gt;[a-zA-Z0-9$]{2,})\s*=\s*function\(\s*a\s*\)\s*{\s*a\s*=\s*a\.split\(\s*""\s*\);[a-zA-Z0-9$]{2}\.[a-zA-Z0-9$]{2}\(a,\d+\)',
1253              r'(?:\b|[^a-zA-Z0-9$])(?P&lt;sig&gt;[a-zA-Z0-9$]{2,})\s*=\s*function\(\s*a\s*\)\s*{\s*a\s*=\s*a\.split\(\s*""\s*\)',
1254              r'(?P&lt;sig&gt;[a-zA-Z0-9$]+)\s*=\s*function\(\s*a\s*\)\s*{\s*a\s*=\s*a\.split\(\s*""\s*\)',
1255              r'(["\'])signature\1\s*,\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1256              r'\.sig\|\|(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1257              r'yt\.akamaized\.net/\)\s*\|\|\s*.*?\s*[cs]\s*&amp;&amp;\s*[adf]\.set\([^,]+\s*,\s*(?:encodeURIComponent\s*\()?\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1258              r'\b[cs]\s*&amp;&amp;\s*[adf]\.set\([^,]+\s*,\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1259              r'\b[a-zA-Z0-9]+\s*&amp;&amp;\s*[a-zA-Z0-9]+\.set\([^,]+\s*,\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1260              r'\bc\s*&amp;&amp;\s*a\.set\([^,]+\s*,\s*\([^)]*\)\s*\(\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1261              r'\bc\s*&amp;&amp;\s*[a-zA-Z0-9]+\.set\([^,]+\s*,\s*\([^)]*\)\s*\(\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1262              r'\bc\s*&amp;&amp;\s*[a-zA-Z0-9]+\.set\([^,]+\s*,\s*\([^)]*\)\s*\(\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\('),
1263             jscode, 'Initial JS player signature function name', group='sig')
1264         jsi = JSInterpreter(jscode)
1265         initial_function = jsi.extract_function(funcname)
1266         return lambda s: initial_function([s])
1267     def _decrypt_signature(self, s, video_id, player_url):
1268         if player_url is None:
1269             raise ExtractorError('Cannot decrypt signature without player_url')
1270         try:
1271             player_id = (player_url, self._signature_cache_id(s))
1272             if player_id not in self._player_cache:
1273                 func = self._extract_signature_function(
1274                     video_id, player_url, s
1275                 )
1276                 self._player_cache[player_id] = func
1277             func = self._player_cache[player_id]
1278             if self._downloader.params.get('youtube_print_sig_code'):
1279                 self._print_sig_code(func, s)
1280             return func(s)
1281         except Exception as e:
1282             tb = traceback.format_exc()
1283             raise ExtractorError(
1284                 'Signature extraction failed: ' + tb, cause=e)
1285     def _extract_player_url(self, webpage):
1286         player_url = self._search_regex(
1287             r'"(?:PLAYER_JS_URL|jsUrl)"\s*:\s*"([^"]+)"',
1288             webpage or '', 'player URL', fatal=False)
1289         if not player_url:
1290             return
1291         if player_url.startswith('//'):
1292             player_url = 'https:' + player_url
1293         elif not re.match(r'https?://', player_url):
1294             player_url = compat_urlparse.urljoin(
1295                 'https://www.youtube.com', player_url)
1296         return player_url
1297     def _extract_n_function_name(self, jscode):
1298         target = r'(?P&lt;nfunc&gt;[a-zA-Z0-9$]{3})(?:\[(?P&lt;idx&gt;\d+)\])?'
1299         nfunc_and_idx = self._search_regex(
1300             r'\.get\("n"\)\)&amp;&amp;\(b=(%s)\([a-zA-Z0-9]\)' % (target, ),
1301             jscode, 'Initial JS player n function name')
1302         nfunc, idx = re.match(target, nfunc_and_idx).group('nfunc', 'idx')
1303         if not idx:
1304             return nfunc
1305         return self._parse_json(self._search_regex(
1306             r'var %s\s*=\s*(\[.+?\]);' % (nfunc, ), jscode,
1307             'Initial JS player n function list ({nfunc}[{idx}])'.format(**locals())), nfunc, transform_source=js_to_json)[int(idx)]
1308     def _extract_n_function(self, video_id, player_url):
1309         player_id = self._extract_player_info(player_url)
1310         func_code = self._downloader.cache.load('youtube-nsig', player_id)
1311         if func_code:
1312             jsi = JSInterpreter(func_code)
1313         else:
1314             player_id = self._extract_player_info(player_url)
1315             jscode = self._get_player_code(video_id, player_url, player_id)
1316             funcname = self._extract_n_function_name(jscode)
1317             jsi = JSInterpreter(jscode)
1318             func_code = jsi.extract_function_code(funcname)
1319             self._downloader.cache.store('youtube-nsig', player_id, func_code)
1320         if self._downloader.params.get('youtube_print_sig_code'):
1321             self.to_screen('Extracted nsig function from {0}:\n{1}\n'.format(player_id, func_code[1]))
1322         return lambda s: jsi.extract_function_from_code(*func_code)([s])
1323     def _n_descramble(self, n_param, player_url, video_id):
1324         sig_id = ('nsig_value', n_param)
1325         if sig_id in self._player_cache:
1326             return self._player_cache[sig_id]
1327         try:
1328             player_id = ('nsig', player_url)
1329             if player_id not in self._player_cache:
1330                 self._player_cache[player_id] = self._extract_n_function(video_id, player_url)
1331             func = self._player_cache[player_id]
1332             self._player_cache[sig_id] = func(n_param)
1333             if self._downloader.params.get('verbose', False):
1334                 self._downloader.to_screen('[debug] [%s] %s' % (self.IE_NAME, 'Decrypted nsig {0} =&gt; {1}'.format(n_param, self._player_cache[sig_id])))
1335             return self._player_cache[sig_id]
1336         except Exception as e:
1337             self._downloader.report_warning(
1338                 '[%s] %s (%s %s)' % (
1339                     self.IE_NAME,
1340                     'Unable to decode n-parameter: download likely to be throttled',
1341                     error_to_compat_str(e),
1342                     traceback.format_exc()))
1343     def _unthrottle_format_urls(self, video_id, player_url, formats):
1344         for fmt in formats:
1345             parsed_fmt_url = compat_urlparse.urlparse(fmt['url'])
1346             qs = compat_urlparse.parse_qs(parsed_fmt_url.query)
1347             n_param = qs.get('n')
1348             if not n_param:
1349                 continue
1350             n_param = n_param[-1]
1351             n_response = self._n_descramble(n_param, player_url, video_id)
1352             if n_response:
1353                 qs['n'] = [n_response]
1354                 fmt['url'] = compat_urlparse.urlunparse(
1355                     parsed_fmt_url._replace(query=compat_urllib_parse_urlencode(qs, True)))
1356     def _mark_watched(self, video_id, player_response):
1357         playback_url = url_or_none(try_get(
1358             player_response,
1359             lambda x: x['playbackTracking']['videostatsPlaybackUrl']['baseUrl']))
1360         if not playback_url:
1361             return
1362         parsed_playback_url = compat_urlparse.urlparse(playback_url)
1363         qs = compat_urlparse.parse_qs(parsed_playback_url.query)
1364         CPN_ALPHABET = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_'
1365         cpn = ''.join((CPN_ALPHABET[random.randint(0, 256) &amp; 63] for _ in range(0, 16)))
1366         qs.update({
1367             'ver': ['2'],
1368             'cpn': [cpn],
1369         })
1370         playback_url = compat_urlparse.urlunparse(
1371             parsed_playback_url._replace(query=compat_urllib_parse_urlencode(qs, True)))
1372         self._download_webpage(
1373             playback_url, video_id, 'Marking watched',
1374             'Unable to mark watched', fatal=False)
1375     @staticmethod
1376     def _extract_urls(webpage):
1377         entries = [
1378             unescapeHTML(mobj.group('url'))
1379             for mobj in re.finditer(r'''(?x)
1380             (?:
1381                 &lt;iframe[^&gt;]+?src=|
1382                 data-video-url=|
1383                 &lt;embed[^&gt;]+?src=|
1384                 embedSWF\(?:\s*|
1385                 &lt;object[^&gt;]+data=|
1386                 new\s+SWFObject\(
1387             )
1388             (["\'])
1389                 (?P&lt;url&gt;(?:https?:)?//(?:www\.)?youtube(?:-nocookie)?\.com/
1390                 (?:embed|v|p)/[0-9A-Za-z_-]{11}.*?)
1391             \1''', webpage)]
1392         entries.extend(list(map(
1393             unescapeHTML,
1394             re.findall(r'class="lazyYT" data-youtube-id="([^"]+)"', webpage))))
1395         matches = re.findall(r'''(?x)&lt;div[^&gt;]+
1396             class=(?P&lt;q1&gt;[\'"])[^\'"]*\byvii_single_video_player\b[^\'"]*(?P=q1)[^&gt;]+
1397             data-video_id=(?P&lt;q2&gt;[\'"])([^\'"]+)(?P=q2)''', webpage)
1398         entries.extend(m[-1] for m in matches)
1399         return entries
1400     @staticmethod
1401     def _extract_url(webpage):
1402         urls = YoutubeIE._extract_urls(webpage)
1403         return urls[0] if urls else None
1404     @classmethod
1405     def extract_id(cls, url):
1406         mobj = re.match(cls._VALID_URL, url, re.VERBOSE)
1407         if mobj is None:
1408             raise ExtractorError('Invalid URL: %s' % url)
1409         video_id = mobj.group(2)
1410         return video_id
1411     def _extract_chapters_from_json(self, data, video_id, duration):
1412         chapters_list = try_get(
1413             data,
1414             lambda x: x['playerOverlays']
1415                        ['playerOverlayRenderer']
1416                        ['decoratedPlayerBarRenderer']
1417                        ['decoratedPlayerBarRenderer']
1418                        ['playerBar']
1419                        ['chapteredPlayerBarRenderer']
1420                        ['chapters'],
1421             list)
1422         if not chapters_list:
1423             return
1424         def chapter_time(chapter):
1425             return float_or_none(
1426                 try_get(
1427                     chapter,
1428                     lambda x: x['chapterRenderer']['timeRangeStartMillis'],
1429                     int),
1430                 scale=1000)
1431         chapters = []
1432         for next_num, chapter in enumerate(chapters_list, start=1):
1433             start_time = chapter_time(chapter)
1434             if start_time is None:
1435                 continue
1436             end_time = (chapter_time(chapters_list[next_num])
1437                         if next_num &lt; len(chapters_list) else duration)
1438             if end_time is None:
1439                 continue
1440             title = try_get(
1441                 chapter, lambda x: x['chapterRenderer']['title']['simpleText'],
1442                 compat_str)
1443             chapters.append({
1444                 'start_time': start_time,
1445                 'end_time': end_time,
1446                 'title': title,
1447             })
1448         return chapters
1449     def _extract_yt_initial_variable(self, webpage, regex, video_id, name):
1450         return self._parse_json(self._search_regex(
1451             (r'%s\s*%s' % (regex, self._YT_INITIAL_BOUNDARY_RE),
1452              regex), webpage, name, default='{}'), video_id, fatal=False)
1453     def _real_extract(self, url):
1454         url, smuggled_data = unsmuggle_url(url, {})
1455         video_id = self._match_id(url)
1456         base_url = self.http_scheme() + '//www.youtube.com/'
1457         webpage_url = base_url + 'watch?v=' + video_id
1458         webpage = self._download_webpage(
1459             webpage_url + '&amp;bpctr=9999999999&amp;has_verified=1', video_id, fatal=False)
1460         player_response = None
1461         if webpage:
1462             player_response = self._extract_yt_initial_variable(
1463                 webpage, self._YT_INITIAL_PLAYER_RESPONSE_RE,
1464                 video_id, 'initial player response')
1465         if not player_response:
1466             player_response = self._call_api(
1467                 'player', {'videoId': video_id}, video_id)
1468         playability_status = player_response.get('playabilityStatus') or {}
1469         if playability_status.get('reason') == 'Sign in to confirm your age':
1470             video_info = self._download_webpage(
1471                 base_url + 'get_video_info', video_id,
1472                 'Refetching age-gated info webpage',
1473                 'unable to download video info webpage', query={
1474                     'video_id': video_id,
1475                     'eurl': 'https://youtube.googleapis.com/v/' + video_id,
1476                     'html5': 1,
1477                     'c': 'TVHTML5',
1478                     'cver': '6.20180913',
1479                 }, fatal=False)
1480             if video_info:
1481                 pr = self._parse_json(
1482                     try_get(
1483                         compat_parse_qs(video_info),
1484                         lambda x: x['player_response'][0], compat_str) or '{}',
1485                     video_id, fatal=False)
1486                 if pr and isinstance(pr, dict):
1487                     player_response = pr
1488         trailer_video_id = try_get(
1489             playability_status,
1490             lambda x: x['errorScreen']['playerLegacyDesktopYpcTrailerRenderer']['trailerVideoId'],
1491             compat_str)
1492         if trailer_video_id:
1493             return self.url_result(
1494                 trailer_video_id, self.ie_key(), trailer_video_id)
1495         def get_text(x):
1496             if not x:
1497                 return
1498             text = x.get('simpleText')
1499             if text and isinstance(text, compat_str):
1500                 return text
1501             runs = x.get('runs')
1502             if not isinstance(runs, list):
1503                 return
1504             return ''.join([r['text'] for r in runs if isinstance(r.get('text'), compat_str)])
1505         search_meta = (
1506             lambda x: self._html_search_meta(x, webpage, default=None)) \
1507             if webpage else lambda x: None
1508         video_details = player_response.get('videoDetails') or {}
1509         microformat = try_get(
1510             player_response,
1511             lambda x: x['microformat']['playerMicroformatRenderer'],
1512             dict) or {}
1513         video_title = video_details.get('title') \
1514             or get_text(microformat.get('title')) \
1515             or search_meta(['og:title', 'twitter:title', 'title'])
1516         video_description = video_details.get('shortDescription')
1517         if not smuggled_data.get('force_singlefeed', False):
1518             if not self._downloader.params.get('noplaylist'):
1519                 multifeed_metadata_list = try_get(
1520                     player_response,
1521                     lambda x: x['multicamera']['playerLegacyMulticameraRenderer']['metadataList'],
1522                     compat_str)
1523                 if multifeed_metadata_list:
1524                     entries = []
1525                     feed_ids = []
1526                     for feed in multifeed_metadata_list.split(','):
1527                         feed_data = compat_parse_qs(
1528                             compat_urllib_parse_unquote_plus(feed))
1529                         def feed_entry(name):
1530                             return try_get(
1531                                 feed_data, lambda x: x[name][0], compat_str)
1532                         feed_id = feed_entry('id')
1533                         if not feed_id:
1534                             continue
1535                         feed_title = feed_entry('title')
1536                         title = video_title
1537                         if feed_title:
1538                             title += ' (%s)' % feed_title
1539                         entries.append({
1540                             '_type': 'url_transparent',
1541                             'ie_key': 'Youtube',
1542                             'url': smuggle_url(
1543                                 base_url + 'watch?v=' + feed_data['id'][0],
1544                                 {'force_singlefeed': True}),
1545                             'title': title,
1546                         })
1547                         feed_ids.append(feed_id)
1548                     self.to_screen(
1549                         'Downloading multifeed video (%s) - add --no-playlist to just download video %s'
1550                         % (', '.join(feed_ids), video_id))
1551                     return self.playlist_result(
1552                         entries, video_id, video_title, video_description)
1553             else:
1554                 self.to_screen('Downloading just video %s because of --no-playlist' % video_id)
1555         formats = []
1556         itags = []
1557         itag_qualities = {}
1558         player_url = None
1559         q = qualities(['tiny', 'small', 'medium', 'large', 'hd720', 'hd1080', 'hd1440', 'hd2160', 'hd2880', 'highres'])
1560         streaming_data = player_response.get('streamingData') or {}
1561         streaming_formats = streaming_data.get('formats') or []
1562         streaming_formats.extend(streaming_data.get('adaptiveFormats') or [])
1563         for fmt in streaming_formats:
1564             if fmt.get('targetDurationSec') or fmt.get('drmFamilies'):
1565                 continue
1566             itag = str_or_none(fmt.get('itag'))
1567             quality = fmt.get('quality')
1568             if itag and quality:
1569                 itag_qualities[itag] = quality
1570             if fmt.get('type') == 'FORMAT_STREAM_TYPE_OTF':
1571                 continue
1572             fmt_url = fmt.get('url')
1573             if not fmt_url:
1574                 sc = compat_parse_qs(fmt.get('signatureCipher'))
1575                 fmt_url = url_or_none(try_get(sc, lambda x: x['url'][0]))
1576                 encrypted_sig = try_get(sc, lambda x: x['s'][0])
1577                 if not (sc and fmt_url and encrypted_sig):
1578                     continue
1579                 if not player_url:
1580                     player_url = self._extract_player_url(webpage)
1581                 if not player_url:
1582                     continue
1583                 signature = self._decrypt_signature(sc['s'][0], video_id, player_url)
1584                 sp = try_get(sc, lambda x: x['sp'][0]) or 'signature'
1585                 fmt_url += '&amp;' + sp + '=' + signature
1586             if itag:
1587                 itags.append(itag)
1588             tbr = float_or_none(
1589                 fmt.get('averageBitrate') or fmt.get('bitrate'), 1000)
1590             dct = {
1591                 'asr': int_or_none(fmt.get('audioSampleRate')),
1592                 'filesize': int_or_none(fmt.get('contentLength')),
1593                 'format_id': itag,
1594                 'format_note': fmt.get('qualityLabel') or quality,
1595                 'fps': int_or_none(fmt.get('fps')),
1596                 'height': int_or_none(fmt.get('height')),
1597                 'quality': q(quality),
1598                 'tbr': tbr,
1599                 'url': fmt_url,
1600                 'width': fmt.get('width'),
1601             }
1602             mimetype = fmt.get('mimeType')
1603             if mimetype:
1604                 mobj = re.match(
1605                     r'((?:[^/]+)/(?:[^;]+))(?:;\s*codecs="([^"]+)")?', mimetype)
1606                 if mobj:
1607                     dct['ext'] = mimetype2ext(mobj.group(1))
1608                     dct.update(parse_codecs(mobj.group(2)))
1609             no_audio = dct.get('acodec') == 'none'
1610             no_video = dct.get('vcodec') == 'none'
1611             if no_audio:
1612                 dct['vbr'] = tbr
1613             if no_video:
1614                 dct['abr'] = tbr
1615             if no_audio or no_video:
1616                 dct['downloader_options'] = {
1617                     'http_chunk_size': 10485760,
1618                 }
1619                 if dct.get('ext'):
1620                     dct['container'] = dct['ext'] + '_dash'
1621             formats.append(dct)
1622         hls_manifest_url = streaming_data.get('hlsManifestUrl')
1623         if hls_manifest_url:
1624             for f in self._extract_m3u8_formats(
1625                     hls_manifest_url, video_id, 'mp4', fatal=False):
1626                 itag = self._search_regex(
1627                     r'/itag/(\d+)', f['url'], 'itag', default=None)
1628                 if itag:
1629                     f['format_id'] = itag
1630                 formats.append(f)
1631         if self._downloader.params.get('youtube_include_dash_manifest', True):
1632             dash_manifest_url = streaming_data.get('dashManifestUrl')
1633             if dash_manifest_url:
1634                 for f in self._extract_mpd_formats(
1635                         dash_manifest_url, video_id, fatal=False):
1636                     itag = f['format_id']
1637                     if itag in itags:
1638                         continue
1639                     if itag in itag_qualities:
1640                         f['quality'] = q(itag_qualities[itag])
1641                     filesize = int_or_none(self._search_regex(
1642                         r'/clen/(\d+)', f.get('fragment_base_url')
1643                         or f['url'], 'file size', default=None))
1644                     if filesize:
1645                         f['filesize'] = filesize
1646                     formats.append(f)
1647         if not formats:
1648             if streaming_data.get('licenseInfos'):
1649                 raise ExtractorError(
1650                     'This video is DRM protected.', expected=True)
1651             pemr = try_get(
1652                 playability_status,
1653                 lambda x: x['errorScreen']['playerErrorMessageRenderer'],
1654                 dict) or {}
1655             reason = get_text(pemr.get('reason')) or playability_status.get('reason')
1656             subreason = pemr.get('subreason')
1657             if subreason:
1658                 subreason = clean_html(get_text(subreason))
1659                 if subreason == 'The uploader has not made this video available in your country.':
1660                     countries = microformat.get('availableCountries')
1661                     if not countries:
1662                         regions_allowed = search_meta('regionsAllowed')
1663                         countries = regions_allowed.split(',') if regions_allowed else None
1664                     self.raise_geo_restricted(
1665                         subreason, countries)
1666                 reason += '\n' + subreason
1667             if reason:
1668                 raise ExtractorError(reason, expected=True)
1669         self._sort_formats(formats)
1670         keywords = video_details.get('keywords') or []
1671         if not keywords and webpage:
1672             keywords = [
1673                 unescapeHTML(m.group('content'))
1674                 for m in re.finditer(self._meta_regex('og:video:tag'), webpage)]
1675         for keyword in keywords:
1676             if keyword.startswith('yt:stretch='):
1677                 mobj = re.search(r'(\d+)\s*:\s*(\d+)', keyword)
1678                 if mobj:
1679                     w, h = (float(v) for v in mobj.groups())
1680                     if w &gt; 0 and h &gt; 0:
1681                         ratio = w / h
1682                         for f in formats:
1683                             if f.get('vcodec') != 'none':
1684                                 f['stretched_ratio'] = ratio
1685                         break
1686         thumbnails = []
1687         for container in (video_details, microformat):
1688             for thumbnail in (try_get(
1689                     container,
1690                     lambda x: x['thumbnail']['thumbnails'], list) or []):
1691                 thumbnail_url = thumbnail.get('url')
1692                 if not thumbnail_url:
1693                     continue
1694                 thumbnails.append({
1695                     'height': int_or_none(thumbnail.get('height')),
1696                     'url': thumbnail_url,
1697                     'width': int_or_none(thumbnail.get('width')),
1698                 })
1699             if thumbnails:
1700                 break
1701         else:
1702             thumbnail = search_meta(['og:image', 'twitter:image'])
1703             if thumbnail:
1704                 thumbnails = [{'url': thumbnail}]
1705         category = microformat.get('category') or search_meta('genre')
1706         channel_id = video_details.get('channelId') \
1707             or microformat.get('externalChannelId') \
1708             or search_meta('channelId')
1709         duration = int_or_none(
1710             video_details.get('lengthSeconds')
1711             or microformat.get('lengthSeconds')) \
1712             or parse_duration(search_meta('duration'))
1713         is_live = video_details.get('isLive')
1714         owner_profile_url = microformat.get('ownerProfileUrl')
1715         if not player_url:
1716             player_url = self._extract_player_url(webpage)
1717         self._unthrottle_format_urls(video_id, player_url, formats)
1718         info = {
1719             'id': video_id,
1720             'title': self._live_title(video_title) if is_live else video_title,
1721             'formats': formats,
1722             'thumbnails': thumbnails,
1723             'description': video_description,
1724             'upload_date': unified_strdate(
1725                 microformat.get('uploadDate')
1726                 or search_meta('uploadDate')),
1727             'uploader': video_details['author'],
1728             'uploader_id': self._search_regex(r'/(?:channel|user)/([^/?&amp;#]+)', owner_profile_url, 'uploader id') if owner_profile_url else None,
1729             'uploader_url': owner_profile_url,
1730             'channel_id': channel_id,
1731             'channel_url': 'https://www.youtube.com/channel/' + channel_id if channel_id else None,
1732             'duration': duration,
1733             'view_count': int_or_none(
1734                 video_details.get('viewCount')
1735                 or microformat.get('viewCount')
1736                 or search_meta('interactionCount')),
1737             'average_rating': float_or_none(video_details.get('averageRating')),
1738             'age_limit': 18 if (
1739                 microformat.get('isFamilySafe') is False
1740                 or search_meta('isFamilyFriendly') == 'false'
1741                 or search_meta('og:restrictions:age') == '18+') else 0,
1742             'webpage_url': webpage_url,
1743             'categories': [category] if category else None,
1744             'tags': keywords,
1745             'is_live': is_live,
1746         }
1747         pctr = try_get(
1748             player_response,
1749             lambda x: x['captions']['playerCaptionsTracklistRenderer'], dict)
1750         if pctr:
1751             def process_language(container, base_url, lang_code, query):
1752                 lang_subs = []
1753                 for fmt in self._SUBTITLE_FORMATS:
1754                     query.update({
1755                         'fmt': fmt,
1756                     })
1757                     lang_subs.append({
1758                         'ext': fmt,
1759                         'url': update_url_query(base_url, query),
1760                     })
1761                 container[lang_code] = lang_subs
1762             subtitles = {}
1763             for caption_track in (pctr.get('captionTracks') or []):
1764                 base_url = caption_track.get('baseUrl')
1765                 if not base_url:
1766                     continue
1767                 if caption_track.get('kind') != 'asr':
1768                     lang_code = caption_track.get('languageCode')
1769                     if not lang_code:
1770                         continue
1771                     process_language(
1772                         subtitles, base_url, lang_code, {})
1773                     continue
1774                 automatic_captions = {}
1775                 for translation_language in (pctr.get('translationLanguages') or []):
1776                     translation_language_code = translation_language.get('languageCode')
1777                     if not translation_language_code:
1778                         continue
1779                     process_language(
1780                         automatic_captions, base_url, translation_language_code,
1781                         {'tlang': translation_language_code})
1782                 info['automatic_captions'] = automatic_captions
1783             info['subtitles'] = subtitles
1784         parsed_url = compat_urllib_parse_urlparse(url)
1785         for component in [parsed_url.fragment, parsed_url.query]:
1786             query = compat_parse_qs(component)
1787             for k, v in query.items():
1788                 for d_k, s_ks in [('start', ('start', 't')), ('end', ('end',))]:
1789                     d_k += '_time'
1790                     if d_k not in info and k in s_ks:
1791                         info[d_k] = parse_duration(query[k][0])
1792         if video_description:
1793             mobj = re.search(r'(?s)(?P&lt;track&gt;[^¬∑\n]+)¬∑(?P&lt;artist&gt;[^\n]+)\n+(?P&lt;album&gt;[^\n]+)(?:.+?‚Ñó\s*(?P&lt;release_year&gt;\d{4})(?!\d))?(?:.+?Released on\s*:\s*(?P&lt;release_date&gt;\d{4}-\d{2}-\d{2}))?(.+?\nArtist\s*:\s*(?P&lt;clean_artist&gt;[^\n]+))?.+\nAuto-generated by YouTube\.\s*$', video_description)
1794             if mobj:
1795                 release_year = mobj.group('release_year')
1796                 release_date = mobj.group('release_date')
1797                 if release_date:
1798                     release_date = release_date.replace('-', '')
1799                         release_year = release_date[:4]
1800                 info.update({
1801                     'album': mobj<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.group('album'.strip()),
1802                     'artist': mobj.group('clean_artist') or ', '.join(a.strip() for a in mobj.group(</b></font>'artist').split('¬∑')),
1803                     'track': mobj.group('track').strip(),
1804                     'release_date': release_date,
1805                     'release_year': int_or_none(release_year),
1806                 })
1807         initial_data = None
1808         if webpage:
1809             initial_data = self._extract_yt_initial_variable(
1810                 webpage, self._YT_INITIAL_DATA_RE, video_id,
1811                 'yt initial data')
1812         if not initial_data:
1813             initial_data = self._call_api(
1814                 'next', {'videoId': video_id}, video_id, fatal=False)
1815         if initial_data:
1816             chapters = self._extract_chapters_from_json(
1817                 initial_data, video_id, duration)
1818             if not chapters:
1819                 for engagment_pannel in (initial_data.get('engagementPanels') or []):
1820                     contents = try_get(
1821                         engagment_pannel, lambda x: x['engagementPanelSectionListRenderer']['content']['macroMarkersListRenderer']['contents'],
1822                         list)
1823                     if not contents:
1824                         continue
1825                     def chapter_time(mmlir):
1826                         return parse_duration(
1827                             get_text(mmlir.get('timeDescription')))
1828                     chapters = []
1829                     for next_num, content in enumerate(contents, start=1):
1830                         mmlir = content.get('macroMarkersListItemRenderer') or {}
1831                         start_time = chapter_time(mmlir)
1832                         end_time = chapter_time(try_get(
1833                             contents, lambda x: x[next_num]['macroMarkersListItemRenderer'])) \
1834                             if next_num &lt; len(contents) else duration
1835                         if start_time is None or end_time is None:
1836                             continue
1837                         chapters.append({
1838                             'start_time': start_time,
1839                             'end_time': end_time,
1840                             'title': get_text(mmlir.get('title')),
1841                         })
1842                     if chapters:
1843                         break
1844             if chapters:
1845                 info['chapters'] = chapters
1846             contents = try_get(
1847                 initial_data,
1848                 lambda x: x['contents']['twoColumnWatchNextResults']['results']['results']['contents'],
1849                 list) or []
1850             for content in contents:
1851                 vpir = content.get('videoPrimaryInfoRenderer')
1852                 if vpir:
1853                     stl = vpir.get('superTitleLink')
1854                     if stl:
1855                         stl = get_text(stl)
1856                         if try_get(
1857                                 vpir,
1858                                 lambda x: x['superTitleIcon']['iconType']) == 'LOCATION_PIN':
1859                             info['location'] = stl
1860                         else:
1861                             mobj = re.search(r'(.+?)\s*S(\d+)\s*‚Ä¢\s*E(\d+)', stl)
1862                             if mobj:
1863                                 info.update({
1864                                     'series': mobj.group(1),
1865                                     'season_number': int(mobj.group(2)),
1866                                     'episode_number': int(mobj.group(3)),
1867                                 })
1868                     for tlb in (try_get(
1869                             vpir,
1870                             lambda x: x['videoActions']['menuRenderer']['topLevelButtons'],
1871                             list) or []):
1872                         tbr = tlb.get('toggleButtonRenderer') or {}
1873                         for getter, regex in [(
1874                                 lambda x: x['defaultText']['accessibility']['accessibilityData'],
1875                                 r'(?P&lt;count&gt;[\d,]+)\s*(?P&lt;type&gt;(?:dis)?like)'), ([
1876                                     lambda x: x['accessibility'],
1877                                     lambda x: x['accessibilityData']['accessibilityData'],
1878                                 ], r'(?P&lt;type&gt;(?:dis)?like) this video along with (?P&lt;count&gt;[\d,]+) other people')]:
1879                             label = (try_get(tbr, getter, dict) or {}).get('label')
1880                             if label:
1881                                 mobj = re.match(regex, label)
1882                                 if mobj:
1883                                     info[mobj.group('type') + '_count'] = str_to_int(mobj.group('count'))
1884                                     break
1885                     sbr_tooltip = try_get(
1886                         vpir, lambda x: x['sentimentBar']['sentimentBarRenderer']['tooltip'])
1887                     if sbr_tooltip:
1888                         like_count, dislike_count = sbr_tooltip.split(' / ')
1889                         info.update({
1890                             'like_count': str_to_int(like_count),
1891                             'dislike_count': str_to_int(dislike_count),
1892                         })
1893                 vsir = content.get('videoSecondaryInfoRenderer')
1894                 if vsir:
1895                     info['channel'] = get_text(try_get(
1896                         vsir,
1897                         lambda x: x['owner']['videoOwnerRenderer']['title'],
1898                         dict))
1899                     rows = try_get(
1900                         vsir,
1901                         lambda x: x['metadataRowContainer']['metadataRowContainerRenderer']['rows'],
1902                         list) or []
1903                     multiple_songs = False
1904                     for row in rows:
1905                         if try_get(row, lambda x: x['metadataRowRenderer']['hasDividerLine']) is True:
1906                             multiple_songs = True
1907                             break
1908                     for row in rows:
1909                         mrr = row.get('metadataRowRenderer') or {}
1910                         mrr_title = mrr.get('title')
1911                         if not mrr_title:
1912                             continue
1913                         mrr_title = get_text(mrr['title'])
1914                         mrr_contents_text = get_text(mrr['contents'][0])
1915                         if mrr_title == 'License':
1916                             info['license'] = mrr_contents_text
1917                         elif not multiple_songs:
1918                             if mrr_title == 'Album':
1919                                 info['album'] = mrr_contents_text
1920                             elif mrr_title == 'Artist':
1921                                 info['artist'] = mrr_contents_text
1922                             elif mrr_title == 'Song':
1923                                 info['track'] = mrr_contents_text
1924         for s_k, d_k in [('artist', 'creator'), ('track', 'alt_title')]:
1925             v = info.get(s_k)
1926             if v:
1927                 info[d_k] = v
1928         self.mark_watched(video_id, player_response)
1929         return info
1930 class YoutubeTabIE(YoutubeBaseInfoExtractor):
1931     IE_DESC = 'YouTube.com tab'
1932     _VALID_URL = r'''(?x)
1933                     https?://
1934                         (?:\w+\.)?
1935                         (?:
1936                             youtube(?:kids)?\.com|
1937                             invidio\.us
1938                         )/
1939                         (?:
1940                             (?:channel|c|user|feed|hashtag)/|
1941                             (?:playlist|watch)\?.*?\blist=|
1942                             (?!(?:watch|embed|v|e|results)\b)
1943                         )
1944                         (?P&lt;id&gt;[^/?\#&amp;]+)
1945                     '''
1946     IE_NAME = 'youtube:tab'
1947     _TESTS = [{
1948         'url': 'https://www.youtube.com/c/–ò–≥–æ—Ä—å–ö–ª–µ–π–Ω–µ—Ä/playlists?view=1&amp;flow=grid',
1949         'playlist_mincount': 94,
1950         'info_dict': {
1951             'id': 'UCqj7Cz7revf5maW9g5pgNcg',
1952             'title': '–ò–≥–æ—Ä—å –ö–ª–µ–π–Ω–µ—Ä - Playlists',
1953             'description': 'md5:be97ee0f14ee314f1f002cf187166ee2',
1954         },
1955     }, {
1956         'url': 'https://www.youtube.com/user/igorkle1/playlists?view=1&amp;sort=dd',
1957         'playlist_mincount': 94,
1958         'info_dict': {
1959             'id': 'UCqj7Cz7revf5maW9g5pgNcg',
1960             'title': '–ò–≥–æ—Ä—å –ö–ª–µ–π–Ω–µ—Ä - Playlists',
1961             'description': 'md5:be97ee0f14ee314f1f002cf187166ee2',
1962         },
1963     }, {
1964         'url': 'https://www.youtube.com/c/3blue1brown/playlists?view=50&amp;sort=dd&amp;shelf_id=3',
1965         'playlist_mincount': 5,
1966         'info_dict': {
1967             'id': 'UCYO_jab_esuFRV4b17AJtAw',
1968             'title': '3Blue1Brown - Playlists',
1969             'description': 'md5:e1384e8a133307dd10edee76e875d62f',
1970         },
1971     }, {
1972         'url': 'https://www.youtube.com/user/ThirstForScience/playlists',
1973         'playlist_mincount': 4,
1974         'info_dict': {
1975             'id': 'UCAEtajcuhQ6an9WEzY9LEMQ',
1976             'title': 'ThirstForScience - Playlists',
1977             'description': 'md5:609399d937ea957b0f53cbffb747a14c',
1978         }
1979     }, {
1980         'url': 'https://www.youtube.com/c/ChristophLaimer/playlists',
1981         'only_matching': True,
1982     }, {
1983         'url': 'https://www.youtube.com/playlist?list=PL4lCao7KL_QFVb7Iudeipvc2BCavECqzc',
1984         'info_dict': {
1985             'uploader_id': 'UCmlqkdCBesrv2Lak1mF_MxA',
1986             'uploader': 'Sergey M.',
1987             'id': 'PL4lCao7KL_QFVb7Iudeipvc2BCavECqzc',
1988             'title': 'youtube-dl public playlist',
1989         },
1990         'playlist_count': 1,
1991     }, {
1992         'url': 'https://www.youtube.com/playlist?list=PL4lCao7KL_QFodcLWhDpGCYnngnHtQ-Xf',
1993         'info_dict': {
1994             'uploader_id': 'UCmlqkdCBesrv2Lak1mF_MxA',
1995             'uploader': 'Sergey M.',
1996             'id': 'PL4lCao7KL_QFodcLWhDpGCYnngnHtQ-Xf',
1997             'title': 'youtube-dl empty playlist',
1998         },
1999         'playlist_count': 0,
2000     }, {
2001         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/featured',
2002         'info_dict': {
2003             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2004             'title': 'lex will - Home',
2005             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2006         },
2007         'playlist_mincount': 2,
2008     }, {
2009         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/videos',
2010         'info_dict': {
2011             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2012             'title': 'lex will - Videos',
2013             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2014         },
2015         'playlist_mincount': 975,
2016     }, {
2017         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/videos?view=0&amp;sort=p&amp;flow=grid',
2018         'info_dict': {
2019             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2020             'title': 'lex will - Videos',
2021             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2022         },
2023         'playlist_mincount': 199,
2024     }, {
2025         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/playlists',
2026         'info_dict': {
2027             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2028             'title': 'lex will - Playlists',
2029             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2030         },
2031         'playlist_mincount': 17,
2032     }, {
2033         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/community',
2034         'info_dict': {
2035             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2036             'title': 'lex will - Community',
2037             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2038         },
2039         'playlist_mincount': 18,
2040     }, {
2041         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/channels',
2042         'info_dict': {
2043             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2044             'title': 'lex will - Channels',
2045             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2046         },
2047         'playlist_mincount': 138,
2048     }, {
2049         'url': 'https://invidio.us/channel/UCmlqkdCBesrv2Lak1mF_MxA',
2050         'only_matching': True,
2051     }, {
2052         'url': 'https://www.youtubekids.com/channel/UCmlqkdCBesrv2Lak1mF_MxA',
2053         'only_matching': True,
2054     }, {
2055         'url': 'https://music.youtube.com/channel/UCmlqkdCBesrv2Lak1mF_MxA',
2056         'only_matching': True,
2057     }, {
2058         'note': 'Playlist with deleted videos (#651). As a bonus, the video #51 is also twice in this list.',
2059         'url': 'https://www.youtube.com/playlist?list=PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC',
2060         'info_dict': {
2061             'title': '29C3: Not my department',
2062             'id': 'PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC',
2063             'uploader': 'Christiaan008',
2064             'uploader_id': 'UCEPzS1rYsrkqzSLNp76nrcg',
2065         },
2066         'playlist_count': 96,
2067     }, {
2068         'note': 'Large playlist',
2069         'url': 'https://www.youtube.com/playlist?list=UUBABnxM4Ar9ten8Mdjj1j0Q',
2070         'info_dict': {
2071             'title': 'Uploads from Cauchemar',
2072             'id': 'UUBABnxM4Ar9ten8Mdjj1j0Q',
2073             'uploader': 'Cauchemar',
2074             'uploader_id': 'UCBABnxM4Ar9ten8Mdjj1j0Q',
2075         },
2076         'playlist_mincount': 1123,
2077     }, {
2078         'url': 'http://www.youtube.com/user/NASAgovVideo/videos',
2079         'only_matching': True,
2080     }, {
2081         'note': 'Buggy playlist: the webpage has a "Load more" button but it doesn\'t have more videos',
2082         'url': 'https://www.youtube.com/playlist?list=UUXw-G3eDE9trcvY2sBMM_aA',
2083         'info_dict': {
2084             'title': 'Uploads from Interstellar Movie',
2085             'id': 'UUXw-G3eDE9trcvY2sBMM_aA',
2086             'uploader': 'Interstellar Movie',
2087             'uploader_id': 'UCXw-G3eDE9trcvY2sBMM_aA',
2088         },
2089         'playlist_mincount': 21,
2090     }, {
2091         'url': 'https://www.youtube.com/playlist?list=PLzH6n4zXuckpfMu_4Ff8E7Z1behQks5ba',
2092         'info_dict': {
2093             'title': 'Data Analysis with Dr Mike Pound',
2094             'id': 'PLzH6n4zXuckpfMu_4Ff8E7Z1behQks5ba',
2095             'uploader_id': 'UC9-y-6csu5WGm29I7JiwpnA',
2096             'uploader': 'Computerphile',
2097         },
2098         'playlist_mincount': 11,
2099     }, {
2100         'url': 'https://invidio.us/playlist?list=PL4lCao7KL_QFVb7Iudeipvc2BCavECqzc',
2101         'only_matching': True,
2102     }, {
2103         'url': 'https://www.youtube.com/watch?v=FqZTN594JQw&amp;list=PLMYEtVRpaqY00V9W81Cwmzp6N6vZqfUKD4',
2104         'info_dict': {
2105             'id': 'FqZTN594JQw',
2106             'ext': 'webm',
2107             'title': "Smiley's People 01 detective, Adventure Series, Action",
2108             'uploader': 'STREEM',
2109             'uploader_id': 'UCyPhqAZgwYWZfxElWVbVJng',
2110             'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCyPhqAZgwYWZfxElWVbVJng',
2111             'upload_date': '20150526',
2112             'license': 'Standard YouTube License',
2113             'description': 'md5:507cdcb5a49ac0da37a920ece610be80',
2114             'categories': ['People &amp; Blogs'],
2115             'tags': list,
2116             'view_count': int,
2117             'like_count': int,
2118             'dislike_count': int,
2119         },
2120         'params': {
2121             'skip_download': True,
2122         },
2123         'skip': 'This video is not available.',
2124         'add_ie': [YoutubeIE.ie_key()],
2125     }, {
2126         'url': 'https://www.youtubekids.com/watch?v=Agk7R8I8o5U&amp;list=PUZ6jURNr1WQZCNHF0ao-c0g',
2127         'only_matching': True,
2128     }, {
2129         'url': 'https://www.youtube.com/watch?v=MuAGGZNfUkU&amp;list=RDMM',
2130         'only_matching': True,
2131     }, {
2132         'url': 'https://www.youtube.com/channel/UCoMdktPbSTixAyNGwb-UYkQ/live',
2133         'info_dict': {
2134             'id': '9Auq9mYxFEE',
2135             'ext': 'mp4',
2136             'title': 'Watch Sky News live',
2137             'uploader': 'Sky News',
2138             'uploader_id': 'skynews',
2139             'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/skynews',
2140             'upload_date': '20191102',
2141             'description': 'md5:78de4e1c2359d0ea3ed829678e38b662',
2142             'categories': ['News &amp; Politics'],
2143             'tags': list,
2144             'like_count': int,
2145             'dislike_count': int,
2146         },
2147         'params': {
2148             'skip_download': True,
2149         },
2150     }, {
2151         'url': 'https://www.youtube.com/user/TheYoungTurks/live',
2152         'info_dict': {
2153             'id': 'a48o2S1cPoo',
2154             'ext': 'mp4',
2155             'title': 'The Young Turks - Live Main Show',
2156             'uploader': 'The Young Turks',
2157             'uploader_id': 'TheYoungTurks',
2158             'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/TheYoungTurks',
2159             'upload_date': '20150715',
2160             'license': 'Standard YouTube License',
2161             'description': 'md5:438179573adcdff3c97ebb1ee632b891',
2162             'categories': ['News &amp; Politics'],
2163             'tags': ['Cenk Uygur (TV Program Creator)', 'The Young Turks (Award-Winning Work)', 'Talk Show (TV Genre)'],
2164             'like_count': int,
2165             'dislike_count': int,
2166         },
2167         'params': {
2168             'skip_download': True,
2169         },
2170         'only_matching': True,
2171     }, {
2172         'url': 'https://www.youtube.com/channel/UC1yBKRuGpC1tSM73A0ZjYjQ/live',
2173         'only_matching': True,
2174     }, {
2175         'url': 'https://www.youtube.com/c/CommanderVideoHq/live',
2176         'only_matching': True,
2177     }, {
2178         'url': 'https://www.youtube.com/feed/trending',
2179         'only_matching': True,
2180     }, {
2181         'url': 'https://www.youtube.com/feed/library',
2182         'only_matching': True,
2183     }, {
2184         'url': 'https://www.youtube.com/feed/history',
2185         'only_matching': True,
2186     }, {
2187         'url': 'https://www.youtube.com/feed/subscriptions',
2188         'only_matching': True,
2189     }, {
2190         'url': 'https://www.youtube.com/feed/watch_later',
2191         'only_matching': True,
2192     }, {
2193         'url': 'https://www.youtube.com/feed/recommended',
2194         'only_matching': True,
2195     }, {
2196         'url': 'https://www.youtube.com/watch?v=UC6u0Tct-Fo&amp;list=PL36D642111D65BE7C',
2197         'only_matching': True,
2198     }, {
2199         'url': 'https://www.youtube.com/course?list=ECUl4u3cNGP61MdtwGTqZA0MreSaDybji8',
2200         'only_matching': True,
2201     }, {
2202         'url': 'https://www.youtube.com/course',
2203         'only_matching': True,
2204     }, {
2205         'url': 'https://www.youtube.com/zsecurity',
2206         'only_matching': True,
2207     }, {
2208         'url': 'http://www.youtube.com/NASAgovVideo/videos',
2209         'only_matching': True,
2210     }, {
2211         'url': 'https://www.youtube.com/TheYoungTurks/live',
2212         'only_matching': True,
2213     }, {
2214         'url': 'https://www.youtube.com/hashtag/cctv9',
2215         'info_dict': {
2216             'id': 'cctv9',
2217             'title': '#cctv9',
2218         },
2219         'playlist_mincount': 350,
2220     }, {
2221         'url': 'https://www.youtube.com/watch?list=PLW4dVinRY435CBE_JD3t-0SRXKfnZHS1P&amp;feature=youtu.be&amp;v=M9cJMXmQ_ZU',
2222         'only_matching': True,
2223     }, {
2224         'note': 'Search tab',
2225         'url': 'https://www.youtube.com/c/3blue1brown/search?query=linear%20algebra',
2226         'playlist_mincount': 40,
2227         'info_dict': {
2228             'id': 'UCYO_jab_esuFRV4b17AJtAw',
2229             'title': '3Blue1Brown - Search - linear algebra',
2230             'description': 'md5:e1384e8a133307dd10edee76e875d62f',
2231             'uploader': '3Blue1Brown',
2232             'uploader_id': 'UCYO_jab_esuFRV4b17AJtAw',
2233         }
2234     }]
2235     @classmethod
2236     def suitable(cls, url):
2237         return False if YoutubeIE.suitable(url) else super(
2238             YoutubeTabIE, cls).suitable(url)
2239     def _extract_channel_id(self, webpage):
2240         channel_id = self._html_search_meta(
2241             'channelId', webpage, 'channel id', default=None)
2242         if channel_id:
2243             return channel_id
2244         channel_url = self._html_search_meta(
2245             ('og:url', 'al:ios:url', 'al:android:url', 'al:web:url',
2246              'twitter:url', 'twitter:app:url:iphone', 'twitter:app:url:ipad',
2247              'twitter:app:url:googleplay'), webpage, 'channel url')
2248         return self._search_regex(
2249             r'https?://(?:www\.)?youtube\.com/channel/([^/?#&amp;])+',
2250             channel_url, 'channel id')
2251     @staticmethod
2252     def _extract_grid_item_renderer(item):
2253         assert isinstance(item, dict)
2254         for key, renderer in item.items():
2255             if not key.startswith('grid') or not key.endswith('Renderer'):
2256                 continue
2257             if not isinstance(renderer, dict):
2258                 continue
2259             return renderer
2260     def _grid_entries(self, grid_renderer):
2261         for item in grid_renderer['items']:
2262             if not isinstance(item, dict):
2263                 continue
2264             renderer = self._extract_grid_item_renderer(item)
2265             if not isinstance(renderer, dict):
2266                 continue
2267             title = try_get(
2268                 renderer, (lambda x: x['title']['runs'][0]['text'],
2269                            lambda x: x['title']['simpleText']), compat_str)
2270             playlist_id = renderer.get('playlistId')
2271             if playlist_id:
2272                 yield self.url_result(
2273                     'https://www.youtube.com/playlist?list=%s' % playlist_id,
2274                     ie=YoutubeTabIE.ie_key(), video_id=playlist_id,
2275                     video_title=title)
2276                 continue
2277             video_id = renderer.get('videoId')
2278             if video_id:
2279                 yield self._extract_video(renderer)
2280                 continue
2281             channel_id = renderer.get('channelId')
2282             if channel_id:
2283                 title = try_get(
2284                     renderer, lambda x: x['title']['simpleText'], compat_str)
2285                 yield self.url_result(
2286                     'https://www.youtube.com/channel/%s' % channel_id,
2287                     ie=YoutubeTabIE.ie_key(), video_title=title)
2288                 continue
2289             ep_url = urljoin('https://www.youtube.com/', try_get(
2290                 renderer, lambda x: x['navigationEndpoint']['commandMetadata']['webCommandMetadata']['url'],
2291                 compat_str))
2292             if ep_url:
2293                 for ie in (YoutubeTabIE, YoutubePlaylistIE, YoutubeIE):
2294                     if ie.suitable(ep_url):
2295                         yield self.url_result(
2296                             ep_url, ie=ie.ie_key(), video_id=ie._match_id(ep_url), video_title=title)
2297                         break
2298     def _shelf_entries_from_content(self, shelf_renderer):
2299         content = shelf_renderer.get('content')
2300         if not isinstance(content, dict):
2301             return
2302         renderer = content.get('gridRenderer')
2303         if renderer:
2304             for entry in self._grid_entries(renderer):
2305                 yield entry
2306         renderer = content.get('horizontalListRenderer')
2307         if renderer:
2308             pass
2309     def _shelf_entries(self, shelf_renderer, skip_channels=False):
2310         ep = try_get(
2311             shelf_renderer, lambda x: x['endpoint']['commandMetadata']['webCommandMetadata']['url'],
2312             compat_str)
2313         shelf_url = urljoin('https://www.youtube.com', ep)
2314         if shelf_url:
2315             if skip_channels and '/channels?' in shelf_url:
2316                 return
2317             title = try_get(
2318                 shelf_renderer, lambda x: x['title']['runs'][0]['text'], compat_str)
2319             yield self.url_result(shelf_url, video_title=title)
2320         for entry in self._shelf_entries_from_content(shelf_renderer):
2321             yield entry
2322     def _playlist_entries(self, video_list_renderer):
2323         for content in video_list_renderer['contents']:
2324             if not isinstance(content, dict):
2325                 continue
2326             renderer = content.get('playlistVideoRenderer') or content.get('playlistPanelVideoRenderer')
2327             if not isinstance(renderer, dict):
2328                 continue
2329             video_id = renderer.get('videoId')
2330             if not video_id:
2331                 continue
2332             yield self._extract_video(renderer)
2333     def _video_entry(self, video_renderer):
2334         video_id = video_renderer.get('videoId')
2335         if video_id:
2336             return self._extract_video(video_renderer)
2337     def _post_thread_entries(self, post_thread_renderer):
2338         post_renderer = try_get(
2339             post_thread_renderer, lambda x: x['post']['backstagePostRenderer'], dict)
2340         if not post_renderer:
2341             return
2342         video_renderer = try_get(
2343             post_renderer, lambda x: x['backstageAttachment']['videoRenderer'], dict)
2344         video_id = None
2345         if video_renderer:
2346             entry = self._video_entry(video_renderer)
2347             if entry:
2348                 yield entry
2349         runs = try_get(post_renderer, lambda x: x['contentText']['runs'], list) or []
2350         for run in runs:
2351             if not isinstance(run, dict):
2352                 continue
2353             ep_url = try_get(
2354                 run, lambda x: x['navigationEndpoint']['urlEndpoint']['url'], compat_str)
2355             if not ep_url:
2356                 continue
2357             if not YoutubeIE.suitable(ep_url):
2358                 continue
2359             ep_video_id = YoutubeIE._match_id(ep_url)
2360             if video_id == ep_video_id:
2361                 continue
2362             yield self.url_result(ep_url, ie=YoutubeIE.ie_key(), video_id=video_id)
2363     def _post_thread_continuation_entries(self, post_thread_continuation):
2364         contents = post_thread_continuation.get('contents')
2365         if not isinstance(contents, list):
2366             return
2367         for content in contents:
2368             renderer = content.get('backstagePostThreadRenderer')
2369             if not isinstance(renderer, dict):
2370                 continue
2371             for entry in self._post_thread_entries(renderer):
2372                 yield entry
2373     def _rich_grid_entries(self, contents):
2374         for content in contents:
2375             video_renderer = try_get(content, lambda x: x['richItemRenderer']['content']['videoRenderer'], dict)
2376             if video_renderer:
2377                 entry = self._video_entry(video_renderer)
2378                 if entry:
2379                     yield entry
2380     @staticmethod
2381     def _build_continuation_query(continuation, ctp=None):
2382         query = {
2383             'ctoken': continuation,
2384             'continuation': continuation,
2385         }
2386         if ctp:
2387             query['itct'] = ctp
2388         return query
2389     @staticmethod
2390     def _extract_next_continuation_data(renderer):
2391         next_continuation = try_get(
2392             renderer, lambda x: x['continuations'][0]['nextContinuationData'], dict)
2393         if not next_continuation:
2394             return
2395         continuation = next_continuation.get('continuation')
2396         if not continuation:
2397             return
2398         ctp = next_continuation.get('clickTrackingParams')
2399         return YoutubeTabIE._build_continuation_query(continuation, ctp)
2400     @classmethod
2401     def _extract_continuation(cls, renderer):
2402         next_continuation = cls._extract_next_continuation_data(renderer)
2403         if next_continuation:
2404             return next_continuation
2405         contents = []
2406         for key in ('contents', 'items'):
2407             contents.extend(try_get(renderer, lambda x: x[key], list) or [])
2408         for content in contents:
2409             if not isinstance(content, dict):
2410                 continue
2411             continuation_ep = try_get(
2412                 content, lambda x: x['continuationItemRenderer']['continuationEndpoint'],
2413                 dict)
2414             if not continuation_ep:
2415                 continue
2416             continuation = try_get(
2417                 continuation_ep, lambda x: x['continuationCommand']['token'], compat_str)
2418             if not continuation:
2419                 continue
2420             ctp = continuation_ep.get('clickTrackingParams')
2421             return YoutubeTabIE._build_continuation_query(continuation, ctp)
2422     def _entries(self, tab, item_id, webpage):
2423         tab_content = try_get(tab, lambda x: x['content'], dict)
2424         if not tab_content:
2425             return
2426         slr_renderer = try_get(tab_content, lambda x: x['sectionListRenderer'], dict)
2427         if slr_renderer:
2428             is_channels_tab = tab.get('title') == 'Channels'
2429             continuation = None
2430             slr_contents = try_get(slr_renderer, lambda x: x['contents'], list) or []
2431             for slr_content in slr_contents:
2432                 if not isinstance(slr_content, dict):
2433                     continue
2434                 is_renderer = try_get(slr_content, lambda x: x['itemSectionRenderer'], dict)
2435                 if not is_renderer:
2436                     continue
2437                 isr_contents = try_get(is_renderer, lambda x: x['contents'], list) or []
2438                 for isr_content in isr_contents:
2439                     if not isinstance(isr_content, dict):
2440                         continue
2441                     renderer = isr_content.get('playlistVideoListRenderer')
2442                     if renderer:
2443                         for entry in self._playlist_entries(renderer):
2444                             yield entry
2445                         continuation = self._extract_continuation(renderer)
2446                         continue
2447                     renderer = isr_content.get('gridRenderer')
2448                     if renderer:
2449                         for entry in self._grid_entries(renderer):
2450                             yield entry
2451                         continuation = self._extract_continuation(renderer)
2452                         continue
2453                     renderer = isr_content.get('shelfRenderer')
2454                     if renderer:
2455                         for entry in self._shelf_entries(renderer, not is_channels_tab):
2456                             yield entry
2457                         continue
2458                     renderer = isr_content.get('backstagePostThreadRenderer')
2459                     if renderer:
2460                         for entry in self._post_thread_entries(renderer):
2461                             yield entry
2462                         continuation = self._extract_continuation(renderer)
2463                         continue
2464                     renderer = isr_content.get('videoRenderer')
2465                     if renderer:
2466                         entry = self._video_entry(renderer)
2467                         if entry:
2468                             yield entry
2469                 if not continuation:
2470                     continuation = self._extract_continuation(is_renderer)
2471             if not continuation:
2472                 continuation = self._extract_continuation(slr_renderer)
2473         else:
2474             rich_grid_renderer = tab_content.get('richGridRenderer')
2475             if not rich_grid_renderer:
2476                 return
2477             for entry in self._rich_grid_entries(rich_grid_renderer.get('contents') or []):
2478                 yield entry
2479             continuation = self._extract_continuation(rich_grid_renderer)
2480         ytcfg = self._extract_ytcfg(item_id, webpage)
2481         client_version = try_get(
2482             ytcfg, lambda x: x['INNERTUBE_CLIENT_VERSION'], compat_str) or '2.20210407.08.00'
2483         headers = {
2484             'x-youtube-client-name': '1',
2485             'x-youtube-client-version': client_version,
2486             'content-type': 'application/json',
2487         }
2488         context = try_get(ytcfg, lambda x: x['INNERTUBE_CONTEXT'], dict) or {
2489             'client': {
2490                 'clientName': 'WEB',
2491                 'clientVersion': client_version,
2492             }
2493         }
2494         visitor_data = try_get(context, lambda x: x['client']['visitorData'], compat_str)
2495         identity_token = self._extract_identity_token(ytcfg, webpage)
2496         if identity_token:
2497             headers['x-youtube-identity-token'] = identity_token
2498         data = {
2499             'context': context,
2500         }
2501         for page_num in itertools.count(1):
2502             if not continuation:
2503                 break
2504             if visitor_data:
2505                 headers['x-goog-visitor-id'] = visitor_data
2506             data['continuation'] = continuation['continuation']
2507             data['clickTracking'] = {
2508                 'clickTrackingParams': continuation['itct']
2509             }
2510             count = 0
2511             retries = 3
2512             while count &lt;= retries:
2513                 try:
2514                     response = self._download_json(
2515                         'https://www.youtube.com/youtubei/v1/browse?key=AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8',
2516                         None, 'Downloading page %d%s' % (page_num, ' (retry #%d)' % count if count else ''),
2517                         headers=headers, data=json.dumps(data).encode('utf8'))
2518                     break
2519                 except ExtractorError as e:
2520                     if isinstance(e.cause, compat_HTTPError) and e.cause.code in (500, 503):
2521                         count += 1
2522                         if count &lt;= retries:
2523                             continue
2524                     raise
2525             if not response:
2526                 break
2527             visitor_data = try_get(
2528                 response, lambda x: x['responseContext']['visitorData'], compat_str) or visitor_data
2529             continuation_contents = try_get(
2530                 response, lambda x: x['continuationContents'], dict)
2531             if continuation_contents:
2532                 continuation_renderer = continuation_contents.get('playlistVideoListContinuation')
2533                 if continuation_renderer:
2534                     for entry in self._playlist_entries(continuation_renderer):
2535                         yield entry
2536                     continuation = self._extract_continuation(continuation_renderer)
2537                     continue
2538                 continuation_renderer = continuation_contents.get('gridContinuation')
2539                 if continuation_renderer:
2540                     for entry in self._grid_entries(continuation_renderer):
2541                         yield entry
2542                     continuation = self._extract_continuation(continuation_renderer)
2543                     continue
2544                 continuation_renderer = continuation_contents.get('itemSectionContinuation')
2545                 if continuation_renderer:
2546                     for entry in self._post_thread_continuation_entries(continuation_renderer):
2547                         yield entry
2548                     continuation = self._extract_continuation(continuation_renderer)
2549                     continue
2550             on_response_received = dict_get(response, ('onResponseReceivedActions', 'onResponseReceivedEndpoints'))
2551             continuation_items = try_get(
2552                 on_response_received, lambda x: x[0]['appendContinuationItemsAction']['continuationItems'], list)
2553             if continuation_items:
2554                 continuation_item = continuation_items[0]
2555                 if not isinstance(continuation_item, dict):
2556                     continue
2557                 renderer = self._extract_grid_item_renderer(continuation_item)
2558                 if renderer:
2559                     grid_renderer = {'items': continuation_items}
2560                     for entry in self._grid_entries(grid_renderer):
2561                         yield entry
2562                     continuation = self._extract_continuation(grid_renderer)
2563                     continue
2564                 renderer = continuation_item.get('playlistVideoRenderer') or continuation_item.get('itemSectionRenderer')
2565                 if renderer:
2566                     video_list_renderer = {'contents': continuation_items}
2567                     for entry in self._playlist_entries(video_list_renderer):
2568                         yield entry
2569                     continuation = self._extract_continuation(video_list_renderer)
2570                     continue
2571                 renderer = continuation_item.get('backstagePostThreadRenderer')
2572                 if renderer:
2573                     continuation_renderer = {'contents': continuation_items}
2574                     for entry in self._post_thread_continuation_entries(continuation_renderer):
2575                         yield entry
2576                     continuation = self._extract_continuation(continuation_renderer)
2577                     continue
2578                 renderer = continuation_item.get('richItemRenderer')
2579                 if renderer:
2580                     for entry in self._rich_grid_entries(continuation_items):
2581                         yield entry
2582                     continuation = self._extract_continuation({'contents': continuation_items})
2583                     continue
2584             break
2585     @staticmethod
2586     def _extract_selected_tab(tabs):
2587         for tab in tabs:
2588             renderer = dict_get(tab, ('tabRenderer', 'expandableTabRenderer')) or {}
2589             if renderer.get('selected') is True:
2590                 return renderer
2591         else:
2592             raise ExtractorError('Unable to find selected tab')
2593     @staticmethod
2594     def _extract_uploader(data):
2595         uploader = {}
2596         sidebar_renderer = try_get(
2597             data, lambda x: x['sidebar']['playlistSidebarRenderer']['items'], list)
2598         if sidebar_renderer:
2599             for item in sidebar_renderer:
2600                 if not isinstance(item, dict):
2601                     continue
2602                 renderer = item.get('playlistSidebarSecondaryInfoRenderer')
2603                 if not isinstance(renderer, dict):
2604                     continue
2605                 owner = try_get(
2606                     renderer, lambda x: x['videoOwner']['videoOwnerRenderer']['title']['runs'][0], dict)
2607                 if owner:
2608                     uploader['uploader'] = owner.get('text')
2609                     uploader['uploader_id'] = try_get(
2610                         owner, lambda x: x['navigationEndpoint']['browseEndpoint']['browseId'], compat_str)
2611                     uploader['uploader_url'] = urljoin(
2612                         'https://www.youtube.com/',
2613                         try_get(owner, lambda x: x['navigationEndpoint']['browseEndpoint']['canonicalBaseUrl'], compat_str))
2614         return uploader
2615     @staticmethod
2616     def _extract_alert(data):
2617         alerts = []
2618         for alert in try_get(data, lambda x: x['alerts'], list) or []:
2619             if not isinstance(alert, dict):
2620                 continue
2621             alert_text = try_get(
2622                 alert, lambda x: x['alertRenderer']['text'], dict)
2623             if not alert_text:
2624                 continue
2625             text = try_get(
2626                 alert_text,
2627                 (lambda x: x['simpleText'], lambda x: x['runs'][0]['text']),
2628                 compat_str)
2629             if text:
2630                 alerts.append(text)
2631         return '\n'.join(alerts)
2632     def _extract_from_tabs(self, item_id, webpage, data, tabs):
2633         selected_tab = self._extract_selected_tab(tabs)
2634         renderer = try_get(
2635             data, lambda x: x['metadata']['channelMetadataRenderer'], dict)
2636         playlist_id = item_id
2637         title = description = None
2638         if renderer:
2639             channel_title = renderer.get('title') or item_id
2640             tab_title = selected_tab.get('title')
2641             title = channel_title or item_id
2642             if tab_title:
2643                 title += ' - %s' % tab_title
2644             if selected_tab.get('expandedText'):
2645                 title += ' - %s' % selected_tab['expandedText']
2646             description = renderer.get('description')
2647             playlist_id = renderer.get('externalId')
2648         else:
2649             renderer = try_get(
2650                 data, lambda x: x['metadata']['playlistMetadataRenderer'], dict)
2651             if renderer:
2652                 title = renderer.get('title')
2653             else:
2654                 renderer = try_get(
2655                     data, lambda x: x['header']['hashtagHeaderRenderer'], dict)
2656                 if renderer:
2657                     title = try_get(renderer, lambda x: x['hashtag']['simpleText'])
2658         playlist = self.playlist_result(
2659             self._entries(selected_tab, item_id, webpage),
2660             playlist_id=playlist_id, playlist_title=title,
2661             playlist_description=description)
2662         playlist.update(self._extract_uploader(data))
2663         return playlist
2664     def _extract_from_playlist(self, item_id, url, data, playlist):
2665         title = playlist.get('title') or try_get(
2666             data, lambda x: x['titleText']['simpleText'], compat_str)
2667         playlist_id = playlist.get('playlistId') or item_id
2668         playlist_url = urljoin(url, try_get(
2669             playlist, lambda x: x['endpoint']['commandMetadata']['webCommandMetadata']['url'],
2670             compat_str))
2671         if playlist_url and playlist_url != url:
2672             return self.url_result(
2673                 playlist_url, ie=YoutubeTabIE.ie_key(), video_id=playlist_id,
2674                 video_title=title)
2675         return self.playlist_result(
2676             self._playlist_entries(playlist), playlist_id=playlist_id,
2677             playlist_title=title)
2678     def _extract_identity_token(self, ytcfg, webpage):
2679         if ytcfg:
2680             token = try_get(ytcfg, lambda x: x['ID_TOKEN'], compat_str)
2681             if token:
2682                 return token
2683         return self._search_regex(
2684             r'\bID_TOKEN["\']\s*:\s*["\'](.+?)["\']', webpage,
2685             'identity token', default=None)
2686     def _real_extract(self, url):
2687         item_id = self._match_id(url)
2688         url = compat_urlparse.urlunparse(
2689             compat_urlparse.urlparse(url)._replace(netloc='www.youtube.com'))
2690         qs = parse_qs(url)
2691         video_id = qs.get('v', [None])[0]
2692         playlist_id = qs.get('list', [None])[0]
2693         if video_id and playlist_id:
2694             if self._downloader.params.get('noplaylist'):
2695                 self.to_screen('Downloading just video %s because of --no-playlist' % video_id)
2696                 return self.url_result(video_id, ie=YoutubeIE.ie_key(), video_id=video_id)
2697             self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))
2698         webpage = self._download_webpage(url, item_id)
2699         data = self._extract_yt_initial_data(item_id, webpage)
2700         tabs = try_get(
2701             data, lambda x: x['contents']['twoColumnBrowseResultsRenderer']['tabs'], list)
2702         if tabs:
2703             return self._extract_from_tabs(item_id, webpage, data, tabs)
2704         playlist = try_get(
2705             data, lambda x: x['contents']['twoColumnWatchNextResults']['playlist']['playlist'], dict)
2706         if playlist:
2707             return self._extract_from_playlist(item_id, url, data, playlist)
2708         video_id = try_get(
2709             data, lambda x: x['currentVideoEndpoint']['watchEndpoint']['videoId'],
2710             compat_str) or video_id
2711         if video_id:
2712             return self.url_result(video_id, ie=YoutubeIE.ie_key(), video_id=video_id)
2713         alert = self._extract_alert(data)
2714         if alert:
2715             raise ExtractorError(alert, expected=True)
2716         raise ExtractorError('Unable to recognize tab page')
2717 class YoutubePlaylistIE(InfoExtractor):
2718     IE_DESC = 'YouTube.com playlists'
2719     _VALID_URL = r'''(?x)(?:
2720                         (?:https?://)?
2721                         (?:\w+\.)?
2722                         (?:
2723                             (?:
2724                                 youtube(?:kids)?\.com|
2725                                 invidio\.us
2726                             )
2727                             /.*?\?.*?\blist=
2728                         )?
2729                         (?P&lt;id&gt;%(playlist_id)s)
2730                      )''' % {'playlist_id': YoutubeBaseInfoExtractor._PLAYLIST_ID_RE}
2731     IE_NAME = 'youtube:playlist'
2732     _TESTS = [{
2733         'note': 'issue #673',
2734         'url': 'PLBB231211A4F62143',
2735         'info_dict': {
2736             'title': '[OLD]Team Fortress 2 (Class-based LP)',
2737             'id': 'PLBB231211A4F62143',
2738             'uploader': 'Wickydoo',
2739             'uploader_id': 'UCKSpbfbl5kRQpTdL7kMc-1Q',
2740         },
2741         'playlist_mincount': 29,
2742     }, {
2743         'url': 'PLtPgu7CB4gbY9oDN3drwC3cMbJggS7dKl',
2744         'info_dict': {
2745             'title': 'YDL_safe_search',
2746             'id': 'PLtPgu7CB4gbY9oDN3drwC3cMbJggS7dKl',
2747         },
2748         'playlist_count': 2,
2749         'skip': 'This playlist is private',
2750     }, {
2751         'note': 'embedded',
2752         'url': 'https://www.youtube.com/embed/videoseries?list=PL6IaIsEjSbf96XFRuNccS_RuEXwNdsoEu',
2753         'playlist_count': 4,
2754         'info_dict': {
2755             'title': 'JODA15',
2756             'id': 'PL6IaIsEjSbf96XFRuNccS_RuEXwNdsoEu',
2757             'uploader': 'milan',
2758             'uploader_id': 'UCEI1-PVPcYXjB73Hfelbmaw',
2759         }
2760     }, {
2761         'url': 'http://www.youtube.com/embed/_xDOZElKyNU?list=PLsyOSbh5bs16vubvKePAQ1x3PhKavfBIl',
2762         'playlist_mincount': 982,
2763         'info_dict': {
2764             'title': '2018 Chinese New Singles (11/6 updated)',
2765             'id': 'PLsyOSbh5bs16vubvKePAQ1x3PhKavfBIl',
2766             'uploader': 'LBK',
2767             'uploader_id': 'UC21nz3_MesPLqtDqwdvnoxA',
2768         }
2769     }, {
2770         'url': 'TLGGrESM50VT6acwMjAyMjAxNw',
2771         'only_matching': True,
2772     }, {
2773         'url': 'OLAK5uy_m4xAFdmMC5rX3Ji3g93pQe3hqLZw_9LhM',
2774         'only_matching': True,
2775     }]
2776     @classmethod
2777     def suitable(cls, url):
2778         if YoutubeTabIE.suitable(url):
2779             return False
2780         from .youtube import parse_qs
2781         qs = parse_qs(url)
2782         if qs.get('v', [None])[0]:
2783             return False
2784         return super(YoutubePlaylistIE, cls).suitable(url)
2785     def _real_extract(self, url):
2786         playlist_id = self._match_id(url)
2787         qs = parse_qs(url)
2788         if not qs:
2789             qs = {'list': playlist_id}
2790         return self.url_result(
2791             update_url_query('https://www.youtube.com/playlist', qs),
2792             ie=YoutubeTabIE.ie_key(), video_id=playlist_id)
2793 class YoutubeYtBeIE(InfoExtractor):
2794     _VALID_URL = r'https?://youtu\.be/(?P&lt;id&gt;[0-9A-Za-z_-]{11})/*?.*?\blist=(?P&lt;playlist_id&gt;%(playlist_id)s)' % {'playlist_id': YoutubeBaseInfoExtractor._PLAYLIST_ID_RE}
2795     _TESTS = [{
2796         'url': 'https://youtu.be/yeWKywCrFtk?list=PL2qgrgXsNUG5ig9cat4ohreBjYLAPC0J5',
2797         'info_dict': {
2798             'id': 'yeWKywCrFtk',
2799             'ext': 'mp4',
2800             'title': 'Small Scale Baler and Braiding Rugs',
2801             'uploader': 'Backus-Page House Museum',
2802             'uploader_id': 'backuspagemuseum',
2803             'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/backuspagemuseum',
2804             'upload_date': '20161008',
2805             'description': 'md5:800c0c78d5eb128500bffd4f0b4f2e8a',
2806             'categories': ['Nonprofits &amp; Activism'],
2807             'tags': list,
2808             'like_count': int,
2809             'dislike_count': int,
2810         },
2811         'params': {
2812             'noplaylist': True,
2813             'skip_download': True,
2814         },
2815     }, {
2816         'url': 'https://youtu.be/uWyaPkt-VOI?list=PL9D9FC436B881BA21',
2817         'only_matching': True,
2818     }]
2819     def _real_extract(self, url):
2820         mobj = re.match(self._VALID_URL, url)
2821         video_id = mobj.group('id')
2822         playlist_id = mobj.group('playlist_id')
2823         return self.url_result(
2824             update_url_query('https://www.youtube.com/watch', {
2825                 'v': video_id,
2826                 'list': playlist_id,
2827                 'feature': 'youtu.be',
2828             }), ie=YoutubeTabIE.ie_key(), video_id=playlist_id)
2829 class YoutubeYtUserIE(InfoExtractor):
2830     _VALID_URL = r'ytuser:(?P&lt;id&gt;.+)'
2831     _TESTS = [{
2832         'url': 'ytuser:phihag',
2833         'only_matching': True,
2834     }]
2835     def _real_extract(self, url):
2836         user_id = self._match_id(url)
2837         return self.url_result(
2838             'https://www.youtube.com/user/%s' % user_id,
2839             ie=YoutubeTabIE.ie_key(), video_id=user_id)
2840 class YoutubeFavouritesIE(YoutubeBaseInfoExtractor):
2841     IE_NAME = 'youtube:favorites'
2842     IE_DESC = 'YouTube.com favourite videos, ":ytfav" for short (requires authentication)'
2843     _VALID_URL = r'https?://(?:www\.)?youtube\.com/my_favorites|:ytfav(?:ou?rites)?'
2844     _LOGIN_REQUIRED = True
2845     _TESTS = [{
2846         'url': ':ytfav',
2847         'only_matching': True,
2848     }, {
2849         'url': ':ytfavorites',
2850         'only_matching': True,
2851     }]
2852     def _real_extract(self, url):
2853         return self.url_result(
2854             'https://www.youtube.com/playlist?list=LL',
2855             ie=YoutubeTabIE.ie_key())
2856 class YoutubeSearchIE(SearchInfoExtractor, YoutubeBaseInfoExtractor):
2857     IE_DESC = 'YouTube.com searches'
2858     IE_NAME = 'youtube:search'
2859     _SEARCH_KEY = 'ytsearch'
2860     _SEARCH_PARAMS = 'EgIQAQ%3D%3D'  # Videos only
2861     _MAX_RESULTS = float('inf')
2862     _TESTS = [{
2863         'url': 'ytsearch10:youtube-dl test video',
2864         'playlist_count': 10,
2865         'info_dict': {
2866             'id': 'youtube-dl test video',
2867             'title': 'youtube-dl test video',
2868         }
2869     }]
2870     def _get_n_results(self, query, n):
2871         entries = itertools.islice(self._search_results(query, self._SEARCH_PARAMS), 0, None if n == float('inf') else n)
2872         return self.playlist_result(entries, query, query)
2873 class YoutubeSearchDateIE(YoutubeSearchIE):
2874     IE_NAME = YoutubeSearchIE.IE_NAME + ':date'
2875     _SEARCH_KEY = 'ytsearchdate'
2876     IE_DESC = 'YouTube.com searches, newest videos first'
2877     _SEARCH_PARAMS = 'CAISAhAB'  # Videos only, sorted by date
2878     _TESTS = [{
2879         'url': 'ytsearchdate10:youtube-dl test video',
2880         'playlist_count': 10,
2881         'info_dict': {
2882             'id': 'youtube-dl test video',
2883             'title': 'youtube-dl test video',
2884         }
2885     }]
2886 class YoutubeSearchURLIE(YoutubeBaseInfoExtractor):
2887     IE_DESC = 'YouTube search URLs with sorting and filter support'
2888     IE_NAME = YoutubeSearchIE.IE_NAME + '_url'
2889     _VALID_URL = r'https?://(?:www\.)?youtube\.com/results\?(.*?&amp;)?(?:search_query|q)=(?:[^&amp;]+)(?:[&amp;]|$)'
2890     _TESTS = [{
2891         'url': 'https://www.youtube.com/results?baz=bar&amp;search_query=youtube-dl+test+video&amp;filters=video&amp;lclk=video',
2892         'playlist_mincount': 5,
2893         'info_dict': {
2894             'id': 'youtube-dl test video',
2895             'title': 'youtube-dl test video',
2896         },
2897         'params': {'playlistend': 5}
2898     }, {
2899         'url': 'https://www.youtube.com/results?q=test&amp;sp=EgQIBBgB',
2900         'only_matching': True,
2901     }]
2902     def _real_extract(self, url):
2903         qs = compat_parse_qs(compat_urllib_parse_urlparse(url).query)
2904         query = (qs.get('search_query') or qs.get('q'))[0]
2905         params = qs.get('sp', ('',))[0]
2906         return self.playlist_result(self._search_results(query, params), query, query)
2907 class YoutubeFeedsInfoExtractor(YoutubeTabIE):
2908     _LOGIN_REQUIRED = True
2909     @property
2910     def IE_NAME(self):
2911         return 'youtube:%s' % self._FEED_NAME
2912     def _real_initialize(self):
2913         self._login()
2914     def _real_extract(self, url):
2915         return self.url_result(
2916             'https://www.youtube.com/feed/%s' % self._FEED_NAME,
2917             ie=YoutubeTabIE.ie_key())
2918 class YoutubeWatchLaterIE(InfoExtractor):
2919     IE_NAME = 'youtube:watchlater'
2920     IE_DESC = 'Youtube watch later list, ":ytwatchlater" for short (requires authentication)'
2921     _VALID_URL = r':ytwatchlater'
2922     _TESTS = [{
2923         'url': ':ytwatchlater',
2924         'only_matching': True,
2925     }]
2926     def _real_extract(self, url):
2927         return self.url_result(
2928             'https://www.youtube.com/playlist?list=WL', ie=YoutubeTabIE.ie_key())
2929 class YoutubeRecommendedIE(YoutubeFeedsInfoExtractor):
2930     IE_DESC = 'YouTube.com recommended videos, ":ytrec" for short (requires authentication)'
2931     _VALID_URL = r':ytrec(?:ommended)?'
2932     _FEED_NAME = 'recommended'
2933     _TESTS = [{
2934         'url': ':ytrec',
2935         'only_matching': True,
2936     }, {
2937         'url': ':ytrecommended',
2938         'only_matching': True,
2939     }]
2940 class YoutubeSubscriptionsIE(YoutubeFeedsInfoExtractor):
2941     IE_DESC = 'YouTube.com subscriptions feed, "ytsubs" keyword (requires authentication)'
2942     _VALID_URL = r':ytsubs(?:criptions)?'
2943     _FEED_NAME = 'subscriptions'
2944     _TESTS = [{
2945         'url': ':ytsubs',
2946         'only_matching': True,
2947     }, {
2948         'url': ':ytsubscriptions',
2949         'only_matching': True,
2950     }]
2951 class YoutubeHistoryIE(YoutubeFeedsInfoExtractor):
2952     IE_DESC = 'Youtube watch history, ":ythistory" for short (requires authentication)'
2953     _VALID_URL = r':ythistory'
2954     _FEED_NAME = 'history'
2955     _TESTS = [{
2956         'url': ':ythistory',
2957         'only_matching': True,
2958     }]
2959 class YoutubeTruncatedURLIE(InfoExtractor):
2960     IE_NAME = 'youtube:truncated_url'
2961     IE_DESC = False  # Do not list
2962     _VALID_URL = r'''(?x)
2963         (?:https?://)?
2964         (?:\w+\.)?[yY][oO][uU][tT][uU][bB][eE](?:-nocookie)?\.com/
2965         (?:watch\?(?:
2966             feature=[a-z_]+|
2967             annotation_id=annotation_[^&amp;]+|
2968             x-yt-cl=[0-9]+|
2969             hl=[^&amp;]*|
2970             t=[0-9]+
2971         )?
2972         |
2973             attribution_link\?a=[^&amp;]+
2974         )
2975         $
2976     '''
2977     _TESTS = [{
2978         'url': 'https://www.youtube.com/watch?annotation_id=annotation_3951667041',
2979         'only_matching': True,
2980     }, {
2981         'url': 'https://www.youtube.com/watch?',
2982         'only_matching': True,
2983     }, {
2984         'url': 'https://www.youtube.com/watch?x-yt-cl=84503534',
2985         'only_matching': True,
2986     }, {
2987         'url': 'https://www.youtube.com/watch?feature=foo',
2988         'only_matching': True,
2989     }, {
2990         'url': 'https://www.youtube.com/watch?hl=en-GB',
2991         'only_matching': True,
2992     }, {
2993         'url': 'https://www.youtube.com/watch?t=2372',
2994         'only_matching': True,
2995     }]
2996     def _real_extract(self, url):
2997         raise ExtractorError(
2998             'Did you forget to quote the URL? Remember that &amp; is a meta '
2999             'character in most shells, so you want to put the URL in quotes, '
3000             'like  youtube-dl '
3001             '"https://www.youtube.com/watch?feature=foo&amp;v=BaW_jenozKc" '
3002             ' or simply  youtube-dl BaW_jenozKc  .',
3003             expected=True)
3004 class YoutubeTruncatedIDIE(InfoExtractor):
3005     IE_NAME = 'youtube:truncated_id'
3006     IE_DESC = False  # Do not list
3007     _VALID_URL = r'https?://(?:www\.)?youtube\.com/watch\?v=(?P&lt;id&gt;[0-9A-Za-z_-]{1,10})$'
3008     _TESTS = [{
3009         'url': 'https://www.youtube.com/watch?v=N_708QY7Ob',
3010         'only_matching': True,
3011     }]
3012     def _real_extract(self, url):
3013         video_id = self._match_id(url)
3014         raise ExtractorError(
3015             'Incomplete YouTube ID %s. URL %s looks truncated.' % (video_id, url),
3016             expected=True)
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
