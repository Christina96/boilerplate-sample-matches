<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for theplatform.py &amp; youtube.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for theplatform.py &amp; youtube.py
      </h3>
<h1 align="center">
        1.2%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>theplatform.py (4.787234%)<th>youtube.py (0.71428573%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(128-196)<td><a href="#" name="0">(506-593)</a><td align="center"><font color="#ff0000">15</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(87-89)<td><a href="#" name="1">(2041-2042)</a><td align="center"><font color="#cc0000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>theplatform.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 from __future__ import unicode_literals
2 import re
3 import time
4 import hmac
5 import binascii
6 import hashlib
7 from .once import OnceIE
8 from .adobepass import AdobePassIE
9 from ..compat import (
10     compat_parse_qs,
11     compat_urllib_parse_urlparse,
12 )
13 from ..utils import (
14     determine_ext,
15     ExtractorError,
16     float_or_none,
17     int_or_none,
18     sanitized_Request,
19     unsmuggle_url,
20     update_url_query,
21     xpath_with_ns,
22     mimetype2ext,
23     find_xpath_attr,
24 )
25 default_ns = 'http://www.w3.org/2005/SMIL21/Language'
26 _x = lambda p: xpath_with_ns(p, {'smil': default_ns})
27 class ThePlatformBaseIE(OnceIE):
28     _TP_TLD = 'com'
29     def _extract_theplatform_smil(self, smil_url, video_id, note='Downloading SMIL data'):
30         meta = self._download_xml(
31             smil_url, video_id, note=note, query={'format': 'SMIL'},
32             headers=self.geo_verification_headers())
33         error_element = find_xpath_attr(meta, _x('.//smil:ref'), 'src')
34         if error_element is not None:
35             exception = find_xpath_attr(
36                 error_element, _x('.//smil:param'), 'name', 'exception')
37             if exception is not None:
38                 if exception.get('value') == 'GeoLocationBlocked':
39                     self.raise_geo_restricted(error_element.attrib['abstract'])
40                 elif error_element.attrib['src'].startswith(
41                         'http://link.theplatform.%s/s/errorFiles/Unavailable.'
42                         % self._TP_TLD):
43                     raise ExtractorError(
44                         error_element.attrib['abstract'], expected=True)
45         smil_formats = self._parse_smil_formats(
46             meta, smil_url, video_id, namespace=default_ns,
47             f4m_params={'g': 'UXWGVKRWHFSP', 'hdcore': '3.0.3'},
48             transform_rtmp_url=lambda streamer, src: (streamer, 'mp4:' + src))
49         formats = []
50         for _format in smil_formats:
51             if OnceIE.suitable(_format['url']):
52                 formats.extend(self._extract_once_formats(_format['url']))
53             else:
54                 media_url = _format['url']
55                 if determine_ext(media_url) == 'm3u8':
56                     hdnea2 = self._get_cookies(media_url).get('hdnea2')
57                     if hdnea2:
58                         _format['url'] = update_url_query(media_url, {'hdnea3': hdnea2.value})
59                 formats.append(_format)
60         subtitles = self._parse_smil_subtitles(meta, default_ns)
61         return formats, subtitles
62     def _download_theplatform_metadata(self, path, video_id):
63         info_url = 'http://link.theplatform.%s/s/%s?format=preview' % (self._TP_TLD, path)
64         return self._download_json(info_url, video_id)
65     def _parse_theplatform_metadata(self, info):
66         subtitles = {}
67 <a name="1"></a>        captions = info.get('captions')
68         if isinstance(captions, list):
69             for caption in captions:
70                 lang, src, mime = caption<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.get('lang', 'en'), caption.get('src'), caption.get('type')
71                 subtitles.setdefault(lang, []).append({
72                     'ext': mimetype2ext(</b></font>mime),
73                     'url': src,
74                 })
75         duration = info.get('duration')
76         tp_chapters = info.get('chapters', [])
77         chapters = []
78         if tp_chapters:
79             def _add_chapter(start_time, end_time):
80                 start_time = float_or_none(start_time, 1000)
81                 end_time = float_or_none(end_time, 1000)
82                 if start_time is None or end_time is None:
83                     return
84                 chapters.append({
85                     'start_time': start_time,
86                     'end_time': end_time,
87                 })
88             for chapter in tp_chapters[:-1]:
89                 _add_chapter(chapter.get('startTime'), chapter.get('endTime'))
90             _add_chapter(tp_chapters[-1].get('startTime'), tp_chapters[-1].get('endTime') or duration)
91         return {
92             'title': info['title'],
93             'subtitles': subtitles,
94             'description': info['description'],
95             'thumbnail': info['defaultThumbnailUrl'],
96             'duration': float_or_none(duration, 1000),
97             'timestamp': int_or_none(info.get('pubDate'), 1000) or None,
98             'uploader': info.get('billingCode'),
99             'chapters': chapters,
100         }
101     def _extract_theplatform_metadata(self, path, video_id):
102         info = self._download_theplatform_metadata(path, video_id)
103         return self._parse_theplatform_metadata(info)
104 <a name="0"></a>
105 class ThePlatformIE(ThePlatformBaseIE, AdobePassIE):
106     _VALID_URL <font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>= r'''(?x)
107         (?:https?://(?:link|player)\.theplatform\.com/[sp]/(?P&lt;provider_id&gt;[^/]+)/
108            (?:(?:(?:[^/]+/)+select/)?(?P&lt;media&gt;media/(?:guid/\d+/)?)?|(?P&lt;config&gt;(?:[^/\?]+/(?:swf|config)|onsite)/select/))?
109          |theplatform:)(?P&lt;id&gt;[^/\?&amp;]+)'''
110     _TESTS = [{
111         'url': 'http://link.theplatform.com/s/dJ5BDC/e9I_cZgTgIPd/meta.smil?format=smil&amp;Tracking=true&amp;mbr=true',
112         'info_dict': {
113             'id': 'e9I_cZgTgIPd',
114             'ext': 'flv',
115             'title': 'Blackberry\'s big, bold Z30',
116             'description': 'The Z30 is Blackberry\'s biggest, baddest mobile messaging device yet.',
117             'duration': 247,
118             'timestamp': 1383239700,
119             'upload_date': '20131031',
120             'uploader': 'CBSI-NEW',
121         },
122         'params': {
123             'skip_download': True,
124         },
125         'skip': '404 Not Found',
126     }, {
127         'url': 'http://link.theplatform.com/s/kYEXFC/22d_qsQ6MIRT',
128         'info_dict': {
129             'id': '22d_qsQ6MIRT',
130             'ext': 'flv',
131             'description': 'md5:ac330c9258c04f9d7512cf26b9595409',
132             'title': 'Tesla Model S: A second step towards a cleaner motoring future',
133             'timestamp': 1426176191,
134             'upload_date': '20150312',
135             'uploader': 'CBSI-NEW',
136         },
137         'params': {
138             'skip_download': True,
139         }
140     }, {
141         'url': 'https://player.theplatform.com/p/D6x-PC/pulse_preview/embed/select/media/yMBg9E8KFxZD',
142         'info_dict': {
143             'id': 'yMBg9E8KFxZD',
144             'ext': 'mp4',
145             'description': 'md5:644ad9188d655b742f942bf2e06b002d',
146             'title': 'HIGHLIGHTS: USA bag first ever series Cup win',
147             'uploader': 'EGSM',
148         }
149     }, {
150         'url': 'http://player.theplatform.com/p/NnzsPC/widget/select/media/4Y0TlYUr_ZT7',
151         'only_matching': True,
152     }, {
153         'url': 'http://player.theplatform.com/p/2E2eJC/nbcNewsOffsite?guid=tdy_or_siri_150701',
154         'md5': 'fb96bb3d85118930a5b055783a3bd992',
155         'info_dict': {
156             'id': 'tdy_or_siri_150701',
157             'ext': 'mp4',
158             'title': 'iPhone Siri’s sassy response to a math question has people talking',
159             'description': 'md5:a565d1deadd5086f3331d57298ec6333',
160             'duration': 83.0,
161             'thumbnail': r're:^https?://.*\.jpg$',
162             'timestamp': 1435752600,
163             'upload_date': '20150701',
164             'uploader': 'NBCU-NEWS',
165         },
166     }, {
167         'url'</b></font>: 'http://player.theplatform.com/p/NnzsPC/onsite_universal/select/media/guid/2410887629/2928790?fwsitesection=nbc_the_blacklist_video_library&amp;autoPlay=true&amp;carouselID=137781',
168         'only_matching': True,
169     }]
170     @classmethod
171     def _extract_urls(cls, webpage):
172         m = re.search(
173             r'''(?x)
174                     &lt;meta\s+
175                         property=(["'])(?:og:video(?::(?:secure_)?url)?|twitter:player)\1\s+
176                         content=(["'])(?P&lt;url&gt;https?://player\.theplatform\.com/p/.+?)\2
177             ''', webpage)
178         if m:
179             return [m.group('url')]
180         matches = re.findall(
181             r'(?s)&lt;(?:iframe|script)[^&gt;]+src=(["\'])((?:https?:)?//player\.theplatform\.com/p/.+?)\1', webpage)
182         if matches:
183             return [re.sub(r'\s', '', list(zip(*matches))[1][0])]
184     @staticmethod
185     def _sign_url(url, sig_key, sig_secret, life=600, include_qs=False):
186         flags = '10' if include_qs else '00'
187         expiration_date = '%x' % (int(time.time()) + life)
188         def str_to_hex(str):
189             return binascii.b2a_hex(str.encode('ascii')).decode('ascii')
190         def hex_to_bytes(hex):
191             return binascii.a2b_hex(hex.encode('ascii'))
192         relative_path = re.match(r'https?://link\.theplatform\.com/s/([^?]+)', url).group(1)
193         clear_text = hex_to_bytes(flags + expiration_date + str_to_hex(relative_path))
194         checksum = hmac.new(sig_key.encode('ascii'), clear_text, hashlib.sha1).hexdigest()
195         sig = flags + expiration_date + checksum + str_to_hex(sig_secret)
196         return '%s&amp;sig=%s' % (url, sig)
197     def _real_extract(self, url):
198         url, smuggled_data = unsmuggle_url(url, {})
199         self._initialize_geo_bypass({
200             'countries': smuggled_data.get('geo_countries'),
201         })
202         mobj = re.match(self._VALID_URL, url)
203         provider_id = mobj.group('provider_id')
204         video_id = mobj.group('id')
205         if not provider_id:
206             provider_id = 'dJ5BDC'
207         path = provider_id + '/'
208         if mobj.group('media'):
209             path += mobj.group('media')
210         path += video_id
211         qs_dict = compat_parse_qs(compat_urllib_parse_urlparse(url).query)
212         if 'guid' in qs_dict:
213             webpage = self._download_webpage(url, video_id)
214             scripts = re.findall(r'&lt;script[^&gt;]+src="([^"]+)"', webpage)
215             feed_id = None
216             for script in reversed(scripts):
217                 feed_script = self._download_webpage(
218                     self._proto_relative_url(script, 'http:'),
219                     video_id, 'Downloading feed script')
220                 feed_id = self._search_regex(
221                     r'defaultFeedId\s*:\s*"([^"]+)"', feed_script,
222                     'default feed id', default=None)
223                 if feed_id is not None:
224                     break
225             if feed_id is None:
226                 raise ExtractorError('Unable to find feed id')
227             return self.url_result('http://feed.theplatform.com/f/%s/%s?byGuid=%s' % (
228                 provider_id, feed_id, qs_dict['guid'][0]))
229         if smuggled_data.get('force_smil_url', False):
230             smil_url = url
231         elif '/guid/' in url:
232             headers = {}
233             source_url = smuggled_data.get('source_url')
234             if source_url:
235                 headers['Referer'] = source_url
236             request = sanitized_Request(url, headers=headers)
237             webpage = self._download_webpage(request, video_id)
238             smil_url = self._search_regex(
239                 r'&lt;link[^&gt;]+href=(["\'])(?P&lt;url&gt;.+?)\1[^&gt;]+type=["\']application/smil\+xml',
240                 webpage, 'smil url', group='url')
241             path = self._search_regex(
242                 r'link\.theplatform\.com/s/((?:[^/?#&amp;]+/)+[^/?#&amp;]+)', smil_url, 'path')
243             smil_url += '?' if '?' not in smil_url else '&amp;' + 'formats=m3u,mpeg4'
244         elif mobj.group('config'):
245             config_url = url + '&amp;form=json'
246             config_url = config_url.replace('swf/', 'config/')
247             config_url = config_url.replace('onsite/', 'onsite/config/')
248             config = self._download_json(config_url, video_id, 'Downloading config')
249             if 'releaseUrl' in config:
250                 release_url = config['releaseUrl']
251             else:
252                 release_url = 'http://link.theplatform.com/s/%s?mbr=true' % path
253             smil_url = release_url + '&amp;formats=MPEG4&amp;manifest=f4m'
254         else:
255             smil_url = 'http://link.theplatform.com/s/%s?mbr=true' % path
256         sig = smuggled_data.get('sig')
257         if sig:
258             smil_url = self._sign_url(smil_url, sig['key'], sig['secret'])
259         formats, subtitles = self._extract_theplatform_smil(smil_url, video_id)
260         self._sort_formats(formats)
261         ret = self._extract_theplatform_metadata(path, video_id)
262         combined_subtitles = self._merge_subtitles(ret.get('subtitles', {}), subtitles)
263         ret.update({
264             'id': video_id,
265             'formats': formats,
266             'subtitles': combined_subtitles,
267         })
268         return ret
269 class ThePlatformFeedIE(ThePlatformBaseIE):
270     _URL_TEMPLATE = '%s//feed.theplatform.com/f/%s/%s?form=json&amp;%s'
271     _VALID_URL = r'https?://feed\.theplatform\.com/f/(?P&lt;provider_id&gt;[^/]+)/(?P&lt;feed_id&gt;[^?/]+)\?(?:[^&amp;]+&amp;)*(?P&lt;filter&gt;by(?:Gui|I)d=(?P&lt;id&gt;[^&amp;]+))'
272     _TESTS = [{
273         'url': 'http://feed.theplatform.com/f/7wvmTC/msnbc_video-p-test?form=json&amp;pretty=true&amp;range=-40&amp;byGuid=n_hardball_5biden_140207',
274         'md5': '6e32495b5073ab414471b615c5ded394',
275         'info_dict': {
276             'id': 'n_hardball_5biden_140207',
277             'ext': 'mp4',
278             'title': 'The Biden factor: will Joe run in 2016?',
279             'description': 'Could Vice President Joe Biden be preparing a 2016 campaign? Mark Halperin and Sam Stein weigh in.',
280             'thumbnail': r're:^https?://.*\.jpg$',
281             'upload_date': '20140208',
282             'timestamp': 1391824260,
283             'duration': 467.0,
284             'categories': ['MSNBC/Issues/Democrats', 'MSNBC/Issues/Elections/Election 2016'],
285             'uploader': 'NBCU-NEWS',
286         },
287     }, {
288         'url': 'http://feed.theplatform.com/f/2E2eJC/nnd_NBCNews?byGuid=nn_netcast_180306.Copy.01',
289         'only_matching': True,
290     }]
291     def _extract_feed_info(self, provider_id, feed_id, filter_query, video_id, custom_fields=None, asset_types_query={}, account_id=None):
292         real_url = self._URL_TEMPLATE % (self.http_scheme(), provider_id, feed_id, filter_query)
293         entry = self._download_json(real_url, video_id)['entries'][0]
294         main_smil_url = 'http://link.theplatform.com/s/%s/media/guid/%d/%s' % (provider_id, account_id, entry['guid']) if account_id else entry.get('plmedia$publicUrl')
295         formats = []
296         subtitles = {}
297         first_video_id = None
298         duration = None
299         asset_types = []
300         for item in entry['media$content']:
301             smil_url = item['plfile$url']
302             cur_video_id = ThePlatformIE._match_id(smil_url)
303             if first_video_id is None:
304                 first_video_id = cur_video_id
305                 duration = float_or_none(item.get('plfile$duration'))
306             file_asset_types = item.get('plfile$assetTypes') or compat_parse_qs(compat_urllib_parse_urlparse(smil_url).query)['assetTypes']
307             for asset_type in file_asset_types:
308                 if asset_type in asset_types:
309                     continue
310                 asset_types.append(asset_type)
311                 query = {
312                     'mbr': 'true',
313                     'formats': item['plfile$format'],
314                     'assetTypes': asset_type,
315                 }
316                 if asset_type in asset_types_query:
317                     query.update(asset_types_query[asset_type])
318                 cur_formats, cur_subtitles = self._extract_theplatform_smil(update_url_query(
319                     main_smil_url or smil_url, query), video_id, 'Downloading SMIL data for %s' % asset_type)
320                 formats.extend(cur_formats)
321                 subtitles = self._merge_subtitles(subtitles, cur_subtitles)
322         self._sort_formats(formats)
323         thumbnails = [{
324             'url': thumbnail['plfile$url'],
325             'width': int_or_none(thumbnail.get('plfile$width')),
326             'height': int_or_none(thumbnail.get('plfile$height')),
327         } for thumbnail in entry.get('media$thumbnails', [])]
328         timestamp = int_or_none(entry.get('media$availableDate'), scale=1000)
329         categories = [item['media$name'] for item in entry.get('media$categories', [])]
330         ret = self._extract_theplatform_metadata('%s/%s' % (provider_id, first_video_id), video_id)
331         subtitles = self._merge_subtitles(subtitles, ret['subtitles'])
332         ret.update({
333             'id': video_id,
334             'formats': formats,
335             'subtitles': subtitles,
336             'thumbnails': thumbnails,
337             'duration': duration,
338             'timestamp': timestamp,
339             'categories': categories,
340         })
341         if custom_fields:
342             ret.update(custom_fields(entry))
343         return ret
344     def _real_extract(self, url):
345         mobj = re.match(self._VALID_URL, url)
346         video_id = mobj.group('id')
347         provider_id = mobj.group('provider_id')
348         feed_id = mobj.group('feed_id')
349         filter_query = mobj.group('filter')
350         return self._extract_feed_info(provider_id, feed_id, filter_query, video_id)
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>youtube.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 from __future__ import unicode_literals
2 import itertools
3 import json
4 import os.path
5 import random
6 import re
7 import traceback
8 from .common import InfoExtractor, SearchInfoExtractor
9 from ..compat import (
10     compat_chr,
11     compat_HTTPError,
12     compat_map as map,
13     compat_parse_qs,
14     compat_str,
15     compat_urllib_parse_unquote_plus,
16     compat_urllib_parse_urlencode,
17     compat_urllib_parse_urlparse,
18     compat_urlparse,
19 )
20 from ..jsinterp import JSInterpreter
21 from ..utils import (
22     ExtractorError,
23     clean_html,
24     dict_get,
25     error_to_compat_str,
26     float_or_none,
27     int_or_none,
28     js_to_json,
29     mimetype2ext,
30     parse_codecs,
31     parse_duration,
32     qualities,
33     remove_start,
34     smuggle_url,
35     str_or_none,
36     str_to_int,
37     try_get,
38     unescapeHTML,
39     unified_strdate,
40     unsmuggle_url,
41     update_url_query,
42     url_or_none,
43     urlencode_postdata,
44     urljoin,
45 )
46 def parse_qs(url):
47     return compat_urlparse.parse_qs(compat_urlparse.urlparse(url).query)
48 class YoutubeBaseInfoExtractor(InfoExtractor):
49     _LOGIN_URL = 'https://accounts.google.com/ServiceLogin'
50     _TWOFACTOR_URL = 'https://accounts.google.com/signin/challenge'
51     _LOOKUP_URL = 'https://accounts.google.com/_/signin/sl/lookup'
52     _CHALLENGE_URL = 'https://accounts.google.com/_/signin/sl/challenge'
53     _TFA_URL = 'https://accounts.google.com/_/signin/challenge?hl=en&amp;TL={0}'
54     _NETRC_MACHINE = 'youtube'
55     _LOGIN_REQUIRED = False
56     _PLAYLIST_ID_RE = r'(?:(?:PL|LL|EC|UU|FL|RD|UL|TL|PU|OLAK5uy_)[0-9A-Za-z-_]{10,}|RDMM)'
57     def _login(self):
58         username, password = self._get_login_info()
59         if username is None:
60             if self._LOGIN_REQUIRED and self._downloader.params.get('cookiefile') is None:
61                 raise ExtractorError('No login info available, needed for using %s.' % self.IE_NAME, expected=True)
62             return True
63         login_page = self._download_webpage(
64             self._LOGIN_URL, None,
65             note='Downloading login page',
66             errnote='unable to fetch login page', fatal=False)
67         if login_page is False:
68             return
69         login_form = self._hidden_inputs(login_page)
70         def req(url, f_req, note, errnote):
71             data = login_form.copy()
72             data.update({
73                 'pstMsg': 1,
74                 'checkConnection': 'youtube',
75                 'checkedDomains': 'youtube',
76                 'hl': 'en',
77                 'deviceinfo': '[null,null,null,[],null,"US",null,null,[],"GlifWebSignIn",null,[null,null,[]]]',
78                 'f.req': json.dumps(f_req),
79                 'flowName': 'GlifWebSignIn',
80                 'flowEntry': 'ServiceLogin',
81                 'bgRequest': '["identifier",""]',
82             })
83             return self._download_json(
84                 url, None, note=note, errnote=errnote,
85                 transform_source=lambda s: re.sub(r'^[^[]*', '', s),
86                 fatal=False,
87                 data=urlencode_postdata(data), headers={
88                     'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8',
89                     'Google-Accounts-XSRF': 1,
90                 })
91         def warn(message):
92             self._downloader.report_warning(message)
93         lookup_req = [
94             username,
95             None, [], None, 'US', None, None, 2, False, True,
96             [
97                 None, None,
98                 [2, 1, None, 1,
99                  'https://accounts.google.com/ServiceLogin?passive=true&amp;continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Fnext%3D%252F%26action_handle_signin%3Dtrue%26hl%3Den%26app%3Ddesktop%26feature%3Dsign_in_button&amp;hl=en&amp;service=youtube&amp;uilel=3&amp;requestPath=%2FServiceLogin&amp;Page=PasswordSeparationSignIn',
100                  None, [], 4],
101                 1, [None, None, []], None, None, None, True
102             ],
103             username,
104         ]
105         lookup_results = req(
106             self._LOOKUP_URL, lookup_req,
107             'Looking up account info', 'Unable to look up account info')
108         if lookup_results is False:
109             return False
110         user_hash = try_get(lookup_results, lambda x: x[0][2], compat_str)
111         if not user_hash:
112             warn('Unable to extract user hash')
113             return False
114         challenge_req = [
115             user_hash,
116             None, 1, None, [1, None, None, None, [password, None, True]],
117             [
118                 None, None, [2, 1, None, 1, 'https://accounts.google.com/ServiceLogin?passive=true&amp;continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Fnext%3D%252F%26action_handle_signin%3Dtrue%26hl%3Den%26app%3Ddesktop%26feature%3Dsign_in_button&amp;hl=en&amp;service=youtube&amp;uilel=3&amp;requestPath=%2FServiceLogin&amp;Page=PasswordSeparationSignIn', None, [], 4],
119                 1, [None, None, []], None, None, None, True
120             ]]
121         challenge_results = req(
122             self._CHALLENGE_URL, challenge_req,
123             'Logging in', 'Unable to log in')
124         if challenge_results is False:
125             return
126         login_res = try_get(challenge_results, lambda x: x[0][5], list)
127         if login_res:
128             login_msg = try_get(login_res, lambda x: x[5], compat_str)
129             warn(
130                 'Unable to login: %s' % 'Invalid password'
131                 if login_msg == 'INCORRECT_ANSWER_ENTERED' else login_msg)
132             return False
133         res = try_get(challenge_results, lambda x: x[0][-1], list)
134         if not res:
135             warn('Unable to extract result entry')
136             return False
137         login_challenge = try_get(res, lambda x: x[0][0], list)
138         if login_challenge:
139             challenge_str = try_get(login_challenge, lambda x: x[2], compat_str)
140             if challenge_str == 'TWO_STEP_VERIFICATION':
141                 status = try_get(login_challenge, lambda x: x[5], compat_str)
142                 if status == 'QUOTA_EXCEEDED':
143                     warn('Exceeded the limit of TFA codes, try later')
144                     return False
145                 tl = try_get(challenge_results, lambda x: x[1][2], compat_str)
146                 if not tl:
147                     warn('Unable to extract TL')
148                     return False
149                 tfa_code = self._get_tfa_info('2-step verification code')
150                 if not tfa_code:
151                     warn(
152                         'Two-factor authentication required. Provide it either interactively or with --twofactor &lt;code&gt;'
153                         '(Note that only TOTP (Google Authenticator App) codes work at this time.)')
154                     return False
155                 tfa_code = remove_start(tfa_code, 'G-')
156                 tfa_req = [
157                     user_hash, None, 2, None,
158                     [
159                         9, None, None, None, None, None, None, None,
160                         [None, tfa_code, True, 2]
161                     ]]
162                 tfa_results = req(
163                     self._TFA_URL.format(tl), tfa_req,
164                     'Submitting TFA code', 'Unable to submit TFA code')
165                 if tfa_results is False:
166                     return False
167                 tfa_res = try_get(tfa_results, lambda x: x[0][5], list)
168                 if tfa_res:
169                     tfa_msg = try_get(tfa_res, lambda x: x[5], compat_str)
170                     warn(
171                         'Unable to finish TFA: %s' % 'Invalid TFA code'
172                         if tfa_msg == 'INCORRECT_ANSWER_ENTERED' else tfa_msg)
173                     return False
174                 check_cookie_url = try_get(
175                     tfa_results, lambda x: x[0][-1][2], compat_str)
176             else:
177                 CHALLENGES = {
178                     'LOGIN_CHALLENGE': "This device isn't recognized. For your security, Google wants to make sure it's really you.",
179                     'USERNAME_RECOVERY': 'Please provide additional information to aid in the recovery process.',
180                     'REAUTH': "There is something unusual about your activity. For your security, Google wants to make sure it's really you.",
181                 }
182                 challenge = CHALLENGES.get(
183                     challenge_str,
184                     '%s returned error %s.' % (self.IE_NAME, challenge_str))
185                 warn('%s\nGo to https://accounts.google.com/, login and solve a challenge.' % challenge)
186                 return False
187         else:
188             check_cookie_url = try_get(res, lambda x: x[2], compat_str)
189         if not check_cookie_url:
190             warn('Unable to extract CheckCookie URL')
191             return False
192         check_cookie_results = self._download_webpage(
193             check_cookie_url, None, 'Checking cookie', fatal=False)
194         if check_cookie_results is False:
195             return False
196         if 'https://myaccount.google.com/' not in check_cookie_results:
197             warn('Unable to log in')
198             return False
199         return True
200     def _initialize_consent(self):
201         cookies = self._get_cookies('https://www.youtube.com/')
202         if cookies.get('__Secure-3PSID'):
203             return
204         consent_id = None
205         consent = cookies.get('CONSENT')
206         if consent:
207             if 'YES' in consent.value:
208                 return
209             consent_id = self._search_regex(
210                 r'PENDING\+(\d+)', consent.value, 'consent', default=None)
211         if not consent_id:
212             consent_id = random.randint(100, 999)
213         self._set_cookie('.youtube.com', 'CONSENT', 'YES+cb.20210328-17-p0.en+FX+%s' % consent_id)
214     def _real_initialize(self):
215         self._initialize_consent()
216         if self._downloader is None:
217             return
218         if not self._login():
219             return
220     _DEFAULT_API_DATA = {
221         'context': {
222             'client': {
223                 'clientName': 'WEB',
224                 'clientVersion': '2.20201021.03.00',
225             }
226         },
227     }
228     _YT_INITIAL_DATA_RE = r'(?:window\s*\[\s*["\']ytInitialData["\']\s*\]|ytInitialData)\s*=\s*({.+?})\s*;'
229     _YT_INITIAL_PLAYER_RESPONSE_RE = r'ytInitialPlayerResponse\s*=\s*({.+?})\s*;'
230     _YT_INITIAL_BOUNDARY_RE = r'(?:var\s+meta|&lt;/script|\n)'
231     def _call_api(self, ep, query, video_id, fatal=True):
232         data = self._DEFAULT_API_DATA.copy()
233         data.update(query)
234         return self._download_json(
235             'https://www.youtube.com/youtubei/v1/%s' % ep, video_id=video_id,
236             note='Downloading API JSON', errnote='Unable to download API page',
237             data=json.dumps(data).encode('utf8'), fatal=fatal,
238             headers={'content-type': 'application/json'},
239             query={'key': 'AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8'})
240     def _extract_yt_initial_data(self, video_id, webpage):
241         return self._parse_json(
242             self._search_regex(
243                 (r'%s\s*%s' % (self._YT_INITIAL_DATA_RE, self._YT_INITIAL_BOUNDARY_RE),
244                  self._YT_INITIAL_DATA_RE), webpage, 'yt initial data'),
245             video_id)
246     def _extract_ytcfg(self, video_id, webpage):
247         return self._parse_json(
248             self._search_regex(
249                 r'ytcfg\.set\s*\(\s*({.+?})\s*\)\s*;', webpage, 'ytcfg',
250                 default='{}'), video_id, fatal=False) or {}
251     def _extract_video(self, renderer):
252         video_id = renderer['videoId']
253         title = try_get(
254             renderer,
255             (lambda x: x['title']['runs'][0]['text'],
256              lambda x: x['title']['simpleText']), compat_str)
257         description = try_get(
258             renderer, lambda x: x['descriptionSnippet']['runs'][0]['text'],
259             compat_str)
260         duration = parse_duration(try_get(
261             renderer, lambda x: x['lengthText']['simpleText'], compat_str))
262         view_count_text = try_get(
263             renderer, lambda x: x['viewCountText']['simpleText'], compat_str) or ''
264         view_count = str_to_int(self._search_regex(
265             r'^([\d,]+)', re.sub(r'\s', '', view_count_text),
266             'view count', default=None))
267         uploader = try_get(
268             renderer,
269             (lambda x: x['ownerText']['runs'][0]['text'],
270              lambda x: x['shortBylineText']['runs'][0]['text']), compat_str)
271         return {
272             '_type': 'url',
273             'ie_key': YoutubeIE.ie_key(),
274             'id': video_id,
275             'url': video_id,
276             'title': title,
277             'description': description,
278             'duration': duration,
279             'view_count': view_count,
280             'uploader': uploader,
281         }
282     def _search_results(self, query, params):
283         data = {
284             'context': {
285                 'client': {
286                     'clientName': 'WEB',
287                     'clientVersion': '2.20201021.03.00',
288                 }
289             },
290             'query': query,
291         }
292         if params:
293             data['params'] = params
294         for page_num in itertools.count(1):
295             search = self._download_json(
296                 'https://www.youtube.com/youtubei/v1/search?key=AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8',
297                 video_id='query "%s"' % query,
298                 note='Downloading page %s' % page_num,
299                 errnote='Unable to download API page', fatal=False,
300                 data=json.dumps(data).encode('utf8'),
301                 headers={'content-type': 'application/json'})
302             if not search:
303                 break
304             slr_contents = try_get(
305                 search,
306                 (lambda x: x['contents']['twoColumnSearchResultsRenderer']['primaryContents']['sectionListRenderer']['contents'],
307                  lambda x: x['onResponseReceivedCommands'][0]['appendContinuationItemsAction']['continuationItems']),
308                 list)
309             if not slr_contents:
310                 break
311             for slr_content in slr_contents:
312                 isr_contents = try_get(
313                     slr_content,
314                     lambda x: x['itemSectionRenderer']['contents'],
315                     list)
316                 if not isr_contents:
317                     continue
318                 for content in isr_contents:
319                     if not isinstance(content, dict):
320                         continue
321                     video = content.get('videoRenderer')
322                     if not isinstance(video, dict):
323                         continue
324                     video_id = video.get('videoId')
325                     if not video_id:
326                         continue
327                     yield self._extract_video(video)
328             token = try_get(
329                 slr_contents,
330                 lambda x: x[-1]['continuationItemRenderer']['continuationEndpoint']['continuationCommand']['token'],
331                 compat_str)
332             if not token:
333                 break
334             data['continuation'] = token
335 class YoutubeIE(YoutubeBaseInfoExtractor):
336     IE_DESC = 'YouTube.com'
337     _INVIDIOUS_SITES = (
338         r'(?:www\.)?redirect\.invidious\.io',
339         r'(?:(?:www|dev)\.)?invidio\.us',
340         r'(?:(?:www|no)\.)?invidiou\.sh',
341         r'(?:(?:www|fi)\.)?invidious\.snopyta\.org',
342         r'(?:www\.)?invidious\.kabi\.tk',
343         r'(?:www\.)?invidious\.13ad\.de',
344         r'(?:www\.)?invidious\.mastodon\.host',
345         r'(?:www\.)?invidious\.zapashcanon\.fr',
346         r'(?:www\.)?(?:invidious(?:-us)?|piped)\.kavin\.rocks',
347         r'(?:www\.)?invidious\.tinfoil-hat\.net',
348         r'(?:www\.)?invidious\.himiko\.cloud',
349         r'(?:www\.)?invidious\.reallyancient\.tech',
350         r'(?:www\.)?invidious\.tube',
351         r'(?:www\.)?invidiou\.site',
352         r'(?:www\.)?invidious\.site',
353         r'(?:www\.)?invidious\.xyz',
354         r'(?:www\.)?invidious\.nixnet\.xyz',
355         r'(?:www\.)?invidious\.048596\.xyz',
356         r'(?:www\.)?invidious\.drycat\.fr',
357         r'(?:www\.)?inv\.skyn3t\.in',
358         r'(?:www\.)?tube\.poal\.co',
359         r'(?:www\.)?tube\.connect\.cafe',
360         r'(?:www\.)?vid\.wxzm\.sx',
361         r'(?:www\.)?vid\.mint\.lgbt',
362         r'(?:www\.)?vid\.puffyan\.us',
363         r'(?:www\.)?yewtu\.be',
364         r'(?:www\.)?yt\.elukerio\.org',
365         r'(?:www\.)?yt\.lelux\.fi',
366         r'(?:www\.)?invidious\.ggc-project\.de',
367         r'(?:www\.)?yt\.maisputain\.ovh',
368         r'(?:www\.)?ytprivate\.com',
369         r'(?:www\.)?invidious\.13ad\.de',
370         r'(?:www\.)?invidious\.toot\.koeln',
371         r'(?:www\.)?invidious\.fdn\.fr',
372         r'(?:www\.)?watch\.nettohikari\.com',
373         r'(?:www\.)?invidious\.namazso\.eu',
374         r'(?:www\.)?invidious\.silkky\.cloud',
375         r'(?:www\.)?invidious\.exonip\.de',
376         r'(?:www\.)?invidious\.riverside\.rocks',
377         r'(?:www\.)?invidious\.blamefran\.net',
378         r'(?:www\.)?invidious\.moomoo\.de',
379         r'(?:www\.)?ytb\.trom\.tf',
380         r'(?:www\.)?yt\.cyberhost\.uk',
381         r'(?:www\.)?kgg2m7yk5aybusll\.onion',
382         r'(?:www\.)?qklhadlycap4cnod\.onion',
383         r'(?:www\.)?axqzx4s6s54s32yentfqojs3x5i7faxza6xo3ehd4bzzsg2ii4fv2iid\.onion',
384         r'(?:www\.)?c7hqkpkpemu6e7emz5b4vyz7idjgdvgaaa3dyimmeojqbgpea3xqjoid\.onion',
385         r'(?:www\.)?fz253lmuao3strwbfbmx46yu7acac2jz27iwtorgmbqlkurlclmancad\.onion',
386         r'(?:www\.)?invidious\.l4qlywnpwqsluw65ts7md3khrivpirse744un3x7mlskqauz5pyuzgqd\.onion',
387         r'(?:www\.)?owxfohz4kjyv25fvlqilyxast7inivgiktls3th44jhk3ej3i7ya\.b32\.i2p',
388         r'(?:www\.)?4l2dgddgsrkf2ous66i6seeyi6etzfgrue332grh2n7madpwopotugyd\.onion',
389         r'(?:www\.)?w6ijuptxiku4xpnnaetxvnkc5vqcdu7mgns2u77qefoixi63vbvnpnqd\.onion',
390         r'(?:www\.)?kbjggqkzv65ivcqj6bumvp337z6264huv5kpkwuv6gu5yjiskvan7fad\.onion',
391         r'(?:www\.)?grwp24hodrefzvjjuccrkw3mjq4tzhaaq32amf33dzpmuxe7ilepcmad\.onion',
392         r'(?:www\.)?hpniueoejy4opn7bc4ftgazyqjoeqwlvh2uiku2xqku6zpoa4bf5ruid\.onion',
393     )
394     _VALID_URL = r"""(?x)^
395                      (
396                          (?:https?://|//)                                    # http(s):// or protocol-independent URL
397                          (?:(?:(?:(?:\w+\.)?[yY][oO][uU][tT][uU][bB][eE](?:-nocookie|kids)?\.com|
398                             (?:www\.)?deturl\.com/www\.youtube\.com|
399                             (?:www\.)?pwnyoutube\.com|
400                             (?:www\.)?hooktube\.com|
401                             (?:www\.)?yourepeat\.com|
402                             tube\.majestyc\.net|
403                             %(invidious)s|
404                             youtube\.googleapis\.com)/                        # the various hostnames, with wildcard subdomains
405                          (?:.*?\#/)?                                          # handle anchor (#/) redirect urls
406                          (?:                                                  # the various things that can precede the ID:
407                              (?:(?:v|embed|e)/(?!videoseries))                # v/ or embed/ or e/
408                              |shorts/
409                              |(?:                                             # or the v= param in all its forms
410                                  (?:(?:watch|movie)(?:_popup)?(?:\.php)?/?)?  # preceding watch(_popup|.php) or nothing (like /?v=xxxx)
411                                  (?:\?|\#!?)                                  # the params delimiter ? or # or #!
412                                  (?:.*?[&amp;;])??                                # any other preceding param (like /?s=tuff&amp;v=xxxx or ?s=tuff&amp;amp;v=V36LpHqtcDY)
413                                  v=
414                              )
415                          ))
416                          |(?:
417                             youtu\.be|                                        # just youtu.be/xxxx
418                             vid\.plus|                                        # or vid.plus/xxxx
419                             zwearz\.com/watch|                                # or zwearz.com/watch/xxxx
420                             %(invidious)s
421                          )/
422                          |(?:www\.)?cleanvideosearch\.com/media/action/yt/watch\?videoId=
423                          )
424                      )?                                                       # all until now is optional -&gt; you can pass the naked ID
425                      (?P&lt;id&gt;[0-9A-Za-z_-]{11})                                # here is it! the YouTube video ID
426                      (?(1).+)?                                                # if we found the ID, everything can follow
427                      $""" % {
428         'invidious': '|'.join(_INVIDIOUS_SITES),
429     }
430     _PLAYER_INFO_RE = (
431         r'/s/player/(?P&lt;id&gt;[a-zA-Z0-9_-]{8,})/player',
432         r'/(?P&lt;id&gt;[a-zA-Z0-9_-]{8,})/player(?:_ias\.vflset(?:/[a-zA-Z]{2,3}_[a-zA-Z]{2,3})?|-plasma-ias-(?:phone|tablet)-[a-z]{2}_[A-Z]{2}\.vflset)/base\.js$',
433         r'\b(?P&lt;id&gt;vfl[a-zA-Z0-9_-]+)\b.*?\.js$',
434     )
435     _SUBTITLE_FORMATS = ('srv1', 'srv2', 'srv3', 'ttml', 'vtt')
436 <a name="0"></a>
437     _GEO_BYPASS = False
438     IE_NAME <font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= 'youtube'
439     _TESTS = [
440         {
441             'url': 'https://www.youtube.com/watch?v=BaW_jenozKc&amp;t=1s&amp;end=9',
442             'info_dict': {
443                 'id': 'BaW_jenozKc',
444                 'ext': 'mp4',
445                 'title': 'youtube-dl test video "\'/\\ä↭𝕐',
446                 'uploader': 'Philipp Hagemeister',
447                 'uploader_id': 'phihag',
448                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/phihag',
449                 'channel_id': 'UCLqxVugv74EIW3VWh2NOa3Q',
450                 'channel_url': r're:https?://(?:www\.)?youtube\.com/channel/UCLqxVugv74EIW3VWh2NOa3Q',
451                 'upload_date': '20121002',
452                 'description': 'test chars:  "\'/\\ä↭𝕐\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\n\nThis is a test video for youtube-dl.\n\nFor more information, contact phihag@phihag.de .',
453                 'categories': ['Science &amp; Technology'],
454                 'tags': ['youtube-dl'],
455                 'duration': 10,
456                 'view_count': int,
457                 'like_count': int,
458                 'dislike_count': int,
459                 'start_time': 1,
460                 'end_time': 9,
461             }
462         },
463         {
464             'url': '//www.YouTube.com/watch?v=yZIXLfi8CZQ',
465             'note': 'Embed-only video (#1746)',
466             'info_dict': {
467                 'id': 'yZIXLfi8CZQ',
468                 'ext': 'mp4',
469                 'upload_date': '20120608',
470                 'title': 'Principal Sexually Assaults A Teacher - Episode 117 - 8th June 2012',
471                 'description': 'md5:09b78bd971f1e3e289601dfba15ca4f7',
472                 'uploader': 'SET India',
473                 'uploader_id': 'setindia',
474                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/setindia',
475                 'age_limit': 18,
476             },
477             'skip': 'Private video',
478         },
479         {
480             'url': 'https://www.youtube.com/watch?v=BaW_jenozKc&amp;v=yZIXLfi8CZQ',
481             'note': 'Use the first video ID in the URL',
482             'info_dict': {
483                 'id': 'BaW_jenozKc',
484                 'ext': 'mp4',
485                 'title': 'youtube-dl test video "\'/\\ä↭𝕐',
486                 'uploader': 'Philipp Hagemeister',
487                 'uploader_id': 'phihag',
488                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/phihag',
489                 'upload_date': '20121002',
490                 'description': 'test chars:  "\'/\\ä↭𝕐\ntest URL: https://github.com/rg3/youtube-dl/issues/1892\n\nThis is a test video for youtube-dl.\n\nFor more information, contact phihag@phihag.de .',
491                 'categories': ['Science &amp; Technology'],
492                 'tags': ['youtube-dl'],
493                 'duration': 10,
494                 'view_count': int,
495                 'like_count': int,
496                 'dislike_count': int,
497             },
498             'params': {
499                 'skip_download': True,
500             },
501         },
502         {
503             'url': 'https://www.youtube.com/watch?v=a9LDPn-MO4I',
504             'note': '256k DASH audio (format 141) via DASH manifest',
505             'info_dict': {
506                 'id': 'a9LDPn-MO4I',
507                 'ext': 'm4a',
508                 'upload_date': '20121002',
509                 'uploader_id': '8KVIDEO',
510                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/8KVIDEO',
511                 'description': '',
512                 'uploader': '8KVIDEO',
513                 'title': 'UHDTV TEST 8K VIDEO.mp4'
514             },
515             'params': {
516                 'youtube_include_dash_manifest': True,
517                 'format': '141',
518             },
519             'skip': 'format 141 not served anymore',
520         },
521         {
522             'url': 'https://www.youtube.com/watch?v=IB3lcPjvWLA',
523             'info_dict': {
524                 'id'</b></font>: 'IB3lcPjvWLA',
525                 'ext': 'm4a',
526                 'title': 'Afrojack, Spree Wilson - The Spark (Official Music Video) ft. Spree Wilson',
527                 'description': 'md5:8f5e2b82460520b619ccac1f509d43bf',
528                 'duration': 244,
529                 'uploader': 'AfrojackVEVO',
530                 'uploader_id': 'AfrojackVEVO',
531                 'upload_date': '20131011',
532                 'abr': 129.495,
533             },
534             'params': {
535                 'youtube_include_dash_manifest': True,
536                 'format': '141/bestaudio[ext=m4a]',
537             },
538         },
539         {
540             'url': 'https://www.youtube.com/watch?v=T4XJQO3qol8',
541             'info_dict': {
542                 'id': 'T4XJQO3qol8',
543                 'ext': 'mp4',
544                 'duration': 219,
545                 'upload_date': '20100909',
546                 'uploader': 'Amazing Atheist',
547                 'uploader_id': 'TheAmazingAtheist',
548                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/TheAmazingAtheist',
549                 'title': 'Burning Everyone\'s Koran',
550                 'description': 'SUBSCRIBE: http://www.youtube.com/saturninefilms \r\n\r\nEven Obama has taken a stand against freedom on this issue: http://www.huffingtonpost.com/2010/09/09/obama-gma-interview-quran_n_710282.html',
551             }
552         },
553         {
554             'url': 'https://youtube.com/watch?v=HtVdAasjOgU',
555             'info_dict': {
556                 'id': 'HtVdAasjOgU',
557                 'ext': 'mp4',
558                 'title': 'The Witcher 3: Wild Hunt - The Sword Of Destiny Trailer',
559                 'description': r're:(?s).{100,}About the Game\n.*?The Witcher 3: Wild Hunt.{100,}',
560                 'duration': 142,
561                 'uploader': 'The Witcher',
562                 'uploader_id': 'WitcherGame',
563                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/WitcherGame',
564                 'upload_date': '20140605',
565                 'age_limit': 18,
566             },
567         },
568         {
569             'url': 'XgnwCQzjau8',
570             'only_matching': True,
571         },
572         {
573             'url': '__2ABJjxzNo',
574             'info_dict': {
575                 'id': '__2ABJjxzNo',
576                 'ext': 'mp4',
577                 'duration': 266,
578                 'upload_date': '20100430',
579                 'uploader_id': 'deadmau5',
580                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/deadmau5',
581                 'creator': 'deadmau5',
582                 'description': 'md5:6cbcd3a92ce1bc676fc4d6ab4ace2336',
583                 'uploader': 'deadmau5',
584                 'title': 'Deadmau5 - Some Chords (HD)',
585                 'alt_title': 'Some Chords',
586             },
587             'expected_warnings': [
588                 'DASH manifest missing',
589             ]
590         },
591         {
592             'url': 'lqQg6PlCWgI',
593             'info_dict': {
594                 'id': 'lqQg6PlCWgI',
595                 'ext': 'mp4',
596                 'duration': 6085,
597                 'upload_date': '20150827',
598                 'uploader_id': 'olympic',
599                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/olympic',
600                 'description': 'HO09  - Women -  GER-AUS - Hockey - 31 July 2012 - London 2012 Olympic Games',
601                 'uploader': 'Olympic',
602                 'title': 'Hockey - Women -  GER-AUS - London 2012 Olympic Games',
603             },
604             'params': {
605                 'skip_download': 'requires avconv',
606             }
607         },
608         {
609             'url': 'https://www.youtube.com/watch?v=_b-2C3KPAM0',
610             'info_dict': {
611                 'id': '_b-2C3KPAM0',
612                 'ext': 'mp4',
613                 'stretched_ratio': 16 / 9.,
614                 'duration': 85,
615                 'upload_date': '20110310',
616                 'uploader_id': 'AllenMeow',
617                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/AllenMeow',
618                 'description': 'made by Wacom from Korea | 字幕&amp;加油添醋 by TY\'s Allen | 感謝heylisa00cavey1001同學熱情提供梗及翻譯',
619                 'uploader': '孫ᄋᄅ',
620                 'title': '[A-made] 變態妍字幕版 太妍 我就是這樣的人',
621             },
622         },
623         {
624             'url': 'qEJwOuvDf7I',
625             'info_dict': {
626                 'id': 'qEJwOuvDf7I',
627                 'ext': 'webm',
628                 'title': 'Обсуждение судебной практики по выборам 14 сентября 2014 года в Санкт-Петербурге',
629                 'description': '',
630                 'upload_date': '20150404',
631                 'uploader_id': 'spbelect',
632                 'uploader': 'Наблюдатели Петербурга',
633             },
634             'params': {
635                 'skip_download': 'requires avconv',
636             },
637             'skip': 'This live event has ended.',
638         },
639         {
640             'url': 'https://www.youtube.com/watch?v=FIl7x6_3R5Y',
641             'info_dict': {
642                 'id': 'FIl7x6_3R5Y',
643                 'ext': 'webm',
644                 'title': 'md5:7b81415841e02ecd4313668cde88737a',
645                 'description': 'md5:116377fd2963b81ec4ce64b542173306',
646                 'duration': 220,
647                 'upload_date': '20150625',
648                 'uploader_id': 'dorappi2000',
649                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/dorappi2000',
650                 'uploader': 'dorappi2000',
651                 'formats': 'mincount:31',
652             },
653             'skip': 'not actual anymore',
654         },
655         {
656             'url': 'https://www.youtube.com/embed/CsmdDsKjzN8',
657             'md5': '8ce563a1d667b599d21064e982ab9e31',
658             'info_dict': {
659                 'id': 'CsmdDsKjzN8',
660                 'ext': 'mp4',
661                 'upload_date': '20150501',  # According to '&lt;meta itemprop="datePublished"', but in other places it's 20150510
662                 'uploader': 'Airtek',
663                 'description': 'Retransmisión en directo de la XVIII media maratón de Zaragoza.',
664                 'uploader_id': 'UCzTzUmjXxxacNnL8I3m4LnQ',
665                 'title': 'Retransmisión XVIII Media maratón Zaragoza 2015',
666             },
667             'params': {
668                 'youtube_include_dash_manifest': True,
669                 'format': '135',  # bestvideo
670             },
671             'skip': 'This live event has ended.',
672         },
673         {
674             'url': 'https://www.youtube.com/watch?v=jvGDaLqkpTg',
675             'info_dict': {
676                 'id': 'jvGDaLqkpTg',
677                 'title': 'Tom Clancy Free Weekend Rainbow Whatever',
678                 'description': 'md5:e03b909557865076822aa169218d6a5d',
679             },
680             'playlist': [{
681                 'info_dict': {
682                     'id': 'jvGDaLqkpTg',
683                     'ext': 'mp4',
684                     'title': 'Tom Clancy Free Weekend Rainbow Whatever (Main Camera)',
685                     'description': 'md5:e03b909557865076822aa169218d6a5d',
686                     'duration': 10643,
687                     'upload_date': '20161111',
688                     'uploader': 'Team PGP',
689                     'uploader_id': 'UChORY56LMMETTuGjXaJXvLg',
690                     'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UChORY56LMMETTuGjXaJXvLg',
691                 },
692             }, {
693                 'info_dict': {
694                     'id': '3AKt1R1aDnw',
695                     'ext': 'mp4',
696                     'title': 'Tom Clancy Free Weekend Rainbow Whatever (Camera 2)',
697                     'description': 'md5:e03b909557865076822aa169218d6a5d',
698                     'duration': 10991,
699                     'upload_date': '20161111',
700                     'uploader': 'Team PGP',
701                     'uploader_id': 'UChORY56LMMETTuGjXaJXvLg',
702                     'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UChORY56LMMETTuGjXaJXvLg',
703                 },
704             }, {
705                 'info_dict': {
706                     'id': 'RtAMM00gpVc',
707                     'ext': 'mp4',
708                     'title': 'Tom Clancy Free Weekend Rainbow Whatever (Camera 3)',
709                     'description': 'md5:e03b909557865076822aa169218d6a5d',
710                     'duration': 10995,
711                     'upload_date': '20161111',
712                     'uploader': 'Team PGP',
713                     'uploader_id': 'UChORY56LMMETTuGjXaJXvLg',
714                     'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UChORY56LMMETTuGjXaJXvLg',
715                 },
716             }, {
717                 'info_dict': {
718                     'id': '6N2fdlP3C5U',
719                     'ext': 'mp4',
720                     'title': 'Tom Clancy Free Weekend Rainbow Whatever (Camera 4)',
721                     'description': 'md5:e03b909557865076822aa169218d6a5d',
722                     'duration': 10990,
723                     'upload_date': '20161111',
724                     'uploader': 'Team PGP',
725                     'uploader_id': 'UChORY56LMMETTuGjXaJXvLg',
726                     'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UChORY56LMMETTuGjXaJXvLg',
727                 },
728             }],
729             'params': {
730                 'skip_download': True,
731             },
732         },
733         {
734             'url': 'https://www.youtube.com/watch?v=gVfLd0zydlo',
735             'info_dict': {
736                 'id': 'gVfLd0zydlo',
737                 'title': 'DevConf.cz 2016 Day 2 Workshops 1 14:00 - 15:30',
738             },
739             'playlist_count': 2,
740             'skip': 'Not multifeed anymore',
741         },
742         {
743             'url': 'https://vid.plus/FlRa-iH7PGw',
744             'only_matching': True,
745         },
746         {
747             'url': 'https://zwearz.com/watch/9lWxNJF-ufM/electra-woman-dyna-girl-official-trailer-grace-helbig.html',
748             'only_matching': True,
749         },
750         {
751             'url': 'https://www.youtube.com/watch?v=lsguqyKfVQg',
752             'info_dict': {
753                 'id': 'lsguqyKfVQg',
754                 'ext': 'mp4',
755                 'title': '{dark walk}; Loki/AC/Dishonored; collab w/Elflover21',
756                 'alt_title': 'Dark Walk - Position Music',
757                 'description': 'md5:8085699c11dc3f597ce0410b0dcbb34a',
758                 'duration': 133,
759                 'upload_date': '20151119',
760                 'uploader_id': 'IronSoulElf',
761                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/IronSoulElf',
762                 'uploader': 'IronSoulElf',
763                 'creator': 'Todd Haberman,  Daniel Law Heath and Aaron Kaplan',
764                 'track': 'Dark Walk - Position Music',
765                 'artist': 'Todd Haberman,  Daniel Law Heath and Aaron Kaplan',
766                 'album': 'Position Music - Production Music Vol. 143 - Dark Walk',
767             },
768             'params': {
769                 'skip_download': True,
770             },
771         },
772         {
773             'url': 'https://www.youtube.com/watch?v=Ms7iBXnlUO8',
774             'only_matching': True,
775         },
776         {
777             'url': 'https://www.youtube.com/watch?v=Q39EVAstoRM',
778             'info_dict': {
779                 'id': 'Q39EVAstoRM',
780                 'ext': 'mp4',
781                 'title': 'Clash Of Clans#14 Dicas De Ataque Para CV 4',
782                 'description': 'md5:ee18a25c350637c8faff806845bddee9',
783                 'upload_date': '20151107',
784                 'uploader_id': 'UCCr7TALkRbo3EtFzETQF1LA',
785                 'uploader': 'CH GAMER DROID',
786             },
787             'params': {
788                 'skip_download': True,
789             },
790             'skip': 'This video does not exist.',
791         },
792         {
793             'url': 'https://www.youtube.com/watch?v=FRhJzUSJbGI',
794             'only_matching': True,
795         },
796         {
797             'url': 'https://www.youtube.com/watch?v=M4gD1WSo5mA',
798             'info_dict': {
799                 'id': 'M4gD1WSo5mA',
800                 'ext': 'mp4',
801                 'title': 'md5:e41008789470fc2533a3252216f1c1d1',
802                 'description': 'md5:a677553cf0840649b731a3024aeff4cc',
803                 'duration': 721,
804                 'upload_date': '20150127',
805                 'uploader_id': 'BerkmanCenter',
806                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/BerkmanCenter',
807                 'uploader': 'The Berkman Klein Center for Internet &amp; Society',
808                 'license': 'Creative Commons Attribution license (reuse allowed)',
809             },
810             'params': {
811                 'skip_download': True,
812             },
813         },
814         {
815             'url': 'https://www.youtube.com/watch?v=eQcmzGIKrzg',
816             'info_dict': {
817                 'id': 'eQcmzGIKrzg',
818                 'ext': 'mp4',
819                 'title': 'Democratic Socialism and Foreign Policy | Bernie Sanders',
820                 'description': 'md5:13a2503d7b5904ef4b223aa101628f39',
821                 'duration': 4060,
822                 'upload_date': '20151119',
823                 'uploader': 'Bernie Sanders',
824                 'uploader_id': 'UCH1dpzjCEiGAt8CXkryhkZg',
825                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCH1dpzjCEiGAt8CXkryhkZg',
826                 'license': 'Creative Commons Attribution license (reuse allowed)',
827             },
828             'params': {
829                 'skip_download': True,
830             },
831         },
832         {
833             'url': 'https://www.youtube.com/watch?feature=player_embedded&amp;amp;amp;v=V36LpHqtcDY',
834             'only_matching': True,
835         },
836         {
837             'url': 'https://www.youtube.com/watch?v=i1Ko8UG-Tdo',
838             'only_matching': True,
839         },
840         {
841             'url': 'https://www.youtube.com/watch?v=yYr8q0y5Jfg',
842             'info_dict': {
843                 'id': 'uGpuVWrhIzE',
844                 'ext': 'mp4',
845                 'title': 'Piku - Trailer',
846                 'description': 'md5:c36bd60c3fd6f1954086c083c72092eb',
847                 'upload_date': '20150811',
848                 'uploader': 'FlixMatrix',
849                 'uploader_id': 'FlixMatrixKaravan',
850                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/FlixMatrixKaravan',
851                 'license': 'Standard YouTube License',
852             },
853             'params': {
854                 'skip_download': True,
855             },
856             'skip': 'This video is not available.',
857         },
858         {
859             'url': 'https://www.youtube.com/watch?v=iqKdEhx-dD4',
860             'info_dict': {
861                 'id': 'iqKdEhx-dD4',
862                 'ext': 'mp4',
863                 'title': 'Isolation - Mind Field (Ep 1)',
864                 'description': 'md5:f540112edec5d09fc8cc752d3d4ba3cd',
865                 'duration': 2085,
866                 'upload_date': '20170118',
867                 'uploader': 'Vsauce',
868                 'uploader_id': 'Vsauce',
869                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/Vsauce',
870                 'series': 'Mind Field',
871                 'season_number': 1,
872                 'episode_number': 1,
873             },
874             'params': {
875                 'skip_download': True,
876             },
877             'expected_warnings': [
878                 'Skipping DASH manifest',
879             ],
880         },
881         {
882             'url': 'https://www.youtube.com/watch?v=6SJNVb0GnPI',
883             'info_dict': {
884                 'id': '6SJNVb0GnPI',
885                 'ext': 'mp4',
886                 'title': 'Race Differences in Intelligence',
887                 'description': 'md5:5d161533167390427a1f8ee89a1fc6f1',
888                 'duration': 965,
889                 'upload_date': '20140124',
890                 'uploader': 'New Century Foundation',
891                 'uploader_id': 'UCEJYpZGqgUob0zVVEaLhvVg',
892                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCEJYpZGqgUob0zVVEaLhvVg',
893             },
894             'params': {
895                 'skip_download': True,
896             },
897             'skip': 'This video has been removed for violating YouTube\'s policy on hate speech.',
898         },
899         {
900             'url': '1t24XAntNCY',
901             'only_matching': True,
902         },
903         {
904             'url': 'sJL6WA-aGkQ',
905             'only_matching': True,
906         },
907         {
908             'url': 'https://invidio.us/watch?v=BaW_jenozKc',
909             'only_matching': True,
910         },
911         {
912             'url': 'https://redirect.invidious.io/watch?v=BaW_jenozKc',
913             'only_matching': True,
914         },
915         {
916             'url': 'https://redirect.invidious.io/Yh0AhrY9GjA',
917             'only_matching': True,
918         },
919         {
920             'url': 'https://www.youtube.com/watch?v=s7_qI6_mIXc',
921             'only_matching': True,
922         },
923         {
924             'url': 'https://www.youtube.com/watch?v=Z4Vy8R84T1U',
925             'info_dict': {
926                 'id': 'Z4Vy8R84T1U',
927                 'ext': 'mp4',
928                 'title': 'saman SMAN 53 Jakarta(Sancety) opening COFFEE4th at SMAN 53 Jakarta',
929                 'description': 'md5:d41d8cd98f00b204e9800998ecf8427e',
930                 'duration': 433,
931                 'upload_date': '20130923',
932                 'uploader': 'Amelia Putri Harwita',
933                 'uploader_id': 'UCpOxM49HJxmC1qCalXyB3_Q',
934                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCpOxM49HJxmC1qCalXyB3_Q',
935                 'formats': 'maxcount:10',
936             },
937             'params': {
938                 'skip_download': True,
939                 'youtube_include_dash_manifest': False,
940             },
941             'skip': 'not actual anymore',
942         },
943         {
944             'url': 'https://music.youtube.com/watch?v=MgNrAu2pzNs',
945             'info_dict': {
946                 'id': 'MgNrAu2pzNs',
947                 'ext': 'mp4',
948                 'title': 'Voyeur Girl',
949                 'description': 'md5:7ae382a65843d6df2685993e90a8628f',
950                 'upload_date': '20190312',
951                 'uploader': 'Stephen - Topic',
952                 'uploader_id': 'UC-pWHpBjdGG69N9mM2auIAA',
953                 'artist': 'Stephen',
954                 'track': 'Voyeur Girl',
955                 'album': 'it\'s too much love to know my dear',
956                 'release_date': '20190313',
957                 'release_year': 2019,
958             },
959             'params': {
960                 'skip_download': True,
961             },
962         },
963         {
964             'url': 'https://www.youtubekids.com/watch?v=3b8nCWDgZ6Q',
965             'only_matching': True,
966         },
967         {
968             'url': 'DJztXj2GPfl',
969             'info_dict': {
970                 'id': 'DJztXj2GPfk',
971                 'ext': 'mp4',
972                 'title': 'Panjabi MC - Mundian To Bach Ke (The Dictator Soundtrack)',
973                 'description': 'md5:bf577a41da97918e94fa9798d9228825',
974                 'upload_date': '20090125',
975                 'uploader': 'Prochorowka',
976                 'uploader_id': 'Prochorowka',
977                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/Prochorowka',
978                 'artist': 'Panjabi MC',
979                 'track': 'Beware of the Boys (Mundian to Bach Ke) - Motivo Hi-Lectro Remix',
980                 'album': 'Beware of the Boys (Mundian To Bach Ke)',
981             },
982             'params': {
983                 'skip_download': True,
984             },
985             'skip': 'Video unavailable',
986         },
987         {
988             'url': 'https://www.youtube.com/watch?v=x41yOUIvK2k',
989             'info_dict': {
990                 'id': 'x41yOUIvK2k',
991                 'ext': 'mp4',
992                 'title': 'IMG 3456',
993                 'description': '',
994                 'upload_date': '20170613',
995                 'uploader_id': 'ElevageOrVert',
996                 'uploader': 'ElevageOrVert',
997             },
998             'params': {
999                 'skip_download': True,
1000             },
1001         },
1002         {
1003             'url': 'https://www.youtube.com/watch?v=CHqg6qOn4no',
1004             'info_dict': {
1005                 'id': 'CHqg6qOn4no',
1006                 'ext': 'mp4',
1007                 'title': 'Part 77   Sort a list of simple types in c#',
1008                 'description': 'md5:b8746fa52e10cdbf47997903f13b20dc',
1009                 'upload_date': '20130831',
1010                 'uploader_id': 'kudvenkat',
1011                 'uploader': 'kudvenkat',
1012             },
1013             'params': {
1014                 'skip_download': True,
1015             },
1016         },
1017         {
1018             'url': 'https://www.youtube.com/watch?v=gVfgbahppCY',
1019             'only_matching': True,
1020         },
1021         {
1022             'url': 'https://www.youtube.com/watch_popup?v=63RmMXCd_bQ',
1023             'only_matching': True,
1024         },
1025         {
1026             'url': 'OtqTfy26tG0',
1027             'info_dict': {
1028                 'id': 'OtqTfy26tG0',
1029                 'ext': 'mp4',
1030                 'title': 'Burn Out',
1031                 'description': 'md5:8d07b84dcbcbfb34bc12a56d968b6131',
1032                 'upload_date': '20141120',
1033                 'uploader': 'The Cinematic Orchestra - Topic',
1034                 'uploader_id': 'UCIzsJBIyo8hhpFm1NK0uLgw',
1035                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCIzsJBIyo8hhpFm1NK0uLgw',
1036                 'artist': 'The Cinematic Orchestra',
1037                 'track': 'Burn Out',
1038                 'album': 'Every Day',
1039                 'release_data': None,
1040                 'release_year': None,
1041             },
1042             'params': {
1043                 'skip_download': True,
1044             },
1045         },
1046         {
1047             'url': 'https://www.youtube.com/watch?v=nGC3D_FkCmg',
1048             'only_matching': True,
1049         },
1050         {
1051             'url': 'cBvYw8_A0vQ',
1052             'info_dict': {
1053                 'id': 'cBvYw8_A0vQ',
1054                 'ext': 'mp4',
1055                 'title': '4K Ueno Okachimachi  Street  Scenes  上野御徒町歩き',
1056                 'description': 'md5:ea770e474b7cd6722b4c95b833c03630',
1057                 'upload_date': '20201120',
1058                 'uploader': 'Walk around Japan',
1059                 'uploader_id': 'UC3o_t8PzBmXf5S9b7GLx1Mw',
1060                 'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UC3o_t8PzBmXf5S9b7GLx1Mw',
1061             },
1062             'params': {
1063                 'skip_download': True,
1064             },
1065         },
1066         {
1067             'url': 'https://youtube.com/shorts/4L2J27mJ3Dc',
1068             'info_dict': {
1069                 'id': '4L2J27mJ3Dc',
1070                 'ext': 'mp4',
1071                 'upload_date': '20211025',
1072                 'uploader': 'Charlie Berens',
1073                 'description': 'md5:976512b8a29269b93bbd8a61edc45a6d',
1074                 'uploader_id': 'fivedlrmilkshake',
1075                 'title': 'Midwest Squid Game #Shorts',
1076             },
1077             'params': {
1078                 'skip_download': True,
1079             },
1080         },
1081     ]
1082     _formats = {
1083         '5': {'ext': 'flv', 'width': 400, 'height': 240, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263'},
1084         '6': {'ext': 'flv', 'width': 450, 'height': 270, 'acodec': 'mp3', 'abr': 64, 'vcodec': 'h263'},
1085         '13': {'ext': '3gp', 'acodec': 'aac', 'vcodec': 'mp4v'},
1086         '17': {'ext': '3gp', 'width': 176, 'height': 144, 'acodec': 'aac', 'abr': 24, 'vcodec': 'mp4v'},
1087         '18': {'ext': 'mp4', 'width': 640, 'height': 360, 'acodec': 'aac', 'abr': 96, 'vcodec': 'h264'},
1088         '22': {'ext': 'mp4', 'width': 1280, 'height': 720, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},
1089         '34': {'ext': 'flv', 'width': 640, 'height': 360, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
1090         '35': {'ext': 'flv', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
1091         '36': {'ext': '3gp', 'width': 320, 'acodec': 'aac', 'vcodec': 'mp4v'},
1092         '37': {'ext': 'mp4', 'width': 1920, 'height': 1080, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},
1093         '38': {'ext': 'mp4', 'width': 4096, 'height': 3072, 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264'},
1094         '43': {'ext': 'webm', 'width': 640, 'height': 360, 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8'},
1095         '44': {'ext': 'webm', 'width': 854, 'height': 480, 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8'},
1096         '45': {'ext': 'webm', 'width': 1280, 'height': 720, 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8'},
1097         '46': {'ext': 'webm', 'width': 1920, 'height': 1080, 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8'},
1098         '59': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
1099         '78': {'ext': 'mp4', 'width': 854, 'height': 480, 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264'},
1100         '82': {'ext': 'mp4', 'height': 360, 'format_note': '3D', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -20},
1101         '83': {'ext': 'mp4', 'height': 480, 'format_note': '3D', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -20},
1102         '84': {'ext': 'mp4', 'height': 720, 'format_note': '3D', 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264', 'preference': -20},
1103         '85': {'ext': 'mp4', 'height': 1080, 'format_note': '3D', 'acodec': 'aac', 'abr': 192, 'vcodec': 'h264', 'preference': -20},
1104         '100': {'ext': 'webm', 'height': 360, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 128, 'vcodec': 'vp8', 'preference': -20},
1105         '101': {'ext': 'webm', 'height': 480, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8', 'preference': -20},
1106         '102': {'ext': 'webm', 'height': 720, 'format_note': '3D', 'acodec': 'vorbis', 'abr': 192, 'vcodec': 'vp8', 'preference': -20},
1107         '91': {'ext': 'mp4', 'height': 144, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},
1108         '92': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},
1109         '93': {'ext': 'mp4', 'height': 360, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -10},
1110         '94': {'ext': 'mp4', 'height': 480, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 128, 'vcodec': 'h264', 'preference': -10},
1111         '95': {'ext': 'mp4', 'height': 720, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 256, 'vcodec': 'h264', 'preference': -10},
1112         '96': {'ext': 'mp4', 'height': 1080, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 256, 'vcodec': 'h264', 'preference': -10},
1113         '132': {'ext': 'mp4', 'height': 240, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 48, 'vcodec': 'h264', 'preference': -10},
1114         '151': {'ext': 'mp4', 'height': 72, 'format_note': 'HLS', 'acodec': 'aac', 'abr': 24, 'vcodec': 'h264', 'preference': -10},
1115         '133': {'ext': 'mp4', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'h264'},
1116         '134': {'ext': 'mp4', 'height': 360, 'format_note': 'DASH video', 'vcodec': 'h264'},
1117         '135': {'ext': 'mp4', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'h264'},
1118         '136': {'ext': 'mp4', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'h264'},
1119         '137': {'ext': 'mp4', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'h264'},
1120         '138': {'ext': 'mp4', 'format_note': 'DASH video', 'vcodec': 'h264'},  # Height can vary (https://github.com/ytdl-org/youtube-dl/issues/4559)
1121         '160': {'ext': 'mp4', 'height': 144, 'format_note': 'DASH video', 'vcodec': 'h264'},
1122         '212': {'ext': 'mp4', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'h264'},
1123         '264': {'ext': 'mp4', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'h264'},
1124         '298': {'ext': 'mp4', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'h264', 'fps': 60},
1125         '299': {'ext': 'mp4', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'h264', 'fps': 60},
1126         '266': {'ext': 'mp4', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'h264'},
1127         '139': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 48, 'container': 'm4a_dash'},
1128         '140': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 128, 'container': 'm4a_dash'},
1129         '141': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'abr': 256, 'container': 'm4a_dash'},
1130         '256': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'container': 'm4a_dash'},
1131         '258': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'aac', 'container': 'm4a_dash'},
1132         '325': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'dtse', 'container': 'm4a_dash'},
1133         '328': {'ext': 'm4a', 'format_note': 'DASH audio', 'acodec': 'ec-3', 'container': 'm4a_dash'},
1134         '167': {'ext': 'webm', 'height': 360, 'width': 640, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1135         '168': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1136         '169': {'ext': 'webm', 'height': 720, 'width': 1280, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1137         '170': {'ext': 'webm', 'height': 1080, 'width': 1920, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1138         '218': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1139         '219': {'ext': 'webm', 'height': 480, 'width': 854, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp8'},
1140         '278': {'ext': 'webm', 'height': 144, 'format_note': 'DASH video', 'container': 'webm', 'vcodec': 'vp9'},
1141         '242': {'ext': 'webm', 'height': 240, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1142         '243': {'ext': 'webm', 'height': 360, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1143         '244': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1144         '245': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1145         '246': {'ext': 'webm', 'height': 480, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1146         '247': {'ext': 'webm', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1147         '248': {'ext': 'webm', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1148         '271': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1149         '272': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1150         '302': {'ext': 'webm', 'height': 720, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},
1151         '303': {'ext': 'webm', 'height': 1080, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},
1152         '308': {'ext': 'webm', 'height': 1440, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},
1153         '313': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9'},
1154         '315': {'ext': 'webm', 'height': 2160, 'format_note': 'DASH video', 'vcodec': 'vp9', 'fps': 60},
1155         '171': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 128},
1156         '172': {'ext': 'webm', 'acodec': 'vorbis', 'format_note': 'DASH audio', 'abr': 256},
1157         '249': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 50},
1158         '250': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 70},
1159         '251': {'ext': 'webm', 'format_note': 'DASH audio', 'acodec': 'opus', 'abr': 160},
1160         '_rtmp': {'protocol': 'rtmp'},
1161         '394': {'acodec': 'none', 'vcodec': 'av01.0.05M.08'},
1162         '395': {'acodec': 'none', 'vcodec': 'av01.0.05M.08'},
1163         '396': {'acodec': 'none', 'vcodec': 'av01.0.05M.08'},
1164         '397': {'acodec': 'none', 'vcodec': 'av01.0.05M.08'},
1165     }
1166     @classmethod
1167     def suitable(cls, url):
1168         from .youtube import parse_qs
1169         qs = parse_qs(url)
1170         if qs.get('list', [None])[0]:
1171             return False
1172         return super(YoutubeIE, cls).suitable(url)
1173     def __init__(self, *args, **kwargs):
1174         super(YoutubeIE, self).__init__(*args, **kwargs)
1175         self._code_cache = {}
1176         self._player_cache = {}
1177     def _signature_cache_id(self, example_sig):
1178         return '.'.join(compat_str(len(part)) for part in example_sig.split('.'))
1179     @classmethod
1180     def _extract_player_info(cls, player_url):
1181         for player_re in cls._PLAYER_INFO_RE:
1182             id_m = re.search(player_re, player_url)
1183             if id_m:
1184                 break
1185         else:
1186             raise ExtractorError('Cannot identify player %r' % player_url)
1187         return id_m.group('id')
1188     def _get_player_code(self, video_id, player_url, player_id=None):
1189         if not player_id:
1190             player_id = self._extract_player_info(player_url)
1191         if player_id not in self._code_cache:
1192             self._code_cache[player_id] = self._download_webpage(
1193                 player_url, video_id,
1194                 note='Downloading player ' + player_id,
1195                 errnote='Download of %s failed' % player_url)
1196         return self._code_cache[player_id]
1197     def _extract_signature_function(self, video_id, player_url, example_sig):
1198         player_id = self._extract_player_info(player_url)
1199         func_id = 'js_%s_%s' % (
1200             player_id, self._signature_cache_id(example_sig))
1201         assert os.path.basename(func_id) == func_id
1202         cache_spec = self._downloader.cache.load('youtube-sigfuncs', func_id)
1203         if cache_spec is not None:
1204             return lambda s: ''.join(s[i] for i in cache_spec)
1205         code = self._get_player_code(video_id, player_url, player_id)
1206         res = self._parse_sig_js(code)
1207         test_string = ''.join(map(compat_chr, range(len(example_sig))))
1208         cache_res = res(test_string)
1209         cache_spec = [ord(c) for c in cache_res]
1210         self._downloader.cache.store('youtube-sigfuncs', func_id, cache_spec)
1211         return res
1212     def _print_sig_code(self, func, example_sig):
1213         def gen_sig_code(idxs):
1214             def _genslice(start, end, step):
1215                 starts = '' if start == 0 else str(start)
1216                 ends = (':%d' % (end + step)) if end + step &gt;= 0 else ':'
1217                 steps = '' if step == 1 else (':%d' % step)
1218                 return 's[%s%s%s]' % (starts, ends, steps)
1219             step = None
1220             start = '(Never used)'
1221             for i, prev in zip(idxs[1:], idxs[:-1]):
1222                 if step is not None:
1223                     if i - prev == step:
1224                         continue
1225                     yield _genslice(start, prev, step)
1226                     step = None
1227                     continue
1228                 if i - prev in [-1, 1]:
1229                     step = i - prev
1230                     start = prev
1231                     continue
1232                 else:
1233                     yield 's[%d]' % prev
1234             if step is None:
1235                 yield 's[%d]' % i
1236             else:
1237                 yield _genslice(start, i, step)
1238         test_string = ''.join(map(compat_chr, range(len(example_sig))))
1239         cache_res = func(test_string)
1240         cache_spec = [ord(c) for c in cache_res]
1241         expr_code = ' + '.join(gen_sig_code(cache_spec))
1242         signature_id_tuple = '(%s)' % (
1243             ', '.join(compat_str(len(p)) for p in example_sig.split('.')))
1244         code = ('if tuple(len(p) for p in s.split(\'.\')) == %s:\n'
1245                 '    return %s\n') % (signature_id_tuple, expr_code)
1246         self.to_screen('Extracted signature function:\n' + code)
1247     def _parse_sig_js(self, jscode):
1248         funcname = self._search_regex(
1249             (r'\b[cs]\s*&amp;&amp;\s*[adf]\.set\([^,]+\s*,\s*encodeURIComponent\s*\(\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1250              r'\b[a-zA-Z0-9]+\s*&amp;&amp;\s*[a-zA-Z0-9]+\.set\([^,]+\s*,\s*encodeURIComponent\s*\(\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1251              r'\bm=(?P&lt;sig&gt;[a-zA-Z0-9$]{2,})\(decodeURIComponent\(h\.s\)\)',
1252              r'\bc&amp;&amp;\(c=(?P&lt;sig&gt;[a-zA-Z0-9$]{2,})\(decodeURIComponent\(c\)\)',
1253              r'(?:\b|[^a-zA-Z0-9$])(?P&lt;sig&gt;[a-zA-Z0-9$]{2,})\s*=\s*function\(\s*a\s*\)\s*{\s*a\s*=\s*a\.split\(\s*""\s*\);[a-zA-Z0-9$]{2}\.[a-zA-Z0-9$]{2}\(a,\d+\)',
1254              r'(?:\b|[^a-zA-Z0-9$])(?P&lt;sig&gt;[a-zA-Z0-9$]{2,})\s*=\s*function\(\s*a\s*\)\s*{\s*a\s*=\s*a\.split\(\s*""\s*\)',
1255              r'(?P&lt;sig&gt;[a-zA-Z0-9$]+)\s*=\s*function\(\s*a\s*\)\s*{\s*a\s*=\s*a\.split\(\s*""\s*\)',
1256              r'(["\'])signature\1\s*,\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1257              r'\.sig\|\|(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1258              r'yt\.akamaized\.net/\)\s*\|\|\s*.*?\s*[cs]\s*&amp;&amp;\s*[adf]\.set\([^,]+\s*,\s*(?:encodeURIComponent\s*\()?\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1259              r'\b[cs]\s*&amp;&amp;\s*[adf]\.set\([^,]+\s*,\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1260              r'\b[a-zA-Z0-9]+\s*&amp;&amp;\s*[a-zA-Z0-9]+\.set\([^,]+\s*,\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1261              r'\bc\s*&amp;&amp;\s*a\.set\([^,]+\s*,\s*\([^)]*\)\s*\(\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1262              r'\bc\s*&amp;&amp;\s*[a-zA-Z0-9]+\.set\([^,]+\s*,\s*\([^)]*\)\s*\(\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\(',
1263              r'\bc\s*&amp;&amp;\s*[a-zA-Z0-9]+\.set\([^,]+\s*,\s*\([^)]*\)\s*\(\s*(?P&lt;sig&gt;[a-zA-Z0-9$]+)\('),
1264             jscode, 'Initial JS player signature function name', group='sig')
1265         jsi = JSInterpreter(jscode)
1266         initial_function = jsi.extract_function(funcname)
1267         return lambda s: initial_function([s])
1268     def _decrypt_signature(self, s, video_id, player_url):
1269         if player_url is None:
1270             raise ExtractorError('Cannot decrypt signature without player_url')
1271         try:
1272             player_id = (player_url, self._signature_cache_id(s))
1273             if player_id not in self._player_cache:
1274                 func = self._extract_signature_function(
1275                     video_id, player_url, s
1276                 )
1277                 self._player_cache[player_id] = func
1278             func = self._player_cache[player_id]
1279             if self._downloader.params.get('youtube_print_sig_code'):
1280                 self._print_sig_code(func, s)
1281             return func(s)
1282         except Exception as e:
1283             tb = traceback.format_exc()
1284             raise ExtractorError(
1285                 'Signature extraction failed: ' + tb, cause=e)
1286     def _extract_player_url(self, webpage):
1287         player_url = self._search_regex(
1288             r'"(?:PLAYER_JS_URL|jsUrl)"\s*:\s*"([^"]+)"',
1289             webpage or '', 'player URL', fatal=False)
1290         if not player_url:
1291             return
1292         if player_url.startswith('//'):
1293             player_url = 'https:' + player_url
1294         elif not re.match(r'https?://', player_url):
1295             player_url = compat_urlparse.urljoin(
1296                 'https://www.youtube.com', player_url)
1297         return player_url
1298     def _extract_n_function_name(self, jscode):
1299         target = r'(?P&lt;nfunc&gt;[a-zA-Z0-9$]{3})(?:\[(?P&lt;idx&gt;\d+)\])?'
1300         nfunc_and_idx = self._search_regex(
1301             r'\.get\("n"\)\)&amp;&amp;\(b=(%s)\([a-zA-Z0-9]\)' % (target, ),
1302             jscode, 'Initial JS player n function name')
1303         nfunc, idx = re.match(target, nfunc_and_idx).group('nfunc', 'idx')
1304         if not idx:
1305             return nfunc
1306         return self._parse_json(self._search_regex(
1307             r'var %s\s*=\s*(\[.+?\]);' % (nfunc, ), jscode,
1308             'Initial JS player n function list ({nfunc}[{idx}])'.format(**locals())), nfunc, transform_source=js_to_json)[int(idx)]
1309     def _extract_n_function(self, video_id, player_url):
1310         player_id = self._extract_player_info(player_url)
1311         func_code = self._downloader.cache.load('youtube-nsig', player_id)
1312         if func_code:
1313             jsi = JSInterpreter(func_code)
1314         else:
1315             player_id = self._extract_player_info(player_url)
1316             jscode = self._get_player_code(video_id, player_url, player_id)
1317             funcname = self._extract_n_function_name(jscode)
1318             jsi = JSInterpreter(jscode)
1319             func_code = jsi.extract_function_code(funcname)
1320             self._downloader.cache.store('youtube-nsig', player_id, func_code)
1321         if self._downloader.params.get('youtube_print_sig_code'):
1322             self.to_screen('Extracted nsig function from {0}:\n{1}\n'.format(player_id, func_code[1]))
1323         return lambda s: jsi.extract_function_from_code(*func_code)([s])
1324     def _n_descramble(self, n_param, player_url, video_id):
1325         sig_id = ('nsig_value', n_param)
1326         if sig_id in self._player_cache:
1327             return self._player_cache[sig_id]
1328         try:
1329             player_id = ('nsig', player_url)
1330             if player_id not in self._player_cache:
1331                 self._player_cache[player_id] = self._extract_n_function(video_id, player_url)
1332             func = self._player_cache[player_id]
1333             self._player_cache[sig_id] = func(n_param)
1334             if self._downloader.params.get('verbose', False):
1335                 self._downloader.to_screen('[debug] [%s] %s' % (self.IE_NAME, 'Decrypted nsig {0} =&gt; {1}'.format(n_param, self._player_cache[sig_id])))
1336             return self._player_cache[sig_id]
1337         except Exception as e:
1338             self._downloader.report_warning(
1339                 '[%s] %s (%s %s)' % (
1340                     self.IE_NAME,
1341                     'Unable to decode n-parameter: download likely to be throttled',
1342                     error_to_compat_str(e),
1343                     traceback.format_exc()))
1344     def _unthrottle_format_urls(self, video_id, player_url, formats):
1345         for fmt in formats:
1346             parsed_fmt_url = compat_urlparse.urlparse(fmt['url'])
1347             qs = compat_urlparse.parse_qs(parsed_fmt_url.query)
1348             n_param = qs.get('n')
1349             if not n_param:
1350                 continue
1351             n_param = n_param[-1]
1352             n_response = self._n_descramble(n_param, player_url, video_id)
1353             if n_response:
1354                 qs['n'] = [n_response]
1355                 fmt['url'] = compat_urlparse.urlunparse(
1356                     parsed_fmt_url._replace(query=compat_urllib_parse_urlencode(qs, True)))
1357     def _mark_watched(self, video_id, player_response):
1358         playback_url = url_or_none(try_get(
1359             player_response,
1360             lambda x: x['playbackTracking']['videostatsPlaybackUrl']['baseUrl']))
1361         if not playback_url:
1362             return
1363         parsed_playback_url = compat_urlparse.urlparse(playback_url)
1364         qs = compat_urlparse.parse_qs(parsed_playback_url.query)
1365         CPN_ALPHABET = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_'
1366         cpn = ''.join((CPN_ALPHABET[random.randint(0, 256) &amp; 63] for _ in range(0, 16)))
1367         qs.update({
1368             'ver': ['2'],
1369             'cpn': [cpn],
1370         })
1371         playback_url = compat_urlparse.urlunparse(
1372             parsed_playback_url._replace(query=compat_urllib_parse_urlencode(qs, True)))
1373         self._download_webpage(
1374             playback_url, video_id, 'Marking watched',
1375             'Unable to mark watched', fatal=False)
1376     @staticmethod
1377     def _extract_urls(webpage):
1378         entries = [
1379             unescapeHTML(mobj.group('url'))
1380             for mobj in re.finditer(r'''(?x)
1381             (?:
1382                 &lt;iframe[^&gt;]+?src=|
1383                 data-video-url=|
1384                 &lt;embed[^&gt;]+?src=|
1385                 embedSWF\(?:\s*|
1386                 &lt;object[^&gt;]+data=|
1387                 new\s+SWFObject\(
1388             )
1389             (["\'])
1390                 (?P&lt;url&gt;(?:https?:)?//(?:www\.)?youtube(?:-nocookie)?\.com/
1391                 (?:embed|v|p)/[0-9A-Za-z_-]{11}.*?)
1392             \1''', webpage)]
1393         entries.extend(list(map(
1394             unescapeHTML,
1395             re.findall(r'class="lazyYT" data-youtube-id="([^"]+)"', webpage))))
1396         matches = re.findall(r'''(?x)&lt;div[^&gt;]+
1397             class=(?P&lt;q1&gt;[\'"])[^\'"]*\byvii_single_video_player\b[^\'"]*(?P=q1)[^&gt;]+
1398             data-video_id=(?P&lt;q2&gt;[\'"])([^\'"]+)(?P=q2)''', webpage)
1399         entries.extend(m[-1] for m in matches)
1400         return entries
1401     @staticmethod
1402     def _extract_url(webpage):
1403         urls = YoutubeIE._extract_urls(webpage)
1404         return urls[0] if urls else None
1405     @classmethod
1406     def extract_id(cls, url):
1407         mobj = re.match(cls._VALID_URL, url, re.VERBOSE)
1408         if mobj is None:
1409             raise ExtractorError('Invalid URL: %s' % url)
1410         video_id = mobj.group(2)
1411         return video_id
1412     def _extract_chapters_from_json(self, data, video_id, duration):
1413         chapters_list = try_get(
1414             data,
1415             lambda x: x['playerOverlays']
1416                        ['playerOverlayRenderer']
1417                        ['decoratedPlayerBarRenderer']
1418                        ['decoratedPlayerBarRenderer']
1419                        ['playerBar']
1420                        ['chapteredPlayerBarRenderer']
1421                        ['chapters'],
1422             list)
1423         if not chapters_list:
1424             return
1425         def chapter_time(chapter):
1426             return float_or_none(
1427                 try_get(
1428                     chapter,
1429                     lambda x: x['chapterRenderer']['timeRangeStartMillis'],
1430                     int),
1431                 scale=1000)
1432         chapters = []
1433         for next_num, chapter in enumerate(chapters_list, start=1):
1434             start_time = chapter_time(chapter)
1435             if start_time is None:
1436                 continue
1437             end_time = (chapter_time(chapters_list[next_num])
1438                         if next_num &lt; len(chapters_list) else duration)
1439             if end_time is None:
1440                 continue
1441             title = try_get(
1442                 chapter, lambda x: x['chapterRenderer']['title']['simpleText'],
1443                 compat_str)
1444             chapters.append({
1445                 'start_time': start_time,
1446                 'end_time': end_time,
1447                 'title': title,
1448             })
1449         return chapters
1450     def _extract_yt_initial_variable(self, webpage, regex, video_id, name):
1451         return self._parse_json(self._search_regex(
1452             (r'%s\s*%s' % (regex, self._YT_INITIAL_BOUNDARY_RE),
1453              regex), webpage, name, default='{}'), video_id, fatal=False)
1454     def _real_extract(self, url):
1455         url, smuggled_data = unsmuggle_url(url, {})
1456         video_id = self._match_id(url)
1457         base_url = self.http_scheme() + '//www.youtube.com/'
1458         webpage_url = base_url + 'watch?v=' + video_id
1459         webpage = self._download_webpage(
1460             webpage_url + '&amp;bpctr=9999999999&amp;has_verified=1', video_id, fatal=False)
1461         player_response = None
1462         if webpage:
1463             player_response = self._extract_yt_initial_variable(
1464                 webpage, self._YT_INITIAL_PLAYER_RESPONSE_RE,
1465                 video_id, 'initial player response')
1466         if not player_response:
1467             player_response = self._call_api(
1468                 'player', {'videoId': video_id}, video_id)
1469         playability_status = player_response.get('playabilityStatus') or {}
1470         if playability_status.get('reason') == 'Sign in to confirm your age':
1471             video_info = self._download_webpage(
1472                 base_url + 'get_video_info', video_id,
1473                 'Refetching age-gated info webpage',
1474                 'unable to download video info webpage', query={
1475                     'video_id': video_id,
1476                     'eurl': 'https://youtube.googleapis.com/v/' + video_id,
1477                     'html5': 1,
1478                     'c': 'TVHTML5',
1479                     'cver': '6.20180913',
1480                 }, fatal=False)
1481             if video_info:
1482                 pr = self._parse_json(
1483                     try_get(
1484                         compat_parse_qs(video_info),
1485                         lambda x: x['player_response'][0], compat_str) or '{}',
1486                     video_id, fatal=False)
1487                 if pr and isinstance(pr, dict):
1488                     player_response = pr
1489         trailer_video_id = try_get(
1490             playability_status,
1491             lambda x: x['errorScreen']['playerLegacyDesktopYpcTrailerRenderer']['trailerVideoId'],
1492             compat_str)
1493         if trailer_video_id:
1494             return self.url_result(
1495                 trailer_video_id, self.ie_key(), trailer_video_id)
1496         def get_text(x):
1497             if not x:
1498                 return
1499             text = x.get('simpleText')
1500             if text and isinstance(text, compat_str):
1501                 return text
1502             runs = x.get('runs')
1503             if not isinstance(runs, list):
1504                 return
1505             return ''.join([r['text'] for r in runs if isinstance(r.get('text'), compat_str)])
1506         search_meta = (
1507             lambda x: self._html_search_meta(x, webpage, default=None)) \
1508             if webpage else lambda x: None
1509         video_details = player_response.get('videoDetails') or {}
1510         microformat = try_get(
1511             player_response,
1512             lambda x: x['microformat']['playerMicroformatRenderer'],
1513             dict) or {}
1514         video_title = video_details.get('title') \
1515             or get_text(microformat.get('title')) \
1516             or search_meta(['og:title', 'twitter:title', 'title'])
1517         video_description = video_details.get('shortDescription')
1518         if not smuggled_data.get('force_singlefeed', False):
1519             if not self._downloader.params.get('noplaylist'):
1520                 multifeed_metadata_list = try_get(
1521                     player_response,
1522                     lambda x: x['multicamera']['playerLegacyMulticameraRenderer']['metadataList'],
1523                     compat_str)
1524                 if multifeed_metadata_list:
1525                     entries = []
1526                     feed_ids = []
1527                     for feed in multifeed_metadata_list.split(','):
1528                         feed_data = compat_parse_qs(
1529                             compat_urllib_parse_unquote_plus(feed))
1530                         def feed_entry(name):
1531                             return try_get(
1532                                 feed_data, lambda x: x[name][0], compat_str)
1533                         feed_id = feed_entry('id')
1534                         if not feed_id:
1535                             continue
1536                         feed_title = feed_entry('title')
1537                         title = video_title
1538                         if feed_title:
1539                             title += ' (%s)' % feed_title
1540                         entries.append({
1541                             '_type': 'url_transparent',
1542                             'ie_key': 'Youtube',
1543                             'url': smuggle_url(
1544                                 base_url + 'watch?v=' + feed_data['id'][0],
1545                                 {'force_singlefeed': True}),
1546                             'title': title,
1547                         })
1548                         feed_ids.append(feed_id)
1549                     self.to_screen(
1550                         'Downloading multifeed video (%s) - add --no-playlist to just download video %s'
1551                         % (', '.join(feed_ids), video_id))
1552                     return self.playlist_result(
1553                         entries, video_id, video_title, video_description)
1554             else:
1555                 self.to_screen('Downloading just video %s because of --no-playlist' % video_id)
1556         formats = []
1557         itags = []
1558         itag_qualities = {}
1559         player_url = None
1560         q = qualities(['tiny', 'small', 'medium', 'large', 'hd720', 'hd1080', 'hd1440', 'hd2160', 'hd2880', 'highres'])
1561         streaming_data = player_response.get('streamingData') or {}
1562         streaming_formats = streaming_data.get('formats') or []
1563         streaming_formats.extend(streaming_data.get('adaptiveFormats') or [])
1564         for fmt in streaming_formats:
1565             if fmt.get('targetDurationSec') or fmt.get('drmFamilies'):
1566                 continue
1567             itag = str_or_none(fmt.get('itag'))
1568             quality = fmt.get('quality')
1569             if itag and quality:
1570                 itag_qualities[itag] = quality
1571             if fmt.get('type') == 'FORMAT_STREAM_TYPE_OTF':
1572                 continue
1573             fmt_url = fmt.get('url')
1574             if not fmt_url:
1575                 sc = compat_parse_qs(fmt.get('signatureCipher'))
1576                 fmt_url = url_or_none(try_get(sc, lambda x: x['url'][0]))
1577                 encrypted_sig = try_get(sc, lambda x: x['s'][0])
1578                 if not (sc and fmt_url and encrypted_sig):
1579                     continue
1580                 if not player_url:
1581                     player_url = self._extract_player_url(webpage)
1582                 if not player_url:
1583                     continue
1584                 signature = self._decrypt_signature(sc['s'][0], video_id, player_url)
1585                 sp = try_get(sc, lambda x: x['sp'][0]) or 'signature'
1586                 fmt_url += '&amp;' + sp + '=' + signature
1587             if itag:
1588                 itags.append(itag)
1589             tbr = float_or_none(
1590                 fmt.get('averageBitrate') or fmt.get('bitrate'), 1000)
1591             dct = {
1592                 'asr': int_or_none(fmt.get('audioSampleRate')),
1593                 'filesize': int_or_none(fmt.get('contentLength')),
1594                 'format_id': itag,
1595                 'format_note': fmt.get('qualityLabel') or quality,
1596                 'fps': int_or_none(fmt.get('fps')),
1597                 'height': int_or_none(fmt.get('height')),
1598                 'quality': q(quality),
1599                 'tbr': tbr,
1600                 'url': fmt_url,
1601                 'width': fmt.get('width'),
1602             }
1603             mimetype = fmt.get('mimeType')
1604             if mimetype:
1605                 mobj = re.match(
1606                     r'((?:[^/]+)/(?:[^;]+))(?:;\s*codecs="([^"]+)")?', mimetype)
1607                 if mobj:
1608                     dct['ext'] = mimetype2ext(mobj.group(1))
1609                     dct.update(parse_codecs(mobj.group(2)))
1610             no_audio = dct.get('acodec') == 'none'
1611             no_video = dct.get('vcodec') == 'none'
1612             if no_audio:
1613                 dct['vbr'] = tbr
1614             if no_video:
1615                 dct['abr'] = tbr
1616             if no_audio or no_video:
1617                 dct['downloader_options'] = {
1618                     'http_chunk_size': 10485760,
1619                 }
1620                 if dct.get('ext'):
1621                     dct['container'] = dct['ext'] + '_dash'
1622             formats.append(dct)
1623         hls_manifest_url = streaming_data.get('hlsManifestUrl')
1624         if hls_manifest_url:
1625             for f in self._extract_m3u8_formats(
1626                     hls_manifest_url, video_id, 'mp4', fatal=False):
1627                 itag = self._search_regex(
1628                     r'/itag/(\d+)', f['url'], 'itag', default=None)
1629                 if itag:
1630                     f['format_id'] = itag
1631                 formats.append(f)
1632         if self._downloader.params.get('youtube_include_dash_manifest', True):
1633             dash_manifest_url = streaming_data.get('dashManifestUrl')
1634             if dash_manifest_url:
1635                 for f in self._extract_mpd_formats(
1636                         dash_manifest_url, video_id, fatal=False):
1637                     itag = f['format_id']
1638                     if itag in itags:
1639                         continue
1640                     if itag in itag_qualities:
1641                         f['quality'] = q(itag_qualities[itag])
1642                     filesize = int_or_none(self._search_regex(
1643                         r'/clen/(\d+)', f.get('fragment_base_url')
1644                         or f['url'], 'file size', default=None))
1645                     if filesize:
1646                         f['filesize'] = filesize
1647                     formats.append(f)
1648         if not formats:
1649             if streaming_data.get('licenseInfos'):
1650                 raise ExtractorError(
1651                     'This video is DRM protected.', expected=True)
1652             pemr = try_get(
1653                 playability_status,
1654                 lambda x: x['errorScreen']['playerErrorMessageRenderer'],
1655                 dict) or {}
1656             reason = get_text(pemr.get('reason')) or playability_status.get('reason')
1657             subreason = pemr.get('subreason')
1658             if subreason:
1659                 subreason = clean_html(get_text(subreason))
1660                 if subreason == 'The uploader has not made this video available in your country.':
1661                     countries = microformat.get('availableCountries')
1662                     if not countries:
1663                         regions_allowed = search_meta('regionsAllowed')
1664                         countries = regions_allowed.split(',') if regions_allowed else None
1665                     self.raise_geo_restricted(
1666                         subreason, countries)
1667                 reason += '\n' + subreason
1668             if reason:
1669                 raise ExtractorError(reason, expected=True)
1670         self._sort_formats(formats)
1671         keywords = video_details.get('keywords') or []
1672         if not keywords and webpage:
1673             keywords = [
1674                 unescapeHTML(m.group('content'))
1675                 for m in re.finditer(self._meta_regex('og:video:tag'), webpage)]
1676         for keyword in keywords:
1677             if keyword.startswith('yt:stretch='):
1678                 mobj = re.search(r'(\d+)\s*:\s*(\d+)', keyword)
1679                 if mobj:
1680                     w, h = (float(v) for v in mobj.groups())
1681                     if w &gt; 0 and h &gt; 0:
1682                         ratio = w / h
1683                         for f in formats:
1684                             if f.get('vcodec') != 'none':
1685                                 f['stretched_ratio'] = ratio
1686                         break
1687         thumbnails = []
1688         for container in (video_details, microformat):
1689             for thumbnail in (try_get(
1690                     container,
1691                     lambda x: x['thumbnail']['thumbnails'], list) or []):
1692                 thumbnail_url = thumbnail.get('url')
1693                 if not thumbnail_url:
1694                     continue
1695                 thumbnails.append({
1696                     'height': int_or_none(thumbnail.get('height')),
1697                     'url': thumbnail_url,
1698                     'width': int_or_none(thumbnail.get('width')),
1699                 })
1700             if thumbnails:
1701                 break
1702         else:
1703             thumbnail = search_meta(['og:image', 'twitter:image'])
1704             if thumbnail:
1705                 thumbnails = [{'url': thumbnail}]
1706         category = microformat.get('category') or search_meta('genre')
1707         channel_id = video_details.get('channelId') \
1708             or microformat.get('externalChannelId') \
1709             or search_meta('channelId')
1710         duration = int_or_none(
1711             video_details.get('lengthSeconds')
1712             or microformat.get('lengthSeconds')) \
1713             or parse_duration(search_meta('duration'))
1714         is_live = video_details.get('isLive')
1715         owner_profile_url = microformat.get('ownerProfileUrl')
1716         if not player_url:
1717             player_url = self._extract_player_url(webpage)
1718         self._unthrottle_format_urls(video_id, player_url, formats)
1719         info = {
1720             'id': video_id,
1721             'title': self._live_title(video_title) if is_live else video_title,
1722             'formats': formats,
1723             'thumbnails': thumbnails,
1724             'description': video_description,
1725             'upload_date': unified_strdate(
1726                 microformat.get('uploadDate')
1727                 or search_meta('uploadDate')),
1728             'uploader': video_details['author'],
1729             'uploader_id': self._search_regex(r'/(?:channel|user)/([^/?&amp;#]+)', owner_profile_url, 'uploader id') if owner_profile_url else None,
1730             'uploader_url': owner_profile_url,
1731             'channel_id': channel_id,
1732             'channel_url': 'https://www.youtube.com/channel/' + channel_id if channel_id else None,
1733             'duration': duration,
1734             'view_count': int_or_none(
1735                 video_details.get('viewCount')
1736                 or microformat.get('viewCount')
1737                 or search_meta('interactionCount')),
1738             'average_rating': float_or_none(video_details.get('averageRating')),
1739             'age_limit': 18 if (
1740                 microformat.get('isFamilySafe') is False
1741                 or search_meta('isFamilyFriendly') == 'false'
1742                 or search_meta('og:restrictions:age') == '18+') else 0,
1743             'webpage_url': webpage_url,
1744             'categories': [category] if category else None,
1745             'tags': keywords,
1746             'is_live': is_live,
1747         }
1748         pctr = try_get(
1749             player_response,
1750             lambda x: x['captions']['playerCaptionsTracklistRenderer'], dict)
1751         if pctr:
1752             def process_language(container, base_url, lang_code, query):
1753                 lang_subs = []
1754                 for fmt in self._SUBTITLE_FORMATS:
1755                     query.update({
1756                         'fmt': fmt,
1757                     })
1758                     lang_subs.append({
1759                         'ext': fmt,
1760                         'url': update_url_query(base_url, query),
1761                     })
1762                 container[lang_code] = lang_subs
1763             subtitles = {}
1764             for caption_track in (pctr.get('captionTracks') or []):
1765                 base_url = caption_track.get('baseUrl')
1766                 if not base_url:
1767                     continue
1768                 if caption_track.get('kind') != 'asr':
1769                     lang_code = caption_track.get('languageCode')
1770                     if not lang_code:
1771                         continue
1772                     process_language(
1773                         subtitles, base_url, lang_code, {})
1774                     continue
1775                 automatic_captions = {}
1776                 for translation_language in (pctr.get('translationLanguages') or []):
1777                     translation_language_code = translation_language.get('languageCode')
1778                     if not translation_language_code:
1779                         continue
1780                     process_language(
1781                         automatic_captions, base_url, translation_language_code,
1782                         {'tlang': translation_language_code})
1783                 info['automatic_captions'] = automatic_captions
1784             info['subtitles'] = subtitles
1785         parsed_url = compat_urllib_parse_urlparse(url)
1786         for component in [parsed_url.fragment, parsed_url.query]:
1787             query = compat_parse_qs(component)
1788             for k, v in query.items():
1789                 for d_k, s_ks in [('start', ('start', 't')), ('end', ('end',))]:
1790                     d_k += '_time'
1791                     if d_k not in info and k in s_ks:
1792                         info[d_k] = parse_duration(query[k][0])
1793         if video_description:
1794             mobj = re.search(r'(?s)(?P&lt;track&gt;[^·\n]+)·(?P&lt;artist&gt;[^\n]+)\n+(?P&lt;album&gt;[^\n]+)(?:.+?℗\s*(?P&lt;release_year&gt;\d{4})(?!\d))?(?:.+?Released on\s*:\s*(?P&lt;release_date&gt;\d{4}-\d{2}-\d{2}))?(.+?\nArtist\s*:\s*(?P&lt;clean_artist&gt;[^\n]+))?.+\nAuto-generated by YouTube\.\s*$', video_description)
1795             if mobj:
1796                 release_year = mobj.group('release_year')
1797                 release_date = mobj.group('release_date')
1798                 if release_date:
1799                     release_date = release_date.replace('-', '')
1800 <a name="1"></a>                    if not release_year:
1801                         release_year = release_date[:4]
1802                 info.update({
1803                     'album': mobj<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.group('album'.strip()),
1804                     'artist': mobj.group('clean_artist') or ', '.join(a.strip() for a in mobj.group(</b></font>'artist').split('·')),
1805                     'track': mobj.group('track').strip(),
1806                     'release_date': release_date,
1807                     'release_year': int_or_none(release_year),
1808                 })
1809         initial_data = None
1810         if webpage:
1811             initial_data = self._extract_yt_initial_variable(
1812                 webpage, self._YT_INITIAL_DATA_RE, video_id,
1813                 'yt initial data')
1814         if not initial_data:
1815             initial_data = self._call_api(
1816                 'next', {'videoId': video_id}, video_id, fatal=False)
1817         if initial_data:
1818             chapters = self._extract_chapters_from_json(
1819                 initial_data, video_id, duration)
1820             if not chapters:
1821                 for engagment_pannel in (initial_data.get('engagementPanels') or []):
1822                     contents = try_get(
1823                         engagment_pannel, lambda x: x['engagementPanelSectionListRenderer']['content']['macroMarkersListRenderer']['contents'],
1824                         list)
1825                     if not contents:
1826                         continue
1827                     def chapter_time(mmlir):
1828                         return parse_duration(
1829                             get_text(mmlir.get('timeDescription')))
1830                     chapters = []
1831                     for next_num, content in enumerate(contents, start=1):
1832                         mmlir = content.get('macroMarkersListItemRenderer') or {}
1833                         start_time = chapter_time(mmlir)
1834                         end_time = chapter_time(try_get(
1835                             contents, lambda x: x[next_num]['macroMarkersListItemRenderer'])) \
1836                             if next_num &lt; len(contents) else duration
1837                         if start_time is None or end_time is None:
1838                             continue
1839                         chapters.append({
1840                             'start_time': start_time,
1841                             'end_time': end_time,
1842                             'title': get_text(mmlir.get('title')),
1843                         })
1844                     if chapters:
1845                         break
1846             if chapters:
1847                 info['chapters'] = chapters
1848             contents = try_get(
1849                 initial_data,
1850                 lambda x: x['contents']['twoColumnWatchNextResults']['results']['results']['contents'],
1851                 list) or []
1852             for content in contents:
1853                 vpir = content.get('videoPrimaryInfoRenderer')
1854                 if vpir:
1855                     stl = vpir.get('superTitleLink')
1856                     if stl:
1857                         stl = get_text(stl)
1858                         if try_get(
1859                                 vpir,
1860                                 lambda x: x['superTitleIcon']['iconType']) == 'LOCATION_PIN':
1861                             info['location'] = stl
1862                         else:
1863                             mobj = re.search(r'(.+?)\s*S(\d+)\s*•\s*E(\d+)', stl)
1864                             if mobj:
1865                                 info.update({
1866                                     'series': mobj.group(1),
1867                                     'season_number': int(mobj.group(2)),
1868                                     'episode_number': int(mobj.group(3)),
1869                                 })
1870                     for tlb in (try_get(
1871                             vpir,
1872                             lambda x: x['videoActions']['menuRenderer']['topLevelButtons'],
1873                             list) or []):
1874                         tbr = tlb.get('toggleButtonRenderer') or {}
1875                         for getter, regex in [(
1876                                 lambda x: x['defaultText']['accessibility']['accessibilityData'],
1877                                 r'(?P&lt;count&gt;[\d,]+)\s*(?P&lt;type&gt;(?:dis)?like)'), ([
1878                                     lambda x: x['accessibility'],
1879                                     lambda x: x['accessibilityData']['accessibilityData'],
1880                                 ], r'(?P&lt;type&gt;(?:dis)?like) this video along with (?P&lt;count&gt;[\d,]+) other people')]:
1881                             label = (try_get(tbr, getter, dict) or {}).get('label')
1882                             if label:
1883                                 mobj = re.match(regex, label)
1884                                 if mobj:
1885                                     info[mobj.group('type') + '_count'] = str_to_int(mobj.group('count'))
1886                                     break
1887                     sbr_tooltip = try_get(
1888                         vpir, lambda x: x['sentimentBar']['sentimentBarRenderer']['tooltip'])
1889                     if sbr_tooltip:
1890                         like_count, dislike_count = sbr_tooltip.split(' / ')
1891                         info.update({
1892                             'like_count': str_to_int(like_count),
1893                             'dislike_count': str_to_int(dislike_count),
1894                         })
1895                 vsir = content.get('videoSecondaryInfoRenderer')
1896                 if vsir:
1897                     info['channel'] = get_text(try_get(
1898                         vsir,
1899                         lambda x: x['owner']['videoOwnerRenderer']['title'],
1900                         dict))
1901                     rows = try_get(
1902                         vsir,
1903                         lambda x: x['metadataRowContainer']['metadataRowContainerRenderer']['rows'],
1904                         list) or []
1905                     multiple_songs = False
1906                     for row in rows:
1907                         if try_get(row, lambda x: x['metadataRowRenderer']['hasDividerLine']) is True:
1908                             multiple_songs = True
1909                             break
1910                     for row in rows:
1911                         mrr = row.get('metadataRowRenderer') or {}
1912                         mrr_title = mrr.get('title')
1913                         if not mrr_title:
1914                             continue
1915                         mrr_title = get_text(mrr['title'])
1916                         mrr_contents_text = get_text(mrr['contents'][0])
1917                         if mrr_title == 'License':
1918                             info['license'] = mrr_contents_text
1919                         elif not multiple_songs:
1920                             if mrr_title == 'Album':
1921                                 info['album'] = mrr_contents_text
1922                             elif mrr_title == 'Artist':
1923                                 info['artist'] = mrr_contents_text
1924                             elif mrr_title == 'Song':
1925                                 info['track'] = mrr_contents_text
1926         for s_k, d_k in [('artist', 'creator'), ('track', 'alt_title')]:
1927             v = info.get(s_k)
1928             if v:
1929                 info[d_k] = v
1930         self.mark_watched(video_id, player_response)
1931         return info
1932 class YoutubeTabIE(YoutubeBaseInfoExtractor):
1933     IE_DESC = 'YouTube.com tab'
1934     _VALID_URL = r'''(?x)
1935                     https?://
1936                         (?:\w+\.)?
1937                         (?:
1938                             youtube(?:kids)?\.com|
1939                             invidio\.us
1940                         )/
1941                         (?:
1942                             (?:channel|c|user|feed|hashtag)/|
1943                             (?:playlist|watch)\?.*?\blist=|
1944                             (?!(?:watch|embed|v|e|results)\b)
1945                         )
1946                         (?P&lt;id&gt;[^/?\#&amp;]+)
1947                     '''
1948     IE_NAME = 'youtube:tab'
1949     _TESTS = [{
1950         'url': 'https://www.youtube.com/c/ИгорьКлейнер/playlists?view=1&amp;flow=grid',
1951         'playlist_mincount': 94,
1952         'info_dict': {
1953             'id': 'UCqj7Cz7revf5maW9g5pgNcg',
1954             'title': 'Игорь Клейнер - Playlists',
1955             'description': 'md5:be97ee0f14ee314f1f002cf187166ee2',
1956         },
1957     }, {
1958         'url': 'https://www.youtube.com/user/igorkle1/playlists?view=1&amp;sort=dd',
1959         'playlist_mincount': 94,
1960         'info_dict': {
1961             'id': 'UCqj7Cz7revf5maW9g5pgNcg',
1962             'title': 'Игорь Клейнер - Playlists',
1963             'description': 'md5:be97ee0f14ee314f1f002cf187166ee2',
1964         },
1965     }, {
1966         'url': 'https://www.youtube.com/c/3blue1brown/playlists?view=50&amp;sort=dd&amp;shelf_id=3',
1967         'playlist_mincount': 5,
1968         'info_dict': {
1969             'id': 'UCYO_jab_esuFRV4b17AJtAw',
1970             'title': '3Blue1Brown - Playlists',
1971             'description': 'md5:e1384e8a133307dd10edee76e875d62f',
1972         },
1973     }, {
1974         'url': 'https://www.youtube.com/user/ThirstForScience/playlists',
1975         'playlist_mincount': 4,
1976         'info_dict': {
1977             'id': 'UCAEtajcuhQ6an9WEzY9LEMQ',
1978             'title': 'ThirstForScience - Playlists',
1979             'description': 'md5:609399d937ea957b0f53cbffb747a14c',
1980         }
1981     }, {
1982         'url': 'https://www.youtube.com/c/ChristophLaimer/playlists',
1983         'only_matching': True,
1984     }, {
1985         'url': 'https://www.youtube.com/playlist?list=PL4lCao7KL_QFVb7Iudeipvc2BCavECqzc',
1986         'info_dict': {
1987             'uploader_id': 'UCmlqkdCBesrv2Lak1mF_MxA',
1988             'uploader': 'Sergey M.',
1989             'id': 'PL4lCao7KL_QFVb7Iudeipvc2BCavECqzc',
1990             'title': 'youtube-dl public playlist',
1991         },
1992         'playlist_count': 1,
1993     }, {
1994         'url': 'https://www.youtube.com/playlist?list=PL4lCao7KL_QFodcLWhDpGCYnngnHtQ-Xf',
1995         'info_dict': {
1996             'uploader_id': 'UCmlqkdCBesrv2Lak1mF_MxA',
1997             'uploader': 'Sergey M.',
1998             'id': 'PL4lCao7KL_QFodcLWhDpGCYnngnHtQ-Xf',
1999             'title': 'youtube-dl empty playlist',
2000         },
2001         'playlist_count': 0,
2002     }, {
2003         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/featured',
2004         'info_dict': {
2005             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2006             'title': 'lex will - Home',
2007             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2008         },
2009         'playlist_mincount': 2,
2010     }, {
2011         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/videos',
2012         'info_dict': {
2013             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2014             'title': 'lex will - Videos',
2015             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2016         },
2017         'playlist_mincount': 975,
2018     }, {
2019         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/videos?view=0&amp;sort=p&amp;flow=grid',
2020         'info_dict': {
2021             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2022             'title': 'lex will - Videos',
2023             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2024         },
2025         'playlist_mincount': 199,
2026     }, {
2027         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/playlists',
2028         'info_dict': {
2029             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2030             'title': 'lex will - Playlists',
2031             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2032         },
2033         'playlist_mincount': 17,
2034     }, {
2035         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/community',
2036         'info_dict': {
2037             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2038             'title': 'lex will - Community',
2039             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2040         },
2041         'playlist_mincount': 18,
2042     }, {
2043         'url': 'https://www.youtube.com/channel/UCKfVa3S1e4PHvxWcwyMMg8w/channels',
2044         'info_dict': {
2045             'id': 'UCKfVa3S1e4PHvxWcwyMMg8w',
2046             'title': 'lex will - Channels',
2047             'description': 'md5:2163c5d0ff54ed5f598d6a7e6211e488',
2048         },
2049         'playlist_mincount': 138,
2050     }, {
2051         'url': 'https://invidio.us/channel/UCmlqkdCBesrv2Lak1mF_MxA',
2052         'only_matching': True,
2053     }, {
2054         'url': 'https://www.youtubekids.com/channel/UCmlqkdCBesrv2Lak1mF_MxA',
2055         'only_matching': True,
2056     }, {
2057         'url': 'https://music.youtube.com/channel/UCmlqkdCBesrv2Lak1mF_MxA',
2058         'only_matching': True,
2059     }, {
2060         'note': 'Playlist with deleted videos (#651). As a bonus, the video #51 is also twice in this list.',
2061         'url': 'https://www.youtube.com/playlist?list=PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC',
2062         'info_dict': {
2063             'title': '29C3: Not my department',
2064             'id': 'PLwP_SiAcdui0KVebT0mU9Apz359a4ubsC',
2065             'uploader': 'Christiaan008',
2066             'uploader_id': 'UCEPzS1rYsrkqzSLNp76nrcg',
2067         },
2068         'playlist_count': 96,
2069     }, {
2070         'note': 'Large playlist',
2071         'url': 'https://www.youtube.com/playlist?list=UUBABnxM4Ar9ten8Mdjj1j0Q',
2072         'info_dict': {
2073             'title': 'Uploads from Cauchemar',
2074             'id': 'UUBABnxM4Ar9ten8Mdjj1j0Q',
2075             'uploader': 'Cauchemar',
2076             'uploader_id': 'UCBABnxM4Ar9ten8Mdjj1j0Q',
2077         },
2078         'playlist_mincount': 1123,
2079     }, {
2080         'url': 'http://www.youtube.com/user/NASAgovVideo/videos',
2081         'only_matching': True,
2082     }, {
2083         'note': 'Buggy playlist: the webpage has a "Load more" button but it doesn\'t have more videos',
2084         'url': 'https://www.youtube.com/playlist?list=UUXw-G3eDE9trcvY2sBMM_aA',
2085         'info_dict': {
2086             'title': 'Uploads from Interstellar Movie',
2087             'id': 'UUXw-G3eDE9trcvY2sBMM_aA',
2088             'uploader': 'Interstellar Movie',
2089             'uploader_id': 'UCXw-G3eDE9trcvY2sBMM_aA',
2090         },
2091         'playlist_mincount': 21,
2092     }, {
2093         'url': 'https://www.youtube.com/playlist?list=PLzH6n4zXuckpfMu_4Ff8E7Z1behQks5ba',
2094         'info_dict': {
2095             'title': 'Data Analysis with Dr Mike Pound',
2096             'id': 'PLzH6n4zXuckpfMu_4Ff8E7Z1behQks5ba',
2097             'uploader_id': 'UC9-y-6csu5WGm29I7JiwpnA',
2098             'uploader': 'Computerphile',
2099         },
2100         'playlist_mincount': 11,
2101     }, {
2102         'url': 'https://invidio.us/playlist?list=PL4lCao7KL_QFVb7Iudeipvc2BCavECqzc',
2103         'only_matching': True,
2104     }, {
2105         'url': 'https://www.youtube.com/watch?v=FqZTN594JQw&amp;list=PLMYEtVRpaqY00V9W81Cwmzp6N6vZqfUKD4',
2106         'info_dict': {
2107             'id': 'FqZTN594JQw',
2108             'ext': 'webm',
2109             'title': "Smiley's People 01 detective, Adventure Series, Action",
2110             'uploader': 'STREEM',
2111             'uploader_id': 'UCyPhqAZgwYWZfxElWVbVJng',
2112             'uploader_url': r're:https?://(?:www\.)?youtube\.com/channel/UCyPhqAZgwYWZfxElWVbVJng',
2113             'upload_date': '20150526',
2114             'license': 'Standard YouTube License',
2115             'description': 'md5:507cdcb5a49ac0da37a920ece610be80',
2116             'categories': ['People &amp; Blogs'],
2117             'tags': list,
2118             'view_count': int,
2119             'like_count': int,
2120             'dislike_count': int,
2121         },
2122         'params': {
2123             'skip_download': True,
2124         },
2125         'skip': 'This video is not available.',
2126         'add_ie': [YoutubeIE.ie_key()],
2127     }, {
2128         'url': 'https://www.youtubekids.com/watch?v=Agk7R8I8o5U&amp;list=PUZ6jURNr1WQZCNHF0ao-c0g',
2129         'only_matching': True,
2130     }, {
2131         'url': 'https://www.youtube.com/watch?v=MuAGGZNfUkU&amp;list=RDMM',
2132         'only_matching': True,
2133     }, {
2134         'url': 'https://www.youtube.com/channel/UCoMdktPbSTixAyNGwb-UYkQ/live',
2135         'info_dict': {
2136             'id': '9Auq9mYxFEE',
2137             'ext': 'mp4',
2138             'title': 'Watch Sky News live',
2139             'uploader': 'Sky News',
2140             'uploader_id': 'skynews',
2141             'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/skynews',
2142             'upload_date': '20191102',
2143             'description': 'md5:78de4e1c2359d0ea3ed829678e38b662',
2144             'categories': ['News &amp; Politics'],
2145             'tags': list,
2146             'like_count': int,
2147             'dislike_count': int,
2148         },
2149         'params': {
2150             'skip_download': True,
2151         },
2152     }, {
2153         'url': 'https://www.youtube.com/user/TheYoungTurks/live',
2154         'info_dict': {
2155             'id': 'a48o2S1cPoo',
2156             'ext': 'mp4',
2157             'title': 'The Young Turks - Live Main Show',
2158             'uploader': 'The Young Turks',
2159             'uploader_id': 'TheYoungTurks',
2160             'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/TheYoungTurks',
2161             'upload_date': '20150715',
2162             'license': 'Standard YouTube License',
2163             'description': 'md5:438179573adcdff3c97ebb1ee632b891',
2164             'categories': ['News &amp; Politics'],
2165             'tags': ['Cenk Uygur (TV Program Creator)', 'The Young Turks (Award-Winning Work)', 'Talk Show (TV Genre)'],
2166             'like_count': int,
2167             'dislike_count': int,
2168         },
2169         'params': {
2170             'skip_download': True,
2171         },
2172         'only_matching': True,
2173     }, {
2174         'url': 'https://www.youtube.com/channel/UC1yBKRuGpC1tSM73A0ZjYjQ/live',
2175         'only_matching': True,
2176     }, {
2177         'url': 'https://www.youtube.com/c/CommanderVideoHq/live',
2178         'only_matching': True,
2179     }, {
2180         'url': 'https://www.youtube.com/feed/trending',
2181         'only_matching': True,
2182     }, {
2183         'url': 'https://www.youtube.com/feed/library',
2184         'only_matching': True,
2185     }, {
2186         'url': 'https://www.youtube.com/feed/history',
2187         'only_matching': True,
2188     }, {
2189         'url': 'https://www.youtube.com/feed/subscriptions',
2190         'only_matching': True,
2191     }, {
2192         'url': 'https://www.youtube.com/feed/watch_later',
2193         'only_matching': True,
2194     }, {
2195         'url': 'https://www.youtube.com/feed/recommended',
2196         'only_matching': True,
2197     }, {
2198         'url': 'https://www.youtube.com/watch?v=UC6u0Tct-Fo&amp;list=PL36D642111D65BE7C',
2199         'only_matching': True,
2200     }, {
2201         'url': 'https://www.youtube.com/course?list=ECUl4u3cNGP61MdtwGTqZA0MreSaDybji8',
2202         'only_matching': True,
2203     }, {
2204         'url': 'https://www.youtube.com/course',
2205         'only_matching': True,
2206     }, {
2207         'url': 'https://www.youtube.com/zsecurity',
2208         'only_matching': True,
2209     }, {
2210         'url': 'http://www.youtube.com/NASAgovVideo/videos',
2211         'only_matching': True,
2212     }, {
2213         'url': 'https://www.youtube.com/TheYoungTurks/live',
2214         'only_matching': True,
2215     }, {
2216         'url': 'https://www.youtube.com/hashtag/cctv9',
2217         'info_dict': {
2218             'id': 'cctv9',
2219             'title': '#cctv9',
2220         },
2221         'playlist_mincount': 350,
2222     }, {
2223         'url': 'https://www.youtube.com/watch?list=PLW4dVinRY435CBE_JD3t-0SRXKfnZHS1P&amp;feature=youtu.be&amp;v=M9cJMXmQ_ZU',
2224         'only_matching': True,
2225     }, {
2226         'note': 'Search tab',
2227         'url': 'https://www.youtube.com/c/3blue1brown/search?query=linear%20algebra',
2228         'playlist_mincount': 40,
2229         'info_dict': {
2230             'id': 'UCYO_jab_esuFRV4b17AJtAw',
2231             'title': '3Blue1Brown - Search - linear algebra',
2232             'description': 'md5:e1384e8a133307dd10edee76e875d62f',
2233             'uploader': '3Blue1Brown',
2234             'uploader_id': 'UCYO_jab_esuFRV4b17AJtAw',
2235         }
2236     }]
2237     @classmethod
2238     def suitable(cls, url):
2239         return False if YoutubeIE.suitable(url) else super(
2240             YoutubeTabIE, cls).suitable(url)
2241     def _extract_channel_id(self, webpage):
2242         channel_id = self._html_search_meta(
2243             'channelId', webpage, 'channel id', default=None)
2244         if channel_id:
2245             return channel_id
2246         channel_url = self._html_search_meta(
2247             ('og:url', 'al:ios:url', 'al:android:url', 'al:web:url',
2248              'twitter:url', 'twitter:app:url:iphone', 'twitter:app:url:ipad',
2249              'twitter:app:url:googleplay'), webpage, 'channel url')
2250         return self._search_regex(
2251             r'https?://(?:www\.)?youtube\.com/channel/([^/?#&amp;])+',
2252             channel_url, 'channel id')
2253     @staticmethod
2254     def _extract_grid_item_renderer(item):
2255         assert isinstance(item, dict)
2256         for key, renderer in item.items():
2257             if not key.startswith('grid') or not key.endswith('Renderer'):
2258                 continue
2259             if not isinstance(renderer, dict):
2260                 continue
2261             return renderer
2262     def _grid_entries(self, grid_renderer):
2263         for item in grid_renderer['items']:
2264             if not isinstance(item, dict):
2265                 continue
2266             renderer = self._extract_grid_item_renderer(item)
2267             if not isinstance(renderer, dict):
2268                 continue
2269             title = try_get(
2270                 renderer, (lambda x: x['title']['runs'][0]['text'],
2271                            lambda x: x['title']['simpleText']), compat_str)
2272             playlist_id = renderer.get('playlistId')
2273             if playlist_id:
2274                 yield self.url_result(
2275                     'https://www.youtube.com/playlist?list=%s' % playlist_id,
2276                     ie=YoutubeTabIE.ie_key(), video_id=playlist_id,
2277                     video_title=title)
2278                 continue
2279             video_id = renderer.get('videoId')
2280             if video_id:
2281                 yield self._extract_video(renderer)
2282                 continue
2283             channel_id = renderer.get('channelId')
2284             if channel_id:
2285                 title = try_get(
2286                     renderer, lambda x: x['title']['simpleText'], compat_str)
2287                 yield self.url_result(
2288                     'https://www.youtube.com/channel/%s' % channel_id,
2289                     ie=YoutubeTabIE.ie_key(), video_title=title)
2290                 continue
2291             ep_url = urljoin('https://www.youtube.com/', try_get(
2292                 renderer, lambda x: x['navigationEndpoint']['commandMetadata']['webCommandMetadata']['url'],
2293                 compat_str))
2294             if ep_url:
2295                 for ie in (YoutubeTabIE, YoutubePlaylistIE, YoutubeIE):
2296                     if ie.suitable(ep_url):
2297                         yield self.url_result(
2298                             ep_url, ie=ie.ie_key(), video_id=ie._match_id(ep_url), video_title=title)
2299                         break
2300     def _shelf_entries_from_content(self, shelf_renderer):
2301         content = shelf_renderer.get('content')
2302         if not isinstance(content, dict):
2303             return
2304         renderer = content.get('gridRenderer')
2305         if renderer:
2306             for entry in self._grid_entries(renderer):
2307                 yield entry
2308         renderer = content.get('horizontalListRenderer')
2309         if renderer:
2310             pass
2311     def _shelf_entries(self, shelf_renderer, skip_channels=False):
2312         ep = try_get(
2313             shelf_renderer, lambda x: x['endpoint']['commandMetadata']['webCommandMetadata']['url'],
2314             compat_str)
2315         shelf_url = urljoin('https://www.youtube.com', ep)
2316         if shelf_url:
2317             if skip_channels and '/channels?' in shelf_url:
2318                 return
2319             title = try_get(
2320                 shelf_renderer, lambda x: x['title']['runs'][0]['text'], compat_str)
2321             yield self.url_result(shelf_url, video_title=title)
2322         for entry in self._shelf_entries_from_content(shelf_renderer):
2323             yield entry
2324     def _playlist_entries(self, video_list_renderer):
2325         for content in video_list_renderer['contents']:
2326             if not isinstance(content, dict):
2327                 continue
2328             renderer = content.get('playlistVideoRenderer') or content.get('playlistPanelVideoRenderer')
2329             if not isinstance(renderer, dict):
2330                 continue
2331             video_id = renderer.get('videoId')
2332             if not video_id:
2333                 continue
2334             yield self._extract_video(renderer)
2335     def _video_entry(self, video_renderer):
2336         video_id = video_renderer.get('videoId')
2337         if video_id:
2338             return self._extract_video(video_renderer)
2339     def _post_thread_entries(self, post_thread_renderer):
2340         post_renderer = try_get(
2341             post_thread_renderer, lambda x: x['post']['backstagePostRenderer'], dict)
2342         if not post_renderer:
2343             return
2344         video_renderer = try_get(
2345             post_renderer, lambda x: x['backstageAttachment']['videoRenderer'], dict)
2346         video_id = None
2347         if video_renderer:
2348             entry = self._video_entry(video_renderer)
2349             if entry:
2350                 yield entry
2351         runs = try_get(post_renderer, lambda x: x['contentText']['runs'], list) or []
2352         for run in runs:
2353             if not isinstance(run, dict):
2354                 continue
2355             ep_url = try_get(
2356                 run, lambda x: x['navigationEndpoint']['urlEndpoint']['url'], compat_str)
2357             if not ep_url:
2358                 continue
2359             if not YoutubeIE.suitable(ep_url):
2360                 continue
2361             ep_video_id = YoutubeIE._match_id(ep_url)
2362             if video_id == ep_video_id:
2363                 continue
2364             yield self.url_result(ep_url, ie=YoutubeIE.ie_key(), video_id=video_id)
2365     def _post_thread_continuation_entries(self, post_thread_continuation):
2366         contents = post_thread_continuation.get('contents')
2367         if not isinstance(contents, list):
2368             return
2369         for content in contents:
2370             renderer = content.get('backstagePostThreadRenderer')
2371             if not isinstance(renderer, dict):
2372                 continue
2373             for entry in self._post_thread_entries(renderer):
2374                 yield entry
2375     def _rich_grid_entries(self, contents):
2376         for content in contents:
2377             video_renderer = try_get(content, lambda x: x['richItemRenderer']['content']['videoRenderer'], dict)
2378             if video_renderer:
2379                 entry = self._video_entry(video_renderer)
2380                 if entry:
2381                     yield entry
2382     @staticmethod
2383     def _build_continuation_query(continuation, ctp=None):
2384         query = {
2385             'ctoken': continuation,
2386             'continuation': continuation,
2387         }
2388         if ctp:
2389             query['itct'] = ctp
2390         return query
2391     @staticmethod
2392     def _extract_next_continuation_data(renderer):
2393         next_continuation = try_get(
2394             renderer, lambda x: x['continuations'][0]['nextContinuationData'], dict)
2395         if not next_continuation:
2396             return
2397         continuation = next_continuation.get('continuation')
2398         if not continuation:
2399             return
2400         ctp = next_continuation.get('clickTrackingParams')
2401         return YoutubeTabIE._build_continuation_query(continuation, ctp)
2402     @classmethod
2403     def _extract_continuation(cls, renderer):
2404         next_continuation = cls._extract_next_continuation_data(renderer)
2405         if next_continuation:
2406             return next_continuation
2407         contents = []
2408         for key in ('contents', 'items'):
2409             contents.extend(try_get(renderer, lambda x: x[key], list) or [])
2410         for content in contents:
2411             if not isinstance(content, dict):
2412                 continue
2413             continuation_ep = try_get(
2414                 content, lambda x: x['continuationItemRenderer']['continuationEndpoint'],
2415                 dict)
2416             if not continuation_ep:
2417                 continue
2418             continuation = try_get(
2419                 continuation_ep, lambda x: x['continuationCommand']['token'], compat_str)
2420             if not continuation:
2421                 continue
2422             ctp = continuation_ep.get('clickTrackingParams')
2423             return YoutubeTabIE._build_continuation_query(continuation, ctp)
2424     def _entries(self, tab, item_id, webpage):
2425         tab_content = try_get(tab, lambda x: x['content'], dict)
2426         if not tab_content:
2427             return
2428         slr_renderer = try_get(tab_content, lambda x: x['sectionListRenderer'], dict)
2429         if slr_renderer:
2430             is_channels_tab = tab.get('title') == 'Channels'
2431             continuation = None
2432             slr_contents = try_get(slr_renderer, lambda x: x['contents'], list) or []
2433             for slr_content in slr_contents:
2434                 if not isinstance(slr_content, dict):
2435                     continue
2436                 is_renderer = try_get(slr_content, lambda x: x['itemSectionRenderer'], dict)
2437                 if not is_renderer:
2438                     continue
2439                 isr_contents = try_get(is_renderer, lambda x: x['contents'], list) or []
2440                 for isr_content in isr_contents:
2441                     if not isinstance(isr_content, dict):
2442                         continue
2443                     renderer = isr_content.get('playlistVideoListRenderer')
2444                     if renderer:
2445                         for entry in self._playlist_entries(renderer):
2446                             yield entry
2447                         continuation = self._extract_continuation(renderer)
2448                         continue
2449                     renderer = isr_content.get('gridRenderer')
2450                     if renderer:
2451                         for entry in self._grid_entries(renderer):
2452                             yield entry
2453                         continuation = self._extract_continuation(renderer)
2454                         continue
2455                     renderer = isr_content.get('shelfRenderer')
2456                     if renderer:
2457                         for entry in self._shelf_entries(renderer, not is_channels_tab):
2458                             yield entry
2459                         continue
2460                     renderer = isr_content.get('backstagePostThreadRenderer')
2461                     if renderer:
2462                         for entry in self._post_thread_entries(renderer):
2463                             yield entry
2464                         continuation = self._extract_continuation(renderer)
2465                         continue
2466                     renderer = isr_content.get('videoRenderer')
2467                     if renderer:
2468                         entry = self._video_entry(renderer)
2469                         if entry:
2470                             yield entry
2471                 if not continuation:
2472                     continuation = self._extract_continuation(is_renderer)
2473             if not continuation:
2474                 continuation = self._extract_continuation(slr_renderer)
2475         else:
2476             rich_grid_renderer = tab_content.get('richGridRenderer')
2477             if not rich_grid_renderer:
2478                 return
2479             for entry in self._rich_grid_entries(rich_grid_renderer.get('contents') or []):
2480                 yield entry
2481             continuation = self._extract_continuation(rich_grid_renderer)
2482         ytcfg = self._extract_ytcfg(item_id, webpage)
2483         client_version = try_get(
2484             ytcfg, lambda x: x['INNERTUBE_CLIENT_VERSION'], compat_str) or '2.20210407.08.00'
2485         headers = {
2486             'x-youtube-client-name': '1',
2487             'x-youtube-client-version': client_version,
2488             'content-type': 'application/json',
2489         }
2490         context = try_get(ytcfg, lambda x: x['INNERTUBE_CONTEXT'], dict) or {
2491             'client': {
2492                 'clientName': 'WEB',
2493                 'clientVersion': client_version,
2494             }
2495         }
2496         visitor_data = try_get(context, lambda x: x['client']['visitorData'], compat_str)
2497         identity_token = self._extract_identity_token(ytcfg, webpage)
2498         if identity_token:
2499             headers['x-youtube-identity-token'] = identity_token
2500         data = {
2501             'context': context,
2502         }
2503         for page_num in itertools.count(1):
2504             if not continuation:
2505                 break
2506             if visitor_data:
2507                 headers['x-goog-visitor-id'] = visitor_data
2508             data['continuation'] = continuation['continuation']
2509             data['clickTracking'] = {
2510                 'clickTrackingParams': continuation['itct']
2511             }
2512             count = 0
2513             retries = 3
2514             while count &lt;= retries:
2515                 try:
2516                     response = self._download_json(
2517                         'https://www.youtube.com/youtubei/v1/browse?key=AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8',
2518                         None, 'Downloading page %d%s' % (page_num, ' (retry #%d)' % count if count else ''),
2519                         headers=headers, data=json.dumps(data).encode('utf8'))
2520                     break
2521                 except ExtractorError as e:
2522                     if isinstance(e.cause, compat_HTTPError) and e.cause.code in (500, 503):
2523                         count += 1
2524                         if count &lt;= retries:
2525                             continue
2526                     raise
2527             if not response:
2528                 break
2529             visitor_data = try_get(
2530                 response, lambda x: x['responseContext']['visitorData'], compat_str) or visitor_data
2531             continuation_contents = try_get(
2532                 response, lambda x: x['continuationContents'], dict)
2533             if continuation_contents:
2534                 continuation_renderer = continuation_contents.get('playlistVideoListContinuation')
2535                 if continuation_renderer:
2536                     for entry in self._playlist_entries(continuation_renderer):
2537                         yield entry
2538                     continuation = self._extract_continuation(continuation_renderer)
2539                     continue
2540                 continuation_renderer = continuation_contents.get('gridContinuation')
2541                 if continuation_renderer:
2542                     for entry in self._grid_entries(continuation_renderer):
2543                         yield entry
2544                     continuation = self._extract_continuation(continuation_renderer)
2545                     continue
2546                 continuation_renderer = continuation_contents.get('itemSectionContinuation')
2547                 if continuation_renderer:
2548                     for entry in self._post_thread_continuation_entries(continuation_renderer):
2549                         yield entry
2550                     continuation = self._extract_continuation(continuation_renderer)
2551                     continue
2552             on_response_received = dict_get(response, ('onResponseReceivedActions', 'onResponseReceivedEndpoints'))
2553             continuation_items = try_get(
2554                 on_response_received, lambda x: x[0]['appendContinuationItemsAction']['continuationItems'], list)
2555             if continuation_items:
2556                 continuation_item = continuation_items[0]
2557                 if not isinstance(continuation_item, dict):
2558                     continue
2559                 renderer = self._extract_grid_item_renderer(continuation_item)
2560                 if renderer:
2561                     grid_renderer = {'items': continuation_items}
2562                     for entry in self._grid_entries(grid_renderer):
2563                         yield entry
2564                     continuation = self._extract_continuation(grid_renderer)
2565                     continue
2566                 renderer = continuation_item.get('playlistVideoRenderer') or continuation_item.get('itemSectionRenderer')
2567                 if renderer:
2568                     video_list_renderer = {'contents': continuation_items}
2569                     for entry in self._playlist_entries(video_list_renderer):
2570                         yield entry
2571                     continuation = self._extract_continuation(video_list_renderer)
2572                     continue
2573                 renderer = continuation_item.get('backstagePostThreadRenderer')
2574                 if renderer:
2575                     continuation_renderer = {'contents': continuation_items}
2576                     for entry in self._post_thread_continuation_entries(continuation_renderer):
2577                         yield entry
2578                     continuation = self._extract_continuation(continuation_renderer)
2579                     continue
2580                 renderer = continuation_item.get('richItemRenderer')
2581                 if renderer:
2582                     for entry in self._rich_grid_entries(continuation_items):
2583                         yield entry
2584                     continuation = self._extract_continuation({'contents': continuation_items})
2585                     continue
2586             break
2587     @staticmethod
2588     def _extract_selected_tab(tabs):
2589         for tab in tabs:
2590             renderer = dict_get(tab, ('tabRenderer', 'expandableTabRenderer')) or {}
2591             if renderer.get('selected') is True:
2592                 return renderer
2593         else:
2594             raise ExtractorError('Unable to find selected tab')
2595     @staticmethod
2596     def _extract_uploader(data):
2597         uploader = {}
2598         sidebar_renderer = try_get(
2599             data, lambda x: x['sidebar']['playlistSidebarRenderer']['items'], list)
2600         if sidebar_renderer:
2601             for item in sidebar_renderer:
2602                 if not isinstance(item, dict):
2603                     continue
2604                 renderer = item.get('playlistSidebarSecondaryInfoRenderer')
2605                 if not isinstance(renderer, dict):
2606                     continue
2607                 owner = try_get(
2608                     renderer, lambda x: x['videoOwner']['videoOwnerRenderer']['title']['runs'][0], dict)
2609                 if owner:
2610                     uploader['uploader'] = owner.get('text')
2611                     uploader['uploader_id'] = try_get(
2612                         owner, lambda x: x['navigationEndpoint']['browseEndpoint']['browseId'], compat_str)
2613                     uploader['uploader_url'] = urljoin(
2614                         'https://www.youtube.com/',
2615                         try_get(owner, lambda x: x['navigationEndpoint']['browseEndpoint']['canonicalBaseUrl'], compat_str))
2616         return uploader
2617     @staticmethod
2618     def _extract_alert(data):
2619         alerts = []
2620         for alert in try_get(data, lambda x: x['alerts'], list) or []:
2621             if not isinstance(alert, dict):
2622                 continue
2623             alert_text = try_get(
2624                 alert, lambda x: x['alertRenderer']['text'], dict)
2625             if not alert_text:
2626                 continue
2627             text = try_get(
2628                 alert_text,
2629                 (lambda x: x['simpleText'], lambda x: x['runs'][0]['text']),
2630                 compat_str)
2631             if text:
2632                 alerts.append(text)
2633         return '\n'.join(alerts)
2634     def _extract_from_tabs(self, item_id, webpage, data, tabs):
2635         selected_tab = self._extract_selected_tab(tabs)
2636         renderer = try_get(
2637             data, lambda x: x['metadata']['channelMetadataRenderer'], dict)
2638         playlist_id = item_id
2639         title = description = None
2640         if renderer:
2641             channel_title = renderer.get('title') or item_id
2642             tab_title = selected_tab.get('title')
2643             title = channel_title or item_id
2644             if tab_title:
2645                 title += ' - %s' % tab_title
2646             if selected_tab.get('expandedText'):
2647                 title += ' - %s' % selected_tab['expandedText']
2648             description = renderer.get('description')
2649             playlist_id = renderer.get('externalId')
2650         else:
2651             renderer = try_get(
2652                 data, lambda x: x['metadata']['playlistMetadataRenderer'], dict)
2653             if renderer:
2654                 title = renderer.get('title')
2655             else:
2656                 renderer = try_get(
2657                     data, lambda x: x['header']['hashtagHeaderRenderer'], dict)
2658                 if renderer:
2659                     title = try_get(renderer, lambda x: x['hashtag']['simpleText'])
2660         playlist = self.playlist_result(
2661             self._entries(selected_tab, item_id, webpage),
2662             playlist_id=playlist_id, playlist_title=title,
2663             playlist_description=description)
2664         playlist.update(self._extract_uploader(data))
2665         return playlist
2666     def _extract_from_playlist(self, item_id, url, data, playlist):
2667         title = playlist.get('title') or try_get(
2668             data, lambda x: x['titleText']['simpleText'], compat_str)
2669         playlist_id = playlist.get('playlistId') or item_id
2670         playlist_url = urljoin(url, try_get(
2671             playlist, lambda x: x['endpoint']['commandMetadata']['webCommandMetadata']['url'],
2672             compat_str))
2673         if playlist_url and playlist_url != url:
2674             return self.url_result(
2675                 playlist_url, ie=YoutubeTabIE.ie_key(), video_id=playlist_id,
2676                 video_title=title)
2677         return self.playlist_result(
2678             self._playlist_entries(playlist), playlist_id=playlist_id,
2679             playlist_title=title)
2680     def _extract_identity_token(self, ytcfg, webpage):
2681         if ytcfg:
2682             token = try_get(ytcfg, lambda x: x['ID_TOKEN'], compat_str)
2683             if token:
2684                 return token
2685         return self._search_regex(
2686             r'\bID_TOKEN["\']\s*:\s*["\'](.+?)["\']', webpage,
2687             'identity token', default=None)
2688     def _real_extract(self, url):
2689         item_id = self._match_id(url)
2690         url = compat_urlparse.urlunparse(
2691             compat_urlparse.urlparse(url)._replace(netloc='www.youtube.com'))
2692         qs = parse_qs(url)
2693         video_id = qs.get('v', [None])[0]
2694         playlist_id = qs.get('list', [None])[0]
2695         if video_id and playlist_id:
2696             if self._downloader.params.get('noplaylist'):
2697                 self.to_screen('Downloading just video %s because of --no-playlist' % video_id)
2698                 return self.url_result(video_id, ie=YoutubeIE.ie_key(), video_id=video_id)
2699             self.to_screen('Downloading playlist %s - add --no-playlist to just download video %s' % (playlist_id, video_id))
2700         webpage = self._download_webpage(url, item_id)
2701         data = self._extract_yt_initial_data(item_id, webpage)
2702         tabs = try_get(
2703             data, lambda x: x['contents']['twoColumnBrowseResultsRenderer']['tabs'], list)
2704         if tabs:
2705             return self._extract_from_tabs(item_id, webpage, data, tabs)
2706         playlist = try_get(
2707             data, lambda x: x['contents']['twoColumnWatchNextResults']['playlist']['playlist'], dict)
2708         if playlist:
2709             return self._extract_from_playlist(item_id, url, data, playlist)
2710         video_id = try_get(
2711             data, lambda x: x['currentVideoEndpoint']['watchEndpoint']['videoId'],
2712             compat_str) or video_id
2713         if video_id:
2714             return self.url_result(video_id, ie=YoutubeIE.ie_key(), video_id=video_id)
2715         alert = self._extract_alert(data)
2716         if alert:
2717             raise ExtractorError(alert, expected=True)
2718         raise ExtractorError('Unable to recognize tab page')
2719 class YoutubePlaylistIE(InfoExtractor):
2720     IE_DESC = 'YouTube.com playlists'
2721     _VALID_URL = r'''(?x)(?:
2722                         (?:https?://)?
2723                         (?:\w+\.)?
2724                         (?:
2725                             (?:
2726                                 youtube(?:kids)?\.com|
2727                                 invidio\.us
2728                             )
2729                             /.*?\?.*?\blist=
2730                         )?
2731                         (?P&lt;id&gt;%(playlist_id)s)
2732                      )''' % {'playlist_id': YoutubeBaseInfoExtractor._PLAYLIST_ID_RE}
2733     IE_NAME = 'youtube:playlist'
2734     _TESTS = [{
2735         'note': 'issue #673',
2736         'url': 'PLBB231211A4F62143',
2737         'info_dict': {
2738             'title': '[OLD]Team Fortress 2 (Class-based LP)',
2739             'id': 'PLBB231211A4F62143',
2740             'uploader': 'Wickydoo',
2741             'uploader_id': 'UCKSpbfbl5kRQpTdL7kMc-1Q',
2742         },
2743         'playlist_mincount': 29,
2744     }, {
2745         'url': 'PLtPgu7CB4gbY9oDN3drwC3cMbJggS7dKl',
2746         'info_dict': {
2747             'title': 'YDL_safe_search',
2748             'id': 'PLtPgu7CB4gbY9oDN3drwC3cMbJggS7dKl',
2749         },
2750         'playlist_count': 2,
2751         'skip': 'This playlist is private',
2752     }, {
2753         'note': 'embedded',
2754         'url': 'https://www.youtube.com/embed/videoseries?list=PL6IaIsEjSbf96XFRuNccS_RuEXwNdsoEu',
2755         'playlist_count': 4,
2756         'info_dict': {
2757             'title': 'JODA15',
2758             'id': 'PL6IaIsEjSbf96XFRuNccS_RuEXwNdsoEu',
2759             'uploader': 'milan',
2760             'uploader_id': 'UCEI1-PVPcYXjB73Hfelbmaw',
2761         }
2762     }, {
2763         'url': 'http://www.youtube.com/embed/_xDOZElKyNU?list=PLsyOSbh5bs16vubvKePAQ1x3PhKavfBIl',
2764         'playlist_mincount': 982,
2765         'info_dict': {
2766             'title': '2018 Chinese New Singles (11/6 updated)',
2767             'id': 'PLsyOSbh5bs16vubvKePAQ1x3PhKavfBIl',
2768             'uploader': 'LBK',
2769             'uploader_id': 'UC21nz3_MesPLqtDqwdvnoxA',
2770         }
2771     }, {
2772         'url': 'TLGGrESM50VT6acwMjAyMjAxNw',
2773         'only_matching': True,
2774     }, {
2775         'url': 'OLAK5uy_m4xAFdmMC5rX3Ji3g93pQe3hqLZw_9LhM',
2776         'only_matching': True,
2777     }]
2778     @classmethod
2779     def suitable(cls, url):
2780         if YoutubeTabIE.suitable(url):
2781             return False
2782         from .youtube import parse_qs
2783         qs = parse_qs(url)
2784         if qs.get('v', [None])[0]:
2785             return False
2786         return super(YoutubePlaylistIE, cls).suitable(url)
2787     def _real_extract(self, url):
2788         playlist_id = self._match_id(url)
2789         qs = parse_qs(url)
2790         if not qs:
2791             qs = {'list': playlist_id}
2792         return self.url_result(
2793             update_url_query('https://www.youtube.com/playlist', qs),
2794             ie=YoutubeTabIE.ie_key(), video_id=playlist_id)
2795 class YoutubeYtBeIE(InfoExtractor):
2796     _VALID_URL = r'https?://youtu\.be/(?P&lt;id&gt;[0-9A-Za-z_-]{11})/*?.*?\blist=(?P&lt;playlist_id&gt;%(playlist_id)s)' % {'playlist_id': YoutubeBaseInfoExtractor._PLAYLIST_ID_RE}
2797     _TESTS = [{
2798         'url': 'https://youtu.be/yeWKywCrFtk?list=PL2qgrgXsNUG5ig9cat4ohreBjYLAPC0J5',
2799         'info_dict': {
2800             'id': 'yeWKywCrFtk',
2801             'ext': 'mp4',
2802             'title': 'Small Scale Baler and Braiding Rugs',
2803             'uploader': 'Backus-Page House Museum',
2804             'uploader_id': 'backuspagemuseum',
2805             'uploader_url': r're:https?://(?:www\.)?youtube\.com/user/backuspagemuseum',
2806             'upload_date': '20161008',
2807             'description': 'md5:800c0c78d5eb128500bffd4f0b4f2e8a',
2808             'categories': ['Nonprofits &amp; Activism'],
2809             'tags': list,
2810             'like_count': int,
2811             'dislike_count': int,
2812         },
2813         'params': {
2814             'noplaylist': True,
2815             'skip_download': True,
2816         },
2817     }, {
2818         'url': 'https://youtu.be/uWyaPkt-VOI?list=PL9D9FC436B881BA21',
2819         'only_matching': True,
2820     }]
2821     def _real_extract(self, url):
2822         mobj = re.match(self._VALID_URL, url)
2823         video_id = mobj.group('id')
2824         playlist_id = mobj.group('playlist_id')
2825         return self.url_result(
2826             update_url_query('https://www.youtube.com/watch', {
2827                 'v': video_id,
2828                 'list': playlist_id,
2829                 'feature': 'youtu.be',
2830             }), ie=YoutubeTabIE.ie_key(), video_id=playlist_id)
2831 class YoutubeYtUserIE(InfoExtractor):
2832     _VALID_URL = r'ytuser:(?P&lt;id&gt;.+)'
2833     _TESTS = [{
2834         'url': 'ytuser:phihag',
2835         'only_matching': True,
2836     }]
2837     def _real_extract(self, url):
2838         user_id = self._match_id(url)
2839         return self.url_result(
2840             'https://www.youtube.com/user/%s' % user_id,
2841             ie=YoutubeTabIE.ie_key(), video_id=user_id)
2842 class YoutubeFavouritesIE(YoutubeBaseInfoExtractor):
2843     IE_NAME = 'youtube:favorites'
2844     IE_DESC = 'YouTube.com favourite videos, ":ytfav" for short (requires authentication)'
2845     _VALID_URL = r'https?://(?:www\.)?youtube\.com/my_favorites|:ytfav(?:ou?rites)?'
2846     _LOGIN_REQUIRED = True
2847     _TESTS = [{
2848         'url': ':ytfav',
2849         'only_matching': True,
2850     }, {
2851         'url': ':ytfavorites',
2852         'only_matching': True,
2853     }]
2854     def _real_extract(self, url):
2855         return self.url_result(
2856             'https://www.youtube.com/playlist?list=LL',
2857             ie=YoutubeTabIE.ie_key())
2858 class YoutubeSearchIE(SearchInfoExtractor, YoutubeBaseInfoExtractor):
2859     IE_DESC = 'YouTube.com searches'
2860     IE_NAME = 'youtube:search'
2861     _SEARCH_KEY = 'ytsearch'
2862     _SEARCH_PARAMS = 'EgIQAQ%3D%3D'  # Videos only
2863     _MAX_RESULTS = float('inf')
2864     _TESTS = [{
2865         'url': 'ytsearch10:youtube-dl test video',
2866         'playlist_count': 10,
2867         'info_dict': {
2868             'id': 'youtube-dl test video',
2869             'title': 'youtube-dl test video',
2870         }
2871     }]
2872     def _get_n_results(self, query, n):
2873         entries = itertools.islice(self._search_results(query, self._SEARCH_PARAMS), 0, None if n == float('inf') else n)
2874         return self.playlist_result(entries, query, query)
2875 class YoutubeSearchDateIE(YoutubeSearchIE):
2876     IE_NAME = YoutubeSearchIE.IE_NAME + ':date'
2877     _SEARCH_KEY = 'ytsearchdate'
2878     IE_DESC = 'YouTube.com searches, newest videos first'
2879     _SEARCH_PARAMS = 'CAISAhAB'  # Videos only, sorted by date
2880     _TESTS = [{
2881         'url': 'ytsearchdate10:youtube-dl test video',
2882         'playlist_count': 10,
2883         'info_dict': {
2884             'id': 'youtube-dl test video',
2885             'title': 'youtube-dl test video',
2886         }
2887     }]
2888 class YoutubeSearchURLIE(YoutubeBaseInfoExtractor):
2889     IE_DESC = 'YouTube search URLs with sorting and filter support'
2890     IE_NAME = YoutubeSearchIE.IE_NAME + '_url'
2891     _VALID_URL = r'https?://(?:www\.)?youtube\.com/results\?(.*?&amp;)?(?:search_query|q)=(?:[^&amp;]+)(?:[&amp;]|$)'
2892     _TESTS = [{
2893         'url': 'https://www.youtube.com/results?baz=bar&amp;search_query=youtube-dl+test+video&amp;filters=video&amp;lclk=video',
2894         'playlist_mincount': 5,
2895         'info_dict': {
2896             'id': 'youtube-dl test video',
2897             'title': 'youtube-dl test video',
2898         },
2899         'params': {'playlistend': 5}
2900     }, {
2901         'url': 'https://www.youtube.com/results?q=test&amp;sp=EgQIBBgB',
2902         'only_matching': True,
2903     }]
2904     def _real_extract(self, url):
2905         qs = compat_parse_qs(compat_urllib_parse_urlparse(url).query)
2906         query = (qs.get('search_query') or qs.get('q'))[0]
2907         params = qs.get('sp', ('',))[0]
2908         return self.playlist_result(self._search_results(query, params), query, query)
2909 class YoutubeFeedsInfoExtractor(YoutubeTabIE):
2910     _LOGIN_REQUIRED = True
2911     @property
2912     def IE_NAME(self):
2913         return 'youtube:%s' % self._FEED_NAME
2914     def _real_initialize(self):
2915         self._login()
2916     def _real_extract(self, url):
2917         return self.url_result(
2918             'https://www.youtube.com/feed/%s' % self._FEED_NAME,
2919             ie=YoutubeTabIE.ie_key())
2920 class YoutubeWatchLaterIE(InfoExtractor):
2921     IE_NAME = 'youtube:watchlater'
2922     IE_DESC = 'Youtube watch later list, ":ytwatchlater" for short (requires authentication)'
2923     _VALID_URL = r':ytwatchlater'
2924     _TESTS = [{
2925         'url': ':ytwatchlater',
2926         'only_matching': True,
2927     }]
2928     def _real_extract(self, url):
2929         return self.url_result(
2930             'https://www.youtube.com/playlist?list=WL', ie=YoutubeTabIE.ie_key())
2931 class YoutubeRecommendedIE(YoutubeFeedsInfoExtractor):
2932     IE_DESC = 'YouTube.com recommended videos, ":ytrec" for short (requires authentication)'
2933     _VALID_URL = r':ytrec(?:ommended)?'
2934     _FEED_NAME = 'recommended'
2935     _TESTS = [{
2936         'url': ':ytrec',
2937         'only_matching': True,
2938     }, {
2939         'url': ':ytrecommended',
2940         'only_matching': True,
2941     }]
2942 class YoutubeSubscriptionsIE(YoutubeFeedsInfoExtractor):
2943     IE_DESC = 'YouTube.com subscriptions feed, "ytsubs" keyword (requires authentication)'
2944     _VALID_URL = r':ytsubs(?:criptions)?'
2945     _FEED_NAME = 'subscriptions'
2946     _TESTS = [{
2947         'url': ':ytsubs',
2948         'only_matching': True,
2949     }, {
2950         'url': ':ytsubscriptions',
2951         'only_matching': True,
2952     }]
2953 class YoutubeHistoryIE(YoutubeFeedsInfoExtractor):
2954     IE_DESC = 'Youtube watch history, ":ythistory" for short (requires authentication)'
2955     _VALID_URL = r':ythistory'
2956     _FEED_NAME = 'history'
2957     _TESTS = [{
2958         'url': ':ythistory',
2959         'only_matching': True,
2960     }]
2961 class YoutubeTruncatedURLIE(InfoExtractor):
2962     IE_NAME = 'youtube:truncated_url'
2963     IE_DESC = False  # Do not list
2964     _VALID_URL = r'''(?x)
2965         (?:https?://)?
2966         (?:\w+\.)?[yY][oO][uU][tT][uU][bB][eE](?:-nocookie)?\.com/
2967         (?:watch\?(?:
2968             feature=[a-z_]+|
2969             annotation_id=annotation_[^&amp;]+|
2970             x-yt-cl=[0-9]+|
2971             hl=[^&amp;]*|
2972             t=[0-9]+
2973         )?
2974         |
2975             attribution_link\?a=[^&amp;]+
2976         )
2977         $
2978     '''
2979     _TESTS = [{
2980         'url': 'https://www.youtube.com/watch?annotation_id=annotation_3951667041',
2981         'only_matching': True,
2982     }, {
2983         'url': 'https://www.youtube.com/watch?',
2984         'only_matching': True,
2985     }, {
2986         'url': 'https://www.youtube.com/watch?x-yt-cl=84503534',
2987         'only_matching': True,
2988     }, {
2989         'url': 'https://www.youtube.com/watch?feature=foo',
2990         'only_matching': True,
2991     }, {
2992         'url': 'https://www.youtube.com/watch?hl=en-GB',
2993         'only_matching': True,
2994     }, {
2995         'url': 'https://www.youtube.com/watch?t=2372',
2996         'only_matching': True,
2997     }]
2998     def _real_extract(self, url):
2999         raise ExtractorError(
3000             'Did you forget to quote the URL? Remember that &amp; is a meta '
3001             'character in most shells, so you want to put the URL in quotes, '
3002             'like  youtube-dl '
3003             '"https://www.youtube.com/watch?feature=foo&amp;v=BaW_jenozKc" '
3004             ' or simply  youtube-dl BaW_jenozKc  .',
3005             expected=True)
3006 class YoutubeTruncatedIDIE(InfoExtractor):
3007     IE_NAME = 'youtube:truncated_id'
3008     IE_DESC = False  # Do not list
3009     _VALID_URL = r'https?://(?:www\.)?youtube\.com/watch\?v=(?P&lt;id&gt;[0-9A-Za-z_-]{1,10})$'
3010     _TESTS = [{
3011         'url': 'https://www.youtube.com/watch?v=N_708QY7Ob',
3012         'only_matching': True,
3013     }]
3014     def _real_extract(self, url):
3015         video_id = self._match_id(url)
3016         raise ExtractorError(
3017             'Incomplete YouTube ID %s. URL %s looks truncated.' % (video_id, url),
3018             expected=True)
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
