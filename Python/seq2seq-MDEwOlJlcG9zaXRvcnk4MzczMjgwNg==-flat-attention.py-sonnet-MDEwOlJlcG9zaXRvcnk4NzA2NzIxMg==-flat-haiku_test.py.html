
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 5.405405405405405%, Tokens: 10, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-attention.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import abc
6  import six
7  import tensorflow as tf
8  from tensorflow.python.framework import function  # pylint: disable=E0611
9  from seq2seq.graph_module import GraphModule
10  from seq2seq.configurable import Configurable
11  @function.Defun(
12      tf.float32,
13      tf.float32,
14      tf.float32,
15      func_name="att_sum_bahdanau",
16      noinline=True)
17  def att_sum_bahdanau(v_att, keys, query):
18    return tf.reduce_sum(v_att * tf.tanh(keys + tf.expand_dims(query, 1)), [2])
19  @function.Defun(tf.float32, tf.float32, func_name="att_sum_dot", noinline=True)
20  def att_sum_dot(keys, query):
21    return tf.reduce_sum(keys * tf.expand_dims(query, 1), [2])
22  @six.add_metaclass(abc.ABCMeta)
23  class AttentionLayer(GraphModule, Configurable):
24    def __init__(self, params, mode, name="attention"):
25      GraphModule.__init__(self, name)
26      Configurable.__init__(self, params, mode)
27    @staticmethod
28    def default_params():
29      return {"num_units": 128}
30    @abc.abstractmethod
31    def score_fn(self, keys, query):
32      raise NotImplementedError
33    def _build(self, query, keys, values, values_length):
34      values_depth = values.get_shape().as_list()[-1]
35      att_keys = tf.contrib.layers.fully_connected(
36          inputs=keys,
37          num_outputs=self.params["num_units"],
38          activation_fn=None,
39          scope="att_keys")
40      att_query = tf.contrib.layers.fully_connected(
41          inputs=query,
42          num_outputs=self.params["num_units"],
43          activation_fn=None,
44          scope="att_query")
<span onclick='openModal()' class='match'>45      scores = self.score_fn(att_keys, att_query)
46      num_scores = tf.shape(scores)[1]
47      scores_mask = tf.sequence_mask(
</span>48          lengths=tf.to_int32(values_length),
49          maxlen=tf.to_int32(num_scores),
50          dtype=tf.float32)
51      scores = scores * scores_mask + ((1.0 - scores_mask) * tf.float32.min)
52      scores_normalized = tf.nn.softmax(scores, name="scores_normalized")
53      context = tf.expand_dims(scores_normalized, 2) * values
54      context = tf.reduce_sum(context, 1, name="context")
55      context.set_shape([None, values_depth])
56      return (scores_normalized, context)
57  class AttentionLayerDot(AttentionLayer):
58    def score_fn(self, keys, query):
59      return att_sum_dot(keys, query)
60  class AttentionLayerBahdanau(AttentionLayer):
61    def score_fn(self, keys, query):
62      v_att = tf.get_variable(
63          "v_att", shape=[self.params["num_units"]], dtype=tf.float32)
64      return att_sum_bahdanau(v_att, keys, query)
</code></pre>
        </div>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-haiku_test.py</h3>
            <pre><code>1  from absl.testing import parameterized
2  import sonnet as snt
3  from sonnet.src import test_utils
4  from sonnet.src.functional import haiku as hk
5  import tensorflow as tf
6  import tree
7  class TensorVariableTest(test_utils.TestCase, parameterized.TestCase):
8    def test_initial_value(self):
9      with hk.variables():
10        v = tf.Variable(tf.ones([]))
11      self.assertIsInstance(v, hk.TensorVariable)
12      self.assertAllEqual(v, 1)
13      self.assertAllEqual(v.read_value(), 1)
14      self.assertAllEqual(v.tensor_value, 1)
15    @parameterized.parameters(None, True, False)
16    def test_trainable(self, trainable):
17      with hk.variables():
18        v = tf.Variable(1., trainable=trainable)
19      if trainable is None:
20        self.assertTrue(v.trainable)
21      else:
22        self.assertEqual(v.trainable, trainable)
23    def test_name(self):
24      with hk.variables():
25        v = tf.Variable(tf.ones([]), name="v")
26      self.assertEqual(v.name, "v:0")
27    def test_name_with_scope(self):
28      with hk.variables(), tf.name_scope("foo"), tf.name_scope("bar"):
29        v = tf.Variable(tf.ones([]), name="v")
30      self.assertEqual(v.name, "foo/bar/v:0")
31    @parameterized.parameters(([],), ([1, 2, 3],))
32    def test_shape(self, shape):
33      with hk.variables():
34        v = tf.Variable(tf.ones(shape))
35      self.assertEqual(shape, v.shape.as_list())
36    @parameterized.parameters(tf.float32, tf.int32)
37    def test_dtype(self, dtype):
38      with hk.variables():
39        v = tf.Variable(tf.ones([], dtype=dtype))
40      self.assertEqual(dtype, v.dtype)
41    def test_attributes_do_not_notify(self):
42      with hk.variables():
43        v = tf.Variable(1.)
44        s = tf.Variable(1., trainable=False)
45      def f():
46        for c in (v, s):
47          self.assertIsNotNone(c.shape)
48          self.assertIsNotNone(c.dtype)
49          self.assertIsNotNone(c.trainable)
50          self.assertIsNotNone(c.name)
51          self.assertIsNotNone(c.device)
52      f = hk.transform_with_state(f)
53      params, state = f.init()
54      self.assertEmpty(params)
55      self.assertEmpty(state)
56      out, state = f.apply(params, state)
57      self.assertIsNone(out)
58      self.assertEmpty(state)
59    def test_read_captured_variables_included(self):
60      with hk.variables():
61        v = tf.Variable(1.)
62        s = tf.Variable(1., trainable=False)
63      f = hk.transform_with_state(lambda: (v.read_value() + s.read_value()))
64      params, state = f.init()
65      self.assertEqual(params, {v.ref(): v.tensor_value})
66      self.assertEqual(state, {s.ref(): s.tensor_value})
67    def test_captured_variable_from_other_function_raises(self):
68      def f(model):
69        if not model:
70          model.append(tf.Variable(1.))
71          model.append(tf.Variable(1., trainable=False))
72        return sum(model)
73      f = hk.transform_with_state(f)
74      model = []
75      params, state = f.init(model)
76      self.assertLen(params, 1)
77      self.assertLen(state, 1)
78      with self.assertRaisesRegex(ValueError, "TensorVariable .* has no value"):
79        f.init(model)
80    def test_assign(self):
81      with hk.variables():
82        v = tf.Variable(tf.ones([]))
83      v.assign(tf.zeros([]))
84      self.assertAllEqual(v.numpy(), 0)
85      self.assertAllEqual(v.read_value().numpy(), 0)
86      self.assertAllEqual(v.tensor_value.numpy(), 0)
87    def test_assign_add(self):
88      with hk.variables():
89        v = tf.Variable(tf.ones([]))
90      v.assign_add(1.)
91      self.assertAllEqual(v.numpy(), 2)
92      self.assertAllEqual(v.read_value().numpy(), 2)
93      self.assertAllEqual(v.tensor_value.numpy(), 2)
94    def test_assign_sub(self):
95      with hk.variables():
96        v = tf.Variable(tf.ones([]))
97      v.assign_sub(1.)
98      self.assertAllEqual(v.numpy(), 0)
99      self.assertAllEqual(v.read_value().numpy(), 0)
100      self.assertAllEqual(v.tensor_value.numpy(), 0)
101  class NetworkTest(test_utils.TestCase, parameterized.TestCase):
102    def test_transform(self):
103      mod = snt.Linear(1, w_init=tf.ones)
104      snt.allow_empty_variables(mod)
105      self.assertEmpty(mod.variables)
<span onclick='openModal()' class='match'>106      f = hk.transform(mod)
107      x = tf.ones([1, 1])
108      params = f.init(x)
</span>109      self.assertLen(params.items(), 2)
110      self.assertAllEqual(params[mod.w.ref()], [[1.]])
111      self.assertAllEqual(params[mod.b.ref()], [0.])
112      y = f.apply(params, x)
113      self.assertEqual(y, [[1.]])
114      params = tree.map_structure(lambda p: p + 1, params)
115      y = f.apply(params, x)
116      self.assertEqual(y, [[3.]])
117    def test_initial_values_preserved(self):
118      with hk.variables():
119        v = tf.Variable(0)
120        v.assign(1)
121      def assert_values():
122        self.assertEqual(v.initial_tensor_value.numpy(), 0)
123        self.assertEqual(v.tensor_value.numpy(), 1)
124      assert_values()
125      f = hk.transform(lambda: v.assign(2))
126      assert_values()
127      params = f.init()
128      assert_values()
129      f.apply(params)
130      assert_values()
131    def test_variables_in_transform_set_to_none(self):
132      mod = snt.Bias()
133      f = hk.transform(mod)
134      params = f.init(tf.ones([1, 1]))  # Will create `mod.b`.
135      self.assertIsNone(mod.b.tensor_value)
136      self.assertIsNone(mod.b.initial_tensor_value)
137      y = f.apply(params, tf.ones([1, 1]))
138      self.assertAllEqual(y.numpy(), [[1.]])
139      self.assertIsNone(mod.b.tensor_value)
140      self.assertIsNone(mod.b.initial_tensor_value)
141    def test_disallows_variables_in_apply(self):
142      _, apply_fn = hk.transform(lambda: tf.Variable(1))
143      with self.assertRaisesRegex(ValueError,
144                                  "Apply function cannot create new variables"):
145        apply_fn({})
146    def test_state_returns_initial_value(self):
147      with hk.variables():
148        v = tf.Variable(0, trainable=False)
149      f = hk.transform_with_state(lambda: v.assign(1))
150      params, state = f.init()
151      initial_v = state[v.ref()]
152      self.assertEqual(initial_v.numpy(), 0)
153      y, state = f.apply(params, state)
154      final_v = state[v.ref()]
155      self.assertEqual(y.numpy(), 1)
156      self.assertEqual(final_v.numpy(), 1)
157    def test_state_counter(self):
158      with hk.variables():
159        v = tf.Variable(0, trainable=False)
160      f = hk.transform_with_state(lambda: v.assign_add(1))
161      params, initial_state = f.init()
162      for _ in range(2):
163        state = initial_state
164        for i in range(10):
165          y, state = f.apply(params, state)
166          self.assertEqual(y.numpy(), i + 1)
167    def test_state_ema(self):
168      with hk.variables():
169        ema = snt.ExponentialMovingAverage(decay=0.5)
170      ema = hk.transform_with_state(ema)
171      params, state = ema.init(3.0)
172      y, state = ema.apply(params, state, 3.0)
173      self.assertAllClose(y.numpy(), 3.0)
174      y, state = ema.apply(params, state, 6.0)
175      self.assertAllClose(y.numpy(), 5.0)
176  if __name__ == "__main__":
177    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-attention.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-haiku_test.py</div>
                </div>
                <div class="column column_space"><pre><code>45      scores = self.score_fn(att_keys, att_query)
46      num_scores = tf.shape(scores)[1]
47      scores_mask = tf.sequence_mask(
</pre></code></div>
                <div class="column column_space"><pre><code>106      f = hk.transform(mod)
107      x = tf.ones([1, 1])
108      params = f.init(x)
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    