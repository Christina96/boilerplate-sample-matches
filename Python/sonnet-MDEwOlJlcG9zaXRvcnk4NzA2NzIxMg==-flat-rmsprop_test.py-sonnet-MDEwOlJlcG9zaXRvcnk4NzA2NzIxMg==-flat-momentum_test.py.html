
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 44, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-rmsprop_test.py</h3>
            <pre><code>1  from sonnet.src import test_utils
2  from sonnet.src.optimizers import optimizer_tests
3  from sonnet.src.optimizers import rmsprop
4  import tensorflow as tf
5  CONFIGS = optimizer_tests.named_product(learning_rate=(0.01, 0.001),
6                                          decay=(0.8, 0.9),
7                                          momentum=(0.0, 0.5),
8                                          epsilon=(1e-7, 1e-8),
9                                          centered=(False, True),
10                                          seed=(28, 2, 90))
11  class ComparisonTest(optimizer_tests.AbstractFuzzTest):
12    def _make_tf(self, learning_rate, decay, momentum, epsilon, centered):
13      optimizer = tf.optimizers.RMSprop(learning_rate=learning_rate,
14                                        rho=decay,
15                                        momentum=momentum,
16                                        epsilon=epsilon,
17                                        centered=centered)
18      return lambda g, p: optimizer.apply_gradients(zip(g, p))
19    def _make_snt(self, learning_rate, decay, momentum, epsilon, centered):
20      optimizer = rmsprop.RMSProp(learning_rate=learning_rate,
21                                  decay=decay,
22                                  momentum=momentum,
23                                  epsilon=epsilon,
24                                  centered=centered)
25      return optimizer.apply
26    @test_utils.combined_named_parameters(CONFIGS)
27    def testComparingSonnetAndTensorFlow(self, config):
28      seed = config.pop("seed")
29      self.assertParametersRemainClose(seed, config, atol=1e-2)
30  class RMSPropTest(optimizer_tests.OptimizerTestBase):
31    def make_optimizer(self, **kwargs):
32      if "learning_rate" not in kwargs:
33        kwargs["learning_rate"] = 0.1
34      return rmsprop.RMSProp(**kwargs)
35    def testDense(self):
36      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
37      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
38      optimizer = self.make_optimizer(learning_rate=0.1)
39      optimizer.apply(updates, parameters)
40      self.assertAllClose([[0.683772, 1.683772], [2.683772, 3.683772]],
41                          [x.numpy() for x in parameters])
42      optimizer.apply(updates, parameters)
43      self.assertAllClose([[0.454357, 1.454357], [2.454357, 3.454357]],
44                          [x.numpy() for x in parameters])
45      optimizer.apply(updates, parameters)
46      self.assertAllClose([[0.262262, 1.262262], [2.262262, 3.262262]],
47                          [x.numpy() for x in parameters])
48    def testDenseCentered(self):
49      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
50      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
51      optimizer = self.make_optimizer(learning_rate=0.1, centered=True)
52      optimizer.apply(updates, parameters)
53      self.assertAllClose([[0.666667, 1.666667], [2.666667, 3.666667]],
54                          [x.numpy() for x in parameters])
55      optimizer.apply(updates, parameters)
56      self.assertAllClose([[0.41176, 1.41176], [2.41176, 3.41176]],
57                          [x.numpy() for x in parameters])
58      optimizer.apply(updates, parameters)
59      self.assertAllClose([[0.186776, 1.186776], [2.186776, 3.186776]],
60                          [x.numpy() for x in parameters])
61    def testSparse(self):
62      if self.primary_device in ("GPU", "TPU"):
63        self.skipTest("IndexedSlices not supported on {}.".format(
64            self.primary_device))
65      parameters = [tf.Variable([[1.], [2.]]), tf.Variable([[3.], [4.]])]
<span onclick='openModal()' class='match'>66      updates = [
67          tf.IndexedSlices(
68              tf.constant([0.1], shape=[1, 1]), tf.constant([0]),
69              tf.constant([2, 1])),
</span>70          tf.IndexedSlices(
71              tf.constant([0.01], shape=[1, 1]), tf.constant([1]),
72              tf.constant([2, 1]))
73      ]
74      optimizer = self.make_optimizer(learning_rate=3.)
75      optimizer.apply(updates, parameters)
76      self.assertAllClose([[-8.486831], [2.0]], parameters[0].numpy(), rtol=1e-4)
77      self.assertAllClose([[3.0], [-5.486784]], parameters[1].numpy(), rtol=1e-4)
78      optimizer.apply(updates, parameters)
79      self.assertAllClose([[-15.369301], [2.0]], parameters[0].numpy(), rtol=1e-4)
80      self.assertAllClose([[3.0], [-12.369237]], parameters[1].numpy(), rtol=1e-4)
81      optimizer.apply(updates, parameters)
82      self.assertAllClose([[-21.132141], [2.0]], parameters[0].numpy(), rtol=1e-4)
83      self.assertAllClose([[3.0], [-18.132067]], parameters[1].numpy(), rtol=1e-4)
84    def testSparseCentered(self):
85      if self.primary_device in ("GPU", "TPU"):
86        self.skipTest("IndexedSlices not supported on {}.".format(
87            self.primary_device))
88      parameters = [tf.Variable([[1.], [2.]]), tf.Variable([[3.], [4.]])]
89      updates = [
90          tf.IndexedSlices(
91              tf.constant([0.1], shape=[1, 1]), tf.constant([0]),
92              tf.constant([2, 1])),
93          tf.IndexedSlices(
94              tf.constant([0.01], shape=[1, 1]), tf.constant([1]),
95              tf.constant([2, 1]))
96      ]
97      optimizer = self.make_optimizer(learning_rate=3., centered=True)
98      optimizer.apply(updates, parameters)
99      self.assertAllClose([[-8.999999], [2.0]], parameters[0].numpy(), rtol=1e-4)
100      self.assertAllClose([[3.0], [-5.999944]], parameters[1].numpy(), rtol=1e-4)
101      optimizer.apply(updates, parameters)
102      self.assertAllClose([[-16.64719], [2.0]], parameters[0].numpy(), rtol=1e-4)
103      self.assertAllClose([[3.0], [-13.647109]], parameters[1].numpy(), rtol=1e-4)
104      optimizer.apply(updates, parameters)
105      self.assertAllClose([[-23.396709], [2.0]], parameters[0].numpy(), rtol=1e-4)
106      self.assertAllClose([[3.0], [-20.39661]], parameters[1].numpy(), rtol=1e-4)
107    def testVariableHyperParams(self):
108      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
109      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
110      learning_rate = tf.Variable(0.1)
111      optimizer = self.make_optimizer(learning_rate=learning_rate)
112      optimizer.apply(updates, parameters)
113      self.assertAllClose([[0.683772, 1.683772], [2.683772, 3.683772]],
114                          [x.numpy() for x in parameters])
115      learning_rate.assign(0.01)
116      self.assertAlmostEqual(0.01, optimizer.learning_rate.numpy())
117      optimizer.apply(updates, parameters)
118      self.assertAllClose([[0.660831, 1.660831], [2.660831, 3.660831]],
119                          [x.numpy() for x in parameters])
120    def testHyperParamDTypeConversion(self):
121      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
122      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
123      dtype = tf.float32 if self.primary_device == "TPU" else tf.float64
124      learning_rate = tf.Variable(0.1, dtype=dtype)
125      decay = tf.Variable(0.9, dtype=dtype)
126      momentum = tf.Variable(0.0, dtype=dtype)
127      epsilon = tf.Variable(1e-7, dtype=dtype)
128      optimizer = self.make_optimizer(
129          learning_rate=learning_rate,
130          decay=decay,
131          momentum=momentum,
132          epsilon=epsilon)
133      if optimizer_tests.is_tf_optimizer(optimizer):
134        self.skipTest("TF optimizers don't support automatic casting.")
135      optimizer.apply(updates, parameters)
136      self.assertAllClose([[0.683772, 1.683772], [2.683772, 3.683772]],
137                          [x.numpy() for x in parameters])
138    def testAuxVariablesColocatedWithOriginal(self):
139      optimizer = self.make_optimizer(learning_rate=0.1)
140      if optimizer_tests.is_tf_optimizer(optimizer):
141        self.skipTest("Aux vars are in a different location for TF optimizers.")
142      with tf.device("CPU:0"):
143        var = tf.Variable(1.0)
144      optimizer.apply([tf.constant(0.1)], [var])
145      self.assertEqual(optimizer.mom[0].device, var.device)
146      self.assertEqual(optimizer.ms[0].device, var.device)
147  class ReferenceRMSPropTest(RMSPropTest):
148    def make_optimizer(self, **kwargs):
149      if "learning_rate" not in kwargs:
150        kwargs["learning_rate"] = 0.1
151      kwargs["rho"] = kwargs.pop("decay", 0.9)
152      if hasattr(tf.keras.optimizers, "legacy"):
153        return optimizer_tests.WrappedTFOptimizer(
154            tf.keras.optimizers.legacy.RMSprop(**kwargs))
155      return optimizer_tests.WrappedTFOptimizer(
156          tf.keras.optimizers.RMSprop(**kwargs))
157  if __name__ == "__main__":
158    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-momentum_test.py</h3>
            <pre><code>1  from sonnet.src import test_utils
2  from sonnet.src.optimizers import momentum as momentum_lib
3  from sonnet.src.optimizers import optimizer_tests
4  import tensorflow as tf
5  CONFIGS = optimizer_tests.named_product(learning_rate=(0.1, 0.01, 0.001),
6                                          momentum=(0.9, 0.5, 0.2),
7                                          use_nesterov=(True, False),
8                                          seed=(28, 2, 90))
9  class ComparisonTest(optimizer_tests.AbstractFuzzTest):
10    def _make_tf(self, learning_rate, momentum, use_nesterov):
11      optimizer = tf.optimizers.SGD(learning_rate=learning_rate,
12                                    momentum=momentum,
13                                    nesterov=use_nesterov)
14      return lambda g, p: optimizer.apply_gradients(zip(g, p))
15    def _make_snt(self, learning_rate, momentum, use_nesterov):
16      optimizer = momentum_lib.Momentum(learning_rate=learning_rate,
17                                        momentum=momentum,
18                                        use_nesterov=use_nesterov)
19      return optimizer.apply
20    @test_utils.combined_named_parameters(CONFIGS)
21    def testComparingSonnetAndTensorFlow(self, config):
22      seed = config.pop("seed")
23      self.assertParametersRemainClose(seed, config)
24  class MomentumTest(optimizer_tests.OptimizerTestBase):
25    def make_optimizer(self, **kwargs):
26      if "learning_rate" not in kwargs:
27        kwargs["learning_rate"] = 0.1
28      if "momentum" not in kwargs:
29        kwargs["momentum"] = 0.9
30      return momentum_lib.Momentum(**kwargs)
31    def testDense(self):
32      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
33      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
34      optimizer = self.make_optimizer(learning_rate=0.1, momentum=0.9)
35      optimizer.apply(updates, parameters)
36      self.assertAllClose([[0.5, 1.5], [2.7, 3.7]],
37                          [x.numpy() for x in parameters])
38      optimizer.apply(updates, parameters)
39      self.assertAllClose([[-0.45, 0.55], [2.13, 3.13]],
40                          [x.numpy() for x in parameters])
41      optimizer.apply(updates, parameters)
42      self.assertAllClose([[-1.805, -0.805], [1.317, 2.317]],
43                          [x.numpy() for x in parameters])
44    def testDenseNesterov(self):
45      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
46      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
47      optimizer = self.make_optimizer(
48          learning_rate=0.1, momentum=0.9, use_nesterov=True)
49      optimizer.apply(updates, parameters)
50      self.assertAllClose([[0.05, 1.05], [2.43, 3.43]],
51                          [x.numpy() for x in parameters])
52      optimizer.apply(updates, parameters)
53      self.assertAllClose([[-1.305, -0.305], [1.617, 2.617]],
54                          [x.numpy() for x in parameters])
55      optimizer.apply(updates, parameters)
56      self.assertAllClose([[-3.0245, -2.0245], [0.5853, 1.5853]],
57                          [x.numpy() for x in parameters])
58    def testSparse(self):
59      if self.primary_device in ("GPU", "TPU"):
60        self.skipTest("IndexedSlices not supported on {}.".format(
61            self.primary_device))
62      parameters = [tf.Variable([[1.], [2.]]), tf.Variable([[3.], [4.]])]
63      updates = [
64          tf.IndexedSlices(
65              tf.constant([0.1], shape=[1, 1]), tf.constant([0]),
66              tf.constant([2, 1])),
67          tf.IndexedSlices(
68              tf.constant([0.01], shape=[1, 1]), tf.constant([1]),
69              tf.constant([2, 1]))
70      ]
71      optimizer = self.make_optimizer(learning_rate=3., momentum=0.9)
72      optimizer.apply(updates, parameters)
73      self.assertAllClose([[1.0 - 3.0 * 0.1], [2.0]], parameters[0].numpy())
74      self.assertAllClose([[3.0], [4.0 - 3.0 * 0.01]], parameters[1].numpy())
75      optimizer.apply(updates, parameters)
76      self.assertAllClose([[0.7 - 3.0 * 0.19], [2.0]], parameters[0].numpy())
77      self.assertAllClose([[3.0], [3.97 - 3.0 * 0.019]], parameters[1].numpy())
78      optimizer.apply(updates, parameters)
79      self.assertAllClose([[0.13 - 3.0 * 0.271], [2.0]], parameters[0].numpy())
80      self.assertAllClose([[3.0], [3.913 - 3.0 * 0.0271]], parameters[1].numpy())
81    def testSparseNesterov(self):
82      if self.primary_device in ("GPU", "TPU"):
83        self.skipTest("IndexedSlices not supported on {}.".format(
84            self.primary_device))
85      parameters = [tf.Variable([[1.], [2.]]), tf.Variable([[3.], [4.]])]
<span onclick='openModal()' class='match'>86      updates = [
87          tf.IndexedSlices(
88              tf.constant([0.1], shape=[1, 1]), tf.constant([0]),
89              tf.constant([2, 1])),
</span>90          tf.IndexedSlices(
91              tf.constant([0.01], shape=[1, 1]), tf.constant([1]),
92              tf.constant([2, 1]))
93      ]
94      optimizer = self.make_optimizer(
95          learning_rate=3., momentum=0.9, use_nesterov=True)
96      optimizer.apply(updates, parameters)
97      self.assertAllClose([[0.43], [2.0]], parameters[0].numpy())
98      self.assertAllClose([[3.0], [3.943]], parameters[1].numpy())
99      optimizer.apply(updates, parameters)
100      self.assertAllClose([[-0.383], [2.0]], parameters[0].numpy())
101      self.assertAllClose([[3.0], [3.8617]], parameters[1].numpy())
102      optimizer.apply(updates, parameters)
103      self.assertAllClose([[-1.4147], [2.0]], parameters[0].numpy())
104      self.assertAllClose([[3.0], [3.75853]], parameters[1].numpy())
105    def testVariableHyperParams(self):
106      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
107      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
108      learning_rate = tf.Variable(0.1)
109      momentum_coeff = tf.Variable(0.9)
110      optimizer = self.make_optimizer(
111          learning_rate=learning_rate, momentum=momentum_coeff)
112      if optimizer_tests.is_tf_optimizer(optimizer):
113        self.skipTest("TF SGD optimizer doesn't support variable learning rate.")
114      optimizer.apply(updates, parameters)
115      self.assertAllClose([[0.5, 1.5], [2.7, 3.7]],
116                          [x.numpy() for x in parameters])
117      learning_rate.assign(0.01)
118      momentum_coeff.assign(0.09)
119      self.assertAlmostEqual(0.01, optimizer.learning_rate.numpy())
120      self.assertAlmostEqual(0.09, optimizer.momentum.numpy())
121      optimizer.apply(updates, parameters)
122      self.assertAllClose([[0.4455, 1.4455], [2.6673, 3.6673]],
123                          [x.numpy() for x in parameters])
124    def testHyperParamDTypeConversion(self):
125      parameters = [tf.Variable([1., 2.]), tf.Variable([3., 4.])]
126      updates = [tf.constant([5., 5.]), tf.constant([3., 3.])]
127      dtype = tf.float32 if self.primary_device == "TPU" else tf.float64
128      learning_rate = tf.Variable(0.1, dtype=dtype)
129      momentum_coeff = tf.Variable(0.9, dtype=dtype)
130      optimizer = self.make_optimizer(
131          learning_rate=learning_rate, momentum=momentum_coeff)
132      optimizer.apply(updates, parameters)
133      self.assertAllClose([[0.5, 1.5], [2.7, 3.7]],
134                          [x.numpy() for x in parameters])
135    def testAuxVariablesColocatedWithOriginal(self):
136      optimizer = self.make_optimizer(learning_rate=0.1, momentum=0.9)
137      if optimizer_tests.is_tf_optimizer(optimizer):
138        self.skipTest("TF slot variables are in a different location.")
139      with tf.device("CPU:0"):
140        var = tf.Variable(1.0)
141      optimizer.apply([tf.constant(0.1)], [var])
142      self.assertEqual(optimizer.accumulated_momentum[0].device, var.device)
143  class ReferenceMomentumTest(MomentumTest):
144    def make_optimizer(self, **kwargs):
145      if "learning_rate" not in kwargs:
146        kwargs["learning_rate"] = 0.1
147      if "momentum" not in kwargs:
148        kwargs["momentum"] = 0.9
149      if "use_nesterov" in kwargs:
150        kwargs["nesterov"] = kwargs["use_nesterov"]
151        del kwargs["use_nesterov"]
152      if hasattr(tf.keras.optimizers, "legacy"):
153        return optimizer_tests.WrappedTFOptimizer(
154            tf.keras.optimizers.legacy.SGD(**kwargs))
155      return optimizer_tests.WrappedTFOptimizer(tf.keras.optimizers.SGD(**kwargs))
156  if __name__ == "__main__":
157    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-rmsprop_test.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-momentum_test.py</div>
                </div>
                <div class="column column_space"><pre><code>66      updates = [
67          tf.IndexedSlices(
68              tf.constant([0.1], shape=[1, 1]), tf.constant([0]),
69              tf.constant([2, 1])),
</pre></code></div>
                <div class="column column_space"><pre><code>86      updates = [
87          tf.IndexedSlices(
88              tf.constant([0.1], shape=[1, 1]), tf.constant([0]),
89              tf.constant([2, 1])),
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    