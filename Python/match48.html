<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for test_algorithm.py &amp; test_quarters_estimates.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for test_algorithm.py &amp; test_quarters_estimates.py
      </h3>
<h1 align="center">
        12.3%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>test_algorithm.py (10.85359%)<th>test_quarters_estimates.py (14.4%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(2095-2131)<td><a href="#" name="0">(2608-2621)</a><td align="center"><font color="#ff0000">26</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(15-40)<td><a href="#" name="1">(1-49)</a><td align="center"><font color="#e10000">23</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(2275-2296)<td><a href="#" name="2">(2646-2658)</a><td align="center"><font color="#d70000">22</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(1159-1174)<td><a href="#" name="3">(1900-1908)</a><td align="center"><font color="#cd0000">21</font>
<tr onclick='openModal("#6cc417")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#6cc417"><font color="#6cc417">-</font><td><a href="#" name="4">(803-807)<td><a href="#" name="4">(1241-1251)</a><td align="center"><font color="#ba0000">19</font>
<tr onclick='openModal("#151b8d")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#151b8d"><font color="#151b8d">-</font><td><a href="#" name="5">(2160-2169)<td><a href="#" name="5">(1787-1793)</a><td align="center"><font color="#b00000">18</font>
<tr onclick='openModal("#8c8774")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#8c8774"><font color="#8c8774">-</font><td><a href="#" name="6">(1384-1402)<td><a href="#" name="6">(1867-1873)</a><td align="center"><font color="#b00000">18</font>
<tr onclick='openModal("#38a4a5")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#38a4a5"><font color="#38a4a5">-</font><td><a href="#" name="7">(205-219)<td><a href="#" name="7">(1049-1054)</a><td align="center"><font color="#b00000">18</font>
<tr onclick='openModal("#c58917")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#c58917"><font color="#c58917">-</font><td><a href="#" name="8">(1324-1329)<td><a href="#" name="8">(1729-1735)</a><td align="center"><font color="#a60000">17</font>
<tr onclick='openModal("#83a33a")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#83a33a"><font color="#83a33a">-</font><td><a href="#" name="9">(1174-1179)<td><a href="#" name="9">(2213-2218)</a><td align="center"><font color="#a60000">17</font>
<tr onclick='openModal("#ad5910")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#ad5910"><font color="#ad5910">-</font><td><a href="#" name="10">(778-791)<td><a href="#" name="10">(1668-1674)</a><td align="center"><font color="#a60000">17</font>
<tr onclick='openModal("#b041ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#b041ff"><font color="#b041ff">-</font><td><a href="#" name="11">(2325-2332)<td><a href="#" name="11">(1799-1804)</a><td align="center"><font color="#9c0000">16</font>
<tr onclick='openModal("#571b7e")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#571b7e"><font color="#571b7e">-</font><td><a href="#" name="12">(1522-1531)<td><a href="#" name="12">(1880-1886)</a><td align="center"><font color="#9c0000">16</font>
<tr onclick='openModal("#3b9c9c")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#3b9c9c"><font color="#3b9c9c">-</font><td><a href="#" name="13">(1213-1218)<td><a href="#" name="13">(1346-1352)</a><td align="center"><font color="#9c0000">16</font>
<tr onclick='openModal("#842dce")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#842dce"><font color="#842dce">-</font><td><a href="#" name="14">(2190-2195)<td><a href="#" name="14">(1909-1913)</a><td align="center"><font color="#930000">15</font>
<tr onclick='openModal("#f52887")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f52887"><font color="#f52887">-</font><td><a href="#" name="15">(634-638)<td><a href="#" name="15">(1810-1815)</a><td align="center"><font color="#930000">15</font>
<tr onclick='openModal("#2981b2")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#2981b2"><font color="#2981b2">-</font><td><a href="#" name="16">(4174-4186)<td><a href="#" name="16">(1466-1478)</a><td align="center"><font color="#890000">14</font>
<tr onclick='openModal("#3090c7")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#3090c7"><font color="#3090c7">-</font><td><a href="#" name="17">(3172-3180)<td><a href="#" name="17">(744-750)</a><td align="center"><font color="#890000">14</font>
<tr onclick='openModal("#800517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#800517"><font color="#800517">-</font><td><a href="#" name="18">(1143-1147)<td><a href="#" name="18">(1776-1781)</a><td align="center"><font color="#890000">14</font>
<tr onclick='openModal("#f62817")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f62817"><font color="#f62817">-</font><td><a href="#" name="19">(935-953)<td><a href="#" name="19">(1975-1978)</a><td align="center"><font color="#890000">14</font>
<tr onclick='openModal("#4e9258")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#4e9258"><font color="#4e9258">-</font><td><a href="#" name="20">(718-721)<td><a href="#" name="20">(969-975)</a><td align="center"><font color="#890000">14</font>
<tr onclick='openModal("#947010")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#947010"><font color="#947010">-</font><td><a href="#" name="21">(3602-3607)<td><a href="#" name="21">(1204-1210)</a><td align="center"><font color="#7f0000">13</font>
<tr onclick='openModal("#4cc417")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#4cc417"><font color="#4cc417">-</font><td><a href="#" name="22">(2555-2562)<td><a href="#" name="22">(2491-2498)</a><td align="center"><font color="#7f0000">13</font>
<tr onclick='openModal("#f660ab")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f660ab"><font color="#f660ab">-</font><td><a href="#" name="23">(2513-2517)<td><a href="#" name="23">(2530-2536)</a><td align="center"><font color="#7f0000">13</font>
<tr onclick='openModal("#79764d")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#79764d"><font color="#79764d">-</font><td><a href="#" name="24">(2495-2499)<td><a href="#" name="24">(2477-2483)</a><td align="center"><font color="#7f0000">13</font>
<tr onclick='openModal("#5eac10")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#5eac10"><font color="#5eac10">-</font><td><a href="#" name="25">(1557-1588)<td><a href="#" name="25">(250-252)</a><td align="center"><font color="#7f0000">13</font>
<tr onclick='openModal("#68818b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#68818b"><font color="#68818b">-</font><td><a href="#" name="26">(1209-1213)<td><a href="#" name="26">(609-615)</a><td align="center"><font color="#7f0000">13</font>
<tr onclick='openModal("#e77471")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#e77471"><font color="#e77471">-</font><td><a href="#" name="27">(686-691)<td><a href="#" name="27">(925-930)</a><td align="center"><font color="#7f0000">13</font>
<tr onclick='openModal("#717d7d")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#717d7d"><font color="#717d7d">-</font><td><a href="#" name="28">(164-168)<td><a href="#" name="28">(1625-1629)</a><td align="center"><font color="#7f0000">13</font>
<tr onclick='openModal("#af7a82")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#af7a82"><font color="#af7a82">-</font><td><a href="#" name="29">(4282-4296)<td><a href="#" name="29">(1194-1197)</a><td align="center"><font color="#750000">12</font>
<tr onclick='openModal("#ae694a")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#ae694a"><font color="#ae694a">-</font><td><a href="#" name="30">(4149-4157)<td><a href="#" name="30">(2427-2430)</a><td align="center"><font color="#750000">12</font>
<tr onclick='openModal("#3ea99f")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#3ea99f"><font color="#3ea99f">-</font><td><a href="#" name="31">(3037-3046)<td><a href="#" name="31">(100-107)</a><td align="center"><font color="#750000">12</font>
<tr onclick='openModal("#5b8daf")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#5b8daf"><font color="#5b8daf">-</font><td><a href="#" name="32">(2773-2775)<td><a href="#" name="32">(1424-1437)</a><td align="center"><font color="#750000">12</font>
<tr onclick='openModal("#736aff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#736aff"><font color="#736aff">-</font><td><a href="#" name="33">(2435-2438)<td><a href="#" name="33">(775-781)</a><td align="center"><font color="#750000">12</font>
<tr onclick='openModal("#827d6b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#827d6b"><font color="#827d6b">-</font><td><a href="#" name="34">(2360-2364)<td><a href="#" name="34">(1586-1589)</a><td align="center"><font color="#750000">12</font>
<tr onclick='openModal("#41a317")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#41a317"><font color="#41a317">-</font><td><a href="#" name="35">(1403-1420)<td><a href="#" name="35">(1575-1579)</a><td align="center"><font color="#750000">12</font>
<tr onclick='openModal("#ff00ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#ff00ff"><font color="#ff00ff">-</font><td><a href="#" name="36">(1329-1333)<td><a href="#" name="36">(2231-2232)</a><td align="center"><font color="#750000">12</font>
<tr onclick='openModal("#810541")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#810541"><font color="#810541">-</font><td><a href="#" name="37">(1220-1221)<td><a href="#" name="37">(2139-2142)</a><td align="center"><font color="#750000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_algorithm.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 <font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>import warnings
2 import datetime
3 from datetime import timedelta
4 from functools import partial
5 from textwrap import dedent
6 from copy import deepcopy
7 import logbook
8 import toolz
9 from logbook import TestHandler, WARNING
10 from nose_parameterized import parameterized
11 from six import iteritems, itervalues, string_types
12 from six.moves import range
13 from testfixtures import TempDirectory
14 import numpy as np
15 import pandas as pd
16 import pytz
17 from pandas.core.common import PerformanceWarning
18 from trading_calendars import get_calendar, register_calendar
19 import zipline.api
20 from zipline.api import FixedSlippage
21 from zipline.assets import Equity, Future, Asset
22 from zipline.assets.continuous_futures import ContinuousFuture
23 from</b></font> zipline.assets.synthetic import (
24     make_jagged_equity_info,
25     make_simple_equity_info,
26 )
27 from zipline.errors import (
28     AccountControlViolation,
29     CannotOrderDelistedAsset,
30     IncompatibleSlippageModel,
31     RegisterTradingControlPostInit,
32     ScheduleFunctionInvalidCalendar,
33     SetCancelPolicyPostInit,
34     SymbolNotFound,
35     TradingControlViolation,
36     UnsupportedCancelPolicy,
37     UnsupportedDatetimeFormat,
38     ZeroCapitalError
39 )
40 from zipline.finance.commission import PerShare, PerTrade
41 from zipline.finance.execution import LimitOrder
42 from zipline.finance.order import ORDER_STATUS
43 from zipline.finance.trading import SimulationParameters
44 from zipline.finance.asset_restrictions import (
45     Restriction,
46     HistoricalRestrictions,
47     StaticRestrictions,
48     RESTRICTION_STATES,
49 )
50 from zipline.finance.controls import AssetDateBounds
51 from zipline.testing import (
52     FakeDataPortal,
53     create_daily_df_for_asset,
54     create_data_portal_from_trade_history,
55     create_minute_df_for_asset,
56     make_test_handler,
57     make_trade_data_for_asset_info,
58     parameter_space,
59     str_to_seconds,
60     to_utc,
61 )
62 from zipline.testing import RecordBatchBlotter
63 import zipline.testing.fixtures as zf
64 from zipline.test_algorithms import (
65     access_account_in_init,
66     access_portfolio_in_init,
67     api_algo,
68     api_get_environment_algo,
69     api_symbol_algo,
70     handle_data_api,
71     handle_data_noop,
72     initialize_api,
73     initialize_noop,
74     noop_algo,
75     record_float_magic,
76     record_variables,
77     call_with_kwargs,
78     call_without_kwargs,
79     call_with_bad_kwargs_current,
80     call_with_bad_kwargs_history,
81     bad_type_history_assets,
82     bad_type_history_fields,
83     bad_type_history_bar_count,
84     bad_type_history_frequency,
85     bad_type_history_assets_kwarg_list,
86     bad_type_current_assets,
87     bad_type_current_fields,
88     bad_type_can_trade_assets,
89     bad_type_is_stale_assets,
90     bad_type_history_assets_kwarg,
91     bad_type_history_fields_kwarg,
92     bad_type_history_bar_count_kwarg,
93     bad_type_history_frequency_kwarg,
94     bad_type_current_assets_kwarg,
95     bad_type_current_fields_kwarg,
96     call_with_bad_kwargs_get_open_orders,
97     call_with_good_kwargs_get_open_orders,
98     call_with_no_kwargs_get_open_orders,
99     empty_positions,
100     no_handle_data,
101 )
102 from zipline.testing.predicates import assert_equal
103 from zipline.utils.api_support import ZiplineAPI
104 from zipline.utils.context_tricks import CallbackManager, nop_context
105 from zipline.utils.events import (
106     date_rules,
107     time_rules,
108     Always,
109     ComposedRule,
110     Never,
111     OncePerDay,
112 )
113 import zipline.utils.factory as factory
114 _multiprocess_can_split_ = False
115 class TestRecord(zf.WithMakeAlgo, zf.ZiplineTestCase):
116     ASSET_FINDER_EQUITY_SIDS = (133,)
117     SIM_PARAMS_DATA_FREQUENCY = 'daily'
118     DATA_PORTAL_USE_MINUTE_DATA = False
119     def test_record_incr(self):
120         def initialize(self):
121             self.incr = 0
122         def handle_data(self, data):
123             self.incr += 1
124             self.record(incr=self.incr)
125             name = 'name'
126             self.record(name, self.incr)
127             zipline.api.record(name, self.incr, 'name2', 2, name3=self.incr)
128         output = self.run_algorithm(
129             initialize=initialize,
130             handle_data=handle_data,
131         )
132 <a name="28"></a>        np.testing.assert_array_equal(output['incr'].values,
133                                       range(1, len(output) + 1))
134         np.testing.assert_array_equal(output['name'].values,
135                                       range(1, len<font color="#717d7d"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(output) + 1))
136         np.testing.assert_array_equal(output['name2'].values,
137                                       [2] * len(output))
138         np.testing.assert_array_equal(output['name3'].values,
139                                       range(</b></font>1, len(output) + 1))
140 class TestMiscellaneousAPI(zf.WithMakeAlgo, zf.ZiplineTestCase):
141     START_DATE = pd.Timestamp('2006-01-03', tz='UTC')
142     END_DATE = pd.Timestamp('2006-01-04', tz='UTC')
143     SIM_PARAMS_DATA_FREQUENCY = 'minute'
144     sids = 1, 2
145     BENCHMARK_SID = None
146     @classmethod
147     def make_equity_info(cls):
148         return pd.concat((
149             make_simple_equity_info(cls.sids, '2002-02-1', '2007-01-01'),
150             pd.DataFrame.from_dict(
151                 {3: {'symbol': 'PLAY',
152                      'start_date': '2002-01-01',
153                      'end_date': '2004-01-01',
154                      'exchange': 'TEST'},
155                  4: {'symbol': 'PLAY',
156                      'start_date': '2005-01-01',
157                      'end_date': '2006-01-01',
158                      'exchange': 'TEST'}},
159                 orient='index',
160             ),
161         ))
162     @classmethod
163     def make_futures_info(cls):
164         return pd.DataFrame.from_dict(
165             {
166 <a name="7"></a>                5: {
167                     'symbol': 'CLG06',
168                     'root_symbol': 'CL',
169                     'start_date': pd.Timestamp('2005-12-01', tz<font color="#38a4a5"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>='UTC'),
170                     'notice_date': pd.Timestamp('2005-12-20', tz='UTC'),
171                     'expiration_date': pd.Timestamp('2006-01-20', tz='UTC'),
172                     'exchange': 'TEST'
173                 },
174                 6: {
175                     'root_symbol': 'CL',
176                     'symbol': 'CLK06',
177                     'start_date': pd.Timestamp('2005-12-01', tz='UTC'),
178                     'notice_date': pd.Timestamp('2006-03-20', tz='UTC'),
179                     'expiration_date': pd.Timestamp('2006-04-20', tz='UTC'),
180                     'exchange': 'TEST',
181                 },
182                 7: {
183                     'symbol'</b></font>: 'CLQ06',
184                     'root_symbol': 'CL',
185                     'start_date': pd.Timestamp('2005-12-01', tz='UTC'),
186                     'notice_date': pd.Timestamp('2006-06-20', tz='UTC'),
187                     'expiration_date': pd.Timestamp('2006-07-20', tz='UTC'),
188                     'exchange': 'TEST',
189                 },
190                 8: {
191                     'symbol': 'CLX06',
192                     'root_symbol': 'CL',
193                     'start_date': pd.Timestamp('2006-02-01', tz='UTC'),
194                     'notice_date': pd.Timestamp('2006-09-20', tz='UTC'),
195                     'expiration_date': pd.Timestamp('2006-10-20', tz='UTC'),
196                     'exchange': 'TEST',
197                 }
198             },
199             orient='index',
200         )
201     def test_cancel_policy_outside_init(self):
202         code = """
203 from zipline.api import cancel_policy, set_cancel_policy
204 def initialize(algo):
205     pass
206 def handle_data(algo, data):
207     set_cancel_policy(cancel_policy.NeverCancel())
208         algo = self.make_algo(script=code)
209         with self.assertRaises(UnsupportedCancelPolicy):
210             algo.run()
211     def test_zipline_api_resolves_dynamically(self):
212         algo = self.make_algo(
213             initialize=lambda context: None,
214             handle_data=lambda context, data: None,
215         )
216         for method in algo.all_api_methods():
217             name = method.__name__
218             sentinel = object()
219             def fake_method(*args, **kwargs):
220                 return sentinel
221             setattr(algo, name, fake_method)
222             with ZiplineAPI(algo):
223                 self.assertIs(sentinel, getattr(zipline.api, name)())
224     def test_sid_datetime(self):
225         algo_text = """
226 from zipline.api import sid, get_datetime
227 def initialize(context):
228     pass
229 def handle_data(context, data):
230     aapl_dt = data.current(sid(1), "last_traded")
231     assert_equal(aapl_dt, get_datetime())
232         algo = self.make_algo(script=algo_text)
233         with self.assertRaises(TypeError):
234             algo.run()
235     @parameterized.expand([
236         (-1000, 'invalid_base'),
237         (0, 'invalid_base'),
238     ])
239     def test_invalid_capital_base(self, cap_base, name):
240         algo_text = """
241 def initialize(context):
242     pass
243 def handle_data(context, data):
244     order(sid(24), 1000)
245         algo = self.make_algo(
246             script=algotext,
247             sim_params=self.make_simparams(
248                 trading_calendar=get_calendar("CMES"),
249             )
250         )
251         algo.run()
252         nyse = get_calendar("NYSE")
253         for minute in algo.nyse_opens:
254             session_label = nyse.minute_to_session_label(minute)
255             session_open = nyse.session_open(session_label)
256             self.assertEqual(session_open, minute)
257         for minute in algo.nyse_closes:
258             session_label = nyse.minute_to_session_label(minute)
259             session_close = nyse.session_close(session_label)
260             self.assertEqual(session_close - timedelta(minutes=1), minute)
261         erroring_algotext = dedent(
262         )
263         algo = self.make_algo(
264             script=erroring_algotext,
265             sim_params=self.make_simparams(
266                 trading_calendar=get_calendar("CMES"),
267             ),
268         )
269         with self.assertRaises(ScheduleFunctionInvalidCalendar):
270             algo.run()
271     def test_schedule_function(self):
272         us_eastern = pytz.timezone('US/Eastern')
273         def incrementer(algo, data):
274             algo.func_called += 1
275             curdt = algo.get_datetime().tz_convert(pytz.utc)
276             self.assertEqual(
277                 curdt,
278                 us_eastern.localize(
279                     datetime.datetime.combine(
280                         curdt.date(),
281                         datetime.time(9, 31)
282                     ),
283                 ),
284             )
285         def initialize(algo):
286             algo.func_called = 0
287             algo.days = 1
288             algo.date = None
289             algo.schedule_function(
290                 func=incrementer,
291                 date_rule=date_rules.every_day(),
292                 time_rule=time_rules.market_open(),
293             )
294         def handle_data(algo, data):
295             if not algo.date:
296                 algo.date = algo.get_datetime().date()
297             if algo.date &lt; algo.get_datetime().date():
298                 algo.days += 1
299                 algo.date = algo.get_datetime().date()
300         algo = self.make_algo(
301             initialize=initialize,
302             handle_data=handle_data,
303         )
304         algo.run()
305         self.assertEqual(algo.func_called, algo.days)
306     def test_event_context(self):
307         expected_data = []
308         collected_data_pre = []
309         collected_data_post = []
310         function_stack = []
311         def pre(data):
312             function_stack.append(pre)
313             collected_data_pre.append(data)
314         def post(data):
315             function_stack.append(post)
316             collected_data_post.append(data)
317         def initialize(context):
318             context.add_event(Always(), f)
319             context.add_event(Always(), g)
320         def handle_data(context, data):
321             function_stack.append(handle_data)
322             expected_data.append(data)
323         def f(context, data):
324             function_stack.append(f)
325         def g(context, data):
326             function_stack.append(g)
327         algo = self.make_algo(
328             initialize=initialize,
329             handle_data=handle_data,
330             create_event_context=CallbackManager(pre, post),
331         )
332         algo.run()
333         self.assertEqual(len(expected_data), 780)
334         self.assertEqual(collected_data_pre, expected_data)
335         self.assertEqual(collected_data_post, expected_data)
336         self.assertEqual(
337             len(function_stack),
338             3900,
339             'Incorrect number of functions called: %s != 3900' %
340             len(function_stack),
341         )
342         expected_functions = [pre, handle_data, f, g, post] * 97530
343         for n, (f, g) in enumerate(zip(function_stack, expected_functions)):
344             self.assertEqual(
345                 f,
346                 g,
347                 'function at position %d was incorrect, expected %s but got %s'
348                 % (n, g.__name__, f.__name__),
349             )
350     @parameterized.expand([
351         ('daily',),
352         ('minute'),
353     ])
354     def test_schedule_function_rule_creation(self, mode):
355         def nop(*args, **kwargs):
356             return None
357         self.sim_params.data_frequency = mode
358         algo = self.make_algo(
359             initialize=nop,
360             handle_data=nop,
361             sim_params=self.sim_params,
362         )
363         algo.schedule_function(nop, time_rule=Never() &amp; Always())
364         event_rule = algo.event_manager._events[1].rule
365         self.assertIsInstance(event_rule, OncePerDay)
366         self.assertEqual(event_rule.cal, algo.trading_calendar)
367         inner_rule = event_rule.rule
368         self.assertIsInstance(inner_rule, ComposedRule)
369         self.assertEqual(inner_rule.cal, algo.trading_calendar)
370         first = inner_rule.first
371         second = inner_rule.second
372         composer = inner_rule.composer
373         self.assertIsInstance(first, Always)
374         self.assertEqual(first.cal, algo.trading_calendar)
375         self.assertEqual(second.cal, algo.trading_calendar)
376         if mode == 'daily':
377 <a name="15"></a>            self.assertIsInstance(second, Always)
378         else:
379             self.assertIsInstance(second, ComposedRule)
380             self<font color="#f52887"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.assertIsInstance(second.first, Never)
381             self.assertEqual(second.first.cal, algo.trading_calendar)
382             self.assertIsInstance(second.second, Always)
383             self.assertEqual(second.second.</b></font>cal, algo.trading_calendar)
384         self.assertIs(composer, ComposedRule.lazy_and)
385     def test_asset_lookup(self):
386         algo = self.make_algo()
387         start_session = pd.Timestamp("2000-01-01", tz="UTC")
388         algo.sim_params = algo.sim_params.create_new(
389             start_session,
390             pd.Timestamp('2001-12-01', tz='UTC')
391         )
392         with self.assertRaises(SymbolNotFound):
393             algo.symbol('PLAY')
394         with self.assertRaises(SymbolNotFound):
395             algo.symbols('PLAY')
396         algo.sim_params = algo.sim_params.create_new(
397             start_session,
398             pd.Timestamp('2002-12-01', tz='UTC')
399         )
400         list_result = algo.symbols('PLAY')
401         self.assertEqual(3, list_result[0])
402         algo.sim_params = algo.sim_params.create_new(
403             start_session,
404             pd.Timestamp('2004-12-01', tz='UTC')
405         )
406         self.assertEqual(3, algo.symbol('PLAY'))
407         algo.sim_params = algo.sim_params.create_new(
408             start_session,
409             pd.Timestamp('2005-12-01', tz='UTC')
410         )
411         self.assertEqual(4, algo.symbol('PLAY'))
412         algo.sim_params = algo.sim_params.create_new(
413             start_session,
414 <a name="27"></a>            pd.Timestamp('2006-12-01', tz='UTC')
415         )
416         self.assertEqual(4, algo.symbol('PLAY'))
417         list_result = algo<font color="#e77471"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.symbols('PLAY')
418         self.assertEqual(4, list_result[0])
419         self.assertIsInstance(algo.sid(3), Equity)
420         self.assertIsInstance(algo.sid(</b></font>4), Equity)
421         with self.assertRaises(TypeError):
422             algo.symbol(1)
423         with self.assertRaises(TypeError):
424             algo.symbol((1,))
425         with self.assertRaises(TypeError):
426             algo.symbol({1})
427         with self.assertRaises(TypeError):
428             algo.symbol([1])
429         with self.assertRaises(TypeError):
430             algo.symbol({'foo': 'bar'})
431     def test_future_symbol(self):
432         algo = self.make_algo()
433         algo.datetime = pd.Timestamp('2006-12-01', tz='UTC')
434 <a name="20"></a>
435         cl = algo.future_symbol('CLG06')
436         self<font color="#4e9258"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.assertEqual(cl.sid, 5)
437         self.assertEqual(cl.symbol, 'CLG06')
438         self.assertEqual(cl.root_symbol, 'CL')
439         self.assertEqual(cl.start_date, pd.Timestamp(</b></font>'2005-12-01', tz='UTC'))
440         self.assertEqual(cl.notice_date, pd.Timestamp('2005-12-20', tz='UTC'))
441         self.assertEqual(cl.expiration_date,
442                          pd.Timestamp('2006-01-20', tz='UTC'))
443         with self.assertRaises(SymbolNotFound):
444             algo.future_symbol('')
445         with self.assertRaises(SymbolNotFound):
446             algo.future_symbol('PLAY')
447         with self.assertRaises(SymbolNotFound):
448             algo.future_symbol('FOOBAR')
449         with self.assertRaises(TypeError):
450             algo.future_symbol(1)
451         with self.assertRaises(TypeError):
452             algo.future_symbol((1,))
453         with self.assertRaises(TypeError):
454             algo.future_symbol({1})
455         with self.assertRaises(TypeError):
456             algo.future_symbol([1])
457         with self.assertRaises(TypeError):
458             algo.future_symbol({'foo': 'bar'})
459 class TestSetSymbolLookupDate(zf.WithMakeAlgo, zf.ZiplineTestCase):
460     START_DATE = pd.Timestamp('2006-01-03', tz='UTC')
461     END_DATE = pd.Timestamp('2006-01-06', tz='UTC')
462     SIM_PARAMS_START_DATE = pd.Timestamp('2006-01-04', tz='UTC')
463     SIM_PARAMS_DATA_FREQUENCY = 'daily'
464     DATA_PORTAL_USE_MINUTE_DATA = False
465     BENCHMARK_SID = 3
466     @classmethod
467     def make_equity_info(cls):
468         dates = pd.date_range(cls.START_DATE, cls.END_DATE)
469         assert len(dates) == 4, "Expected four dates."
470 <a name="10"></a>        cls.sids = [1, 2, 3]
471         cls.asset_starts = [dates[0], dates[2]]
472         cls.asset_ends = [dates[1], dates[3]]
473         return pd<font color="#ad5910"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.DataFrame.from_records([
474             {'symbol': 'DUP',
475              'start_date': cls.asset_starts[0],
476              'end_date': cls.asset_ends[0],
477              'exchange': 'TEST',
478              'asset_name': 'FIRST'},
479             {'symbol': 'DUP',
480              'start_date': cls.asset_starts[1],
481              'end_date': cls.asset_ends[1],
482              'exchange': 'TEST',
483              'asset_name': 'SECOND'},
484             {'symbol': 'BENCH',
485              'start_date': cls.START_DATE,
486              'end_date': cls.</b></font>END_DATE,
487              'exchange': 'TEST',
488              'asset_name': 'BENCHMARK'},
489         ], index=cls.sids)
490     def test_set_symbol_lookup_date(self):
491 <a name="4"></a>        set_symbol_lookup_date = zipline.api.set_symbol_lookup_date
492         def initialize(context):
493             set_symbol_lookup_date(self<font color="#6cc417"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.asset_ends[0])
494             self.assertEqual(zipline.api.symbol('DUP').sid, self.sids[0])
495             set_symbol_lookup_date(self.asset_ends[1])
496             self.assertEqual(zipline.api.symbol('DUP').</b></font>sid, self.sids[1])
497             with self.assertRaises(UnsupportedDatetimeFormat):
498                 set_symbol_lookup_date('foobar')
499         self.run_algorithm(initialize=initialize)
500 class TestPositions(zf.WithMakeAlgo, zf.ZiplineTestCase):
501     START_DATE = pd.Timestamp('2006-01-03', tz='utc')
502     END_DATE = pd.Timestamp('2006-01-06', tz='utc')
503     SIM_PARAMS_CAPITAL_BASE = 1000
504     ASSET_FINDER_EQUITY_SIDS = (1, 133)
505     SIM_PARAMS_DATA_FREQUENCY = 'daily'
506     @classmethod
507     def make_equity_daily_bar_data(cls, country_code, sids):
508         frame = pd.DataFrame(
509             {
510                 'open': [90, 95, 100, 105],
511                 'high': [90, 95, 100, 105],
512                 'low': [90, 95, 100, 105],
513                 'close': [90, 95, 100, 105],
514                 'volume': 100,
515             },
516             index=cls.equity_daily_bar_days,
517         )
518         return ((sid, frame) for sid in sids)
519     @classmethod
520     def make_futures_info(cls):
521         return pd.DataFrame.from_dict(
522             {
523                 1000: {
524                     'symbol': 'CLF06',
525                     'root_symbol': 'CL',
526                     'start_date': cls.START_DATE,
527                     'end_date': cls.END_DATE,
528                     'auto_close_date': cls.END_DATE + cls.trading_calendar.day,
529                     'exchange': 'CMES',
530                     'multiplier': 100,
531                 },
532             },
533             orient='index',
534         )
535     @classmethod
536     def make_future_minute_bar_data(cls):
537         trading_calendar = cls.trading_calendars[Future]
538         sids = cls.asset_finder.futures_sids
539         minutes = trading_calendar.minutes_for_sessions_in_range(
540             cls.future_minute_bar_days[0],
541             cls.future_minute_bar_days[-1],
542         )
543         frame = pd.DataFrame(
544             {
545                 'open': 2.0,
546                 'high': 2.0,
547                 'low': 2.0,
548                 'close': 2.0,
549                 'volume': 100,
550             },
551             index=minutes,
552         )
553         return ((sid, frame) for sid in sids)
554     def test_portfolio_exited_position(self):
555         def initialize(context, sids):
556             context.ordered = False
557             context.exited = False
558             context.sids = sids
559         def handle_data(context, data):
560             if not context.ordered:
561                 for s in context.sids:
562                     context.order(context.sid(s), 1)
563                 context.ordered = True
564             if not context.exited:
565                 amounts = [pos.amount for pos
566                            in itervalues(context.portfolio.positions)]
567                 if (
568                     len(amounts) &gt; 0 and
569                     all([(amount == 1) for amount in amounts])
570                 ):
571                     for stock in context.portfolio.positions:
572                         context.order(context.sid(stock), -1)
573                     context.exited = True
574             context.record(num_positions=len(context.portfolio.positions))
575         result = self.run_algorithm(
576             initialize=initialize,
577             handle_data=handle_data,
578             sids=self.ASSET_FINDER_EQUITY_SIDS,
579         )
580         expected_position_count = [
581             0,  # Before entering the first position
582             2,  # After entering, exiting on this date
583             0,  # After exiting
584             0,
585         ]
586         for i, expected in enumerate(expected_position_count):
587             self.assertEqual(result.ix[i]['num_positions'], expected)
588     def test_noop_orders(self):
589         asset = self.asset_finder.retrieve_asset(1)
590         def handle_data(algo, data):
591             algo.order(asset, 100, limit_price<font color="#f62817"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>=1)
592             algo.order(asset, 100, stop_price=10000000)
593             algo.order(asset, 100, limit_price=10000000, stop_price=10000000)
594             algo.order(asset, 100, limit_price=1, stop_price=1)
595             algo.order(</b></font>asset, -100, limit_price=1000000)
596             algo.order(asset, -100, stop_price=1)
597             algo.order(asset, -100, limit_price=1000000, stop_price=1000000)
598             algo.order(asset, -100, limit_price=1, stop_price=1)
599             algo.order(asset, 100, limit_price=.00000001)
600             algo.order(asset, -100, stop_price=.00000001)
601         daily_stats = self.run_algorithm(handle_data=handle_data)
602         empty_positions = daily_stats.positions.map(lambda x: len(x) == 0)
603         self.assertTrue(empty_positions.all())
604     def test_position_weights(self):
605         sids = (1, 133, 1000)
606         equity_1, equity_133, future_1000 = \
607             self.asset_finder.retrieve_all(sids)
608         def initialize(algo, sids_and_amounts, *args, **kwargs):
609             algo.ordered = False
610             algo.sids_and_amounts = sids_and_amounts
611             algo.set_commission(
612                 us_equities=PerTrade(0), us_futures=PerTrade(0),
613             )
614             algo.set_slippage(
615                 us_equities=FixedSlippage(0),
616                 us_futures=FixedSlippage(0),
617             )
618         def handle_data(algo, data):
619             if not algo.ordered:
620                 for s, amount in algo.sids_and_amounts:
621                     algo.order(algo.sid(s), amount)
622                 algo.ordered = True
623             algo.record(
624                 position_weights=algo.portfolio.current_portfolio_weights,
625             )
626         daily_stats = self.run_algorithm(
627             sids_and_amounts=zip(sids, [2, -1, 1]),
628             initialize=initialize,
629             handle_data=handle_data,
630         )
631         expected_position_weights = [
632             pd.Series({}),
633             pd.Series({
634                 equity_1: 190.0 / (190.0 - 95.0 + 905.0),
635                 equity_133: -95.0 / (190.0 - 95.0 + 905.0),
636                 future_1000: 200.0 / (190.0 - 95.0 + 905.0),
637             }),
638             pd.Series({
639                 equity_1: 200.0 / (200.0 - 100.0 + 905.0),
640                 equity_133: -100.0 / (200.0 - 100.0 + 905.0),
641                 future_1000: 200.0 / (200.0 - 100.0 + 905.0),
642             }),
643             pd.Series({
644                 equity_1: 210.0 / (210.0 - 105.0 + 905.0),
645                 equity_133: -105.0 / (210.0 - 105.0 + 905.0),
646                 future_1000: 200.0 / (210.0 - 105.0 + 905.0),
647             }),
648         ]
649         for i, expected in enumerate(expected_position_weights):
650             assert_equal(daily_stats.iloc[i]['position_weights'], expected)
651 class TestBeforeTradingStart(zf.WithMakeAlgo, zf.ZiplineTestCase):
652     START_DATE = pd.Timestamp('2016-01-06', tz='utc')
653     END_DATE = pd.Timestamp('2016-01-07', tz='utc')
654     SIM_PARAMS_CAPITAL_BASE = 10000
655     SIM_PARAMS_DATA_FREQUENCY = 'minute'
656     EQUITY_DAILY_BAR_LOOKBACK_DAYS = EQUITY_MINUTE_BAR_LOOKBACK_DAYS = 1
657     DATA_PORTAL_FIRST_TRADING_DAY = pd.Timestamp("2016-01-05", tz='UTC')
658     EQUITY_MINUTE_BAR_START_DATE = pd.Timestamp("2016-01-05", tz='UTC')
659     FUTURE_MINUTE_BAR_START_DATE = pd.Timestamp("2016-01-05", tz='UTC')
660     data_start = ASSET_FINDER_EQUITY_START_DATE = pd.Timestamp(
661         '2016-01-05',
662         tz='utc',
663     )
664     SPLIT_ASSET_SID = 3
665     ASSET_FINDER_EQUITY_SIDS = 1, 2, SPLIT_ASSET_SID
666     @classmethod
667     def make_equity_minute_bar_data(cls):
668         asset_minutes = \
669             cls.trading_calendar.minutes_in_range(
670                 cls.data_start,
671                 cls.END_DATE,
672             )
673         minutes_count = len(asset_minutes)
674         minutes_arr = np.arange(minutes_count) + 1
675         split_data = pd.DataFrame(
676             {
677                 'open': minutes_arr + 1,
678                 'high': minutes_arr + 2,
679                 'low': minutes_arr - 1,
680                 'close': minutes_arr,
681                 'volume': 100 * minutes_arr,
682             },
683             index=asset_minutes,
684         )
685         split_data.iloc[780:] = split_data.iloc[780:] / 2.0
686         for sid in (1, 8554):
687             yield sid, create_minute_df_for_asset(
688                 cls.trading_calendar,
689                 cls.data_start,
690                 cls.END_DATE,
691             )
692         yield 2, create_minute_df_for_asset(
693             cls.trading_calendar,
694             cls.data_start,
695             cls.END_DATE,
696             50,
697         )
698         yield cls.SPLIT_ASSET_SID, split_data
699     @classmethod
700     def make_splits_data(cls):
701         return pd.DataFrame.from_records([
702             {
703                 'effective_date': str_to_seconds('2016-01-07'),
704                 'ratio': 0.5,
705                 'sid': cls.SPLIT_ASSET_SID,
706             }
707         ])
708     @classmethod
709     def make_equity_daily_bar_data(cls, country_code, sids):
710         for sid in sids:
711             yield sid, create_daily_df_for_asset(
712                 cls.trading_calendar,
713                 cls.data_start,
714                 cls.END_DATE,
715             )
716     def test_data_in_bts_minute(self):
717         algo_code = dedent("""
718         from zipline.api import record, sid
719         def initialize(context):
720             context.history_values = []
721         def before_trading_start(context, data):
722             record(the_price1=data.current(sid(1), "price"))
723             record(the_high1=data.current(sid(1), "high"))
724             record(the_price2=data.current(sid(2), "price"))
725             record(the_high2=data.current(sid(2), "high"))
726             context.history_values.append(data.history(
727                 [sid(1), sid(2)],
728                 ["price", "high"],
729                 60,
730                 "1m"
731             ))
732         def handle_data(context, data):
733             pass
734         self<font color="#800517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.assertEqual(390, results.iloc[0].the_price1)
735         self.assertEqual(392, results.iloc[0].the_high1)
736         self.assertEqual(350, results.iloc[</b></font>0].the_price2)
737         self.assertTrue(np.isnan(results.iloc[0].the_high2))
738         np.testing.assert_array_equal(
739             range(331, 391), algo.history_values[0]["price"][1]
740         )
741 <a name="3"></a>
742         np.testing.assert_array_equal(
743             range(333, 393), algo.history_values[0]["high"]<font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>[1]
744         )
745         np.testing.assert_array_equal(
746             [300] * 19, algo.history_values[0]["price"][2][0:19]
747         )
748         np.testing.assert_array_equal(
749             [350] * 40, algo.history_values[0]["price"][2][20:]
750         )
751         np.testing.assert_array_equal(
752             np.</b></font>full<font color="#83a33a"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(19, np.nan), algo.history_values[0]["high"][2][0:19]
753         )
754         self.assertEqual(352, algo.history_values[0]["high"][2][19])
755         np.testing.assert_array_equal(</b></font>
756             np.full(40, np.nan), algo.history_values[0]["high"][2][20:]
757         )
758     def test_data_in_bts_daily(self):
759         algo_code = dedent("""
760         from zipline.api import record, sid
761         def initialize(context):
762             context.history_values = []
763         def before_trading_start(context, data):
764             record(the_price1=data.current(sid(1), "price"))
765             record(the_high1=data.current(sid(1), "high"))
766             record(the_price2=data.current(sid(2), "price"))
767             record(the_high2=data.current(sid(2), "high"))
768             context.history_values.append(data.history(
769                 [sid(1), sid(2)],
770                 ["price", "high"],
771                 1,
772                 "1d",
773             ))
774         def handle_data(context, data):
775             pass
776         self<font color="#68818b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.assertEqual(392, results.the_high1[0])
777 <a name="13"></a>        self.assertEqual(390, results.the_price1[0])
778         self.assertTrue(np.isnan(results.</b></font>the_high2<font color="#3b9c9c"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>[0]))
779         self.assertTrue(350, results.the_price2[0])
780 <a name="37"></a>        self.assertEqual(392, algo.history_values[0]["high"][1][0])
781         self.assertEqual(390, algo.history_values[</b></font>0]["price"][1][0])
782         self.assertEqual(352, algo<font color="#810541"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.history_values[0]["high"][2][0])
783         self.assertEqual(350, algo.history_values[0]["price"][2][</b></font>0])
784     def test_portfolio_bts(self):
785         algo_code = dedent("""
786         from zipline.api import order, sid, record
787         def initialize(context):
788             context.ordered = False
789             context.hd_portfolio = context.portfolio
790         def before_trading_start(context, data):
791             bts_portfolio = context.portfolio
792             assert (context.hd_portfolio == bts_portfolio)
793             record(pos_value=bts_portfolio.positions_value)
794         def handle_data(context, data):
795             if not context.ordered:
796                 order(sid(1), 1)
797                 context.ordered = True
798             context.hd_portfolio = context.portfolio
799         algo = self.make_algo(script=algo_code)
800         results = algo.run()
801         self.assertEqual(results.port_value.iloc[0], 10000)
802         self.assertAlmostEqual(results.port_value.iloc[1],
803                                10000 + 780 - 392 - 0,
804                                places=2)
805     def test_portfolio_bts_with_overnight_split(self):
806         algo_code = dedent("""
807         from zipline.api import order, sid, record
808         def initialize(context):
809             context.ordered = False
810             context.hd_portfolio = context.portfolio
811         def before_trading_start(context, data):
812             bts_portfolio = context.portfolio
813             for k in bts_portfolio.__dict__:
814                 if k != 'positions':
815                     assert (context.hd_portfolio.__dict__[k]
816                             == bts_portfolio.__dict__[k])
817             record(pos_value=bts_portfolio.positions_value)
818             record(pos_amount=bts_portfolio.positions[sid(3)].amount)
819             record(
820                 last_sale_price=bts_portfolio.positions[sid(3)].last_sale_price
821             )
822         def handle_data(context, data):
823             if not context.ordered:
824                 order(sid(3), 1)
825                 context.ordered = True
826             context.hd_portfolio = context.portfolio
827         self.assertEqual(results<font color="#c58917"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.pos_value.iloc[0], 0)
828         self.assertEqual(results.pos_value.iloc[1], 780)
829 <a name="36"></a>
830         self.assertEqual(results.pos_amount.iloc[0], 0)
831         self.assertEqual(results.pos_amount.</b></font>iloc<font color="#ff00ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>[1], 2)
832         self.assertEqual(results.last_sale_price.iloc[0], 0)
833         self.assertEqual(results.last_sale_price.iloc[</b></font>1], 390)
834     def test_account_bts_with_overnight_split(self):
835         algo_code = dedent("""
836         from zipline.api import order, sid, record, set_slippage, slippage
837         def initialize(context):
838             context.ordered = False
839             context.hd_account = context.account
840             set_slippage(slippage.VolumeShareSlippage())
841         def before_trading_start(context, data):
842             bts_account = context.account
843             assert (context.hd_account == bts_account)
844             record(port_value=bts_account.equity_with_loan)
845         def handle_data(context, data):
846             if not context.ordered:
847                 order(sid(1), 1)
848                 context.ordered = True
849             context.hd_account = context.account
850         <font color="#8c8774"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>('history__assets', (bad_type_history_assets,
851                              ASSET_OR_STRING_OR_CF_TYPE_NAMES,
852                              True)),
853         ('history__fields', (bad_type_history_fields,
854                              STRING_TYPE_NAMES_STRING,
855                              True)),
856         ('history__bar_count', (bad_type_history_bar_count, 'int', False)),
857         ('history__frequency', (bad_type_history_frequency,
858                                 STRING_TYPE_NAMES_STRING,
859                                 False)),
860         ('current__assets', (bad_type_current_assets,
861                              ASSET_OR_STRING_OR_CF_TYPE_NAMES,
862                              True)),
863         ('current__fields', (bad_type_current_fields,
864                              STRING_TYPE_NAMES_STRING,
865                              True)),
866 <a name="35"></a>        ('is_stale__assets', (bad_type_is_stale_assets, 'Asset', True)),
867         ('can_trade__assets', (bad_type_can_trade_assets, 'Asset', True)),
868         ('history_kwarg__assets'</b></font>,
869          (<font color="#41a317"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>bad_type_history_assets_kwarg,
870           ASSET_OR_STRING_OR_CF_TYPE_NAMES,
871           True)),
872         ('history_kwarg_bad_list__assets',
873          (bad_type_history_assets_kwarg_list,
874           ASSET_OR_STRING_OR_CF_TYPE_NAMES,
875           True)),
876         ('history_kwarg__fields',
877          (bad_type_history_fields_kwarg, STRING_TYPE_NAMES_STRING, True)),
878         ('history_kwarg__bar_count',
879          (bad_type_history_bar_count_kwarg, 'int', False)),
880         ('history_kwarg__frequency',
881          (bad_type_history_frequency_kwarg, STRING_TYPE_NAMES_STRING, False)),
882         ('current_kwarg__assets',
883          (bad_type_current_assets_kwarg,
884           ASSET_OR_STRING_OR_CF_TYPE_NAMES,
885           True)),
886         ('current_kwarg__fields'</b></font>,
887          (bad_type_current_fields_kwarg, STRING_TYPE_NAMES_STRING, True)),
888     )
889     sids = 0, 1, 3, 133
890     BENCHMARK_SID = None
891     @classmethod
892     def make_equity_info(cls):
893         register_calendar("TEST", get_calendar("NYSE"), force=True)
894         data = make_simple_equity_info(
895             cls.sids,
896             cls.START_DATE,
897             cls.END_DATE,
898         )
899         data.loc[3, 'symbol'] = 'TEST'
900         return data
901     @classmethod
902     def make_equity_daily_bar_data(cls, country_code, sids):
903         cal = cls.trading_calendars[Equity]
904         sessions = cal.sessions_in_range(cls.START_DATE, cls.END_DATE)
905         frame = pd.DataFrame({
906             'close': 10., 'high': 10.5, 'low': 9.5, 'open': 10., 'volume': 100,
907         }, index=sessions)
908         for sid in sids:
909             yield sid, frame
910     def test_noop(self):
911         self.run_algorithm(
912             initialize=initialize_noop,
913             handle_data=handle_data_noop,
914         )
915     def test_noop_string(self):
916         self.run_algorithm(script=noop_algo)
917     def test_no_handle_data(self):
918         self.run_algorithm(script=no_handle_data)
919     def test_api_calls(self):
920         self.run_algorithm(
921             initialize=initialize_api,
922             handle_data=handle_data_api,
923         )
924     def test_api_calls_string(self):
925         self.run_algorithm(script=api_algo)
926     def test_api_get_environment(self):
927         platform = 'zipline'
928         algo = self.make_algo(
929             script=api_get_environment_algo,
930             platform=platform,
931         )
932         algo.run()
933         self.assertEqual(algo.environment, platform)
934     def test_api_symbol(self):
935         self.run_algorithm(script=api_symbol_algo)
936     def test_fixed_slippage(self):
937         test_algo = self.make_algo(
938             script="""
939 from zipline.api import (slippage,
940                          commission,
941                          set_slippage,
942                          set_commission,
943                          order,
944                          record,
945                          sid)
946 def initialize(context):
947     model = slippage.FixedSlippage(spread=0.10)
948     set_slippage(model)
949     set_commission(commission.PerTrade(100.00))
950     context.count = 1
951     context.incr = 0
952 def handle_data(context, data):
953     if context.incr &lt; context.count:
954         order(sid(0), -1000)
955     record(price=data.current(sid(0), "price"))
956     context.incr += 1""",
957         )
958         results = test_algo.run()
959         all_txns = [val for sublist in results["transactions"].tolist()
960                     for val in sublist]
961         self.assertEqual(len(all_txns), 1)
962 <a name="12"></a>        txn = all_txns[0]
963         expected_spread = 0.05
964         expected_price = test_algo<font color="#571b7e"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.recorded_vars["price"] - expected_spread
965         self.assertEqual(expected_price, txn['price'])
966         self.assertEqual(9850, results.capital_used[1])
967         self.assertEqual(100, results["orders"].iloc[1][0][</b></font>"commission"])
968     @parameterized.expand(
969         [
970             ('no_minimum_commission', 0,),
971             ('default_minimum_commission', 0,),
972             ('alternate_minimum_commission', 2,),
973         ]
974     )
975     def test_volshare_slippage(self, name, minimum_commission):
976         tempdir = TempDirectory()
977         try:
978             if name == "default_minimum_commission":
979                 commission_line = "set_commission(commission.PerShare(0.02))"
980             else:
981                 commission_line = \
982                     "set_commission(commission.PerShare(0.02, " \
983                     "min_trade_cost={0}))".format(minimum_commission)
984 <a name="25"></a>            trades = factory.create_daily_trade_source(
985                 [0], self.sim_params, self.asset_finder, self.trading_calendar
986             )
987             data_portal = create_data_portal_from_trade_history<font color="#5eac10"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(
988                 self.asset_finder, self.trading_calendar, tempdir,
989                 self.sim_params, {0: trades}
990             )
991             test_algo = self.make_algo(
992                 data_portal=data_portal,
993                 script="""
994 from zipline.api import *
995 def initialize(context):
996     model = slippage.VolumeShareSlippage(
997                             volume_limit=.3,
998                             price_impact=0.05
999                        )
1000     set_slippage(model)
1001     {0}
1002     context.count = 2
1003     context.incr = 0
1004 def handle_data(context, data):
1005     if context.incr &lt; context.count:
1006         order(sid(0), 5000)
1007     record(price=data.current(sid(0), "price"))
1008     record(volume=data.current(sid(0), "volume"))
1009     record(incr=context.incr)
1010     context.incr += 1
1011             results =</b></font> test_algo.run()
1012             all_txns = [
1013                 val for sublist in results["transactions"].tolist()
1014                 for val in sublist]
1015             self.assertEqual(len(all_txns), 67)
1016             all_orders = list(toolz.concat(results['orders']))
1017             if minimum_commission == 0:
1018                 for order_ in all_orders:
1019                     self.assertAlmostEqual(
1020                         order_["filled"] * 0.02,
1021                         order_["commission"]
1022                     )
1023             else:
1024                 for order_ in all_orders:
1025                     if order_["filled"] &gt; 0:
1026                         self.assertAlmostEqual(
1027                             max(order_["filled"] * 0.02, minimum_commission),
1028                             order_["commission"]
1029                         )
1030                     else:
1031                         self.assertEqual(0, order_["commission"])
1032         finally:
1033             tempdir.cleanup()
1034     def test_incorrectly_set_futures_slippage_model(self):
1035         code = dedent(
1036         )
1037         test_algo = self.make_algo(script=code)
1038         with self.assertRaises(IncompatibleSlippageModel):
1039             test_algo.run()
1040     def test_algo_record_vars(self):
1041         test_algo = self.make_algo(script=record_variables)
1042         results = test_algo.run()
1043         for i in range(1, 252):
1044             self.assertEqual(results.iloc[i-1]["incr"], i)
1045     def test_algo_record_nan(self):
1046         test_algo = self.make_algo(script=record_float_magic % 'nan')
1047         results = test_algo.run()
1048         for i in range(1, 252):
1049             self.assertTrue(np.isnan(results.iloc[i-1]["data"]))
1050     def test_batch_market_order_matches_multiple_manual_orders(self):
1051         share_counts = pd.Series([50, 100])
1052         multi_blotter = RecordBatchBlotter()
1053         multi_test_algo = self.make_algo(
1054             script=dedent("""\
1055                 from collections import OrderedDict
1056                 from six import iteritems
1057                 from zipline.api import sid, order
1058                 def initialize(context):
1059                     context.assets = [sid(0), sid(3)]
1060                     context.placed = False
1061                 def handle_data(context, data):
1062                     if not context.placed:
1063                         it = zip(context.assets, {share_counts})
1064                         for asset, shares in it:
1065                             order(asset, shares)
1066                         context.placed = True
1067             blotter=batch_blotter,
1068         )
1069         batch_stats = batch_test_algo.run()
1070         self.assertTrue(batch_blotter.order_batch_called)
1071         for stats in (multi_stats, batch_stats):
1072             stats.orders = stats.orders.apply(
1073                 lambda orders: [toolz.dissoc(o, 'id') for o in orders]
1074             )
1075             stats.transactions = stats.transactions.apply(
1076                 lambda txns: [toolz.dissoc(txn, 'order_id') for txn in txns]
1077             )
1078         assert_equal(multi_stats, batch_stats)
1079     def test_batch_market_order_filters_null_orders(self):
1080         share_counts = [50, 0]
1081         batch_blotter = RecordBatchBlotter()
1082         batch_test_algo = self.make_algo(
1083             script=dedent("""\
1084                 import pandas as pd
1085                 from zipline.api import sid, batch_market_order
1086                 def initialize(context):
1087                     context.assets = [sid(0), sid(3)]
1088                     context.placed = False
1089                 def handle_data(context, data):
1090                     if not context.placed:
1091                         orders = batch_market_order(pd.Series(
1092                             index=context.assets, data={share_counts}
1093                         ))
1094                         assert len(orders) == 1, \
1095                             "len(orders) was %s but expected 1" % len(orders)
1096                         for o in orders:
1097                             assert o is not None, "An order is None"
1098                         context.placed = True
1099         )
1100         for order_str in ["order_value", "order_percent"]:
1101             test_algo = self.make_algo(
1102                 script="""
1103 from zipline.api import order_percent, order_value, sid
1104 def initialize(context):
1105     pass
1106 def handle_data(context, data):
1107     {0}(sid(0), 10)
1108         Test that accessing portfolio in init doesn't break.
1109         Test that accessing account in init doesn't break.
1110         Test that api methods on the data object can be called with positional
1111         arguments.
1112         Test that api methods on the data object can be called with keyword
1113         arguments.
1114         Test that api methods on the data object called with bad kwargs return
1115         a meaningful TypeError that we create, rather than an unhelpful cython
1116         error
1117             sim_params=params,
1118         )
1119     @parameterized.expand(
1120         [('bad_kwargs', call_with_bad_kwargs_get_open_orders),
1121          ('good_kwargs', call_with_good_kwargs_get_open_orders),
1122          ('no_kwargs', call_with_no_kwargs_get_open_orders)]
1123     )
1124     def test_get_open_orders_kwargs(self, name, script):
1125         algo = self.make_algo(script=script)
1126         if name == 'bad_kwargs':
1127             with self.assertRaises(TypeError) as cm:
1128                 algo.run()
1129                 self.assertEqual('Keyword argument `sid` is no longer '
1130                                  'supported for get_open_orders. Use `asset` '
1131                                  'instead.', cm.exception.args[0])
1132         else:
1133             algo.run()
1134     def test_empty_positions(self):
1135         results = self.run_algorithm(script=empty_positions)
1136         num_positions = results.num_positions
1137         amounts = results.amounts
1138         self.assertTrue(all(num_positions == 0))
1139         self.assertTrue(all(amounts == 0))
1140     def test_schedule_function_time_rule_positionally_misplaced(self):
1141         sim_params = factory.create_simulation_parameters(
1142             start=pd.Timestamp('2006-01-12', tz='UTC'),
1143             end=pd.Timestamp('2006-01-13', tz='UTC'),
1144             data_frequency='minute'
1145         )
1146         algocode = dedent("""
1147         from zipline.api import time_rules, schedule_function
1148         def do_at_open(context, data):
1149             context.done_at_open.append(context.get_datetime())
1150         def do_at_close(context, data):
1151             context.done_at_close.append(context.get_datetime())
1152         def initialize(context):
1153             context.done_at_open = []
1154             context.done_at_close = []
1155             schedule_function(do_at_open, time_rules.market_open())
1156             schedule_function(do_at_close, time_rules.market_close())
1157         def handle_data(algo, data):
1158             pass
1159         algo = self.make_algo(
1160             script=algocode,
1161             capital_changes=capital_changes,
1162             sim_params=SimulationParameters(
1163                 start_session=self.START_DATE,
1164                 end_session=self.END_DATE,
1165                 trading_calendar=self.nyse_calendar,
1166             )
1167         )
1168         gen = algo.get_generator()
1169         results = list(gen)
1170         cumulative_perf = \
1171             [r['cumulative_perf'] for r in results if 'cumulative_perf' in r]
1172         daily_perf = [r['daily_perf'] for r in results if 'daily_perf' in r]
1173         capital_change_packets = \
1174             [r['capital_change'] for r in results if 'capital_change' in r]
1175         self.assertEqual(len(capital_change_packets), 1)
1176         self.assertEqual(
1177             capital_change_packets[0],
1178             {'date': pd.Timestamp('2006-01-06', tz='UTC'),
1179              'type': 'cash',
1180              'target': 151000.0 if change_type == 'target' else None,
1181              'delta': 50000.0})
1182 <a name="0"></a>
1183         expected_daily = {}
1184         expected_capital_changes <font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>= np.array([
1185             0.0, 0.0, 0.0, 50000.0, 0.0
1186         ])
1187         expected_daily['returns'] = np.array([
1188             0.0,
1189             0.0,
1190             (100000.0 + 1000.0) / 100000.0 - 1.0,
1191             (151000.0 + 2000.0) / 151000.0 - 1.0,
1192             (153000.0 + 3000.0) / 153000.0 - 1.0,
1193         ])
1194         expected_daily['pnl'] = np.array([
1195             0.0,
1196             0.0,
1197             1000.00,  # 1000 shares * gain of 1
1198             2000.00,  # 2000 shares * gain of 1
1199             3000.00,  # 3000 shares * gain of 1
1200         ])
1201         expected_daily['capital_used'] = np.array([
1202             0.0,
1203             -11000.0,  # 1000 shares at price = 11
1204             -12000.0,  # 1000 shares at price = 12
1205             -13000.0,  # 1000 shares at price = 13
1206             -14000.0,  # 1000 shares at price = 14
1207         ])
1208         expected_daily['ending_cash'] = \
1209             np.array([100000.0] * 5) + \
1210             np.cumsum(expected_capital_changes) + \
1211             np.</b></font>cumsum(expected_daily['capital_used'])
1212         expected_daily['starting_cash'] = \
1213             expected_daily['ending_cash'] - \
1214             expected_daily['capital_used']
1215         expected_daily['starting_value'] = np.array([
1216             0.0,
1217             0.0,
1218             11000.0,  # 1000 shares at price = 11
1219             24000.0,  # 2000 shares at price = 12
1220             39000.0,  # 3000 shares at price = 13
1221         ])
1222         expected_daily['ending_value'] = \
1223             expected_daily['starting_value'] + \
1224             expected_daily['pnl'] - \
1225             expected_daily['capital_used']
1226         expected_daily['portfolio_value'] = \
1227             expected_daily['ending_value'] + \
1228             expected_daily['ending_cash']
1229         stats = [
1230             'returns', 'pnl', 'capital_used', 'starting_cash', 'ending_cash',
1231             'starting_value', 'ending_value', 'portfolio_value'
1232 <a name="5"></a>        ]
1233         expected_cumulative = {
1234             'returns': np.cumprod(expected_daily<font color="#151b8d"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>['returns'] + 1) - 1,
1235             'pnl': np.cumsum(expected_daily['pnl']),
1236             'capital_used': np.cumsum(expected_daily['capital_used']),
1237             'starting_cash':
1238                 np.repeat(expected_daily['starting_cash'][0:1], 5),
1239             'ending_cash': expected_daily['ending_cash'],
1240             'starting_value':
1241                 np.repeat(expected_daily['starting_value'][0:1], 5),
1242             'ending_value': expected_daily['ending_value'],
1243             'portfolio_value': expected_daily[</b></font>'portfolio_value'],
1244         }
1245         for stat in stats:
1246             np.testing.assert_array_almost_equal(
1247                 np.array([perf[stat] for perf in daily_perf]),
1248                 expected_daily[stat],
1249                 err_msg='daily ' + stat,
1250             )
1251             np.testing.assert_array_almost_equal(
1252                 np.array([perf[stat] for perf in cumulative_perf]),
1253                 expected_cumulative[stat],
1254                 err_msg='cumulative ' + stat,
1255             )
1256         self.assertEqual(
1257             algo.capital_change_deltas,
1258             {pd.Timestamp('2006-01-06', tz='UTC'): 50000.0}
1259 <a name="14"></a>        )
1260     @parameterized.expand([
1261         <font color="#842dce"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>('interday_target', [('2006-01-04', 2388.0)]),
1262         ('interday_delta', [('2006-01-04', 1000.0)]),
1263         ('intraday_target', [('2006-01-04 17:00', 2184.0),
1264                              ('2006-01-04 18:00', 2804.0)]),
1265         ('intraday_delta', [('2006-01-04 17:00', 500.0),
1266                             ('2006-01-04 18:00'</b></font>, 500.0)]),
1267     ])
1268     def test_capital_changes_minute_mode_daily_emission(self, change, values):
1269         change_loc, change_type = change.split('_')
1270         sim_params = SimulationParameters(
1271             start_session=pd.Timestamp('2006-01-03', tz='UTC'),
1272             end_session=pd.Timestamp('2006-01-05', tz='UTC'),
1273             data_frequency='minute',
1274             capital_base=1000.0,
1275             trading_calendar=self.nyse_calendar,
1276         )
1277         capital_changes = {
1278             pd.Timestamp(datestr, tz='UTC'): {
1279                 'type': change_type,
1280                 'value': value
1281             }
1282             for datestr, value in values
1283         }
1284         algocode = """
1285 from zipline.api import set_slippage, set_commission, slippage, commission, \
1286     schedule_function, time_rules, order, sid
1287 def initialize(context):
1288     set_slippage(slippage.FixedSlippage(spread=0))
1289     set_commission(commission.PerShare(0, 0))
1290     schedule_function(order_stuff, time_rule=time_rules.market_open())
1291 def order_stuff(context, data):
1292     order(sid(1), 1)
1293         expected_daily<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>['returns'] = np.array([
1294             (1000.0 + 489 - 101) / 1000.0 - 1.0,
1295             day2_return,
1296             (3166.0 + 390.0 + 390.0 + 388.0) / 3166.0 - 1.0,
1297         ])
1298         expected_daily['pnl'] = np.array([
1299             388.0,
1300             390.0 + 388.0,
1301             390.0 + 390.0 + 388.0,
1302         ])
1303         expected_daily['capital_used'] = np.array([
1304             -101.0, -491.0, -881.0
1305         ])
1306         expected_daily['ending_cash'] = \
1307             np.array([1000.0] * 3) + \
1308             np.cumsum(expected_capital_changes) + \
1309             np.</b></font>cumsum(expected_daily['capital_used'])
1310         expected_daily['starting_cash'] = \
1311             expected_daily['ending_cash'] - \
1312             expected_daily['capital_used']
1313         if change_loc == 'intraday':
1314             expected_daily['starting_cash'] -= expected_capital_changes
1315         expected_daily['starting_value'] = np.array([
1316             0.0, 489.0, 879.0 * 2
1317         ])
1318         expected_daily['ending_value'] = \
1319             expected_daily['starting_value'] + \
1320             expected_daily['pnl'] - \
1321             expected_daily['capital_used']
1322         expected_daily['portfolio_value'] = \
1323             expected_daily['ending_value'] + \
1324             expected_daily['ending_cash']
1325         stats = [
1326             'returns', 'pnl', 'capital_used', 'starting_cash', 'ending_cash',
1327             'starting_value', 'ending_value', 'portfolio_value'
1328 <a name="11"></a>        ]
1329         expected_cumulative = {
1330             'returns': np.cumprod(expected_daily<font color="#b041ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>['returns'] + 1) - 1,
1331             'pnl': np.cumsum(expected_daily['pnl']),
1332             'capital_used': np.cumsum(expected_daily['capital_used']),
1333             'starting_cash':
1334                 np.repeat(expected_daily['starting_cash'][0:1], 3),
1335             'ending_cash': expected_daily['ending_cash'],
1336             'starting_value':
1337                 np.repeat(expected_daily['starting_value'][</b></font>0:1], 3),
1338             'ending_value': expected_daily['ending_value'],
1339             'portfolio_value': expected_daily['portfolio_value'],
1340         }
1341         for stat in stats:
1342             np.testing.assert_array_almost_equal(
1343                 np.array([perf[stat] for perf in daily_perf]),
1344                 expected_daily[stat]
1345             )
1346             np.testing.assert_array_almost_equal(
1347                 np.array([perf[stat] for perf in cumulative_perf]),
1348                 expected_cumulative[stat]
1349             )
1350         if change_loc == 'interday':
1351             self.assertEqual(
1352                 algo.capital_change_deltas,
1353                 {pd.Timestamp('2006-01-04', tz='UTC'): 1000.0}
1354             )
1355         else:
1356             self.assertEqual(
1357                 algo.capital_change_deltas,
1358                 {pd.Timestamp('2006-01-04 17:00', tz='UTC'): 500.0,
1359                  pd.Timestamp('2006-01-04 18:00', tz='UTC'): 500.0}
1360 <a name="34"></a>            )
1361     @parameterized.expand([
1362         <font color="#827d6b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>('interday_target', [('2006-01-04', 2388.0)]),
1363         ('interday_delta', [('2006-01-04', 1000.0)]),
1364         ('intraday_target', [('2006-01-04 17:00', 2184.0),
1365                              ('2006-01-04 18:00', 2804.0)]),
1366         ('intraday_delta'</b></font>, [('2006-01-04 17:00', 500.0),
1367                             ('2006-01-04 18:00', 500.0)]),
1368     ])
1369     def test_capital_changes_minute_mode_minute_emission(self, change, values):
1370         change_loc, change_type = change.split('_')
1371         sim_params = SimulationParameters(
1372             start_session=pd.Timestamp('2006-01-03', tz='UTC'),
1373             end_session=pd.Timestamp('2006-01-05', tz='UTC'),
1374             data_frequency='minute',
1375             emission_rate='minute',
1376             capital_base=1000.0,
1377             trading_calendar=self.nyse_calendar,
1378         )
1379         capital_changes = {pd.Timestamp(val[0], tz='UTC'): {
1380             'type': change_type, 'value': val[1]} for val in values}
1381         algocode = """
1382 from zipline.api import set_slippage, set_commission, slippage, commission, \
1383     schedule_function, time_rules, order, sid
1384 def initialize(context):
1385     set_slippage(slippage.FixedSlippage(spread=0))
1386     set_commission(commission.PerShare(0, 0))
1387     schedule_function(order_stuff, time_rule=time_rules.market_open())
1388 def order_stuff(context, data):
1389     order(sid(1), 1)
1390         expected_minute<font color="#736aff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>['pnl'][:2] = 0.0
1391         expected_minute['pnl'][2:392] = 1.0
1392         expected_minute['pnl'][392:782] = 2.0
1393         expected_minute['pnl'][782:] =</b></font> 3.0
1394         for start, end in ((0, 390), (390, 780), (780, 1170)):
1395             expected_minute['pnl'][start:end] = \
1396                 np.cumsum(expected_minute['pnl'][start:end])
1397         expected_minute['capital_used'] = np.concatenate((
1398             [0.0] * 1, [-101.0] * 389,
1399             [0.0] * 1, [-491.0] * 389,
1400             [0.0] * 1, [-881.0] * 389,
1401         ))
1402         day2adj = 0.0 if change_loc == 'intraday' else 1000.0
1403         expected_minute['starting_cash'] = np.concatenate((
1404             [1000.0] * 390,
1405             [1000.0 - 101.0 + day2adj] * 390,
1406             [1000.0 - 101.0 - 491.0 + 1000] * 390
1407         ))
1408         expected_minute['ending_cash'] = \
1409             expected_minute['starting_cash'] + \
1410             expected_minute['capital_used'] + \
1411             capital_changes_after_start
1412         expected_minute['starting_value'] = np.concatenate((
1413             [0.0] * 390,
1414             [489.0] * 390,
1415             [879.0 * 2] * 390
1416         ))
1417         expected_minute['ending_value'] = \
1418             expected_minute['starting_value'] + \
1419             expected_minute['pnl'] - \
1420             expected_minute['capital_used']
1421         expected_minute['portfolio_value'] = \
1422             expected_minute['ending_value'] + \
1423             expected_minute['ending_cash']
1424         expected_minute['returns'] = \
1425             expected_minute['pnl'] / \
1426             (expected_minute['starting_value'] +
1427              expected_minute['starting_cash'])
1428         if change_loc == 'intraday':
1429             prev_subperiod_return = expected_minute['returns'][538]
1430 <a name="24"></a>
1431             cur_subperiod_pnl = \
1432                 expected_minute['pnl']<font color="#79764d"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>[539:599] - expected_minute['pnl'][538]
1433             cur_subperiod_starting_value = \
1434                 np.array([expected_minute['ending_value'][538]] * 60)
1435             cur_subperiod_starting_cash = \
1436                 np.array([expected_minute['ending_cash'][</b></font>538] + 500] * 60)
1437             cur_subperiod_returns = cur_subperiod_pnl / \
1438                 (cur_subperiod_starting_value + cur_subperiod_starting_cash)
1439             expected_minute['returns'][539:599] = \
1440                 (cur_subperiod_returns + 1.0) * \
1441                 (prev_subperiod_return + 1.0) - \
1442                 1.0
1443             prev_subperiod_return = expected_minute['returns'][598]
1444 <a name="23"></a>
1445             cur_subperiod_pnl = \
1446                 expected_minute['pnl']<font color="#f660ab"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>[599:780] - expected_minute['pnl'][598]
1447             cur_subperiod_starting_value = \
1448                 np.array([expected_minute['ending_value'][598]] * 181)
1449             cur_subperiod_starting_cash = \
1450                 np.array([expected_minute['ending_cash'][</b></font>598] + 500] * 181)
1451             cur_subperiod_returns = cur_subperiod_pnl / \
1452                 (cur_subperiod_starting_value + cur_subperiod_starting_cash)
1453             expected_minute['returns'][599:780] = \
1454                 (cur_subperiod_returns + 1.0) * \
1455                 (prev_subperiod_return + 1.0) - \
1456                 1.0
1457         expected_daily = {
1458             k: np.array([v[389], v[779], v[1169]])
1459             for k, v in iteritems(expected_minute)
1460         }
1461         stats = [
1462             'pnl', 'capital_used', 'starting_cash', 'ending_cash',
1463             'starting_value', 'ending_value', 'portfolio_value', 'returns'
1464         ]
1465         expected_cumulative = deepcopy(expected_minute)
1466         expected_cumulative['returns'][390:] = \
1467             (expected_cumulative['returns'][390:] + 1) * \
1468             (expected_daily['returns'][0] + 1) - 1
1469         expected_cumulative['returns'][780:] = \
1470             (expected_cumulative['returns'][780:] + 1) * \
1471             (expected_daily['returns'][1] + 1) - 1
1472         expected_cumulative['pnl'][390:] += expected_daily['pnl'][0]
1473         expected_cumulative['pnl'][780:] += expected_daily['pnl'][1]
1474 <a name="22"></a>        expected_cumulative['capital_used'][390:] += \
1475             expected_daily['capital_used'][0]
1476         expected_cumulative['capital_used'][780:] += \
1477             expected_daily['capital_used']<font color="#4cc417"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>[1]
1478         expected_cumulative['starting_cash'] = \
1479             np.repeat(expected_daily['starting_cash'][0:1], 1170)
1480         expected_cumulative['starting_value'] = \
1481             np.repeat(expected_daily['starting_value'][</b></font>0:1], 1170)
1482         for stat in stats:
1483             for i in (390, 781, 1172):
1484                 expected_cumulative[stat] = np.insert(
1485                     expected_cumulative[stat],
1486                     i,
1487                     expected_cumulative[stat][i-1]
1488                 )
1489         for stat in stats:
1490             np.testing.assert_array_almost_equal(
1491                 np.array([perf[stat] for perf in minute_perf]),
1492                 expected_minute[stat]
1493             )
1494             np.testing.assert_array_almost_equal(
1495                 np.array([perf[stat] for perf in daily_perf]),
1496                 expected_daily[stat]
1497             )
1498             np.testing.assert_array_almost_equal(
1499                 np.array([perf[stat] for perf in cumulative_perf]),
1500                 expected_cumulative[stat]
1501             )
1502         if change_loc == 'interday':
1503             self.assertEqual(
1504                 algo.capital_change_deltas,
1505                 {pd.Timestamp('2006-01-04', tz='UTC'): 1000.0}
1506             )
1507         else:
1508             self.assertEqual(
1509                 algo.capital_change_deltas,
1510                 {pd.Timestamp('2006-01-04 17:00', tz='UTC'): 500.0,
1511                  pd.Timestamp('2006-01-04 18:00', tz='UTC'): 500.0}
1512             )
1513 class TestGetDatetime(zf.WithMakeAlgo, zf.ZiplineTestCase):
1514     SIM_PARAMS_DATA_FREQUENCY = 'minute'
1515     START_DATE = to_utc('2014-01-02 9:31')
1516     END_DATE = to_utc('2014-01-03 9:31')
1517     ASSET_FINDER_EQUITY_SIDS = 0, 1
1518     BENCHMARK_SID = None
1519     @parameterized.expand(
1520         [
1521             ('default', None,),
1522             ('utc', 'UTC',),
1523             ('us_east', 'US/Eastern',),
1524         ]
1525     )
1526     def test_get_datetime(self, name, tz):
1527         algo = dedent(
1528         )
1529         algo = self.make_algo(script=algo)
1530         algo.run()
1531         self.assertFalse(algo.first_bar)
1532 class TestTradingControls(zf.WithMakeAlgo,
1533                           zf.ZiplineTestCase):
1534     START_DATE = pd.Timestamp('2006-01-03', tz='utc')
1535     END_DATE = pd.Timestamp('2006-01-06', tz='utc')
1536     sid = 133
1537     sids = ASSET_FINDER_EQUITY_SIDS = 133, 134
1538     SIM_PARAMS_DATA_FREQUENCY = 'daily'
1539     DATA_PORTAL_USE_MINUTE_DATA = True
1540     @classmethod
1541     def init_class_fixtures(cls):
1542         super(TestTradingControls, cls).init_class_fixtures()
1543         cls.asset = cls.asset_finder.retrieve_asset(cls.sid)
1544         cls.another_asset = cls.asset_finder.retrieve_asset(134)
1545     def _check_algo(self,
1546                     algo,
1547                     expected_order_count,
1548                     expected_exc):
1549         with self.assertRaises(expected_exc) if expected_exc else nop_context:
1550             algo.run()
1551         self.assertEqual(algo.order_count, expected_order_count)
1552     def check_algo_succeeds(self, algo, order_count=4):
1553         self._check_algo(algo, order_count, None)
1554     def check_algo_fails(self, algo, order_count):
1555         self._check_algo(algo,
1556                          order_count,
1557                          TradingControlViolation)
1558     def test_set_max_position_size(self):
1559         def initialize(self, asset, max_shares, max_notional):
1560             self.set_slippage(FixedSlippage())
1561             self.order_count = 0
1562             self.set_max_position_size(asset=asset,
1563                                        max_shares=max_shares,
1564                                        max_notional=max_notional)
1565         def handle_data(algo, data):
1566             algo.order(algo.sid(self.sid), 1)
1567             algo.order_count += 1
1568         algo = self.make_algo(
1569             asset=self.asset,
1570             max_shares=10,
1571             max_notional=500.0,
1572             initialize=initialize,
1573             handle_data=handle_data,
1574         )
1575         self.check_algo_succeeds(algo)
1576         def handle_data(algo, data):
1577             algo.order(algo.sid(self.sid), 3)
1578             algo.order_count += 1
1579         algo = self.make_algo(
1580             asset=self.asset,
1581             max_shares=10,
1582             max_notional=500.0,
1583             initialize=initialize,
1584             handle_data=handle_data,
1585         )
1586         self.check_algo_fails(algo, 3)
1587         def handle_data(algo, data):
1588             algo.order(algo.sid(self.sid), 3)
1589             algo.order_count += 1
1590         algo = self.make_algo(
1591             asset=self.asset,
1592             max_shares=10,
1593             max_notional=67.0,
1594             initialize=initialize,
1595             handle_data=handle_data,
1596         )
1597         self.check_algo_fails(algo, 2)
1598         def handle_data(algo, data):
1599             algo.order(algo.sid(self.sid), 10000)
1600             algo.order_count += 1
1601         algo = self.make_algo(
1602             asset=self.another_asset,
1603             max_shares=10,
1604             max_notional=67.0,
1605             initialize=initialize,
1606             handle_data=handle_data,
1607         )
1608         self.check_algo_succeeds(algo)
1609         def handle_data(algo, data):
1610             algo.order(algo.sid(self.sid), 10000)
1611             algo.order_count += 1
1612         algo = self.make_algo(
1613             max_shares=10,
1614             max_notional=61.0,
1615             asset=None,
1616             initialize=initialize,
1617             handle_data=handle_data,
1618         )
1619         self.check_algo_fails(algo, 0)
1620     def test_set_asset_restrictions(self):
1621         def initialize(algo, sid, restrictions, on_error):
1622             algo.order_count = 0
1623 <a name="32"></a>            algo.set_asset_restrictions(restrictions, on_error)
1624         def handle_data(algo, data):
1625             algo.could_trade = data<font color="#5b8daf"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.can_trade(algo.sid(self.sid))
1626             algo.order(algo.sid(self.sid), 100)
1627             algo.order_count +=</b></font> 1
1628         rlm = HistoricalRestrictions([
1629             Restriction(
1630                 self.sid,
1631                 self.sim_params.start_session,
1632                 RESTRICTION_STATES.FROZEN)
1633         ])
1634         algo = self.make_algo(
1635             sid=self.sid,
1636             restrictions=rlm,
1637             on_error='fail',
1638             initialize=initialize,
1639             handle_data=handle_data,
1640         )
1641         self.check_algo_fails(algo, 0)
1642         self.assertFalse(algo.could_trade)
1643         rlm = StaticRestrictions([self.sid])
1644         algo = self.make_algo(
1645             sid=self.sid,
1646             restrictions=rlm,
1647             on_error='fail',
1648             initialize=initialize,
1649             handle_data=handle_data,
1650         )
1651         self.check_algo_fails(algo, 0)
1652         self.assertFalse(algo.could_trade)
1653         algo = self.make_algo(
1654             sid=self.sid,
1655             restrictions=rlm,
1656             on_error='log',
1657             initialize=initialize,
1658             handle_data=handle_data,
1659         )
1660         with make_test_handler(self) as log_catcher:
1661             self.check_algo_succeeds(algo)
1662         logs = [r.message for r in log_catcher.records]
1663         self.assertIn("Order for 100 shares of Equity(133 [A]) at "
1664                       "2006-01-03 21:00:00+00:00 violates trading constraint "
1665                       "RestrictedListOrder({})", logs)
1666         self.assertFalse(algo.could_trade)
1667         rlm = HistoricalRestrictions([
1668             Restriction(
1669                 sid,
1670                 self.sim_params.start_session,
1671                 RESTRICTION_STATES.FROZEN) for sid in [134, 135, 136]
1672         ])
1673         algo = self.make_algo(
1674             sid=self.sid,
1675             restrictions=rlm,
1676             on_error='fail',
1677             initialize=initialize,
1678             handle_data=handle_data,
1679         )
1680         self.check_algo_succeeds(algo)
1681         self.assertTrue(algo.could_trade)
1682     @parameterized.expand([
1683         ('order_first_restricted_sid', 0),
1684         ('order_second_restricted_sid', 1)
1685     ])
1686     def test_set_multiple_asset_restrictions(self, name, to_order_idx):
1687         def initialize(algo, restrictions1, restrictions2, on_error):
1688             algo.order_count = 0
1689             algo.set_asset_restrictions(restrictions1, on_error)
1690             algo.set_asset_restrictions(restrictions2, on_error)
1691         def handle_data(algo, data):
1692             algo.could_trade1 = data.can_trade(algo.sid(self.sids[0]))
1693             algo.could_trade2 = data.can_trade(algo.sid(self.sids[1]))
1694             algo.order(algo.sid(self.sids[to_order_idx]), 100)
1695             algo.order_count += 1
1696         rl1 = StaticRestrictions([self.sids[0]])
1697         rl2 = StaticRestrictions([self.sids[1]])
1698         algo = self.make_algo(
1699             restrictions1=rl1,
1700             restrictions2=rl2,
1701             initialize=initialize,
1702             handle_data=handle_data,
1703             on_error='fail',
1704         )
1705         self.check_algo_fails(algo, 0)
1706         self.assertFalse(algo.could_trade1)
1707         self.assertFalse(algo.could_trade2)
1708     def test_set_do_not_order_list(self):
1709         def initialize(self, restricted_list):
1710             self.order_count = 0
1711             self.set_do_not_order_list(restricted_list, on_error='fail')
1712         def handle_data(algo, data):
1713             algo.could_trade = data.can_trade(algo.sid(self.sid))
1714             algo.order(algo.sid(self.sid), 100)
1715             algo.order_count += 1
1716         rlm = [self.sid]
1717         algo = self.make_algo(
1718             restricted_list=rlm,
1719             initialize=initialize,
1720             handle_data=handle_data,
1721         )
1722         self.check_algo_fails(algo, 0)
1723         self.assertFalse(algo.could_trade)
1724     def test_set_max_order_size(self):
1725         def initialize(algo, asset, max_shares, max_notional):
1726             algo.order_count = 0
1727             algo.set_max_order_size(asset=asset,
1728                                     max_shares=max_shares,
1729                                     max_notional=max_notional)
1730         def handle_data(algo, data):
1731             algo.order(algo.sid(self.sid), 1)
1732             algo.order_count += 1
1733         algo = self.make_algo(
1734             initialize=initialize,
1735             handle_data=handle_data,
1736             asset=self.asset,
1737             max_shares=10,
1738             max_notional=500.0,
1739         )
1740         self.check_algo_succeeds(algo)
1741         def handle_data(algo, data):
1742             algo.order(algo.sid(self.sid), algo.order_count + 1)
1743             algo.order_count += 1
1744         algo = self.make_algo(
1745             initialize=initialize,
1746             handle_data=handle_data,
1747             asset=self.asset,
1748             max_shares=3,
1749             max_notional=500.0,
1750         )
1751         self.check_algo_fails(algo, 3)
1752         def handle_data(algo, data):
1753             algo.order(algo.sid(self.sid), algo.order_count + 1)
1754             algo.order_count += 1
1755         algo = self.make_algo(
1756             initialize=initialize,
1757             handle_data=handle_data,
1758             asset=self.asset,
1759             max_shares=10,
1760             max_notional=40.0,
1761         )
1762         self.check_algo_fails(algo, 3)
1763         def handle_data(algo, data):
1764             algo.order(algo.sid(self.sid), 10000)
1765             algo.order_count += 1
1766         algo = self.make_algo(
1767             initialize=initialize,
1768             handle_data=handle_data,
1769             asset=self.another_asset,
1770             max_shares=1,
1771             max_notional=1.0,
1772         )
1773         self.check_algo_succeeds(algo)
1774         def handle_data(algo, data):
1775             algo.order(algo.sid(self.sid), 10000)
1776             algo.order_count += 1
1777         algo = self.make_algo(
1778             initialize=initialize,
1779             handle_data=handle_data,
1780             asset=None,
1781             max_shares=1,
1782             max_notional=1.0,
1783         )
1784         self.check_algo_fails(algo, 0)
1785     def test_set_max_order_count(self):
1786         def initialize(algo, count):
1787             algo.order_count = 0
1788             algo.set_max_order_count(count)
1789         def handle_data(algo, data):
1790             for i in range(5):
1791                 algo.order(self.asset, 1)
1792                 algo.order_count += 1
1793         algo = self.make_algo(
1794             count=3,
1795             initialize=initialize,
1796             handle_data=handle_data,
1797         )
1798         with self.assertRaises(TradingControlViolation):
1799             algo.run()
1800         self.assertEqual(algo.order_count, 3)
1801     def test_set_max_order_count_minutely(self):
1802         sim_params = self.make_simparams(data_frequency='minute')
1803         def initialize(algo, max_orders_per_day):
1804             algo.minute_count = 0
1805             algo.order_count = 0
1806             algo.set_max_order_count(max_orders_per_day)
1807         def handle_data(algo, data):
1808             if algo.minute_count == 0 or algo.minute_count == 100:
1809                 for i in range(5):
1810                     algo.order(self.asset, 1)
1811                     algo.order_count += 1
1812             algo.minute_count += 1
1813         algo = self.make_algo(
1814             initialize=initialize,
1815             handle_data=handle_data,
1816             max_orders_per_day=9,
1817             sim_params=sim_params,
1818         )
1819         with self.assertRaises(TradingControlViolation):
1820             algo.run()
1821         self.assertEqual(algo.order_count, 9)
1822         def handle_data(algo, data):
1823             if (algo.minute_count % 390) == 0:
1824                 for i in range(5):
1825                     algo.order(self.asset, 1)
1826                     algo.order_count += 1
1827 <a name="31"></a>
1828             algo.minute_count += 1
1829         algo <font color="#3ea99f"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>= self.make_algo(
1830             initialize=initialize,
1831             handle_data=handle_data,
1832             max_orders_per_day=5,
1833             sim_params=sim_params,
1834         )
1835         algo.run()
1836         self.assertEqual(algo.</b></font>order_count, 20)
1837     def test_long_only(self):
1838         def initialize(algo):
1839             algo.order_count = 0
1840             algo.set_long_only()
1841         def handle_data(algo, data):
1842             algo.order(algo.sid(self.sid), -1)
1843             algo.order_count += 1
1844         algo = self.make_algo(initialize=initialize, handle_data=handle_data)
1845         self.check_algo_fails(algo, 0)
1846         def handle_data(algo, data):
1847             if (algo.order_count % 2) == 0:
1848                 algo.order(algo.sid(self.sid), 1)
1849             else:
1850                 algo.order(algo.sid(self.sid), -1)
1851             algo.order_count += 1
1852         algo = self.make_algo(initialize=initialize, handle_data=handle_data)
1853         self.check_algo_succeeds(algo)
1854         def handle_data(algo, data):
1855             amounts = [1, 1, 1, -3]
1856             algo.order(algo.sid(self.sid), amounts[algo.order_count])
1857             algo.order_count += 1
1858         algo = self.make_algo(initialize=initialize, handle_data=handle_data)
1859         self.check_algo_succeeds(algo)
1860         def handle_data(algo, data):
1861             amounts = [1, 1, 1, -4]
1862             algo.order(algo.sid(self.sid), amounts[algo.order_count])
1863             algo.order_count += 1
1864         algo = self.make_algo(initialize=initialize, handle_data=handle_data)
1865         self.check_algo_fails(algo, 3)
1866     def test_register_post_init(self):
1867         def initialize(algo):
1868             algo.initialized = True
1869         def handle_data(algo, data):
1870             with self.assertRaises(RegisterTradingControlPostInit):
1871                 algo.set_max_position_size(self.sid, 1, 1)
1872             with self.assertRaises(RegisterTradingControlPostInit):
1873                 algo.set_max_order_size(self.sid, 1, 1)
1874             with self.assertRaises(RegisterTradingControlPostInit):
1875                 algo.set_max_order_count(1)
1876             with self.assertRaises(RegisterTradingControlPostInit):
1877                 algo.set_long_only()
1878         self.run_algorithm(initialize=initialize, handle_data=handle_data)
1879 class TestAssetDateBounds(zf.WithMakeAlgo, zf.ZiplineTestCase):
1880     START_DATE = pd.Timestamp('2014-01-02', tz='UTC')
1881     END_DATE = pd.Timestamp('2014-01-03', tz='UTC')
1882     SIM_PARAMS_START_DATE = END_DATE  # Only run for one day.
1883     SIM_PARAMS_DATA_FREQUENCY = 'daily'
1884     DATA_PORTAL_USE_MINUTE_DATA = False
1885     BENCHMARK_SID = 3
1886     @classmethod
1887     def make_equity_info(cls):
1888         T = partial(pd.Timestamp, tz='UTC')
1889         return pd.DataFrame.from_records([
1890             {'sid': 1,
1891              'symbol': 'OLD',
1892              'start_date': T('1990'),
1893              'end_date': T('1991'),
1894              'exchange': 'TEST'},
1895             {'sid': 2,
1896              'symbol': 'NEW',
1897              'start_date': T('2017'),
1898              'end_date': T('2018'),
1899              'exchange': 'TEST'},
1900             {'sid': 3,
1901              'symbol': 'GOOD',
1902              'start_date': cls.START_DATE,
1903              'end_date': cls.END_DATE,
1904              'exchange': 'TEST'},
1905         ])
1906     def test_asset_date_bounds(self):
1907         def initialize(algo):
1908             algo.ran = False
1909             algo.register_trading_control(AssetDateBounds(on_error='fail'))
1910         def handle_data(algo, data):
1911             algo.order(algo.sid(3), 1)
1912             with self.assertRaises(TradingControlViolation):
1913                 algo.order(algo.sid(1), 1)
1914             with self.assertRaises(TradingControlViolation):
1915                 algo.order(algo.sid(2), 1)
1916             algo.ran = True
1917         algo = self.make_algo(initialize=initialize, handle_data=handle_data)
1918         algo.run()
1919         self.assertTrue(algo.ran)
1920 class TestAccountControls(zf.WithMakeAlgo,
1921                           zf.ZiplineTestCase):
1922     START_DATE = pd.Timestamp('2006-01-03', tz='utc')
1923     END_DATE = pd.Timestamp('2006-01-06', tz='utc')
1924     sidint, = ASSET_FINDER_EQUITY_SIDS = (133,)
1925     BENCHMARK_SID = None
1926 <a name="17"></a>    SIM_PARAMS_DATA_FREQUENCY = 'daily'
1927     DATA_PORTAL_USE_MINUTE_DATA = False
1928     <font color="#3090c7"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>@classmethod
1929     def make_equity_daily_bar_data(cls, country_code, sids):
1930         frame = pd.DataFrame(data={
1931             'close': [10., 10., 11., 11.],
1932             'open': [10., 10., 11., 11.],
1933             'low': [9.5, 9.5, 10.45, 10.45],
1934             'high': [10.5, 10.5, 11.55, 11.55],
1935             'volume': [100, 100, 100, 300],
1936         }, index=cls.</b></font>equity_daily_bar_days)
1937         yield cls.sidint, frame
1938     def _check_algo(self, algo, expected_exc):
1939         with self.assertRaises(expected_exc) if expected_exc else nop_context:
1940             algo.run()
1941     def check_algo_succeeds(self, algo):
1942         self._check_algo(algo, None)
1943     def check_algo_fails(self, algo):
1944         self._check_algo(algo, AccountControlViolation)
1945     def test_set_max_leverage(self):
1946         def initialize(algo, max_leverage):
1947             algo.set_max_leverage(max_leverage=max_leverage)
1948         def handle_data(algo, data):
1949             algo.order(algo.sid(self.sidint), 1)
1950             algo.record(latest_time=algo.get_datetime())
1951         algo = self.make_algo(
1952             initialize=initialize,
1953             handle_data=handle_data,
1954             max_leverage=0,
1955         )
1956         self.check_algo_fails(algo)
1957         self.assertEqual(
1958             algo.recorded_vars['latest_time'],
1959             pd.Timestamp('2006-01-04 21:00:00', tz='UTC'),
1960         )
1961         def handle_data(algo, data):
1962             algo.order(algo.sid(self.sidint), 1)
1963         algo = self.make_algo(
1964             initialize=initialize,
1965             handle_data=handle_data,
1966             max_leverage=1,
1967         )
1968         self.check_algo_succeeds(algo)
1969     def test_set_min_leverage(self):
1970         def initialize(algo, min_leverage, grace_period):
1971             algo.set_min_leverage(
1972                 min_leverage=min_leverage, grace_period=grace_period
1973             )
1974         def handle_data(algo, data):
1975             algo.order_target_percent(algo.sid(self.sidint), .5)
1976             algo.record(latest_time=algo.get_datetime())
1977         def make_algo(min_leverage, grace_period):
1978             return self.make_algo(
1979                 initialize=initialize,
1980                 handle_data=handle_data,
1981                 min_leverage=min_leverage,
1982                 grace_period=grace_period,
1983             )
1984         offset = pd.Timedelta('10 days')
1985         algo = make_algo(min_leverage=1, grace_period=offset)
1986         self.check_algo_succeeds(algo)
1987         offset = pd.Timedelta('1 days')
1988         algo = make_algo(min_leverage=1, grace_period=offset)
1989         self.check_algo_fails(algo)
1990         self.assertEqual(
1991             algo.recorded_vars['latest_time'],
1992             pd.Timestamp('2006-01-04 21:00:00', tz='UTC'),
1993         )
1994         offset = pd.Timedelta('2 days')
1995         algo = make_algo(min_leverage=1, grace_period=offset)
1996         self.check_algo_fails(algo)
1997         self.assertEqual(
1998             algo.recorded_vars['latest_time'],
1999             pd.Timestamp('2006-01-05 21:00:00', tz='UTC'),
2000         )
2001         algo = make_algo(min_leverage=.0001, grace_period=offset)
2002         self.check_algo_succeeds(algo)
2003 class TestFuturesAlgo(zf.WithMakeAlgo, zf.ZiplineTestCase):
2004     START_DATE = pd.Timestamp('2016-01-06', tz='utc')
2005     END_DATE = pd.Timestamp('2016-01-07', tz='utc')
2006     FUTURE_MINUTE_BAR_START_DATE = pd.Timestamp('2016-01-05', tz='UTC')
2007     SIM_PARAMS_DATA_FREQUENCY = 'minute'
2008     TRADING_CALENDAR_STRS = ('us_futures',)
2009     TRADING_CALENDAR_PRIMARY_CAL = 'us_futures'
2010     BENCHMARK_SID = None
2011     @classmethod
2012     def make_futures_info(cls):
2013         return pd.DataFrame.from_dict(
2014             {
2015                 1: {
2016                     'symbol': 'CLG16',
2017                     'root_symbol': 'CL',
2018                     'start_date': pd.Timestamp('2015-12-01', tz='UTC'),
2019                     'notice_date': pd.Timestamp('2016-01-20', tz='UTC'),
2020                     'expiration_date': pd.Timestamp('2016-02-19', tz='UTC'),
2021                     'auto_close_date': pd.Timestamp('2016-01-18', tz='UTC'),
2022                     'exchange': 'TEST',
2023                 },
2024             },
2025             orient='index',
2026         )
2027     def test_futures_history(self):
2028         algo_code = dedent(
2029         )
2030         algo = self.make_algo(
2031             script=algo_code,
2032             trading_calendar=get_calendar('us_futures'),
2033         )
2034         algo.run()
2035         np.testing.assert_array_equal(
2036             algo.history_values[0].index,
2037             pd.date_range(
2038                 '2016-01-06 6:27',
2039                 '2016-01-06 6:31',
2040                 freq='min',
2041                 tz='US/Eastern',
2042             ),
2043         )
2044         np.testing.assert_array_equal(
2045             algo.history_values[1].index,
2046             pd.date_range(
2047                 '2016-01-07 6:27',
2048                 '2016-01-07 6:31',
2049                 freq='min',
2050                 tz='US/Eastern',
2051             ),
2052         )
2053         np.testing.assert_array_equal(
2054             algo.history_values[0].values, list(map(float, range(2196, 2201))),
2055         )
2056         np.testing.assert_array_equal(
2057             algo.history_values[1].values, list(map(float, range(3636, 3641))),
2058         )
2059     @staticmethod
2060     def algo_with_slippage(slippage_model):
2061         return dedent(
2062         ).format(model=slippage_model)
2063     def test_fixed_future_slippage(self):
2064         algo_code = self.algo_with_slippage('FixedSlippage(spread=0.10)')
2065         algo = self.make_algo(
2066             script=algo_code,
2067             trading_calendar=get_calendar('us_futures'),
2068         )
2069         results = algo.run()
2070         all_txns = [
2071             val for sublist in results['transactions'].tolist()
2072             for val in sublist
2073         ]
2074         self.assertEqual(len(all_txns), 1)
2075         txn = all_txns[0]
2076         expected_spread = 0.05
2077         expected_price = (algo.order_price + 1) + expected_spread
2078         self.assertEqual(txn['price'], expected_price)
2079         self.assertEqual(results['orders'][0][0]['commission'], 0.0)
2080     def test_volume_contract_slippage(self):
2081         algo_code = self.algo_with_slippage(
2082             'VolumeShareSlippage(volume_limit=0.05, price_impact=0.1)',
2083         )
2084         algo = self.make_algo(
2085             script=algo_code,
2086             trading_calendar=get_calendar('us_futures'),
2087         )
2088         results = algo.run()
2089         self.assertEqual(results['orders'][0][0]['commission'], 0.0)
2090         all_txns = [
2091             val for sublist in results['transactions'].tolist()
2092             for val in sublist
2093         ]
2094         self.assertEqual(len(all_txns), 2)
2095         for i, txn in enumerate(all_txns):
2096             order_price = algo.order_price + i + 1
2097             expected_impact = order_price * 0.1 * (0.05 ** 2)
2098             expected_price = order_price + expected_impact
2099             self.assertEqual(txn['price'], expected_price)
2100 class TestAnalyzeAPIMethod(zf.WithMakeAlgo, zf.ZiplineTestCase):
2101     START_DATE = pd.Timestamp('2016-01-05', tz='utc')
2102     END_DATE = pd.Timestamp('2016-01-05', tz='utc')
2103     SIM_PARAMS_DATA_FREQUENCY = 'daily'
2104     DATA_PORTAL_USE_MINUTE_DATA = False
2105     def test_analyze_called(self):
2106         self.perf_ref = None
2107         def initialize(context):
2108             pass
2109         def handle_data(context, data):
2110             pass
2111         def analyze(context, perf):
2112             self.perf_ref = perf
2113         algo = self.make_algo(
2114             initialize=initialize, handle_data=handle_data, analyze=analyze,
2115         )
2116         results = algo.run()
2117         self.assertIs(results, self.perf_ref)
2118 class TestOrderCancelation(zf.WithMakeAlgo, zf.ZiplineTestCase):
2119     START_DATE = pd.Timestamp('2016-01-05', tz='utc')
2120     END_DATE = pd.Timestamp('2016-01-07', tz='utc')
2121     ASSET_FINDER_EQUITY_SIDS = (1,)
2122     ASSET_FINDER_EQUITY_SYMBOLS = ('ASSET1',)
2123     BENCHMARK_SID = None
2124     code = dedent(
2125     )
2126     @classmethod
2127     def make_equity_minute_bar_data(cls):
2128         asset_minutes = \
2129             cls.trading_calendar.minutes_for_sessions_in_range(
2130                 cls.START_DATE,
2131                 cls.END_DATE,
2132             )
2133         minutes_count = len(asset_minutes)
2134         minutes_arr = np.arange(1, 1 + minutes_count)
2135         yield 1, pd.DataFrame(
2136             {
2137                 'open': minutes_arr + 1,
2138                 'high': minutes_arr + 2,
2139                 'low': minutes_arr - 1,
2140                 'close': minutes_arr,
2141                 'volume': np.full(minutes_count, 1.0),
2142             },
2143             index=asset_minutes,
2144         )
2145     @classmethod
2146     def make_equity_daily_bar_data(cls, country_code, sids):
2147         yield 1, pd.DataFrame(
2148             {
2149                 'open': np.full(3, 1, dtype=np.float64),
2150                 'high': np.full(3, 1, dtype=np.float64),
2151                 'low': np.full(3, 1, dtype=np.float64),
2152                 'close': np.full(3, 1, dtype=np.float64),
2153                 'volume': np.full(3, 1, dtype=np.float64),
2154             },
2155             index=cls.equity_daily_bar_days,
2156         )
2157     def prep_algo(self,
2158                   cancelation_string,
2159                   data_frequency="minute",
2160                   amount=1000,
2161                   minute_emission=False):
2162         code = self.code.format(cancelation_string, amount)
2163         return self.make_algo(
2164             script=code,
2165             sim_params=self.make_simparams(
2166                 data_frequency=data_frequency,
2167                 emission_rate='minute' if minute_emission else 'daily',
2168             )
2169         )
2170     @parameter_space(
2171         direction=[1, -1],
2172         minute_emission=[True, False],
2173     )
2174     def test_eod_order_cancel_minute(self, direction, minute_emission):
2175         algo = self.prep_algo(
2176             "set_cancel_policy(cancel_policy.EODCancel())",
2177             amount=np.copysign(1000, direction),
2178             minute_emission=minute_emission
2179         )
2180         log_catcher = TestHandler()
2181         with log_catcher:
2182 <a name="21"></a>            results = algo.run()
2183             for daily_positions in results.positions:
2184                 self.assertEqual(1, len<font color="#947010"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(daily_positions))
2185                 self.assertEqual(
2186                     np.copysign(389, direction),
2187                     daily_positions[0]["amount"],
2188                 )
2189                 self.assertEqual(1, results.positions[0][0][</b></font>"sid"])
2190             np.testing.assert_array_equal([1, 0, 0],
2191                                           list(map(len, results.orders)))
2192             np.testing.assert_array_equal([389, 0, 0],
2193                                           list(map(len, results.transactions)))
2194             the_order = results.orders[0][0]
2195             self.assertEqual(ORDER_STATUS.CANCELLED, the_order["status"])
2196             self.assertEqual(np.copysign(389, direction), the_order["filled"])
2197             warnings = [record for record in log_catcher.records if
2198                         record.level == WARNING]
2199             self.assertEqual(1, len(warnings))
2200             if direction == 1:
2201                 self.assertEqual(
2202                     "Your order for 1000 shares of ASSET1 has been partially "
2203                     "filled. 389 shares were successfully purchased. "
2204                     "611 shares were not filled by the end of day and "
2205                     "were canceled.",
2206                     str(warnings[0].message)
2207                 )
2208             elif direction == -1:
2209                 self.assertEqual(
2210                     "Your order for -1000 shares of ASSET1 has been partially "
2211                     "filled. 389 shares were successfully sold. "
2212                     "611 shares were not filled by the end of day and "
2213                     "were canceled.",
2214                     str(warnings[0].message)
2215                 )
2216     def test_default_cancelation_policy(self):
2217         algo = self.prep_algo("")
2218         log_catcher = TestHandler()
2219         with log_catcher:
2220             results = algo.run()
2221             np.testing.assert_array_equal([1, 1, 1],
2222                                           list(map(len, results.orders)))
2223             np.testing.assert_array_equal([389, 390, 221],
2224                                           list(map(len, results.transactions)))
2225             self.assertFalse(log_catcher.has_warnings)
2226     def test_eod_order_cancel_daily(self):
2227         algo = self.prep_algo(
2228             "set_cancel_policy(cancel_policy.EODCancel())",
2229             "daily"
2230         )
2231         log_catcher = TestHandler()
2232         with log_catcher:
2233             results = algo.run()
2234             np.testing.assert_array_equal([1, 1, 1],
2235                                           list(map(len, results.orders)))
2236             np.testing.assert_array_equal([0, 1, 1],
2237                                           list(map(len, results.transactions)))
2238             self.assertFalse(log_catcher.has_warnings)
2239 class TestDailyEquityAutoClose(zf.WithMakeAlgo, zf.ZiplineTestCase):
2240     START_DATE = pd.Timestamp('2015-01-05', tz='UTC')
2241     END_DATE = pd.Timestamp('2015-01-13', tz='UTC')
2242     SIM_PARAMS_DATA_FREQUENCY = 'daily'
2243     DATA_PORTAL_USE_MINUTE_DATA = False
2244     BENCHMARK_SID = None
2245     @classmethod
2246     def init_class_fixtures(cls):
2247         super(TestDailyEquityAutoClose, cls).init_class_fixtures()
2248         cls.assets = (
2249             cls.asset_finder.retrieve_all(cls.asset_finder.equities_sids)
2250         )
2251     @classmethod
2252     def make_equity_info(cls):
2253         cls.test_days = cls.trading_calendar.sessions_in_range(
2254             cls.START_DATE, cls.END_DATE,
2255         )
2256         assert len(cls.test_days) == 7, "Number of days in test changed!"
2257         cls.first_asset_expiration = cls.test_days[2]
2258         cls.asset_info = make_jagged_equity_info(
2259             num_assets=3,
2260             start_date=cls.test_days[0],
2261             first_end=cls.first_asset_expiration,
2262             frequency=cls.trading_calendar.day,
2263             periods_between_ends=2,
2264             auto_close_delta=2 * cls.trading_calendar.day,
2265         )
2266         return cls.asset_info
2267     @classmethod
2268     def make_equity_daily_bar_data(cls, country_code, sids):
2269         cls.daily_data = make_trade_data_for_asset_info(
2270             dates=cls.test_days,
2271             asset_info=cls.asset_info,
2272             price_start=10,
2273             price_step_by_sid=10,
2274             price_step_by_date=1,
2275             volume_start=100,
2276             volume_step_by_sid=100,
2277             volume_step_by_date=10,
2278         )
2279         return cls.daily_data.items()
2280     def daily_prices_on_tick(self, row):
2281         return [
2282             trades.iloc[row].close for trades in itervalues(self.daily_data)
2283         ]
2284     def final_daily_price(self, asset):
2285         return self.daily_data[asset.sid].loc[asset.end_date].close
2286     def default_initialize(self):
2287         def initialize(context):
2288             context.ordered = False
2289             context.set_commission(PerShare(0, 0))
2290             context.set_slippage(FixedSlippage(spread=0))
2291             context.num_positions = []
2292             context.cash = []
2293         return initialize
2294     def default_handle_data(self, assets, order_size):
2295         def handle_data(context, data):
2296             if not context.ordered:
2297                 for asset in assets:
2298                     context.order(asset, order_size)
2299                 context.ordered = True
2300             context.cash.append(context.portfolio.cash)
2301             context.num_positions.append(len(context.portfolio.positions))
2302         return handle_data
2303     @parameter_space(
2304         order_size=[10, -10],
2305         capital_base=[1, 100000],
2306         __fail_fast=True,
2307     )
2308     def test_daily_delisted_equities(self,
2309                                      order_size,
2310                                      capital_base):
2311         assets = self.assets
2312         final_prices = {
2313             asset.sid: self.final_daily_price(asset)
2314             for asset in assets
2315         }
2316         initial_fill_prices = self.daily_prices_on_tick(1)
2317         cost_basis = sum(initial_fill_prices) * order_size
2318         fp0 = final_prices[0]
2319         fp1 = final_prices[1]
2320         algo = self.make_algo(
2321             initialize=self.default_initialize(),
2322             handle_data=self.default_handle_data(assets, order_size),
2323             sim_params=self.make_simparams(
2324                 capital_base=capital_base,
2325                 data_frequency='daily',
2326             ),
2327         )
2328         output = algo.run()
2329         initial_cash = capital_base
2330         after_fills = initial_cash - cost_basis
2331         after_first_auto_close = after_fills + fp0 * (order_size)
2332         after_second_auto_close = after_first_auto_close + fp1 * (order_size)
2333         expected_cash = [
2334             initial_cash,
2335             after_fills,
2336             after_fills,
2337             after_fills,
2338             after_first_auto_close,
2339             after_first_auto_close,
2340             after_second_auto_close,
2341         ]
2342         expected_num_positions = [0, 3, 3, 3, 2, 2, 1]
2343         self.assertEqual(expected_cash, list(output['ending_cash']))
2344         expected_cash.insert(3, after_fills)
2345         self.assertEqual(algo.cash, expected_cash[:-1])
2346         if order_size &gt; 0:
2347             self.assertEqual(
2348                 expected_num_positions,
2349                 list(output['longs_count']),
2350             )
2351             self.assertEqual(
2352                 [0] * len(self.test_days),
2353                 list(output['shorts_count']),
2354             )
2355         else:
2356             self.assertEqual(
2357                 expected_num_positions,
2358                 list(output['shorts_count']),
2359             )
2360             self.assertEqual(
2361                 [0] * len(self.test_days),
2362                 list(output['longs_count']),
2363             )
2364         expected_num_positions.insert(3, 3)
2365         self.assertEqual(algo.num_positions, expected_num_positions[:-1])
2366         transactions = output['transactions']
2367         initial_fills = transactions.iloc[1]
2368         self.assertEqual(len(initial_fills), len(assets))
2369         last_minute_of_session = \
2370             self.trading_calendar.session_close(self.test_days[1])
2371         for asset, txn in zip(assets, initial_fills):
2372             self.assertDictContainsSubset(
2373                 {
2374                     'amount': order_size,
2375                     'commission': None,
2376                     'dt': last_minute_of_session,
2377                     'price': initial_fill_prices[asset],
2378                     'sid': asset,
2379                 },
2380                 txn,
2381             )
2382             self.assertIsInstance(txn['order_id'], str)
2383         def transactions_for_date(date):
2384             return transactions.iloc[self.test_days.get_loc(date)]
2385         (first_auto_close_transaction,) = transactions_for_date(
2386             assets[0].auto_close_date
2387         )
2388         self.assertEqual(
2389             first_auto_close_transaction,
2390             {
2391                 'amount': -order_size,
2392                 'commission': None,
2393                 'dt': self.trading_calendar.session_close(
2394                     assets[0].auto_close_date,
2395                 ),
2396                 'price': fp0,
2397                 'sid': assets[0],
2398                 'order_id': None,  # Auto-close txns emit Nones for order_id.
2399             },
2400         )
2401         (second_auto_close_transaction,) = transactions_for_date(
2402             assets[1].auto_close_date
2403         )
2404         self.assertEqual(
2405             second_auto_close_transaction,
2406             {
2407                 'amount': -order_size,
2408                 'commission': None,
2409                 'dt': self.trading_calendar.session_close(
2410                     assets[1].auto_close_date,
2411                 ),
2412                 'price': fp1,
2413                 'sid': assets[1],
2414                 'order_id': None,  # Auto-close txns emit Nones for order_id.
2415             },
2416         )
2417     def test_cancel_open_orders(self):
2418         assets = self.assets
2419         first_asset_end_date = assets[0].end_date
2420         first_asset_auto_close_date = assets[0].auto_close_date
2421         def initialize(context):
2422             pass
2423         def handle_data(context, data):
2424             assert (
2425                 context.portfolio.cash == context.portfolio.starting_cash
2426             )
2427             today_session = self.trading_calendar.minute_to_session_label(
2428                 context.get_datetime()
2429             )
2430             day_after_auto_close = self.trading_calendar.next_session_label(
2431                 first_asset_auto_close_date,
2432             )
2433             if today_session == first_asset_end_date:
2434                 assert len(context.get_open_orders()) == 0
2435                 context.order(context.sid(0), 10)
2436                 assert len(context.get_open_orders()) == 1
2437             elif today_session == first_asset_auto_close_date:
2438                 assert len(context.get_open_orders()) == 1
2439             elif today_session == day_after_auto_close:
2440                 assert len(context.get_open_orders()) == 0
2441         algo = self.make_algo(
2442             initialize=initialize,
2443             handle_data=handle_data,
2444             sim_params=self.make_simparams(
2445                 data_frequency='daily',
2446             ),
2447         )
2448         results = algo.run()
2449         orders = results['orders']
2450         def orders_for_date(date):
2451             return orders.iloc[self.test_days.get_loc(date)]
2452         original_open_orders = orders_for_date(first_asset_end_date)
2453         assert len(original_open_orders) == 1
2454         last_close_for_asset = \
2455             algo.trading_calendar.session_close(first_asset_end_date)
2456         self.assertDictContainsSubset(
2457             {
2458                 'amount': 10,
2459                 'commission': 0.0,
2460                 'created': last_close_for_asset,
2461                 'dt': last_close_for_asset,
2462                 'sid': assets[0],
2463                 'status': ORDER_STATUS.OPEN,
2464                 'filled': 0,
2465             },
2466             original_open_orders[0],
2467         )
2468         orders_after_auto_close = orders_for_date(first_asset_auto_close_date)
2469         assert len(orders_after_auto_close) == 1
2470         self.assertDictContainsSubset(
2471             {
2472                 'amount': 10,
2473                 'commission': 0.0,
2474                 'created': last_close_for_asset,
2475                 'dt': algo.trading_calendar.session_close(
2476                     first_asset_auto_close_date,
2477                 ),
2478                 'sid': assets[0],
2479                 'status': ORDER_STATUS.CANCELLED,
2480                 'filled': 0,
2481             },
2482             orders_after_auto_close[0],
2483         )
2484 class TestMinutelyEquityAutoClose(zf.WithMakeAlgo,
2485                                   zf.ZiplineTestCase):
2486     START_DATE = pd.Timestamp('2015-01-05', tz='UTC')
2487     END_DATE = pd.Timestamp('2015-01-13', tz='UTC')
2488     BENCHMARK_SID = None
2489     @classmethod
2490     def init_class_fixtures(cls):
2491         super(TestMinutelyEquityAutoClose, cls).init_class_fixtures()
2492         cls.assets = (
2493             cls.asset_finder.retrieve_all(cls.asset_finder.equities_sids)
2494         )
2495     @classmethod
2496     def make_equity_info(cls):
2497         cls.test_days = cls.trading_calendar.sessions_in_range(
2498             cls.START_DATE, cls.END_DATE,
2499         )
2500         cls.test_minutes = cls.trading_calendar.minutes_for_sessions_in_range(
2501             cls.START_DATE, cls.END_DATE,
2502         )
2503         cls.first_asset_expiration = cls.test_days[2]
2504         cls.asset_info = make_jagged_equity_info(
2505             num_assets=3,
2506             start_date=cls.test_days[0],
2507             first_end=cls.first_asset_expiration,
2508             frequency=cls.trading_calendar.day,
2509             periods_between_ends=2,
2510             auto_close_delta=1 * cls.trading_calendar.day,
2511         )
2512         return cls.asset_info
2513     @classmethod
2514     def make_equity_minute_bar_data(cls):
2515         cls.minute_data = make_trade_data_for_asset_info(
2516             dates=cls.test_minutes,
2517             asset_info=cls.asset_info,
2518             price_start=10,
2519             price_step_by_sid=10,
2520             price_step_by_date=1,
2521             volume_start=100,
2522             volume_step_by_sid=100,
2523             volume_step_by_date=10,
2524         )
2525         return cls.minute_data.items()
2526     def minute_prices_on_tick(self, row):
2527         return [
2528             trades.iloc[row].close for trades in itervalues(self.minute_data)
2529         ]
2530     def final_minute_price(self, asset):
2531         return self.minute_data[asset.sid].loc[
2532             self.trading_calendar.session_close(asset.end_date)
2533         ].close
2534     def default_initialize(self):
2535         def initialize(context):
2536             context.ordered = False
2537             context.set_commission(PerShare(0, 0))
2538             context.set_slippage(FixedSlippage(spread=0))
2539             context.num_positions = []
2540             context.cash = []
2541         return initialize
2542     def default_handle_data(self, assets, order_size):
2543         def handle_data(context, data):
2544             if not context.ordered:
2545                 for asset in assets:
2546                     context.order(asset, order_size)
2547                 context.ordered = True
2548             context.cash.append(context.portfolio.cash)
2549             context.num_positions.append(len(context.portfolio.positions))
2550         return handle_data
2551     def test_minutely_delisted_equities(self):
2552         assets = self.assets
2553         final_prices = {
2554             asset.sid: self.final_minute_price(asset)
2555             for asset in assets
2556         }
2557         backtest_minutes = self.minute_data[0].index.tolist()
2558         order_size = 10
2559 <a name="30"></a>        capital_base = 100000
2560         algo = self.make_algo(
2561             initialize=self.default_initialize(),
2562             handle_data=self.default_handle_data<font color="#ae694a"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(assets, order_size),
2563             sim_params=self.make_simparams(
2564                 capital_base=capital_base,
2565                 data_frequency='minute',
2566             )
2567         )
2568         output = algo.run()
2569         initial_fill_prices = self.minute_prices_on_tick(</b></font>1)
2570         cost_basis = sum(initial_fill_prices) * order_size
2571         fp0 = final_prices[0]
2572         fp1 = final_prices[1]
2573         initial_cash = capital_base
2574         after_fills = initial_cash - cost_basis
2575         after_first_auto_close = after_fills + fp0 * (order_size)
2576         after_second_auto_close = after_first_auto_close + fp1 * (order_size)
2577         expected_cash = [initial_cash]
2578         expected_position_counts = [0]
2579 <a name="16"></a>
2580         expected_cash<font color="#2981b2"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.extend([after_fills] * (389 + 390 + 390 + 390))
2581         expected_position_counts.extend([3] * (389 + 390 + 390 + 390))
2582         expected_cash.extend([after_first_auto_close] * (390 + 390))
2583         expected_position_counts.extend([2] * (390 + 390))
2584         expected_cash.extend([after_second_auto_close] * 390)
2585         expected_position_counts.extend([1] * 390)
2586         self.assertEqual(</b></font>len(algo.cash), len(expected_cash))
2587         self.assertEqual(algo.cash, expected_cash)
2588         self.assertEqual(
2589             list(output['ending_cash']),
2590             [
2591                 after_fills,
2592                 after_fills,
2593                 after_fills,
2594                 after_first_auto_close,
2595                 after_first_auto_close,
2596                 after_second_auto_close,
2597                 after_second_auto_close,
2598             ],
2599         )
2600         self.assertEqual(algo.num_positions, expected_position_counts)
2601         self.assertEqual(
2602             list(output['longs_count']),
2603             [3, 3, 3, 2, 2, 1, 1],
2604         )
2605         transactions = output['transactions']
2606         initial_fills = transactions.iloc[0]
2607         self.assertEqual(len(initial_fills), len(assets))
2608         for asset, txn in zip(assets, initial_fills):
2609             self.assertDictContainsSubset(
2610                 {
2611                     'amount': order_size,
2612                     'commission': None,
2613                     'dt': backtest_minutes[1],
2614                     'price': initial_fill_prices[asset],
2615                     'sid': asset,
2616                 },
2617                 txn,
2618             )
2619             self.assertIsInstance(txn['order_id'], str)
2620         def transactions_for_date(date):
2621             return transactions.iloc[self.test_days.get_loc(date)]
2622         (first_auto_close_transaction,) = transactions_for_date(
2623             assets[0].auto_close_date
2624         )
2625         self.assertEqual(
2626             first_auto_close_transaction,
2627             {
2628                 'amount': -order_size,
2629                 'commission': None,
2630                 'dt': algo.trading_calendar.session_close(
2631                     assets[0].auto_close_date,
2632                 ),
2633                 'price': fp0,
2634                 'sid': assets[0],
2635                 'order_id': None,  # Auto-close txns emit Nones for order_id.
2636             },
2637         )
2638         (second_auto_close_transaction,) = transactions_for_date(
2639             assets[1].auto_close_date
2640         )
2641         self.assertEqual(
2642             second_auto_close_transaction,
2643             {
2644                 'amount': -order_size,
2645                 'commission': None,
2646                 'dt': algo.trading_calendar.session_close(
2647                     assets[1].auto_close_date,
2648                 ),
2649                 'price': fp1,
2650                 'sid': assets[1],
2651                 'order_id': None,  # Auto-close txns emit Nones for order_id.
2652             },
2653         )
2654 class TestOrderAfterDelist(zf.WithMakeAlgo, zf.ZiplineTestCase):
2655     start = pd.Timestamp('2016-01-05', tz='utc')
2656     day_1 = pd.Timestamp('2016-01-06', tz='utc')
2657     day_4 = pd.Timestamp('2016-01-11', tz='utc')
2658     end = pd.Timestamp('2016-01-15', tz='utc')
2659     BENCHMARK_SID = None
2660 <a name="29"></a>
2661     @classmethod
2662     def make_equity_info(cls):
2663         return pd<font color="#af7a82"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.DataFrame.from_dict(
2664             {
2665                 1: {
2666                     'start_date': cls.start,
2667                     'end_date': cls.day_1,
2668                     'auto_close_date': cls.day_4,
2669                     'symbol': "ASSET1",
2670                     'exchange': "TEST",
2671                 },
2672                 2: {
2673                     'start_date': cls.start,
2674                     'end_date': cls.day_4,
2675                     'auto_close_date': cls.</b></font>day_1,
2676                     'symbol': 'ASSET2',
2677                     'exchange': 'TEST',
2678                 },
2679             },
2680             orient='index',
2681         )
2682     def init_instance_fixtures(self):
2683         super(TestOrderAfterDelist, self).init_instance_fixtures()
2684         self.data_portal = FakeDataPortal(self.asset_finder)
2685     @parameterized.expand([
2686         ('auto_close_after_end_date', 1),
2687         ('auto_close_before_end_date', 2),
2688     ])
2689     def test_order_in_quiet_period(self, name, sid):
2690         asset = self.asset_finder.retrieve_asset(sid)
2691         algo_code = dedent("""
2692         from zipline.api import (
2693             sid,
2694             order,
2695             order_value,
2696             order_percent,
2697             order_target,
2698             order_target_percent,
2699             order_target_value
2700         )
2701         def initialize(context):
2702             pass
2703         def handle_data(context, data):
2704             order(sid({sid}), 1)
2705             order_value(sid({sid}), 100)
2706             order_percent(sid({sid}), 0.5)
2707             order_target(sid({sid}), 50)
2708             order_target_percent(sid({sid}), 0.5)
2709             order_target_value(sid({sid}), 50)
2710             def initialize(context):
2711                 pass
2712             def handle_data(context, data):
2713                 pass
2714             def before_trading_start(context, data):
2715                 pass
2716             def analyze(context, results):
2717                 pass
2718 <a name="1"></a><font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>from __future__ import division
2719 from datetime import timedelta
2720 from functools import partial
2721 import blaze as bz
2722 import itertools
2723 from nose.tools import assert_true
2724 from nose_parameterized import parameterized
2725 import numpy as np
2726 from numpy.testing import assert_array_equal, assert_almost_equal
2727 import pandas as pd
2728 from toolz import merge
2729 from zipline.pipeline import SimplePipelineEngine, Pipeline, CustomFactor
2730 from zipline.pipeline.common import (
2731     EVENT_DATE_FIELD_NAME,
2732     FISCAL_QUARTER_FIELD_NAME,
2733     FISCAL_YEAR_FIELD_NAME,
2734     SID_FIELD_NAME,
2735     TS_FIELD_NAME,
2736 )
2737 from zipline.pipeline.data import DataSet
2738 from zipline.pipeline.data import Column
2739 from zipline.pipeline.domain import EquitySessionDomain
2740 from zipline.pipeline.loaders.blaze.estimates import (
2741     BlazeNextEstimatesLoader,
2742     BlazeNextSplitAdjustedEstimatesLoader,
2743     BlazePreviousEstimatesLoader,
2744     BlazePreviousSplitAdjustedEstimatesLoader,
2745 )
2746 from zipline.pipeline.loaders.earnings_estimates import (
2747     INVALID_NUM_QTRS_MESSAGE,
2748     NextEarningsEstimatesLoader,
2749     NextSplitAdjustedEarningsEstimatesLoader,
2750     normalize_quarters,
2751     PreviousEarningsEstimatesLoader,
2752     PreviousSplitAdjustedEarningsEstimatesLoader,
2753     split_normalized_quarters,
2754 )
2755 from zipline.testing.fixtures import (
2756     WithAdjustmentReader,
2757     WithTradingSessions,
2758     ZiplineTestCase,
2759 )
2760 from zipline.testing.predicates import assert_equal, assert_raises_regex
2761 from zipline.testing.predicates import assert_frame_equal
2762 from zipline.utils.numpy_utils import datetime64ns_dtype
2763 from</b></font> zipline.utils.numpy_utils import float64_dtype
2764 class Estimates(DataSet):
2765     event_date = Column(dtype=datetime64ns_dtype)
2766     fiscal_quarter = Column(dtype=float64_dtype)
2767     fiscal_year = Column(dtype=float64_dtype)
2768     estimate = Column(dtype=float64_dtype)
2769 class MultipleColumnsEstimates(DataSet):
2770     event_date = Column(dtype=datetime64ns_dtype)
2771     fiscal_quarter = Column(dtype=float64_dtype)
2772     fiscal_year = Column(dtype=float64_dtype)
2773     estimate1 = Column(dtype=float64_dtype)
2774     estimate2 = Column(dtype=float64_dtype)
2775 def QuartersEstimates(announcements_out):
2776     class QtrEstimates(Estimates):
2777         num_announcements = announcements_out
2778         name = Estimates
2779     return QtrEstimates
2780 def MultipleColumnsQuartersEstimates(announcements_out):
2781     class QtrEstimates(MultipleColumnsEstimates):
2782         num_announcements = announcements_out
2783         name = Estimates
2784     return QtrEstimates
2785 def QuartersEstimatesNoNumQuartersAttr(num_qtr):
2786     class QtrEstimates(Estimates):
2787         name = Estimates
2788     return QtrEstimates
2789 def create_expected_df_for_factor_compute(start_date,
2790                                           sids,
2791                                           tuples,
2792                                           end_date):
2793     df = pd.DataFrame(tuples,
2794 <a name="31"></a>                      columns=[SID_FIELD_NAME,
2795                                'estimate',
2796                                'knowledge_date'])
2797     df <font color="#3ea99f"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= df.pivot_table(columns=SID_FIELD_NAME,
2798                         values='estimate',
2799                         index='knowledge_date')
2800     df = df.reindex(
2801         pd.date_range(start_date, end_date)
2802     )
2803     df.</b></font>index = df.index.rename('knowledge_date')
2804     df['at_date'] = end_date.tz_localize('utc')
2805     df = df.set_index(['at_date', df.index.tz_localize('utc')]).ffill()
2806     new_sids = set(sids) - set(df.columns)
2807     df = df.reindex(columns=df.columns.union(new_sids))
2808     return df
2809 class WithEstimates(WithTradingSessions, WithAdjustmentReader):
2810     START_DATE = pd.Timestamp('2014-12-28')
2811     END_DATE = pd.Timestamp('2015-02-04')
2812     @classmethod
2813     def make_loader(cls, events, columns):
2814         raise NotImplementedError('make_loader')
2815     @classmethod
2816     def make_events(cls):
2817         raise NotImplementedError('make_events')
2818     @classmethod
2819     def get_sids(cls):
2820         return cls.events[SID_FIELD_NAME].unique()
2821     @classmethod
2822     def make_columns(cls):
2823         return {
2824             Estimates.event_date: 'event_date',
2825             Estimates.fiscal_quarter: 'fiscal_quarter',
2826             Estimates.fiscal_year: 'fiscal_year',
2827             Estimates.estimate: 'estimate'
2828         }
2829     def make_engine(self, loader=None):
2830         if loader is None:
2831             loader = self.loader
2832         return SimplePipelineEngine(
2833             lambda x: loader,
2834             self.asset_finder,
2835             default_domain=EquitySessionDomain(
2836                 self.trading_days, self.ASSET_FINDER_COUNTRY_CODE,
2837             ),
2838         )
2839     @classmethod
2840     def init_class_fixtures(cls):
2841         cls.events = cls.make_events()
2842         cls.ASSET_FINDER_EQUITY_SIDS = cls.get_sids()
2843         cls.ASSET_FINDER_EQUITY_SYMBOLS = [
2844             's' + str(n) for n in cls.ASSET_FINDER_EQUITY_SIDS
2845         ]
2846         super(WithEstimates, cls).init_class_fixtures()
2847         cls.columns = cls.make_columns()
2848         cls.loader = cls.make_loader(cls.events, {column.name: val for
2849                                                   column, val in
2850                                                   cls.columns.items()})
2851 class WithOneDayPipeline(WithEstimates):
2852     @classmethod
2853     def make_columns(cls):
2854         return {
2855             MultipleColumnsEstimates.event_date: 'event_date',
2856             MultipleColumnsEstimates.fiscal_quarter: 'fiscal_quarter',
2857             MultipleColumnsEstimates.fiscal_year: 'fiscal_year',
2858             MultipleColumnsEstimates.estimate1: 'estimate1',
2859             MultipleColumnsEstimates.estimate2: 'estimate2'
2860         }
2861     @classmethod
2862     def make_events(cls):
2863         return pd.DataFrame({
2864             SID_FIELD_NAME: [0] * 2,
2865             TS_FIELD_NAME: [pd.Timestamp('2015-01-01'),
2866                             pd.Timestamp('2015-01-06')],
2867             EVENT_DATE_FIELD_NAME: [pd.Timestamp('2015-01-10'),
2868                                     pd.Timestamp('2015-01-20')],
2869             'estimate1': [1., 2.],
2870             'estimate2': [3., 4.],
2871             FISCAL_QUARTER_FIELD_NAME: [1, 2],
2872             FISCAL_YEAR_FIELD_NAME: [2015, 2015]
2873         })
2874     @classmethod
2875     def make_expected_out(cls):
2876         raise NotImplementedError('make_expected_out')
2877     @classmethod
2878     def init_class_fixtures(cls):
2879         super(WithOneDayPipeline, cls).init_class_fixtures()
2880         cls.sid0 = cls.asset_finder.retrieve_asset(0)
2881         cls.expected_out = cls.make_expected_out()
2882     def test_load_one_day(self):
2883 <a name="25"></a>        dataset = MultipleColumnsQuartersEstimates(1)
2884         engine = self.make_engine()
2885         results = engine.run_pipeline(
2886             Pipeline<font color="#5eac10"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>({c.name: c.latest for c in dataset.columns}),
2887             start_date=pd.Timestamp('2015-01-15', tz='utc'),
2888             end_date=pd.Timestamp('2015-01-15', tz=</b></font>'utc'),
2889         )
2890         assert_frame_equal(results, self.expected_out)
2891 class PreviousWithOneDayPipeline(WithOneDayPipeline, ZiplineTestCase):
2892     @classmethod
2893     def make_loader(cls, events, columns):
2894         return PreviousEarningsEstimatesLoader(events, columns)
2895     @classmethod
2896     def make_expected_out(cls):
2897         return pd.DataFrame(
2898             {
2899                 EVENT_DATE_FIELD_NAME: pd.Timestamp('2015-01-10'),
2900                 'estimate1': 1.,
2901                 'estimate2': 3.,
2902                 FISCAL_QUARTER_FIELD_NAME: 1.,
2903                 FISCAL_YEAR_FIELD_NAME: 2015.,
2904             },
2905             index=pd.MultiIndex.from_tuples(
2906                 ((pd.Timestamp('2015-01-15', tz='utc'), cls.sid0),)
2907             )
2908         )
2909 class NextWithOneDayPipeline(WithOneDayPipeline, ZiplineTestCase):
2910     @classmethod
2911     def make_loader(cls, events, columns):
2912         return NextEarningsEstimatesLoader(events, columns)
2913     @classmethod
2914     def make_expected_out(cls):
2915         return pd.DataFrame(
2916             {
2917                 EVENT_DATE_FIELD_NAME: pd.Timestamp('2015-01-20'),
2918                 'estimate1': 2.,
2919                 'estimate2': 4.,
2920                 FISCAL_QUARTER_FIELD_NAME: 2.,
2921                 FISCAL_YEAR_FIELD_NAME: 2015.,
2922             },
2923             index=pd.MultiIndex.from_tuples(
2924                 ((pd.Timestamp('2015-01-15', tz='utc'), cls.sid0),)
2925             )
2926         )
2927 dummy_df = pd.DataFrame({SID_FIELD_NAME: 0},
2928                         columns=[SID_FIELD_NAME,
2929                                  TS_FIELD_NAME,
2930                                  EVENT_DATE_FIELD_NAME,
2931                                  FISCAL_QUARTER_FIELD_NAME,
2932                                  FISCAL_YEAR_FIELD_NAME,
2933                                  'estimate'],
2934                         index=[0])
2935 class WithWrongLoaderDefinition(WithEstimates):
2936     @classmethod
2937     def make_events(cls):
2938         return dummy_df
2939     def test_wrong_num_announcements_passed(self):
2940         bad_dataset1 = QuartersEstimates(-1)
2941         bad_dataset2 = QuartersEstimates(-2)
2942         good_dataset = QuartersEstimates(1)
2943         engine = self.make_engine()
2944         columns = {c.name + str(dataset.num_announcements): c.latest
2945                    for dataset in (bad_dataset1,
2946                                    bad_dataset2,
2947                                    good_dataset)
2948                    for c in dataset.columns}
2949         p = Pipeline(columns)
2950         with self.assertRaises(ValueError) as e:
2951             engine.run_pipeline(
2952                 p,
2953                 start_date=self.trading_days[0],
2954                 end_date=self.trading_days[-1],
2955             )
2956             assert_raises_regex(e, INVALID_NUM_QTRS_MESSAGE % "-1,-2")
2957     def test_no_num_announcements_attr(self):
2958         dataset = QuartersEstimatesNoNumQuartersAttr(1)
2959         engine = self.make_engine()
2960         p = Pipeline({c.name: c.latest for c in dataset.columns})
2961         with self.assertRaises(AttributeError):
2962             engine.run_pipeline(
2963                 p,
2964                 start_date=self.trading_days[0],
2965                 end_date=self.trading_days[-1],
2966             )
2967 class PreviousWithWrongNumQuarters(WithWrongLoaderDefinition,
2968                                    ZiplineTestCase):
2969     @classmethod
2970     def make_loader(cls, events, columns):
2971         return PreviousEarningsEstimatesLoader(events, columns)
2972 class NextWithWrongNumQuarters(WithWrongLoaderDefinition,
2973                                ZiplineTestCase):
2974     @classmethod
2975     def make_loader(cls, events, columns):
2976         return NextEarningsEstimatesLoader(events, columns)
2977 options = ["split_adjustments_loader",
2978            "split_adjusted_column_names",
2979            "split_adjusted_asof"]
2980 class WrongSplitsLoaderDefinition(WithEstimates, ZiplineTestCase):
2981     @classmethod
2982     def init_class_fixtures(cls):
2983         super(WithEstimates, cls).init_class_fixtures()
2984     @parameterized.expand(itertools.product(
2985         (NextSplitAdjustedEarningsEstimatesLoader,
2986          PreviousSplitAdjustedEarningsEstimatesLoader),
2987     ))
2988     def test_extra_splits_columns_passed(self, loader):
2989         columns = {
2990             Estimates.event_date: 'event_date',
2991             Estimates.fiscal_quarter: 'fiscal_quarter',
2992             Estimates.fiscal_year: 'fiscal_year',
2993             Estimates.estimate: 'estimate'
2994         }
2995         with self.assertRaises(ValueError):
2996             loader(dummy_df,
2997                    {column.name: val for column, val in
2998                     columns.items()},
2999                    split_adjustments_loader=self.adjustment_reader,
3000                    split_adjusted_column_names=["estimate", "extra_col"],
3001                    split_adjusted_asof=pd.Timestamp("2015-01-01"))
3002 class WithEstimatesTimeZero(WithEstimates):
3003     END_DATE = pd.Timestamp('2015-01-28')
3004     q1_knowledge_dates = [pd.Timestamp('2015-01-01'),
3005                           pd.Timestamp('2015-01-04'),
3006                           pd.Timestamp('2015-01-07'),
3007                           pd.Timestamp('2015-01-11')]
3008     q2_knowledge_dates = [pd.Timestamp('2015-01-14'),
3009                           pd.Timestamp('2015-01-17'),
3010                           pd.Timestamp('2015-01-20'),
3011                           pd.Timestamp('2015-01-23')]
3012     q1_release_dates = [pd.Timestamp('2015-01-13'),
3013                         pd.Timestamp('2015-01-14')]  # One day late
3014     q2_release_dates = [pd.Timestamp('2015-01-25'),  # One day early
3015                         pd.Timestamp('2015-01-26')]
3016     @classmethod
3017     def make_events(cls):
3018         sid_estimates = []
3019         sid_releases = []
3020         it = enumerate(
3021             itertools.permutations(cls.q1_knowledge_dates +
3022                                    cls.q2_knowledge_dates,
3023                                    4)
3024         )
3025         for sid, (q1e1, q1e2, q2e1, q2e2) in it:
3026             if (q1e1 &lt; q1e2 and
3027                     q2e1 &lt; q2e2 and
3028                     q1e1 &lt; cls.q1_release_dates[0] and
3029                     q1e2 &lt; cls.q1_release_dates[0]):
3030                 sid_estimates.append(cls.create_estimates_df(q1e1,
3031                                                              q1e2,
3032                                                              q2e1,
3033                                                              q2e2,
3034                                                              sid))
3035                 sid_releases.append(cls.create_releases_df(sid))
3036         return pd.concat(sid_estimates +
3037                          sid_releases).reset_index(drop=True)
3038     @classmethod
3039     def get_sids(cls):
3040         sids = cls.events[SID_FIELD_NAME].unique()
3041         return list(sids) + [max(sids) + 1]
3042     @classmethod
3043     def create_releases_df(cls, sid):
3044         return pd.DataFrame({
3045             TS_FIELD_NAME: [pd.Timestamp('2015-01-13'),
3046                             pd.Timestamp('2015-01-26')],
3047             EVENT_DATE_FIELD_NAME: [pd.Timestamp('2015-01-13'),
3048                                     pd.Timestamp('2015-01-26')],
3049             'estimate': [0.5, 0.8],
3050             FISCAL_QUARTER_FIELD_NAME: [1.0, 2.0],
3051             FISCAL_YEAR_FIELD_NAME: [2015.0, 2015.0],
3052             SID_FIELD_NAME: sid
3053         })
3054     @classmethod
3055     def create_estimates_df(cls,
3056                             q1e1,
3057                             q1e2,
3058                             q2e1,
3059                             q2e2,
3060                             sid):
3061         return pd.DataFrame({
3062             EVENT_DATE_FIELD_NAME: cls.q1_release_dates + cls.q2_release_dates,
3063             'estimate': [.1, .2, .3, .4],
3064             FISCAL_QUARTER_FIELD_NAME: [1.0, 1.0, 2.0, 2.0],
3065             FISCAL_YEAR_FIELD_NAME: [2015.0, 2015.0, 2015.0, 2015.0],
3066             TS_FIELD_NAME: [q1e1, q1e2, q2e1, q2e2],
3067             SID_FIELD_NAME: sid,
3068         })
3069     def get_expected_estimate(self,
3070                               q1_knowledge,
3071                               q2_knowledge,
3072                               comparable_date):
3073         return pd.DataFrame()
3074     def test_estimates(self):
3075         dataset = QuartersEstimates(1)
3076         engine = self.make_engine()
3077         results = engine.run_pipeline(
3078             Pipeline({c.name: c.latest for c in dataset.columns}),
3079             start_date=self.trading_days[1],
3080             end_date=self.trading_days[-2],
3081         )
3082         for sid in self.ASSET_FINDER_EQUITY_SIDS:
3083             sid_estimates = results.xs(sid, level=1)
3084             if sid == max(self.ASSET_FINDER_EQUITY_SIDS):
3085                 assert_true(sid_estimates.isnull().all().all())
3086             else:
3087                 ts_sorted_estimates = self.events[
3088                     self.events[SID_FIELD_NAME] == sid
3089                 ].sort_values(TS_FIELD_NAME)
3090                 q1_knowledge = ts_sorted_estimates[
3091                     ts_sorted_estimates[FISCAL_QUARTER_FIELD_NAME] == 1
3092                 ]
3093                 q2_knowledge = ts_sorted_estimates[
3094 <a name="26"></a>                    ts_sorted_estimates[FISCAL_QUARTER_FIELD_NAME] == 2
3095                 ]
3096                 all_expected = pd.concat(
3097                     [self<font color="#68818b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.get_expected_estimate(
3098                         q1_knowledge[q1_knowledge[TS_FIELD_NAME] &lt;=
3099                                      date.tz_localize(None)],
3100                         q2_knowledge[q2_knowledge[TS_FIELD_NAME] &lt;=
3101                                      date.tz_localize(None)],
3102                         date.tz_localize(None),
3103                     ).</b></font>set_index([[date]]) for date in sid_estimates.index],
3104                     axis=0)
3105                 assert_equal(all_expected[sid_estimates.columns],
3106                              sid_estimates)
3107 class NextEstimate(WithEstimatesTimeZero, ZiplineTestCase):
3108     @classmethod
3109     def make_loader(cls, events, columns):
3110         return NextEarningsEstimatesLoader(events, columns)
3111     def get_expected_estimate(self,
3112                               q1_knowledge,
3113                               q2_knowledge,
3114                               comparable_date):
3115         if (not q1_knowledge.empty and
3116             q1_knowledge[EVENT_DATE_FIELD_NAME].iloc[-1] &gt;=
3117                 comparable_date):
3118             return q1_knowledge.iloc[-1:]
3119         elif (not q2_knowledge.empty and
3120               q2_knowledge[EVENT_DATE_FIELD_NAME].iloc[-1] &gt;=
3121                 comparable_date):
3122             return q2_knowledge.iloc[-1:]
3123         return pd.DataFrame(columns=q1_knowledge.columns,
3124                             index=[comparable_date])
3125 class BlazeNextEstimateLoaderTestCase(NextEstimate):
3126     @classmethod
3127     def make_loader(cls, events, columns):
3128         return BlazeNextEstimatesLoader(
3129             bz.data(events),
3130             columns,
3131         )
3132 class PreviousEstimate(WithEstimatesTimeZero, ZiplineTestCase):
3133     @classmethod
3134     def make_loader(cls, events, columns):
3135         return PreviousEarningsEstimatesLoader(events, columns)
3136     def get_expected_estimate(self,
3137                               q1_knowledge,
3138                               q2_knowledge,
3139                               comparable_date):
3140         if (not q2_knowledge.empty and
3141             q2_knowledge[EVENT_DATE_FIELD_NAME].iloc[-1] &lt;=
3142                 comparable_date):
3143             return q2_knowledge.iloc[-1:]
3144         elif (not q1_knowledge.empty and
3145               q1_knowledge[EVENT_DATE_FIELD_NAME].iloc[-1] &lt;=
3146                 comparable_date):
3147             return q1_knowledge.iloc[-1:]
3148         return pd.DataFrame(columns=q1_knowledge.columns,
3149                             index=[comparable_date])
3150 class BlazePreviousEstimateLoaderTestCase(PreviousEstimate):
3151     @classmethod
3152     def make_loader(cls, events, columns):
3153         return BlazePreviousEstimatesLoader(
3154             bz.data(events),
3155             columns,
3156         )
3157 class WithEstimateMultipleQuarters(WithEstimates):
3158     @classmethod
3159     def make_events(cls):
3160         return pd.DataFrame({
3161             SID_FIELD_NAME: [0] * 2,
3162             TS_FIELD_NAME: [pd.Timestamp('2015-01-01'),
3163                             pd.Timestamp('2015-01-06')],
3164             EVENT_DATE_FIELD_NAME: [pd.Timestamp('2015-01-10'),
3165                                     pd.Timestamp('2015-01-20')],
3166             'estimate': [1., 2.],
3167             FISCAL_QUARTER_FIELD_NAME: [1, 2],
3168             FISCAL_YEAR_FIELD_NAME: [2015, 2015]
3169         })
3170     @classmethod
3171     def init_class_fixtures(cls):
3172 <a name="17"></a>        super(WithEstimateMultipleQuarters, cls).init_class_fixtures()
3173         cls.expected_out = cls.make_expected_out()
3174     <font color="#3090c7"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>@classmethod
3175     def make_expected_out(cls):
3176         expected = pd.DataFrame(columns=[cls.columns[col] + '1'
3177                                          for col in cls.columns] +
3178                                         [cls.columns[col] + '2'
3179                                          for col in cls.columns],
3180                                 index=cls.</b></font>trading_days)
3181         for (col, raw_name), suffix in itertools.product(
3182             cls.columns.items(), ('1', '2')
3183         ):
3184             expected_name = raw_name + suffix
3185             if col.dtype == datetime64ns_dtype:
3186                 expected[expected_name] = pd.to_datetime(
3187                     expected[expected_name]
3188                 )
3189             else:
3190                 expected[expected_name] = expected[
3191                     expected_name
3192                 ].astype(col.dtype)
3193         cls.fill_expected_out(expected)
3194         return expected.reindex(cls.trading_days)
3195     def test_multiple_qtrs_requested(self):
3196         dataset1 = QuartersEstimates(1)
3197         dataset2 = QuartersEstimates(2)
3198         engine = self.make_engine()
3199 <a name="33"></a>        results = engine.run_pipeline(
3200             Pipeline(
3201                 merge([{c.name + '1': c.latest for c in dataset1.columns},
3202                        {c.name + '2': c<font color="#736aff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.latest for c in dataset2.columns}])
3203             ),
3204             start_date=self.trading_days[0],
3205             end_date=self.trading_days[-1],
3206         )
3207         q1_columns = [col.name + '1' for col in self.columns]
3208         q2_columns =</b></font> [col.name + '2' for col in self.columns]
3209         assert_equal(sorted(np.array(q1_columns + q2_columns)),
3210                      sorted(results.columns.values))
3211         assert_equal(self.expected_out.sort_index(axis=1),
3212                      results.xs(0, level=1).sort_index(axis=1))
3213 class NextEstimateMultipleQuarters(
3214     WithEstimateMultipleQuarters, ZiplineTestCase
3215 ):
3216     @classmethod
3217     def make_loader(cls, events, columns):
3218         return NextEarningsEstimatesLoader(events, columns)
3219     @classmethod
3220     def fill_expected_out(cls, expected):
3221         for raw_name in cls.columns.values():
3222             expected.loc[
3223                 pd.Timestamp('2015-01-01'):pd.Timestamp('2015-01-11'),
3224                 raw_name + '1'
3225             ] = cls.events[raw_name].iloc[0]
3226             expected.loc[
3227                 pd.Timestamp('2015-01-11'):pd.Timestamp('2015-01-20'),
3228                 raw_name + '1'
3229             ] = cls.events[raw_name].iloc[1]
3230         for col_name in ['estimate', 'event_date']:
3231             expected.loc[
3232                 pd.Timestamp('2015-01-06'):pd.Timestamp('2015-01-10'),
3233                 col_name + '2'
3234             ] = cls.events[col_name].iloc[1]
3235         expected.loc[
3236             pd.Timestamp('2015-01-01'):pd.Timestamp('2015-01-09'),
3237             FISCAL_QUARTER_FIELD_NAME + '2'
3238         ] = 2
3239         expected.loc[
3240             pd.Timestamp('2015-01-12'):pd.Timestamp('2015-01-20'),
3241             FISCAL_QUARTER_FIELD_NAME + '2'
3242         ] = 3
3243         expected.loc[
3244             pd.Timestamp('2015-01-01'):pd.Timestamp('2015-01-20'),
3245             FISCAL_YEAR_FIELD_NAME + '2'
3246         ] = 2015
3247         return expected
3248 class BlazeNextEstimateMultipleQuarters(NextEstimateMultipleQuarters):
3249     @classmethod
3250     def make_loader(cls, events, columns):
3251         return BlazeNextEstimatesLoader(
3252             bz.data(events),
3253             columns,
3254         )
3255 class PreviousEstimateMultipleQuarters(
3256     WithEstimateMultipleQuarters,
3257     ZiplineTestCase
3258 ):
3259     @classmethod
3260     def make_loader(cls, events, columns):
3261         return PreviousEarningsEstimatesLoader(events, columns)
3262     @classmethod
3263     def fill_expected_out(cls, expected):
3264         for raw_name in cls.columns.values():
3265             expected[raw_name + '1'].loc[
3266                 pd.Timestamp('2015-01-12'):pd.Timestamp('2015-01-19')
3267             ] = cls.events[raw_name].iloc[0]
3268             expected[raw_name + '1'].loc[
3269                 pd.Timestamp('2015-01-20'):
3270             ] = cls.events[raw_name].iloc[1]
3271         for col_name in ['estimate', 'event_date']:
3272             expected[col_name + '2'].loc[
3273                 pd.Timestamp('2015-01-20'):
3274             ] = cls.events[col_name].iloc[0]
3275         expected[
3276             FISCAL_QUARTER_FIELD_NAME + '2'
3277         ].loc[pd.Timestamp('2015-01-12'):pd.Timestamp('2015-01-20')] = 4
3278         expected[
3279             FISCAL_YEAR_FIELD_NAME + '2'
3280         ].loc[pd.Timestamp('2015-01-12'):pd.Timestamp('2015-01-20')] = 2014
3281         expected[
3282             FISCAL_QUARTER_FIELD_NAME + '2'
3283         ].loc[pd.Timestamp('2015-01-20'):] = 1
3284         expected[
3285             FISCAL_YEAR_FIELD_NAME + '2'
3286         ].loc[pd.Timestamp('2015-01-20'):] = 2015
3287         return expected
3288 class BlazePreviousEstimateMultipleQuarters(PreviousEstimateMultipleQuarters):
3289     @classmethod
3290     def make_loader(cls, events, columns):
3291         return BlazePreviousEstimatesLoader(
3292             bz.data(events),
3293             columns,
3294         )
3295 class WithVaryingNumEstimates(WithEstimates):
3296     @classmethod
3297     def make_events(cls):
3298 <a name="27"></a>        return pd.DataFrame({
3299             SID_FIELD_NAME: [0] * 3 + [1] * 3,
3300             TS_FIELD_NAME: [pd.Timestamp('2015-01-09'),
3301                             pd<font color="#e77471"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.Timestamp('2015-01-12'),
3302                             pd.Timestamp('2015-01-13')] * 2,
3303             EVENT_DATE_FIELD_NAME: [pd.Timestamp('2015-01-12'),
3304                                     pd.Timestamp('2015-01-13'),
3305                                     pd.Timestamp('2015-01-20'),
3306                                     pd.Timestamp(</b></font>'2015-01-13'),
3307                                     pd.Timestamp('2015-01-12'),
3308                                     pd.Timestamp('2015-01-20')],
3309             'estimate': [11., 12., 21.] * 2,
3310             FISCAL_QUARTER_FIELD_NAME: [1, 1, 2] * 2,
3311             FISCAL_YEAR_FIELD_NAME: [2015] * 6
3312         })
3313     @classmethod
3314     def assert_compute(cls, estimate, today):
3315         raise NotImplementedError('assert_compute')
3316     def test_windows_with_varying_num_estimates(self):
3317         dataset = QuartersEstimates(1)
3318         assert_compute = self.assert_compute
3319         class SomeFactor(CustomFactor):
3320             inputs = [dataset.estimate]
3321             window_length = 3
3322             def compute(self, today, assets, out, estimate):
3323                 assert_compute(estimate, today)
3324         engine = self.make_engine()
3325         engine.run_pipeline(
3326             Pipeline({'est': SomeFactor()}),
3327             start_date=pd.Timestamp('2015-01-13', tz='utc'),
3328             end_date=pd.Timestamp('2015-01-14', tz='utc'),
3329         )
3330 class PreviousVaryingNumEstimates(
3331     WithVaryingNumEstimates,
3332     ZiplineTestCase
3333 ):
3334 <a name="20"></a>    def assert_compute(self, estimate, today):
3335         if today == pd.Timestamp('2015-01-13', tz='utc'):
3336             assert_array_equal(estimate[:, 0],
3337                                np.array([np.NaN, np<font color="#4e9258"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.NaN, 12]))
3338             assert_array_equal(estimate[:, 1],
3339                                np.array([np.NaN, 12, 12]))
3340         else:
3341             assert_array_equal(estimate[:, 0],
3342                                np.array([np.NaN, 12, 12]))
3343             assert_array_equal(</b></font>estimate[:, 1],
3344                                np.array([12, 12, 12]))
3345     @classmethod
3346     def make_loader(cls, events, columns):
3347         return PreviousEarningsEstimatesLoader(events, columns)
3348 class BlazePreviousVaryingNumEstimates(PreviousVaryingNumEstimates):
3349     @classmethod
3350     def make_loader(cls, events, columns):
3351         return BlazePreviousEstimatesLoader(
3352             bz.data(events),
3353             columns,
3354         )
3355 class NextVaryingNumEstimates(
3356     WithVaryingNumEstimates,
3357     ZiplineTestCase
3358 ):
3359     def assert_compute(self, estimate, today):
3360         if today == pd.Timestamp('2015-01-13', tz='utc'):
3361             assert_array_equal(estimate[:, 0],
3362                                np.array([11, 12, 12]))
3363             assert_array_equal(estimate[:, 1],
3364                                np.array([np.NaN, np.NaN, 21]))
3365         else:
3366             assert_array_equal(estimate[:, 0],
3367                                np.array([np.NaN, 21, 21]))
3368             assert_array_equal(estimate[:, 1],
3369                                np.array([np.NaN, 21, 21]))
3370     @classmethod
3371     def make_loader(cls, events, columns):
3372         return NextEarningsEstimatesLoader(events, columns)
3373 class BlazeNextVaryingNumEstimates(NextVaryingNumEstimates):
3374     @classmethod
3375     def make_loader(cls, events, columns):
3376         return BlazeNextEstimatesLoader(
3377             bz.data(events),
3378             columns,
3379         )
3380 class WithEstimateWindows(WithEstimates):
3381     END_DATE <font color="#38a4a5"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= pd.Timestamp('2015-02-10')
3382     window_test_start_date = pd.Timestamp('2015-01-05')
3383     critical_dates = [pd.Timestamp('2015-01-09', tz='utc'),
3384                       pd.Timestamp('2015-01-15', tz='utc'),
3385                       pd.Timestamp('2015-01-20', tz='utc'),
3386                       pd.</b></font>Timestamp('2015-01-26', tz='utc'),
3387                       pd.Timestamp('2015-02-05', tz='utc'),
3388                       pd.Timestamp('2015-02-10', tz='utc')]
3389     window_test_cases = list(itertools.product(critical_dates, (1, 2)))
3390     @classmethod
3391     def make_events(cls):
3392         sid_0_timeline = pd.DataFrame({
3393             TS_FIELD_NAME: [cls.window_test_start_date,
3394                             pd.Timestamp('2015-01-20'),
3395                             pd.Timestamp('2015-01-12'),
3396                             pd.Timestamp('2015-02-10'),
3397                             pd.Timestamp('2015-01-18')],
3398             EVENT_DATE_FIELD_NAME:
3399                 [pd.Timestamp('2015-01-20'),
3400                  pd.Timestamp('2015-01-20'),
3401                  pd.Timestamp('2015-02-10'),
3402                  pd.Timestamp('2015-02-10'),
3403                  pd.Timestamp('2015-04-01')],
3404             'estimate': [100., 101.] + [200., 201.] + [400],
3405             FISCAL_QUARTER_FIELD_NAME: [1] * 2 + [2] * 2 + [4],
3406             FISCAL_YEAR_FIELD_NAME: 2015,
3407             SID_FIELD_NAME: 0,
3408         })
3409         sid_10_timeline = pd.DataFrame({
3410             TS_FIELD_NAME: [pd.Timestamp('2015-01-09'),
3411                             pd.Timestamp('2015-01-12'),
3412                             pd.Timestamp('2015-01-09'),
3413                             pd.Timestamp('2015-01-15')],
3414             EVENT_DATE_FIELD_NAME:
3415                 [pd.Timestamp('2015-01-22'), pd.Timestamp('2015-01-22'),
3416                  pd.Timestamp('2015-02-05'), pd.Timestamp('2015-02-05')],
3417             'estimate': [110., 111.] + [310., 311.],
3418             FISCAL_QUARTER_FIELD_NAME: [1] * 2 + [3] * 2,
3419             FISCAL_YEAR_FIELD_NAME: 2015,
3420             SID_FIELD_NAME: 10
3421         })
3422         sid_20_timeline = pd.DataFrame({
3423             TS_FIELD_NAME: [cls.window_test_start_date,
3424                             pd.Timestamp('2015-01-07'),
3425                             cls.window_test_start_date,
3426                             pd.Timestamp('2015-01-17')],
3427             EVENT_DATE_FIELD_NAME:
3428                 [pd.Timestamp('2015-01-20'),
3429                  pd.Timestamp('2015-01-20'),
3430                  pd.Timestamp('2015-02-10'),
3431                  pd.Timestamp('2015-02-10')],
3432             'estimate': [120., 121.] + [220., 221.],
3433             FISCAL_QUARTER_FIELD_NAME: [1] * 2 + [2] * 2,
3434             FISCAL_YEAR_FIELD_NAME: 2015,
3435             SID_FIELD_NAME: 20
3436         })
3437         concatted = pd.concat([sid_0_timeline,
3438                                sid_10_timeline,
3439                                sid_20_timeline]).reset_index()
3440         np.random.seed(0)
3441         return concatted.reindex(np.random.permutation(concatted.index))
3442     @classmethod
3443     def get_sids(cls):
3444         sids = sorted(cls.events[SID_FIELD_NAME].unique())
3445         return [sid for i in range(len(sids) - 1)
3446                 for sid in range(sids[i], sids[i+1])] + [sids[-1]]
3447     @classmethod
3448     def make_expected_timelines(cls):
3449         return {}
3450     @classmethod
3451     def init_class_fixtures(cls):
3452         super(WithEstimateWindows, cls).init_class_fixtures()
3453         cls.create_expected_df_for_factor_compute = partial(
3454             create_expected_df_for_factor_compute,
3455             cls.window_test_start_date,
3456             cls.get_sids()
3457         )
3458         cls.timelines = cls.make_expected_timelines()
3459     @parameterized.expand(window_test_cases)
3460     def test_estimate_windows_at_quarter_boundaries(self,
3461                                                     start_date,
3462                                                     num_announcements_out):
3463         dataset = QuartersEstimates(num_announcements_out)
3464         trading_days = self.trading_days
3465         timelines = self.timelines
3466         window_len = (
3467             self.trading_days.get_loc(start_date) -
3468             self.trading_days.get_loc(self.window_test_start_date) + 1
3469         )
3470         class SomeFactor(CustomFactor):
3471             inputs = [dataset.estimate]
3472             window_length = window_len
3473             def compute(self, today, assets, out, estimate):
3474                 today_idx = trading_days.get_loc(today)
3475                 today_timeline = timelines[
3476                     num_announcements_out
3477                 ].loc[today].reindex(
3478                     trading_days[:today_idx + 1]
3479                 ).values
3480                 timeline_start_idx = (len(today_timeline) - window_len)
3481                 assert_almost_equal(estimate,
3482                                     today_timeline[timeline_start_idx:])
3483         engine = self.make_engine()
3484         engine.run_pipeline(
3485             Pipeline({'est': SomeFactor()}),
3486             start_date=start_date,
3487             end_date=pd.Timestamp('2015-02-10', tz='utc'),
3488         )
3489 class PreviousEstimateWindows(WithEstimateWindows, ZiplineTestCase):
3490     @classmethod
3491     def make_loader(cls, events, columns):
3492         return PreviousEarningsEstimatesLoader(events, columns)
3493     @classmethod
3494 <a name="29"></a>    def make_expected_timelines(cls):
3495         oneq_previous = pd.concat([
3496             pd.concat([
3497                 <font color="#af7a82"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>cls.create_expected_df_for_factor_compute([
3498                     (0, np.NaN, cls.window_test_start_date),
3499                     (10, np.NaN, cls.window_test_start_date),
3500                     (20, np.</b></font>NaN, cls.window_test_start_date)
3501                 ], end_date)
3502                 for end_date in pd.date_range('2015-01-09', '2015-01-19')
3503             ]),
3504 <a name="21"></a>            cls.create_expected_df_for_factor_compute(
3505                 [(0, 101, pd.Timestamp('2015-01-20')),
3506                  (10, np.NaN, cls.window_test_start_date),
3507                  (20, 121, pd.Timestamp<font color="#947010"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>('2015-01-20'))],
3508                 pd.Timestamp('2015-01-20')
3509             ),
3510             cls.create_expected_df_for_factor_compute(
3511                 [(0, 101, pd.Timestamp('2015-01-20')),
3512                  (10, np.NaN, cls.window_test_start_date),
3513                  (20</b></font>, 121, pd.Timestamp('2015-01-20'))],
3514                 pd.Timestamp('2015-01-21')
3515             ),
3516             pd.concat([
3517                 cls.create_expected_df_for_factor_compute(
3518                     [(0, 101, pd.Timestamp('2015-01-20')),
3519                      (10, 111, pd.Timestamp('2015-01-22')),
3520                      (20, 121, pd.Timestamp('2015-01-20'))],
3521                     end_date
3522                 ) for end_date in pd.date_range('2015-01-22', '2015-02-04')
3523             ]),
3524             pd.concat([
3525                 cls.create_expected_df_for_factor_compute(
3526                     [(0, 101, pd.Timestamp('2015-01-20')),
3527                      (10, 311, pd.Timestamp('2015-02-05')),
3528                      (20, 121, pd.Timestamp('2015-01-20'))],
3529                     end_date
3530                 ) for end_date in pd.date_range('2015-02-05', '2015-02-09')
3531                 ]),
3532             cls.create_expected_df_for_factor_compute(
3533                 [(0, 201, pd.Timestamp('2015-02-10')),
3534                  (10, 311, pd.Timestamp('2015-02-05')),
3535                  (20, 221, pd.Timestamp('2015-02-10'))],
3536                 pd.Timestamp('2015-02-10')
3537             ),
3538         ])
3539         twoq_previous = pd.concat(
3540 <a name="4"></a>            [cls.create_expected_df_for_factor_compute(
3541                 [(0, np.NaN, cls.window_test_start_date),
3542                  (10, np.NaN, cls.window_test_start_date),
3543                  (20, np<font color="#6cc417"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.NaN, cls.window_test_start_date)],
3544                 end_date
3545             ) for end_date in pd.date_range('2015-01-09', '2015-02-09')] +
3546             [cls.create_expected_df_for_factor_compute(
3547                 [(0, 101, pd.Timestamp('2015-02-10')),
3548                  (10, np.NaN, pd.Timestamp('2015-02-05')),
3549                  (20, 121, pd.Timestamp('2015-02-10'))],
3550                 pd.</b></font>Timestamp('2015-02-10')
3551             )]
3552         )
3553         return {
3554             1: oneq_previous,
3555             2: twoq_previous
3556         }
3557 class BlazePreviousEstimateWindows(PreviousEstimateWindows):
3558     @classmethod
3559     def make_loader(cls, events, columns):
3560         return BlazePreviousEstimatesLoader(bz.data(events), columns)
3561 class NextEstimateWindows(WithEstimateWindows, ZiplineTestCase):
3562     @classmethod
3563     def make_loader(cls, events, columns):
3564         return NextEarningsEstimatesLoader(events, columns)
3565     @classmethod
3566     def make_expected_timelines(cls):
3567         oneq_next = pd.concat([
3568             cls.create_expected_df_for_factor_compute(
3569                 [(0, 100, cls.window_test_start_date),
3570                  (10, 110, pd.Timestamp('2015-01-09')),
3571                  (20, 120, cls.window_test_start_date),
3572                  (20, 121, pd.Timestamp('2015-01-07'))],
3573                 pd.Timestamp('2015-01-09')
3574             ),
3575             pd.concat([
3576                 cls.create_expected_df_for_factor_compute(
3577                     [(0, 100, cls.window_test_start_date),
3578                      (10, 110, pd.Timestamp('2015-01-09')),
3579                      (10, 111, pd.Timestamp('2015-01-12')),
3580                      (20, 120, cls.window_test_start_date),
3581                      (20, 121, pd.Timestamp('2015-01-07'))],
3582                     end_date
3583                 ) for end_date in pd.date_range('2015-01-12', '2015-01-19')
3584             ]),
3585             cls.create_expected_df_for_factor_compute(
3586                 [(0, 100, cls.window_test_start_date),
3587                  (0, 101, pd.Timestamp('2015-01-20')),
3588                  (10, 110, pd.Timestamp('2015-01-09')),
3589                  (10, 111, pd.Timestamp('2015-01-12')),
3590                  (20, 120, cls.window_test_start_date),
3591                  (20, 121, pd.Timestamp('2015-01-07'))],
3592                 pd.Timestamp('2015-01-20')
3593             ),
3594             pd.concat([
3595                 cls.create_expected_df_for_factor_compute(
3596                     [(0, 200, pd.Timestamp('2015-01-12')),
3597                      (10, 110, pd.Timestamp('2015-01-09')),
3598                      (10, 111, pd.Timestamp('2015-01-12')),
3599                      (20, 220, cls.window_test_start_date),
3600                      (20, 221, pd.Timestamp('2015-01-17'))],
3601                     end_date
3602                 ) for end_date in pd.date_range('2015-01-21', '2015-01-22')
3603             ]),
3604             pd.concat([
3605                 cls.create_expected_df_for_factor_compute(
3606                     [(0, 200, pd.Timestamp('2015-01-12')),
3607                      (10, 310, pd.Timestamp('2015-01-09')),
3608                      (10, 311, pd.Timestamp('2015-01-15')),
3609                      (20, 220, cls.window_test_start_date),
3610                      (20, 221, pd.Timestamp('2015-01-17'))],
3611                     end_date
3612                 ) for end_date in pd.date_range('2015-01-23', '2015-02-05')
3613             ]),
3614             pd.concat([
3615                 cls.create_expected_df_for_factor_compute(
3616                     [(0, 200, pd.Timestamp('2015-01-12')),
3617                      (10, np.NaN, cls.window_test_start_date),
3618                      (20, 220, cls.window_test_start_date),
3619                      (20, 221, pd.Timestamp('2015-01-17'))],
3620                     end_date
3621                 ) for end_date in pd.date_range('2015-02-06', '2015-02-09')
3622             ]),
3623             cls.create_expected_df_for_factor_compute(
3624                 [(0, 200, pd.Timestamp('2015-01-12')),
3625                  (0, 201, pd.Timestamp('2015-02-10')),
3626                  (10, np.NaN, cls.window_test_start_date),
3627                  (20, 220, cls.window_test_start_date),
3628                  (20, 221, pd.Timestamp('2015-01-17'))],
3629                 pd.Timestamp('2015-02-10')
3630             )
3631         ])
3632         twoq_next = pd.concat(
3633             [cls.create_expected_df_for_factor_compute(
3634                 [(0, np.NaN, cls.window_test_start_date),
3635                  (10, np.NaN, cls.window_test_start_date),
3636 <a name="13"></a>                 (20, 220, cls.window_test_start_date)],
3637                 end_date
3638             ) for end_date in pd.date_range('2015-01-09', '2015-01-11')] +
3639             [<font color="#3b9c9c"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>cls.create_expected_df_for_factor_compute(
3640                 [(0, 200, pd.Timestamp('2015-01-12')),
3641                  (10, np.NaN, cls.window_test_start_date),
3642                  (20, 220, cls.window_test_start_date)],
3643                 end_date
3644             ) for end_date in pd.date_range('2015-01-12', '2015-01-16')] +
3645             [cls.</b></font>create_expected_df_for_factor_compute(
3646                 [(0, 200, pd.Timestamp('2015-01-12')),
3647                  (10, np.NaN, cls.window_test_start_date),
3648                  (20, 220, cls.window_test_start_date),
3649                  (20, 221, pd.Timestamp('2015-01-17'))],
3650                 pd.Timestamp('2015-01-20')
3651             )] +
3652             [cls.create_expected_df_for_factor_compute(
3653                 [(0, np.NaN, cls.window_test_start_date),
3654                  (10, np.NaN, cls.window_test_start_date),
3655                  (20, np.NaN, cls.window_test_start_date)],
3656                 end_date
3657             ) for end_date in pd.date_range('2015-01-21', '2015-02-10')]
3658         )
3659         return {
3660             1: oneq_next,
3661             2: twoq_next
3662         }
3663 class BlazeNextEstimateWindows(NextEstimateWindows):
3664     @classmethod
3665     def make_loader(cls, events, columns):
3666         return BlazeNextEstimatesLoader(bz.data(events), columns)
3667 class WithSplitAdjustedWindows(WithEstimateWindows):
3668     split_adjusted_asof_date = pd.Timestamp('2015-01-14')
3669     @classmethod
3670     def make_events(cls):
3671         sid_30 = pd.DataFrame({
3672             TS_FIELD_NAME: [cls.window_test_start_date,
3673                             pd.Timestamp('2015-01-09'),
3674                             cls.window_test_start_date,
3675                             pd.Timestamp('2015-01-20')],
3676             EVENT_DATE_FIELD_NAME:
3677                 [pd.Timestamp('2015-01-09'),
3678                  pd.Timestamp('2015-01-09'),
3679                  pd.Timestamp('2015-01-20'),
3680                  pd.Timestamp('2015-01-20')],
3681             'estimate': [130., 131., 230., 231.],
3682             FISCAL_QUARTER_FIELD_NAME: [1] * 2 + [2] * 2,
3683             FISCAL_YEAR_FIELD_NAME: 2015,
3684             SID_FIELD_NAME: 30
3685         })
3686         sid_40 = pd.DataFrame({
3687             TS_FIELD_NAME: [pd<font color="#5b8daf"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.Timestamp('2015-01-09'),
3688                             pd.Timestamp('2015-01-15')],
3689             EVENT_DATE_FIELD_NAME: [pd.Timestamp('2015-01-09'),
3690                                     pd.Timestamp('2015-02-10')],
3691             'estimate': [140., 240.],
3692             FISCAL_QUARTER_FIELD_NAME: [1, 2],
3693             FISCAL_YEAR_FIELD_NAME: 2015,
3694             SID_FIELD_NAME: 40
3695         })
3696         sid_50 =</b></font> pd.DataFrame({
3697             TS_FIELD_NAME: [pd.Timestamp('2015-01-09'),
3698                             pd.Timestamp('2015-01-12')],
3699             EVENT_DATE_FIELD_NAME: [pd.Timestamp('2015-01-09'),
3700                                     pd.Timestamp('2015-02-10')],
3701             'estimate': [150., 250.],
3702             FISCAL_QUARTER_FIELD_NAME: [1, 2],
3703             FISCAL_YEAR_FIELD_NAME: 2015,
3704             SID_FIELD_NAME: 50
3705         })
3706         return pd.concat([
3707             cls.__base__.make_events(),
3708             sid_30,
3709             sid_40,
3710             sid_50,
3711         ])
3712     @classmethod
3713     def make_splits_data(cls):
3714 <a name="16"></a>        sid_0_splits = pd.DataFrame({
3715             SID_FIELD_NAME: 0,
3716             'ratio': (-1., 2., 3., 4., 5., 6., 7., 100),
3717             'effective_date': (pd<font color="#2981b2"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.Timestamp('2014-01-01'),  # Filter out
3718                                pd.Timestamp('2015-01-07'),
3719                                pd.Timestamp('2015-01-09'),
3720                                pd.Timestamp('2015-01-13'),
3721                                pd.Timestamp('2015-01-15'),
3722                                pd.Timestamp('2015-01-18'),
3723                                pd.Timestamp(</b></font>'2015-01-30'),
3724                                pd.Timestamp('2016-01-01'))
3725         })
3726         sid_10_splits = pd.DataFrame({
3727             SID_FIELD_NAME: 10,
3728             'ratio': (.2, .3),
3729             'effective_date': (
3730                 pd.Timestamp('2015-01-07'),
3731                 pd.Timestamp('2015-01-20')),
3732         })
3733         sid_20_splits = pd.DataFrame({
3734             SID_FIELD_NAME: 20,
3735             'ratio': (.4, .5, .6, .7, .8, .9,),
3736             'effective_date': (
3737                 pd.Timestamp('2015-01-07'),
3738                 pd.Timestamp('2015-01-09'),
3739                 pd.Timestamp('2015-01-13'),
3740                 pd.Timestamp('2015-01-15'),
3741                 pd.Timestamp('2015-01-18'),
3742                 pd.Timestamp('2015-01-30')),
3743         })
3744         sid_30_splits = pd.DataFrame({
3745             SID_FIELD_NAME: 30,
3746             'ratio': (8, 9, 10, 11, 12),
3747             'effective_date': (
3748                 pd.Timestamp('2015-01-07'),
3749                 pd.Timestamp('2015-01-09'),
3750                 pd.Timestamp('2015-01-13'),
3751                 pd.Timestamp('2015-01-15'),
3752                 pd.Timestamp('2015-01-18')),
3753         })
3754         sid_40_splits = pd.DataFrame({
3755             SID_FIELD_NAME: 40,
3756             'ratio': (13, 14),
3757             'effective_date': (
3758                 pd.Timestamp('2015-01-20'),
3759                 pd.Timestamp('2015-01-22')
3760             )
3761         })
3762         sid_50_splits = pd.DataFrame({
3763             SID_FIELD_NAME: 50,
3764             'ratio': (15, 16),
3765             'effective_date': (
3766                 pd.Timestamp('2015-01-13'),
3767                 pd.Timestamp('2015-01-14')
3768             )
3769         })
3770         return pd.concat([
3771             sid_0_splits,
3772             sid_10_splits,
3773             sid_20_splits,
3774             sid_30_splits,
3775             sid_40_splits,
3776             sid_50_splits,
3777         ])
3778 class PreviousWithSplitAdjustedWindows(WithSplitAdjustedWindows,
3779                                        ZiplineTestCase):
3780     @classmethod
3781     def make_loader(cls, events, columns):
3782         return PreviousSplitAdjustedEarningsEstimatesLoader(
3783             events,
3784             columns,
3785             split_adjustments_loader=cls.adjustment_reader,
3786             split_adjusted_column_names=['estimate'],
3787             split_adjusted_asof=cls.split_adjusted_asof_date,
3788         )
3789     @classmethod
3790     def make_expected_timelines(cls):
3791 <a name="35"></a>        oneq_previous = pd.concat([
3792             pd.concat([
3793                 cls.create_expected_df_for_factor_compute([
3794                     <font color="#41a317"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(0, np.NaN, cls.window_test_start_date),
3795                     (10, np.NaN, cls.window_test_start_date),
3796                     (20, np.NaN, cls.window_test_start_date),
3797                     (30, 131*1/10, pd.</b></font>Timestamp('2015-01-09')),
3798                     (40, 140., pd.Timestamp('2015-01-09')),
3799                     (50, 150 * 1 / 15 * 1 / 16, pd.Timestamp('2015-01-09')),
3800                 ], end_date)
3801 <a name="34"></a>                for end_date in pd.date_range('2015-01-09', '2015-01-12')
3802             ]),
3803             cls.create_expected_df_for_factor_compute([
3804                 <font color="#827d6b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(0, np.NaN, cls.window_test_start_date),
3805                 (10, np.NaN, cls.window_test_start_date),
3806                 (20, np.NaN, cls.window_test_start_date),
3807                 (30, 131, pd.</b></font>Timestamp('2015-01-09')),
3808                 (40, 140., pd.Timestamp('2015-01-09')),
3809                 (50, 150. * 1 / 16, pd.Timestamp('2015-01-09')),
3810             ], pd.Timestamp('2015-01-13')),
3811             cls.create_expected_df_for_factor_compute([
3812                 (0, np.NaN, cls.window_test_start_date),
3813                 (10, np.NaN, cls.window_test_start_date),
3814                 (20, np.NaN, cls.window_test_start_date),
3815                 (30, 131, pd.Timestamp('2015-01-09')),
3816                 (40, 140., pd.Timestamp('2015-01-09')),
3817                 (50, 150., pd.Timestamp('2015-01-09'))
3818             ], pd.Timestamp('2015-01-14')),
3819             pd.concat([
3820                 cls.create_expected_df_for_factor_compute([
3821                     (0, np.NaN, cls.window_test_start_date),
3822                     (10, np.NaN, cls.window_test_start_date),
3823                     (20, np.NaN, cls.window_test_start_date),
3824                     (30, 131*11, pd.Timestamp('2015-01-09')),
3825                     (40, 140., pd.Timestamp('2015-01-09')),
3826                     (50, 150., pd.Timestamp('2015-01-09')),
3827                 ], end_date)
3828                 for end_date in pd.date_range('2015-01-15', '2015-01-16')
3829             ]),
3830             pd.concat([
3831                 cls.create_expected_df_for_factor_compute(
3832                     [(0, 101, pd.Timestamp('2015-01-20')),
3833                      (10, np.NaN, cls.window_test_start_date),
3834                      (20, 121*.7*.8, pd.Timestamp('2015-01-20')),
3835                      (30, 231, pd.Timestamp('2015-01-20')),
3836                      (40, 140.*13, pd.Timestamp('2015-01-09')),
3837                      (50, 150., pd.Timestamp('2015-01-09'))],
3838                     end_date
3839                 ) for end_date in pd.date_range('2015-01-20', '2015-01-21')
3840 <a name="28"></a>            ]),
3841             pd.concat([
3842                 cls.create_expected_df_for_factor_compute(
3843                     [(0, 101, pd.Timestamp<font color="#717d7d"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>('2015-01-20')),
3844                      (10, 111*.3, pd.Timestamp('2015-01-22')),
3845                      (20, 121*.7*.8, pd.Timestamp('2015-01-20')),
3846                      (30, 231, pd.Timestamp('2015-01-20')),
3847                      (40, 140.*13*14, pd.Timestamp(</b></font>'2015-01-09')),
3848                      (50, 150., pd.Timestamp('2015-01-09'))],
3849                     end_date
3850                 ) for end_date in pd.date_range('2015-01-22', '2015-01-29')
3851             ]),
3852             pd.concat([
3853                 cls.create_expected_df_for_factor_compute(
3854                     [(0, 101*7, pd.Timestamp('2015-01-20')),
3855                      (10, 111*.3, pd.Timestamp('2015-01-22')),
3856                      (20, 121*.7*.8*.9, pd.Timestamp('2015-01-20')),
3857                      (30, 231, pd.Timestamp('2015-01-20')),
3858                      (40, 140.*13*14, pd.Timestamp('2015-01-09')),
3859                      (50, 150., pd.Timestamp('2015-01-09'))],
3860                     end_date
3861                 ) for end_date in pd.date_range('2015-01-30', '2015-02-04')
3862             ]),
3863             pd.concat([
3864                 cls.create_expected_df_for_factor_compute(
3865                     [(0, 101*7, pd.Timestamp('2015-01-20')),
3866                      (10, 311*.3, pd.Timestamp('2015-02-05')),
3867                      (20, 121*.7*.8*.9, pd.Timestamp('2015-01-20')),
3868                      (30, 231, pd.Timestamp('2015-01-20')),
3869                      (40, 140.*13*14, pd.Timestamp('2015-01-09')),
3870                      (50, 150., pd.Timestamp('2015-01-09'))],
3871                     end_date
3872                 ) for end_date in pd.date_range('2015-02-05', '2015-02-09')
3873                 ]),
3874             cls.create_expected_df_for_factor_compute(
3875                 [(0, 201, pd.Timestamp('2015-02-10')),
3876                  (10, 311*.3, pd.Timestamp('2015-02-05')),
3877                  (20, 221*.8*.9, pd.Timestamp('2015-02-10')),
3878                  (30, 231, pd.Timestamp('2015-01-20')),
3879                  (40, 240.*13*14, pd.Timestamp('2015-02-10')),
3880                  (50, 250., pd.Timestamp('2015-02-10'))],
3881                 pd.Timestamp('2015-02-10')
3882             ),
3883 <a name="10"></a>        ])
3884         twoq_previous = pd.concat(
3885             [<font color="#ad5910"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>cls.create_expected_df_for_factor_compute(
3886                 [(0, np.NaN, cls.window_test_start_date),
3887                  (10, np.NaN, cls.window_test_start_date),
3888                  (20, np.NaN, cls.window_test_start_date),
3889                  (30, np.NaN, cls.window_test_start_date)],
3890                 end_date
3891             ) for end_date in pd.</b></font>date_range('2015-01-09', '2015-01-19')] +
3892             [cls.create_expected_df_for_factor_compute(
3893                 [(0, np.NaN, cls.window_test_start_date),
3894                  (10, np.NaN, cls.window_test_start_date),
3895                  (20, np.NaN, cls.window_test_start_date),
3896                  (30, 131*11*12, pd.Timestamp('2015-01-20'))],
3897                 end_date
3898             ) for end_date in pd.date_range('2015-01-20', '2015-02-09')] +
3899             [cls.create_expected_df_for_factor_compute(
3900                 [(0, 101*7, pd.Timestamp('2015-02-10')),
3901                  (10, np.NaN, pd.Timestamp('2015-02-05')),
3902                  (20, 121*.7*.8*.9, pd.Timestamp('2015-02-10')),
3903                  (30, 131*11*12, pd.Timestamp('2015-01-20')),
3904                  (40, 140. * 13 * 14, pd.Timestamp('2015-02-10')),
3905                  (50, 150., pd.Timestamp('2015-02-10'))],
3906                 pd.Timestamp('2015-02-10')
3907             )]
3908         )
3909         return {
3910             1: oneq_previous,
3911             2: twoq_previous
3912         }
3913 class BlazePreviousWithSplitAdjustedWindows(PreviousWithSplitAdjustedWindows):
3914     @classmethod
3915     def make_loader(cls, events, columns):
3916         return BlazePreviousSplitAdjustedEstimatesLoader(
3917             bz.data(events),
3918             columns,
3919             split_adjustments_loader=cls.adjustment_reader,
3920             split_adjusted_column_names=['estimate'],
3921             split_adjusted_asof=cls.split_adjusted_asof_date,
3922         )
3923 class NextWithSplitAdjustedWindows(WithSplitAdjustedWindows, ZiplineTestCase):
3924     @classmethod
3925     def make_loader(cls, events, columns):
3926         return NextSplitAdjustedEarningsEstimatesLoader(
3927             events,
3928             columns,
3929             split_adjustments_loader=cls.adjustment_reader,
3930             split_adjusted_column_names=['estimate'],
3931             split_adjusted_asof=cls.split_adjusted_asof_date,
3932         )
3933     @classmethod
3934 <a name="8"></a>    def make_expected_timelines(cls):
3935         oneq_next = pd.concat([
3936             cls.create_expected_df_for_factor_compute(
3937                 [(<font color="#c58917"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>0, 100*1/4, cls.window_test_start_date),
3938                  (10, 110, pd.Timestamp('2015-01-09')),
3939                  (20, 120*5/3, cls.window_test_start_date),
3940                  (20, 121*5/3, pd.Timestamp('2015-01-07')),
3941                  (30, 130*1/10, cls.window_test_start_date),
3942                  (30, 131*1/10, pd.Timestamp('2015-01-09')),
3943                  (40, 140, pd.</b></font>Timestamp('2015-01-09')),
3944                  (50, 150.*1/15*1/16, pd.Timestamp('2015-01-09'))],
3945                 pd.Timestamp('2015-01-09')
3946             ),
3947             cls.create_expected_df_for_factor_compute(
3948                 [(0, 100*1/4, cls.window_test_start_date),
3949                  (10, 110, pd.Timestamp('2015-01-09')),
3950                  (10, 111, pd.Timestamp('2015-01-12')),
3951                  (20, 120*5/3, cls.window_test_start_date),
3952                  (20, 121*5/3, pd.Timestamp('2015-01-07')),
3953                  (30, 230*1/10, cls.window_test_start_date),
3954                  (40, np.NaN, pd.Timestamp('2015-01-10')),
3955                  (50, 250.*1/15*1/16, pd.Timestamp('2015-01-12'))],
3956                 pd.Timestamp('2015-01-12')
3957             ),
3958             cls.create_expected_df_for_factor_compute(
3959                 [(0, 100, cls.window_test_start_date),
3960                  (10, 110, pd.Timestamp('2015-01-09')),
3961                  (10, 111, pd.Timestamp('2015-01-12')),
3962                  (20, 120, cls.window_test_start_date),
3963                  (20, 121, pd.Timestamp('2015-01-07')),
3964                  (30, 230, cls.window_test_start_date),
3965                  (40, np.NaN, pd.Timestamp('2015-01-10')),
3966                  (50, 250.*1/16, pd.Timestamp('2015-01-12'))],
3967                 pd.Timestamp('2015-01-13')
3968             ),
3969             cls.create_expected_df_for_factor_compute(
3970                 [(0, 100, cls.window_test_start_date),
3971                  (10, 110, pd.Timestamp('2015-01-09')),
3972                  (10, 111, pd.Timestamp('2015-01-12')),
3973                  (20, 120, cls.window_test_start_date),
3974                  (20, 121, pd.Timestamp('2015-01-07')),
3975                  (30, 230, cls.window_test_start_date),
3976                  (40, np.NaN, pd.Timestamp('2015-01-10')),
3977                  (50, 250., pd.Timestamp('2015-01-12'))],
3978                 pd.Timestamp('2015-01-14')
3979             ),
3980             pd.concat([
3981 <a name="18"></a>                cls.create_expected_df_for_factor_compute(
3982                     [(0, 100*5, cls.window_test_start_date),
3983                      (10, 110, pd.Timestamp('2015-01-09')),
3984                      (10, 111, pd<font color="#800517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.Timestamp('2015-01-12')),
3985                      (20, 120*.7, cls.window_test_start_date),
3986                      (20, 121*.7, pd.Timestamp('2015-01-07')),
3987                      (30, 230*11, cls.window_test_start_date),
3988                      (40, 240, pd.Timestamp('2015-01-15')),
3989                      (50, 250., pd.</b></font>Timestamp('2015-01-12'))],
3990                     end_date
3991                 ) for end_date in pd.date_range('2015-01-15', '2015-01-16')
3992 <a name="5"></a>            ]),
3993             cls.create_expected_df_for_factor_compute(
3994                 [(0, 100*5*6, cls.window_test_start_date),
3995                  (<font color="#151b8d"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>0, 101, pd.Timestamp('2015-01-20')),
3996                  (10, 110*.3, pd.Timestamp('2015-01-09')),
3997                  (10, 111*.3, pd.Timestamp('2015-01-12')),
3998                  (20, 120*.7*.8, cls.window_test_start_date),
3999                  (20, 121*.7*.8, pd.Timestamp('2015-01-07')),
4000                  (30, 230*11*12, cls.window_test_start_date),
4001                  (30, 231, pd.</b></font>Timestamp('2015-01-20')),
4002                  (40, 240*13, pd.Timestamp('2015-01-15')),
4003                  (50, 250., pd.Timestamp('2015-01-12'))],
4004 <a name="11"></a>                pd.Timestamp('2015-01-20')
4005             ),
4006             cls.create_expected_df_for_factor_compute(
4007                 [(<font color="#b041ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>0, 200 * 5 * 6, pd.Timestamp('2015-01-12')),
4008                  (10, 110 * .3, pd.Timestamp('2015-01-09')),
4009                  (10, 111 * .3, pd.Timestamp('2015-01-12')),
4010                  (20, 220 * .7 * .8, cls.window_test_start_date),
4011                  (20, 221 * .8, pd.Timestamp('2015-01-17')),
4012                  (40, 240 * 13, pd.</b></font>Timestamp('2015-01-15')),
4013                  (50, 250., pd.Timestamp('2015-01-12'))],
4014                 pd.Timestamp('2015-01-21')
4015 <a name="15"></a>            ),
4016             cls.create_expected_df_for_factor_compute(
4017                 [(0, 200 * 5 * 6, pd.Timestamp('2015-01-12')),
4018                  (10, 110 * .3, pd<font color="#f52887"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.Timestamp('2015-01-09')),
4019                  (10, 111 * .3, pd.Timestamp('2015-01-12')),
4020                  (20, 220 * .7 * .8, cls.window_test_start_date),
4021                  (20, 221 * .8, pd.Timestamp('2015-01-17')),
4022                  (40, 240 * 13 * 14, pd.Timestamp('2015-01-15')),
4023                  (50, 250., pd.</b></font>Timestamp('2015-01-12'))],
4024                 pd.Timestamp('2015-01-22')
4025             ),
4026             pd.concat([
4027                 cls.create_expected_df_for_factor_compute(
4028                     [(0, 200*5*6, pd.Timestamp('2015-01-12')),
4029                      (10, 310*.3, pd.Timestamp('2015-01-09')),
4030                      (10, 311*.3, pd.Timestamp('2015-01-15')),
4031                      (20, 220*.7*.8, cls.window_test_start_date),
4032                      (20, 221*.8, pd.Timestamp('2015-01-17')),
4033                      (40, 240 * 13 * 14, pd.Timestamp('2015-01-15')),
4034                      (50, 250., pd.Timestamp('2015-01-12'))],
4035                     end_date
4036                 ) for end_date in pd.date_range('2015-01-23', '2015-01-29')
4037             ]),
4038             pd.concat([
4039                 cls.create_expected_df_for_factor_compute(
4040                     [(0, 200*5*6*7, pd.Timestamp('2015-01-12')),
4041                      (10, 310*.3, pd.Timestamp('2015-01-09')),
4042                      (10, 311*.3, pd.Timestamp('2015-01-15')),
4043                      (20, 220*.7*.8*.9, cls.window_test_start_date),
4044                      (20, 221*.8*.9, pd.Timestamp('2015-01-17')),
4045                      (40, 240 * 13 * 14, pd.Timestamp('2015-01-15')),
4046                      (50, 250., pd.Timestamp('2015-01-12'))],
4047                     end_date
4048                 ) for end_date in pd.date_range('2015-01-30', '2015-02-05')
4049             ]),
4050             pd.concat([
4051                 cls.create_expected_df_for_factor_compute(
4052                     [(0, 200*5*6*7, pd.Timestamp('2015-01-12')),
4053                      (10, np.NaN, cls.window_test_start_date),
4054                      (20, 220*.7*.8*.9, cls.window_test_start_date),
4055                      (20, 221*.8*.9, pd.Timestamp('2015-01-17')),
4056                      (40, 240 * 13 * 14, pd.Timestamp('2015-01-15')),
4057                      (50, 250., pd.Timestamp('2015-01-12'))],
4058                     end_date
4059                 ) for end_date in pd.date_range('2015-02-06', '2015-02-09')
4060             ]),
4061             cls.create_expected_df_for_factor_compute(
4062                 [(0, 200*5*6*7, pd.Timestamp('2015-01-12')),
4063                  (0, 201, pd.Timestamp('2015-02-10')),
4064                  (10, np.NaN, cls.window_test_start_date),
4065                  (20, 220*.7*.8*.9, cls.window_test_start_date),
4066                  (20, 221*.8*.9, pd.Timestamp('2015-01-17')),
4067                  (40, 240 * 13 * 14, pd.Timestamp('2015-01-15')),
4068                  (50, 250., pd.Timestamp('2015-01-12'))],
4069                 pd.Timestamp('2015-02-10')
4070             )
4071         ])
4072 <a name="6"></a>
4073         twoq_next = pd.concat(
4074             [cls.create_expected_df_for_factor_compute(
4075                 [<font color="#8c8774"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(0, np.NaN, cls.window_test_start_date),
4076                  (10, np.NaN, cls.window_test_start_date),
4077                  (20, 220*5/3, cls.window_test_start_date),
4078                  (30, 230*1/10, cls.window_test_start_date),
4079                  (40, np.NaN, cls.window_test_start_date),
4080                  (50, np.NaN, cls.window_test_start_date)],
4081                 pd.</b></font>Timestamp('2015-01-09')
4082             )] +
4083             [cls.create_expected_df_for_factor_compute(
4084                 [(0, 200*1/4, pd.Timestamp('2015-01-12')),
4085 <a name="12"></a>                 (10, np.NaN, cls.window_test_start_date),
4086                  (20, 220*5/3, cls.window_test_start_date),
4087                  (30, np.NaN, cls.window_test_start_date),
4088                  (40, np<font color="#571b7e"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.NaN, cls.window_test_start_date)],
4089                 pd.Timestamp('2015-01-12')
4090             )] +
4091             [cls.create_expected_df_for_factor_compute(
4092                 [(0, 200, pd.Timestamp('2015-01-12')),
4093                  (10, np.NaN, cls.window_test_start_date),
4094                  (20, 220, cls.</b></font>window_test_start_date),
4095                  (30, np.NaN, cls.window_test_start_date),
4096                  (40, np.NaN, cls.window_test_start_date)],
4097                 end_date
4098             ) for end_date in pd.date_range('2015-01-13', '2015-01-14')] +
4099             [cls.create_expected_df_for_factor_compute(
4100                 [(0, 200*5, pd.Timestamp('2015-01-12')),
4101                  (10, np.NaN, cls.window_test_start_date),
4102                  (20, 220*.7, cls.window_test_start_date),
4103                  (30, np.NaN, cls.window_test_start_date),
4104                  (40, np.NaN, cls.window_test_start_date)],
4105 <a name="3"></a>                end_date
4106             ) for end_date in pd.date_range('2015-01-15', '2015-01-16')] +
4107             [cls.create_expected_df_for_factor_compute(
4108                 [<font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(0, 200*5*6, pd.Timestamp('2015-01-12')),
4109                  (10, np.NaN, cls.window_test_start_date),
4110                  (20, 220*.7*.8, cls.window_test_start_date),
4111                  (20, 221*.8, pd.Timestamp('2015-01-17')),
4112                  (30, np.NaN, cls.window_test_start_date),
4113                  (40, np.NaN, cls.window_test_start_date)],
4114 <a name="14"></a>                pd.Timestamp('2015-01-20')
4115             )] +
4116             [cls</b></font>.create_expected_df_for_factor_compute(
4117                 [<font color="#842dce"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(0, np.NaN, cls.window_test_start_date),
4118                  (10, np.NaN, cls.window_test_start_date),
4119                  (20, np.NaN, cls.window_test_start_date),
4120                  (30, np.NaN, cls.window_test_start_date),
4121                  (40, np.</b></font>NaN, cls.window_test_start_date)],
4122                 end_date
4123             ) for end_date in pd.date_range('2015-01-21', '2015-02-10')]
4124         )
4125         return {
4126             1: oneq_next,
4127             2: twoq_next
4128         }
4129 class BlazeNextWithSplitAdjustedWindows(NextWithSplitAdjustedWindows):
4130     @classmethod
4131     def make_loader(cls, events, columns):
4132         return BlazeNextSplitAdjustedEstimatesLoader(
4133             bz.data(events),
4134             columns,
4135             split_adjustments_loader=cls.adjustment_reader,
4136             split_adjusted_column_names=['estimate'],
4137             split_adjusted_asof=cls.split_adjusted_asof_date,
4138         )
4139 class WithSplitAdjustedMultipleEstimateColumns(WithEstimates):
4140     END_DATE <font color="#f62817"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= pd.Timestamp('2015-02-10')
4141     test_start_date = pd.Timestamp('2015-01-06', tz='utc')
4142     test_end_date = pd.Timestamp('2015-01-12', tz='utc')
4143     split_adjusted_asof = pd.Timestamp(</b></font>'2015-01-08')
4144     @classmethod
4145     def make_columns(cls):
4146         return {
4147             MultipleColumnsEstimates.event_date: 'event_date',
4148             MultipleColumnsEstimates.fiscal_quarter: 'fiscal_quarter',
4149             MultipleColumnsEstimates.fiscal_year: 'fiscal_year',
4150             MultipleColumnsEstimates.estimate1: 'estimate1',
4151             MultipleColumnsEstimates.estimate2: 'estimate2'
4152         }
4153     @classmethod
4154     def make_events(cls):
4155         sid_0_events = pd.DataFrame({
4156             TS_FIELD_NAME: [pd.Timestamp('2015-01-05'),
4157                             pd.Timestamp('2015-01-05')],
4158             EVENT_DATE_FIELD_NAME:
4159                 [pd.Timestamp('2015-01-09'),
4160                  pd.Timestamp('2015-01-12')],
4161             'estimate1': [1100., 1200.],
4162             'estimate2': [2100., 2200.],
4163             FISCAL_QUARTER_FIELD_NAME: [1, 2],
4164             FISCAL_YEAR_FIELD_NAME: 2015,
4165             SID_FIELD_NAME: 0,
4166         })
4167         sid_1_events = pd.DataFrame({
4168             TS_FIELD_NAME: [pd.Timestamp('2015-01-05'),
4169                             pd.Timestamp('2015-01-05')],
4170             EVENT_DATE_FIELD_NAME:
4171                 [pd.Timestamp('2015-01-08'),
4172                  pd.Timestamp('2015-01-11')],
4173             'estimate1': [1110., 1210.],
4174             'estimate2': [2110., 2210.],
4175             FISCAL_QUARTER_FIELD_NAME: [1, 2],
4176             FISCAL_YEAR_FIELD_NAME: 2015,
4177             SID_FIELD_NAME: 1,
4178         })
4179         return pd.concat([sid_0_events, sid_1_events])
4180     @classmethod
4181     def make_splits_data(cls):
4182         sid_0_splits = pd.DataFrame({
4183             SID_FIELD_NAME: 0,
4184             'ratio': (.3, 3.),
4185             'effective_date': (pd.Timestamp('2015-01-07'),
4186                                pd.Timestamp('2015-01-09')),
4187         })
4188         sid_1_splits = pd.DataFrame({
4189             SID_FIELD_NAME: 1,
4190             'ratio': (.4, 4.),
4191             'effective_date': (pd.Timestamp('2015-01-07'),
4192                                pd.Timestamp('2015-01-09')),
4193         })
4194         return pd.concat([sid_0_splits, sid_1_splits])
4195     @classmethod
4196     def make_expected_timelines_1q_out(cls):
4197         return {}
4198     @classmethod
4199     def make_expected_timelines_2q_out(cls):
4200         return {}
4201     @classmethod
4202     def init_class_fixtures(cls):
4203         super(
4204             WithSplitAdjustedMultipleEstimateColumns, cls
4205         ).init_class_fixtures()
4206         cls.timelines_1q_out = cls.make_expected_timelines_1q_out()
4207         cls.timelines_2q_out = cls.make_expected_timelines_2q_out()
4208     def test_adjustments_with_multiple_adjusted_columns(self):
4209         dataset = MultipleColumnsQuartersEstimates(1)
4210         timelines = self.timelines_1q_out
4211         window_len = 3
4212         class SomeFactor(CustomFactor):
4213             inputs = [dataset.estimate1, dataset.estimate2]
4214             window_length = window_len
4215             def compute(self, today, assets, out, estimate1, estimate2):
4216                 assert_almost_equal(estimate1, timelines[today]['estimate1'])
4217                 assert_almost_equal(estimate2, timelines[today]['estimate2'])
4218         engine = self.make_engine()
4219         engine.run_pipeline(
4220             Pipeline({'est': SomeFactor()}),
4221             start_date=self.test_start_date,
4222             end_date=self.test_end_date,
4223         )
4224     def test_multiple_datasets_different_num_announcements(self):
4225         dataset1 = MultipleColumnsQuartersEstimates(1)
4226         dataset2 = MultipleColumnsQuartersEstimates(2)
4227         timelines_1q_out = self.timelines_1q_out
4228         timelines_2q_out = self.timelines_2q_out
4229         window_len = 3
4230         class SomeFactor1(CustomFactor):
4231             inputs = [dataset1.estimate1]
4232             window_length = window_len
4233             def compute(self, today, assets, out, estimate1):
4234                 assert_almost_equal(
4235                     estimate1, timelines_1q_out[today]['estimate1']
4236                 )
4237         class SomeFactor2(CustomFactor):
4238             inputs = [dataset2.estimate2]
4239             window_length = window_len
4240             def compute(self, today, assets, out, estimate2):
4241                 assert_almost_equal(
4242                     estimate2, timelines_2q_out[today]['estimate2']
4243                 )
4244         engine = self.make_engine()
4245         engine.run_pipeline(
4246             Pipeline({'est1': SomeFactor1(), 'est2': SomeFactor2()}),
4247             start_date=self.test_start_date,
4248             end_date=self.test_end_date,
4249         )
4250 class PreviousWithSplitAdjustedMultipleEstimateColumns(
4251     WithSplitAdjustedMultipleEstimateColumns, ZiplineTestCase
4252 ):
4253     @classmethod
4254     def make_loader(cls, events, columns):
4255         return PreviousSplitAdjustedEarningsEstimatesLoader(
4256             events,
4257             columns,
4258             split_adjustments_loader=cls.adjustment_reader,
4259             split_adjusted_column_names=['estimate1', 'estimate2'],
4260             split_adjusted_asof=cls.split_adjusted_asof,
4261         )
4262     @classmethod
4263     def make_expected_timelines_1q_out(cls):
4264         return {
4265             pd.Timestamp('2015-01-06', tz='utc'): {
4266                 'estimate1': np.array([[np.NaN, np.NaN]] * 3),
4267                 'estimate2': np.array([[np.NaN, np.NaN]] * 3)
4268             },
4269             pd.Timestamp('2015-01-07', tz='utc'): {
4270                 'estimate1': np.array([[np.NaN, np.NaN]] * 3),
4271 <a name="37"></a>                'estimate2': np.array([[np.NaN, np.NaN]] * 3)
4272             },
4273             pd.Timestamp('2015-01-08', tz='utc'): {
4274                 'estimate1': np.array([[np<font color="#810541"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.NaN, np.NaN]] * 2 +
4275                                       [[np.NaN, 1110.]]),
4276                 'estimate2': np.array([[np.NaN, np.NaN]] * 2 +
4277                                       [[</b></font>np.NaN, 2110.]])
4278             },
4279             pd.Timestamp('2015-01-09', tz='utc'): {
4280                 'estimate1': np.array([[np.NaN, np.NaN]] +
4281                                       [[np.NaN, 1110. * 4]] +
4282                                       [[1100 * 3., 1110. * 4]]),
4283                 'estimate2': np.array([[np.NaN, np.NaN]] +
4284                                       [[np.NaN, 2110. * 4]] +
4285                                       [[2100 * 3., 2110. * 4]])
4286             },
4287             pd.Timestamp('2015-01-12', tz='utc'): {
4288                 'estimate1': np.array([[np.NaN, np.NaN]] * 2 +
4289                                       [[1200 * 3., 1210. * 4]]),
4290                 'estimate2': np.array([[np.NaN, np.NaN]] * 2 +
4291                                       [[2200 * 3., 2210. * 4]])
4292             }
4293         }
4294     @classmethod
4295     def make_expected_timelines_2q_out(cls):
4296         return {
4297             pd.Timestamp('2015-01-06', tz='utc'): {
4298                 'estimate2': np.array([[np.NaN, np.NaN]] * 3)
4299             },
4300             pd.Timestamp('2015-01-07', tz='utc'): {
4301                 'estimate2': np.array([[np.NaN, np.NaN]] * 3)
4302             },
4303             pd.Timestamp('2015-01-08', tz='utc'): {
4304                 'estimate2': np.array([[np.NaN, np.NaN]] * 3)
4305             },
4306             pd.Timestamp('2015-01-09', tz='utc'): {
4307                 'estimate2': np.array([[np.NaN, np.NaN]] * 3)
4308             },
4309             pd.Timestamp('2015-01-12', tz='utc'): {
4310                 'estimate2': np.array([[np.NaN, np.NaN]] * 2 +
4311                                       [[2100 * 3., 2110. * 4]])
4312             }
4313         }
4314 class BlazePreviousWithMultipleEstimateColumns(
4315     PreviousWithSplitAdjustedMultipleEstimateColumns
4316 ):
4317     @classmethod
4318     def make_loader(cls, events, columns):
4319         return BlazePreviousSplitAdjustedEstimatesLoader(
4320             bz.data(events),
4321             columns,
4322             split_adjustments_loader=cls.adjustment_reader,
4323             split_adjusted_column_names=['estimate1', 'estimate2'],
4324             split_adjusted_asof=cls.split_adjusted_asof,
4325         )
4326 class NextWithSplitAdjustedMultipleEstimateColumns(
4327     WithSplitAdjustedMultipleEstimateColumns, ZiplineTestCase
4328 ):
4329     @classmethod
4330     def make_loader(cls, events, columns):
4331         return NextSplitAdjustedEarningsEstimatesLoader(
4332             events,
4333             columns,
4334             split_adjustments_loader=cls.adjustment_reader,
4335             split_adjusted_column_names=['estimate1', 'estimate2'],
4336             split_adjusted_asof=cls.split_adjusted_asof,
4337         )
4338     @classmethod
4339 <a name="9"></a>    def make_expected_timelines_1q_out(cls):
4340         return {
4341             pd.Timestamp('2015-01-06', tz='utc'): {
4342                 'estimate1': np.array<font color="#83a33a"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>([[np.NaN, np.NaN]] +
4343                                       [[1100. * 1/.3, 1110. * 1/.4]] * 2),
4344                 'estimate2': np.array([[np.NaN, np.NaN]] +
4345                                       [[2100. * 1/.3, 2110. * 1/.4]] * 2),
4346             },
4347             pd.Timestamp(</b></font>'2015-01-07', tz='utc'): {
4348                 'estimate1': np.array([[1100., 1110.]] * 3),
4349                 'estimate2': np.array([[2100., 2110.]] * 3)
4350             },
4351             pd.Timestamp('2015-01-08', tz='utc'): {
4352                 'estimate1': np.array([[1100., 1110.]] * 3),
4353                 'estimate2': np.array([[2100., 2110.]] * 3)
4354             },
4355             pd.Timestamp('2015-01-09', tz='utc'): {
4356                 'estimate1': np.array([[1100 * 3., 1210. * 4]] * 3),
4357 <a name="36"></a>                'estimate2': np.array([[2100 * 3., 2210. * 4]] * 3)
4358             },
4359             pd.Timestamp('2015-01-12', tz='utc'): {
4360                 <font color="#ff00ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>'estimate1': np.array([[1200 * 3., np.NaN]] * 3),
4361                 'estimate2': np.array([[2200 * 3., np.</b></font>NaN]] * 3)
4362             }
4363         }
4364     @classmethod
4365     def make_expected_timelines_2q_out(cls):
4366         return {
4367             pd.Timestamp('2015-01-06', tz='utc'): {
4368                 'estimate2': np.array([[np.NaN, np.NaN]] +
4369                                       [[2200 * 1/.3, 2210. * 1/.4]] * 2)
4370             },
4371             pd.Timestamp('2015-01-07', tz='utc'): {
4372                 'estimate2': np.array([[2200., 2210.]] * 3)
4373             },
4374             pd.Timestamp('2015-01-08', tz='utc'): {
4375                 'estimate2': np.array([[2200, 2210.]] * 3)
4376             },
4377             pd.Timestamp('2015-01-09', tz='utc'): {
4378                 'estimate2': np.array([[2200 * 3., np.NaN]] * 3)
4379             },
4380             pd.Timestamp('2015-01-12', tz='utc'): {
4381                 'estimate2': np.array([[np.NaN, np.NaN]] * 3)
4382             }
4383         }
4384 class BlazeNextWithMultipleEstimateColumns(
4385     NextWithSplitAdjustedMultipleEstimateColumns
4386 ):
4387     @classmethod
4388     def make_loader(cls, events, columns):
4389         return BlazeNextSplitAdjustedEstimatesLoader(
4390             bz.data(events),
4391             columns,
4392             split_adjustments_loader=cls.adjustment_reader,
4393             split_adjusted_column_names=['estimate1', 'estimate2'],
4394             split_adjusted_asof=cls.split_adjusted_asof,
4395         )
4396 class WithAdjustmentBoundaries(WithEstimates):
4397     START_DATE = pd.Timestamp('2015-01-04')
4398     test_start_date = pd.Timestamp('2015-01-05')
4399     END_DATE = test_end_date = pd.Timestamp('2015-01-12')
4400     split_adjusted_before_start = (
4401         test_start_date - timedelta(days=1)
4402     )
4403     split_adjusted_after_end = (
4404         test_end_date + timedelta(days=1)
4405     )
4406     split_adjusted_asof_dates = [(test_start_date,),
4407                                  (test_end_date,),
4408                                  (split_adjusted_before_start,),
4409                                  (split_adjusted_after_end,)]
4410     @classmethod
4411     def init_class_fixtures(cls):
4412         super(WithAdjustmentBoundaries, cls).init_class_fixtures()
4413         cls.s0 = cls.asset_finder.retrieve_asset(0)
4414         cls.s1 = cls.asset_finder.retrieve_asset(1)
4415         cls.s2 = cls.asset_finder.retrieve_asset(2)
4416         cls.s3 = cls.asset_finder.retrieve_asset(3)
4417         cls.s4 = cls.asset_finder.retrieve_asset(4)
4418         cls.expected = cls.make_expected_out()
4419     @classmethod
4420     def make_events(cls):
4421         sid_0_timeline = pd.DataFrame({
4422             TS_FIELD_NAME: cls.test_start_date,
4423             EVENT_DATE_FIELD_NAME: pd.Timestamp('2015-01-09'),
4424             'estimate': 10.,
4425             FISCAL_QUARTER_FIELD_NAME: 1,
4426             FISCAL_YEAR_FIELD_NAME: 2015,
4427             SID_FIELD_NAME: 0,
4428         }, index=[0])
4429         sid_1_timeline = pd.DataFrame({
4430             TS_FIELD_NAME: cls.test_start_date,
4431             EVENT_DATE_FIELD_NAME: cls.test_start_date,
4432             'estimate': 11.,
4433             FISCAL_QUARTER_FIELD_NAME: 1,
4434             FISCAL_YEAR_FIELD_NAME: 2015,
4435             SID_FIELD_NAME: 1,
4436         }, index=[0])
4437         sid_2_timeline = pd.DataFrame({
4438             TS_FIELD_NAME: cls.test_end_date,
4439             EVENT_DATE_FIELD_NAME: cls.test_end_date + timedelta(days=1),
4440             'estimate': 12.,
4441             FISCAL_QUARTER_FIELD_NAME: 1,
4442             FISCAL_YEAR_FIELD_NAME: 2015,
4443             SID_FIELD_NAME: 2,
4444         }, index=[0])
4445         sid_3_timeline = pd.DataFrame({
4446             TS_FIELD_NAME: cls.test_end_date - timedelta(days=1),
4447             EVENT_DATE_FIELD_NAME: cls.test_end_date,
4448             'estimate': 13.,
4449             FISCAL_QUARTER_FIELD_NAME: 1,
4450             FISCAL_YEAR_FIELD_NAME: 2015,
4451             SID_FIELD_NAME: 3,
4452         }, index=[0])
4453         sid_4_timeline = pd.DataFrame({
4454             TS_FIELD_NAME: cls.test_end_date - timedelta(days=1),
4455             EVENT_DATE_FIELD_NAME: cls.test_end_date - timedelta(days=1),
4456             'estimate': 14.,
4457             FISCAL_QUARTER_FIELD_NAME: 1,
4458             FISCAL_YEAR_FIELD_NAME: 2015,
4459             SID_FIELD_NAME: 4,
4460         }, index=[0])
4461         return pd.concat([sid_0_timeline,
4462                           sid_1_timeline,
4463                           sid_2_timeline,
4464                           sid_3_timeline,
4465                           sid_4_timeline])
4466     @classmethod
4467     def make_splits_data(cls):
4468         sid_0_splits = pd.DataFrame({
4469             SID_FIELD_NAME: 0,
4470             'ratio': .10,
4471             'effective_date': cls.test_start_date,
4472         }, index=[0])
4473         sid_1_splits = pd.DataFrame({
4474             SID_FIELD_NAME: 1,
4475             'ratio': .11,
4476             'effective_date': cls.test_start_date,
4477         }, index=[0])
4478         sid_2_splits = pd.DataFrame({
4479             SID_FIELD_NAME: 2,
4480             'ratio': .12,
4481             'effective_date': cls.test_end_date,
4482         }, index=[0])
4483         sid_3_splits = pd.DataFrame({
4484             SID_FIELD_NAME: 3,
4485             'ratio': .13,
4486             'effective_date': cls.test_end_date,
4487         }, index=[0])
4488         sid_4_splits = pd.DataFrame({
4489             SID_FIELD_NAME: 4,
4490             'ratio': (.14, .15),
4491             'effective_date': (cls.test_start_date, cls.test_end_date),
4492         })
4493         return pd.concat([sid_0_splits,
4494                           sid_1_splits,
4495                           sid_2_splits,
4496                           sid_3_splits,
4497                           sid_4_splits])
4498 <a name="30"></a>
4499     @parameterized.expand(split_adjusted_asof_dates)
4500     def test_boundaries(self, split_date):
4501         dataset = QuartersEstimates<font color="#ae694a"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(1)
4502         loader = self.loader(split_adjusted_asof=split_date)
4503         engine = engine = self.make_engine(loader)
4504         result = engine.run_pipeline(</b></font>
4505             Pipeline({'estimate': dataset.estimate.latest}),
4506             start_date=self.trading_days[0],
4507             end_date=self.trading_days[-1],
4508         )
4509         expected = self.expected[split_date]
4510         assert_frame_equal(result, expected, check_names=False)
4511     @classmethod
4512     def make_expected_out(cls):
4513         return {}
4514 class PreviousWithAdjustmentBoundaries(WithAdjustmentBoundaries,
4515                                        ZiplineTestCase):
4516     @classmethod
4517     def make_loader(cls, events, columns):
4518         return partial(PreviousSplitAdjustedEarningsEstimatesLoader,
4519                        events,
4520                        columns,
4521                        split_adjustments_loader=cls.adjustment_reader,
4522                        split_adjusted_column_names=['estimate'])
4523     @classmethod
4524     def make_expected_out(cls):
4525         split_adjusted_at_start_boundary = pd.concat([
4526             pd.DataFrame({
4527                 SID_FIELD_NAME: cls.s0,
4528                 'estimate': np.NaN,
4529             }, index=pd.date_range(
4530                 cls.test_start_date,
4531                 pd.Timestamp('2015-01-08'),
4532                 tz='utc'
4533             )),
4534             pd.DataFrame({
4535                 SID_FIELD_NAME: cls.s0,
4536                 'estimate': 10.,
4537             }, index=pd.date_range(
4538                 pd.Timestamp('2015-01-09'), cls.test_end_date, tz='utc'
4539             )),
4540             pd.DataFrame({
4541                 SID_FIELD_NAME: cls.s1,
4542                 'estimate': 11.,
4543 <a name="24"></a>            }, index=pd.date_range(cls.test_start_date, cls.test_end_date,
4544                                    tz='utc')),
4545             pd.DataFrame({
4546                 <font color="#79764d"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>SID_FIELD_NAME: cls.s2,
4547                 'estimate': np.NaN
4548             }, index=pd.date_range(cls.test_start_date,
4549                                    cls.test_end_date,
4550                                    tz='utc')),
4551             pd.DataFrame({
4552                 SID_FIELD_NAME: cls.</b></font>s3,
4553                 'estimate': np.NaN
4554             }, index=pd.date_range(
4555                 cls.test_start_date, cls.test_end_date - timedelta(1), tz='utc'
4556             )),
4557 <a name="22"></a>            pd.DataFrame({
4558                 SID_FIELD_NAME: cls.s3,
4559                 'estimate': 13. * .13
4560             }, index=pd.date_range(cls<font color="#4cc417"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.test_end_date,
4561                                    cls.test_end_date,
4562                                    tz='utc')),
4563             pd.DataFrame({
4564                 SID_FIELD_NAME: cls.s4,
4565                 'estimate': np.NaN
4566             }, index=pd.date_range(
4567                 cls.test_start_date, cls.</b></font>test_end_date - timedelta(2), tz='utc'
4568             )),
4569             pd.DataFrame({
4570                 SID_FIELD_NAME: cls.s4,
4571                 'estimate': 14. * .15
4572             }, index=pd.date_range(
4573                 cls.test_end_date - timedelta(1), cls.test_end_date, tz='utc'
4574             )),
4575         ]).set_index(SID_FIELD_NAME, append=True).unstack(
4576             SID_FIELD_NAME).reindex(cls.trading_days).stack(
4577             SID_FIELD_NAME, dropna=False)
4578         split_adjusted_at_end_boundary = pd.concat([
4579             pd.DataFrame({
4580                 SID_FIELD_NAME: cls.s0,
4581                 'estimate': np.NaN,
4582             }, index=pd.date_range(
4583                 cls.test_start_date, pd.Timestamp('2015-01-08'), tz='utc'
4584             )),
4585             pd.DataFrame({
4586                 SID_FIELD_NAME: cls.s0,
4587                 'estimate': 10.,
4588             }, index=pd.date_range(
4589                 pd.Timestamp('2015-01-09'), cls.test_end_date, tz='utc'
4590             )),
4591             pd.DataFrame({
4592                 SID_FIELD_NAME: cls.s1,
4593                 'estimate': 11.,
4594             }, index=pd.date_range(cls.test_start_date,
4595 <a name="23"></a>                                   cls.test_end_date,
4596                                    tz='utc')),
4597             pd.DataFrame({
4598                 <font color="#f660ab"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>SID_FIELD_NAME: cls.s2,
4599                 'estimate': np.NaN
4600             }, index=pd.date_range(cls.test_start_date,
4601                                    cls.test_end_date,
4602                                    tz='utc')),
4603             pd.DataFrame({
4604                 SID_FIELD_NAME: cls.</b></font>s3,
4605                 'estimate': np.NaN
4606             }, index=pd.date_range(
4607                 cls.test_start_date, cls.test_end_date - timedelta(1), tz='utc'
4608             )),
4609             pd.DataFrame({
4610                 SID_FIELD_NAME: cls.s3,
4611                 'estimate': 13.
4612             }, index=pd.date_range(cls.test_end_date,
4613                                    cls.test_end_date,
4614                                    tz='utc')),
4615             pd.DataFrame({
4616                 SID_FIELD_NAME: cls.s4,
4617                 'estimate': np.NaN
4618             }, index=pd.date_range(
4619                 cls.test_start_date, cls.test_end_date - timedelta(2), tz='utc'
4620             )),
4621             pd.DataFrame({
4622                 SID_FIELD_NAME: cls.s4,
4623                 'estimate': 14.
4624             }, index=pd.date_range(cls.test_end_date - timedelta(1),
4625                                    cls.test_end_date,
4626                                    tz='utc')),
4627         ]).set_index(SID_FIELD_NAME, append=True).unstack(
4628             SID_FIELD_NAME).reindex(cls.trading_days).stack(SID_FIELD_NAME,
4629                                                             dropna=False)
4630         split_adjusted_before_start_boundary = split_adjusted_at_start_boundary
4631         split_adjusted_after_end_boundary = split_adjusted_at_end_boundary
4632         return {cls.test_start_date:
4633                 split_adjusted_at_start_boundary,
4634                 cls.split_adjusted_before_start:
4635                 split_adjusted_before_start_boundary,
4636                 cls.test_end_date:
4637                 split_adjusted_at_end_boundary,
4638                 cls.split_adjusted_after_end:
4639                 split_adjusted_after_end_boundary}
4640 class BlazePreviousWithAdjustmentBoundaries(PreviousWithAdjustmentBoundaries):
4641     @classmethod
4642     def make_loader(cls, events, columns):
4643         return partial(BlazePreviousSplitAdjustedEstimatesLoader,
4644                        bz.data(events),
4645                        columns,
4646                        split_adjustments_loader=cls.adjustment_reader,
4647                        split_adjusted_column_names=['estimate'])
4648 class NextWithAdjustmentBoundaries(WithAdjustmentBoundaries,
4649                                    ZiplineTestCase):
4650     @classmethod
4651     def make_loader(cls, events, columns):
4652         return partial(NextSplitAdjustedEarningsEstimatesLoader,
4653                        events,
4654                        columns,
4655                        split_adjustments_loader=cls.adjustment_reader,
4656                        split_adjusted_column_names=['estimate'])
4657     @classmethod
4658     def make_expected_out(cls):
4659         split_adjusted_at_start_boundary = pd.concat([
4660             pd.DataFrame({
4661                 SID_FIELD_NAME: cls.s0,
4662                 'estimate': 10,
4663             }, index=pd.date_range(
4664                 cls.test_start_date, pd.Timestamp('2015-01-09'), tz='utc'
4665             )),
4666 <a name="0"></a>            pd.DataFrame({
4667                 SID_FIELD_NAME: cls.s1,
4668                 'estimate': 11.,
4669             }, index<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>=pd.date_range(cls.test_start_date,
4670                                    cls.test_start_date,
4671                                    tz='utc')),
4672             pd.DataFrame({
4673                 SID_FIELD_NAME: cls.s2,
4674                 'estimate': 12.,
4675             }, index=pd.date_range(cls.test_end_date,
4676                                    cls.test_end_date,
4677                                    tz='utc')),
4678             pd.DataFrame({
4679                 SID_FIELD_NAME: cls.s3,
4680                 'estimate': 13. * .13,
4681             }, index=pd.date_range(
4682                 cls.test_end_date - timedelta(1), cls.</b></font>test_end_date, tz='utc'
4683             )),
4684             pd.DataFrame({
4685                 SID_FIELD_NAME: cls.s4,
4686                 'estimate': 14.,
4687             }, index=pd.date_range(
4688                 cls.test_end_date - timedelta(1),
4689                 cls.test_end_date - timedelta(1),
4690                 tz='utc'
4691             )),
4692         ]).set_index(SID_FIELD_NAME, append=True).unstack(
4693             SID_FIELD_NAME).reindex(cls.trading_days).stack(
4694             SID_FIELD_NAME, dropna=False)
4695         split_adjusted_at_end_boundary = pd.concat([
4696             pd.DataFrame({
4697                 SID_FIELD_NAME: cls.s0,
4698                 'estimate': 10,
4699             }, index=pd.date_range(
4700                 cls.test_start_date, pd.Timestamp('2015-01-09'), tz='utc'
4701             )),
4702             pd.DataFrame({
4703 <a name="2"></a>                SID_FIELD_NAME: cls.s1,
4704                 'estimate': 11.,
4705             }, index=pd.date_range(cls.test_start_date,
4706                                    cls<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.test_start_date,
4707                                    tz='utc')),
4708             pd.DataFrame({
4709                 SID_FIELD_NAME: cls.s2,
4710                 'estimate': 12.,
4711             }, index=pd.date_range(cls.test_end_date,
4712                                    cls.test_end_date,
4713                                    tz='utc')),
4714             pd.DataFrame({
4715                 SID_FIELD_NAME: cls.s3,
4716                 'estimate': 13.,
4717             }, index=pd.date_range(
4718                 cls.test_end_date - timedelta(1), cls.</b></font>test_end_date, tz='utc'
4719             )),
4720             pd.DataFrame({
4721                 SID_FIELD_NAME: cls.s4,
4722                 'estimate': 14.,
4723             }, index=pd.date_range(
4724                 cls.test_end_date - timedelta(1),
4725                 cls.test_end_date - timedelta(1),
4726                 tz='utc'
4727             )),
4728         ]).set_index(SID_FIELD_NAME, append=True).unstack(
4729             SID_FIELD_NAME).reindex(cls.trading_days).stack(
4730             SID_FIELD_NAME, dropna=False)
4731         split_adjusted_before_start_boundary = split_adjusted_at_start_boundary
4732         split_adjusted_after_end_boundary = split_adjusted_at_end_boundary
4733         return {cls.test_start_date:
4734                 split_adjusted_at_start_boundary,
4735                 cls.split_adjusted_before_start:
4736                 split_adjusted_before_start_boundary,
4737                 cls.test_end_date:
4738                 split_adjusted_at_end_boundary,
4739                 cls.split_adjusted_after_end:
4740                 split_adjusted_after_end_boundary}
4741 class BlazeNextWithAdjustmentBoundaries(NextWithAdjustmentBoundaries):
4742     @classmethod
4743     def make_loader(cls, events, columns):
4744         return partial(BlazeNextSplitAdjustedEstimatesLoader,
4745                        bz.data(events),
4746                        columns,
4747                        split_adjustments_loader=cls.adjustment_reader,
4748                        split_adjusted_column_names=['estimate'])
4749 class QuarterShiftTestCase(ZiplineTestCase):
4750     def test_quarter_normalization(self):
4751         input_yrs = pd.Series(range(2011, 2015), dtype=np.int64)
4752         input_qtrs = pd.Series(range(1, 5), dtype=np.int64)
4753         result_years, result_quarters = split_normalized_quarters(
4754             normalize_quarters(input_yrs, input_qtrs)
4755         )
4756         assert_equal(input_yrs, result_years)
4757         assert_equal(input_qtrs, result_quarters)
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
