<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for test_sort_1.py &amp; test_opt_4.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for test_sort_1.py &amp; test_opt_4.py
      </h3>
<h1 align="center">
        3.0%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>test_sort_1.py (22.916666%)<th>test_opt_4.py (1.6571811%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(163-170)<td><a href="#" name="0">(4410-4416)</a><td align="center"><font color="#ff0000">18</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(386-388)<td><a href="#" name="1">(5008-5011)</a><td align="center"><font color="#c60000">14</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(321-324)<td><a href="#" name="2">(4383-4385)</a><td align="center"><font color="#c60000">14</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(293-295)<td><a href="#" name="3">(4368-4370)</a><td align="center"><font color="#c60000">14</font>
<tr onclick='openModal("#6cc417")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#6cc417"><font color="#6cc417">-</font><td><a href="#" name="4">(156-163)<td><a href="#" name="4">(4198-4204)</a><td align="center"><font color="#c60000">14</font>
<tr onclick='openModal("#151b8d")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#151b8d"><font color="#151b8d">-</font><td><a href="#" name="5">(1-16)<td><a href="#" name="5">(44-69)</a><td align="center"><font color="#c60000">14</font>
<tr onclick='openModal("#8c8774")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#8c8774"><font color="#8c8774">-</font><td><a href="#" name="6">(290-292)<td><a href="#" name="6">(6810-6815)</a><td align="center"><font color="#b80000">13</font>
<tr onclick='openModal("#38a4a5")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#38a4a5"><font color="#38a4a5">-</font><td><a href="#" name="7">(171-178)<td><a href="#" name="7">(4359-4363)</a><td align="center"><font color="#b80000">13</font>
<tr onclick='openModal("#c58917")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#c58917"><font color="#c58917">-</font><td><a href="#" name="8">(151-156)<td><a href="#" name="8">(695-701)</a><td align="center"><font color="#b80000">13</font>
<tr onclick='openModal("#83a33a")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#83a33a"><font color="#83a33a">-</font><td><a href="#" name="9">(80-84)<td><a href="#" name="9">(3623-3628)</a><td align="center"><font color="#b80000">13</font>
<tr onclick='openModal("#ad5910")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#ad5910"><font color="#ad5910">-</font><td><a href="#" name="10">(29-33)<td><a href="#" name="10">(6560-6567)</a><td align="center"><font color="#b80000">13</font>
<tr onclick='openModal("#b041ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#b041ff"><font color="#b041ff">-</font><td><a href="#" name="11">(418-419)<td><a href="#" name="11">(2086-2090)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#571b7e")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#571b7e"><font color="#571b7e">-</font><td><a href="#" name="12">(410-411)<td><a href="#" name="12">(5648-5651)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#3b9c9c")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#3b9c9c"><font color="#3b9c9c">-</font><td><a href="#" name="13">(382-383)<td><a href="#" name="13">(4683-4687)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#842dce")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#842dce"><font color="#842dce">-</font><td><a href="#" name="14">(349-350)<td><a href="#" name="14">(5687-5690)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#f52887")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f52887"><font color="#f52887">-</font><td><a href="#" name="15">(270-271)<td><a href="#" name="15">(5657-5660)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#2981b2")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#2981b2"><font color="#2981b2">-</font><td><a href="#" name="16">(259-261)<td><a href="#" name="16">(4455-4456)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#3090c7")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#3090c7"><font color="#3090c7">-</font><td><a href="#" name="17">(248-250)<td><a href="#" name="17">(4437-4438)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#800517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#800517"><font color="#800517">-</font><td><a href="#" name="18">(244-247)<td><a href="#" name="18">(960-963)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#f62817")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f62817"><font color="#f62817">-</font><td><a href="#" name="19">(218-224)<td><a href="#" name="19">(6301-6304)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#4e9258")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#4e9258"><font color="#4e9258">-</font><td><a href="#" name="20">(189-195)<td><a href="#" name="20">(3523-3528)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#947010")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#947010"><font color="#947010">-</font><td><a href="#" name="21">(53-59)<td><a href="#" name="21">(852-862)</a><td align="center"><font color="#aa0000">12</font>
<tr onclick='openModal("#4cc417")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#4cc417"><font color="#4cc417">-</font><td><a href="#" name="22">(49-53)<td><a href="#" name="22">(301-313)</a><td align="center"><font color="#aa0000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_sort_1.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 <a name="5"></a><font color="#151b8d"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>from __future__ import absolute_import, print_function, division
2 from itertools import product, chain
3 from functools import reduce
4 import unittest
5 from theano.tests import unittest_tools as utt
6 import numpy as np
7 import theano
8 from theano import tensor
9 from theano.tensor.sort import sort, SortOp
10 from theano.tensor.sort import argsort, ArgSortOp
11 from theano.tensor.sort import topk, argtopk, topk_and_argtopk, TopKOp
12 _all_dtypes = tensor.integer_dtypes + tensor.</b></font>float_dtypes
13 def gen_unique_vector(size, dtype):
14     retval = np.arange(size) * 3. + np.random.uniform(-1., 1.)
15     return (retval[np.random.permutation(size)] - size * 1.5).astype(dtype)
16 class Test_sort(unittest.TestCase):
17 <a name="10"></a>
18     def setUp(self):
19         self.rng = np.random.RandomState(seed=utt.fetch_seed())
20         self.m_val = self<font color="#ad5910"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.rng.rand(3, 2)
21         self.v_val = self.rng.rand(4)
22     def test1(self):
23         a = tensor.dmatrix(</b></font>)
24         w = sort(a)
25         f = theano.function([a], w)
26         utt.assert_allclose(f(self.m_val), np.sort(self.m_val))
27     def test2(self):
28         a = tensor.dmatrix()
29         axis = tensor.scalar()
30         w = sort(a, axis)
31         f = theano.function([a, axis], w)
32         for axis_val in 0, 1:
33             gv = f(self.m_val, axis_val)
34             gt = np.sort(self.m_val, axis_val)
35 <a name="22"></a>            utt.assert_allclose(gv, gt)
36     def test3(self):
37         a = tensor.dvector<font color="#4cc417"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>()
38 <a name="21"></a>        w2 = sort(a)
39         f = theano.function([a], w2)
40         gv = f(self.v_val)
41         gt = np.sort(</b></font>self<font color="#947010"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.v_val)
42         utt.assert_allclose(gv, gt)
43     def test4(self):
44         a = tensor.dmatrix()
45         axis = tensor.scalar()
46         l =</b></font> sort(a, axis, "mergesort")
47         f = theano.function([a, axis], l)
48         for axis_val in 0, 1:
49             gv = f(self.m_val, axis_val)
50             gt = np.sort(self.m_val, axis_val)
51             utt.assert_allclose(gv, gt)
52     def test5(self):
53         a1 = SortOp("mergesort", [])
54         a2 = SortOp("quicksort", [])
55         assert a1 != a2
56         assert a1 == SortOp("mergesort", [])
57         assert a2 == SortOp("quicksort", [])
58     def test_None(self):
59         a = tensor.dmatrix()
60 <a name="9"></a>        l = sort(a, None)
61         f = theano.function([a], l)
62         gv = f(self.m_val)
63         gt = np<font color="#83a33a"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.sort(self.m_val, None)
64         utt.assert_allclose(gv, gt)
65     def test_grad_vector(self):
66         data = np.random.rand(10).astype(</b></font>theano.config.floatX)
67         utt.verify_grad(sort, [data])
68     def test_grad_none_axis(self):
69         data = np.random.rand(10).astype(theano.config.floatX)
70         utt.verify_grad(lambda x: sort(x, None), [data])
71         utt.verify_grad(lambda x: sort(x, 0), [data])
72         data = np.random.rand(2, 3).astype(theano.config.floatX)
73         utt.verify_grad(lambda x: sort(x, None), [data])
74         data = np.random.rand(2, 3, 4).astype(theano.config.floatX)
75         utt.verify_grad(lambda x: sort(x, None), [data])
76     def test_grad_negative_axis_2d(self):
77         data = np.random.rand(2, 3).astype(theano.config.floatX)
78         utt.verify_grad(lambda x: sort(x, -1), [data])
79         data = np.random.rand(2, 3).astype(theano.config.floatX)
80         utt.verify_grad(lambda x: sort(x, -2), [data])
81     def test_grad_negative_axis_3d(self):
82         data = np.random.rand(2, 3, 4).astype(theano.config.floatX)
83         utt.verify_grad(lambda x: sort(x, -1), [data])
84         data = np.random.rand(2, 3, 4).astype(theano.config.floatX)
85         utt.verify_grad(lambda x: sort(x, -2), [data])
86         data = np.random.rand(2, 3, 4).astype(theano.config.floatX)
87         utt.verify_grad(lambda x: sort(x, -3), [data])
88     def test_grad_negative_axis_4d(self):
89         data = np.random.rand(2, 3, 4, 2).astype(theano.config.floatX)
90         utt.verify_grad(lambda x: sort(x, -1), [data])
91         data = np.random.rand(2, 3, 4, 2).astype(theano.config.floatX)
92         utt.verify_grad(lambda x: sort(x, -2), [data])
93         data = np.random.rand(2, 3, 4, 2).astype(theano.config.floatX)
94         utt.verify_grad(lambda x: sort(x, -3), [data])
95         data = np.random.rand(2, 3, 4, 2).astype(theano.config.floatX)
96         utt.verify_grad(lambda x: sort(x, -4), [data])
97     def test_grad_nonnegative_axis_2d(self):
98         data = np.random.rand(2, 3).astype(theano.config.floatX)
99         utt.verify_grad(lambda x: sort(x, 0), [data])
100         data = np.random.rand(2, 3).astype(theano.config.floatX)
101         utt.verify_grad(lambda x: sort(x, 1), [data])
102     def test_grad_nonnegative_axis_3d(self):
103         data = np.random.rand(2, 3, 4).astype(theano.config.floatX)
104         utt.verify_grad(lambda x: sort(x, 0), [data])
105         data = np.random.rand(2, 3, 4).astype(theano.config.floatX)
106         utt.verify_grad(lambda x: sort(x, 1), [data])
107         data = np.random.rand(2, 3, 4).astype(theano.config.floatX)
108         utt.verify_grad(lambda x: sort(x, 2), [data])
109     def test_grad_nonnegative_axis_4d(self):
110         data = np.random.rand(2, 3, 4, 2).astype(theano.config.floatX)
111         utt.verify_grad(lambda x: sort(x, 0), [data])
112         data = np.random.rand(2, 3, 4, 2).astype(theano.config.floatX)
113         utt.verify_grad(lambda x: sort(x, 1), [data])
114         data = np.random.rand(2, 3, 4, 2).astype(theano.config.floatX)
115         utt.verify_grad(lambda x: sort(x, 2), [data])
116         data = np.random.rand(2, 3, 4, 2).astype(theano.config.floatX)
117         utt.verify_grad(lambda x: sort(x, 3), [data])
118 class SortInferShapeTester(utt.InferShapeTester):
119     def test_sort(self):
120 <a name="8"></a>        x = tensor.matrix()
121         self._compile_and_check(
122             [x],
123             [sort<font color="#c58917"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(x)],
124             [np.random.randn(10, 40).astype(theano.config.floatX)],
125 <a name="4"></a>            SortOp)
126         self._compile_and_check(
127             [x],
128             [sort(</b></font>x, axis<font color="#6cc417"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>=None)],
129             [np.random.randn(10, 40).astype(theano.config.floatX)],
130             SortOp)
131 <a name="0"></a>
132 def test_argsort():
133     rng = np.</b></font>random<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.RandomState(seed=utt.fetch_seed())
134     m_val = rng.rand(3, 2)
135     v_val = rng.rand(4)
136 <a name="7"></a>    a = tensor.dmatrix()
137     w = argsort(a)
138     f = theano.</b></font>function([a], w)
139     gv = f<font color="#38a4a5"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(m_val)
140     gt = np.argsort(m_val)
141     utt.assert_allclose(gv, gt)
142     a = tensor.dmatrix()
143     axis = tensor.lscalar()
144     w =</b></font> argsort(a, axis)
145     f = theano.function([a, axis], w)
146     for axis_val in 0, 1:
147         gv = f(m_val, axis_val)
148         gt = np.argsort(m_val, axis_val)
149         utt.assert_allclose(gv, gt)
150 <a name="20"></a>    a = tensor.dvector()
151     w2 = argsort(a)
152     f = theano.function([a], w2)
153     gv = f<font color="#4e9258"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(v_val)
154     gt = np.argsort(v_val)
155     utt.assert_allclose(gv, gt)
156     a = tensor.dmatrix()
157     axis = tensor.lscalar(</b></font>)
158     l = argsort(a, axis, "mergesort")
159     f = theano.function([a, axis], l)
160     for axis_val in 0, 1:
161         gv = f(m_val, axis_val)
162         gt = np.argsort(m_val, axis_val)
163         utt.assert_allclose(gv, gt)
164     a = tensor.dmatrix()
165     axis = tensor.lscalar()
166     a1 = ArgSortOp("mergesort", [])
167     a2 = ArgSortOp("quicksort", [])
168     assert a1 != a2
169     assert a1 == ArgSortOp("mergesort", [])
170     assert a2 == ArgSortOp("quicksort", [])
171     a = tensor.dmatrix()
172 <a name="19"></a>    w2 = argsort(a, None)
173     f = theano.function([a], w2)
174     gv = f(m_val)
175     gt = np<font color="#f62817"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.argsort(m_val, None)
176     utt.assert_allclose(gv, gt)
177 def test_argsort_grad():
178     data = np.random.rand(2, 3).astype(</b></font>theano.config.floatX)
179     utt.verify_grad(lambda x: argsort(x, axis=-1), [data])
180     data = np.random.rand(2, 3, 4, 5).astype(theano.config.floatX)
181     utt.verify_grad(lambda x: argsort(x, axis=-3), [data])
182     data = np.random.rand(2, 3, 3).astype(theano.config.floatX)
183     utt.verify_grad(lambda x: argsort(x, axis=2), [data])
184 class Test_TopK(unittest.TestCase):
185     mode = None
186     op_class = TopKOp
187     def setUp(self):
188         pass
189 <a name="18"></a>    @utt.parameterized.expand(product(
190         _all_dtypes, tensor.integer_dtypes, [-1, 0, None], [False]))
191     def test_argtopk_sanity(self, dtype, idx_dtype, axis, sorted):
192         x = tensor.vector<font color="#800517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(name='x', dtype=dtype)
193 <a name="17"></a>        fn = theano.function([x],
194                              argtopk(x, 1, axis=axis, sorted=sorted, idx_dtype=idx_dtype),
195                              mode=self.</b></font>mode)
196         assert any([isinstance<font color="#3090c7"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(n.op, self.op_class) for n in fn.maker.fgraph.apply_nodes])
197         xval = np.asarray([1]).astype(dtype)
198         yval =</b></font> fn(xval)
199         assert yval == np.asarray([0], dtype=idx_dtype)
200         assert yval.dtype == np.dtype(idx_dtype)
201     @utt.parameterized.expand(product(
202         _all_dtypes, [-1, 0, None], [False]))
203 <a name="16"></a>    def test_topk_sanity(self, dtype, axis, sorted):
204         x = tensor.vector(name='x', dtype=dtype)
205         fn = theano.function([x], topk(x, 1, axis=axis, sorted=sorted), mode=self.mode)
206         assert any([isinstance<font color="#2981b2"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(n.op, self.op_class) for n in fn.maker.fgraph.apply_nodes])
207         xval = np.asarray([1]).astype(dtype)
208         yval =</b></font> fn(xval)
209         assert yval == xval
210         assert yval.dtype == xval.dtype
211     @utt.parameterized.expand(product(
212         _all_dtypes, tensor.integer_dtypes, [-1, 0, None], [False]))
213 <a name="15"></a>    def test_combined_sanity(self, dtype, idx_dtype, axis, sorted):
214         x = tensor.vector(name='x', dtype=dtype)
215         yv, yi = topk_and_argtopk(x, 1, axis=axis, sorted=sorted, idx_dtype=idx_dtype)
216         fn = theano.function([x], [<font color="#f52887"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>yv, yi], mode=self.mode)
217         assert any([isinstance(n.op, self.op_class) for n in fn.maker.fgraph.</b></font>apply_nodes])
218         xval = np.asarray([1]).astype(dtype)
219         yvval, yival = fn(xval)
220         assert yival == np.asarray([0], dtype=idx_dtype)
221         utt.assert_allclose(xval, yvval)
222         assert yvval.dtype == xval.dtype
223         assert yival.dtype == np.dtype(idx_dtype)
224     @utt.parameterized.expand(chain(
225         product(
226             (16, 61, 257),
227             (1, -1, -10, 'n//2', 'n-1', '-n', '1-n'),
228             ('float64', 'float16', 'int16', 'int8'),
229             (False,)),
230         ((2049, 1337, 'float64', False),)))
231     def test_topk_1d(self, size, k, dtype, sorted):
232 <a name="6"></a>        if isinstance(k, str):
233             k = eval(k.replace('n', str(size)))
234 <a name="3"></a>        x = theano<font color="#8c8774"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.tensor.vector(name='x', dtype=dtype)
235         y = topk(x, k, sorted=sorted)
236         fn = theano.function([x], y, mode=self.</b></font>mode)
237         assert any([<font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>isinstance(n.op, self.op_class) for n in fn.maker.fgraph.apply_nodes])
238         assert 1 == len(fn.maker.fgraph.outputs[0].</b></font>owner.outputs)
239         xval = gen_unique_vector(size, dtype)
240         yval = fn(xval)
241         idx = (slice(-k, None) if k &gt; 0 else slice(-k))
242         goal = np.sort(xval)[idx]
243         assert yval.dtype == goal.dtype
244         utt.assert_allclose(goal, np.sort(yval))
245     @utt.parameterized.expand(chain(
246         product(
247             (16, 61, 257),
248             (1, -1, -10, 'n//2', 'n-1', '-n'),
249             ('float32', 'int32'),
250             (False,),
251             ('int32', 'int64')),
252         ((2049, 1337, 'float32', False, 'int32'),)))
253     def test_argtopk_1d(self, size, k, dtype, sorted, idx_dtype):
254         if isinstance(k, str):
255             k = eval(k.replace('n', str(size)))
256 <a name="2"></a>        x = theano.tensor.vector(name='x', dtype=dtype)
257         y = argtopk(x, k, sorted=sorted, idx_dtype=idx_dtype)
258         fn = theano.function([x], y, mode=self.mode)
259         assert any([<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>isinstance(n.op, self.op_class) for n in fn.maker.fgraph.apply_nodes])
260         assert 1 == len(fn.maker.fgraph.outputs[0].</b></font>owner.outputs)
261         xval = gen_unique_vector(size, dtype)
262         yval = fn(xval)
263         idx = (slice(-k, None) if k &gt; 0 else slice(-k))
264         goal = np.argsort(xval)[idx].astype(idx_dtype)
265         assert np.all(xval[np.sort(yval)] == xval[np.sort(goal)])
266     @utt.parameterized.expand(chain(
267         product(
268             (16, 61, 257),
269             (1, -1, 10, 'n//2', 'n-1', '1-n'),
270             ('float32', 'int32'),
271             (False,),
272             ('int32', 'int64')),
273         ((2049, 1337, 'float32', False, 'int32'),)))
274     def test_combined_1d(self, size, k, dtype, sorted, idx_dtype):
275         if isinstance(k, str):
276             k = eval(k.replace('n', str(size)))
277 <a name="14"></a>
278         x = theano.tensor.vector(name='x', dtype=dtype)
279         yv, yi = topk_and_argtopk(x, k, sorted=sorted, idx_dtype=idx_dtype)
280         fn = theano.function([x], [<font color="#842dce"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>yv, yi], mode=self.mode)
281         assert any([isinstance(n.op, self.op_class) for n in fn.maker.fgraph.</b></font>apply_nodes])
282         xval = gen_unique_vector(size, dtype)
283         yvval, yival = fn(xval)
284         idx = (slice(-k, None) if k &gt; 0 else slice(-k))
285         goali = np.argsort(xval)[idx].astype(idx_dtype)
286         goalv = xval[goali]
287         assert np.all(xval[np.sort(yival)] == xval[np.sort(goali)])
288         utt.assert_allclose(np.sort(yvval), goalv)
289     @utt.parameterized.expand(chain(
290         product(
291             (18, 62, 258),
292             (1, -1, 'n//2'),
293             ('int32', 'float32'),
294             (False,)),
295         ((2048, 1337, 'float32', False),)))
296     def test_argtopk_1d_collision(self, size, k, dtype, sorted):
297         if isinstance(k, str):
298             k = eval(k.replace('n', str(size)))
299         x = theano.tensor.vector(name='x', dtype=dtype)
300         y = argtopk(x, k, sorted=sorted, idx_dtype='int32')
301         mode = self.mode
302 <a name="13"></a>        if isinstance(self.mode, theano.compile.DebugMode):
303             mode = theano.Mode(optimizer=mode.optimizer)
304         fn = theano.function([x], y, mode=mode)
305         assert any([<font color="#3b9c9c"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>isinstance(n.op, self.op_class) for n in fn.maker.fgraph.apply_nodes])
306 <a name="1"></a>        xval = np.repeat(np.random.</b></font>uniform(-100., 100., size=size // 2).astype(dtype), 2)
307         xval = xval[np.random.permutation(size)]
308         yval = fn(xval)
309         idx = (<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>slice(-k, None) if k &gt; 0 else slice(-k))
310         goal = np.argsort(xval)[idx].astype('int32')
311         utt.assert_allclose(np.sort(xval[</b></font>yval]), np.sort(xval[goal]))
312     @utt.parameterized.expand(product(
313         ((17, 15), (2, 3, 5, 7, 11), (500, 5, 3)),  # NB: Test may fail with bigger sizes (e.g. (2017, 5, 3)) due to "too many resources requested" kernel error on some GPUs.
314         (-1, '(1+n)//2', '-n', '1-n'),
315         ('float32', 'int32'),
316         (False,),
317         ('int32', 'int64')))
318     def test_argtopk_nd(self, shp, k_, dtype, sorted, idx_dtype):
319         ndim = len(shp)
320         for axis in range(-ndim, ndim):
321             if isinstance(k_, str):
322                 k = eval(k_.replace('n', str(shp[axis])))
323             else:
324                 k = k_
325             if k == 0:
326                 continue
327 <a name="12"></a>            x = theano.tensor.tensor(
328                 name='x', broadcastable=(False,) * len(shp), dtype=dtype)
329             y = argtopk(x, k, axis=axis, sorted=sorted, idx_dtype=idx_dtype)
330             fn = theano.function<font color="#571b7e"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>([x], y, mode=self.mode)
331             assert any([isinstance(n.op, self.op_class) for n in fn.maker.fgraph.</b></font>apply_nodes])
332             size = reduce(int.__mul__, shp)
333             xval = gen_unique_vector(size, dtype).reshape(shp)
334             yval = fn(xval)
335 <a name="11"></a>            idx = slice(-k, None) if k &gt; 0 else slice(-k)
336             l = axis % ndim
337             r = ndim - l
338             idx = (<font color="#b041ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>slice(None),) * l + (idx,) + (slice(None),) * (r - 1)
339             goal = np.argsort(xval, axis=axis)[idx].astype(</b></font>idx_dtype)
340             assert np.all(np.sort(yval, axis=axis) == np.sort(goal, axis=axis))
341     @utt.parameterized.expand(product(
342         ((257,), (17, 15), (5, 3, 5, 3), (2, 3, 5, 7, 11)),
343         (1, -1, '(1+n)//2', 'n-1', '-n', '1-n'), (False,)))
344     def test_grad(self, shp, k_, sorted):
345         ndim = len(shp)
346         for axis in range(-ndim, ndim):
347             if isinstance(k_, str):
348                 k = eval(k_.replace('n', str(shp[axis])))
349             else:
350                 k = k_
351             if k == 0:
352                 continue
353             xval = gen_unique_vector(
354                 reduce(int.__mul__, shp),
355                 dtype=theano.config.floatX
356             ).reshape(shp)
357             utt.verify_grad(lambda x: topk(x, k, axis=axis, sorted=sorted), [xval], eps=1e-2)
358 class TopKInferShapeTester(utt.InferShapeTester):
359     @utt.parameterized.expand(product(
360         ((2, 3), (15, 17), (11, 7, 5), (2, 3, 5, 7, 11), (2, 4, 3, 1)),
361         (1, '(1+n)//2', 'n-1', 'n')))
362     def test_combined_infer_shape(self, shp, k_):
363         ndim = len(shp)
364         for axis in range(-ndim, ndim):
365             if isinstance(k_, str):
366                 k = eval(k_.replace('n', str(shp[axis])))
367             else:
368                 k = k_
369             if k == 0:
370                 continue
371             x = theano.tensor.tensor(
372                 name='x', broadcastable=(False,) * len(shp),
373                 dtype=theano.config.floatX)
374             yv, yi = topk_and_argtopk(x, k, axis=axis, sorted=False, idx_dtype='int32')
375             size = reduce(int.__mul__, shp)
376             xval = gen_unique_vector(size, theano.config.floatX).reshape(shp)
377             self._compile_and_check(
378                 [x], [yv, yi], [xval], TopKOp)
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>test_opt_4.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 from __future__ import absolute_import, print_function, division
2 import copy
3 import logging
4 import time
5 import unittest
6 import numpy as np
7 from six.moves import xrange
8 from nose.plugins.skip import SkipTest
9 from nose.tools import assert_raises, assert_true
10 import theano
11 import theano.scalar as scal
12 from six import StringIO
13 from theano import compile
14 from theano.compile import deep_copy_op, DeepCopyOp
15 from theano.compile import get_mode
16 from theano import config
17 from theano import function
18 from theano import gof
19 from theano import pprint
20 from theano import shared
21 from theano.gof import FunctionGraph
22 import theano.tensor.opt as opt
23 from theano.tensor.opt import (
24     local_add_specialize,
25     local_dimshuffle_lift,
26     local_useless_dimshuffle_in_reshape,
27     local_useless_alloc,
28     local_merge_alloc,
29     local_greedy_distributor,
30     local_useless_reshape,
31     local_reshape_to_dimshuffle,
32     mul_canonizer,
33     Shape_i,
34     Assert,
35     MakeVector,
36     make_vector,
37     local_canonicalize_alloc
38 <a name="5"></a>    )
39 from theano import tensor
40 from theano import tensor as T
41 <font color="#151b8d"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>from theano.tensor import scalar, iscalar, lscalar, fscalar, dscalar
42 from theano.tensor import vector, lvector, fvector, dvector
43 from theano.tensor import matrix, fmatrix, dmatrix, tensor3
44 from theano.tensor import vectors, matrices, fmatrices, dmatrices
45 from theano.tensor import (
46     AdvancedSubtensor,
47     AdvancedSubtensor1,
48     as_tensor_variable,
49     IncSubtensor,
50     AdvancedIncSubtensor,
51     AdvancedIncSubtensor1,
52     inplace,
53     Join,
54     join,
55     Subtensor,
56     TensorType,
57     tile
58     )
59 from theano.tensor.elemwise import DimShuffle
60 from theano.tensor.type import values_eq_approx_remove_nan
61 from theano.tests import unittest_tools as utt
62 from theano.gof.opt import check_stack_trace, out2in
63 from theano import change_flags
64 from nose.plugins.attrib import attr
65 mode_opt = theano.config.</b></font>mode
66 if mode_opt == 'FAST_COMPILE':
67     mode_opt = 'FAST_RUN'
68 mode_opt = theano.compile.mode.get_mode(mode_opt)
69 dimshuffle_lift = out2in(local_dimshuffle_lift)
70 _optimizer_stabilize = gof.Query(include=['fast_run'])
71 _optimizer_stabilize.position_cutoff = 1.51
72 _optimizer_stabilize = compile.optdb.query(_optimizer_stabilize)
73 _optimizer_specialize = gof.Query(include=['fast_run'])
74 _optimizer_specialize.position_cutoff = 2.01
75 _optimizer_specialize = compile.optdb.query(_optimizer_specialize)
76 _optimizer_fast_run = gof.Query(include=['fast_run'])
77 _optimizer_fast_run = compile.optdb.query(_optimizer_fast_run)
78 def ds(x, y):
79     return DimShuffle(x.type.broadcastable, y)(x)
80 def optimize(g, level='fast_run'):
81     if level == 'fast_run':
82         _optimizer_fast_run.optimize(g)
83     elif level == 'specialize':
84         _optimizer_specialize.optimize(g)
85     elif level == 'stabilize':
86         _optimizer_stabilize.optimize(g)
87     else:
88         raise ValueError(level)
89     return g
90 def inputs(xbc=(0, 0), ybc=(0, 0), zbc=(0, 0)):
91     x = TensorType(broadcastable=xbc, dtype='float64')('x')
92     y = TensorType(broadcastable=ybc, dtype='float64')('y')
93     z = TensorType(broadcastable=zbc, dtype='float64')('z')
94     return x, y, z
95 class test_dimshuffle_lift(unittest.TestCase):
96     def test_double_transpose(self):
97         x, y, z = inputs()
98         e = ds(ds(x, (1, 0)), (1, 0))
99         g = FunctionGraph([x], [e])
100         self.assertTrue(str(g) == "[InplaceDimShuffle{1,0}(InplaceDimShuffle{1,0}(x))]")
101         dimshuffle_lift.optimize(g)
102         self.assertTrue(str(g) == "[x]")
103     def test_merge2(self):
104         x, y, z = inputs()
105         e = ds(ds(x, (1, 'x', 0)), (2, 0, 'x', 1))
106         g = FunctionGraph([x], [e])
107         self.assertTrue(str(g) == "[InplaceDimShuffle{2,0,x,1}(InplaceDimShuffle{1,x,0}(x))]",
108                         str(g))
109         dimshuffle_lift.optimize(g)
110         self.assertTrue(str(g) == "[InplaceDimShuffle{0,1,x,x}(x)]", str(g))
111         self.assertTrue(check_stack_trace(g, ops_to_check='all'))
112     def test_elim3(self):
113         x, y, z = inputs()
114         e = ds(ds(ds(x, (0, 'x', 1)), (2, 0, 'x', 1)), (1, 0))
115         g = FunctionGraph([x], [e])
116         self.assertTrue(str(g) == ("[InplaceDimShuffle{1,0}(InplaceDimShuffle{2,0,x,1}"
117                                    "(InplaceDimShuffle{0,x,1}(x)))]"),
118                         str(g))
119         dimshuffle_lift.optimize(g)
120         self.assertTrue(str(g) == "[x]", str(g))
121     def test_lift(self):
122         x, y, z = inputs([False] * 1, [False] * 2, [False] * 3)
123         e = x + y + z
124         g = FunctionGraph([x, y, z], [e])
125         init_str_g_inplace = (
126             "[Elemwise{add,no_inplace}(InplaceDimShuffle{x,0,1}"
127             "(Elemwise{add,no_inplace}(InplaceDimShuffle{x,0}(x), y)), z)]")
128         init_str_g_noinplace = (
129             "[Elemwise{add,no_inplace}(DimShuffle{x,0,1}"
130             "(Elemwise{add,no_inplace}(DimShuffle{x,0}(x), y)), z)]")
131         self.assertTrue(str(g) in (init_str_g_inplace, init_str_g_noinplace),
132                         str(g))
133         opt_str_g_inplace = (
134             "[Elemwise{add,no_inplace}(Elemwise{add,no_inplace}"
135             "(InplaceDimShuffle{x,x,0}(x), InplaceDimShuffle{x,0,1}(y)), z)]")
136         opt_str_g_noinplace = (
137             "[Elemwise{add,no_inplace}(Elemwise{add,no_inplace}"
138             "(DimShuffle{x,x,0}(x), DimShuffle{x,0,1}(y)), z)]")
139         dimshuffle_lift.optimize(g)
140         self.assertTrue(str(g) in (opt_str_g_inplace, opt_str_g_noinplace),
141                         str(g))
142         self.assertTrue(check_stack_trace(g, ops_to_check='all'))
143     def test_recursive_lift(self):
144         v = T.vector(dtype="float64")
145         m = T.matrix(dtype="float64")
146         out = ((v + 42) * (m + 84)).T
147         g = FunctionGraph([v, m], [out])
148         init_str_g = ("[InplaceDimShuffle{1,0}(Elemwise{mul,no_inplace}"
149                       "(InplaceDimShuffle{x,0}(Elemwise{add,no_inplace}"
150                       "(&lt;TensorType(float64, vector)&gt;, "
151                       "InplaceDimShuffle{x}(TensorConstant{42}))), "
152                       "Elemwise{add,no_inplace}"
153                       "(&lt;TensorType(float64, matrix)&gt;, "
154                       "InplaceDimShuffle{x,x}(TensorConstant{84}))))]")
155         self.assertTrue(str(g) == init_str_g)
156         new_out = local_dimshuffle_lift.transform(g.outputs[0].owner)[0]
157         new_g = FunctionGraph(g.inputs, [new_out])
158         opt_str_g = ("[Elemwise{mul,no_inplace}(Elemwise{add,no_inplace}"
159                      "(InplaceDimShuffle{0,x}(&lt;TensorType(float64, vector)&gt;), "
160                      "InplaceDimShuffle{x,x}(TensorConstant{42})), "
161                      "Elemwise{add,no_inplace}(InplaceDimShuffle{1,0}"
162                      "(&lt;TensorType(float64, matrix)&gt;), "
163                      "InplaceDimShuffle{x,x}(TensorConstant{84})))]")
164         self.assertTrue(str(new_g) == opt_str_g)
165         self.assertTrue(check_stack_trace(new_g, ops_to_check='all'))
166     def test_useless_dimshuffle(self):
167         x, _, _ = inputs()
168         e = ds(x, (0, 1))
169         g = FunctionGraph([x], [e])
170         self.assertTrue(str(g) == "[InplaceDimShuffle{0,1}(x)]")
171         dimshuffle_lift.optimize(g)
172         self.assertTrue(str(g) == "[x]")
173         self.assertTrue(hasattr(g.outputs[0].tag, 'trace'))
174     def test_dimshuffle_on_broadcastable(self):
175         x, y, z = inputs([False, True], [True, False, True], [False, False, True])
176         u = tensor.constant(1)
177         ds_x = ds(x, (0, 'x'))   # useless
178         ds_y = ds(y, (2, 1, 0))  # useless
179         ds_z = ds(z, (2, 1, 0))  # useful
180         ds_u = ds(u, ('x'))  # useful
181         g = FunctionGraph([x, y, z, u], [ds_x, ds_y, ds_z, ds_u])
182         self.assertTrue(str(g) == "[InplaceDimShuffle{0,x}(x), InplaceDimShuffle{2,1,0}(y), InplaceDimShuffle{2,1,0}(z), InplaceDimShuffle{x}(TensorConstant{1})]")
183         dimshuffle_lift.optimize(g)
184         self.assertTrue(str(g) == "[x, y, InplaceDimShuffle{2,1,0}(z), InplaceDimShuffle{x}(TensorConstant{1})]")
185         self.assertTrue(hasattr(g.outputs[0].tag, 'trace'))
186 def test_local_useless_dimshuffle_in_reshape():
187     vector = TensorType(broadcastable=(False,), dtype='float64')('vector')
188     mat = TensorType(broadcastable=(False, False), dtype='float64')('mat')
189     row = TensorType(broadcastable=(True, False), dtype='float64')('row')
190     col = TensorType(broadcastable=(False, True), dtype='float64')('col')
191     reshape_dimshuffle_vector = tensor.reshape(vector.dimshuffle('x', 0), vector.shape)
192     reshape_dimshuffle_mat = tensor.reshape(mat.dimshuffle('x', 0, 'x', 1), mat.shape)
193     reshape_dimshuffle_row = tensor.reshape(row.dimshuffle(1, 'x'), row.shape)
194     reshape_dimshuffle_col = tensor.reshape(col.dimshuffle(0), col.shape)
195     g = FunctionGraph([vector, mat, row, col],
196                       [reshape_dimshuffle_vector, reshape_dimshuffle_mat,
197                        reshape_dimshuffle_row, reshape_dimshuffle_col])
198     print(str(g))
199     assert_true(str(g) == "[Reshape{1}(InplaceDimShuffle{x,0}(vector), Shape(vector)), "
200                           "Reshape{2}(InplaceDimShuffle{x,0,x,1}(mat), Shape(mat)), "
201                           "Reshape{2}(InplaceDimShuffle{1,x}(row), Shape(row)), "
202                           "Reshape{2}(InplaceDimShuffle{0}(col), Shape(col))]")
203     useless_dimshuffle_in_reshape = out2in(local_useless_dimshuffle_in_reshape)
204     useless_dimshuffle_in_reshape.optimize(g)
205     assert_true(str(g) == "[Reshape{1}(vector, Shape(vector)), "
206                           "Reshape{2}(mat, Shape(mat)), "
207                           "Reshape{2}(row, Shape(row)), "
208                           "Reshape{2}(col, Shape(col))]")
209     assert_true(check_stack_trace(g, ops_to_check='all'))
210     reshape_dimshuffle_mat2 = tensor.reshape(mat.dimshuffle('x', 1, 'x', 0), mat.shape)
211     h = FunctionGraph([mat], [reshape_dimshuffle_mat2])
212     str_h = str(h)
213     useless_dimshuffle_in_reshape.optimize(h)
214     assert_true(str(h) == str_h)
215 def test_add_canonizer_problem0():
216     n_segments = 10
217     label = lscalar('label')
218     segment_labels = label + theano._asarray([0] * n_segments, dtype='int64')
219     r = segment_labels * 5
220     f = function([label], r)
221     f(3)
222     c0 = theano.tensor.constant([True])
223     c1 = theano.tensor.constant([True])
224     theano.function([], c0 + c1)
225 class test_greedy_distribute(unittest.TestCase):
226     def test_main(self):
227         a, b, c, d, x, y, z = matrices('abcdxyz')
228         e = (a / z + b / x) * x * z
229         g = FunctionGraph([a, b, c, d, x, y, z], [e])
230         mul_canonizer.optimize(g)
231         gof.TopoOptimizer(gof.LocalOptGroup(local_greedy_distributor),
232                           order='out_to_in').optimize(g)
233         assert str(pprint(g.outputs[0])) == "((a * x) + (b * z))"
234         e = (a / x + b) * x
235         g = FunctionGraph([a, b, x], [e])
236         mul_canonizer.optimize(g)
237         gof.TopoOptimizer(gof.LocalOptGroup(local_greedy_distributor),
238                           order='out_to_in').optimize(g)
239         assert str(pprint(g.outputs[0])) == "(a + (b * x))"
240 <a name="22"></a>
241     def test_kording_bug(self):
242         x, y = vectors('xy')
243         eps = scalar<font color="#4cc417"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>('eps')
244         s = scalar('s')
245         r = tensor.mul(s - 1,
246                        eps + x / s,
247                        eps + y / s,
248                        s)
249         f = function([s, eps, x, y], r ** 2)
250         s_val = np.asarray(</b></font>4, dtype=config.floatX)
251         eps_val = np.asarray(1.e-6, dtype=config.floatX)
252         x_val = np.asarray([1.5, 2], dtype=config.floatX)
253         y_val = np.asarray([2.3, 3.1], dtype=config.floatX)
254         r0 = f(s_val, eps_val, x_val, y_val)
255         r1 = f(s_val, eps_val, x_val, y_val)
256         r2 = f(s_val, eps_val, x_val, y_val)
257         assert np.all(r0 == r1)
258         assert np.all(r0 == r2)
259 class test_canonize(unittest.TestCase):
260     def test_muldiv(self):
261         x, y, z = matrices('xyz')
262         a, b, c, d = matrices('abcd')
263         e = (-1 * x) / y / (-2 * z)
264         g = FunctionGraph([x, y, z, a, b, c, d], [e])
265         print(pprint(g.outputs[0]))
266         mul_canonizer.optimize(g)
267         print(pprint(g.outputs[0]))
268     def test_elemwise_multiple_inputs_optimisation(self):
269         shp = (5, 5)
270         fx, fy, fz = fmatrices('xyz')
271         dx, dy, dz = dmatrices('xyz')
272         fxv = theano._asarray(np.random.rand(*shp), dtype='float32')
273         fyv = theano._asarray(np.random.rand(*shp), dtype='float32')
274         fzv = theano._asarray(np.random.rand(*shp), dtype='float32')
275         cases = [
276             (fx + fy, (fx, fy), (fxv, fyv), 1, 'float32'),
277             (fx * fy, (fx, fy), (fxv, fyv), 1, 'float32'),
278             (fx + fy + fz + 2, (fx, fy, fz), (fxv, fyv, fzv), 1,
279                 {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
280             (fx * fy * fz * 2, (fx, fy, fz), (fxv, fyv, fzv), 1,
281                 {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
282             (2 + fx + fy + fz + 2, (fx, fy, fz), (fxv, fyv, fzv), 1,
283                 {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
284             (2 * fx * fy * fz * 2, (fx, fy, fz), (fxv, fyv, fzv), 1,
285                 {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
286             (fx * fy * 2 * (fx + fy + fz + 2), (fx, fy, fz), (fxv, fyv, fzv), 2,
287                 {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
288             ]  # [10:11]
289         mode = compile.mode.get_default_mode()
290         opt = gof.Query(["canonicalize"])
291         opt = opt.excluding('local_elemwise_fusion')
292         mode = mode.__class__(linker=mode.linker, optimizer=opt)
293         for id, [g, sym_inputs, val_inputs,
294                  nb_elemwise, out_dtype] in enumerate(cases):
295             if isinstance(out_dtype, dict):
296                 out_dtype = out_dtype[config.cast_policy]
297             f = compile.function(list(sym_inputs), g,
298                                  mode=mode)
299             out = f(*val_inputs)
300             assert(len(f.maker.fgraph.toposort()) == nb_elemwise)
301             assert(out_dtype == out.dtype)
302     def test_elemwise_multiple_inputs_optimisation2(self):
303         raise SkipTest("Current implementation of Canonizer does not "
304                        "implement all cases. Skip the corresponding test.")
305         shp = (5, 5)
306         fx, fy, fz = fmatrices('xyz')
307         dx, dy, dz = dmatrices('xyz')
308         fv = fvector('r').dimshuffle('x', 0)
309         dv = dvector('s').dimshuffle('x', 0)
310         fxv = theano._asarray(np.random.rand(*shp), dtype='float32')
311         fyv = theano._asarray(np.random.rand(*shp), dtype='float32')
312         fzv = theano._asarray(np.random.rand(*shp), dtype='float32')
313         fvv = theano._asarray(np.random.rand(shp[0]), dtype='float32').reshape(1, shp[0])
314         dxv = theano._asarray(np.random.rand(*shp), dtype='float64')
315         dyv = theano._asarray(np.random.rand(*shp), dtype='float64')
316         dzv = theano._asarray(np.random.rand(*shp), dtype='float64')
317         dvv = theano._asarray(np.random.rand(shp[0]), dtype='float64').reshape(1, shp[0])
318         cases = [
319             (fx + fy, (fx, fy), (fxv, fyv), 1, 'float32'),
320             (fx * fy, (fx, fy), (fxv, fyv), 1, 'float32'),
321             (fx + fy + fz, (fx, fy, fz), (fxv, fyv, fzv), 1, 'float32'),
322             (dx + dy + dz, (dx, dy, dz), (dxv, dyv, dzv), 1, 'float64'),
323             (fx * fy * fz, (fx, fy, fz), (fxv, fyv, fzv), 1, 'float32'),
324             (dx * dy * dz, (dx, dy, dz), (dxv, dyv, dzv), 1, 'float64'),
325             (fx * fy * (fx + fy + fz), (fx, fy, fz), (fxv, fyv, fzv), 2, 'float32'),
326             (dx * dy * (dx + dy + dz), (dx, dy, dz), (dxv, dyv, dzv), 2, 'float64'),
327             (fx * fy * (fx + fy + dz), (fx, fy, dz), (dxv, dyv, dzv), 2, 'float64'),  # check mixed type add
328             (dz * fy * (fx + fy), (fx, fy, dz), (dxv, dyv, dzv), 2, 'float64'),  # check mixed type mul
329             (fx + fy + fz + 2, (fx, fy, fz), (fxv, fyv, fzv), 1, 'float32'),
330             (fx * fy * fz * 2, (fx, fy, fz), (fxv, fyv, fzv), 1, 'float32'),
331             (2 + fx + fy + fz, (fx, fy, fz), (fxv, fyv, fzv), 1, 'float32'),
332             (2 * fx * fy * fz, (fx, fy, fz), (fxv, fyv, fzv), 1, 'float32'),
333             (2 + fx + fy + fz + 2, (fx, fy, fz), (fxv, fyv, fzv), 1, 'float32'),
334             (2 * fx * fy * fz * 2, (fx, fy, fz), (fxv, fyv, fzv), 1, 'float32'),
335             (fx * fy * 2 * (fx + fy + fz), (fx, fy, fz), (fxv, fyv, fzv), 2, 'float32'),
336             (fx * fy * (2 + fx + fy + fz), (fx, fy, fz), (fxv, fyv, fzv), 2, 'float32'),
337             (fx * fy * 2 * (fx + fy + fz + 2), (fx, fy, fz), (fxv, fyv, fzv), 2, 'float32'),
338             (fx + fy + fz + fv, (fx, fy, fz, fv), (fxv, fyv, fzv, fvv), 1, 'float32'),
339             (fx * fy * fz * fv, (fx, fy, fz, fv), (fxv, fyv, fzv, fvv), 1, 'float32'),
340             (fv + fx + fy + fz, (fx, fy, fz, fv), (fxv, fyv, fzv, fvv), 1, 'float32'),
341             (fv * fx * fy * fz, (fx, fy, fz, fv), (fxv, fyv, fzv, fvv), 1, 'float32'),
342             (fx * fy * fv * (fx + fy + fz), (fx, fy, fz, fv), (fxv, fyv, fzv, fvv), 2, 'float32'),
343             (fx * fy * (fv + fx + fy + fz), (fx, fy, fz, fv), (fxv, fyv, fzv, fvv), 2, 'float32'),
344             (fx * fy * fv * (fv + fx + fy + fz), (fx, fy, fz, fv), (fxv, fyv, fzv, fvv), 2, 'float32'),
345             (dx + dy + dz + dv, (dx, dy, dz, dv), (dxv, dyv, dzv, dvv), 1, 'float64'),
346             (dx * dy * dz * dv, (dx, dy, dz, dv), (dxv, dyv, dzv, dvv), 1, 'float64'),
347             (dv + dx + dy + dz, (dx, dy, dz, dv), (dxv, dyv, dzv, dvv), 1, 'float64'),
348             (dv * dx * dy * dz, (dx, dy, dz, dv), (dxv, dyv, dzv, dvv), 1, 'float64'),
349             (dx * dy * dv * (dx + dy + dz), (dx, dy, dz, dv), (dxv, dyv, dzv, dvv), 2, 'float64'),
350             (dx * dy * (dv + dx + dy + dz), (dx, dy, dz, dv), (dxv, dyv, dzv, dvv), 2, 'float64'),
351             (dx * dy * dv * (dv + dx + dy + dz), (dx, dy, dz, dv), (dxv, dyv, dzv, dvv), 2, 'float64'),
352             ]  # [10:11]
353         mode = compile.mode.get_default_mode()
354         mode._optimizer = gof.Query(["canonicalize"])
355         mode._optimizer = mode._optimizer.excluding('local_elemwise_fusion')
356         for id, [g, sym_inputs, val_inputs, nb_elemwise, out_dtype] in enumerate(cases):
357             f = compile.function(list(sym_inputs), g,
358                                  mode=mode)
359             out = f(*val_inputs)
360             assert(len(f.maker.fgraph.toposort()) == nb_elemwise)
361             assert(out_dtype == out.dtype)
362     @attr('slow')
363     def test_multiple_case(self):
364         shp = (3, 3)
365         fx, fy, fz, fw = fmatrices('xyzw')
366         dx, dy, dz, dw = dmatrices('xyzw')
367         fv = fvector('r').dimshuffle('x', 0)
368         dv = dvector('s').dimshuffle('x', 0)
369         fxv = theano._asarray(np.random.rand(*shp), dtype='float32')
370         fyv = theano._asarray(np.random.rand(*shp), dtype='float32')
371         fzv = theano._asarray(np.random.rand(*shp), dtype='float32')
372         fwv = theano._asarray(np.random.rand(*shp), dtype='float32')
373         fvv = theano._asarray(np.random.rand(shp[0]), dtype='float32').reshape(1, shp[0])
374         dxv = theano._asarray(np.random.rand(*shp), dtype='float64')
375         dyv = theano._asarray(np.random.rand(*shp), dtype='float64')
376         dzv = theano._asarray(np.random.rand(*shp), dtype='float64')
377         dwv = theano._asarray(np.random.rand(*shp), dtype='float64')
378         dvv = theano._asarray(np.random.rand(shp[0]), dtype='float64').reshape(1, shp[0])
379         mode = compile.mode.get_default_mode()
380         opt = gof.Query(["canonicalize"])
381         opt = opt.including('ShapeOpt', 'local_fill_to_alloc')
382         opt = opt.excluding(
383             'local_elemwise_fusion')
384         mode = mode.__class__(linker=mode.linker, optimizer=opt)
385         for id, (g, sym_inputs, val_inputs, out_dtype) in enumerate([
386                 (fx / fx, [fx], [fxv], 'float32'),
387                 (dx / dx, [dx], [dxv], 'float64'),
388                 (fv / fv, [fv], [fvv], 'float32'),
389                 (dv / dv, [dv], [dvv], 'float64')]):
390             f = compile.function(list(sym_inputs), g,
391                                  mode=mode)
392             out = f(*val_inputs)
393             assert (out == np.ones(shp, dtype=out_dtype)).all()
394             topo = f.maker.fgraph.toposort()
395             if sym_inputs[0].broadcastable[0]:
396                 assert len(topo) == 2
397                 assert isinstance(topo[0].op, Shape_i)
398                 assert isinstance(topo[1].op, tensor.Alloc)
399             else:
400                 assert len(topo) == 3
401                 assert isinstance(topo[0].op, Shape_i)
402                 assert isinstance(topo[1].op, Shape_i)
403                 assert isinstance(topo[2].op, tensor.Alloc)
404             assert(out_dtype == out.dtype)
405         for id, (g, sym_inputs, val_inputs, nb_elemwise, out_dtype) in enumerate([
406                 ((dx * dy) / dx, [dx, dy], [dxv, dyv], 0, 'float64'),
407                 ((fx * fy) / fx, [fx, fy], [fxv, fyv], 0, 'float32'),
408                 ((dv * dy) / dv, [dv, dy], [dvv, dyv], 0, 'float64'),
409                 ((fv * fy) / fv, [fv, fy], [fvv, fyv], 0, 'float32'),
410                 ((dx * dv) / dx, [dx, dv], [dxv, dvv], 1, 'float64'),
411                 ((fx * fv) / fx, [fx, fv], [fxv, fvv], 1, 'float32')
412                 ]):
413             f = compile.function(list(sym_inputs), g,
414                                  mode=mode)
415             out = f(*val_inputs)
416             assert(out_dtype == out.dtype)
417             utt.assert_allclose(out, val_inputs[1])
418             topo = f.maker.fgraph.toposort()
419             if topo and not(len(topo) == 1 and topo[0].op == deep_copy_op):
420                 for node in topo[:-1]:
421                     assert isinstance(node.op, Shape_i)
422                 assert isinstance(topo[-1].op, tensor.Alloc)
423         for id, (g, sym_inputs, val_inputs, nb_elemwise, out_dtype) in enumerate([
424                 ((dx / dy) / dx, [dx, dy], [dxv, dyv], 1, 'float64'),
425                 ((fx / fy) / fx, [fx, fy], [fxv, fyv], 1, 'float32'),
426                 ((dv / dy) / dv, [dv, dy], [dvv, dyv], 1, 'float64'),
427                 ((fv / fy) / fv, [fv, fy], [fvv, fyv], 1, 'float32'),
428                 ((dx / dv) / dx, [dx, dv], [dxv, dvv], 1, 'float64'),
429                 ((fx / fv) / fx, [fx, fv], [fxv, fvv], 1, 'float32'),
430                 ]):
431             f = compile.function(list(sym_inputs), g, mode=mode)
432             out = f(*val_inputs)
433             utt.assert_allclose(out, (1 / val_inputs[1]))
434             topo = f.maker.fgraph.toposort()
435             elem = [t for t in topo if isinstance(t.op, T.Elemwise)]
436             assert len(elem) == nb_elemwise
437             assert isinstance(elem[0].op, (T.Elemwise, ))
438             assert isinstance(elem[0].op.scalar_op, (
439                 theano.scalar.basic.Inv, theano.scalar.basic.TrueDiv))
440             assert(out_dtype == out.dtype)
441         for id, (g, sym_inputs, val_inputs, out_dtype) in enumerate([
442                 ((dx / dy) * (dy / dz) * (dz / dw), [dx, dy, dz, dw], [dxv, dyv, dzv, dwv], 'float64'),
443                 ((fx / fy) * (fy / fz) * (fz / fw), [fx, fy, fz, fw], [fxv, fyv, fzv, fwv], 'float32'),
444                 ((dv / dy) * (dy / dz) * (dz / dw), [dv, dy, dz, dw], [dvv, dyv, dzv, dwv], 'float64'),
445                 ((fv / fy) * (fy / fz) * (fz / fw), [fv, fy, fz, fw], [fvv, fyv, fzv, fwv], 'float32'),
446                 ((dx / dv) * (dv / dz) * (dz / dw), [dx, dv, dz, dw], [dxv, dvv, dzv, dwv], 'float64'),
447                 ((fx / fv) * (fv / fz) * (fz / fw), [fx, fv, fz, fw], [fxv, fvv, fzv, fwv], 'float32'),
448                 ((dx / dy) * (dy / dv) * (dv / dw), [dx, dy, dv, dw], [dxv, dyv, dvv, dwv], 'float64'),
449                 ((fx / fy) * (fy / fv) * (fv / fw), [fx, fy, fv, fw], [fxv, fyv, fvv, fwv], 'float32'),
450                 ((dx / dy) * (dy / dz) * (dz / dv), [dx, dy, dz, dv], [dxv, dyv, dzv, dvv], 'float64'),
451                 ((fx / fy) * (fy / fz) * (fz / fv), [fx, fy, fz, fv], [fxv, fyv, fzv, fvv], 'float32'),
452                 ]):
453             f = compile.function(list(sym_inputs), g, mode=mode)
454             out = f(*val_inputs)
455             utt.assert_allclose(out, (val_inputs[0] / val_inputs[3]))
456             topo = f.maker.fgraph.toposort()
457             assert len(topo) == 1
458             assert isinstance(topo[0].op, (T.Elemwise, ))
459             assert isinstance(topo[0].op.scalar_op, theano.scalar.basic.TrueDiv)
460             assert len(topo[0].inputs) == 2
461             assert(out_dtype == out.dtype)
462         for id, (g, sym_inputs, val_inputs, out_dtype) in enumerate([
463                 (((2.0 * dx) / (4.0 * dy)), [dx, dy], [dxv, dyv], 'float64'),
464                 (((2.0 * fx) / (4.0 * fy)), [fx, fy], [fxv, fyv], {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
465                 (((2.0 * dv) / (4.0 * dy)), [dv, dy], [dvv, dyv], 'float64'),
466                 (((2.0 * fv) / (4.0 * fy)), [fv, fy], [fvv, fyv], {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
467                 (((2.0 * dx) / (4.0 * dv)), [dx, dv], [dxv, dvv], 'float64'),
468                 (((2.0 * fx) / (4.0 * fv)), [fx, fv], [fxv, fvv], {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
469                 ]):
470             if isinstance(out_dtype, dict):
471                 out_dtype = out_dtype[config.cast_policy]
472             f = compile.function(list(sym_inputs), g, mode=mode)
473             out = f(*val_inputs)
474             utt.assert_allclose(out, (0.5 * val_inputs[0] / val_inputs[1]))
475             topo = f.maker.fgraph.toposort()
476             assert len(topo) == 2
477             assert isinstance(topo[0].op, (T.Elemwise, ))
478             assert isinstance(topo[0].op.scalar_op, theano.scalar.basic.Mul)
479             assert len(topo[0].inputs) == 2
480             assert isinstance(topo[1].op, (T.Elemwise, ))
481             assert isinstance(topo[1].op.scalar_op, theano.scalar.basic.TrueDiv)
482             assert len(topo[1].inputs) == 2
483             assert(out_dtype == out.dtype)
484         for id, (g, sym_inputs, val_inputs, out_dtype) in enumerate([
485                 ((2 * dx) / 2, [dx], [dxv], 'float64'),
486                 ((2 * fx) / 2, [fx], [fxv], {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
487                 ((2 * dv) / 2, [dv], [dvv], 'float64'),
488                 ((2 * fv) / 2, [fv], [fvv], {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
489                 ]):
490             if isinstance(out_dtype, dict):
491                 out_dtype = out_dtype[config.cast_policy]
492             f = compile.function(list(sym_inputs), g, mode=mode)
493             out = f(*val_inputs)
494             utt.assert_allclose(out, val_inputs[0])
495             topo = f.maker.fgraph.toposort()
496             assert len(topo) == 1
497             topo[0].op == deep_copy_op
498             assert(out_dtype == out.dtype)
499         for id, (g, sym_inputs, val_inputs, out_dtype) in enumerate([
500                 (dx / abs(dx), [dx], [0.5 - dxv], 'float64'),
501                 (fx / abs(fx), [fx], [0.5 - fxv], 'float32'),
502                 (dx / abs(dx), [dx], [0.1 * dxv], 'float64'),
503                 (fx / abs(fx), [fx], [0.1 * fxv], 'float32'),
504                 (dv / abs(dv), [dv], [0.5 - dvv], 'float64'),
505                 (fv / abs(fv), [fv], [0.5 - fvv], 'float32'),
506                 ]):
507             f = compile.function(list(sym_inputs), g, mode=mode)
508             out = f(*val_inputs)
509             assert np.all(np.isfinite(out))
510             utt.assert_allclose(out, np.sign(val_inputs[0]))
511             assert(out_dtype == out.dtype)
512             assert len(f.maker.fgraph.toposort()) == 1
513         for id, (g, sym_inputs, val_inputs, out_dtype) in enumerate([
514                 ((2 * dx) / (3 * abs(dx)), [dx], [0.5 - dxv], 'float64'),
515                 ((2 * fx) / (3 * abs<font color="#c58917"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(fx)), [fx], [0.5 - fxv],
516                     {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
517                 ((2 * dx) / (3 * abs(dx)), [dx], [0.1 * dxv], 'float64'),
518                 ((2 * fx) / (3 * abs(fx)), [fx], [0.1 * fxv],
519                     {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
520                 ((2 * dv) / (3 * abs(dv)), [dv], [0.5 - dvv], 'float64'),
521                 ((2 * fv) / (3 * abs(</b></font>fv)), [fv], [0.5 - fvv],
522                     {'custom': 'float32', 'numpy+floatX': config.floatX, 'numpy': 'float64'}),
523                 ]):
524             if isinstance(out_dtype, dict):
525                 out_dtype = out_dtype[config.cast_policy]
526             f = compile.function(list(sym_inputs), g,
527                                  mode=mode)
528             topo = f.maker.fgraph.toposort()
529             out = f(*val_inputs)
530             assert np.all(np.isfinite(out))
531             utt.assert_allclose(out, np.sign(val_inputs[0]) * 2 / 3)
532             assert(out_dtype == out.dtype)
533     def test_abs_mul_div(self):
534         x = T.dscalar()
535         if theano.config.mode == 'FAST_COMPILE':
536             mode = theano.compile.mode.get_mode('FAST_RUN').excluding(
537                 "local_elemwise_fusion")
538         else:
539             mode = theano.compile.mode.get_default_mode().excluding(
540                 "local_elemwise_fusion")
541         f = theano.function([x], [(4 * x) / abs(2 * x)], mode=mode)
542         print(f.maker.fgraph.toposort())
543         print()
544         f(.1)
545         f(-1)
546         if not isinstance(mode, theano.compile.debugmode.DebugMode):
547             assert np.isfinite(f(0))
548         assert len(f.maker.fgraph.toposort()) == 2
549         assert f.maker.fgraph.toposort()[0].op == T.sgn
550         f = theano.function([x], [(4 * x) / abs(x / 2)], mode=mode)
551         print(f.maker.fgraph.toposort())
552         print()
553         f(.1)
554         f(-1)
555         if not isinstance(mode, theano.compile.debugmode.DebugMode):
556             assert np.isfinite(f(0))
557         assert len(f.maker.fgraph.toposort()) == 2
558         assert f.maker.fgraph.toposort()[0].op == T.sgn
559     def test_multiple_case_that_fail(self):
560         raise SkipTest("Current implementation of Canonizer does not "
561                        "implement all cases. Skip the corresponding test.")
562         shp = (4, 4)
563         fx, fy, fz = fmatrices('xyz')
564         dx, dy, dz = dmatrices('xyz')
565         fxv = theano._asarray(np.random.rand(*shp), dtype='float32')
566         fyv = theano._asarray(np.random.rand(*shp), dtype='float32')
567         fzv = theano._asarray(np.random.rand(*shp), dtype='float32')
568         dxv = theano._asarray(np.random.rand(*shp), dtype='float32')
569         dyv = theano._asarray(np.random.rand(*shp), dtype='float32')
570         dzv = theano._asarray(np.random.rand(*shp), dtype='float32')
571         mode = compile.mode.get_default_mode()
572         opt = gof.Query(["canonicalize"])
573         opt = opt.excluding('local_elemwise_fusion')
574         mode = mode.__class__(linker=mode.linker, optimizer=opt)
575         for (g, sym_inputs, val_inputs, out_dtype) in [
576                 ((dx / dy) / dz, [dx, dy, dz], [dxv, dyv, dzv], 'float64'),
577                 ((fx / fy) / fz, [fx, fy, fz], [fxv, fyv, fzv], 'float32')
578                 ]:
579             f = compile.function(list(sym_inputs), g, mode=mode)
580             out = f(*val_inputs)
581             utt.assert_allclose(out, val_inputs[0] / val_inputs[1] / val_inputs[2])
582             topo = f.maker.fgraph.toposort()
583             assert len(topo) == 2
584             assert isinstance(topo[0].op, (T.Elemwise, ))
585             assert isinstance(topo[0].op.scalar_op, theano.scalar.basic.Inv)
586             assert len(topo[0].inputs) == 1
587             assert(out_dtype == out.dtype)
588         for (g, sym_inputs, val_inputs, out_dtype) in [
589                 (dx / (dy / dz), [dx, dy, dz], [dxv, dyv, dzv], 'float64'),
590                 (fx / (fy / fz), [fx, fy, fz], [fxv, fyv, fzv], 'float32')
591                 ]:
592             f = compile.function(list(sym_inputs), g,
593                                  mode=mode)
594             out = f(*val_inputs)
595             utt.assert_allclose(out, val_inputs[0] / (val_inputs[1] / val_inputs[2]))
596             topo = f.maker.fgraph.toposort()
597             assert len(topo) == 2
598             assert isinstance(topo[0].op, (T.Elemwise, ))
599             assert isinstance(topo[0].op.scalar_op, theano.scalar.basic.Inv)
600             assert len(topo[0].inputs) == 1
601             assert(out_dtype == out.dtype)
602     def test_dont_merge_if_multiple_client(self):
603         raise SkipTest("Not implemented")
604     def test_canonicalize_nan(self):
605         sio = StringIO()
606         handler = logging.StreamHandler(sio)
607         handler.setLevel(logging.ERROR)
608         logging.getLogger('theano.gof.opt').addHandler(handler)
609         try:
610             x = vector()
611             theano.function([x], x + np.nan)
612         finally:
613             logging.getLogger('theano.gof.opt').removeHandler(handler)
614         assert not sio.getvalue()
615 def test_local_merge_abs():
616     x, y, z = T.matrices('xyz')
617     x_val = np.random.rand(5, 5).astype(config.floatX)
618     y_val = np.random.rand(5, 5).astype(config.floatX)
619     z_val = np.random.rand(5, 5).astype(config.floatX)
620     mode = theano.config.mode
621     if mode == "FAST_COMPILE":
622         mode = "FAST_RUN"
623     mode = theano.compile.mode.get_mode(mode).excluding(
624         "local_elemwise_fusion")
625     f = theano.function([y, z], (abs(y * z * -2)), mode=mode)
626     f(y_val, z_val)
627     assert isinstance(f.maker.fgraph.toposort()[1].op.scalar_op, scal.Abs)
628     assert len(f.maker.fgraph.toposort()) == 2
629 <a name="21"></a>    f = theano.function([x, y], abs(x / y), mode=mode)
630     f(x_val, y_val)
631     assert isinstance(f.maker.fgraph.toposort()[1].op.scalar_op, scal.Abs)
632     assert len(f.maker<font color="#947010"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.fgraph.toposort()) == 2
633 def test_merge_abs_bugfix():
634     input = T.matrix()
635     step1 = input / input.sum(0)
636     step2 =</b></font> step1 / step1.sum(1)
637     l1_norm = T.abs_(step2).sum()
638     theano.function([input], T.grad(l1_norm, input))
639 def test_mixeddiv():
640     i = iscalar()
641     d = dscalar()
642     assert 0 == function([i, d], d * (i // (i + 1)))(3, 1.0)
643 def test_const_type_in_mul_canonizer():
644     input = dmatrix()
645     w = dmatrix()
646     visb = dvector()
647     hidb = dvector()
648     betas = dvector()
649     a = dvector()
650     def sigm(x):
651         return 1. / (1 + tensor.exp(-x))
652     hid = sigm((tensor.dot(w, input) + hidb) * betas)
653     vis_gauss1 = (tensor.dot(w.T, hid) + visb) * betas / (2 * a * a)
654     vis_gauss2 = (tensor.dot(w.T, hid) + visb) * betas / (2. * a * a)
655     f1 = function([input, w, visb, hidb, betas, a], vis_gauss1)
656     f2 = function([input, w, visb, hidb, betas, a], vis_gauss2)
657     ival = np.random.rand(5, 5)
658     wval = np.random.rand(5, 5)
659     visbval = np.random.rand(5)
660     hidbval = np.random.rand(5)
661     betaval = np.random.rand(5)
662     aval = np.random.rand(5)
663     utt.assert_allclose(
664         f2(ival, wval, visbval, hidbval, betaval, aval),
665         f1(ival, wval, visbval, hidbval, betaval, aval))
666 def test_cast_in_mul_canonizer():
667     x, y = tensor.vectors('xy')
668     m = tensor.minimum(x, y)
669     o = m.sum()
670     go = tensor.fill(o, 1)
671     e = tensor.eq(go, x)
672     o1 = (1 - e) * go
673     o2 = e * go
674     mode = theano.compile.get_default_mode().excluding('fusion').including('fast_run')
675     f = theano.function([x, y], [o1, o2], mode=mode)
676     theano.printing.debugprint(f, print_type=True)
677     nodes = f.maker.fgraph.apply_nodes
678     assert len([n for n in nodes if isinstance(getattr(n.op, 'scalar_op', None),
679                                                theano.scalar.Identity)]) == 0
680     assert len([n for n in nodes if isinstance(getattr(n.op, 'scalar_op'),
681                                                theano.scalar.Cast)]) == 1
682     f([1], [1])
683 class test_fusion(unittest.TestCase):
684     mode = copy.copy(compile.mode.get_default_mode())
685     _shared = staticmethod(shared)
686     topo_exclude = ()
687     def do(self, mode, shared_fn, shp, nb_repeat=1, assert_len_topo=True, slice=None):
688         def my_init(shp, dtype='float64', num=0):
689             ret = np.zeros(shp, dtype=dtype) + num
690             return ret
691         fw, fx, fy, fz = [theano.tensor.tensor(dtype='float32',
692                                                broadcastable=[False] * len(shp),
693                                                name=n) for n in 'wxyz']
694         dw, dx, dy, dz = [theano.tensor.tensor(dtype='float64',
695                                                broadcastable=[False] * len(shp),
696                                                name=n) for n in 'wxyz']
697         ix, iy, iz = [theano.tensor.tensor(dtype='int32',
698                                            broadcastable=[False] * len(shp),
699                                            name=n) for n in 'xyz']
700         fv = fvector('v')
701         fs = fscalar('s')
702         fwv = my_init(shp, 'float32', 1)
703         fxv = my_init(shp, 'float32', 2)
704         fyv = my_init(shp, 'float32', 3)
705         fzv = my_init(shp, 'float32', 4)
706         fvv = theano._asarray(np.random.rand(shp[0]), dtype='float32')
707 <a name="18"></a>        fsv = np.asarray(np.random.rand(), dtype='float32')
708         dwv = my_init(shp, 'float64', 5)
709         ixv = theano._asarray(my_init(shp, num=60), dtype='int32')
710         iyv = theano._asarray(my_init<font color="#800517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(shp, num=70), dtype='int32')
711         izv = theano._asarray(my_init(shp, num=70), dtype='int32')
712         fwx = fw + fx
713         ftanx = theano.</b></font>tensor.tan(fx)
714         cases = [
715             (fx + fy + fz, (fx, fy, fz), (fxv, fyv, fzv), 1, fxv +
716                 fyv + fzv, 'float32'),  # 0
717             (fx * fy * fz, (fx, fy, fz), (fxv, fyv, fzv), 1, fxv *
718                 fyv * fzv, 'float32'),  # 1
719             (fx + fy * fz, (fx, fy, fz), (fxv, fyv, fzv), 1, fxv +
720                 fyv * fzv, 'float32'),  # 2
721             (fx * fy + fz, (fx, fy, fz), (fxv, fyv, fzv), 1, fxv *
722                 fyv + fzv, 'float32'),  # 3
723             (fw + fx + fy + fz, (fw, fx, fy, fz), (fwv, fxv, fyv, fzv), 1,
724                 fwv + fxv + fyv + fzv, 'float32'),
725             ((fw + fx) + (fy + fz), (fw, fx, fy, fz), (fwv, fxv, fyv, fzv), 1,
726                 fwv + fxv + fyv + fzv, 'float32'),  # 5
727             (((fw + fx) + fy) + fz, (fw, fx, fy, fz), (fwv, fxv, fyv, fzv), 1,
728                 fwv + fxv + fyv + fzv, 'float32'),
729             ((fw + (fx + fy)) + fz, (fw, fx, fy, fz), (fwv, fxv, fyv, fzv), 1,
730                 fwv + fxv + fyv + fzv, 'float32'),
731             ((fw + (fx + fy) + fz), (fw, fx, fy, fz), (fwv, fxv, fyv, fzv), 1,
732                 fwv + fxv + fyv + fzv, 'float32'),
733             (fw + (fx + (fy + fz)), (fw, fx, fy, fz), (fwv, fxv, fyv, fzv), 1,
734                 fwv + fxv + fyv + fzv, 'float32'),
735             ((fw + fx) + (fy + fz), (fw, fx, fy, fz), (fwv, fxv, fyv, fzv), 1,
736                 fwv + fxv + fyv + fzv, 'float32'),  # 10
737             (fw * fx * fy * fz, (fw, fx, fy, fz), (fwv, fxv, fyv, fzv), 1,
738                 fwv * fxv * fyv * fzv, 'float32'),
739             (fw + fx * fy * fz, (fw, fx, fy, fz), (fwv, fxv, fyv, fzv), 1,
740                 fwv + fxv * fyv * fzv, 'float32'),
741             (fx + fy * fz * fx, (fx, fy, fz), (fxv, fyv, fzv), 1,
742                 fxv + fyv * fzv * fxv, 'float32'),
743             (fx * fy + fz + fy, (fx, fy, fz), (fxv, fyv, fzv), 1,
744                 fxv * fyv + fzv + fyv, 'float32'),
745             (fx * fy * fz * fw + fx + fy + fz + fw, (fw, fx, fy, fz), (fwv, fxv, fyv, fzv), 1,
746                 fxv * fyv * fzv * fwv + fxv + fyv + fzv + fwv, 'float32'),  # 15
747             ((fw + fx) + (fy + fz) + 2., (fw, fx, fy, fz), (fwv, fxv, fyv, fzv),
748                 1, fwv + fxv + fyv + fzv + 2, 'float32'),
749             (((fw + fx) + 2. + fy) + fz, (fw, fx, fy, fz), (fwv, fxv, fyv, fzv),
750                 1, fwv + fxv + fyv + fzv + 2, 'float32'),
751             ((fw + (fx + 2. + fy)) + fz, (fw, fx, fy, fz), (fwv, fxv, fyv, fzv),
752                 1, fwv + fxv + fyv + fzv + 2, 'float32'),
753             ((fw + (fx + fy) + 2 + fz), (fw, fx, fy, fz), (fwv, fxv, fyv, fzv),
754                 1, fwv + fxv + fyv + fzv + 2, 'float32'),
755             (fw + (fx + (fy + fz) + 2.), (fw, fx, fy, fz), (fwv, fxv, fyv, fzv),
756                 1, fwv + fxv + fyv + fzv + 2, 'float32'),  # 20
757             (2 + (fw + fx) + (fy + fz), (fw, fx, fy, fz), (fwv, fxv, fyv, fzv),
758                 1, fwv + fxv + fyv + fzv + 2, 'float32'),
759             (2 + (dw + fx) + (fy + fz), (dw, fx, fy, fz), (dwv, fxv, fyv, fzv),
760                 1, dwv + fxv + fyv + fzv + 2, 'float64'),
761             (2 + (fw + dw) + (fy + fz), (fw, dw, fy, fz), (fwv, dwv, fyv, fzv),
762                 1, fwv + dwv + fyv + fzv + 2, 'float64'),
763             (2 + (fw + fx) + (dw + fz), (fw, fx, dw, fz), (fwv, fxv, dwv, fzv),
764                 1, fwv + fxv + dwv + fzv + 2, 'float64'),
765             (2 + (fw + fx) + (fy + dw), (fw, fx, fy, dw), (fwv, fxv, fyv, dwv),
766                 1, fwv + fxv + fyv + dwv + 2, 'float64'),  # 25
767             ((fwx.sum()) + (fwx) + (fy + fz), (fw, fx, fy, fz), (fwv, fxv, fyv, fzv),
768                 4, (fwv + fxv).sum() + fwv + fxv + fyv + fzv, 'float32'),
769             (fx + fy + tensor.cos(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
770                 fxv + fyv + np.cos(fzv), 'float32'),
771             (fx + fy + tensor.cosh(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
772                 fxv + fyv + np.cosh(fzv), 'float32'),
773             (fx + fy + abs(fz), (fx, fy, fz), (fxv, fyv, fzv), 1, fxv + fyv +
774                 np.absolute(fzv), 'float32'),
775             (ix + iy + abs(iz), (ix, iy, iz), (ixv, iyv, izv), 1, ixv + iyv +
776                 np.absolute(izv), 'int32'),  # 30
777             (fx + fy + theano.tensor.log(fz), (fx, fy, fz), (fxv, fyv, fzv),
778                 1, fxv + fyv + np.log(fzv), 'float32'),
779             (fx + fy + theano.tensor.log2(fz), (fx, fy, fz), (fxv, fyv, fzv),
780                 1, fxv + fyv + np.log2(fzv), 'float32'),
781             (fx + fy + theano.tensor.log10(fz), (fx, fy, fz), (fxv, fyv, fzv),
782                 1, fxv + fyv + np.log10(fzv), 'float32'),
783             (fx + fy ** fz, (fx, fy, fz), (fxv, fyv, fzv), 1, fxv + fyv ** fzv,
784                 'float32'),  # pow
785             (fx + fy + theano.tensor.exp(fz), (fx, fy, fz), (fxv, fyv, fzv),
786                 1, fxv + fyv + np.exp(fzv), 'float32'),  # 35
787             (fx - fy - fz, (fx, fy, fz), (fxv, fyv, fzv), 1, fxv - fyv - fzv, 'float32'),
788             (fx - (fy / fz), (fx, fy, fz), (fxv, fyv, fzv), 1, fxv - (fyv / fzv), 'float32'),
789             (fx - theano.tensor.true_div(fy, 2), (fx, fy), (fxv, fyv),
790                 1, fxv - (fyv / 2), 'float32'),
791             (fx - theano.tensor.true_div(fy, fz), (fx, fy, fz), (fxv, fyv, fzv),
792                 1, fxv - (fyv / fzv), 'float32'),
793             (fx - theano.tensor.int_div(ix * 100, iy * 1000), (fx, ix, iy), (fxv, ixv, iyv),
794                 1, fxv - ((ixv * 100) // (iyv * 1000)), {'custom': 'float64', 'numpy + floatX': config.floatX, 'numpy': 'float64'}),  # 40
795             (fx - (fy / 2), (fx, fy), (fxv, fyv), 1, fxv - (fyv / 2), 'float32'),
796             (fx - (fy % fz), (fx, fy, fz), (fxv, fyv, fzv), 1, fxv - (fyv % fzv), 'float32'),
797             (fx - (fy &gt; fz), (fx, fy, fz), (fxv, fyv, fzv), 1, fxv - (fyv &gt; fzv), 'float32'),
798             (fx - (fy &gt;= fz), (fx, fy, fz), (fxv, fyv, fzv), 1, fxv - (fyv &gt;= fzv), 'float32'),
799             (fx - (fy &lt; fz), (fx, fy, fz), (fxv, fyv, fzv), 1, fxv - (fyv &lt; fzv), 'float32'),  # 45
800             (fx - (fy &lt;= fz), (fx, fy, fz), (fxv, fyv, fzv), 1, fxv - (fyv &lt;= fzv), 'float32'),
801             (fx - T.eq(fy, fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
802                 fxv - (fyv == fzv), 'float32'),
803             (fx - T.neq(fy, fz), (fx, fy, fz), (fxv, fyv, fzv), 1, fxv - (
804                 fyv != fzv), 'float32'),
805             (fx - fy + tensor.tan(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
806                 fxv - fyv + np.tan(fzv), 'float32'),
807             (fx - fy + tensor.tanh(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
808                 fxv - fyv + np.tanh(fzv), 'float32'),  # 50
809             (fx - fy + tensor.sin(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
810                 fxv - fyv + np.sin(fzv), 'float32'),
811             (fx - fy + tensor.sinh(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
812                 fxv - fyv + np.sinh(fzv), 'float32'),
813             (fx - fy + theano.tensor.sqr(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
814                 fxv - fyv + (fzv * fzv), 'float32'),
815             (fx - fy + theano.tensor.sqrt(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
816                 fxv - fyv + np.sqrt(fzv), 'float32'),
817             (fx - fy + theano.tensor.inv(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
818                 fxv - fyv + (1 / fzv), 'float32'),  # 55
819             (fx - fy + theano.tensor.neg(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
820                 fxv - fyv + (-fzv), 'float32'),
821             (fx - fy + theano.tensor.round(fz), (fx, fy, fz), (fxv, fyv, fzv), 1,
822                 fxv - fyv + np.round(fzv), 'float32'),
823             (ix - iy + theano.tensor.iround(fz), (ix, iy, fz), (ixv, iyv, fzv), 1,
824                 ixv - iyv + np.round(fzv), 'int64'),
825             (fx - theano.tensor.or_(iy, iz), (fx, iy, iz), (fxv, iyv, izv), 1,
826                 fxv - (iyv | izv), {'custom': 'float64', 'numpy + floatX': config.floatX, 'numpy': 'float64'}),
827             (fx - theano.tensor.xor(iy, iz), (fx, iy, iz), (fxv, iyv, izv), 1,
828                 fxv - (iyv ^ izv), {'custom': 'float64', 'numpy + floatX': config.floatX, 'numpy': 'float64'}),  # 60
829             (fx - theano.tensor.and_(iy, iz), (fx, iy, iz), (fxv, iyv, izv), 1,
830                 fxv - (iyv &amp; izv), {'custom': 'float64', 'numpy + floatX': config.floatX, 'numpy': 'float64'}),
831             (fx - theano.tensor.invert(iy), (fx, iy), (fxv, iyv), 1,
832                 fxv - (~iyv), {'custom': 'float64', 'numpy + floatX': config.floatX, 'numpy': 'float64'}),
833             (fx - theano.tensor.cast(fy, dtype='float64'), (fx, fy), (fxv, fyv), 1,
834                 fxv - np.asarray(fyv, 'float64'), 'float64'),
835             (theano.tensor.pow(fx * fy + fz, fx * fy), (fx, fy, fz), (fxv, fyv, fzv), 1,
836                 np.power(fxv * fyv + fzv, fxv * fyv), 'float32'),
837             (fv + fy ** fz, (fv, fy, fz), (fvv, fyv, fzv), 2, fvv + fyv ** fzv, 'float32'),  # fused with a dimshuffle #65
838             (fv - fy + tensor.tanh(fz), (fv, fy, fz), (fvv, fyv, fzv), 2,
839                 fvv - fyv + np.tanh(fzv), 'float32'),  # fused with a dimshuffle
840             (theano.tensor.mul(fx, fx, fx, fx), (fx,), (fxv,), 1, fxv *
841                 fxv * fxv * fxv, 'float32'),
842             (theano.tensor.mul(fx, ftanx, ftanx), (fx,), (fxv,), 1,
843                 fxv * np.tan(fxv) * np.tan(fxv), 'float32'),
844             (theano.tensor.mul(fx, ftanx, ftanx, fx), (fx,), (fxv,),
845                 1, fxv * np.tan(fxv) * np.tan(fxv) * fxv, 'float32'),
846             (theano.tensor.mul(ftanx, ftanx, fx + fy), (fx, fy), (fxv, fyv),
847                 1, np.tan(fxv) * np.tan(fxv) * (fxv + fyv), 'float32'),  # 70
848             (fx * theano.tensor.sin(fs), (fx, fs), (fxv, fsv), 3,
849                 fxv * np.sin(fsv), 'float32'),
850             ]
851         if slice:
852             cases = cases[slice]
853         times = np.zeros(len(cases))
854         fail1 = []
855         fail2 = []
856         fail3 = []
857         fail4 = []
858         for id, [g, sym_inputs, val_inputs,
859                  nb_elemwise, answer, out_dtype] in enumerate(cases):
860             if isinstance(out_dtype, dict):
861                 out_dtype = out_dtype[config.cast_policy]
862             if shared_fn is None:
863                 f = compile.function(list(sym_inputs), g, mode=mode)
864                 for x in xrange(nb_repeat):
865                     out = f(*val_inputs)
866                 t1 = time.time()
867             else:
868                 out = shared_fn(np.zeros(shp, dtype=out_dtype), 'out')
869                 assert out.dtype == g.dtype
870                 f = function(sym_inputs, [], updates=[(out, g)], mode=mode)
871                 t0 = time.time()
872                 for x in xrange(nb_repeat):
873                     f(*val_inputs)
874                 t1 = time.time()
875                 out = out.get_value()
876             times[id] = t1 - t0
877             atol = 1e-8
878             if out_dtype == 'float32':
879                 atol = 1e-6
880             if not np.allclose(out, answer * nb_repeat, atol=atol):
881                 fail1.append(id)
882                 print("cases", id)
883                 print(val_inputs)
884                 print(out)
885                 print(answer * nb_repeat)
886             topo = f.maker.fgraph.toposort()
887             topo_ = [n for n in topo
888                      if not isinstance(n.op, self.topo_exclude)]
889             if assert_len_topo:
890                 if not len(topo_) == nb_elemwise:
891                     fail3.append((id, topo_, nb_elemwise))
892                 if nb_elemwise == 1:
893                     if len(set(g.owner.inputs)) == len(g.owner.inputs):
894                         expected_len_sym_inputs = np.sum(
895                             [not isinstance(x, theano.gof.Constant)
896                              for x in topo_[0].inputs])
897                         assert expected_len_sym_inputs == len(sym_inputs)
898             if not out_dtype == out.dtype:
899                 fail4.append((id, out_dtype, out.dtype))
900         failed = len(fail1 + fail2 + fail3 + fail4)
901         if failed &gt; 0:
902             print("Executed", len(cases), "cases", "failed", failed)
903             raise Exception("Failed %d cases" % failed, fail1,
904                             fail2, fail3, fail4)
905         return times
906     def test_elemwise_fusion(self):
907         shp = (5, 5)
908         mode = copy.copy(self.mode)
909         mode._optimizer = mode._optimizer.including(
910             'local_elemwise_fusion', 'composite_elemwise_fusion',
911             'canonicalize')
912         self.do(mode, self._shared, shp)
913     @attr('slow')
914     def test_elemwise_fusion_4d(self):
915         shp = (3, 3, 3, 3)
916         mode = copy.copy(self.mode)
917         mode._optimizer = mode._optimizer.including(
918             'local_elemwise_fusion', 'composite_elemwise_fusion',
919             'canonicalize')
920         self.do(mode, self._shared, shp, slice=slice(0, 1))
921     def test_fusion_35inputs(self):
922         inpts = vectors(['i%i' % i for i in xrange(35)])
923         out = tensor.sin(inpts[0])
924         for idx in xrange(1, 35):
925             out = tensor.sin(inpts[idx] + out)
926         f = function(inpts, out, mode=self.mode)
927         f(*[list(range(i, 4 + i)) for i in xrange(35)])
928     def test_pickle_big_fusion(self):
929         if not theano.config.cxx:
930             raise SkipTest("no c compiler, so can't use big elemwise!")
931         factors = []
932         sd = tensor.dscalar()
933         means = tensor.dvector()
934         cst_05 = theano.tensor.constant(.5)
935         cst_m05 = theano.tensor.constant(-.5)
936         cst_2 = theano.tensor.constant(2)
937         cst_m2 = theano.tensor.constant(-2)
938         ones = theano.tensor.constant(np.ones(10))
939         n = 85
940         if theano.config.mode in ["DebugMode", "DEBUG_MODE"]:
941             n = 10
942         for i in xrange(n):
943             f = (cst_m05 * sd ** cst_m2 * (ones - means[i]) ** cst_2 +
944                  cst_05 * tensor.log(cst_05 * (sd ** cst_m2) / np.pi))
945             factors.append(tensor.sum(f))
946         logp = tensor.add(*factors)
947         vars = [sd, means]
948         dlogp = function(vars, [theano.grad(logp, v) for v in vars])
949         dlogp(2, np.random.rand(n))
950     def speed_fusion(self, s=None):
951         shp = (3000, 3000)
952         shp = (1000, 1000)
953         nb_repeat = 50
954         mode1 = copy.copy(self.mode)
955         mode1._optimizer = mode1._optimizer.including('local_elemwise_fusion')
956         mode2 = copy.copy(self.mode)
957         mode2._optimizer = mode2._optimizer.excluding('local_elemwise_fusion')
958         print("test with linker", str(mode1.linker))
959         times1 = self.do(mode1, self._shared, shp, nb_repeat=nb_repeat,
960                          assert_len_topo=False, slice=s)
961         times2 = self.do(mode2, self._shared, shp, nb_repeat=nb_repeat,
962                          assert_len_topo=False, slice=s)
963         print("times1 with local_elemwise_fusion")
964         print(times1, times1.min(), times1.max(), times1.sum())
965         print("times2 without local_elemwise_fusion")
966         print(times2, times2.min(), times2.max(), times2.sum())
967         d = times2 / times1
968         print("times2/times1")
969         print(d)
970         print("min", d.min(), "argmin", d.argmin(), "max", d.max(),
971               "mean", d.mean(), "std", d.std())
972     def test_fusion_inplace(self):
973         mode = copy.copy(self.mode)
974         mode._optimizer = mode._optimizer.including(
975             'local_elemwise_fusion', 'composite_elemwise_fusion',
976             'canonicalize', 'inplace')
977         x, y, z = dmatrices('xyz')
978         f = theano.function([x, y, z], tensor.dot(x, y) + x + y + z, mode=mode)
979         topo = [n for n in f.maker.fgraph.toposort()
980                 if not isinstance(n.op, self.topo_exclude)]
981         assert len(topo) == 2
982         assert topo[-1].op.inplace_pattern
983         f(np.random.random((5, 5)), np.random.random((5, 5)),
984             np.random.random((5, 5)))
985     def speed_log_exp(self):
986         s = slice(31, 36)
987         print("time", self.do(self.mode, self._shared, shp=(1000, 1000),
988                               assert_len_topo=False, slice=s, nb_repeat=100))
989 class TimesN(theano.scalar.basic.UnaryScalarOp):
990     def __eq__(self, other):
991         return super(TimesN, self).__eq__(other) and self.n == other.n
992     def __hash__(self):
993         return super(TimesN, self).__hash__() ^ hash(self.n)
994     def __init__(self, n, *args, **kwargs):
995         self.n = n
996         theano.scalar.basic.UnaryScalarOp.__init__(self, *args, **kwargs)
997     def impl(self, x):
998         return x * self.n
999     def c_support_code_apply(self, node, nodename):
1000         n = str(self.n)
1001         return """
1002         float %(nodename)s_timesn(float x) { return x * %(n)s; }
1003     Test The Composite Ops code generation in a case where there is multiple
1004     scalar ops with support code.
1005         assert (<font color="#b041ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>f1(xval) == xval[:2, :5]).all()
1006         y = tensor.tensor4('x')
1007         yval = np.random.rand(</b></font>1, 10, 1, 3).astype(config.floatX)
1008         assert y.broadcastable == (False, False, False, False)
1009         newy = tensor.Rebroadcast((0, True), (2, True))(y)
1010         assert newy.broadcastable == (True, False, True, False)
1011         f2 = function([y], newy[:, 3, 0, :], mode=mode_opt)
1012         self.assertTrue(check_stack_trace(f2, ops_to_check=[
1013                         Subtensor, tensor.Rebroadcast]))
1014         prog = f2.maker.fgraph.toposort()
1015         assert isinstance(prog[0].op, tensor.Subtensor)
1016         assert isinstance(prog[1].op, tensor.Rebroadcast)
1017         assert (f2(yval) == yval[:, 3, 0, :]).all()
1018         f3 = function([y], newy[:, 3, 0], mode=mode_opt)
1019         self.assertTrue(check_stack_trace(f3, ops_to_check=[
1020             Subtensor, tensor.Rebroadcast]))
1021         prog = f3.maker.fgraph.toposort()
1022         assert isinstance(prog[0].op, tensor.Subtensor)
1023         assert isinstance(prog[1].op, tensor.Rebroadcast)
1024         assert (f3(yval) == yval[:, 3, 0]).all()
1025         z = tensor.tensor4('x')
1026         zval = np.random.rand(4, 10, 3, 1).astype(config.floatX)
1027         assert z.broadcastable == (False, False, False, False)
1028         newz = tensor.Rebroadcast((3, True))(z)
1029         assert newz.broadcastable == (False, False, False, True)
1030         f4 = function([z], newz[:, 3, 0], mode=mode_opt)
1031         self.assertTrue(check_stack_trace(f4, ops_to_check=[
1032             Subtensor, tensor.Rebroadcast]))
1033         prog = f4.maker.fgraph.toposort()
1034         assert isinstance(prog[0].op, tensor.Subtensor)
1035         assert isinstance(prog[1].op, tensor.Rebroadcast)
1036         assert (f4(zval) == zval[:, 3, 0]).all()
1037 class test_local_subtensor_merge(unittest.TestCase):
1038     def setUp(self):
1039         utt.seed_rng()
1040         self.x_shapes = [(2, 2), (5, 3), (4, 1), (1, 2),
1041                          (0, 2), (2, 0), (1, 0), (0, 0)]
1042         self.rng = np.random.RandomState(seed=utt.fetch_seed())
1043     def test_const(self):
1044         x = tensor.matrix('x')
1045         for idx in xrange(-7, 6):
1046             f = function([x], x[idx::][-1], mode=mode_opt)
1047             g = function([x], x[idx::][-1], mode=mode_opt.excluding(
1048                 'local_subtensor_merge'))
1049             self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1050             topo = f.maker.fgraph.toposort()
1051             assert len([t for t in topo
1052                         if isinstance(t.op, tensor.Subtensor)]) == 1
1053             assert isinstance(topo[-1].op, DeepCopyOp)
1054             for x_s in self.x_shapes:
1055                 x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1056                 if idx &lt; x_s[0] and x_s[0] &gt; 0:
1057                     f(x_val)  # let debugmode test something
1058                 else:
1059                     self.assertRaises(IndexError, f, x_val)
1060                     self.assertRaises(IndexError, g, x_val)
1061     def test_scalar(self):
1062         x = tensor.matrix('x')
1063         y = tensor.iscalar('y')
1064         f = function([x, y], x[y::][-1], mode=mode_opt)
1065         g = function([x, y], x[y::][-1],
1066                      mode=mode_opt.excluding('local_subtensor_merge'))
1067         self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1068         topo = f.maker.fgraph.toposort()
1069         assert len([t for t in topo
1070                     if isinstance(t.op, tensor.Subtensor)]) == 1
1071         assert isinstance(topo[-1].op, DeepCopyOp)
1072         for x_s in self.x_shapes:
1073             x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1074             for idx in xrange(-9, 8):
1075                 if (idx &lt; x_s[0]) and (x_s[0] &gt; 0):
1076                     f(x_val, idx)  # let debugmode test something
1077                 else:
1078                     self.assertRaises(IndexError, f, x_val, idx)
1079                     self.assertRaises(IndexError, g, x_val, idx)
1080     @attr('slow')
1081     def test_const2(self):
1082         x = tensor.matrix('x')
1083         for idx in xrange(-8, 7):
1084             f = function([x], x[::-1][idx], mode=mode_opt)
1085             g = function([x], x[::-1][idx],
1086                          mode=mode_opt.excluding('local_subtensor_merge'))
1087             self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1088             topo = f.maker.fgraph.toposort()
1089             assert len([t for t in topo
1090                         if isinstance(t.op, tensor.Subtensor)]) == 1
1091             assert isinstance(topo[-1].op, DeepCopyOp)
1092             for x_s in self.x_shapes:
1093                 x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1094                 if (idx &lt; x_s[0]) and (idx &gt;= -x_s[0]):
1095                     f(x_val)  # let debugmode test something
1096                 else:
1097                     self.assertRaises(IndexError, f, x_val)
1098                     self.assertRaises(IndexError, g, x_val)
1099     def test_scalar2(self):
1100         x = tensor.matrix('x')
1101         y = tensor.iscalar('y')
1102         f = function([x, y], x[::-1][y], mode=mode_opt)
1103         g = function([x, y], x[::-1][y],
1104                      mode=mode_opt.excluding('local_subtensor_merge'))
1105         self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1106         topo = f.maker.fgraph.toposort()
1107         assert len([t for t in topo
1108                     if isinstance(t.op, tensor.Subtensor)]) == 1
1109         assert isinstance(topo[-1].op, DeepCopyOp)
1110         for x_s in self.x_shapes:
1111             x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1112             for idx in xrange(-x_s[0], x_s[0]):
1113                 f(x_val, idx)  # let debugmode test something
1114             for idx in (list(range(x_s[0], 9)) + list(range(-9, -x_s[0]))):
1115                 self.assertRaises(IndexError, f, x_val, idx)
1116                 self.assertRaises(IndexError, g, x_val, idx)
1117     def test_const3(self):
1118         x = tensor.matrix('x')
1119         for idx in xrange(-9, 8):
1120             f = function([x], x[::-1][:idx], mode=mode_opt)
1121             self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1122             topo = f.maker.fgraph.toposort()
1123             assert len([t for t in topo
1124                         if isinstance(t.op, tensor.Subtensor)]) == 1
1125             assert isinstance(topo[-1].op, DeepCopyOp)
1126             for x_s in self.x_shapes:
1127                 x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1128                 f(x_val)  # let debugmode test something
1129     def test_scalar3(self):
1130         x = tensor.matrix('x')
1131         y = tensor.iscalar('y')
1132         f = function([x, y], x[::-1][:y], mode=mode_opt)
1133         self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1134         topo = f.maker.fgraph.toposort()
1135         assert len([t for t in topo
1136                     if isinstance(t.op, tensor.Subtensor)]) == 1
1137         assert isinstance(topo[-1].op, DeepCopyOp)
1138         for x_s in self.x_shapes:
1139             x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1140             for idx in xrange(-7, 7):
1141                 f(x_val, idx)  # let debugmode test something
1142     def test_const4(self):
1143         x = tensor.matrix('x')
1144         for idx1 in xrange(-7, 7):
1145             for idx2 in xrange(-7, 7):
1146                 f = function([x], x[idx1:][:idx2], mode=mode_opt)
1147                 self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1148                 topo = f.maker.fgraph.toposort()
1149                 assert len([t for t in topo
1150                             if isinstance(t.op, tensor.Subtensor)]) == 1
1151                 assert isinstance(topo[-1].op, DeepCopyOp)
1152                 for x_s in self.x_shapes:
1153                     x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1154                     f(x_val)  # let debugmode test something
1155     def test_scalar4(self):
1156         x = tensor.matrix('x')
1157         y = tensor.iscalar('y')
1158         z = tensor.iscalar('y')
1159         f = function([x, y, z], x[y:][:z], mode=mode_opt)
1160         self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1161         topo = f.maker.fgraph.toposort()
1162         assert len([t for t in topo
1163                     if isinstance(t.op, tensor.Subtensor)]) == 1
1164         assert isinstance(topo[-1].op, DeepCopyOp)
1165         for x_s in self.x_shapes:
1166             x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1167             for idx1 in xrange(-11, 11):
1168                 for idx2 in xrange(-11, 11):
1169                     f(x_val, idx1, idx2)  # let debugmode test something
1170     def test_const_general(self):
1171         cases = [
1172             ((2, 3), (None, None, None), (None, None, -1)),
1173             ((12, 1), (None, None, -4), (None, None, 1)),
1174             ((5, 3), (1, 4, 2), (None, None, -1)),
1175         ]
1176         x = tensor.matrix('x')
1177         for shape, sl1, sl2 in cases:
1178             z = x[slice(*sl1)][slice(*sl2)]
1179             f = function([x], z, mode=mode_opt)
1180             self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1181             x_val = self.rng.uniform(size=shape).astype(config.floatX)
1182             f(x_val)
1183     def test_scalar5(self):
1184         x = tensor.matrix('x')
1185         b1 = tensor.iscalar('b1')
1186         e1 = tensor.iscalar('e1')
1187         s1 = tensor.iscalar('s1')
1188         b2 = tensor.iscalar('b2')
1189         e2 = tensor.iscalar('e2')
1190         s2 = tensor.iscalar('s2')
1191         f = function([x, b1, e1, s1, b2, e2, s2], x[b1:e1:s1][b2:e2:s2],
1192                      mode=mode_opt)
1193         self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1194         topo = f.maker.fgraph.toposort()
1195         assert len([t for t in topo if isinstance(t.op, tensor.
1196                                                   Subtensor)]) == 1
1197         assert isinstance(topo[-1].op, DeepCopyOp)
1198         b1r = self.rng.permutation(list(range(-8, 8)))[:2]
1199         e1r = self.rng.permutation(list(range(-8, 8)))[:2]
1200         b2r = self.rng.permutation(list(range(-8, 8)))[:2]
1201         e2r = self.rng.permutation(list(range(-8, 8)))[:2]
1202         s1r = self.rng.permutation([-7, -6, -5, -4, -3, -2, -1, 1,
1203                                     2, 3, 4, 5, 6, 7])[:2]
1204         s2r = self.rng.permutation([-7, -6, -5, -4, -3, -2, -1, 1,
1205                                     2, 3, 4, 5, 6, 7])[:2]
1206         for x_s in self.x_shapes:
1207             x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1208             for b1 in b1r:
1209                 for e1 in e1r:
1210                     for s1 in s1r:
1211                         for b2 in b2r:
1212                             for e2 in e2r:
1213                                 for s2 in s2r:
1214                                     f(x_val, b1, e1, s1, b2, e2, s2)
1215     def test_const5(self):
1216         data = np.asarray(np.arange(8),
1217                           dtype=theano.config.floatX)
1218         x = theano.tensor.vector('x')
1219         y = x[7:1:-1]
1220         t = theano.shared(np.int64(0))
1221         fun = theano.function([x], y[t])
1222         val = fun(data)
1223         assert val == data[7:1:-1][0]
1224     def test_const6(self):
1225         data = self.rng.uniform(size=(8, 8, 8)).astype(theano.config.floatX)
1226         x = theano.tensor.tensor3('x')
1227         nops = 1
1228         if theano.config.mode == "FAST_COMPILE":
1229             nops = 2
1230         y = x[3:6, 2:6, 1:7][1]
1231         fun = theano.function([x], y)
1232         val = fun(data)
1233         assert np.all(val == data[3:6, 2:6, 1:7][1])
1234         assert len([n for n in fun.maker.fgraph.toposort()
1235                     if isinstance(n.op, Subtensor)]) == nops
1236         y = x[2, 3][1]
1237         fun = theano.function([x], y)
1238         val = fun(data)
1239         assert np.all(val == data[2, 3][1])
1240         assert len([n for n in fun.maker.fgraph.toposort()
1241                     if isinstance(n.op, Subtensor)]) == nops
1242         y = x[3:6, 2, 1:7][1]
1243         fun = theano.function([x], y)
1244         val = fun(data)
1245         assert np.all(val == data[3:6, 2, 1:7][1])
1246         assert len([n for n in fun.maker.fgraph.toposort()
1247                     if isinstance(n.op, Subtensor)]) == nops
1248     def test_scalar6(self):
1249         x = tensor.matrix('x')
1250         b = tensor.iscalar('b')
1251         e = tensor.iscalar('e')
1252         s = tensor.iscalar('s')
1253         i = tensor.iscalar('i')
1254         f = function([x, b, e, s, i], x[b:e:s][i], mode=mode_opt)
1255         self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1256         topo = f.maker.fgraph.toposort()
1257         assert len([t for t in topo if isinstance(t.op, tensor.
1258                                                   Subtensor)]) == 1
1259         assert isinstance(topo[-1].op, DeepCopyOp)
1260         b_r = self.rng.permutation(list(range(-4, 4)))[:3]
1261         e_r = self.rng.permutation(list(range(-4, 4)))[:3]
1262         i_r = self.rng.permutation(list(range(-4, 4)))[:3]
1263         s_r = self.rng.permutation([-3, -2, -1, 1, 2, 3])[:3]
1264         for x_s in self.x_shapes:
1265             n_index_err = 0
1266             n_ok = 0
1267             x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1268             for b_v in b_r:
1269                 for e_v in e_r:
1270                     for s_v in s_r:
1271                         for i_v in i_r:
1272                             try:
1273                                 x_val[b_v:e_v:s_v][i_v]
1274                             except IndexError:
1275                                 n_index_err += 1
1276                                 self.assertRaises(IndexError,
1277                                                   f, x_val, b_v, e_v, s_v, i_v)
1278                             else:
1279                                 n_ok += 1
1280                                 f(x_val, b_v, e_v, s_v, i_v)
1281     @attr('slow')
1282     def test_none_slice(self):
1283         x = tensor.matrix('x')
1284         b1 = tensor.iscalar('b1')
1285         e1 = tensor.iscalar('e1')
1286         s1 = tensor.iscalar('s1')
1287         b2 = tensor.iscalar('b2')
1288         e2 = tensor.iscalar('e2')
1289         s2 = tensor.iscalar('s2')
1290         none_positions = np.ndindex(2, 2, 2, 2, 2, 2)
1291         b1r = self.rng.permutation(list(range(-4, 4)))[:]
1292         e1r = self.rng.permutation(list(range(-4, 4)))[:]
1293         b2r = self.rng.permutation(list(range(-4, 4)))[:]
1294         e2r = self.rng.permutation(list(range(-4, 4)))[:]
1295         s1r = self.rng.permutation([-4, -3, -2, -1, 1, 2, 3, 4])[:]
1296         s2r = self.rng.permutation([-4, -3, -2, -1, 1, 2, 3, 4])[:]
1297         scalar_vars = [b1, e1, s1, b2, e2, s2]
1298         scalar_ranges = [b1r, e1r, s1r, b2r, e2r, s2r]
1299         for none_pos in none_positions:
1300             slice_inputs = []
1301             input_vars = []
1302             values = []
1303             if sum(none_pos) == 0:
1304                 continue
1305             for i, none_i in enumerate(none_pos):
1306                 if none_i:
1307                     slice_inputs.append(None)
1308                 else:
1309                     slice_inputs.append(scalar_vars[i])
1310                     input_vars.append(scalar_vars[i])
1311                     values.append(scalar_ranges[i])
1312             slice1 = slice(*slice_inputs[:3])
1313             slice2 = slice(*slice_inputs[3:])
1314             sub_x = x[slice1][slice2]
1315             f = theano.function([x] + input_vars, sub_x, mode=mode_opt)
1316             self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor,
1317                                               bug_print='ignore'))
1318             topo = f.maker.fgraph.toposort()
1319             assert len([t for t in topo if isinstance(t.op,
1320                                                       tensor.Subtensor)]) &lt;= 1
1321             assert isinstance(topo[-1].op, DeepCopyOp)
1322             for x_s in self.x_shapes:
1323                 x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1324                 for i_val in zip(*values):
1325                     f(x_val, *i_val)
1326     def test_none_index(self):
1327         x = tensor.matrix('x')
1328         b = tensor.iscalar('b')
1329         e = tensor.iscalar('e')
1330         s = tensor.iscalar('s')
1331         i = tensor.iscalar('i')
1332         none_positions = np.ndindex(2, 2, 2, 1)
1333         b_r = self.rng.permutation(list(range(-4, 4)))[:]
1334         e_r = self.rng.permutation(list(range(-4, 4)))[:]
1335         i_r = self.rng.permutation(list(range(-4, 4)))[:]
1336         s_r = self.rng.permutation([-4, -3, -2, -1, 1, 2, 3, 4])[:]
1337         scalar_vars = [b, e, s, i]
1338         scalar_ranges = [b_r, e_r, s_r, i_r]
1339         for none_pos in none_positions:
1340             slice_inputs = []
1341             input_vars = []
1342             values = []
1343             if sum(none_pos) == 0:
1344                 continue
1345             for j, none_j in enumerate(none_pos):
1346                 if none_j:
1347                     slice_inputs.append(None)
1348                 else:
1349                     slice_inputs.append(scalar_vars[j])
1350                     input_vars.append(scalar_vars[j])
1351                     values.append(scalar_ranges[j])
1352             symbol_slice = slice(*slice_inputs[:3])
1353             sub_x = x[symbol_slice][i]
1354             f = theano.function([x] + input_vars, sub_x, mode=mode_opt)
1355             self.assertTrue(check_stack_trace(f, ops_to_check=Subtensor))
1356             topo = f.maker.fgraph.toposort()
1357             assert len([t for t in topo if isinstance(t.op,
1358                                                       tensor.Subtensor)]) &lt;= 1
1359             assert isinstance(topo[-1].op, DeepCopyOp)
1360             for x_s in self.x_shapes:
1361                 x_val = self.rng.uniform(size=x_s).astype(config.floatX)
1362                 for i_val in zip(*values):
1363                     i_val_idx = 0
1364                     num_slice_inputs = []
1365                     for none_j in none_pos:
1366                         if none_j:
1367                             num_slice_inputs.append(None)
1368                         else:
1369                             num_slice_inputs.append(i_val[i_val_idx])
1370                             i_val_idx += 1
1371                     num_slice = slice(*num_slice_inputs[:3])
1372                     num_i = num_slice_inputs[3]
1373                     try:
1374                         x_val[num_slice][num_i]
1375                     except IndexError:
1376                         self.assertRaises(IndexError, f, x_val, *i_val)
1377                     else:
1378                         f(x_val, *i_val)
1379 class test_local_adv_sub1_adv_inc_sub1(unittest.TestCase):
1380     def setUp(self):
1381         utt.seed_rng()
1382         mode = theano.compile.mode.get_default_mode()
1383         self.mode = mode.including("local_adv_sub1_adv_inc_sub1").excluding("fusion")
1384         self.mode_no_assert = self.mode.including("local_remove_all_assert")
1385     def test0(self):
1386         for dtype1, dtype2 in [("float32", "float32"),
1387                                ("float32", "float64"),
1388                                ("float64", "float32"),
1389                                ("float64", "float64")]:
1390             x = tensor.matrix(dtype=dtype1)
1391             y = tensor.matrix(dtype=dtype2)
1392             idx = tensor.ivector()
1393             dx = np.random.rand(4, 5).astype(dtype1)
1394             dy = np.random.rand(2, 5).astype(dtype2)
1395             dy = np.vstack([dy, dy[-1:]])
1396             didx = np.asarray([1, 3, 3], "int32")
1397             inc = tensor.set_subtensor(x[idx], y)
1398             o = inc[idx]
1399             f = theano.function([x, y, idx], o, self.mode_no_assert)
1400             res = f(dx, dy, didx)
1401             utt.assert_allclose(dy, res)
1402             topo = f.maker.fgraph.toposort()
1403             assert len(topo) == 1
1404             assert isinstance(topo[0].op, (compile.DeepCopyOp, T.Elemwise))
1405             inc = tensor.inc_subtensor(x[idx], y)
1406             o = inc[idx]
1407             f = theano.function([x, y, idx], o, self.mode_no_assert)
1408             res = f(dx, dy, didx)
1409             _dx = dx.copy()
1410             np.add.at(_dx, didx, dy)
1411             utt.assert_allclose(_dx[didx], res)
1412             topo = f.maker.fgraph.toposort()
1413             len(topo) == 2
1414             inc = tensor.inc_subtensor(x.zeros_like()[idx], y)
1415             o = inc[idx]
1416             f = theano.function([x, y, idx], o, self.mode_no_assert)
1417             res = f(dx, dy, didx)
1418             utt.assert_allclose(np.vstack([dy[0], 2 * dy[1], 2 * dy[2]]), res)
1419     def test_assert(self):
1420             x = tensor.matrix("x")
1421             y = tensor.matrix("y")
1422             idx = tensor.ivector()
1423             dx = np.random.rand(4, 5).astype(config.floatX)
1424             dy = np.random.rand(2, 5).astype(config.floatX)
1425             inc = tensor.set_subtensor(x[idx], y)
1426             o = inc[idx]
1427             f = theano.function([x, y, idx], o, self.mode)
1428             for i in [dx.shape[0], -dx.shape[0] - 1]:
1429                 self.assertRaises((AssertionError, IndexError),
1430                                   f, dx, dy, [i, i])
1431             self.assertRaises((AssertionError, ValueError),
1432                               f, dx, dy, [1])
1433     def test_stack_trace(self):
1434         x = tensor.matrix("x")
1435         ys = [tensor.matrix("y"), tensor.dmatrix("y")]
1436         idx = tensor.ivector()
1437         incs = [tensor.set_subtensor(x[idx], y) for y in ys]
1438         outs = [inc[idx] for inc in incs]
1439         for y, out in zip(ys, outs):
1440             f = theano.function([x, y, idx], out, self.mode)
1441             self.assertTrue(check_stack_trace(
1442                 f, ops_to_check=(Assert, scal.Cast)))
1443 class Test_alloc_zero(unittest.TestCase):
1444     def setUp(self):
1445         mode = theano.compile.mode.get_default_mode()
1446         self.mode = mode.including("local_incsubtensor_of_zeros",
1447                                    "local_setsubtensor_of_constants",
1448                                    "local_0_dot_x")
1449     def test_setsubtensor_allocs0(self):
1450         x = tensor.matrix()
1451         y = tensor.matrix()
1452         x0 = tensor.zeros_like(x)
1453         y0 = tensor.zeros_like(y)
1454         z = tensor.set_subtensor(x0[:4], y0)
1455         f = theano.function([x, y], z, mode=self.mode)
1456         assert np.all([not isinstance(n.op, tensor.IncSubtensor)
1457                        for n in f.maker.fgraph.toposort()])
1458     def test_setsubtensor_allocs1(self):
1459         y = tensor.matrix()
1460         x0 = tensor.constant(np.asarray(np.zeros((4, 4)),
1461                                         dtype=config.floatX))
1462         y0 = tensor.zeros_like(y)
1463         z = tensor.set_subtensor(x0[:4], y0)
1464         f = theano.function([y], z, mode=self.mode)
1465         assert np.all([not isinstance(n.op, tensor.IncSubtensor)
1466                        for n in f.maker.fgraph.toposort()])
1467     def test_setsubtensor_allocs1t(self):
1468         y = tensor.matrix()
1469         x0 = tensor.constant(np.asarray(np.zeros((4, 4)),
1470                                         dtype=config.floatX))
1471         y0 = tensor.zeros_like(y)
1472         z = tensor.set_subtensor(x0[:4], y0.T)
1473         f = theano.function([y], z, mode=mode_opt)
1474         assert np.all([not isinstance(n.op, tensor.IncSubtensor)
1475                       for n in f.maker.fgraph.toposort()])
1476     def test_setsubtensor_allocs2(self):
1477         x = tensor.matrix()
1478         y0 = tensor.constant(np.asarray(np.zeros_like((4, 4)),
1479                                         dtype=config.floatX))
1480         x0 = tensor.zeros_like(x)
1481         z = tensor.set_subtensor(x0[:4], y0)
1482         f = theano.function([x], z, mode=self.mode)
1483         assert np.all([not isinstance(n.op, tensor.IncSubtensor)
1484                        for n in f.maker.fgraph.toposort()])
1485     def test_incsubtensor_allocs0(self):
1486         x = tensor.matrix()
1487         y = tensor.matrix()
1488         y0 = tensor.zeros_like(y)
1489         z = tensor.inc_subtensor(x[:4], y0)
1490         f = theano.function([x, y], z, mode=self.mode)
1491         assert np.all([not isinstance(n.op, tensor.IncSubtensor)
1492                        for n in f.maker.fgraph.toposort()])
1493     def test_incsubtensor_allocs0t(self):
1494         x = tensor.matrix()
1495         y = tensor.matrix()
1496         y0 = tensor.zeros_like(y)
1497         z = tensor.inc_subtensor(x[:4], y0.T)
1498         f = theano.function([x, y], z, mode=mode_opt)
1499         assert np.all([not isinstance(n.op, tensor.IncSubtensor)
1500                        for n in f.maker.fgraph.toposort()])
1501     def test_incsubtensor_allocs1(self):
1502         x = tensor.matrix()
1503         y0 = tensor.constant(np.asarray(np.zeros_like((4, 4)),
1504                                         dtype=config.floatX))
1505         z = tensor.inc_subtensor(x[:4], y0)
1506         f = theano.function([x], z, mode=self.mode)
1507         assert np.all([not isinstance(n.op, tensor.IncSubtensor)
1508                        for n in f.maker.fgraph.toposort()])
1509     def test_incsubtensor_x_zeros(self):
1510         x = tensor.constant(np.asarray(np.zeros((4, 4)),
1511                                        dtype=config.floatX))
1512         y = tensor.matrix()
1513         z = tensor.inc_subtensor(x[:4], y)
1514         f = theano.function([y], z)
1515         inc_nodes = [n for n in f.maker.fgraph.toposort()
1516                      if isinstance(n.op, tensor.IncSubtensor)]
1517         assert(len(inc_nodes) == 1)
1518         node_is_set_instead_of_inc = inc_nodes[0].op.set_instead_of_inc
1519         mode = theano.config.mode
1520         assert((mode != "FAST_COMPILE" and node_is_set_instead_of_inc) or
1521                (mode == "FAST_COMPILE" and not node_is_set_instead_of_inc))
1522         test_X = np.random.random((4, 4)).astype(config.floatX)
1523         utt.assert_allclose(f(test_X), test_X)
1524         not_all_zeros = np.zeros((4, 4))
1525         not_all_zeros[1, 0] = 0.001
1526         x = tensor.constant(np.asarray(not_all_zeros, dtype=config.floatX))
1527         y = tensor.matrix()
1528         z = tensor.inc_subtensor(x[:4], y)
1529         f = theano.function([y], z)
1530         inc_nodes = [n for n in f.maker.fgraph.toposort()
1531                      if isinstance(n.op, tensor.IncSubtensor)]
1532         assert(len(inc_nodes) == 1)
1533         assert(inc_nodes[0].op.set_instead_of_inc is False)
1534         test_X = np.random.random((4, 4)).astype(config.floatX)
1535         utt.assert_allclose(f(test_X), test_X + not_all_zeros)
1536     def test_advancedincsubtensor1_allocs0(self):
1537         x = tensor.matrix()
1538         y = tensor.matrix()
1539         y0 = tensor.zeros_like(y)
1540         z = tensor.inc_subtensor(x[[0, 1, 2, 3]], y0)
1541         f = theano.function([x, y], z, mode=self.mode)
1542         assert np.all([not isinstance(n.op, tensor.AdvancedIncSubtensor1)
1543                        for n in f.maker.fgraph.toposort()])
1544     def test_advancedincsubtensor1_allocs0t(self):
1545         x = tensor.matrix()
1546         y = tensor.matrix()
1547         y0 = tensor.zeros_like(y)
1548         z = tensor.inc_subtensor(x[[0, 1, 2, 3]], y0.T)
1549         f = theano.function([x, y], z, mode=mode_opt)
1550         assert np.all([not isinstance(n.op, tensor.AdvancedIncSubtensor1)
1551                        for n in f.maker.fgraph.toposort()])
1552     def test_advancedincsubtensor1_allocs1(self):
1553         x = tensor.matrix()
1554         y0 = tensor.constant(np.asarray(np.zeros_like((4, 4)),
1555                                         dtype=config.floatX))
1556         z = tensor.inc_subtensor(x[[0, 1, 2, 3]], y0)
1557         f = theano.function([x], z, mode=self.mode)
1558         assert np.all([not isinstance(n.op, tensor.AdvancedIncSubtensor1)
1559                        for n in f.maker.fgraph.toposort()])
1560     def test_advancedincsubtensor_allocs0(self):
1561         x = tensor.matrix()
1562         y = tensor.matrix()
1563         y0 = tensor.zeros_like(y)
1564         z = tensor.inc_subtensor(x[[[0, 0], [1, 1]], [[0, 1], [0, 1]]], y0)
1565         f = theano.function([x, y], z, mode=self.mode)
1566         assert np.all([not isinstance(n.op, tensor.AdvancedIncSubtensor)
1567                        for n in f.maker.fgraph.toposort()])
1568     def test_advancedincsubtensor_allocs0t(self):
1569         x = tensor.matrix()
1570         y = tensor.matrix()
1571         y0 = tensor.zeros_like(y)
1572         z = tensor.inc_subtensor(x[[[0, 0], [1, 1]], [[0, 1], [0, 1]]], y0.T)
1573         f = theano.function([x, y], z, mode=mode_opt)
1574         assert np.all([not isinstance(n.op, tensor.AdvancedIncSubtensor)
1575                        for n in f.maker.fgraph.toposort()])
1576     def test_advancedincsubtensor_allocs1(self):
1577         x = tensor.matrix()
1578         y0 = tensor.constant(np.asarray(np.zeros_like((2, 2)),
1579                                         dtype=config.floatX))
1580         z = tensor.inc_subtensor(x[[[0, 0], [1, 1]], [[0, 1], [0, 1]]], y0)
1581         f = theano.function([x], z, mode=self.mode)
1582         assert np.all([not isinstance(n.op, tensor.AdvancedIncSubtensor)
1583                        for n in f.maker.fgraph.toposort()])
1584     def test_dot_allocs_0(self):
1585         v1 = tensor.vector('v1')
1586         v2 = tensor.vector('v2')
1587         m1 = tensor.matrix('m1')
1588         m2 = tensor.matrix('m2')
1589         vv2 = np.asarray([0, 1], dtype=theano.config.floatX)
1590         vm2 = np.asarray([[1, 2], [4, 5]],
1591                          dtype=theano.config.floatX)
1592         vv3 = np.asarray([0, 1, 2], dtype=theano.config.floatX)
1593         vm3 = np.asarray([[1, 2, 3], [4, 5, 6], [7, 8, 9]],
1594                          dtype=theano.config.floatX)
1595         for _e1 in [(v1, vv2, vv3), (m1, vm2, vm3)]:
1596             for _e2 in [(v2, vv2, vv3), (m2, vm2, vm3)]:
1597                 for p in [0, 1]:
1598                     if p == 0:
1599                         e1 = tensor.zeros_like(_e1[0])
1600                         e2 = _e2[0]
1601                     else:
1602                         e1 = _e1[0]
1603                         e2 = tensor.zeros_like(_e2[0])
1604                     o = tensor.dot(e1, e2)
1605                     f = theano.function([_e1[0], _e2[0]], o, mode=self.mode)
1606                     f(_e1[1], _e2[1])
1607                     f(_e1[2], _e2[2])
1608                     assert np.all([not isinstance(n.op, tensor.Dot) for n in
1609                                    f.maker.fgraph.toposort()])
1610                     self.assertRaises((ValueError, AssertionError), f,
1611                                       _e1[1], _e2[2])
1612                     self.assertRaises((ValueError, AssertionError), f,
1613                                       _e1[2], _e2[1])
1614 def test_local_IncSubtensor_serialize():
1615     d = np.random.normal(0, 0.01, size=(100, 100))
1616     d = d.astype(theano.config.floatX)
1617     W = theano.shared(d, name='W')
1618     i = T.vector('i', dtype='int64')
1619     j = T.vector('j', dtype='int64')
1620     t = T.scalar('t')
1621     y = (W[i] + W[j] + W[1] + W[i, j]).sum()
1622     cost = T.sqr(t - y)
1623     dW = theano.grad(cost, W)
1624     mode = theano.compile.mode.get_default_mode().excluding('fusion')
1625     mode = mode.including("local_IncSubtensor_serialize")
1626     f = theano.function([i, j, t], updates=[(W, W - 0.01 * dW)], mode=mode)
1627     topo = f.maker.fgraph.toposort()
1628     adds = [n for n in topo if isinstance(n.op, T.Elemwise) and
1629             isinstance(n.op.scalar_op, theano.scalar.Add)]
1630     for a in adds:
1631         assert not any([inp.owner and
1632                         isinstance(inp.owner.op,
1633                                    (tensor.IncSubtensor,
1634                                     tensor.AdvancedIncSubtensor,
1635                                     tensor.AdvancedIncSubtensor1))
1636                         for inp in a.inputs])
1637     f = theano.function([i, j, t], dW, mode=mode)
1638     assert check_stack_trace(f, ops_to_check=[
1639         tensor.IncSubtensor, tensor.AdvancedIncSubtensor,
1640         tensor.AdvancedIncSubtensor1])
1641 def test_local_set_to_inc_subtensor():
1642     v = theano.tensor.fmatrix()
1643     s = v[[2, 1]]
1644     g = s + 3
1645     r = theano.tensor.set_subtensor(s, g)
1646     moder = compile.get_default_mode().excluding('local_set_to_inc_subtensor')
1647     modet = compile.get_default_mode().including('local_set_to_inc_subtensor')
1648     f1 = theano.function([v], r, mode=moder)
1649     f2 = theano.function([v], r, mode=modet)
1650     advi1 = [n for n in f1.maker.fgraph.toposort()
1651              if isinstance(n.op, tensor.AdvancedIncSubtensor1)]
1652     advi2 = [n for n in f2.maker.fgraph.toposort()
1653              if isinstance(n.op, tensor.AdvancedIncSubtensor1)]
1654     assert all(n.op.set_instead_of_inc for n in advi1)
1655     assert all(not n.op.set_instead_of_inc for n in advi2)
1656     val = np.random.randn(3, 2).astype('float32')
1657     r1 = f1(val)
1658     r2 = f2(val)
1659     utt.assert_allclose(r1, r2)
1660     assert check_stack_trace(f1, ops_to_check=tensor.AdvancedIncSubtensor1)
1661     assert check_stack_trace(f2, ops_to_check='all')
1662 def test_local_subtensor_of_dot():
1663     m1 = theano.tensor.matrix()
1664     m2 = theano.tensor.matrix()
1665     d1 = np.arange(6).reshape((3, 2)).astype(config.floatX)
1666     d2 = np.arange(8).reshape((2, 4)).astype(config.floatX) + 10
1667     mode = compile.get_default_mode().including("local_subtensor_of_dot")
1668     def test_equality(a, b):
1669         return a.shape == b.shape and np.allclose(a, b)
1670     f = theano.function([m1, m2], theano.dot(m1, m2)[1], mode=mode)
1671     topo = f.maker.fgraph.toposort()
1672     assert test_equality(f(d1, d2), np.dot(d1, d2)[1])
1673     assert isinstance(topo[-1].op, (T.blas_c.CGemv, T.blas.Gemv, T.DimShuffle))
1674     f = theano.function([m1, m2], theano.dot(m1, m2)[1:2], mode=mode)
1675     topo = f.maker.fgraph.toposort()
1676     assert test_equality(f(d1, d2), np.dot(d1, d2)[1:2])
1677     assert isinstance(topo[-1].op, (T.blas.Dot22))
1678     m1 = theano.tensor.tensor3()
1679     m2 = theano.tensor.tensor3()
1680     idx = theano.tensor.iscalar()
1681     d1 = np.arange(30).reshape(2, 5, 3).astype(config.floatX)
1682     d2 = np.arange(72).reshape(4, 3, 6).astype(config.floatX) + 100
1683     f = theano.function([m1, m2, idx], theano.dot(m1, m2)[idx, 1:4, :, idx:], mode=mode)
1684     assert test_equality(f(d1, d2, 1), np.dot(d1, d2)[1, 1:4, :, 1:])
1685     assert check_stack_trace(f, ops_to_check='last')
1686     f = theano.function([m1, m2, idx], theano.dot(m1, m2)[1:4, :, idx:, idx], mode=mode)
1687     assert test_equality(f(d1, d2, 1), np.dot(d1, d2)[1:4, :, 1:, 1])
1688     assert check_stack_trace(f, ops_to_check='last')
1689 class Test_local_elemwise_alloc(unittest.TestCase):
1690     dtype = config.floatX
1691     def setUp(self):
1692         self.fast_compile_mode = get_mode('FAST_COMPILE')
1693         self.fast_run_mode = get_mode('FAST_RUN')
1694         self.vec = T.vector('vec', dtype=self.dtype)
1695         self.mat = T.matrix('mat', dtype=self.dtype)
1696         self.tens = T.tensor3('tens', dtype=self.dtype)
1697         self.alloc_wo_dep = T.alloc(self.vec, 2, 2)
1698         self.alloc_wo_dep_broad = T.alloc(self.vec, 1, 2)
1699         self.alloc_w_dep = T.alloc(self.vec, *self.mat.shape)
1700         self.alloc_w_dep_broad = T.alloc(self.vec, 1, *self.mat.shape)
1701         self.alloc_w_dep_broad2 = T.alloc(self.vec, self.mat.shape[0],
1702                                           self.mat.shape[1], 1)
1703         self.alloc_w_dep_tens = T.alloc(
1704             self.vec,
1705             self.tens.shape[0],
1706             self.tens.shape[1]
1707         )
1708         self.tv_wo_dep = T.alloc(self.vec, 5, 5)
1709         self.tm_wo_dep = T.alloc(self.mat, 5, 5, 5)
1710         self.s = T.iscalar('s')
1711         self.tv_w_dep = T.alloc(self.vec, self.s, self.s)
1712         self.tm_w_dep = T.alloc(self.mat, 5, 5, 5)
1713         self.row = theano.tensor.row(dtype=self.dtype)
1714         self.o = T.alloc(self.row, 5, 5)
1715     def _verify_alloc_count(self, f, count):
1716         assert(
1717             sum([isinstance(elem.op, T.Alloc)
1718                  for elem in f.maker.fgraph.toposort()
1719                  if elem.op is not None]) == count
1720         )
1721     def _verify_assert_count(self, f, count):
1722         assert(
1723             sum([isinstance(elem.op, T.opt.Assert)
1724                  for elem in f.maker.fgraph.toposort()
1725                  if elem.op is not None]) == count
1726         )
1727     def test_remove_alloc_wo_dimshuffle(self):
1728         self.fast_run_mode = self.fast_run_mode.excluding(
1729             'local_useless_alloc', 'local_canonicalize_alloc')
1730         func = function(
1731             [self.vec, self.mat],
1732             self.alloc_wo_dep + self.mat,
1733             mode=self.fast_compile_mode
1734         )
1735         self._verify_alloc_count(func, 1)
1736         self._verify_assert_count(func, 0)
1737         self.assertTrue(check_stack_trace(func, ops_to_check='all'))
1738         func = function(
1739             [self.vec, self.mat],
1740             self.alloc_wo_dep + self.mat,
1741             mode=self.fast_run_mode
1742         )
1743         self._verify_alloc_count(func, 0)
1744         self._verify_assert_count(func, 1)
1745         func = function(
1746             [self.vec, self.mat],
1747             self.alloc_wo_dep_broad + self.mat,
1748             mode=self.fast_run_mode
1749         )
1750         self._verify_alloc_count(func, 0)
1751         self._verify_assert_count(func, 1)
1752         func = function(
1753             [self.vec, self.mat],
1754             self.alloc_w_dep + self.mat,
1755             mode=self.fast_compile_mode
1756         )
1757         self._verify_alloc_count(func, 1)
1758         self._verify_assert_count(func, 0)
1759         func = function(
1760             [self.vec, self.mat],
1761             self.alloc_w_dep + self. mat,
1762             mode=self.fast_run_mode
1763         )
1764         self._verify_alloc_count(func, 0)
1765         self._verify_assert_count(func, 0)
1766         func = function(
1767             [self.vec, self.mat],
1768             self.alloc_w_dep_broad + self. mat,
1769             mode=self.fast_run_mode
1770         )
1771         self._verify_alloc_count(func, 0)
1772         self._verify_assert_count(func, 0)
1773         func = function(
1774             [self.vec, self.mat],
1775             self.alloc_w_dep_broad2 + self. mat,
1776             mode=self.fast_run_mode
1777         )
1778         self._verify_alloc_count(func, 1)
1779         self._verify_assert_count(func, 0)
1780     def test_remove_alloc_w_dimshuffle(self):
1781         func = function(
1782             [self.vec, self.tens],
1783             self.alloc_wo_dep.dimshuffle(0, 1, 'x') + self.tens,
1784             mode=self.fast_compile_mode
1785         )
1786         self._verify_alloc_count(func, 1)
1787         self._verify_assert_count(func, 0)
1788         func = function(
1789             [self.vec, self.tens],
1790             self.alloc_wo_dep.dimshuffle(0, 1, 'x') + self.tens,
1791             mode=self.fast_run_mode
1792         )
1793         self._verify_alloc_count(func, 0)
1794         self._verify_assert_count(func, 1)
1795         func = function(
1796             [self.vec, self.tens],
1797             self.alloc_w_dep_tens.dimshuffle(0, 1, 'x') + self.tens,
1798             mode=self.fast_compile_mode
1799         )
1800         self._verify_alloc_count(func, 1)
1801         self._verify_assert_count(func, 0)
1802         func = function(
1803             [self.vec, self.tens],
1804             self.alloc_w_dep_tens.dimshuffle(0, 1, 'x') + self.tens,
1805             mode=self.fast_run_mode
1806         )
1807         self._verify_alloc_count(func, 0)
1808         self._verify_assert_count(func, 0)
1809     def test_multi_input_single_alloc(self):
1810         func = function(
1811             [self.vec, self.mat],
1812             self.tv_wo_dep + self.tm_wo_dep,
1813             mode=self.fast_compile_mode
1814         )
1815         self._verify_alloc_count(func, 2)
1816         self._verify_assert_count(func, 0)
1817         func = function(
1818             [self.vec, self.mat],
1819             self.tv_wo_dep + self.tm_wo_dep,
1820             mode=self.fast_run_mode
1821         )
1822         self._verify_alloc_count(func, 1)
1823         self._verify_assert_count(func, 0)
1824         func = function(
1825             [self.vec, self.mat, self.s],
1826             self.tv_w_dep + self.tm_w_dep,
1827             mode=self.fast_compile_mode
1828         )
1829         self._verify_alloc_count(func, 2)
1830         self._verify_assert_count(func, 0)
1831         func = function(
1832             [self.vec, self.mat, self.s],
1833             self.tv_w_dep + self.tm_w_dep,
1834             mode=self.fast_run_mode
1835         )
1836         self._verify_alloc_count(func, 1)
1837         self._verify_assert_count(func, 1)
1838     def test_error(self):
1839         t3fft = theano.tensor.tensor(dtype=self.dtype,
1840                                      broadcastable=(False, False, True))
1841         o = self.o.dimshuffle(0, 1, 'x') + t3fft
1842         func = function(
1843             [t3fft, self.row],
1844             o,
1845             mode=self.fast_run_mode
1846         )
1847         self._verify_alloc_count(func, 0)
1848         self._verify_assert_count(func, 1)
1849         d = np.random.rand(5, 5, 1).astype(self.dtype)
1850         r = np.random.rand(1, 5).astype(self.dtype)
1851         func(d, r)
1852 def test_local_subtensor_of_alloc():
1853     for shape in [(3, 5), (4, 6), (3, 8), (4, 7),
1854                   (1, 5), (5, 1)]:
1855         x = tensor.tensor(dtype=theano.config.floatX,
1856                           broadcastable=(shape[0] == 1, shape[1] == 1))
1857         xval = np.zeros(shape, dtype=config.floatX)
1858         yval = np.arange(shape[1], dtype=config.floatX)
1859         for y in [theano.shared(yval), tensor.constant([1.])]:
1860             yx = tensor.alloc(y, x.shape[0], x.shape[1])
1861             z_mat = yx[:, 3:]
1862             assert z_mat.ndim == 2
1863             z_vec = yx[:, 3]
1864             assert z_vec.ndim == 1
1865             slicess = []
1866             if shape[0] != 1:
1867                 slicess.append((2, slice(None)))
1868             if shape[1] != 1:
1869                 slicess.append((slice(None), 3))
1870             slicess += [
1871                 (slice(None), slice(3, None)),
1872                 (slice(3, None), ),
1873                 (slice(3, None), slice(3, None)),
1874                 (slice(1, 3), slice(None, -1)),
1875                 (slice(None, None, 2)),
1876                 (slice(1, None, 2)),
1877             ]
1878             for slices in slicess:
1879                 z = yx.__getitem__(slices)
1880                 f = theano.function([x], z)
1881                 if theano.config.mode != 'FAST_COMPILE':
1882                     assert not isinstance(f.maker.fgraph.toposort()[-1].op,
1883                                           Subtensor)
1884                 val = f(xval)
1885                 assert xval.__getitem__(slices).shape == val.shape
1886 def test_local_fill_useless():
1887     x = dvector()
1888     y = dvector()
1889     z = lvector()
1890     m = dmatrix()
1891     x_ = np.random.rand(5,)
1892     y_ = np.random.rand(5,)
1893     z_ = (np.random.rand(5,) * 5).astype("int64")
1894     m_ = np.random.rand(5, 5)
1895     f = function([x], T.fill(x, x) * 2, mode=mode_opt)
1896     assert [node.op for node in f.maker.fgraph.toposort()] == [T.mul]
1897     f(x_)
1898     f = function([x, y], T.second(y, x) * 2, mode=mode_opt)
1899     assert [node.op for node in f.maker.fgraph.toposort()] == [T.mul]
1900     f(x_, y_)
1901     f = function([x, y], T.fill(x, y) * 2, mode=mode_opt)
1902     assert [node.op for node in f.maker.fgraph.toposort()] == [T.mul]
1903     f(x_, y_)
1904     f = function([x, z], T.fill(z, x) * 2, mode=mode_opt)
1905     assert [node.op for node in f.maker.fgraph.toposort()] == [T.mul]
1906     f(x_, z_)
1907     f = function([x, z], T.fill(x, z) * 2, mode=mode_opt)
1908     assert [node.op for node in f.maker.fgraph.toposort()] == [T.mul]
1909     f(x_, z_)
1910     f = function([x, y], T.fill(x, y) * 2, mode=mode_opt)
1911     assert [node.op for node in f.maker.fgraph.toposort()] == [T.mul]
1912     f(x_, y_)
1913     f = function([m, x], T.fill(m, x) * 2, mode=mode_opt)
1914     ops = [node.op.__class__ for node in f.maker.fgraph.toposort()]
1915     assert T.Alloc in ops
1916     f(m_, x_)
1917 def test_local_elemwise_sub_zeros():
1918     scalar = T.scalar()
1919     vect = T.vector()
1920     mat = T.matrix()
1921     rng = np.random.RandomState(seed=utt.fetch_seed())
1922     scalar_val = rng.rand(1).astype(config.floatX)[0]
1923     vect_val = rng.rand(5).astype(config.floatX)
1924     mat_val = rng.rand(3, 2).astype(config.floatX)
1925     mode = theano.compile.get_default_mode()\
1926         .excluding('canonicalize', 'uncanonicalize',
1927                    'ShapeOpt', 'local_fill_to_alloc',
1928                    'local_elemwise_alloc')\
1929         .including('local_elemwise_sub_zeros')
1930     f = function([scalar], scalar - scalar, mode=mode)
1931     assert isinstance(f.maker.fgraph.toposort()[0].op, T.Elemwise)
1932     assert isinstance(f.maker.fgraph.toposort()[0].op.scalar_op,
1933                       theano.scalar.Second)
1934     assert isinstance(f.maker.fgraph.toposort()[0].inputs[1],
1935                       T.TensorConstant) or\
1936         isinstance(f.maker.fgraph.toposort()[0].inputs[1],
1937                    T.TensorConstant)
1938     utt.assert_allclose(f(scalar_val), 0.0)
1939     assert check_stack_trace(f, ops_to_check='all')
1940     f = function([vect], vect - vect, mode=mode)
1941     assert isinstance(f.maker.fgraph.toposort()[0].op, T.Elemwise)
1942     assert isinstance(f.maker.fgraph.toposort()[0].op.scalar_op,
1943                       theano.scalar.Second)
1944     assert isinstance(f.maker.fgraph.toposort()[0].inputs[1],
1945                       T.TensorConstant) or\
1946         isinstance(f.maker.fgraph.toposort()[0].inputs[1],
1947                    T.TensorConstant)
1948     utt.assert_allclose(f(vect_val), np.zeros(vect_val.shape))
1949     assert check_stack_trace(f, ops_to_check='all')
1950     f = function([mat], mat - mat, mode=mode)
1951     assert isinstance(f.maker.fgraph.toposort()[0].op, T.Elemwise)
1952     assert isinstance(f.maker.fgraph.toposort()[0].op.scalar_op,
1953                       theano.scalar.Second)
1954     assert isinstance(f.maker.fgraph.toposort()[0].inputs[1],
1955                       T.TensorConstant) or\
1956         isinstance(f.maker.fgraph.toposort()[0].inputs[1],
1957                    T.TensorConstant)
1958     utt.assert_allclose(f(mat_val), np.zeros(mat_val.shape))
1959     assert check_stack_trace(f, ops_to_check='all')
1960 class Test_local_useless_elemwise_comparison(unittest.TestCase):
1961     def setUp(self):
1962         self.rng = np.random.RandomState(utt.fetch_seed())
1963     def test_local_useless_elemwise_comparison(self):
1964         X = T.matrix('X')
1965         Y = T.vector('Y')
1966         X_sum, updates = theano.scan(fn=lambda x: x.sum(),
1967                                      outputs_info=None,
1968                                      sequences=[X],
1969                                      non_sequences=None)
1970         Z = X_sum + Y
1971         mode = theano.compile.get_default_mode().excluding('fusion')
1972         f = theano.function([X, Y], Z, mode=mode)
1973         f(self.rng.rand(2, 3).astype(config.floatX),
1974           self.rng.rand(2).astype(config.floatX))
1975     def assert_eqs_const(self, f, val, op=deep_copy_op):
1976         topo = f.maker.fgraph.toposort()
1977         elem = topo[0]
1978         assert len(topo) == 1, topo
1979         assert elem.op == op, elem.op
1980         if op == deep_copy_op:
1981             assert len(elem.inputs) == 1, elem.inputs
1982             assert isinstance(elem.inputs[0], T.TensorConstant), elem
1983             assert T.extract_constant(elem.inputs[0]) == val, val
1984         else:
1985             assert len(elem.inputs) == 2, elem.inputs
1986             assert isinstance(elem.inputs[0], T.TensorConstant), elem
1987             assert T.extract_constant(elem.inputs[0]) == val, val
1988     def assert_identity(self, f):
1989         topo = f.maker.fgraph.toposort()
1990         assert len(topo) == 1
1991         assert topo[0].op == deep_copy_op
1992         if f.outputs[0].variable.dtype == 'bool':
1993             x_vals = [0, 1]
1994         else:
1995             x_vals = [0, 1, 10]
1996         for x_val in x_vals:
1997             assert f(x_val) == x_val
1998 <a name="20"></a>
1999     def test_inequality_with_self(self):
2000         x = T.scalar('x', dtype=config.floatX)
2001         mode = theano.compile.get_default_mode().including<font color="#4e9258"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>('local_useless_elemwise_comparison')
2002         f = theano.function([x], T.lt(x, x), mode=mode)
2003         self.assert_eqs_const(f, 0)
2004         f = theano.function(</b></font>[x], T.le(x, x), mode=mode)
2005         self.assert_eqs_const(f, 1)
2006         f = theano.function([x], T.gt(x, x), mode=mode)
2007         self.assert_eqs_const(f, 0)
2008         f = theano.function([x], T.ge(x, x), mode=mode)
2009         self.assert_eqs_const(f, 1)
2010         f = theano.function([x], T.minimum(x, x), mode=mode)
2011         self.assert_identity(f)
2012         f = theano.function([x], T.maximum(x, x), mode=mode)
2013         self.assert_identity(f)
2014     def test_shape_inequality_with_self(self):
2015         x = T.vector('x', dtype=config.floatX)
2016         mode = theano.compile.get_default_mode().including(
2017             'local_useless_elemwise_comparison',
2018             'local_shape_to_shape_i',
2019             'local_track_shape_i',
2020             'local_subtensor_make_vector')
2021         f = theano.function([x], T.lt(x.shape[0], 0), mode=mode)
2022         self.assert_eqs_const(f, 0)
2023         f = theano.function([x], T.ge(x.shape[0], 0), mode=mode)
2024         self.assert_eqs_const(f, 1)
2025         f = theano.function([x], T.maximum(x.shape[0], 0), mode=mode)
2026         topo = f.maker.fgraph.toposort()
2027         assert len(topo) == 1
2028         assert isinstance(topo[0].op, Shape_i), topo[0].op
2029         x_val = np.ones(100, dtype=config.floatX)
2030         assert f(x_val) == x_val.shape[0]
2031         f = theano.function([x], T.maximum(0, x.shape[0]), mode=mode)
2032         topo = f.maker.fgraph.toposort()
2033         assert len(topo) == 1
2034         assert isinstance(topo[0].op, Shape_i), topo[0].op
2035         x_val = np.ones(100, dtype=config.floatX)
2036         assert f(x_val) == x_val.shape[0]
2037         f = theano.function([x], T.minimum(x.shape[0], 0), mode=mode)
2038         self.assert_eqs_const(f, 0)
2039         assert f(x_val) == 0
2040         f = theano.function([x], T.minimum(0, x.shape[0]), mode=mode)
2041         self.assert_eqs_const(f, 0)
2042         assert f(x_val) == 0
2043         f = theano.function([x], T.minimum([0, 0], x.shape[0]), mode=mode)
2044         utt.assert_allclose(f(x_val), [0, 0])
2045     def test_shape_add_inequality(self):
2046         x = T.vector('x', dtype=config.floatX)
2047         mode = theano.compile.get_default_mode().including(
2048             'local_useless_elemwise_comparison',
2049             'local_shape_to_shape_i',
2050             'local_track_shape_i',
2051             'local_subtensor_make_vector')
2052         y = T.vector('y', dtype=config.floatX)
2053         f = theano.function([x, y], T.lt(x.shape[0] + y.shape[0], 0), mode=mode)
2054         self.assert_eqs_const(f, 0)
2055         f = theano.function([x, y], T.ge(x.shape[0] + y.shape[0], 0), mode=mode)
2056         self.assert_eqs_const(f, 1)
2057     def test_equality_shapes(self):
2058         if theano.config.mode == "FAST_COMPILE":
2059             raise SkipTest("Skip opt test as the opt is disabled")
2060         x = T.vector('x', dtype=config.floatX)
2061         for g in [x.shape[0],
2062                   Shape_i(0)(x)]:
2063             f = theano.function([x], T.eq(g, 0))
2064             assert f([3, 3]) == 0
2065             assert f([]) == 1
2066             f = theano.function([x], T.eq(g, -1))
2067             self.assert_eqs_const(f, 0)
2068             assert f([3, 3]) == 0
2069         g = join(0,
2070                  x.shape[0:],  # todo test reshape, dimshuffle
2071                  x.shape[0:1])
2072         f = theano.function([x], T.eq(g, 0))
2073         assert (f([3, 3]) == 0).all()
2074         assert (f([]) == 1).all()
2075 <a name="9"></a>
2076         f = theano.function([x], T.eq(g, -1))
2077         self.assert_eqs_const(f, 0, op=T.alloc)
2078         assert (<font color="#83a33a"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>f([3, 3]) == 0).all()
2079     def test_and(self):
2080         mode = theano.compile.get_default_mode().including(</b></font>'canonicalize')
2081         for dtype, zero, one in [('bool', np.array(False), np.array(True)),
2082                                  ('int8', np.int8(0), np.int8(1)),
2083                                  ('int8', 0, 1)]:
2084             x = T.scalar('x', dtype=dtype)
2085             f = theano.function([x], T.and_(x, zero), mode=mode)
2086             self.assert_eqs_const(f, 0)
2087             f = theano.function([x], T.and_(zero, x), mode=mode)
2088             self.assert_eqs_const(f, 0)
2089             f = theano.function([x], T.and_(x, one), mode=mode)
2090             if dtype == 'bool':
2091                 self.assert_identity(f)
2092             f = theano.function([x], T.and_(one, x), mode=mode)
2093             if dtype == 'bool':
2094                 self.assert_identity(f)
2095     def test_and_int(self):
2096         f = theano.function([], T.and_(5, 6))
2097         assert f() == 4
2098     def test_or(self):
2099         mode = theano.compile.get_default_mode().including('canonicalize')
2100         for dtype, zero, one in [('bool', np.array(False), np.array(True)),
2101                                  ('int8', np.int8(0), np.int8(1)),
2102                                  ('int8', 0, 1)]:
2103             x = T.scalar('x', dtype=dtype)
2104             f = theano.function([x], T.or_(x, one), mode=mode)
2105             if dtype == 'bool':
2106                 self.assert_eqs_const(f, 1)
2107             f = theano.function([x], T.or_(one, x), mode=mode)
2108             if dtype == 'bool':
2109                 self.assert_eqs_const(f, 1)
2110             f = theano.function([x], T.or_(x, zero), mode=mode)
2111             self.assert_identity(f)
2112             f = theano.function([x], T.or_(zero, x), mode=mode)
2113             self.assert_identity(f)
2114     def test_or_int(self):
2115         f = theano.function([], T.or_(5, 6))
2116         assert f() == 7
2117     def test_xor(self):
2118         mode = theano.compile.get_default_mode().including('canonicalize')
2119         for dtype in ('bool', 'int8'):
2120             x = T.scalar('x', dtype=dtype)
2121             f = theano.function([x], T.xor(x, x), mode=mode)
2122             self.assert_eqs_const(f, 0)
2123     def test_stacktrace(self):
2124         mode = theano.compile.get_default_mode().including(
2125             'local_useless_elemwise_comparison')
2126         x = T.vector('x', dtype=config.floatX)
2127         f = theano.function([x], T.gt(x, x), mode=mode)
2128         self.assertTrue(check_stack_trace(f, ops_to_check='last'))
2129         f = theano.function([x], T.le(x, x), mode=mode)
2130         self.assertTrue(check_stack_trace(f, ops_to_check='last'))
2131 class Test_local_canonicalize_alloc(unittest.TestCase):
2132     def setUp(self):
2133         self.rng = np.random.RandomState(utt.fetch_seed())
2134     @change_flags(compute_test_value='off')
2135     def test0(self):
2136         x = shared(self.rng.randn(3, 7))
2137         a = tensor.alloc(x, 6, 7)
2138         assert a.owner and isinstance(a.owner.op, tensor.Alloc)
2139         f = function([], a, mode=mode_opt)
2140         assert ([node.op for node in f.maker.fgraph.toposort()] ==
2141                 [deep_copy_op])
2142         if isinstance(mode_opt, compile.DebugMode):
2143             self.assertRaises(ValueError, f)
2144     def test1(self):
2145         mode = mode_opt.excluding('local_canonicalize_alloc')
2146         x = tensor.matrix('x')
2147         xx = tensor.fill(x, x)
2148         f = function([x], [xx], mode=mode)
2149         op_classes = [node.op.__class__ for node in f.maker.fgraph.toposort()]
2150         assert tensor.Alloc not in op_classes
2151     def test2(self):
2152         mode = mode_opt.excluding('local_canonicalize_alloc')
2153         x = tensor.matrix('x')
2154         y = tensor.tile(x, (1,) * 2)
2155         f = function([x], [y], mode=mode)
2156         op_classes = [node.op.__class__ for node in f.maker.fgraph.toposort()]
2157         print(op_classes)
2158         assert tensor.Alloc in op_classes
2159     def test_useless_alloc_with_shape_one(self):
2160         alloc_lift = out2in(local_canonicalize_alloc)
2161         x = shared(self.rng.randn(2,))
2162         y = shared(self.rng.randn())
2163         z = shared(self.rng.randn(1, 1))
2164         w = shared(self.rng.randn(1, 1))
2165         alloc_x = tensor.alloc(x, 1, 3, 2)
2166         alloc_y = tensor.alloc(y, 1, 1)
2167         alloc_z = tensor.alloc(z, 1, 1, 2)
2168         alloc_w = tensor.alloc(w, 1, 2)
2169         g = FunctionGraph([x, y, z, w], [alloc_x, alloc_y, alloc_z, alloc_w])
2170         self.assertTrue(str(g) == ("[Alloc(&lt;TensorType(float64, vector)&gt;, "
2171                                    "TensorConstant{1}, "
2172                                    "TensorConstant{3}, "
2173                                    "TensorConstant{2}), "
2174                                    "Alloc(&lt;TensorType(float64, scalar)&gt;, "
2175                                    "TensorConstant{1}, "
2176                                    "TensorConstant{1}), "
2177                                    "Alloc(&lt;TensorType(float64, matrix)&gt;, "
2178                                    "TensorConstant{1}, "
2179                                    "TensorConstant{1}, "
2180                                    "TensorConstant{2}), "
2181                                    "Alloc(&lt;TensorType(float64, matrix)&gt;, "
2182                                    "TensorConstant{1}, "
2183                                    "TensorConstant{2})]"))
2184         alloc_lift.optimize(g)
2185         self.assertTrue(str(g) == "[InplaceDimShuffle{x,0,1}"
2186                                   "(Alloc(&lt;TensorType(float64, vector)&gt;, "
2187                                   "TensorConstant{3}, "
2188                                   "TensorConstant{2})), "
2189                                   "InplaceDimShuffle{x,x}"
2190                                   "(&lt;TensorType(float64, scalar)&gt;), "
2191                                   "InplaceDimShuffle{x,0,1}"
2192                                   "(Alloc(&lt;TensorType(float64, matrix)&gt;, "
2193                                   "TensorConstant{1}, "
2194                                   "TensorConstant{2})), "
2195                                   "Alloc(&lt;TensorType(float64, matrix)&gt;, "
2196                                   "TensorConstant{1}, "
2197                                   "TensorConstant{2})]")
2198         self.assertTrue(check_stack_trace(g, ops_to_check='all'))
2199 class Test_local_useless_inc_subtensor_alloc(unittest.TestCase):
2200     opt_name = 'local_useless_inc_subtensor_alloc'
2201     def setUp(self):
2202         mode = theano.config.mode
2203         if mode == 'FAST_COMPILE':
2204             mode = 'FAST_RUN'
2205         self.mode = compile.mode.get_mode(mode)
2206     def test_advanced_inc_subtensor(self):
2207         x = tensor.vector('x')
2208         y = tensor.scalar('y')
2209         i = tensor.matrix('i', dtype='int64')
2210         z = tensor.advanced_inc_subtensor(x, T.alloc(y, *i.shape), i)
2211         mode1 = self.mode.excluding(self.opt_name)
2212         mode2 = self.mode.including(self.opt_name)
2213         f1 = theano.function([x, i, y], z, mode=mode1)
2214         f2 = theano.function([x, i, y], z, mode=mode2)
2215         assert (len([n for n in f1.maker.fgraph.toposort()
2216                      if isinstance(n.op, tensor.Alloc)]) == 1)
2217         assert (len([n for n in f2.maker.fgraph.toposort()
2218                      if isinstance(n.op, tensor.Alloc)]) == 0)
2219         x_value = np.random.randn(5).astype(config.floatX)
2220         y_value = np.random.randn()
2221         i_value = np.random.randint(0, 3, size=(2, 3))
2222         r1 = f1(x_value, i_value, y_value)
2223         r2 = f2(x_value, i_value, y_value)
2224         utt.assert_allclose(r1, r2)
2225         self.assertTrue(check_stack_trace(f1, ops_to_check=tensor.AdvancedIncSubtensor))
2226         self.assertTrue(check_stack_trace(f2, ops_to_check=tensor.AdvancedIncSubtensor))
2227     def test_advanced_inc_subtensor1(self):
2228         x = tensor.vector('x')
2229         y = tensor.scalar('y')
2230         i = tensor.vector('i', dtype='int64')
2231         z = tensor.advanced_inc_subtensor1(x, T.alloc(y, *i.shape), i)
2232         mode1 = self.mode.excluding(self.opt_name)
2233         mode2 = self.mode.including(self.opt_name)
2234         f1 = theano.function([x, i, y], z, mode=mode1)
2235         f2 = theano.function([x, i, y], z, mode=mode2)
2236         assert (len([n for n in f1.maker.fgraph.toposort()
2237                      if isinstance(n.op, tensor.Alloc)]) == 1)
2238         assert (len([n for n in f2.maker.fgraph.toposort()
2239                      if isinstance(n.op, tensor.Alloc)]) == 0)
2240         x_value = np.random.randn(5).astype(config.floatX)
2241         y_value = np.random.randn()
2242         i_value = np.random.randint(0, 3, size=2)
2243         r1 = f1(x_value, i_value, y_value)
2244         r2 = f2(x_value, i_value, y_value)
2245         utt.assert_allclose(r1, r2)
2246         self.assertTrue(check_stack_trace(
2247             f1, ops_to_check=tensor.AdvancedIncSubtensor1))
2248         self.assertTrue(check_stack_trace(f2, ops_to_check='all'))
2249     def test_incsubtensor(self):
2250         x = tensor.vector('x')
2251         y = tensor.scalar('y')
2252         i = tensor.scalar('i', dtype='int64')
2253         z = tensor.inc_subtensor(x[:i], T.alloc(y, i))
2254         mode1 = self.mode.excluding(self.opt_name)
2255         mode2 = self.mode.including(self.opt_name)
2256         f1 = theano.function([x, i, y], z, mode=mode1)
2257         f2 = theano.function([x, i, y], z, mode=mode2)
2258         assert (len([n for n in f1.maker.fgraph.toposort()
2259                      if isinstance(n.op, tensor.Alloc)]) == 1)
2260         assert (len([n for n in f2.maker.fgraph.toposort()
2261                      if isinstance(n.op, tensor.Alloc)]) == 0)
2262         x_value = np.random.randn(5).astype(config.floatX)
2263         y_value = np.random.randn()
2264         i_value = 3
2265         r1 = f1(x_value, i_value, y_value)
2266         r2 = f2(x_value, i_value, y_value)
2267         utt.assert_allclose(r1, r2)
2268         self.assertTrue(check_stack_trace(f1, ops_to_check='last'))
2269         self.assertTrue(check_stack_trace(f2, ops_to_check='last'))
2270 class test_shapeoptimizer(unittest.TestCase):
2271     def setUp(self):
2272         utt.seed_rng()
2273     def test0(self):
2274         mode = theano.config.mode
2275         if mode == 'FAST_COMPILE':
2276             mode = 'FAST_RUN'
2277         v = T.vector()
2278         m = T.matrix()
2279         f = function([v, m], (v + m).shape, mode=mode)
2280         for node in f.maker.fgraph.toposort():
2281             assert node.op != T.add
2282     def test_constant(self):
2283         mode = theano.config.mode
2284         if mode == 'FAST_COMPILE':
2285             mode = 'FAST_RUN'
2286         v = T.vector()
2287         f = function([v], v.dimshuffle('x', 'x', 0).shape[1], mode=mode)
2288         topo = f.maker.fgraph.toposort()
2289         assert len(topo) == 1
2290         assert topo[0].op == deep_copy_op
2291     @staticmethod
2292     def max_pool_c01b(c01b, pool_shp, pool_stride, img_shp):
2293         mx = None
2294         def last_pool(im_shp, p_shp, p_strd):
2295             rval = int(np.ceil(float(im_shp - p_shp) / p_strd))
2296             assert p_strd * rval + p_shp &gt;= im_shp
2297             assert p_strd * (rval - 1) + p_shp &lt; im_shp
2298             return rval
2299         last_pool_r = last_pool(img_shp, pool_shp, pool_stride) * pool_stride
2300         required_r = last_pool_r + pool_shp
2301         last_pool_c = last_pool(img_shp, pool_shp, pool_stride) * pool_stride
2302         required_c = last_pool_c + pool_shp
2303         wide_infinity = T.alloc(-np.inf, c01b.shape[0],
2304                                 required_r, required_c, c01b.shape[3])
2305         c01b = T.set_subtensor(wide_infinity[:, 0:img_shp, 0:img_shp, :], c01b)
2306         for row_within_pool in xrange(pool_shp):
2307             row_stop = last_pool_r + row_within_pool + 1
2308             for col_within_pool in xrange(pool_shp):
2309                 col_stop = last_pool_c + col_within_pool + 1
2310                 cur = c01b[:, row_within_pool:row_stop:pool_stride,
2311                            col_within_pool:col_stop:pool_stride, :]
2312                 if mx is None:
2313                     mx = cur
2314                 else:
2315                     mx = T.maximum(mx, cur)
2316         return mx
2317     def test_broadcasted_dims(self):
2318         shp = (1, 1, 1, 1)
2319         rng = np.random.RandomState(utt.fetch_seed())
2320         a = shared(rng.rand(*shp).astype(config.floatX))
2321         out = self.max_pool_c01b(a, 1, 1, 1)
2322         mode = copy.copy(theano.compile.get_default_mode())
2323         mode.check_isfinite = False
2324         f = theano.function([], out, mode=mode)
2325         f()
2326     def test_constant_merge(self):
2327         x = tensor.constant([0, 0])
2328         y = x[1:]
2329         x1 = x - tensor.join(0, y, y)
2330         x1.eval()
2331     def test_local_track_shape_i(self):
2332         class IdentityNoShape(gof.Op):
2333             def make_node(self, x):
2334                 x = as_tensor_variable(x)
2335                 return gof.Apply(self, [x], [x.type()])
2336             def perform(self, node, inp, out_):
2337                 x, = inp
2338                 out, = out_
2339                 out[0] = x.copy()
2340         identity_noshape = IdentityNoShape()
2341         class IdentityShape(gof.Op):
2342             def make_node(self, x):
2343                 x = as_tensor_variable(x)
2344                 return gof.Apply(self, [x], [x.type()])
2345             def perform(self, node, inp, out_):
2346                 x, = inp
2347                 out, = out_
2348                 out[0] = x.copy()
2349             def infer_shape(self, node, xshp_):
2350                 xshp, = xshp_
2351                 return (xshp,)
2352         identity_shape = IdentityShape()
2353         @gof.local_optimizer([IdentityNoShape])
2354         def local_identity_noshape_to_identity_shape(node):
2355             if isinstance(node.op, IdentityNoShape):
2356                 return [identity_shape(node.inputs[0])]
2357         mode = theano.compile.get_default_mode().including(
2358             'ShapeOpt', 'specialize')
2359         rng = np.random.RandomState(utt.fetch_seed())
2360         x = T.tensor3('x')
2361         ins_x = identity_noshape(x)
2362         f = theano.function([x], ins_x.shape, mode=mode)
2363         xval = rng.randn(3, 4, 7).astype(config.floatX)
2364         assert np.all(f(xval) == [3, 4, 7])
2365         f_ops = [node.op for node in f.maker.fgraph.toposort()]
2366         assert len(f_ops) == 5
2367         assert identity_noshape in f_ops
2368         assert identity_shape not in f_ops
2369         opt.register_specialize(local_identity_noshape_to_identity_shape)
2370         mode = theano.compile.get_default_mode().including(
2371             'ShapeOpt', 'specialize')
2372         g = theano.function([x], ins_x.shape, mode=mode)
2373         xval = rng.randn(6, 1, 2).astype(config.floatX)
2374         assert np.all(g(xval) == [6, 1, 2])
2375         g_ops = [node.op for node in g.maker.fgraph.toposort()]
2376         assert len(g_ops) == 4
2377         assert identity_noshape not in g_ops
2378         assert identity_shape not in g_ops
2379         ins_x3 = identity_noshape(identity_noshape(identity_noshape(x)))
2380         h = theano.function([x], ins_x3.shape, mode=mode)
2381         xval = rng.randn(6, 1, 2).astype(config.floatX)
2382         assert np.all(h(xval) == [6, 1, 2])
2383         h_ops = [node.op for node in h.maker.fgraph.toposort()]
2384         assert len(h_ops) == 4
2385         assert identity_noshape not in h_ops
2386         assert identity_shape not in h_ops
2387     def test_no_shapeopt(self):
2388         X = T.matrix()
2389         expr = X.shape[0]
2390         mode = theano.compile.get_default_mode().excluding('ShapeOpt')
2391         f = theano.function([X], expr, mode=mode)
2392         print(f([[1, 2], [2, 3]]))
2393 class test_assert(utt.InferShapeTester):
2394     def setUp(self):
2395         super(test_assert, self).setUp()
2396     def test0(self):
2397         x = T.scalar()
2398         y = T.scalar()
2399         f = theano.function([x, y], theano.tensor.opt.assert_op(x, T.eq(x, y)))
2400         f(1, 1)
2401         self.assertRaises(AssertionError, f, 1, 0)
2402     def test_local_remove_useless_assert1(self):
2403         mode = theano.config.mode
2404         if mode == 'FAST_COMPILE':
2405             mode = 'FAST_RUN'
2406         mode = compile.mode.get_mode(mode)
2407         x = T.scalar()
2408         f = theano.function([x], theano.tensor.opt.assert_op(x, 1), mode=mode)
2409         assert f(1) == 1
2410         assert f(5) == 5
2411         topo = f.maker.fgraph.toposort()
2412         assert len(topo) == 1
2413         assert topo[0].op == deep_copy_op
2414     def test_test_local_remove_useless_assert2(self):
2415         mode = theano.config.mode
2416         if mode == 'FAST_COMPILE':
2417             mode = 'FAST_RUN'
2418         mode = compile.mode.get_mode(mode)
2419         x = T.scalar()
2420         y = T.scalar()
2421         f = theano.function([x, y], theano.tensor.opt.assert_op(x, y, 1),
2422                             mode=mode)
2423         assert f(1, 1) == 1
2424         assert f(5, 1) == 5
2425         topo = f.maker.fgraph.toposort()
2426         assert len(topo) == 2
2427         assert len(topo[0].inputs) == 2
2428         assert topo[1].op == deep_copy_op
2429     def test_local_remove_useless_assert3(self):
2430         mode = theano.config.mode
2431         if mode == 'FAST_COMPILE':
2432             mode = 'FAST_RUN'
2433         mode = compile.mode.get_mode(mode)
2434         x = T.scalar()
2435         y = T.scalar()
2436         f = theano.function([x, y], theano.tensor.opt.assert_op(x, y, 0),
2437                             mode=mode)
2438         self.assertRaises(AssertionError, f, 1, 0)
2439         topo = f.maker.fgraph.toposort()
2440         assert len(topo) == 2
2441         assert len(topo[0].inputs) == 3
2442         assert topo[1].op == deep_copy_op
2443     def test_local_remove_all_assert1(self):
2444         mode = theano.config.mode
2445         if mode == 'FAST_COMPILE':
2446             mode = 'FAST_RUN'
2447         mode = compile.mode.get_mode(mode).including('local_remove_all_assert')
2448         x = T.scalar()
2449         y = T.scalar()
2450         f = theano.function([x, y], theano.tensor.opt.assert_op(x, y),
2451                             mode=mode)
2452         if isinstance(mode, theano.compile.debugmode.DebugMode):
2453             self.assertRaises(AssertionError, f, 1, 0)
2454         else:
2455             f(1, 0)  # Without opt, it should fail.
2456         topo = f.maker.fgraph.toposort()
2457         assert len(topo) == 1, topo
2458         assert topo[0].op == deep_copy_op, topo
2459         mode = compile.mode.get_default_mode()
2460         a = theano.tensor.opt.assert_op(x, T.eq(x, 0).any())
2461         f = theano.function([x], a, mode=mode.excluding('unsafe'))
2462         topo = f.maker.fgraph.toposort()
2463         a_op = [n for n in topo if isinstance(n.op, T.opt.Assert)]
2464         assert len(a_op) == 1
2465     def test_infer_shape(self):
2466         adscal = dscalar()
2467         bdscal = dscalar()
2468         adscal_val = np.random.rand()
2469         bdscal_val = np.random.rand() + 1
2470         out = theano.tensor.opt.assert_op(adscal, bdscal)
2471         self._compile_and_check([adscal, bdscal], [out],
2472                                 [adscal_val, bdscal_val], Assert)
2473 <a name="4"></a>        admat = dmatrix()
2474         admat_val = np.random.rand(3, 4)
2475         adscal_val += 1
2476         out <font color="#6cc417"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= theano.tensor.opt.assert_op(admat, adscal, bdscal)
2477         self._compile_and_check([admat, adscal, bdscal], [out],
2478                                 [admat_val, adscal_val, bdscal_val], Assert)
2479 def test_local_mul_specialize():
2480     mode = theano.</b></font>config.mode
2481     if mode == 'FAST_COMPILE':
2482         mode = 'FAST_RUN'
2483     mode = compile.mode.get_mode(mode)
2484     mode = mode.excluding('fusion')
2485     v = T.vector()
2486     m = T.vector()
2487     f = function([v], v * 1, mode=mode)
2488     nodes = [node.op for node in f.maker.fgraph.toposort()]
2489     nodes == [deep_copy_op]
2490     f = function([v], v * 0, mode=mode)
2491     nodes = [node.op for node in f.maker.fgraph.toposort()]
2492     assert nodes == [Shape_i(0), T.alloc]
2493     f = function([v], v * (-1), mode=mode)
2494     nodes = [node.op for node in f.maker.fgraph.toposort()]
2495     assert nodes == [T.neg]
2496     f = function([v, m], v * 1 * (-m), mode=mode)
2497     nodes = [node.op for node in f.maker.fgraph.toposort()]
2498     assert nodes == [T.mul]
2499     f = function([v, m], v * 0 * (-m), mode=mode)
2500     nodes = [node.op for node in f.maker.fgraph.toposort()]
2501     assert nodes == [Shape_i(0), T.alloc]
2502     f = function([v, m], v * (-1) * (-m), mode=mode)
2503     nodes = [node.op for node in f.maker.fgraph.toposort()]
2504     assert nodes == [T.mul]
2505     f = function([v, m], v * (-1) * m, mode=mode)
2506     nodes = [node.op for node in f.maker.fgraph.toposort()]
2507     assert nodes == [T.mul]
2508 class T_Tile(unittest.TestCase):
2509     def test_local_useless_tile(self):
2510         v = T.vector()
2511         m = T.matrix()
2512         mode = None
2513         if theano.config.mode == "FAST_COMPILE":
2514             mode = "FAST_RUN"
2515         for var, data in [(v, [1, 2, 3]), (m, [[1, 2], [3, 4]])]:
2516             for ndim in range(var.ndim + 1):
2517                 f = theano.function([var], tile(var, (1,) * ndim), mode=mode)
2518                 topo = f.maker.fgraph.toposort()
2519                 assert len(topo) == 1
2520                 assert isinstance(topo[0].op, compile.DeepCopyOp)
2521                 f(data)
2522             for ndim in range(var.ndim + 1, var.ndim + 3):
2523                 f = theano.function([var], tile(var, (1,) * ndim), mode=mode)
2524                 topo = f.maker.fgraph.toposort()
2525                 assert len(topo) &lt;= 2
2526                 assert isinstance(topo[0].op, DimShuffle)
2527                 assert check_stack_trace(f, ops_to_check=[DimShuffle])
2528                 f(data)
2529 def speed_local_pow_specialize_range():
2530     val = np.random.rand(1e7)
2531     v = T.vector()
2532     mode = compile.mode.get_default_mode()
2533     mode_without_pow_opt = mode.excluding('local_pow_specialize')
2534     for i in xrange(500, 513):
2535         f1 = function([v], v ** i, mode=mode)
2536         f2 = function([v], v ** i, mode=mode_without_pow_opt)
2537         assert len(f1.maker.fgraph.toposort()) == 1
2538         t1 = time.time()
2539         f1(val)
2540         t2 = time.time()
2541         f2(val)
2542         t3 = time.time()
2543         print(i, t2 - t1, t3 - t2, t2 - t1 &lt; t3 - t2)
2544         if not t2 - t1 &lt; t3 - t2:
2545             print("WARNING WE ARE SLOWER")
2546     for i in xrange(-3, -1500, -1):
2547         f1 = function([v], v ** i, mode=mode)
2548         f2 = function([v], v ** i, mode=mode_without_pow_opt)
2549         assert len(f1.maker.fgraph.toposort()) == 1
2550         t1 = time.time()
2551         f1(val)
2552         t2 = time.time()
2553         f2(val)
2554         t3 = time.time()
2555         print(i, t2 - t1, t3 - t2, t2 - t1 &lt; t3 - t2)
2556         if not t2 - t1 &lt; t3 - t2:
2557             print("WARNING WE ARE SLOWER")
2558 def test_local_pow_specialize():
2559     mode = theano.config.mode
2560     if mode == 'FAST_COMPILE':
2561         mode = 'FAST_RUN'
2562     mode = compile.mode.get_mode(mode)
2563     mode = mode.excluding('fusion')
2564     v = T.vector()
2565     val = np.arange(10, dtype=theano.config.floatX)
2566     val_no0 = np.arange(1, 10, dtype=theano.config.floatX)
2567     f = function([v], v ** 0, mode=mode)
2568     nodes = [node.op for node in f.maker.fgraph.toposort()]
2569     assert nodes == [Shape_i(0), T.alloc]
2570     utt.assert_allclose(f(val), val ** 0)
2571     f = function([v], v ** 1, mode=mode)
2572     nodes = [node.op for node in f.maker.fgraph.toposort()]
2573     nodes == [deep_copy_op]
2574     utt.assert_allclose(f(val), val ** 1)
2575     f = function([v], v ** (-1), mode=mode)
2576     nodes = [node.op for node in f.maker.fgraph.toposort()]
2577     assert nodes == [T.inv]
2578     utt.assert_allclose(f(val_no0), val_no0 ** (-1))
2579     f = function([v], v ** 2, mode=mode)
2580     nodes = [node.op for node in f.maker.fgraph.toposort()]
2581     assert nodes == [T.sqr]
2582     utt.assert_allclose(f(val), val ** 2)
2583     f = function([v], v ** (-2), mode=mode)
2584     nodes = [node.op for node in f.maker.fgraph.toposort()]
2585     assert len(nodes) == 2
2586     assert nodes[0] == T.sqr
2587     assert isinstance(nodes[1].scalar_op, theano.scalar.basic.Inv)
2588     utt.assert_allclose(f(val_no0), val_no0 ** (-2))
2589     f = function([v], v ** (.5), mode=mode)
2590     nodes = [node.op for node in f.maker.fgraph.toposort()]
2591     assert nodes == [T.sqrt]
2592     utt.assert_allclose(f(val), val ** (.5))
2593     f = function([v], v ** (-.5), mode=mode)
2594     nodes = [node.op for node in f.maker.fgraph.toposort()]
2595     assert len(nodes) == 2
2596     assert nodes[0] == T.sqrt
2597     assert isinstance(nodes[1].scalar_op, theano.scalar.basic.Inv)
2598     utt.assert_allclose(f(val_no0), val_no0 ** (-.5))
2599 def test_local_pow_specialize_device_more_aggressive_on_cpu():
2600 <a name="7"></a>    mode = theano.config.mode
2601     if mode == 'FAST_COMPILE':
2602         mode = 'FAST_RUN'
2603     mode = compile.mode.get_mode<font color="#38a4a5"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(mode)
2604     mode = mode.excluding('fusion').excluding('gpu')
2605     v = T.vector()
2606     val = np.arange(10, dtype=</b></font>theano.config.floatX)
2607     val_no0 = np.arange(1, 10, dtype=theano.config.floatX)
2608 <a name="3"></a>    f = function([v], v ** (15), mode=mode)
2609     nodes = [node.op for node in f.maker.fgraph.toposort()]
2610     assert len(nodes) == 1
2611     assert len(f.maker.fgraph<font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.toposort()[0].op.scalar_op.fgraph.apply_nodes) == 6
2612     assert isinstance(nodes[0].scalar_op, theano.scalar.Composite)
2613     utt.</b></font>assert_allclose(f(val), val ** 15)
2614     f = function([v], v ** (-15), mode=mode)
2615     nodes = [node.op for node in f.maker.fgraph.toposort()]
2616     assert len(nodes) == 2
2617     assert len(f.maker.fgraph.toposort()[0].op.scalar_op.fgraph.apply_nodes) == 6
2618     assert isinstance(nodes[0].scalar_op, theano.scalar.Composite)
2619     assert isinstance(nodes[-1].scalar_op, theano.scalar.basic.Inv)
2620     utt.assert_allclose(f(val_no0), val_no0 ** (-15))
2621 <a name="2"></a>    f = function([v], v ** (16), mode=mode)
2622     nodes = [node.op for node in f.maker.fgraph.toposort()]
2623     assert len(nodes) == 1
2624     assert len(f.maker.fgraph<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.toposort()[0].op.scalar_op.fgraph.apply_nodes) == 4
2625     assert isinstance(nodes[0].scalar_op, theano.scalar.Composite)
2626     utt.</b></font>assert_allclose(f(val), val ** 16)
2627     f = function([v], v ** (-16), mode=mode)
2628     nodes = [node.op for node in f.maker.fgraph.toposort()]
2629     assert len(nodes) == 2
2630     assert len(f.maker.fgraph.toposort()[0].op.scalar_op.fgraph.apply_nodes) == 4
2631     assert isinstance(nodes[0].scalar_op, theano.scalar.Composite)
2632     assert isinstance(nodes[-1].scalar_op, theano.scalar.basic.Inv)
2633     utt.assert_allclose(f(val_no0), val_no0 ** (-16))
2634 class T_Rebroadcast(unittest.TestCase):
2635     def test_local_useless_rebroadcast(self):
2636         mode = theano.compile.get_default_mode().including('canonicalize')
2637         v1 = T.vector()
2638         v2 = T.vector()
2639         j = T.join(0, v1, v2)
2640         f = theano.function([v1, v2], j, mode=mode)
2641         f([1, 2], [3, 4, 5])
2642         e = f.maker.fgraph.toposort()
2643         assert len([n for n in e if isinstance(n.op, T.Rebroadcast)]) == 0
2644 <a name="0"></a>        assert check_stack_trace(f, ops_to_check='all')
2645     def test_rebroadcast_rebroadcast(self):
2646         mode = theano.compile.get_default_mode()<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.including('canonicalize')
2647         m = T.matrix()
2648         s = T.addbroadcast(m, 0, 1)
2649         v = T.unbroadcast(s, 1)
2650         f = theano.function([m], v, mode=mode)
2651         f([[76]])
2652         e = f.</b></font>maker.fgraph.toposort()
2653         rebroadcast_nodes = [n for n in e if isinstance(n.op, T.Rebroadcast)]
2654         assert len(rebroadcast_nodes) == 1
2655         assert rebroadcast_nodes[0].op.axis == {0: True}
2656 class T_useless_elemwise(unittest.TestCase):
2657     def setUp(self):
2658         self.mode = theano.compile.get_default_mode().including(
2659             'canonicalize', 'local_fill_to_alloc')
2660     def test_eq(self):
2661         x = T.dmatrix()
2662         y = T.dmatrix()
2663         f = theano.function([x, y], T.eq(x, y), mode=self.mode)
2664         vx = np.random.rand(5, 4)
2665         vy = np.random.rand(5, 4)
2666         f(vx, vy)
2667 <a name="17"></a>        topo = f.maker.fgraph.toposort()
2668         assert len(topo) == 1
2669         assert isinstance(topo[0].op, T.Elemwise)
2670         assert isinstance<font color="#3090c7"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(topo[0].op.scalar_op, theano.scalar.EQ)
2671         f2 = theano.function([x], T.eq(x, x), mode=</b></font>self.mode)
2672         assert np.all(f2(vx) == np.ones((5, 4)))
2673         topo2 = f2.maker.fgraph.toposort()
2674         assert len(topo2) == 3
2675         assert isinstance(topo2[-1].op, T.Alloc)
2676     def test_neq(self):
2677         x = T.dmatrix()
2678         y = T.dmatrix()
2679         f = theano.function([x, y], T.neq(x, y), mode=self.mode)
2680         vx = np.random.rand(5, 4)
2681         vy = np.random.rand(5, 4)
2682         f(vx, vy)
2683 <a name="16"></a>        topo = f.maker.fgraph.toposort()
2684         assert len(topo) == 1
2685         assert isinstance(topo[0].op, T.Elemwise)
2686         assert isinstance<font color="#2981b2"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(topo[0].op.scalar_op, theano.scalar.NEQ)
2687         f2 = theano.function([x], T.neq(x, x), mode=</b></font>self.mode)
2688         assert np.all(f2(vx) == np.zeros((5, 4)))
2689         topo2 = f2.maker.fgraph.toposort()
2690         assert len(topo2) == 3
2691         assert isinstance(topo2[-1].op, T.Alloc)
2692     def test_mul(self):
2693         x = T.dmatrix()
2694         y = T.dmatrix()
2695         f = theano.function([x], T.mul(x), mode=self.mode)
2696         vx = np.random.rand(5, 4)
2697         vy = np.random.rand(5, 4)
2698         f(vx)
2699         topo = f.maker.fgraph.toposort()
2700         assert len(topo) == 1
2701         assert topo[0].op == deep_copy_op
2702         f2 = theano.function([x, y], T.mul(x, y), mode=self.mode)
2703         assert np.all(f2(vx, vy) == vx * vy)
2704         topo2 = f2.maker.fgraph.toposort()
2705         assert len(topo2) == 1
2706         assert isinstance(topo2[0].op, T.Elemwise)
2707         assert isinstance(topo2[0].op.scalar_op, theano.scalar.Mul)
2708     def test_add(self):
2709         x = T.dmatrix()
2710         y = T.dmatrix()
2711         f = theano.function([x], T.add(x), mode=self.mode)
2712         vx = np.random.rand(5, 4)
2713         vy = np.random.rand(5, 4)
2714         f(vx)
2715         topo = f.maker.fgraph.toposort()
2716         assert len(topo) == 1
2717         assert topo[0].op == deep_copy_op
2718         f2 = theano.function([x, y], T.add(x, y), mode=self.mode)
2719         assert np.all(f2(vx, vy) == vx + vy)
2720         topo2 = f2.maker.fgraph.toposort()
2721         assert len(topo2) == 1
2722         assert isinstance(topo2[0].op, T.Elemwise)
2723         assert isinstance(topo2[0].op.scalar_op, theano.scalar.Add)
2724     def test_identity(self):
2725         x = T.matrix()
2726         f = theano.function([x], T.tensor_copy(x), mode=self.mode)
2727         vx = np.random.rand(5, 4).astype(config.floatX)
2728         f(vx)
2729         topo = f.maker.fgraph.toposort()
2730         assert len(topo) == 1
2731         assert topo[0].op == deep_copy_op
2732 class T_cast_cast(unittest.TestCase):
2733     def setUp(self):
2734         mode = theano.compile.get_default_mode()
2735         self.mode = mode.including('local_cast_cast')
2736     def test_consecutive(self):
2737         x = T.fmatrix()
2738         o = T.Elemwise(scal.Cast(scal.Scalar("float64")))(x.astype("float64"))
2739         f = theano.function([x], o, mode=self.mode)
2740         dx = np.random.rand(5, 4).astype("float32")
2741         f(dx)
2742         topo = f.maker.fgraph.toposort()
2743         assert len(topo) == 1
2744         assert isinstance(topo[0].op.scalar_op, scal.basic.Cast)
2745         x = T.dmatrix()
2746         o = T.Elemwise(scal.Cast(scal.Scalar("float32")))(x.astype("float32"))
2747         f = theano.function([x], o, mode=self.mode)
2748         dx = np.random.rand(5, 4)
2749         f(dx)
2750         topo = f.maker.fgraph.toposort()
2751         assert len(topo) == 1
2752         assert isinstance(topo[0].op.scalar_op, scal.basic.Cast)
2753     def test_upcast(self):
2754         x = T.fmatrix()
2755         o = T.Elemwise(scal.Cast(scal.Scalar("complex128")))(x.astype("complex64"))
2756         f = theano.function([x], o, mode=self.mode)
2757         dx = np.random.rand(5, 4).astype("float32")
2758         f(dx)
2759         topo = f.maker.fgraph.toposort()
2760         assert len(topo) == 1
2761         assert isinstance(topo[0].op.scalar_op, scal.basic.Cast)
2762         x = T.fmatrix()
2763         o = T.Elemwise(scal.Cast(scal.Scalar("float32")))(x.astype("float64"))
2764         f = theano.function([x], o, mode=self.mode)
2765         dx = np.random.rand(5, 4).astype('float32')
2766         f(dx)
2767         topo = f.maker.fgraph.toposort()
2768         assert len(topo) == 1
2769         assert isinstance(topo[0].op, DeepCopyOp)
2770         x = T.dmatrix()
2771         o = T.Elemwise(scal.Cast(scal.Scalar("float64")))(x.astype("float32"))
2772         f = theano.function([x], o, mode=self.mode)
2773         dx = np.random.rand(5, 4)
2774         f(dx)
2775         topo = f.maker.fgraph.toposort()
2776         assert (len(topo) == 1 and isinstance(topo[0].op.scalar_op, scal.basic.Composite)) or (len(topo) &gt; 1)
2777 class T_func_inverse(unittest.TestCase):
2778     def setUp(self):
2779         mode = theano.compile.get_default_mode()
2780         self.mode = mode.including('local_func_inv')
2781     def assert_func_pair_optimized(self, func1, func2, data,
2782                                    should_copy=True, is_complex=False):
2783         x = T.cmatrix() if is_complex else T.fmatrix()
2784         o = func2(func1(x))
2785         f = theano.function([x], o, mode=self.mode)
2786         delta = f(data) - data
2787         topo = f.maker.fgraph.toposort()
2788         if should_copy:
2789             acceptable_topo_lens = [1]
2790         else:
2791             acceptable_topo_lens = [1, 2]
2792         if should_copy:
2793             delta_condition = np.all(delta == 0)
2794         else:
2795             delta_condition = np.all(delta != 0)
2796         self.assertTrue(len(topo) in acceptable_topo_lens)
2797         self.assertTrue(delta_condition)
2798         self.assertEqual(isinstance(topo[0].op, DeepCopyOp), should_copy,
2799                          "Inverse functions not removed!")
2800     def test(self):
2801         dx = np.random.rand(5, 4).astype("float32")
2802         self.assert_func_pair_optimized(T.deg2rad, T.rad2deg, dx)
2803         dx = np.random.rand(5, 4).astype("float32") * 180
2804         self.assert_func_pair_optimized(T.rad2deg, T.deg2rad, dx)
2805         dx = np.random.rand(5, 4).astype("float32")
2806         self.assert_func_pair_optimized(T.cosh, T.arccosh, dx)
2807         self.assert_func_pair_optimized(T.arcsinh, T.sinh, dx)
2808         self.assert_func_pair_optimized(T.arctanh, T.tanh, dx)
2809         self.assert_func_pair_optimized(T.inv, T.inv, dx)
2810         self.assert_func_pair_optimized(T.neg, T.neg, dx)
2811         cx = dx + complex(0, 1) * (dx + 0.01)
2812         self.assert_func_pair_optimized(T.conj, T.conj, cx, is_complex=True)
2813         self.assert_func_pair_optimized(T.conj, T.neg, cx,
2814                                         should_copy=False, is_complex=True)
2815         dx = np.random.rand(5, 4).astype("float32") + 0.01
2816         self.assert_func_pair_optimized(T.rad2deg, T.rad2deg, dx,
2817                                         should_copy=False)
2818         self.assert_func_pair_optimized(T.rad2deg, T.cosh, dx,
2819                                         should_copy=False)
2820 def test_constant_folding():
2821     x = tensor.dvector()
2822     mode = theano.compile.get_mode("FAST_COMPILE").excluding("fusion")
2823     f = theano.function([x], [x * 2, x + x], mode=mode)
2824     topo = f.maker.fgraph.toposort()
2825     assert len(topo) == 2
2826     x = tensor.constant(3)
2827     assert x.ndim == 0
2828     mode = theano.compile.get_mode("FAST_COMPILE").excluding("fusion")
2829     f = theano.function([], [x * 2, x + x], mode=mode)
2830     topo = f.maker.fgraph.toposort()
2831     assert len(topo) == 2
2832     assert all([isinstance(n.op, DeepCopyOp) for n in topo])
2833 def test_constant_get_stabilized():
2834     x2 = T.scalar()
2835     y2 = T.log(1 + T.exp(x2))
2836     mode = theano.compile.get_default_mode()
2837     mode.check_isfinite = False
2838     f2 = theano.function([x2], y2, mode=mode)
2839     try:
2840         assert len(f2.maker.fgraph.toposort()) == 1
2841         assert (f2.maker.fgraph.toposort()[0].op ==
2842                 theano.tensor.nnet.sigm.softplus)
2843         assert f2(800) == 800
2844         x = T.as_tensor_variable(800)
2845         y = T.log(1 + T.exp(x))
2846         f = theano.function([], y, mode=mode)
2847         assert len(f.maker.fgraph.toposort()) == 0
2848         assert np.isinf(f())
2849         assert f() == 800, f()
2850     except AssertionError:
2851         raise SkipTest('Theano optimizes constant before stabilization. '
2852                        'This breaks stabilization optimization in some '
2853                        'cases. See #504.')
2854 <a name="13"></a>class T_local_switch_sink(unittest.TestCase):
2855     def setUp(self):
2856         self.condm = np<font color="#3b9c9c"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.asarray([[0.1, 0, 1, -1],
2857                                  [0., 0., 0., 0.],
2858                                  [1, 1, 1, 1]])
2859         self.condv = np.asarray([0.1, 0, 1, -1])
2860         self.</b></font>conds = [0.1, 0, 1, -1]
2861         self.xm = np.ones((3, 4))
2862         self.xv = np.ones((4,))
2863         self.xs = 1.
2864         self.resm = (
2865             [np.asarray([[1, 0, 1, 0], [0, 0, 0, 0], [1, 1, 1, 1]])] * 3 +
2866             [np.asarray([[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]])] +
2867             2 * [np.asarray([[1, 0, 1, 0]])] +
2868             [[np.ones((3, 4)), np.zeros((3, 4)), np.ones((3, 4)), np.zeros((3, 4))]] +
2869             [[np.ones((4,)), np.zeros((4,)), np.ones((4,)), np.zeros((4,))]] +
2870             [[np.asarray(1.0), np.asarray(0.0), np.asarray(1.0), np.asarray(0.0)]])
2871         self.mode = theano.compile.mode.get_default_mode().including(
2872             'canonicalize', 'fast_run').excluding('gpu', 'fusion')
2873         self.mode = copy.copy(self.mode)
2874         self.mode.check_isfinite = False
2875     def function_remove_nan(self, *args, **kwargs):
2876         f = theano.function(*args, **kwargs)
2877         def wrapped_f(*args, **kwargs):
2878             old_values_eq_approx = staticmethod(TensorType.values_eq_approx)
2879             TensorType.values_eq_approx = staticmethod(values_eq_approx_remove_nan)
2880             try:
2881                 out = f(*args, **kwargs)
2882             finally:
2883                 TensorType.values_eq_approx = old_values_eq_approx
2884             return out
2885         return wrapped_f
2886     def test_local_mul_switch_sink(self):
2887         c = T.dscalar()
2888         idx = 0
2889         for condition in [(T.dmatrix('cond'), self.condm),
2890                           (T.dvector('cond'), self.condv),
2891                           (T.dscalar('cond'), self.conds)]:
2892             for x in [(T.dmatrix('x'), self.xm), (T.dvector('x'), self.xv),
2893                       (T.dscalar('x'), self.xs)]:
2894                 y = T.mul(T.switch(condition[0] &gt; 0, 1. * x[0], 0. * x[0]),
2895                           T.switch(condition[0] &gt; 0,
2896                                    1. * x[0], T.log(c) * x[0]))
2897                 f = self.function_remove_nan([condition[0], x[0], c],
2898                                              [y], mode=self.mode)
2899                 if type(condition[1]) is list:
2900                     for i in xrange(len(condition[1])):
2901                         res = f(condition[1][i], x[1], -1)
2902                         assert (res == np.asarray(
2903                             self.resm[idx][i])).sum() == self.resm[idx][i].size
2904                 else:
2905                     res = f(condition[1], x[1], -1)
2906                     assert ((res == np.asarray(self.resm[idx])).sum() ==
2907                             self.resm[idx].size)
2908                 idx += 1
2909         x = T.dscalar('x')
2910         y = T.switch(x &lt; 7, x, T.sqrt(x - 7))
2911         f = self.function_remove_nan([x], T.grad(y, x), self.mode)
2912         assert f(5) == 1, f(5)
2913     @attr('slow')
2914     def test_local_div_switch_sink(self):
2915         c = T.dscalar()
2916         idx = 0
2917         for condition in [(T.dmatrix('cond'), self.condm), (T.dvector('cond'), self.condv), (T.dscalar('cond'), self.conds)]:
2918             for x in [(T.dmatrix('x'), self.xm), (T.dvector('x'), self.xv), (T.dscalar('x'), self.xs)]:
2919                 y = T.true_div(
2920                     T.switch(condition[0] &gt; 0, 1. * x[0], 0. * x[0]),
2921                     T.switch(condition[0] &gt; 0, 1. * x[0], T.log(c) * x[0]))
2922                 f = self.function_remove_nan([condition[0], x[0], c],
2923                                              [y], mode=self.mode)
2924                 if type(condition[1]) is list:
2925                     for i in xrange(len(condition[1])):
2926                         res = f(condition[1][i], x[1], -1)
2927                         assert ((res == np.asarray(self.resm[idx][i])).sum() ==
2928                                 self.resm[idx][i].size)
2929                 else:
2930                     res = f(condition[1], x[1], -1)
2931                     assert ((res == np.asarray(self.resm[idx])).sum() ==
2932                             self.resm[idx].size)
2933                 idx += 1
2934 class T_local_erf(unittest.TestCase):
2935     def setUp(self):
2936         self.mode = theano.compile.mode.get_default_mode().including(
2937             'canonicalize', 'fast_run').excluding('gpu', 'fusion')
2938         self.mode._optimizer.position_cutoff = 1.50001
2939         if theano.config.cxx == '' and not theano.scalar.basic_scipy.imported_scipy_special:
2940             raise SkipTest("erf need a c++ compiler or scipy")
2941     def test_local_one_plus_erf(self):
2942         val = np.asarray([-30, -3, -2, -1, 0, 1, 2, 3, 30],
2943                          dtype=config.floatX)
2944         x = T.vector()
2945         f = theano.function([x], 1 + T.erf(x), mode=self.mode)
2946         assert [n.op for n in f.maker.fgraph.toposort()] == [
2947             T.mul, T.erfc], f.maker.fgraph.toposort()
2948         f(val)
2949         f = theano.function([x], T.erf(x) + 1, mode=self.mode)
2950         assert [n.op for n in f.maker.fgraph.toposort()] == [
2951             T.mul, T.erfc], f.maker.fgraph.toposort()
2952         f(val)
2953         f = theano.function([x], T.erf(x) + 2, mode=self.mode)
2954         topo = f.maker.fgraph.toposort()
2955         assert len(topo) == 2
2956         assert topo[0].op == T.erf
2957         assert isinstance(topo[1].op, T.Elemwise)
2958         assert isinstance(topo[1].op.scalar_op, scal.Add)
2959         f(val)
2960     def test_local_one_minus_erf(self):
2961         val = np.asarray([-30, -3, -2, -1, 0, 1, 2, 3, 30],
2962                          dtype=config.floatX)
2963         x = T.vector()
2964         f = theano.function([x], 1 - T.erf(x), mode=self.mode)
2965         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erfc],\
2966             f.maker.fgraph.toposort()
2967         print(f(val))
2968         f = theano.function([x], 1 + (-T.erf(x)), mode=self.mode)
2969         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erfc],\
2970             f.maker.fgraph.toposort()
2971         print(f(val))
2972         f = theano.function([x], (-T.erf(x)) + 1, mode=self.mode)
2973         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erfc],\
2974             f.maker.fgraph.toposort()
2975         print(f(val))
2976         f = theano.function([x], 2 - T.erf(x), mode=self.mode)
2977         topo = f.maker.fgraph.toposort()
2978         assert len(topo) == 2, f.maker.fgraph.toposort()
2979         assert topo[0].op == T.erf, f.maker.fgraph.toposort()
2980         assert isinstance(topo[1].op, T.Elemwise), f.maker.fgraph.toposort()
2981         assert isinstance(topo[1].op.scalar_op, scal.Add)\
2982             or isinstance(topo[1].op.scalar_op, scal.Sub), f.maker.fgraph.toposort()
2983         print(f(val))
2984     def test_local_erf_minus_one(self):
2985         val = np.asarray([-30, -3, -2, -1, 0, 1, 2, 3, 30],
2986                          dtype=config.floatX)
2987         x = T.vector()
2988         f = theano.function([x], T.erf(x) - 1, mode=self.mode)
2989         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erfc, T.mul]
2990         print(f(val))
2991         f = theano.function([x], T.erf(x) + (-1), mode=self.mode)
2992         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erfc, T.mul]
2993         print(f(val))
2994         f = theano.function([x], -1 + T.erf(x), mode=self.mode)
2995         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erfc, T.mul]
2996         print(f(val))
2997         f = theano.function([x], T.erf(x) - 2, mode=self.mode)
2998         topo = f.maker.fgraph.toposort()
2999         assert len(topo) == 2
3000         assert topo[0].op == T.erf
3001         assert isinstance(topo[1].op, T.Elemwise)
3002         assert isinstance(topo[1].op.scalar_op, scal.Add)\
3003             or isinstance(topo[1].op.scalar_op, scal.Sub)
3004         print(f(val))
3005 class T_local_erfc(unittest.TestCase):
3006     def setUp(self):
3007         self.mode_fusion = theano.compile.mode.get_default_mode().including(
3008             'canonicalize').including('fast_run').excluding('gpu')
3009         self.mode = self.mode_fusion.excluding('fusion')
3010         self.mode._optimizer.position_cutoff = 1.50001
3011         if (theano.config.cxx == '' and
3012                 not theano.scalar.basic_scipy.imported_scipy_special):
3013             raise SkipTest("erfc need a c++ compiler or scipy")
3014     def test_local_one_minus_erfc(self):
3015         val = np.asarray([-30, -3, -2, -1, 0, 1, 2, 3, 30],
3016                          dtype=config.floatX)
3017         x = T.vector('x')
3018         f = theano.function([x], 1 - T.erfc(x), mode=self.mode)
3019         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erf],\
3020             f.maker.fgraph.toposort()
3021         print(f(val))
3022         f = theano.function([x], (-T.erfc(x)) + 1, mode=self.mode)
3023         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erf],\
3024             f.maker.fgraph.toposort()
3025         print(f(val))
3026         f = theano.function([x], 2 - T.erfc(x), mode=self.mode)
3027         topo = f.maker.fgraph.toposort()
3028         assert len(topo) == 2, f.maker.fgraph.toposort()
3029         assert topo[0].op == T.erfc, f.maker.fgraph.toposort()
3030         assert isinstance(topo[1].op, T.Elemwise), f.maker.fgraph.toposort()
3031         assert isinstance(topo[1].op.scalar_op, scal.Sub),\
3032             f.maker.fgraph.toposort()
3033         print(f(val))
3034     def test_local_erf_neg_minus_one(self):
3035         val = np.asarray([-30, -3, -2, -1, 0, 1, 2, 3, 30],
3036                          dtype=config.floatX)
3037         x = T.vector('x')
3038         f = theano.function([x], -1 + T.erfc(-x), mode=self.mode)
3039         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erf],\
3040             f.maker.fgraph.toposort()
3041         print(f(val))
3042         f = theano.function([x], T.erfc(-x) - 1, mode=self.mode)
3043         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erf],\
3044             f.maker.fgraph.toposort()
3045         print(f(val))
3046         f = theano.function([x], T.erfc(-x) + (-1), mode=self.mode)
3047         assert [n.op for n in f.maker.fgraph.toposort()] == [T.erf],\
3048             f.maker.fgraph.toposort()
3049         print(f(val))
3050     def test_local_log_erfc(self):
3051         val = [-30, -27, -26, -11, -10, -3, -2, -1, 0, 1, 2, 3, 10,
3052                11, 26, 27, 28, 30]
3053         if theano.config.mode in ["DebugMode", "DEBUG_MODE", "FAST_COMPILE"]:
3054             val.remove(0)
3055         val = np.asarray(val, dtype=config.floatX)
3056         x = T.vector('x')
3057         mode = copy.copy(self.mode)
3058         mode.check_isfinite = False
3059         mode_fusion = copy.copy(self.mode_fusion)
3060         mode_fusion.check_isfinite = False
3061         f = theano.function([x], T.log(T.erfc(x)), mode=mode)
3062         assert len(f.maker.fgraph.apply_nodes) == 23, len(f.maker.fgraph.apply_nodes)
3063         assert f.maker.fgraph.outputs[0].dtype == theano.config.floatX
3064         assert all(np.isfinite(f(val)))
3065         f = theano.function([x], T.log(T.erfc(-x)), mode=mode)
3066         assert len(f.maker.fgraph.apply_nodes) == 24, len(f.maker.fgraph.apply_nodes)
3067         assert f.maker.fgraph.outputs[0].dtype == theano.config.floatX
3068         assert all(np.isfinite(f(-val)))
3069         f = theano.function([x], T.log(T.erfc(x)), mode=mode_fusion)
3070         assert len(f.maker.fgraph.apply_nodes) == 1, len(f.maker.fgraph.apply_nodes)
3071         assert f.maker.fgraph.outputs[0].dtype == theano.config.floatX
3072         assert len(f.maker.fgraph.toposort()[0].fgraph.toposort()[
3073             0].op.scalar_op.fgraph.apply_nodes) == 22, len(f.maker.fgraph.toposort()[0].fgraph.toposort()[0].op.scalar_op.fgraph.apply_nodes)
3074         if theano.config.floatX == "float32" and theano.config.mode in ["DebugMode", "DEBUG_MODE"]:
3075             raise SkipTest('The python code upcast somewhere internally '
3076                            'some value of float32 to python float for '
3077                            'part of its computation. That make that the '
3078                            'c and python code don\'t generate the same value. '
3079                            'You can ignore this error.')
3080         assert all(np.isfinite(f(val)))
3081     def test_local_grad_log_erfc_neg(self):
3082         val = [-100, -30, -27, -26.4, -26.2, -26, -11, -10, -9, -3, -2, -1, 0,
3083                1, 2, 3, 9, 10, 11, 27, 26.4, 26.2, 26, 28, 30, 100]
3084         if theano.config.mode in ["DebugMode", "DEBUG_MODE", "FAST_COMPILE"]:
3085             val.remove(0)
3086         if theano.config.mode in ["DebugMode", "DEBUG_MODE"] and theano.config.floatX == 'float32':
3087             val.remove(10)
3088         val = np.asarray(val, dtype=config.floatX)
3089         x = T.vector('x')
3090         y = T.vector('y')
3091         mode = copy.copy(self.mode)
3092         mode.check_isfinite = False
3093         mode_fusion = copy.copy(self.mode_fusion)
3094         mode_fusion.check_isfinite = False
3095         f = theano.function([x], T.grad(T.log(T.erfc(x)).sum(), x), mode=mode)
3096         assert len(f.maker.fgraph.apply_nodes) == 23, len(f.maker.fgraph.apply_nodes)
3097         assert all(np.isfinite(f(val)))
3098         assert f.maker.fgraph.outputs[0].dtype == theano.config.floatX
3099         f = theano.function(
3100             [x],
3101             T.mul(T.exp(T.neg(T.sqr(x))), - 10.12837917) / T.erfc(x),
3102             mode=mode)
3103         assert len(f.maker.fgraph.apply_nodes) == 23, len(f.maker.fgraph.apply_nodes)
3104         assert f.maker.fgraph.outputs[0].dtype == theano.config.floatX
3105         assert all(np.isfinite(f(val)))
3106 <a name="1"></a>        f = theano.function([x], T.exp(T.neg(T.sqr(x))) / T.erfc(x), mode=mode)
3107         assert len(f.maker.fgraph.apply_nodes) == 22, len(f.maker.fgraph.apply_nodes)
3108         assert f.maker.fgraph.outputs[0].dtype == theano.config.floatX
3109         assert all(np<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.isfinite(f(val)))
3110         f = theano.function([x, y], T.exp(T.neg(T.sqr(x))) / T.</b></font>erfc(
3111             y), mode=mode)
3112         assert len(f.maker.fgraph.apply_nodes) == 5, len(f.maker.fgraph.apply_nodes)
3113         assert f.maker.fgraph.outputs[0].dtype == theano.config.floatX
3114         f(val, val - 3)
3115         f = theano.function([x], T.exp(T.mul(-1, x, x)) / T.erfc(x), mode=mode)
3116         assert len(f.maker.fgraph.apply_nodes) == 21, len(f.maker.fgraph.apply_nodes)
3117         assert f.maker.fgraph.outputs[0].dtype == theano.config.floatX
3118         assert all(np.isfinite(f(val)))
3119         f = theano.function([x], T.grad(T.log(T.erfc(2 * x)).sum(), x), mode=mode)
3120         assert len(f.maker.fgraph.apply_nodes) == 23, len(f.maker.fgraph.apply_nodes)
3121         assert np.isfinite(f(val)).all()
3122         assert f.maker.fgraph.outputs[0].dtype == theano.config.floatX
3123         f = theano.function([x], T.grad(T.log(T.erfc(x)).sum(), x), mode=mode_fusion)
3124         assert len(f.maker.fgraph.apply_nodes) == 1, len(f.maker.fgraph.apply_nodes)
3125         assert f.maker.fgraph.outputs[0].dtype == theano.config.floatX
3126         if theano.config.floatX == "float32" and theano.config.mode in ["DebugMode", "DEBUG_MODE"]:
3127             pass
3128         else:
3129             assert all(np.isfinite(f(val)))
3130     def speed_local_log_erfc(self):
3131         val = np.random.rand(1e6)
3132         x = T.vector()
3133         mode = theano.compile.mode.get_mode("FAST_RUN")
3134         f1 = theano.function([x], T.log(T.erfc(x)),
3135                              mode=mode.excluding("local_log_erfc"))
3136         f2 = theano.function([x], T.log(T.erfc(x)), mode=mode)
3137         print(f1.maker.fgraph.toposort())
3138         print(f2.maker.fgraph.toposort())
3139         t0 = time.time()
3140         f1(val)
3141         t1 = time.time()
3142         f2(val)
3143         t2 = time.time()
3144         print(t1 - t0, t2 - t1)
3145 class test_local_useless_switch(unittest.TestCase):
3146     def setUp(self):
3147         self.mode = mode_opt.excluding('constant_folding')
3148     def test_const0(self):
3149         for dtype1 in ['int32', 'int64']:
3150             for dtype2 in ['int32', 'int64']:
3151                 x = theano.tensor.matrix('x', dtype=dtype1)
3152                 y = theano.tensor.matrix('y', dtype=dtype2)
3153                 z = theano.tensor.switch(0, x, y)
3154                 f = theano.function([x, y], z, mode=self.mode)
3155                 assert len([node.op for node in f.maker.fgraph.toposort() if
3156                             (isinstance(node.op, theano.tensor.Elemwise) and
3157                              isinstance(node.op.scalar_op,
3158                                         theano.scalar.basic.Switch))]) == 0
3159                 vx = np.array([[1, 2, 3], [4, 5, 6]], dtype=dtype1)
3160                 vy = np.array([[7, 8, 9], [10, 11, 12]], dtype=dtype2)
3161                 assert np.all(f(vx, vy) == vy)
3162     def test_const1(self):
3163         for dtype1 in ['int32', 'int64']:
3164             for dtype2 in ['int32', 'int64']:
3165                 x = theano.tensor.matrix('x', dtype=dtype1)
3166                 y = theano.tensor.matrix('y', dtype=dtype2)
3167                 z = theano.tensor.switch(1, x, y)
3168                 f = theano.function([x, y], z, mode=self.mode)
3169                 assert len([node.op for node in f.maker.fgraph.toposort() if
3170                             (isinstance(node.op, theano.tensor.Elemwise) and
3171                              isinstance(node.op.scalar_op,
3172                                         theano.scalar.basic.Switch))]) == 0
3173                 vx = np.array([[1, 2, 3], [4, 5, 6]], dtype=dtype1)
3174                 vy = np.array([[7, 8, 9], [10, 11, 12]], dtype=dtype2)
3175                 assert np.all(f(vx, vy) == vx)
3176     def test_left_is_right(self):
3177         for dtype1 in ['int32', 'int64']:
3178             x = theano.tensor.matrix('x', dtype=dtype1)
3179             varc = theano.tensor.matrix('varc', dtype=dtype1)
3180             z1 = theano.tensor.switch(1, x, x)
3181             z0 = theano.tensor.switch(0, x, x)
3182             z2 = theano.tensor.switch(varc, x, x)
3183             f1 = theano.function([x], z1, mode=self.mode)
3184             f0 = theano.function([x], z0, mode=self.mode)
3185             f2 = theano.function([x, varc], z2, mode=self.mode)
3186             topo = f1.maker.fgraph.toposort()
3187             assert len(topo) == 1
3188             assert topo[0].op == deep_copy_op
3189             topo = f0.maker.fgraph.toposort()
3190             assert len(topo) == 1
3191             assert topo[0].op == deep_copy_op
3192             topo = f2.maker.fgraph.toposort()
3193             assert len(topo) == 1
3194             assert topo[0].op == deep_copy_op
3195             vx = np.array([[1, 2, 3], [4, 5, 6]], dtype=dtype1)
3196             vc = np.array([[1, 2, 3], [4, 5, 6]], dtype=dtype1)
3197             assert np.all(f1(vx) == vx)
3198             assert np.all(f0(vx) == vx)
3199             assert np.all(f2(vx, vc) == vx)
3200     def test_shape_le_0(self):
3201         for dtype1 in ['float32', 'float64']:
3202             x = theano.tensor.matrix('x', dtype=dtype1)
3203             z0 = theano.tensor.switch(theano.tensor.le(x.shape[0], 0), 0, x.shape[0])
3204             f0 = theano.function([x], z0, mode=self.mode)
3205             assert isinstance(f0.maker.fgraph.toposort()[0].op, Shape_i)
3206             z1 = theano.tensor.switch(theano.tensor.le(x.shape[1], 0), 0, x.shape[1])
3207             f1 = theano.function([x], z1, mode=self.mode)
3208             assert isinstance(f1.maker.fgraph.toposort()[0].op, Shape_i)
3209             vx = np.random.randn(0, 5).astype(dtype1)
3210             assert f0(vx) == 0
3211             assert f1(vx) == 5
3212     def test_broadcast1(self):
3213         x = theano.tensor.matrix('x', dtype='int32')
3214         y = theano.tensor.vector('y', dtype='int64')
3215         z = theano.tensor.switch(1, x, y)
3216         f = theano.function([x, y], z, mode=self.mode)
3217         assert len([node.op for node in f.maker.fgraph.toposort() if
3218                     isinstance(node.op, theano.tensor.Elemwise) and
3219                     not isinstance(node.op.scalar_op, theano.scalar.basic.Cast)]) == 0
3220         vx = np.array([[1, 2, 3], [4, 5, 6]], dtype='int32')
3221         vy = np.array([10, 11, 12], dtype='int64')
3222         assert np.all(f(vx, vy) == vx)
3223         z = theano.tensor.switch(0, x, y)
3224         f = theano.function([x, y], z, mode=self.mode)
3225         assert len([node.op for node in f.maker.fgraph.toposort() if
3226                     isinstance(node.op, theano.tensor.Elemwise)]) == 0
3227         vx = np.array([[1, 2, 3], [4, 5, 6]], dtype='int32')
3228         vy = np.array([10, 11, 12], dtype='int64')
3229         assert np.all(f(vx, vy) == vy)
3230     def test_broadcast2(self):
3231         x = theano.tensor.vector('x', dtype='int32')
3232         y = theano.tensor.matrix('y', dtype='int64')
3233         z = theano.tensor.switch(1, x, y)
3234         f = theano.function([x, y], z, mode=self.mode)
3235         assert len([node.op for node in f.maker.fgraph.toposort() if
3236                     isinstance(node.op, theano.tensor.Elemwise) and
3237                     not isinstance(node.op.scalar_op, theano.scalar.basic.Cast)]) == 0
3238         vx = np.array([4, 5, 6], dtype='int32')
3239         vy = np.array([[7, 8, 9], [10, 11, 12]], dtype='int64')
3240         assert np.all(f(vx, vy) == vx)
3241         z = theano.tensor.switch(0, x, y)
3242         f = theano.function([x, y], z, mode=self.mode)
3243         assert len([node.op for node in f.maker.fgraph.toposort() if
3244                     isinstance(node.op, theano.tensor.Elemwise)]) == 0
3245         vx = np.array([4, 5, 6], dtype='int32')
3246         vy = np.array([[7, 8, 9], [10, 11, 12]], dtype='int64')
3247         assert np.all(f(vx, vy) == vy)
3248     def test_broadcast3(self):
3249         x = theano.tensor.matrix('x', dtype='int32')
3250         y = theano.tensor.vector('y', dtype='int64')
3251         z = theano.tensor.switch(x, y, y)
3252         f = theano.function([x, y], z, mode=self.mode)
3253         vx = np.array([[0, 1], [1, 0]], dtype='int32')
3254         vy = np.array([7, 8], dtype='int64')
3255         utt.assert_allclose(f(vx, vy), np.where(vx, vy, vy))
3256         assert len([node.op for node in f.maker.fgraph.toposort() if
3257                     isinstance(node.op, theano.tensor.Elemwise)]) == 0
3258 class test_local_merge_switch_same_cond(unittest.TestCase):
3259     def test_elemwise(self):
3260         mats = theano.tensor.matrices('cabxy')
3261         c, a, b, x, y = mats
3262         s1 = T.switch(c, a, b)
3263         s2 = T.switch(c, x, y)
3264         for op in (T.add, T.sub, T.mul, T.true_div, T.int_div, T.floor_div,
3265                    T.minimum, T.maximum, T.gt, T.lt, T.ge, T.le, T.eq, T.neq,
3266                    T.pow):
3267             g = optimize(FunctionGraph(mats, [op(s1, s2)]))
3268             assert str(g).count('Switch') == 1
3269         mats = theano.tensor.imatrices('cabxy')
3270         c, a, b, x, y = mats
3271         s1 = T.switch(c, a, b)
3272         s2 = T.switch(c, x, y)
3273         for op in (T.and_, T.or_, T.xor,
3274                    T.bitwise_and, T.bitwise_or, T.bitwise_xor):
3275             g = optimize(FunctionGraph(mats, [op(s1, s2)]))
3276             assert str(g).count('Switch') == 1
3277         u, v = theano.tensor.matrices('uv')
3278         s3 = T.switch(c, u, v)
3279         for op in (T.add, T.mul):
3280             g = optimize(FunctionGraph(mats + [u, v], [op(s1, s2, s3)]))
3281             assert str(g).count('Switch') == 1
3282 class T_local_sum_prod(unittest.TestCase):
3283     def setUp(self):
3284         self.mode = theano.compile.get_default_mode().including('canonicalize',
3285                                                                 'specialize')
3286     def test_local_sum_prod_mul_by_scalar(self):
3287         vect = T.dvector()
3288         mat = T.dmatrix()
3289         scalar1 = T.dscalar()
3290         scalar2 = T.dscalar()
3291         v_val = np.random.rand(2)
3292         m_val = np.random.rand(2, 2)
3293         s1_val = np.random.rand()
3294         s2_val = np.random.rand()
3295         def test_reduction_opt(inputs, inputs_val, reduction_op,
3296                                expected_output, nb_expected_sum_nodes):
3297             mul_out = T.mul(*inputs)
3298             f = theano.function(inputs, reduction_op()(mul_out),
3299                                 mode=self.mode)
3300             out = f(*inputs_val)
3301             utt.assert_allclose(out, expected_output)
3302             prod_nodes = [n for n in f.maker.fgraph.toposort()
3303                           if isinstance(n.op, reduction_op)]
3304             assert len(prod_nodes) == nb_expected_sum_nodes
3305         test_reduction_opt([scalar1], [s1_val], T.Sum, s1_val, 0)
3306         test_reduction_opt([vect, scalar1], [v_val, s1_val], T.Sum,
3307                            s1_val * v_val.sum(), 1)
3308         test_reduction_opt([vect, mat, scalar1], [v_val, m_val, s1_val], T.Sum,
3309                            s1_val * (v_val * m_val).sum(), 1)
3310         test_reduction_opt([scalar1, scalar2], [s1_val, s2_val], T.Sum,
3311                            s1_val * s2_val, 0)
3312         test_reduction_opt([vect, scalar1, scalar2], [v_val, s1_val, s2_val],
3313                            T.Sum, s1_val * s2_val * v_val.sum(), 1)
3314         test_reduction_opt([vect, mat, scalar1, scalar2],
3315                            [v_val, m_val, s1_val, s2_val], T.Sum,
3316                            s1_val * s2_val * (v_val * m_val).sum(), 1)
3317         test_reduction_opt([scalar1], [s1_val], T.elemwise.Prod, s1_val, 0)
3318         test_reduction_opt([vect, scalar1], [v_val, s1_val], T.elemwise.Prod,
3319                            (s1_val * v_val).prod(), 1)
3320         test_reduction_opt([vect, mat, scalar1], [v_val, m_val, s1_val],
3321                            T.elemwise.Prod, (s1_val * v_val * m_val).prod(), 2)
3322         test_reduction_opt([scalar1, scalar2], [s1_val, s2_val],
3323                            T.elemwise.Prod, s1_val * s2_val, 0)
3324         test_reduction_opt([vect, scalar1, scalar2], [v_val, s1_val, s2_val],
3325                            T.elemwise.Prod, (s1_val * s2_val * v_val).prod(),
3326                            1)
3327         test_reduction_opt([vect, mat, scalar1, scalar2],
3328                            [v_val, m_val, s1_val, s2_val], T.elemwise.Prod,
3329                            (s1_val * s2_val * v_val * m_val).prod(), 2)
3330     def test_local_sum_prod_all_to_none(self):
3331         a = T.tensor3()
3332         input = np.arange(3 * 4 * 5, dtype=config.floatX).reshape(3, 4, 5)
3333         f = theano.function([a], a.sum(), mode=self.mode)
3334         assert len(f.maker.fgraph.apply_nodes) == 1
3335         utt.assert_allclose(f(input), input.sum())
3336         f = theano.function([a], a.prod(), mode=self.mode)
3337         assert len(f.maker.fgraph.apply_nodes) == 1
3338         utt.assert_allclose(f(input), input.prod())
3339         f = theano.function([a], a.sum([0, 1, 2]), mode=self.mode)
3340         assert len(f.maker.fgraph.apply_nodes) == 1
3341         utt.assert_allclose(f(input), input.sum())
3342         f = theano.function([a], a.prod([0, 1, 2]), mode=self.mode)
3343         assert len(f.maker.fgraph.apply_nodes) == 1
3344         utt.assert_allclose(f(input), input.prod())
3345         backup = config.warn.sum_sum_bug
3346         config.warn.sum_sum_bug = False
3347         try:
3348             f = theano.function([a], a.sum(0).sum(0).sum(0), mode=self.mode)
3349             assert len(f.maker.fgraph.apply_nodes) == 1
3350             utt.assert_allclose(f(input), input.sum())
3351         finally:
3352             config.warn.sum_sum_bug = backup
3353     def test_local_sum_sum_prod_prod(self):
3354         a = T.tensor3()
3355         input = np.arange(3 * 4 * 5, dtype=config.floatX).reshape(3, 4, 5)
3356         dims = [(0, 0), (1, 0), (2, 0), (0, 1), (1, 1), (2, 1),
3357                 ((0, 1), 0), ((1, 2), 0), (0, (0, 1)),
3358                 (1, (0, 1)), (2, (0, 1))]
3359         backup = config.warn.sum_sum_bug
3360         config.warn.sum_sum_bug = False
3361         def my_prod(data, d, dd):
3362             if not isinstance(d, tuple) and not isinstance(dd, tuple):
3363                 return data.prod(d).prod(dd)
3364             if isinstance(d, tuple):
3365                 d = sorted(d)
3366                 return data.prod(d[1]).prod(d[0]).prod(dd)
3367             else:
3368                 dd = sorted(dd)
3369                 return data.prod(d).prod(dd[1]).prod(dd[0])
3370         def my_sum(data, d, dd):
3371             if not isinstance(d, tuple) and not isinstance(dd, tuple):
3372                 return data.sum(d).sum(dd)
3373             if isinstance(d, tuple):
3374                 d = sorted(d)
3375                 return data.sum(d[1]).sum(d[0]).sum(dd)
3376             else:
3377                 dd = sorted(dd)
3378                 return data.sum(d).sum(dd[1]).sum(dd[0])
3379         def my_sum_prod(data, d, dd):
3380             if not isinstance(d, tuple) and not isinstance(dd, tuple):
3381                 return data.sum(d).prod(dd)
3382             if isinstance(d, tuple):
3383                 d = sorted(d)
3384                 return data.sum(d[1]).sum(d[0]).prod(dd)
3385             else:
3386                 dd = sorted(dd)
3387                 return data.sum(d).prod(dd[1]).prod(dd[0])
3388         try:
3389             for d, dd in dims:
3390                 expected = my_sum(input, d, dd)
3391                 f = theano.function([a], a.sum(d).sum(dd), mode=self.mode)
3392                 utt.assert_allclose(f(input), expected)
3393                 assert len(f.maker.fgraph.apply_nodes) == 1
3394             for d, dd in dims[:6]:
3395                 f = theano.function([a], a.sum(d).sum(dd).
3396                                     sum(0), mode=self.mode)
3397                 utt.assert_allclose(f(input), input.sum(d).sum(dd).sum(0))
3398                 assert len(f.maker.fgraph.apply_nodes) == 1
3399             for d in [0, 1, 2]:
3400                 f = theano.function([a], a.sum(d).sum(None), mode=self.mode)
3401                 utt.assert_allclose(f(input), input.sum(d).sum())
3402                 assert len(f.maker.fgraph.apply_nodes) == 1
3403             f = theano.function([a], a.sum(None).sum(), mode=self.mode)
3404             utt.assert_allclose(f(input), input.sum())
3405             assert len(f.maker.fgraph.apply_nodes) == 1
3406         finally:
3407             config.warn.sum_sum_bug = backup
3408         for d, dd in dims:
3409             expected = my_prod(input, d, dd)
3410             f = theano.function([a], a.prod(d).prod(dd), mode=self.mode)
3411             utt.assert_allclose(f(input), expected)
3412             assert len(f.maker.fgraph.apply_nodes) == 1
3413         for d, dd in dims[:6]:
3414             f = theano.function([a], a.prod(d).prod(dd).
3415                                 prod(0), mode=self.mode)
3416             utt.assert_allclose(f(input), input.prod(d).prod(dd).prod(0))
3417             assert len(f.maker.fgraph.apply_nodes) == 1
3418         for d in [0, 1, 2]:
3419             f = theano.function([a], a.prod(d).prod(None), mode=self.mode)
3420             utt.assert_allclose(f(input), input.prod(d).prod())
3421             assert len(f.maker.fgraph.apply_nodes) == 1
3422         f = theano.function([a], a.prod(None).prod(), mode=self.mode)
3423         utt.assert_allclose(f(input), input.prod())
3424         assert len(f.maker.fgraph.apply_nodes) == 1
3425         for d, dd in dims:
3426             expected = my_sum_prod(input, d, dd)
3427             f = theano.function([a], a.sum(d).prod(dd), mode=self.mode)
3428             utt.assert_allclose(f(input), expected)
3429             assert len(f.maker.fgraph.apply_nodes) == 2
3430         for d, dd in dims[:6]:
3431             f = theano.function([a], a.sum(d).prod(dd).
3432                                 prod(0), mode=self.mode)
3433             utt.assert_allclose(f(input), input.sum(d).prod(dd).prod(0))
3434             assert len(f.maker.fgraph.apply_nodes) == 2
3435         for d in [0, 1, 2]:
3436             f = theano.function([a], a.sum(d).prod(None), mode=self.mode)
3437             utt.assert_allclose(f(input), input.sum(d).prod())
3438             assert len(f.maker.fgraph.apply_nodes) == 2
3439         f = theano.function([a], a.sum(None).prod(), mode=self.mode)
3440         utt.assert_allclose(f(input), input.sum())
3441         assert len(f.maker.fgraph.apply_nodes) == 1
3442     def test_local_sum_prod_alloc(self):
3443         a = T.dtensor3()
3444         input = np.asarray(np.arange(2 * 3 * 4).reshape(2, 3, 4),
3445                            dtype='float64')
3446         mode = self.mode.including('specialize').excluding('fusion')
3447         for t_like, n_like, nb_nodes in [
3448                 (tensor.zeros_like, np.zeros_like, (1, 3, 3, 2)),
3449                 (tensor.ones_like, np.ones_like, (5, 5, 5, 6))]:
3450             f = theano.function([a], t_like(a).sum(None), mode=mode)
3451             utt.assert_allclose(f(input), n_like(input).sum())
3452             assert len(f.maker.fgraph.apply_nodes) == nb_nodes[0]
3453             f = theano.function([a], t_like(a).sum([0, 1, 2]), mode=mode)
3454             utt.assert_allclose(f(input), n_like(input).sum())
3455             assert len(f.maker.fgraph.apply_nodes) == nb_nodes[0]
3456             for d in xrange(3):
3457                 f = theano.function([a], t_like(a).sum(d), mode=mode)
3458                 utt.assert_allclose(f(input), n_like(input).sum(d))
3459                 assert len(f.maker.fgraph.apply_nodes) == nb_nodes[1]
3460                 topo = f.maker.fgraph.toposort()
3461                 assert topo[-1].op == T.alloc
3462                 assert not any([isinstance(node.op, T.Sum) for node in topo])
3463             for i in xrange(3):
3464                 f = theano.function([a], t_like(a).sum(i), mode=mode)
3465                 utt.assert_allclose(f(input), n_like(input).sum(i))
3466                 assert len(f.maker.fgraph.apply_nodes) == nb_nodes[2]
3467                 topo = f.maker.fgraph.toposort()
3468                 assert topo[-1].op == T.alloc
3469                 assert not any([isinstance(node.op, T.Sum) for node in topo])
3470             f = theano.function([a], t_like(a).prod(None), mode=mode)
3471             utt.assert_allclose(f(input), n_like(input).prod())
3472             f = theano.function([a], t_like(a).prod([0, 1, 2]), mode=mode)
3473             utt.assert_allclose(f(input), n_like(input).prod())
3474             for d in range(3):
3475                 f = theano.function([a], t_like(a).prod(d), mode=mode)
3476                 utt.assert_allclose(f(input), n_like(input).prod(d))
3477                 topo = f.maker.fgraph.toposort()
3478                 assert topo[-1].op == T.alloc
3479                 assert not any([isinstance(node.op, T.elemwise.Prod) for node in topo])
3480             for i in range(3):
3481                 f = theano.function([a], t_like(a).prod(i), mode=mode)
3482                 utt.assert_allclose(f(input), n_like(input).prod(i))
3483                 topo = f.maker.fgraph.toposort()
3484                 assert topo[-1].op == T.alloc
3485                 assert not any([isinstance(node.op, T.elemwise.Prod) for node in topo])
3486             backup = config.warn.sum_sum_bug
3487             config.warn.sum_sum_bug = False
3488             try:
3489                 for d, dd in [(0, 0), (1, 0), (2, 0), (0, 1), (1, 1), (2, 1)]:
3490                     f = theano.function([a], t_like(a).
3491                                         sum(d).sum(dd), mode=mode)
3492                     utt.assert_allclose(f(input),
3493                                         n_like(input).sum(d).sum(dd))
3494                     assert len(f.maker.fgraph.apply_nodes) == nb_nodes[3]
3495                     topo = f.maker.fgraph.toposort()
3496                     assert topo[-1].op == T.alloc
3497                     assert not any([isinstance(node.op,
3498                                                T.Sum) for node in topo])
3499             finally:
3500                 config.warn.sum_sum_bug = backup
3501     def test_local_sum_sum_int8(self):
3502         x = tensor.tensor3(dtype='int8')
3503         y = x.sum(axis=0).sum(axis=1)
3504         backup = config.on_opt_error
3505         config.on_opt_error = 'raise'
3506         try:
3507             theano.function([x], y)
3508         finally:
3509             config.on_opt_error = backup
3510     def test_local_sum_sum_dtype(self):
3511         x = tensor.tensor3(dtype='int8')
3512         y = x.sum(axis=0, dtype='int32').sum(axis=1, dtype='int64')
3513         backup = config.on_opt_error
3514         config.on_opt_error = 'raise'
3515         try:
3516             theano.function([x], y)
3517         finally:
3518             config.on_opt_error = backup
3519     def test_local_sum_prod_mul_by_scalar_stack_trace(self):
3520         m0 = theano.compile.get_default_mode()\
3521             .excluding('inplace_elemwise_opt')\
3522             .including('canonicalize', 'specialize')
3523         vect = T.dvector()
3524         mat = T.dmatrix()
3525         scalar = T.dscalar()
3526         f = theano.function([vect, scalar], T.sum(vect * scalar), mode=m0)
3527         assert check_stack_trace(f, ops_to_check='all')
3528         f = theano.function([vect], T.sum(-vect), mode=m0)
3529         assert check_stack_trace(f, ops_to_check=[T.Sum])
3530         f = theano.function([vect, scalar],
3531                             T.elemwise.Prod()(vect * scalar), mode=m0)
3532         assert check_stack_trace(f, ops_to_check=[T.elemwise.Prod])
3533         f = theano.function([vect], T.elemwise.Prod()(-vect), mode=m0)
3534         assert check_stack_trace(f, ops_to_check=[T.elemwise.Prod])
3535         f = theano.function([mat, scalar], T.sum(mat * scalar), mode=m0)
3536         assert check_stack_trace(f, ops_to_check='all')
3537         f = theano.function([mat], T.sum(-mat), mode=m0)
3538         assert check_stack_trace(f, ops_to_check=[T.Sum])
3539 class T_local_opt_alloc(unittest.TestCase):
3540     dtype = 'float32'
3541     def test_sum_upcast(self):
3542         s = theano.tensor.lscalar()
3543         a = theano.tensor.alloc(np.asarray(5, dtype=self.dtype), s, s)
3544         orig = theano.config.warn_float64
3545         theano.config.warn_float64 = "raise"
3546         try:
3547             f = theano.function([s], a.sum())
3548             f(5)
3549         finally:
3550             theano.config.warn_float64 = orig
3551     def test_prod_upcast(self):
3552         s = theano.tensor.lscalar()
3553         a = theano.tensor.alloc(np.asarray(5, dtype=self.dtype), s, s)
3554         orig = theano.config.warn_float64
3555         theano.config.warn_float64 = "raise"
3556         try:
3557             f = theano.function([s], a.prod())
3558             f(5)
3559         finally:
3560             theano.config.warn_float64 = orig
3561     @change_flags(on_opt_error='raise')
3562     def test_sum_bool_upcast(self):
3563         s = theano.tensor.lscalar()
3564         a = theano.tensor.alloc(np.asarray(True, dtype='bool'), s, s)
3565         f = theano.function([s], a.sum())
3566         f(5)
3567         f = theano.function([s], a.sum(dtype=self.dtype))
3568         f(5)
3569         f = theano.function([s], a.sum(axis=0, dtype=self.dtype))
3570         f(5)
3571         print(self.dtype)
3572 class T_local_opt_alloc_f16(T_local_opt_alloc):
3573     dtype = 'float16'
3574 class T_local_reduce(unittest.TestCase):
3575     def setUp(self):
3576         self.mode = theano.compile.get_default_mode().including(
3577             'canonicalize',
3578             'specialize',
3579             'uncanonicalize', 'local_max_and_argmax')
3580     def test_local_reduce_broadcast_all_0(self):
3581 <a name="12"></a>        for fct in [tensor.sum, tensor.all, tensor.any, tensor.prod,
3582                     tensor.max, tensor.min]:
3583             x = T.TensorType('int64', (True, True, True))()
3584             f = theano.function([x], [fct<font color="#571b7e"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>(x)], mode=self.mode)
3585             assert not any([
3586                 isinstance(node.op, T.CAReduce)
3587                 for node in f.maker.fgraph.</b></font>toposort()])
3588     def test_local_reduce_broadcast_all_1(self):
3589 <a name="15"></a>        for fct in [tensor.sum, tensor.all, tensor.any, tensor.prod,
3590                     tensor.max, tensor.min]:
3591             x = T.TensorType('int64', (True, True))()
3592             f = theano.function([x], [fct(x, axis=[<font color="#f52887"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>0, 1])], mode=self.mode)
3593             assert not any([
3594                 isinstance(node.op, T.CAReduce)
3595                 for node in f.maker.fgraph.</b></font>toposort()])
3596     def test_local_reduce_broadcast_some_0(self):
3597         for fct in [tensor.sum, tensor.all, tensor.any, tensor.prod,
3598                     tensor.max, tensor.min]:
3599             x = T.TensorType('int64', (True, False, True))()
3600             f = theano.function([x], [fct(x, axis=[0, 1])], mode=self.mode)
3601             order = f.maker.fgraph.toposort()
3602             assert 1 == sum([isinstance(node.op, T.CAReduce)
3603                              for node in order])
3604             node = [node for node in order if isinstance(node.op,
3605                                                          tensor.CAReduce)][0]
3606             op = node.op
3607             assert isinstance(op, T.CAReduce)
3608             assert node.inputs[0].ndim == 2, node
3609             assert op.axis == (0,), op.axis
3610     def test_local_reduce_broadcast_some_1(self):
3611 <a name="14"></a>        for fct in [tensor.sum, tensor.all, tensor.any, tensor.prod,
3612                     tensor.max, tensor.min]:
3613             x = T.TensorType('int64', (True, True, True))()
3614             f = theano.function([x], [fct(x, axis=[<font color="#842dce"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>0, 2])], mode=self.mode)
3615             assert not any([
3616                 isinstance(node.op, T.CAReduce)
3617                 for node in f.maker.fgraph.</b></font>toposort()])
3618     def test_local_reduce_join(self):
3619         vx = matrix()
3620         vy = matrix()
3621         vz = matrix()
3622         x = np.asarray([[1, 0], [3, 4]], dtype=config.floatX)
3623         y = np.asarray([[4, 0], [2, 1]], dtype=config.floatX)
3624         z = np.asarray([[5, 0], [1, 2]], dtype=config.floatX)
3625         for out, res in [
3626             (T.max((vx, vy), 0), np.max((x, y), 0)),
3627             (T.min((vx, vy), 0), np.min((x, y), 0)),
3628             (T.sum((vx, vy, vz), 0), np.sum((x, y, z), 0)),
3629             (T.prod((vx, vy, vz), 0), np.prod((x, y, z), 0)),
3630             (T.prod((vx, vy.T, vz), 0), np.prod((x, y.T, z), 0)),
3631         ]:
3632             f = theano.function([vx, vy, vz], out,
3633                                 on_unused_input='ignore', mode=self.mode)
3634             assert (f(x, y, z) == res).all(), out
3635             topo = f.maker.fgraph.toposort()
3636             assert len(topo) &lt;= 2, out
3637             assert isinstance(topo[-1].op, T.Elemwise), out
3638         A = theano.shared(np.array([1, 2, 3, 4, 5], dtype='int64'))
3639         f = theano.function([], T.sum(T.stack([A, A]), axis=0), mode=self.mode)
3640         utt.assert_allclose(f(), [2, 4, 6, 8, 10])
3641         topo = f.maker.fgraph.toposort()
3642         assert isinstance(topo[-1].op, T.Elemwise)
3643         try:
3644             old = theano.config.warn.reduce_join
3645             theano.config.warn.reduce_join = False
3646             f = theano.function([], T.sum(T.stack([A, A]), axis=1),
3647                                 mode=self.mode)
3648         finally:
3649             theano.config.warn.reduce_join = old
3650         utt.assert_allclose(f(), [15, 15])
3651         topo = f.maker.fgraph.toposort()
3652         assert not isinstance(topo[-1].op, T.Elemwise)
3653         A = theano.shared(np.array([1, 2, 3, 4, 5]).reshape(5, 1))
3654         f = theano.function([], T.sum(T.concatenate((A, A), axis=1), axis=1),
3655                             mode=self.mode)
3656         utt.assert_allclose(f(), [2, 4, 6, 8, 10])
3657         topo = f.maker.fgraph.toposort()
3658         assert not isinstance(topo[-1].op, T.Elemwise)
3659         A = theano.shared(np.array([1, 2, 3, 4, 5]).reshape(5, 1))
3660         f = theano.function([], T.sum(T.concatenate((A, A), axis=1), axis=0),
3661                             mode=self.mode)
3662         utt.assert_allclose(f(), [15, 15])
3663         topo = f.maker.fgraph.toposort()
3664         assert not isinstance(topo[-1].op, T.Elemwise)
3665         old = theano.config.warn.reduce_join
3666         try:
3667             theano.config.warn.reduce_join = False
3668             out = tensor.sum([vx, vy, vz], axis=None)
3669             f = theano.function([vx, vy, vz], out)
3670         finally:
3671             theano.config.warn.reduce_join = old
3672 class T_local_sum_prod_dimshuffle(unittest.TestCase):
3673     def setUp(self):
3674         self.mode = theano.compile.get_default_mode().including('canonicalize')
3675     def test_local_sum_div_dimshuffle(self):
3676         a = T.matrix('a')
3677         b = T.vector('b')
3678         c = T.tensor3('c')
3679         d = T.scalar('d')
3680         sum = tensor.sum
3681         sums = [
3682             sum(a / d),
3683             sum(a / d.dimshuffle('x', 'x')),
3684             sum(a / d.dimshuffle('x', 'x'), axis=0),
3685             sum(a / d.dimshuffle('x', 'x'), axis=1),
3686             sum(b / d),
3687             sum(b / d.dimshuffle('x')),
3688             sum(c / d),
3689             sum(c / d.dimshuffle('x', 'x', 'x')),
3690             sum(c / d.dimshuffle('x', 'x', 'x'), axis=0),
3691             sum(c / d.dimshuffle('x', 'x', 'x'), axis=1),
3692             sum(c / d.dimshuffle('x', 'x', 'x'), axis=2),
3693             sum(a / b, axis=0),
3694             sum(a / b.dimshuffle(0, 'x'), axis=1),
3695             sum(a.dimshuffle(0, 1) / b.dimshuffle(0, 'x'), axis=1),
3696             sum(a.dimshuffle(1, 0) / b.dimshuffle(0, 'x'), axis=1),
3697             sum(c / a, axis=0),
3698             sum(c / a.dimshuffle(1, 0), axis=0),
3699             sum(c / a.dimshuffle(0, 'x', 1), axis=1),
3700             sum(c / a.dimshuffle(1, 'x', 0), axis=1),
3701             sum(c / a.dimshuffle(0, 1, 'x'), axis=2),
3702             sum(c / a.dimshuffle(1, 0, 'x'), axis=2),
3703             sum(c / b, axis=0),
3704             sum(c / b, axis=1),
3705             sum(c / b, axis=(0, 1)),
3706             sum(c / b.dimshuffle(0, 'x'), axis=0),
3707             sum(c / b.dimshuffle(0, 'x'), axis=2),
3708             sum(c / b.dimshuffle(0, 'x'), axis=(0, 2)),
3709             sum(c / b.dimshuffle(0, 'x', 'x'), axis=1),
3710             sum(c / b.dimshuffle(0, 'x', 'x'), axis=2),
3711             sum(c / b.dimshuffle(0, 'x', 'x'), axis=(1, 2)),
3712             sum(sum(c, axis=0) / b, axis=0),
3713             sum(sum(c, axis=1) / b, axis=0),
3714             ]
3715         rng = np.random.RandomState(utt.fetch_seed())
3716         a_val = rng.randn(2, 2).astype(config.floatX)
3717         b_val = rng.randn(2).astype(config.floatX)
3718         c_val = rng.randn(2, 2, 2).astype(config.floatX)
3719         d_val = np.asarray(rng.randn(), config.floatX)
3720         backup = config.warn.sum_sum_bug, config.warn.sum_div_dimshuffle_bug
3721         config.warn.sum_sum_bug = False
3722         config.warn.sum_div_dimshuffle_bug = False
3723         try:
3724             for i, s in enumerate(sums):
3725                 print(i)
3726                 f = theano.function([a, b, c, d], s, mode=self.mode,
3727                                     on_unused_input='ignore')
3728                 g = f.maker.fgraph.toposort()
3729                 assert isinstance(g[-1].op.scalar_op,
3730                                   theano.scalar.basic.TrueDiv)
3731                 f(a_val, b_val, c_val, d_val)
3732         finally:
3733             config.warn.sum_sum_bug, config.warn.sum_div_dimshuffle_bug =\
3734                 backup
3735     def test_local_prod_div_dimshuffle(self):
3736         a = T.matrix('a')
3737         b = T.vector('b')
3738         c = T.tensor3('c')
3739         e = T.matrix('e')
3740         d = T.scalar('d')
3741         prod = T.prod
3742         prods = [
3743             prod(a / d),
3744             prod(a / d.dimshuffle('x', 'x')),
3745             prod(a / d.dimshuffle('x', 'x'), axis=0),
3746             prod(a / d.dimshuffle('x', 'x'), axis=1),
3747             prod(b / d),
3748             prod(b / d.dimshuffle('x')),
3749             prod(c / d),
3750             prod(c / d.dimshuffle('x', 'x', 'x')),
3751             prod(c / d.dimshuffle('x', 'x', 'x'), axis=0),
3752             prod(c / d.dimshuffle('x', 'x', 'x'), axis=1),
3753             prod(c / d.dimshuffle('x', 'x', 'x'), axis=2),
3754             prod(a / b, axis=0),
3755             prod(a / b.dimshuffle(0, 'x'), axis=1),
3756             prod(a.dimshuffle(0, 1) / b.dimshuffle(0, 'x'), axis=1),
3757             prod(a.dimshuffle(1, 0) / b.dimshuffle(0, 'x'), axis=1),
3758             prod(c / a, axis=0),
3759             prod(c / a.dimshuffle(1, 0), axis=0),
3760             prod(c / a.dimshuffle(0, 'x', 1), axis=1),
3761             prod(c / a.dimshuffle(1, 'x', 0), axis=1),
3762             prod(c / a.dimshuffle(0, 1, 'x'), axis=2),
3763             prod(c / a.dimshuffle(1, 0, 'x'), axis=2),
3764             prod(c / b, axis=0),
3765             prod(c / b, axis=1),
3766             prod(c / b, axis=(0, 1)),
3767             prod(c / b.dimshuffle(0, 'x'), axis=0),
3768             prod(c / b.dimshuffle(0, 'x'), axis=2),
3769             prod(c / b.dimshuffle(0, 'x'), axis=(0, 2)),
3770             prod(c / b.dimshuffle(0, 'x', 'x'), axis=1),
3771             prod(c / b.dimshuffle(0, 'x', 'x'), axis=2),
3772             prod(c / b.dimshuffle(0, 'x', 'x'), axis=(1, 2)),
3773             prod(c / b.dimshuffle(0, 'x', 'x'), axis=(0, 1)),
3774             prod(c / b.dimshuffle(0, 'x', 'x'), axis=(1, 0)),
3775             prod(prod(c, axis=0) / b, axis=0),
3776             prod(prod(c, axis=1) / b, axis=0)]
3777         rng = np.random.RandomState(utt.fetch_seed())
3778         a_val = rng.randn(2, 2).astype(config.floatX)
3779         b_val = rng.randn(2).astype(config.floatX)
3780         c_val = rng.randn(2, 2, 2).astype(config.floatX)
3781         d_val = np.asarray(rng.randn(), config.floatX)
3782         default_mode = theano.compile.mode.get_default_mode()
3783         mode_with_opt = default_mode.including('local_sum_prod_div_dimshuffle',
3784                                                'FusionOptimizer')
3785         mode_without_opt = default_mode.excluding('local_sum_prod_div_dimshuffle')
3786         for i, s in enumerate(prods):
3787             f = theano.function([a, b, c, d], s,
3788                                 on_unused_input='ignore',
3789                                 mode=mode_without_opt)
3790             g = theano.function([a, b, c, d], s,
3791                                 on_unused_input='ignore',
3792                                 mode=mode_with_opt)
3793             utt.assert_allclose(f(a_val, b_val, c_val, d_val),
3794                                 g(a_val, b_val, c_val, d_val))
3795         prods = [
3796             prod(a / e),
3797             prod(a / d),
3798             prod(a / d.dimshuffle('x', 'x')),
3799             prod(c / d.dimshuffle('x', 'x', 'x'), axis=1),
3800             prod(a.dimshuffle(1, 0) / b.dimshuffle(0, 'x'), axis=1),
3801             prod(c / b.dimshuffle(0, 'x', 'x'), axis=(1, 0)),
3802             prod(prod(c, axis=1) / b, axis=0),
3803             prod(prod(c, axis=(1, 2)) / b, axis=0)]
3804         expected_outer_operator = [theano.scalar.basic.Mul,
3805                                    theano.scalar.basic.Composite,
3806                                    theano.scalar.basic.Composite,
3807                                    theano.scalar.basic.TrueDiv,
3808                                    theano.scalar.basic.Composite,
3809                                    theano.scalar.basic.Mul,
3810                                    theano.scalar.basic.Composite,
3811                                    theano.scalar.basic.Mul]
3812         for i, s in enumerate(prods):
3813             g = theano.function([a, b, c, d, e], s,
3814                                 on_unused_input='ignore',
3815                                 mode=mode_with_opt)
3816             assert isinstance(g.maker.fgraph.toposort()[-1].op.scalar_op,
3817                               expected_outer_operator[i])
3818 class TestMakeVector(utt.InferShapeTester):
3819     def setUp(self):
3820         super(TestMakeVector, self).setUp()
3821     def test_make_vector(self):
3822         b = T.bscalar()
3823         i = T.iscalar()
3824         d = T.dscalar()
3825         val = {b: 2,
3826                i: -3,
3827                d: 0.7}
3828         for (dtype, inputs) in [("int8", (b, b)),
3829                                 ("int32", (i, b)),
3830                                 ("int32", (b, i)),
3831                                 ("float64", (b, i)),
3832                                 ("float64", (b, d)),
3833                                 ("float64", (d, i)),
3834                                 ("float64", ()),
3835                                 ("int64", ()),
3836                                 ]:
3837             mv = opt.MakeVector(dtype=dtype)(*inputs)
3838             assert mv.dtype == dtype
3839             f = theano.function([b, i, d], mv, on_unused_input='ignore')
3840             f(val[b], val[i], val[d])
3841             s = mv.sum()
3842             gb = T.grad(s, b, disconnected_inputs='ignore')
3843             gi = T.grad(s, i, disconnected_inputs='ignore')
3844             gd = T.grad(s, d, disconnected_inputs='ignore')
3845             g = theano.function([b, i, d], [gb, gi, gd])
3846             g_val = g(val[b], val[i], val[d])
3847             if dtype in tensor.int_dtypes:
3848                 utt.assert_allclose(g_val, 0)
3849             else:
3850                 for var, grval in zip((b, i, d), g_val):
3851                     float_inputs = []
3852                     if var.dtype in tensor.int_dtypes:
3853                         pass
3854                     elif var not in inputs:
3855                         assert grval == 0
3856                     else:
3857                         float_inputs.append(var)
3858                 if float_inputs:
3859                     def fun(*fl_inputs):
3860                         f_inputs = []
3861                         for var in f_inputs:
3862                             if var in fl_inputs:
3863                                 f_inputs.append(var)
3864                             else:
3865                                 f_inputs.append(val[var])
3866                         return opt.MakeVector(dtype=dtype)(*f_inputs)
3867                     utt.verify_grad(fun, [val[ri] for ri in float_inputs])
3868         for (dtype, inputs) in [("int8", (b, i)),
3869                                 ("int8", (i, b)),
3870                                 ("int8", (b, d)),
3871                                 ("int8", (i, i)),
3872                                 ("int32", (d, i)),
3873                                 ("int32", (i, d)),
3874                                 ("float32", (i, d)),
3875                                 ]:
3876             try:
3877                 opt.MakeVector(dtype=dtype)(*inputs)
3878                 raise Exception("Theano should have raised an error")
3879             except AssertionError:
3880                 pass
3881     def test_infer_shape(self):
3882         adscal = dscalar()
3883         bdscal = dscalar()
3884         aiscal = iscalar()
3885         biscal = iscalar()
3886         ciscal = iscalar()
3887         discal = iscalar()
3888         adscal_val = np.random.rand()
3889         bdscal_val = np.random.rand()
3890         aiscal_val = np.random.randint(10)
3891         biscal_val = np.random.randint(10)
3892         ciscal_val = np.random.randint(10)
3893         discal_val = np.random.randint(10)
3894         self._compile_and_check([adscal, aiscal],
3895                                 [MakeVector('float64')(adscal, aiscal)],
3896                                 [adscal_val, aiscal_val], MakeVector)
3897         self._compile_and_check([adscal, bdscal, aiscal],
3898                                 [MakeVector('float64')(adscal, bdscal, aiscal)],
3899                                 [adscal_val, bdscal_val, aiscal_val], MakeVector)
3900         self._compile_and_check([aiscal, biscal, ciscal, discal],
3901                                 [MakeVector('int32')(aiscal, biscal, ciscal, discal)],
3902                                 [aiscal_val, biscal_val, ciscal_val, discal_val],
3903                                 MakeVector)
3904 def test_local_join_1():
3905     a = tensor.vector('a')
3906     s = tensor.stack([a])
3907     f = function([a], s, mode=mode_opt)
3908     val = f([1])
3909     assert np.all(val == [1])
3910     e = f.maker.fgraph.toposort()
3911     assert len([n for n in e if isinstance(n.op, Join)]) == 0
3912     assert f.maker.fgraph.outputs[0].dtype == config.floatX
3913     a = tensor.matrix('a')
3914     s = join(0, a)
3915     f = function([a], s, mode=mode_opt)
3916     val = f([[1]])
3917     assert np.all(val == [[1]])
3918     e = f.maker.fgraph.toposort()
3919     assert len([n for n in e if isinstance(n.op, Join)]) == 0
3920     assert f.maker.fgraph.outputs[0].dtype == config.floatX
3921     s = join(1, a)
3922     f = function([a], s, mode=mode_opt)
3923     val = f([[1]])
3924     assert np.all(val == [[1]])
3925     e = f.maker.fgraph.toposort()
3926     assert len([n for n in e if isinstance(n.op, Join)]) == 0
3927     assert f.maker.fgraph.outputs[0].dtype == config.floatX
3928     s = join(1, a, a)
3929     f = function([a], s, mode=mode_opt)
3930     val = f([[1]])
3931     assert np.all(val == [[1]])
3932     e = f.maker.fgraph.toposort()
3933     assert len([n for n in e if isinstance(n.op, Join)]) == 1
3934     assert f.maker.fgraph.outputs[0].dtype == config.floatX
3935 def test_local_join_empty():
3936     empty_vec = np.asarray([], dtype=config.floatX)
3937     a = tensor.vector('a')
3938     s = tensor.join(0, a, a, empty_vec)
3939     f = function([a], s, mode=mode_opt)
3940     val = f([1])
3941     assert np.all(val == [1])
3942     e = f.maker.fgraph.toposort()
3943     assert len([n for n in e if isinstance(n.op, Join)]) == 1
3944     assert all([not isinstance(n.op, Join) or len(n.inputs) == 3
3945                 for n in e if isinstance(n.op, Join)])
3946     assert f.maker.fgraph.outputs[0].dtype == config.floatX
3947     empty_mat = np.asarray([[]], dtype=config.floatX)
3948     m = tensor.matrix('m')
3949     s = join(1, empty_mat, m, m, m)
3950     f = function([m], s, mode=mode_opt)
3951     val = f([[1]])
3952     assert np.all(val == [[1]])
3953     e = f.maker.fgraph.toposort()
3954     assert len([n for n in e if isinstance(n.op, Join)]) == 1
3955     assert all([not isinstance(n.op, Join) or len(n.inputs) == 4
3956                 for n in e if isinstance(n.op, Join)])
3957     assert f.maker.fgraph.outputs[0].dtype == config.floatX
3958     s = tensor.stack([a, a, empty_vec])
3959     f = function([a], s, mode=mode_opt)
3960     val = f([])
3961     assert np.all(val == [1])
3962     e = f.maker.fgraph.toposort()
3963     assert len([n for n in e if isinstance(n.op, Join)]) == 1
3964     assert all([not isinstance(n.op, Join) or len(n.inputs) == 4
3965                 for n in e if isinstance(n.op, Join)])
3966     assert f.maker.fgraph.outputs[0].dtype == config.floatX
3967     s = join(0, m, np.asarray([[2.]], dtype=config.floatX), m)
3968     f = function([m], s, mode=mode_opt)
3969     val = f([[1]])
3970     assert np.all(val == [[1], [2], [1]])
3971     e = f.maker.fgraph.toposort()
3972     assert len([n for n in e if isinstance(n.op, Join)]) == 1
3973     assert all([not isinstance(n.op, Join) or len(n.inputs) == 4
3974                 for n in e if isinstance(n.op, Join)])
3975     assert f.maker.fgraph.outputs[0].dtype == config.floatX
3976 def test_local_join_make_vector():
3977     a, b, c, d, e = tensor.scalars('abcde')
3978     v = tensor.vector('v')
3979     mv = MakeVector(config.floatX)
3980     s = tensor.join(0, mv(a), v, mv(b, c), mv(d, e))
3981     f = function([a, b, c, d, e, v], s, mode=mode_opt)
3982     theano.printing.debugprint(f)
3983     val = f(1, 2, 3, 4, 6, [7, 8])
3984     assert np.all(val == [1, 7, 8, 2, 3, 4, 6])
3985     e = f.maker.fgraph.toposort()
3986     assert len([n for n in e if isinstance(n.op, Join)]) == 1
3987     assert all([not isinstance(n.op, Join) or len(n.inputs) == 4
3988                 for n in e if isinstance(n.op, Join)])
3989     assert f.maker.fgraph.outputs[0].dtype == config.floatX
3990     assert check_stack_trace(f, ops_to_check='all')
3991 def test_local_add_specialize():
3992     a = tensor.vector()
3993     s = tensor.add(tensor.zeros_like(a))
3994     assert local_add_specialize.transform(s.owner)
3995     a = tensor.scalar()
3996     s = tensor.add(tensor.zeros_like(a))
3997     assert local_add_specialize.transform(s.owner)
3998     a = tensor.constant(0, dtype='int64')
3999     b = tensor.constant(1, dtype='int32')
4000     s = a + b
4001     transformed = local_add_specialize.transform(s.owner)
4002     assert transformed
4003     assert transformed[0].type == s.type
4004 def test_local_tensor_scalar_tensor():
4005     dtypes = ['int8', 'int16', 'int32', 'int64',
4006               'uint8', 'uint16', 'uint32', 'uint64',
4007               'float32', 'float64',
4008               'complex64', 'complex128'
4009               ]
4010     for dtype in dtypes:
4011         t_type = TensorType(dtype=dtype, broadcastable=())
4012         t = t_type()
4013         s = tensor.scalar_from_tensor(t)
4014         t2 = tensor.tensor_from_scalar(s)
4015         f = function([t], t2, mode=mode_opt)
4016         e = f.maker.fgraph.toposort()
4017         cast_nodes = [n for n in e
4018                       if isinstance(n.op, (tensor.TensorFromScalar,
4019                                            tensor.ScalarFromTensor))]
4020         assert len(cast_nodes) == 0
4021         f(0)
4022 def test_local_scalar_tensor_scalar():
4023     dtypes = ['int8', 'int16', 'int32', 'int64',
4024               'uint8', 'uint16', 'uint32', 'uint64',
4025               'float32', 'float64',
4026               'complex64', 'complex128'
4027               ]
4028     for dtype in dtypes:
4029         s_type = theano.scalar.Scalar(dtype=dtype)
4030         s = s_type()
4031         t = tensor.tensor_from_scalar(s)
4032         s2 = tensor.scalar_from_tensor(t)
4033         f = function([s], s2, mode=mode_opt)
4034         e = f.maker.fgraph.toposort()
4035         cast_nodes = [n for n in e
4036                       if isinstance(n.op, (tensor.TensorFromScalar,
4037                                            tensor.ScalarFromTensor))]
4038         assert len(cast_nodes) == 0
4039         f(0)
4040 def test_local_div_to_inv():
4041     num_len_s = tensor.lscalar('num_len')
4042     denom_s = tensor.scalar('denom')
4043     num_v = tensor.alloc(1, num_len_s)
4044     denom_m = denom_s.dimshuffle('x', 'x')
4045     out = num_v / denom_m
4046     assert np.all(out.broadcastable == (True, False))
4047     f = theano.function([num_len_s, denom_s], out)
4048     out_val = f(3, 2.)
4049     assert out_val.shape == (1, 3)
4050     utt.assert_allclose(out_val, 0.5)
4051 def test_local_useless_split():
4052     x = tensor.matrix('x')
4053     splits = tensor.ivector('splits')
4054     opt = tensor.split(x, splits, n_splits=1)
4055     nonopt = tensor.split(x, splits, n_splits=3)
4056     mode = compile.get_default_mode().including("local_useless_split")
4057     f_opt = theano.function([x, splits], opt, mode=mode)
4058     f_nonopt = theano.function([x, splits], nonopt, mode=mode)
4059     f_opt(np.random.rand(4, 4).astype(config.floatX), [4])
4060     f_nonopt(np.random.rand(4, 4).astype(config.floatX), [1, 2, 1])
4061     graph_opt = f_opt.maker.fgraph.toposort()
4062     graph_nonopt = f_nonopt.maker.fgraph.toposort()
4063     assert isinstance(graph_opt[-1].op, DeepCopyOp)
4064     assert len(graph_nonopt) == 1
4065     assert isinstance(graph_nonopt[0].op, tensor.Split)
4066     assert check_stack_trace(f_opt, ops_to_check=[Assert])
4067     assert check_stack_trace(f_nonopt, ops_to_check='all')
4068 def test_local_flatten_lift():
4069     for i in xrange(1, 4):
4070         x = tensor.tensor4()
4071         out = tensor.flatten(T.exp(x), i)
4072         assert out.ndim == i
4073         mode = compile.mode.get_default_mode()
4074         mode = mode.including('local_reshape_lift')
4075         f = theano.function([x], out, mode=mode)
4076         x_np = np.random.rand(5, 4, 3, 2).astype(config.floatX)
4077         out_np = f(x_np)
4078         topo = f.maker.fgraph.toposort()
4079         shape_out_np = tuple(x_np.shape[:i - 1]) + (np.prod(x_np.shape[i - 1:]),)
4080         assert shape_out_np == out_np.shape
4081         reshape_nodes = [n for n in topo if isinstance(n.op, tensor.Reshape)]
4082         assert (len(reshape_nodes) == 1 and
4083                 tensor.is_flat(reshape_nodes[0].outputs[0], ndim=i))
4084         assert isinstance(topo[-1].op, tensor.Elemwise)
4085 class Test_Reshape(unittest.TestCase):
4086     def setUp(self):
4087         self.mode = mode_opt
4088         self.op = tensor.Reshape
4089     def test_local_reshape(self):
4090         a = tensor.fmatrix()
4091         b = self.op(3)(a, [2, 3, 4])
4092         c = self.op(1)(b, [24])
4093         f = theano.function([a], c, mode=self.mode)
4094         topo = f.maker.fgraph.toposort()
4095         assert sum(isinstance(node.op, self.op) for node in topo) == 1
4096         self.assertTrue(check_stack_trace(f, ops_to_check=[self.op]))
4097 <a name="19"></a>
4098 class Test_local_useless_reshape(unittest.TestCase):
4099     def setUp(self):
4100         self.rng = np.random<font color="#f62817"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.RandomState(utt.fetch_seed())
4101     def test_0(self):
4102         mode = theano.compile.get_default_mode().including(</b></font>
4103             'local_useless_reshape')
4104         i = T.iscalar('i')
4105         m = theano.tensor.mgrid[0:i, ]
4106         f = theano.function([i], m, mode=mode)
4107         topo = f.maker.fgraph.toposort()
4108         assert not any(isinstance(n.op, tensor.basic.Reshape) for n in topo)
4109     def test_1(self):
4110         x = theano.tensor.matrix('x')
4111         r = x.reshape(x.shape)
4112         m0 = theano.compile.get_default_mode()
4113         m1 = m0.including('local_useless_reshape')
4114         f1 = theano.function([x], r, mode=m1)
4115         topo = f1.maker.fgraph.toposort()
4116         assert not any(isinstance(n.op, tensor.basic.Reshape) for n in topo)
4117         m2 = m1.excluding('ShapeOpt')
4118         f2 = theano.function([x], r, mode=m2)
4119         topo = f2.maker.fgraph.toposort()
4120         assert not any(isinstance(n.op, tensor.basic.Reshape) for n in topo)
4121     def test_2(self):
4122         x = theano.tensor.matrix('x')
4123         r = x.reshape([Shape_i(i)(x) for i in xrange(x.ndim)])
4124         m0 = theano.compile.get_default_mode()
4125         m1 = m0.including('local_useless_reshape')
4126         f1 = theano.function([x], r, mode=m1)
4127         topo = f1.maker.fgraph.toposort()
4128         assert not any(isinstance(n.op, tensor.basic.Reshape) for n in topo)
4129         m2 = m1.excluding('ShapeOpt')
4130         f2 = theano.function([x], r, mode=m2)
4131         topo = f2.maker.fgraph.toposort()
4132         assert not any(isinstance(n.op, tensor.basic.Reshape) for n in topo)
4133     def test_m1(self):
4134             x = theano.tensor.matrix('x')
4135             r = x.reshape((x.shape[0], -1))
4136             m0 = theano.compile.get_default_mode()
4137             m1 = m0.including('local_useless_reshape')
4138             f1 = theano.function([x], r, mode=m1)
4139             topo = f1.maker.fgraph.toposort()
4140             assert not any(isinstance(n.op, tensor.basic.Reshape) for n in topo)
4141             m2 = m1.excluding('ShapeOpt')
4142             f2 = theano.function([x], r, mode=m2)
4143             topo = f2.maker.fgraph.toposort()
4144             assert not any(isinstance(n.op, tensor.basic.Reshape) for n in topo)
4145 class Test_local_reshape_to_dimshuffle(unittest.TestCase):
4146     def setUp(self):
4147         self.rng = np.random.RandomState(utt.fetch_seed())
4148     def test_1(self):
4149         reshape_lift = out2in(local_reshape_to_dimshuffle)
4150         useless_reshape = out2in(local_useless_reshape)
4151         x = shared(self.rng.randn(4,))
4152         y = shared(self.rng.randn(5, 6))
4153         reshape_x = tensor.reshape(x, (1, 4))
4154         reshape_y = tensor.reshape(y, (1, 5, 1, 6, 1, 1))
4155         g = FunctionGraph([x, y], [reshape_x, reshape_y])
4156         self.assertTrue(str(g) == ("[Reshape{2}"
4157                                    "(&lt;TensorType(float64, vector)&gt;, "
4158                                    "TensorConstant{[1 4]}), "
4159                                    "Reshape{6}"
4160                                    "(&lt;TensorType(float64, matrix)&gt;, "
4161                                    "TensorConstant{[1 5 1 6 1 1]})]"))
4162         reshape_lift.optimize(g)
4163         useless_reshape.optimize(g)
4164         self.assertTrue(str(g) == "[InplaceDimShuffle{x,0}"
4165                                   "(&lt;TensorType(float64, vector)&gt;), "
4166                                   "InplaceDimShuffle{x,0,x,1,x,x}"
4167                                   "(Reshape{2}(&lt;TensorType(float64, matrix)&gt;, "
4168                                   "TensorConstant{[5 6]}))]")
4169         assert check_stack_trace(g, ops_to_check=(T.DimShuffle, T.Reshape))
4170 def test_local_reshape_lift():
4171     x = tensor.tensor4()
4172     out = T.exp(x).reshape([x.size])
4173     assert out.ndim == 1
4174     mode = compile.mode.get_default_mode()
4175     mode = mode.including('local_reshape_lift')
4176     f = theano.function([x], out, mode=mode)
4177     f(np.random.rand(5, 4, 3, 2).astype(config.floatX))
4178     topo = f.maker.fgraph.toposort()
4179     assert isinstance(topo[-2].op, tensor.Reshape)
4180     assert isinstance(topo[-1].op, tensor.Elemwise)
4181     assert check_stack_trace(f, ops_to_check='last')
4182 class Test_lift_transpose_through_dot(unittest.TestCase):
4183     def simple_optimize(self, g):
4184         out2in(opt.local_useless_elemwise).optimize(g)
4185         out2in(opt.local_lift_transpose_through_dot).optimize(g)
4186         out2in(opt.local_useless_elemwise).optimize(g)
4187         return g
4188     def test_matrix_matrix(self):
4189         a, b = matrices('ab')
4190         g = self.simple_optimize(FunctionGraph([a, b], [tensor.dot(a, b).T]))
4191         sg = '[dot(InplaceDimShuffle{1,0}(b), InplaceDimShuffle{1,0}(a))]'
4192         assert str(g) == sg, (str(g), sg)
4193         self.assertTrue(check_stack_trace(g, ops_to_check='all'))
4194     def test_row_matrix(self):
4195         a = vector('a')
4196         b = matrix('b')
4197         g = optimize(FunctionGraph(
4198             [a, b],
4199             [tensor.dot(a.dimshuffle('x', 0), b).T]),
4200             level='stabilize')
4201         sg = '[dot(InplaceDimShuffle{1,0}(b), InplaceDimShuffle{0,x}(a))]'
4202         assert str(g) == sg, (str(g), sg)
4203         self.assertTrue(check_stack_trace(g, ops_to_check='all'))
4204     def test_matrix_col(self):
4205         a = vector('a')
4206         b = matrix('b')
4207         g = optimize(FunctionGraph(
4208             [a, b],
4209             [tensor.dot(b, a.dimshuffle(0, 'x')).T]),
4210             level='stabilize')
4211         sg = '[dot(InplaceDimShuffle{x,0}(a), InplaceDimShuffle{1,0}(b))]'
4212         assert str(g) == sg, (str(g), sg)
4213         self.assertTrue(check_stack_trace(g, ops_to_check='all'))
4214 def test_local_upcast_elemwise_constant_inputs():
4215     s = dvector("s")
4216     x = tensor.sum(tensor.log(10 ** s))
4217     f = function([s], [tensor.grad(x, s)])
4218     f([-42, -2.1, -1, -0.5, 0, 0.2, 1, 2, 12])
4219     old = theano.config.floatX
4220     theano.config.floatX = 'float32'
4221     try:
4222         v = lvector()
4223         function([v], theano.tensor.basic.true_div(v, 2))
4224     finally:
4225         theano.config.floatX = old
4226 class TestShape_i(utt.InferShapeTester):
4227     def setUp(self):
4228         super(TestShape_i, self).setUp()
4229     def test_perform(self):
4230         advec = vector()
4231         advec_val = np.random.rand(3).astype(config.floatX)
4232         f = function([advec], Shape_i(0)(advec))
4233         out = f(advec_val)
4234         utt.assert_allclose(out, advec_val.shape[0])
4235         admat = matrix()
4236         admat_val = np.random.rand(4, 3).astype(config.floatX)
4237         for i in xrange(2):
4238             f = function([admat], Shape_i(i)(admat))
4239             out = f(admat_val)
4240             utt.assert_allclose(out, admat_val.shape[i])
4241     def test_infer_shape(self):
4242         admat = matrix()
4243         admat_val = np.random.rand(3, 4).astype(config.floatX)
4244         self._compile_and_check([admat], [Shape_i(0)(admat)],
4245                                 [admat_val], Shape_i)
4246         self._compile_and_check([admat], [Shape_i(1)(admat)],
4247                                 [admat_val], Shape_i)
4248 class TestShapeFeature(unittest.TestCase):
4249     def test_scalar(self):
4250         x = scalar()
4251         cst = T.constant(1).clone()
4252         o = x + cst
4253         fgraph = FunctionGraph([x], [o], clone=False)
4254         shape_feature = opt.ShapeFeature()
4255         fgraph.attach_feature(shape_feature)
4256         assert shape_feature.same_shape(x, o)
4257     def test_vector(self):
4258         x = vector()
4259         cst = T.constant(1).clone()
4260         o = x + cst
4261         fgraph = FunctionGraph([x], [o], clone=False)
4262         shape_feature = opt.ShapeFeature()
4263         fgraph.attach_feature(shape_feature)
4264         assert shape_feature.same_shape(x, o)
4265     def test_vector2(self):
4266         x = vector()
4267         y = vector()
4268         o = x + y
4269         fgraph = FunctionGraph([x, y], [o], clone=False)
4270         shape_feature = opt.ShapeFeature()
4271         fgraph.attach_feature(shape_feature)
4272         assert shape_feature.same_shape(x, o)
4273         assert not shape_feature.same_shape(y, o)
4274     def test_vector_dim(self):
4275         x = vector()
4276         y = vector()
4277         o = x + y
4278         fgraph = FunctionGraph([x, y], [o], clone=False)
4279         shape_feature = opt.ShapeFeature()
4280         fgraph.attach_feature(shape_feature)
4281         assert shape_feature.same_shape(x, o, 0, 0)
4282         assert not shape_feature.same_shape(y, o, 0, 0)
4283     def test_vector_dim_err(self):
4284         x = vector()
4285         y = vector()
4286         o = x + y
4287         fgraph = FunctionGraph([x, y], [o], clone=False)
4288         shape_feature = opt.ShapeFeature()
4289         fgraph.attach_feature(shape_feature)
4290         self.assertRaises(IndexError, shape_feature.same_shape, x, o, 1, 0)
4291         self.assertRaises(IndexError, shape_feature.same_shape, x, o, 0, 1)
4292 def test_assert_op_gradient():
4293     x = T.vector('x')
4294     assert_op = Assert()
4295     cost = T.sum(assert_op(x, x.size &lt; 2))
4296     grad = T.grad(cost, x)
4297     func = theano.function([x], grad)
4298     x_val = np.ones(shape=(1,), dtype=theano.config.floatX)
4299     assert func(x_val) == 1
4300 <a name="10"></a>class TestIntDivByOne(unittest.TestCase):
4301     def setUp(self):
4302         self.mode = theano.compile<font color="#ad5910"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.mode.get_default_mode()
4303         self.mode = self.mode.including('local_intdiv_by_one')
4304     def test1(self):
4305         y = T.tensor4(</b></font>'y')
4306         self.mode = self.mode.excluding('fusion')
4307         f = theano.function([y], y[::-1][::-1], mode=self.mode)
4308         graph = f.maker.fgraph.toposort()
4309         divs = [node for node in graph
4310                 if isinstance(node.op, T.elemwise.Elemwise) and
4311                 isinstance(node.op.scalar_op, theano.scalar.IntDiv)]
4312         assert len(divs) == 0
4313     def test2(self):
4314         y = T.tensor4('y')
4315         z = y // 1
4316         f = theano.function([y], z, mode=self.mode)
4317         graph = f.maker.fgraph.toposort()
4318         divs = [node for node in graph
4319                 if isinstance(node.op, T.elemwise.Elemwise) and
4320                 isinstance(node.op.scalar_op, theano.scalar.IntDiv)]
4321         assert len(divs) == 0
4322     def test3(self):
4323         y = T.tensor4('y')
4324         z = y // np.ones((2, 2, 2, 2))
4325         f = theano.function([y], z, mode=self.mode)
4326         graph = f.maker.fgraph.toposort()
4327         divs = [node for node in graph
4328                 if isinstance(node.op, T.elemwise.Elemwise) and
4329                 isinstance(node.op.scalar_op, theano.scalar.IntDiv)]
4330         assert len(divs) == 0
4331 def test_local_zero_div():
4332     for t in (T.scalar, T.ivector, T.ftensor4):
4333         x = t('x')
4334         for op in (T.int_div, T.true_div):
4335             y = op(0, x)
4336             g = optimize(FunctionGraph([x], [y]))
4337             divs = [node for node in g.toposort()
4338                     if isinstance(node.op, T.elemwise.Elemwise) and
4339                     isinstance(node.op.scalar_op, type(op.scalar_op))]
4340             assert len(divs) == 0
4341             output = g.outputs[0]
4342             assert output.ndim == y.ndim
4343             assert output.type == y.type
4344             assert theano.tensor.get_scalar_constant_value(output) == 0
4345 def test_local_sumsqr2dot():
4346     G = matrix('G')
4347     W = matrix('W')
4348     y = T.sqr(W.dimshuffle('x', 0, 1) * G.dimshuffle(0, 'x', 1)).sum(axis=(1, 2))
4349     MODE = theano.compile.get_default_mode().including('local_sumsqr2dot')
4350     f = function([W, G], y, mode=MODE)
4351     w_val = np.random.rand(4, 3).astype(config.floatX)
4352     g_val = np.random.rand(5, 3).astype(config.floatX)
4353     f_val = f(w_val, g_val)
4354     f_test = np.dot(np.square(g_val), np.square(w_val).sum(axis=0))
4355     utt.assert_allclose(f_val, f_test)
4356     assert any(isinstance(n.op, (tensor.basic.Dot, tensor.blas.Dot22,
4357                                  tensor.blas.Gemv, tensor.blas_c.CGemv))
4358                for n in f.maker.fgraph.toposort())
4359 def test_local_expm1():
4360     x = matrix('x')
4361     u = T.scalar('u')
4362     y = T.exp(x) - 1.
4363     z = T.exp(x) - 2.
4364     t = T.exp(x) - x
4365     s = T.exp(u) - np.ones((4, 3)).astype(config.floatX)
4366     MODE = theano.compile.get_default_mode().including('local_expm1')
4367     f = function([x], y, mode=MODE)
4368     g = function([x], z, mode=MODE)
4369     h = function([x], t, mode=MODE)
4370     r = function([u], s, mode=MODE)
4371     x_val = np.random.rand(4, 3).astype(config.floatX)
4372     f_val = f(x_val)
4373     f_test = function([x], T.expm1(x), mode=MODE)
4374     utt.assert_allclose(f_val, f_test(x_val))
4375     assert any(isinstance(n.op, T.Elemwise) and isinstance(n.op.scalar_op, theano.scalar.basic.Expm1)
4376                for n in f.maker.fgraph.toposort())
4377     assert not any(isinstance(n.op, T.Elemwise) and isinstance(n.op.scalar_op, theano.scalar.basic.Expm1)
4378                    for n in g.maker.fgraph.toposort())
4379     assert not any(isinstance(n.op, T.Elemwise) and isinstance(n.op.scalar_op, theano.scalar.basic.Expm1)
4380                    for n in h.maker.fgraph.toposort())
4381     assert not any(isinstance(n.op, T.Elemwise) and isinstance(n.op.scalar_op, theano.scalar.basic.Expm1)
4382                    for n in r.maker.fgraph.toposort())
4383 def test_local_merge_alloc():
4384     default_mode = theano.compile.mode.get_default_mode()
4385     opt_mode = default_mode.including("local_merge_alloc")
4386     x = T.iscalar('x')
4387     y = T.iscalar('y')
4388     y2 = T.iscalar('y2')
4389     z = T.iscalar('z')
4390     w = T.iscalar('w')
4391     m = T.fscalar('m')
4392     output = T.alloc(T.alloc(m, 1, y, 1, 1), x, y, z, w)
4393     f = theano.function([m, x, y, z, w], output, mode=opt_mode)
4394     topo = f.maker.fgraph.toposort()
4395     assert len(topo) == 1
4396     assert isinstance(topo[0].op, T.Alloc)
4397     o = f(0., 1, 2, 3, 4)
4398     assert o.shape == (1, 2, 3, 4)
4399     output = T.alloc(T.alloc(m, y, 1, 1), x, y, z, w)
4400     f = theano.function([m, x, y, z, w], output, mode=opt_mode)
4401     topo = f.maker.fgraph.toposort()
4402     assert len(topo) == 1
4403     assert isinstance(topo[0].op, T.Alloc)
4404     o = f(0., 1, 2, 3, 4)
4405     assert o.shape == (1, 2, 3, 4)
4406     output = T.alloc(T.alloc(m, y, 1, 1), x, y2, z, w)
4407     f = theano.function([m, x, y, y2, z, w], output, mode=opt_mode)
4408     topo = f.maker.fgraph.toposort()
4409     assert len(topo) == 3
4410     assert isinstance(topo[-2].op, T.opt.Assert)
4411     assert isinstance(topo[-1].op, T.Alloc)
4412     o = f(0., 1, 2, 2, 3, 4)
4413     assert o.shape == (1, 2, 3, 4)
4414     assert_raises((AssertionError, ValueError), f, 0., 1, 2, 5, 3, 4)
4415 def test_local_useless_alloc():
4416     useless_alloc = out2in(local_useless_alloc)
4417     merge_alloc = out2in(local_merge_alloc)
4418     x = T.iscalar('x')
4419     y = T.iscalar('y')
4420     y2 = T.iscalar('y2')
4421     z = T.iscalar('z')
4422     w = T.iscalar('w')
4423     m = T.fscalar('m')
4424     output = T.alloc(T.alloc(m, 1, y, 1, 1), x, y, z, w)
4425     g = FunctionGraph([m, x, y, z, w], [output])
4426     useless_alloc.optimize(g)
4427     merge_alloc.optimize(g)
4428     useless_alloc.optimize(g)
4429     topo = g.toposort()
4430     assert len(topo) == 1
4431     assert isinstance(topo[0].op, T.Alloc)
4432     output = T.alloc(T.alloc(m, y, 1, 1), x, y, z, w)
4433     g = FunctionGraph([m, x, y, z, w], [output])
4434     useless_alloc.optimize(g)
4435     merge_alloc.optimize(g)
4436     useless_alloc.optimize(g)
4437     topo = g.toposort()
4438     assert len(topo) == 1
4439     assert isinstance(topo[0].op, T.Alloc)
4440     output = T.alloc(T.alloc(m, y, 1, 1), x, y2, z, w)
4441     g = FunctionGraph([m, x, y, y2, z, w], [output])
4442     useless_alloc.optimize(g)
4443     merge_alloc.optimize(g)
4444     useless_alloc.optimize(g)
4445     topo = g.toposort()
4446     assert len(topo) == 3
4447     assert isinstance(topo[-2].op, T.opt.Assert)
4448     assert isinstance(topo[-1].op, T.Alloc)
4449 def compile_graph_log_sum_exp(x, axis, dimshuffle_op=None):
4450     sum_exp = T.sum(T.exp(x), axis=axis)
4451     if dimshuffle_op:
4452         sum_exp = dimshuffle_op(sum_exp)
4453     y = T.log(sum_exp)
4454     MODE = theano.compile.get_default_mode().including('local_log_sum_exp')
4455     return function([x], y, mode=MODE)
4456 def check_max_log_sum_exp(x, axis, dimshuffle_op=None):
4457     f = compile_graph_log_sum_exp(x, axis, dimshuffle_op)
4458     fgraph = f.maker.fgraph.toposort()
4459     for node in fgraph:
4460         if (hasattr(node.op, 'scalar_op') and
4461                 node.op.scalar_op == theano.scalar.basic.maximum):
4462             return
4463         if isinstance(node.op, theano.tensor.MaxAndArgmax):
4464             return
4465     raise Exception('No maximum detected after log_sum_exp optimisation')
4466 def test_local_log_sum_exp1():
4467     x = tensor3('x')
4468     check_max_log_sum_exp(x, axis=(0,), dimshuffle_op=None)
4469     check_max_log_sum_exp(x, axis=(1,), dimshuffle_op=None)
4470     check_max_log_sum_exp(x, axis=(2,), dimshuffle_op=None)
4471     check_max_log_sum_exp(x, axis=(0, 1), dimshuffle_op=None)
4472 <a name="6"></a>    check_max_log_sum_exp(x, axis=(0, 1, 2), dimshuffle_op=None)
4473     transpose_op = DimShuffle((<font color="#8c8774"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>False, False), (1, 0))
4474     check_max_log_sum_exp(x, axis=2, dimshuffle_op=transpose_op)
4475     x = TensorType(dtype='floatX', broadcastable=(False, True, False))('x')
4476     sum_keepdims_op = x.</b></font>sum(axis=(0, 1), keepdims=True).owner.op
4477     check_max_log_sum_exp(x, axis=(0, 1), dimshuffle_op=sum_keepdims_op)
4478 def test_local_log_sum_exp2():
4479     x = tensor3('x')
4480     x_val = 1.0 + np.random.rand(4, 3, 2).astype(config.floatX) / 10.0
4481     f = compile_graph_log_sum_exp(x, axis=(1,))
4482     naive_ret = np.log(np.sum(np.exp(x_val), axis=1))
4483     optimised_ret = f(x_val)
4484     assert np.allclose(naive_ret, optimised_ret)
4485     transpose_op = DimShuffle((False, False), (1, 0))
4486     f = compile_graph_log_sum_exp(x, axis=(1,), dimshuffle_op=transpose_op)
4487     naive_ret = np.log(np.sum(np.exp(x_val), axis=1).T)
4488     optimised_ret = f(x_val)
4489     assert np.allclose(naive_ret, optimised_ret)
4490 def test_local_log_sum_exp3():
4491     x = vector('x')
4492     f = compile_graph_log_sum_exp(x, axis=0)
4493     x_val = np.array([-100., 100.]).astype(config.floatX)
4494     optimised_ret = f(x_val)
4495     assert np.allclose(optimised_ret, 100.)
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
