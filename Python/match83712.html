<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for s3fs.py & boto_secgroup.py</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for s3fs.py & boto_secgroup.py
      </h3>
      <h1 align="center">
        3.9%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>s3fs.py (4.6568627%)<TH>boto_secgroup.py (3.442029%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match83712-0.html#0',2,'match83712-1.html#0',3)" NAME="0">(730-743)<TD><A HREF="javascript:ZweiFrames('match83712-0.html#0',2,'match83712-1.html#0',3)" NAME="0">(960-970)</A><TD ALIGN=center><FONT COLOR="#ff0000">13</FONT>
<TR><TD BGCOLOR="#f63526"><FONT COLOR="#f63526">-</FONT><TD><A HREF="javascript:ZweiFrames('match83712-0.html#1',2,'match83712-1.html#1',3)" NAME="1">(424-436)<TD><A HREF="javascript:ZweiFrames('match83712-0.html#1',2,'match83712-1.html#1',3)" NAME="1">(128-197)</A><TD ALIGN=center><FONT COLOR="#ff0000">13</FONT>
<TR><TD BGCOLOR="#980517"><FONT COLOR="#980517">-</FONT><TD><A HREF="javascript:ZweiFrames('match83712-0.html#2',2,'match83712-1.html#2',3)" NAME="2">(774-782)<TD><A HREF="javascript:ZweiFrames('match83712-0.html#2',2,'match83712-1.html#2',3)" NAME="2">(301-311)</A><TD ALIGN=center><FONT COLOR="#eb0000">12</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>s3fs.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
&quot;&quot;&quot;
Amazon S3 Fileserver Backend

.. versionadded:: 0.16.0

This backend exposes directories in S3 buckets as Salt environments. To enable
this backend, add ``s3fs`` to the :conf_master:`fileserver_backend` option in the
Master config file.

.. code-block:: yaml

    fileserver_backend:
      - s3fs

S3 credentials must also be set in the master config file:

.. code-block:: yaml

    s3.keyid: GKTADJGHEIQSXMKKRBJ08H
    s3.key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs

Alternatively, if on EC2 these credentials can be automatically loaded from
instance metadata.

This fileserver supports two modes of operation for the buckets:

1. :strong:`A single bucket per environment`

   .. code-block:: yaml

    s3.buckets:
      production:
        - bucket1
        - bucket2
      staging:
        - bucket3
        - bucket4

2. :strong:`Multiple environments per bucket`

   .. code-block:: yaml

    s3.buckets:
      - bucket1
      - bucket2
      - bucket3
      - bucket4

Note that bucket names must be all lowercase both in the AWS console and in
Salt, otherwise you may encounter ``SignatureDoesNotMatch`` errors.

A multiple-environment bucket must adhere to the following root directory
structure::

    s3://&lt;bucket name&gt;/&lt;environment&gt;/&lt;files&gt;

.. note:: This fileserver back-end requires the use of the MD5 hashing algorithm.
    MD5 may not be compliant with all security policies.

.. note:: This fileserver back-end is only compatible with MD5 ETag hashes in
    the S3 metadata. This means that you must use SSE-S3 or plaintext for
    bucket encryption, and that you must not use multipart upload when
    uploading to your bucket. More information here:
    https://docs.aws.amazon.com/AmazonS3/latest/API/RESTCommonResponseHeaders.html

    Objects without an MD5 ETag will be fetched on every fileserver update.

    If you deal with objects greater than 8MB, then you should use the
    following AWS CLI config to avoid mutipart upload:

    .. code-block:: text

        s3 =
          multipart_threshold = 1024MB

    More info here:
    https://docs.aws.amazon.com/cli/latest/topic/s3-config.html
&quot;&quot;&quot;


import datetime
import logging
import os
import pickle
import time
import urllib.parse

import salt.fileserver as fs
import salt.modules
import salt.utils.files
import salt.utils.gzip_util
import salt.utils.hashutils
import salt.utils.versions

log = logging.getLogger(__name__)

S3_CACHE_EXPIRE = 30  # cache for 30 seconds
S3_SYNC_ON_UPDATE = True  # sync cache on update rather than jit


def envs():
    &quot;&quot;&quot;
    Return a list of directories within the bucket that can be
    used as environments.
    &quot;&quot;&quot;

    # update and grab the envs from the metadata keys
    metadata = _init()
    return list(metadata.keys())


def update():
    &quot;&quot;&quot;
    Update the cache file for the bucket.
    &quot;&quot;&quot;

    metadata = _init()

    if S3_SYNC_ON_UPDATE:
        # sync the buckets to the local cache
        log.info(&quot;Syncing local cache from S3...&quot;)
        for saltenv, env_meta in metadata.items():
            for bucket_files in _find_files(env_meta):
                for bucket, files in bucket_files.items():
                    for file_path in files:
                        cached_file_path = _get_cached_file_name(
                            bucket, saltenv, file_path
                        )
                        log.info(&quot;%s - %s : %s&quot;, bucket, saltenv, file_path)

                        # load the file from S3 if it's not in the cache or it's old
                        _get_file_from_s3(
                            metadata, saltenv, bucket, file_path, cached_file_path
                        )

        log.info(&quot;Sync local cache from S3 completed.&quot;)


def find_file(path, saltenv=&quot;base&quot;, **kwargs):
    &quot;&quot;&quot;
    Look through the buckets cache file for a match.
    If the field is found, it is retrieved from S3 only if its cached version
    is missing, or if the MD5 does not match.
    &quot;&quot;&quot;
    if &quot;env&quot; in kwargs:
        # &quot;env&quot; is not supported; Use &quot;saltenv&quot;.
        kwargs.pop(&quot;env&quot;)

    fnd = {&quot;bucket&quot;: None, &quot;path&quot;: None}

    metadata = _init()
    if not metadata or saltenv not in metadata:
        return fnd

    env_files = _find_files(metadata[saltenv])

    if not _is_env_per_bucket():
        path = os.path.join(saltenv, path)

    # look for the files and check if they're ignored globally
    for bucket in env_files:
        for bucket_name, files in bucket.items():
            if path in files and not fs.is_file_ignored(__opts__, path):
                fnd[&quot;bucket&quot;] = bucket_name
                fnd[&quot;path&quot;] = path
                break
        else:
            continue  # only executes if we didn't break
        break

    if not fnd[&quot;path&quot;] or not fnd[&quot;bucket&quot;]:
        return fnd

    cached_file_path = _get_cached_file_name(fnd[&quot;bucket&quot;], saltenv, path)

    # jit load the file from S3 if it's not in the cache or it's old
    _get_file_from_s3(metadata, saltenv, fnd[&quot;bucket&quot;], path, cached_file_path)

    return fnd


def file_hash(load, fnd):
    &quot;&quot;&quot;
    Return an MD5 file hash
    &quot;&quot;&quot;
    if &quot;env&quot; in load:
        # &quot;env&quot; is not supported; Use &quot;saltenv&quot;.
        load.pop(&quot;env&quot;)

    ret = {}

    if &quot;saltenv&quot; not in load:
        return ret

    if &quot;path&quot; not in fnd or &quot;bucket&quot; not in fnd or not fnd[&quot;path&quot;]:
        return ret

    cached_file_path = _get_cached_file_name(
        fnd[&quot;bucket&quot;], load[&quot;saltenv&quot;], fnd[&quot;path&quot;]
    )

    if os.path.isfile(cached_file_path):
        ret[&quot;hsum&quot;] = salt.utils.hashutils.get_hash(cached_file_path)
        ret[&quot;hash_type&quot;] = &quot;md5&quot;

    return ret


def serve_file(load, fnd):
    &quot;&quot;&quot;
    Return a chunk from a file based on the data received
    &quot;&quot;&quot;
    if &quot;env&quot; in load:
        # &quot;env&quot; is not supported; Use &quot;saltenv&quot;.
        load.pop(&quot;env&quot;)

    ret = {&quot;data&quot;: &quot;&quot;, &quot;dest&quot;: &quot;&quot;}

    if &quot;path&quot; not in load or &quot;loc&quot; not in load or &quot;saltenv&quot; not in load:
        return ret

    if &quot;path&quot; not in fnd or &quot;bucket&quot; not in fnd:
        return ret

    gzip = load.get(&quot;gzip&quot;, None)

    # get the saltenv/path file from the cache
    cached_file_path = _get_cached_file_name(
        fnd[&quot;bucket&quot;], load[&quot;saltenv&quot;], fnd[&quot;path&quot;]
    )

    ret[&quot;dest&quot;] = _trim_env_off_path([fnd[&quot;path&quot;]], load[&quot;saltenv&quot;])[0]

    with salt.utils.files.fopen(cached_file_path, &quot;rb&quot;) as fp_:
        fp_.seek(load[&quot;loc&quot;])
        data = fp_.read(__opts__[&quot;file_buffer_size&quot;])
        if data and not salt.utils.files.is_binary(cached_file_path):
            data = data.decode(__salt_system_encoding__)
        if gzip and data:
            data = salt.utils.gzip_util.compress(data, gzip)
            ret[&quot;gzip&quot;] = gzip
        ret[&quot;data&quot;] = data
    return ret


def file_list(load):
    &quot;&quot;&quot;
    Return a list of all files on the file server in a specified environment
    &quot;&quot;&quot;
    if &quot;env&quot; in load:
        # &quot;env&quot; is not supported; Use &quot;saltenv&quot;.
        load.pop(&quot;env&quot;)

    ret = []

    if &quot;saltenv&quot; not in load:
        return ret

    saltenv = load[&quot;saltenv&quot;]
    metadata = _init()

    if not metadata or saltenv not in metadata:
        return ret
    for bucket in _find_files(metadata[saltenv]):
        for buckets in bucket.values():
            files = [f for f in buckets if not fs.is_file_ignored(__opts__, f)]
            ret += _trim_env_off_path(files, saltenv)

    return ret


def file_list_emptydirs(load):
    &quot;&quot;&quot;
    Return a list of all empty directories on the master
    &quot;&quot;&quot;
    # TODO - implement this
    _init()

    return []


def dir_list(load):
    &quot;&quot;&quot;
    Return a list of all directories on the master
    &quot;&quot;&quot;
    if &quot;env&quot; in load:
        # &quot;env&quot; is not supported; Use &quot;saltenv&quot;.
        load.pop(&quot;env&quot;)

    ret = []

    if &quot;saltenv&quot; not in load:
        return ret

    saltenv = load[&quot;saltenv&quot;]
    metadata = _init()

    if not metadata or saltenv not in metadata:
        return ret

    # grab all the dirs from the buckets cache file
    for bucket in _find_dirs(metadata[saltenv]):
        for dirs in bucket.values():
            # trim env and trailing slash
            dirs = _trim_env_off_path(dirs, saltenv, trim_slash=True)
            # remove empty string left by the base env dir in single bucket mode
            ret += [_f for _f in dirs if _f]

    return ret


def _get_s3_key():
    &quot;&quot;&quot;
    Get AWS keys from pillar or config
    &quot;&quot;&quot;

    key = __opts__[&quot;s3.key&quot;] if &quot;s3.key&quot; in __opts__ else None
    keyid = __opts__[&quot;s3.keyid&quot;] if &quot;s3.keyid&quot; in __opts__ else None
    service_url = __opts__[&quot;s3.service_url&quot;] if &quot;s3.service_url&quot; in __opts__ else None
    verify_ssl = __opts__[&quot;s3.verify_ssl&quot;] if &quot;s3.verify_ssl&quot; in __opts__ else None
    kms_keyid = __opts__[&quot;aws.kmw.keyid&quot;] if &quot;aws.kms.keyid&quot; in __opts__ else None
    location = __opts__[&quot;s3.location&quot;] if &quot;s3.location&quot; in __opts__ else None
    path_style = __opts__[&quot;s3.path_style&quot;] if &quot;s3.path_style&quot; in __opts__ else None
    https_enable = (
        __opts__[&quot;s3.https_enable&quot;] if &quot;s3.https_enable&quot; in __opts__ else None
    )

    return (
        key,
        keyid,
        service_url,
        verify_ssl,
        kms_keyid,
        location,
        path_style,
        https_enable,
    )


def _init():
    &quot;&quot;&quot;
    Connect to S3 and download the metadata for each file in all buckets
    specified and cache the data to disk.
    &quot;&quot;&quot;
    cache_file = _get_buckets_cache_filename()
    exp = time.time() - S3_CACHE_EXPIRE

    # check mtime of the buckets files cache
    metadata = None
    try:
        if os.path.getmtime(cache_file) &gt; exp:
            metadata = _read_buckets_cache_file(cache_file)
    except OSError:
        pass

    if metadata is None:
        # bucket files cache expired or does not exist
        metadata = _refresh_buckets_cache_file(cache_file)

    return metadata


def _get_cache_dir():
    &quot;&quot;&quot;
    Return the path to the s3cache dir
    &quot;&quot;&quot;

    # Or is that making too many assumptions?
    return os.path.join(__opts__[&quot;cachedir&quot;], &quot;s3cache&quot;)


def _get_cached_file_name(bucket_name, saltenv, path):
    &quot;&quot;&quot;
    Return the cached file name for a bucket path file
    &quot;&quot;&quot;

    file_path = os.path.join(_get_cache_dir(), saltenv, bucket_name, path)

    # make sure bucket and saltenv directories exist
    if not os.path.exists(os.path.dirname(file_path)):
        os.makedirs(os.path.dirname(file_path))

    return file_path


def _get_buckets_cache_filename():
    &quot;&quot;&quot;
    Return the filename of the cache for bucket contents.
    Create the path if it does not exist.
    &quot;&quot;&quot;

    cache_dir = _get_cache_dir()
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)

    return os.path.join(cache_dir, &quot;buckets_files.cache&quot;)


def _refresh_buckets_cache_file(cache_file):
    &quot;&quot;&quot;
    Retrieve the content of all buckets and cache the metadata to the buckets
    cache file
    &quot;&quot;&quot;

    log.debug(&quot;Refreshing buckets cache file&quot;)

    (
        key,
        keyid,
        service_url,
        verify_ssl,
        kms_keyid,
        location,
        path_style,
        https_enable,
    ) = _get_s3_key()
    metadata = {}

    # helper s3 query function
    def __get_s3_meta(bucket, key=key, keyid=keyid):
<A NAME="1"></A>        ret, marker = [], &quot;&quot;
        while True:
            tmp = __utils__[&quot;s3.query&quot;](
                key<FONT color="#f63526"><A HREF="javascript:ZweiFrames('match83712-1.html#1',3,'match83712-top.html#1',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>=key,
                keyid=keyid,
                kms_keyid=keyid,
                bucket=bucket,
                service_url=service_url,
                verify_ssl=verify_ssl,
                location=location,
                return_bin=False,
                path_style=path_style,
                https_enable=https_enable,
                params={&quot;marker&quot;: marker},
            )
            headers =</B></FONT> []
            for header in tmp:
                if &quot;Key&quot; in header:
                    break
                headers.append(header)
            ret.extend(tmp)
            if all(
                [header.get(&quot;IsTruncated&quot;, &quot;false&quot;) == &quot;false&quot; for header in headers]
            ):
                break
            marker = tmp[-1][&quot;Key&quot;]
        return ret

    if _is_env_per_bucket():
        # Single environment per bucket
        for saltenv, buckets in _get_buckets().items():
            bucket_files_list = []
            for bucket_name in buckets:
                bucket_files = {}
                s3_meta = __get_s3_meta(bucket_name)

                # s3 query returned nothing
                if not s3_meta:
                    continue

                # grab only the files/dirs
                bucket_files[bucket_name] = [k for k in s3_meta if &quot;Key&quot; in k]
                bucket_files_list.append(bucket_files)

                # check to see if we added any keys, otherwise investigate possible error conditions
                if not bucket_files[bucket_name]:
                    meta_response = {}
                    for k in s3_meta:
                        if &quot;Code&quot; in k or &quot;Message&quot; in k:
                            # assumes no duplicate keys, consisdent with current erro response.
                            meta_response.update(k)
                    # attempt use of human readable output first.
                    try:
                        log.warning(
                            &quot;'%s' response for bucket '%s'&quot;,
                            meta_response[&quot;Message&quot;],
                            bucket_name,
                        )
                        continue
                    except KeyError:
                        # no human readable error message provided
                        if &quot;Code&quot; in meta_response:
                            log.warning(
                                &quot;'%s' response for bucket '%s'&quot;,
                                meta_response[&quot;Code&quot;],
                                bucket_name,
                            )
                            continue
                        else:
                            log.warning(
                                &quot;S3 Error! Do you have any files in your S3 bucket?&quot;
                            )
                            return {}

            metadata[saltenv] = bucket_files_list

    else:
        # Multiple environments per buckets
        for bucket_name in _get_buckets():
            s3_meta = __get_s3_meta(bucket_name)

            # s3 query returned nothing
            if not s3_meta:
                continue

            # pull out the environment dirs (e.g. the root dirs)
            files = [k for k in s3_meta if &quot;Key&quot; in k]

            # check to see if we added any keys, otherwise investigate possible error conditions
            if not files:
                meta_response = {}
                for k in s3_meta:
                    if &quot;Code&quot; in k or &quot;Message&quot; in k:
                        # assumes no duplicate keys, consisdent with current erro response.
                        meta_response.update(k)
                # attempt use of human readable output first.
                try:
                    log.warning(
                        &quot;'%s' response for bucket '%s'&quot;,
                        meta_response[&quot;Message&quot;],
                        bucket_name,
                    )
                    continue
                except KeyError:
                    # no human readable error message provided
                    if &quot;Code&quot; in meta_response:
                        log.warning(
                            &quot;'%s' response for bucket '%s'&quot;,
                            meta_response[&quot;Code&quot;],
                            bucket_name,
                        )
                        continue
                    else:
                        log.warning(
                            &quot;S3 Error! Do you have any files in your S3 bucket?&quot;
                        )
                        return {}

            environments = [(os.path.dirname(k[&quot;Key&quot;]).split(&quot;/&quot;, 1))[0] for k in files]
            environments = set(environments)

            # pull out the files for the environment
            for saltenv in environments:
                # grab only files/dirs that match this saltenv
                env_files = [k for k in files if k[&quot;Key&quot;].startswith(saltenv)]

                if saltenv not in metadata:
                    metadata[saltenv] = []

                found = False
                for bucket_files in metadata[saltenv]:
                    if bucket_name in bucket_files:
                        bucket_files[bucket_name] += env_files
                        found = True
                        break
                if not found:
                    metadata[saltenv].append({bucket_name: env_files})

    # write the metadata to disk
    _write_buckets_cache_file(metadata, cache_file)

    return metadata


def _write_buckets_cache_file(metadata, cache_file):
    &quot;&quot;&quot;
    Write the contents of the buckets cache file
    &quot;&quot;&quot;
    if os.path.isfile(cache_file):
        os.remove(cache_file)

    log.debug(&quot;Writing buckets cache file&quot;)

    with salt.utils.files.fopen(cache_file, &quot;wb&quot;) as fp_:
        pickle.dump(metadata, fp_)


def _read_buckets_cache_file(cache_file):
    &quot;&quot;&quot;
    Return the contents of the buckets cache file
    &quot;&quot;&quot;

    log.debug(&quot;Reading buckets cache file&quot;)

    with salt.utils.files.fopen(cache_file, &quot;rb&quot;) as fp_:
        try:
            data = pickle.load(fp_)
        except (
            pickle.UnpicklingError,
            AttributeError,
            EOFError,
            ImportError,
            IndexError,
            KeyError,
            ValueError,
        ) as exc:
            log.debug(&quot;Exception reading buckets cache file: '%s'&quot;, exc)
            data = None

    return data


def _find_files(metadata):
    &quot;&quot;&quot;
    Looks for all the files in the S3 bucket cache metadata
    &quot;&quot;&quot;

    ret = []
    found = {}

    for bucket_dict in metadata:
        for bucket_name, data in bucket_dict.items():
            filepaths = [k[&quot;Key&quot;] for k in data]
            filepaths = [k for k in filepaths if not k.endswith(&quot;/&quot;)]
            if bucket_name not in found:
                found[bucket_name] = True
                ret.append({bucket_name: filepaths})
            else:
                for bucket in ret:
                    if bucket_name in bucket:
                        bucket[bucket_name] += filepaths
                        break
    return ret


def _find_dirs(metadata):
    &quot;&quot;&quot;
    Looks for all the directories in the S3 bucket cache metadata.

    Supports trailing '/' keys (as created by S3 console) as well as
    directories discovered in the path of file keys.
    &quot;&quot;&quot;

    ret = []
    found = {}

    for bucket_dict in metadata:
        for bucket_name, data in bucket_dict.items():
            dirpaths = set()
            for path in [k[&quot;Key&quot;] for k in data]:
                prefix = &quot;&quot;
                for part in path.split(&quot;/&quot;)[:-1]:
                    directory = prefix + part + &quot;/&quot;
                    dirpaths.add(directory)
                    prefix = directory
            if bucket_name not in found:
                found[bucket_name] = True
                ret.append({bucket_name: list(dirpaths)})
            else:
                for bucket in ret:
                    if bucket_name in bucket:
                        bucket[bucket_name] += list(dirpaths)
                        bucket[bucket_name] = list(set(bucket[bucket_name]))
                        break
    return ret


def _find_file_meta(metadata, bucket_name, saltenv, path):
    &quot;&quot;&quot;
    Looks for a file's metadata in the S3 bucket cache file
    &quot;&quot;&quot;
    env_meta = metadata[saltenv] if saltenv in metadata else {}
    bucket_meta = {}
    for bucket in env_meta:
        if bucket_name in bucket:
            bucket_meta = bucket[bucket_name]
    files_meta = list(list(filter((lambda k: &quot;Key&quot; in k), bucket_meta)))

    for item_meta in files_meta:
        if &quot;Key&quot; in item_meta and item_meta[&quot;Key&quot;] == path:
            try:
                # Get rid of quotes surrounding md5
                item_meta[&quot;ETag&quot;] = item_meta[&quot;ETag&quot;].strip('&quot;')
            except KeyError:
                pass
            return item_meta


def _get_buckets():
    &quot;&quot;&quot;
    Return the configuration buckets
    &quot;&quot;&quot;

    return __opts__[&quot;s3.buckets&quot;] if &quot;s3.buckets&quot; in __opts__ else {}


def _get_file_from_s3(metadata, saltenv, bucket_name, path, cached_file_path):
    &quot;&quot;&quot;
    Checks the local cache for the file, if it's old or missing go grab the
    file from S3 and update the cache
    &quot;&quot;&quot;
    (
        key,
        keyid,
        service_url,
        verify_ssl,
        kms_keyid,
        location,
        path_style,
        https_enable,
    ) = _get_s3_key()

    # check the local cache...
    if os.path.isfile(cached_file_path):
        file_meta = _find_file_meta(metadata, bucket_name, saltenv, path)
        if file_meta:
            file_etag = file_meta[&quot;ETag&quot;]

            if file_etag.find(&quot;-&quot;) == -1:
                file_md5 = file_etag
                cached_md5 = salt.utils.hashutils.get_hash(cached_file_path, &quot;md5&quot;)

                # hashes match we have a cache hit
                if cached_md5 == file_md5:
                    return
            else:
                cached_file_stat = os.stat(cached_file_path)
                cached_file_size = cached_file_stat.st_size
                cached_file_mtime = datetime.datetime.fromtimestamp(
                    cached_file_stat.st_mtime
                )

                cached_file_lastmod = datetime.datetime.strptime(
                    file_meta[&quot;LastModified&quot;], &quot;%Y-%m-%dT%H:%M:%S.%fZ&quot;
                )
                if (
<A NAME="0"></A>                    cached_file_size == int(file_meta[&quot;Size&quot;])
                    and cached_file_mtime &gt; cached_file_lastmod
                ):
                    log<FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match83712-1.html#0',3,'match83712-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>.debug(
                        &quot;cached file size equal to metadata size and &quot;
                        &quot;cached file mtime later than metadata last &quot;
                        &quot;modification time.&quot;
                    )
                    ret = __utils__[&quot;s3.query&quot;](
                        key=key,
                        keyid=keyid,
                        kms_keyid=keyid,
                        method=&quot;HEAD&quot;,
                        bucket=bucket_name,
                        service_url=service_url,
                        verify_ssl=verify_ssl,
                        location=</B></FONT>location,
                        path=urllib.parse.quote(path),
                        local_file=cached_file_path,
                        full_headers=True,
                        path_style=path_style,
                        https_enable=https_enable,
                    )
                    if ret is not None:
                        for header_name, header_value in ret[&quot;headers&quot;].items():
                            name = header_name.strip()
                            value = header_value.strip()
                            if str(name).lower() == &quot;last-modified&quot;:
                                s3_file_mtime = datetime.datetime.strptime(
                                    value, &quot;%a, %d %b %Y %H:%M:%S %Z&quot;
                                )
                            elif str(name).lower() == &quot;content-length&quot;:
                                s3_file_size = int(value)
                        if (
                            cached_file_size == s3_file_size
                            and cached_file_mtime &gt; s3_file_mtime
                        ):
                            log.info(
                                &quot;%s - %s : %s skipped download since cached file size &quot;
                                &quot;equal to and mtime after s3 values&quot;,
                                bucket_name,
                                saltenv,
                                path,
                            )
<A NAME="2"></A>                            return

    # ... or get the file from S3
    __utils__<FONT color="#980517"><A HREF="javascript:ZweiFrames('match83712-1.html#2',3,'match83712-top.html#2',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>[&quot;s3.query&quot;](
        key=key,
        keyid=keyid,
        kms_keyid=keyid,
        bucket=bucket_name,
        service_url=service_url,
        verify_ssl=verify_ssl,
        location=location,
        path=urllib.parse.</B></FONT>quote(path),
        local_file=cached_file_path,
        path_style=path_style,
        https_enable=https_enable,
    )


def _trim_env_off_path(paths, saltenv, trim_slash=False):
    &quot;&quot;&quot;
    Return a list of file paths with the saltenv directory removed
    &quot;&quot;&quot;
    env_len = None if _is_env_per_bucket() else len(saltenv) + 1
    slash_len = -1 if trim_slash else None

    return [d[env_len:slash_len] for d in paths]


def _is_env_per_bucket():
    &quot;&quot;&quot;
    Return the configuration mode, either buckets per environment or a list of
    buckets that have environment dirs in their root
    &quot;&quot;&quot;

    buckets = _get_buckets()
    if isinstance(buckets, dict):
        return True
    elif isinstance(buckets, list):
        return False
    else:
        raise ValueError(&quot;Incorrect s3.buckets type given in config&quot;)
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>boto_secgroup.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
&quot;&quot;&quot;
Manage Security Groups
======================

.. versionadded:: 2014.7.0

Create and destroy Security Groups. Be aware that this interacts with Amazon's
services, and so may incur charges.

This module uses ``boto``, which can be installed via package, or pip.

This module accepts explicit EC2 credentials but can also utilize
IAM roles assigned to the instance through Instance Profiles. Dynamic
credentials are then automatically obtained from AWS API and no further
configuration is necessary. More information available `here
&lt;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html&gt;`_.

If IAM roles are not used you need to specify them either in a pillar file or
in the minion's config file:

.. code-block:: yaml

    secgroup.keyid: GKTADJGHEIQSXMKKRBJ08H
    secgroup.key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs

It's also possible to specify ``key``, ``keyid`` and ``region`` via a profile, either
passed in as a dict, or as a string to pull from pillars or minion config:

.. code-block:: yaml

    myprofile:
        keyid: GKTADJGHEIQSXMKKRBJ08H
        key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
        region: us-east-1

.. code-block:: yaml

    Ensure mysecgroup exists:
        boto_secgroup.present:
            - name: mysecgroup
            - description: My security group
            - vpc_name: myvpc
            - rules:
                - ip_protocol: tcp
                  from_port: 80
                  to_port: 80
                  cidr_ip:
                    - 10.0.0.0/8
                    - 192.168.0.0/16
                - ip_protocol: tcp
                  from_port: 8080
                  to_port: 8090
                  cidr_ip:
                    - 10.0.0.0/8
                    - 192.168.0.0/16
                - ip_protocol: icmp
                  from_port: -1
                  to_port: -1
                  source_group_name: mysecgroup
                - ip_protocol: tcp
                  from_port: 8080
                  to_port: 8080
                  source_group_name: MyOtherSecGroup
                  source_group_name_vpc: MyPeeredVPC
            - rules_egress:
                - ip_protocol: all
                  from_port: -1
                  to_port: -1
                  cidr_ip:
                    - 10.0.0.0/8
                    - 192.168.0.0/16
            - tags:
                SomeTag: 'My Tag Value'
                SomeOtherTag: 'Other Tag Value'
            - region: us-east-1
            - keyid: GKTADJGHEIQSXMKKRBJ08H
            - key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs

    # Using a profile from pillars
    Ensure mysecgroup exists:
        boto_secgroup.present:
            - name: mysecgroup
            - description: My security group
            - profile: myprofile

    # Passing in a profile
    Ensure mysecgroup exists:
        boto_secgroup.present:
            - name: mysecgroup
            - description: My security group
            - profile:
                keyid: GKTADJGHEIQSXMKKRBJ08H
                key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
                region: us-east-1

.. note::

    When using the ``profile`` parameter and ``region`` is set outside of
    the profile group, region is ignored and a default region will be used.

    If ``region`` is missing from the ``profile`` data set, ``us-east-1``
    will be used as the default region.

&quot;&quot;&quot;

import logging
import pprint

import salt.utils.dictupdate as dictupdate
from salt.exceptions import SaltInvocationError

log = logging.getLogger(__name__)


def __virtual__():
    &quot;&quot;&quot;
    Only load if boto is available.
    &quot;&quot;&quot;
    if &quot;boto_secgroup.exists&quot; in __salt__:
        return &quot;boto_secgroup&quot;
    return (False, &quot;boto_secgroup module could not be loaded&quot;)


def present(
<A NAME="1"></A>    name,
    description,
    vpc_id=None,
    vpc_name<FONT color="#f63526"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match83712-0.html#1',2,'match83712-top.html#1',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>=None,
    rules=None,
    rules_egress=None,
    delete_ingress_rules=True,
    delete_egress_rules=True,
    region=None,
    key=None,
    keyid=None,
    profile=None,
    tags=None,
):
    &quot;&quot;&quot;
    Ensure the security group exists with the specified rules.

    name
        Name of the security group.

    description
        A description of this security group.

    vpc_id
        The ID of the VPC to create the security group in, if any. Exclusive with vpc_name.

    vpc_name
        The name of the VPC to create the security group in, if any. Exclusive with vpc_id.

        .. versionadded:: 2016.3.0

        .. versionadded:: 2015.8.2

    rules
        A list of ingress rule dicts. If not specified, ``rules=None``,
        the ingress rules will be unmanaged. If set to an empty list, ``[]``,
        then all ingress rules will be removed.

    rules_egress
        A list of egress rule dicts. If not specified, ``rules_egress=None``,
        the egress rules will be unmanaged. If set to an empty list, ``[]``,
        then all egress rules will be removed.

    delete_ingress_rules
        Some tools (EMR comes to mind) insist on adding rules on-the-fly, which
        salt will happily remove on the next run.  Set this param to False to
        avoid deleting rules which were added outside of salt.

    delete_egress_rules
        Some tools (EMR comes to mind) insist on adding rules on-the-fly, which
        salt will happily remove on the next run.  Set this param to False to
        avoid deleting rules which were added outside of salt.

    region
        Region to connect to.

    key
        Secret key to be used.

    keyid
        Access key to be used.

    profile
        A dict with region, key and keyid, or a pillar key (string)
        that contains a dict with region, key, and keyid.

    tags
        List of key:value pairs of tags to set on the security group

        .. versionadded:: 2016.3.0
    &quot;&quot;&quot;
    ret = {&quot;name&quot;: name, &quot;result&quot;: True, &quot;comment&quot;: &quot;&quot;, &quot;changes&quot;: {}}
    _ret =</B></FONT> _security_group_present(
        name,
        description,
        vpc_id=vpc_id,
        vpc_name=vpc_name,
        region=region,
        key=key,
        keyid=keyid,
        profile=profile,
    )
    ret[&quot;changes&quot;] = _ret[&quot;changes&quot;]
    ret[&quot;comment&quot;] = &quot; &quot;.join([ret[&quot;comment&quot;], _ret[&quot;comment&quot;]])
    if not _ret[&quot;result&quot;]:
        ret[&quot;result&quot;] = _ret[&quot;result&quot;]
        if ret[&quot;result&quot;] is False:
            return ret
        elif ret[&quot;result&quot;] is None:
            return ret
    if rules is not None:
        _ret = _rules_present(
            name,
            rules,
            delete_ingress_rules,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
        )
        ret[&quot;changes&quot;] = dictupdate.update(ret[&quot;changes&quot;], _ret[&quot;changes&quot;])
        ret[&quot;comment&quot;] = &quot; &quot;.join([ret[&quot;comment&quot;], _ret[&quot;comment&quot;]])
        if not _ret[&quot;result&quot;]:
            ret[&quot;result&quot;] = _ret[&quot;result&quot;]
    if rules_egress is not None:
        _ret = _rules_egress_present(
            name,
            rules_egress,
            delete_egress_rules,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
        )
        ret[&quot;changes&quot;] = dictupdate.update(ret[&quot;changes&quot;], _ret[&quot;changes&quot;])
        ret[&quot;comment&quot;] = &quot; &quot;.join([ret[&quot;comment&quot;], _ret[&quot;comment&quot;]])
        if not _ret[&quot;result&quot;]:
            ret[&quot;result&quot;] = _ret[&quot;result&quot;]
    _ret = _tags_present(
        name=name,
        tags=tags,
        vpc_id=vpc_id,
        vpc_name=vpc_name,
        region=region,
        key=key,
        keyid=keyid,
        profile=profile,
    )
    ret[&quot;changes&quot;] = dictupdate.update(ret[&quot;changes&quot;], _ret[&quot;changes&quot;])
    ret[&quot;comment&quot;] = &quot; &quot;.join([ret[&quot;comment&quot;], _ret[&quot;comment&quot;]])
    if not _ret[&quot;result&quot;]:
        ret[&quot;result&quot;] = _ret[&quot;result&quot;]
    return ret


def _security_group_present(
    name,
    description,
    vpc_id=None,
    vpc_name=None,
    region=None,
    key=None,
    keyid=None,
    profile=None,
):
    &quot;&quot;&quot;
    given a group name or a group name and vpc id (or vpc name):
    1. determine if the group exists
    2. if the group does not exist, creates the group
    3. return the group's configuration and any changes made
    &quot;&quot;&quot;
    ret = {&quot;result&quot;: True, &quot;comment&quot;: &quot;&quot;, &quot;changes&quot;: {}}
    exists = __salt__[&quot;boto_secgroup.exists&quot;](
        name, region, key, keyid, profile, vpc_id, vpc_name
    )
    if not exists:
        if __opts__[&quot;test&quot;]:
            ret[&quot;comment&quot;] = &quot;Security group {} is set to be created.&quot;.format(name)
            ret[&quot;result&quot;] = None
            return ret
        created = __salt__[&quot;boto_secgroup.create&quot;](
            name=name,
            description=description,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
<A NAME="2"></A>        )
        if created:
            ret[&quot;changes&quot;][&quot;old&quot;] = {&quot;secgroup&quot;: None}
            sg = __salt__<FONT color="#980517"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match83712-0.html#2',2,'match83712-top.html#2',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>[&quot;boto_secgroup.get_config&quot;](
                name=name,
                group_id=None,
                region=region,
                key=key,
                keyid=keyid,
                profile=profile,
                vpc_id=vpc_id,
                vpc_name=vpc_name,
            )
            ret[&quot;changes&quot;][</B></FONT>&quot;new&quot;] = {&quot;secgroup&quot;: sg}
            ret[&quot;comment&quot;] = &quot;Security group {} created.&quot;.format(name)
        else:
            ret[&quot;result&quot;] = False
            ret[&quot;comment&quot;] = &quot;Failed to create {} security group.&quot;.format(name)
    else:
        ret[&quot;comment&quot;] = &quot;Security group {} present.&quot;.format(name)
    return ret


def _split_rules(rules):
    &quot;&quot;&quot;
    Split rules with lists into individual rules.

    We accept some attributes as lists or strings. The data we get back from
    the execution module lists rules as individual rules. We need to split the
    provided rules into individual rules to compare them.
    &quot;&quot;&quot;
    split = []
    for rule in rules:
        cidr_ip = rule.get(&quot;cidr_ip&quot;)
        group_name = rule.get(&quot;source_group_name&quot;)
        group_id = rule.get(&quot;source_group_group_id&quot;)
        if cidr_ip and not isinstance(cidr_ip, str):
            for ip in cidr_ip:
                _rule = rule.copy()
                _rule[&quot;cidr_ip&quot;] = ip
                split.append(_rule)
        elif group_name and not isinstance(group_name, str):
            for name in group_name:
                _rule = rule.copy()
                _rule[&quot;source_group_name&quot;] = name
                split.append(_rule)
        elif group_id and not isinstance(group_id, str):
            for _id in group_id:
                _rule = rule.copy()
                _rule[&quot;source_group_group_id&quot;] = _id
                split.append(_rule)
        else:
            split.append(rule)
    return split


def _check_rule(rule, _rule):
    &quot;&quot;&quot;
    Check to see if two rules are the same. Needed to compare rules fetched
    from boto, since they may not completely match rules defined in sls files
    but may be functionally equivalent.
    &quot;&quot;&quot;

    # We need to alter what Boto returns if no ports are specified
    # so that we can compare rules fairly.
    #
    # Boto returns None for from_port and to_port where we're required
    # to pass in &quot;-1&quot; instead.
    if _rule.get(&quot;from_port&quot;) is None:
        _rule[&quot;from_port&quot;] = -1
    if _rule.get(&quot;to_port&quot;) is None:
        _rule[&quot;to_port&quot;] = -1

    if (
        rule[&quot;ip_protocol&quot;] == _rule[&quot;ip_protocol&quot;]
        and str(rule[&quot;from_port&quot;]) == str(_rule[&quot;from_port&quot;])
        and str(rule[&quot;to_port&quot;]) == str(_rule[&quot;to_port&quot;])
    ):
        _cidr_ip = _rule.get(&quot;cidr_ip&quot;)
        if _cidr_ip and _cidr_ip == rule.get(&quot;cidr_ip&quot;):
            return True
        _owner_id = _rule.get(&quot;source_group_owner_id&quot;)
        if _owner_id and _owner_id == rule.get(&quot;source_group_owner_id&quot;):
            return True
        _group_id = _rule.get(&quot;source_group_group_id&quot;)
        if _group_id and _group_id == rule.get(&quot;source_group_group_id&quot;):
            return True
        _group_name = _rule.get(&quot;source_group_name&quot;)
        if _group_name and _group_id == rule.get(&quot;source_group_name&quot;):
            return True
    return False


def _get_rule_changes(rules, _rules):
    &quot;&quot;&quot;
    given a list of desired rules (rules) and existing rules (_rules) return
    a list of rules to delete (to_delete) and to create (to_create)
    &quot;&quot;&quot;
    to_delete = []
    to_create = []
    # for each rule in state file
    # 1. validate rule
    # 2. determine if rule exists in existing security group rules
    for rule in rules:
        try:
            ip_protocol = str(rule.get(&quot;ip_protocol&quot;))
        except KeyError:
            raise SaltInvocationError(
                &quot;ip_protocol, to_port, and from_port are&quot;
                &quot; required arguments for security group&quot;
                &quot; rules.&quot;
            )
        supported_protocols = [
            &quot;tcp&quot;,
            &quot;6&quot;,
            6,
            &quot;udp&quot;,
            &quot;17&quot;,
            17,
            &quot;icmp&quot;,
            &quot;1&quot;,
            1,
            &quot;all&quot;,
            &quot;-1&quot;,
            -1,
        ]
        if ip_protocol not in supported_protocols and (
            not &quot;{}&quot;.format(ip_protocol).isdigit() or int(ip_protocol) &gt; 255
        ):
            raise SaltInvocationError(
                &quot;Invalid ip_protocol {} specified in security group rule.&quot;.format(
                    ip_protocol
                )
            )
        # For the 'all' case, we need to change the protocol name to '-1'.
        if ip_protocol == &quot;all&quot;:
            rule[&quot;ip_protocol&quot;] = &quot;-1&quot;
        cidr_ip = rule.get(&quot;cidr_ip&quot;, None)
        group_name = rule.get(&quot;source_group_name&quot;, None)
        group_id = rule.get(&quot;source_group_group_id&quot;, None)
        if cidr_ip and (group_id or group_name):
            raise SaltInvocationError(
                &quot;cidr_ip and source groups can not both&quot;
                &quot; be specified in security group rules.&quot;
            )
        if group_id and group_name:
            raise SaltInvocationError(
                &quot;Either source_group_group_id or&quot;
                &quot; source_group_name can be specified in&quot;
                &quot; security group rules, but not both.&quot;
            )
        if not (cidr_ip or group_id or group_name):
            raise SaltInvocationError(
                &quot;cidr_ip, source_group_group_id, or&quot;
                &quot; source_group_name must be provided for&quot;
                &quot; security group rules.&quot;
            )
        rule_found = False
        # for each rule in existing security group ruleset determine if
        # new rule exists
        for _rule in _rules:
            if _check_rule(rule, _rule):
                rule_found = True
                break
        if not rule_found:
            to_create.append(rule)
    # for each rule in existing security group configuration
    # 1. determine if rules needed to be deleted
    for _rule in _rules:
        rule_found = False
        for rule in rules:
            if _check_rule(rule, _rule):
                rule_found = True
                break
        if not rule_found:
            # Can only supply name or id, not both. Since we're deleting
            # entries, it doesn't matter which we pick.
            _rule.pop(&quot;source_group_name&quot;, None)
            to_delete.append(_rule)
    log.debug(&quot;Rules to be deleted: %s&quot;, to_delete)
    log.debug(&quot;Rules to be created: %s&quot;, to_create)
    return (to_delete, to_create)


def _rules_present(
    name,
    rules,
    delete_ingress_rules=True,
    vpc_id=None,
    vpc_name=None,
    region=None,
    key=None,
    keyid=None,
    profile=None,
):
    &quot;&quot;&quot;
    given a group name or group name and vpc_id (or vpc name):
    1. get lists of desired rule changes (using _get_rule_changes)
    2. authorize/create rules missing rules
    3. if delete_ingress_rules is True, delete/revoke non-requested rules
    4. return 'old' and 'new' group rules
    &quot;&quot;&quot;
    ret = {&quot;result&quot;: True, &quot;comment&quot;: &quot;&quot;, &quot;changes&quot;: {}}
    sg = __salt__[&quot;boto_secgroup.get_config&quot;](
        name=name,
        group_id=None,
        region=region,
        key=key,
        keyid=keyid,
        profile=profile,
        vpc_id=vpc_id,
        vpc_name=vpc_name,
    )
    if not sg:
        ret[
            &quot;comment&quot;
        ] = &quot;{} security group configuration could not be retrieved.&quot;.format(name)
        ret[&quot;result&quot;] = False
        return ret
    rules = _split_rules(rules)
    if vpc_id or vpc_name:
        for rule in rules:
            _source_group_name = rule.get(&quot;source_group_name&quot;, None)
            if _source_group_name:
                _group_vpc_name = vpc_name
                _group_vpc_id = vpc_id
                _source_group_name_vpc = rule.get(&quot;source_group_name_vpc&quot;, None)
                if _source_group_name_vpc:
                    _group_vpc_name = _source_group_name_vpc
                    _group_vpc_id = None
                _group_id = __salt__[&quot;boto_secgroup.get_group_id&quot;](
                    name=_source_group_name,
                    vpc_id=_group_vpc_id,
                    vpc_name=_group_vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                )
                if not _group_id:
                    raise SaltInvocationError(
                        &quot;source_group_name {} does not map to a valid &quot;
                        &quot;source group id.&quot;.format(_source_group_name)
                    )
                rule[&quot;source_group_name&quot;] = None
                if _source_group_name_vpc:
                    rule.pop(&quot;source_group_name_vpc&quot;)
                rule[&quot;source_group_group_id&quot;] = _group_id
    # rules = rules that exist in salt state
    # sg['rules'] = that exist in present group
    to_delete, to_create = _get_rule_changes(rules, sg[&quot;rules&quot;])
    to_delete = to_delete if delete_ingress_rules else []
    if to_create or to_delete:
        if __opts__[&quot;test&quot;]:
            msg = &quot;&quot;&quot;Security group {} set to have rules modified.
            To be created: {}
            To be deleted: {}&quot;&quot;&quot;.format(
                name, pprint.pformat(to_create), pprint.pformat(to_delete)
            )
            ret[&quot;comment&quot;] = msg
            ret[&quot;result&quot;] = None
            return ret
        if to_delete:
            deleted = True
            for rule in to_delete:
                _deleted = __salt__[&quot;boto_secgroup.revoke&quot;](
                    name,
                    vpc_id=vpc_id,
                    vpc_name=vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                    **rule
                )
                if not _deleted:
                    deleted = False
            if deleted:
                ret[&quot;comment&quot;] = &quot;Removed rules on {} security group.&quot;.format(name)
            else:
                ret[&quot;comment&quot;] = &quot;Failed to remove rules on {} security group.&quot;.format(
                    name
                )
                ret[&quot;result&quot;] = False
        if to_create:
            created = True
            for rule in to_create:
                _created = __salt__[&quot;boto_secgroup.authorize&quot;](
                    name,
                    vpc_id=vpc_id,
                    vpc_name=vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                    **rule
                )
                if not _created:
                    created = False
            if created:
                ret[&quot;comment&quot;] = &quot; &quot;.join(
                    [
                        ret[&quot;comment&quot;],
                        &quot;Created rules on {} security group.&quot;.format(name),
                    ]
                )
            else:
                ret[&quot;comment&quot;] = &quot; &quot;.join(
                    [
                        ret[&quot;comment&quot;],
                        &quot;Failed to create rules on {} security group.&quot;.format(name),
                    ]
                )
                ret[&quot;result&quot;] = False
        ret[&quot;changes&quot;][&quot;old&quot;] = {&quot;rules&quot;: sg[&quot;rules&quot;]}
        sg = __salt__[&quot;boto_secgroup.get_config&quot;](
            name=name,
            group_id=None,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
        )
        ret[&quot;changes&quot;][&quot;new&quot;] = {&quot;rules&quot;: sg[&quot;rules&quot;]}
    return ret


def _rules_egress_present(
    name,
    rules_egress,
    delete_egress_rules=True,
    vpc_id=None,
    vpc_name=None,
    region=None,
    key=None,
    keyid=None,
    profile=None,
):
    &quot;&quot;&quot;
    given a group name or group name and vpc_id (or vpc name):
    1. get lists of desired rule changes (using _get_rule_changes)
    2. authorize/create missing rules
    3. if delete_egress_rules is True, delete/revoke non-requested rules
    4. return 'old' and 'new' group rules
    &quot;&quot;&quot;
    ret = {&quot;result&quot;: True, &quot;comment&quot;: &quot;&quot;, &quot;changes&quot;: {}}
    sg = __salt__[&quot;boto_secgroup.get_config&quot;](
        name=name,
        group_id=None,
        region=region,
        key=key,
        keyid=keyid,
        profile=profile,
        vpc_id=vpc_id,
        vpc_name=vpc_name,
    )
    if not sg:
        ret[
            &quot;comment&quot;
        ] = &quot;{} security group configuration could not be retrieved.&quot;.format(name)
        ret[&quot;result&quot;] = False
        return ret
    rules_egress = _split_rules(rules_egress)
    if vpc_id or vpc_name:
        for rule in rules_egress:
            _source_group_name = rule.get(&quot;source_group_name&quot;, None)
            if _source_group_name:
                _group_vpc_name = vpc_name
                _group_vpc_id = vpc_id
                _source_group_name_vpc = rule.get(&quot;source_group_name_vpc&quot;, None)
                if _source_group_name_vpc:
                    _group_vpc_name = _source_group_name_vpc
                    _group_vpc_id = None
                _group_id = __salt__[&quot;boto_secgroup.get_group_id&quot;](
                    name=_source_group_name,
                    vpc_id=_group_vpc_id,
                    vpc_name=_group_vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                )
                if not _group_id:
                    raise SaltInvocationError(
                        &quot;source_group_name {} does not map to a valid &quot;
                        &quot;source group id.&quot;.format(_source_group_name)
                    )
                rule[&quot;source_group_name&quot;] = None
                if _source_group_name_vpc:
                    rule.pop(&quot;source_group_name_vpc&quot;)
                rule[&quot;source_group_group_id&quot;] = _group_id
    # rules_egress = rules that exist in salt state
    # sg['rules_egress'] = that exist in present group
    to_delete, to_create = _get_rule_changes(rules_egress, sg[&quot;rules_egress&quot;])
    to_delete = to_delete if delete_egress_rules else []
    if to_create or to_delete:
        if __opts__[&quot;test&quot;]:
            msg = &quot;&quot;&quot;Security group {} set to have rules modified.
            To be created: {}
            To be deleted: {}&quot;&quot;&quot;.format(
                name, pprint.pformat(to_create), pprint.pformat(to_delete)
            )
            ret[&quot;comment&quot;] = msg
            ret[&quot;result&quot;] = None
            return ret
        if to_delete:
            deleted = True
            for rule in to_delete:
                _deleted = __salt__[&quot;boto_secgroup.revoke&quot;](
                    name,
                    vpc_id=vpc_id,
                    vpc_name=vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                    egress=True,
                    **rule
                )
                if not _deleted:
                    deleted = False
            if deleted:
                ret[&quot;comment&quot;] = &quot; &quot;.join(
                    [
                        ret[&quot;comment&quot;],
                        &quot;Removed egress rule on {} security group.&quot;.format(name),
                    ]
                )
            else:
                ret[&quot;comment&quot;] = &quot; &quot;.join(
                    [
                        ret[&quot;comment&quot;],
                        &quot;Failed to remove egress rule on {} security group.&quot;.format(
                            name
                        ),
                    ]
                )
                ret[&quot;result&quot;] = False
        if to_create:
            created = True
            for rule in to_create:
                _created = __salt__[&quot;boto_secgroup.authorize&quot;](
                    name,
                    vpc_id=vpc_id,
                    vpc_name=vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                    egress=True,
                    **rule
                )
                if not _created:
                    created = False
            if created:
                ret[&quot;comment&quot;] = &quot; &quot;.join(
                    [
                        ret[&quot;comment&quot;],
                        &quot;Created egress rules on {} security group.&quot;.format(name),
                    ]
                )
            else:
                ret[&quot;comment&quot;] = &quot; &quot;.join(
                    [
                        ret[&quot;comment&quot;],
                        &quot;Failed to create egress rules on {} security group.&quot;.format(
                            name
                        ),
                    ]
                )
                ret[&quot;result&quot;] = False

        ret[&quot;changes&quot;][&quot;old&quot;] = {&quot;rules_egress&quot;: sg[&quot;rules_egress&quot;]}
        sg = __salt__[&quot;boto_secgroup.get_config&quot;](
            name=name,
            group_id=None,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
        )
        ret[&quot;changes&quot;][&quot;new&quot;] = {&quot;rules_egress&quot;: sg[&quot;rules_egress&quot;]}
    return ret


def absent(
    name, vpc_id=None, vpc_name=None, region=None, key=None, keyid=None, profile=None
):
    &quot;&quot;&quot;
    Ensure a security group with the specified name does not exist.

    name
        Name of the security group.

    vpc_id
        The ID of the VPC to remove the security group from, if any. Exclusive with vpc_name.

    vpc_name
        The name of the VPC to remove the security group from, if any. Exclusive with vpc_name.

        .. versionadded:: 2016.3.0

    region
        Region to connect to.

    key
        Secret key to be used.

    keyid
        Access key to be used.

    profile
        A dict with region, key and keyid, or a pillar key (string)
        that contains a dict with region, key and keyid.

        .. versionadded:: 2016.3.0
    &quot;&quot;&quot;
    ret = {&quot;name&quot;: name, &quot;result&quot;: True, &quot;comment&quot;: &quot;&quot;, &quot;changes&quot;: {}}

    sg = __salt__[&quot;boto_secgroup.get_config&quot;](
        name=name,
        group_id=None,
        region=region,
        key=key,
        keyid=keyid,
        profile=profile,
        vpc_id=vpc_id,
        vpc_name=vpc_name,
    )

    if sg:
        if __opts__[&quot;test&quot;]:
            ret[&quot;comment&quot;] = &quot;Security group {} is set to be removed.&quot;.format(name)
            ret[&quot;result&quot;] = None
            return ret
        deleted = __salt__[&quot;boto_secgroup.delete&quot;](
            name=name,
            group_id=None,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
        )
        if deleted:
            ret[&quot;changes&quot;][&quot;old&quot;] = {&quot;secgroup&quot;: sg}
            ret[&quot;changes&quot;][&quot;new&quot;] = {&quot;secgroup&quot;: None}
            ret[&quot;comment&quot;] = &quot;Security group {} deleted.&quot;.format(name)
        else:
            ret[&quot;result&quot;] = False
            ret[&quot;comment&quot;] = &quot;Failed to delete {} security group.&quot;.format(name)
    else:
        ret[&quot;comment&quot;] = &quot;{} security group does not exist.&quot;.format(name)
    return ret


def _tags_present(
    name,
    tags,
    vpc_id=None,
    vpc_name=None,
    region=None,
    key=None,
    keyid=None,
    profile=None,
):
    &quot;&quot;&quot;
    helper function to validate tags are correct
    &quot;&quot;&quot;
    ret = {&quot;result&quot;: True, &quot;comment&quot;: &quot;&quot;, &quot;changes&quot;: {}}
    if tags:
        sg = __salt__[&quot;boto_secgroup.get_config&quot;](
            name=name,
            group_id=None,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
        )
        if not sg:
            ret[
                &quot;comment&quot;
            ] = &quot;{} security group configuration could not be retrieved.&quot;.format(name)
            ret[&quot;result&quot;] = False
            return ret
        tags_to_add = tags
        tags_to_update = {}
        tags_to_remove = []
        if sg.get(&quot;tags&quot;):
            for existing_tag in sg[&quot;tags&quot;]:
                if existing_tag not in tags:
                    if existing_tag not in tags_to_remove:
                        tags_to_remove.append(existing_tag)
                else:
                    if tags[existing_tag] != sg[&quot;tags&quot;][existing_tag]:
                        tags_to_update[existing_tag] = tags[existing_tag]
                    tags_to_add.pop(existing_tag)
        if tags_to_remove:
            if __opts__[&quot;test&quot;]:
                msg = &quot;The following tag{} set to be removed: {}.&quot;.format(
                    (&quot;s are&quot; if len(tags_to_remove) &gt; 1 else &quot; is&quot;),
                    &quot;, &quot;.join(tags_to_remove),
                )
                ret[&quot;comment&quot;] = &quot; &quot;.join([ret[&quot;comment&quot;], msg])
                ret[&quot;result&quot;] = None
            else:
                temp_ret = __salt__[&quot;boto_secgroup.delete_tags&quot;](
                    tags_to_remove,
                    name=name,
                    group_id=None,
                    vpc_name=vpc_name,
                    vpc_id=vpc_id,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                )
                if not temp_ret:
                    ret[&quot;result&quot;] = False
                    ret[&quot;comment&quot;] = &quot; &quot;.join(
                        [
                            ret[&quot;comment&quot;],
                            &quot;Error attempting to delete tags {}.&quot;.format(
                                tags_to_remove
                            ),
                        ]
                    )
                    return ret
                if &quot;old&quot; not in ret[&quot;changes&quot;]:
                    ret[&quot;changes&quot;] = dictupdate.update(
                        ret[&quot;changes&quot;], {&quot;old&quot;: {&quot;tags&quot;: {}}}
                    )
                for rem_tag in tags_to_remove:
                    ret[&quot;changes&quot;][&quot;old&quot;][&quot;tags&quot;][rem_tag] = sg[&quot;tags&quot;][rem_tag]
        if tags_to_add or tags_to_update:
            if __opts__[&quot;test&quot;]:
                if tags_to_add:
                    msg = &quot;The following tag{} set to be added: {}.&quot;.format(
                        (&quot;s are&quot; if len(tags_to_add.keys()) &gt; 1 else &quot; is&quot;),
                        &quot;, &quot;.join(tags_to_add.keys()),
                    )
                    ret[&quot;comment&quot;] = &quot; &quot;.join([ret[&quot;comment&quot;], msg])
                    ret[&quot;result&quot;] = None
                if tags_to_update:
                    msg = &quot;The following tag {} set to be updated: {}.&quot;.format(
                        (
                            &quot;values are&quot;
                            if len(tags_to_update.keys()) &gt; 1
                            else &quot;value is&quot;
                        ),
                        &quot;, &quot;.join(tags_to_update.keys()),
                    )
<A NAME="0"></A>                    ret[&quot;comment&quot;] = &quot; &quot;.join([ret[&quot;comment&quot;], msg])
                    ret[&quot;result&quot;] = None
            else:
                all_tag_changes = dictupdate<FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match83712-0.html#0',2,'match83712-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>.update(tags_to_add, tags_to_update)
                temp_ret = __salt__[&quot;boto_secgroup.set_tags&quot;](
                    all_tag_changes,
                    name=name,
                    group_id=None,
                    vpc_name=vpc_name,
                    vpc_id=vpc_id,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=</B></FONT>profile,
                )
                if not temp_ret:
                    ret[&quot;result&quot;] = False
                    msg = &quot;Error attempting to set tags.&quot;
                    ret[&quot;comment&quot;] = &quot; &quot;.join([ret[&quot;comment&quot;], msg])
                    return ret
                if &quot;old&quot; not in ret[&quot;changes&quot;]:
                    ret[&quot;changes&quot;] = dictupdate.update(
                        ret[&quot;changes&quot;], {&quot;old&quot;: {&quot;tags&quot;: {}}}
                    )
                if &quot;new&quot; not in ret[&quot;changes&quot;]:
                    ret[&quot;changes&quot;] = dictupdate.update(
                        ret[&quot;changes&quot;], {&quot;new&quot;: {&quot;tags&quot;: {}}}
                    )
                for tag in all_tag_changes:
                    ret[&quot;changes&quot;][&quot;new&quot;][&quot;tags&quot;][tag] = tags[tag]
                    if &quot;tags&quot; in sg:
                        if sg[&quot;tags&quot;]:
                            if tag in sg[&quot;tags&quot;]:
                                ret[&quot;changes&quot;][&quot;old&quot;][&quot;tags&quot;][tag] = sg[&quot;tags&quot;][tag]
        if not tags_to_update and not tags_to_remove and not tags_to_add:
            ret[&quot;comment&quot;] = &quot; &quot;.join([ret[&quot;comment&quot;], &quot;Tags are already set.&quot;])
    return ret
</PRE>
</div>
  </div>
</body>
</html>
