<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for s3fs.py &amp; boto_secgroup.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for s3fs.py &amp; boto_secgroup.py
      </h3>
<h1 align="center">
        3.9%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>s3fs.py (4.6568627%)<th>boto_secgroup.py (3.442029%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(730-743)<td><a href="#" name="0">(960-970)</a><td align="center"><font color="#ff0000">13</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(424-436)<td><a href="#" name="1">(128-197)</a><td align="center"><font color="#ff0000">13</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(774-782)<td><a href="#" name="2">(301-311)</a><td align="center"><font color="#eb0000">12</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>s3fs.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
"""
Amazon S3 Fileserver Backend
.. versionadded:: 0.16.0
This backend exposes directories in S3 buckets as Salt environments. To enable
this backend, add ``s3fs`` to the :conf_master:`fileserver_backend` option in the
Master config file.
.. code-block:: yaml
    fileserver_backend:
      - s3fs
S3 credentials must also be set in the master config file:
.. code-block:: yaml
    s3.keyid: GKTADJGHEIQSXMKKRBJ08H
    s3.key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
Alternatively, if on EC2 these credentials can be automatically loaded from
instance metadata.
This fileserver supports two modes of operation for the buckets:
1. :strong:`A single bucket per environment`
   .. code-block:: yaml
    s3.buckets:
      production:
        - bucket1
        - bucket2
      staging:
        - bucket3
        - bucket4
2. :strong:`Multiple environments per bucket`
   .. code-block:: yaml
    s3.buckets:
      - bucket1
      - bucket2
      - bucket3
      - bucket4
Note that bucket names must be all lowercase both in the AWS console and in
Salt, otherwise you may encounter ``SignatureDoesNotMatch`` errors.
A multiple-environment bucket must adhere to the following root directory
structure::
    s3://&lt;bucket name&gt;/&lt;environment&gt;/&lt;files&gt;
.. note:: This fileserver back-end requires the use of the MD5 hashing algorithm.
    MD5 may not be compliant with all security policies.
.. note:: This fileserver back-end is only compatible with MD5 ETag hashes in
    the S3 metadata. This means that you must use SSE-S3 or plaintext for
    bucket encryption, and that you must not use multipart upload when
    uploading to your bucket. More information here:
    https://docs.aws.amazon.com/AmazonS3/latest/API/RESTCommonResponseHeaders.html
    Objects without an MD5 ETag will be fetched on every fileserver update.
    If you deal with objects greater than 8MB, then you should use the
    following AWS CLI config to avoid mutipart upload:
    .. code-block:: text
        s3 =
          multipart_threshold = 1024MB
    More info here:
    https://docs.aws.amazon.com/cli/latest/topic/s3-config.html
"""
import datetime
import logging
import os
import pickle
import time
import urllib.parse
import salt.fileserver as fs
import salt.modules
import salt.utils.files
import salt.utils.gzip_util
import salt.utils.hashutils
import salt.utils.versions
log = logging.getLogger(__name__)
S3_CACHE_EXPIRE = 30  # cache for 30 seconds
S3_SYNC_ON_UPDATE = True  # sync cache on update rather than jit
def envs():
    """
    Return a list of directories within the bucket that can be
    used as environments.
    """
    metadata = _init()
    return list(metadata.keys())
def update():
    """
    Update the cache file for the bucket.
    """
    metadata = _init()
    if S3_SYNC_ON_UPDATE:
        log.info("Syncing local cache from S3...")
        for saltenv, env_meta in metadata.items():
            for bucket_files in _find_files(env_meta):
                for bucket, files in bucket_files.items():
                    for file_path in files:
                        cached_file_path = _get_cached_file_name(
                            bucket, saltenv, file_path
                        )
                        log.info("%s - %s : %s", bucket, saltenv, file_path)
                        _get_file_from_s3(
                            metadata, saltenv, bucket, file_path, cached_file_path
                        )
        log.info("Sync local cache from S3 completed.")
def find_file(path, saltenv="base", **kwargs):
    """
    Look through the buckets cache file for a match.
    If the field is found, it is retrieved from S3 only if its cached version
    is missing, or if the MD5 does not match.
    """
    if "env" in kwargs:
        kwargs.pop("env")
    fnd = {"bucket": None, "path": None}
    metadata = _init()
    if not metadata or saltenv not in metadata:
        return fnd
    env_files = _find_files(metadata[saltenv])
    if not _is_env_per_bucket():
        path = os.path.join(saltenv, path)
    for bucket in env_files:
        for bucket_name, files in bucket.items():
            if path in files and not fs.is_file_ignored(__opts__, path):
                fnd["bucket"] = bucket_name
                fnd["path"] = path
                break
        else:
            continue  # only executes if we didn't break
        break
    if not fnd["path"] or not fnd["bucket"]:
        return fnd
    cached_file_path = _get_cached_file_name(fnd["bucket"], saltenv, path)
    _get_file_from_s3(metadata, saltenv, fnd["bucket"], path, cached_file_path)
    return fnd
def file_hash(load, fnd):
    """
    Return an MD5 file hash
    """
    if "env" in load:
        load.pop("env")
    ret = {}
    if "saltenv" not in load:
        return ret
    if "path" not in fnd or "bucket" not in fnd or not fnd["path"]:
        return ret
    cached_file_path = _get_cached_file_name(
        fnd["bucket"], load["saltenv"], fnd["path"]
    )
    if os.path.isfile(cached_file_path):
        ret["hsum"] = salt.utils.hashutils.get_hash(cached_file_path)
        ret["hash_type"] = "md5"
    return ret
def serve_file(load, fnd):
    """
    Return a chunk from a file based on the data received
    """
    if "env" in load:
        load.pop("env")
    ret = {"data": "", "dest": ""}
    if "path" not in load or "loc" not in load or "saltenv" not in load:
        return ret
    if "path" not in fnd or "bucket" not in fnd:
        return ret
    gzip = load.get("gzip", None)
    cached_file_path = _get_cached_file_name(
        fnd["bucket"], load["saltenv"], fnd["path"]
    )
    ret["dest"] = _trim_env_off_path([fnd["path"]], load["saltenv"])[0]
    with salt.utils.files.fopen(cached_file_path, "rb") as fp_:
        fp_.seek(load["loc"])
        data = fp_.read(__opts__["file_buffer_size"])
        if data and not salt.utils.files.is_binary(cached_file_path):
            data = data.decode(__salt_system_encoding__)
        if gzip and data:
            data = salt.utils.gzip_util.compress(data, gzip)
            ret["gzip"] = gzip
        ret["data"] = data
    return ret
def file_list(load):
    """
    Return a list of all files on the file server in a specified environment
    """
    if "env" in load:
        load.pop("env")
    ret = []
    if "saltenv" not in load:
        return ret
    saltenv = load["saltenv"]
    metadata = _init()
    if not metadata or saltenv not in metadata:
        return ret
    for bucket in _find_files(metadata[saltenv]):
        for buckets in bucket.values():
            files = [f for f in buckets if not fs.is_file_ignored(__opts__, f)]
            ret += _trim_env_off_path(files, saltenv)
    return ret
def file_list_emptydirs(load):
    """
    Return a list of all empty directories on the master
    """
    _init()
    return []
def dir_list(load):
    """
    Return a list of all directories on the master
    """
    if "env" in load:
        load.pop("env")
    ret = []
    if "saltenv" not in load:
        return ret
    saltenv = load["saltenv"]
    metadata = _init()
    if not metadata or saltenv not in metadata:
        return ret
    for bucket in _find_dirs(metadata[saltenv]):
        for dirs in bucket.values():
            dirs = _trim_env_off_path(dirs, saltenv, trim_slash=True)
            ret += [_f for _f in dirs if _f]
    return ret
def _get_s3_key():
    """
    Get AWS keys from pillar or config
    """
    key = __opts__["s3.key"] if "s3.key" in __opts__ else None
    keyid = __opts__["s3.keyid"] if "s3.keyid" in __opts__ else None
    service_url = __opts__["s3.service_url"] if "s3.service_url" in __opts__ else None
    verify_ssl = __opts__["s3.verify_ssl"] if "s3.verify_ssl" in __opts__ else None
    kms_keyid = __opts__["aws.kmw.keyid"] if "aws.kms.keyid" in __opts__ else None
    location = __opts__["s3.location"] if "s3.location" in __opts__ else None
    path_style = __opts__["s3.path_style"] if "s3.path_style" in __opts__ else None
    https_enable = (
        __opts__["s3.https_enable"] if "s3.https_enable" in __opts__ else None
    )
    return (
        key,
        keyid,
        service_url,
        verify_ssl,
        kms_keyid,
        location,
        path_style,
        https_enable,
    )
def _init():
    """
    Connect to S3 and download the metadata for each file in all buckets
    specified and cache the data to disk.
    """
    cache_file = _get_buckets_cache_filename()
    exp = time.time() - S3_CACHE_EXPIRE
    metadata = None
    try:
        if os.path.getmtime(cache_file) &gt; exp:
            metadata = _read_buckets_cache_file(cache_file)
    except OSError:
        pass
    if metadata is None:
        metadata = _refresh_buckets_cache_file(cache_file)
    return metadata
def _get_cache_dir():
    """
    Return the path to the s3cache dir
    """
    return os.path.join(__opts__["cachedir"], "s3cache")
def _get_cached_file_name(bucket_name, saltenv, path):
    """
    Return the cached file name for a bucket path file
    """
    file_path = os.path.join(_get_cache_dir(), saltenv, bucket_name, path)
    if not os.path.exists(os.path.dirname(file_path)):
        os.makedirs(os.path.dirname(file_path))
    return file_path
def _get_buckets_cache_filename():
    """
    Return the filename of the cache for bucket contents.
    Create the path if it does not exist.
    """
    cache_dir = _get_cache_dir()
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)
    return os.path.join(cache_dir, "buckets_files.cache")
def _refresh_buckets_cache_file(cache_file):
    """
    Retrieve the content of all buckets and cache the metadata to the buckets
    cache file
    """
    log.debug("Refreshing buckets cache file")
    (
        key,
        keyid,
        service_url,
        verify_ssl,
        kms_keyid,
        location,
        path_style,
        https_enable,
    ) = _get_s3_key()
    metadata = {}
    def __get_s3_meta(bucket, key=key, keyid=keyid):
        while True:
            tmp = __utils__["s3.query"](
                key<font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>=key,
                keyid=keyid,
                kms_keyid=keyid,
                bucket=bucket,
                service_url=service_url,
                verify_ssl=verify_ssl,
                location=location,
                return_bin=False,
                path_style=path_style,
                https_enable=https_enable,
                params={"marker": marker},
            )
            headers =</b></font> []
            for header in tmp:
                if "Key" in header:
                    break
                headers.append(header)
            ret.extend(tmp)
            if all(
                [header.get("IsTruncated", "false") == "false" for header in headers]
            ):
                break
            marker = tmp[-1]["Key"]
        return ret
    if _is_env_per_bucket():
        for saltenv, buckets in _get_buckets().items():
            bucket_files_list = []
            for bucket_name in buckets:
                bucket_files = {}
                s3_meta = __get_s3_meta(bucket_name)
                if not s3_meta:
                    continue
                bucket_files[bucket_name] = [k for k in s3_meta if "Key" in k]
                bucket_files_list.append(bucket_files)
                if not bucket_files[bucket_name]:
                    meta_response = {}
                    for k in s3_meta:
                        if "Code" in k or "Message" in k:
                            meta_response.update(k)
                    try:
                        log.warning(
                            "'%s' response for bucket '%s'",
                            meta_response["Message"],
                            bucket_name,
                        )
                        continue
                    except KeyError:
                        if "Code" in meta_response:
                            log.warning(
                                "'%s' response for bucket '%s'",
                                meta_response["Code"],
                                bucket_name,
                            )
                            continue
                        else:
                            log.warning(
                                "S3 Error! Do you have any files in your S3 bucket?"
                            )
                            return {}
            metadata[saltenv] = bucket_files_list
    else:
        for bucket_name in _get_buckets():
            s3_meta = __get_s3_meta(bucket_name)
            if not s3_meta:
                continue
            files = [k for k in s3_meta if "Key" in k]
            if not files:
                meta_response = {}
                for k in s3_meta:
                    if "Code" in k or "Message" in k:
                        meta_response.update(k)
                try:
                    log.warning(
                        "'%s' response for bucket '%s'",
                        meta_response["Message"],
                        bucket_name,
                    )
                    continue
                except KeyError:
                    if "Code" in meta_response:
                        log.warning(
                            "'%s' response for bucket '%s'",
                            meta_response["Code"],
                            bucket_name,
                        )
                        continue
                    else:
                        log.warning(
                            "S3 Error! Do you have any files in your S3 bucket?"
                        )
                        return {}
            environments = [(os.path.dirname(k["Key"]).split("/", 1))[0] for k in files]
            environments = set(environments)
            for saltenv in environments:
                env_files = [k for k in files if k["Key"].startswith(saltenv)]
                if saltenv not in metadata:
                    metadata[saltenv] = []
                found = False
                for bucket_files in metadata[saltenv]:
                    if bucket_name in bucket_files:
                        bucket_files[bucket_name] += env_files
                        found = True
                        break
                if not found:
                    metadata[saltenv].append({bucket_name: env_files})
    _write_buckets_cache_file(metadata, cache_file)
    return metadata
def _write_buckets_cache_file(metadata, cache_file):
    """
    Write the contents of the buckets cache file
    """
    if os.path.isfile(cache_file):
        os.remove(cache_file)
    log.debug("Writing buckets cache file")
    with salt.utils.files.fopen(cache_file, "wb") as fp_:
        pickle.dump(metadata, fp_)
def _read_buckets_cache_file(cache_file):
    """
    Return the contents of the buckets cache file
    """
    log.debug("Reading buckets cache file")
    with salt.utils.files.fopen(cache_file, "rb") as fp_:
        try:
            data = pickle.load(fp_)
        except (
            pickle.UnpicklingError,
            AttributeError,
            EOFError,
            ImportError,
            IndexError,
            KeyError,
            ValueError,
        ) as exc:
            log.debug("Exception reading buckets cache file: '%s'", exc)
            data = None
    return data
def _find_files(metadata):
    """
    Looks for all the files in the S3 bucket cache metadata
    """
    ret = []
    found = {}
    for bucket_dict in metadata:
        for bucket_name, data in bucket_dict.items():
            filepaths = [k["Key"] for k in data]
            filepaths = [k for k in filepaths if not k.endswith("/")]
            if bucket_name not in found:
                found[bucket_name] = True
                ret.append({bucket_name: filepaths})
            else:
                for bucket in ret:
                    if bucket_name in bucket:
                        bucket[bucket_name] += filepaths
                        break
    return ret
def _find_dirs(metadata):
    """
    Looks for all the directories in the S3 bucket cache metadata.
    Supports trailing '/' keys (as created by S3 console) as well as
    directories discovered in the path of file keys.
    """
    ret = []
    found = {}
    for bucket_dict in metadata:
        for bucket_name, data in bucket_dict.items():
            dirpaths = set()
            for path in [k["Key"] for k in data]:
                prefix = ""
                for part in path.split("/")[:-1]:
                    directory = prefix + part + "/"
                    dirpaths.add(directory)
                    prefix = directory
            if bucket_name not in found:
                found[bucket_name] = True
                ret.append({bucket_name: list(dirpaths)})
            else:
                for bucket in ret:
                    if bucket_name in bucket:
                        bucket[bucket_name] += list(dirpaths)
                        bucket[bucket_name] = list(set(bucket[bucket_name]))
                        break
    return ret
def _find_file_meta(metadata, bucket_name, saltenv, path):
    """
    Looks for a file's metadata in the S3 bucket cache file
    """
    env_meta = metadata[saltenv] if saltenv in metadata else {}
    bucket_meta = {}
    for bucket in env_meta:
        if bucket_name in bucket:
            bucket_meta = bucket[bucket_name]
    files_meta = list(list(filter((lambda k: "Key" in k), bucket_meta)))
    for item_meta in files_meta:
        if "Key" in item_meta and item_meta["Key"] == path:
            try:
                item_meta["ETag"] = item_meta["ETag"].strip('"')
            except KeyError:
                pass
            return item_meta
def _get_buckets():
    """
    Return the configuration buckets
    """
    return __opts__["s3.buckets"] if "s3.buckets" in __opts__ else {}
def _get_file_from_s3(metadata, saltenv, bucket_name, path, cached_file_path):
    """
    Checks the local cache for the file, if it's old or missing go grab the
    file from S3 and update the cache
    """
    (
        key,
        keyid,
        service_url,
        verify_ssl,
        kms_keyid,
        location,
        path_style,
        https_enable,
    ) = _get_s3_key()
    if os.path.isfile(cached_file_path):
        file_meta = _find_file_meta(metadata, bucket_name, saltenv, path)
        if file_meta:
            file_etag = file_meta["ETag"]
            if file_etag.find("-") == -1:
                file_md5 = file_etag
                cached_md5 = salt.utils.hashutils.get_hash(cached_file_path, "md5")
                if cached_md5 == file_md5:
                    return
            else:
                cached_file_stat = os.stat(cached_file_path)
                cached_file_size = cached_file_stat.st_size
                cached_file_mtime = datetime.datetime.fromtimestamp(
                    cached_file_stat.st_mtime
                )
                cached_file_lastmod = datetime.datetime.strptime(
                    file_meta["LastModified"], "%Y-%m-%dT%H:%M:%S.%fZ"
                )
                if (
                    and cached_file_mtime &gt; cached_file_lastmod
                ):
                    log<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>.debug(
                        "cached file size equal to metadata size and "
                        "cached file mtime later than metadata last "
                        "modification time."
                    )
                    ret = __utils__["s3.query"](
                        key=key,
                        keyid=keyid,
                        kms_keyid=keyid,
                        method="HEAD",
                        bucket=bucket_name,
                        service_url=service_url,
                        verify_ssl=verify_ssl,
                        location=</b></font>location,
                        path=urllib.parse.quote(path),
                        local_file=cached_file_path,
                        full_headers=True,
                        path_style=path_style,
                        https_enable=https_enable,
                    )
                    if ret is not None:
                        for header_name, header_value in ret["headers"].items():
                            name = header_name.strip()
                            value = header_value.strip()
                            if str(name).lower() == "last-modified":
                                s3_file_mtime = datetime.datetime.strptime(
                                    value, "%a, %d %b %Y %H:%M:%S %Z"
                                )
                            elif str(name).lower() == "content-length":
                                s3_file_size = int(value)
                        if (
                            cached_file_size == s3_file_size
                            and cached_file_mtime &gt; s3_file_mtime
                        ):
                            log.info(
                                "%s - %s : %s skipped download since cached file size "
                                "equal to and mtime after s3 values",
                                bucket_name,
                                saltenv,
                                path,
                            )
    __utils__<font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>["s3.query"](
        key=key,
        keyid=keyid,
        kms_keyid=keyid,
        bucket=bucket_name,
        service_url=service_url,
        verify_ssl=verify_ssl,
        location=location,
        path=urllib.parse.</b></font>quote(path),
        local_file=cached_file_path,
        path_style=path_style,
        https_enable=https_enable,
    )
def _trim_env_off_path(paths, saltenv, trim_slash=False):
    """
    Return a list of file paths with the saltenv directory removed
    """
    env_len = None if _is_env_per_bucket() else len(saltenv) + 1
    slash_len = -1 if trim_slash else None
    return [d[env_len:slash_len] for d in paths]
def _is_env_per_bucket():
    """
    Return the configuration mode, either buckets per environment or a list of
    buckets that have environment dirs in their root
    """
    buckets = _get_buckets()
    if isinstance(buckets, dict):
        return True
    elif isinstance(buckets, list):
        return False
    else:
        raise ValueError("Incorrect s3.buckets type given in config")
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>boto_secgroup.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
"""
Manage Security Groups
======================
.. versionadded:: 2014.7.0
Create and destroy Security Groups. Be aware that this interacts with Amazon's
services, and so may incur charges.
This module uses ``boto``, which can be installed via package, or pip.
This module accepts explicit EC2 credentials but can also utilize
IAM roles assigned to the instance through Instance Profiles. Dynamic
credentials are then automatically obtained from AWS API and no further
configuration is necessary. More information available `here
&lt;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html&gt;`_.
If IAM roles are not used you need to specify them either in a pillar file or
in the minion's config file:
.. code-block:: yaml
    secgroup.keyid: GKTADJGHEIQSXMKKRBJ08H
    secgroup.key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
It's also possible to specify ``key``, ``keyid`` and ``region`` via a profile, either
passed in as a dict, or as a string to pull from pillars or minion config:
.. code-block:: yaml
    myprofile:
        keyid: GKTADJGHEIQSXMKKRBJ08H
        key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
        region: us-east-1
.. code-block:: yaml
    Ensure mysecgroup exists:
        boto_secgroup.present:
            - name: mysecgroup
            - description: My security group
            - vpc_name: myvpc
            - rules:
                - ip_protocol: tcp
                  from_port: 80
                  to_port: 80
                  cidr_ip:
                    - 10.0.0.0/8
                    - 192.168.0.0/16
                - ip_protocol: tcp
                  from_port: 8080
                  to_port: 8090
                  cidr_ip:
                    - 10.0.0.0/8
                    - 192.168.0.0/16
                - ip_protocol: icmp
                  from_port: -1
                  to_port: -1
                  source_group_name: mysecgroup
                - ip_protocol: tcp
                  from_port: 8080
                  to_port: 8080
                  source_group_name: MyOtherSecGroup
                  source_group_name_vpc: MyPeeredVPC
            - rules_egress:
                - ip_protocol: all
                  from_port: -1
                  to_port: -1
                  cidr_ip:
                    - 10.0.0.0/8
                    - 192.168.0.0/16
            - tags:
                SomeTag: 'My Tag Value'
                SomeOtherTag: 'Other Tag Value'
            - region: us-east-1
            - keyid: GKTADJGHEIQSXMKKRBJ08H
            - key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
    Ensure mysecgroup exists:
        boto_secgroup.present:
            - name: mysecgroup
            - description: My security group
            - profile: myprofile
    Ensure mysecgroup exists:
        boto_secgroup.present:
            - name: mysecgroup
            - description: My security group
            - profile:
                keyid: GKTADJGHEIQSXMKKRBJ08H
                key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
                region: us-east-1
.. note::
    When using the ``profile`` parameter and ``region`` is set outside of
    the profile group, region is ignored and a default region will be used.
    If ``region`` is missing from the ``profile`` data set, ``us-east-1``
    will be used as the default region.
"""
import logging
import pprint
import salt.utils.dictupdate as dictupdate
from salt.exceptions import SaltInvocationError
log = logging.getLogger(__name__)
def __virtual__():
    """
    Only load if boto is available.
    """
    if "boto_secgroup.exists" in __salt__:
        return "boto_secgroup"
    return (False, "boto_secgroup module could not be loaded")
def present(
    description,
    vpc_id=None,
    vpc_name<font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>=None,
    rules=None,
    rules_egress=None,
    delete_ingress_rules=True,
    delete_egress_rules=True,
    region=None,
    key=None,
    keyid=None,
    profile=None,
    tags=None,
):
    """
    Ensure the security group exists with the specified rules.
    name
        Name of the security group.
    description
        A description of this security group.
    vpc_id
        The ID of the VPC to create the security group in, if any. Exclusive with vpc_name.
    vpc_name
        The name of the VPC to create the security group in, if any. Exclusive with vpc_id.
        .. versionadded:: 2016.3.0
        .. versionadded:: 2015.8.2
    rules
        A list of ingress rule dicts. If not specified, ``rules=None``,
        the ingress rules will be unmanaged. If set to an empty list, ``[]``,
        then all ingress rules will be removed.
    rules_egress
        A list of egress rule dicts. If not specified, ``rules_egress=None``,
        the egress rules will be unmanaged. If set to an empty list, ``[]``,
        then all egress rules will be removed.
    delete_ingress_rules
        Some tools (EMR comes to mind) insist on adding rules on-the-fly, which
        salt will happily remove on the next run.  Set this param to False to
        avoid deleting rules which were added outside of salt.
    delete_egress_rules
        Some tools (EMR comes to mind) insist on adding rules on-the-fly, which
        salt will happily remove on the next run.  Set this param to False to
        avoid deleting rules which were added outside of salt.
    region
        Region to connect to.
    key
        Secret key to be used.
    keyid
        Access key to be used.
    profile
        A dict with region, key and keyid, or a pillar key (string)
        that contains a dict with region, key, and keyid.
    tags
        List of key:value pairs of tags to set on the security group
        .. versionadded:: 2016.3.0
    """
    ret = {"name": name, "result": True, "comment": "", "changes": {}}
    _ret =</b></font> _security_group_present(
        name,
        description,
        vpc_id=vpc_id,
        vpc_name=vpc_name,
        region=region,
        key=key,
        keyid=keyid,
        profile=profile,
    )
    ret["changes"] = _ret["changes"]
    ret["comment"] = " ".join([ret["comment"], _ret["comment"]])
    if not _ret["result"]:
        ret["result"] = _ret["result"]
        if ret["result"] is False:
            return ret
        elif ret["result"] is None:
            return ret
    if rules is not None:
        _ret = _rules_present(
            name,
            rules,
            delete_ingress_rules,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
        )
        ret["changes"] = dictupdate.update(ret["changes"], _ret["changes"])
        ret["comment"] = " ".join([ret["comment"], _ret["comment"]])
        if not _ret["result"]:
            ret["result"] = _ret["result"]
    if rules_egress is not None:
        _ret = _rules_egress_present(
            name,
            rules_egress,
            delete_egress_rules,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
        )
        ret["changes"] = dictupdate.update(ret["changes"], _ret["changes"])
        ret["comment"] = " ".join([ret["comment"], _ret["comment"]])
        if not _ret["result"]:
            ret["result"] = _ret["result"]
    _ret = _tags_present(
        name=name,
        tags=tags,
        vpc_id=vpc_id,
        vpc_name=vpc_name,
        region=region,
        key=key,
        keyid=keyid,
        profile=profile,
    )
    ret["changes"] = dictupdate.update(ret["changes"], _ret["changes"])
    ret["comment"] = " ".join([ret["comment"], _ret["comment"]])
    if not _ret["result"]:
        ret["result"] = _ret["result"]
    return ret
def _security_group_present(
    name,
    description,
    vpc_id=None,
    vpc_name=None,
    region=None,
    key=None,
    keyid=None,
    profile=None,
):
    """
    given a group name or a group name and vpc id (or vpc name):
    1. determine if the group exists
    2. if the group does not exist, creates the group
    3. return the group's configuration and any changes made
    """
    ret = {"result": True, "comment": "", "changes": {}}
    exists = __salt__["boto_secgroup.exists"](
        name, region, key, keyid, profile, vpc_id, vpc_name
    )
    if not exists:
        if __opts__["test"]:
            ret["comment"] = "Security group {} is set to be created.".format(name)
            ret["result"] = None
            return ret
        created = __salt__["boto_secgroup.create"](
            name=name,
            description=description,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
        if created:
            ret["changes"]["old"] = {"secgroup": None}
            sg = __salt__<font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>["boto_secgroup.get_config"](
                name=name,
                group_id=None,
                region=region,
                key=key,
                keyid=keyid,
                profile=profile,
                vpc_id=vpc_id,
                vpc_name=vpc_name,
            )
            ret["changes"][</b></font>"new"] = {"secgroup": sg}
            ret["comment"] = "Security group {} created.".format(name)
        else:
            ret["result"] = False
            ret["comment"] = "Failed to create {} security group.".format(name)
    else:
        ret["comment"] = "Security group {} present.".format(name)
    return ret
def _split_rules(rules):
    """
    Split rules with lists into individual rules.
    We accept some attributes as lists or strings. The data we get back from
    the execution module lists rules as individual rules. We need to split the
    provided rules into individual rules to compare them.
    """
    split = []
    for rule in rules:
        cidr_ip = rule.get("cidr_ip")
        group_name = rule.get("source_group_name")
        group_id = rule.get("source_group_group_id")
        if cidr_ip and not isinstance(cidr_ip, str):
            for ip in cidr_ip:
                _rule = rule.copy()
                _rule["cidr_ip"] = ip
                split.append(_rule)
        elif group_name and not isinstance(group_name, str):
            for name in group_name:
                _rule = rule.copy()
                _rule["source_group_name"] = name
                split.append(_rule)
        elif group_id and not isinstance(group_id, str):
            for _id in group_id:
                _rule = rule.copy()
                _rule["source_group_group_id"] = _id
                split.append(_rule)
        else:
            split.append(rule)
    return split
def _check_rule(rule, _rule):
    """
    Check to see if two rules are the same. Needed to compare rules fetched
    from boto, since they may not completely match rules defined in sls files
    but may be functionally equivalent.
    """
    if _rule.get("from_port") is None:
        _rule["from_port"] = -1
    if _rule.get("to_port") is None:
        _rule["to_port"] = -1
    if (
        rule["ip_protocol"] == _rule["ip_protocol"]
        and str(rule["from_port"]) == str(_rule["from_port"])
        and str(rule["to_port"]) == str(_rule["to_port"])
    ):
        _cidr_ip = _rule.get("cidr_ip")
        if _cidr_ip and _cidr_ip == rule.get("cidr_ip"):
            return True
        _owner_id = _rule.get("source_group_owner_id")
        if _owner_id and _owner_id == rule.get("source_group_owner_id"):
            return True
        _group_id = _rule.get("source_group_group_id")
        if _group_id and _group_id == rule.get("source_group_group_id"):
            return True
        _group_name = _rule.get("source_group_name")
        if _group_name and _group_id == rule.get("source_group_name"):
            return True
    return False
def _get_rule_changes(rules, _rules):
    """
    given a list of desired rules (rules) and existing rules (_rules) return
    a list of rules to delete (to_delete) and to create (to_create)
    """
    to_delete = []
    to_create = []
    for rule in rules:
        try:
            ip_protocol = str(rule.get("ip_protocol"))
        except KeyError:
            raise SaltInvocationError(
                "ip_protocol, to_port, and from_port are"
                " required arguments for security group"
                " rules."
            )
        supported_protocols = [
            "tcp",
            "6",
            6,
            "udp",
            "17",
            17,
            "icmp",
            "1",
            1,
            "all",
            "-1",
            -1,
        ]
        if ip_protocol not in supported_protocols and (
            not "{}".format(ip_protocol).isdigit() or int(ip_protocol) &gt; 255
        ):
            raise SaltInvocationError(
                "Invalid ip_protocol {} specified in security group rule.".format(
                    ip_protocol
                )
            )
        if ip_protocol == "all":
            rule["ip_protocol"] = "-1"
        cidr_ip = rule.get("cidr_ip", None)
        group_name = rule.get("source_group_name", None)
        group_id = rule.get("source_group_group_id", None)
        if cidr_ip and (group_id or group_name):
            raise SaltInvocationError(
                "cidr_ip and source groups can not both"
                " be specified in security group rules."
            )
        if group_id and group_name:
            raise SaltInvocationError(
                "Either source_group_group_id or"
                " source_group_name can be specified in"
                " security group rules, but not both."
            )
        if not (cidr_ip or group_id or group_name):
            raise SaltInvocationError(
                "cidr_ip, source_group_group_id, or"
                " source_group_name must be provided for"
                " security group rules."
            )
        rule_found = False
        for _rule in _rules:
            if _check_rule(rule, _rule):
                rule_found = True
                break
        if not rule_found:
            to_create.append(rule)
    for _rule in _rules:
        rule_found = False
        for rule in rules:
            if _check_rule(rule, _rule):
                rule_found = True
                break
        if not rule_found:
            _rule.pop("source_group_name", None)
            to_delete.append(_rule)
    log.debug("Rules to be deleted: %s", to_delete)
    log.debug("Rules to be created: %s", to_create)
    return (to_delete, to_create)
def _rules_present(
    name,
    rules,
    delete_ingress_rules=True,
    vpc_id=None,
    vpc_name=None,
    region=None,
    key=None,
    keyid=None,
    profile=None,
):
    """
    given a group name or group name and vpc_id (or vpc name):
    1. get lists of desired rule changes (using _get_rule_changes)
    2. authorize/create rules missing rules
    3. if delete_ingress_rules is True, delete/revoke non-requested rules
    4. return 'old' and 'new' group rules
    """
    ret = {"result": True, "comment": "", "changes": {}}
    sg = __salt__["boto_secgroup.get_config"](
        name=name,
        group_id=None,
        region=region,
        key=key,
        keyid=keyid,
        profile=profile,
        vpc_id=vpc_id,
        vpc_name=vpc_name,
    )
    if not sg:
        ret[
            "comment"
        ] = "{} security group configuration could not be retrieved.".format(name)
        ret["result"] = False
        return ret
    rules = _split_rules(rules)
    if vpc_id or vpc_name:
        for rule in rules:
            _source_group_name = rule.get("source_group_name", None)
            if _source_group_name:
                _group_vpc_name = vpc_name
                _group_vpc_id = vpc_id
                _source_group_name_vpc = rule.get("source_group_name_vpc", None)
                if _source_group_name_vpc:
                    _group_vpc_name = _source_group_name_vpc
                    _group_vpc_id = None
                _group_id = __salt__["boto_secgroup.get_group_id"](
                    name=_source_group_name,
                    vpc_id=_group_vpc_id,
                    vpc_name=_group_vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                )
                if not _group_id:
                    raise SaltInvocationError(
                        "source_group_name {} does not map to a valid "
                        "source group id.".format(_source_group_name)
                    )
                rule["source_group_name"] = None
                if _source_group_name_vpc:
                    rule.pop("source_group_name_vpc")
                rule["source_group_group_id"] = _group_id
    to_delete, to_create = _get_rule_changes(rules, sg["rules"])
    to_delete = to_delete if delete_ingress_rules else []
    if to_create or to_delete:
        if __opts__["test"]:
            msg = """Security group {} set to have rules modified.
            To be created: {}
            To be deleted: {}""".format(
                name, pprint.pformat(to_create), pprint.pformat(to_delete)
            )
            ret["comment"] = msg
            ret["result"] = None
            return ret
        if to_delete:
            deleted = True
            for rule in to_delete:
                _deleted = __salt__["boto_secgroup.revoke"](
                    name,
                    vpc_id=vpc_id,
                    vpc_name=vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                    **rule
                )
                if not _deleted:
                    deleted = False
            if deleted:
                ret["comment"] = "Removed rules on {} security group.".format(name)
            else:
                ret["comment"] = "Failed to remove rules on {} security group.".format(
                    name
                )
                ret["result"] = False
        if to_create:
            created = True
            for rule in to_create:
                _created = __salt__["boto_secgroup.authorize"](
                    name,
                    vpc_id=vpc_id,
                    vpc_name=vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                    **rule
                )
                if not _created:
                    created = False
            if created:
                ret["comment"] = " ".join(
                    [
                        ret["comment"],
                        "Created rules on {} security group.".format(name),
                    ]
                )
            else:
                ret["comment"] = " ".join(
                    [
                        ret["comment"],
                        "Failed to create rules on {} security group.".format(name),
                    ]
                )
                ret["result"] = False
        ret["changes"]["old"] = {"rules": sg["rules"]}
        sg = __salt__["boto_secgroup.get_config"](
            name=name,
            group_id=None,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
        )
        ret["changes"]["new"] = {"rules": sg["rules"]}
    return ret
def _rules_egress_present(
    name,
    rules_egress,
    delete_egress_rules=True,
    vpc_id=None,
    vpc_name=None,
    region=None,
    key=None,
    keyid=None,
    profile=None,
):
    """
    given a group name or group name and vpc_id (or vpc name):
    1. get lists of desired rule changes (using _get_rule_changes)
    2. authorize/create missing rules
    3. if delete_egress_rules is True, delete/revoke non-requested rules
    4. return 'old' and 'new' group rules
    """
    ret = {"result": True, "comment": "", "changes": {}}
    sg = __salt__["boto_secgroup.get_config"](
        name=name,
        group_id=None,
        region=region,
        key=key,
        keyid=keyid,
        profile=profile,
        vpc_id=vpc_id,
        vpc_name=vpc_name,
    )
    if not sg:
        ret[
            "comment"
        ] = "{} security group configuration could not be retrieved.".format(name)
        ret["result"] = False
        return ret
    rules_egress = _split_rules(rules_egress)
    if vpc_id or vpc_name:
        for rule in rules_egress:
            _source_group_name = rule.get("source_group_name", None)
            if _source_group_name:
                _group_vpc_name = vpc_name
                _group_vpc_id = vpc_id
                _source_group_name_vpc = rule.get("source_group_name_vpc", None)
                if _source_group_name_vpc:
                    _group_vpc_name = _source_group_name_vpc
                    _group_vpc_id = None
                _group_id = __salt__["boto_secgroup.get_group_id"](
                    name=_source_group_name,
                    vpc_id=_group_vpc_id,
                    vpc_name=_group_vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                )
                if not _group_id:
                    raise SaltInvocationError(
                        "source_group_name {} does not map to a valid "
                        "source group id.".format(_source_group_name)
                    )
                rule["source_group_name"] = None
                if _source_group_name_vpc:
                    rule.pop("source_group_name_vpc")
                rule["source_group_group_id"] = _group_id
    to_delete, to_create = _get_rule_changes(rules_egress, sg["rules_egress"])
    to_delete = to_delete if delete_egress_rules else []
    if to_create or to_delete:
        if __opts__["test"]:
            msg = """Security group {} set to have rules modified.
            To be created: {}
            To be deleted: {}""".format(
                name, pprint.pformat(to_create), pprint.pformat(to_delete)
            )
            ret["comment"] = msg
            ret["result"] = None
            return ret
        if to_delete:
            deleted = True
            for rule in to_delete:
                _deleted = __salt__["boto_secgroup.revoke"](
                    name,
                    vpc_id=vpc_id,
                    vpc_name=vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                    egress=True,
                    **rule
                )
                if not _deleted:
                    deleted = False
            if deleted:
                ret["comment"] = " ".join(
                    [
                        ret["comment"],
                        "Removed egress rule on {} security group.".format(name),
                    ]
                )
            else:
                ret["comment"] = " ".join(
                    [
                        ret["comment"],
                        "Failed to remove egress rule on {} security group.".format(
                            name
                        ),
                    ]
                )
                ret["result"] = False
        if to_create:
            created = True
            for rule in to_create:
                _created = __salt__["boto_secgroup.authorize"](
                    name,
                    vpc_id=vpc_id,
                    vpc_name=vpc_name,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                    egress=True,
                    **rule
                )
                if not _created:
                    created = False
            if created:
                ret["comment"] = " ".join(
                    [
                        ret["comment"],
                        "Created egress rules on {} security group.".format(name),
                    ]
                )
            else:
                ret["comment"] = " ".join(
                    [
                        ret["comment"],
                        "Failed to create egress rules on {} security group.".format(
                            name
                        ),
                    ]
                )
                ret["result"] = False
        ret["changes"]["old"] = {"rules_egress": sg["rules_egress"]}
        sg = __salt__["boto_secgroup.get_config"](
            name=name,
            group_id=None,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
        )
        ret["changes"]["new"] = {"rules_egress": sg["rules_egress"]}
    return ret
def absent(
    name, vpc_id=None, vpc_name=None, region=None, key=None, keyid=None, profile=None
):
    """
    Ensure a security group with the specified name does not exist.
    name
        Name of the security group.
    vpc_id
        The ID of the VPC to remove the security group from, if any. Exclusive with vpc_name.
    vpc_name
        The name of the VPC to remove the security group from, if any. Exclusive with vpc_name.
        .. versionadded:: 2016.3.0
    region
        Region to connect to.
    key
        Secret key to be used.
    keyid
        Access key to be used.
    profile
        A dict with region, key and keyid, or a pillar key (string)
        that contains a dict with region, key and keyid.
        .. versionadded:: 2016.3.0
    """
    ret = {"name": name, "result": True, "comment": "", "changes": {}}
    sg = __salt__["boto_secgroup.get_config"](
        name=name,
        group_id=None,
        region=region,
        key=key,
        keyid=keyid,
        profile=profile,
        vpc_id=vpc_id,
        vpc_name=vpc_name,
    )
    if sg:
        if __opts__["test"]:
            ret["comment"] = "Security group {} is set to be removed.".format(name)
            ret["result"] = None
            return ret
        deleted = __salt__["boto_secgroup.delete"](
            name=name,
            group_id=None,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
        )
        if deleted:
            ret["changes"]["old"] = {"secgroup": sg}
            ret["changes"]["new"] = {"secgroup": None}
            ret["comment"] = "Security group {} deleted.".format(name)
        else:
            ret["result"] = False
            ret["comment"] = "Failed to delete {} security group.".format(name)
    else:
        ret["comment"] = "{} security group does not exist.".format(name)
    return ret
def _tags_present(
    name,
    tags,
    vpc_id=None,
    vpc_name=None,
    region=None,
    key=None,
    keyid=None,
    profile=None,
):
    """
    helper function to validate tags are correct
    """
    ret = {"result": True, "comment": "", "changes": {}}
    if tags:
        sg = __salt__["boto_secgroup.get_config"](
            name=name,
            group_id=None,
            region=region,
            key=key,
            keyid=keyid,
            profile=profile,
            vpc_id=vpc_id,
            vpc_name=vpc_name,
        )
        if not sg:
            ret[
                "comment"
            ] = "{} security group configuration could not be retrieved.".format(name)
            ret["result"] = False
            return ret
        tags_to_add = tags
        tags_to_update = {}
        tags_to_remove = []
        if sg.get("tags"):
            for existing_tag in sg["tags"]:
                if existing_tag not in tags:
                    if existing_tag not in tags_to_remove:
                        tags_to_remove.append(existing_tag)
                else:
                    if tags[existing_tag] != sg["tags"][existing_tag]:
                        tags_to_update[existing_tag] = tags[existing_tag]
                    tags_to_add.pop(existing_tag)
        if tags_to_remove:
            if __opts__["test"]:
                msg = "The following tag{} set to be removed: {}.".format(
                    ("s are" if len(tags_to_remove) &gt; 1 else " is"),
                    ", ".join(tags_to_remove),
                )
                ret["comment"] = " ".join([ret["comment"], msg])
                ret["result"] = None
            else:
                temp_ret = __salt__["boto_secgroup.delete_tags"](
                    tags_to_remove,
                    name=name,
                    group_id=None,
                    vpc_name=vpc_name,
                    vpc_id=vpc_id,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=profile,
                )
                if not temp_ret:
                    ret["result"] = False
                    ret["comment"] = " ".join(
                        [
                            ret["comment"],
                            "Error attempting to delete tags {}.".format(
                                tags_to_remove
                            ),
                        ]
                    )
                    return ret
                if "old" not in ret["changes"]:
                    ret["changes"] = dictupdate.update(
                        ret["changes"], {"old": {"tags": {}}}
                    )
                for rem_tag in tags_to_remove:
                    ret["changes"]["old"]["tags"][rem_tag] = sg["tags"][rem_tag]
        if tags_to_add or tags_to_update:
            if __opts__["test"]:
                if tags_to_add:
                    msg = "The following tag{} set to be added: {}.".format(
                        ("s are" if len(tags_to_add.keys()) &gt; 1 else " is"),
                        ", ".join(tags_to_add.keys()),
                    )
                    ret["comment"] = " ".join([ret["comment"], msg])
                    ret["result"] = None
                if tags_to_update:
                    msg = "The following tag {} set to be updated: {}.".format(
                        (
                            "values are"
                            if len(tags_to_update.keys()) &gt; 1
                            else "value is"
                        ),
                        ", ".join(tags_to_update.keys()),
                    )
                    ret["result"] = None
            else:
                all_tag_changes = dictupdate<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>.update(tags_to_add, tags_to_update)
                temp_ret = __salt__["boto_secgroup.set_tags"](
                    all_tag_changes,
                    name=name,
                    group_id=None,
                    vpc_name=vpc_name,
                    vpc_id=vpc_id,
                    region=region,
                    key=key,
                    keyid=keyid,
                    profile=</b></font>profile,
                )
                if not temp_ret:
                    ret["result"] = False
                    msg = "Error attempting to set tags."
                    ret["comment"] = " ".join([ret["comment"], msg])
                    return ret
                if "old" not in ret["changes"]:
                    ret["changes"] = dictupdate.update(
                        ret["changes"], {"old": {"tags": {}}}
                    )
                if "new" not in ret["changes"]:
                    ret["changes"] = dictupdate.update(
                        ret["changes"], {"new": {"tags": {}}}
                    )
                for tag in all_tag_changes:
                    ret["changes"]["new"]["tags"][tag] = tags[tag]
                    if "tags" in sg:
                        if sg["tags"]:
                            if tag in sg["tags"]:
                                ret["changes"]["old"]["tags"][tag] = sg["tags"][tag]
        if not tags_to_update and not tags_to_remove and not tags_to_add:
            ret["comment"] = " ".join([ret["comment"], "Tags are already set."])
    return ret
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
