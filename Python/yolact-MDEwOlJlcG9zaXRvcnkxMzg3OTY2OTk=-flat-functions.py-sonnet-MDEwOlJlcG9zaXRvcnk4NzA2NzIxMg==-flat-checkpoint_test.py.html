
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 1.9138755980861244%, Tokens: 10</h2>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-functions.py</h3>
            <pre><code><span onclick='openModal()' class='match'>1  import torch
2  import torch.nn as nn
3  import os
4  import math
5  from collections import deque
6  from pathlib import Path
7  from layers.interpolate import InterpolateModule
8  class MovingAverage():
9      def __init__(self, max_window_size=1000):
</span>10          self.max_window_size = max_window_size
11          self.reset()
12      def add(self, elem):
13          if not math.isfinite(elem):
14              print('Warning: Moving average ignored a value of %f' % elem)
15              return
16          self.window.append(elem)
17          self.sum += elem
18          if len(self.window) > self.max_window_size:
19              self.sum -= self.window.popleft()
20      def append(self, elem):
21          self.add(elem)
22      def reset(self):
23          self.window = deque()
24          self.sum = 0
25      def get_avg(self):
26          return self.sum / max(len(self.window), 1)
27      def __str__(self):
28          return str(self.get_avg())
29      def __repr__(self):
30          return repr(self.get_avg())
31      def __len__(self):
32          return len(self.window)
33  class ProgressBar():
34      def __init__(self, length, max_val):
35          self.max_val = max_val
36          self.length = length
37          self.cur_val = 0
38          self.cur_num_bars = -1
39          self._update_str()
40      def set_val(self, new_val):
41          self.cur_val = new_val
42          if self.cur_val > self.max_val:
43              self.cur_val = self.max_val
44          if self.cur_val < 0:
45              self.cur_val = 0
46          self._update_str()
47      def is_finished(self):
48          return self.cur_val == self.max_val
49      def _update_str(self):
50          num_bars = int(self.length * (self.cur_val / self.max_val))
51          if num_bars != self.cur_num_bars:
52              self.cur_num_bars = num_bars
53              self.string = '█' * num_bars + '░' * (self.length - num_bars)
54      def __repr__(self):
55          return self.string
56      def __str__(self):
57          return self.string
58  def init_console():
59      if os.name == 'nt':
60          from colorama import init
61          init()
62  class SavePath:
63      def __init__(self, model_name:str, epoch:int, iteration:int):
64          self.model_name = model_name
65          self.epoch = epoch
66          self.iteration = iteration
67      def get_path(self, root:str=''):
68          file_name = self.model_name + '_' + str(self.epoch) + '_' + str(self.iteration) + '.pth'
69          return os.path.join(root, file_name)
70      @staticmethod
71      def from_str(path:str):
72          file_name = os.path.basename(path)
73          if file_name.endswith('.pth'):
74              file_name = file_name[:-4]
75          params = file_name.split('_')
76          if file_name.endswith('interrupt'):
77              params = params[:-1]
78          model_name = '_'.join(params[:-2])
79          epoch = params[-2]
80          iteration = params[-1]
81          return SavePath(model_name, int(epoch), int(iteration))
82      @staticmethod
83      def remove_interrupt(save_folder):
84          for p in Path(save_folder).glob('*_interrupt.pth'):
85              p.unlink()
86      @staticmethod
87      def get_interrupt(save_folder):
88          for p in Path(save_folder).glob('*_interrupt.pth'): 
89              return str(p)
90          return None
91      @staticmethod
92      def get_latest(save_folder, config):
93          max_iter = -1
94          max_name = None
95          for p in Path(save_folder).glob(config + '_*'):
96              path_name = str(p)
97              try:
98                  save = SavePath.from_str(path_name)
99              except:
100                  continue 
101              if save.model_name == config and save.iteration > max_iter:
102                  max_iter = save.iteration
103                  max_name = path_name
104          return max_name
105  def make_net(in_channels, conf, include_last_relu=True):
106      def make_layer(layer_cfg):
107          nonlocal in_channels
108          if isinstance(layer_cfg[0], str):
109              layer_name = layer_cfg[0]
110              if layer_name == 'cat':
111                  nets = [make_net(in_channels, x) for x in layer_cfg[1]]
112                  layer = Concat([net[0] for net in nets], layer_cfg[2])
113                  num_channels = sum([net[1] for net in nets])
114          else:
115              num_channels = layer_cfg[0]
116              kernel_size = layer_cfg[1]
117              if kernel_size > 0:
118                  layer = nn.Conv2d(in_channels, num_channels, kernel_size, **layer_cfg[2])
119              else:
120                  if num_channels is None:
121                      layer = InterpolateModule(scale_factor=-kernel_size, mode='bilinear', align_corners=False, **layer_cfg[2])
122                  else:
123                      layer = nn.ConvTranspose2d(in_channels, num_channels, -kernel_size, **layer_cfg[2])
124          in_channels = num_channels if num_channels is not None else in_channels
125          return [layer, nn.ReLU(inplace=True)]
126      net = sum([make_layer(x) for x in conf], [])
127      if not include_last_relu:
128          net = net[:-1]
129      return nn.Sequential(*(net)), in_channels
</code></pre>
        </div>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-checkpoint_test.py</h3>
            <pre><code>1  import os
2  from absl import logging
3  from absl.testing import absltest
<span onclick='openModal()' class='match'>4  from absl.testing import parameterized
5  from sonnet.src import test_utils
6  from sonnet.src.conformance import goldens
7  from sonnet.src.distribute import replicator as snt_replicator
8  from sonnet.src.distribute import replicator_test_utils as replicator_utils
9  import tensorflow as tf
10  import tree
11  class TestCheckpoint:
12    def __init__(self, golden=None, **kwargs):
</span>13      if golden is None:
14        root = absltest.get_default_test_tmpdir()
15      else:
16        root = os.path.join(
17            "sonnet/src/conformance/checkpoints/", golden.name)
18      self._root = root
19      self._prefix = os.path.join(self._root, "checkpoint")
20      self._checkpoint = tf.train.Checkpoint(**kwargs)
21    def save(self):
22      self._checkpoint.save(file_prefix=self._prefix)
23    def restore_latest(self, assert_consumed):
24      status = self._checkpoint.restore(tf.train.latest_checkpoint(self._root))
25      if assert_consumed:
26        status.assert_consumed()
27      return status
28  def with_soft_placement(f):
29    def wrapper(*a, **k):
30      with tf.device(None):
31        return f(*a, **k)
32    return wrapper
33  class GoldenCheckpointsTest(test_utils.TestCase, parameterized.TestCase):
34    @goldens.all_goldens
35    def test_save_load(self, golden):
36      module = golden.create_module()
37      checkpoint = TestCheckpoint(module=module)
38      all_variables = golden.create_all_variables(module)
39      self.assertNotEmpty(all_variables)
40      self.assertEqual(all_variables, module.variables)
41      for variable in all_variables:
42        variable.assign(goldens.range_like(variable))
43      checkpoint.save()
44      old_y = golden.forward(module)
45      for variable in all_variables:
46        variable.assign(tf.ones_like(variable))
47      checkpoint.restore_latest(assert_consumed=True)
48      for variable in all_variables:
49        self.assertAllClose(
50            variable.read_value(),
51            goldens.range_like(variable),
52            msg=variable.name)
53      if golden.deterministic:
54        tree.map_structure(self.assertAllClose, golden.forward(module), old_y)
55    @goldens.all_goldens
56    def test_save_then_load_new_instance(self, golden):
57      module_1 = golden.create_module()
58      checkpoint_1 = TestCheckpoint(module=module_1)
59      variables_1 = golden.create_all_variables(module_1)
60      module_2 = golden.create_module()
61      checkpoint_2 = TestCheckpoint(module=module_2)
62      variables_2 = golden.create_all_variables(module_2)
63      for v1, v2 in zip(variables_1, variables_2):
64        v1.assign(goldens.range_like(v1))
65        v2.assign(tf.ones_like(v2))
66      checkpoint_1.save()
67      checkpoint_2.restore_latest(assert_consumed=True)
68      for variable in variables_2:
69        self.assertAllClose(
70            variable.read_value(),
71            goldens.range_like(variable),
72            msg=variable.name)
73      if golden.deterministic:
74        tree.map_structure(self.assertAllClose, golden.forward(module_1),
75                           golden.forward(module_2))
76    @goldens.all_goldens
77    def test_restore_on_create(self, golden):
78      module_1 = golden.create_module()
79      checkpoint_1 = TestCheckpoint(module=module_1)
80      variables_1 = golden.create_all_variables(module_1)
81      for variable in variables_1:
82        variable.assign(goldens.range_like(variable))
83      checkpoint_1.save()
84      golden.forward(module_1)
85      module_2 = golden.create_module()
86      checkpoint_2 = TestCheckpoint(module=module_2)
87      status = checkpoint_2.restore_latest(assert_consumed=False)
88      variables_2 = golden.create_all_variables(module_2)
89      status.assert_consumed()
90      for var1, var2 in zip(variables_1, variables_2):
91        self.assertAllEqual(var1.read_value(), var2.read_value(), msg=var1.name)
92      if golden.deterministic:
93        tree.map_structure(self.assertAllClose, golden.forward(module_1),
94                           golden.forward(module_2))
95    @goldens.all_goldens
96    def test_restore_golden(self, golden):
97      module = golden.create_module()
98      checkpoint = TestCheckpoint(golden=golden, module=module)
99      variables = golden.create_all_variables(module)
100      for variable in variables:
101        variable.assign(tf.zeros_like(variable))
102      checkpoint.restore_latest(assert_consumed=True)
103      for variable in variables:
104        self.assertAllEqual(
105            variable.read_value(),
106            goldens.range_like(variable),
107            msg=variable.name)
108  class ReplicatorCheckpointTest(test_utils.TestCase, parameterized.TestCase):
109    def replicator_or_skip(self, replicator_fn, use_function):
110      replicator = replicator_fn()
111      if not use_function and isinstance(replicator,
112                                         snt_replicator.TpuReplicator):
113        self.skipTest("TpuReplicator does not support eager mode.")
114      return replicator
115    @test_utils.combined_named_parameters(goldens.named_goldens(),
116                                          replicator_utils.named_replicators(),
117                                          test_utils.named_bools("use_function"))
118    def test_save_restore(self, golden, replicator_fn, use_function):
119      replicator = self.replicator_or_skip(replicator_fn, use_function)
120      with replicator.scope():
121        module = golden.create_module()
122        variables = golden.create_all_variables(module)
123      def forward():
124        per_replica = replicator.run(
125            lambda: golden.forward(module))
126        return tree.map_structure(
127            lambda args: tf.stack(replicator.unwrap(args), axis=0), per_replica)
128      if use_function:
129        forward = tf.function(forward)
130        if self.primary_device == "TPU":
131          forward = with_soft_placement(forward)
132      for index, variable in enumerate(variables):
133        variable.assign(goldens.range_like(variable, start=index))
134      checkpoint = TestCheckpoint(module=module)
135      checkpoint.save()
136      before_save_ys = forward()
137      for variable in variables:
138        variable.assign(-tf.ones_like(variable))
139      if golden.deterministic:
140        y = forward()
141        self.assertNotAllClose(y, before_save_ys)
142      checkpoint.restore_latest(assert_consumed=True)
143      for index, variable in enumerate(variables):
144        self.assertAllEqual(
145            variable.read_value(),
146            goldens.range_like(variable, start=index),
147            msg=variable.name)
148      if golden.deterministic:
149        tree.map_structure(self.assertAllEqual, forward(), before_save_ys)
150    @test_utils.combined_named_parameters(goldens.named_goldens(),
151                                          replicator_utils.named_replicators())
152    def test_restore_from_golden(self, golden, replicator_fn):
153      replicator = self.replicator_or_skip(replicator_fn, use_function=False)
154      with replicator.scope():
155        module = golden.create_module()
156        variables = golden.create_all_variables(module)
157      checkpoint = TestCheckpoint(golden=golden, module=module)
158      checkpoint.restore_latest(assert_consumed=True)
159      for variable in variables:
160        self.assertAllEqual(
161            variable.read_value(),
162            goldens.range_like(variable),
163            msg=variable.name)
164    @test_utils.combined_named_parameters(goldens.named_goldens(),
165                                          replicator_utils.named_replicators(),
166                                          test_utils.named_bools("use_function"))
167    def test_restore_from_non_distributed(self, golden, replicator_fn,
168                                          use_function):
169      replicator = self.replicator_or_skip(replicator_fn, use_function)
170      module = golden.create_module()
171      normal_variables = golden.create_all_variables(module)
172      for index, variable in enumerate(normal_variables):
173        variable.assign(goldens.range_like(variable, start=(index + 1)))
174      checkpoint = TestCheckpoint(module=module)
175      checkpoint.save()
176      with replicator.scope():
177        module2 = golden.create_module()
178        replicator_variables = golden.create_all_variables(module2)
179      for normal, distributed in zip(normal_variables, replicator_variables):
180        distributed.assign(tf.zeros_like(distributed))
181        self.assertNotAllClose(normal.read_value(), distributed.read_value())
182      checkpoint = TestCheckpoint(module=module2)
183      checkpoint.restore_latest(assert_consumed=True)
184      for normal, distributed in zip(normal_variables, replicator_variables):
185        self.assertAllEqual(
186            normal.read_value(), distributed.read_value(), msg=normal.name)
187      if golden.deterministic:
188        def run_forward(module):
189          forward = lambda: golden.forward(module)
190          if use_function:
191            forward = tf.function(forward)
192            if self.primary_device == "TPU":
193              forward = with_soft_placement(forward)
194          return forward()
195        y_before = run_forward(module)
196        y_after = run_forward(module2)
197        tree.map_structure(self.assertAllEqual, y_before, y_after)
198    @test_utils.combined_named_parameters(goldens.named_goldens(),
199                                          replicator_utils.named_replicators())
200    def test_restore_on_create(self, golden, replicator_fn):
201      replicator = self.replicator_or_skip(replicator_fn, use_function=False)
202      module = golden.create_module()
203      normal_variables = golden.create_all_variables(module)
204      for index, variable in enumerate(normal_variables):
205        variable.assign(goldens.range_like(variable, start=(index + 1)))
206      checkpoint = TestCheckpoint(module=module)
207      checkpoint.save()
208      golden.forward(module)
209      with replicator.scope():
210        module = golden.create_module()
211        checkpoint = TestCheckpoint(module=module)
212        status = checkpoint.restore_latest(assert_consumed=False)
213        golden.forward(module)
214        status.assert_consumed()
215        replicator_variables = module.variables
216      for normal, distributed in zip(normal_variables, replicator_variables):
217        self.assertAllEqual(
218            normal.read_value(), distributed.read_value(), msg=normal.name)
219    @test_utils.combined_named_parameters(goldens.named_goldens(),
220                                          replicator_utils.named_replicators(),
221                                          test_utils.named_bools("use_function"))
222    def test_restore_on_create_in_replica_context(self, golden, replicator_fn,
223                                                  use_function):
224      replicator = self.replicator_or_skip(replicator_fn, use_function)
225      module = golden.create_module()
226      normal_variables = golden.create_all_variables(module)
227      for index, variable in enumerate(normal_variables):
228        variable.assign(goldens.range_like(variable, start=(index + 1)))
229      checkpoint = TestCheckpoint(module=module)
230      checkpoint.save()
231      golden.forward(module)
232      with replicator.scope():
233        module = golden.create_module()
234      def forward():
235        return replicator.run(lambda: golden.forward(module))
236      if use_function:
237        forward = tf.function(forward)
238        if self.primary_device == "TPU":
239          forward = with_soft_placement(forward)
240      checkpoint = TestCheckpoint(module=module)
241      status = checkpoint.restore_latest(assert_consumed=False)
242      result = forward()
243      status.assert_consumed()
244      if golden.deterministic:
245        result_iter = iter(replicator.experimental_local_results(result))
246        first_replica = next(result_iter)
247        for next_replica in result_iter:
248          tree.map_structure(self.assertAllEqual, first_replica, next_replica)
249      if not golden.has_side_effects:
250        replicator_variables = module.variables
251        for normal, distributed in zip(normal_variables, replicator_variables):
252          self.assertAllClose(
253              normal.read_value(), distributed.read_value(), msg=normal.name)
254  def setUpModule():
255    gpus = tf.config.experimental.list_physical_devices(device_type="GPU")
256    if len(gpus) == 1:
257      logging.info("Splitting one physical GPU into two logical GPUs.")
258      tf.config.experimental.set_virtual_device_configuration(
259          gpus[0], [
260              tf.config.experimental.VirtualDeviceConfiguration(
261                  memory_limit=1024),
262              tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)
263          ])
264  if __name__ == "__main__":
265    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-functions.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-checkpoint_test.py</div>
                </div>
                <div class="column column_space"><pre><code>1  import torch
2  import torch.nn as nn
3  import os
4  import math
5  from collections import deque
6  from pathlib import Path
7  from layers.interpolate import InterpolateModule
8  class MovingAverage():
9      def __init__(self, max_window_size=1000):
</pre></code></div>
                <div class="column column_space"><pre><code>4  from absl.testing import parameterized
5  from sonnet.src import test_utils
6  from sonnet.src.conformance import goldens
7  from sonnet.src.distribute import replicator as snt_replicator
8  from sonnet.src.distribute import replicator_test_utils as replicator_utils
9  import tensorflow as tf
10  import tree
11  class TestCheckpoint:
12    def __init__(self, golden=None, **kwargs):
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    