
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 17.799158147925436%, Tokens: 11</h2>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-multibox_loss.py</h3>
            <pre><code>1  import torch
2  import torch.nn as nn
3  import torch.nn.functional as F
4  from torch.autograd import Variable
5  from ..box_utils import match, log_sum_exp, decode, center_size, crop, elemwise_mask_iou, elemwise_box_iou
6  from data import cfg, mask_type, activation_func
7  class MultiBoxLoss(nn.Module):
8      def __init__(self, num_classes, pos_threshold, neg_threshold, negpos_ratio):
9          super(MultiBoxLoss, self).__init__()
10          self.num_classes = num_classes
11          self.pos_threshold = pos_threshold
12          self.neg_threshold = neg_threshold
13          self.negpos_ratio = negpos_ratio
14          self.l1_expected_area = 20*20/70/70
15          self.l1_alpha = 0.1
16          if cfg.use_class_balanced_conf:
17              self.class_instances = None
18              self.total_instances = 0
19      def forward(self, net, predictions, targets, masks, num_crowds):
20          loc_data  = predictions['loc']
21          conf_data = predictions['conf']
22          mask_data = predictions['mask']
23          priors    = predictions['priors']
24          if cfg.mask_type == mask_type.lincomb:
25              proto_data = predictions['proto']
26          score_data = predictions['score'] if cfg.use_mask_scoring   else None   
27          inst_data  = predictions['inst']  if cfg.use_instance_coeff else None
28          labels = [None] * len(targets) # Used in sem segm loss
29          batch_size = loc_data.size(0)
30          num_priors = priors.size(0)
31          num_classes = self.num_classes
32          loc_t = loc_data.new(batch_size, num_priors, 4)
33          gt_box_t = loc_data.new(batch_size, num_priors, 4)
34          conf_t = loc_data.new(batch_size, num_priors).long()
35          idx_t = loc_data.new(batch_size, num_priors).long()
36          if cfg.use_class_existence_loss:
37              class_existence_t = loc_data.new(batch_size, num_classes-1)
38          for idx in range(batch_size):
39              truths      = targets[idx][:, :-1].data
40              labels[idx] = targets[idx][:, -1].data.long()
41              if cfg.use_class_existence_loss:
42                  class_existence_t[idx, :] = torch.eye(num_classes-1, device=conf_t.get_device())[labels[idx]].max(dim=0)[0]
43              cur_crowds = num_crowds[idx]
44              if cur_crowds > 0:
45                  split = lambda x: (x[-cur_crowds:], x[:-cur_crowds])
46                  crowd_boxes, truths = split(truths)
47                  _, labels[idx] = split(labels[idx])
48                  _, masks[idx]  = split(masks[idx])
49              else:
50                  crowd_boxes = None
51              match(self.pos_threshold, self.neg_threshold,
52                    truths, priors.data, labels[idx], crowd_boxes,
53                    loc_t, conf_t, idx_t, idx, loc_data[idx])
54              gt_box_t[idx, :, :] = truths[idx_t[idx]]
55          loc_t = Variable(loc_t, requires_grad=False)
56          conf_t = Variable(conf_t, requires_grad=False)
57          idx_t = Variable(idx_t, requires_grad=False)
58          pos = conf_t > 0
59          num_pos = pos.sum(dim=1, keepdim=True)
60          pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)
61          losses = {}
62          if cfg.train_boxes:
63              loc_p = loc_data[pos_idx].view(-1, 4)
64              loc_t = loc_t[pos_idx].view(-1, 4)
65              losses['B'] = F.smooth_l1_loss(loc_p, loc_t, reduction='sum') * cfg.bbox_alpha
66          if cfg.train_masks:
67              if cfg.mask_type == mask_type.direct:
68                  if cfg.use_gt_bboxes:
69                      pos_masks = []
70                      for idx in range(batch_size):
71                          pos_masks.append(masks[idx][idx_t[idx, pos[idx]]])
72                      masks_t = torch.cat(pos_masks, 0)
73                      masks_p = mask_data[pos, :].view(-1, cfg.mask_dim)
74                      losses['M'] = F.binary_cross_entropy(torch.clamp(masks_p, 0, 1), masks_t, reduction='sum') * cfg.mask_alpha
75                  else:
76                      losses['M'] = self.direct_mask_loss(pos_idx, idx_t, loc_data, mask_data, priors, masks)
77              elif cfg.mask_type == mask_type.lincomb:
78                  ret = self.lincomb_mask_loss(pos, idx_t, loc_data, mask_data, priors, proto_data, masks, gt_box_t, score_data, inst_data, labels)
79                  if cfg.use_maskiou:
80                      loss, maskiou_targets = ret
81                  else:
82                      loss = ret
83                  losses.update(loss)
84                  if cfg.mask_proto_loss is not None:
85                      if cfg.mask_proto_loss == 'l1':
86                          losses['P'] = torch.mean(torch.abs(proto_data)) / self.l1_expected_area * self.l1_alpha
87                      elif cfg.mask_proto_loss == 'disj':
88                          losses['P'] = -torch.mean(torch.max(F.log_softmax(proto_data, dim=-1), dim=-1)[0])
89          if cfg.use_focal_loss:
90              if cfg.use_sigmoid_focal_loss:
91                  losses['C'] = self.focal_conf_sigmoid_loss(conf_data, conf_t)
92              elif cfg.use_objectness_score:
93                  losses['C'] = self.focal_conf_objectness_loss(conf_data, conf_t)
94              else:
95                  losses['C'] = self.focal_conf_loss(conf_data, conf_t)
96          else:
97              if cfg.use_objectness_score:
98                  losses['C'] = self.conf_objectness_loss(conf_data, conf_t, batch_size, loc_p, loc_t, priors)
99              else:
100                  losses['C'] = self.ohem_conf_loss(conf_data, conf_t, pos, batch_size)
101          if cfg.use_maskiou and maskiou_targets is not None:
102              losses['I'] = self.mask_iou_loss(net, maskiou_targets)
103          if cfg.use_class_existence_loss:
104              losses['E'] = self.class_existence_loss(predictions['classes'], class_existence_t)
105          if cfg.use_semantic_segmentation_loss:
106              losses['S'] = self.semantic_segmentation_loss(predictions['segm'], masks, labels)
107          total_num_pos = num_pos.data.sum().float()
108          for k in losses:
109              if k not in ('P', 'E', 'S'):
110                  losses[k] /= total_num_pos
111              else:
112                  losses[k] /= batch_size
113          return losses
114      def class_existence_loss(self, class_data, class_existence_t):
115          return cfg.class_existence_alpha * F.binary_cross_entropy_with_logits(class_data, class_existence_t, reduction='sum')
116      def semantic_segmentation_loss(self, segment_data, mask_t, class_t, interpolation_mode='bilinear'):
117          batch_size, num_classes, mask_h, mask_w = segment_data.size()
118          loss_s = 0
119          for idx in range(batch_size):
120              cur_segment = segment_data[idx]
121              cur_class_t = class_t[idx]
122              with torch.no_grad():
123                  downsampled_masks = F.interpolate(mask_t[idx].unsqueeze(0), (mask_h, mask_w),
124                                                    mode=interpolation_mode, align_corners=False).squeeze(0)
125                  downsampled_masks = downsampled_masks.gt(0.5).float()
126                  segment_t = torch.zeros_like(cur_segment, requires_grad=False)
127                  for obj_idx in range(downsampled_masks.size(0)):
128                      segment_t[cur_class_t[obj_idx]] = torch.max(segment_t[cur_class_t[obj_idx]], downsampled_masks[obj_idx])
129              loss_s += F.binary_cross_entropy_with_logits(cur_segment, segment_t, reduction='sum')
130          return loss_s / mask_h / mask_w * cfg.semantic_segmentation_alpha
131      def ohem_conf_loss(self, conf_data, conf_t, pos, num):
132          batch_conf = conf_data.view(-1, self.num_classes)
133          if cfg.ohem_use_most_confident:
134              batch_conf = F.softmax(batch_conf, dim=1)
135              loss_c, _ = batch_conf[:, 1:].max(dim=1)
136          else:
137              loss_c = log_sum_exp(batch_conf) - batch_conf[:, 0]
138          loss_c = loss_c.view(num, -1)
139          loss_c[pos]        = 0 # filter out pos boxes
140          loss_c[conf_t < 0] = 0 # filter out neutrals (conf_t = -1)
141          _, loss_idx = loss_c.sort(1, descending=True)
142          _, idx_rank = loss_idx.sort(1)
143          num_pos = pos.long().sum(1, keepdim=True)
144          num_neg = torch.clamp(self.negpos_ratio*num_pos, max=pos.size(1)-1)
145          neg = idx_rank < num_neg.expand_as(idx_rank)
146          neg[pos]        = 0
147          neg[conf_t < 0] = 0 # Filter out neutrals
148          pos_idx = pos.unsqueeze(2).expand_as(conf_data)
149          neg_idx = neg.unsqueeze(2).expand_as(conf_data)
150          conf_p = conf_data[(pos_idx+neg_idx).gt(0)].view(-1, self.num_classes)
151          targets_weighted = conf_t[(pos+neg).gt(0)]
152          loss_c = F.cross_entropy(conf_p, targets_weighted, reduction='none')
153          if cfg.use_class_balanced_conf:
154              if self.class_instances is None:
155                  self.class_instances = torch.zeros(self.num_classes, device=targets_weighted.device)
156              classes, counts = targets_weighted.unique(return_counts=True)
157              for _cls, _cnt in zip(classes.cpu().numpy(), counts.cpu().numpy()):
158                  self.class_instances[_cls] += _cnt
159              self.total_instances += targets_weighted.size(0)
160              weighting = 1 - (self.class_instances[targets_weighted] / self.total_instances)
161              weighting = torch.clamp(weighting, min=1/self.num_classes)
162              avg_weight = (self.num_classes - 1) / self.num_classes
163              loss_c = (loss_c * weighting).sum() / avg_weight
164          else:
165              loss_c = loss_c.sum()
166          return cfg.conf_alpha * loss_c
167      def focal_conf_loss(self, conf_data, conf_t):
168          conf_t = conf_t.view(-1) # [batch_size*num_priors]
169          conf_data = conf_data.view(-1, conf_data.size(-1)) # [batch_size*num_priors, num_classes]
170          keep = (conf_t >= 0).float()
171          conf_t[conf_t < 0] = 0 # so that gather doesn't drum up a fuss
172          logpt = F.log_softmax(conf_data, dim=-1)
173          logpt = logpt.gather(1, conf_t.unsqueeze(-1))
174          logpt = logpt.view(-1)
175          pt    = logpt.exp()
176          background = (conf_t == 0).float()
177          at = (1 - cfg.focal_loss_alpha) * background + cfg.focal_loss_alpha * (1 - background)
178          loss = -at * (1 - pt) ** cfg.focal_loss_gamma * logpt
179          return cfg.conf_alpha * (loss * keep).sum()
180      def focal_conf_sigmoid_loss(self, conf_data, conf_t):
181          num_classes = conf_data.size(-1)
182          conf_t = conf_t.view(-1) # [batch_size*num_priors]
183          conf_data = conf_data.view(-1, num_classes) # [batch_size*num_priors, num_classes]
184          keep = (conf_t >= 0).float()
185          conf_t[conf_t < 0] = 0 # can't mask with -1, so filter that out
186          conf_one_t = torch.eye(num_classes, device=conf_t.get_device())[conf_t]
187          conf_pm_t  = conf_one_t * 2 - 1 # -1 if background, +1 if forground for specific class
188          logpt = F.logsigmoid(conf_data * conf_pm_t) # note: 1 - sigmoid(x) = sigmoid(-x)
189          pt    = logpt.exp()
190          at = cfg.focal_loss_alpha * conf_one_t + (1 - cfg.focal_loss_alpha) * (1 - conf_one_t)
191          at[..., 0] = 0 # Set alpha for the background class to 0 because sigmoid focal loss doesn't use it
192          loss = -at * (1 - pt) ** cfg.focal_loss_gamma * logpt
193          loss = keep * loss.sum(dim=-1)
194          return cfg.conf_alpha * loss.sum()
195      def focal_conf_objectness_loss(self, conf_data, conf_t):
196          conf_t = conf_t.view(-1) # [batch_size*num_priors]
197          conf_data = conf_data.view(-1, conf_data.size(-1)) # [batch_size*num_priors, num_classes]
198          keep = (conf_t >= 0).float()
199          conf_t[conf_t < 0] = 0 # so that gather doesn't drum up a fuss
200          background = (conf_t == 0).float()
201          at = (1 - cfg.focal_loss_alpha) * background + cfg.focal_loss_alpha * (1 - background)
202          logpt = F.logsigmoid(conf_data[:, 0]) * (1 - background) + F.logsigmoid(-conf_data[:, 0]) * background
203          pt    = logpt.exp()
204          obj_loss = -at * (1 - pt) ** cfg.focal_loss_gamma * logpt
205          pos_mask = conf_t > 0
206          conf_data_pos = (conf_data[:, 1:])[pos_mask] # Now this has just 80 classes
207          conf_t_pos    = conf_t[pos_mask] - 1         # So subtract 1 here
208          class_loss = F.cross_entropy(conf_data_pos, conf_t_pos, reduction='sum')
209          return cfg.conf_alpha * (class_loss + (obj_loss * keep).sum())
210      def conf_objectness_loss(self, conf_data, conf_t, batch_size, loc_p, loc_t, priors):
211          conf_t = conf_t.view(-1) # [batch_size*num_priors]
212          conf_data = conf_data.view(-1, conf_data.size(-1)) # [batch_size*num_priors, num_classes]
213          pos_mask = (conf_t > 0)
214          neg_mask = (conf_t == 0)
215          obj_data = conf_data[:, 0]
216          obj_data_pos = obj_data[pos_mask]
217          obj_data_neg = obj_data[neg_mask]
218          obj_neg_loss = - F.logsigmoid(-obj_data_neg).sum()
219          with torch.no_grad():
220              pos_priors = priors.unsqueeze(0).expand(batch_size, -1, -1).reshape(-1, 4)[pos_mask, :]
221              boxes_pred = decode(loc_p, pos_priors, cfg.use_yolo_regressors)
222              boxes_targ = decode(loc_t, pos_priors, cfg.use_yolo_regressors)
223              iou_targets = elemwise_box_iou(boxes_pred, boxes_targ)
224          obj_pos_loss = - iou_targets * F.logsigmoid(obj_data_pos) - (1 - iou_targets) * F.logsigmoid(-obj_data_pos)
225          obj_pos_loss = obj_pos_loss.sum()
226          conf_data_pos = (conf_data[:, 1:])[pos_mask] # Now this has just 80 classes
227          conf_t_pos    = conf_t[pos_mask] - 1         # So subtract 1 here
228          class_loss = F.cross_entropy(conf_data_pos, conf_t_pos, reduction='sum')
229          return cfg.conf_alpha * (class_loss + obj_pos_loss + obj_neg_loss)
230      def direct_mask_loss(self, pos_idx, idx_t, loc_data, mask_data, priors, masks):
231          loss_m = 0
232          for idx in range(mask_data.size(0)):
233              with torch.no_grad():
234                  cur_pos_idx = pos_idx[idx, :, :]
235                  cur_pos_idx_squeezed = cur_pos_idx[:, 1]
236                  pos_bboxes = decode(loc_data[idx, :, :], priors.data, cfg.use_yolo_regressors)
237                  pos_bboxes = pos_bboxes[cur_pos_idx].view(-1, 4).clamp(0, 1)
238                  pos_lookup = idx_t[idx, cur_pos_idx_squeezed]
239                  cur_masks = masks[idx]
240                  pos_masks = cur_masks[pos_lookup, :, :]
241                  num_pos, img_height, img_width = pos_masks.size()
242                  x1, x2 = sanitize_coordinates(pos_bboxes[:, 0], pos_bboxes[:, 2], img_width)
243                  y1, y2 = sanitize_coordinates(pos_bboxes[:, 1], pos_bboxes[:, 3], img_height)
244                  scaled_masks = []
245                  for jdx in range(num_pos):
246                      tmp_mask = pos_masks[jdx, y1[jdx]:y2[jdx], x1[jdx]:x2[jdx]]
247                      while tmp_mask.dim() < 2:
248                          tmp_mask = tmp_mask.unsqueeze(0)
249                      new_mask = F.adaptive_avg_pool2d(tmp_mask.unsqueeze(0), cfg.mask_size)
250                      scaled_masks.append(new_mask.view(1, -1))
251                  mask_t = torch.cat(scaled_masks, 0).gt(0.5).float() # Threshold downsampled mask
252              pos_mask_data = mask_data[idx, cur_pos_idx_squeezed, :]
253              loss_m += F.binary_cross_entropy(torch.clamp(pos_mask_data, 0, 1), mask_t, reduction='sum') * cfg.mask_alpha
254          return loss_m
255      def coeff_diversity_loss(self, coeffs, instance_t):
256          num_pos = coeffs.size(0)
257          instance_t = instance_t.view(-1) # juuuust to make sure
258          coeffs_norm = F.normalize(coeffs, dim=1)
259          cos_sim = coeffs_norm @ coeffs_norm.t()
260          inst_eq = (instance_t[:, None].expand_as(cos_sim) == instance_t[None, :].expand_as(cos_sim)).float()
261          cos_sim = (cos_sim + 1) / 2
262          loss = (1 - cos_sim) * inst_eq + cos_sim * (1 - inst_eq)
263          return cfg.mask_proto_coeff_diversity_alpha * loss.sum() / num_pos
264      def lincomb_mask_loss(self, pos, idx_t, loc_data, mask_data, priors, proto_data, masks, gt_box_t, score_data, inst_data, labels, interpolation_mode='bilinear'):
265          mask_h = proto_data.size(1)
266          mask_w = proto_data.size(2)
267          process_gt_bboxes = cfg.mask_proto_normalize_emulate_roi_pooling or cfg.mask_proto_crop
268          if cfg.mask_proto_remove_empty_masks:
269              pos = pos.clone()
270          loss_m = 0
271          loss_d = 0 # Coefficient diversity loss
272          maskiou_t_list = []
273          maskiou_net_input_list = []
274          label_t_list = []
275          for idx in range(mask_data.size(0)):
276              with torch.no_grad():
277                  downsampled_masks = F.interpolate(masks[idx].unsqueeze(0), (mask_h, mask_w),
278                                                    mode=interpolation_mode, align_corners=False).squeeze(0)
279                  downsampled_masks = downsampled_masks.permute(1, 2, 0).contiguous()
280                  if cfg.mask_proto_binarize_downsampled_gt:
281                      downsampled_masks = downsampled_masks.gt(0.5).float()
282                  if cfg.mask_proto_remove_empty_masks:
283                      very_small_masks = (downsampled_masks.sum(dim=(0,1)) <= 0.0001)
284                      for i in range(very_small_masks.size(0)):
285                          if very_small_masks[i]:
286                              pos[idx, idx_t[idx] == i] = 0
287                  if cfg.mask_proto_reweight_mask_loss:
288                      if not cfg.mask_proto_binarize_downsampled_gt:
289                          bin_gt = downsampled_masks.gt(0.5).float()
290                      else:
291                          bin_gt = downsampled_masks
292                      gt_foreground_norm = bin_gt     / (torch.sum(bin_gt,   dim=(0,1), keepdim=True) + 0.0001)
293                      gt_background_norm = (1-bin_gt) / (torch.sum(1-bin_gt, dim=(0,1), keepdim=True) + 0.0001)
294                      mask_reweighting   = gt_foreground_norm * cfg.mask_proto_reweight_coeff + gt_background_norm
295                      mask_reweighting  *= mask_h * mask_w
296              cur_pos = pos[idx]
297              pos_idx_t = idx_t[idx, cur_pos]
298              if process_gt_bboxes:
299                  if cfg.mask_proto_crop_with_pred_box:
300                      pos_gt_box_t = decode(loc_data[idx, :, :], priors.data, cfg.use_yolo_regressors)[cur_pos]
301                  else:
302                      pos_gt_box_t = gt_box_t[idx, cur_pos]
303              if pos_idx_t.size(0) == 0:
304                  continue
305              proto_masks = proto_data[idx]
306              proto_coef  = mask_data[idx, cur_pos, :]
307              if cfg.use_mask_scoring:
308                  mask_scores = score_data[idx, cur_pos, :]
309              if cfg.mask_proto_coeff_diversity_loss:
310                  if inst_data is not None:
311                      div_coeffs = inst_data[idx, cur_pos, :]
312                  else:
313                      div_coeffs = proto_coef
314                  loss_d += self.coeff_diversity_loss(div_coeffs, pos_idx_t)
315              old_num_pos = proto_coef.size(0)
316              if old_num_pos > cfg.masks_to_train:
317                  perm = torch.randperm(proto_coef.size(0))
318                  select = perm[:cfg.masks_to_train]
319                  proto_coef = proto_coef[select, :]
320                  pos_idx_t  = pos_idx_t[select]
321                  if process_gt_bboxes:
322                      pos_gt_box_t = pos_gt_box_t[select, :]
323                  if cfg.use_mask_scoring:
324                      mask_scores = mask_scores[select, :]
325              num_pos = proto_coef.size(0)
326              mask_t = downsampled_masks[:, :, pos_idx_t]     
327              label_t = labels[idx][pos_idx_t]     
328              pred_masks = proto_masks @ proto_coef.t()
329              pred_masks = cfg.mask_proto_mask_activation(pred_masks)
330              if cfg.mask_proto_double_loss:
331                  if cfg.mask_proto_mask_activation == activation_func.sigmoid:
332                      pre_loss = F.binary_cross_entropy(torch.clamp(pred_masks, 0, 1), mask_t, reduction='sum')
333                  else:
334                      pre_loss = F.smooth_l1_loss(pred_masks, mask_t, reduction='sum')
335                  loss_m += cfg.mask_proto_double_loss_alpha * pre_loss
336              if cfg.mask_proto_crop:
337                  pred_masks = crop(pred_masks, pos_gt_box_t)
338              if cfg.mask_proto_mask_activation == activation_func.sigmoid:
339                  pre_loss = F.binary_cross_entropy(torch.clamp(pred_masks, 0, 1), mask_t, reduction='none')
340              else:
341                  pre_loss = F.smooth_l1_loss(pred_masks, mask_t, reduction='none')
342              if cfg.mask_proto_normalize_mask_loss_by_sqrt_area:
343                  gt_area  = torch.sum(mask_t, dim=(0, 1), keepdim=True)
344                  pre_loss = pre_loss / (torch.sqrt(gt_area) + 0.0001)
345              if cfg.mask_proto_reweight_mask_loss:
346                  pre_loss = pre_loss * mask_reweighting[:, :, pos_idx_t]
347              if cfg.mask_proto_normalize_emulate_roi_pooling:
348                  weight = mask_h * mask_w if cfg.mask_proto_crop else 1
349                  pos_gt_csize = center_size(pos_gt_box_t)
350                  gt_box_width  = pos_gt_csize[:, 2] * mask_w
351                  gt_box_height = pos_gt_csize[:, 3] * mask_h
352                  pre_loss = pre_loss.sum(dim=(0, 1)) / gt_box_width / gt_box_height * weight
353              if old_num_pos > num_pos:
354                  pre_loss *= old_num_pos / num_pos
355              loss_m += torch.sum(pre_loss)
356              if cfg.use_maskiou:
357                  if cfg.discard_mask_area > 0:
358                      gt_mask_area = torch.sum(mask_t, dim=(0, 1))
359                      select = gt_mask_area > cfg.discard_mask_area
360                      if torch.sum(select) < 1:
361                          continue
362                      pos_gt_box_t = pos_gt_box_t[select, :]
363                      pred_masks = pred_masks[:, :, select]
364                      mask_t = mask_t[:, :, select]
365                      label_t = label_t[select]
366                  maskiou_net_input = pred_masks.permute(2, 0, 1).contiguous().unsqueeze(1)
367                  pred_masks = pred_masks.gt(0.5).float()                
368                  maskiou_t = self._mask_iou(pred_masks, mask_t)
369                  maskiou_net_input_list.append(maskiou_net_input)
370                  maskiou_t_list.append(maskiou_t)
371                  label_t_list.append(label_t)
372          losses = {'M': loss_m * cfg.mask_alpha / mask_h / mask_w}
373          if cfg.mask_proto_coeff_diversity_loss:
374              losses['D'] = loss_d
375          if cfg.use_maskiou:
376              if len(maskiou_t_list) == 0:
377                  return losses, None
<span onclick='openModal()' class='match'>378              maskiou_t = torch.cat(maskiou_t_list)
379              label_t = torch.cat(label_t_list)
380              maskiou_net_input = torch.cat(maskiou_net_input_list)
381              num_samples = maskiou_t.size(0)
</span>382              if cfg.maskious_to_train > 0 and num_samples > cfg.maskious_to_train:
383                  perm = torch.randperm(num_samples)
384                  select = perm[:cfg.masks_to_train]
385                  maskiou_t = maskiou_t[select]
386                  label_t = label_t[select]
387                  maskiou_net_input = maskiou_net_input[select]
388              return losses, [maskiou_net_input, maskiou_t, label_t]
389          return losses
390      def _mask_iou(self, mask1, mask2):
391          intersection = torch.sum(mask1*mask2, dim=(0, 1))
392          area1 = torch.sum(mask1, dim=(0, 1))
393          area2 = torch.sum(mask2, dim=(0, 1))
394          union = (area1 + area2) - intersection
395          ret = intersection / union
396          return ret
397      def mask_iou_loss(self, net, maskiou_targets):
398          maskiou_net_input, maskiou_t, label_t = maskiou_targets
399          maskiou_p = net.maskiou_net(maskiou_net_input)
400          label_t = label_t[:, None]
401          maskiou_p = torch.gather(maskiou_p, dim=1, index=label_t).view(-1)
402          loss_i = F.smooth_l1_loss(maskiou_p, maskiou_t, reduction='sum')
403          return loss_i * cfg.maskiou_alpha
</code></pre>
        </div>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-recurrent_test.py</h3>
            <pre><code>1  import itertools
2  import unittest
3  from absl.testing import parameterized
4  import numpy as np
5  from sonnet.src import initializers
6  from sonnet.src import recurrent
7  from sonnet.src import test_utils
8  import tensorflow as tf
9  import tree
10  class VanillaRNNTest(test_utils.TestCase, parameterized.TestCase):
11    def setUp(self):
12      super().setUp()
13      self.batch_size = 3
14      self.input_size = 2
15      self.hidden_size = 16
16    @parameterized.parameters([False, True])
17    def testComputationAgainstNumPy(self, use_tf_function):
18      inputs = self.evaluate(
19          tf.random.uniform([self.batch_size, self.input_size]))
20      core = recurrent.VanillaRNN(
21          hidden_size=self.hidden_size, activation=tf.tanh)
22      prev_state = self.evaluate(core.initial_state(self.batch_size))
23      core_fn = tf.function(core) if use_tf_function else core
24      outputs, next_state = core_fn(tf.convert_to_tensor(inputs), prev_state)
25      expected_output = np.tanh(
26          inputs.dot(self.evaluate(core.input_to_hidden)) +
27          prev_state.dot(self.evaluate(core.hidden_to_hidden)) +
28          self.evaluate(core._b))
29      atol = 3e-2 if self.primary_device == "TPU" else 1e-6
30      self.assertAllClose(outputs, expected_output, atol=atol)
31      self.assertAllClose(next_state, expected_output, atol=atol)
32    def testDtypeMismatch(self):
33      core = recurrent.VanillaRNN(hidden_size=self.hidden_size, dtype=tf.bfloat16)
34      inputs = tf.random.uniform([self.batch_size, self.input_size])
35      prev_state = core.initial_state(self.batch_size)
36      self.assertIs(prev_state.dtype, tf.bfloat16)
37      with self.assertRaisesRegex(
38          TypeError, "inputs must have dtype tf.bfloat16, got tf.float32"):
39        core(inputs, prev_state)
40    def testInitialization(self):
41      core = recurrent.VanillaRNN(
42          hidden_size=self.hidden_size,
43          w_i_init=initializers.Ones(),
44          w_h_init=initializers.Ones(),
45          b_init=initializers.Ones())
46      inputs = tf.random.uniform([self.batch_size, self.input_size])
47      prev_state = core.initial_state(self.batch_size)
48      core(inputs, prev_state)
49      for v in core.variables:
50        self.assertAllClose(self.evaluate(v), self.evaluate(tf.ones_like(v)))
51  class DeepRNNTest(test_utils.TestCase, parameterized.TestCase):
52    def setUp(self):
53      super().setUp()
54      self.batch_size = 3
55      self.input_size = 2
56      self.hidden_size = 16
57    @parameterized.parameters([False, True])
58    def testComputationAgainstNumPy(self, use_tf_function):
59      inputs = self.evaluate(
60          tf.random.uniform([self.batch_size, self.input_size]))
61      core = recurrent.DeepRNN([
62          recurrent.VanillaRNN(hidden_size=self.hidden_size),
63          recurrent.VanillaRNN(hidden_size=2 * self.hidden_size)
64      ])
65      prev_state = self.evaluate(core.initial_state(self.batch_size))
66      core_fn = tf.function(core) if use_tf_function else core
67      outputs, next_state = core_fn(tf.convert_to_tensor(inputs), prev_state)
68      expected_outputs = inputs
69      expected_next_state = list(prev_state)
70      for idx, l in enumerate(core._layers):
71        expected_outputs, expected_next_state[idx] = l(expected_outputs,
72                                                       prev_state[idx])
73      self.assertAllClose(outputs, expected_outputs)
74      self.assertAllClose(next_state, tuple(expected_next_state))
75    @parameterized.parameters([False, True])
76    def testComputationAgainstNumPyWithCallables(self, use_tf_function):
77      inputs = self.evaluate(
78          tf.random.uniform([self.batch_size, self.input_size]))
79      core = recurrent.DeepRNN([tf.tanh, tf.sign])
80      prev_state = self.evaluate(core.initial_state(self.batch_size))
81      core_fn = tf.function(core) if use_tf_function else core
82      outputs, next_state = core_fn(tf.convert_to_tensor(inputs), prev_state)
83      self.assertAllClose(outputs, np.sign(np.tanh(inputs)))
84      self.assertEqual(next_state, prev_state)
85    def testInitialState(self):
86      core0 = recurrent.VanillaRNN(hidden_size=self.hidden_size)
87      core1 = recurrent.VanillaRNN(hidden_size=2 * self.hidden_size)
88      deep_rnn = recurrent.DeepRNN([core0, tf.tanh, core1, tf.sign])
89      prev_state = deep_rnn.initial_state(self.batch_size)
90      self.assertAllClose(prev_state[0], core0.initial_state(self.batch_size))
91      self.assertAllClose(prev_state[1], core1.initial_state(self.batch_size))
92    @parameterized.parameters([False, True])
93    def testWithSkipConnectionsOutputs(self, use_tf_function):
94      inputs = self.evaluate(
95          tf.random.uniform([self.batch_size, self.input_size]))
96      core = recurrent.deep_rnn_with_skip_connections([
97          recurrent.VanillaRNN(hidden_size=self.hidden_size),
98          recurrent.VanillaRNN(hidden_size=2 * self.hidden_size)
99      ],
100                                                      concat_final_output=False)
101      prev_state = self.evaluate(core.initial_state(self.batch_size))
102      core_fn = tf.function(core) if use_tf_function else core
103      outputs, _ = core_fn(tf.convert_to_tensor(inputs), prev_state)
104      self.assertEqual(outputs.shape,
105                       tf.TensorShape([self.batch_size, 2 * self.hidden_size]))
106    def testWithConnectionsValidation(self):
107      with self.assertRaisesRegex(ValueError, "to be instances of RNNCore"):
108        recurrent.deep_rnn_with_skip_connections([tf.tanh])
109      with self.assertRaisesRegex(ValueError, "to be instances of RNNCore"):
110        recurrent.deep_rnn_with_residual_connections([tf.tanh])
111  class LSTMTest(test_utils.TestCase, parameterized.TestCase):
112    def setUp(self):
113      super().setUp()
114      self.batch_size = 3
115      self.input_size = 2
116      self.hidden_size = 16
117    @parameterized.parameters(
118        itertools.product([False, True], [None, 4], [0.0, 1.0]))
119    def testComputationAgainstNumPy(self, use_tf_function, projection_size,
120                                    forget_bias):
121      inputs = self.evaluate(
122          tf.random.uniform([self.batch_size, self.input_size]))
123      core = recurrent.LSTM(
124          self.hidden_size,
125          projection_size=projection_size,
126          forget_bias=forget_bias)
127      prev_state = self.evaluate(core.initial_state(self.batch_size))
128      core_fn = tf.function(core) if use_tf_function else core
129      outputs, next_state = core_fn(tf.convert_to_tensor(inputs), prev_state)
130      w_ii, w_if, w_ig, w_io = np.hsplit(self.evaluate(core.input_to_hidden), 4)
131      w_hi, w_hf, w_hg, w_ho = np.hsplit(self.evaluate(core.hidden_to_hidden), 4)
132      b_i, b_f, b_g, b_o = np.hsplit(self.evaluate(core.b), 4)
133      i = expit(inputs.dot(w_ii) + prev_state.hidden.dot(w_hi) + b_i)
134      f = expit(inputs.dot(w_if) + prev_state.hidden.dot(w_hf) + b_f)
135      g = np.tanh(inputs.dot(w_ig) + prev_state.hidden.dot(w_hg) + b_g)
136      o = expit(inputs.dot(w_io) + prev_state.hidden.dot(w_ho) + b_o)
137      expected_cell = f * prev_state.cell + i * g
138      expected_hidden = o * np.tanh(expected_cell)
139      if projection_size is not None:
140        expected_hidden = expected_hidden.dot(self.evaluate(core.projection))
141      atol = 1e-2 if self.primary_device == "TPU" else 1e-6
142      self.assertAllClose(outputs, next_state.hidden, atol=atol)
143      self.assertAllClose(expected_hidden, next_state.hidden, atol=atol)
144      self.assertAllClose(expected_cell, next_state.cell, atol=atol)
145    def testDtypeMismatch(self):
146      core = recurrent.LSTM(hidden_size=self.hidden_size, dtype=tf.bfloat16)
147      inputs = tf.random.uniform([self.batch_size, self.input_size])
148      prev_state = core.initial_state(self.batch_size)
149      self.assertIs(prev_state.hidden.dtype, tf.bfloat16)
150      self.assertIs(prev_state.cell.dtype, tf.bfloat16)
151      with self.assertRaisesRegex(
152          TypeError, "inputs must have dtype tf.bfloat16, got tf.float32"):
153        core(inputs, prev_state)
154    def testInitialization(self):
155      projection_size = 4
156      core = recurrent.LSTM(
157          hidden_size=self.hidden_size,
158          projection_size=projection_size,
159          projection_init=initializers.Ones(),
160          w_i_init=initializers.Ones(),
161          w_h_init=initializers.Ones(),
162          b_init=initializers.Ones(),
163          forget_bias=0.0)
164      inputs = tf.random.uniform([self.batch_size, self.input_size])
165      prev_state = core.initial_state(self.batch_size)
166      core(inputs, prev_state)
167      for v in core.variables:
168        self.assertAllClose(self.evaluate(v), self.evaluate(tf.ones_like(v)))
169    @parameterized.parameters([1e-6, 0.5, 1 - 1e-6])
170    def testRecurrentDropout(self, rate):
171      num_steps = 2
172      inputs = tf.random.uniform([num_steps, self.batch_size, self.input_size])
173      train_core, test_core = recurrent.lstm_with_recurrent_dropout(
174          self.hidden_size, dropout=rate)
175      [_, train_output
176      ], _ = recurrent.dynamic_unroll(train_core, inputs,
177                                      train_core.initial_state(self.batch_size))
178      [_, test_output
179      ], _ = recurrent.dynamic_unroll(test_core, inputs,
180                                      test_core.initial_state(self.batch_size))
181      almost_zero = rate == 1e-6
182      if almost_zero:
183        rtol = 1e-3 if self.primary_device == "TPU" else 1e-6
184        self.assertAllClose(train_output, test_output, rtol=rtol)
185      else:
186        self.assertGreater(
187            self.evaluate(tf.reduce_max(tf.abs(train_output - test_output))),
188            0.001)
189    def testRecurrentDropoutInvalid(self):
190      with self.assertRaisesRegex(ValueError,
191                                  r"dropout must be in the range \[0, 1\).+"):
192        recurrent.lstm_with_recurrent_dropout(self.hidden_size, -1)
193  class UnrolledLSTMTest(test_utils.TestCase, parameterized.TestCase):
194    def setUp(self):
195      super().setUp()
196      self.batch_size = 3
197      self.input_size = 2
198      self.hidden_size = 16
199    @parameterized.parameters(itertools.product([1, 4], [True, False]))
200    def testComputationAgainstLSTM(self, num_steps, use_tf_function):
201      unrolled_lstm = recurrent.UnrolledLSTM(self.hidden_size)
202      initial_state = unrolled_lstm.initial_state(self.batch_size)
203      if use_tf_function:
204        @tf.function
205        def unrolled_lstm_fn(*args, **kwargs):
206          with tf.device("/device:{}:0".format(self.primary_device)):
207            return unrolled_lstm(*args, **kwargs)
208      else:
209        unrolled_lstm_fn = unrolled_lstm
210      input_sequence = tf.random.uniform(
211          [num_steps, self.batch_size, self.input_size])
212      output_sequence, final_state = unrolled_lstm_fn(input_sequence,
213                                                      initial_state)
214      with tf.device("/device:CPU:0"):  # Use CPU as the baseline.
215        lstm = recurrent.LSTM(self.hidden_size)
216        lstm._initialize(input_sequence[0])
217        lstm._w_i = unrolled_lstm._w_i
218        lstm._w_h = unrolled_lstm._w_h
219        lstm.b = unrolled_lstm.b
220        expected_output_sequence, expected_final_state = recurrent.dynamic_unroll(
221            lstm, input_sequence, lstm.initial_state(self.batch_size))
222      atol = 1e-2 if self.primary_device == "TPU" else 1e-6
223      self.assertAllClose(output_sequence, expected_output_sequence, atol=atol)
224      self.assertAllClose(
225          final_state.hidden, expected_final_state.hidden, atol=atol)
226      self.assertAllClose(final_state.cell, expected_final_state.cell, atol=atol)
227    @parameterized.parameters([True, False])
228    def testNumStepsPolymorphism(self, use_tf_function):
229      unrolled_lstm = recurrent.UnrolledLSTM(self.hidden_size)
230      initial_state = unrolled_lstm.initial_state(self.batch_size)
231      if use_tf_function:
232        @tf.function
233        def unrolled_lstm_fn(*args, **kwargs):
234          with tf.device("/device:%s:0" % self.primary_device):
235            return unrolled_lstm(*args, **kwargs)
236      else:
237        unrolled_lstm_fn = unrolled_lstm
238      for num_steps in [1, 2, 4]:
239        output_sequence, _ = unrolled_lstm_fn(
240            tf.random.uniform([num_steps, self.batch_size, self.input_size]),
241            initial_state)
242        self.assertEqual(output_sequence.shape[0], num_steps)
243    def testDtypeMismatch(self):
244      unrolled_lstm = recurrent.UnrolledLSTM(
245          hidden_size=self.hidden_size, dtype=tf.bfloat16)
246      input_sequence = tf.random.uniform([1, self.batch_size, self.input_size])
247      initial_state = unrolled_lstm.initial_state(self.batch_size)
248      self.assertIs(initial_state.hidden.dtype, tf.bfloat16)
249      self.assertIs(initial_state.cell.dtype, tf.bfloat16)
250      with self.assertRaisesRegex(
251          TypeError, "inputs must have dtype tf.bfloat16, got tf.float32"):
252        unrolled_lstm(input_sequence, initial_state)
253    def testInitialization(self):
254      unrolled_lstm = recurrent.UnrolledLSTM(
255          hidden_size=self.hidden_size,
256          forget_bias=0.0,
<span onclick='openModal()' class='match'>257          w_i_init=initializers.Ones(),
258          w_h_init=initializers.Ones(),
259          b_init=initializers.Ones())
260      input_sequence = tf.random.uniform([1, self.batch_size, self.input_size])
</span>261      initial_state = unrolled_lstm.initial_state(self.batch_size)
262      unrolled_lstm(input_sequence, initial_state)
263      for v in unrolled_lstm.variables:
264        self.assertAllClose(self.evaluate(v), self.evaluate(tf.ones_like(v)))
265  class ConvNDLSTMTest(test_utils.TestCase, parameterized.TestCase):
266    def setUp(self):
267      super().setUp()
268      self.batch_size = 3
269      self.input_size = 2
270      self.hidden_size = 16
271      self.input_channels = 3
272      self.output_channels = 5
273    @parameterized.parameters(
274        itertools.product(
275            [False, True],
276            [recurrent.Conv1DLSTM, recurrent.Conv2DLSTM, recurrent.Conv3DLSTM]))
277    def testComputationAgainstNumPy(self, use_tf_function, core_cls):
278      if core_cls is recurrent.Conv1DLSTM:
279        num_spatial_dims = 1
280      elif core_cls is recurrent.Conv2DLSTM:
281        num_spatial_dims = 2
282      else:
283        assert core_cls is recurrent.Conv3DLSTM
284        num_spatial_dims = 3
285      input_shape = ((self.batch_size,) + (self.input_size,) * num_spatial_dims +
286                     (self.input_channels,))
287      inputs = self.evaluate(tf.random.uniform(input_shape))
288      core = core_cls(input_shape[1:], self.output_channels, kernel_shape=1)
289      prev_state = self.evaluate(core.initial_state(self.batch_size))
290      core_fn = tf.function(core) if use_tf_function else core
291      outputs, next_state = core_fn(tf.convert_to_tensor(inputs), prev_state)
292      def conv(x, f):
293        return self.evaluate(tf.nn.convolution(x, f, strides=1, padding="SAME"))
294      w_i = self.evaluate(core.input_to_hidden)
295      w_h = self.evaluate(core.hidden_to_hidden)
296      w_ii, w_if, w_ig, w_io = np.split(w_i, 4, axis=-1)
297      w_hi, w_hf, w_hg, w_ho = np.split(w_h, 4, axis=-1)
298      b_i, b_f, b_g, b_o = np.hsplit(self.evaluate(core.b), 4)
299      i = expit(conv(inputs, w_ii) + conv(prev_state.hidden, w_hi) + b_i)
300      f = expit(conv(inputs, w_if) + conv(prev_state.hidden, w_hf) + b_f)
301      g = np.tanh(conv(inputs, w_ig) + conv(prev_state.hidden, w_hg) + b_g)
302      o = expit(conv(inputs, w_io) + conv(prev_state.hidden, w_ho) + b_o)
303      expected_cell = f * prev_state.cell + i * g
304      expected_hidden = o * np.tanh(expected_cell)
305      atol = 1e-2 if self.primary_device == "TPU" else 1e-6
306      self.assertAllClose(outputs, next_state.hidden, atol=atol)
307      self.assertAllClose(expected_hidden, next_state.hidden, atol=atol)
308      self.assertAllClose(expected_cell, next_state.cell, atol=atol)
309    def testDtypeMismatch(self):
310      num_spatial_dims = 1
311      input_shape = ((self.batch_size,) + (self.input_size,) * num_spatial_dims +
312                     (self.input_channels,))
313      core = recurrent.Conv1DLSTM(
314          input_shape[1:],
315          self.output_channels,
316          kernel_shape=1,
317          dtype=tf.bfloat16)
318      inputs = tf.random.uniform(input_shape)
319      prev_state = core.initial_state(self.batch_size)
320      self.assertIs(prev_state.hidden.dtype, tf.bfloat16)
321      self.assertIs(prev_state.cell.dtype, tf.bfloat16)
322      with self.assertRaisesRegex(
323          TypeError, "inputs must have dtype tf.bfloat16, got tf.float32"):
324        core(inputs, prev_state)
325    def testInitialization(self):
326      num_spatial_dims = 1
327      input_shape = ((self.batch_size,) + (self.input_size,) * num_spatial_dims +
328                     (self.input_channels,))
329      inputs = tf.random.uniform(input_shape)
330      core = recurrent.Conv1DLSTM(
331          input_shape[1:],
332          self.output_channels,
333          kernel_shape=1,
334          forget_bias=0.0,
335          w_i_init=initializers.Ones(),
336          w_h_init=initializers.Ones(),
337          b_init=initializers.Ones())
338      prev_state = core.initial_state(self.batch_size)
339      core(inputs, prev_state)
340      for v in core.variables:
341        self.assertAllClose(self.evaluate(v), self.evaluate(tf.ones_like(v)))
342  class GRUTest(test_utils.TestCase, parameterized.TestCase):
343    def setUp(self):
344      super().setUp()
345      self.batch_size = 3
346      self.input_size = 2
347      self.hidden_size = 16
348    @parameterized.parameters([False, True])
349    def testComputationAgainstNumPy(self, use_tf_function):
350      inputs = self.evaluate(
351          tf.random.uniform([self.batch_size, self.input_size]))
352      core = recurrent.GRU(self.hidden_size)
353      prev_state = self.evaluate(core.initial_state(self.batch_size))
354      core_fn = tf.function(core) if use_tf_function else core
355      outputs, next_state = core_fn(tf.convert_to_tensor(inputs), prev_state)
356      w_iz, w_ir, w_ia = np.hsplit(self.evaluate(core.input_to_hidden), 3)
357      w_hz, w_hr, w_ha = np.hsplit(self.evaluate(core.hidden_to_hidden), 3)
358      b_z, b_r, b_a = np.hsplit(self.evaluate(core.b), 3)
359      z = expit(inputs.dot(w_iz) + prev_state.dot(w_hz) + b_z)
360      r = expit(inputs.dot(w_ir) + prev_state.dot(w_hr) + b_r)
361      a = np.tanh(inputs.dot(w_ia) + (r * prev_state).dot(w_ha) + b_a)
362      expected_state = (1 - z) * prev_state + z * a
363      atol = 1e-2 if self.primary_device == "TPU" else 1e-6
364      self.assertAllClose(outputs, next_state, atol=atol)
365      self.assertAllClose(self.evaluate(next_state), expected_state, atol=atol)
366    def testDtypeMismatch(self):
367      core = recurrent.GRU(hidden_size=self.hidden_size, dtype=tf.bfloat16)
368      inputs = tf.random.uniform([self.batch_size, self.input_size])
369      prev_state = core.initial_state(self.batch_size)
370      self.assertIs(prev_state.dtype, tf.bfloat16)
371      with self.assertRaisesRegex(
372          TypeError, "inputs must have dtype tf.bfloat16, got tf.float32"):
373        core(inputs, prev_state)
374    def testInitialization(self):
375      core = recurrent.GRU(
376          hidden_size=self.hidden_size,
377          w_i_init=initializers.Ones(),
378          w_h_init=initializers.Ones(),
379          b_init=initializers.Ones())
380      inputs = tf.random.uniform([self.batch_size, self.input_size])
381      prev_state = core.initial_state(self.batch_size)
382      core(inputs, prev_state)
383      for v in core.variables:
384        self.assertAllClose(self.evaluate(v), self.evaluate(tf.ones_like(v)))
385  def expit(x):
386    return 1.0 / (1 + np.exp(-x))
387  class CuDNNGRUTest(test_utils.TestCase, parameterized.TestCase):
388    def setUp(self):
389      super().setUp()
390      if self.primary_device != "GPU":
391        self.skipTest("Only available on GPU")
392      self.batch_size = 1
393      self.input_size = 1
394      self.hidden_size = 1
395    @parameterized.parameters([1, 4])
396    def testComputationAgainstTF(self, num_steps):
397      inputs = tf.random.uniform([num_steps, self.batch_size, self.input_size])
398      cudnn_gru = recurrent.CuDNNGRU(self.hidden_size)
399      prev_state = cudnn_gru.initial_state(self.batch_size)
400      outputs, states = cudnn_gru(inputs, prev_state)
401      def cudnn_compatible_gru_fn(inputs, prev_state):
402        w_i = cudnn_gru.input_to_hidden
403        w_h = cudnn_gru.hidden_to_hidden
404        w_iz, w_ir, w_ia = tf.split(w_i, num_or_size_splits=3, axis=1)
405        w_hz, w_hr, w_ha = tf.split(w_h, num_or_size_splits=3, axis=1)
406        b_z, b_r, b_a = tf.split(cudnn_gru.b, num_or_size_splits=3)
407        z = tf.sigmoid(
408            tf.matmul(inputs, w_iz) + tf.matmul(prev_state, w_hz) + b_z)
409        r = tf.sigmoid(
410            tf.matmul(inputs, w_ir) + tf.matmul(prev_state, w_hr) + b_r)
411        a = tf.tanh(
412            tf.matmul(inputs, w_ia) + r * tf.matmul(prev_state, w_ha) + b_a)
413        next_state = (1 - z) * a + z * prev_state
414        return next_state, next_state
415      expected_outputs, expected_final_state = recurrent.dynamic_unroll(
416          cudnn_compatible_gru_fn, inputs, prev_state)
417      self.assertAllClose(outputs, expected_outputs)
418      self.assertAllClose(states[-1], expected_final_state)
419    def testDtypeMismatch(self):
420      core = recurrent.CuDNNGRU(hidden_size=self.hidden_size, dtype=tf.bfloat16)
421      inputs = tf.random.uniform([1, self.batch_size, self.input_size])
422      prev_state = core.initial_state(self.batch_size)
423      self.assertIs(prev_state.dtype, tf.bfloat16)
424      with self.assertRaisesRegex(
425          TypeError, "inputs must have dtype tf.bfloat16, got tf.float32"):
426        core(inputs, prev_state)
427    def testInitialization(self):
428      core = recurrent.CuDNNGRU(
429          hidden_size=self.hidden_size,
430          w_i_init=initializers.Ones(),
431          w_h_init=initializers.Ones(),
432          b_init=initializers.Ones())
433      inputs = tf.random.uniform([1, self.batch_size, self.input_size])
434      prev_state = core.initial_state(self.batch_size)
435      core(inputs, prev_state)
436      for v in core.variables:
437        self.assertAllClose(self.evaluate(v), self.evaluate(tf.ones_like(v)))
438  class Counter(recurrent.RNNCore):
439    def __init__(self, hidden_size, name=None):
440      super().__init__(name)
441      self._hidden_size = hidden_size
442      self._built = False
443    def __call__(self, inputs, prev_state):
444      if not self._built:
445        self.one = tf.Variable(1.0)
446        self._built = True
447      t, h = prev_state
448      return inputs * (h + t), (t + self.one, h)
449    def initial_state(self, batch_size):
450      return (tf.cast(0.0, tf.float32), tf.zeros([batch_size, self._hidden_size]))
451  class Replicate(recurrent.RNNCore):
452    def __init__(self, base_core, n, name=None):
453      super().__init__(name)
454      self._base_core = base_core
455      self._n = n
456    def __call__(self, inputs, prev_state):
457      outputs, next_state = self._base_core(inputs, prev_state)
458      return (outputs,) * self._n, next_state
459    def initial_state(self, batch_size, **kwargs):
460      return self._base_core.initial_state(batch_size, **kwargs)
461  class TrainableStateTest(test_utils.TestCase, parameterized.TestCase):
462    @parameterized.parameters([
463        {
464            "initial_values_shape": []
465        },
466        {
467            "initial_values_shape": tf.TensorShape([42])
468        },
469        {
470            "initial_values_shape": (tf.TensorShape([4]), tf.TensorShape([2]))
471        },
472    ])
473    def testUnmasked(self, initial_values_shape):
474      trainable_state = recurrent.TrainableState(
475          tree.map_structure(tf.ones, initial_values_shape))
476      if initial_values_shape:
477        self.assertEqual(
478            len(trainable_state.trainable_variables), len(initial_values_shape))
479      initial_state = trainable_state(batch_size=42)
480      for s, shape in zip(
481          tree.flatten(initial_state), tree.flatten(initial_values_shape)):
482        self.assertEqual(s.shape, tf.TensorShape([42] + shape.as_list()))
483    def testMasked(self):
484      mask = (True, False)
485      trainable_state = recurrent.TrainableState((tf.zeros([16]), tf.zeros([3])),
486                                                 mask)
487      for var in trainable_state.trainable_variables:
488        var.assign_add(tf.ones_like(var))
489      initial_state = trainable_state(batch_size=42)
490      for s, trainable in zip(tree.flatten(initial_state), tree.flatten(mask)):
491        if trainable:
492          self.assertNotAllClose(s, tf.zeros_like(s))
493        else:
494          self.assertAllClose(s, tf.zeros_like(s))
495    def testForCore(self):
496      core = recurrent.LSTM(hidden_size=16)
497      trainable_state = recurrent.TrainableState.for_core(core)
498      self.assertAllClose(
499          trainable_state(batch_size=42), core.initial_state(batch_size=42))
500  @parameterized.parameters([
501      {
502          "use_tf_function": False,
503          "unroll_fn": recurrent.dynamic_unroll
504      },
505      {
506          "use_tf_function": False,
507          "unroll_fn": recurrent.static_unroll
508      },
509      {
510          "use_tf_function": True,
511          "unroll_fn": recurrent.dynamic_unroll
512      },
513      {
514          "use_tf_function": True,
515          "unroll_fn": recurrent.static_unroll
516      },
517  ])
518  class UnrollTest(test_utils.TestCase, parameterized.TestCase):
519    def setUp(self):
520      super().setUp()
521      self.num_steps = 5
522      self.batch_size = 3
523      self.hidden_size = 2
524      self.core = Counter(self.hidden_size)
525    def testFlat(self, use_tf_function, unroll_fn):
526      if use_tf_function:
527        unroll_fn = tf.function(unroll_fn)
528      initial_state = _, h = self.core.initial_state(self.batch_size)
529      input_sequence = tf.random.uniform([self.num_steps, self.batch_size, 1])
530      output_sequence, final_state = unroll_fn(self.core, input_sequence,
531                                               initial_state)
532      self.assertAllClose(
533          output_sequence,
534          [inputs * (h + t) for t, inputs in enumerate(input_sequence)])
535      self.assertAllClose(final_state, (tf.cast(self.num_steps, tf.float32), h))
536    def testNestedInputs(self, use_tf_function, unroll_fn):
537      if use_tf_function:
538        unroll_fn = tf.function(unroll_fn)
539      initial_state = _, h = self.core.initial_state(self.batch_size)
540      input_sequence = tf.random.uniform([self.num_steps, self.batch_size, 1])
541      output_sequence, final_state = unroll_fn(
542          lambda inputs, prev_state: self.core(inputs["x"]["y"], prev_state),
543          {"x": {
544              "y": input_sequence
545          }}, initial_state)
546      self.assertAllClose(
547          output_sequence,
548          [inputs * (h + t) for t, inputs in enumerate(input_sequence)])
549      self.assertAllClose(final_state, (tf.cast(self.num_steps, tf.float32), h))
550    def testNestedOutputs(self, use_tf_function, unroll_fn):
551      if use_tf_function:
552        unroll_fn = tf.function(unroll_fn)
553      num_replicas = 2
554      core = Replicate(self.core, num_replicas)
555      initial_state = _, h = core.initial_state(self.batch_size)
556      input_sequence = tf.random.uniform([self.num_steps, self.batch_size, 1])
557      output_sequence, final_state = unroll_fn(core, input_sequence,
558                                               initial_state)
559      expected_outputs = [
560          inputs * (h + t) for t, inputs in enumerate(input_sequence)
561      ]
562      self.assertAllClose(output_sequence, (expected_outputs,) * num_replicas)
563      self.assertAllClose(final_state, (tf.cast(self.num_steps, tf.float32), h))
564    def testEmptyOutputs(self, use_tf_function, unroll_fn):
565      if use_tf_function:
566        unroll_fn = tf.function(unroll_fn)
567      def core_fn(inputs, prev_state):
568        return (inputs, tf.zeros(shape=(0,))), prev_state
569      input_sequence = tf.random.uniform([self.num_steps, self.batch_size, 1])
570      (_, empty), unused_final_state = unroll_fn(
571          core_fn, input_sequence, initial_state=tf.constant(0.0))
572      self.assertEqual(empty.shape, tf.TensorShape([self.num_steps, 0]))
573    def testZeroSteps(self, use_tf_function, unroll_fn):
574      if use_tf_function:
575        unroll_fn = tf.function(unroll_fn)
576      initial_state = self.core.initial_state(self.batch_size)
577      input_sequence = tf.random.uniform([0, self.batch_size])
578      with self.assertRaisesRegex(ValueError,
579                                  "must have at least a single time step"):
580        unroll_fn(self.core, input_sequence, initial_state)
581    def testInconsistentSteps(self, use_tf_function, unroll_fn):
582      if use_tf_function:
583        unroll_fn = tf.function(unroll_fn)
584      initial_state = self.core.initial_state(self.batch_size)
585      input_sequence = (tf.random.uniform([1, self.batch_size]),
586                        tf.random.uniform([2, self.batch_size]))
587      with self.assertRaisesRegex(ValueError,
588                                  "must have consistent number of time steps"):
589        unroll_fn(self.core, input_sequence, initial_state)
590    def testVariableLengthOneZeroLength(self, use_tf_function, unroll_fn):
591      if use_tf_function:
592        unroll_fn = tf.function(unroll_fn)
593      sequence_length = tf.constant([0] + [self.num_steps] *
594                                    (self.batch_size - 1))
595      initial_state = self.core.initial_state(self.batch_size)
596      input_sequence = tf.random.uniform([self.num_steps, self.batch_size, 1])
597      output_sequence, _ = unroll_fn(
598          self.core,
599          input_sequence,
600          initial_state,
601          sequence_length=sequence_length)
602      self.assertConsistentWithLength(output_sequence, sequence_length)
603    def testVariableLengthRange(self, use_tf_function, unroll_fn):
604      if use_tf_function:
605        unroll_fn = tf.function(unroll_fn)
606      sequence_length = tf.range(self.batch_size)
607      initial_state = self.core.initial_state(self.batch_size)
608      input_sequence = tf.random.uniform([self.num_steps, self.batch_size, 1])
609      output_sequence, _ = unroll_fn(
610          self.core,
611          input_sequence,
612          initial_state,
613          sequence_length=sequence_length)
614      self.assertConsistentWithLength(output_sequence, sequence_length)
615    def assertConsistentWithLength(self, output_sequence, sequence_length):
616      for t, _ in enumerate(output_sequence):
617        for b in range(self.batch_size):
618          if tf.equal(sequence_length[b], t):
619            if t == 0:
620              self.assertAllEqual(tf.reduce_sum(output_sequence[t, b]), 0.0)
621            else:
622              self.assertAllClose(output_sequence[t, b], output_sequence[t - 1,
623                                                                         b])
624    def testVariableLengthAllFull(self, use_tf_function, unroll_fn):
625      if use_tf_function:
626        unroll_fn = tf.function(unroll_fn)
627      initial_state = self.core.initial_state(self.batch_size)
628      input_sequence = tf.random.uniform([self.num_steps, self.batch_size, 1])
629      output_sequence, final_state = unroll_fn(
630          self.core,
631          input_sequence,
632          initial_state,
633          sequence_length=tf.constant([self.num_steps] * self.batch_size))
634      expected_output_sequence, expected_final_state = unroll_fn(
635          self.core, input_sequence, initial_state)
636      self.assertAllClose(output_sequence, expected_output_sequence)
637      self.assertAllClose(final_state, expected_final_state)
638    def testVariableLengthAllEmpty(self, use_tf_function, unroll_fn):
639      if use_tf_function:
640        unroll_fn = tf.function(unroll_fn)
641      initial_state = self.core.initial_state(self.batch_size)
642      input_sequence = tf.random.uniform([self.num_steps, self.batch_size, 1])
643      output_sequence, final_state = unroll_fn(
644          self.core,
645          input_sequence,
646          initial_state,
647          sequence_length=tf.zeros(self.batch_size, tf.int32))
648      self.assertAllClose(output_sequence, tf.zeros_like(output_sequence))
649      self.assertAllClose(final_state[0], self.num_steps)
650      self.assertAllClose(final_state[1], initial_state[1])
651  class UnknownStepsUnrollTest(test_utils.TestCase):
652    def setUp(self):
653      super().setUp()
654      self.num_steps = 5
655      self.batch_size = 3
656      self.hidden_size = 2
657      self.core = Counter(self.hidden_size)
658    def testStaticUnroll(self):
659      def do_unroll(input_sequence):
660        initial_state = self.core.initial_state(self.batch_size)
661        return recurrent.static_unroll(self.core, input_sequence, initial_state)
662      with self.assertRaisesRegex(
663          ValueError, "must have a statically known number of time steps"):
664        tf.function(do_unroll).get_concrete_function(
665            tf.TensorSpec([None, None, 1]))
666    def testDynamicUnroll(self):
667      def do_unroll(input_sequence):
668        initial_state = self.core.initial_state(self.batch_size)
669        return recurrent.dynamic_unroll(self.core, input_sequence, initial_state)
670      cf = tf.function(do_unroll).get_concrete_function(
671          tf.TensorSpec([None, None, 1]))
672      output_sequence, unused_final_state = cf(
673          tf.random.uniform([self.num_steps, self.batch_size, 1]))
674      self.assertEqual(output_sequence.shape[0], self.num_steps)
675    @unittest.skip("b/141910613")
676    def testDynamicUnrollInconsistentSteps(self):
677      def do_unroll(*input_sequence):
678        return recurrent.dynamic_unroll(lambda inputs, _: inputs, input_sequence,
679                                        ())
680      cf = tf.function(do_unroll).get_concrete_function(
681          tf.TensorSpec([None, None, 1]), tf.TensorSpec([None, None, 1]))
682      with self.assertRaisesRegex(tf.errors.InvalidArgumentError,
683                                  "must have consistent number of time steps"):
684        cf(
685            tf.random.uniform([self.num_steps, self.batch_size, 1]),
686            tf.random.uniform([self.num_steps + 1, self.batch_size, 1]))
687  if __name__ == "__main__":
688    tf.test.main()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-multibox_loss.py</div>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-recurrent_test.py</div>
                <div class="column column_space"><pre><code>378              maskiou_t = torch.cat(maskiou_t_list)
379              label_t = torch.cat(label_t_list)
380              maskiou_net_input = torch.cat(maskiou_net_input_list)
381              num_samples = maskiou_t.size(0)
</pre></code></div>
                <div class="column column_space"><pre><code>257          w_i_init=initializers.Ones(),
258          w_h_init=initializers.Ones(),
259          b_init=initializers.Ones())
260      input_sequence = tf.random.uniform([1, self.batch_size, self.input_size])
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    