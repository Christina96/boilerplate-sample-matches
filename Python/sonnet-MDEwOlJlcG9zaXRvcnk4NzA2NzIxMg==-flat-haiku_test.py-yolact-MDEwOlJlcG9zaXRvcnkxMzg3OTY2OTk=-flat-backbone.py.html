
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 12.099644128113878%, Tokens: 15, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-haiku_test.py</h3>
            <pre><code>1  from absl.testing import parameterized
2  import sonnet as snt
3  from sonnet.src import test_utils
4  from sonnet.src.functional import haiku as hk
5  import tensorflow as tf
6  import tree
7  class TensorVariableTest(test_utils.TestCase, parameterized.TestCase):
8    def test_initial_value(self):
9      with hk.variables():
10        v = tf.Variable(tf.ones([]))
11      self.assertIsInstance(v, hk.TensorVariable)
12      self.assertAllEqual(v, 1)
13      self.assertAllEqual(v.read_value(), 1)
14      self.assertAllEqual(v.tensor_value, 1)
15    @parameterized.parameters(None, True, False)
16    def test_trainable(self, trainable):
17      with hk.variables():
18        v = tf.Variable(1., trainable=trainable)
19      if trainable is None:
20        self.assertTrue(v.trainable)
21      else:
22        self.assertEqual(v.trainable, trainable)
23    def test_name(self):
24      with hk.variables():
25        v = tf.Variable(tf.ones([]), name="v")
26      self.assertEqual(v.name, "v:0")
27    def test_name_with_scope(self):
28      with hk.variables(), tf.name_scope("foo"), tf.name_scope("bar"):
29        v = tf.Variable(tf.ones([]), name="v")
30      self.assertEqual(v.name, "foo/bar/v:0")
31    @parameterized.parameters(([],), ([1, 2, 3],))
32    def test_shape(self, shape):
33      with hk.variables():
34        v = tf.Variable(tf.ones(shape))
35      self.assertEqual(shape, v.shape.as_list())
36    @parameterized.parameters(tf.float32, tf.int32)
37    def test_dtype(self, dtype):
38      with hk.variables():
39        v = tf.Variable(tf.ones([], dtype=dtype))
40      self.assertEqual(dtype, v.dtype)
41    def test_attributes_do_not_notify(self):
42      with hk.variables():
43        v = tf.Variable(1.)
44        s = tf.Variable(1., trainable=False)
45      def f():
46        for c in (v, s):
<span onclick='openModal()' class='match'>47          self.assertIsNotNone(c.shape)
48          self.assertIsNotNone(c.dtype)
49          self.assertIsNotNone(c.trainable)
50          self.assertIsNotNone(c.name)
51          self.assertIsNotNone(c.device)
</span>52      f = hk.transform_with_state(f)
53      params, state = f.init()
54      self.assertEmpty(params)
55      self.assertEmpty(state)
56      out, state = f.apply(params, state)
57      self.assertIsNone(out)
58      self.assertEmpty(state)
59    def test_read_captured_variables_included(self):
60      with hk.variables():
61        v = tf.Variable(1.)
62        s = tf.Variable(1., trainable=False)
63      f = hk.transform_with_state(lambda: (v.read_value() + s.read_value()))
64      params, state = f.init()
65      self.assertEqual(params, {v.ref(): v.tensor_value})
66      self.assertEqual(state, {s.ref(): s.tensor_value})
67    def test_captured_variable_from_other_function_raises(self):
68      def f(model):
69        if not model:
70          model.append(tf.Variable(1.))
71          model.append(tf.Variable(1., trainable=False))
72        return sum(model)
73      f = hk.transform_with_state(f)
74      model = []
75      params, state = f.init(model)
76      self.assertLen(params, 1)
77      self.assertLen(state, 1)
78      with self.assertRaisesRegex(ValueError, "TensorVariable .* has no value"):
79        f.init(model)
80    def test_assign(self):
81      with hk.variables():
82        v = tf.Variable(tf.ones([]))
83      v.assign(tf.zeros([]))
84      self.assertAllEqual(v.numpy(), 0)
85      self.assertAllEqual(v.read_value().numpy(), 0)
86      self.assertAllEqual(v.tensor_value.numpy(), 0)
87    def test_assign_add(self):
88      with hk.variables():
89        v = tf.Variable(tf.ones([]))
90      v.assign_add(1.)
91      self.assertAllEqual(v.numpy(), 2)
92      self.assertAllEqual(v.read_value().numpy(), 2)
93      self.assertAllEqual(v.tensor_value.numpy(), 2)
94    def test_assign_sub(self):
95      with hk.variables():
96        v = tf.Variable(tf.ones([]))
97      v.assign_sub(1.)
98      self.assertAllEqual(v.numpy(), 0)
99      self.assertAllEqual(v.read_value().numpy(), 0)
100      self.assertAllEqual(v.tensor_value.numpy(), 0)
101  class NetworkTest(test_utils.TestCase, parameterized.TestCase):
102    def test_transform(self):
103      mod = snt.Linear(1, w_init=tf.ones)
104      snt.allow_empty_variables(mod)
105      self.assertEmpty(mod.variables)
106      f = hk.transform(mod)
107      x = tf.ones([1, 1])
108      params = f.init(x)
109      self.assertLen(params.items(), 2)
110      self.assertAllEqual(params[mod.w.ref()], [[1.]])
111      self.assertAllEqual(params[mod.b.ref()], [0.])
112      y = f.apply(params, x)
113      self.assertEqual(y, [[1.]])
114      params = tree.map_structure(lambda p: p + 1, params)
115      y = f.apply(params, x)
116      self.assertEqual(y, [[3.]])
117    def test_initial_values_preserved(self):
118      with hk.variables():
119        v = tf.Variable(0)
120        v.assign(1)
121      def assert_values():
122        self.assertEqual(v.initial_tensor_value.numpy(), 0)
123        self.assertEqual(v.tensor_value.numpy(), 1)
124      assert_values()
125      f = hk.transform(lambda: v.assign(2))
126      assert_values()
127      params = f.init()
128      assert_values()
129      f.apply(params)
130      assert_values()
131    def test_variables_in_transform_set_to_none(self):
132      mod = snt.Bias()
133      f = hk.transform(mod)
134      params = f.init(tf.ones([1, 1]))  # Will create `mod.b`.
135      self.assertIsNone(mod.b.tensor_value)
136      self.assertIsNone(mod.b.initial_tensor_value)
137      y = f.apply(params, tf.ones([1, 1]))
138      self.assertAllEqual(y.numpy(), [[1.]])
139      self.assertIsNone(mod.b.tensor_value)
140      self.assertIsNone(mod.b.initial_tensor_value)
141    def test_disallows_variables_in_apply(self):
142      _, apply_fn = hk.transform(lambda: tf.Variable(1))
143      with self.assertRaisesRegex(ValueError,
144                                  "Apply function cannot create new variables"):
145        apply_fn({})
146    def test_state_returns_initial_value(self):
147      with hk.variables():
148        v = tf.Variable(0, trainable=False)
149      f = hk.transform_with_state(lambda: v.assign(1))
150      params, state = f.init()
151      initial_v = state[v.ref()]
152      self.assertEqual(initial_v.numpy(), 0)
153      y, state = f.apply(params, state)
154      final_v = state[v.ref()]
155      self.assertEqual(y.numpy(), 1)
156      self.assertEqual(final_v.numpy(), 1)
157    def test_state_counter(self):
158      with hk.variables():
159        v = tf.Variable(0, trainable=False)
160      f = hk.transform_with_state(lambda: v.assign_add(1))
161      params, initial_state = f.init()
162      for _ in range(2):
163        state = initial_state
164        for i in range(10):
165          y, state = f.apply(params, state)
166          self.assertEqual(y.numpy(), i + 1)
167    def test_state_ema(self):
168      with hk.variables():
169        ema = snt.ExponentialMovingAverage(decay=0.5)
170      ema = hk.transform_with_state(ema)
171      params, state = ema.init(3.0)
172      y, state = ema.apply(params, state, 3.0)
173      self.assertAllClose(y.numpy(), 3.0)
174      y, state = ema.apply(params, state, 6.0)
175      self.assertAllClose(y.numpy(), 5.0)
176  if __name__ == "__main__":
177    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-backbone.py</h3>
            <pre><code>1  import torch
2  import torch.nn as nn
3  import pickle
4  from collections import OrderedDict
5  try:
6      from dcn_v2 import DCN
7  except ImportError:
8      def DCN(*args, **kwdargs):
9          raise Exception('DCN could not be imported. If you want to use YOLACT++ models, compile DCN. Check the README for instructions.')
10  class Bottleneck(nn.Module):
11      expansion = 4
12      def __init__(self, inplanes, planes, stride=1, downsample=None, norm_layer=nn.BatchNorm2d, dilation=1, use_dcn=False):
13          super(Bottleneck, self).__init__()
14          self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False, dilation=dilation)
15          self.bn1 = norm_layer(planes)
16          if use_dcn:
17              self.conv2 = DCN(planes, planes, kernel_size=3, stride=stride,
18                                  padding=dilation, dilation=dilation, deformable_groups=1)
19              self.conv2.bias.data.zero_()
20              self.conv2.conv_offset_mask.weight.data.zero_()
21              self.conv2.conv_offset_mask.bias.data.zero_()
22          else:
23              self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
24                                  padding=dilation, bias=False, dilation=dilation)
25          self.bn2 = norm_layer(planes)
26          self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False, dilation=dilation)
27          self.bn3 = norm_layer(planes * 4)
28          self.relu = nn.ReLU(inplace=True)
29          self.downsample = downsample
30          self.stride = stride
31      def forward(self, x):
32          residual = x
33          out = self.conv1(x)
34          out = self.bn1(out)
35          out = self.relu(out)
36          out = self.conv2(out)
37          out = self.bn2(out)
38          out = self.relu(out)
39          out = self.conv3(out)
40          out = self.bn3(out)
41          if self.downsample is not None:
42              residual = self.downsample(x)
43          out += residual
44          out = self.relu(out)
45          return out
46  class ResNetBackbone(nn.Module):
47      def __init__(self, layers, dcn_layers=[0, 0, 0, 0], dcn_interval=1, atrous_layers=[], block=Bottleneck, norm_layer=nn.BatchNorm2d):
48          super().__init__()
49          self.num_base_layers = len(layers)
50          self.layers = nn.ModuleList()
51          self.channels = []
52          self.norm_layer = norm_layer
53          self.dilation = 1
54          self.atrous_layers = atrous_layers
55          self.inplanes = 64
56          self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
57          self.bn1 = norm_layer(64)
58          self.relu = nn.ReLU(inplace=True)
59          self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
60          self._make_layer(block, 64, layers[0], dcn_layers=dcn_layers[0], dcn_interval=dcn_interval)
61          self._make_layer(block, 128, layers[1], stride=2, dcn_layers=dcn_layers[1], dcn_interval=dcn_interval)
62          self._make_layer(block, 256, layers[2], stride=2, dcn_layers=dcn_layers[2], dcn_interval=dcn_interval)
63          self._make_layer(block, 512, layers[3], stride=2, dcn_layers=dcn_layers[3], dcn_interval=dcn_interval)
64          self.backbone_modules = [m for m in self.modules() if isinstance(m, nn.Conv2d)]
65      def _make_layer(self, block, planes, blocks, stride=1, dcn_layers=0, dcn_interval=1):
66          downsample = None
67          if stride != 1 or self.inplanes != planes * block.expansion:
68              if len(self.layers) in self.atrous_layers:
69                  self.dilation += 1
70                  stride = 1
71              downsample = nn.Sequential(
72                  nn.Conv2d(self.inplanes, planes * block.expansion,
73                            kernel_size=1, stride=stride, bias=False,
74                            dilation=self.dilation),
75                  self.norm_layer(planes * block.expansion),
76              )
77          layers = []
78          use_dcn = (dcn_layers >= blocks)
79          layers.append(block(self.inplanes, planes, stride, downsample, self.norm_layer, self.dilation, use_dcn=use_dcn))
80          self.inplanes = planes * block.expansion
81          for i in range(1, blocks):
82              use_dcn = ((i+dcn_layers) >= blocks) and (i % dcn_interval == 0)
83              layers.append(block(self.inplanes, planes, norm_layer=self.norm_layer, use_dcn=use_dcn))
84          layer = nn.Sequential(*layers)
85          self.channels.append(planes * block.expansion)
86          self.layers.append(layer)
87          return layer
88      def forward(self, x):
89          x = self.conv1(x)
90          x = self.bn1(x)
91          x = self.relu(x)
92          x = self.maxpool(x)
93          outs = []
94          for layer in self.layers:
95              x = layer(x)
96              outs.append(x)
97          return tuple(outs)
98      def init_backbone(self, path):
99          state_dict = torch.load(path)
100          keys = list(state_dict)
101          for key in keys:
102              if key.startswith('layer'):
103                  idx = int(key[5])
104                  new_key = 'layers.' + str(idx-1) + key[6:]
105                  state_dict[new_key] = state_dict.pop(key)
106          self.load_state_dict(state_dict, strict=False)
107      def add_layer(self, conv_channels=1024, downsample=2, depth=1, block=Bottleneck):
108          self._make_layer(block, conv_channels // block.expansion, blocks=depth, stride=downsample)
109  class ResNetBackboneGN(ResNetBackbone):
110      def __init__(self, layers, num_groups=32):
111          super().__init__(layers, norm_layer=lambda x: nn.GroupNorm(num_groups, x))
112      def init_backbone(self, path):
113          with open(path, 'rb') as f:
114              state_dict = pickle.load(f, encoding='latin1') # From the detectron source
115              state_dict = state_dict['blobs']
116          our_state_dict_keys = list(self.state_dict().keys())
117          new_state_dict = {}
118          gn_trans     = lambda x: ('gn_s' if x == 'weight' else 'gn_b')
119          layeridx2res = lambda x: 'res' + str(int(x)+2)
120          block2branch = lambda x: 'branch2' + ('a', 'b', 'c')[int(x[-1:])-1]
121          for key in our_state_dict_keys:
122              parts = key.split('.')
123              transcribed_key = ''
124              if (parts[0] == 'conv1'):
125                  transcribed_key = 'conv1_w'
126              elif (parts[0] == 'bn1'):
127                  transcribed_key = 'conv1_' + gn_trans(parts[1])
128              elif (parts[0] == 'layers'):
129                  if int(parts[1]) >= self.num_base_layers: continue
130                  transcribed_key = layeridx2res(parts[1])
131                  transcribed_key += '_' + parts[2] + '_'
132                  if parts[3] == 'downsample':
133                      transcribed_key += 'branch1_'
134                      if parts[4] == '0':
135                          transcribed_key += 'w'
136                      else:
137                          transcribed_key += gn_trans(parts[5])
138                  else:
139                      transcribed_key += block2branch(parts[3]) + '_'
140                      if 'conv' in parts[3]:
141                          transcribed_key += 'w'
142                      else:
143                          transcribed_key += gn_trans(parts[4])
144              new_state_dict[key] = torch.Tensor(state_dict[transcribed_key])
145          self.load_state_dict(new_state_dict, strict=False)
146  def darknetconvlayer(in_channels, out_channels, *args, **kwdargs):
147      return nn.Sequential(
148          nn.Conv2d(in_channels, out_channels, *args, **kwdargs, bias=False),
149          nn.BatchNorm2d(out_channels),
150          nn.LeakyReLU(0.1, inplace=True)
151      )
152  class DarkNetBlock(nn.Module):
153      expansion = 2
154      def __init__(self, in_channels, channels):
155          super().__init__()
156          self.conv1 = darknetconvlayer(in_channels, channels,                  kernel_size=1)
157          self.conv2 = darknetconvlayer(channels,    channels * self.expansion, kernel_size=3, padding=1)
158      def forward(self, x):
159          return self.conv2(self.conv1(x)) + x
160  class DarkNetBackbone(nn.Module):
161      def __init__(self, layers=[1, 2, 8, 8, 4], block=DarkNetBlock):
162          super().__init__()
163          self.num_base_layers = len(layers)
164          self.layers = nn.ModuleList()
165          self.channels = []
166          self._preconv = darknetconvlayer(3, 32, kernel_size=3, padding=1)
167          self.in_channels = 32
<span onclick='openModal()' class='match'>168          self._make_layer(block, 32,  layers[0])
169          self._make_layer(block, 64,  layers[1])
170          self._make_layer(block, 128, layers[2])
171          self._make_layer(block, 256, layers[3])
172          self._make_layer(block, 512, layers[4])
</span>173          self.backbone_modules = [m for m in self.modules() if isinstance(m, nn.Conv2d)]
174      def _make_layer(self, block, channels, num_blocks, stride=2):
175          layer_list = []
176          layer_list.append(
177              darknetconvlayer(self.in_channels, channels * block.expansion,
178                               kernel_size=3, padding=1, stride=stride))
179          self.in_channels = channels * block.expansion
180          layer_list += [block(self.in_channels, channels) for _ in range(num_blocks)]
181          self.channels.append(self.in_channels)
182          self.layers.append(nn.Sequential(*layer_list))
183      def forward(self, x):
184          x = self._preconv(x)
185          outs = []
186          for layer in self.layers:
187              x = layer(x)
188              outs.append(x)
189          return tuple(outs)
190      def add_layer(self, conv_channels=1024, stride=2, depth=1, block=DarkNetBlock):
191          self._make_layer(block, conv_channels // block.expansion, num_blocks=depth, stride=stride)
192      def init_backbone(self, path):
193          self.load_state_dict(torch.load(path), strict=False)
194  class VGGBackbone(nn.Module):
195      def __init__(self, cfg, extra_args=[], norm_layers=[]):
196          super().__init__()
197          self.channels = []
198          self.layers = nn.ModuleList()
199          self.in_channels = 3
200          self.extra_args = list(reversed(extra_args)) # So I can use it as a stack
201          self.total_layer_count = 0
202          self.state_dict_lookup = {}
203          for idx, layer_cfg in enumerate(cfg):
204              self._make_layer(layer_cfg)
205          self.norms = nn.ModuleList([nn.BatchNorm2d(self.channels[l]) for l in norm_layers])
206          self.norm_lookup = {l: idx for idx, l in enumerate(norm_layers)}
207          self.backbone_modules = [m for m in self.modules() if isinstance(m, nn.Conv2d)]
208      def _make_layer(self, cfg):
209          layers = []
210          for v in cfg:
211              args = None
212              if isinstance(v, tuple):
213                  args = v[1]
214                  v = v[0]
215              if v == 'M':
216                  if args is None:
217                      args = {'kernel_size': 2, 'stride': 2}
218                  layers.append(nn.MaxPool2d(**args))
219              else:
220                  cur_layer_idx = self.total_layer_count + len(layers)
221                  self.state_dict_lookup[cur_layer_idx] = '%d.%d' % (len(self.layers), len(layers))
222                  if args is None:
223                      args = {'kernel_size': 3, 'padding': 1}
224                  layers.append(nn.Conv2d(self.in_channels, v, **args))
225                  layers.append(nn.ReLU(inplace=True))
226                  self.in_channels = v
227          self.total_layer_count += len(layers)
228          self.channels.append(self.in_channels)
229          self.layers.append(nn.Sequential(*layers))
230      def forward(self, x):
231          outs = []
232          for idx, layer in enumerate(self.layers):
233              x = layer(x)
234              if idx in self.norm_lookup:
235                  x = self.norms[self.norm_lookup[idx]](x)
236              outs.append(x)
237          return tuple(outs)
238      def transform_key(self, k):
239          vals = k.split('.')
240          layerIdx = self.state_dict_lookup[int(vals[0])]
241          return 'layers.%s.%s' % (layerIdx, vals[1])
242      def init_backbone(self, path):
243          state_dict = torch.load(path)
244          state_dict = OrderedDict([(self.transform_key(k), v) for k,v in state_dict.items()])
245          self.load_state_dict(state_dict, strict=False)
246      def add_layer(self, conv_channels=128, downsample=2):
247          if len(self.extra_args) > 0:
248              conv_channels, downsample = self.extra_args.pop()
249          padding = 1 if downsample > 1 else 0
250          layer = nn.Sequential(
251              nn.Conv2d(self.in_channels, conv_channels, kernel_size=1),
252              nn.ReLU(inplace=True),
253              nn.Conv2d(conv_channels, conv_channels*2, kernel_size=3, stride=downsample, padding=padding),
254              nn.ReLU(inplace=True)
255          )
256          self.in_channels = conv_channels*2
257          self.channels.append(self.in_channels)
258          self.layers.append(layer)
259  def construct_backbone(cfg):
260      backbone = cfg.type(*cfg.args)
261      num_layers = max(cfg.selected_layers) + 1
262      while len(backbone.layers) < num_layers:
263          backbone.add_layer()
264      return backbone
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-haiku_test.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-backbone.py</div>
                </div>
                <div class="column column_space"><pre><code>47          self.assertIsNotNone(c.shape)
48          self.assertIsNotNone(c.dtype)
49          self.assertIsNotNone(c.trainable)
50          self.assertIsNotNone(c.name)
51          self.assertIsNotNone(c.device)
</pre></code></div>
                <div class="column column_space"><pre><code>168          self._make_layer(block, 32,  layers[0])
169          self._make_layer(block, 64,  layers[1])
170          self._make_layer(block, 128, layers[2])
171          self._make_layer(block, 256, layers[3])
172          self._make_layer(block, 512, layers[4])
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    