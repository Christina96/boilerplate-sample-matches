<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for common_1.py &amp; minoto.py</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for common_1.py &amp; minoto.py
      </h3>
<h1 align="center">
        1.2%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>common_1.py (0.6497871%)<th>minoto.py (36.25%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(1290-1295)<td><a href="#" name="0">(34-41)</a><td align="center"><font color="#ff0000">16</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(2662-2666)<td><a href="#" name="1">(17-20)</a><td align="center"><font color="#cf0000">13</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>common_1.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 from __future__ import unicode_literals
2 import base64
3 import datetime
4 import hashlib
5 import json
6 import netrc
7 import os
8 import random
9 import re
10 import socket
11 import ssl
12 import sys
13 import time
14 import math
15 from ..compat import (
16     compat_cookiejar_Cookie,
17     compat_cookies_SimpleCookie,
18     compat_etree_Element,
19     compat_etree_fromstring,
20     compat_getpass,
21     compat_integer_types,
22     compat_http_client,
23     compat_os_name,
24     compat_str,
25     compat_urllib_error,
26     compat_urllib_parse_unquote,
27     compat_urllib_parse_urlencode,
28     compat_urllib_request,
29     compat_urlparse,
30     compat_xml_parse_error,
31 )
32 from ..downloader.f4m import (
33     get_base_url,
34     remove_encrypted_media,
35 )
36 from ..utils import (
37     NO_DEFAULT,
38     age_restricted,
39     base_url,
40     bug_reports_message,
41     clean_html,
42     compiled_regex_type,
43     determine_ext,
44     determine_protocol,
45     dict_get,
46     error_to_compat_str,
47     ExtractorError,
48     extract_attributes,
49     fix_xml_ampersands,
50     float_or_none,
51     GeoRestrictedError,
52     GeoUtils,
53     int_or_none,
54     js_to_json,
55     JSON_LD_RE,
56     mimetype2ext,
57     orderedSet,
58     parse_bitrate,
59     parse_codecs,
60     parse_duration,
61     parse_iso8601,
62     parse_m3u8_attributes,
63     parse_resolution,
64     RegexNotFoundError,
65     sanitized_Request,
66     sanitize_filename,
67     str_or_none,
68     str_to_int,
69     strip_or_none,
70     unescapeHTML,
71     unified_strdate,
72     unified_timestamp,
73     update_Request,
74     update_url_query,
75     urljoin,
76     url_basename,
77     url_or_none,
78     xpath_element,
79     xpath_text,
80     xpath_with_ns,
81 )
82 class InfoExtractor(object):
83     _ready = False
84     _downloader = None
85     _x_forwarded_for_ip = None
86     _GEO_BYPASS = True
87     _GEO_COUNTRIES = None
88     _GEO_IP_BLOCKS = None
89     _WORKING = True
90     def __init__(self, downloader=None):
91         self._ready = False
92         self._x_forwarded_for_ip = None
93         self.set_downloader(downloader)
94     @classmethod
95     def suitable(cls, url):
96         if '_VALID_URL_RE' not in cls.__dict__:
97             cls._VALID_URL_RE = re.compile(cls._VALID_URL)
98         return cls._VALID_URL_RE.match(url) is not None
99     @classmethod
100     def _match_id(cls, url):
101         if '_VALID_URL_RE' not in cls.__dict__:
102             cls._VALID_URL_RE = re.compile(cls._VALID_URL)
103         m = cls._VALID_URL_RE.match(url)
104         assert m
105         return compat_str(m.group('id'))
106     @classmethod
107     def working(cls):
108         return cls._WORKING
109     def initialize(self):
110         self._initialize_geo_bypass({
111             'countries': self._GEO_COUNTRIES,
112             'ip_blocks': self._GEO_IP_BLOCKS,
113         })
114         if not self._ready:
115             self._real_initialize()
116             self._ready = True
117     def _initialize_geo_bypass(self, geo_bypass_context):
118         if not self._x_forwarded_for_ip:
119             if not self._downloader.params.get('geo_bypass', True):
120                 return
121             if not geo_bypass_context:
122                 geo_bypass_context = {}
123             if isinstance(geo_bypass_context, (list, tuple)):
124                 geo_bypass_context = {
125                     'countries': geo_bypass_context,
126                 }
127             ip_block = self._downloader.params.get('geo_bypass_ip_block', None)
128             if not ip_block:
129                 ip_blocks = geo_bypass_context.get('ip_blocks')
130                 if self._GEO_BYPASS and ip_blocks:
131                     ip_block = random.choice(ip_blocks)
132             if ip_block:
133                 self._x_forwarded_for_ip = GeoUtils.random_ipv4(ip_block)
134                 if self._downloader.params.get('verbose', False):
135                     self._downloader.to_screen(
136                         '[debug] Using fake IP %s as X-Forwarded-For.'
137                         % self._x_forwarded_for_ip)
138                 return
139             country = self._downloader.params.get('geo_bypass_country', None)
140             if not country:
141                 countries = geo_bypass_context.get('countries')
142                 if self._GEO_BYPASS and countries:
143                     country = random.choice(countries)
144             if country:
145                 self._x_forwarded_for_ip = GeoUtils.random_ipv4(country)
146                 if self._downloader.params.get('verbose', False):
147                     self._downloader.to_screen(
148                         '[debug] Using fake IP %s (%s) as X-Forwarded-For.'
149                         % (self._x_forwarded_for_ip, country.upper()))
150     def extract(self, url):
151         try:
152             for _ in range(2):
153                 try:
154                     self.initialize()
155                     ie_result = self._real_extract(url)
156                     if self._x_forwarded_for_ip:
157                         ie_result['__x_forwarded_for_ip'] = self._x_forwarded_for_ip
158                     return ie_result
159                 except GeoRestrictedError as e:
160                     if self.__maybe_fake_ip_and_retry(e.countries):
161                         continue
162                     raise
163         except ExtractorError:
164             raise
165         except compat_http_client.IncompleteRead as e:
166             raise ExtractorError('A network error has occurred.', cause=e, expected=True)
167         except (KeyError, StopIteration) as e:
168             raise ExtractorError('An extractor error has occurred.', cause=e)
169     def __maybe_fake_ip_and_retry(self, countries):
170         if (not self._downloader.params.get('geo_bypass_country', None)
171                 and self._GEO_BYPASS
172                 and self._downloader.params.get('geo_bypass', True)
173                 and not self._x_forwarded_for_ip
174                 and countries):
175             country_code = random.choice(countries)
176             self._x_forwarded_for_ip = GeoUtils.random_ipv4(country_code)
177             if self._x_forwarded_for_ip:
178                 self.report_warning(
179                     'Video is geo restricted. Retrying extraction with fake IP %s (%s) as X-Forwarded-For.'
180                     % (self._x_forwarded_for_ip, country_code.upper()))
181                 return True
182         return False
183     def set_downloader(self, downloader):
184         self._downloader = downloader
185     def _real_initialize(self):
186         pass
187     def _real_extract(self, url):
188         pass
189     @classmethod
190     def ie_key(cls):
191         return compat_str(cls.__name__[:-2])
192     @property
193     def IE_NAME(self):
194         return compat_str(type(self).__name__[:-2])
195     @staticmethod
196     def __can_accept_status_code(err, expected_status):
197         assert isinstance(err, compat_urllib_error.HTTPError)
198         if expected_status is None:
199             return False
200         if isinstance(expected_status, compat_integer_types):
201             return err.code == expected_status
202         elif isinstance(expected_status, (list, tuple)):
203             return err.code in expected_status
204         elif callable(expected_status):
205             return expected_status(err.code) is True
206         else:
207             assert False
208     def _request_webpage(self, url_or_request, video_id, note=None, errnote=None, fatal=True, data=None, headers={}, query={}, expected_status=None):
209         if note is None:
210             self.report_download_webpage(video_id)
211         elif note is not False:
212             if video_id is None:
213                 self.to_screen('%s' % (note,))
214             else:
215                 self.to_screen('%s: %s' % (video_id, note))
216         if self._x_forwarded_for_ip:
217             if 'X-Forwarded-For' not in headers:
218                 headers['X-Forwarded-For'] = self._x_forwarded_for_ip
219         if isinstance(url_or_request, compat_urllib_request.Request):
220             url_or_request = update_Request(
221                 url_or_request, data=data, headers=headers, query=query)
222         else:
223             if query:
224                 url_or_request = update_url_query(url_or_request, query)
225             if data is not None or headers:
226                 url_or_request = sanitized_Request(url_or_request, data, headers)
227         exceptions = [compat_urllib_error.URLError, compat_http_client.HTTPException, socket.error]
228         if hasattr(ssl, 'CertificateError'):
229             exceptions.append(ssl.CertificateError)
230         try:
231             return self._downloader.urlopen(url_or_request)
232         except tuple(exceptions) as err:
233             if isinstance(err, compat_urllib_error.HTTPError):
234                 if self.__can_accept_status_code(err, expected_status):
235                     err.fp._error = err
236                     return err.fp
237             if errnote is False:
238                 return False
239             if errnote is None:
240                 errnote = 'Unable to download webpage'
241             errmsg = '%s: %s' % (errnote, error_to_compat_str(err))
242             if fatal:
243                 raise ExtractorError(errmsg, sys.exc_info()[2], cause=err)
244             else:
245                 self._downloader.report_warning(errmsg)
246                 return False
247     def _download_webpage_handle(self, url_or_request, video_id, note=None, errnote=None, fatal=True, encoding=None, data=None, headers={}, query={}, expected_status=None):
248         if isinstance(url_or_request, (compat_str, str)):
249             url_or_request = url_or_request.partition('#')[0]
250         urlh = self._request_webpage(url_or_request, video_id, note, errnote, fatal, data=data, headers=headers, query=query, expected_status=expected_status)
251         if urlh is False:
252             assert not fatal
253             return False
254         content = self._webpage_read_content(urlh, url_or_request, video_id, note, errnote, fatal, encoding=encoding)
255         return (content, urlh)
256     @staticmethod
257     def _guess_encoding_from_content(content_type, webpage_bytes):
258         m = re.match(r'[a-zA-Z0-9_.-]+/[a-zA-Z0-9_.-]+\s*;\s*charset=(.+)', content_type)
259         if m:
260             encoding = m.group(1)
261         else:
262             m = re.search(br'&lt;meta[^&gt;]+charset=[\'"]?([^\'")]+)[ /\'"&gt;]',
263                           webpage_bytes[:1024])
264             if m:
265                 encoding = m.group(1).decode('ascii')
266             elif webpage_bytes.startswith(b'\xff\xfe'):
267                 encoding = 'utf-16'
268             else:
269                 encoding = 'utf-8'
270         return encoding
271     def __check_blocked(self, content):
272         first_block = content[:512]
273         if ('&lt;title&gt;Access to this site is blocked&lt;/title&gt;' in content
274                 and 'Websense' in first_block):
275             msg = 'Access to this webpage has been blocked by Websense filtering software in your network.'
276             blocked_iframe = self._html_search_regex(
277                 r'&lt;iframe src="([^"]+)"', content,
278                 'Websense information URL', default=None)
279             if blocked_iframe:
280                 msg += ' Visit %s for more details' % blocked_iframe
281             raise ExtractorError(msg, expected=True)
282         if '&lt;title&gt;The URL you requested has been blocked&lt;/title&gt;' in first_block:
283             msg = (
284                 'Access to this webpage has been blocked by Indian censorship. '
285                 'Use a VPN or proxy server (with --proxy) to route around it.')
286             block_msg = self._html_search_regex(
287                 r'&lt;/h1&gt;&lt;p&gt;(.*?)&lt;/p&gt;',
288                 content, 'block message', default=None)
289             if block_msg:
290                 msg += ' (Message: "%s")' % block_msg.replace('\n', ' ')
291             raise ExtractorError(msg, expected=True)
292         if ('&lt;title&gt;TTK :: Доступ к ресурсу ограничен&lt;/title&gt;' in content
293                 and 'blocklist.rkn.gov.ru' in content):
294             raise ExtractorError(
295                 'Access to this webpage has been blocked by decision of the Russian government. '
296                 'Visit http://blocklist.rkn.gov.ru/ for a block reason.',
297                 expected=True)
298     def _webpage_read_content(self, urlh, url_or_request, video_id, note=None, errnote=None, fatal=True, prefix=None, encoding=None):
299         content_type = urlh.headers.get('Content-Type', '')
300         webpage_bytes = urlh.read()
301         if prefix is not None:
302             webpage_bytes = prefix + webpage_bytes
303         if not encoding:
304             encoding = self._guess_encoding_from_content(content_type, webpage_bytes)
305         if self._downloader.params.get('dump_intermediate_pages', False):
306             self.to_screen('Dumping request to ' + urlh.geturl())
307             dump = base64.b64encode(webpage_bytes).decode('ascii')
308             self._downloader.to_screen(dump)
309         if self._downloader.params.get('write_pages', False):
310             basen = '%s_%s' % (video_id, urlh.geturl())
311             if len(basen) &gt; 240:
312                 h = '___' + hashlib.md5(basen.encode('utf-8')).hexdigest()
313                 basen = basen[:240 - len(h)] + h
314             raw_filename = basen + '.dump'
315             filename = sanitize_filename(raw_filename, restricted=True)
316             self.to_screen('Saving request to ' + filename)
317             if compat_os_name == 'nt':
318                 absfilepath = os.path.abspath(filename)
319                 if len(absfilepath) &gt; 259:
320                     filename = '\\\\?\\' + absfilepath
321             with open(filename, 'wb') as outf:
322                 outf.write(webpage_bytes)
323         try:
324             content = webpage_bytes.decode(encoding, 'replace')
325         except LookupError:
326             content = webpage_bytes.decode('utf-8', 'replace')
327         self.__check_blocked(content)
328         return content
329     def _download_webpage(
330             self, url_or_request, video_id, note=None, errnote=None,
331             fatal=True, tries=1, timeout=5, encoding=None, data=None,
332             headers={}, query={}, expected_status=None):
333         success = False
334         try_count = 0
335         while success is False:
336             try:
337                 res = self._download_webpage_handle(
338                     url_or_request, video_id, note, errnote, fatal,
339                     encoding=encoding, data=data, headers=headers, query=query,
340                     expected_status=expected_status)
341                 success = True
342             except compat_http_client.IncompleteRead as e:
343                 try_count += 1
344                 if try_count &gt;= tries:
345                     raise e
346                 self._sleep(timeout, video_id)
347         if res is False:
348             return res
349         else:
350             content, _ = res
351             return content
352     def _download_xml_handle(
353             self, url_or_request, video_id, note='Downloading XML',
354             errnote='Unable to download XML', transform_source=None,
355             fatal=True, encoding=None, data=None, headers={}, query={},
356             expected_status=None):
357         res = self._download_webpage_handle(
358             url_or_request, video_id, note, errnote, fatal=fatal,
359             encoding=encoding, data=data, headers=headers, query=query,
360             expected_status=expected_status)
361         if res is False:
362             return res
363         xml_string, urlh = res
364         return self._parse_xml(
365             xml_string, video_id, transform_source=transform_source,
366             fatal=fatal), urlh
367     def _download_xml(
368             self, url_or_request, video_id,
369             note='Downloading XML', errnote='Unable to download XML',
370             transform_source=None, fatal=True, encoding=None,
371             data=None, headers={}, query={}, expected_status=None):
372         res = self._download_xml_handle(
373             url_or_request, video_id, note=note, errnote=errnote,
374             transform_source=transform_source, fatal=fatal, encoding=encoding,
375             data=data, headers=headers, query=query,
376             expected_status=expected_status)
377         return res if res is False else res[0]
378     def _parse_xml(self, xml_string, video_id, transform_source=None, fatal=True):
379         if transform_source:
380             xml_string = transform_source(xml_string)
381         try:
382             return compat_etree_fromstring(xml_string.encode('utf-8'))
383         except compat_xml_parse_error as ve:
384             errmsg = '%s: Failed to parse XML ' % video_id
385             if fatal:
386                 raise ExtractorError(errmsg, cause=ve)
387             else:
388                 self.report_warning(errmsg + str(ve))
389     def _download_json_handle(
390             self, url_or_request, video_id, note='Downloading JSON metadata',
391             errnote='Unable to download JSON metadata', transform_source=None,
392             fatal=True, encoding=None, data=None, headers={}, query={},
393             expected_status=None):
394         res = self._download_webpage_handle(
395             url_or_request, video_id, note, errnote, fatal=fatal,
396             encoding=encoding, data=data, headers=headers, query=query,
397             expected_status=expected_status)
398         if res is False:
399             return res
400         json_string, urlh = res
401         return self._parse_json(
402             json_string, video_id, transform_source=transform_source,
403             fatal=fatal), urlh
404     def _download_json(
405             self, url_or_request, video_id, note='Downloading JSON metadata',
406             errnote='Unable to download JSON metadata', transform_source=None,
407             fatal=True, encoding=None, data=None, headers={}, query={},
408             expected_status=None):
409         res = self._download_json_handle(
410             url_or_request, video_id, note=note, errnote=errnote,
411             transform_source=transform_source, fatal=fatal, encoding=encoding,
412             data=data, headers=headers, query=query,
413             expected_status=expected_status)
414         return res if res is False else res[0]
415     def _parse_json(self, json_string, video_id, transform_source=None, fatal=True):
416         if transform_source:
417             json_string = transform_source(json_string)
418         try:
419             return json.loads(json_string)
420         except ValueError as ve:
421             errmsg = '%s: Failed to parse JSON ' % video_id
422             if fatal:
423                 raise ExtractorError(errmsg, cause=ve)
424             else:
425                 self.report_warning(errmsg + str(ve))
426     def report_warning(self, msg, video_id=None):
427         idstr = '' if video_id is None else '%s: ' % video_id
428         self._downloader.report_warning(
429             '[%s] %s%s' % (self.IE_NAME, idstr, msg))
430     def to_screen(self, msg):
431         self._downloader.to_screen('[%s] %s' % (self.IE_NAME, msg))
432     def report_extraction(self, id_or_name):
433         self.to_screen('%s: Extracting information' % id_or_name)
434     def report_download_webpage(self, video_id):
435         self.to_screen('%s: Downloading webpage' % video_id)
436     def report_age_confirmation(self):
437         self.to_screen('Confirming age')
438     def report_login(self):
439         self.to_screen('Logging in')
440     @staticmethod
441     def raise_login_required(msg='This video is only available for registered users'):
442         raise ExtractorError(
443             '%s. Use --username and --password or --netrc to provide account credentials.' % msg,
444             expected=True)
445     @staticmethod
446     def raise_geo_restricted(msg='This video is not available from your location due to geo restriction', countries=None):
447         raise GeoRestrictedError(msg, countries=countries)
448     @staticmethod
449     def url_result(url, ie=None, video_id=None, video_title=None):
450         video_info = {'_type': 'url',
451                       'url': url,
452                       'ie_key': ie}
453         if video_id is not None:
454             video_info['id'] = video_id
455         if video_title is not None:
456             video_info['title'] = video_title
457         return video_info
458     def playlist_from_matches(self, matches, playlist_id=None, playlist_title=None, getter=None, ie=None):
459         urls = orderedSet(
460             self.url_result(self._proto_relative_url(getter(m) if getter else m), ie)
461             for m in matches)
462         return self.playlist_result(
463             urls, playlist_id=playlist_id, playlist_title=playlist_title)
464     @staticmethod
465     def playlist_result(entries, playlist_id=None, playlist_title=None, playlist_description=None):
466         video_info = {'_type': 'playlist',
467                       'entries': entries}
468         if playlist_id:
469             video_info['id'] = playlist_id
470         if playlist_title:
471             video_info['title'] = playlist_title
472         if playlist_description:
473             video_info['description'] = playlist_description
474         return video_info
475     def _search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None):
476         if isinstance(pattern, (str, compat_str, compiled_regex_type)):
477             mobj = re.search(pattern, string, flags)
478         else:
479             for p in pattern:
480                 mobj = re.search(p, string, flags)
481                 if mobj:
482                     break
483         if not self._downloader.params.get('no_color') and compat_os_name != 'nt' and sys.stderr.isatty():
484             _name = '\033[0;34m%s\033[0m' % name
485         else:
486             _name = name
487         if mobj:
488             if group is None:
489                 return next(g for g in mobj.groups() if g is not None)
490             else:
491                 return mobj.group(group)
492         elif default is not NO_DEFAULT:
493             return default
494         elif fatal:
495             raise RegexNotFoundError('Unable to extract %s' % _name)
496         else:
497             self._downloader.report_warning('unable to extract %s' % _name + bug_reports_message())
498             return None
499     def _html_search_regex(self, pattern, string, name, default=NO_DEFAULT, fatal=True, flags=0, group=None):
500         res = self._search_regex(pattern, string, name, default, fatal, flags, group)
501         if res:
502             return clean_html(res).strip()
503         else:
504             return res
505     def _get_netrc_login_info(self, netrc_machine=None):
506         username = None
507         password = None
508         netrc_machine = netrc_machine or self._NETRC_MACHINE
509         if self._downloader.params.get('usenetrc', False):
510             try:
511                 info = netrc.netrc().authenticators(netrc_machine)
512                 if info is not None:
513                     username = info[0]
514                     password = info[2]
515                 else:
516                     raise netrc.NetrcParseError(
517                         'No authenticators for %s' % netrc_machine)
518             except (IOError, netrc.NetrcParseError) as err:
519                 self._downloader.report_warning(
520                     'parsing .netrc: %s' % error_to_compat_str(err))
521         return username, password
522     def _get_login_info(self, username_option='username', password_option='password', netrc_machine=None):
523         if self._downloader is None:
524             return (None, None)
525         downloader_params = self._downloader.params
526         if downloader_params.get(username_option) is not None:
527             username = downloader_params[username_option]
528             password = downloader_params[password_option]
529         else:
530             username, password = self._get_netrc_login_info(netrc_machine)
531         return username, password
532     def _get_tfa_info(self, note='two-factor verification code'):
533         if self._downloader is None:
534             return None
535         downloader_params = self._downloader.params
536         if downloader_params.get('twofactor') is not None:
537             return downloader_params['twofactor']
538         return compat_getpass('Type %s and press [Return]: ' % note)
539     @staticmethod
540     def _og_regexes(prop):
541         content_re = r'content=(?:"([^"]+?)"|\'([^\']+?)\'|\s*([^\s"\'=&lt;&gt;`]+?))'
542         property_re = (r'(?:name|property)=(?:\'og[:-]%(prop)s\'|"og[:-]%(prop)s"|\s*og[:-]%(prop)s\b)'
543                        % {'prop': re.escape(prop)})
544         template = r'&lt;meta[^&gt;]+?%s[^&gt;]+?%s'
545         return [
546             template % (property_re, content_re),
547             template % (content_re, property_re),
548         ]
549     @staticmethod
550     def _meta_regex(prop):
551         return r'''(?isx)&lt;meta
552                     (?=[^&gt;]+(?:itemprop|name|property|id|http-equiv)=(["\']?)%s\1)
553                     [^&gt;]+?content=(["\'])(?P&lt;content&gt;.*?)\2''' % re.escape(prop)
554     def _og_search_property(self, prop, html, name=None, **kargs):
555         if not isinstance(prop, (list, tuple)):
556             prop = [prop]
557         if name is None:
558             name = 'OpenGraph %s' % prop[0]
559         og_regexes = []
560         for p in prop:
561             og_regexes.extend(self._og_regexes(p))
562         escaped = self._search_regex(og_regexes, html, name, flags=re.DOTALL, **kargs)
563         if escaped is None:
564             return None
565         return unescapeHTML(escaped)
566     def _og_search_thumbnail(self, html, **kargs):
567         return self._og_search_property('image', html, 'thumbnail URL', fatal=False, **kargs)
568     def _og_search_description(self, html, **kargs):
569         return self._og_search_property('description', html, fatal=False, **kargs)
570     def _og_search_title(self, html, **kargs):
571         return self._og_search_property('title', html, **kargs)
572     def _og_search_video_url(self, html, name='video url', secure=True, **kargs):
573         regexes = self._og_regexes('video') + self._og_regexes('video:url')
574         if secure:
575             regexes = self._og_regexes('video:secure_url') + regexes
576         return self._html_search_regex(regexes, html, name, **kargs)
577     def _og_search_url(self, html, **kargs):
578         return self._og_search_property('url', html, **kargs)
579     def _html_search_meta(self, name, html, display_name=None, fatal=False, **kwargs):
580         if not isinstance(name, (list, tuple)):
581             name = [name]
582         if display_name is None:
583             display_name = name[0]
584         return self._html_search_regex(
585             [self._meta_regex(n) for n in name],
586             html, display_name, fatal=fatal, group='content', **kwargs)
587     def _dc_search_uploader(self, html):
588         return self._html_search_meta('dc.creator', html, 'uploader')
589     def _rta_search(self, html):
590         if re.search(r'(?ix)&lt;meta\s+name="rating"\s+'
591                      r'     content="RTA-5042-1996-1400-1577-RTA"',
592                      html):
593             return 18
594         return 0
595     def _media_rating_search(self, html):
596         rating = self._html_search_meta('rating', html)
597         if not rating:
598             return None
599         RATING_TABLE = {
600             'safe for kids': 0,
601             'general': 8,
602             '14 years': 14,
603             'mature': 17,
604             'restricted': 19,
605         }
606         return RATING_TABLE.get(rating.lower())
607     def _family_friendly_search(self, html):
608         family_friendly = self._html_search_meta(
609             'isFamilyFriendly', html, default=None)
610         if not family_friendly:
611             return None
612         RATING_TABLE = {
613             '1': 0,
614             'true': 0,
615             '0': 18,
616             'false': 18,
617         }
618         return RATING_TABLE.get(family_friendly.lower())
619     def _twitter_search_player(self, html):
620         return self._html_search_meta('twitter:player', html,
621                                       'twitter card player')
622     def _search_json_ld(self, html, video_id, expected_type=None, **kwargs):
623         json_ld_list = list(re.finditer(JSON_LD_RE, html))
624         default = kwargs.get('default', NO_DEFAULT)
625         fatal = kwargs.get('fatal', True) if default == NO_DEFAULT else False
626         json_ld = []
627         for mobj in json_ld_list:
628             json_ld_item = self._parse_json(
629                 mobj.group('json_ld'), video_id, fatal=fatal)
630             if not json_ld_item:
631                 continue
632             if isinstance(json_ld_item, dict):
633                 json_ld.append(json_ld_item)
634             elif isinstance(json_ld_item, (list, tuple)):
635                 json_ld.extend(json_ld_item)
636         if json_ld:
637             json_ld = self._json_ld(json_ld, video_id, fatal=fatal, expected_type=expected_type)
638         if json_ld:
639             return json_ld
640         if default is not NO_DEFAULT:
641             return default
642         elif fatal:
643             raise RegexNotFoundError('Unable to extract JSON-LD')
644         else:
645             self._downloader.report_warning('unable to extract JSON-LD %s' % bug_reports_message())
646             return {}
647     def _json_ld(self, json_ld, video_id, fatal=True, expected_type=None):
648         if isinstance(json_ld, compat_str):
649             json_ld = self._parse_json(json_ld, video_id, fatal=fatal)
650         if not json_ld:
651             return {}
652         info = {}
653         if not isinstance(json_ld, (list, tuple, dict)):
654             return info
655         if isinstance(json_ld, dict):
656             json_ld = [json_ld]
657         INTERACTION_TYPE_MAP = {
658             'CommentAction': 'comment',
659             'AgreeAction': 'like',
660             'DisagreeAction': 'dislike',
661             'LikeAction': 'like',
662             'DislikeAction': 'dislike',
663             'ListenAction': 'view',
664             'WatchAction': 'view',
665             'ViewAction': 'view',
666         }
667         def extract_interaction_type(e):
668             interaction_type = e.get('interactionType')
669             if isinstance(interaction_type, dict):
670                 interaction_type = interaction_type.get('@type')
671             return str_or_none(interaction_type)
672         def extract_interaction_statistic(e):
673             interaction_statistic = e.get('interactionStatistic')
674             if isinstance(interaction_statistic, dict):
675                 interaction_statistic = [interaction_statistic]
676             if not isinstance(interaction_statistic, list):
677                 return
678             for is_e in interaction_statistic:
679                 if not isinstance(is_e, dict):
680                     continue
681                 if is_e.get('@type') != 'InteractionCounter':
682                     continue
683                 interaction_type = extract_interaction_type(is_e)
684                 if not interaction_type:
685                     continue
686                 interaction_count = str_to_int(is_e.get('userInteractionCount'))
687                 if interaction_count is None:
688                     continue
689                 count_kind = INTERACTION_TYPE_MAP.get(interaction_type.split('/')[-1])
690                 if not count_kind:
691                     continue
692                 count_key = '%s_count' % count_kind
693                 if info.get(count_key) is not None:
694                     continue
695                 info[count_key] = interaction_count
696         def extract_video_object(e):
697             assert e['@type'] == 'VideoObject'
698             author = e.get('author')
699             info.update({
700                 'url': url_or_none(e.get('contentUrl')),
701                 'title': unescapeHTML(e.get('name')),
702                 'description': unescapeHTML(e.get('description')),
703                 'thumbnail': url_or_none(e.get('thumbnailUrl') or e.get('thumbnailURL')),
704                 'duration': parse_duration(e.get('duration')),
705                 'timestamp': unified_timestamp(e.get('uploadDate')),
706                 'uploader': author.get('name') if isinstance(author, dict) else author if isinstance<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>(author, compat_str) else None,
707                 'filesize': float_or_none(e.get('contentSize')),
708                 'tbr': int_or_none(e.get('bitrate')),
709                 'width': int_or_none(e.get('width')),
710                 'height': int_or_none(e.get('height')),
711                 'view_count': int_or_none(e.get(</b></font>'interactionCount')),
712             })
713             extract_interaction_statistic(e)
714         for e in json_ld:
715             if '@context' in e:
716                 item_type = e.get('@type')
717                 if expected_type is not None and expected_type != item_type:
718                     continue
719                 if item_type in ('TVEpisode', 'Episode'):
720                     episode_name = unescapeHTML(e.get('name'))
721                     info.update({
722                         'episode': episode_name,
723                         'episode_number': int_or_none(e.get('episodeNumber')),
724                         'description': unescapeHTML(e.get('description')),
725                     })
726                     if not info.get('title') and episode_name:
727                         info['title'] = episode_name
728                     part_of_season = e.get('partOfSeason')
729                     if isinstance(part_of_season, dict) and part_of_season.get('@type') in ('TVSeason', 'Season', 'CreativeWorkSeason'):
730                         info.update({
731                             'season': unescapeHTML(part_of_season.get('name')),
732                             'season_number': int_or_none(part_of_season.get('seasonNumber')),
733                         })
734                     part_of_series = e.get('partOfSeries') or e.get('partOfTVSeries')
735                     if isinstance(part_of_series, dict) and part_of_series.get('@type') in ('TVSeries', 'Series', 'CreativeWorkSeries'):
736                         info['series'] = unescapeHTML(part_of_series.get('name'))
737                 elif item_type == 'Movie':
738                     info.update({
739                         'title': unescapeHTML(e.get('name')),
740                         'description': unescapeHTML(e.get('description')),
741                         'duration': parse_duration(e.get('duration')),
742                         'timestamp': unified_timestamp(e.get('dateCreated')),
743                     })
744                 elif item_type in ('Article', 'NewsArticle'):
745                     info.update({
746                         'timestamp': parse_iso8601(e.get('datePublished')),
747                         'title': unescapeHTML(e.get('headline')),
748                         'description': unescapeHTML(e.get('articleBody')),
749                     })
750                 elif item_type == 'VideoObject':
751                     extract_video_object(e)
752                     if expected_type is None:
753                         continue
754                     else:
755                         break
756                 video = e.get('video')
757                 if isinstance(video, dict) and video.get('@type') == 'VideoObject':
758                     extract_video_object(video)
759                 if expected_type is None:
760                     continue
761                 else:
762                     break
763         return dict((k, v) for k, v in info.items() if v is not None)
764     @staticmethod
765     def _hidden_inputs(html):
766         html = re.sub(r'&lt;!--(?:(?!&lt;!--).)*--&gt;', '', html)
767         hidden_inputs = {}
768         for input in re.findall(r'(?i)(&lt;input[^&gt;]+&gt;)', html):
769             attrs = extract_attributes(input)
770             if not input:
771                 continue
772             if attrs.get('type') not in ('hidden', 'submit'):
773                 continue
774             name = attrs.get('name') or attrs.get('id')
775             value = attrs.get('value')
776             if name and value is not None:
777                 hidden_inputs[name] = value
778         return hidden_inputs
779     def _form_hidden_inputs(self, form_id, html):
780         form = self._search_regex(
781             r'(?is)&lt;form[^&gt;]+?id=(["\'])%s\1[^&gt;]*&gt;(?P&lt;form&gt;.+?)&lt;/form&gt;' % form_id,
782             html, '%s form' % form_id, group='form')
783         return self._hidden_inputs(form)
784     def _sort_formats(self, formats, field_preference=None):
785         if not formats:
786             raise ExtractorError('No video formats found')
787         for f in formats:
788             if 'tbr' not in f and f.get('abr') is not None and f.get('vbr') is not None:
789                 f['tbr'] = f['abr'] + f['vbr']
790         def _formats_key(f):
791             from ..utils import determine_ext
792             if not f.get('ext') and 'url' in f:
793                 f['ext'] = determine_ext(f['url'])
794             if isinstance(field_preference, (list, tuple)):
795                 return tuple(
796                     f.get(field)
797                     if f.get(field) is not None
798                     else ('' if field == 'format_id' else -1)
799                     for field in field_preference)
800             preference = f.get('preference')
801             if preference is None:
802                 preference = 0
803                 if f.get('ext') in ['f4f', 'f4m']:  # Not yet supported
804                     preference -= 0.5
805             protocol = f.get('protocol') or determine_protocol(f)
806             proto_preference = 0 if protocol in ['http', 'https'] else (-0.5 if protocol == 'rtsp' else -0.1)
807             if f.get('vcodec') == 'none':  # audio only
808                 preference -= 50
809                 if self._downloader.params.get('prefer_free_formats'):
810                     ORDER = ['aac', 'mp3', 'm4a', 'webm', 'ogg', 'opus']
811                 else:
812                     ORDER = ['webm', 'opus', 'ogg', 'mp3', 'aac', 'm4a']
813                 ext_preference = 0
814                 try:
815                     audio_ext_preference = ORDER.index(f['ext'])
816                 except ValueError:
817                     audio_ext_preference = -1
818             else:
819                 if f.get('acodec') == 'none':  # video only
820                     preference -= 40
821                 if self._downloader.params.get('prefer_free_formats'):
822                     ORDER = ['flv', 'mp4', 'webm']
823                 else:
824                     ORDER = ['webm', 'flv', 'mp4']
825                 try:
826                     ext_preference = ORDER.index(f['ext'])
827                 except ValueError:
828                     ext_preference = -1
829                 audio_ext_preference = 0
830             return (
831                 preference,
832                 f.get('language_preference') if f.get('language_preference') is not None else -1,
833                 f.get('quality') if f.get('quality') is not None else -1,
834                 f.get('tbr') if f.get('tbr') is not None else -1,
835                 f.get('filesize') if f.get('filesize') is not None else -1,
836                 f.get('vbr') if f.get('vbr') is not None else -1,
837                 f.get('height') if f.get('height') is not None else -1,
838                 f.get('width') if f.get('width') is not None else -1,
839                 proto_preference,
840                 ext_preference,
841                 f.get('abr') if f.get('abr') is not None else -1,
842                 audio_ext_preference,
843                 f.get('fps') if f.get('fps') is not None else -1,
844                 f.get('filesize_approx') if f.get('filesize_approx') is not None else -1,
845                 f.get('source_preference') if f.get('source_preference') is not None else -1,
846                 f.get('format_id') if f.get('format_id') is not None else '',
847             )
848         formats.sort(key=_formats_key)
849     def _check_formats(self, formats, video_id):
850         if formats:
851             formats[:] = filter(
852                 lambda f: self._is_valid_url(
853                     f['url'], video_id,
854                     item='%s video format' % f.get('format_id') if f.get('format_id') else 'video'),
855                 formats)
856     @staticmethod
857     def _remove_duplicate_formats(formats):
858         format_urls = set()
859         unique_formats = []
860         for f in formats:
861             if f['url'] not in format_urls:
862                 format_urls.add(f['url'])
863                 unique_formats.append(f)
864         formats[:] = unique_formats
865     def _is_valid_url(self, url, video_id, item='video', headers={}):
866         url = self._proto_relative_url(url, scheme='http:')
867         if not (url.startswith('http://') or url.startswith('https://')):
868             return True
869         try:
870             self._request_webpage(url, video_id, 'Checking %s URL' % item, headers=headers)
871             return True
872         except ExtractorError as e:
873             self.to_screen(
874                 '%s: %s URL is invalid, skipping: %s'
875                 % (video_id, item, error_to_compat_str(e.cause)))
876             return False
877     def http_scheme(self):
878         return (
879             'http:'
880             if self._downloader.params.get('prefer_insecure', False)
881             else 'https:')
882     def _proto_relative_url(self, url, scheme=None):
883         if url is None:
884             return url
885         if url.startswith('//'):
886             if scheme is None:
887                 scheme = self.http_scheme()
888             return scheme + url
889         else:
890             return url
891     def _sleep(self, timeout, video_id, msg_template=None):
892         if msg_template is None:
893             msg_template = '%(video_id)s: Waiting for %(timeout)s seconds'
894         msg = msg_template % {'video_id': video_id, 'timeout': timeout}
895         self.to_screen(msg)
896         time.sleep(timeout)
897     def _extract_f4m_formats(self, manifest_url, video_id, preference=None, f4m_id=None,
898                              transform_source=lambda s: fix_xml_ampersands(s).strip(),
899                              fatal=True, m3u8_id=None, data=None, headers={}, query={}):
900         manifest = self._download_xml(
901             manifest_url, video_id, 'Downloading f4m manifest',
902             'Unable to download f4m manifest',
903             transform_source=transform_source,
904             fatal=fatal, data=data, headers=headers, query=query)
905         if manifest is False:
906             return []
907         return self._parse_f4m_formats(
908             manifest, manifest_url, video_id, preference=preference, f4m_id=f4m_id,
909             transform_source=transform_source, fatal=fatal, m3u8_id=m3u8_id)
910     def _parse_f4m_formats(self, manifest, manifest_url, video_id, preference=None, f4m_id=None,
911                            transform_source=lambda s: fix_xml_ampersands(s).strip(),
912                            fatal=True, m3u8_id=None):
913         if not isinstance(manifest, compat_etree_Element) and not fatal:
914             return []
915         akamai_pv = manifest.find('{http://ns.adobe.com/f4m/1.0}pv-2.0')
916         if akamai_pv is not None and ';' in akamai_pv.text:
917             playerVerificationChallenge = akamai_pv.text.split(';')[0]
918             if playerVerificationChallenge.strip() != '':
919                 return []
920         formats = []
921         manifest_version = '1.0'
922         media_nodes = manifest.findall('{http://ns.adobe.com/f4m/1.0}media')
923         if not media_nodes:
924             manifest_version = '2.0'
925             media_nodes = manifest.findall('{http://ns.adobe.com/f4m/2.0}media')
926         media_nodes = remove_encrypted_media(media_nodes)
927         if not media_nodes:
928             return formats
929         manifest_base_url = get_base_url(manifest)
930         bootstrap_info = xpath_element(
931             manifest, ['{http://ns.adobe.com/f4m/1.0}bootstrapInfo', '{http://ns.adobe.com/f4m/2.0}bootstrapInfo'],
932             'bootstrap info', default=None)
933         vcodec = None
934         mime_type = xpath_text(
935             manifest, ['{http://ns.adobe.com/f4m/1.0}mimeType', '{http://ns.adobe.com/f4m/2.0}mimeType'],
936             'base URL', default=None)
937         if mime_type and mime_type.startswith('audio/'):
938             vcodec = 'none'
939         for i, media_el in enumerate(media_nodes):
940             tbr = int_or_none(media_el.attrib.get('bitrate'))
941             width = int_or_none(media_el.attrib.get('width'))
942             height = int_or_none(media_el.attrib.get('height'))
943             format_id = '-'.join(filter(None, [f4m_id, compat_str(i if tbr is None else tbr)]))
944             if bootstrap_info is None:
945                 media_url = None
946                 if manifest_version == '2.0':
947                     media_url = media_el.attrib.get('href')
948                 if media_url is None:
949                     media_url = media_el.attrib.get('url')
950                 if not media_url:
951                     continue
952                 manifest_url = (
953                     media_url if media_url.startswith('http://') or media_url.startswith('https://')
954                     else ((manifest_base_url or '/'.join(manifest_url.split('/')[:-1])) + '/' + media_url))
955                 ext = determine_ext(manifest_url)
956                 if ext == 'f4m':
957                     f4m_formats = self._extract_f4m_formats(
958                         manifest_url, video_id, preference=preference, f4m_id=f4m_id,
959                         transform_source=transform_source, fatal=fatal)
960                     if len(f4m_formats) == 1:
961                         f = f4m_formats[0]
962                         f.update({
963                             'tbr': f.get('tbr') or tbr,
964                             'width': f.get('width') or width,
965                             'height': f.get('height') or height,
966                             'format_id': f.get('format_id') if not tbr else format_id,
967                             'vcodec': vcodec,
968                         })
969                     formats.extend(f4m_formats)
970                     continue
971                 elif ext == 'm3u8':
972                     formats.extend(self._extract_m3u8_formats(
973                         manifest_url, video_id, 'mp4', preference=preference,
974                         m3u8_id=m3u8_id, fatal=fatal))
975                     continue
976             formats.append({
977                 'format_id': format_id,
978                 'url': manifest_url,
979                 'manifest_url': manifest_url,
980                 'ext': 'flv' if bootstrap_info is not None else None,
981                 'protocol': 'f4m',
982                 'tbr': tbr,
983                 'width': width,
984                 'height': height,
985                 'vcodec': vcodec,
986                 'preference': preference,
987             })
988         return formats
989     def _m3u8_meta_format(self, m3u8_url, ext=None, preference=None, m3u8_id=None):
990         return {
991             'format_id': '-'.join(filter(None, [m3u8_id, 'meta'])),
992             'url': m3u8_url,
993             'ext': ext,
994             'protocol': 'm3u8',
995             'preference': preference - 100 if preference else -100,
996             'resolution': 'multiple',
997             'format_note': 'Quality selection URL',
998         }
999     def _extract_m3u8_formats(self, m3u8_url, video_id, ext=None,
1000                               entry_protocol='m3u8', preference=None,
1001                               m3u8_id=None, note=None, errnote=None,
1002                               fatal=True, live=False, data=None, headers={},
1003                               query={}):
1004         res = self._download_webpage_handle(
1005             m3u8_url, video_id,
1006             note=note or 'Downloading m3u8 information',
1007             errnote=errnote or 'Failed to download m3u8 information',
1008             fatal=fatal, data=data, headers=headers, query=query)
1009         if res is False:
1010             return []
1011         m3u8_doc, urlh = res
1012         m3u8_url = urlh.geturl()
1013         return self._parse_m3u8_formats(
1014             m3u8_doc, m3u8_url, ext=ext, entry_protocol=entry_protocol,
1015             preference=preference, m3u8_id=m3u8_id, live=live)
1016     def _parse_m3u8_formats(self, m3u8_doc, m3u8_url, ext=None,
1017                             entry_protocol='m3u8', preference=None,
1018                             m3u8_id=None, live=False):
1019         if '#EXT-X-FAXS-CM:' in m3u8_doc:  # Adobe Flash Access
1020             return []
1021         if re.search(r'#EXT-X-SESSION-KEY:.*?URI="skd://', m3u8_doc):  # Apple FairPlay
1022             return []
1023         formats = []
1024         format_url = lambda u: (
1025             u
1026             if re.match(r'^https?://', u)
1027             else compat_urlparse.urljoin(m3u8_url, u))
1028         if '#EXT-X-TARGETDURATION' in m3u8_doc:  # media playlist, return as is
1029             return [{
1030                 'url': m3u8_url,
1031                 'format_id': m3u8_id,
1032                 'ext': ext,
1033                 'protocol': entry_protocol,
1034                 'preference': preference,
1035             }]
1036         groups = {}
1037         last_stream_inf = {}
1038         def extract_media(x_media_line):
1039             media = parse_m3u8_attributes(x_media_line)
1040             media_type, group_id, name = media.get('TYPE'), media.get('GROUP-ID'), media.get('NAME')
1041             if not (media_type and group_id and name):
1042                 return
1043             groups.setdefault(group_id, []).append(media)
1044             if media_type not in ('VIDEO', 'AUDIO'):
1045                 return
1046             media_url = media.get('URI')
1047             if media_url:
1048                 format_id = []
1049                 for v in (m3u8_id, group_id, name):
1050                     if v:
1051                         format_id.append(v)
1052                 f = {
1053                     'format_id': '-'.join(format_id),
1054                     'url': format_url(media_url),
1055                     'manifest_url': m3u8_url,
1056                     'language': media.get('LANGUAGE'),
1057                     'ext': ext,
1058                     'protocol': entry_protocol,
1059                     'preference': preference,
1060                 }
1061                 if media_type == 'AUDIO':
1062                     f['vcodec'] = 'none'
1063                 formats.append(f)
1064         def build_stream_name():
1065             stream_name = last_stream_inf.get('NAME')
1066             if stream_name:
1067                 return stream_name
1068             stream_group_id = last_stream_inf.get('VIDEO')
1069             if not stream_group_id:
1070                 return
1071             stream_group = groups.get(stream_group_id)
1072             if not stream_group:
1073                 return stream_group_id
1074             rendition = stream_group[0]
1075             return rendition.get('NAME') or stream_group_id
1076         for line in m3u8_doc.splitlines():
1077             if line.startswith('#EXT-X-MEDIA:'):
1078                 extract_media(line)
1079         for line in m3u8_doc.splitlines():
1080             if line.startswith('#EXT-X-STREAM-INF:'):
1081                 last_stream_inf = parse_m3u8_attributes(line)
1082             elif line.startswith('#') or not line.strip():
1083                 continue
1084             else:
1085                 tbr = float_or_none(
1086                     last_stream_inf.get('AVERAGE-BANDWIDTH')
1087                     or last_stream_inf.get('BANDWIDTH'), scale=1000)
1088                 format_id = []
1089                 if m3u8_id:
1090                     format_id.append(m3u8_id)
1091                 stream_name = build_stream_name()
1092                 if not live:
1093                     format_id.append(stream_name if stream_name else '%d' % (tbr if tbr else len(formats)))
1094                 manifest_url = format_url(line.strip())
1095                 f = {
1096                     'format_id': '-'.join(format_id),
1097                     'url': manifest_url,
1098                     'manifest_url': m3u8_url,
1099                     'tbr': tbr,
1100                     'ext': ext,
1101                     'fps': float_or_none(last_stream_inf.get('FRAME-RATE')),
1102                     'protocol': entry_protocol,
1103                     'preference': preference,
1104                 }
1105                 resolution = last_stream_inf.get('RESOLUTION')
1106                 if resolution:
1107                     mobj = re.search(r'(?P&lt;width&gt;\d+)[xX](?P&lt;height&gt;\d+)', resolution)
1108                     if mobj:
1109                         f['width'] = int(mobj.group('width'))
1110                         f['height'] = int(mobj.group('height'))
1111                 mobj = re.search(
1112                     r'audio.*?(?:%3D|=)(\d+)(?:-video.*?(?:%3D|=)(\d+))?', f['url'])
1113                 if mobj:
1114                     abr, vbr = mobj.groups()
1115                     abr, vbr = float_or_none(abr, 1000), float_or_none(vbr, 1000)
1116                     f.update({
1117                         'vbr': vbr,
1118                         'abr': abr,
1119                     })
1120                 codecs = parse_codecs(last_stream_inf.get('CODECS'))
1121                 f.update(codecs)
1122                 audio_group_id = last_stream_inf.get('AUDIO')
1123                 if audio_group_id and codecs and f.get('vcodec') != 'none':
1124                     audio_group = groups.get(audio_group_id)
1125                     if audio_group and audio_group[0].get('URI'):
1126                         f['acodec'] = 'none'
1127                 formats.append(f)
1128                 progressive_uri = last_stream_inf.get('PROGRESSIVE-URI')
1129                 if progressive_uri:
1130                     http_f = f.copy()
1131                     del http_f['manifest_url']
1132                     http_f.update({
1133                         'format_id': f['format_id'].replace('hls-', 'http-'),
1134                         'protocol': 'http',
1135                         'url': progressive_uri,
1136                     })
1137                     formats.append(http_f)
1138                 last_stream_inf = {}
1139         return formats
1140     @staticmethod
1141     def _xpath_ns(path, namespace=None):
1142         if not namespace:
1143             return path
1144         out = []
1145         for c in path.split('/'):
1146             if not c or c == '.':
1147                 out.append(c)
1148             else:
1149                 out.append('{%s}%s' % (namespace, c))
1150         return '/'.join(out)
1151     def _extract_smil_formats(self, smil_url, video_id, fatal=True, f4m_params=None, transform_source=None):
1152         smil = self._download_smil(smil_url, video_id, fatal=fatal, transform_source=transform_source)
1153         if smil is False:
1154             assert not fatal
1155             return []
1156         namespace = self._parse_smil_namespace(smil)
1157         return self._parse_smil_formats(
1158             smil, smil_url, video_id, namespace=namespace, f4m_params=f4m_params)
1159     def _extract_smil_info(self, smil_url, video_id, fatal=True, f4m_params=None):
1160         smil = self._download_smil(smil_url, video_id, fatal=fatal)
1161         if smil is False:
1162             return {}
1163         return self._parse_smil(smil, smil_url, video_id, f4m_params=f4m_params)
1164     def _download_smil(self, smil_url, video_id, fatal=True, transform_source=None):
1165         return self._download_xml(
1166             smil_url, video_id, 'Downloading SMIL file',
1167             'Unable to download SMIL file', fatal=fatal, transform_source=transform_source)
1168     def _parse_smil(self, smil, smil_url, video_id, f4m_params=None):
1169         namespace = self._parse_smil_namespace(smil)
1170         formats = self._parse_smil_formats(
1171             smil, smil_url, video_id, namespace=namespace, f4m_params=f4m_params)
1172         subtitles = self._parse_smil_subtitles(smil, namespace=namespace)
1173         video_id = os.path.splitext(url_basename(smil_url))[0]
1174         title = None
1175         description = None
1176         upload_date = None
1177         for meta in smil.findall(self._xpath_ns('./head/meta', namespace)):
1178             name = meta.attrib.get('name')
1179             content = meta.attrib.get('content')
1180             if not name or not content:
1181                 continue
1182             if not title and name == 'title':
1183                 title = content
1184             elif not description and name in ('description', 'abstract'):
1185                 description = content
1186             elif not upload_date and name == 'date':
1187                 upload_date = unified_strdate(content)
1188         thumbnails = [{
1189             'id': image.get('type'),
1190             'url': image.get('src'),
1191             'width': int_or_none(image.get('width')),
1192             'height': int_or_none(image.get('height')),
1193         } for image in smil.findall(self._xpath_ns('.//image', namespace)) if image.get('src')]
1194         return {
1195             'id': video_id,
1196             'title': title or video_id,
1197             'description': description,
1198             'upload_date': upload_date,
1199             'thumbnails': thumbnails,
1200             'formats': formats,
1201             'subtitles': subtitles,
1202         }
1203     def _parse_smil_namespace(self, smil):
1204         return self._search_regex(
1205             r'(?i)^{([^}]+)?}smil$', smil.tag, 'namespace', default=None)
1206     def _parse_smil_formats(self, smil, smil_url, video_id, namespace=None, f4m_params=None, transform_rtmp_url=None):
1207         base = smil_url
1208         for meta in smil.findall(self._xpath_ns('./head/meta', namespace)):
1209             b = meta.get('base') or meta.get('httpBase')
1210             if b:
1211                 base = b
1212                 break
1213         formats = []
1214         rtmp_count = 0
1215         http_count = 0
1216         m3u8_count = 0
1217         srcs = []
1218         media = smil.findall(self._xpath_ns('.//video', namespace)) + smil.findall(self._xpath_ns('.//audio', namespace))
1219         for medium in media:
1220             src = medium.get('src')
1221             if not src or src in srcs:
1222                 continue
1223             srcs.append(src)
1224             bitrate = float_or_none(medium.get('system-bitrate') or medium.get('systemBitrate'), 1000)
1225             filesize = int_or_none(medium.get('size') or medium.get('fileSize'))
1226             width = int_or_none(medium.get('width'))
1227             height = int_or_none(medium.get('height'))
1228             proto = medium.get('proto')
1229             ext = medium.get('ext')
1230             src_ext = determine_ext(src)
1231             streamer = medium.get('streamer') or base
1232             if proto == 'rtmp' or streamer.startswith('rtmp'):
1233                 rtmp_count += 1
1234                 formats.append({
1235                     'url': streamer,
1236                     'play_path': src,
1237                     'ext': 'flv',
1238                     'format_id': 'rtmp-%d' % (rtmp_count if bitrate is None else bitrate),
1239                     'tbr': bitrate,
1240                     'filesize': filesize,
1241                     'width': width,
1242                     'height': height,
1243                 })
1244                 if transform_rtmp_url:
1245                     streamer, src = transform_rtmp_url(streamer, src)
1246                     formats[-1].update({
1247                         'url': streamer,
1248                         'play_path': src,
1249                     })
1250                 continue
1251             src_url = src if src.startswith('http') else compat_urlparse.urljoin(base, src)
1252             src_url = src_url.strip()
1253             if proto == 'm3u8' or src_ext == 'm3u8':
1254                 m3u8_formats = self._extract_m3u8_formats(
1255                     src_url, video_id, ext or 'mp4', m3u8_id='hls', fatal=False)
1256                 if len(m3u8_formats) == 1:
1257                     m3u8_count += 1
1258                     m3u8_formats[0].update({
1259                         'format_id': 'hls-%d' % (m3u8_count if bitrate is None else bitrate),
1260                         'tbr': bitrate,
1261                         'width': width,
1262                         'height': height,
1263                     })
1264                 formats.extend(m3u8_formats)
1265             elif src_ext == 'f4m':
1266                 f4m_url = src_url
1267                 if not f4m_params:
1268                     f4m_params = {
1269                         'hdcore': '3.2.0',
1270                         'plugin': 'flowplayer-3.2.0.1',
1271                     }
1272                 f4m_url += '&amp;' if '?' in f4m_url else '?'
1273                 f4m_url += compat_urllib_parse_urlencode(f4m_params)
1274                 formats.extend(self._extract_f4m_formats(f4m_url, video_id, f4m_id='hds', fatal=False))
1275             elif src_ext == 'mpd':
1276                 formats.extend(self._extract_mpd_formats(
1277                     src_url, video_id, mpd_id='dash', fatal=False))
1278             elif re.search(r'\.ism/[Mm]anifest', src_url):
1279                 formats.extend(self._extract_ism_formats(
1280                     src_url, video_id, ism_id='mss', fatal=False))
1281             elif src_url.startswith('http') and self._is_valid_url(src, video_id):
1282                 http_count += 1
1283                 formats.append({
1284                     'url': src_url,
1285                     'ext': ext or src_ext or 'flv',
1286                     'format_id': 'http-%d' % (bitrate or http_count),
1287                     'tbr': bitrate,
1288                     'filesize': filesize,
1289                     'width': width,
1290                     'height': height,
1291                 })
1292         return formats
1293     def _parse_smil_subtitles(self, smil, namespace=None, subtitles_lang='en'):
1294         urls = []
1295         subtitles = {}
1296         for num, textstream in enumerate(smil.findall(self._xpath_ns('.//textstream', namespace))):
1297             src = textstream.get('src')
1298             if not src or src in urls:
1299                 continue
1300             urls.append(src)
1301             ext = textstream.get('ext') or mimetype2ext(textstream.get('type')) or determine_ext(src)
1302             lang = textstream.get('systemLanguage') or textstream.get('systemLanguageName') or textstream.get('lang') or subtitles_lang
1303             subtitles.setdefault(lang, []).append({
1304                 'url': src,
1305                 'ext': ext,
1306             })
1307         return subtitles
1308     def _extract_xspf_playlist(self, xspf_url, playlist_id, fatal=True):
1309         xspf = self._download_xml(
1310             xspf_url, playlist_id, 'Downloading xpsf playlist',
1311             'Unable to download xspf manifest', fatal=fatal)
1312         if xspf is False:
1313             return []
1314         return self._parse_xspf(
1315             xspf, playlist_id, xspf_url=xspf_url,
1316             xspf_base_url=base_url(xspf_url))
1317     def _parse_xspf(self, xspf_doc, playlist_id, xspf_url=None, xspf_base_url=None):
1318         NS_MAP = {
1319             'xspf': 'http://xspf.org/ns/0/',
1320             's1': 'http://static.streamone.nl/player/ns/0',
1321         }
1322         entries = []
1323         for track in xspf_doc.findall(xpath_with_ns('./xspf:trackList/xspf:track', NS_MAP)):
1324             title = xpath_text(
1325                 track, xpath_with_ns('./xspf:title', NS_MAP), 'title', default=playlist_id)
1326             description = xpath_text(
1327                 track, xpath_with_ns('./xspf:annotation', NS_MAP), 'description')
1328             thumbnail = xpath_text(
1329                 track, xpath_with_ns('./xspf:image', NS_MAP), 'thumbnail')
1330             duration = float_or_none(
1331                 xpath_text(track, xpath_with_ns('./xspf:duration', NS_MAP), 'duration'), 1000)
1332             formats = []
1333             for location in track.findall(xpath_with_ns('./xspf:location', NS_MAP)):
1334                 format_url = urljoin(xspf_base_url, location.text)
1335                 if not format_url:
1336                     continue
1337                 formats.append({
1338                     'url': format_url,
1339                     'manifest_url': xspf_url,
1340                     'format_id': location.get(xpath_with_ns('s1:label', NS_MAP)),
1341                     'width': int_or_none(location.get(xpath_with_ns('s1:width', NS_MAP))),
1342                     'height': int_or_none(location.get(xpath_with_ns('s1:height', NS_MAP))),
1343                 })
1344             self._sort_formats(formats)
1345             entries.append({
1346                 'id': playlist_id,
1347                 'title': title,
1348                 'description': description,
1349                 'thumbnail': thumbnail,
1350                 'duration': duration,
1351                 'formats': formats,
1352             })
1353         return entries
1354     def _extract_mpd_formats(self, mpd_url, video_id, mpd_id=None, note=None, errnote=None, fatal=True, data=None, headers={}, query={}):
1355         res = self._download_xml_handle(
1356             mpd_url, video_id,
1357             note=note or 'Downloading MPD manifest',
1358             errnote=errnote or 'Failed to download MPD manifest',
1359             fatal=fatal, data=data, headers=headers, query=query)
1360         if res is False:
1361             return []
1362         mpd_doc, urlh = res
1363         if mpd_doc is None:
1364             return []
1365         mpd_base_url = base_url(urlh.geturl())
1366         return self._parse_mpd_formats(
1367             mpd_doc, mpd_id, mpd_base_url, mpd_url)
1368     def _parse_mpd_formats(self, mpd_doc, mpd_id=None, mpd_base_url='', mpd_url=None):
1369         if mpd_doc.get('type') == 'dynamic':
1370             return []
1371         namespace = self._search_regex(r'(?i)^{([^}]+)?}MPD$', mpd_doc.tag, 'namespace', default=None)
1372         def _add_ns(path):
1373             return self._xpath_ns(path, namespace)
1374         def is_drm_protected(element):
1375             return element.find(_add_ns('ContentProtection')) is not None
1376         def extract_multisegment_info(element, ms_parent_info):
1377             ms_info = ms_parent_info.copy()
1378             def extract_common(source):
1379                 segment_timeline = source.find(_add_ns('SegmentTimeline'))
1380                 if segment_timeline is not None:
1381                     s_e = segment_timeline.findall(_add_ns('S'))
1382                     if s_e:
1383                         ms_info['total_number'] = 0
1384                         ms_info['s'] = []
1385                         for s in s_e:
1386                             r = int(s.get('r', 0))
1387                             ms_info['total_number'] += 1 + r
1388                             ms_info['s'].append({
1389                                 't': int(s.get('t', 0)),
1390                                 'd': int(s.attrib['d']),
1391                                 'r': r,
1392                             })
1393                 start_number = source.get('startNumber')
1394                 if start_number:
1395                     ms_info['start_number'] = int(start_number)
1396                 timescale = source.get('timescale')
1397                 if timescale:
1398                     ms_info['timescale'] = int(timescale)
1399                 segment_duration = source.get('duration')
1400                 if segment_duration:
1401                     ms_info['segment_duration'] = float(segment_duration)
1402             def extract_Initialization(source):
1403                 initialization = source.find(_add_ns('Initialization'))
1404                 if initialization is not None:
1405                     ms_info['initialization_url'] = initialization.attrib['sourceURL']
1406             segment_list = element.find(_add_ns('SegmentList'))
1407             if segment_list is not None:
1408                 extract_common(segment_list)
1409                 extract_Initialization(segment_list)
1410                 segment_urls_e = segment_list.findall(_add_ns('SegmentURL'))
1411                 if segment_urls_e:
1412                     ms_info['segment_urls'] = [segment.attrib['media'] for segment in segment_urls_e]
1413             else:
1414                 segment_template = element.find(_add_ns('SegmentTemplate'))
1415                 if segment_template is not None:
1416                     extract_common(segment_template)
1417                     media = segment_template.get('media')
1418                     if media:
1419                         ms_info['media'] = media
1420                     initialization = segment_template.get('initialization')
1421                     if initialization:
1422                         ms_info['initialization'] = initialization
1423                     else:
1424                         extract_Initialization(segment_template)
1425             return ms_info
1426         mpd_duration = parse_duration(mpd_doc.get('mediaPresentationDuration'))
1427         formats = []
1428         for period in mpd_doc.findall(_add_ns('Period')):
1429             period_duration = parse_duration(period.get('duration')) or mpd_duration
1430             period_ms_info = extract_multisegment_info(period, {
1431                 'start_number': 1,
1432                 'timescale': 1,
1433             })
1434             for adaptation_set in period.findall(_add_ns('AdaptationSet')):
1435                 if is_drm_protected(adaptation_set):
1436                     continue
1437                 adaption_set_ms_info = extract_multisegment_info(adaptation_set, period_ms_info)
1438                 for representation in adaptation_set.findall(_add_ns('Representation')):
1439                     if is_drm_protected(representation):
1440                         continue
1441                     representation_attrib = adaptation_set.attrib.copy()
1442                     representation_attrib.update(representation.attrib)
1443                     mime_type = representation_attrib['mimeType']
1444                     content_type = mime_type.split('/')[0]
1445                     if content_type == 'text':
1446                         pass
1447                     elif content_type in ('video', 'audio'):
1448                         base_url = ''
1449                         for element in (representation, adaptation_set, period, mpd_doc):
1450                             base_url_e = element.find(_add_ns('BaseURL'))
1451                             if base_url_e is not None:
1452                                 base_url = base_url_e.text + base_url
1453                                 if re.match(r'^https?://', base_url):
1454                                     break
1455                         if mpd_base_url and not re.match(r'^https?://', base_url):
1456                             if not mpd_base_url.endswith('/') and not base_url.startswith('/'):
1457                                 mpd_base_url += '/'
1458                             base_url = mpd_base_url + base_url
1459                         representation_id = representation_attrib.get('id')
1460                         lang = representation_attrib.get('lang')
1461                         url_el = representation.find(_add_ns('BaseURL'))
1462                         filesize = int_or_none(url_el.attrib.get('{http://youtube.com/yt/2012/10/10}contentLength') if url_el is not None else None)
1463                         bandwidth = int_or_none(representation_attrib.get('bandwidth'))
1464                         f = {
1465                             'format_id': '%s-%s' % (mpd_id, representation_id) if mpd_id else representation_id,
1466                             'manifest_url': mpd_url,
1467                             'ext': mimetype2ext(mime_type),
1468                             'width': int_or_none(representation_attrib.get('width')),
1469                             'height': int_or_none(representation_attrib.get('height')),
1470                             'tbr': float_or_none(bandwidth, 1000),
1471                             'asr': int_or_none(representation_attrib.get('audioSamplingRate')),
1472                             'fps': int_or_none(representation_attrib.get('frameRate')),
1473                             'language': lang if lang not in ('mul', 'und', 'zxx', 'mis') else None,
1474                             'format_note': 'DASH %s' % content_type,
1475                             'filesize': filesize,
1476                             'container': mimetype2ext(mime_type) + '_dash',
1477                         }
1478                         f.update(parse_codecs(representation_attrib.get('codecs')))
1479                         representation_ms_info = extract_multisegment_info(representation, adaption_set_ms_info)
1480                         def prepare_template(template_name, identifiers):
1481                             tmpl = representation_ms_info[template_name]
1482                             t = ''
1483                             in_template = False
1484                             for c in tmpl:
1485                                 t += c
1486                                 if c == '$':
1487                                     in_template = not in_template
1488                                 elif c == '%' and not in_template:
1489                                     t += c
1490                             t = t.replace('$RepresentationID$', representation_id)
1491                             t = re.sub(r'\$(%s)\$' % '|'.join(identifiers), r'%(\1)d', t)
1492                             t = re.sub(r'\$(%s)%%([^$]+)\$' % '|'.join(identifiers), r'%(\1)\2', t)
1493                             t.replace('$$', '$')
1494                             return t
1495                         if 'initialization' in representation_ms_info:
1496                             initialization_template = prepare_template(
1497                                 'initialization',
1498                                 ('Bandwidth', ))
1499                             representation_ms_info['initialization_url'] = initialization_template % {
1500                                 'Bandwidth': bandwidth,
1501                             }
1502                         def location_key(location):
1503                             return 'url' if re.match(r'^https?://', location) else 'path'
1504                         if 'segment_urls' not in representation_ms_info and 'media' in representation_ms_info:
1505                             media_template = prepare_template('media', ('Number', 'Bandwidth', 'Time'))
1506                             media_location_key = location_key(media_template)
1507                             if '%(Number' in media_template and 's' not in representation_ms_info:
1508                                 segment_duration = None
1509                                 if 'total_number' not in representation_ms_info and 'segment_duration' in representation_ms_info:
1510                                     segment_duration = float_or_none(representation_ms_info['segment_duration'], representation_ms_info['timescale'])
1511                                     representation_ms_info['total_number'] = int(math.ceil(float(period_duration) / segment_duration))
1512                                 representation_ms_info['fragments'] = [{
1513                                     media_location_key: media_template % {
1514                                         'Number': segment_number,
1515                                         'Bandwidth': bandwidth,
1516                                     },
1517                                     'duration': segment_duration,
1518                                 } for segment_number in range(
1519                                     representation_ms_info['start_number'],
1520                                     representation_ms_info['total_number'] + representation_ms_info['start_number'])]
1521                             else:
1522                                 representation_ms_info['fragments'] = []
1523                                 segment_time = 0
1524                                 segment_d = None
1525                                 segment_number = representation_ms_info['start_number']
1526                                 def add_segment_url():
1527                                     segment_url = media_template % {
1528                                         'Time': segment_time,
1529                                         'Bandwidth': bandwidth,
1530                                         'Number': segment_number,
1531                                     }
1532                                     representation_ms_info['fragments'].append({
1533                                         media_location_key: segment_url,
1534                                         'duration': float_or_none(segment_d, representation_ms_info['timescale']),
1535                                     })
1536                                 for num, s in enumerate(representation_ms_info['s']):
1537                                     segment_time = s.get('t') or segment_time
1538                                     segment_d = s['d']
1539                                     add_segment_url()
1540                                     segment_number += 1
1541                                     for r in range(s.get('r', 0)):
1542                                         segment_time += segment_d
1543                                         add_segment_url()
1544                                         segment_number += 1
1545                                     segment_time += segment_d
1546                         elif 'segment_urls' in representation_ms_info and 's' in representation_ms_info:
1547                             fragments = []
1548                             segment_index = 0
1549                             timescale = representation_ms_info['timescale']
1550                             for s in representation_ms_info['s']:
1551                                 duration = float_or_none(s['d'], timescale)
1552                                 for r in range(s.get('r', 0) + 1):
1553                                     segment_uri = representation_ms_info['segment_urls'][segment_index]
1554                                     fragments.append({
1555                                         location_key(segment_uri): segment_uri,
1556                                         'duration': duration,
1557                                     })
1558                                     segment_index += 1
1559                             representation_ms_info['fragments'] = fragments
1560                         elif 'segment_urls' in representation_ms_info:
1561                             fragments = []
1562                             segment_duration = float_or_none(
1563                                 representation_ms_info['segment_duration'],
1564                                 representation_ms_info['timescale']) if 'segment_duration' in representation_ms_info else None
1565                             for segment_url in representation_ms_info['segment_urls']:
1566                                 fragment = {
1567                                     location_key(segment_url): segment_url,
1568                                 }
1569                                 if segment_duration:
1570                                     fragment['duration'] = segment_duration
1571                                 fragments.append(fragment)
1572                             representation_ms_info['fragments'] = fragments
1573                         if 'fragments' in representation_ms_info:
1574                             f.update({
1575                                 'url': mpd_url or base_url,
1576                                 'fragment_base_url': base_url,
1577                                 'fragments': [],
1578                                 'protocol': 'http_dash_segments',
1579                             })
1580                             if 'initialization_url' in representation_ms_info:
1581                                 initialization_url = representation_ms_info['initialization_url']
1582                                 if not f.get('url'):
1583                                     f['url'] = initialization_url
1584                                 f['fragments'].append({location_key(initialization_url): initialization_url})
1585                             f['fragments'].extend(representation_ms_info['fragments'])
1586                         else:
1587                             f['url'] = base_url
1588                         formats.append(f)
1589                     else:
1590                         self.report_warning('Unknown MIME type %s in DASH manifest' % mime_type)
1591         return formats
1592     def _extract_ism_formats(self, ism_url, video_id, ism_id=None, note=None, errnote=None, fatal=True, data=None, headers={}, query={}):
1593         res = self._download_xml_handle(
1594             ism_url, video_id,
1595             note=note or 'Downloading ISM manifest',
1596             errnote=errnote or 'Failed to download ISM manifest',
1597             fatal=fatal, data=data, headers=headers, query=query)
1598         if res is False:
1599             return []
1600         ism_doc, urlh = res
1601         if ism_doc is None:
1602             return []
1603         return self._parse_ism_formats(ism_doc, urlh.geturl(), ism_id)
1604     def _parse_ism_formats(self, ism_doc, ism_url, ism_id=None):
1605         if ism_doc.get('IsLive') == 'TRUE' or ism_doc.find('Protection') is not None:
1606             return []
1607         duration = int(ism_doc.attrib['Duration'])
1608         timescale = int_or_none(ism_doc.get('TimeScale')) or 10000000
1609         formats = []
1610         for stream in ism_doc.findall('StreamIndex'):
1611             stream_type = stream.get('Type')
1612             if stream_type not in ('video', 'audio'):
1613                 continue
1614             url_pattern = stream.attrib['Url']
1615             stream_timescale = int_or_none(stream.get('TimeScale')) or timescale
1616             stream_name = stream.get('Name')
1617             for track in stream.findall('QualityLevel'):
1618                 fourcc = track.get('FourCC', 'AACL' if track.get('AudioTag') == '255' else None)
1619                 if fourcc not in ('H264', 'AVC1', 'AACL'):
1620                     self.report_warning('%s is not a supported codec' % fourcc)
1621                     continue
1622                 tbr = int(track.attrib['Bitrate']) // 1000
1623                 width = int_or_none(track.get('MaxWidth') or track.get('Width'))
1624                 height = int_or_none(track.get('MaxHeight') or track.get('Height'))
1625                 sampling_rate = int_or_none(track.get('SamplingRate'))
1626                 track_url_pattern = re.sub(r'{[Bb]itrate}', track.attrib['Bitrate'], url_pattern)
1627                 track_url_pattern = compat_urlparse.urljoin(ism_url, track_url_pattern)
1628                 fragments = []
1629                 fragment_ctx = {
1630                     'time': 0,
1631                 }
1632                 stream_fragments = stream.findall('c')
1633                 for stream_fragment_index, stream_fragment in enumerate(stream_fragments):
1634                     fragment_ctx['time'] = int_or_none(stream_fragment.get('t')) or fragment_ctx['time']
1635                     fragment_repeat = int_or_none(stream_fragment.get('r')) or 1
1636                     fragment_ctx['duration'] = int_or_none(stream_fragment.get('d'))
1637                     if not fragment_ctx['duration']:
1638                         try:
1639                             next_fragment_time = int(stream_fragment[stream_fragment_index + 1].attrib['t'])
1640                         except IndexError:
1641                             next_fragment_time = duration
1642                         fragment_ctx['duration'] = (next_fragment_time - fragment_ctx['time']) / fragment_repeat
1643                     for _ in range(fragment_repeat):
1644                         fragments.append({
1645                             'url': re.sub(r'{start[ _]time}', compat_str(fragment_ctx['time']), track_url_pattern),
1646                             'duration': fragment_ctx['duration'] / stream_timescale,
1647                         })
1648                         fragment_ctx['time'] += fragment_ctx['duration']
1649                 format_id = []
1650                 if ism_id:
1651                     format_id.append(ism_id)
1652                 if stream_name:
1653                     format_id.append(stream_name)
1654                 format_id.append(compat_str(tbr))
1655                 formats.append({
1656                     'format_id': '-'.join(format_id),
1657                     'url': ism_url,
1658                     'manifest_url': ism_url,
1659                     'ext': 'ismv' if stream_type == 'video' else 'isma',
1660                     'width': width,
1661                     'height': height,
1662                     'tbr': tbr,
1663                     'asr': sampling_rate,
1664                     'vcodec': 'none' if stream_type == 'audio' else fourcc,
1665                     'acodec': 'none' if stream_type == 'video' else fourcc,
1666                     'protocol': 'ism',
1667                     'fragments': fragments,
1668                     '_download_params': {
1669                         'duration': duration,
1670                         'timescale': stream_timescale,
1671                         'width': width or 0,
1672                         'height': height or 0,
1673                         'fourcc': fourcc,
1674                         'codec_private_data': track.get('CodecPrivateData'),
1675                         'sampling_rate': sampling_rate,
1676                         'channels': int_or_none(track.get('Channels', 2)),
1677                         'bits_per_sample': int_or_none(track.get('BitsPerSample', 16)),
1678                         'nal_unit_length_field': int_or_none(track.get('NALUnitLengthField', 4)),
1679                     },
1680                 })
1681         return formats
1682     def _parse_html5_media_entries(self, base_url, webpage, video_id, m3u8_id=None, m3u8_entry_protocol='m3u8', mpd_id=None, preference=None):
1683         def absolute_url(item_url):
1684             return urljoin(base_url, item_url)
1685         def parse_content_type(content_type):
1686             if not content_type:
1687                 return {}
1688             ctr = re.search(r'(?P&lt;mimetype&gt;[^/]+/[^;]+)(?:;\s*codecs="?(?P&lt;codecs&gt;[^"]+))?', content_type)
1689             if ctr:
1690                 mimetype, codecs = ctr.groups()
1691                 f = parse_codecs(codecs)
1692                 f['ext'] = mimetype2ext(mimetype)
1693                 return f
1694             return {}
1695         def _media_formats(src, cur_media_type, type_info={}):
1696             full_url = absolute_url(src)
1697             ext = type_info.get('ext') or determine_ext(full_url)
1698             if ext == 'm3u8':
1699                 is_plain_url = False
1700                 formats = self._extract_m3u8_formats(
1701                     full_url, video_id, ext='mp4',
1702                     entry_protocol=m3u8_entry_protocol, m3u8_id=m3u8_id,
1703                     preference=preference, fatal=False)
1704             elif ext == 'mpd':
1705                 is_plain_url = False
1706                 formats = self._extract_mpd_formats(
1707                     full_url, video_id, mpd_id=mpd_id, fatal=False)
1708             else:
1709                 is_plain_url = True
1710                 formats = [{
1711                     'url': full_url,
1712                     'vcodec': 'none' if cur_media_type == 'audio' else None,
1713                 }]
1714             return is_plain_url, formats
1715         entries = []
1716         _MEDIA_TAG_NAME_RE = r'(?:(?:amp|dl8(?:-live)?)-)?(video|audio)'
1717         media_tags = [(media_tag, media_tag_name, media_type, '')
1718                       for media_tag, media_tag_name, media_type
1719                       in re.findall(r'(?s)(&lt;(%s)[^&gt;]*/&gt;)' % _MEDIA_TAG_NAME_RE, webpage)]
1720         media_tags.extend(re.findall(
1721             r'(?s)(&lt;(?P&lt;tag&gt;%s)(?:\s+[^&gt;]*)?&gt;)(.*?)&lt;/(?P=tag)&gt;' % _MEDIA_TAG_NAME_RE, webpage))
1722         for media_tag, _, media_type, media_content in media_tags:
1723             media_info = {
1724                 'formats': [],
1725                 'subtitles': {},
1726             }
1727             media_attributes = extract_attributes(media_tag)
1728             src = strip_or_none(media_attributes.get('src'))
1729             if src:
1730                 _, formats = _media_formats(src, media_type)
1731                 media_info['formats'].extend(formats)
1732             media_info['thumbnail'] = absolute_url(media_attributes.get('poster'))
1733             if media_content:
1734                 for source_tag in re.findall(r'&lt;source[^&gt;]+&gt;', media_content):
1735                     s_attr = extract_attributes(source_tag)
1736                     src = strip_or_none(dict_get(s_attr, ('src', 'data-video-src', 'data-src')))
1737                     if not src:
1738                         continue
1739                     f = parse_content_type(s_attr.get('type'))
1740                     is_plain_url, formats = _media_formats(src, media_type, f)
1741                     if is_plain_url:
1742                         labels = [
1743                             s_attr.get(lbl)
1744                             for lbl in ('label', 'title')
1745                             if str_or_none(s_attr.get(lbl))
1746                         ]
1747                         width = int_or_none(s_attr.get('width'))
1748                         height = (int_or_none(s_attr.get('height'))
1749                                   or int_or_none(s_attr.get('res')))
1750                         if not width or not height:
1751                             for lbl in labels:
1752                                 resolution = parse_resolution(lbl)
1753                                 if not resolution:
1754                                     continue
1755                                 width = width or resolution.get('width')
1756                                 height = height or resolution.get('height')
1757                         for lbl in labels:
1758                             tbr = parse_bitrate(lbl)
1759                             if tbr:
1760                                 break
1761                         else:
1762                             tbr = None
1763                         f.update({
1764                             'width': width,
1765                             'height': height,
1766                             'tbr': tbr,
1767                             'format_id': s_attr.get('label') or s_attr.get('title'),
1768                         })
1769                         f.update(formats[0])
1770                         media_info['formats'].append(f)
1771                     else:
1772                         media_info['formats'].extend(formats)
1773                 for track_tag in re.findall(r'&lt;track[^&gt;]+&gt;', media_content):
1774                     track_attributes = extract_attributes(track_tag)
1775                     kind = track_attributes.get('kind')
1776                     if not kind or kind in ('subtitles', 'captions'):
1777                         src = strip_or_none(track_attributes.get('src'))
1778                         if not src:
1779                             continue
1780                         lang = track_attributes.get('srclang') or track_attributes.get('lang') or track_attributes.get('label')
1781                         media_info['subtitles'].setdefault(lang, []).append({
1782                             'url': absolute_url(src),
1783                         })
1784             for f in media_info['formats']:
1785                 f.setdefault('http_headers', {})['Referer'] = base_url
1786             if media_info['formats'] or media_info['subtitles']:
1787                 entries.append(media_info)
1788         return entries
1789     def _extract_akamai_formats(self, manifest_url, video_id, hosts={}):
1790         signed = 'hdnea=' in manifest_url
1791         if not signed:
1792             manifest_url = re.sub(
1793                 r'(?:b=[\d,-]+|(?:__a__|attributes)=off|__b__=\d+)&amp;?',
1794                 '', manifest_url).strip('?')
1795         formats = []
1796         hdcore_sign = 'hdcore=3.7.0'
1797         f4m_url = re.sub(r'(https?://[^/]+)/i/', r'\1/z/', manifest_url).replace('/master.m3u8', '/manifest.f4m')
1798         hds_host = hosts.get('hds')
1799         if hds_host:
1800             f4m_url = re.sub(r'(https?://)[^/]+', r'\1' + hds_host, f4m_url)
1801         if 'hdcore=' not in f4m_url:
1802             f4m_url += ('&amp;' if '?' in f4m_url else '?') + hdcore_sign
1803         f4m_formats = self._extract_f4m_formats(
1804             f4m_url, video_id, f4m_id='hds', fatal=False)
1805         for entry in f4m_formats:
1806             entry.update({'extra_param_to_segment_url': hdcore_sign})
1807         formats.extend(f4m_formats)
1808         m3u8_url = re.sub(r'(https?://[^/]+)/z/', r'\1/i/', manifest_url).replace('/manifest.f4m', '/master.m3u8')
1809         hls_host = hosts.get('hls')
1810         if hls_host:
1811             m3u8_url = re.sub(r'(https?://)[^/]+', r'\1' + hls_host, m3u8_url)
1812         m3u8_formats = self._extract_m3u8_formats(
1813             m3u8_url, video_id, 'mp4', 'm3u8_native',
1814             m3u8_id='hls', fatal=False)
1815         formats.extend(m3u8_formats)
1816         http_host = hosts.get('http')
1817         if http_host and m3u8_formats and not signed:
1818             REPL_REGEX = r'https?://[^/]+/i/([^,]+),([^/]+),([^/]+)\.csmil/.+'
1819             qualities = re.match(REPL_REGEX, m3u8_url).group(2).split(',')
1820             qualities_length = len(qualities)
1821             if len(m3u8_formats) in (qualities_length, qualities_length + 1):
1822                 i = 0
1823                 for f in m3u8_formats:
1824                     if f['vcodec'] != 'none':
1825                         for protocol in ('http', 'https'):
1826                             http_f = f.copy()
1827                             del http_f['manifest_url']
1828                             http_url = re.sub(
1829                                 REPL_REGEX, protocol + r'://%s/\g&lt;1&gt;%s\3' % (http_host, qualities[i]), f['url'])
1830                             http_f.update({
1831                                 'format_id': http_f['format_id'].replace('hls-', protocol + '-'),
1832                                 'url': http_url,
1833                                 'protocol': protocol,
1834                             })
1835                             formats.append(http_f)
1836                         i += 1
1837     def _extract_wowza_formats(self, url, video_id, m3u8_entry_protocol='m3u8_native', skip_protocols=[]):
1838         query <font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>= compat_urlparse.urlparse(url).query
1839         url = re.sub(r'/(?:manifest|playlist|jwplayer)\.(?:m3u8|f4m|mpd|smil)', '', url)
1840         mobj = re.search(
1841             r'(?:(?:http|rtmp|rtsp)(?P&lt;s&gt;s)?:)?(?P&lt;url&gt;//[^?]+)', url)
1842         url_base = mobj.group(</b></font>'url')
1843         http_base_url = '%s%s:%s' % ('http', mobj.group('s') or '', url_base)
1844         formats = []
1845         def manifest_url(manifest):
1846             m_url = '%s/%s' % (http_base_url, manifest)
1847             if query:
1848                 m_url += '?%s' % query
1849             return m_url
1850         if 'm3u8' not in skip_protocols:
1851             formats.extend(self._extract_m3u8_formats(
1852                 manifest_url('playlist.m3u8'), video_id, 'mp4',
1853                 m3u8_entry_protocol, m3u8_id='hls', fatal=False))
1854         if 'f4m' not in skip_protocols:
1855             formats.extend(self._extract_f4m_formats(
1856                 manifest_url('manifest.f4m'),
1857                 video_id, f4m_id='hds', fatal=False))
1858         if 'dash' not in skip_protocols:
1859             formats.extend(self._extract_mpd_formats(
1860                 manifest_url('manifest.mpd'),
1861                 video_id, mpd_id='dash', fatal=False))
1862         if re.search(r'(?:/smil:|\.smil)', url_base):
1863             if 'smil' not in skip_protocols:
1864                 rtmp_formats = self._extract_smil_formats(
1865                     manifest_url('jwplayer.smil'),
1866                     video_id, fatal=False)
1867                 for rtmp_format in rtmp_formats:
1868                     rtsp_format = rtmp_format.copy()
1869                     rtsp_format['url'] = '%s/%s' % (rtmp_format['url'], rtmp_format['play_path'])
1870                     del rtsp_format['play_path']
1871                     del rtsp_format['ext']
1872                     rtsp_format.update({
1873                         'url': rtsp_format['url'].replace('rtmp://', 'rtsp://'),
1874                         'format_id': rtmp_format['format_id'].replace('rtmp', 'rtsp'),
1875                         'protocol': 'rtsp',
1876                     })
1877                     formats.extend([rtmp_format, rtsp_format])
1878         else:
1879             for protocol in ('rtmp', 'rtsp'):
1880                 if protocol not in skip_protocols:
1881                     formats.append({
1882                         'url': '%s:%s' % (protocol, url_base),
1883                         'format_id': protocol,
1884                         'protocol': protocol,
1885                     })
1886         return formats
1887     def _find_jwplayer_data(self, webpage, video_id=None, transform_source=js_to_json):
1888         mobj = re.search(
1889             r'(?s)jwplayer\((?P&lt;quote&gt;[\'"])[^\'" ]+(?P=quote)\)(?!&lt;/script&gt;).*?\.setup\s*\((?P&lt;options&gt;[^)]+)\)',
1890             webpage)
1891         if mobj:
1892             try:
1893                 jwplayer_data = self._parse_json(mobj.group('options'),
1894                                                  video_id=video_id,
1895                                                  transform_source=transform_source)
1896             except ExtractorError:
1897                 pass
1898             else:
1899                 if isinstance(jwplayer_data, dict):
1900                     return jwplayer_data
1901     def _extract_jwplayer_data(self, webpage, video_id, *args, **kwargs):
1902         jwplayer_data = self._find_jwplayer_data(
1903             webpage, video_id, transform_source=js_to_json)
1904         return self._parse_jwplayer_data(
1905             jwplayer_data, video_id, *args, **kwargs)
1906     def _parse_jwplayer_data(self, jwplayer_data, video_id=None, require_title=True,
1907                              m3u8_id=None, mpd_id=None, rtmp_params=None, base_url=None):
1908         if 'playlist' not in jwplayer_data:
1909             jwplayer_data = {'playlist': [jwplayer_data]}
1910         entries = []
1911         if not isinstance(jwplayer_data['playlist'], list):
1912             jwplayer_data['playlist'] = [jwplayer_data['playlist']]
1913         for video_data in jwplayer_data['playlist']:
1914             if 'sources' not in video_data:
1915                 video_data['sources'] = [video_data]
1916             this_video_id = video_id or video_data['mediaid']
1917             formats = self._parse_jwplayer_formats(
1918                 video_data['sources'], video_id=this_video_id, m3u8_id=m3u8_id,
1919                 mpd_id=mpd_id, rtmp_params=rtmp_params, base_url=base_url)
1920             subtitles = {}
1921             tracks = video_data.get('tracks')
1922             if tracks and isinstance(tracks, list):
1923                 for track in tracks:
1924                     if not isinstance(track, dict):
1925                         continue
1926                     track_kind = track.get('kind')
1927                     if not track_kind or not isinstance(track_kind, compat_str):
1928                         continue
1929                     if track_kind.lower() not in ('captions', 'subtitles'):
1930                         continue
1931                     track_url = urljoin(base_url, track.get('file'))
1932                     if not track_url:
1933                         continue
1934                     subtitles.setdefault(track.get('label') or 'en', []).append({
1935                         'url': self._proto_relative_url(track_url)
1936                     })
1937             entry = {
1938                 'id': this_video_id,
1939                 'title': unescapeHTML(video_data['title'] if require_title else video_data.get('title')),
1940                 'description': clean_html(video_data.get('description')),
1941                 'thumbnail': urljoin(base_url, self._proto_relative_url(video_data.get('image'))),
1942                 'timestamp': int_or_none(video_data.get('pubdate')),
1943                 'duration': float_or_none(jwplayer_data.get('duration') or video_data.get('duration')),
1944                 'subtitles': subtitles,
1945             }
1946             if len(formats) == 1 and re.search(r'^(?:http|//).*(?:youtube\.com|youtu\.be)/.+', formats[0]['url']):
1947                 entry.update({
1948                     '_type': 'url_transparent',
1949                     'url': formats[0]['url'],
1950                 })
1951             else:
1952                 self._sort_formats(formats)
1953                 entry['formats'] = formats
1954             entries.append(entry)
1955         if len(entries) == 1:
1956             return entries[0]
1957         else:
1958             return self.playlist_result(entries)
1959     def _parse_jwplayer_formats(self, jwplayer_sources_data, video_id=None,
1960                                 m3u8_id=None, mpd_id=None, rtmp_params=None, base_url=None):
1961         urls = []
1962         formats = []
1963         for source in jwplayer_sources_data:
1964             if not isinstance(source, dict):
1965                 continue
1966             source_url = urljoin(
1967                 base_url, self._proto_relative_url(source.get('file')))
1968             if not source_url or source_url in urls:
1969                 continue
1970             urls.append(source_url)
1971             source_type = source.get('type') or ''
1972             ext = mimetype2ext(source_type) or determine_ext(source_url)
1973             if source_type == 'hls' or ext == 'm3u8':
1974                 formats.extend(self._extract_m3u8_formats(
1975                     source_url, video_id, 'mp4', entry_protocol='m3u8_native',
1976                     m3u8_id=m3u8_id, fatal=False))
1977             elif source_type == 'dash' or ext == 'mpd':
1978                 formats.extend(self._extract_mpd_formats(
1979                     source_url, video_id, mpd_id=mpd_id, fatal=False))
1980             elif ext == 'smil':
1981                 formats.extend(self._extract_smil_formats(
1982                     source_url, video_id, fatal=False))
1983             elif source_type.startswith('audio') or ext in (
1984                     'oga', 'aac', 'mp3', 'mpeg', 'vorbis'):
1985                 formats.append({
1986                     'url': source_url,
1987                     'vcodec': 'none',
1988                     'ext': ext,
1989                 })
1990             else:
1991                 height = int_or_none(source.get('height'))
1992                 if height is None:
1993                     height = int_or_none(self._search_regex(
1994                         r'^(\d{3,4})[pP]?(?:\b|$)', compat_str(source.get('label') or ''),
1995                         'height', default=None))
1996                 a_format = {
1997                     'url': source_url,
1998                     'width': int_or_none(source.get('width')),
1999                     'height': height,
2000                     'tbr': int_or_none(source.get('bitrate')),
2001                     'ext': ext,
2002                 }
2003                 if source_url.startswith('rtmp'):
2004                     a_format['ext'] = 'flv'
2005                     rtmp_url_parts = re.split(
2006                         r'((?:mp4|mp3|flv):)', source_url, 1)
2007                     if len(rtmp_url_parts) == 3:
2008                         rtmp_url, prefix, play_path = rtmp_url_parts
2009                         a_format.update({
2010                             'url': rtmp_url,
2011                             'play_path': prefix + play_path,
2012                         })
2013                     if rtmp_params:
2014                         a_format.update(rtmp_params)
2015                 formats.append(a_format)
2016         return formats
2017     def _live_title(self, name):
2018         now = datetime.datetime.now()
2019         now_str = now.strftime('%Y-%m-%d %H:%M')
2020         return name + ' ' + now_str
2021     def _int(self, v, name, fatal=False, **kwargs):
2022         res = int_or_none(v, **kwargs)
2023         if 'get_attr' in kwargs:
2024             print(getattr(v, kwargs['get_attr']))
2025         if res is None:
2026             msg = 'Failed to extract %s: Could not parse value %r' % (name, v)
2027             if fatal:
2028                 raise ExtractorError(msg)
2029             else:
2030                 self._downloader.report_warning(msg)
2031         return res
2032     def _float(self, v, name, fatal=False, **kwargs):
2033         res = float_or_none(v, **kwargs)
2034         if res is None:
2035             msg = 'Failed to extract %s: Could not parse value %r' % (name, v)
2036             if fatal:
2037                 raise ExtractorError(msg)
2038             else:
2039                 self._downloader.report_warning(msg)
2040         return res
2041     def _set_cookie(self, domain, name, value, expire_time=None, port=None,
2042                     path='/', secure=False, discard=False, rest={}, **kwargs):
2043         cookie = compat_cookiejar_Cookie(
2044             0, name, value, port, port is not None, domain, True,
2045             domain.startswith('.'), path, True, secure, expire_time,
2046             discard, None, None, rest)
2047         self._downloader.cookiejar.set_cookie(cookie)
2048     def _get_cookies(self, url):
2049         req = sanitized_Request(url)
2050         self._downloader.cookiejar.add_cookie_header(req)
2051         return compat_cookies_SimpleCookie(req.get_header('Cookie'))
2052     def _apply_first_set_cookie_header(self, url_handle, cookie):
2053         for header, cookies in url_handle.headers.items():
2054             if header.lower() != 'set-cookie':
2055                 continue
2056             if sys.version_info[0] &gt;= 3:
2057                 cookies = cookies.encode('iso-8859-1')
2058             cookies = cookies.decode('utf-8')
2059             cookie_value = re.search(
2060                 r'%s=(.+?);.*?\b[Dd]omain=(.+?)(?:[,;]|$)' % cookie, cookies)
2061             if cookie_value:
2062                 value, domain = cookie_value.groups()
2063                 self._set_cookie(domain, cookie, value)
2064                 break
2065     def get_testcases(self, include_onlymatching=False):
2066         t = getattr(self, '_TEST', None)
2067         if t:
2068             assert not hasattr(self, '_TESTS'), \
2069                 '%s has _TEST and _TESTS' % type(self).__name__
2070             tests = [t]
2071         else:
2072             tests = getattr(self, '_TESTS', [])
2073         for t in tests:
2074             if not include_onlymatching and t.get('only_matching', False):
2075                 continue
2076             t['name'] = type(self).__name__[:-len('IE')]
2077             yield t
2078     def is_suitable(self, age_limit):
2079         will be dropped. """
2080         list1_urls = set([item['url'] for item in subtitle_list1])
2081         ret = list(subtitle_list1)
2082         ret.extend([item for item in subtitle_list2 if item['url'] not in list1_urls])
2083         return ret
2084     @classmethod
2085     def _merge_subtitles(cls, subtitle_dict1, subtitle_dict2):
2086         ret = dict(subtitle_dict1)
2087         for lang in subtitle_dict2:
2088             ret[lang] = cls._merge_subtitle_items(subtitle_dict1.get(lang, []), subtitle_dict2[lang])
2089         return ret
2090     def extract_automatic_captions(self, *args, **kwargs):
2091         if (self._downloader.params.get('writeautomaticsub', False)
2092                 or self._downloader.params.get('listsubtitles')):
2093             return self._get_automatic_captions(*args, **kwargs)
2094         return {}
2095     def _get_automatic_captions(self, *args, **kwargs):
2096         raise NotImplementedError('This method must be implemented by subclasses')
2097     def mark_watched(self, *args, **kwargs):
2098         if (self._downloader.params.get('mark_watched', False)
2099                 and (self._get_login_info()[0] is not None
2100                      or self._downloader.params.get('cookiefile') is not None)):
2101             self._mark_watched(*args, **kwargs)
2102     def _mark_watched(self, *args, **kwargs):
2103         raise NotImplementedError('This method must be implemented by subclasses')
2104     def geo_verification_headers(self):
2105         headers = {}
2106         geo_verification_proxy = self._downloader.params.get('geo_verification_proxy')
2107         if geo_verification_proxy:
2108             headers['Ytdl-request-proxy'] = geo_verification_proxy
2109         return headers
2110     def _generic_id(self, url):
2111         return compat_urllib_parse_unquote(os.path.splitext(url.rstrip('/').split('/')[-1])[0])
2112     def _generic_title(self, url):
2113         return compat_urllib_parse_unquote(os.path.splitext(url_basename(url))[0])
2114 class SearchInfoExtractor(InfoExtractor):
2115     @classmethod
2116     def _make_valid_url(cls):
2117         return r'%s(?P&lt;prefix&gt;|[1-9][0-9]*|all):(?P&lt;query&gt;[\s\S]+)' % cls._SEARCH_KEY
2118     @classmethod
2119     def suitable(cls, url):
2120         return re.match(cls._make_valid_url(), url) is not None
2121     def _real_extract(self, query):
2122         mobj = re.match(self._make_valid_url(), query)
2123         if mobj is None:
2124             raise ExtractorError('Invalid search query "%s"' % query)
2125         prefix = mobj.group('prefix')
2126         query = mobj.group('query')
2127         if prefix == '':
2128             return self._get_n_results(query, 1)
2129         elif prefix == 'all':
2130             return self._get_n_results(query, self._MAX_RESULTS)
2131         else:
2132             n = int(prefix)
2133             if n &lt;= 0:
2134                 raise ExtractorError('invalid download number %s for query "%s"' % (n, query))
2135             elif n &gt; self._MAX_RESULTS:
2136                 self._downloader.report_warning('%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))
2137                 n = self._MAX_RESULTS
2138             return self._get_n_results(query, n)
2139     def _get_n_results(self, query, n):
2140         raise NotImplementedError('This method must be implemented by subclasses')
2141     @property
2142     def SEARCH_KEY(self):
2143         return self._SEARCH_KEY
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>minoto.py</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
1 from __future__ import unicode_literals
2 import re
3 from .common import InfoExtractor
4 from ..utils import (
5     int_or_none,
6     parse_codecs,
7 )
8 class MinotoIE(InfoExtractor):
9     def _real_extract(self, url):
10         mobj <font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>= re.match(self._VALID_URL, url)
11         player_id = mobj.group('player_id') or '1'
12         video_id = mobj.group('id')
13         video_data = self._download_json(</b></font>'http://play.minoto-video.com/%s/%s.js' % (player_id, video_id), video_id)
14         video_metadata = video_data['video-metadata']
15         formats = []
16         for fmt in video_data['video-files']:
17             fmt_url = fmt.get('url')
18             if not fmt_url:
19                 continue
20             container = fmt.get('container')
21             if container == 'hls':
22                 formats.extend(fmt_url, video_id, 'mp4', m3u8_id='hls', fatal=False)
23             else:
24                 formats.append({
25                     'format_id': fmt_profile.get('name-short'),
26                     'format_note': fmt_profile.get<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>('name'),
27                     'url': fmt_url,
28                     'container': container,
29                     'tbr': int_or_none(fmt.get('bitrate')),
30                     'filesize': int_or_none(fmt.get('filesize')),
31                     'width': int_or_none(fmt.get('width')),
32                     'height': int_or_none(fmt.get('height')),
33                     'codecs': parse_codecs(fmt.get(</b></font>'codecs')),
34                 })
35         self._sort_formats(formats)
36         return {
37             'id': video_id,
38             'title': video_metadata['title'],
39             'description': video_metadata.get('description'),
40             'thumbnail': video_metadata.get('video-poster', {}).get('url'),
41             'formats': formats,
42         }
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
