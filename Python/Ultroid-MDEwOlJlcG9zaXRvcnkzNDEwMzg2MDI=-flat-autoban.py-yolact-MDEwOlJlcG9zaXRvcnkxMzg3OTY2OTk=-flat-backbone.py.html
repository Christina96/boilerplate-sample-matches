
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 2.1810250817884405%, Tokens: 10</h2>
        <div class="column">
            <h3>Ultroid-MDEwOlJlcG9zaXRvcnkzNDEwMzg2MDI=-flat-autoban.py</h3>
            <pre><code>1  from . import get_help
2  __doc__ = get_help("help_autoban")
3  from telethon import events
4  from pyUltroid.dB.base import KeyManager
5  from . import LOGS, asst, ultroid_bot, ultroid_cmd
6  Keym = KeyManager("DND_CHATS", cast=list)
7  def join_func(e):
8      return e.user_joined and Keym.contains(e.chat_id)
9  async def dnd_func(event):
10      for user in event.users:
11          try:
12              await (await event.client.kick_participant(event.chat_id, user)).delete()
13          except Exception as ex:
14              LOGS.error("Error in DND:")
15              LOGS.exception(ex)
16      await event.delete()
17  @ultroid_cmd(
18      pattern="autokick (on|off)$",
19      admins_only=True,
20      manager=True,
21      require="ban_users",
22      fullsudo=True,
23  )
24  async def _(event):
25      match = event.pattern_match.group(1)
26      if match == "on":
27          if Keym.contains(event.chat_id):
28              return await event.eor("`Chat already in do not disturb mode.`", time=3)
29          Keym.add(event.chat_id)
30          event.client.add_handler(dnd_func, events.ChatAction(func=join_func))
31          await event.eor("`Do not disturb mode activated for this chat.`", time=3)
32      elif match == "off":
33          if not Keym.contains(event.chat_id):
34              return await event.eor("`Chat is not in do not disturb mode.`", time=3)
35          Keym.remove(event.chat_id)
36          await event.eor("`Do not disturb mode deactivated for this chat.`", time=3)
37  if Keym.get():
<span onclick='openModal()' class='match'>38      ultroid_bot.add_handler(dnd_func, events.ChatAction(func=join_func))
39      asst.add_handler(dnd_func, events.ChatAction(func=join_func))
</span></code></pre>
        </div>
        <div class="column">
            <h3>yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-backbone.py</h3>
            <pre><code>1  import torch
2  import torch.nn as nn
3  import pickle
4  from collections import OrderedDict
5  try:
6      from dcn_v2 import DCN
7  except ImportError:
8      def DCN(*args, **kwdargs):
9          raise Exception('DCN could not be imported. If you want to use YOLACT++ models, compile DCN. Check the README for instructions.')
10  class Bottleneck(nn.Module):
11      expansion = 4
12      def __init__(self, inplanes, planes, stride=1, downsample=None, norm_layer=nn.BatchNorm2d, dilation=1, use_dcn=False):
13          super(Bottleneck, self).__init__()
14          self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False, dilation=dilation)
15          self.bn1 = norm_layer(planes)
16          if use_dcn:
17              self.conv2 = DCN(planes, planes, kernel_size=3, stride=stride,
18                                  padding=dilation, dilation=dilation, deformable_groups=1)
19              self.conv2.bias.data.zero_()
20              self.conv2.conv_offset_mask.weight.data.zero_()
21              self.conv2.conv_offset_mask.bias.data.zero_()
22          else:
23              self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
24                                  padding=dilation, bias=False, dilation=dilation)
25          self.bn2 = norm_layer(planes)
26          self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False, dilation=dilation)
27          self.bn3 = norm_layer(planes * 4)
28          self.relu = nn.ReLU(inplace=True)
29          self.downsample = downsample
30          self.stride = stride
31      def forward(self, x):
32          residual = x
33          out = self.conv1(x)
34          out = self.bn1(out)
35          out = self.relu(out)
36          out = self.conv2(out)
37          out = self.bn2(out)
38          out = self.relu(out)
39          out = self.conv3(out)
40          out = self.bn3(out)
41          if self.downsample is not None:
42              residual = self.downsample(x)
43          out += residual
44          out = self.relu(out)
45          return out
46  class ResNetBackbone(nn.Module):
47      def __init__(self, layers, dcn_layers=[0, 0, 0, 0], dcn_interval=1, atrous_layers=[], block=Bottleneck, norm_layer=nn.BatchNorm2d):
48          super().__init__()
49          self.num_base_layers = len(layers)
50          self.layers = nn.ModuleList()
51          self.channels = []
52          self.norm_layer = norm_layer
53          self.dilation = 1
54          self.atrous_layers = atrous_layers
55          self.inplanes = 64
56          self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
57          self.bn1 = norm_layer(64)
58          self.relu = nn.ReLU(inplace=True)
59          self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
60          self._make_layer(block, 64, layers[0], dcn_layers=dcn_layers[0], dcn_interval=dcn_interval)
61          self._make_layer(block, 128, layers[1], stride=2, dcn_layers=dcn_layers[1], dcn_interval=dcn_interval)
62          self._make_layer(block, 256, layers[2], stride=2, dcn_layers=dcn_layers[2], dcn_interval=dcn_interval)
63          self._make_layer(block, 512, layers[3], stride=2, dcn_layers=dcn_layers[3], dcn_interval=dcn_interval)
64          self.backbone_modules = [m for m in self.modules() if isinstance(m, nn.Conv2d)]
65      def _make_layer(self, block, planes, blocks, stride=1, dcn_layers=0, dcn_interval=1):
66          downsample = None
67          if stride != 1 or self.inplanes != planes * block.expansion:
68              if len(self.layers) in self.atrous_layers:
69                  self.dilation += 1
70                  stride = 1
71              downsample = nn.Sequential(
72                  nn.Conv2d(self.inplanes, planes * block.expansion,
73                            kernel_size=1, stride=stride, bias=False,
74                            dilation=self.dilation),
75                  self.norm_layer(planes * block.expansion),
76              )
77          layers = []
78          use_dcn = (dcn_layers >= blocks)
79          layers.append(block(self.inplanes, planes, stride, downsample, self.norm_layer, self.dilation, use_dcn=use_dcn))
80          self.inplanes = planes * block.expansion
81          for i in range(1, blocks):
82              use_dcn = ((i+dcn_layers) >= blocks) and (i % dcn_interval == 0)
83              layers.append(block(self.inplanes, planes, norm_layer=self.norm_layer, use_dcn=use_dcn))
84          layer = nn.Sequential(*layers)
85          self.channels.append(planes * block.expansion)
86          self.layers.append(layer)
87          return layer
88      def forward(self, x):
89          x = self.conv1(x)
90          x = self.bn1(x)
91          x = self.relu(x)
92          x = self.maxpool(x)
93          outs = []
94          for layer in self.layers:
95              x = layer(x)
96              outs.append(x)
97          return tuple(outs)
98      def init_backbone(self, path):
99          state_dict = torch.load(path)
100          keys = list(state_dict)
101          for key in keys:
102              if key.startswith('layer'):
103                  idx = int(key[5])
104                  new_key = 'layers.' + str(idx-1) + key[6:]
105                  state_dict[new_key] = state_dict.pop(key)
106          self.load_state_dict(state_dict, strict=False)
107      def add_layer(self, conv_channels=1024, downsample=2, depth=1, block=Bottleneck):
108          self._make_layer(block, conv_channels // block.expansion, blocks=depth, stride=downsample)
109  class ResNetBackboneGN(ResNetBackbone):
110      def __init__(self, layers, num_groups=32):
111          super().__init__(layers, norm_layer=lambda x: nn.GroupNorm(num_groups, x))
112      def init_backbone(self, path):
113          with open(path, 'rb') as f:
114              state_dict = pickle.load(f, encoding='latin1') # From the detectron source
115              state_dict = state_dict['blobs']
116          our_state_dict_keys = list(self.state_dict().keys())
117          new_state_dict = {}
118          gn_trans     = lambda x: ('gn_s' if x == 'weight' else 'gn_b')
119          layeridx2res = lambda x: 'res' + str(int(x)+2)
120          block2branch = lambda x: 'branch2' + ('a', 'b', 'c')[int(x[-1:])-1]
121          for key in our_state_dict_keys:
122              parts = key.split('.')
123              transcribed_key = ''
124              if (parts[0] == 'conv1'):
125                  transcribed_key = 'conv1_w'
126              elif (parts[0] == 'bn1'):
127                  transcribed_key = 'conv1_' + gn_trans(parts[1])
128              elif (parts[0] == 'layers'):
129                  if int(parts[1]) >= self.num_base_layers: continue
130                  transcribed_key = layeridx2res(parts[1])
131                  transcribed_key += '_' + parts[2] + '_'
132                  if parts[3] == 'downsample':
133                      transcribed_key += 'branch1_'
134                      if parts[4] == '0':
135                          transcribed_key += 'w'
136                      else:
137                          transcribed_key += gn_trans(parts[5])
138                  else:
139                      transcribed_key += block2branch(parts[3]) + '_'
140                      if 'conv' in parts[3]:
141                          transcribed_key += 'w'
142                      else:
143                          transcribed_key += gn_trans(parts[4])
144              new_state_dict[key] = torch.Tensor(state_dict[transcribed_key])
145          self.load_state_dict(new_state_dict, strict=False)
146  def darknetconvlayer(in_channels, out_channels, *args, **kwdargs):
<span onclick='openModal()' class='match'>147      return nn.Sequential(
148          nn.Conv2d(in_channels, out_channels, *args, **kwdargs, bias=False),
149          nn.BatchNorm2d(out_channels),
150          nn.LeakyReLU(0.1, inplace=True)
</span>151      )
152  class DarkNetBlock(nn.Module):
153      expansion = 2
154      def __init__(self, in_channels, channels):
155          super().__init__()
156          self.conv1 = darknetconvlayer(in_channels, channels,                  kernel_size=1)
157          self.conv2 = darknetconvlayer(channels,    channels * self.expansion, kernel_size=3, padding=1)
158      def forward(self, x):
159          return self.conv2(self.conv1(x)) + x
160  class DarkNetBackbone(nn.Module):
161      def __init__(self, layers=[1, 2, 8, 8, 4], block=DarkNetBlock):
162          super().__init__()
163          self.num_base_layers = len(layers)
164          self.layers = nn.ModuleList()
165          self.channels = []
166          self._preconv = darknetconvlayer(3, 32, kernel_size=3, padding=1)
167          self.in_channels = 32
168          self._make_layer(block, 32,  layers[0])
169          self._make_layer(block, 64,  layers[1])
170          self._make_layer(block, 128, layers[2])
171          self._make_layer(block, 256, layers[3])
172          self._make_layer(block, 512, layers[4])
173          self.backbone_modules = [m for m in self.modules() if isinstance(m, nn.Conv2d)]
174      def _make_layer(self, block, channels, num_blocks, stride=2):
175          layer_list = []
176          layer_list.append(
177              darknetconvlayer(self.in_channels, channels * block.expansion,
178                               kernel_size=3, padding=1, stride=stride))
179          self.in_channels = channels * block.expansion
180          layer_list += [block(self.in_channels, channels) for _ in range(num_blocks)]
181          self.channels.append(self.in_channels)
182          self.layers.append(nn.Sequential(*layer_list))
183      def forward(self, x):
184          x = self._preconv(x)
185          outs = []
186          for layer in self.layers:
187              x = layer(x)
188              outs.append(x)
189          return tuple(outs)
190      def add_layer(self, conv_channels=1024, stride=2, depth=1, block=DarkNetBlock):
191          self._make_layer(block, conv_channels // block.expansion, num_blocks=depth, stride=stride)
192      def init_backbone(self, path):
193          self.load_state_dict(torch.load(path), strict=False)
194  class VGGBackbone(nn.Module):
195      def __init__(self, cfg, extra_args=[], norm_layers=[]):
196          super().__init__()
197          self.channels = []
198          self.layers = nn.ModuleList()
199          self.in_channels = 3
200          self.extra_args = list(reversed(extra_args)) # So I can use it as a stack
201          self.total_layer_count = 0
202          self.state_dict_lookup = {}
203          for idx, layer_cfg in enumerate(cfg):
204              self._make_layer(layer_cfg)
205          self.norms = nn.ModuleList([nn.BatchNorm2d(self.channels[l]) for l in norm_layers])
206          self.norm_lookup = {l: idx for idx, l in enumerate(norm_layers)}
207          self.backbone_modules = [m for m in self.modules() if isinstance(m, nn.Conv2d)]
208      def _make_layer(self, cfg):
209          layers = []
210          for v in cfg:
211              args = None
212              if isinstance(v, tuple):
213                  args = v[1]
214                  v = v[0]
215              if v == 'M':
216                  if args is None:
217                      args = {'kernel_size': 2, 'stride': 2}
218                  layers.append(nn.MaxPool2d(**args))
219              else:
220                  cur_layer_idx = self.total_layer_count + len(layers)
221                  self.state_dict_lookup[cur_layer_idx] = '%d.%d' % (len(self.layers), len(layers))
222                  if args is None:
223                      args = {'kernel_size': 3, 'padding': 1}
224                  layers.append(nn.Conv2d(self.in_channels, v, **args))
225                  layers.append(nn.ReLU(inplace=True))
226                  self.in_channels = v
227          self.total_layer_count += len(layers)
228          self.channels.append(self.in_channels)
229          self.layers.append(nn.Sequential(*layers))
230      def forward(self, x):
231          outs = []
232          for idx, layer in enumerate(self.layers):
233              x = layer(x)
234              if idx in self.norm_lookup:
235                  x = self.norms[self.norm_lookup[idx]](x)
236              outs.append(x)
237          return tuple(outs)
238      def transform_key(self, k):
239          vals = k.split('.')
240          layerIdx = self.state_dict_lookup[int(vals[0])]
241          return 'layers.%s.%s' % (layerIdx, vals[1])
242      def init_backbone(self, path):
243          state_dict = torch.load(path)
244          state_dict = OrderedDict([(self.transform_key(k), v) for k,v in state_dict.items()])
245          self.load_state_dict(state_dict, strict=False)
246      def add_layer(self, conv_channels=128, downsample=2):
247          if len(self.extra_args) > 0:
248              conv_channels, downsample = self.extra_args.pop()
249          padding = 1 if downsample > 1 else 0
250          layer = nn.Sequential(
251              nn.Conv2d(self.in_channels, conv_channels, kernel_size=1),
252              nn.ReLU(inplace=True),
253              nn.Conv2d(conv_channels, conv_channels*2, kernel_size=3, stride=downsample, padding=padding),
254              nn.ReLU(inplace=True)
255          )
256          self.in_channels = conv_channels*2
257          self.channels.append(self.in_channels)
258          self.layers.append(layer)
259  def construct_backbone(cfg):
260      backbone = cfg.type(*cfg.args)
261      num_layers = max(cfg.selected_layers) + 1
262      while len(backbone.layers) < num_layers:
263          backbone.add_layer()
264      return backbone
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from Ultroid-MDEwOlJlcG9zaXRvcnkzNDEwMzg2MDI=-flat-autoban.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from yolact-MDEwOlJlcG9zaXRvcnkxMzg3OTY2OTk=-flat-backbone.py</div>
                </div>
                <div class="column column_space"><pre><code>38      ultroid_bot.add_handler(dnd_func, events.ChatAction(func=join_func))
39      asst.add_handler(dnd_func, events.ChatAction(func=join_func))
</pre></code></div>
                <div class="column column_space"><pre><code>147      return nn.Sequential(
148          nn.Conv2d(in_channels, out_channels, *args, **kwdargs, bias=False),
149          nn.BatchNorm2d(out_channels),
150          nn.LeakyReLU(0.1, inplace=True)
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    