
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 5.697022011221407%, Tokens: 9, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-helper.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  import abc
5  import six
6  from tensorflow.contrib.distributions.python.ops import bernoulli
7  from tensorflow.contrib.distributions.python.ops import categorical
8  from tensorflow.python.framework import dtypes
9  from tensorflow.python.framework import ops
10  from tensorflow.python.layers import base as layers_base
11  from tensorflow.python.ops import array_ops
12  from tensorflow.python.ops import control_flow_ops
13  from tensorflow.python.ops import embedding_ops
14  from tensorflow.python.ops import math_ops
15  from tensorflow.python.ops import random_ops
16  from tensorflow.python.ops import tensor_array_ops
17  from tensorflow.python.util import nest
18  from seq2seq.contrib.seq2seq import decoder
19  __all__ = [
20      "Helper",
21      "TrainingHelper",
22      "GreedyEmbeddingHelper",
23      "CustomHelper",
24      "ScheduledEmbeddingTrainingHelper",
25      "ScheduledOutputTrainingHelper",
26  ]
27  _transpose_batch_time = decoder._transpose_batch_time  # pylint: disable=protected-access
28  def _unstack_ta(inp):
29    return tensor_array_ops.TensorArray(
30        dtype=inp.dtype, size=array_ops.shape(inp)[0],
31        element_shape=inp.get_shape()[1:]).unstack(inp)
32  @six.add_metaclass(abc.ABCMeta)
33  class Helper(object):
34    @abc.abstractproperty
35    def batch_size(self):
36      raise NotImplementedError("batch_size has not been implemented")
37    @abc.abstractmethod
38    def initialize(self, name=None):
39      pass
40    @abc.abstractmethod
41    def sample(self, time, outputs, state, name=None):
42      pass
43    @abc.abstractmethod
44    def next_inputs(self, time, outputs, state, sample_ids, name=None):
45      pass
46  class CustomHelper(Helper):
47    def __init__(self, initialize_fn, sample_fn, next_inputs_fn):
48      self._initialize_fn = initialize_fn
49      self._sample_fn = sample_fn
50      self._next_inputs_fn = next_inputs_fn
51      self._batch_size = None
52    @property
53    def batch_size(self):
54      if self._batch_size is None:
55        raise ValueError("batch_size accessed before initialize was called")
56      return self._batch_size
57    def initialize(self, name=None):
58      with ops.name_scope(name, "%sInitialize" % type(self).__name__):
59        (finished, next_inputs) = self._initialize_fn()
60        if self._batch_size is None:
61          self._batch_size = array_ops.size(finished)
62      return (finished, next_inputs)
63    def sample(self, time, outputs, state, name=None):
64      with ops.name_scope(
65          name, "%sSample" % type(self).__name__, (time, outputs, state)):
66        return self._sample_fn(time=time, outputs=outputs, state=state)
67    def next_inputs(self, time, outputs, state, sample_ids, name=None):
68      with ops.name_scope(
69          name, "%sNextInputs" % type(self).__name__, (time, outputs, state)):
70        return self._next_inputs_fn(
71            time=time, outputs=outputs, state=state, sample_ids=sample_ids)
72  class TrainingHelper(Helper):
73    def __init__(self, inputs, sequence_length, time_major=False, name=None):
74      with ops.name_scope(name, "TrainingHelper", [inputs, sequence_length]):
75        inputs = ops.convert_to_tensor(inputs, name="inputs")
76        if not time_major:
77          inputs = nest.map_structure(_transpose_batch_time, inputs)
78        self._input_tas = nest.map_structure(_unstack_ta, inputs)
79        self._sequence_length = ops.convert_to_tensor(
80            sequence_length, name="sequence_length")
81        if self._sequence_length.get_shape().ndims != 1:
82          raise ValueError(
83              "Expected sequence_length to be a vector, but received shape: %s" %
84              self._sequence_length.get_shape())
85        self._zero_inputs = nest.map_structure(
86            lambda inp: array_ops.zeros_like(inp[0, :]), inputs)
87        self._batch_size = array_ops.size(sequence_length)
88    @property
89    def batch_size(self):
90      return self._batch_size
91    def initialize(self, name=None):
92      with ops.name_scope(name, "TrainingHelperInitialize"):
93        finished = math_ops.equal(0, self._sequence_length)
94        all_finished = math_ops.reduce_all(finished)
95        next_inputs = control_flow_ops.cond(
96            all_finished, lambda: self._zero_inputs,
97            lambda: nest.map_structure(lambda inp: inp.read(0), self._input_tas))
98        return (finished, next_inputs)
99    def sample(self, time, outputs, name=None, **unused_kwargs):
100      with ops.name_scope(name, "TrainingHelperSample", [time, outputs]):
101        sample_ids = math_ops.cast(
102            math_ops.argmax(outputs, axis=-1), dtypes.int32)
103        return sample_ids
104    def next_inputs(self, time, outputs, state, name=None, **unused_kwargs):
105      with ops.name_scope(name, "TrainingHelperNextInputs",
106                          [time, outputs, state]):
107        next_time = time + 1
108        finished = (next_time >= self._sequence_length)
109        all_finished = math_ops.reduce_all(finished)
110        def read_from_ta(inp):
111          return inp.read(next_time)
112        next_inputs = control_flow_ops.cond(
113            all_finished, lambda: self._zero_inputs,
114            lambda: nest.map_structure(read_from_ta, self._input_tas))
115        return (finished, next_inputs, state)
116  class ScheduledEmbeddingTrainingHelper(TrainingHelper):
117    def __init__(self, inputs, sequence_length, embedding, sampling_probability,
118                 time_major=False, seed=None, scheduling_seed=None, name=None):
119      with ops.name_scope(name, "ScheduledEmbeddingSamplingWrapper",
120                          [embedding, sampling_probability]):
121        if callable(embedding):
122          self._embedding_fn = embedding
123        else:
124          self._embedding_fn = (
125              lambda ids: embedding_ops.embedding_lookup(embedding, ids))
126        self._sampling_probability = ops.convert_to_tensor(
127            sampling_probability, name="sampling_probability")
128        if self._sampling_probability.get_shape().ndims not in (0, 1):
129          raise ValueError(
130              "sampling_probability must be either a scalar or a vector. "
131              "saw shape: %s" % (self._sampling_probability.get_shape()))
132        self._seed = seed
133        self._scheduling_seed = scheduling_seed
134        super(ScheduledEmbeddingTrainingHelper, self).__init__(
135            inputs=inputs,
136            sequence_length=sequence_length,
137            time_major=time_major,
138            name=name)
139    def initialize(self, name=None):
140      return super(ScheduledEmbeddingTrainingHelper, self).initialize(name=name)
141    def sample(self, time, outputs, state, name=None):
142      with ops.name_scope(name, "ScheduledEmbeddingTrainingHelperSample",
143                          [time, outputs, state]):
144        select_sample_noise = random_ops.random_uniform(
145            [self.batch_size], seed=self._scheduling_seed)
146        select_sample = (self._sampling_probability > select_sample_noise)
147        sample_id_sampler = categorical.Categorical(logits=outputs)
148        return array_ops.where(
149            select_sample,
150            sample_id_sampler.sample(seed=self._seed),
151            array_ops.tile([-1], [self.batch_size]))
152    def next_inputs(self, time, outputs, state, sample_ids, name=None):
153      with ops.name_scope(name, "ScheduledEmbeddingTrainingHelperSample",
154                          [time, outputs, state, sample_ids]):
155        (finished, base_next_inputs, state) = (
156            super(ScheduledEmbeddingTrainingHelper, self).next_inputs(
157                time=time,
158                outputs=outputs,
159                state=state,
160                sample_ids=sample_ids,
161                name=name))
162        def maybe_sample():
163          where_sampling = math_ops.cast(
164              array_ops.where(sample_ids > -1), dtypes.int32)
165          where_not_sampling = math_ops.cast(
166              array_ops.where(sample_ids <= -1), dtypes.int32)
167          where_sampling_flat = array_ops.reshape(where_sampling, [-1])
168          where_not_sampling_flat = array_ops.reshape(where_not_sampling, [-1])
169          sample_ids_sampling = array_ops.gather(sample_ids, where_sampling_flat)
170          inputs_not_sampling = array_ops.gather(
171              base_next_inputs, where_not_sampling_flat)
172          sampled_next_inputs = self._embedding_fn(sample_ids_sampling)
173          base_shape = array_ops.shape(base_next_inputs)
174          return (array_ops.scatter_nd(indices=where_sampling,
175                                       updates=sampled_next_inputs,
176                                       shape=base_shape)
177                  + array_ops.scatter_nd(indices=where_not_sampling,
178                                         updates=inputs_not_sampling,
179                                         shape=base_shape))
180        all_finished = math_ops.reduce_all(finished)
181        next_inputs = control_flow_ops.cond(
182            all_finished, lambda: base_next_inputs, maybe_sample)
183        return (finished, next_inputs, state)
184  class ScheduledOutputTrainingHelper(TrainingHelper):
185    def __init__(self, inputs, sequence_length, sampling_probability,
186                 time_major=False, seed=None, next_input_layer=None,
187                 auxiliary_inputs=None, name=None):
188      with ops.name_scope(name, "ScheduledOutputTrainingHelper",
189                          [inputs, auxiliary_inputs, sampling_probability]):
190        self._sampling_probability = ops.convert_to_tensor(
191            sampling_probability, name="sampling_probability")
192        if self._sampling_probability.get_shape().ndims not in (0, 1):
193          raise ValueError(
194              "sampling_probability must be either a scalar or a vector. "
195              "saw shape: %s" % (self._sampling_probability.get_shape()))
196        if auxiliary_inputs is None:
197          maybe_concatenated_inputs = inputs
198        else:
199          inputs = ops.convert_to_tensor(inputs, name="inputs")
200          auxiliary_inputs = ops.convert_to_tensor(
201              auxiliary_inputs, name="auxiliary_inputs")
202          maybe_concatenated_inputs = nest.map_structure(
203              lambda x, y: array_ops.concat((x, y), -1),
204              inputs, auxiliary_inputs)
205          if not time_major:
206            auxiliary_inputs = nest.map_structure(
207                _transpose_batch_time, auxiliary_inputs)
208        self._auxiliary_input_tas = (
209            nest.map_structure(_unstack_ta, auxiliary_inputs)
210            if auxiliary_inputs is not None else None)
211        self._seed = seed
212        if (next_input_layer is not None and not isinstance(next_input_layer,
213                                                            layers_base._Layer)):  # pylint: disable=protected-access
214          raise TypeError("next_input_layer must be a Layer, received: %s" %
215                          type(next_input_layer))
216        self._next_input_layer = next_input_layer
217        super(ScheduledOutputTrainingHelper, self).__init__(
218            inputs=maybe_concatenated_inputs,
219            sequence_length=sequence_length,
220            time_major=time_major,
221            name=name)
222    def initialize(self, name=None):
223      return super(ScheduledOutputTrainingHelper, self).initialize(name=name)
224    def sample(self, time, outputs, state, name=None):
225      with ops.name_scope(name, "ScheduledOutputTrainingHelperSample",
226                          [time, outputs, state]):
227        sampler = bernoulli.Bernoulli(probs=self._sampling_probability)
228        return math_ops.cast(
229            sampler.sample(sample_shape=self.batch_size, seed=self._seed),
230            dtypes.bool)
231    def next_inputs(self, time, outputs, state, sample_ids, name=None):
232      with ops.name_scope(name, "ScheduledOutputTrainingHelperNextInputs",
233                          [time, outputs, state, sample_ids]):
234        (finished, base_next_inputs, state) = (
235            super(ScheduledOutputTrainingHelper, self).next_inputs(
236                time=time,
237                outputs=outputs,
238                state=state,
239                sample_ids=sample_ids,
240                name=name))
241        def maybe_sample():
242          def maybe_concatenate_auxiliary_inputs(outputs_, indices=None):
243            if self._auxiliary_input_tas is None:
244              return outputs_
245            next_time = time + 1
246            auxiliary_inputs = nest.map_structure(
247                lambda ta: ta.read(next_time), self._auxiliary_input_tas)
248            if indices is not None:
249              auxiliary_inputs = array_ops.gather_nd(auxiliary_inputs, indices)
250            return nest.map_structure(
251                lambda x, y: array_ops.concat((x, y), -1),
252                outputs_, auxiliary_inputs)
253          if self._next_input_layer is None:
254            return array_ops.where(
255                sample_ids, maybe_concatenate_auxiliary_inputs(outputs),
256                base_next_inputs)
257          where_sampling = math_ops.cast(
258              array_ops.where(sample_ids), dtypes.int32)
259          where_not_sampling = math_ops.cast(
260              array_ops.where(math_ops.logical_not(sample_ids)), dtypes.int32)
261          outputs_sampling = array_ops.gather_nd(outputs, where_sampling)
262          inputs_not_sampling = array_ops.gather_nd(base_next_inputs,
263                                                    where_not_sampling)
264          sampled_next_inputs = maybe_concatenate_auxiliary_inputs(
265              self._next_input_layer(outputs_sampling), where_sampling)
266          base_shape = array_ops.shape(base_next_inputs)
267          return (array_ops.scatter_nd(indices=where_sampling,
268                                       updates=sampled_next_inputs,
269                                       shape=base_shape)
270                  + array_ops.scatter_nd(indices=where_not_sampling,
271                                         updates=inputs_not_sampling,
272                                         shape=base_shape))
273        all_finished = math_ops.reduce_all(finished)
274        next_inputs = control_flow_ops.cond(
275            all_finished, lambda: base_next_inputs, maybe_sample)
276        return (finished, next_inputs, state)
277  class GreedyEmbeddingHelper(Helper):
278    def __init__(self, embedding, start_tokens, end_token):
279      if callable(embedding):
280        self._embedding_fn = embedding
281      else:
282        self._embedding_fn = (
283            lambda ids: embedding_ops.embedding_lookup(embedding, ids))
284      self._start_tokens = ops.convert_to_tensor(
285          start_tokens, dtype=dtypes.int32, name="start_tokens")
286      self._end_token = ops.convert_to_tensor(
287          end_token, dtype=dtypes.int32, name="end_token")
288      if self._start_tokens.get_shape().ndims != 1:
289        raise ValueError("start_tokens must be a vector")
290      self._batch_size = array_ops.size(start_tokens)
291      if self._end_token.get_shape().ndims != 0:
292        raise ValueError("end_token must be a scalar")
293      self._start_inputs = self._embedding_fn(self._start_tokens)
294    @property
295    def batch_size(self):
296      return self._batch_size
297    def initialize(self, name=None):
298      finished = array_ops.tile([False], [self._batch_size])
299      return (finished, self._start_inputs)
300    def sample(self, time, outputs, state, name=None):
301      del time, state  # unused by sample_fn
<span onclick='openModal()' class='match'>302      if not isinstance(outputs, ops.Tensor):
303        raise TypeError("Expected outputs to be a single Tensor, got: %s" %
304                        type(outputs))
305      sample_ids = math_ops.cast(
306          math_ops.argmax(outputs, axis=-1), dtypes.int32)
</span>307      return sample_ids
308    def next_inputs(self, time, outputs, state, sample_ids, name=None):
309      del time, outputs  # unused by next_inputs_fn
310      finished = math_ops.equal(sample_ids, self._end_token)
311      all_finished = math_ops.reduce_all(finished)
312      next_inputs = control_flow_ops.cond(
313          all_finished,
314          lambda: self._start_inputs,
315          lambda: self._embedding_fn(sample_ids))
316      return (finished, next_inputs, state)
</code></pre>
        </div>
        <div class="column">
            <h3>esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-bin_image.py</h3>
            <pre><code>1  import binascii
2  import copy
3  import hashlib
4  import io
5  import os
6  import re
7  import struct
8  from .loader import ESPLoader
9  from .targets import (
10      ESP32C2ROM,
11      ESP32C3ROM,
12      ESP32C6BETAROM,
13      ESP32C6ROM,
14      ESP32H2BETA1ROM,
15      ESP32H2BETA2ROM,
16      ESP32H2ROM,
17      ESP32ROM,
18      ESP32S2ROM,
19      ESP32S3BETA2ROM,
20      ESP32S3ROM,
21      ESP8266ROM,
22  )
23  from .util import FatalError, byte, pad_to
24  def align_file_position(f, size):
25      align = (size - 1) - (f.tell() % size)
26      f.seek(align, 1)
27  def LoadFirmwareImage(chip, image_file):
28      def select_image_class(f, chip):
29          chip = re.sub(r"[-()]", "", chip.lower())
30          if chip != "esp8266":
31              return {
32                  "esp32": ESP32FirmwareImage,
33                  "esp32s2": ESP32S2FirmwareImage,
34                  "esp32s3beta2": ESP32S3BETA2FirmwareImage,
35                  "esp32s3": ESP32S3FirmwareImage,
36                  "esp32c3": ESP32C3FirmwareImage,
37                  "esp32c6beta": ESP32C6BETAFirmwareImage,
38                  "esp32h2beta1": ESP32H2BETA1FirmwareImage,
39                  "esp32h2beta2": ESP32H2BETA2FirmwareImage,
40                  "esp32c2": ESP32C2FirmwareImage,
41                  "esp32c6": ESP32C6FirmwareImage,
42                  "esp32h2": ESP32H2FirmwareImage,
43              }[chip](f)
44          else:  # Otherwise, ESP8266 so look at magic to determine the image type
45              magic = ord(f.read(1))
46              f.seek(0)
47              if magic == ESPLoader.ESP_IMAGE_MAGIC:
48                  return ESP8266ROMFirmwareImage(f)
49              elif magic == ESP8266V2FirmwareImage.IMAGE_V2_MAGIC:
50                  return ESP8266V2FirmwareImage(f)
51              else:
52                  raise FatalError("Invalid image magic number: %d" % magic)
53      if isinstance(image_file, str):
54          with open(image_file, "rb") as f:
55              return select_image_class(f, chip)
56      return select_image_class(image_file, chip)
57  class ImageSegment(object):
58      def __init__(self, addr, data, file_offs=None):
59          self.addr = addr
60          self.data = data
61          self.file_offs = file_offs
62          self.include_in_checksum = True
63          if self.addr != 0:
64              self.pad_to_alignment(
65                  4
66              )  # pad all "real" ImageSegments 4 byte aligned length
67      def copy_with_new_addr(self, new_addr):
68          return ImageSegment(new_addr, self.data, 0)
69      def split_image(self, split_len):
70          result = copy.copy(self)
71          result.data = self.data[:split_len]
72          self.data = self.data[split_len:]
73          self.addr += split_len
74          self.file_offs = None
75          result.file_offs = None
76          return result
77      def __repr__(self):
78          r = "len 0x%05x load 0x%08x" % (len(self.data), self.addr)
79          if self.file_offs is not None:
80              r += " file_offs 0x%08x" % (self.file_offs)
81          return r
82      def get_memory_type(self, image):
83          return [
84              map_range[2]
85              for map_range in image.ROM_LOADER.MEMORY_MAP
86              if map_range[0] <= self.addr < map_range[1]
87          ]
88      def pad_to_alignment(self, alignment):
89          self.data = pad_to(self.data, alignment, b"\x00")
90  class ELFSection(ImageSegment):
91      def __init__(self, name, addr, data):
92          super(ELFSection, self).__init__(addr, data)
93          self.name = name.decode("utf-8")
94      def __repr__(self):
95          return "%s %s" % (self.name, super(ELFSection, self).__repr__())
96  class BaseFirmwareImage(object):
97      SEG_HEADER_LEN = 8
98      SHA256_DIGEST_LEN = 32
99      def __init__(self):
100          self.segments = []
101          self.entrypoint = 0
102          self.elf_sha256 = None
103          self.elf_sha256_offset = 0
104          self.pad_to_size = 0
105      def load_common_header(self, load_file, expected_magic):
106          (
107              magic,
108              segments,
109              self.flash_mode,
110              self.flash_size_freq,
111              self.entrypoint,
112          ) = struct.unpack("<BBBBI", load_file.read(8))
113          if magic != expected_magic:
114              raise FatalError("Invalid firmware image magic=0x%x" % (magic))
115          return segments
116      def verify(self):
117          if len(self.segments) > 16:
118              raise FatalError(
119                  "Invalid segment count %d (max 16). "
120                  "Usually this indicates a linker script problem." % len(self.segments)
121              )
122      def load_segment(self, f, is_irom_segment=False):
123          file_offs = f.tell()
124          (offset, size) = struct.unpack("<II", f.read(8))
125          self.warn_if_unusual_segment(offset, size, is_irom_segment)
126          segment_data = f.read(size)
127          if len(segment_data) < size:
128              raise FatalError(
129                  "End of file reading segment 0x%x, length %d (actual length %d)"
130                  % (offset, size, len(segment_data))
131              )
132          segment = ImageSegment(offset, segment_data, file_offs)
133          self.segments.append(segment)
134          return segment
135      def warn_if_unusual_segment(self, offset, size, is_irom_segment):
136          if not is_irom_segment:
137              if offset > 0x40200000 or offset < 0x3FFE0000 or size > 65536:
138                  print("WARNING: Suspicious segment 0x%x, length %d" % (offset, size))
139      def maybe_patch_segment_data(self, f, segment_data):
140          segment_len = len(segment_data)
141          file_pos = f.tell()  # file_pos is position in the .bin file
142          if (
143              self.elf_sha256_offset >= file_pos
144              and self.elf_sha256_offset < file_pos + segment_len
145          ):
146              patch_offset = self.elf_sha256_offset - file_pos
147              if (
148                  patch_offset < self.SEG_HEADER_LEN
149                  or patch_offset + self.SHA256_DIGEST_LEN > segment_len
150              ):
151                  raise FatalError(
152                      "Cannot place SHA256 digest on segment boundary"
153                      "(elf_sha256_offset=%d, file_pos=%d, segment_size=%d)"
154                      % (self.elf_sha256_offset, file_pos, segment_len)
155                  )
156              patch_offset -= self.SEG_HEADER_LEN
157              if (
158                  segment_data[patch_offset : patch_offset + self.SHA256_DIGEST_LEN]
159                  != b"\x00" * self.SHA256_DIGEST_LEN
160              ):
161                  raise FatalError(
162                      "Contents of segment at SHA256 digest offset 0x%x are not all zero."
163                      " Refusing to overwrite." % self.elf_sha256_offset
164                  )
165              assert len(self.elf_sha256) == self.SHA256_DIGEST_LEN
166              segment_data = (
167                  segment_data[0:patch_offset]
168                  + self.elf_sha256
169                  + segment_data[patch_offset + self.SHA256_DIGEST_LEN :]
170              )
171          return segment_data
172      def save_segment(self, f, segment, checksum=None):
173          segment_data = self.maybe_patch_segment_data(f, segment.data)
174          f.write(struct.pack("<II", segment.addr, len(segment_data)))
175          f.write(segment_data)
176          if checksum is not None:
177              return ESPLoader.checksum(segment_data, checksum)
178      def read_checksum(self, f):
179          align_file_position(f, 16)
180          return ord(f.read(1))
181      def calculate_checksum(self):
182          checksum = ESPLoader.ESP_CHECKSUM_MAGIC
183          for seg in self.segments:
184              if seg.include_in_checksum:
185                  checksum = ESPLoader.checksum(seg.data, checksum)
186          return checksum
187      def append_checksum(self, f, checksum):
188          align_file_position(f, 16)
189          f.write(struct.pack(b"B", checksum))
190      def write_common_header(self, f, segments):
191          f.write(
192              struct.pack(
193                  "<BBBBI",
194                  ESPLoader.ESP_IMAGE_MAGIC,
195                  len(segments),
196                  self.flash_mode,
197                  self.flash_size_freq,
198                  self.entrypoint,
199              )
200          )
201      def is_irom_addr(self, addr):
202          return ESP8266ROM.IROM_MAP_START <= addr < ESP8266ROM.IROM_MAP_END
203      def get_irom_segment(self):
204          irom_segments = [s for s in self.segments if self.is_irom_addr(s.addr)]
205          if len(irom_segments) > 0:
206              if len(irom_segments) != 1:
207                  raise FatalError(
208                      "Found %d segments that could be irom0. Bad ELF file?"
209                      % len(irom_segments)
210                  )
211              return irom_segments[0]
212          return None
213      def get_non_irom_segments(self):
214          irom_segment = self.get_irom_segment()
215          return [s for s in self.segments if s != irom_segment]
216      def merge_adjacent_segments(self):
217          if not self.segments:
218              return  # nothing to merge
219          segments = []
220          for i in range(len(self.segments) - 1, 0, -1):
221              elem = self.segments[i - 1]
222              next_elem = self.segments[i]
223              if all(
224                  (
225                      elem.get_memory_type(self) == next_elem.get_memory_type(self),
226                      elem.include_in_checksum == next_elem.include_in_checksum,
227                      next_elem.addr == elem.addr + len(elem.data),
228                  )
229              ):
230                  elem.data += next_elem.data
231              else:
232                  segments.insert(0, next_elem)
233          segments.insert(0, self.segments[0])
234          self.segments = segments
235      def set_mmu_page_size(self, size):
236          print(
237              "WARNING: Changing MMU page size is not supported on {}! "
238              "Defaulting to 64KB.".format(self.ROM_LOADER.CHIP_NAME)
239          )
240  class ESP8266ROMFirmwareImage(BaseFirmwareImage):
241      ROM_LOADER = ESP8266ROM
242      def __init__(self, load_file=None):
243          super(ESP8266ROMFirmwareImage, self).__init__()
244          self.flash_mode = 0
245          self.flash_size_freq = 0
246          self.version = 1
247          if load_file is not None:
248              segments = self.load_common_header(load_file, ESPLoader.ESP_IMAGE_MAGIC)
249              for _ in range(segments):
250                  self.load_segment(load_file)
251              self.checksum = self.read_checksum(load_file)
252              self.verify()
253      def default_output_name(self, input_file):
254          return input_file + "-"
255      def save(self, basename):
256          irom_segment = self.get_irom_segment()
257          if irom_segment is not None:
258              with open(
259                  "%s0x%05x.bin"
260                  % (basename, irom_segment.addr - ESP8266ROM.IROM_MAP_START),
261                  "wb",
262              ) as f:
263                  f.write(irom_segment.data)
264          normal_segments = self.get_non_irom_segments()
265          with open("%s0x00000.bin" % basename, "wb") as f:
266              self.write_common_header(f, normal_segments)
267              checksum = ESPLoader.ESP_CHECKSUM_MAGIC
268              for segment in normal_segments:
269                  checksum = self.save_segment(f, segment, checksum)
270              self.append_checksum(f, checksum)
271  ESP8266ROM.BOOTLOADER_IMAGE = ESP8266ROMFirmwareImage
272  class ESP8266V2FirmwareImage(BaseFirmwareImage):
273      ROM_LOADER = ESP8266ROM
274      IMAGE_V2_MAGIC = 0xEA
275      IMAGE_V2_SEGMENT = 4
276      def __init__(self, load_file=None):
277          super(ESP8266V2FirmwareImage, self).__init__()
278          self.version = 2
279          if load_file is not None:
280              segments = self.load_common_header(load_file, self.IMAGE_V2_MAGIC)
281              if segments != self.IMAGE_V2_SEGMENT:
282                  print(
283                      'Warning: V2 header has unexpected "segment" count %d (usually 4)'
284                      % segments
285                  )
286              irom_segment = self.load_segment(load_file, True)
287              irom_segment.addr = 0
288              irom_segment.include_in_checksum = False
289              first_flash_mode = self.flash_mode
290              first_flash_size_freq = self.flash_size_freq
291              first_entrypoint = self.entrypoint
292              segments = self.load_common_header(load_file, ESPLoader.ESP_IMAGE_MAGIC)
293              if first_flash_mode != self.flash_mode:
294                  print(
295                      "WARNING: Flash mode value in first header (0x%02x) disagrees "
296                      "with second (0x%02x). Using second value."
297                      % (first_flash_mode, self.flash_mode)
298                  )
299              if first_flash_size_freq != self.flash_size_freq:
300                  print(
301                      "WARNING: Flash size/freq value in first header (0x%02x) disagrees "
302                      "with second (0x%02x). Using second value."
303                      % (first_flash_size_freq, self.flash_size_freq)
304                  )
305              if first_entrypoint != self.entrypoint:
306                  print(
307                      "WARNING: Entrypoint address in first header (0x%08x) disagrees "
308                      "with second header (0x%08x). Using second value."
309                      % (first_entrypoint, self.entrypoint)
310                  )
311              for _ in range(segments):
312                  self.load_segment(load_file)
313              self.checksum = self.read_checksum(load_file)
314              self.verify()
315      def default_output_name(self, input_file):
316          irom_segment = self.get_irom_segment()
317          if irom_segment is not None:
318              irom_offs = irom_segment.addr - ESP8266ROM.IROM_MAP_START
319          else:
320              irom_offs = 0
321          return "%s-0x%05x.bin" % (
322              os.path.splitext(input_file)[0],
323              irom_offs & ~(ESPLoader.FLASH_SECTOR_SIZE - 1),
324          )
325      def save(self, filename):
326          with open(filename, "wb") as f:
327              f.write(
328                  struct.pack(
329                      b"<BBBBI",
330                      self.IMAGE_V2_MAGIC,
331                      self.IMAGE_V2_SEGMENT,
332                      self.flash_mode,
333                      self.flash_size_freq,
334                      self.entrypoint,
335                  )
336              )
337              irom_segment = self.get_irom_segment()
<span onclick='openModal()' class='match'>338              if irom_segment is not None:
339                  irom_segment = irom_segment.copy_with_new_addr(0)
340                  irom_segment.pad_to_alignment(
341                      16
342                  )  # irom_segment must end on a 16 byte boundary
343                  self.save_segment(f, irom_segment)
344              normal_segments = self.get_non_irom_segments()
345              self.write_common_header(f, normal_segments)
346              checksum = ESPLoader.ESP_CHECKSUM_MAGIC
</span>347              for segment in normal_segments:
348                  checksum = self.save_segment(f, segment, checksum)
349              self.append_checksum(f, checksum)
350          with open(filename, "rb") as f:
351              crc = esp8266_crc32(f.read())
352          with open(filename, "ab") as f:
353              f.write(struct.pack(b"<I", crc))
354  def esp8266_crc32(data):
355      crc = binascii.crc32(data, 0) & 0xFFFFFFFF
356      if crc & 0x80000000:
357          return crc ^ 0xFFFFFFFF
358      else:
359          return crc + 1
360  class ESP32FirmwareImage(BaseFirmwareImage):
361      ROM_LOADER = ESP32ROM
362      WP_PIN_DISABLED = 0xEE
363      EXTENDED_HEADER_STRUCT_FMT = "<BBBBHBHH" + ("B" * 4) + "B"
364      IROM_ALIGN = 65536
365      def __init__(self, load_file=None, append_digest=True):
366          super(ESP32FirmwareImage, self).__init__()
367          self.secure_pad = None
368          self.flash_mode = 0
369          self.flash_size_freq = 0
370          self.version = 1
371          self.wp_pin = self.WP_PIN_DISABLED
372          self.clk_drv = 0
373          self.q_drv = 0
374          self.d_drv = 0
375          self.cs_drv = 0
376          self.hd_drv = 0
377          self.wp_drv = 0
378          self.chip_id = 0
379          self.min_rev = 0
380          self.min_rev_full = 0
381          self.max_rev_full = 0
382          self.append_digest = append_digest
383          if load_file is not None:
384              start = load_file.tell()
385              segments = self.load_common_header(load_file, ESPLoader.ESP_IMAGE_MAGIC)
386              self.load_extended_header(load_file)
387              for _ in range(segments):
388                  self.load_segment(load_file)
389              self.checksum = self.read_checksum(load_file)
390              if self.append_digest:
391                  end = load_file.tell()
392                  self.stored_digest = load_file.read(32)
393                  load_file.seek(start)
394                  calc_digest = hashlib.sha256()
395                  calc_digest.update(load_file.read(end - start))
396                  self.calc_digest = calc_digest.digest()  # TODO: decide what to do here?
397              self.verify()
398      def is_flash_addr(self, addr):
399          return (
400              self.ROM_LOADER.IROM_MAP_START <= addr < self.ROM_LOADER.IROM_MAP_END
401          ) or (self.ROM_LOADER.DROM_MAP_START <= addr < self.ROM_LOADER.DROM_MAP_END)
402      def default_output_name(self, input_file):
403          return "%s.bin" % (os.path.splitext(input_file)[0])
404      def warn_if_unusual_segment(self, offset, size, is_irom_segment):
405          pass  # TODO: add warnings for wrong ESP32 segment offset/size combinations
406      def save(self, filename):
407          total_segments = 0
408          with io.BytesIO() as f:  # write file to memory first
409              self.write_common_header(f, self.segments)
410              self.save_extended_header(f)
411              checksum = ESPLoader.ESP_CHECKSUM_MAGIC
412              flash_segments = [
413                  copy.deepcopy(s)
414                  for s in sorted(self.segments, key=lambda s: s.addr)
415                  if self.is_flash_addr(s.addr)
416              ]
417              ram_segments = [
418                  copy.deepcopy(s)
419                  for s in sorted(self.segments, key=lambda s: s.addr)
420                  if not self.is_flash_addr(s.addr)
421              ]
422              for segment in flash_segments:
423                  if segment.name == ".flash.appdesc":
424                      flash_segments.remove(segment)
425                      flash_segments.insert(0, segment)
426                      break
427              for segment in ram_segments:
428                  if segment.name == ".dram0.bootdesc":
429                      ram_segments.remove(segment)
430                      ram_segments.insert(0, segment)
431                      break
432              if len(flash_segments) > 0:
433                  last_addr = flash_segments[0].addr
434                  for segment in flash_segments[1:]:
435                      if segment.addr // self.IROM_ALIGN == last_addr // self.IROM_ALIGN:
436                          raise FatalError(
437                              "Segment loaded at 0x%08x lands in same 64KB flash mapping "
438                              "as segment loaded at 0x%08x. Can't generate binary. "
439                              "Suggest changing linker script or ELF to merge sections."
440                              % (segment.addr, last_addr)
441                          )
442                      last_addr = segment.addr
443              def get_alignment_data_needed(segment):
444                  align_past = (segment.addr % self.IROM_ALIGN) - self.SEG_HEADER_LEN
445                  pad_len = (self.IROM_ALIGN - (f.tell() % self.IROM_ALIGN)) + align_past
446                  if pad_len == 0 or pad_len == self.IROM_ALIGN:
447                      return 0  # already aligned
448                  pad_len -= self.SEG_HEADER_LEN
449                  if pad_len < 0:
450                      pad_len += self.IROM_ALIGN
451                  return pad_len
452              while len(flash_segments) > 0:
453                  segment = flash_segments[0]
454                  pad_len = get_alignment_data_needed(segment)
455                  if pad_len > 0:  # need to pad
456                      if len(ram_segments) > 0 and pad_len > self.SEG_HEADER_LEN:
457                          pad_segment = ram_segments[0].split_image(pad_len)
458                          if len(ram_segments[0].data) == 0:
459                              ram_segments.pop(0)
460                      else:
461                          pad_segment = ImageSegment(0, b"\x00" * pad_len, f.tell())
462                      checksum = self.save_segment(f, pad_segment, checksum)
463                      total_segments += 1
464                  else:
465                      assert (
466                          f.tell() + 8
467                      ) % self.IROM_ALIGN == segment.addr % self.IROM_ALIGN
468                      checksum = self.save_flash_segment(f, segment, checksum)
469                      flash_segments.pop(0)
470                      total_segments += 1
471              for segment in ram_segments:
472                  checksum = self.save_segment(f, segment, checksum)
473                  total_segments += 1
474              if self.secure_pad:
475                  if not self.append_digest:
476                      raise FatalError(
477                          "secure_pad only applies if a SHA-256 digest "
478                          "is also appended to the image"
479                      )
480                  align_past = (f.tell() + self.SEG_HEADER_LEN) % self.IROM_ALIGN
481                  checksum_space = 16
482                  if self.secure_pad == "1":
483                      space_after_checksum = 32 + 4 + 64 + 12
484                  elif self.secure_pad == "2":  # Secure Boot V2
485                      space_after_checksum = 32
486                  pad_len = (
487                      self.IROM_ALIGN - align_past - checksum_space - space_after_checksum
488                  ) % self.IROM_ALIGN
489                  pad_segment = ImageSegment(0, b"\x00" * pad_len, f.tell())
490                  checksum = self.save_segment(f, pad_segment, checksum)
491                  total_segments += 1
492              self.append_checksum(f, checksum)
493              image_length = f.tell()
494              if self.secure_pad:
495                  assert ((image_length + space_after_checksum) % self.IROM_ALIGN) == 0
496              f.seek(1)
497              f.write(bytes([total_segments]))
498              if self.append_digest:
499                  f.seek(0)
500                  digest = hashlib.sha256()
501                  digest.update(f.read(image_length))
502                  f.write(digest.digest())
503              if self.pad_to_size:
504                  image_length = f.tell()
505                  if image_length % self.pad_to_size != 0:
506                      pad_by = self.pad_to_size - (image_length % self.pad_to_size)
507                      f.write(b"\xff" * pad_by)
508              with open(filename, "wb") as real_file:
509                  real_file.write(f.getvalue())
510      def save_flash_segment(self, f, segment, checksum=None):
511          segment_end_pos = f.tell() + len(segment.data) + self.SEG_HEADER_LEN
512          segment_len_remainder = segment_end_pos % self.IROM_ALIGN
513          if segment_len_remainder < 0x24:
514              segment.data += b"\x00" * (0x24 - segment_len_remainder)
515          return self.save_segment(f, segment, checksum)
516      def load_extended_header(self, load_file):
517          def split_byte(n):
518              return (n & 0x0F, (n >> 4) & 0x0F)
519          fields = list(
520              struct.unpack(self.EXTENDED_HEADER_STRUCT_FMT, load_file.read(16))
521          )
522          self.wp_pin = fields[0]
523          self.clk_drv, self.q_drv = split_byte(fields[1])
524          self.d_drv, self.cs_drv = split_byte(fields[2])
525          self.hd_drv, self.wp_drv = split_byte(fields[3])
526          self.chip_id = fields[4]
527          if self.chip_id != self.ROM_LOADER.IMAGE_CHIP_ID:
528              print(
529                  (
530                      "Unexpected chip id in image. Expected %d but value was %d. "
531                      "Is this image for a different chip model?"
532                  )
533                  % (self.ROM_LOADER.IMAGE_CHIP_ID, self.chip_id)
534              )
535          self.min_rev = fields[5]
536          self.min_rev_full = fields[6]
537          self.max_rev_full = fields[7]
538          append_digest = fields[-1]  # last byte is append_digest
539          if append_digest in [0, 1]:
540              self.append_digest = append_digest == 1
541          else:
542              raise RuntimeError(
543                  "Invalid value for append_digest field (0x%02x). Should be 0 or 1.",
544                  append_digest,
545              )
546      def save_extended_header(self, save_file):
547          def join_byte(ln, hn):
548              return (ln & 0x0F) + ((hn & 0x0F) << 4)
549          append_digest = 1 if self.append_digest else 0
550          fields = [
551              self.wp_pin,
552              join_byte(self.clk_drv, self.q_drv),
553              join_byte(self.d_drv, self.cs_drv),
554              join_byte(self.hd_drv, self.wp_drv),
555              self.ROM_LOADER.IMAGE_CHIP_ID,
556              self.min_rev,
557              self.min_rev_full,
558              self.max_rev_full,
559          ]
560          fields += [0] * 4  # padding
561          fields += [append_digest]
562          packed = struct.pack(self.EXTENDED_HEADER_STRUCT_FMT, *fields)
563          save_file.write(packed)
564  class ESP8266V3FirmwareImage(ESP32FirmwareImage):
565      EXTENDED_HEADER_STRUCT_FMT = "B" * 16
566      def is_flash_addr(self, addr):
567          return addr > ESP8266ROM.IROM_MAP_START
568      def save(self, filename):
569          total_segments = 0
570          with io.BytesIO() as f:  # write file to memory first
571              self.write_common_header(f, self.segments)
572              checksum = ESPLoader.ESP_CHECKSUM_MAGIC
573              flash_segments = [
574                  copy.deepcopy(s)
575                  for s in sorted(self.segments, key=lambda s: s.addr)
576                  if self.is_flash_addr(s.addr) and len(s.data)
577              ]
578              ram_segments = [
579                  copy.deepcopy(s)
580                  for s in sorted(self.segments, key=lambda s: s.addr)
581                  if not self.is_flash_addr(s.addr) and len(s.data)
582              ]
583              if len(flash_segments) > 0:
584                  last_addr = flash_segments[0].addr
585                  for segment in flash_segments[1:]:
586                      if segment.addr // self.IROM_ALIGN == last_addr // self.IROM_ALIGN:
587                          raise FatalError(
588                              "Segment loaded at 0x%08x lands in same 64KB flash mapping "
589                              "as segment loaded at 0x%08x. Can't generate binary. "
590                              "Suggest changing linker script or ELF to merge sections."
591                              % (segment.addr, last_addr)
592                          )
593                      last_addr = segment.addr
594              while len(flash_segments) > 0:
595                  segment = flash_segments[0]
596                  if segment.name == ".flash.rodata":
597                      segment.data = segment.data[8:]
598                  checksum = self.save_segment(f, segment, checksum)
599                  flash_segments.pop(0)
600                  total_segments += 1
601              for segment in ram_segments:
602                  checksum = self.save_segment(f, segment, checksum)
603                  total_segments += 1
604              self.append_checksum(f, checksum)
605              image_length = f.tell()
606              f.seek(1)
607              f.write(bytes([total_segments]))
608              if self.append_digest:
609                  f.seek(0)
610                  digest = hashlib.sha256()
611                  digest.update(f.read(image_length))
612                  f.write(digest.digest())
613              with open(filename, "wb") as real_file:
614                  real_file.write(f.getvalue())
615      def load_extended_header(self, load_file):
616          def split_byte(n):
617              return (n & 0x0F, (n >> 4) & 0x0F)
618          fields = list(
619              struct.unpack(self.EXTENDED_HEADER_STRUCT_FMT, load_file.read(16))
620          )
621          self.wp_pin = fields[0]
622          self.clk_drv, self.q_drv = split_byte(fields[1])
623          self.d_drv, self.cs_drv = split_byte(fields[2])
624          self.hd_drv, self.wp_drv = split_byte(fields[3])
625          if fields[15] in [0, 1]:
626              self.append_digest = fields[15] == 1
627          else:
628              raise RuntimeError(
629                  "Invalid value for append_digest field (0x%02x). Should be 0 or 1.",
630                  fields[15],
631              )
632          if any(f for f in fields[4:15] if f != 0):
633              print(
634                  "Warning: some reserved header fields have non-zero values. "
635                  "This image may be from a newer esptool.py?"
636              )
637  ESP32ROM.BOOTLOADER_IMAGE = ESP32FirmwareImage
638  class ESP32S2FirmwareImage(ESP32FirmwareImage):
639      ROM_LOADER = ESP32S2ROM
640  ESP32S2ROM.BOOTLOADER_IMAGE = ESP32S2FirmwareImage
641  class ESP32S3BETA2FirmwareImage(ESP32FirmwareImage):
642      ROM_LOADER = ESP32S3BETA2ROM
643  ESP32S3BETA2ROM.BOOTLOADER_IMAGE = ESP32S3BETA2FirmwareImage
644  class ESP32S3FirmwareImage(ESP32FirmwareImage):
645      ROM_LOADER = ESP32S3ROM
646  ESP32S3ROM.BOOTLOADER_IMAGE = ESP32S3FirmwareImage
647  class ESP32C3FirmwareImage(ESP32FirmwareImage):
648      ROM_LOADER = ESP32C3ROM
649  ESP32C3ROM.BOOTLOADER_IMAGE = ESP32C3FirmwareImage
650  class ESP32C6BETAFirmwareImage(ESP32FirmwareImage):
651      ROM_LOADER = ESP32C6BETAROM
652  ESP32C6BETAROM.BOOTLOADER_IMAGE = ESP32C6BETAFirmwareImage
653  class ESP32H2BETA1FirmwareImage(ESP32FirmwareImage):
654      ROM_LOADER = ESP32H2BETA1ROM
655  ESP32H2BETA1ROM.BOOTLOADER_IMAGE = ESP32H2BETA1FirmwareImage
656  class ESP32H2BETA2FirmwareImage(ESP32FirmwareImage):
657      ROM_LOADER = ESP32H2BETA2ROM
658  ESP32H2BETA2ROM.BOOTLOADER_IMAGE = ESP32H2BETA2FirmwareImage
659  class ESP32C2FirmwareImage(ESP32FirmwareImage):
660      ROM_LOADER = ESP32C2ROM
661      def set_mmu_page_size(self, size):
662          if size not in [16384, 32768, 65536]:
663              raise FatalError(
664                  "{} bytes is not a valid ESP32-C2 page size, "
665                  "select from 64KB, 32KB, 16KB.".format(size)
666              )
667          self.IROM_ALIGN = size
668  ESP32C2ROM.BOOTLOADER_IMAGE = ESP32C2FirmwareImage
669  class ESP32C6FirmwareImage(ESP32FirmwareImage):
670      ROM_LOADER = ESP32C6ROM
671      def set_mmu_page_size(self, size):
672          if size not in [8192, 16384, 32768, 65536]:
673              raise FatalError(
674                  "{} bytes is not a valid ESP32-C6 page size, "
675                  "select from 64KB, 32KB, 16KB, 8KB.".format(size)
676              )
677          self.IROM_ALIGN = size
678  ESP32C6ROM.BOOTLOADER_IMAGE = ESP32C6FirmwareImage
679  class ESP32H2FirmwareImage(ESP32C6FirmwareImage):
680      ROM_LOADER = ESP32H2ROM
681  ESP32H2ROM.BOOTLOADER_IMAGE = ESP32H2FirmwareImage
682  class ELFFile(object):
683      SEC_TYPE_PROGBITS = 0x01
684      SEC_TYPE_STRTAB = 0x03
685      SEC_TYPE_INITARRAY = 0x0E
686      SEC_TYPE_FINIARRAY = 0x0F
687      PROG_SEC_TYPES = (SEC_TYPE_PROGBITS, SEC_TYPE_INITARRAY, SEC_TYPE_FINIARRAY)
688      LEN_SEC_HEADER = 0x28
689      SEG_TYPE_LOAD = 0x01
690      LEN_SEG_HEADER = 0x20
691      def __init__(self, name):
692          self.name = name
693          with open(self.name, "rb") as f:
694              self._read_elf_file(f)
695      def get_section(self, section_name):
696          for s in self.sections:
697              if s.name == section_name:
698                  return s
699          raise ValueError("No section %s in ELF file" % section_name)
700      def _read_elf_file(self, f):
701          LEN_FILE_HEADER = 0x34
702          try:
703              (
704                  ident,
705                  _type,
706                  machine,
707                  _version,
708                  self.entrypoint,
709                  _phoff,
710                  shoff,
711                  _flags,
712                  _ehsize,
713                  _phentsize,
714                  _phnum,
715                  shentsize,
716                  shnum,
717                  shstrndx,
718              ) = struct.unpack("<16sHHLLLLLHHHHHH", f.read(LEN_FILE_HEADER))
719          except struct.error as e:
720              raise FatalError(
721                  "Failed to read a valid ELF header from %s: %s" % (self.name, e)
722              )
723          if byte(ident, 0) != 0x7F or ident[1:4] != b"ELF":
724              raise FatalError("%s has invalid ELF magic header" % self.name)
725          if machine not in [0x5E, 0xF3]:
726              raise FatalError(
727                  "%s does not appear to be an Xtensa or an RISCV ELF file. "
728                  "e_machine=%04x" % (self.name, machine)
729              )
730          if shentsize != self.LEN_SEC_HEADER:
731              raise FatalError(
732                  "%s has unexpected section header entry size 0x%x (not 0x%x)"
733                  % (self.name, shentsize, self.LEN_SEC_HEADER)
734              )
735          if shnum == 0:
736              raise FatalError("%s has 0 section headers" % (self.name))
737          self._read_sections(f, shoff, shnum, shstrndx)
738          self._read_segments(f, _phoff, _phnum, shstrndx)
739      def _read_sections(self, f, section_header_offs, section_header_count, shstrndx):
740          f.seek(section_header_offs)
741          len_bytes = section_header_count * self.LEN_SEC_HEADER
742          section_header = f.read(len_bytes)
743          if len(section_header) == 0:
744              raise FatalError(
745                  "No section header found at offset %04x in ELF file."
746                  % section_header_offs
747              )
748          if len(section_header) != (len_bytes):
749              raise FatalError(
750                  "Only read 0x%x bytes from section header (expected 0x%x.) "
751                  "Truncated ELF file?" % (len(section_header), len_bytes)
752              )
753          section_header_offsets = range(0, len(section_header), self.LEN_SEC_HEADER)
754          def read_section_header(offs):
755              name_offs, sec_type, _flags, lma, sec_offs, size = struct.unpack_from(
756                  "<LLLLLL", section_header[offs:]
757              )
758              return (name_offs, sec_type, lma, size, sec_offs)
759          all_sections = [read_section_header(offs) for offs in section_header_offsets]
760          prog_sections = [s for s in all_sections if s[1] in ELFFile.PROG_SEC_TYPES]
761          if not (shstrndx * self.LEN_SEC_HEADER) in section_header_offsets:
762              raise FatalError("ELF file has no STRTAB section at shstrndx %d" % shstrndx)
763          _, sec_type, _, sec_size, sec_offs = read_section_header(
764              shstrndx * self.LEN_SEC_HEADER
765          )
766          if sec_type != ELFFile.SEC_TYPE_STRTAB:
767              print(
768                  "WARNING: ELF file has incorrect STRTAB section type 0x%02x" % sec_type
769              )
770          f.seek(sec_offs)
771          string_table = f.read(sec_size)
772          def lookup_string(offs):
773              raw = string_table[offs:]
774              return raw[: raw.index(b"\x00")]
775          def read_data(offs, size):
776              f.seek(offs)
777              return f.read(size)
778          prog_sections = [
779              ELFSection(lookup_string(n_offs), lma, read_data(offs, size))
780              for (n_offs, _type, lma, size, offs) in prog_sections
781              if lma != 0 and size > 0
782          ]
783          self.sections = prog_sections
784      def _read_segments(self, f, segment_header_offs, segment_header_count, shstrndx):
785          f.seek(segment_header_offs)
786          len_bytes = segment_header_count * self.LEN_SEG_HEADER
787          segment_header = f.read(len_bytes)
788          if len(segment_header) == 0:
789              raise FatalError(
790                  "No segment header found at offset %04x in ELF file."
791                  % segment_header_offs
792              )
793          if len(segment_header) != (len_bytes):
794              raise FatalError(
795                  "Only read 0x%x bytes from segment header (expected 0x%x.) "
796                  "Truncated ELF file?" % (len(segment_header), len_bytes)
797              )
798          segment_header_offsets = range(0, len(segment_header), self.LEN_SEG_HEADER)
799          def read_segment_header(offs):
800              (
801                  seg_type,
802                  seg_offs,
803                  _vaddr,
804                  lma,
805                  size,
806                  _memsize,
807                  _flags,
808                  _align,
809              ) = struct.unpack_from("<LLLLLLLL", segment_header[offs:])
810              return (seg_type, lma, size, seg_offs)
811          all_segments = [read_segment_header(offs) for offs in segment_header_offsets]
812          prog_segments = [s for s in all_segments if s[0] == ELFFile.SEG_TYPE_LOAD]
813          def read_data(offs, size):
814              f.seek(offs)
815              return f.read(size)
816          prog_segments = [
817              ELFSection(b"PHDR", lma, read_data(offs, size))
818              for (_type, lma, size, offs) in prog_segments
819              if lma != 0 and size > 0
820          ]
821          self.segments = prog_segments
822      def sha256(self):
823          sha256 = hashlib.sha256()
824          with open(self.name, "rb") as f:
825              sha256.update(f.read())
826          return sha256.digest()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-helper.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from esptool-MDEwOlJlcG9zaXRvcnkyMzczNjkxNA==-flat-bin_image.py</div>
                </div>
                <div class="column column_space"><pre><code>302      if not isinstance(outputs, ops.Tensor):
303        raise TypeError("Expected outputs to be a single Tensor, got: %s" %
304                        type(outputs))
305      sample_ids = math_ops.cast(
306          math_ops.argmax(outputs, axis=-1), dtypes.int32)
</pre></code></div>
                <div class="column column_space"><pre><code>338              if irom_segment is not None:
339                  irom_segment = irom_segment.copy_with_new_addr(0)
340                  irom_segment.pad_to_alignment(
341                      16
342                  )  # irom_segment must end on a 16 byte boundary
343                  self.save_segment(f, irom_segment)
344              normal_segments = self.get_non_irom_segments()
345              self.write_common_header(f, normal_segments)
346              checksum = ESPLoader.ESP_CHECKSUM_MAGIC
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    