
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 2.0179372197309418%, Tokens: 9</h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-util_test.py</h3>
            <pre><code>1  from absl.testing import parameterized
2  import numpy as np
3  from sonnet.src import linear
4  from sonnet.src import test_utils
5  from sonnet.src.nets.dnc import util
6  import tensorflow as tf
7  import tree
8  class SegmentDimTest(test_utils.TestCase, parameterized.TestCase):
9    @parameterized.parameters(([2], [7]), ([], [7]), ([2], []), ([2], [7, 11]),
10                              ([2, 11], [7]))
11    def testShape(self, initial_shape, final_shape):
12      first_shape = tf.TensorShape([3, 3])
13      second_shape = tf.TensorShape([5])
14      segment_shapes = [first_shape, second_shape]
15      inputs_shape = (
16          initial_shape +
17          [first_shape.num_elements() + second_shape.num_elements()] +
18          final_shape)
19      inputs = tf.random.uniform(inputs_shape)
20      first, second = util.segment_dim(
21          inputs, dim=len(initial_shape), shapes=segment_shapes)
22      self.assertAllEqual(first.shape.as_list(),
23                          initial_shape + first_shape.as_list() + final_shape)
24      self.assertAllEqual(second.shape.as_list(),
25                          initial_shape + second_shape.as_list() + final_shape)
26    @parameterized.parameters(([2], [7]), ([], [7]), ([2], []), ([2], [7, 11]),
27                              ([2, 11], [7]))
28    def testShapeNegative(self, initial_shape, final_shape):
29      first_shape = tf.TensorShape([3, 3])
30      second_shape = tf.TensorShape([5])
31      segment_shapes = [first_shape, second_shape]
32      inputs_shape = (
33          initial_shape +
34          [first_shape.num_elements() + second_shape.num_elements()] +
35          final_shape)
36      inputs = tf.random.uniform(inputs_shape)
37      first, second = util.segment_dim(
38          inputs, dim=-len(final_shape) - 1, shapes=segment_shapes)
39      self.assertAllEqual(first.shape.as_list(),
40                          initial_shape + first_shape.as_list() + final_shape)
41      self.assertAllEqual(second.shape.as_list(),
42                          initial_shape + second_shape.as_list() + final_shape)
43    def testValues(self):
44      segment_shapes = [tf.TensorShape([2]), tf.TensorShape([3])]
45      inputs = tf.constant(
46          np.hstack([np.zeros((5, 2)), np.ones((5, 3))]), dtype=tf.float32)
47      first, second = util.segment_dim(inputs, dim=1, shapes=segment_shapes)
48      self.assertAllEqual(first.numpy(), np.zeros_like(first))
49      self.assertAllEqual(second.numpy(), np.ones_like(second))
50    def testInvalidDims(self):
51      segment_shapes = [tf.TensorShape([3]), tf.TensorShape([2])]
52      inputs = tf.random.uniform([5, 5])
53      with self.assertRaisesRegex(ValueError, 'Invalid dims'):
54        util.segment_dim(inputs, 3, segment_shapes)
55  class BatchInvertPermutationTest(test_utils.TestCase):
56    def testCorrectOutput(self):
57      batch_size = 5
58      length = 7
59      permutations = np.empty([batch_size, length], dtype=int)
60      for i in range(batch_size):
61        permutations[i] = np.random.permutation(length)
62      inverse = util.batch_invert_permutation(tf.constant(permutations, tf.int32))
63      inverse_np = inverse.numpy()
64      for i in range(batch_size):
65        for j in range(length):
66          self.assertEqual(permutations[i][inverse_np[i][j]], j)
67  class BatchGatherTest(test_utils.TestCase):
68    def testCorrectOutput(self):
<span onclick='openModal()' class='match'>69      values = np.array([[3, 1, 4, 1], [5, 9, 2, 6], [5, 3, 5, 7]])
70      indices = np.array([[1, 2, 0, 3], [3, 0, 1, 2], [0, 2, 1, 3]])
</span>71      target = np.array([[1, 4, 3, 1], [6, 5, 9, 2], [5, 5, 3, 7]])
72      result = util.batch_gather(tf.constant(values), tf.constant(indices))
73      self.assertAllEqual(target, result)
74  class LinearTest(test_utils.TestCase, parameterized.TestCase):
75    def testLinearOutputOneModule(self):
76      batch_size = 4
77      input_size = 5
78      output_size = 3
79      lin_a = linear.Linear(output_size)
80      inputs = tf.random.uniform([batch_size, input_size])
81      output = util.apply_linear(inputs, lin_a, activation=tf.nn.tanh)
82      expected_output = np.tanh(
83          np.matmul(inputs.numpy(), lin_a.w.numpy()) + lin_a.b.numpy())
84      self.assertAllClose(expected_output, output.numpy(), atol=self.get_atol())
85    def testLinearOutputTwoModules(self):
86      batch_size = 4
87      input_size_a = 5
88      input_size_b = 6
89      output_size = 3
90      lin_a = linear.Linear(output_size, name='lin_a')
91      lin_b = linear.Linear(output_size, name='lin_b')
92      input_a = tf.random.uniform([batch_size, input_size_a])
93      input_b = tf.random.uniform([batch_size, input_size_b])
94      output = util.apply_linear((input_a, input_b), (lin_a, lin_b),
95                                 activation=tf.nn.relu)
96      expected_output = np.maximum(
97          0, (np.matmul(input_a.numpy(), lin_a.w.numpy()) + lin_a.b.numpy() +
98              np.matmul(input_b.numpy(), lin_b.w.numpy()) + lin_b.b.numpy()))
99      self.assertAllClose(expected_output, output.numpy(), atol=self.get_atol())
100    def testDifferentOutputSizeBreaks(self):
101      batch_size = 4
102      input_size = 5
103      output_size_a = 6
104      output_size_b = 3
105      lin_a = linear.Linear(output_size_a, name='lin_a')
106      lin_b = linear.Linear(output_size_b, name='lin_b')
107      input_a = tf.random.uniform([batch_size, input_size])
108      input_b = tf.random.uniform([batch_size, input_size])
109      with self.assertRaisesIncompatibleShapesError(
110          tf.errors.InvalidArgumentError):
111        util.apply_linear((input_a, input_b), (lin_a, lin_b))
112    @parameterized.parameters(
113        {
114            'input_sizes': 4,
115            'module_hidden_sizes': (2, 3)
116        },
117        {
118            'input_sizes': (5, 7),
119            'module_hidden_sizes': 10
120        },
121    )
122    def testNonMatchingStructureBreaks(self, input_sizes, module_hidden_sizes):
123      batch_size = 16
124      inputs = tree.map_structure(
125          lambda size: tf.random.uniform([batch_size, size]), input_sizes)
126      modules = tree.map_structure(linear.Linear, module_hidden_sizes)
127      with self.assertRaisesRegex(ValueError,
128                                  'don\'t have the same nested structure'):
129        util.apply_linear(inputs, modules)
130    @parameterized.parameters(
131        {
132            'input_sizes': [10] * 3,
133            'module_hidden_sizes': [3] * 3
134        },
135        {
136            'input_sizes': [1],
137            'module_hidden_sizes': [4]
138        })
139    def testListMustBeLengthTwo(self, input_sizes, module_hidden_sizes):
140      batch_size = 16
141      inputs = tree.map_structure(
142          lambda size: tf.random.uniform([batch_size, size]), input_sizes)
143      modules = tree.map_structure(linear.Linear, module_hidden_sizes)
144      with self.assertRaisesRegex(AssertionError, 'must be length 2'):
145        util.apply_linear(inputs, modules)
146  if __name__ == '__main__':
147    tf.test.main()
</code></pre>
        </div>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-input_pipeline.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import abc
6  import sys
7  import six
8  import tensorflow as tf
9  from tensorflow.contrib.slim.python.slim.data import tfexample_decoder
10  from seq2seq.configurable import Configurable
11  from seq2seq.data import split_tokens_decoder, parallel_data_provider
12  from seq2seq.data.sequence_example_decoder import TFSEquenceExampleDecoder
13  def make_input_pipeline_from_def(def_dict, mode, **kwargs):
14    if not "class" in def_dict:
15      raise ValueError("Input Pipeline definition must have a class property.")
16    class_ = def_dict["class"]
17    if not hasattr(sys.modules[__name__], class_):
18      raise ValueError("Invalid Input Pipeline class: {}".format(class_))
19    pipeline_class = getattr(sys.modules[__name__], class_)
20    params = {}
21    if "params" in def_dict:
22      params.update(def_dict["params"])
23    params.update(kwargs)
24    return pipeline_class(params=params, mode=mode)
25  @six.add_metaclass(abc.ABCMeta)
26  class InputPipeline(Configurable):
27    def __init__(self, params, mode):
28      Configurable.__init__(self, params, mode)
29    @staticmethod
30    def default_params():
31      return {
32          "shuffle": True,
33          "num_epochs": None,
34      }
35    def make_data_provider(self, **kwargs):
36      raise NotImplementedError("Not implemented.")
37    @property
38    def feature_keys(self):
39      return set()
40    @property
41    def label_keys(self):
42      return set()
43    @staticmethod
44    def read_from_data_provider(data_provider):
45      item_values = data_provider.get(list(data_provider.list_items()))
46      items_dict = dict(zip(data_provider.list_items(), item_values))
47      return items_dict
48  class ParallelTextInputPipeline(InputPipeline):
49    @staticmethod
50    def default_params():
51      params = InputPipeline.default_params()
52      params.update({
53          "source_files": [],
54          "target_files": [],
55          "source_delimiter": " ",
56          "target_delimiter": " ",
57      })
58      return params
59    def make_data_provider(self, **kwargs):
60      decoder_source = split_tokens_decoder.SplitTokensDecoder(
61          tokens_feature_name="source_tokens",
62          length_feature_name="source_len",
63          append_token="SEQUENCE_END",
64          delimiter=self.params["source_delimiter"])
65      dataset_source = tf.contrib.slim.dataset.Dataset(
66          data_sources=self.params["source_files"],
67          reader=tf.TextLineReader,
68          decoder=decoder_source,
69          num_samples=None,
70          items_to_descriptions={})
71      dataset_target = None
72      if len(self.params["target_files"]) > 0:
73        decoder_target = split_tokens_decoder.SplitTokensDecoder(
74            tokens_feature_name="target_tokens",
75            length_feature_name="target_len",
76            prepend_token="SEQUENCE_START",
77            append_token="SEQUENCE_END",
78            delimiter=self.params["target_delimiter"])
79        dataset_target = tf.contrib.slim.dataset.Dataset(
80            data_sources=self.params["target_files"],
81            reader=tf.TextLineReader,
82            decoder=decoder_target,
83            num_samples=None,
84            items_to_descriptions={})
85      return parallel_data_provider.ParallelDataProvider(
86          dataset1=dataset_source,
87          dataset2=dataset_target,
88          shuffle=self.params["shuffle"],
89          num_epochs=self.params["num_epochs"],
90          **kwargs)
91    @property
92    def feature_keys(self):
93      return set(["source_tokens", "source_len"])
94    @property
95    def label_keys(self):
96      return set(["target_tokens", "target_len"])
97  class TFRecordInputPipeline(InputPipeline):
98    @staticmethod
99    def default_params():
100      params = InputPipeline.default_params()
101      params.update({
102          "files": [],
103          "source_field": "source",
104          "target_field": "target",
105          "source_delimiter": " ",
106          "target_delimiter": " ",
107      })
108      return params
109    def make_data_provider(self, **kwargs):
110      splitter_source = split_tokens_decoder.SplitTokensDecoder(
111          tokens_feature_name="source_tokens",
112          length_feature_name="source_len",
113          append_token="SEQUENCE_END",
114          delimiter=self.params["source_delimiter"])
115      splitter_target = split_tokens_decoder.SplitTokensDecoder(
116          tokens_feature_name="target_tokens",
117          length_feature_name="target_len",
118          prepend_token="SEQUENCE_START",
119          append_token="SEQUENCE_END",
120          delimiter=self.params["target_delimiter"])
121      keys_to_features = {
122          self.params["source_field"]: tf.FixedLenFeature((), tf.string),
123          self.params["target_field"]: tf.FixedLenFeature(
124              (), tf.string, default_value="")
125      }
126      items_to_handlers = {}
127      items_to_handlers["source_tokens"] = tfexample_decoder.ItemHandlerCallback(
128          keys=[self.params["source_field"]],
129          func=lambda dict: splitter_source.decode(
130              dict[self.params["source_field"]], ["source_tokens"])[0])
131      items_to_handlers["source_len"] = tfexample_decoder.ItemHandlerCallback(
132          keys=[self.params["source_field"]],
133          func=lambda dict: splitter_source.decode(
134              dict[self.params["source_field"]], ["source_len"])[0])
135      items_to_handlers["target_tokens"] = tfexample_decoder.ItemHandlerCallback(
136          keys=[self.params["target_field"]],
137          func=lambda dict: splitter_target.decode(
138              dict[self.params["target_field"]], ["target_tokens"])[0])
139      items_to_handlers["target_len"] = tfexample_decoder.ItemHandlerCallback(
140          keys=[self.params["target_field"]],
<span onclick='openModal()' class='match'>141          func=lambda dict: splitter_target.decode(
142              dict[self.params["target_field"]], ["target_len"])[0])
143      decoder = tfexample_decoder.TFExampleDecoder(keys_to_features,
</span>144                                                   items_to_handlers)
145      dataset = tf.contrib.slim.dataset.Dataset(
146          data_sources=self.params["files"],
147          reader=tf.TFRecordReader,
148          decoder=decoder,
149          num_samples=None,
150          items_to_descriptions={})
151      return tf.contrib.slim.dataset_data_provider.DatasetDataProvider(
152          dataset=dataset,
153          shuffle=self.params["shuffle"],
154          num_epochs=self.params["num_epochs"],
155          **kwargs)
156    @property
157    def feature_keys(self):
158      return set(["source_tokens", "source_len"])
159    @property
160    def label_keys(self):
161      return set(["target_tokens", "target_len"])
162  class ImageCaptioningInputPipeline(InputPipeline):
163    @staticmethod
164    def default_params():
165      params = InputPipeline.default_params()
166      params.update({
167          "files": [],
168          "image_field": "image/data",
169          "image_format": "jpg",
170          "caption_ids_field": "image/caption_ids",
171          "caption_tokens_field": "image/caption",
172      })
173      return params
174    def make_data_provider(self, **kwargs):
175      context_keys_to_features = {
176          self.params["image_field"]: tf.FixedLenFeature(
177              [], dtype=tf.string),
178          "image/format": tf.FixedLenFeature(
179              [], dtype=tf.string, default_value=self.params["image_format"]),
180      }
181      sequence_keys_to_features = {
182          self.params["caption_ids_field"]: tf.FixedLenSequenceFeature(
183              [], dtype=tf.int64),
184          self.params["caption_tokens_field"]: tf.FixedLenSequenceFeature(
185              [], dtype=tf.string)
186      }
187      items_to_handlers = {
188          "image": tfexample_decoder.Image(
189              image_key=self.params["image_field"],
190              format_key="image/format",
191              channels=3),
192          "target_ids":
193          tfexample_decoder.Tensor(self.params["caption_ids_field"]),
194          "target_tokens":
195          tfexample_decoder.Tensor(self.params["caption_tokens_field"]),
196          "target_len": tfexample_decoder.ItemHandlerCallback(
197              keys=[self.params["caption_tokens_field"]],
198              func=lambda x: tf.size(x[self.params["caption_tokens_field"]]))
199      }
200      decoder = TFSEquenceExampleDecoder(
201          context_keys_to_features, sequence_keys_to_features, items_to_handlers)
202      dataset = tf.contrib.slim.dataset.Dataset(
203          data_sources=self.params["files"],
204          reader=tf.TFRecordReader,
205          decoder=decoder,
206          num_samples=None,
207          items_to_descriptions={})
208      return tf.contrib.slim.dataset_data_provider.DatasetDataProvider(
209          dataset=dataset,
210          shuffle=self.params["shuffle"],
211          num_epochs=self.params["num_epochs"],
212          **kwargs)
213    @property
214    def feature_keys(self):
215      return set(["image"])
216    @property
217    def label_keys(self):
218      return set(["target_tokens", "target_ids", "target_len"])
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-util_test.py</div>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-input_pipeline.py</div>
                <div class="column column_space"><pre><code>69      values = np.array([[3, 1, 4, 1], [5, 9, 2, 6], [5, 3, 5, 7]])
70      indices = np.array([[1, 2, 0, 3], [3, 0, 1, 2], [0, 2, 1, 3]])
</pre></code></div>
                <div class="column column_space"><pre><code>141          func=lambda dict: splitter_target.decode(
142              dict[self.params["target_field"]], ["target_len"])[0])
143      decoder = tfexample_decoder.TFExampleDecoder(keys_to_features,
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    