
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Tokens: 12, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-utils.py</h3>
            <pre><code>1  from __future__ import absolute_import
2  from __future__ import division
3  from __future__ import print_function
4  from __future__ import unicode_literals
5  import inspect
6  import os
7  from collections import defaultdict
8  from pydoc import locate
9  import json
10  import tensorflow as tf
11  from tensorflow import gfile
12  from seq2seq.contrib import rnn_cell
13  class TrainOptions(object):
14    def __init__(self, model_class, model_params):
15      self._model_class = model_class
16      self._model_params = model_params
17    @property
18    def model_class(self):
19      return self._model_class
20    @property
21    def model_params(self):
22      return self._model_params
23    @staticmethod
24    def path(model_dir):
25      return os.path.join(model_dir, "train_options.json")
26    def dump(self, model_dir):
27      gfile.MakeDirs(model_dir)
28      options_dict = {
29          "model_class": self.model_class,
30          "model_params": self.model_params,
31      }
32      with gfile.GFile(TrainOptions.path(model_dir), "wb") as file:
33        file.write(json.dumps(options_dict).encode("utf-8"))
34    @staticmethod
35    def load(model_dir):
36      with gfile.GFile(TrainOptions.path(model_dir), "rb") as file:
37        options_dict = json.loads(file.read().decode("utf-8"))
38      options_dict = defaultdict(None, options_dict)
39      return TrainOptions(
40          model_class=options_dict["model_class"],
41          model_params=options_dict["model_params"])
42  def cell_from_spec(cell_classname, cell_params):
43    cell_params = cell_params.copy()
44    cell_class = locate(cell_classname) or getattr(rnn_cell, cell_classname)
45    cell_args = set(inspect.getargspec(cell_class.__init__).args[1:])
46    for key in cell_params.keys():
47      if key not in cell_args:
48        raise ValueError(
49            .format(key, cell_class.__name__, cell_args))
50    return cell_class(**cell_params)
51  def get_rnn_cell(cell_class,
52                   cell_params,
53                   num_layers=1,
<span onclick='openModal()' class='match'>54                   dropout_input_keep_prob=1.0,
55                   dropout_output_keep_prob=1.0,
56                   residual_connections=False,
57                   residual_combiner="add",
</span>58                   residual_dense=False):
59    cells = []
60    for _ in range(num_layers):
61      cell = cell_from_spec(cell_class, cell_params)
62      if dropout_input_keep_prob < 1.0 or dropout_output_keep_prob < 1.0:
63        cell = tf.contrib.rnn.DropoutWrapper(
64            cell=cell,
65            input_keep_prob=dropout_input_keep_prob,
66            output_keep_prob=dropout_output_keep_prob)
67      cells.append(cell)
68    if len(cells) > 1:
69      final_cell = rnn_cell.ExtendedMultiRNNCell(
70          cells=cells,
71          residual_connections=residual_connections,
72          residual_combiner=residual_combiner,
73          residual_dense=residual_dense)
74    else:
75      final_cell = cells[0]
76    return final_cell
77  def create_learning_rate_decay_fn(decay_type,
78                                    decay_steps,
79                                    decay_rate,
80                                    start_decay_at=0,
81                                    stop_decay_at=1e9,
82                                    min_learning_rate=None,
83                                    staircase=False):
84    if decay_type is None or decay_type == "":
85      return None
86    start_decay_at = tf.to_int32(start_decay_at)
87    stop_decay_at = tf.to_int32(stop_decay_at)
88    def decay_fn(learning_rate, global_step):
89      global_step = tf.to_int32(global_step)
90      decay_type_fn = getattr(tf.train, decay_type)
91      decayed_learning_rate = decay_type_fn(
92          learning_rate=learning_rate,
93          global_step=tf.minimum(global_step, stop_decay_at) - start_decay_at,
94          decay_steps=decay_steps,
95          decay_rate=decay_rate,
96          staircase=staircase,
97          name="decayed_learning_rate")
98      final_lr = tf.train.piecewise_constant(
99          x=global_step,
100          boundaries=[start_decay_at],
101          values=[learning_rate, decayed_learning_rate])
102      if min_learning_rate:
103        final_lr = tf.maximum(final_lr, min_learning_rate)
104      return final_lr
105    return decay_fn
106  def create_input_fn(pipeline,
107                      batch_size,
108                      bucket_boundaries=None,
109                      allow_smaller_final_batch=False,
110                      scope=None):
111    def input_fn():
112      with tf.variable_scope(scope or "input_fn"):
113        data_provider = pipeline.make_data_provider()
114        features_and_labels = pipeline.read_from_data_provider(data_provider)
115        if bucket_boundaries:
116          _, batch = tf.contrib.training.bucket_by_sequence_length(
117              input_length=features_and_labels["source_len"],
118              bucket_boundaries=bucket_boundaries,
119              tensors=features_and_labels,
120              batch_size=batch_size,
121              keep_input=features_and_labels["source_len"] >= 1,
122              dynamic_pad=True,
123              capacity=5000 + 16 * batch_size,
124              allow_smaller_final_batch=allow_smaller_final_batch,
125              name="bucket_queue")
126        else:
127          batch = tf.train.batch(
128              tensors=features_and_labels,
129              enqueue_many=False,
130              batch_size=batch_size,
131              dynamic_pad=True,
132              capacity=5000 + 16 * batch_size,
133              allow_smaller_final_batch=allow_smaller_final_batch,
134              name="batch_queue")
135        features_batch = {k: batch[k] for k in pipeline.feature_keys}
136        if set(batch.keys()).intersection(pipeline.label_keys):
137          labels_batch = {k: batch[k] for k in pipeline.label_keys}
138        else:
139          labels_batch = None
140        return features_batch, labels_batch
141    return input_fn
</code></pre>
        </div>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-resnet_7.py</h3>
            <pre><code>1  from typing import Mapping, Optional, Sequence, Union
2  from sonnet.src import base
3  from sonnet.src import batch_norm
4  from sonnet.src import conv
5  from sonnet.src import initializers
6  from sonnet.src import linear
7  from sonnet.src import pad
8  import tensorflow as tf
9  class BottleNeckBlockV1(base.Module):
10    def __init__(self,
11                 channels: int,
12                 stride: Union[int, Sequence[int]],
13                 use_projection: bool,
14                 bn_config: Mapping[str, float],
15                 name: Optional[str] = None):
16      super().__init__(name=name)
17      self._channels = channels
18      self._stride = stride
19      self._use_projection = use_projection
20      self._bn_config = bn_config
21      batchnorm_args = {"create_scale": True, "create_offset": True}
22      batchnorm_args.update(bn_config)
23      if self._use_projection:
24        self._proj_conv = conv.Conv2D(
25            output_channels=channels,
26            kernel_shape=1,
27            stride=stride,
28            with_bias=False,
29            padding=pad.same,
30            name="shortcut_conv")
31        self._proj_batchnorm = batch_norm.BatchNorm(
32            name="shortcut_batchnorm", **batchnorm_args)
33      self._layers = []
34      conv_0 = conv.Conv2D(
35          output_channels=channels // 4,
36          kernel_shape=1,
37          stride=1,
38          with_bias=False,
39          padding=pad.same,
40          name="conv_0")
41      self._layers.append(
42          [conv_0,
43           batch_norm.BatchNorm(name="batchnorm_0", **batchnorm_args)])
44      conv_1 = conv.Conv2D(
45          output_channels=channels // 4,
46          kernel_shape=3,
47          stride=stride,
48          with_bias=False,
49          padding=pad.same,
50          name="conv_1")
51      self._layers.append(
52          [conv_1,
53           batch_norm.BatchNorm(name="batchnorm_1", **batchnorm_args)])
54      conv_2 = conv.Conv2D(
55          output_channels=channels,
56          kernel_shape=1,
57          stride=1,
58          with_bias=False,
59          padding=pad.same,
60          name="conv_2")
61      batchnorm_2 = batch_norm.BatchNorm(
62          name="batchnorm_2", scale_init=initializers.Zeros(), **batchnorm_args)
63      self._layers.append([conv_2, batchnorm_2])
64    def __call__(self, inputs, is_training):
65      if self._use_projection:
66        shortcut = self._proj_conv(inputs)
67        shortcut = self._proj_batchnorm(shortcut, is_training=is_training)
68      else:
69        shortcut = inputs
70      net = inputs
71      for i, [conv_layer, batchnorm_layer] in enumerate(self._layers):
72        net = conv_layer(net)
73        net = batchnorm_layer(net, is_training=is_training)
74        net = tf.nn.relu(net) if i < 2 else net  # Don't apply relu on last layer
75      return tf.nn.relu(net + shortcut)
76  class BottleNeckBlockV2(base.Module):
77    def __init__(self,
78                 channels: int,
79                 stride: Union[int, Sequence[int]],
80                 use_projection: bool,
81                 bn_config: Mapping[str, float],
82                 name: Optional[str] = None):
83      super().__init__(name=name)
84      self._channels = channels
85      self._stride = stride
86      self._use_projection = use_projection
87      self._bn_config = bn_config
88      batchnorm_args = {"create_scale": True, "create_offset": True}
89      batchnorm_args.update(bn_config)
90      if self._use_projection:
91        self._proj_conv = conv.Conv2D(
92            output_channels=channels,
93            kernel_shape=1,
94            stride=stride,
95            with_bias=False,
96            padding=pad.same,
97            name="shortcut_conv")
98      self._conv_0 = conv.Conv2D(
99          output_channels=channels // 4,
<span onclick='openModal()' class='match'>100          kernel_shape=1,
101          stride=1,
102          with_bias=False,
103          padding=pad.same,
</span>104          name="conv_0")
105      self._bn_0 = batch_norm.BatchNorm(name="batchnorm_0", **batchnorm_args)
106      self._conv_1 = conv.Conv2D(
107          output_channels=channels // 4,
108          kernel_shape=3,
109          stride=stride,
110          with_bias=False,
111          padding=pad.same,
112          name="conv_1")
113      self._bn_1 = batch_norm.BatchNorm(name="batchnorm_1", **batchnorm_args)
114      self._conv_2 = conv.Conv2D(
115          output_channels=channels,
116          kernel_shape=1,
117          stride=1,
118          with_bias=False,
119          padding=pad.same,
120          name="conv_2")
121      self._bn_2 = batch_norm.BatchNorm(name="batchnorm_2", **batchnorm_args)
122    def __call__(self, inputs, is_training):
123      net = inputs
124      shortcut = inputs
125      for i, (conv_i, bn_i) in enumerate(((self._conv_0, self._bn_0),
126                                          (self._conv_1, self._bn_1),
127                                          (self._conv_2, self._bn_2))):
128        net = bn_i(net, is_training=is_training)
129        net = tf.nn.relu(net)
130        if i == 0 and self._use_projection:
131          shortcut = self._proj_conv(net)
132        net = conv_i(net)
133      return net + shortcut
134  class BlockGroup(base.Module):
135    def __init__(self,
136                 channels: int,
137                 num_blocks: int,
138                 stride: Union[int, Sequence[int]],
139                 bn_config: Mapping[str, float],
140                 resnet_v2: bool = False,
141                 name: Optional[str] = None):
142      super().__init__(name=name)
143      self._channels = channels
144      self._num_blocks = num_blocks
145      self._stride = stride
146      self._bn_config = bn_config
147      if resnet_v2:
148        bottle_neck_block = BottleNeckBlockV2
149      else:
150        bottle_neck_block = BottleNeckBlockV1
151      self._blocks = []
152      for id_block in range(num_blocks):
153        self._blocks.append(
154            bottle_neck_block(
155                channels=channels,
156                stride=stride if id_block == 0 else 1,
157                use_projection=(id_block == 0),
158                bn_config=bn_config,
159                name="block_%d" % (id_block)))
160    def __call__(self, inputs, is_training):
161      net = inputs
162      for block in self._blocks:
163        net = block(net, is_training=is_training)
164      return net
165  class ResNet(base.Module):
166    def __init__(self,
167                 blocks_per_group_list: Sequence[int],
168                 num_classes: int,
169                 bn_config: Optional[Mapping[str, float]] = None,
170                 resnet_v2: bool = False,
171                 channels_per_group_list: Sequence[int] = (256, 512, 1024, 2048),
172                 name: Optional[str] = None):
173      super().__init__(name=name)
174      if bn_config is None:
175        bn_config = {"decay_rate": 0.9, "eps": 1e-5}
176      self._bn_config = bn_config
177      self._resnet_v2 = resnet_v2
178      if len(blocks_per_group_list) != 4:
179        raise ValueError(
180            "`blocks_per_group_list` must be of length 4 not {}".format(
181                len(blocks_per_group_list)))
182      self._blocks_per_group_list = blocks_per_group_list
183      if len(channels_per_group_list) != 4:
184        raise ValueError(
185            "`channels_per_group_list` must be of length 4 not {}".format(
186                len(channels_per_group_list)))
187      self._channels_per_group_list = channels_per_group_list
188      self._initial_conv = conv.Conv2D(
189          output_channels=64,
190          kernel_shape=7,
191          stride=2,
192          with_bias=False,
193          padding=pad.same,
194          name="initial_conv")
195      if not self._resnet_v2:
196        self._initial_batchnorm = batch_norm.BatchNorm(
197            create_scale=True,
198            create_offset=True,
199            name="initial_batchnorm",
200            **bn_config)
201      self._block_groups = []
202      strides = [1, 2, 2, 2]
203      for i in range(4):
204        self._block_groups.append(
205            BlockGroup(
206                channels=self._channels_per_group_list[i],
207                num_blocks=self._blocks_per_group_list[i],
208                stride=strides[i],
209                bn_config=bn_config,
210                resnet_v2=resnet_v2,
211                name="block_group_%d" % (i)))
212      if self._resnet_v2:
213        self._final_batchnorm = batch_norm.BatchNorm(
214            create_scale=True,
215            create_offset=True,
216            name="final_batchnorm",
217            **bn_config)
218      self._logits = linear.Linear(
219          output_size=num_classes, w_init=initializers.Zeros(), name="logits")
220    def __call__(self, inputs, is_training):
221      net = inputs
222      net = self._initial_conv(net)
223      if not self._resnet_v2:
224        net = self._initial_batchnorm(net, is_training=is_training)
225        net = tf.nn.relu(net)
226      net = tf.nn.max_pool2d(
227          net, ksize=3, strides=2, padding="SAME", name="initial_max_pool")
228      for block_group in self._block_groups:
229        net = block_group(net, is_training)
230      if self._resnet_v2:
231        net = self._final_batchnorm(net, is_training=is_training)
232        net = tf.nn.relu(net)
233      net = tf.reduce_mean(net, axis=[1, 2], name="final_avg_pool")
234      return self._logits(net)
235  class ResNet50(ResNet):
236    def __init__(self,
237                 num_classes: int,
238                 bn_config: Optional[Mapping[str, float]] = None,
239                 resnet_v2: bool = False,
240                 name: Optional[str] = None):
241      super().__init__([3, 4, 6, 3],
242                       num_classes=num_classes,
243                       bn_config=bn_config,
244                       resnet_v2=resnet_v2,
245                       name=name)
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-utils.py</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-resnet_7.py</div>
                </div>
                <div class="column column_space"><pre><code>54                   dropout_input_keep_prob=1.0,
55                   dropout_output_keep_prob=1.0,
56                   residual_connections=False,
57                   residual_combiner="add",
</pre></code></div>
                <div class="column column_space"><pre><code>100          kernel_shape=1,
101          stride=1,
102          with_bias=False,
103          padding=pad.same,
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    