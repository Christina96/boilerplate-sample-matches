
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 6.3439065108514185%, Tokens: 9</h2>
        <div class="column">
            <h3>sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-group_norm.py</h3>
            <pre><code>1  import collections.abc
2  from typing import Optional
3  from sonnet.src import base
4  from sonnet.src import initializers
5  from sonnet.src import once
6  from sonnet.src import types
7  from sonnet.src import utils
8  import tensorflow as tf
9  class GroupNorm(base.Module):
10    r
11    def __init__(self,
12                 groups: int,
13                 axis: types.Axis = slice(1, None),
14                 create_scale: bool = True,
15                 create_offset: bool = True,
16                 eps: types.FloatLike = 1e-5,
17                 scale_init: Optional[initializers.Initializer] = None,
18                 offset_init: Optional[initializers.Initializer] = None,
19                 data_format: str = "channels_last",
20                 name: Optional[str] = None):
21      super().__init__(name=name)
22      if isinstance(axis, slice):
23        self._axis = axis
24      elif isinstance(axis, int):
25        self._axis = [axis]
26      elif (isinstance(axis, collections.abc.Iterable) and
27            all(isinstance(ax, int) for ax in axis)):
28        self._axis = axis
29      else:
30        raise ValueError("`axis` should be an int, slice or iterable of ints.")
<span onclick='openModal()' class='match'>31      self._groups = groups
32      self._eps = eps
33      self._data_format = data_format
34      self._channel_index = utils.get_channel_index(data_format)
</span>35      self._create_scale = create_scale
36      self._create_offset = create_offset
37      if self._create_scale:
38        self._scale_init = (
39            scale_init if scale_init is not None else initializers.Ones())
40      elif scale_init is not None:
41        raise ValueError("Cannot set `scale_init` if `create_scale=False`.")
42      if self._create_offset:
43        self._offset_init = (
44            offset_init if offset_init is not None else initializers.Zeros())
45      elif offset_init is not None:
46        raise ValueError("Cannot set `offset_init` if `create_offset=False`.")
47    def __call__(self,
48                 inputs: tf.Tensor,
49                 scale: Optional[tf.Tensor] = None,
50                 offset: Optional[tf.Tensor] = None):
51      self._initialize(inputs)
52      if self._create_scale:
53        if scale is not None:
54          raise ValueError(
55              "Cannot pass `scale` at call time if `create_scale=True`.")
56        scale = self.scale
57      if self._create_offset:
58        if offset is not None:
59          raise ValueError(
60              "Cannot pass `offset` at call time if `create_offset=True`.")
61        offset = self.offset
62      if len(inputs.shape) != self._rank:
63        raise ValueError(
64            "The rank of the inputs cannot change between calls, the"
65            " original call was rank={} but this call was rank={}.".format(
66                self._rank, len(inputs.shape)))
67      inputs = tf.reshape(inputs, self._inputs_reshape)
68      mean, var = tf.nn.moments(inputs, self._axis, keepdims=True)
69      normalized = tf.nn.batch_normalization(
70          inputs,
71          mean=mean,
72          variance=var,
73          scale=None,
74          offset=None,
75          variance_epsilon=self._eps)
76      outputs = tf.reshape(normalized, self._outputs_reshape)
77      outputs = outputs * scale if scale is not None else outputs
78      outputs = outputs + offset if offset is not None else outputs
79      return outputs
80    @once.once
81    def _initialize(self, inputs: tf.Tensor):
82      self._rank = len(inputs.shape)
83      if isinstance(self._axis, slice):
84        axes = tuple(range(self._rank))
85        self._axis = axes[self._axis]
86      dtype = inputs.dtype
87      if self._channel_index == -1:
88        params_shape = [inputs.shape[-1]]
89      else:  # self._channel_index == 1
90        params_shape = [inputs.shape[1]] + [1] * (self._rank - 2)
91      if self._create_scale:
92        self.scale = tf.Variable(
93            self._scale_init(params_shape, dtype), name="scale")
94      else:
95        self.scale = None
96      if self._create_offset:
97        self.offset = tf.Variable(
98            self._offset_init(params_shape, dtype), name="offset")
99      else:
100        self.offset = None
101      num_channels = inputs.shape[self._channel_index]
102      if num_channels % self._groups != 0:
103        raise ValueError(
104            "The number of channels must be divisible by the number of groups, "
105            "was channels = {}, groups = {}".format(num_channels, self._groups))
106      if self._channel_index == -1:
107        self._inputs_reshape = [-1] + list(
108            inputs.shape[1:-1]) + [self._groups, num_channels // self._groups]
109        self._axis = [a if a != self._rank - 1 else a + 1 for a in self._axis]
110      else:
111        self._inputs_reshape = [-1] + [
112            self._groups, num_channels // self._groups
113        ] + list(inputs.shape[2:])
114        self._axis = [a if a == 0 else a + 1 for a in self._axis]
115      self._outputs_reshape = [-1] + list(inputs.shape[1:])
</code></pre>
        </div>
        <div class="column">
            <h3>seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-train.py</h3>
            <pre><code>1  #! /usr/bin/env python
2  from __future__ import absolute_import
3  from __future__ import division
4  from __future__ import print_function
5  from __future__ import unicode_literals
6  import os
7  import tempfile
8  import yaml
9  import tensorflow as tf
10  from tensorflow.contrib.learn.python.learn import learn_runner
11  from tensorflow.contrib.learn.python.learn.estimators import run_config
12  from tensorflow import gfile
13  from seq2seq import models
14  from seq2seq.contrib.experiment import Experiment as PatchedExperiment
15  from seq2seq.configurable import _maybe_load_yaml, _create_from_dict
16  from seq2seq.configurable import _deep_merge_dict
17  from seq2seq.data import input_pipeline
18  from seq2seq.metrics import metric_specs
19  from seq2seq.training import hooks
20  from seq2seq.training import utils as training_utils
21  tf.flags.DEFINE_string("config_paths", "",
22                         )
23  tf.flags.DEFINE_string("hooks", "[]",
24                         )
25  tf.flags.DEFINE_string("metrics", "[]",
26                         )
27  tf.flags.DEFINE_string("model", "",
28                         )
29  tf.flags.DEFINE_string("model_params", "{}",
30                         )
31  tf.flags.DEFINE_string("input_pipeline_train", "{}",
32                         )
33  tf.flags.DEFINE_string("input_pipeline_dev", "{}",
34                         )
35  tf.flags.DEFINE_string("buckets", None,
36                         )
37  tf.flags.DEFINE_integer("batch_size", 16,
38                          )
39  tf.flags.DEFINE_string("output_dir", None,
40                         )
41  tf.flags.DEFINE_string("schedule", "continuous_train_and_eval",
42                         )
43  tf.flags.DEFINE_integer("train_steps", None,
44                          )
45  tf.flags.DEFINE_integer("eval_every_n_steps", 1000,
46                          "Run evaluation on validation data every N steps.")
47  tf.flags.DEFINE_integer("tf_random_seed", None,
48                          )
49  tf.flags.DEFINE_integer("save_checkpoints_secs", None,
50                          )
51  tf.flags.DEFINE_integer("save_checkpoints_steps", None,
52                          )
53  tf.flags.DEFINE_integer("keep_checkpoint_max", 5,
54                          )
55  tf.flags.DEFINE_integer("keep_checkpoint_every_n_hours", 4,
56                          )
57  tf.flags.DEFINE_float("gpu_memory_fraction", 1.0,
58                        )
59  tf.flags.DEFINE_boolean("gpu_allow_growth", False,
60                          )
61  tf.flags.DEFINE_boolean("log_device_placement", False,
62                          )
63  FLAGS = tf.flags.FLAGS
64  def create_experiment(output_dir):
65    config = run_config.RunConfig(
<span onclick='openModal()' class='match'>66        tf_random_seed=FLAGS.tf_random_seed,
67        save_checkpoints_secs=FLAGS.save_checkpoints_secs,
68        save_checkpoints_steps=FLAGS.save_checkpoints_steps,
69        keep_checkpoint_max=FLAGS.keep_checkpoint_max,
70        keep_checkpoint_every_n_hours=FLAGS.keep_checkpoint_every_n_hours,
</span>71        gpu_memory_fraction=FLAGS.gpu_memory_fraction)
72    config.tf_config.gpu_options.allow_growth = FLAGS.gpu_allow_growth
73    config.tf_config.log_device_placement = FLAGS.log_device_placement
74    train_options = training_utils.TrainOptions(
75        model_class=FLAGS.model,
76        model_params=FLAGS.model_params)
77    if config.is_chief:
78      gfile.MakeDirs(output_dir)
79      train_options.dump(output_dir)
80    bucket_boundaries = None
81    if FLAGS.buckets:
82      bucket_boundaries = list(map(int, FLAGS.buckets.split(",")))
83    train_input_pipeline = input_pipeline.make_input_pipeline_from_def(
84        def_dict=FLAGS.input_pipeline_train,
85        mode=tf.contrib.learn.ModeKeys.TRAIN)
86    train_input_fn = training_utils.create_input_fn(
87        pipeline=train_input_pipeline,
88        batch_size=FLAGS.batch_size,
89        bucket_boundaries=bucket_boundaries,
90        scope="train_input_fn")
91    dev_input_pipeline = input_pipeline.make_input_pipeline_from_def(
92        def_dict=FLAGS.input_pipeline_dev,
93        mode=tf.contrib.learn.ModeKeys.EVAL,
94        shuffle=False, num_epochs=1)
95    eval_input_fn = training_utils.create_input_fn(
96        pipeline=dev_input_pipeline,
97        batch_size=FLAGS.batch_size,
98        allow_smaller_final_batch=True,
99        scope="dev_input_fn")
100    def model_fn(features, labels, params, mode):
101      model = _create_from_dict({
102          "class": train_options.model_class,
103          "params": train_options.model_params
104      }, models, mode=mode)
105      return model(features, labels, params)
106    estimator = tf.contrib.learn.Estimator(
107        model_fn=model_fn,
108        model_dir=output_dir,
109        config=config,
110        params=FLAGS.model_params)
111    train_hooks = []
112    for dict_ in FLAGS.hooks:
113      hook = _create_from_dict(
114          dict_, hooks,
115          model_dir=estimator.model_dir,
116          run_config=config)
117      train_hooks.append(hook)
118    eval_metrics = {}
119    for dict_ in FLAGS.metrics:
120      metric = _create_from_dict(dict_, metric_specs)
121      eval_metrics[metric.name] = metric
122    experiment = PatchedExperiment(
123        estimator=estimator,
124        train_input_fn=train_input_fn,
125        eval_input_fn=eval_input_fn,
126        min_eval_frequency=FLAGS.eval_every_n_steps,
127        train_steps=FLAGS.train_steps,
128        eval_steps=None,
129        eval_metrics=eval_metrics,
130        train_monitors=train_hooks)
131    return experiment
132  def main(_argv):
133    FLAGS.hooks = _maybe_load_yaml(FLAGS.hooks)
134    FLAGS.metrics = _maybe_load_yaml(FLAGS.metrics)
135    FLAGS.model_params = _maybe_load_yaml(FLAGS.model_params)
136    FLAGS.input_pipeline_train = _maybe_load_yaml(FLAGS.input_pipeline_train)
137    FLAGS.input_pipeline_dev = _maybe_load_yaml(FLAGS.input_pipeline_dev)
138    final_config = {}
139    if FLAGS.config_paths:
140      for config_path in FLAGS.config_paths.split(","):
141        config_path = config_path.strip()
142        if not config_path:
143          continue
144        config_path = os.path.abspath(config_path)
145        tf.logging.info("Loading config from %s", config_path)
146        with gfile.GFile(config_path.strip()) as config_file:
147          config_flags = yaml.load(config_file)
148          final_config = _deep_merge_dict(final_config, config_flags)
149    tf.logging.info("Final Config:\n%s", yaml.dump(final_config))
150    for flag_key, flag_value in final_config.items():
151      if hasattr(FLAGS, flag_key) and isinstance(getattr(FLAGS, flag_key), dict):
152        merged_value = _deep_merge_dict(flag_value, getattr(FLAGS, flag_key))
153        setattr(FLAGS, flag_key, merged_value)
154      elif hasattr(FLAGS, flag_key):
155        setattr(FLAGS, flag_key, flag_value)
156      else:
157        tf.logging.warning("Ignoring config flag: %s", flag_key)
158    if FLAGS.save_checkpoints_secs is None \
159      and FLAGS.save_checkpoints_steps is None:
160      FLAGS.save_checkpoints_secs = 600
161      tf.logging.info("Setting save_checkpoints_secs to %d",
162                      FLAGS.save_checkpoints_secs)
163    if not FLAGS.output_dir:
164      FLAGS.output_dir = tempfile.mkdtemp()
165    if not FLAGS.input_pipeline_train:
166      raise ValueError("You must specify input_pipeline_train")
167    if not FLAGS.input_pipeline_dev:
168      raise ValueError("You must specify input_pipeline_dev")
169    learn_runner.run(
170        experiment_fn=create_experiment,
171        output_dir=FLAGS.output_dir,
172        schedule=FLAGS.schedule)
173  if __name__ == "__main__":
174    tf.logging.set_verbosity(tf.logging.INFO)
175    tf.app.run()
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from sonnet-MDEwOlJlcG9zaXRvcnk4NzA2NzIxMg==-flat-group_norm.py</div>
                <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from seq2seq-MDEwOlJlcG9zaXRvcnk4MzczMjgwNg==-flat-train.py</div>
                <div class="column column_space"><pre><code>31      self._groups = groups
32      self._eps = eps
33      self._data_format = data_format
34      self._channel_index = utils.get_channel_index(data_format)
</pre></code></div>
                <div class="column column_space"><pre><code>66        tf_random_seed=FLAGS.tf_random_seed,
67        save_checkpoints_secs=FLAGS.save_checkpoints_secs,
68        save_checkpoints_steps=FLAGS.save_checkpoints_steps,
69        keep_checkpoint_max=FLAGS.keep_checkpoint_max,
70        keep_checkpoint_every_n_hours=FLAGS.keep_checkpoint_every_n_hours,
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    