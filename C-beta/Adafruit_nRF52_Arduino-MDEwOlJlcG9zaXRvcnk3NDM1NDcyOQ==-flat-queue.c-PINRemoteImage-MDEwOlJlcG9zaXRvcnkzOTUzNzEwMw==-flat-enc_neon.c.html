
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Code Files</title>
            <style>
                .column {
                    width: 47%;
                    float: left;
                    padding: 12px;
                    border: 2px solid #ffd0d0;
                }
        
                .modal {
                    display: none;
                    position: fixed;
                    z-index: 1;
                    left: 0;
                    top: 0;
                    width: 100%;
                    height: 100%;
                    overflow: auto;
                    background-color: rgb(0, 0, 0);
                    background-color: rgba(0, 0, 0, 0.4);
                }
    
                .modal-content {
                    height: 250%;
                    background-color: #fefefe;
                    margin: 5% auto;
                    padding: 20px;
                    border: 1px solid #888;
                    width: 80%;
                }
    
                .close {
                    color: #aaa;
                    float: right;
                    font-size: 20px;
                    font-weight: bold;
                    text-align: right;
                }
    
                .close:hover, .close:focus {
                    color: black;
                    text-decoration: none;
                    cursor: pointer;
                }
    
                .row {
                    float: right;
                    width: 100%;
                }
    
                .column_space  {
                    white - space: pre-wrap;
                }
                 
                pre {
                    width: 100%;
                    overflow-y: auto;
                    background: #f8fef2;
                }
                
                .match {
                    cursor:pointer; 
                    background-color:#00ffbb;
                }
        </style>
    </head>
    <body>
        <h2>Similarity: 15.069398545935227%, Tokens: 8, <button onclick='openModal()' class='match'></button></h2>
        <div class="column">
            <h3>Adafruit_nRF52_Arduino-MDEwOlJlcG9zaXRvcnk3NDM1NDcyOQ==-flat-queue.c</h3>
            <pre><code>1  #include <stdlib.h>
2  #include <string.h>
3  #define MPU_WRAPPERS_INCLUDED_FROM_API_FILE
4  #include "FreeRTOS.h"
5  #include "task.h"
6  #include "queue.h"
7  #if ( configUSE_CO_ROUTINES == 1 )
8  	#include "croutine.h"
9  #endif
10  #undef MPU_WRAPPERS_INCLUDED_FROM_API_FILE &bsol;*lint !e961 !e750. */
11  #define queueUNLOCKED					( ( int8_t ) -1 )
12  #define queueLOCKED_UNMODIFIED			( ( int8_t ) 0 )
13  #define pxMutexHolder					pcTail
14  #define uxQueueType						pcHead
15  #define queueQUEUE_IS_MUTEX				NULL
16  #define queueSEMAPHORE_QUEUE_ITEM_LENGTH ( ( UBaseType_t ) 0 )
17  #define queueMUTEX_GIVE_BLOCK_TIME		 ( ( TickType_t ) 0U )
18  #if( configUSE_PREEMPTION == 0 )
19  	#define queueYIELD_IF_USING_PREEMPTION()
20  #else
21  	#define queueYIELD_IF_USING_PREEMPTION() portYIELD_WITHIN_API()
22  #endif
23  typedef struct QueueDefinition
24  {
25  	int8_t *pcHead;					&bsol;*< Points to the beginning of the queue storage area. */
26  	int8_t *pcTail;					&bsol;*< Points to the byte at the end of the queue storage area.  Once more byte is allocated than necessary to store the queue items, this is used as a marker. */
27  	int8_t *pcWriteTo;				&bsol;*< Points to the free next place in the storage area. */
28  	union							&bsol;* Use of a union is an exception to the coding standard to ensure two mutually exclusive structure members don't appear simultaneously (wasting RAM). */
29  	{
30  		int8_t *pcReadFrom;			&bsol;*< Points to the last place that a queued item was read from when the structure is used as a queue. */
31  		UBaseType_t uxRecursiveCallCount;&bsol;*< Maintains a count of the number of times a recursive mutex has been recursively 'taken' when the structure is used as a mutex. */
32  	} u;
33  	List_t xTasksWaitingToSend;		&bsol;*< List of tasks that are blocked waiting to post onto this queue.  Stored in priority order. */
34  	List_t xTasksWaitingToReceive;	&bsol;*< List of tasks that are blocked waiting to read from this queue.  Stored in priority order. */
35  	volatile UBaseType_t uxMessagesWaiting;&bsol;*< The number of items currently in the queue. */
36  	UBaseType_t uxLength;			&bsol;*< The length of the queue defined as the number of items it will hold, not the number of bytes. */
37  	UBaseType_t uxItemSize;			&bsol;*< The size of each items that the queue will hold. */
38  	volatile int8_t cRxLock;		&bsol;*< Stores the number of items received from the queue (removed from the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */
39  	volatile int8_t cTxLock;		&bsol;*< Stores the number of items transmitted to the queue (added to the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */
40  	#if( ( configSUPPORT_STATIC_ALLOCATION == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
41  		uint8_t ucStaticallyAllocated;	&bsol;*< Set to pdTRUE if the memory used by the queue was statically allocated to ensure no attempt is made to free the memory. */
42  	#endif
43  	#if ( configUSE_QUEUE_SETS == 1 )
44  		struct QueueDefinition *pxQueueSetContainer;
45  	#endif
46  	#if ( configUSE_TRACE_FACILITY == 1 )
47  		UBaseType_t uxQueueNumber;
48  		uint8_t ucQueueType;
49  	#endif
50  } xQUEUE;
51  typedef xQUEUE Queue_t;
52  #if ( configQUEUE_REGISTRY_SIZE > 0 )
53  	typedef struct QUEUE_REGISTRY_ITEM
54  	{
55  		const char *pcQueueName; &bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
56  		QueueHandle_t xHandle;
57  	} xQueueRegistryItem;
58  	typedef xQueueRegistryItem QueueRegistryItem_t;
59  	PRIVILEGED_DATA QueueRegistryItem_t xQueueRegistry[ configQUEUE_REGISTRY_SIZE ];
60  #endif &bsol;* configQUEUE_REGISTRY_SIZE */
61  static void prvUnlockQueue( Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;
62  static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue ) PRIVILEGED_FUNCTION;
63  static BaseType_t prvIsQueueFull( const Queue_t *pxQueue ) PRIVILEGED_FUNCTION;
64  static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition ) PRIVILEGED_FUNCTION;
65  static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer ) PRIVILEGED_FUNCTION;
66  #if ( configUSE_QUEUE_SETS == 1 )
67  	static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue, const BaseType_t xCopyPosition ) PRIVILEGED_FUNCTION;
68  #endif
69  static void prvInitialiseNewQueue( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, const uint8_t ucQueueType, Queue_t *pxNewQueue ) PRIVILEGED_FUNCTION;
70  #if( configUSE_MUTEXES == 1 )
71  	static void prvInitialiseMutex( Queue_t *pxNewQueue ) PRIVILEGED_FUNCTION;
72  #endif
73  #if( configUSE_MUTEXES == 1 )
74  	static UBaseType_t prvGetDisinheritPriorityAfterTimeout( const Queue_t * const pxQueue ) PRIVILEGED_FUNCTION;
75  #endif
76  #define prvLockQueue( pxQueue )								\
77  	taskENTER_CRITICAL();									\
78  	{														\
79  		if( ( pxQueue )->cRxLock == queueUNLOCKED )			\
80  		{													\
81  			( pxQueue )->cRxLock = queueLOCKED_UNMODIFIED;	\
82  		}													\
83  		if( ( pxQueue )->cTxLock == queueUNLOCKED )			\
84  		{													\
85  			( pxQueue )->cTxLock = queueLOCKED_UNMODIFIED;	\
86  		}													\
87  	}														\
88  	taskEXIT_CRITICAL()
89  BaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue )
90  {
91  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
92  	configASSERT( pxQueue );
93  	taskENTER_CRITICAL();
94  	{
95  		pxQueue->pcTail = pxQueue->pcHead + ( pxQueue->uxLength * pxQueue->uxItemSize );
96  		pxQueue->uxMessagesWaiting = ( UBaseType_t ) 0U;
97  		pxQueue->pcWriteTo = pxQueue->pcHead;
98  		pxQueue->u.pcReadFrom = pxQueue->pcHead + ( ( pxQueue->uxLength - ( UBaseType_t ) 1U ) * pxQueue->uxItemSize );
99  		pxQueue->cRxLock = queueUNLOCKED;
100  		pxQueue->cTxLock = queueUNLOCKED;
101  		if( xNewQueue == pdFALSE )
102  		{
103  			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
104  			{
105  				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
106  				{
107  					queueYIELD_IF_USING_PREEMPTION();
108  				}
109  				else
110  				{
111  					mtCOVERAGE_TEST_MARKER();
112  				}
113  			}
114  			else
115  			{
116  				mtCOVERAGE_TEST_MARKER();
117  			}
118  		}
119  		else
120  		{
121  			vListInitialise( &( pxQueue->xTasksWaitingToSend ) );
122  			vListInitialise( &( pxQueue->xTasksWaitingToReceive ) );
123  		}
124  	}
125  	taskEXIT_CRITICAL();
126  	return pdPASS;
127  }
128  #if( configSUPPORT_STATIC_ALLOCATION == 1 )
129  	QueueHandle_t xQueueGenericCreateStatic( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, StaticQueue_t *pxStaticQueue, const uint8_t ucQueueType )
130  	{
131  	Queue_t *pxNewQueue;
132  		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );
133  		configASSERT( pxStaticQueue != NULL );
134  		configASSERT( !( ( pucQueueStorage != NULL ) && ( uxItemSize == 0 ) ) );
135  		configASSERT( !( ( pucQueueStorage == NULL ) && ( uxItemSize != 0 ) ) );
136  		#if( configASSERT_DEFINED == 1 )
137  		{
138  			volatile size_t xSize = sizeof( StaticQueue_t );
139  			configASSERT( xSize == sizeof( Queue_t ) );
140  		}
141  		#endif &bsol;* configASSERT_DEFINED */
142  		pxNewQueue = ( Queue_t * ) pxStaticQueue; &bsol;*lint !e740 Unusual cast is ok as the structures are designed to have the same alignment, and the size is checked by an assert. */
143  		if( pxNewQueue != NULL )
144  		{
145  			#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
146  			{
147  				pxNewQueue->ucStaticallyAllocated = pdTRUE;
148  			}
149  			#endif &bsol;* configSUPPORT_DYNAMIC_ALLOCATION */
150  			prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );
151  		}
152  		else
153  		{
154  			traceQUEUE_CREATE_FAILED( ucQueueType );
155  		}
156  		return pxNewQueue;
157  	}
158  #endif &bsol;* configSUPPORT_STATIC_ALLOCATION */
159  #if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )
160  	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType )
161  	{
162  	Queue_t *pxNewQueue;
163  	size_t xQueueSizeInBytes;
164  	uint8_t *pucQueueStorage;
165  		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );
166  		if( uxItemSize == ( UBaseType_t ) 0 )
167  		{
168  			xQueueSizeInBytes = ( size_t ) 0;
169  		}
170  		else
171  		{
172  			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
173  		}
174  		pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes );
175  		if( pxNewQueue != NULL )
176  		{
177  			pucQueueStorage = ( ( uint8_t * ) pxNewQueue ) + sizeof( Queue_t );
178  			#if( configSUPPORT_STATIC_ALLOCATION == 1 )
179  			{
180  				pxNewQueue->ucStaticallyAllocated = pdFALSE;
181  			}
182  			#endif &bsol;* configSUPPORT_STATIC_ALLOCATION */
183  			prvInitialiseNewQueue( uxQueueLength, uxItemSize, pucQueueStorage, ucQueueType, pxNewQueue );
184  		}
185  		else
186  		{
187  			traceQUEUE_CREATE_FAILED( ucQueueType );
188  		}
189  		return pxNewQueue;
190  	}
191  #endif &bsol;* configSUPPORT_STATIC_ALLOCATION */
192  static void prvInitialiseNewQueue( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, uint8_t *pucQueueStorage, const uint8_t ucQueueType, Queue_t *pxNewQueue )
193  {
194  	( void ) ucQueueType;
195  	if( uxItemSize == ( UBaseType_t ) 0 )
196  	{
197  		pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
198  	}
199  	else
200  	{
201  		pxNewQueue->pcHead = ( int8_t * ) pucQueueStorage;
202  	}
203  	pxNewQueue->uxLength = uxQueueLength;
204  	pxNewQueue->uxItemSize = uxItemSize;
205  	( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
206  	#if ( configUSE_TRACE_FACILITY == 1 )
207  	{
208  		pxNewQueue->ucQueueType = ucQueueType;
209  	}
210  	#endif &bsol;* configUSE_TRACE_FACILITY */
211  	#if( configUSE_QUEUE_SETS == 1 )
212  	{
213  		pxNewQueue->pxQueueSetContainer = NULL;
214  	}
215  	#endif &bsol;* configUSE_QUEUE_SETS */
216  	traceQUEUE_CREATE( pxNewQueue );
217  }
218  #if( configUSE_MUTEXES == 1 )
219  	static void prvInitialiseMutex( Queue_t *pxNewQueue )
220  	{
221  		if( pxNewQueue != NULL )
222  		{
223  			pxNewQueue->pxMutexHolder = NULL;
224  			pxNewQueue->uxQueueType = queueQUEUE_IS_MUTEX;
225  			pxNewQueue->u.uxRecursiveCallCount = 0;
226  			traceCREATE_MUTEX( pxNewQueue );
227  			( void ) xQueueGenericSend( pxNewQueue, NULL, ( TickType_t ) 0U, queueSEND_TO_BACK );
228  		}
229  		else
230  		{
231  			traceCREATE_MUTEX_FAILED();
232  		}
<span onclick='openModal()' class='match'>233  	}
234  #endif &bsol;* configUSE_MUTEXES */
235  #if( ( configUSE_MUTEXES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
236  	QueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType )
237  	{
238  	Queue_t *pxNewQueue;
239  	const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;
</span>240  		pxNewQueue = ( Queue_t * ) xQueueGenericCreate( uxMutexLength, uxMutexSize, ucQueueType );
241  		prvInitialiseMutex( pxNewQueue );
242  		return pxNewQueue;
243  	}
244  #endif &bsol;* configUSE_MUTEXES */
245  #if( ( configUSE_MUTEXES == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
246  	QueueHandle_t xQueueCreateMutexStatic( const uint8_t ucQueueType, StaticQueue_t *pxStaticQueue )
247  	{
248  	Queue_t *pxNewQueue;
249  	const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;
250  		( void ) ucQueueType;
251  		pxNewQueue = ( Queue_t * ) xQueueGenericCreateStatic( uxMutexLength, uxMutexSize, NULL, pxStaticQueue, ucQueueType );
252  		prvInitialiseMutex( pxNewQueue );
253  		return pxNewQueue;
254  	}
255  #endif &bsol;* configUSE_MUTEXES */
256  #if ( ( configUSE_MUTEXES == 1 ) && ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) )
257  	void* xQueueGetMutexHolder( QueueHandle_t xSemaphore )
258  	{
259  	void *pxReturn;
260  		taskENTER_CRITICAL();
261  		{
262  			if( ( ( Queue_t * ) xSemaphore )->uxQueueType == queueQUEUE_IS_MUTEX )
263  			{
264  				pxReturn = ( void * ) ( ( Queue_t * ) xSemaphore )->pxMutexHolder;
265  			}
266  			else
267  			{
268  				pxReturn = NULL;
269  			}
270  		}
271  		taskEXIT_CRITICAL();
272  		return pxReturn;
273  	} &bsol;*lint !e818 xSemaphore cannot be a pointer to const because it is a typedef. */
274  #endif
275  #if ( ( configUSE_MUTEXES == 1 ) && ( INCLUDE_xSemaphoreGetMutexHolder == 1 ) )
276  	void* xQueueGetMutexHolderFromISR( QueueHandle_t xSemaphore )
277  	{
278  	void *pxReturn;
279  		configASSERT( xSemaphore );
280  		if( ( ( Queue_t * ) xSemaphore )->uxQueueType == queueQUEUE_IS_MUTEX )
281  		{
282  			pxReturn = ( void * ) ( ( Queue_t * ) xSemaphore )->pxMutexHolder;
283  		}
284  		else
285  		{
286  			pxReturn = NULL;
287  		}
288  		return pxReturn;
289  	} &bsol;*lint !e818 xSemaphore cannot be a pointer to const because it is a typedef. */
290  #endif
291  #if ( configUSE_RECURSIVE_MUTEXES == 1 )
292  	BaseType_t xQueueGiveMutexRecursive( QueueHandle_t xMutex )
293  	{
294  	BaseType_t xReturn;
295  	Queue_t * const pxMutex = ( Queue_t * ) xMutex;
296  		configASSERT( pxMutex );
297  		if( pxMutex->pxMutexHolder == ( void * ) xTaskGetCurrentTaskHandle() ) &bsol;*lint !e961 Not a redundant cast as TaskHandle_t is a typedef. */
298  		{
299  			traceGIVE_MUTEX_RECURSIVE( pxMutex );
300  			( pxMutex->u.uxRecursiveCallCount )--;
301  			if( pxMutex->u.uxRecursiveCallCount == ( UBaseType_t ) 0 )
302  			{
303  				( void ) xQueueGenericSend( pxMutex, NULL, queueMUTEX_GIVE_BLOCK_TIME, queueSEND_TO_BACK );
304  			}
305  			else
306  			{
307  				mtCOVERAGE_TEST_MARKER();
308  			}
309  			xReturn = pdPASS;
310  		}
311  		else
312  		{
313  			xReturn = pdFAIL;
314  			traceGIVE_MUTEX_RECURSIVE_FAILED( pxMutex );
315  		}
316  		return xReturn;
317  	}
318  #endif &bsol;* configUSE_RECURSIVE_MUTEXES */
319  #if ( configUSE_RECURSIVE_MUTEXES == 1 )
320  	BaseType_t xQueueTakeMutexRecursive( QueueHandle_t xMutex, TickType_t xTicksToWait )
321  	{
322  	BaseType_t xReturn;
323  	Queue_t * const pxMutex = ( Queue_t * ) xMutex;
324  		configASSERT( pxMutex );
325  		traceTAKE_MUTEX_RECURSIVE( pxMutex );
326  		if( pxMutex->pxMutexHolder == ( void * ) xTaskGetCurrentTaskHandle() ) &bsol;*lint !e961 Cast is not redundant as TaskHandle_t is a typedef. */
327  		{
328  			( pxMutex->u.uxRecursiveCallCount )++;
329  			xReturn = pdPASS;
330  		}
331  		else
332  		{
333  			xReturn = xQueueSemaphoreTake( pxMutex, xTicksToWait );
334  			if( xReturn != pdFAIL )
335  			{
336  				( pxMutex->u.uxRecursiveCallCount )++;
337  			}
338  			else
339  			{
340  				traceTAKE_MUTEX_RECURSIVE_FAILED( pxMutex );
341  			}
342  		}
343  		return xReturn;
344  	}
345  #endif &bsol;* configUSE_RECURSIVE_MUTEXES */
346  #if( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
347  	QueueHandle_t xQueueCreateCountingSemaphoreStatic( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount, StaticQueue_t *pxStaticQueue )
348  	{
349  	QueueHandle_t xHandle;
350  		configASSERT( uxMaxCount != 0 );
351  		configASSERT( uxInitialCount <= uxMaxCount );
352  		xHandle = xQueueGenericCreateStatic( uxMaxCount, queueSEMAPHORE_QUEUE_ITEM_LENGTH, NULL, pxStaticQueue, queueQUEUE_TYPE_COUNTING_SEMAPHORE );
353  		if( xHandle != NULL )
354  		{
355  			( ( Queue_t * ) xHandle )->uxMessagesWaiting = uxInitialCount;
356  			traceCREATE_COUNTING_SEMAPHORE();
357  		}
358  		else
359  		{
360  			traceCREATE_COUNTING_SEMAPHORE_FAILED();
361  		}
362  		return xHandle;
363  	}
364  #endif &bsol;* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
365  #if( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
366  	QueueHandle_t xQueueCreateCountingSemaphore( const UBaseType_t uxMaxCount, const UBaseType_t uxInitialCount )
367  	{
368  	QueueHandle_t xHandle;
369  		configASSERT( uxMaxCount != 0 );
370  		configASSERT( uxInitialCount <= uxMaxCount );
371  		xHandle = xQueueGenericCreate( uxMaxCount, queueSEMAPHORE_QUEUE_ITEM_LENGTH, queueQUEUE_TYPE_COUNTING_SEMAPHORE );
372  		if( xHandle != NULL )
373  		{
374  			( ( Queue_t * ) xHandle )->uxMessagesWaiting = uxInitialCount;
375  			traceCREATE_COUNTING_SEMAPHORE();
376  		}
377  		else
378  		{
379  			traceCREATE_COUNTING_SEMAPHORE_FAILED();
380  		}
381  		return xHandle;
382  	}
383  #endif &bsol;* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
384  BaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition )
385  {
386  BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
387  TimeOut_t xTimeOut;
388  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
389  	configASSERT( pxQueue );
390  	configASSERT( !( ( pvItemToQueue == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );
391  	configASSERT( !( ( xCopyPosition == queueOVERWRITE ) && ( pxQueue->uxLength != 1 ) ) );
392  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
393  	{
394  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
395  	}
396  	#endif
397  	for( ;; )
398  	{
399  		taskENTER_CRITICAL();
400  		{
401  			if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
402  			{
403  				traceQUEUE_SEND( pxQueue );
404  				xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
405  				#if ( configUSE_QUEUE_SETS == 1 )
406  				{
407  					if( pxQueue->pxQueueSetContainer != NULL )
408  					{
409  						if( prvNotifyQueueSetContainer( pxQueue, xCopyPosition ) != pdFALSE )
410  						{
411  							queueYIELD_IF_USING_PREEMPTION();
412  						}
413  						else
414  						{
415  							mtCOVERAGE_TEST_MARKER();
416  						}
417  					}
418  					else
419  					{
420  						if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
421  						{
422  							if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
423  							{
424  								queueYIELD_IF_USING_PREEMPTION();
425  							}
426  							else
427  							{
428  								mtCOVERAGE_TEST_MARKER();
429  							}
430  						}
431  						else if( xYieldRequired != pdFALSE )
432  						{
433  							queueYIELD_IF_USING_PREEMPTION();
434  						}
435  						else
436  						{
437  							mtCOVERAGE_TEST_MARKER();
438  						}
439  					}
440  				}
441  				#else &bsol;* configUSE_QUEUE_SETS */
442  				{
443  					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
444  					{
445  						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
446  						{
447  							queueYIELD_IF_USING_PREEMPTION();
448  						}
449  						else
450  						{
451  							mtCOVERAGE_TEST_MARKER();
452  						}
453  					}
454  					else if( xYieldRequired != pdFALSE )
455  					{
456  						queueYIELD_IF_USING_PREEMPTION();
457  					}
458  					else
459  					{
460  						mtCOVERAGE_TEST_MARKER();
461  					}
462  				}
463  				#endif &bsol;* configUSE_QUEUE_SETS */
464  				taskEXIT_CRITICAL();
465  				return pdPASS;
466  			}
467  			else
468  			{
469  				if( xTicksToWait == ( TickType_t ) 0 )
470  				{
471  					taskEXIT_CRITICAL();
472  					traceQUEUE_SEND_FAILED( pxQueue );
473  					return errQUEUE_FULL;
474  				}
475  				else if( xEntryTimeSet == pdFALSE )
476  				{
477  					vTaskInternalSetTimeOutState( &xTimeOut );
478  					xEntryTimeSet = pdTRUE;
479  				}
480  				else
481  				{
482  					mtCOVERAGE_TEST_MARKER();
483  				}
484  			}
485  		}
486  		taskEXIT_CRITICAL();
487  		vTaskSuspendAll();
488  		prvLockQueue( pxQueue );
489  		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
490  		{
491  			if( prvIsQueueFull( pxQueue ) != pdFALSE )
492  			{
493  				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
494  				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
495  				prvUnlockQueue( pxQueue );
496  				if( xTaskResumeAll() == pdFALSE )
497  				{
498  					portYIELD_WITHIN_API();
499  				}
500  			}
501  			else
502  			{
503  				prvUnlockQueue( pxQueue );
504  				( void ) xTaskResumeAll();
505  			}
506  		}
507  		else
508  		{
509  			prvUnlockQueue( pxQueue );
510  			( void ) xTaskResumeAll();
511  			traceQUEUE_SEND_FAILED( pxQueue );
512  			return errQUEUE_FULL;
513  		}
514  	}
515  }
516  BaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition )
517  {
518  BaseType_t xReturn;
519  UBaseType_t uxSavedInterruptStatus;
520  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
521  	configASSERT( pxQueue );
522  	configASSERT( !( ( pvItemToQueue == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );
523  	configASSERT( !( ( xCopyPosition == queueOVERWRITE ) && ( pxQueue->uxLength != 1 ) ) );
524  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
525  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
526  	{
527  		if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
528  		{
529  			const int8_t cTxLock = pxQueue->cTxLock;
530  			traceQUEUE_SEND_FROM_ISR( pxQueue );
531  			( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
532  			if( cTxLock == queueUNLOCKED )
533  			{
534  				#if ( configUSE_QUEUE_SETS == 1 )
535  				{
536  					if( pxQueue->pxQueueSetContainer != NULL )
537  					{
538  						if( prvNotifyQueueSetContainer( pxQueue, xCopyPosition ) != pdFALSE )
539  						{
540  							if( pxHigherPriorityTaskWoken != NULL )
541  							{
542  								*pxHigherPriorityTaskWoken = pdTRUE;
543  							}
544  							else
545  							{
546  								mtCOVERAGE_TEST_MARKER();
547  							}
548  						}
549  						else
550  						{
551  							mtCOVERAGE_TEST_MARKER();
552  						}
553  					}
554  					else
555  					{
556  						if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
557  						{
558  							if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
559  							{
560  								if( pxHigherPriorityTaskWoken != NULL )
561  								{
562  									*pxHigherPriorityTaskWoken = pdTRUE;
563  								}
564  								else
565  								{
566  									mtCOVERAGE_TEST_MARKER();
567  								}
568  							}
569  							else
570  							{
571  								mtCOVERAGE_TEST_MARKER();
572  							}
573  						}
574  						else
575  						{
576  							mtCOVERAGE_TEST_MARKER();
577  						}
578  					}
579  				}
580  				#else &bsol;* configUSE_QUEUE_SETS */
581  				{
582  					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
583  					{
584  						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
585  						{
586  							if( pxHigherPriorityTaskWoken != NULL )
587  							{
588  								*pxHigherPriorityTaskWoken = pdTRUE;
589  							}
590  							else
591  							{
592  								mtCOVERAGE_TEST_MARKER();
593  							}
594  						}
595  						else
596  						{
597  							mtCOVERAGE_TEST_MARKER();
598  						}
599  					}
600  					else
601  					{
602  						mtCOVERAGE_TEST_MARKER();
603  					}
604  				}
605  				#endif &bsol;* configUSE_QUEUE_SETS */
606  			}
607  			else
608  			{
609  				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
610  			}
611  			xReturn = pdPASS;
612  		}
613  		else
614  		{
615  			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
616  			xReturn = errQUEUE_FULL;
617  		}
618  	}
619  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
620  	return xReturn;
621  }
622  BaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken )
623  {
624  BaseType_t xReturn;
625  UBaseType_t uxSavedInterruptStatus;
626  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
627  	configASSERT( pxQueue );
628  	configASSERT( pxQueue->uxItemSize == 0 );
629  	configASSERT( !( ( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX ) && ( pxQueue->pxMutexHolder != NULL ) ) );
630  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
631  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
632  	{
633  		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
634  		if( uxMessagesWaiting < pxQueue->uxLength )
635  		{
636  			const int8_t cTxLock = pxQueue->cTxLock;
637  			traceQUEUE_SEND_FROM_ISR( pxQueue );
638  			pxQueue->uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
639  			if( cTxLock == queueUNLOCKED )
640  			{
641  				#if ( configUSE_QUEUE_SETS == 1 )
642  				{
643  					if( pxQueue->pxQueueSetContainer != NULL )
644  					{
645  						if( prvNotifyQueueSetContainer( pxQueue, queueSEND_TO_BACK ) != pdFALSE )
646  						{
647  							if( pxHigherPriorityTaskWoken != NULL )
648  							{
649  								*pxHigherPriorityTaskWoken = pdTRUE;
650  							}
651  							else
652  							{
653  								mtCOVERAGE_TEST_MARKER();
654  							}
655  						}
656  						else
657  						{
658  							mtCOVERAGE_TEST_MARKER();
659  						}
660  					}
661  					else
662  					{
663  						if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
664  						{
665  							if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
666  							{
667  								if( pxHigherPriorityTaskWoken != NULL )
668  								{
669  									*pxHigherPriorityTaskWoken = pdTRUE;
670  								}
671  								else
672  								{
673  									mtCOVERAGE_TEST_MARKER();
674  								}
675  							}
676  							else
677  							{
678  								mtCOVERAGE_TEST_MARKER();
679  							}
680  						}
681  						else
682  						{
683  							mtCOVERAGE_TEST_MARKER();
684  						}
685  					}
686  				}
687  				#else &bsol;* configUSE_QUEUE_SETS */
688  				{
689  					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
690  					{
691  						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
692  						{
693  							if( pxHigherPriorityTaskWoken != NULL )
694  							{
695  								*pxHigherPriorityTaskWoken = pdTRUE;
696  							}
697  							else
698  							{
699  								mtCOVERAGE_TEST_MARKER();
700  							}
701  						}
702  						else
703  						{
704  							mtCOVERAGE_TEST_MARKER();
705  						}
706  					}
707  					else
708  					{
709  						mtCOVERAGE_TEST_MARKER();
710  					}
711  				}
712  				#endif &bsol;* configUSE_QUEUE_SETS */
713  			}
714  			else
715  			{
716  				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
717  			}
718  			xReturn = pdPASS;
719  		}
720  		else
721  		{
722  			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
723  			xReturn = errQUEUE_FULL;
724  		}
725  	}
726  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
727  	return xReturn;
728  }
729  BaseType_t xQueueReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait )
730  {
731  BaseType_t xEntryTimeSet = pdFALSE;
732  TimeOut_t xTimeOut;
733  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
734  	configASSERT( ( pxQueue ) );
735  	configASSERT( !( ( ( pvBuffer ) == NULL ) && ( ( pxQueue )->uxItemSize != ( UBaseType_t ) 0U ) ) );
736  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
737  	{
738  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
739  	}
740  	#endif
741  	for( ;; )
742  	{
743  		taskENTER_CRITICAL();
744  		{
745  			const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
746  			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
747  			{
748  				prvCopyDataFromQueue( pxQueue, pvBuffer );
749  				traceQUEUE_RECEIVE( pxQueue );
750  				pxQueue->uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
751  				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
752  				{
753  					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
754  					{
755  						queueYIELD_IF_USING_PREEMPTION();
756  					}
757  					else
758  					{
759  						mtCOVERAGE_TEST_MARKER();
760  					}
761  				}
762  				else
763  				{
764  					mtCOVERAGE_TEST_MARKER();
765  				}
766  				taskEXIT_CRITICAL();
767  				return pdPASS;
768  			}
769  			else
770  			{
771  				if( xTicksToWait == ( TickType_t ) 0 )
772  				{
773  					taskEXIT_CRITICAL();
774  					traceQUEUE_RECEIVE_FAILED( pxQueue );
775  					return errQUEUE_EMPTY;
776  				}
777  				else if( xEntryTimeSet == pdFALSE )
778  				{
779  					vTaskInternalSetTimeOutState( &xTimeOut );
780  					xEntryTimeSet = pdTRUE;
781  				}
782  				else
783  				{
784  					mtCOVERAGE_TEST_MARKER();
785  				}
786  			}
787  		}
788  		taskEXIT_CRITICAL();
789  		vTaskSuspendAll();
790  		prvLockQueue( pxQueue );
791  		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
792  		{
793  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
794  			{
795  				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
796  				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
797  				prvUnlockQueue( pxQueue );
798  				if( xTaskResumeAll() == pdFALSE )
799  				{
800  					portYIELD_WITHIN_API();
801  				}
802  				else
803  				{
804  					mtCOVERAGE_TEST_MARKER();
805  				}
806  			}
807  			else
808  			{
809  				prvUnlockQueue( pxQueue );
810  				( void ) xTaskResumeAll();
811  			}
812  		}
813  		else
814  		{
815  			prvUnlockQueue( pxQueue );
816  			( void ) xTaskResumeAll();
817  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
818  			{
819  				traceQUEUE_RECEIVE_FAILED( pxQueue );
820  				return errQUEUE_EMPTY;
821  			}
822  			else
823  			{
824  				mtCOVERAGE_TEST_MARKER();
825  			}
826  		}
827  	}
828  }
829  BaseType_t xQueueSemaphoreTake( QueueHandle_t xQueue, TickType_t xTicksToWait )
830  {
831  BaseType_t xEntryTimeSet = pdFALSE;
832  TimeOut_t xTimeOut;
833  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
834  #if( configUSE_MUTEXES == 1 )
835  	BaseType_t xInheritanceOccurred = pdFALSE;
836  #endif
837  	configASSERT( ( pxQueue ) );
838  	configASSERT( pxQueue->uxItemSize == 0 );
839  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
840  	{
841  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
842  	}
843  	#endif
844  	for( ;; )
845  	{
846  		taskENTER_CRITICAL();
847  		{
848  			const UBaseType_t uxSemaphoreCount = pxQueue->uxMessagesWaiting;
849  			if( uxSemaphoreCount > ( UBaseType_t ) 0 )
850  			{
851  				traceQUEUE_RECEIVE( pxQueue );
852  				pxQueue->uxMessagesWaiting = uxSemaphoreCount - ( UBaseType_t ) 1;
853  				#if ( configUSE_MUTEXES == 1 )
854  				{
855  					if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
856  					{
857  						pxQueue->pxMutexHolder = ( int8_t * ) pvTaskIncrementMutexHeldCount(); &bsol;*lint !e961 Cast is not redundant as TaskHandle_t is a typedef. */
858  					}
859  					else
860  					{
861  						mtCOVERAGE_TEST_MARKER();
862  					}
863  				}
864  				#endif &bsol;* configUSE_MUTEXES */
865  				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
866  				{
867  					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
868  					{
869  						queueYIELD_IF_USING_PREEMPTION();
870  					}
871  					else
872  					{
873  						mtCOVERAGE_TEST_MARKER();
874  					}
875  				}
876  				else
877  				{
878  					mtCOVERAGE_TEST_MARKER();
879  				}
880  				taskEXIT_CRITICAL();
881  				return pdPASS;
882  			}
883  			else
884  			{
885  				if( xTicksToWait == ( TickType_t ) 0 )
886  				{
887  					#if( configUSE_MUTEXES == 1 )
888  					{
889  						configASSERT( xInheritanceOccurred == pdFALSE );
890  					}
891  					#endif &bsol;* configUSE_MUTEXES */
892  					taskEXIT_CRITICAL();
893  					traceQUEUE_RECEIVE_FAILED( pxQueue );
894  					return errQUEUE_EMPTY;
895  				}
896  				else if( xEntryTimeSet == pdFALSE )
897  				{
898  					vTaskInternalSetTimeOutState( &xTimeOut );
899  					xEntryTimeSet = pdTRUE;
900  				}
901  				else
902  				{
903  					mtCOVERAGE_TEST_MARKER();
904  				}
905  			}
906  		}
907  		taskEXIT_CRITICAL();
908  		vTaskSuspendAll();
909  		prvLockQueue( pxQueue );
910  		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
911  		{
912  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
913  			{
914  				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
915  				#if ( configUSE_MUTEXES == 1 )
916  				{
917  					if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
918  					{
919  						taskENTER_CRITICAL();
920  						{
921  							xInheritanceOccurred = xTaskPriorityInherit( ( void * ) pxQueue->pxMutexHolder );
922  						}
923  						taskEXIT_CRITICAL();
924  					}
925  					else
926  					{
927  						mtCOVERAGE_TEST_MARKER();
928  					}
929  				}
930  				#endif
931  				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
932  				prvUnlockQueue( pxQueue );
933  				if( xTaskResumeAll() == pdFALSE )
934  				{
935  					portYIELD_WITHIN_API();
936  				}
937  				else
938  				{
939  					mtCOVERAGE_TEST_MARKER();
940  				}
941  			}
942  			else
943  			{
944  				prvUnlockQueue( pxQueue );
945  				( void ) xTaskResumeAll();
946  			}
947  		}
948  		else
949  		{
950  			prvUnlockQueue( pxQueue );
951  			( void ) xTaskResumeAll();
952  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
953  			{
954  				#if ( configUSE_MUTEXES == 1 )
955  				{
956  					if( xInheritanceOccurred != pdFALSE )
957  					{
958  						taskENTER_CRITICAL();
959  						{
960  							UBaseType_t uxHighestWaitingPriority;
961  							uxHighestWaitingPriority = prvGetDisinheritPriorityAfterTimeout( pxQueue );
962  							vTaskPriorityDisinheritAfterTimeout( ( void * ) pxQueue->pxMutexHolder, uxHighestWaitingPriority );
963  						}
964  						taskEXIT_CRITICAL();
965  					}
966  				}
967  				#endif &bsol;* configUSE_MUTEXES */
968  				traceQUEUE_RECEIVE_FAILED( pxQueue );
969  				return errQUEUE_EMPTY;
970  			}
971  			else
972  			{
973  				mtCOVERAGE_TEST_MARKER();
974  			}
975  		}
976  	}
977  }
978  BaseType_t xQueuePeek( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait )
979  {
980  BaseType_t xEntryTimeSet = pdFALSE;
981  TimeOut_t xTimeOut;
982  int8_t *pcOriginalReadPosition;
983  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
984  	configASSERT( ( pxQueue ) );
985  	configASSERT( !( ( ( pvBuffer ) == NULL ) && ( ( pxQueue )->uxItemSize != ( UBaseType_t ) 0U ) ) );
986  	#if ( ( INCLUDE_xTaskGetSchedulerState == 1 ) || ( configUSE_TIMERS == 1 ) )
987  	{
988  		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
989  	}
990  	#endif
991  	for( ;; )
992  	{
993  		taskENTER_CRITICAL();
994  		{
995  			const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
996  			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
997  			{
998  				pcOriginalReadPosition = pxQueue->u.pcReadFrom;
999  				prvCopyDataFromQueue( pxQueue, pvBuffer );
1000  				traceQUEUE_PEEK( pxQueue );
1001  				pxQueue->u.pcReadFrom = pcOriginalReadPosition;
1002  				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
1003  				{
1004  					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
1005  					{
1006  						queueYIELD_IF_USING_PREEMPTION();
1007  					}
1008  					else
1009  					{
1010  						mtCOVERAGE_TEST_MARKER();
1011  					}
1012  				}
1013  				else
1014  				{
1015  					mtCOVERAGE_TEST_MARKER();
1016  				}
1017  				taskEXIT_CRITICAL();
1018  				return pdPASS;
1019  			}
1020  			else
1021  			{
1022  				if( xTicksToWait == ( TickType_t ) 0 )
1023  				{
1024  					taskEXIT_CRITICAL();
1025  					traceQUEUE_PEEK_FAILED( pxQueue );
1026  					return errQUEUE_EMPTY;
1027  				}
1028  				else if( xEntryTimeSet == pdFALSE )
1029  				{
1030  					vTaskInternalSetTimeOutState( &xTimeOut );
1031  					xEntryTimeSet = pdTRUE;
1032  				}
1033  				else
1034  				{
1035  					mtCOVERAGE_TEST_MARKER();
1036  				}
1037  			}
1038  		}
1039  		taskEXIT_CRITICAL();
1040  		vTaskSuspendAll();
1041  		prvLockQueue( pxQueue );
1042  		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
1043  		{
1044  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
1045  			{
1046  				traceBLOCKING_ON_QUEUE_PEEK( pxQueue );
1047  				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
1048  				prvUnlockQueue( pxQueue );
1049  				if( xTaskResumeAll() == pdFALSE )
1050  				{
1051  					portYIELD_WITHIN_API();
1052  				}
1053  				else
1054  				{
1055  					mtCOVERAGE_TEST_MARKER();
1056  				}
1057  			}
1058  			else
1059  			{
1060  				prvUnlockQueue( pxQueue );
1061  				( void ) xTaskResumeAll();
1062  			}
1063  		}
1064  		else
1065  		{
1066  			prvUnlockQueue( pxQueue );
1067  			( void ) xTaskResumeAll();
1068  			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
1069  			{
1070  				traceQUEUE_PEEK_FAILED( pxQueue );
1071  				return errQUEUE_EMPTY;
1072  			}
1073  			else
1074  			{
1075  				mtCOVERAGE_TEST_MARKER();
1076  			}
1077  		}
1078  	}
1079  }
1080  BaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken )
1081  {
1082  BaseType_t xReturn;
1083  UBaseType_t uxSavedInterruptStatus;
1084  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1085  	configASSERT( pxQueue );
1086  	configASSERT( !( ( pvBuffer == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );
1087  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
1088  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
1089  	{
1090  		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
1091  		if( uxMessagesWaiting > ( UBaseType_t ) 0 )
1092  		{
1093  			const int8_t cRxLock = pxQueue->cRxLock;
1094  			traceQUEUE_RECEIVE_FROM_ISR( pxQueue );
1095  			prvCopyDataFromQueue( pxQueue, pvBuffer );
1096  			pxQueue->uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
1097  			if( cRxLock == queueUNLOCKED )
1098  			{
1099  				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
1100  				{
1101  					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
1102  					{
1103  						if( pxHigherPriorityTaskWoken != NULL )
1104  						{
1105  							*pxHigherPriorityTaskWoken = pdTRUE;
1106  						}
1107  						else
1108  						{
1109  							mtCOVERAGE_TEST_MARKER();
1110  						}
1111  					}
1112  					else
1113  					{
1114  						mtCOVERAGE_TEST_MARKER();
1115  					}
1116  				}
1117  				else
1118  				{
1119  					mtCOVERAGE_TEST_MARKER();
1120  				}
1121  			}
1122  			else
1123  			{
1124  				pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
1125  			}
1126  			xReturn = pdPASS;
1127  		}
1128  		else
1129  		{
1130  			xReturn = pdFAIL;
1131  			traceQUEUE_RECEIVE_FROM_ISR_FAILED( pxQueue );
1132  		}
1133  	}
1134  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
1135  	return xReturn;
1136  }
1137  BaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,  void * const pvBuffer )
1138  {
1139  BaseType_t xReturn;
1140  UBaseType_t uxSavedInterruptStatus;
1141  int8_t *pcOriginalReadPosition;
1142  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1143  	configASSERT( pxQueue );
1144  	configASSERT( !( ( pvBuffer == NULL ) && ( pxQueue->uxItemSize != ( UBaseType_t ) 0U ) ) );
1145  	configASSERT( pxQueue->uxItemSize != 0 ); &bsol;* Can't peek a semaphore. */
1146  	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();
1147  	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
1148  	{
1149  		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
1150  		{
1151  			traceQUEUE_PEEK_FROM_ISR( pxQueue );
1152  			pcOriginalReadPosition = pxQueue->u.pcReadFrom;
1153  			prvCopyDataFromQueue( pxQueue, pvBuffer );
1154  			pxQueue->u.pcReadFrom = pcOriginalReadPosition;
1155  			xReturn = pdPASS;
1156  		}
1157  		else
1158  		{
1159  			xReturn = pdFAIL;
1160  			traceQUEUE_PEEK_FROM_ISR_FAILED( pxQueue );
1161  		}
1162  	}
1163  	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
1164  	return xReturn;
1165  }
1166  UBaseType_t uxQueueMessagesWaiting( const QueueHandle_t xQueue )
1167  {
1168  UBaseType_t uxReturn;
1169  	configASSERT( xQueue );
1170  	taskENTER_CRITICAL();
1171  	{
1172  		uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
1173  	}
1174  	taskEXIT_CRITICAL();
1175  	return uxReturn;
1176  } &bsol;*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
1177  UBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue )
1178  {
1179  UBaseType_t uxReturn;
1180  Queue_t *pxQueue;
1181  	pxQueue = ( Queue_t * ) xQueue;
1182  	configASSERT( pxQueue );
1183  	taskENTER_CRITICAL();
1184  	{
1185  		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
1186  	}
1187  	taskEXIT_CRITICAL();
1188  	return uxReturn;
1189  } &bsol;*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
1190  UBaseType_t uxQueueMessagesWaitingFromISR( const QueueHandle_t xQueue )
1191  {
1192  UBaseType_t uxReturn;
1193  	configASSERT( xQueue );
1194  	uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
1195  	return uxReturn;
1196  } &bsol;*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
1197  void vQueueDelete( QueueHandle_t xQueue )
1198  {
1199  Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1200  	configASSERT( pxQueue );
1201  	traceQUEUE_DELETE( pxQueue );
1202  	#if ( configQUEUE_REGISTRY_SIZE > 0 )
1203  	{
1204  		vQueueUnregisterQueue( pxQueue );
1205  	}
1206  	#endif
1207  	#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
1208  	{
1209  		vPortFree( pxQueue );
1210  	}
1211  	#elif( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 1 ) )
1212  	{
1213  		if( pxQueue->ucStaticallyAllocated == ( uint8_t ) pdFALSE )
1214  		{
1215  			vPortFree( pxQueue );
1216  		}
1217  		else
1218  		{
1219  			mtCOVERAGE_TEST_MARKER();
1220  		}
1221  	}
1222  	#else
1223  	{
1224  		( void ) pxQueue;
1225  	}
1226  	#endif &bsol;* configSUPPORT_DYNAMIC_ALLOCATION */
1227  }
1228  #if ( configUSE_TRACE_FACILITY == 1 )
1229  	UBaseType_t uxQueueGetQueueNumber( QueueHandle_t xQueue )
1230  	{
1231  		return ( ( Queue_t * ) xQueue )->uxQueueNumber;
1232  	}
1233  #endif &bsol;* configUSE_TRACE_FACILITY */
1234  #if ( configUSE_TRACE_FACILITY == 1 )
1235  	void vQueueSetQueueNumber( QueueHandle_t xQueue, UBaseType_t uxQueueNumber )
1236  	{
1237  		( ( Queue_t * ) xQueue )->uxQueueNumber = uxQueueNumber;
1238  	}
1239  #endif &bsol;* configUSE_TRACE_FACILITY */
1240  #if ( configUSE_TRACE_FACILITY == 1 )
1241  	uint8_t ucQueueGetQueueType( QueueHandle_t xQueue )
1242  	{
1243  		return ( ( Queue_t * ) xQueue )->ucQueueType;
1244  	}
1245  #endif &bsol;* configUSE_TRACE_FACILITY */
1246  #if( configUSE_MUTEXES == 1 )
1247  	static UBaseType_t prvGetDisinheritPriorityAfterTimeout( const Queue_t * const pxQueue )
1248  	{
1249  	UBaseType_t uxHighestPriorityOfWaitingTasks;
1250  		if( listCURRENT_LIST_LENGTH( &( pxQueue->xTasksWaitingToReceive ) ) > 0 )
1251  		{
1252  			uxHighestPriorityOfWaitingTasks = configMAX_PRIORITIES - listGET_ITEM_VALUE_OF_HEAD_ENTRY( &( pxQueue->xTasksWaitingToReceive ) );
1253  		}
1254  		else
1255  		{
1256  			uxHighestPriorityOfWaitingTasks = tskIDLE_PRIORITY;
1257  		}
1258  		return uxHighestPriorityOfWaitingTasks;
1259  	}
1260  #endif &bsol;* configUSE_MUTEXES */
1261  static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
1262  {
1263  BaseType_t xReturn = pdFALSE;
1264  UBaseType_t uxMessagesWaiting;
1265  	uxMessagesWaiting = pxQueue->uxMessagesWaiting;
1266  	if( pxQueue->uxItemSize == ( UBaseType_t ) 0 )
1267  	{
1268  		#if ( configUSE_MUTEXES == 1 )
1269  		{
1270  			if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )
1271  			{
1272  				xReturn = xTaskPriorityDisinherit( ( void * ) pxQueue->pxMutexHolder );
1273  				pxQueue->pxMutexHolder = NULL;
1274  			}
1275  			else
1276  			{
1277  				mtCOVERAGE_TEST_MARKER();
1278  			}
1279  		}
1280  		#endif &bsol;* configUSE_MUTEXES */
1281  	}
1282  	else if( xPosition == queueSEND_TO_BACK )
1283  	{
1284  		( void ) memcpy( ( void * ) pxQueue->pcWriteTo, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); &bsol;*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a null pointer can only be passed to memcpy() if the copy size is 0. */
1285  		pxQueue->pcWriteTo += pxQueue->uxItemSize;
1286  		if( pxQueue->pcWriteTo >= pxQueue->pcTail ) &bsol;*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
1287  		{
1288  			pxQueue->pcWriteTo = pxQueue->pcHead;
1289  		}
1290  		else
1291  		{
1292  			mtCOVERAGE_TEST_MARKER();
1293  		}
1294  	}
1295  	else
1296  	{
1297  		( void ) memcpy( ( void * ) pxQueue->u.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); &bsol;*lint !e961 MISRA exception as the casts are only redundant for some ports. */
1298  		pxQueue->u.pcReadFrom -= pxQueue->uxItemSize;
1299  		if( pxQueue->u.pcReadFrom < pxQueue->pcHead ) &bsol;*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
1300  		{
1301  			pxQueue->u.pcReadFrom = ( pxQueue->pcTail - pxQueue->uxItemSize );
1302  		}
1303  		else
1304  		{
1305  			mtCOVERAGE_TEST_MARKER();
1306  		}
1307  		if( xPosition == queueOVERWRITE )
1308  		{
1309  			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
1310  			{
1311  				--uxMessagesWaiting;
1312  			}
1313  			else
1314  			{
1315  				mtCOVERAGE_TEST_MARKER();
1316  			}
1317  		}
1318  		else
1319  		{
1320  			mtCOVERAGE_TEST_MARKER();
1321  		}
1322  	}
1323  	pxQueue->uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
1324  	return xReturn;
1325  }
1326  static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer )
1327  {
1328  	if( pxQueue->uxItemSize != ( UBaseType_t ) 0 )
1329  	{
1330  		pxQueue->u.pcReadFrom += pxQueue->uxItemSize;
1331  		if( pxQueue->u.pcReadFrom >= pxQueue->pcTail ) &bsol;*lint !e946 MISRA exception justified as use of the relational operator is the cleanest solutions. */
1332  		{
1333  			pxQueue->u.pcReadFrom = pxQueue->pcHead;
1334  		}
1335  		else
1336  		{
1337  			mtCOVERAGE_TEST_MARKER();
1338  		}
1339  		( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.pcReadFrom, ( size_t ) pxQueue->uxItemSize ); &bsol;*lint !e961 !e418 MISRA exception as the casts are only redundant for some ports.  Also previous logic ensures a null pointer can only be passed to memcpy() when the count is 0. */
1340  	}
1341  }
1342  static void prvUnlockQueue( Queue_t * const pxQueue )
1343  {
1344  	taskENTER_CRITICAL();
1345  	{
1346  		int8_t cTxLock = pxQueue->cTxLock;
1347  		while( cTxLock > queueLOCKED_UNMODIFIED )
1348  		{
1349  			#if ( configUSE_QUEUE_SETS == 1 )
1350  			{
1351  				if( pxQueue->pxQueueSetContainer != NULL )
1352  				{
1353  					if( prvNotifyQueueSetContainer( pxQueue, queueSEND_TO_BACK ) != pdFALSE )
1354  					{
1355  						vTaskMissedYield();
1356  					}
1357  					else
1358  					{
1359  						mtCOVERAGE_TEST_MARKER();
1360  					}
1361  				}
1362  				else
1363  				{
1364  					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
1365  					{
1366  						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
1367  						{
1368  							vTaskMissedYield();
1369  						}
1370  						else
1371  						{
1372  							mtCOVERAGE_TEST_MARKER();
1373  						}
1374  					}
1375  					else
1376  					{
1377  						break;
1378  					}
1379  				}
1380  			}
1381  			#else &bsol;* configUSE_QUEUE_SETS */
1382  			{
1383  				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
1384  				{
1385  					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
1386  					{
1387  						vTaskMissedYield();
1388  					}
1389  					else
1390  					{
1391  						mtCOVERAGE_TEST_MARKER();
1392  					}
1393  				}
1394  				else
1395  				{
1396  					break;
1397  				}
1398  			}
1399  			#endif &bsol;* configUSE_QUEUE_SETS */
1400  			--cTxLock;
1401  		}
1402  		pxQueue->cTxLock = queueUNLOCKED;
1403  	}
1404  	taskEXIT_CRITICAL();
1405  	taskENTER_CRITICAL();
1406  	{
1407  		int8_t cRxLock = pxQueue->cRxLock;
1408  		while( cRxLock > queueLOCKED_UNMODIFIED )
1409  		{
1410  			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
1411  			{
1412  				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
1413  				{
1414  					vTaskMissedYield();
1415  				}
1416  				else
1417  				{
1418  					mtCOVERAGE_TEST_MARKER();
1419  				}
1420  				--cRxLock;
1421  			}
1422  			else
1423  			{
1424  				break;
1425  			}
1426  		}
1427  		pxQueue->cRxLock = queueUNLOCKED;
1428  	}
1429  	taskEXIT_CRITICAL();
1430  }
1431  static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue )
1432  {
1433  BaseType_t xReturn;
1434  	taskENTER_CRITICAL();
1435  	{
1436  		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
1437  		{
1438  			xReturn = pdTRUE;
1439  		}
1440  		else
1441  		{
1442  			xReturn = pdFALSE;
1443  		}
1444  	}
1445  	taskEXIT_CRITICAL();
1446  	return xReturn;
1447  }
1448  BaseType_t xQueueIsQueueEmptyFromISR( const QueueHandle_t xQueue )
1449  {
1450  BaseType_t xReturn;
1451  	configASSERT( xQueue );
1452  	if( ( ( Queue_t * ) xQueue )->uxMessagesWaiting == ( UBaseType_t ) 0 )
1453  	{
1454  		xReturn = pdTRUE;
1455  	}
1456  	else
1457  	{
1458  		xReturn = pdFALSE;
1459  	}
1460  	return xReturn;
1461  } &bsol;*lint !e818 xQueue could not be pointer to const because it is a typedef. */
1462  static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
1463  {
1464  BaseType_t xReturn;
1465  	taskENTER_CRITICAL();
1466  	{
1467  		if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
1468  		{
1469  			xReturn = pdTRUE;
1470  		}
1471  		else
1472  		{
1473  			xReturn = pdFALSE;
1474  		}
1475  	}
1476  	taskEXIT_CRITICAL();
1477  	return xReturn;
1478  }
1479  BaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )
1480  {
1481  BaseType_t xReturn;
1482  	configASSERT( xQueue );
1483  	if( ( ( Queue_t * ) xQueue )->uxMessagesWaiting == ( ( Queue_t * ) xQueue )->uxLength )
1484  	{
1485  		xReturn = pdTRUE;
1486  	}
1487  	else
1488  	{
1489  		xReturn = pdFALSE;
1490  	}
1491  	return xReturn;
1492  } &bsol;*lint !e818 xQueue could not be pointer to const because it is a typedef. */
1493  #if ( configUSE_CO_ROUTINES == 1 )
1494  	BaseType_t xQueueCRSend( QueueHandle_t xQueue, const void *pvItemToQueue, TickType_t xTicksToWait )
1495  	{
1496  	BaseType_t xReturn;
1497  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1498  		portDISABLE_INTERRUPTS();
1499  		{
1500  			if( prvIsQueueFull( pxQueue ) != pdFALSE )
1501  			{
1502  				if( xTicksToWait > ( TickType_t ) 0 )
1503  				{
1504  					vCoRoutineAddToDelayedList( xTicksToWait, &( pxQueue->xTasksWaitingToSend ) );
1505  					portENABLE_INTERRUPTS();
1506  					return errQUEUE_BLOCKED;
1507  				}
1508  				else
1509  				{
1510  					portENABLE_INTERRUPTS();
1511  					return errQUEUE_FULL;
1512  				}
1513  			}
1514  		}
1515  		portENABLE_INTERRUPTS();
1516  		portDISABLE_INTERRUPTS();
1517  		{
1518  			if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
1519  			{
1520  				prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
1521  				xReturn = pdPASS;
1522  				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
1523  				{
1524  					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
1525  					{
1526  						xReturn = errQUEUE_YIELD;
1527  					}
1528  					else
1529  					{
1530  						mtCOVERAGE_TEST_MARKER();
1531  					}
1532  				}
1533  				else
1534  				{
1535  					mtCOVERAGE_TEST_MARKER();
1536  				}
1537  			}
1538  			else
1539  			{
1540  				xReturn = errQUEUE_FULL;
1541  			}
1542  		}
1543  		portENABLE_INTERRUPTS();
1544  		return xReturn;
1545  	}
1546  #endif &bsol;* configUSE_CO_ROUTINES */
1547  #if ( configUSE_CO_ROUTINES == 1 )
1548  	BaseType_t xQueueCRReceive( QueueHandle_t xQueue, void *pvBuffer, TickType_t xTicksToWait )
1549  	{
1550  	BaseType_t xReturn;
1551  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1552  		portDISABLE_INTERRUPTS();
1553  		{
1554  			if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )
1555  			{
1556  				if( xTicksToWait > ( TickType_t ) 0 )
1557  				{
1558  					vCoRoutineAddToDelayedList( xTicksToWait, &( pxQueue->xTasksWaitingToReceive ) );
1559  					portENABLE_INTERRUPTS();
1560  					return errQUEUE_BLOCKED;
1561  				}
1562  				else
1563  				{
1564  					portENABLE_INTERRUPTS();
1565  					return errQUEUE_FULL;
1566  				}
1567  			}
1568  			else
1569  			{
1570  				mtCOVERAGE_TEST_MARKER();
1571  			}
1572  		}
1573  		portENABLE_INTERRUPTS();
1574  		portDISABLE_INTERRUPTS();
1575  		{
1576  			if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
1577  			{
1578  				pxQueue->u.pcReadFrom += pxQueue->uxItemSize;
1579  				if( pxQueue->u.pcReadFrom >= pxQueue->pcTail )
1580  				{
1581  					pxQueue->u.pcReadFrom = pxQueue->pcHead;
1582  				}
1583  				else
1584  				{
1585  					mtCOVERAGE_TEST_MARKER();
1586  				}
1587  				--( pxQueue->uxMessagesWaiting );
1588  				( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );
1589  				xReturn = pdPASS;
1590  				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
1591  				{
1592  					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
1593  					{
1594  						xReturn = errQUEUE_YIELD;
1595  					}
1596  					else
1597  					{
1598  						mtCOVERAGE_TEST_MARKER();
1599  					}
1600  				}
1601  				else
1602  				{
1603  					mtCOVERAGE_TEST_MARKER();
1604  				}
1605  			}
1606  			else
1607  			{
1608  				xReturn = pdFAIL;
1609  			}
1610  		}
1611  		portENABLE_INTERRUPTS();
1612  		return xReturn;
1613  	}
1614  #endif &bsol;* configUSE_CO_ROUTINES */
1615  #if ( configUSE_CO_ROUTINES == 1 )
1616  	BaseType_t xQueueCRSendFromISR( QueueHandle_t xQueue, const void *pvItemToQueue, BaseType_t xCoRoutinePreviouslyWoken )
1617  	{
1618  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1619  		if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
1620  		{
1621  			prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
1622  			if( xCoRoutinePreviouslyWoken == pdFALSE )
1623  			{
1624  				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
1625  				{
1626  					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
1627  					{
1628  						return pdTRUE;
1629  					}
1630  					else
1631  					{
1632  						mtCOVERAGE_TEST_MARKER();
1633  					}
1634  				}
1635  				else
1636  				{
1637  					mtCOVERAGE_TEST_MARKER();
1638  				}
1639  			}
1640  			else
1641  			{
1642  				mtCOVERAGE_TEST_MARKER();
1643  			}
1644  		}
1645  		else
1646  		{
1647  			mtCOVERAGE_TEST_MARKER();
1648  		}
1649  		return xCoRoutinePreviouslyWoken;
1650  	}
1651  #endif &bsol;* configUSE_CO_ROUTINES */
1652  #if ( configUSE_CO_ROUTINES == 1 )
1653  	BaseType_t xQueueCRReceiveFromISR( QueueHandle_t xQueue, void *pvBuffer, BaseType_t *pxCoRoutineWoken )
1654  	{
1655  	BaseType_t xReturn;
1656  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1657  		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
1658  		{
1659  			pxQueue->u.pcReadFrom += pxQueue->uxItemSize;
1660  			if( pxQueue->u.pcReadFrom >= pxQueue->pcTail )
1661  			{
1662  				pxQueue->u.pcReadFrom = pxQueue->pcHead;
1663  			}
1664  			else
1665  			{
1666  				mtCOVERAGE_TEST_MARKER();
1667  			}
1668  			--( pxQueue->uxMessagesWaiting );
1669  			( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );
1670  			if( ( *pxCoRoutineWoken ) == pdFALSE )
1671  			{
1672  				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
1673  				{
1674  					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
1675  					{
1676  						*pxCoRoutineWoken = pdTRUE;
1677  					}
1678  					else
1679  					{
1680  						mtCOVERAGE_TEST_MARKER();
1681  					}
1682  				}
1683  				else
1684  				{
1685  					mtCOVERAGE_TEST_MARKER();
1686  				}
1687  			}
1688  			else
1689  			{
1690  				mtCOVERAGE_TEST_MARKER();
1691  			}
1692  			xReturn = pdPASS;
1693  		}
1694  		else
1695  		{
1696  			xReturn = pdFAIL;
1697  		}
1698  		return xReturn;
1699  	}
1700  #endif &bsol;* configUSE_CO_ROUTINES */
1701  #if ( configQUEUE_REGISTRY_SIZE > 0 )
1702  	void vQueueAddToRegistry( QueueHandle_t xQueue, const char *pcQueueName ) &bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1703  	{
1704  	UBaseType_t ux;
1705  		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
1706  		{
1707  			if( xQueueRegistry[ ux ].pcQueueName == NULL )
1708  			{
1709  				xQueueRegistry[ ux ].pcQueueName = pcQueueName;
1710  				xQueueRegistry[ ux ].xHandle = xQueue;
1711  				traceQUEUE_REGISTRY_ADD( xQueue, pcQueueName );
1712  				break;
1713  			}
1714  			else
1715  			{
1716  				mtCOVERAGE_TEST_MARKER();
1717  			}
1718  		}
1719  	}
1720  #endif &bsol;* configQUEUE_REGISTRY_SIZE */
1721  #if ( configQUEUE_REGISTRY_SIZE > 0 )
1722  	const char *pcQueueGetName( QueueHandle_t xQueue ) &bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1723  	{
1724  	UBaseType_t ux;
1725  	const char *pcReturn = NULL; &bsol;*lint !e971 Unqualified char types are allowed for strings and single characters only. */
1726  		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
1727  		{
1728  			if( xQueueRegistry[ ux ].xHandle == xQueue )
1729  			{
1730  				pcReturn = xQueueRegistry[ ux ].pcQueueName;
1731  				break;
1732  			}
1733  			else
1734  			{
1735  				mtCOVERAGE_TEST_MARKER();
1736  			}
1737  		}
1738  		return pcReturn;
1739  	} &bsol;*lint !e818 xQueue cannot be a pointer to const because it is a typedef. */
1740  #endif &bsol;* configQUEUE_REGISTRY_SIZE */
1741  #if ( configQUEUE_REGISTRY_SIZE > 0 )
1742  	void vQueueUnregisterQueue( QueueHandle_t xQueue )
1743  	{
1744  	UBaseType_t ux;
1745  		for( ux = ( UBaseType_t ) 0U; ux < ( UBaseType_t ) configQUEUE_REGISTRY_SIZE; ux++ )
1746  		{
1747  			if( xQueueRegistry[ ux ].xHandle == xQueue )
1748  			{
1749  				xQueueRegistry[ ux ].pcQueueName = NULL;
1750  				xQueueRegistry[ ux ].xHandle = ( QueueHandle_t ) 0;
1751  				break;
1752  			}
1753  			else
1754  			{
1755  				mtCOVERAGE_TEST_MARKER();
1756  			}
1757  		}
1758  	} &bsol;*lint !e818 xQueue could not be pointer to const because it is a typedef. */
1759  #endif &bsol;* configQUEUE_REGISTRY_SIZE */
1760  #if ( configUSE_TIMERS == 1 )
1761  	void vQueueWaitForMessageRestricted( QueueHandle_t xQueue, TickType_t xTicksToWait, const BaseType_t xWaitIndefinitely )
1762  	{
1763  	Queue_t * const pxQueue = ( Queue_t * ) xQueue;
1764  		prvLockQueue( pxQueue );
1765  		if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0U )
1766  		{
1767  			vTaskPlaceOnEventListRestricted( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait, xWaitIndefinitely );
1768  		}
1769  		else
1770  		{
1771  			mtCOVERAGE_TEST_MARKER();
1772  		}
1773  		prvUnlockQueue( pxQueue );
1774  	}
1775  #endif &bsol;* configUSE_TIMERS */
1776  #if( ( configUSE_QUEUE_SETS == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
1777  	QueueSetHandle_t xQueueCreateSet( const UBaseType_t uxEventQueueLength )
1778  	{
1779  	QueueSetHandle_t pxQueue;
1780  		pxQueue = xQueueGenericCreate( uxEventQueueLength, ( UBaseType_t ) sizeof( Queue_t * ), queueQUEUE_TYPE_SET );
1781  		return pxQueue;
1782  	}
1783  #endif &bsol;* configUSE_QUEUE_SETS */
1784  #if ( configUSE_QUEUE_SETS == 1 )
1785  	BaseType_t xQueueAddToSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet )
1786  	{
1787  	BaseType_t xReturn;
1788  		taskENTER_CRITICAL();
1789  		{
1790  			if( ( ( Queue_t * ) xQueueOrSemaphore )->pxQueueSetContainer != NULL )
1791  			{
1792  				xReturn = pdFAIL;
1793  			}
1794  			else if( ( ( Queue_t * ) xQueueOrSemaphore )->uxMessagesWaiting != ( UBaseType_t ) 0 )
1795  			{
1796  				xReturn = pdFAIL;
1797  			}
1798  			else
1799  			{
1800  				( ( Queue_t * ) xQueueOrSemaphore )->pxQueueSetContainer = xQueueSet;
1801  				xReturn = pdPASS;
1802  			}
1803  		}
1804  		taskEXIT_CRITICAL();
1805  		return xReturn;
1806  	}
1807  #endif &bsol;* configUSE_QUEUE_SETS */
1808  #if ( configUSE_QUEUE_SETS == 1 )
1809  	BaseType_t xQueueRemoveFromSet( QueueSetMemberHandle_t xQueueOrSemaphore, QueueSetHandle_t xQueueSet )
1810  	{
1811  	BaseType_t xReturn;
1812  	Queue_t * const pxQueueOrSemaphore = ( Queue_t * ) xQueueOrSemaphore;
1813  		if( pxQueueOrSemaphore->pxQueueSetContainer != xQueueSet )
1814  		{
1815  			xReturn = pdFAIL;
1816  		}
1817  		else if( pxQueueOrSemaphore->uxMessagesWaiting != ( UBaseType_t ) 0 )
1818  		{
1819  			xReturn = pdFAIL;
1820  		}
1821  		else
1822  		{
1823  			taskENTER_CRITICAL();
1824  			{
1825  				pxQueueOrSemaphore->pxQueueSetContainer = NULL;
1826  			}
1827  			taskEXIT_CRITICAL();
1828  			xReturn = pdPASS;
1829  		}
1830  		return xReturn;
1831  	} &bsol;*lint !e818 xQueueSet could not be declared as pointing to const as it is a typedef. */
1832  #endif &bsol;* configUSE_QUEUE_SETS */
1833  #if ( configUSE_QUEUE_SETS == 1 )
1834  	QueueSetMemberHandle_t xQueueSelectFromSet( QueueSetHandle_t xQueueSet, TickType_t const xTicksToWait )
1835  	{
1836  	QueueSetMemberHandle_t xReturn = NULL;
1837  		( void ) xQueueReceive( ( QueueHandle_t ) xQueueSet, &xReturn, xTicksToWait ); &bsol;*lint !e961 Casting from one typedef to another is not redundant. */
1838  		return xReturn;
1839  	}
1840  #endif &bsol;* configUSE_QUEUE_SETS */
1841  #if ( configUSE_QUEUE_SETS == 1 )
1842  	QueueSetMemberHandle_t xQueueSelectFromSetFromISR( QueueSetHandle_t xQueueSet )
1843  	{
1844  	QueueSetMemberHandle_t xReturn = NULL;
1845  		( void ) xQueueReceiveFromISR( ( QueueHandle_t ) xQueueSet, &xReturn, NULL ); &bsol;*lint !e961 Casting from one typedef to another is not redundant. */
1846  		return xReturn;
1847  	}
1848  #endif &bsol;* configUSE_QUEUE_SETS */
1849  #if ( configUSE_QUEUE_SETS == 1 )
1850  	static BaseType_t prvNotifyQueueSetContainer( const Queue_t * const pxQueue, const BaseType_t xCopyPosition )
1851  	{
1852  	Queue_t *pxQueueSetContainer = pxQueue->pxQueueSetContainer;
1853  	BaseType_t xReturn = pdFALSE;
1854  		configASSERT( pxQueueSetContainer );
1855  		configASSERT( pxQueueSetContainer->uxMessagesWaiting < pxQueueSetContainer->uxLength );
1856  		if( pxQueueSetContainer->uxMessagesWaiting < pxQueueSetContainer->uxLength )
1857  		{
1858  			const int8_t cTxLock = pxQueueSetContainer->cTxLock;
1859  			traceQUEUE_SEND( pxQueueSetContainer );
1860  			xReturn = prvCopyDataToQueue( pxQueueSetContainer, &pxQueue, xCopyPosition );
1861  			if( cTxLock == queueUNLOCKED )
1862  			{
1863  				if( listLIST_IS_EMPTY( &( pxQueueSetContainer->xTasksWaitingToReceive ) ) == pdFALSE )
1864  				{
1865  					if( xTaskRemoveFromEventList( &( pxQueueSetContainer->xTasksWaitingToReceive ) ) != pdFALSE )
1866  					{
1867  						xReturn = pdTRUE;
1868  					}
1869  					else
1870  					{
1871  						mtCOVERAGE_TEST_MARKER();
1872  					}
1873  				}
1874  				else
1875  				{
1876  					mtCOVERAGE_TEST_MARKER();
1877  				}
1878  			}
1879  			else
1880  			{
1881  				pxQueueSetContainer->cTxLock = ( int8_t ) ( cTxLock + 1 );
1882  			}
1883  		}
1884  		else
1885  		{
1886  			mtCOVERAGE_TEST_MARKER();
1887  		}
1888  		return xReturn;
1889  	}
1890  #endif &bsol;* configUSE_QUEUE_SETS */
</code></pre>
        </div>
        <div class="column">
            <h3>PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-enc_neon.c</h3>
            <pre><code>1  #include "src/dsp/dsp.h"
2  #if defined(WEBP_USE_NEON)
3  #include <assert.h>
4  #include "src/dsp/neon.h"
5  #include "src/enc/vp8i_enc.h"
6  static const int16_t kC1 = 20091;
7  static const int16_t kC2 = 17734;  
8  #if defined(WEBP_USE_INTRINSICS)
9  static WEBP_INLINE int16x8_t ConvertU8ToS16_NEON(uint32x2_t v) {
10    return vreinterpretq_s16_u16(vmovl_u8(vreinterpret_u8_u32(v)));
11  }
12  static WEBP_INLINE void SaturateAndStore4x4_NEON(uint8_t* const dst,
13                                                   const int16x8_t dst01,
14                                                   const int16x8_t dst23) {
15    const uint8x8_t dst01_u8 = vqmovun_s16(dst01);
16    const uint8x8_t dst23_u8 = vqmovun_s16(dst23);
17    vst1_lane_u32((uint32_t*)(dst + 0 * BPS), vreinterpret_u32_u8(dst01_u8), 0);
18    vst1_lane_u32((uint32_t*)(dst + 1 * BPS), vreinterpret_u32_u8(dst01_u8), 1);
19    vst1_lane_u32((uint32_t*)(dst + 2 * BPS), vreinterpret_u32_u8(dst23_u8), 0);
20    vst1_lane_u32((uint32_t*)(dst + 3 * BPS), vreinterpret_u32_u8(dst23_u8), 1);
21  }
22  static WEBP_INLINE void Add4x4_NEON(const int16x8_t row01,
23                                      const int16x8_t row23,
24                                      const uint8_t* const ref,
25                                      uint8_t* const dst) {
26    uint32x2_t dst01 = vdup_n_u32(0);
27    uint32x2_t dst23 = vdup_n_u32(0);
28    dst01 = vld1_lane_u32((uint32_t*)(ref + 0 * BPS), dst01, 0);
29    dst23 = vld1_lane_u32((uint32_t*)(ref + 2 * BPS), dst23, 0);
30    dst01 = vld1_lane_u32((uint32_t*)(ref + 1 * BPS), dst01, 1);
31    dst23 = vld1_lane_u32((uint32_t*)(ref + 3 * BPS), dst23, 1);
32    {
33      const int16x8_t dst01_s16 = ConvertU8ToS16_NEON(dst01);
34      const int16x8_t dst23_s16 = ConvertU8ToS16_NEON(dst23);
35      const int16x8_t out01 = vrsraq_n_s16(dst01_s16, row01, 3);
36      const int16x8_t out23 = vrsraq_n_s16(dst23_s16, row23, 3);
37      SaturateAndStore4x4_NEON(dst, out01, out23);
38    }
39  }
40  static WEBP_INLINE void Transpose8x2_NEON(const int16x8_t in0,
41                                            const int16x8_t in1,
42                                            int16x8x2_t* const out) {
43    const int16x8x2_t tmp0 = vzipq_s16(in0, in1);   
44    *out = vzipq_s16(tmp0.val[0], tmp0.val[1]);
45  }
46  static WEBP_INLINE void TransformPass_NEON(int16x8x2_t* const rows) {
47    const int16x8_t B1 =
48        vcombine_s16(vget_high_s16(rows->val[0]), vget_high_s16(rows->val[1]));
49    const int16x8_t C0 = vsraq_n_s16(B1, vqdmulhq_n_s16(B1, kC1), 1);
50    const int16x8_t C1 = vqdmulhq_n_s16(B1, kC2);
51    const int16x4_t a = vqadd_s16(vget_low_s16(rows->val[0]),
52                                  vget_low_s16(rows->val[1]));   
53    const int16x4_t b = vqsub_s16(vget_low_s16(rows->val[0]),
54                                  vget_low_s16(rows->val[1]));   
55    const int16x4_t c = vqsub_s16(vget_low_s16(C1), vget_high_s16(C0));
56    const int16x4_t d = vqadd_s16(vget_low_s16(C0), vget_high_s16(C1));
57    const int16x8_t D0 = vcombine_s16(a, b);      
58    const int16x8_t D1 = vcombine_s16(d, c);      
59    const int16x8_t E0 = vqaddq_s16(D0, D1);      
60    const int16x8_t E_tmp = vqsubq_s16(D0, D1);   
61    const int16x8_t E1 = vcombine_s16(vget_high_s16(E_tmp), vget_low_s16(E_tmp));
62    Transpose8x2_NEON(E0, E1, rows);
63  }
64  static void ITransformOne_NEON(const uint8_t* ref,
65                                 const int16_t* in, uint8_t* dst) {
66    int16x8x2_t rows;
67    INIT_VECTOR2(rows, vld1q_s16(in + 0), vld1q_s16(in + 8));
68    TransformPass_NEON(&rows);
69    TransformPass_NEON(&rows);
70    Add4x4_NEON(rows.val[0], rows.val[1], ref, dst);
71  }
72  #else
73  static void ITransformOne_NEON(const uint8_t* ref,
74                                 const int16_t* in, uint8_t* dst) {
75    const int kBPS = BPS;
76    const int16_t kC1C2[] = { kC1, kC2, 0, 0 };
77    __asm__ volatile (
78      "vld1.16         {q1, q2}, [%[in]]           \n"
79      "vld1.16         {d0}, [%[kC1C2]]            \n"
80      "vswp            d3, d4                      \n"
81      "vqdmulh.s16     q8, q2, d0[0]               \n"
82      "vqdmulh.s16     q9, q2, d0[1]               \n"
83      "vqadd.s16       d22, d2, d3                 \n"
84      "vqsub.s16       d23, d2, d3                 \n"
85      "vshr.s16        q8, q8, #1                  \n"
86      "vqadd.s16       q8, q2, q8                  \n"
87      "vqsub.s16       d20, d18, d17               \n"
88      "vqadd.s16       d21, d19, d16               \n"
89      "vqadd.s16       d2, d22, d21                \n"
90      "vqadd.s16       d3, d23, d20                \n"
91      "vqsub.s16       d4, d23, d20                \n"
92      "vqsub.s16       d5, d22, d21                \n"
93      "vzip.16         q1, q2                      \n"
94      "vzip.16         q1, q2                      \n"
95      "vswp            d3, d4                      \n"
96      "vqdmulh.s16     q8, q2, d0[0]               \n"
97      "vqdmulh.s16     q9, q2, d0[1]               \n"
98      "vqadd.s16       d22, d2, d3                 \n"
99      "vqsub.s16       d23, d2, d3                 \n"
100      "vshr.s16        q8, q8, #1                  \n"
101      "vqadd.s16       q8, q2, q8                  \n"
102      "vqsub.s16       d20, d18, d17               \n"
103      "vqadd.s16       d21, d19, d16               \n"
104      "vqadd.s16       d2, d22, d21                \n"
105      "vqadd.s16       d3, d23, d20                \n"
106      "vqsub.s16       d4, d23, d20                \n"
107      "vqsub.s16       d5, d22, d21                \n"
108      "vld1.32         d6[0], [%[ref]], %[kBPS]    \n"
109      "vld1.32         d6[1], [%[ref]], %[kBPS]    \n"
110      "vld1.32         d7[0], [%[ref]], %[kBPS]    \n"
111      "vld1.32         d7[1], [%[ref]], %[kBPS]    \n"
112      "sub         %[ref], %[ref], %[kBPS], lsl #2 \n"
113      "vrshr.s16       d2, d2, #3                  \n"
114      "vrshr.s16       d3, d3, #3                  \n"
115      "vrshr.s16       d4, d4, #3                  \n"
116      "vrshr.s16       d5, d5, #3                  \n"
117      "vzip.16         q1, q2                      \n"
118      "vzip.16         q1, q2                      \n"
119      "vmovl.u8        q8, d6                      \n"
120      "vmovl.u8        q9, d7                      \n"
121      "vqadd.s16       q1, q1, q8                  \n"
122      "vqadd.s16       q2, q2, q9                  \n"
123      "vqmovun.s16     d0, q1                      \n"
124      "vqmovun.s16     d1, q2                      \n"
125      "vst1.32         d0[0], [%[dst]], %[kBPS]    \n"
126      "vst1.32         d0[1], [%[dst]], %[kBPS]    \n"
127      "vst1.32         d1[0], [%[dst]], %[kBPS]    \n"
128      "vst1.32         d1[1], [%[dst]]             \n"
129      : [in] "+r"(in), [dst] "+r"(dst)               
130      : [kBPS] "r"(kBPS), [kC1C2] "r"(kC1C2), [ref] "r"(ref)  
131      : "memory", "q0", "q1", "q2", "q8", "q9", "q10", "q11"  
132    );
133  }
134  #endif    
135  static void ITransform_NEON(const uint8_t* ref,
136                              const int16_t* in, uint8_t* dst, int do_two) {
137    ITransformOne_NEON(ref, in, dst);
138    if (do_two) {
139      ITransformOne_NEON(ref + 4, in + 16, dst + 4);
140    }
141  }
142  static uint8x16_t Load4x4_NEON(const uint8_t* src) {
143    uint32x4_t out = vdupq_n_u32(0);
144    out = vld1q_lane_u32((const uint32_t*)(src + 0 * BPS), out, 0);
145    out = vld1q_lane_u32((const uint32_t*)(src + 1 * BPS), out, 1);
146    out = vld1q_lane_u32((const uint32_t*)(src + 2 * BPS), out, 2);
147    out = vld1q_lane_u32((const uint32_t*)(src + 3 * BPS), out, 3);
148    return vreinterpretq_u8_u32(out);
149  }
150  #if defined(WEBP_USE_INTRINSICS)
151  static WEBP_INLINE void Transpose4x4_S16_NEON(const int16x4_t A,
152                                                const int16x4_t B,
153                                                const int16x4_t C,
154                                                const int16x4_t D,
155                                                int16x8_t* const out01,
156                                                int16x8_t* const out32) {
157    const int16x4x2_t AB = vtrn_s16(A, B);
158    const int16x4x2_t CD = vtrn_s16(C, D);
159    const int32x2x2_t tmp02 = vtrn_s32(vreinterpret_s32_s16(AB.val[0]),
160                                       vreinterpret_s32_s16(CD.val[0]));
161    const int32x2x2_t tmp13 = vtrn_s32(vreinterpret_s32_s16(AB.val[1]),
162                                       vreinterpret_s32_s16(CD.val[1]));
163    *out01 = vreinterpretq_s16_s64(
164        vcombine_s64(vreinterpret_s64_s32(tmp02.val[0]),
165                     vreinterpret_s64_s32(tmp13.val[0])));
166    *out32 = vreinterpretq_s16_s64(
167        vcombine_s64(vreinterpret_s64_s32(tmp13.val[1]),
168                     vreinterpret_s64_s32(tmp02.val[1])));
169  }
170  static WEBP_INLINE int16x8_t DiffU8ToS16_NEON(const uint8x8_t a,
171                                                const uint8x8_t b) {
172    return vreinterpretq_s16_u16(vsubl_u8(a, b));
173  }
174  static void FTransform_NEON(const uint8_t* src, const uint8_t* ref,
175                              int16_t* out) {
176    int16x8_t d0d1, d3d2;   
177    {
178      const uint8x16_t S0 = Load4x4_NEON(src);
179      const uint8x16_t R0 = Load4x4_NEON(ref);
180      const int16x8_t D0D1 = DiffU8ToS16_NEON(vget_low_u8(S0), vget_low_u8(R0));
181      const int16x8_t D2D3 = DiffU8ToS16_NEON(vget_high_u8(S0), vget_high_u8(R0));
182      const int16x4_t D0 = vget_low_s16(D0D1);
183      const int16x4_t D1 = vget_high_s16(D0D1);
184      const int16x4_t D2 = vget_low_s16(D2D3);
185      const int16x4_t D3 = vget_high_s16(D2D3);
186      Transpose4x4_S16_NEON(D0, D1, D2, D3, &d0d1, &d3d2);
187    }
188    {    
189      const int32x4_t kCst937 = vdupq_n_s32(937);
190      const int32x4_t kCst1812 = vdupq_n_s32(1812);
191      const int16x8_t a0a1 = vaddq_s16(d0d1, d3d2);   
192      const int16x8_t a3a2 = vsubq_s16(d0d1, d3d2);   
193      const int16x8_t a0a1_2 = vshlq_n_s16(a0a1, 3);
194      const int16x4_t tmp0 = vadd_s16(vget_low_s16(a0a1_2),
195                                      vget_high_s16(a0a1_2));
196      const int16x4_t tmp2 = vsub_s16(vget_low_s16(a0a1_2),
197                                      vget_high_s16(a0a1_2));
198      const int32x4_t a3_2217 = vmull_n_s16(vget_low_s16(a3a2), 2217);
199      const int32x4_t a2_2217 = vmull_n_s16(vget_high_s16(a3a2), 2217);
200      const int32x4_t a2_p_a3 = vmlal_n_s16(a2_2217, vget_low_s16(a3a2), 5352);
201      const int32x4_t a3_m_a2 = vmlsl_n_s16(a3_2217, vget_high_s16(a3a2), 5352);
202      const int16x4_t tmp1 = vshrn_n_s32(vaddq_s32(a2_p_a3, kCst1812), 9);
203      const int16x4_t tmp3 = vshrn_n_s32(vaddq_s32(a3_m_a2, kCst937), 9);
204      Transpose4x4_S16_NEON(tmp0, tmp1, tmp2, tmp3, &d0d1, &d3d2);
205    }
206    {    
207      const int32x4_t kCst12000 = vdupq_n_s32(12000 + (1 << 16));
208      const int32x4_t kCst51000 = vdupq_n_s32(51000);
209      const int16x8_t a0a1 = vaddq_s16(d0d1, d3d2);   
210      const int16x8_t a3a2 = vsubq_s16(d0d1, d3d2);   
211      const int16x4_t a0_k7 = vadd_s16(vget_low_s16(a0a1), vdup_n_s16(7));
212      const int16x4_t out0 = vshr_n_s16(vadd_s16(a0_k7, vget_high_s16(a0a1)), 4);
213      const int16x4_t out2 = vshr_n_s16(vsub_s16(a0_k7, vget_high_s16(a0a1)), 4);
214      const int32x4_t a3_2217 = vmull_n_s16(vget_low_s16(a3a2), 2217);
215      const int32x4_t a2_2217 = vmull_n_s16(vget_high_s16(a3a2), 2217);
216      const int32x4_t a2_p_a3 = vmlal_n_s16(a2_2217, vget_low_s16(a3a2), 5352);
217      const int32x4_t a3_m_a2 = vmlsl_n_s16(a3_2217, vget_high_s16(a3a2), 5352);
218      const int16x4_t tmp1 = vaddhn_s32(a2_p_a3, kCst12000);
219      const int16x4_t out3 = vaddhn_s32(a3_m_a2, kCst51000);
220      const int16x4_t a3_eq_0 =
221          vreinterpret_s16_u16(vceq_s16(vget_low_s16(a3a2), vdup_n_s16(0)));
222      const int16x4_t out1 = vadd_s16(tmp1, a3_eq_0);
223      vst1_s16(out +  0, out0);
224      vst1_s16(out +  4, out1);
225      vst1_s16(out +  8, out2);
226      vst1_s16(out + 12, out3);
227    }
228  }
229  #else
230  static const int16_t kCoeff16[] = {
231    5352,  5352,  5352, 5352, 2217,  2217,  2217, 2217
232  };
233  static const int32_t kCoeff32[] = {
234     1812,  1812,  1812,  1812,
235      937,   937,   937,   937,
236    12000, 12000, 12000, 12000,
237    51000, 51000, 51000, 51000
238  };
239  static void FTransform_NEON(const uint8_t* src, const uint8_t* ref,
240                              int16_t* out) {
241    const int kBPS = BPS;
242    const uint8_t* src_ptr = src;
243    const uint8_t* ref_ptr = ref;
244    const int16_t* coeff16 = kCoeff16;
245    const int32_t* coeff32 = kCoeff32;
246    __asm__ volatile (
247      "vld1.8 {d8},  [%[src_ptr]], %[kBPS]      \n"
248      "vld1.8 {d10}, [%[src_ptr]], %[kBPS]      \n"
249      "vld1.8 {d9},  [%[src_ptr]], %[kBPS]      \n"
250      "vld1.8 {d11}, [%[src_ptr]]               \n"
251      "vld1.8 {d12}, [%[ref_ptr]], %[kBPS]      \n"
252      "vld1.8 {d14}, [%[ref_ptr]], %[kBPS]      \n"
253      "vld1.8 {d13}, [%[ref_ptr]], %[kBPS]      \n"
254      "vld1.8 {d15}, [%[ref_ptr]]               \n"
255      "vtrn.32     q4, q5                       \n"
256      "vtrn.32     q6, q7                       \n"
257      "vsubl.u8    q0, d8, d12                  \n"
258      "vsubl.u8    q1, d9, d13                  \n"
259      "vld1.16     {q8}, [%[coeff16]]           \n"
260      "vld1.32     {q9, q10}, [%[coeff32]]!     \n"
261      "vld1.32     {q11,q12}, [%[coeff32]]      \n"
262      "vtrn.32         d0, d2                   \n"
263      "vtrn.32         d1, d3                   \n"
264      "vtrn.16         d0, d1                   \n"
265      "vtrn.16         d2, d3                   \n"
266      "vadd.s16        d4, d0, d3               \n" 
267      "vadd.s16        d5, d1, d2               \n" 
268      "vsub.s16        d6, d1, d2               \n" 
269      "vsub.s16        d7, d0, d3               \n" 
270      "vadd.s16        d0, d4, d5               \n" 
271      "vshl.s16        d0, d0, #3               \n" 
272      "vsub.s16        d2, d4, d5               \n" 
273      "vshl.s16        d2, d2, #3               \n" 
274      "vmlal.s16       q9, d7, d16              \n" 
275      "vmlal.s16       q10, d7, d17             \n" 
276      "vmlal.s16       q9, d6, d17              \n" 
277      "vmlsl.s16       q10, d6, d16             \n" 
278      "vshrn.s32       d1, q9, #9               \n"
279      "vshrn.s32       d3, q10, #9              \n"
280      "vtrn.32         d0, d2                   \n"
281      "vtrn.32         d1, d3                   \n"
282      "vtrn.16         d0, d1                   \n"
283      "vtrn.16         d2, d3                   \n"
284      "vmov.s16        d26, #7                  \n"
285      "vadd.s16        d4, d0, d3               \n" 
286      "vadd.s16        d5, d1, d2               \n" 
287      "vsub.s16        d6, d1, d2               \n" 
288      "vadd.s16        d4, d4, d26              \n" 
289      "vsub.s16        d7, d0, d3               \n" 
290      "vadd.s16        d0, d4, d5               \n" 
291      "vsub.s16        d2, d4, d5               \n" 
292      "vmlal.s16       q11, d7, d16             \n" 
293      "vmlal.s16       q12, d7, d17             \n" 
294      "vceq.s16        d4, d7, #0               \n"
295      "vshr.s16        d0, d0, #4               \n"
296      "vshr.s16        d2, d2, #4               \n"
297      "vmlal.s16       q11, d6, d17             \n" 
298      "vmlsl.s16       q12, d6, d16             \n" 
299      "vmvn            d4, d4                   \n" 
300      "vshrn.s32       d1, q11, #16             \n"
301      "vsub.s16        d1, d1, d4               \n"
302      "vshrn.s32       d3, q12, #16             \n"
303      "vst1.16         {q0, q1}, [%[out]]   \n"
304      : [src_ptr] "+r"(src_ptr), [ref_ptr] "+r"(ref_ptr),
305        [coeff32] "+r"(coeff32)          
306      : [kBPS] "r"(kBPS), [coeff16] "r"(coeff16),
307        [out] "r"(out)                   
308      : "memory", "q0", "q1", "q2", "q3", "q4", "q5", "q6", "q7", "q8", "q9",
309        "q10", "q11", "q12", "q13"       
310    );
<span onclick='openModal()' class='match'>311  }
312  #endif
313  #define LOAD_LANE_16b(VALUE, LANE) do {             \
314    (VALUE) = vld1_lane_s16(src, (VALUE), (LANE));    \
315    src += stride;                                    \
316  } while (0)
317  static void FTransformWHT_NEON(const int16_t* src, int16_t* out) {
318    const int stride = 16;
319    const int16x4_t zero = vdup_n_s16(0);
</span>320    int32x4x4_t tmp0;
321    int16x4x4_t in;
322    INIT_VECTOR4(in, zero, zero, zero, zero);
323    LOAD_LANE_16b(in.val[0], 0);
324    LOAD_LANE_16b(in.val[1], 0);
325    LOAD_LANE_16b(in.val[2], 0);
326    LOAD_LANE_16b(in.val[3], 0);
327    LOAD_LANE_16b(in.val[0], 1);
328    LOAD_LANE_16b(in.val[1], 1);
329    LOAD_LANE_16b(in.val[2], 1);
330    LOAD_LANE_16b(in.val[3], 1);
331    LOAD_LANE_16b(in.val[0], 2);
332    LOAD_LANE_16b(in.val[1], 2);
333    LOAD_LANE_16b(in.val[2], 2);
334    LOAD_LANE_16b(in.val[3], 2);
335    LOAD_LANE_16b(in.val[0], 3);
336    LOAD_LANE_16b(in.val[1], 3);
337    LOAD_LANE_16b(in.val[2], 3);
338    LOAD_LANE_16b(in.val[3], 3);
339    {
340      const int32x4_t a0 = vaddl_s16(in.val[0], in.val[2]);
341      const int32x4_t a1 = vaddl_s16(in.val[1], in.val[3]);
342      const int32x4_t a2 = vsubl_s16(in.val[1], in.val[3]);
343      const int32x4_t a3 = vsubl_s16(in.val[0], in.val[2]);
344      tmp0.val[0] = vaddq_s32(a0, a1);
345      tmp0.val[1] = vaddq_s32(a3, a2);
346      tmp0.val[2] = vsubq_s32(a3, a2);
347      tmp0.val[3] = vsubq_s32(a0, a1);
348    }
349    {
350      const int32x4x4_t tmp1 = Transpose4x4_NEON(tmp0);
351      const int32x4_t a0 = vaddq_s32(tmp1.val[0], tmp1.val[2]);
352      const int32x4_t a1 = vaddq_s32(tmp1.val[1], tmp1.val[3]);
353      const int32x4_t a2 = vsubq_s32(tmp1.val[1], tmp1.val[3]);
354      const int32x4_t a3 = vsubq_s32(tmp1.val[0], tmp1.val[2]);
355      const int32x4_t b0 = vhaddq_s32(a0, a1);  
356      const int32x4_t b1 = vhaddq_s32(a3, a2);  
357      const int32x4_t b2 = vhsubq_s32(a3, a2);  
358      const int32x4_t b3 = vhsubq_s32(a0, a1);  
359      const int16x4_t out0 = vmovn_s32(b0);
360      const int16x4_t out1 = vmovn_s32(b1);
361      const int16x4_t out2 = vmovn_s32(b2);
362      const int16x4_t out3 = vmovn_s32(b3);
363      vst1_s16(out +  0, out0);
364      vst1_s16(out +  4, out1);
365      vst1_s16(out +  8, out2);
366      vst1_s16(out + 12, out3);
367    }
368  }
369  #undef LOAD_LANE_16b
370  static WEBP_INLINE int16x8x4_t DistoTranspose4x4S16_NEON(int16x8x4_t q4_in) {
371    const int16x8x2_t q2_tmp0 = vtrnq_s16(q4_in.val[0], q4_in.val[1]);
372    const int16x8x2_t q2_tmp1 = vtrnq_s16(q4_in.val[2], q4_in.val[3]);
373    const int32x4x2_t q2_tmp2 = vtrnq_s32(vreinterpretq_s32_s16(q2_tmp0.val[0]),
374                                          vreinterpretq_s32_s16(q2_tmp1.val[0]));
375    const int32x4x2_t q2_tmp3 = vtrnq_s32(vreinterpretq_s32_s16(q2_tmp0.val[1]),
376                                          vreinterpretq_s32_s16(q2_tmp1.val[1]));
377    q4_in.val[0] = vreinterpretq_s16_s32(q2_tmp2.val[0]);
378    q4_in.val[2] = vreinterpretq_s16_s32(q2_tmp2.val[1]);
379    q4_in.val[1] = vreinterpretq_s16_s32(q2_tmp3.val[0]);
380    q4_in.val[3] = vreinterpretq_s16_s32(q2_tmp3.val[1]);
381    return q4_in;
382  }
383  static WEBP_INLINE int16x8x4_t DistoHorizontalPass_NEON(
384      const int16x8x4_t q4_in) {
385    const int16x8_t q_a0 = vaddq_s16(q4_in.val[0], q4_in.val[2]);
386    const int16x8_t q_a1 = vaddq_s16(q4_in.val[1], q4_in.val[3]);
387    const int16x8_t q_a3 = vsubq_s16(q4_in.val[0], q4_in.val[2]);
388    const int16x8_t q_a2 = vsubq_s16(q4_in.val[1], q4_in.val[3]);
389    int16x8x4_t q4_out;
390    INIT_VECTOR4(q4_out,
391                 vabsq_s16(vaddq_s16(q_a0, q_a1)),
392                 vabsq_s16(vaddq_s16(q_a3, q_a2)),
393                 vabdq_s16(q_a3, q_a2), vabdq_s16(q_a0, q_a1));
394    return q4_out;
395  }
396  static WEBP_INLINE int16x8x4_t DistoVerticalPass_NEON(const uint8x8x4_t q4_in) {
397    const int16x8_t q_a0 = vreinterpretq_s16_u16(vaddl_u8(q4_in.val[0],
398                                                          q4_in.val[2]));
399    const int16x8_t q_a1 = vreinterpretq_s16_u16(vaddl_u8(q4_in.val[1],
400                                                          q4_in.val[3]));
401    const int16x8_t q_a2 = vreinterpretq_s16_u16(vsubl_u8(q4_in.val[1],
402                                                          q4_in.val[3]));
403    const int16x8_t q_a3 = vreinterpretq_s16_u16(vsubl_u8(q4_in.val[0],
404                                                          q4_in.val[2]));
405    int16x8x4_t q4_out;
406    INIT_VECTOR4(q4_out,
407                 vaddq_s16(q_a0, q_a1), vaddq_s16(q_a3, q_a2),
408                 vsubq_s16(q_a3, q_a2), vsubq_s16(q_a0, q_a1));
409    return q4_out;
410  }
411  static WEBP_INLINE int16x4x4_t DistoLoadW_NEON(const uint16_t* w) {
412    const uint16x8_t q_w07 = vld1q_u16(&w[0]);
413    const uint16x8_t q_w8f = vld1q_u16(&w[8]);
414    int16x4x4_t d4_w;
415    INIT_VECTOR4(d4_w,
416                 vget_low_s16(vreinterpretq_s16_u16(q_w07)),
417                 vget_high_s16(vreinterpretq_s16_u16(q_w07)),
418                 vget_low_s16(vreinterpretq_s16_u16(q_w8f)),
419                 vget_high_s16(vreinterpretq_s16_u16(q_w8f)));
420    return d4_w;
421  }
422  static WEBP_INLINE int32x2_t DistoSum_NEON(const int16x8x4_t q4_in,
423                                             const int16x4x4_t d4_w) {
424    int32x2_t d_sum;
425    int32x4_t q_sum0 = vmull_s16(d4_w.val[0], vget_low_s16(q4_in.val[0]));
426    int32x4_t q_sum1 = vmull_s16(d4_w.val[1], vget_low_s16(q4_in.val[1]));
427    int32x4_t q_sum2 = vmull_s16(d4_w.val[2], vget_low_s16(q4_in.val[2]));
428    int32x4_t q_sum3 = vmull_s16(d4_w.val[3], vget_low_s16(q4_in.val[3]));
429    q_sum0 = vmlsl_s16(q_sum0, d4_w.val[0], vget_high_s16(q4_in.val[0]));
430    q_sum1 = vmlsl_s16(q_sum1, d4_w.val[1], vget_high_s16(q4_in.val[1]));
431    q_sum2 = vmlsl_s16(q_sum2, d4_w.val[2], vget_high_s16(q4_in.val[2]));
432    q_sum3 = vmlsl_s16(q_sum3, d4_w.val[3], vget_high_s16(q4_in.val[3]));
433    q_sum0 = vaddq_s32(q_sum0, q_sum1);
434    q_sum2 = vaddq_s32(q_sum2, q_sum3);
435    q_sum2 = vaddq_s32(q_sum0, q_sum2);
436    d_sum = vpadd_s32(vget_low_s32(q_sum2), vget_high_s32(q_sum2));
437    d_sum = vpadd_s32(d_sum, d_sum);
438    return d_sum;
439  }
440  #define LOAD_LANE_32b(src, VALUE, LANE) \
441      (VALUE) = vld1_lane_u32((const uint32_t*)(src), (VALUE), (LANE))
442  static int Disto4x4_NEON(const uint8_t* const a, const uint8_t* const b,
443                           const uint16_t* const w) {
444    uint32x2_t d_in_ab_0123 = vdup_n_u32(0);
445    uint32x2_t d_in_ab_4567 = vdup_n_u32(0);
446    uint32x2_t d_in_ab_89ab = vdup_n_u32(0);
447    uint32x2_t d_in_ab_cdef = vdup_n_u32(0);
448    uint8x8x4_t d4_in;
449    LOAD_LANE_32b(a + 0 * BPS, d_in_ab_0123, 0);
450    LOAD_LANE_32b(a + 1 * BPS, d_in_ab_4567, 0);
451    LOAD_LANE_32b(a + 2 * BPS, d_in_ab_89ab, 0);
452    LOAD_LANE_32b(a + 3 * BPS, d_in_ab_cdef, 0);
453    LOAD_LANE_32b(b + 0 * BPS, d_in_ab_0123, 1);
454    LOAD_LANE_32b(b + 1 * BPS, d_in_ab_4567, 1);
455    LOAD_LANE_32b(b + 2 * BPS, d_in_ab_89ab, 1);
456    LOAD_LANE_32b(b + 3 * BPS, d_in_ab_cdef, 1);
457    INIT_VECTOR4(d4_in,
458                 vreinterpret_u8_u32(d_in_ab_0123),
459                 vreinterpret_u8_u32(d_in_ab_4567),
460                 vreinterpret_u8_u32(d_in_ab_89ab),
461                 vreinterpret_u8_u32(d_in_ab_cdef));
462    {
463      const int16x8x4_t q4_v = DistoVerticalPass_NEON(d4_in);
464      const int16x4x4_t d4_w = DistoLoadW_NEON(w);
465      const int16x8x4_t q4_t = DistoTranspose4x4S16_NEON(q4_v);
466      const int16x8x4_t q4_h = DistoHorizontalPass_NEON(q4_t);
467      int32x2_t d_sum = DistoSum_NEON(q4_h, d4_w);
468      d_sum = vabs_s32(d_sum);
469      d_sum = vshr_n_s32(d_sum, 5);
470      return vget_lane_s32(d_sum, 0);
471    }
472  }
473  #undef LOAD_LANE_32b
474  static int Disto16x16_NEON(const uint8_t* const a, const uint8_t* const b,
475                             const uint16_t* const w) {
476    int D = 0;
477    int x, y;
478    for (y = 0; y < 16 * BPS; y += 4 * BPS) {
479      for (x = 0; x < 16; x += 4) {
480        D += Disto4x4_NEON(a + x + y, b + x + y, w);
481      }
482    }
483    return D;
484  }
485  static void CollectHistogram_NEON(const uint8_t* ref, const uint8_t* pred,
486                                    int start_block, int end_block,
487                                    VP8Histogram* const histo) {
488    const uint16x8_t max_coeff_thresh = vdupq_n_u16(MAX_COEFF_THRESH);
489    int j;
490    int distribution[MAX_COEFF_THRESH + 1] = { 0 };
491    for (j = start_block; j < end_block; ++j) {
492      int16_t out[16];
493      FTransform_NEON(ref + VP8DspScan[j], pred + VP8DspScan[j], out);
494      {
495        int k;
496        const int16x8_t a0 = vld1q_s16(out + 0);
497        const int16x8_t b0 = vld1q_s16(out + 8);
498        const uint16x8_t a1 = vreinterpretq_u16_s16(vabsq_s16(a0));
499        const uint16x8_t b1 = vreinterpretq_u16_s16(vabsq_s16(b0));
500        const uint16x8_t a2 = vshrq_n_u16(a1, 3);
501        const uint16x8_t b2 = vshrq_n_u16(b1, 3);
502        const uint16x8_t a3 = vminq_u16(a2, max_coeff_thresh);
503        const uint16x8_t b3 = vminq_u16(b2, max_coeff_thresh);
504        vst1q_s16(out + 0, vreinterpretq_s16_u16(a3));
505        vst1q_s16(out + 8, vreinterpretq_s16_u16(b3));
506        for (k = 0; k < 16; ++k) {
507          ++distribution[out[k]];
508        }
509      }
510    }
511    VP8SetHistogramData(distribution, histo);
512  }
513  static WEBP_INLINE void AccumulateSSE16_NEON(const uint8_t* const a,
514                                               const uint8_t* const b,
515                                               uint32x4_t* const sum) {
516    const uint8x16_t a0 = vld1q_u8(a);
517    const uint8x16_t b0 = vld1q_u8(b);
518    const uint8x16_t abs_diff = vabdq_u8(a0, b0);
519    const uint16x8_t prod1 = vmull_u8(vget_low_u8(abs_diff),
520                                      vget_low_u8(abs_diff));
521    const uint16x8_t prod2 = vmull_u8(vget_high_u8(abs_diff),
522                                      vget_high_u8(abs_diff));
523    const uint32x4_t sum1 = vpaddlq_u16(prod1);
524    const uint32x4_t sum2 = vpaddlq_u16(prod2);
525    *sum = vaddq_u32(*sum, vaddq_u32(sum1, sum2));
526  }
527  static int SumToInt_NEON(uint32x4_t sum) {
528    const uint64x2_t sum2 = vpaddlq_u32(sum);
529    const uint64_t sum3 = vgetq_lane_u64(sum2, 0) + vgetq_lane_u64(sum2, 1);
530    return (int)sum3;
531  }
532  static int SSE16x16_NEON(const uint8_t* a, const uint8_t* b) {
533    uint32x4_t sum = vdupq_n_u32(0);
534    int y;
535    for (y = 0; y < 16; ++y) {
536      AccumulateSSE16_NEON(a + y * BPS, b + y * BPS, &sum);
537    }
538    return SumToInt_NEON(sum);
539  }
540  static int SSE16x8_NEON(const uint8_t* a, const uint8_t* b) {
541    uint32x4_t sum = vdupq_n_u32(0);
542    int y;
543    for (y = 0; y < 8; ++y) {
544      AccumulateSSE16_NEON(a + y * BPS, b + y * BPS, &sum);
545    }
546    return SumToInt_NEON(sum);
547  }
548  static int SSE8x8_NEON(const uint8_t* a, const uint8_t* b) {
549    uint32x4_t sum = vdupq_n_u32(0);
550    int y;
551    for (y = 0; y < 8; ++y) {
552      const uint8x8_t a0 = vld1_u8(a + y * BPS);
553      const uint8x8_t b0 = vld1_u8(b + y * BPS);
554      const uint8x8_t abs_diff = vabd_u8(a0, b0);
555      const uint16x8_t prod = vmull_u8(abs_diff, abs_diff);
556      sum = vpadalq_u16(sum, prod);
557    }
558    return SumToInt_NEON(sum);
559  }
560  static int SSE4x4_NEON(const uint8_t* a, const uint8_t* b) {
561    const uint8x16_t a0 = Load4x4_NEON(a);
562    const uint8x16_t b0 = Load4x4_NEON(b);
563    const uint8x16_t abs_diff = vabdq_u8(a0, b0);
564    const uint16x8_t prod1 = vmull_u8(vget_low_u8(abs_diff),
565                                      vget_low_u8(abs_diff));
566    const uint16x8_t prod2 = vmull_u8(vget_high_u8(abs_diff),
567                                      vget_high_u8(abs_diff));
568    const uint32x4_t sum1 = vpaddlq_u16(prod1);
569    const uint32x4_t sum2 = vpaddlq_u16(prod2);
570    return SumToInt_NEON(vaddq_u32(sum1, sum2));
571  }
572  #if !defined(WORK_AROUND_GCC)
573  static int16x8_t Quantize_NEON(int16_t* const in,
574                                 const VP8Matrix* const mtx, int offset) {
575    const uint16x8_t sharp = vld1q_u16(&mtx->sharpen_[offset]);
576    const uint16x8_t q = vld1q_u16(&mtx->q_[offset]);
577    const uint16x8_t iq = vld1q_u16(&mtx->iq_[offset]);
578    const uint32x4_t bias0 = vld1q_u32(&mtx->bias_[offset + 0]);
579    const uint32x4_t bias1 = vld1q_u32(&mtx->bias_[offset + 4]);
580    const int16x8_t a = vld1q_s16(in + offset);                
581    const uint16x8_t b = vreinterpretq_u16_s16(vabsq_s16(a));  
582    const int16x8_t sign = vshrq_n_s16(a, 15);                 
583    const uint16x8_t c = vaddq_u16(b, sharp);                  
584    const uint32x4_t m0 = vmull_u16(vget_low_u16(c), vget_low_u16(iq));
585    const uint32x4_t m1 = vmull_u16(vget_high_u16(c), vget_high_u16(iq));
586    const uint32x4_t m2 = vhaddq_u32(m0, bias0);
587    const uint32x4_t m3 = vhaddq_u32(m1, bias1);     
588    const uint16x8_t c0 = vcombine_u16(vshrn_n_u32(m2, 16),
589                                       vshrn_n_u32(m3, 16));   
590    const uint16x8_t c1 = vminq_u16(c0, vdupq_n_u16(MAX_LEVEL));
591    const int16x8_t c2 = veorq_s16(vreinterpretq_s16_u16(c1), sign);
592    const int16x8_t c3 = vsubq_s16(c2, sign);                  
593    const int16x8_t c4 = vmulq_s16(c3, vreinterpretq_s16_u16(q));
594    vst1q_s16(in + offset, c4);
595    assert(QFIX == 17);  
596    return c3;
597  }
598  static const uint8_t kShuffles[4][8] = {
599    { 0,   1,  2,  3,  8,  9, 16, 17 },
600    { 10, 11,  4,  5,  6,  7, 12, 13 },
601    { 18, 19, 24, 25, 26, 27, 20, 21 },
602    { 14, 15, 22, 23, 28, 29, 30, 31 }
603  };
604  static int QuantizeBlock_NEON(int16_t in[16], int16_t out[16],
605                                const VP8Matrix* const mtx) {
606    const int16x8_t out0 = Quantize_NEON(in, mtx, 0);
607    const int16x8_t out1 = Quantize_NEON(in, mtx, 8);
608    uint8x8x4_t shuffles;
609  #if defined(__APPLE__) && defined(__aarch64__) && \
610      defined(__apple_build_version__) && (__apple_build_version__< 6020037)
611    uint8x16x2_t all_out;
612    INIT_VECTOR2(all_out, vreinterpretq_u8_s16(out0), vreinterpretq_u8_s16(out1));
613    INIT_VECTOR4(shuffles,
614                 vtbl2q_u8(all_out, vld1_u8(kShuffles[0])),
615                 vtbl2q_u8(all_out, vld1_u8(kShuffles[1])),
616                 vtbl2q_u8(all_out, vld1_u8(kShuffles[2])),
617                 vtbl2q_u8(all_out, vld1_u8(kShuffles[3])));
618  #else
619    uint8x8x4_t all_out;
620    INIT_VECTOR4(all_out,
621                 vreinterpret_u8_s16(vget_low_s16(out0)),
622                 vreinterpret_u8_s16(vget_high_s16(out0)),
623                 vreinterpret_u8_s16(vget_low_s16(out1)),
624                 vreinterpret_u8_s16(vget_high_s16(out1)));
625    INIT_VECTOR4(shuffles,
626                 vtbl4_u8(all_out, vld1_u8(kShuffles[0])),
627                 vtbl4_u8(all_out, vld1_u8(kShuffles[1])),
628                 vtbl4_u8(all_out, vld1_u8(kShuffles[2])),
629                 vtbl4_u8(all_out, vld1_u8(kShuffles[3])));
630  #endif
631    vst1_u8((uint8_t*)(out +  0), shuffles.val[0]);
632    vst1_u8((uint8_t*)(out +  4), shuffles.val[1]);
633    vst1_u8((uint8_t*)(out +  8), shuffles.val[2]);
634    vst1_u8((uint8_t*)(out + 12), shuffles.val[3]);
635    if (*(uint64_t*)(out +  0) != 0) return 1;
636    if (*(uint64_t*)(out +  4) != 0) return 1;
637    if (*(uint64_t*)(out +  8) != 0) return 1;
638    if (*(uint64_t*)(out + 12) != 0) return 1;
639    return 0;
640  }
641  static int Quantize2Blocks_NEON(int16_t in[32], int16_t out[32],
642                                  const VP8Matrix* const mtx) {
643    int nz;
644    nz  = QuantizeBlock_NEON(in + 0 * 16, out + 0 * 16, mtx) << 0;
645    nz |= QuantizeBlock_NEON(in + 1 * 16, out + 1 * 16, mtx) << 1;
646    return nz;
647  }
648  #endif   
649  extern void VP8EncDspInitNEON(void);
650  WEBP_TSAN_IGNORE_FUNCTION void VP8EncDspInitNEON(void) {
651    VP8ITransform = ITransform_NEON;
652    VP8FTransform = FTransform_NEON;
653    VP8FTransformWHT = FTransformWHT_NEON;
654    VP8TDisto4x4 = Disto4x4_NEON;
655    VP8TDisto16x16 = Disto16x16_NEON;
656    VP8CollectHistogram = CollectHistogram_NEON;
657    VP8SSE16x16 = SSE16x16_NEON;
658    VP8SSE16x8 = SSE16x8_NEON;
659    VP8SSE8x8 = SSE8x8_NEON;
660    VP8SSE4x4 = SSE4x4_NEON;
661  #if !defined(WORK_AROUND_GCC)
662    VP8EncQuantizeBlock = QuantizeBlock_NEON;
663    VP8EncQuantize2Blocks = Quantize2Blocks_NEON;
664  #endif
665  }
666  #else  
667  WEBP_DSP_INIT_STUB(VP8EncDspInitNEON)
668  #endif  
</code></pre>
        </div>
    
        <!-- The Modal -->
        <div id="myModal" class="modal">
            <div class="modal-content">
                <span class="row close">&times;</span>
                <div class='row'>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from Adafruit_nRF52_Arduino-MDEwOlJlcG9zaXRvcnk3NDM1NDcyOQ==-flat-queue.c</div>
                    <div class="column" style="font-weight: bold;text-decoration: underline">Fragment from PINRemoteImage-MDEwOlJlcG9zaXRvcnkzOTUzNzEwMw==-flat-enc_neon.c</div>
                </div>
                <div class="column column_space"><pre><code>233  	}
234  #endif &bsol;* configUSE_MUTEXES */
235  #if( ( configUSE_MUTEXES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) )
236  	QueueHandle_t xQueueCreateMutex( const uint8_t ucQueueType )
237  	{
238  	Queue_t *pxNewQueue;
239  	const UBaseType_t uxMutexLength = ( UBaseType_t ) 1, uxMutexSize = ( UBaseType_t ) 0;
</pre></code></div>
                <div class="column column_space"><pre><code>311  }
312  #endif
313  #define LOAD_LANE_16b(VALUE, LANE) do {             \
314    (VALUE) = vld1_lane_s16(src, (VALUE), (LANE));    \
315    src += stride;                                    \
316  } while (0)
317  static void FTransformWHT_NEON(const int16_t* src, int16_t* out) {
318    const int stride = 16;
319    const int16x4_t zero = vdup_n_s16(0);
</pre></code></div>
            </div>
        </div>
        <script>
        // Get the modal
        var modal = document.getElementById("myModal");
        
        // Get the button that opens the modal
        var btn = document.getElementById("myBtn");
        
        // Get the <span> element that closes the modal
        var span = document.getElementsByClassName("close")[0];
        
        // When the user clicks the button, open the modal
        function openModal(){
          modal.style.display = "block";
        }
        
        // When the user clicks on <span> (x), close the modal
        span.onclick = function() {
        modal.style.display = "none";
        }
        
        // When the user clicks anywhere outside of the modal, close it
        window.onclick = function(event) {
        if (event.target == modal) {
        modal.style.display = "none";
        } }
        
        </script>
    </body>
    </html>
    