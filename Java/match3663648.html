<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for NodeService.java & JobLauncher.java</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for NodeService.java & JobLauncher.java
      </h3>
      <h1 align="center">
        5.4%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>NodeService.java (22.64151%)<TH>JobLauncher.java (3.0769231%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match3663648-0.html#0',2,'match3663648-1.html#0',3)" NAME="0">(22-36)<TD><A HREF="javascript:ZweiFrames('match3663648-0.html#0',2,'match3663648-1.html#0',3)" NAME="0">(54-103)</A><TD ALIGN=center><FONT COLOR="#ff0000">12</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>NodeService.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the &quot;License&quot;); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
<A NAME="0"></A>
package org.elasticsearch.node;

<FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match3663648-1.html#0',3,'match3663648-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
import io.crate.common.io.IOUtils;
import org.elasticsearch.indices.IndicesService;
import org.elasticsearch.monitor.MonitorService;
import org.elasticsearch.transport.TransportService;

import java.io.Closeable;
import java.io.IOException;
import java.util.concurrent.TimeUnit;

public class NodeService implements Closeable {

    private final MonitorService monitorService;
    private final IndicesService indicesService;
    private final TransportService transportService</B></FONT>;

    NodeService(MonitorService monitorService, IndicesService indicesService, TransportService transportService) {
        this.monitorService = monitorService;
        this.indicesService = indicesService;
        this.transportService = transportService;
    }

    public MonitorService getMonitorService() {
        return monitorService;
    }

    @Override
    public void close() throws IOException {
        IOUtils.close(indicesService);
    }

    public NodeStats stats() {
        return new NodeStats(transportService.getLocalNode(), System.currentTimeMillis(), monitorService.fsService().stats());
    }

    /**
     * Wait for the node to be effectively closed.
     * @see IndicesService#awaitClose(long, TimeUnit)
     */
    public boolean awaitClose(long timeout, TimeUnit timeUnit) throws InterruptedException {
        return indicesService.awaitClose(timeout, timeUnit);
    }
}
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>JobLauncher.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Crate.io GmbH (&quot;Crate&quot;) under one or more contributor
 * license agreements.  See the NOTICE file distributed with this work for
 * additional information regarding copyright ownership.  Crate licenses
 * this file to you under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.  You may
 * obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
 * License for the specific language governing permissions and limitations
 * under the License.
 *
 * However, if you have executed another commercial license agreement
 * with Crate these terms will supersede the license and you may use the
 * software solely pursuant to the terms of the relevant commercial agreement.
 */

package io.crate.execution.engine;

import io.crate.concurrent.CompletableFutures;
import io.crate.data.CollectingRowConsumer;
import io.crate.data.RowConsumer;
import io.crate.execution.dsl.phases.ExecutionPhase;
import io.crate.execution.dsl.phases.ExecutionPhases;
import io.crate.execution.dsl.phases.NodeOperation;
import io.crate.execution.dsl.phases.NodeOperationGrouper;
import io.crate.execution.dsl.phases.NodeOperationTree;
import io.crate.execution.engine.distribution.StreamBucket;
import io.crate.execution.jobs.DownstreamRXTask;
import io.crate.execution.jobs.InstrumentedIndexSearcher;
import io.crate.execution.jobs.JobSetup;
import io.crate.execution.jobs.PageBucketReceiver;
import io.crate.execution.jobs.RootTask;
import io.crate.execution.jobs.SharedShardContexts;
import io.crate.execution.jobs.Task;
import io.crate.execution.jobs.TasksService;
import io.crate.execution.jobs.kill.TransportKillJobsNodeAction;
import io.crate.execution.jobs.transport.JobRequest;
import io.crate.execution.jobs.transport.TransportJobAction;
import io.crate.metadata.TransactionContext;
import io.crate.profile.ProfilingContext;
import org.elasticsearch.cluster.service.ClusterService;
import io.crate.common.collections.Tuple;
import org.elasticsearch.indices.IndicesService;
import org.elasticsearch.search.profile.query.QueryProfiler;

<A NAME="0"></A>import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
<FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match3663648-0.html#0',2,'match3663648-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>import java.util.List;
import java.util.ListIterator;
import java.util.Map;
import java.util.UUID;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.Executor;
import java.util.function.UnaryOperator;
import java.util.stream.Collectors;


/**
 * Creates and starts local and remote execution jobs using the provided
 * NodeOperationTrees
 * &lt;p&gt;
 * &lt;pre&gt;
 * Direct Result:
 *
 *       N1   N2    N3  // &lt;-- job created via jobRequests using TransportJobAction
 *        ^    ^    ^
 *        |    |    |
 *        +----+----+
 *             |
 *             |        // result is received via DirectResponseFutures
 *             v
 *            N1        // &lt;-- job created via JobSetup.prepareOnHandler
 *             |
 *          BatchConsumer
 *
 *
 * Push Result:
 *                  // result is sent via DistributingConsumer
 *       +-------------------&gt;---+
 *       ^     ^     ^           |
 *       |     |     |           |
 *       N1   N2    N3           |
 *        ^    ^    ^            |
 *        |    |    |            |
 *        +----+----+            |
 *             |                 |  result is received via
 *             |                 v  TransportDistributedResultAction
 *            N1&lt;----------------+  and passed into a DistResultRXTask
 *             |
 *          BatchConsumer
 * &lt;/pre&gt;
 **/
public final class JobLauncher {

    private final TransportJobAction transportJobAction;
    private final TransportKillJobsNodeAction transportKillJobsNodeAction;
    private final List&lt;NodeOperationTree&gt; nodeOperationTrees</B></FONT>;
    private final UUID jobId;
    private final ClusterService clusterService;
    private final JobSetup jobSetup;
    private final TasksService tasksService;
    private final IndicesService indicesService;
    private final boolean enableProfiling;
    private final Executor executor;

    private boolean hasDirectResponse;

    JobLauncher(UUID jobId,
                ClusterService clusterService,
                JobSetup jobSetup,
                TasksService tasksService,
                IndicesService indicesService,
                TransportJobAction transportJobAction,
                TransportKillJobsNodeAction transportKillJobsNodeAction,
                List&lt;NodeOperationTree&gt; nodeOperationTrees,
                boolean enableProfiling,
                Executor executor) {
        this.jobId = jobId;
        this.clusterService = clusterService;
        this.jobSetup = jobSetup;
        this.tasksService = tasksService;
        this.indicesService = indicesService;
        this.transportJobAction = transportJobAction;
        this.transportKillJobsNodeAction = transportKillJobsNodeAction;
        this.nodeOperationTrees = nodeOperationTrees;
        this.enableProfiling = enableProfiling;
        this.executor = executor;

        for (NodeOperationTree nodeOperationTree : nodeOperationTrees) {
            for (NodeOperation nodeOperation : nodeOperationTree.nodeOperations()) {
                if (ExecutionPhases.hasDirectResponseDownstream(nodeOperation.downstreamNodes())) {
                    hasDirectResponse = true;
                    break;
                }
            }
        }
    }

    public void execute(RowConsumer consumer, TransactionContext txnCtx) {
        assert nodeOperationTrees.size() == 1 : &quot;must only have 1 NodeOperationTree for non-bulk operations&quot;;
        NodeOperationTree nodeOperationTree = nodeOperationTrees.get(0);
        Map&lt;String, Collection&lt;NodeOperation&gt;&gt; operationByServer = NodeOperationGrouper.groupByServer(nodeOperationTree.nodeOperations());

        List&lt;ExecutionPhase&gt; handlerPhases = Collections.singletonList(nodeOperationTree.leaf());
        List&lt;RowConsumer&gt; handlerConsumers = Collections.singletonList(consumer);
        try {
            setupTasks(txnCtx, operationByServer, handlerPhases, handlerConsumers);
        } catch (Throwable throwable) {
            consumer.accept(null, throwable);
        }
    }

    public List&lt;CompletableFuture&lt;Long&gt;&gt; executeBulk(TransactionContext txnCtx) {
        Iterable&lt;NodeOperation&gt; nodeOperations = nodeOperationTrees.stream()
            .flatMap(opTree -&gt; opTree.nodeOperations().stream())
            ::iterator;
        Map&lt;String, Collection&lt;NodeOperation&gt;&gt; operationByServer = NodeOperationGrouper.groupByServer(nodeOperations);

        List&lt;ExecutionPhase&gt; handlerPhases = new ArrayList&lt;&gt;(nodeOperationTrees.size());
        List&lt;RowConsumer&gt; handlerConsumers = new ArrayList&lt;&gt;(nodeOperationTrees.size());
        List&lt;CompletableFuture&lt;Long&gt;&gt; results = new ArrayList&lt;&gt;(nodeOperationTrees.size());
        for (NodeOperationTree nodeOperationTree : nodeOperationTrees) {
            CollectingRowConsumer&lt;?, Long&gt; consumer = new CollectingRowConsumer&lt;&gt;(
                Collectors.collectingAndThen(Collectors.summingLong(r -&gt; ((long) r.get(0))), sum -&gt; sum));
            handlerConsumers.add(consumer);
            results.add(consumer.completionFuture());
            handlerPhases.add(nodeOperationTree.leaf());
        }
        try {
            setupTasks(txnCtx, operationByServer, handlerPhases, handlerConsumers);
        } catch (Throwable throwable) {
            return Collections.singletonList(CompletableFuture.failedFuture(throwable));
        }
        return results;
    }

    private void setupTasks(TransactionContext txnCtx,
                            Map&lt;String, Collection&lt;NodeOperation&gt;&gt; operationByServer,
                            List&lt;ExecutionPhase&gt; handlerPhases,
                            List&lt;RowConsumer&gt; handlerConsumers) throws Throwable {
        assert handlerPhases.size() == handlerConsumers.size() : &quot;handlerPhases size must match handlerConsumers size&quot;;

        String localNodeId = clusterService.localNode().getId();
        Collection&lt;NodeOperation&gt; localNodeOperations = operationByServer.remove(localNodeId);
        if (localNodeOperations == null) {
            localNodeOperations = Collections.emptyList();
        }
        // + 1 for localTask which is always created
        InitializationTracker initializationTracker = new InitializationTracker(operationByServer.size() + 1);

        List&lt;Tuple&lt;ExecutionPhase, RowConsumer&gt;&gt; handlerPhaseAndReceiver = createHandlerPhaseAndReceivers(
            handlerPhases, handlerConsumers, initializationTracker);

        RootTask.Builder builder = tasksService.newBuilder(
            jobId,
            txnCtx.sessionSettings().userName(),
            localNodeId,
            operationByServer.keySet()
        );
        SharedShardContexts sharedShardContexts = maybeInstrumentProfiler(builder);
        List&lt;CompletableFuture&lt;StreamBucket&gt;&gt; directResponseFutures = jobSetup.prepareOnHandler(
            txnCtx.sessionSettings(),
            localNodeOperations,
            builder,
            handlerPhaseAndReceiver,
            sharedShardContexts);
        RootTask localTask = tasksService.createTask(builder);

        List&lt;PageBucketReceiver&gt; pageBucketReceivers = getHandlerBucketReceivers(localTask, handlerPhaseAndReceiver);
        int bucketIdx = 0;

        /*
         * If you touch anything here make sure the following tests pass with &gt; 1k iterations:
         *
         * Seed: 112E1807417E925A - testInvalidPatternSyntax
         * Seed: Any              - testRegularSelectWithFewAvailableThreadsShouldNeverGetStuck
         * Seed: CC456FF5004F35D3 - testFailureOfJoinDownstream
         */
        if (!localNodeOperations.isEmpty() &amp;&amp; !directResponseFutures.isEmpty()) {
            assert directResponseFutures.size() == pageBucketReceivers.size() : &quot;directResponses size must match pageBucketReceivers&quot;;
            CompletableFutures.allAsList(directResponseFutures)
                .whenComplete(BucketForwarder.asConsumer(pageBucketReceivers, bucketIdx, initializationTracker));
            bucketIdx++;
            try {
                // initializationTracker for localNodeOperations is triggered via SetBucketCallback

                localTask.start();
            } catch (Throwable t) {
                accountFailureForRemoteOperations(operationByServer, initializationTracker, handlerPhaseAndReceiver, t);
                return;
            }
        } else {
            try {
                localTask.start();
                initializationTracker.jobInitialized();
            } catch (Throwable t) {
                initializationTracker.jobInitializationFailed(t);
                accountFailureForRemoteOperations(operationByServer, initializationTracker, handlerPhaseAndReceiver, t);
                return;
            }
        }
        sendJobRequests(
            txnCtx,
            localNodeId,
            operationByServer,
            pageBucketReceivers,
            handlerPhaseAndReceiver,
            bucketIdx,
            initializationTracker
        );
    }

    private SharedShardContexts maybeInstrumentProfiler(RootTask.Builder builder) {
        if (enableProfiling) {
            var profilers = new ArrayList&lt;QueryProfiler&gt;();
            ProfilingContext profilingContext = new ProfilingContext(profilers);
            builder.profilingContext(profilingContext);
            return new SharedShardContexts(
                indicesService,
                indexSearcher -&gt; {
                    var queryProfiler = new QueryProfiler();
                    profilers.add(queryProfiler);
                    return new InstrumentedIndexSearcher(indexSearcher, queryProfiler);
                }
            );
        } else {
            return new SharedShardContexts(indicesService, UnaryOperator.identity());
        }
    }

    private void accountFailureForRemoteOperations(Map&lt;String, Collection&lt;NodeOperation&gt;&gt; operationByServer,
                                                   InitializationTracker initializationTracker,
                                                   List&lt;Tuple&lt;ExecutionPhase, RowConsumer&gt;&gt; handlerPhaseAndReceiver,
                                                   Throwable t) {
        for (Tuple&lt;ExecutionPhase, RowConsumer&gt; executionPhaseRowReceiverTuple : handlerPhaseAndReceiver) {
            executionPhaseRowReceiverTuple.v2().accept(null, t);
        }
        for (int i = 0; i &lt; operationByServer.size() + 1; i++) {
            initializationTracker.jobInitializationFailed(t);
        }
    }

    private List&lt;Tuple&lt;ExecutionPhase, RowConsumer&gt;&gt; createHandlerPhaseAndReceivers(List&lt;ExecutionPhase&gt; handlerPhases,
                                                                                         List&lt;RowConsumer&gt; handlerReceivers,
                                                                                         InitializationTracker initializationTracker) {
        List&lt;Tuple&lt;ExecutionPhase, RowConsumer&gt;&gt; handlerPhaseAndReceiver = new ArrayList&lt;&gt;();
        ListIterator&lt;RowConsumer&gt; consumerIt = handlerReceivers.listIterator();

        for (ExecutionPhase handlerPhase : handlerPhases) {
            InterceptingRowConsumer interceptingBatchConsumer = new InterceptingRowConsumer(
                jobId,
                consumerIt.next(),
                initializationTracker,
                executor,
                transportKillJobsNodeAction
            );
            handlerPhaseAndReceiver.add(new Tuple&lt;&gt;(handlerPhase, interceptingBatchConsumer));
        }
        return handlerPhaseAndReceiver;
    }

    private void sendJobRequests(TransactionContext txnCtx,
                                 String localNodeId,
                                 Map&lt;String, Collection&lt;NodeOperation&gt;&gt; operationByServer,
                                 List&lt;PageBucketReceiver&gt; pageBucketReceivers,
                                 List&lt;Tuple&lt;ExecutionPhase, RowConsumer&gt;&gt; handlerPhases,
                                 int bucketIdx,
                                 InitializationTracker initializationTracker) {
        for (Map.Entry&lt;String, Collection&lt;NodeOperation&gt;&gt; entry : operationByServer.entrySet()) {
            String serverNodeId = entry.getKey();
            JobRequest request = new JobRequest(
                jobId,
                txnCtx.sessionSettings(),
                localNodeId,
                entry.getValue(),
                enableProfiling);
            if (hasDirectResponse) {
                transportJobAction.execute(serverNodeId, request,
                    BucketForwarder.asActionListener(pageBucketReceivers, bucketIdx, initializationTracker));
            } else {
                transportJobAction.execute(serverNodeId, request, new FailureOnlyResponseListener(handlerPhases, initializationTracker));
            }
            bucketIdx++;
        }
    }

    private List&lt;PageBucketReceiver&gt; getHandlerBucketReceivers(RootTask rootTask,
                                                               List&lt;Tuple&lt;ExecutionPhase, RowConsumer&gt;&gt; handlerPhases) {
        final List&lt;PageBucketReceiver&gt; pageBucketReceivers = new ArrayList&lt;&gt;(handlerPhases.size());
        for (Tuple&lt;ExecutionPhase, ?&gt; handlerPhase : handlerPhases) {
            Task ctx = rootTask.getTaskOrNull(handlerPhase.v1().phaseId());
            if (ctx instanceof DownstreamRXTask) {
                PageBucketReceiver pageBucketReceiver = ((DownstreamRXTask) ctx).getBucketReceiver((byte) 0);
                pageBucketReceivers.add(pageBucketReceiver);
            }
        }
        return pageBucketReceivers;
    }
}
</PRE>
</div>
  </div>
</body>
</html>
