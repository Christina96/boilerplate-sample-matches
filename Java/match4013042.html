<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for BrazilianAnalyzerProvider.java & BackgroundIndexer.java</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for BrazilianAnalyzerProvider.java & BackgroundIndexer.java
      </h3>
      <h1 align="center">
        4.2%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>BrazilianAnalyzerProvider.java (28.125%)<TH>BackgroundIndexer.java (2.2959185%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match4013042-0.html#0',2,'match4013042-1.html#0',3)" NAME="0">(22-32)<TD><A HREF="javascript:ZweiFrames('match4013042-0.html#0',2,'match4013042-1.html#0',3)" NAME="0">(47-58)</A><TD ALIGN=center><FONT COLOR="#ff0000">9</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>BrazilianAnalyzerProvider.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the &quot;License&quot;); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
<A NAME="0"></A>
package org.elasticsearch.analysis.common;

<FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match4013042-1.html#0',3,'match4013042-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>import org.apache.lucene.analysis.CharArraySet;
import org.apache.lucene.analysis.br.BrazilianAnalyzer;
import org.elasticsearch.common.settings.Settings;
import org.elasticsearch.env.Environment;
import org.elasticsearch.index.IndexSettings;
import org.elasticsearch.index.analysis.AbstractIndexAnalyzerProvider;
import org.elasticsearch.index.analysis.Analysis;

public class BrazilianAnalyzerProvider extends AbstractIndexAnalyzerProvider&lt;BrazilianAnalyzer&gt; {

    private final BrazilianAnalyzer analyzer</B></FONT>;

    BrazilianAnalyzerProvider(IndexSettings indexSettings, Environment env, String name, Settings settings) {
        super(indexSettings, name, settings);
        analyzer = new BrazilianAnalyzer(
            Analysis.parseStopWords(env, settings, BrazilianAnalyzer.getDefaultStopSet()),
            Analysis.parseStemExclusion(settings, CharArraySet.EMPTY_SET)
        );
        analyzer.setVersion(version);
    }

    @Override
    public BrazilianAnalyzer get() {
        return this.analyzer;
    }
}
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>BackgroundIndexer.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the &quot;License&quot;); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.elasticsearch.test;

import static org.hamcrest.Matchers.emptyIterable;
import static org.hamcrest.Matchers.equalTo;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Locale;
import java.util.Properties;
import java.util.Random;
import java.util.Set;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicLong;
import java.util.function.Consumer;

import javax.annotation.Nullable;

import com.carrotsearch.randomizedtesting.RandomizedTest;
<A NAME="0"></A>
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
<FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match4013042-0.html#0',2,'match4013042-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>import org.apache.logging.log4j.message.ParameterizedMessage;
import org.apache.logging.log4j.util.Supplier;
import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
import org.junit.Assert;

import io.crate.common.unit.TimeValue;
import io.crate.testing.DataTypeTesting;
import io.crate.types.DataTypes;

public class BackgroundIndexer implements AutoCloseable {

    private final Logger logger = LogManager.getLogger(getClass())</B></FONT>;

    final Thread[] writers;
    final CountDownLatch stopLatch;
    final Collection&lt;Exception&gt; failures = new ArrayList&lt;&gt;();
    final AtomicBoolean stop = new AtomicBoolean(false);
    final AtomicLong idGenerator = new AtomicLong();
    final CountDownLatch startLatch = new CountDownLatch(1);
    final AtomicBoolean hasBudget = new AtomicBoolean(false); // when set to true, writers will acquire writes from a semaphore
    final Semaphore availableBudget = new Semaphore(0);
    private final Set&lt;String&gt; ids = ConcurrentCollections.newConcurrentSet();
    private volatile Consumer&lt;Exception&gt; failureAssertion = null;
    final String table;

    volatile int minFieldSize = 10;
    volatile int maxFieldSize = 140;


    /**
     * Start indexing in the background using a given number of threads. Indexing will be paused after numOfDocs docs has
     * been indexed.
     *
     * @param table       table name to write data
     * @param column      column name to write data
     * @param numOfDocs   number of document to index before pausing. Set to -1 to have no limit.
     * @param writerCount number of indexing threads to use
     * @param autoStart   set to true to start indexing as soon as all threads have been created.
     * @param random      random instance to use
     */
    public BackgroundIndexer(String table,
                             String column,
                             String pgUrl,
                             int numOfDocs,
                             int writerCount,
                             boolean autoStart,
                             @Nullable Random random) {
        if (random == null) {
            random = RandomizedTest.getRandom();
        }
        this.table = table;
        writers = new Thread[writerCount];
        stopLatch = new CountDownLatch(writers.length);
        logger.info(&quot;--&gt; creating {} indexing threads (auto start: [{}], numOfDocs: [{}])&quot;, writerCount, autoStart, numOfDocs);
        for (int i = 0; i &lt; writers.length; i++) {
            final int indexerId = i;
            final boolean batch = random.nextBoolean();
            final Random threadRandom = new Random(random.nextLong());
            writers[i] = new Thread() {
                @Override
                public void run() {
                    long id = -1;
                    var textGenerator = DataTypeTesting.getDataGenerator(DataTypes.STRING);
                    Properties properties = new Properties();
                    properties.setProperty(&quot;user&quot;, &quot;crate&quot;);
                    try (Connection conn = DriverManager.getConnection(pgUrl, properties)) {
                        PreparedStatement insertValues = conn.prepareStatement(String.format(
                            Locale.ENGLISH,
                            &quot;insert into %s (id, %s) values (?, ?) returning _id&quot;,
                            table,
                            column
                        ));
                        PreparedStatement insertUnnest = conn.prepareStatement(String.format(
                            Locale.ENGLISH,
                            &quot;insert into %s (id, %s) (select * from unnest(?, ?)) returning _id&quot;,
                            table,
                            column
                        ));
                        startLatch.await();
                        logger.info(&quot;**** starting indexing thread {}&quot;, indexerId);
                        while (!stop.get()) {
                            if (batch) {
                                int batchSize = threadRandom.nextInt(20) + 1;
                                if (hasBudget.get()) {
                                    // always try to get at least one
                                    batchSize = Math.max(Math.min(batchSize, availableBudget.availablePermits()), 1);
                                    if (!availableBudget.tryAcquire(batchSize, 250, TimeUnit.MILLISECONDS)) {
                                        // time out -&gt; check if we have to stop.
                                        continue;
                                    }
                                }
                                Object[] insertIds = new Object[batchSize];
                                Object[] strings = new Object[batchSize];
                                for (int i = 0; i &lt; batchSize; i++) {
                                    insertIds[i] = idGenerator.incrementAndGet();
                                    strings[i] = textGenerator.get();
                                }
                                try {
                                    insertUnnest.setObject(1, conn.createArrayOf(&quot;bigint&quot;, insertIds));
                                    insertUnnest.setObject(2, conn.createArrayOf(&quot;text&quot;, strings));
                                    var result = insertUnnest.executeQuery();
                                    while (result.next()) {
                                        ids.add(result.getString(1));
                                    }
                                } catch (Exception e) {
                                    if (ignoreIndexingFailures == false) {
                                        throw e;
                                    }
                                }
                            } else {
                                if (hasBudget.get() &amp;&amp; !availableBudget.tryAcquire(250, TimeUnit.MILLISECONDS)) {
                                    // time out -&gt; check if we have to stop.
                                    continue;
                                }
                                try {
                                    insertValues.setLong(1, idGenerator.incrementAndGet());
                                    insertValues.setObject(2, textGenerator.get());
                                    var result = insertValues.executeQuery();
                                    while (result.next()) {
                                        ids.add(result.getString(1));
                                    }
                                } catch (Exception e) {
                                    if (ignoreIndexingFailures == false) {
                                        throw e;
                                    }
                                }
                            }
                        }
                        logger.info(&quot;**** done indexing thread {}  stop: {} numDocsIndexed: {}&quot;, indexerId, stop.get(), ids.size());
                    } catch (Exception e) {
                        trackFailure(e);
                        final long docId = id;
                        logger.warn(
                            (Supplier&lt;?&gt;)
                                () -&gt; new ParameterizedMessage(&quot;**** failed indexing thread {} on doc id {}&quot;, indexerId, docId), e);
                    } finally {
                        stopLatch.countDown();
                    }
                }
            };
            writers[i].start();
        }

        if (autoStart) {
            start(numOfDocs);
        }
    }

    private void trackFailure(Exception e) {
        synchronized (failures) {
            if (failureAssertion != null) {
                failureAssertion.accept(e);
            } else {
                failures.add(e);
            }
        }
    }

    private volatile TimeValue timeout = new TimeValue(1, TimeUnit.MINUTES);

    public void setRequestTimeout(TimeValue timeout) {
        this.timeout = timeout;
    }

    private volatile boolean ignoreIndexingFailures;

    public void setIgnoreIndexingFailures(boolean ignoreIndexingFailures) {
        this.ignoreIndexingFailures = ignoreIndexingFailures;
    }

    private void setBudget(int numOfDocs) {
        logger.debug(&quot;updating budget to [{}]&quot;, numOfDocs);
        if (numOfDocs &gt;= 0) {
            hasBudget.set(true);
            availableBudget.release(numOfDocs);
        } else {
            hasBudget.set(false);
        }

    }

    /**
     * Start indexing
     *
     * @param numOfDocs number of document to index before pausing. Set to -1 to have no limit.
     */
    public void start(int numOfDocs) {
        assert !stop.get() : &quot;background indexer can not be started after it has stopped&quot;;
        setBudget(numOfDocs);
        startLatch.countDown();
    }

    /** Pausing indexing by setting current document limit to 0 */
    public void pauseIndexing() {
        availableBudget.drainPermits();
        setBudget(0);
    }

    /**
     * Continue indexing after it has paused.
     *
     * @param numOfDocs number of document to index before pausing. Set to -1 to have no limit.
     */
    public void continueIndexing(int numOfDocs) {
        setBudget(numOfDocs);
    }

    /** Stop all background threads but don't wait for ongoing indexing operations to finish * */
    public void stop() {
        stop.set(true);
    }

    public void awaitStopped() throws InterruptedException {
        assert stop.get();
        Assert.assertThat(&quot;timeout while waiting for indexing threads to stop&quot;, stopLatch.await(6, TimeUnit.MINUTES), equalTo(true));
        if (failureAssertion == null) {
            assertNoFailures();
        }
    }

    /** Stop all background threads and wait for ongoing indexing operations to finish * */
    public void stopAndAwaitStopped() throws InterruptedException {
        stop();
        awaitStopped();
    }

    public long totalIndexedDocs() {
        return ids.size();
    }

    public void assertNoFailures() {
        synchronized (failures) {
            Assert.assertThat(failures, emptyIterable());
        }
    }

    /**
     * Set a consumer that can be used to run assertions on failures during indexing. If such a consumer is set then it disables adding
     * failures to {@link #failures}. Should be used if the number of expected failures during indexing could become very large.
     */
    public void setFailureAssertion(Consumer&lt;Exception&gt; failureAssertion) {
        synchronized (failures) {
            this.failureAssertion = failureAssertion;
            boolean success = false;
            try {
                for (Exception failure : failures) {
                    failureAssertion.accept(failure);
                }
                failures.clear();
                success = true;
            } finally {
                if (success == false) {
                    stop();
                }
            }
        }
    }

    @Override
    public void close() throws Exception {
        stop();
    }

    /**
     * Returns the ID set of all documents indexed by this indexer run
     */
    public Set&lt;String&gt; getIds() {
        return this.ids;
    }
}
</PRE>
</div>
  </div>
</body>
</html>
