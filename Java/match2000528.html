<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for FsDirectoryFactory.java & ExplainPlan.java</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for FsDirectoryFactory.java & ExplainPlan.java
      </h3>
      <h1 align="center">
        10.8%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>FsDirectoryFactory.java (13.571428%)<TH>ExplainPlan.java (9.090909%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match2000528-0.html#0',2,'match2000528-1.html#0',3)" NAME="0">(20-48)<TD><A HREF="javascript:ZweiFrames('match2000528-0.html#0',2,'match2000528-1.html#0',3)" NAME="0">(22-48)</A><TD ALIGN=center><FONT COLOR="#ff0000">26</FONT>
<TR><TD BGCOLOR="#f63526"><FONT COLOR="#f63526">-</FONT><TD><A HREF="javascript:ZweiFrames('match2000528-0.html#1',2,'match2000528-1.html#1',3)" NAME="1">(69-74)<TD><A HREF="javascript:ZweiFrames('match2000528-0.html#1',2,'match2000528-1.html#1',3)" NAME="1">(276-282)</A><TD ALIGN=center><FONT COLOR="#750000">12</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>FsDirectoryFactory.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the &quot;License&quot;); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
<A NAME="0"></A> * under the License.
 */

<FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match2000528-1.html#0',3,'match2000528-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>package org.elasticsearch.index.store;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.HashSet;
import java.util.Set;

import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.store.FileSwitchDirectory;
import org.apache.lucene.store.FilterDirectory;
import org.apache.lucene.store.IOContext;
import org.apache.lucene.store.IndexInput;
import org.apache.lucene.store.LockFactory;
import org.apache.lucene.store.MMapDirectory;
import org.apache.lucene.store.NIOFSDirectory;
import org.apache.lucene.store.NativeFSLockFactory;
import org.apache.lucene.store.SimpleFSDirectory;
import org.apache.lucene.store.SimpleFSLockFactory;
import org.elasticsearch.common.settings.Setting;
import org.elasticsearch.common.settings.Setting.Property;
import org.elasticsearch.index.IndexModule;
import org.elasticsearch.index.IndexSettings;
import org.elasticsearch.index.shard.ShardPath;
import org.elasticsearch.plugins.IndexStorePlugin;

import io.crate.common.io.IOUtils;
import</B></FONT> io.crate.types.DataTypes;

public class FsDirectoryFactory implements IndexStorePlugin.DirectoryFactory {

    public static final Setting&lt;LockFactory&gt; INDEX_LOCK_FACTOR_SETTING = new Setting&lt;&gt;(&quot;index.store.fs.fs_lock&quot;, &quot;native&quot;, (s) -&gt; {
        switch (s) {
            case &quot;native&quot;:
                return NativeFSLockFactory.INSTANCE;
            case &quot;simple&quot;:
                return SimpleFSLockFactory.INSTANCE;
            default:
                throw new IllegalArgumentException(&quot;unrecognized [index.store.fs.fs_lock] \&quot;&quot; + s + &quot;\&quot;: must be native or simple&quot;);
        } // can we set on both - node and index level, some nodes might be running on NFS so they might need simple rather than native
    }, DataTypes.STRING, Property.IndexScope, Property.NodeScope);


    @Override
    public Directory newDirectory(IndexSettings indexSettings, ShardPath path) throws IOException {
<A NAME="1"></A>        final Path location = path.resolveIndex();
        final LockFactory lockFactory = indexSettings.getValue(INDEX_LOCK_FACTOR_SETTING);
        Files.createDirectories(location);
        <FONT color="#f63526"><A HREF="javascript:ZweiFrames('match2000528-1.html#1',3,'match2000528-top.html#1',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>return newFSDirectory(location, lockFactory, indexSettings);
    }


    protected Directory newFSDirectory(Path location, LockFactory lockFactory, IndexSettings indexSettings) throws IOException {
        final String storeType = indexSettings.getSettings</B></FONT>()
            .get(IndexModule.INDEX_STORE_TYPE_SETTING.getKey(), IndexModule.Type.FS.getSettingsKey());
        IndexModule.Type type;
        if (IndexModule.Type.FS.match(storeType)) {
            type = IndexModule.defaultStoreType(
                IndexModule.NODE_STORE_ALLOW_MMAP.getWithFallback(indexSettings.getNodeSettings()));
        } else {
            type = IndexModule.Type.fromSettingsKey(storeType);
        }
        Set&lt;String&gt; preLoadExtensions = new HashSet&lt;&gt;(indexSettings.getValue(IndexModule.INDEX_STORE_PRE_LOAD_SETTING));
        switch (type) {
            case HYBRIDFS:
                // Use Lucene defaults
                final FSDirectory primaryDirectory = FSDirectory.open(location, lockFactory);
                if (primaryDirectory instanceof MMapDirectory) {
                    MMapDirectory mMapDirectory = (MMapDirectory) primaryDirectory;
                    return new HybridDirectory(lockFactory, setPreload(mMapDirectory, lockFactory, preLoadExtensions));
                } else {
                    return primaryDirectory;
                }
            case MMAPFS:
                return setPreload(new MMapDirectory(location, lockFactory), lockFactory, preLoadExtensions);
            case SIMPLEFS:
                return new SimpleFSDirectory(location, lockFactory);
            case NIOFS:
                return new NIOFSDirectory(location, lockFactory);
            default:
                throw new AssertionError(&quot;unexpected built-in store type [&quot; + type + &quot;]&quot;);
        }
    }

    public static MMapDirectory setPreload(MMapDirectory mMapDirectory,
                                           LockFactory lockFactory,
                                           Set&lt;String&gt; preLoadExtensions) throws IOException {
        assert mMapDirectory.getPreload() == false;
        if (preLoadExtensions.isEmpty() == false) {
            if (preLoadExtensions.contains(&quot;*&quot;)) {
                mMapDirectory.setPreload(true);
            } else {
                return new PreLoadMMapDirectory(mMapDirectory, lockFactory, preLoadExtensions);
            }
        }
        return mMapDirectory;
    }

    public static boolean isHybridFs(Directory directory) {
        Directory unwrap = FilterDirectory.unwrap(directory);
        return unwrap instanceof HybridDirectory;
    }

    static final class HybridDirectory extends NIOFSDirectory {

        private final MMapDirectory delegate;


        HybridDirectory(LockFactory lockFactory, MMapDirectory delegate) throws IOException {
            super(delegate.getDirectory(), lockFactory);
            this.delegate = delegate;
        }

        @Override
        public IndexInput openInput(String name, IOContext context) throws IOException {
            if (useDelegate(name)) {
                // we need to do these checks on the outer directory since the inner doesn't know about pending deletes
                ensureOpen();
                ensureCanRead(name);
                // we only use the mmap to open inputs. Everything else is managed by the NIOFSDirectory otherwise
                // we might run into trouble with files that are pendingDelete in one directory but still
                // listed in listAll() from the other. We on the other hand don't want to list files from both dirs
                // and intersect for perf reasons.
                return delegate.openInput(name, context);
            } else {
                return super.openInput(name, context);
            }
        }

        @Override
        public void close() throws IOException {
            IOUtils.close(super::close, delegate);
        }

        boolean useDelegate(String name) {
            String extension = FileSwitchDirectory.getExtension(name);
            switch (extension) {
                // Norms, doc values and term dictionaries are typically performance-sensitive and hot in the page
                // cache, so we use mmap, which provides better performance.
                case &quot;nvd&quot;:
                case &quot;dvd&quot;:
                case &quot;tim&quot;:
                // We want to open the terms index and KD-tree index off-heap to save memory, but this only performs
                // well if using mmap.
                case &quot;tip&quot;:
                // dim files only apply up to lucene 8.x indices. It can be removed once we are in lucene 10
                case &quot;dim&quot;:
                case &quot;kdd&quot;:
                case &quot;kdi&quot;:
                // Compound files are tricky because they store all the information for the segment. Benchmarks
                // suggested that not mapping them hurts performance.
                case &quot;cfs&quot;:
                // MMapDirectory has special logic to read long[] arrays in little-endian order that helps speed
                // up the decoding of postings. The same logic applies to positions (.pos) of offsets (.pay) but we
                // are not mmaping them as queries that leverage positions are more costly and the decoding of postings
                // tends to be less a bottleneck.
                case &quot;doc&quot;:
                    return true;
                // Other files are either less performance-sensitive (e.g. stored field index, norms metadata)
                // or are large and have a random access pattern and mmap leads to page cache trashing
                // (e.g. stored fields and term vectors).
                default:
                    return false;
            }
        }

        MMapDirectory getDelegate() {
            return delegate;
        }
    }


    // TODO it would be nice to share code between PreLoadMMapDirectory and HybridDirectory but due to the nesting aspect of
    // directories here makes it tricky. It would be nice to allow MMAPDirectory to pre-load on a per IndexInput basis.
    static final class PreLoadMMapDirectory extends MMapDirectory {
        private final MMapDirectory delegate;
        private final Set&lt;String&gt; preloadExtensions;

        PreLoadMMapDirectory(MMapDirectory delegate, LockFactory lockFactory, Set&lt;String&gt; preload) throws IOException {
            super(delegate.getDirectory(), lockFactory);
            super.setPreload(false);
            this.delegate = delegate;
            this.delegate.setPreload(true);
            this.preloadExtensions = preload;
            assert getPreload() == false;
        }

        @Override
        public void setPreload(boolean preload) {
            throw new IllegalArgumentException(&quot;can't set preload on a preload-wrapper&quot;);
        }

        @Override
        public IndexInput openInput(String name, IOContext context) throws IOException {
            if (useDelegate(name)) {
                // we need to do these checks on the outer directory since the inner doesn't
                // know about pending deletes
                ensureOpen();
                ensureCanRead(name);
                return delegate.openInput(name, context);
            }
            return super.openInput(name, context);
        }

        @Override
        public synchronized void close() throws IOException {
            IOUtils.close(super::close, delegate);
        }

        boolean useDelegate(String name) {
            final String extension = FileSwitchDirectory.getExtension(name);
            return preloadExtensions.contains(extension);
        }

        MMapDirectory getDelegate() {
            return delegate;
        }
    }
}
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>ExplainPlan.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Crate.io GmbH (&quot;Crate&quot;) under one or more contributor
 * license agreements.  See the NOTICE file distributed with this work for
 * additional information regarding copyright ownership.  Crate licenses
 * this file to you under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.  You may
 * obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
 * License for the specific language governing permissions and limitations
 * under the License.
 *
 * However, if you have executed another commercial license agreement
 * with Crate these terms will supersede the license and you may use the
<A NAME="0"></A> * software solely pursuant to the terms of the relevant commercial agreement.
 */

<FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2000528-0.html#0',2,'match2000528-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>package io.crate.planner.node.management;

import io.crate.action.sql.BaseResultReceiver;
import io.crate.action.sql.RowConsumerToResultReceiver;
import io.crate.common.annotations.VisibleForTesting;
import io.crate.common.collections.MapBuilder;
import io.crate.data.InMemoryBatchIterator;
import io.crate.data.Row;
import io.crate.data.Row1;
import io.crate.data.RowConsumer;
import io.crate.execution.dsl.phases.ExecutionPhase;
import io.crate.execution.dsl.phases.NodeOperation;
import io.crate.execution.dsl.phases.NodeOperationGrouper;
import io.crate.execution.dsl.phases.NodeOperationTree;
import io.crate.execution.engine.profile.TransportCollectProfileNodeAction;
import io.crate.execution.engine.profile.TransportCollectProfileOperation;
import io.crate.execution.support.OneRowActionListener;
import io.crate.planner.DependencyCarrier;
import io.crate.planner.ExecutionPlan;
import io.crate.planner.Plan;
import io.crate.planner.PlanPrinter;
import io.crate.planner.PlannerContext;
import io.crate.planner.operators.LogicalPlan;
import io.crate.planner.operators.LogicalPlanner;
import io.crate.planner.operators.PrintContext;
import io.crate.planner.operators.SubQueryResults;
import</B></FONT> io.crate.planner.statement.CopyFromPlan;
import io.crate.profile.ProfilingContext;
import io.crate.profile.Timer;
import io.crate.types.DataTypes;

import javax.annotation.Nullable;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.Map;
import java.util.Set;
import java.util.TreeMap;
import java.util.UUID;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.function.BiConsumer;

import static io.crate.data.SentinelRow.SENTINEL;

public class ExplainPlan implements Plan {

    public enum Phase {
        Analyze,
        Plan,
        Execute
    }

    private final Plan subPlan;
    @Nullable
    private final ProfilingContext context;

    public ExplainPlan(Plan subExecutionPlan, @Nullable ProfilingContext context) {
        this.subPlan = subExecutionPlan;
        this.context = context;
    }

    public Plan subPlan() {
        return subPlan;
    }

    @Override
    public StatementType type() {
        return StatementType.MANAGEMENT;
    }

    @Override
    public void executeOrFail(DependencyCarrier dependencies,
                              PlannerContext plannerContext,
                              RowConsumer consumer,
                              Row params,
                              SubQueryResults subQueryResults) {
        if (context != null) {
            assert subPlan instanceof LogicalPlan : &quot;subPlan must be a LogicalPlan&quot;;
            LogicalPlan plan = (LogicalPlan) subPlan;
            /**
             * EXPLAIN ANALYZE does not support analyzing {@link io.crate.planner.MultiPhasePlan}s
             */
            if (plan.dependencies().isEmpty()) {
                UUID jobId = plannerContext.jobId();
                BaseResultReceiver resultReceiver = new BaseResultReceiver();
                RowConsumer noopRowConsumer = new RowConsumerToResultReceiver(resultReceiver, 0, t -&gt; {});

                Timer timer = context.createTimer(Phase.Execute.name());
                timer.start();

                NodeOperationTree operationTree = LogicalPlanner.getNodeOperationTree(
                    plan, dependencies, plannerContext, params, subQueryResults);

                resultReceiver.completionFuture()
                    .whenComplete(createResultConsumer(dependencies, consumer, jobId, timer, operationTree));

                LogicalPlanner.executeNodeOpTree(
                    dependencies,
                    plannerContext.transactionContext(),
                    jobId,
                    noopRowConsumer,
                    true,
                    operationTree
                );
            } else {
                consumer.accept(null,
                    new UnsupportedOperationException(&quot;EXPLAIN ANALYZE does not support profiling multi-phase plans, &quot; +
                                                      &quot;such as queries with scalar subselects.&quot;));
            }
        } else {
            if (subPlan instanceof LogicalPlan) {
                PrintContext printContext = new PrintContext();
                ((LogicalPlan) subPlan).print(printContext);
                consumer.accept(InMemoryBatchIterator.of(new Row1(printContext.toString()), SENTINEL), null);
            } else if (subPlan instanceof CopyFromPlan) {
                ExecutionPlan executionPlan = CopyFromPlan.planCopyFromExecution(
                        ((CopyFromPlan) subPlan).copyFrom(),
                        dependencies.clusterService().state().nodes(),
                        plannerContext,
                        params,
                        subQueryResults
                    );
                String planAsJson = DataTypes.STRING.implicitCast(PlanPrinter.objectMap(executionPlan));
                consumer.accept(InMemoryBatchIterator.of(new Row1(planAsJson), SENTINEL), null);
            } else {
                consumer.accept(InMemoryBatchIterator.of(
                    new Row1(&quot;EXPLAIN not supported for &quot; + subPlan.getClass().getSimpleName()), SENTINEL), null);
            }
        }
    }

    private BiConsumer&lt;Void, Throwable&gt; createResultConsumer(DependencyCarrier executor,
                                                             RowConsumer consumer,
                                                             UUID jobId,
                                                             Timer timer,
                                                             NodeOperationTree operationTree) {
        assert context != null : &quot;profilingContext must be available if createResultconsumer is used&quot;;
        return (ignored, t) -&gt; {
            context.stopTimerAndStoreDuration(timer);
            if (t == null) {
                OneRowActionListener&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; actionListener =
                    new OneRowActionListener&lt;&gt;(consumer,
                        resp -&gt; buildResponse(context.getDurationInMSByTimer(), resp, operationTree));
                collectTimingResults(jobId, executor, operationTree.nodeOperations())
                    .whenComplete(actionListener);
            } else {
                consumer.accept(null, t);
            }
        };
    }

    private TransportCollectProfileOperation getRemoteCollectOperation(DependencyCarrier executor, UUID jobId) {
        TransportCollectProfileNodeAction nodeAction = executor.transportActionProvider()
            .transportCollectProfileNodeAction();
        return new TransportCollectProfileOperation(nodeAction, jobId);
    }

    private Row buildResponse(Map&lt;String, Object&gt; apeTimings,
                              Map&lt;String, Map&lt;String, Object&gt;&gt; timingsByNodeId,
                              NodeOperationTree operationTree) {
        MapBuilder&lt;String, Object&gt; mapBuilder = MapBuilder.newMapBuilder();
        apeTimings.forEach(mapBuilder::put);

        // Each node collects the timings for each phase it executes. We want to extract the phases from each node
        // under a dedicated &quot;Phases&quot; key so it's easier for the user to follow the execution.
        // So we'll transform the response from what the nodes send which looks like this:
        //
        // &quot;Execute&quot;: {
        //      &quot;nodeId1&quot;: {&quot;0-collect&quot;: 23, &quot;2-fetchPhase&quot;: 334, &quot;QueryBreakDown&quot;: {...}}
        //      &quot;nodeId2&quot;: {&quot;0-collect&quot;: 12, &quot;2-fetchPhase&quot;: 222, &quot;QueryBreakDown&quot;: {...}}
        //  }
        //
        // To:
        // &quot;Execute&quot;: {
        //      &quot;Phases&quot;: {
        //         &quot;0-collect&quot;: {
        //              &quot;nodes&quot;: {&quot;nodeId1&quot;: 23, &quot;nodeId2&quot;: 12}
        //          },
        //         &quot;2-fetchPhase&quot;: {
        //              &quot;nodes&quot;: {&quot;nodeId1&quot;: 334, &quot;nodeId2&quot;: 222}
        //          }
        //      }
        //      &quot;nodeId1&quot;: {&quot;QueryBreakDown&quot;: {...}}
        //      &quot;nodeId2&quot;: {&quot;QueryBreakDown&quot;: {...}}
        //  }

        Map&lt;String, Object&gt; phasesTimings = extractPhasesTimingsFrom(timingsByNodeId, operationTree);
        Map&lt;String, Map&lt;String, Object&gt;&gt; resultNodeTimings = getNodeTimingsWithoutPhases(phasesTimings.keySet(), timingsByNodeId);
        MapBuilder&lt;String, Object&gt; executionTimingsMap = MapBuilder.newMapBuilder();
        executionTimingsMap.put(&quot;Phases&quot;, phasesTimings);
        resultNodeTimings.forEach(executionTimingsMap::put);
        executionTimingsMap.put(&quot;Total&quot;, apeTimings.get(Phase.Execute.name()));

        mapBuilder.put(Phase.Execute.name(), executionTimingsMap.immutableMap());
        return new Row1(mapBuilder.immutableMap());
    }

    private static Map&lt;String, Object&gt; extractPhasesTimingsFrom(Map&lt;String, Map&lt;String, Object&gt;&gt; timingsByNodeId,
                                                                NodeOperationTree operationTree) {
        Map&lt;String, Object&gt; allPhases = new TreeMap&lt;&gt;();
        for (NodeOperation operation : operationTree.nodeOperations()) {
            ExecutionPhase phase = operation.executionPhase();
            getPhaseTimingsAndAddThemToPhasesMap(phase, timingsByNodeId, allPhases);
        }

        ExecutionPhase leafExecutionPhase = operationTree.leaf();
        getPhaseTimingsAndAddThemToPhasesMap(leafExecutionPhase, timingsByNodeId, allPhases);

        return allPhases;
    }

    private static void getPhaseTimingsAndAddThemToPhasesMap(ExecutionPhase leafExecutionPhase,
                                                             Map&lt;String, Map&lt;String, Object&gt;&gt; timingsByNodeId,
                                                             Map&lt;String, Object&gt; allPhases) {
        String phaseName = ProfilingContext.generateProfilingKey(leafExecutionPhase.phaseId(), leafExecutionPhase.name());
        Map&lt;String, Object&gt; phaseTimingsAcrossNodes = getPhaseTimingsAcrossNodes(phaseName, timingsByNodeId);

        if (!phaseTimingsAcrossNodes.isEmpty()) {
            allPhases.put(phaseName, Map.of(&quot;nodes&quot;, phaseTimingsAcrossNodes));
        }
    }

    private static Map&lt;String, Object&gt; getPhaseTimingsAcrossNodes(String phaseName,
                                                                  Map&lt;String, Map&lt;String, Object&gt;&gt; timingsByNodeId) {
        Map&lt;String, Object&gt; timingsForPhaseAcrossNodes = new HashMap&lt;&gt;();
        for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; nodeToTimingsEntry : timingsByNodeId.entrySet()) {
            Map&lt;String, Object&gt; timingsForNode = nodeToTimingsEntry.getValue();
            if (timingsForNode != null) {
                Object phaseTiming = timingsForNode.get(phaseName);
                if (phaseTiming != null) {
                    String node = nodeToTimingsEntry.getKey();
                    timingsForPhaseAcrossNodes.put(node, phaseTiming);
                }
            }
        }

        return Collections.unmodifiableMap(timingsForPhaseAcrossNodes);
    }

    private static Map&lt;String, Map&lt;String, Object&gt;&gt; getNodeTimingsWithoutPhases(Set&lt;String&gt; phasesNames,
                                                                                Map&lt;String, Map&lt;String, Object&gt;&gt; timingsByNodeId) {
        Map&lt;String, Map&lt;String, Object&gt;&gt; nodeTimingsWithoutPhases = new HashMap&lt;&gt;(timingsByNodeId.size());
        for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; nodeToTimingsEntry : timingsByNodeId.entrySet()) {
            nodeTimingsWithoutPhases.put(nodeToTimingsEntry.getKey(), new HashMap&lt;&gt;(nodeToTimingsEntry.getValue()));
        }

        for (Map&lt;String, Object&gt; timings : nodeTimingsWithoutPhases.values()) {
            for (String phaseToRemove : phasesNames) {
                timings.remove(phaseToRemove);
<A NAME="1"></A>            }
        }

        <FONT color="#f63526"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2000528-0.html#1',2,'match2000528-top.html#1',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>return Collections.unmodifiableMap(nodeTimingsWithoutPhases);
    }

    private CompletableFuture&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; collectTimingResults(UUID jobId,
                                                                                     DependencyCarrier executor,
                                                                                     Collection&lt;NodeOperation&gt; nodeOperations) {
        Set&lt;String&gt; nodeIds = NodeOperationGrouper.groupByServer</B></FONT>(nodeOperations).keySet();

        CompletableFuture&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; resultFuture = new CompletableFuture&lt;&gt;();
        TransportCollectProfileOperation remoteCollectOperation = getRemoteCollectOperation(executor, jobId);

        ConcurrentHashMap&lt;String, Map&lt;String, Object&gt;&gt; timingsByNodeId = new ConcurrentHashMap&lt;&gt;(nodeIds.size());
        boolean needsCollectLocal = !nodeIds.contains(executor.localNodeId());

        AtomicInteger remainingCollectOps = new AtomicInteger(nodeIds.size());
        if (needsCollectLocal) {
            remainingCollectOps.incrementAndGet();
        }

        for (String nodeId : nodeIds) {
            remoteCollectOperation.collect(nodeId)
                .whenComplete(mergeResultsAndCompleteFuture(resultFuture, timingsByNodeId, remainingCollectOps, nodeId));
        }

        if (needsCollectLocal) {
            executor
                .transportActionProvider()
                .transportCollectProfileNodeAction()
                .collectExecutionTimesAndFinishContext(jobId)
                .whenComplete(mergeResultsAndCompleteFuture(resultFuture, timingsByNodeId, remainingCollectOps, executor.localNodeId()));
        }
        return resultFuture;
    }

    private static BiConsumer&lt;Map&lt;String, Object&gt;, Throwable&gt; mergeResultsAndCompleteFuture(CompletableFuture&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; resultFuture,
                                                                                            ConcurrentHashMap&lt;String, Map&lt;String, Object&gt;&gt; timingsByNodeId,
                                                                                            AtomicInteger remainingOperations,
                                                                                            String nodeId) {
        return (map, throwable) -&gt; {
            if (throwable == null) {
                timingsByNodeId.put(nodeId, map);
                if (remainingOperations.decrementAndGet() == 0) {
                    resultFuture.complete(timingsByNodeId);
                }
            } else {
                resultFuture.completeExceptionally(throwable);
            }
        };
    }

    @VisibleForTesting
    public boolean doAnalyze() {
        return context != null;
    }
}
</PRE>
</div>
  </div>
</body>
</html>
