<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for ArrayMinFunctionTest.java & PublicationTests.java</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for ArrayMinFunctionTest.java & PublicationTests.java
      </h3>
      <h1 align="center">
        2.1%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>ArrayMinFunctionTest.java (13.580247%)<TH>PublicationTests.java (1.1434511%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match4479498-0.html#0',2,'match4479498-1.html#0',3)" NAME="0">(1-14)<TD><A HREF="javascript:ZweiFrames('match4479498-0.html#0',2,'match4479498-1.html#0',3)" NAME="0">(20-31)</A><TD ALIGN=center><FONT COLOR="#ff0000">11</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>ArrayMinFunctionTest.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
<A NAME="0"></A><FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match4479498-1.html#0',3,'match4479498-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>package io.crate.expression.scalar;

import io.crate.expression.symbol.Literal;
import io.crate.testing.TestingHelpers;
import io.crate.types.ArrayType;
import io.crate.types.DataType;
import io.crate.types.DataTypes;
import org.junit.Test;

import java.util.ArrayList;
import java.util.List;
import java.util.Locale;

import</B></FONT> static io.crate.testing.Asserts.assertThrowsMatches;

public class ArrayMinFunctionTest extends ScalarTestCase {

    @Test
    public void test_array_returns_min_element() {
        List&lt;DataType&gt; typesToTest = new ArrayList(DataTypes.PRIMITIVE_TYPES);
        typesToTest.add(DataTypes.NUMERIC);

        for(DataType type: typesToTest) {
            var valuesToTest = TestingHelpers.getRandomsOfType(2, 10, type);

            var optional = valuesToTest.stream()
                .filter(o -&gt; o != null)
                .min((o1, o2) -&gt; type.compare(o1, o2));
            var expected = optional.orElse(null);

            String expression = String.format(Locale.ENGLISH, &quot;array_min(?::%s[])&quot;, type.getName());
            assertEvaluate(expression, expected, Literal.of(valuesToTest, new ArrayType&lt;&gt;(type)));
        }
    }

    @Test
    public void test_array_first_element_null_returns_min() {
        assertEvaluate(&quot;array_min([null, 1])&quot;, 1);
    }

    @Test
    public void test_all_elements_nulls_results_in_null() {
        assertEvaluate(&quot;array_min(cast([null, null] as array(integer)))&quot;, null);
    }

    @Test
    public void test_null_array_results_in_null() {
        assertEvaluate(&quot;array_min(null::int[])&quot;, null);
    }

    @Test
    public void test_null_array_given_directly_results_in_null() {
        assertEvaluate(&quot;array_min(null)&quot;, null);
    }

    @Test
    public void test_empty_array_results_in_null() {
        assertEvaluate(&quot;array_min(cast([] as array(integer)))&quot;, null);
    }

    @Test
    public void test_empty_array_given_directly_throws_exception() {
        assertThrowsMatches(() -&gt; assertEvaluate(&quot;array_min([])&quot;, null),
            UnsupportedOperationException.class,
            &quot;Unknown function: array_min([]), no overload found for matching argument types: (undefined_array).&quot;);
    }
}
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>PublicationTests.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the &quot;License&quot;); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
<A NAME="0"></A> * under the License.
 */

<FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match4479498-0.html#0',2,'match4479498-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>package org.elasticsearch.cluster.coordination;

import org.elasticsearch.Version;
import org.elasticsearch.action.ActionListener;
import org.elasticsearch.cluster.ClusterState;
import org.elasticsearch.cluster.coordination.CoordinationMetadata.VotingConfiguration;
import org.elasticsearch.cluster.node.DiscoveryNode;
import org.elasticsearch.cluster.node.DiscoveryNodeRole;
import org.elasticsearch.cluster.node.DiscoveryNodes;
import javax.annotation.Nullable;
import io.crate.common.collections.Tuple;
import</B></FONT> org.elasticsearch.common.settings.Settings;
import io.crate.common.unit.TimeValue;
import io.crate.common.collections.Sets;
import org.elasticsearch.discovery.Discovery;
import org.elasticsearch.test.ESTestCase;
import org.elasticsearch.transport.TransportException;
import org.elasticsearch.transport.TransportResponse;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.Set;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.function.Function;
import java.util.function.LongSupplier;
import java.util.stream.Collector;
import java.util.stream.Collectors;
import java.util.stream.Stream;

import static org.hamcrest.Matchers.containsInAnyOrder;
import static org.hamcrest.Matchers.containsString;
import static org.hamcrest.Matchers.empty;
import static org.hamcrest.Matchers.emptyIterable;
import static org.hamcrest.Matchers.equalTo;

public class PublicationTests extends ESTestCase {

    class MockNode {

        MockNode(Settings settings, DiscoveryNode localNode) {
            this.localNode = localNode;
            ClusterState initialState = CoordinationStateTests.clusterState(0L, 0L, localNode,
                CoordinationMetadata.VotingConfiguration.EMPTY_CONFIG, CoordinationMetadata.VotingConfiguration.EMPTY_CONFIG, 0L);
            coordinationState = new CoordinationState(settings, localNode, new InMemoryPersistedState(0L, initialState));
        }

        final DiscoveryNode localNode;

        final CoordinationState coordinationState;

        public MockPublication publish(ClusterState clusterState, Discovery.AckListener ackListener, Set&lt;DiscoveryNode&gt; faultyNodes) {
            PublishRequest publishRequest = coordinationState.handleClientValue(clusterState);
            MockPublication currentPublication = new MockPublication(publishRequest, ackListener, () -&gt; 0L) {
                @Override
                protected boolean isPublishQuorum(CoordinationState.VoteCollection votes) {
                    return coordinationState.isPublishQuorum(votes);
                }

                @Override
                protected Optional&lt;ApplyCommitRequest&gt; handlePublishResponse(DiscoveryNode sourceNode, PublishResponse publishResponse) {
                    return coordinationState.handlePublishResponse(sourceNode, publishResponse);
                }
            };
            currentPublication.start(faultyNodes);
            return currentPublication;
        }
    }

    abstract class MockPublication extends Publication {

        final PublishRequest publishRequest;

        ApplyCommitRequest applyCommit;

        boolean completed;

        boolean committed;

        Map&lt;DiscoveryNode, ActionListener&lt;PublishWithJoinResponse&gt;&gt; pendingPublications = new LinkedHashMap&lt;&gt;();
        Map&lt;DiscoveryNode, ActionListener&lt;TransportResponse.Empty&gt;&gt; pendingCommits = new LinkedHashMap&lt;&gt;();
        Map&lt;DiscoveryNode, Join&gt; joins = new HashMap&lt;&gt;();
        Set&lt;DiscoveryNode&gt; missingJoins = new HashSet&lt;&gt;();

        MockPublication(PublishRequest publishRequest, Discovery.AckListener ackListener, LongSupplier currentTimeSupplier) {
            super(publishRequest, ackListener, currentTimeSupplier);
            this.publishRequest = publishRequest;
        }

        @Override
        protected void onCompletion(boolean committed) {
            assertFalse(completed);
            completed = true;
            this.committed = committed;
        }

        @Override
        protected void onJoin(Join join) {
            assertNull(joins.put(join.getSourceNode(), join));
        }

        @Override
        protected void onMissingJoin(DiscoveryNode discoveryNode) {
            assertTrue(missingJoins.add(discoveryNode));
        }

        @Override
        protected void sendPublishRequest(DiscoveryNode destination, PublishRequest publishRequest,
                                          ActionListener&lt;PublishWithJoinResponse&gt; responseActionListener) {
            assertSame(publishRequest, this.publishRequest);
            assertNull(pendingPublications.put(destination, responseActionListener));
        }

        @Override
        protected void sendApplyCommit(DiscoveryNode destination, ApplyCommitRequest applyCommit,
                                       ActionListener&lt;TransportResponse.Empty&gt; responseActionListener) {
            if (this.applyCommit == null) {
                this.applyCommit = applyCommit;
            } else {
                assertSame(applyCommit, this.applyCommit);
            }
            assertNull(pendingCommits.put(destination, responseActionListener));
        }
    }

    DiscoveryNode n1 = CoordinationStateTests.createNode(&quot;node1&quot;);
    DiscoveryNode n2 = CoordinationStateTests.createNode(&quot;node2&quot;);
    DiscoveryNode n3 = CoordinationStateTests.createNode(&quot;node3&quot;);
    Set&lt;DiscoveryNode&gt; discoNodes = Set.of(n1, n2, n3);

    MockNode node1 = new MockNode(Settings.EMPTY, n1);
    MockNode node2 = new MockNode(Settings.EMPTY, n2);
    MockNode node3 = new MockNode(Settings.EMPTY, n3);
    List&lt;MockNode&gt; nodes = Arrays.asList(node1, node2, node3);

    Function&lt;DiscoveryNode, MockNode&gt; nodeResolver = dn -&gt; nodes.stream().filter(mn -&gt; mn.localNode.equals(dn)).findFirst().get();

    private void initializeCluster(VotingConfiguration initialConfig) {
        node1.coordinationState.setInitialState(CoordinationStateTests.clusterState(0L, 0L, n1, initialConfig, initialConfig, 0L));
        StartJoinRequest startJoinRequest = new StartJoinRequest(n1, 1L);
        node1.coordinationState.handleJoin(node1.coordinationState.handleStartJoin(startJoinRequest));
        node1.coordinationState.handleJoin(node2.coordinationState.handleStartJoin(startJoinRequest));
        node1.coordinationState.handleJoin(node3.coordinationState.handleStartJoin(startJoinRequest));
        assertTrue(node1.coordinationState.electionWon());
    }

    public void testSimpleClusterStatePublishing() throws InterruptedException {
        VotingConfiguration singleNodeConfig = new VotingConfiguration(Set.of(n1.getId()));
        initializeCluster(singleNodeConfig);

        AssertingAckListener ackListener = new AssertingAckListener(nodes.size());
        DiscoveryNodes discoveryNodes = DiscoveryNodes.builder().add(n1).add(n2).add(n3).localNodeId(n1.getId()).build();
        MockPublication publication = node1.publish(CoordinationStateTests.clusterState(1L, 2L,
            discoveryNodes, singleNodeConfig, singleNodeConfig, 42L), ackListener, Collections.emptySet());

        assertThat(publication.pendingPublications.keySet(), equalTo(discoNodes));
        assertThat(publication.completedNodes(), empty());
        assertTrue(publication.pendingCommits.isEmpty());
        AtomicBoolean processedNode1PublishResponse = new AtomicBoolean();
        boolean delayProcessingNode2PublishResponse = randomBoolean();
        publication.pendingPublications.entrySet().stream().collect(shuffle()).forEach(e -&gt; {
            if (delayProcessingNode2PublishResponse &amp;&amp; e.getKey().equals(n2)) {
                return;
            }
            PublishResponse publishResponse = nodeResolver.apply(e.getKey()).coordinationState.handlePublishRequest(
                publication.publishRequest);
            assertNotEquals(processedNode1PublishResponse.get(), publication.pendingCommits.isEmpty());
            assertFalse(publication.joins.containsKey(e.getKey()));
            PublishWithJoinResponse publishWithJoinResponse = new PublishWithJoinResponse(publishResponse,
                randomBoolean() ? Optional.empty() : Optional.of(new Join(e.getKey(), randomFrom(n1, n2, n3), publishResponse.getTerm(),
                    randomNonNegativeLong(), randomNonNegativeLong())));
            e.getValue().onResponse(publishWithJoinResponse);
            if (publishWithJoinResponse.getJoin().isPresent()) {
                assertTrue(publication.joins.containsKey(e.getKey()));
                assertFalse(publication.missingJoins.contains(e.getKey()));
                assertEquals(publishWithJoinResponse.getJoin().get(), publication.joins.get(e.getKey()));
            } else {
                assertFalse(publication.joins.containsKey(e.getKey()));
                assertTrue(publication.missingJoins.contains(e.getKey()));
            }
            if (e.getKey().equals(n1)) {
                processedNode1PublishResponse.set(true);
            }
            assertNotEquals(processedNode1PublishResponse.get(), publication.pendingCommits.isEmpty());
        });

        if (delayProcessingNode2PublishResponse) {
            assertThat(publication.pendingCommits.keySet(), equalTo(Set.of(n1, n3)));
        } else {
            assertThat(publication.pendingCommits.keySet(), equalTo(discoNodes));
        }
        assertNotNull(publication.applyCommit);
        assertEquals(publication.applyCommit.getTerm(), publication.publishRequest.getAcceptedState().term());
        assertEquals(publication.applyCommit.getVersion(), publication.publishRequest.getAcceptedState().version());
        publication.pendingCommits.entrySet().stream().collect(shuffle()).forEach(e -&gt; {
            assertFalse(publication.completed);
            assertFalse(publication.committed);
            nodeResolver.apply(e.getKey()).coordinationState.handleCommit(publication.applyCommit);
            e.getValue().onResponse(TransportResponse.Empty.INSTANCE);
        });

        if (delayProcessingNode2PublishResponse) {
            assertFalse(publication.completed);
            assertFalse(publication.committed);
            PublishResponse publishResponse = nodeResolver.apply(n2).coordinationState.handlePublishRequest(
                publication.publishRequest);
            publication.pendingPublications.get(n2).onResponse(new PublishWithJoinResponse(publishResponse, Optional.empty()));
            assertThat(publication.pendingCommits.keySet(), equalTo(discoNodes));

            assertFalse(publication.completed);
            assertFalse(publication.committed);
            assertThat(publication.completedNodes(), containsInAnyOrder(n1, n3));
            publication.pendingCommits.get(n2).onResponse(TransportResponse.Empty.INSTANCE);
        }

        assertTrue(publication.completed);
        assertThat(publication.completedNodes(), containsInAnyOrder(n1, n2, n3));
        assertTrue(publication.committed);

        assertThat(ackListener.await(0L, TimeUnit.SECONDS), containsInAnyOrder(n1, n2, n3));
    }

    public void testClusterStatePublishingWithFaultyNodeBeforeCommit() throws InterruptedException {
        VotingConfiguration singleNodeConfig = new VotingConfiguration(Set.of(n1.getId()));
        initializeCluster(singleNodeConfig);

        AssertingAckListener ackListener = new AssertingAckListener(nodes.size());
        DiscoveryNodes discoveryNodes = DiscoveryNodes.builder().add(n1).add(n2).add(n3).localNodeId(n1.getId()).build();

        AtomicInteger remainingActions = new AtomicInteger(4); // number of publish actions + initial faulty nodes injection
        int injectFaultAt = randomInt(remainingActions.get() - 1);
        logger.info(&quot;Injecting fault at: {}&quot;, injectFaultAt);

        Set&lt;DiscoveryNode&gt; initialFaultyNodes = remainingActions.decrementAndGet() == injectFaultAt ?
            Collections.singleton(n2) : Collections.emptySet();
        MockPublication publication = node1.publish(CoordinationStateTests.clusterState(1L, 2L,
            discoveryNodes, singleNodeConfig, singleNodeConfig, 42L), ackListener, initialFaultyNodes);

        publication.pendingPublications.entrySet().stream().collect(shuffle()).forEach(e -&gt; {
            if (remainingActions.decrementAndGet() == injectFaultAt) {
                publication.onFaultyNode(n2);
            }
            if (e.getKey().equals(n2) == false || randomBoolean()) {
                PublishResponse publishResponse = nodeResolver.apply(e.getKey()).coordinationState.handlePublishRequest(
                    publication.publishRequest);
                e.getValue().onResponse(new PublishWithJoinResponse(publishResponse, Optional.empty()));
            }
        });

        publication.pendingCommits.entrySet().stream().collect(shuffle()).forEach(e -&gt; {
            nodeResolver.apply(e.getKey()).coordinationState.handleCommit(publication.applyCommit);
            e.getValue().onResponse(TransportResponse.Empty.INSTANCE);
        });

        assertTrue(publication.completed);
        assertTrue(publication.committed);

        publication.onFaultyNode(randomFrom(n1, n3)); // has no influence

        List&lt;Tuple&lt;DiscoveryNode, Throwable&gt;&gt; errors = ackListener.awaitErrors(0L, TimeUnit.SECONDS);
        assertThat(errors.size(), equalTo(1));
        assertThat(errors.get(0).v1(), equalTo(n2));
        assertThat(errors.get(0).v2().getMessage(), containsString(&quot;faulty node&quot;));
    }

    public void testClusterStatePublishingWithFaultyNodeAfterCommit() throws InterruptedException {
        VotingConfiguration singleNodeConfig = new VotingConfiguration(Set.of(n1.getId()));
        initializeCluster(singleNodeConfig);

        AssertingAckListener ackListener = new AssertingAckListener(nodes.size());
        DiscoveryNodes discoveryNodes = DiscoveryNodes.builder().add(n1).add(n2).add(n3).localNodeId(n1.getId()).build();

        boolean publicationDidNotMakeItToNode2 = randomBoolean();
        AtomicInteger remainingActions = new AtomicInteger(publicationDidNotMakeItToNode2 ? 2 : 3);
        int injectFaultAt = randomInt(remainingActions.get() - 1);
        logger.info(&quot;Injecting fault at: {}, publicationDidNotMakeItToNode2: {}&quot;, injectFaultAt, publicationDidNotMakeItToNode2);

        MockPublication publication = node1.publish(CoordinationStateTests.clusterState(1L, 2L,
            discoveryNodes, singleNodeConfig, singleNodeConfig, 42L), ackListener, Collections.emptySet());

        publication.pendingPublications.entrySet().stream().collect(shuffle()).forEach(e -&gt; {
            if (e.getKey().equals(n2) == false || publicationDidNotMakeItToNode2 == false) {
                PublishResponse publishResponse = nodeResolver.apply(e.getKey()).coordinationState.handlePublishRequest(
                    publication.publishRequest);
                e.getValue().onResponse(new PublishWithJoinResponse(publishResponse, Optional.empty()));
            }
        });

        publication.pendingCommits.entrySet().stream().collect(shuffle()).forEach(e -&gt; {
            if (e.getKey().equals(n2)) {
                // we must fail node before committing for the node, otherwise failing the node is ignored
                publication.onFaultyNode(n2);
            }
            if (remainingActions.decrementAndGet() == injectFaultAt) {
                publication.onFaultyNode(n2);
            }
            if (e.getKey().equals(n2) == false || randomBoolean()) {
                nodeResolver.apply(e.getKey()).coordinationState.handleCommit(publication.applyCommit);
                e.getValue().onResponse(TransportResponse.Empty.INSTANCE);
            }
        });

        // we need to complete publication by failing the node
        if (publicationDidNotMakeItToNode2 &amp;&amp; remainingActions.get() &gt; injectFaultAt) {
            publication.onFaultyNode(n2);
        }

        assertTrue(publication.completed);
        assertTrue(publication.committed);

        publication.onFaultyNode(randomFrom(n1, n3)); // has no influence

        List&lt;Tuple&lt;DiscoveryNode, Throwable&gt;&gt; errors = ackListener.awaitErrors(0L, TimeUnit.SECONDS);
        assertThat(errors.size(), equalTo(1));
        assertThat(errors.get(0).v1(), equalTo(n2));
        assertThat(errors.get(0).v2().getMessage(), containsString(&quot;faulty node&quot;));
    }

    public void testClusterStatePublishingFailsOrTimesOutBeforeCommit() throws InterruptedException {
        VotingConfiguration config = new VotingConfiguration(Set.of(n1.getId(), n2.getId()));
        initializeCluster(config);

        AssertingAckListener ackListener = new AssertingAckListener(nodes.size());
        DiscoveryNodes discoveryNodes = DiscoveryNodes.builder().add(n1).add(n2).add(n3).localNodeId(n1.getId()).build();
        MockPublication publication = node1.publish(CoordinationStateTests.clusterState(1L, 2L,
            discoveryNodes, config, config, 42L), ackListener, Collections.emptySet());

        boolean timeOut = randomBoolean();
        publication.pendingPublications.entrySet().stream().collect(shuffle()).forEach(e -&gt; {
            if (e.getKey().equals(n2)) {
                if (timeOut) {
                    publication.cancel(&quot;timed out&quot;);
                } else {
                    e.getValue().onFailure(new TransportException(new Exception(&quot;dummy failure&quot;)));
                }
                assertTrue(publication.completed);
                assertFalse(publication.committed);
            } else if (randomBoolean()) {
                PublishResponse publishResponse = nodeResolver.apply(e.getKey()).coordinationState.handlePublishRequest(
                    publication.publishRequest);
                e.getValue().onResponse(new PublishWithJoinResponse(publishResponse, Optional.empty()));
            }
        });

        assertThat(publication.pendingCommits.keySet(), equalTo(Collections.emptySet()));
        assertNull(publication.applyCommit);
        assertTrue(publication.completed);
        assertFalse(publication.committed);

        List&lt;Tuple&lt;DiscoveryNode, Throwable&gt;&gt; errors = ackListener.awaitErrors(0L, TimeUnit.SECONDS);
        assertThat(errors.size(), equalTo(3));
        assertThat(errors.stream().map(Tuple::v1).collect(Collectors.toList()), containsInAnyOrder(n1, n2, n3));
        errors.stream().forEach(tuple -&gt;
            assertThat(tuple.v2().getMessage(), containsString(timeOut ? &quot;timed out&quot; :
                tuple.v1().equals(n2) ? &quot;dummy failure&quot; : &quot;non-failed nodes do not form a quorum&quot;)));
    }

    public void testPublishingToMastersFirst() {
        VotingConfiguration singleNodeConfig = new VotingConfiguration(Set.of(n1.getId()));
        initializeCluster(singleNodeConfig);

        DiscoveryNodes.Builder discoNodesBuilder = DiscoveryNodes.builder();
        randomNodes(10).forEach(dn -&gt; discoNodesBuilder.add(dn));
        DiscoveryNodes discoveryNodes = discoNodesBuilder.add(n1).localNodeId(n1.getId()).build();
        MockPublication publication = node1.publish(CoordinationStateTests.clusterState(1L, 2L,
            discoveryNodes, singleNodeConfig, singleNodeConfig, 42L), null, Collections.emptySet());

        List&lt;DiscoveryNode&gt; publicationTargets = new ArrayList&lt;&gt;(publication.pendingPublications.keySet());
        List&lt;DiscoveryNode&gt; sortedPublicationTargets = new ArrayList&lt;&gt;(publicationTargets);
        Collections.sort(sortedPublicationTargets, Comparator.comparing(n -&gt; n.isMasterEligibleNode() == false));
        assertEquals(sortedPublicationTargets, publicationTargets);
    }

    public void testClusterStatePublishingTimesOutAfterCommit() throws InterruptedException {
        VotingConfiguration config = new VotingConfiguration(randomBoolean() ?
            Set.of(n1.getId(), n2.getId()) : Set.of(n1.getId(), n2.getId(), n3.getId()));
        initializeCluster(config);

        AssertingAckListener ackListener = new AssertingAckListener(nodes.size());
        DiscoveryNodes discoveryNodes = DiscoveryNodes.builder().add(n1).add(n2).add(n3).localNodeId(n1.getId()).build();
        MockPublication publication = node1.publish(CoordinationStateTests.clusterState(1L, 2L,
            discoveryNodes, config, config, 42L), ackListener, Collections.emptySet());

        boolean publishedToN3 = randomBoolean();
        publication.pendingPublications.entrySet().stream().collect(shuffle()).forEach(e -&gt; {
            if (e.getKey().equals(n3) == false || publishedToN3) {
                PublishResponse publishResponse = nodeResolver.apply(e.getKey()).coordinationState.handlePublishRequest(
                    publication.publishRequest);
                e.getValue().onResponse(new PublishWithJoinResponse(publishResponse, Optional.empty()));
            }
        });

        assertNotNull(publication.applyCommit);

        Set&lt;DiscoveryNode&gt; committingNodes = new HashSet&lt;&gt;(randomSubsetOf(discoNodes));
        if (publishedToN3 == false) {
            committingNodes.remove(n3);
        }

        logger.info(&quot;Committing nodes: {}&quot;, committingNodes);

        publication.pendingCommits.entrySet().stream().collect(shuffle()).forEach(e -&gt; {
            if (committingNodes.contains(e.getKey())) {
                nodeResolver.apply(e.getKey()).coordinationState.handleCommit(publication.applyCommit);
                e.getValue().onResponse(TransportResponse.Empty.INSTANCE);
            }
        });

        publication.cancel(&quot;timed out&quot;);
        assertTrue(publication.completed);
        assertTrue(publication.committed);
        assertEquals(committingNodes, ackListener.await(0L, TimeUnit.SECONDS));

        // check that acking still works after publication completed
        if (publishedToN3 == false) {
            publication.pendingPublications.get(n3).onResponse(
                new PublishWithJoinResponse(node3.coordinationState.handlePublishRequest(publication.publishRequest), Optional.empty()));
        }

        assertEquals(discoNodes, publication.pendingCommits.keySet());

        Set&lt;DiscoveryNode&gt; nonCommittedNodes = Sets.difference(discoNodes, committingNodes);
        logger.info(&quot;Non-committed nodes: {}&quot;, nonCommittedNodes);
        nonCommittedNodes.stream().collect(shuffle()).forEach(n -&gt;
            publication.pendingCommits.get(n).onResponse(TransportResponse.Empty.INSTANCE));

        assertEquals(discoNodes, ackListener.await(0L, TimeUnit.SECONDS));
    }

    private static List&lt;DiscoveryNode&gt; randomNodes(final int numNodes) {
        List&lt;DiscoveryNode&gt; nodesList = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; numNodes; i++) {
            Map&lt;String, String&gt; attributes = new HashMap&lt;&gt;();
            if (frequently()) {
                attributes.put(&quot;custom&quot;, randomBoolean() ? &quot;match&quot; : randomAlphaOfLengthBetween(3, 5));
            }
            final DiscoveryNode node = newNode(i, attributes,
                new HashSet&lt;&gt;(randomSubsetOf(DiscoveryNodeRole.BUILT_IN_ROLES)));
            nodesList.add(node);
        }
        return nodesList;
    }

    private static DiscoveryNode newNode(int nodeId, Map&lt;String, String&gt; attributes, Set&lt;DiscoveryNodeRole&gt; roles) {
        return new DiscoveryNode(&quot;name_&quot; + nodeId, &quot;node_&quot; + nodeId, buildNewFakeTransportAddress(), attributes, roles,
            Version.CURRENT);
    }

    public static &lt;T&gt; Collector&lt;T, ?, Stream&lt;T&gt;&gt; shuffle() {
        return Collectors.collectingAndThen(Collectors.toList(),
            ts -&gt; {
                Collections.shuffle(ts, random());
                return ts.stream();
            });
    }

    public static class AssertingAckListener implements Discovery.AckListener {
        private final List&lt;Tuple&lt;DiscoveryNode, Throwable&gt;&gt; errors = new CopyOnWriteArrayList&lt;&gt;();
        private final Set&lt;DiscoveryNode&gt; successfulAcks = Collections.synchronizedSet(new HashSet&lt;&gt;());
        private final CountDownLatch countDown;
        private final CountDownLatch commitCountDown;

        public AssertingAckListener(int nodeCount) {
            countDown = new CountDownLatch(nodeCount);
            commitCountDown = new CountDownLatch(1);
        }

        @Override
        public void onCommit(TimeValue commitTime) {
            commitCountDown.countDown();
        }

        @Override
        public void onNodeAck(DiscoveryNode node, @Nullable Exception e) {
            if (e != null) {
                errors.add(new Tuple&lt;&gt;(node, e));
            } else {
                successfulAcks.add(node);
            }
            countDown.countDown();
        }

        public Set&lt;DiscoveryNode&gt; await(long timeout, TimeUnit unit) throws InterruptedException {
            assertThat(awaitErrors(timeout, unit), emptyIterable());
            assertTrue(commitCountDown.await(timeout, unit));
            return new HashSet&lt;&gt;(successfulAcks);
        }

        public List&lt;Tuple&lt;DiscoveryNode, Throwable&gt;&gt; awaitErrors(long timeout, TimeUnit unit) throws InterruptedException {
            countDown.await(timeout, unit);
            return errors;
        }

    }
}
</PRE>
</div>
  </div>
</body>
</html>
