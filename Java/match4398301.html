<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>Matches for CastFunctionResolver.java &amp; InternalTestCluster.java</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for CastFunctionResolver.java &amp; InternalTestCluster.java
      </h3>
<h1 align="center">
        2.5%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>CastFunctionResolver.java (51.724136%)<th>InternalTestCluster.java (1.3278253%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(24-42)<td><a href="#" name="0">(138-165)</a><td align="center"><font color="#ff0000">15</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(91-101)<td><a href="#" name="1">(472-476)</a><td align="center"><font color="#bb0000">11</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(78-90)<td><a href="#" name="2">(440-443)</a><td align="center"><font color="#aa0000">10</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(53-58)<td><a href="#" name="3">(401-404)</a><td align="center"><font color="#990000">9</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>CastFunctionResolver.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
<a name="0"></a>
package io.crate.expression.scalar.cast;
<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>import io.crate.exceptions.ConversionException;
import io.crate.expression.symbol.Function;
import io.crate.expression.symbol.Literal;
import io.crate.expression.symbol.Symbol;
import io.crate.metadata.functions.Signature;
import io.crate.types.DataType;
import io.crate.types.DataTypes;
import java.util.List;
import java.util.Set;
import javax.annotation.Nullable;
import static io.crate.metadata.functions.TypeVariableConstraint.typeVariable;
import static io.crate.types.TypeSignature.parseTypeSignature;
public class CastFunctionResolver {
    public static final List&lt;String&gt; CAST_FUNCTION_NAMES = List.of</b></font>(
        ExplicitCastFunction.NAME, ImplicitCastFunction.NAME, TryCastFunction.NAME);
    @Nullable
    public static CastMode getCastMode(String functionName) {
        return switch (functionName) {
            case ExplicitCastFunction.NAME -&gt; CastMode.EXPLICIT;
            case ImplicitCastFunction.NAME -&gt; CastMode.IMPLICIT;
<a name="3"></a>            case TryCastFunction.NAME -&gt; CastMode.TRY;
            default -&gt; null;
        };
    <font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>}
    public static Symbol generateCastFunction(Symbol sourceSymbol,
                                              DataType&lt;?&gt; targetType,
                                              CastMode... castModes) {
        var modes = Set.of</b></font>(castModes);
        assert !modes.containsAll(List.of(CastMode.EXPLICIT, CastMode.IMPLICIT))
            : "explicit and implicit cast modes are mutually exclusive";
        DataType&lt;?&gt; sourceType = sourceSymbol.valueType();
        if (!sourceType.isConvertableTo(targetType, modes.contains(CastMode.EXPLICIT))) {
            throw new ConversionException(sourceType, targetType);
        }
        if (modes.contains(CastMode.TRY) || modes.contains(CastMode.EXPLICIT)) {
            var name = modes.contains(CastMode.TRY)
<a name="2"></a>                ? TryCastFunction.NAME
                : ExplicitCastFunction.NAME;
            return new Function(
                <font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>Signature
                    .scalar(
                        name,
                        parseTypeSignature("E"),
                        parseTypeSignature("V"),
                        parseTypeSignature("V")
                    ).withTypeVariableConstraints(typeVariable("E"), typeVariable("V")),
                List.of(sourceSymbol, Literal.of(targetType, null)),
<a name="1"></a>                targetType
            );
        }</b></font> else {
            return <font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>new Function(
                Signature
                    .scalar(
                        ImplicitCastFunction.NAME,
                        parseTypeSignature("E"),
                        DataTypes.STRING.getTypeSignature(),
                        DataTypes.UNDEFINED.getTypeSignature())
                    .withTypeVariableConstraints(typeVariable("E")),
                List.of(
                    sourceSymbol,
                    Literal.of(targetType.getTypeSignature</b></font>().toString())
                ),
                targetType
            );
        }
    }
}
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>InternalTestCluster.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
package org.elasticsearch.test;
import static io.crate.common.unit.TimeValue.timeValueSeconds;
import static org.apache.lucene.util.LuceneTestCase.TEST_NIGHTLY;
import static org.apache.lucene.util.LuceneTestCase.rarely;
import static org.elasticsearch.cluster.coordination.ClusterBootstrapService.INITIAL_MASTER_NODES_SETTING;
import static org.elasticsearch.discovery.DiscoveryModule.DISCOVERY_TYPE_SETTING;
import static org.elasticsearch.discovery.DiscoveryModule.ZEN2_DISCOVERY_TYPE;
import static org.elasticsearch.node.Node.INITIAL_STATE_TIMEOUT_SETTING;
import static org.elasticsearch.discovery.FileBasedSeedHostsProvider.UNICAST_HOSTS_FILE;
import static org.elasticsearch.indices.breaker.HierarchyCircuitBreakerService.TOTAL_CIRCUIT_BREAKER_LIMIT_SETTING;
import static org.elasticsearch.test.ESTestCase.assertBusy;
import static org.elasticsearch.test.ESTestCase.randomFrom;
import static org.hamcrest.Matchers.equalTo;
import static org.hamcrest.Matchers.greaterThan;
import static org.hamcrest.Matchers.greaterThanOrEqualTo;
import static org.hamcrest.Matchers.not;
import static org.hamcrest.Matchers.nullValue;
import static org.junit.Assert.assertThat;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import java.io.Closeable;
import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.NavigableMap;
import java.util.Objects;
import java.util.Random;
import java.util.Set;
import java.util.TreeMap;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.function.Predicate;
import java.util.stream.Collectors;
import java.util.stream.IntStream;
import java.util.stream.Stream;
import javax.annotation.Nullable;
import com.carrotsearch.hppc.ObjectLongMap;
import com.carrotsearch.hppc.cursors.IntObjectCursor;
import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
import com.carrotsearch.randomizedtesting.RandomizedTest;
import com.carrotsearch.randomizedtesting.SeedUtils;
import com.carrotsearch.randomizedtesting.generators.RandomNumbers;
import com.carrotsearch.randomizedtesting.generators.RandomPicks;
import com.carrotsearch.randomizedtesting.generators.RandomStrings;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.apache.lucene.store.AlreadyClosedException;
import org.elasticsearch.action.admin.cluster.configuration.AddVotingConfigExclusionsAction;
import org.elasticsearch.action.admin.cluster.configuration.AddVotingConfigExclusionsRequest;
import org.elasticsearch.action.admin.cluster.configuration.ClearVotingConfigExclusionsAction;
import org.elasticsearch.action.admin.cluster.configuration.ClearVotingConfigExclusionsRequest;
import org.elasticsearch.client.Client;
import org.elasticsearch.cluster.ClusterName;
import org.elasticsearch.cluster.ClusterState;
import org.elasticsearch.cluster.action.index.MappingUpdatedAction;
import org.elasticsearch.cluster.coordination.ClusterBootstrapService;
import org.elasticsearch.cluster.metadata.IndexMetadata;
import org.elasticsearch.cluster.node.DiscoveryNode;
import org.elasticsearch.cluster.node.DiscoveryNodeRole;
import org.elasticsearch.cluster.node.DiscoveryNodes;
import org.elasticsearch.cluster.routing.IndexRoutingTable;
import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
import org.elasticsearch.cluster.routing.OperationRouting;
import org.elasticsearch.cluster.routing.ShardRouting;
import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;
import org.elasticsearch.cluster.routing.allocation.decider.ThrottlingAllocationDecider;
import org.elasticsearch.cluster.service.ClusterService;
import org.elasticsearch.common.Randomness;
import org.elasticsearch.common.Strings;
import org.elasticsearch.common.breaker.CircuitBreaker;
import org.elasticsearch.common.component.LifecycleListener;
import org.elasticsearch.common.io.FileSystemUtils;
import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
import org.elasticsearch.common.lease.Releasables;
import org.elasticsearch.common.settings.Settings;
import org.elasticsearch.common.settings.Settings.Builder;
import org.elasticsearch.common.unit.ByteSizeUnit;
import org.elasticsearch.common.unit.ByteSizeValue;
import org.elasticsearch.common.util.PageCacheRecycler;
import org.elasticsearch.common.util.concurrent.EsExecutors;
import org.elasticsearch.common.util.concurrent.FutureUtils;
import org.elasticsearch.env.Environment;
import org.elasticsearch.env.NodeEnvironment;
import org.elasticsearch.env.ShardLockObtainFailedException;
import org.elasticsearch.http.HttpServerTransport;
import org.elasticsearch.index.Index;
import org.elasticsearch.index.IndexService;
import org.elasticsearch.index.engine.CommitStats;
import org.elasticsearch.index.engine.DocIdSeqNoAndSource;
import org.elasticsearch.index.engine.Engine;
import org.elasticsearch.index.engine.InternalEngine;
import org.elasticsearch.index.seqno.SeqNoStats;
import org.elasticsearch.index.seqno.SequenceNumbers;
import org.elasticsearch.index.shard.IndexShard;
import org.elasticsearch.index.shard.IndexShardTestCase;
import org.elasticsearch.index.shard.ShardId;
<a name="0"></a>import org.elasticsearch.indices.IndicesService;
import org.elasticsearch.indices.breaker.CircuitBreakerService;
import org.elasticsearch.indices.breaker.HierarchyCircuitBreakerService;
<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>import org.elasticsearch.indices.recovery.RecoverySettings;
import org.elasticsearch.node.MockNode;
import org.elasticsearch.node.Node;
import org.elasticsearch.node.NodeValidationException;
import org.elasticsearch.plugins.Plugin;
import org.elasticsearch.test.disruption.ServiceDisruptionScheme;
import org.elasticsearch.test.transport.MockTransportService;
import org.elasticsearch.transport.TransportService;
import org.elasticsearch.transport.TransportSettings;
import io.crate.common.io.IOUtils;
import io.crate.common.unit.TimeValue;
import static org.junit.Assert.assertEquals;
public final class InternalTestCluster extends TestCluster {
    private final Logger logger = LogManager.getLogger</b></font>(getClass());
    private static final Predicate&lt;NodeAndClient&gt; DATA_NODE_PREDICATE =
        nodeAndClient -&gt; DiscoveryNode.isDataNode(nodeAndClient.node.settings());
    private static final Predicate&lt;NodeAndClient&gt; NO_DATA_NO_MASTER_PREDICATE = nodeAndClient -&gt;
        DiscoveryNode.isMasterEligibleNode(nodeAndClient.node.settings()) == false
            &amp;&amp; DiscoveryNode.isDataNode(nodeAndClient.node.settings()) == false;
    private static final Predicate&lt;NodeAndClient&gt; MASTER_NODE_PREDICATE =
        nodeAndClient -&gt; DiscoveryNode.isMasterEligibleNode(nodeAndClient.node.settings());
    public static final int DEFAULT_LOW_NUM_MASTER_NODES = 1;
    public static final int DEFAULT_HIGH_NUM_MASTER_NODES = 3;
    static final int DEFAULT_MIN_NUM_DATA_NODES = 1;
    static final int DEFAULT_MAX_NUM_DATA_NODES = TEST_NIGHTLY ? 6 : 3;
    static final int DEFAULT_NUM_CLIENT_NODES = -1;
    static final int DEFAULT_MIN_NUM_CLIENT_NODES = 0;
    static final int DEFAULT_MAX_NUM_CLIENT_NODES = 1;
    private volatile NavigableMap&lt;String, NodeAndClient&gt; nodes = Collections.emptyNavigableMap();
    private final Set&lt;Path&gt; dataDirToClean = new HashSet&lt;&gt;();
    private final String clusterName;
    private final AtomicBoolean open = new AtomicBoolean(true);
    private final Settings defaultSettings;
    private final AtomicInteger nextNodeId = new AtomicInteger(0);
    private final long[] sharedNodesSeeds;
    private final int numSharedDedicatedMasterNodes;
    private final int numSharedDataNodes;
    private final int numSharedCoordOnlyNodes;
    private final NodeConfigurationSource nodeConfigurationSource;
    private final ExecutorService executor;
    private final boolean autoManageMasterNodes;
    private final Collection&lt;Class&lt;? extends Plugin&gt;&gt; mockPlugins;
    private final boolean forbidPrivateIndexSettings;
    private final int numDataPaths;
    private final String nodePrefix;
    private final Path baseDir;
    private ServiceDisruptionScheme activeDisruptionScheme;
    private int bootstrapMasterNodeIndex = -1;
    public InternalTestCluster(
            final long clusterSeed,
            final Path baseDir,
            final boolean randomlyAddDedicatedMasters,
            final boolean autoManageMasterNodes,
            final int minNumDataNodes,
            final int maxNumDataNodes,
            final String clusterName,
            final NodeConfigurationSource nodeConfigurationSource,
            final int numClientNodes,
            final String nodePrefix,
            final Collection&lt;Class&lt;? extends Plugin&gt;&gt; mockPlugins) {
        this(
                clusterSeed,
                baseDir,
                randomlyAddDedicatedMasters,
                autoManageMasterNodes,
                minNumDataNodes,
                maxNumDataNodes,
                clusterName,
                nodeConfigurationSource,
                numClientNodes,
                nodePrefix,
                mockPlugins,
                true);
    }
    public InternalTestCluster(
            final long clusterSeed,
            final Path baseDir,
            final boolean randomlyAddDedicatedMasters,
            final boolean autoManageMasterNodes,
            final int minNumDataNodes,
            final int maxNumDataNodes,
            final String clusterName,
            final NodeConfigurationSource nodeConfigurationSource,
            final int numClientNodes,
            final String nodePrefix,
            final Collection&lt;Class&lt;? extends Plugin&gt;&gt; mockPlugins,
            final boolean forbidPrivateIndexSettings) {
        super(clusterSeed);
        this.autoManageMasterNodes = autoManageMasterNodes;
        this.forbidPrivateIndexSettings = forbidPrivateIndexSettings;
        this.baseDir = baseDir;
        this.clusterName = clusterName;
        if (minNumDataNodes &lt; 0 || maxNumDataNodes &lt; 0) {
            throw new IllegalArgumentException("minimum and maximum number of data nodes must be &gt;= 0");
        }
        if (maxNumDataNodes &lt; minNumDataNodes) {
            throw new IllegalArgumentException("maximum number of data nodes must be &gt;= minimum number of  data nodes");
        }
        Random random = new Random(clusterSeed);
        boolean useDedicatedMasterNodes = randomlyAddDedicatedMasters &amp;&amp; random.nextBoolean();
        this.numSharedDataNodes = RandomNumbers.randomIntBetween(random, minNumDataNodes, maxNumDataNodes);
        assert this.numSharedDataNodes &gt;= 0;
        if (numSharedDataNodes == 0) {
            this.numSharedCoordOnlyNodes = 0;
            this.numSharedDedicatedMasterNodes = 0;
        } else {
            if (useDedicatedMasterNodes) {
                if (random.nextBoolean()) {
                    this.numSharedDedicatedMasterNodes = DEFAULT_LOW_NUM_MASTER_NODES;
                } else {
                    this.numSharedDedicatedMasterNodes = DEFAULT_HIGH_NUM_MASTER_NODES;
                }
            } else {
                this.numSharedDedicatedMasterNodes = 0;
            }
            if (numClientNodes &lt; 0) {
                this.numSharedCoordOnlyNodes =  RandomNumbers.randomIntBetween(random,
                        DEFAULT_MIN_NUM_CLIENT_NODES, DEFAULT_MAX_NUM_CLIENT_NODES);
            } else {
                this.numSharedCoordOnlyNodes = numClientNodes;
            }
        }
        assert this.numSharedCoordOnlyNodes &gt;= 0;
        this.nodePrefix = nodePrefix;
        assert nodePrefix != null;
        this.mockPlugins = mockPlugins;
        sharedNodesSeeds = new long[numSharedDedicatedMasterNodes + numSharedDataNodes + numSharedCoordOnlyNodes];
        for (int i = 0; i &lt; sharedNodesSeeds.length; i++) {
            sharedNodesSeeds[i] = random.nextLong();
        }
        logger.info("Setup InternalTestCluster [{}] with seed [{}] using [{}] dedicated masters, " +
                "[{}] (data) nodes and [{}] coord only nodes (master nodes are [{}])",
            clusterName, SeedUtils.formatSeed(clusterSeed),
            numSharedDedicatedMasterNodes, numSharedDataNodes, numSharedCoordOnlyNodes,
            autoManageMasterNodes ? "auto-managed" : "manual");
        this.nodeConfigurationSource = nodeConfigurationSource;
        numDataPaths = random.nextInt(5) == 0 ? 2 + random.nextInt(3) : 1;
        Builder builder = Settings.builder();
        builder.put(Environment.PATH_HOME_SETTING.getKey(), baseDir);
        builder.put(Environment.PATH_REPO_SETTING.getKey(), baseDir.resolve("repos"));
        builder.put(TransportSettings.PORT.getKey(), 0);
        builder.put("http.port", 0);
        if (Strings.hasLength(System.getProperty("tests.es.logger.level"))) {
            builder.put("logger.level", System.getProperty("tests.es.logger.level"));
        }
        if (Strings.hasLength(System.getProperty("es.logger.prefix"))) {
            builder.put("logger.prefix", System.getProperty("es.logger.prefix"));
        }
        builder.put(TOTAL_CIRCUIT_BREAKER_LIMIT_SETTING.getKey(), "100%");
        builder.put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK_SETTING.getKey(), "1b");
        builder.put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK_SETTING.getKey(), "1b");
        builder.put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_DISK_FLOOD_STAGE_WATERMARK_SETTING.getKey(), "1b");
        if (TEST_NIGHTLY) {
            builder.put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_INCOMING_RECOVERIES_SETTING.getKey(),
                    RandomNumbers.randomIntBetween(random, 5, 10));
            builder.put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_OUTGOING_RECOVERIES_SETTING.getKey(),
                    RandomNumbers.randomIntBetween(random, 5, 10));
        } else if (random.nextInt(100) &lt;= 90) {
            builder.put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_INCOMING_RECOVERIES_SETTING.getKey(),
                    RandomNumbers.randomIntBetween(random, 2, 5));
            builder.put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_OUTGOING_RECOVERIES_SETTING.getKey(),
                    RandomNumbers.randomIntBetween(random, 2, 5));
        }
        builder.put(RecoverySettings.INDICES_RECOVERY_RETRY_DELAY_STATE_SYNC_SETTING.getKey(), TimeValue.timeValueMillis(
                RandomNumbers.randomIntBetween(random, 20, 50)));
        builder.put(RecoverySettings.INDICES_RECOVERY_MAX_CONCURRENT_FILE_CHUNKS_SETTING.getKey(),
                    RandomNumbers.randomIntBetween(random, 1, 5));
        defaultSettings = builder.build();
        executor = EsExecutors.newScaling(
            "internal_test_cluster_executor",
            0,
            Integer.MAX_VALUE,
            0,
            TimeUnit.SECONDS,
            EsExecutors.daemonThreadFactory("test_" + clusterName));
    }
    public void setBootstrapMasterNodeIndex(int bootstrapMasterNodeIndex) {
        assert autoManageMasterNodes == false || bootstrapMasterNodeIndex == -1
            : "bootstrapMasterNodeIndex should be -1 if autoManageMasterNodes is true, but was " + bootstrapMasterNodeIndex;
        this.bootstrapMasterNodeIndex = bootstrapMasterNodeIndex;
    }
    @Override
    public String getClusterName() {
        return clusterName;
    }
<a name="3"></a>
    public String[] getNodeNames() {
        return nodes.keySet().toArray(Strings.EMPTY_ARRAY);
    <font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>}
    private Settings getSettings(int nodeOrdinal, long nodeSeed, Settings others) {
        Builder builder = Settings.builder().put(defaultSettings)</b></font>
            .put(getRandomNodeSettings(nodeSeed));
        Settings settings = nodeConfigurationSource.nodeSettings(nodeOrdinal);
        if (settings != null) {
            if (settings.get(ClusterName.CLUSTER_NAME_SETTING.getKey()) != null) {
                throw new IllegalStateException("Tests must not set a '" + ClusterName.CLUSTER_NAME_SETTING.getKey()
                        + "' as a node setting set '" + ClusterName.CLUSTER_NAME_SETTING.getKey() + "': ["
                        + settings.get(ClusterName.CLUSTER_NAME_SETTING.getKey()) + "]");
            }
            builder.put(settings);
        }
        if (others != null) {
            builder.put(others);
        }
        builder.put(ClusterName.CLUSTER_NAME_SETTING.getKey(), clusterName);
        return builder.build();
    }
    public Collection&lt;Class&lt;? extends Plugin&gt;&gt; getPlugins() {
        Set&lt;Class&lt;? extends Plugin&gt;&gt; plugins = new HashSet&lt;&gt;(nodeConfigurationSource.nodePlugins());
        plugins.addAll(mockPlugins);
        return plugins;
    }
    private static Settings getRandomNodeSettings(long seed) {
        Random random = new Random(seed);
        Builder builder = Settings.builder();
        builder.put(TransportSettings.TRANSPORT_COMPRESS.getKey(), rarely(random));
        if (random.nextBoolean()) {
            builder.put("cache.recycler.page.type", RandomPicks.randomFrom(random, PageCacheRecycler.Type.values()));
        }
        builder.put(EsExecutors.PROCESSORS_SETTING.getKey(), 1 + random.nextInt(3));
<a name="2"></a>
        if (random.nextBoolean()) {
            <font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>builder.put(TransportSettings.CONNECTIONS_PER_NODE_RECOVERY.getKey(), random.nextInt(2) + 1);
            builder.put(TransportSettings.CONNECTIONS_PER_NODE_BULK.getKey(), random.nextInt(3) + 1);
            builder.put(TransportSettings.CONNECTIONS_PER_NODE_REG.getKey(), random.nextInt(6) + 1);
        }</b></font>
        if (random.nextBoolean()) {
            builder.put(MappingUpdatedAction.INDICES_MAPPING_DYNAMIC_TIMEOUT_SETTING.getKey(),
                    timeValueSeconds(RandomNumbers.randomIntBetween(random, 10, 30)).getStringRep());
        }
        if (random.nextInt(10) == 0) {
            builder.put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_TYPE_SETTING.getKey(), "noop");
        }
        if (random.nextBoolean()) {
            if (random.nextInt(10) == 0) {                 builder.put(RecoverySettings.INDICES_RECOVERY_MAX_BYTES_PER_SEC_SETTING.getKey(),
                        new ByteSizeValue(RandomNumbers.randomIntBetween(random, 1, 10), ByteSizeUnit.MB));
            } else {
                builder.put(RecoverySettings.INDICES_RECOVERY_MAX_BYTES_PER_SEC_SETTING.getKey(),
                        new ByteSizeValue(RandomNumbers.randomIntBetween(random, 10, 200), ByteSizeUnit.MB));
            }
        }
        if (random.nextBoolean()) {
            builder.put(TransportSettings.PING_SCHEDULE.getKey(), RandomNumbers.randomIntBetween(random, 100, 2000) + "ms");
        }
        return builder.build();
<a name="1"></a>    }
    public static String clusterName(String prefix, long clusterSeed) {
        StringBuilder builder = <font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>new StringBuilder(prefix);
        builder.append("-TEST_WORKER_VM=[").append(ESTestCase.TEST_WORKER_VM_ID).append(']');
        builder.append("-CLUSTER_SEED=[").append(clusterSeed).append(']');
        builder.append("-HASH=[").append(SeedUtils.formatSeed</b></font>(System.nanoTime())).append(']');
        return builder.toString();
    }
    private void ensureOpen() {
        if (!open.get()) {
            throw new RuntimeException("Cluster is already closed");
        }
    }
    private NodeAndClient getOrBuildRandomNode() {
        assert Thread.holdsLock(this);
        final NodeAndClient randomNodeAndClient = getRandomNodeAndClient();
        if (randomNodeAndClient != null) {
            return randomNodeAndClient;
        }
        final Runnable onTransportServiceStarted = () -&gt; {}; 
        final int nodeId = nextNodeId.getAndIncrement();
        final Settings settings = getNodeSettings(nodeId, random.nextLong(), Settings.EMPTY);
        final Settings nodeSettings = Settings.builder()
                .putList(INITIAL_MASTER_NODES_SETTING.getKey(), Node.NODE_NAME_SETTING.get(settings))
                .put(settings)
                .build();
        final NodeAndClient buildNode = buildNode(nodeId, nodeSettings, false, onTransportServiceStarted);
        assert nodes.isEmpty();
        buildNode.startNode();
        publishNode(buildNode);
        return buildNode;
    }
    private NodeAndClient getRandomNodeAndClient() {
        return getRandomNodeAndClient(nc -&gt; true);
    }
    private synchronized NodeAndClient getRandomNodeAndClient(Predicate&lt;NodeAndClient&gt; predicate) {
        ensureOpen();
        List&lt;NodeAndClient&gt; values = nodes.values().stream().filter(predicate).collect(Collectors.toList());
        if (values.isEmpty() == false) {
            return randomFrom(random, values);
        }
        return null;
    }
    public synchronized void ensureAtLeastNumDataNodes(int n) {
        int size = numDataNodes();
        if (size &lt; n) {
            logger.info("increasing cluster size from {} to {}", size, n);
            if (numSharedDedicatedMasterNodes &gt; 0) {
                startDataOnlyNodes(n - size);
            } else {
                startNodes(n - size);
            }
            validateClusterFormed();
        }
    }
    public synchronized void ensureAtMostNumDataNodes(int n) throws IOException {
        int size = numDataNodes();
        if (size &lt;= n) {
            return;
        }
        final Stream&lt;NodeAndClient&gt; collection = n == 0
                ? nodes.values().stream()
                : nodes.values().stream()
                        .filter(DATA_NODE_PREDICATE.and(new NodeNamePredicate(getMasterName()).negate()));
        final Iterator&lt;NodeAndClient&gt; values = collection.iterator();
        logger.info("changing cluster size from {} data nodes to {}", size, n);
        Set&lt;NodeAndClient&gt; nodesToRemove = new HashSet&lt;&gt;();
        int numNodesAndClients = 0;
        while (values.hasNext() &amp;&amp; numNodesAndClients++ &lt; size - n) {
            NodeAndClient next = values.next();
            nodesToRemove.add(next);
        }
        stopNodesAndClients(nodesToRemove);
        if (!nodesToRemove.isEmpty() &amp;&amp; size() &gt; 0) {
            validateClusterFormed();
        }
    }
    private Settings getNodeSettings(final int nodeId, final long seed, final Settings extraSettings) {
        final Settings settings = getSettings(nodeId, seed, extraSettings);
        final String name = buildNodeName(nodeId, settings);
        final Settings.Builder updatedSettings = Settings.builder();
        updatedSettings.put(Environment.PATH_HOME_SETTING.getKey(), baseDir);
        if (numDataPaths &gt; 1) {
            updatedSettings.putList(Environment.PATH_DATA_SETTING.getKey(), IntStream.range(0, numDataPaths).mapToObj(i -&gt;
                baseDir.resolve(name).resolve("d" + i).toString()).collect(Collectors.toList()));
        } else {
            updatedSettings.put(Environment.PATH_DATA_SETTING.getKey(), baseDir.resolve(name));
        }
        updatedSettings.put(Environment.PATH_SHARED_DATA_SETTING.getKey(), baseDir.resolve(name + "-shared"));
        updatedSettings.put(settings);
        updatedSettings.put("node.name", name);
        updatedSettings.put(NodeEnvironment.NODE_ID_SEED_SETTING.getKey(), seed);
        if (autoManageMasterNodes) {
            assertThat("if master nodes are automatically managed then nodes must complete a join cycle when starting",
                updatedSettings.get(INITIAL_STATE_TIMEOUT_SETTING.getKey()), nullValue());
        }
        return updatedSettings.build();
    }
    private synchronized NodeAndClient buildNode(int nodeId, Settings settings,
                                    boolean reuseExisting, Runnable onTransportServiceStarted) {
        assert Thread.holdsLock(this);
        ensureOpen();
        Collection&lt;Class&lt;? extends Plugin&gt;&gt; plugins = getPlugins();
        String name = settings.get("node.name");
        final NodeAndClient nodeAndClient = nodes.get(name);
        if (reuseExisting &amp;&amp; nodeAndClient != null) {
            onTransportServiceStarted.run();             return nodeAndClient;
        }
        assert reuseExisting || nodeAndClient == null : "node name [" + name + "] already exists but not allowed to use it";
        MockNode node = new MockNode(
                settings,
                plugins,
                nodeConfigurationSource.nodeConfigPath(nodeId),
                forbidPrivateIndexSettings);
        node.injector().getInstance(TransportService.class).addLifecycleListener(new LifecycleListener() {
            @Override
            public void afterStart() {
                onTransportServiceStarted.run();
            }
        });
        return new NodeAndClient(name, node, settings, nodeId);
    }
    private String getNodePrefix(Settings settings) {
        return nodePrefix + getRoleSuffix(settings);
    }
    private String buildNodeName(int id, Settings settings) {
        return getNodePrefix(settings) + id;
    }
    private static String getRoleSuffix(Settings settings) {
        String suffix = "";
        if (Node.NODE_MASTER_SETTING.exists(settings) &amp;&amp; Node.NODE_MASTER_SETTING.get(settings)) {
            suffix = suffix + DiscoveryNodeRole.MASTER_ROLE.roleNameAbbreviation();
        }
        if (Node.NODE_DATA_SETTING.exists(settings) &amp;&amp; Node.NODE_DATA_SETTING.get(settings)) {
            suffix = suffix + DiscoveryNodeRole.DATA_ROLE.roleNameAbbreviation();
        }
        if (Node.NODE_MASTER_SETTING.exists(settings) &amp;&amp; Node.NODE_MASTER_SETTING.get(settings) == false &amp;&amp;
            Node.NODE_DATA_SETTING.exists(settings) &amp;&amp; Node.NODE_DATA_SETTING.get(settings) == false
            ) {
            suffix = suffix + "c";
        }
        return suffix;
    }
    @Override
    public synchronized Client client() {
        ensureOpen();
        return getOrBuildRandomNode().client();
    }
    public Client dataNodeClient() {
        return getRandomNodeAndClient(DATA_NODE_PREDICATE).client();
    }
    public Client masterClient() {
        NodeAndClient randomNodeAndClient = getRandomNodeAndClient(new NodeNamePredicate(getMasterName()));
        if (randomNodeAndClient != null) {
            return randomNodeAndClient.nodeClient();         }
        throw new AssertionError("No master client found");
    }
    public Client nonMasterClient() {
        NodeAndClient randomNodeAndClient = getRandomNodeAndClient(new NodeNamePredicate(getMasterName()).negate());
        if (randomNodeAndClient != null) {
            return randomNodeAndClient.nodeClient();         }
        throw new AssertionError("No non-master client found");
    }
    public synchronized Client coordOnlyNodeClient() {
        ensureOpen();
        NodeAndClient randomNodeAndClient = getRandomNodeAndClient(NO_DATA_NO_MASTER_PREDICATE);
        if (randomNodeAndClient != null) {
            return randomNodeAndClient.client();
        }
        int nodeId = nextNodeId.getAndIncrement();
        Settings settings = getSettings(nodeId, random.nextLong(), Settings.EMPTY);
        startCoordinatingOnlyNode(settings);
        return getRandomNodeAndClient(NO_DATA_NO_MASTER_PREDICATE).client();
    }
    public synchronized String startCoordinatingOnlyNode(Settings settings) {
        ensureOpen();         Builder builder = Settings.builder().put(settings).put(Node.NODE_MASTER_SETTING.getKey(), false)
            .put(Node.NODE_DATA_SETTING.getKey(), false);
        return startNode(builder);
    }
    public Client client(String nodeName) {
        NodeAndClient nodeAndClient = nodes.get(nodeName);
        if (nodeAndClient != null) {
            return nodeAndClient.client();
        }
        throw new AssertionError("No node found with name: [" + nodeName + "]");
    }
    public Client smartClient() {
        NodeAndClient randomNodeAndClient = getRandomNodeAndClient();
        if (randomNodeAndClient != null) {
            return randomNodeAndClient.nodeClient();
        }
        throw new AssertionError("No smart client found");
    }
    @Override
    public synchronized void close() throws IOException {
        if (this.open.compareAndSet(true, false)) {
            if (activeDisruptionScheme != null) {
                activeDisruptionScheme.testClusterClosed();
                activeDisruptionScheme = null;
            }
            try {
                IOUtils.close(nodes.values());
            } finally {
                nodes = Collections.emptyNavigableMap();
                executor.shutdownNow();
            }
        }
    }
    private final class NodeAndClient implements Closeable {
        private MockNode node;
        private final Settings originalNodeSettings;
        private Client nodeClient;
        private final AtomicBoolean closed = new AtomicBoolean(false);
        private final String name;
        private final int nodeAndClientId;
        NodeAndClient(String name, MockNode node, Settings originalNodeSettings, int nodeAndClientId) {
            this.node = node;
            this.name = name;
            this.originalNodeSettings = originalNodeSettings;
            this.nodeAndClientId = nodeAndClientId;
            markNodeDataDirsAsNotEligibleForWipe(node);
        }
        Node node() {
            if (closed.get()) {
                throw new RuntimeException("already closed");
            }
            return node;
        }
        public int nodeAndClientId() {
            return nodeAndClientId;
        }
        public String getName() {
            return name;
        }
        public boolean isMasterEligible() {
            return Node.NODE_MASTER_SETTING.get(node.settings());
        }
        Client client() {
            return getOrBuildNodeClient();
        }
        Client nodeClient() {
            if (closed.get()) {
                throw new RuntimeException("already closed");
            }
            return getOrBuildNodeClient();
        }
        private Client getOrBuildNodeClient() {
            synchronized (InternalTestCluster.this) {
                if (closed.get()) {
                    throw new RuntimeException("already closed");
                }
                if (nodeClient == null) {
                    nodeClient = node.client();
                }
                return nodeClient;
            }
        }
        void resetClient() {
            if (closed.get() == false) {
                Releasables.close(nodeClient);
                nodeClient = null;
            }
        }
        void startNode() {
            boolean success = false;
            try {
                node.start();
                success = true;
            } catch (NodeValidationException e) {
                throw new RuntimeException(e);
            } finally {
                if (success == false) {
                    IOUtils.closeWhileHandlingException(node);
                }
            }
        }
        Settings closeForRestart(RestartCallback callback) throws Exception {
            assert callback != null;
            close();
            removeNode(this);
            Settings callbackSettings = callback.onNodeStopped(name);
            assert callbackSettings != null;
            Settings.Builder newSettings = Settings.builder();
            if (autoManageMasterNodes) {
                newSettings.putList(INITIAL_MASTER_NODES_SETTING.getKey());
            }
            newSettings.put(callbackSettings);
            clearDataIfNeeded(callback);
            return newSettings.build();
        }
        private void clearDataIfNeeded(RestartCallback callback) throws IOException {
            if (callback.clearData(name)) {
                NodeEnvironment nodeEnv = node.getNodeEnvironment();
                if (nodeEnv.hasNodeFile()) {
                    final Path[] locations = nodeEnv.nodeDataPaths();
                    logger.debug("removing node data paths: [{}]", Arrays.toString(locations));
                    IOUtils.rm(locations);
                }
            }
        }
        private void recreateNode(final Settings newSettings, final Runnable onTransportServiceStarted) {
            if (closed.get() == false) {
                throw new IllegalStateException("node " + name + " should be closed before recreating it");
            }
            final long newIdSeed = NodeEnvironment.NODE_ID_SEED_SETTING.get(node.settings()) + 1;
            Settings finalSettings = Settings.builder()
                    .put(originalNodeSettings)
                    .put(newSettings)
                    .put(NodeEnvironment.NODE_ID_SEED_SETTING.getKey(), newIdSeed)
                    .build();
            Collection&lt;Class&lt;? extends Plugin&gt;&gt; plugins = node.getClasspathPlugins();
            node = new MockNode(finalSettings, plugins);
            node.injector().getInstance(TransportService.class).addLifecycleListener(new LifecycleListener() {
                @Override
                public void afterStart() {
                    onTransportServiceStarted.run();
                }
            });
            closed.set(false);
            markNodeDataDirsAsNotEligibleForWipe(node);
        }
        @Override
        public void close() throws IOException {
            assert Thread.holdsLock(InternalTestCluster.this);
            try {
                resetClient();
            } finally {
                closed.set(true);
                markNodeDataDirsAsPendingForWipe(node);
                node.close();
                try {
                    if (node.awaitClose(10, TimeUnit.SECONDS) == false) {
                        throw new IOException("Node didn't close within 10 seconds.");
                    }
                } catch (InterruptedException e) {
                    throw new AssertionError("Interruption while waiting for the node to close", e);
                }
            }
        }
        private void markNodeDataDirsAsPendingForWipe(Node node) {
            assert Thread.holdsLock(InternalTestCluster.this);
            NodeEnvironment nodeEnv = node.getNodeEnvironment();
            if (nodeEnv.hasNodeFile()) {
                dataDirToClean.addAll(Arrays.asList(nodeEnv.nodeDataPaths()));
            }
        }
        private void markNodeDataDirsAsNotEligibleForWipe(Node node) {
            assert Thread.holdsLock(InternalTestCluster.this);
            NodeEnvironment nodeEnv = node.getNodeEnvironment();
            if (nodeEnv.hasNodeFile()) {
                dataDirToClean.removeAll(Arrays.asList(nodeEnv.nodeDataPaths()));
            }
        }
    }
    @Override
    public synchronized void beforeTest(Random random) throws IOException, InterruptedException {
        super.beforeTest(random);
        reset(true);
    }
    private synchronized void reset(boolean wipeData) throws IOException {
        for (NodeAndClient nodeAndClient : nodes.values()) {
            TransportService transportService = nodeAndClient.node.injector().getInstance(TransportService.class);
            if (transportService instanceof MockTransportService) {
                final MockTransportService mockTransportService = (MockTransportService) transportService;
                mockTransportService.clearAllRules();
            }
        }
        randomlyResetClients();
        final int newSize = sharedNodesSeeds.length;
        if (nextNodeId.get() == newSize &amp;&amp; nodes.size() == newSize) {
            if (wipeData) {
                wipePendingDataDirectories();
            }
            logger.debug("Cluster hasn't changed - moving out - nodes: [{}] nextNodeId: [{}] numSharedNodes: [{}]",
                    nodes.keySet(), nextNodeId.get(), newSize);
            return;
        }
        logger.debug("Cluster is NOT consistent - restarting shared nodes - nodes: [{}] nextNodeId: [{}] numSharedNodes: [{}]",
                nodes.keySet(), nextNodeId.get(), newSize);
        final List&lt;NodeAndClient&gt; toClose = new ArrayList&lt;&gt;();
        for (NodeAndClient nodeAndClient : nodes.values()) {
            if (nodeAndClient.nodeAndClientId() &gt;= sharedNodesSeeds.length) {
                logger.debug("Close Node [{}] not shared", nodeAndClient.name);
                toClose.add(nodeAndClient);
            }
        }
        stopNodesAndClients(toClose);
        if (wipeData) {
            wipePendingDataDirectories();
        }
        assertTrue("expected at least one master-eligible node left in " + nodes,
            nodes.isEmpty() || nodes.values().stream().anyMatch(NodeAndClient::isMasterEligible));
        final int prevNodeCount = nodes.size();
        assert newSize == numSharedDedicatedMasterNodes + numSharedDataNodes + numSharedCoordOnlyNodes;
        final List&lt;NodeAndClient&gt; toStartAndPublish = new ArrayList&lt;&gt;();         final Runnable onTransportServiceStarted = () -&gt; rebuildUnicastHostFiles(toStartAndPublish);
        final List&lt;Settings&gt; settings = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; numSharedDedicatedMasterNodes; i++) {
            final Settings.Builder extraSettings = Settings.builder();
            extraSettings.put(Node.NODE_MASTER_SETTING.getKey(), true);
            extraSettings.put(Node.NODE_DATA_SETTING.getKey(), false);
            settings.add(getNodeSettings(i, sharedNodesSeeds[i], extraSettings.build()));
        }
        for (int i = numSharedDedicatedMasterNodes; i &lt; numSharedDedicatedMasterNodes + numSharedDataNodes; i++) {
            final Settings.Builder extraSettings = Settings.builder();
            if (numSharedDedicatedMasterNodes &gt; 0) {
                extraSettings.put(Node.NODE_MASTER_SETTING.getKey(), false).build();
                extraSettings.put(Node.NODE_DATA_SETTING.getKey(), true).build();
            }
            settings.add(getNodeSettings(i, sharedNodesSeeds[i], extraSettings.build()));
        }
        for (int i = numSharedDedicatedMasterNodes + numSharedDataNodes;
             i &lt; numSharedDedicatedMasterNodes + numSharedDataNodes + numSharedCoordOnlyNodes; i++) {
            final Builder extraSettings = Settings.builder().put(Node.NODE_MASTER_SETTING.getKey(), false)
                .put(Node.NODE_DATA_SETTING.getKey(), false);
            settings.add(getNodeSettings(i, sharedNodesSeeds[i], extraSettings.build()));
        }
        int autoBootstrapMasterNodeIndex = -1;
        final List&lt;String&gt; masterNodeNames = settings.stream()
                .filter(Node.NODE_MASTER_SETTING::get)
                .map(Node.NODE_NAME_SETTING::get)
                .collect(Collectors.toList());
        if (prevNodeCount == 0 &amp;&amp; autoManageMasterNodes) {
            if (numSharedDedicatedMasterNodes &gt; 0) {
                autoBootstrapMasterNodeIndex = RandomNumbers.randomIntBetween(random, 0, numSharedDedicatedMasterNodes - 1);
            } else if (numSharedDataNodes &gt; 0) {
                autoBootstrapMasterNodeIndex = RandomNumbers.randomIntBetween(random, 0, numSharedDataNodes - 1);
            }
        }
        final List&lt;Settings&gt; updatedSettings = bootstrapMasterNodeWithSpecifiedIndex(settings);
        for (int i = 0; i &lt; numSharedDedicatedMasterNodes + numSharedDataNodes + numSharedCoordOnlyNodes; i++) {
            Settings nodeSettings = updatedSettings.get(i);
            if (i == autoBootstrapMasterNodeIndex) {
                nodeSettings = Settings.builder().putList(INITIAL_MASTER_NODES_SETTING.getKey(), masterNodeNames).put(nodeSettings).build();
            }
            final NodeAndClient nodeAndClient = buildNode(i, nodeSettings, true, onTransportServiceStarted);
            toStartAndPublish.add(nodeAndClient);
        }
        startAndPublishNodesAndClients(toStartAndPublish);
        nextNodeId.set(newSize);
        assert size() == newSize;
        if (autoManageMasterNodes &amp;&amp; newSize &gt; 0) {
            validateClusterFormed();
        }
        logger.debug("Cluster is consistent again - nodes: [{}] nextNodeId: [{}] numSharedNodes: [{}]",
                nodes.keySet(), nextNodeId.get(), newSize);
    }
    public synchronized void validateClusterFormed() {
        final Set&lt;DiscoveryNode&gt; expectedNodes = new HashSet&lt;&gt;();
        for (NodeAndClient nodeAndClient : nodes.values()) {
            expectedNodes.add(getInstanceFromNode(ClusterService.class, nodeAndClient.node()).localNode());
        }
        logger.trace("validating cluster formed, expecting {}", expectedNodes);
        try {
            assertBusy(() -&gt; {
                final List&lt;ClusterState&gt; states = nodes.values().stream()
                    .map(node -&gt; getInstanceFromNode(ClusterService.class, node.node()))
                    .map(ClusterService::state)
                    .collect(Collectors.toList());
                final String debugString = ", expected nodes: " + expectedNodes + " and actual cluster states " + states;
                assertTrue("Missing master" + debugString, states.stream().allMatch(cs -&gt; cs.nodes().getMasterNodeId() != null));
                assertEquals("Not all masters in same term" + debugString, 1,
                    states.stream().mapToLong(ClusterState::term).distinct().count());
                states.forEach(cs -&gt; {
                    DiscoveryNodes discoveryNodes = cs.nodes();
                    assertEquals("Node size mismatch" + debugString, expectedNodes.size(), discoveryNodes.getSize());
                    for (DiscoveryNode expectedNode : expectedNodes) {
                        assertTrue("Expected node to exist: " + expectedNode + debugString, discoveryNodes.nodeExists(expectedNode));
                    }
                });
            }, 30, TimeUnit.SECONDS);
        } catch (AssertionError ae) {
            throw new IllegalStateException("cluster failed to form", ae);
        } catch (Exception e) {
            throw new IllegalStateException(e);
        }
    }
    @Override
    public synchronized void afterTest() {
        wipePendingDataDirectories();
        randomlyResetClients();     }
    @Override
    public void beforeIndexDeletion() throws Exception {
        assertNoPendingIndexOperations();
        //check that shards that have same sync id also contain same number of documents
        assertSameSyncIdSameDocs();
        assertOpenTranslogReferences();
    }
    private void assertSameSyncIdSameDocs() {
        Map&lt;String, Long&gt; docsOnShards = new HashMap&lt;&gt;();
        final Collection&lt;NodeAndClient&gt; nodesAndClients = nodes.values();
        for (NodeAndClient nodeAndClient : nodesAndClients) {
            IndicesService indexServices = getInstance(IndicesService.class, nodeAndClient.name);
            for (IndexService indexService : indexServices) {
                for (IndexShard indexShard : indexService) {
                    try {
                        CommitStats commitStats = indexShard.commitStats();
                        String syncId = commitStats.getUserData().get(Engine.SYNC_COMMIT_ID);
                        if (syncId != null) {
                            long liveDocsOnShard = commitStats.getNumDocs();
                            if (docsOnShards.get(syncId) != null) {
                                assertThat("sync id is equal but number of docs does not match on node "
                                    + nodeAndClient.name + ". expected " + docsOnShards.get(syncId) + " but got "
                                    + liveDocsOnShard, docsOnShards.get(syncId), equalTo(liveDocsOnShard));
                            } else {
                                docsOnShards.put(syncId, liveDocsOnShard);
                            }
                        }
                    } catch (AlreadyClosedException e) {
                    }
                }
            }
        }
    }
    private void assertNoPendingIndexOperations() throws Exception {
        assertBusy(() -&gt; {
            for (NodeAndClient nodeAndClient : nodes.values()) {
                IndicesService indexServices = getInstance(IndicesService.class, nodeAndClient.name);
                for (IndexService indexService : indexServices) {
                    for (IndexShard indexShard : indexService) {
                        List&lt;String&gt; operations = indexShard.getActiveOperations();
                        if (operations.size() &gt; 0) {
                            throw new AssertionError(
                                "shard " + indexShard.shardId() + " on node [" + nodeAndClient.name + "] has pending operations:\n --&gt; " +
                                    String.join("\n --&gt; ", operations)
                            );
                        }
                    }
                }
            }
        }, 60, TimeUnit.SECONDS);
    }
    private void assertOpenTranslogReferences() throws Exception {
        assertBusy(() -&gt; {
            for (NodeAndClient nodeAndClient : nodes.values()) {
                IndicesService indexServices = getInstance(IndicesService.class, nodeAndClient.name);
                for (IndexService indexService : indexServices) {
                    for (IndexShard indexShard : indexService) {
                        try {
                            if (IndexShardTestCase.getEngine(indexShard) instanceof InternalEngine) {
                                IndexShardTestCase.getTranslog(indexShard).getDeletionPolicy().assertNoOpenTranslogRefs();
                            }
                        } catch (AlreadyClosedException ok) {
                        }
                    }
                }
            }
        }, 60, TimeUnit.SECONDS);
    }
    public void assertConsistentHistoryBetweenTranslogAndLuceneIndex() throws IOException {
        for (NodeAndClient nodeAndClient : nodes.values()) {
            IndicesService indexServices = getInstance(IndicesService.class, nodeAndClient.name);
            for (IndexService indexService : indexServices) {
                for (IndexShard indexShard : indexService) {
                    try {
                        IndexShardTestCase.assertConsistentHistoryBetweenTranslogAndLucene(indexShard);
                    } catch (AlreadyClosedException ignored) {
                    }
                }
            }
        }
    }
    private IndexShard getShardOrNull(ClusterState clusterState, ShardRouting shardRouting) {
        if (shardRouting == null || shardRouting.assignedToNode() == false) {
            return null;
        }
        final DiscoveryNode assignedNode = clusterState.nodes().get(shardRouting.currentNodeId());
        if (assignedNode == null) {
            return null;
        }
        return getInstance(IndicesService.class, assignedNode.getName()).getShardOrNull(shardRouting.shardId());
    }
    public void assertSeqNos() throws Exception {
        assertBusy(() -&gt; {
            final ClusterState state = clusterService().state();
            for (ObjectObjectCursor&lt;String, IndexRoutingTable&gt; indexRoutingTable : state.routingTable().indicesRouting()) {
                for (IntObjectCursor&lt;IndexShardRoutingTable&gt; indexShardRoutingTable : indexRoutingTable.value.shards()) {
                    ShardRouting primaryShardRouting = indexShardRoutingTable.value.primaryShard();
                    final IndexShard primaryShard = getShardOrNull(state, primaryShardRouting);
                    if (primaryShard == null) {
                        continue; //just ignore - shard movement
                    }
                    final SeqNoStats primarySeqNoStats;
                    final ObjectLongMap&lt;String&gt; syncGlobalCheckpoints;
                    try {
                        primarySeqNoStats = primaryShard.seqNoStats();
                        syncGlobalCheckpoints = primaryShard.getInSyncGlobalCheckpoints();
                    } catch (AlreadyClosedException ex) {
                        continue;                     }
                    assertThat(primaryShardRouting + " should have set the global checkpoint",
                        primarySeqNoStats.getGlobalCheckpoint(), not(equalTo(SequenceNumbers.UNASSIGNED_SEQ_NO)));
                    for (ShardRouting replicaShardRouting : indexShardRoutingTable.value.replicaShards()) {
                        final IndexShard replicaShard = getShardOrNull(state, replicaShardRouting);
                        if (replicaShard == null) {
                            continue; //just ignore - shard movement
                        }
                        final SeqNoStats seqNoStats;
                        try {
                            seqNoStats = replicaShard.seqNoStats();
                        } catch (AlreadyClosedException e) {
                            continue;                         }
                        assertThat(replicaShardRouting + " seq_no_stats mismatch", seqNoStats, equalTo(primarySeqNoStats));
                        assertThat(replicaShardRouting + " global checkpoint syncs mismatch", seqNoStats.getGlobalCheckpoint(),
                            equalTo(syncGlobalCheckpoints.get(replicaShardRouting.allocationId().getId())));
                    }
                }
            }
        }, 60, TimeUnit.SECONDS);
    }
    public void assertSameDocIdsOnShards() throws Exception {
        assertBusy(() -&gt; {
            ClusterState state = client().admin().cluster().prepareState().get().getState();
            for (ObjectObjectCursor&lt;String, IndexRoutingTable&gt; indexRoutingTable : state.routingTable().indicesRouting()) {
                for (IntObjectCursor&lt;IndexShardRoutingTable&gt; indexShardRoutingTable : indexRoutingTable.value.shards()) {
                    ShardRouting primaryShardRouting = indexShardRoutingTable.value.primaryShard();
                    IndexShard primaryShard = getShardOrNull(state, primaryShardRouting);
                    if (primaryShard == null) {
                        continue;
                    }
                    final List&lt;DocIdSeqNoAndSource&gt; docsOnPrimary;
                    try {
                        docsOnPrimary = IndexShardTestCase.getDocIdAndSeqNos(primaryShard);
                    } catch (AlreadyClosedException ex) {
                        continue;
                    }
                    for (ShardRouting replicaShardRouting : indexShardRoutingTable.value.replicaShards()) {
                        IndexShard replicaShard = getShardOrNull(state, replicaShardRouting);
                        if (replicaShard == null) {
                            continue;
                        }
                        final List&lt;DocIdSeqNoAndSource&gt; docsOnReplica;
                        try {
                            docsOnReplica = IndexShardTestCase.getDocIdAndSeqNos(replicaShard);
                        } catch (AlreadyClosedException ex) {
                            continue;
                        }
                        assertThat("out of sync shards: primary=[" + primaryShardRouting + "] num_docs_on_primary=[" + docsOnPrimary.size()
                                + "] vs replica=[" + replicaShardRouting + "] num_docs_on_replica=[" + docsOnReplica.size() + "]",
                            docsOnReplica, equalTo(docsOnPrimary));
                    }
                }
            }
        });
    }
    private void randomlyResetClients() {
        assert Thread.holdsLock(this);
        if (RandomizedTest.isNightly() &amp;&amp; rarely(random)) {
            final Collection&lt;NodeAndClient&gt; nodesAndClients = nodes.values();
            for (NodeAndClient nodeAndClient : nodesAndClients) {
                nodeAndClient.resetClient();
            }
        }
    }
    public synchronized void wipePendingDataDirectories() {
        if (!dataDirToClean.isEmpty()) {
            try {
                for (Path path : dataDirToClean) {
                    try {
                        FileSystemUtils.deleteSubDirectories(path);
                        logger.info("Successfully wiped data directory for node location: {}", path);
                    } catch (IOException e) {
                        logger.info("Failed to wipe data directory for node location: {}", path);
                    }
                }
            } finally {
                dataDirToClean.clear();
            }
        }
    }
    public ClusterService clusterService() {
        return clusterService(null);
    }
    public ClusterService clusterService(@Nullable String node) {
        return getInstance(ClusterService.class, node);
    }
    public &lt;T&gt; Iterable&lt;T&gt; getInstances(Class&lt;T&gt; clazz) {
        return nodes.values().stream().map(node -&gt; getInstanceFromNode(clazz, node.node)).collect(Collectors.toList());
    }
    public &lt;T&gt; Iterable&lt;T&gt; getDataNodeInstances(Class&lt;T&gt; clazz) {
        return getInstances(clazz, DATA_NODE_PREDICATE);
    }
    public synchronized &lt;T&gt; T getCurrentMasterNodeInstance(Class&lt;T&gt; clazz) {
        return getInstance(clazz, new NodeNamePredicate(getMasterName()));
    }
    public &lt;T&gt; Iterable&lt;T&gt; getDataOrMasterNodeInstances(Class&lt;T&gt; clazz) {
        return getInstances(clazz, DATA_NODE_PREDICATE.or(MASTER_NODE_PREDICATE));
    }
    private &lt;T&gt; Iterable&lt;T&gt; getInstances(Class&lt;T&gt; clazz, Predicate&lt;NodeAndClient&gt; predicate) {
        Iterable&lt;NodeAndClient&gt; filteredNodes = nodes.values().stream().filter(predicate)::iterator;
        List&lt;T&gt; instances = new ArrayList&lt;&gt;();
        for (NodeAndClient nodeAndClient : filteredNodes) {
            instances.add(getInstanceFromNode(clazz, nodeAndClient.node));
        }
        return instances;
    }
    public &lt;T&gt; T getInstance(Class&lt;T&gt; clazz, final String node) {
        return getInstance(clazz, nc -&gt; node == null || node.equals(nc.name));
    }
    public &lt;T&gt; T getDataNodeInstance(Class&lt;T&gt; clazz) {
        return getInstance(clazz, DATA_NODE_PREDICATE);
    }
    public &lt;T&gt; T getMasterNodeInstance(Class&lt;T&gt; clazz) {
        return getInstance(clazz, MASTER_NODE_PREDICATE);
    }
    private synchronized &lt;T&gt; T getInstance(Class&lt;T&gt; clazz, Predicate&lt;NodeAndClient&gt; predicate) {
        NodeAndClient randomNodeAndClient = getRandomNodeAndClient(predicate);
        assert randomNodeAndClient != null;
        return getInstanceFromNode(clazz, randomNodeAndClient.node);
    }
    public &lt;T&gt; T getInstance(Class&lt;T&gt; clazz) {
        return getInstance(clazz, nc -&gt; true);
    }
    private static &lt;T&gt; T getInstanceFromNode(Class&lt;T&gt; clazz, Node node) {
        return node.injector().getInstance(clazz);
    }
    public Settings dataPathSettings(String node) {
        return nodes.values()
            .stream()
            .filter(nc -&gt; nc.name.equals(node))
            .findFirst().get().node().settings()
            .filter(key -&gt; key.equals(Environment.PATH_DATA_SETTING.getKey()) ||  key.equals(Environment.PATH_SHARED_DATA_SETTING.getKey()));
    }
    @Override
    public int size() {
        return nodes.size();
    }
    @Override
    public InetSocketAddress[] httpAddresses() {
        List&lt;InetSocketAddress&gt; addresses = new ArrayList&lt;&gt;();
        for (HttpServerTransport httpServerTransport : getInstances(HttpServerTransport.class)) {
            addresses.add(httpServerTransport.boundAddress().publishAddress().address());
        }
        return addresses.toArray(new InetSocketAddress[0]);
    }
    public synchronized boolean stopRandomDataNode() throws IOException {
        ensureOpen();
        NodeAndClient nodeAndClient = getRandomNodeAndClient(DATA_NODE_PREDICATE);
        if (nodeAndClient != null) {
            logger.info("Closing random node [{}] ", nodeAndClient.name);
            stopNodesAndClient(nodeAndClient);
            return true;
        }
        return false;
    }
    public synchronized void stopRandomNode(final Predicate&lt;Settings&gt; filter) throws IOException {
        ensureOpen();
        NodeAndClient nodeAndClient = getRandomNodeAndClient(nc -&gt; filter.test(nc.node.settings()));
        if (nodeAndClient != null) {
            if (nodeAndClient.nodeAndClientId() &lt; sharedNodesSeeds.length &amp;&amp; nodeAndClient.isMasterEligible() &amp;&amp; autoManageMasterNodes
                &amp;&amp; nodes.values().stream()
                        .filter(NodeAndClient::isMasterEligible)
                        .filter(n -&gt; n.nodeAndClientId() &lt; sharedNodesSeeds.length)
                        .count() == 1) {
                throw new AssertionError("Tried to stop the only master eligible shared node");
            }
            logger.info("Closing filtered random node [{}] ", nodeAndClient.name);
            stopNodesAndClient(nodeAndClient);
        }
    }
    public synchronized void stopCurrentMasterNode() throws IOException {
        ensureOpen();
        assert size() &gt; 0;
        String masterNodeName = getMasterName();
        final NodeAndClient masterNode = nodes.get(masterNodeName);
        assert masterNode != null;
        logger.info("Closing master node [{}] ", masterNodeName);
        stopNodesAndClient(masterNode);
    }
    public synchronized void stopRandomNonMasterNode() throws IOException {
        NodeAndClient nodeAndClient = getRandomNodeAndClient(new NodeNamePredicate(getMasterName()).negate());
        if (nodeAndClient != null) {
            logger.info("Closing random non master node [{}] current master [{}] ", nodeAndClient.name, getMasterName());
            stopNodesAndClient(nodeAndClient);
        }
    }
    private synchronized void startAndPublishNodesAndClients(List&lt;NodeAndClient&gt; nodeAndClients) {
        if (nodeAndClients.size() &gt; 0) {
            final int newMasters = (int) nodeAndClients.stream().filter(NodeAndClient::isMasterEligible)
                .filter(nac -&gt; nodes.containsKey(nac.name) == false)                 .count();
            rebuildUnicastHostFiles(nodeAndClients);             List&lt;Future&lt;?&gt;&gt; futures = nodeAndClients.stream().map(node -&gt; executor.submit(node::startNode)).collect(Collectors.toList());
            try {
                for (Future&lt;?&gt; future : futures) {
                    future.get();
                }
            } catch (InterruptedException e) {
                throw new AssertionError("interrupted while starting nodes", e);
            } catch (ExecutionException e) {
                RuntimeException re = FutureUtils.rethrowExecutionException(e);
                re.addSuppressed(new RuntimeException("failed to start nodes"));
                throw re;
            }
            nodeAndClients.forEach(this::publishNode);
            if (autoManageMasterNodes &amp;&amp; newMasters &gt; 0) {
                validateClusterFormed();
            }
        }
    }
    private final Object discoveryFileMutex = new Object();
    private void rebuildUnicastHostFiles(List&lt;NodeAndClient&gt; newNodes) {
        synchronized (discoveryFileMutex) {
            try {
                final Collection&lt;NodeAndClient&gt; currentNodes = nodes.values();
                Stream&lt;NodeAndClient&gt; unicastHosts = Stream.concat(currentNodes.stream(), newNodes.stream());
                List&lt;String&gt; discoveryFileContents = unicastHosts.map(
                    nac -&gt; nac.node.injector().getInstance(TransportService.class)
                ).filter(Objects::nonNull)
                    .map(TransportService::getLocalNode).filter(Objects::nonNull).filter(DiscoveryNode::isMasterEligibleNode)
                    .map(n -&gt; n.getAddress().toString())
                    .distinct().collect(Collectors.toList());
                Set&lt;Path&gt; configPaths = Stream.concat(currentNodes.stream(), newNodes.stream())
                    .map(nac -&gt; nac.node.getEnvironment().configFile()).collect(Collectors.toSet());
                logger.debug("configuring discovery with {} at {}", discoveryFileContents, configPaths);
                for (final Path configPath : configPaths) {
                    Files.createDirectories(configPath);
                    Files.write(configPath.resolve(UNICAST_HOSTS_FILE), discoveryFileContents);
                }
            } catch (IOException e) {
                throw new AssertionError("failed to configure file-based discovery", e);
            }
        }
    }
    private void stopNodesAndClient(NodeAndClient nodeAndClient) throws IOException {
        stopNodesAndClients(Collections.singleton(nodeAndClient));
    }
    private synchronized void stopNodesAndClients(Collection&lt;NodeAndClient&gt; nodeAndClients) throws IOException {
        final Set&lt;String&gt; excludedNodeIds = excludeMasters(nodeAndClients);
        for (NodeAndClient nodeAndClient: nodeAndClients) {
            removeDisruptionSchemeFromNode(nodeAndClient);
            final NodeAndClient previous = removeNode(nodeAndClient);
            assert previous == nodeAndClient;
            nodeAndClient.close();
        }
        removeExclusions(excludedNodeIds);
    }
    public void restartRandomDataNode() throws Exception {
        restartRandomDataNode(EMPTY_CALLBACK);
    }
    public synchronized void restartRandomDataNode(RestartCallback callback) throws Exception {
        ensureOpen();
        NodeAndClient nodeAndClient = getRandomNodeAndClient(InternalTestCluster.DATA_NODE_PREDICATE);
        if (nodeAndClient != null) {
            restartNode(nodeAndClient, callback);
        }
    }
    public synchronized void restartNode(String nodeName, RestartCallback callback) throws Exception {
        ensureOpen();
        NodeAndClient nodeAndClient = nodes.get(nodeName);
        if (nodeAndClient != null) {
            restartNode(nodeAndClient, callback);
        }
    }
    public static final RestartCallback EMPTY_CALLBACK = new RestartCallback();
    public void fullRestart() throws Exception {
        fullRestart(EMPTY_CALLBACK);
    }
    public synchronized void rollingRestart(RestartCallback callback) throws Exception {
        int numNodesRestarted = 0;
        for (NodeAndClient nodeAndClient : nodes.values()) {
            callback.doAfterNodes(numNodesRestarted++, nodeAndClient.nodeClient());
            restartNode(nodeAndClient, callback);
        }
    }
    private void restartNode(NodeAndClient nodeAndClient, RestartCallback callback) throws Exception {
        assert Thread.holdsLock(this);
        logger.info("Restarting node [{}] ", nodeAndClient.name);
        if (activeDisruptionScheme != null) {
            activeDisruptionScheme.removeFromNode(nodeAndClient.name, this);
        }
        final Set&lt;String&gt; excludedNodeIds = excludeMasters(Collections.singleton(nodeAndClient));
        final Settings newSettings = nodeAndClient.closeForRestart(callback);
        removeExclusions(excludedNodeIds);
        nodeAndClient.recreateNode(newSettings, () -&gt; rebuildUnicastHostFiles(Collections.singletonList(nodeAndClient)));
        nodeAndClient.startNode();
        publishNode(nodeAndClient);
        if (callback.validateClusterForming() || excludedNodeIds.isEmpty() == false) {
            validateClusterFormed();
        }
    }
    private NodeAndClient removeNode(NodeAndClient nodeAndClient) {
        assert Thread.holdsLock(this);
        final NavigableMap&lt;String, NodeAndClient&gt; newNodes = new TreeMap&lt;&gt;(nodes);
        final NodeAndClient previous = newNodes.remove(nodeAndClient.name);
        nodes = Collections.unmodifiableNavigableMap(newNodes);
        return previous;
    }
    private Set&lt;String&gt; excludeMasters(Collection&lt;NodeAndClient&gt; nodeAndClients) {
        assert Thread.holdsLock(this);
        final Set&lt;String&gt; excludedNodeIds = new HashSet&lt;&gt;();
        if (autoManageMasterNodes &amp;&amp; nodeAndClients.size() &gt; 0) {
            final long currentMasters = nodes.values().stream().filter(NodeAndClient::isMasterEligible).count();
            final long stoppingMasters = nodeAndClients.stream().filter(NodeAndClient::isMasterEligible).count();
            assert stoppingMasters &lt;= currentMasters : currentMasters + " &lt; " + stoppingMasters;
            if (stoppingMasters != currentMasters &amp;&amp; stoppingMasters &gt; 0) {
                nodeAndClients.stream().filter(NodeAndClient::isMasterEligible).map(NodeAndClient::getName).forEach(excludedNodeIds::add);
                assert excludedNodeIds.size() == stoppingMasters;
                logger.info("adding voting config exclusions {} prior to restart/shutdown", excludedNodeIds);
                try {
                    client().execute(AddVotingConfigExclusionsAction.INSTANCE,
                            new AddVotingConfigExclusionsRequest(excludedNodeIds.toArray(Strings.EMPTY_ARRAY))).get();
                } catch (InterruptedException | ExecutionException e) {
                    throw new AssertionError("unexpected", e);
                }
            }
        }
        return excludedNodeIds;
    }
    private void removeExclusions(Set&lt;String&gt; excludedNodeIds) {
        assert Thread.holdsLock(this);
        if (excludedNodeIds.isEmpty() == false) {
            logger.info("removing voting config exclusions for {} after restart/shutdown", excludedNodeIds);
            try {
                Client client = getRandomNodeAndClient(node -&gt; excludedNodeIds.contains(node.name) == false).client();
                client.execute(ClearVotingConfigExclusionsAction.INSTANCE, new ClearVotingConfigExclusionsRequest()).get();
            } catch (InterruptedException | ExecutionException e) {
                throw new AssertionError("unexpected", e);
            }
        }
    }
    public synchronized void fullRestart(RestartCallback callback) throws Exception {
        int numNodesRestarted = 0;
        final Settings[] newNodeSettings = new Settings[nextNodeId.get()];
        final List&lt;NodeAndClient&gt; toStartAndPublish = new ArrayList&lt;&gt;();         for (NodeAndClient nodeAndClient : nodes.values()) {
            callback.doAfterNodes(numNodesRestarted++, nodeAndClient.nodeClient());
            logger.info("Stopping and resetting node [{}] ", nodeAndClient.name);
            if (activeDisruptionScheme != null) {
                activeDisruptionScheme.removeFromNode(nodeAndClient.name, this);
            }
            final Settings newSettings = nodeAndClient.closeForRestart(callback);
            newNodeSettings[nodeAndClient.nodeAndClientId()] = newSettings;
            toStartAndPublish.add(nodeAndClient);
        }
        callback.onAllNodesStopped();
        Randomness.shuffle(toStartAndPublish);
        for (NodeAndClient nodeAndClient : toStartAndPublish) {
            logger.info("recreating node [{}] ", nodeAndClient.name);
            nodeAndClient.recreateNode(newNodeSettings[nodeAndClient.nodeAndClientId()], () -&gt; rebuildUnicastHostFiles(toStartAndPublish));
        }
        startAndPublishNodesAndClients(toStartAndPublish);
        if (callback.validateClusterForming()) {
            validateClusterFormed();
        }
    }
    public String getMasterName() {
        return getMasterName(null);
    }
    public String getMasterName(@Nullable String viaNode) {
        try {
            Client client = viaNode != null ? client(viaNode) : client();
            return client.admin().cluster().prepareState().get().getState().nodes().getMasterNode().getName();
        } catch (Exception e) {
            logger.warn("Can't fetch cluster state", e);
            throw new RuntimeException("Can't get master node " + e.getMessage(), e);
        }
    }
    synchronized Set&lt;String&gt; allDataNodesButN(int count) {
        final int numNodes = numDataNodes() - count;
        assert size() &gt;= numNodes;
        Map&lt;String, NodeAndClient&gt; dataNodes =
            nodes
                .entrySet()
                .stream()
                .filter(entry -&gt; DATA_NODE_PREDICATE.test(entry.getValue()))
                .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
        final HashSet&lt;String&gt; set = new HashSet&lt;&gt;();
        final Iterator&lt;String&gt; iterator = dataNodes.keySet().iterator();
        for (int i = 0; i &lt; numNodes; i++) {
            assert iterator.hasNext();
            set.add(iterator.next());
        }
        return set;
    }
    public synchronized Set&lt;String&gt; nodesInclude(String index) {
        if (clusterService().state().routingTable().hasIndex(index)) {
            List&lt;ShardRouting&gt; allShards = clusterService().state().routingTable().allShards(index);
            DiscoveryNodes discoveryNodes = clusterService().state().getNodes();
            Set&lt;String&gt; nodes = new HashSet&lt;&gt;();
            for (ShardRouting shardRouting : allShards) {
                if (shardRouting.assignedToNode()) {
                    DiscoveryNode discoveryNode = discoveryNodes.get(shardRouting.currentNodeId());
                    nodes.add(discoveryNode.getName());
                }
            }
            return nodes;
        }
        return Collections.emptySet();
    }
    private List&lt;Settings&gt; bootstrapMasterNodeWithSpecifiedIndex(List&lt;Settings&gt; allNodesSettings) {
        assert Thread.holdsLock(this);
        if (bootstrapMasterNodeIndex == -1) {             return allNodesSettings;
        }
        int currentNodeId = numMasterNodes() - 1;
        List&lt;Settings&gt; newSettings = new ArrayList&lt;&gt;();
        for (Settings settings : allNodesSettings) {
            if (Node.NODE_MASTER_SETTING.get(settings) == false) {
                newSettings.add(settings);
            } else {
                currentNodeId++;
                if (currentNodeId != bootstrapMasterNodeIndex) {
                    newSettings.add(settings);
                } else {
                    List&lt;String&gt; nodeNames = new ArrayList&lt;&gt;();
                    for (Settings nodeSettings : getDataOrMasterNodeInstances(Settings.class)) {
                        if (Node.NODE_MASTER_SETTING.get(nodeSettings)) {
                            nodeNames.add(Node.NODE_NAME_SETTING.get(nodeSettings));
                        }
                    }
                    for (Settings nodeSettings : allNodesSettings) {
                        if (Node.NODE_MASTER_SETTING.get(nodeSettings)) {
                            nodeNames.add(Node.NODE_NAME_SETTING.get(nodeSettings));
                        }
                    }
                    newSettings.add(Settings.builder().put(settings)
                            .putList(ClusterBootstrapService.INITIAL_MASTER_NODES_SETTING.getKey(), nodeNames)
                            .build());
                    setBootstrapMasterNodeIndex(-1);
                }
            }
        }
        return newSettings;
    }
    public String startNode() {
        return startNode(Settings.EMPTY);
    }
    public String startNode(Settings.Builder settings) {
        return startNode(settings.build());
    }
    public String startNode(Settings settings) {
        return startNodes(settings).get(0);
    }
    public List&lt;String&gt; startNodes(int numOfNodes) {
        return startNodes(numOfNodes, Settings.EMPTY);
    }
    public List&lt;String&gt; startNodes(int numOfNodes, Settings settings) {
        return startNodes(Collections.nCopies(numOfNodes, settings).toArray(new Settings[0]));
    }
    public synchronized List&lt;String&gt; startNodes(Settings... extraSettings) {
        final int newMasterCount = Math.toIntExact(Stream.of(extraSettings).filter(Node.NODE_MASTER_SETTING::get).count());
        final List&lt;NodeAndClient&gt; nodes = new ArrayList&lt;&gt;();
        final int prevMasterCount = getMasterNodesCount();
        int autoBootstrapMasterNodeIndex = autoManageMasterNodes &amp;&amp; prevMasterCount == 0 &amp;&amp; newMasterCount &gt; 0
            &amp;&amp; Arrays.stream(extraSettings)
                    .allMatch(s -&gt; Node.NODE_MASTER_SETTING.get(s) == false || ZEN2_DISCOVERY_TYPE.equals(DISCOVERY_TYPE_SETTING.get(s)))
            ? RandomNumbers.randomIntBetween(random, 0, newMasterCount - 1) : -1;
        final int numOfNodes = extraSettings.length;
        final int firstNodeId = nextNodeId.getAndIncrement();
        final List&lt;Settings&gt; settings = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; numOfNodes; i++) {
            settings.add(getNodeSettings(firstNodeId + i, random.nextLong(), extraSettings[i]));
        }
        nextNodeId.set(firstNodeId + numOfNodes);
        final List&lt;String&gt; initialMasterNodes = settings.stream()
                .filter(Node.NODE_MASTER_SETTING::get)
                .map(Node.NODE_NAME_SETTING::get)
                .collect(Collectors.toList());
        final List&lt;Settings&gt; updatedSettings = bootstrapMasterNodeWithSpecifiedIndex(settings);
        for (int i = 0; i &lt; numOfNodes; i++) {
            final Settings nodeSettings = updatedSettings.get(i);
            final Builder builder = Settings.builder();
            if (Node.NODE_MASTER_SETTING.get(nodeSettings)) {
                if (autoBootstrapMasterNodeIndex == 0) {
                    builder.putList(INITIAL_MASTER_NODES_SETTING.getKey(), initialMasterNodes);
                }
                autoBootstrapMasterNodeIndex -= 1;
            }
            final NodeAndClient nodeAndClient =
                    buildNode(firstNodeId + i, builder.put(nodeSettings).build(), false, () -&gt; rebuildUnicastHostFiles(nodes));
            nodes.add(nodeAndClient);
        }
        startAndPublishNodesAndClients(nodes);
        if (autoManageMasterNodes) {
            validateClusterFormed();
        }
        return nodes.stream().map(NodeAndClient::getName).collect(Collectors.toList());
    }
    public List&lt;String&gt; startMasterOnlyNodes(int numNodes) {
        return startMasterOnlyNodes(numNodes, Settings.EMPTY);
    }
    public List&lt;String&gt; startMasterOnlyNodes(int numNodes, Settings settings) {
        Settings settings1 = Settings.builder()
                .put(settings)
                .put(Node.NODE_MASTER_SETTING.getKey(), true)
                .put(Node.NODE_DATA_SETTING.getKey(), false)
                .build();
        return startNodes(numNodes, settings1);
    }
    public List&lt;String&gt; startDataOnlyNodes(int numNodes) {
        return startDataOnlyNodes(numNodes, Settings.EMPTY);
    }
    public List&lt;String&gt; startDataOnlyNodes(int numNodes, Settings settings) {
        return startNodes(
            numNodes,
            Settings.builder().put(settings).put(Node.NODE_MASTER_SETTING.getKey(), false)
                .put(Node.NODE_DATA_SETTING.getKey(), true).build());
    }
    private int getMasterNodesCount() {
        return (int) nodes.values().stream().filter(n -&gt; Node.NODE_MASTER_SETTING.get(n.node().settings())).count();
    }
    public String startMasterOnlyNode() {
        return startMasterOnlyNode(Settings.EMPTY);
    }
    public String startMasterOnlyNode(Settings settings) {
        Settings settings1 = Settings.builder()
                .put(settings)
                .put(Node.NODE_MASTER_SETTING.getKey(), true)
                .put(Node.NODE_DATA_SETTING.getKey(), false)
                .build();
        return startNode(settings1);
    }
    public String startDataOnlyNode() {
        return startDataOnlyNode(Settings.EMPTY);
    }
    public String startDataOnlyNode(Settings settings) {
        Settings settings1 = Settings.builder()
                .put(settings)
                .put(Node.NODE_MASTER_SETTING.getKey(), false)
                .put(Node.NODE_DATA_SETTING.getKey(), true)
                .build();
        return startNode(settings1);
    }
    private synchronized void publishNode(NodeAndClient nodeAndClient) {
        assert !nodeAndClient.node().isClosed();
        final NavigableMap&lt;String, NodeAndClient&gt; newNodes = new TreeMap&lt;&gt;(nodes);
        newNodes.put(nodeAndClient.name, nodeAndClient);
        nodes = Collections.unmodifiableNavigableMap(newNodes);
        applyDisruptionSchemeToNode(nodeAndClient);
    }
    public void closeNonSharedNodes(boolean wipeData) throws IOException {
        reset(wipeData);
    }
    @Override
    public int numDataNodes() {
        return dataNodeAndClients().size();
    }
    @Override
    public int numDataAndMasterNodes() {
        return filterNodes(nodes, DATA_NODE_PREDICATE.or(MASTER_NODE_PREDICATE)).size();
    }
    public int numMasterNodes() {
      return filterNodes(nodes, NodeAndClient::isMasterEligible).size();
    }
    public void setDisruptionScheme(ServiceDisruptionScheme scheme) {
        assert activeDisruptionScheme == null :
            "there is already and active disruption [" + activeDisruptionScheme + "]. call clearDisruptionScheme first";
        scheme.applyToCluster(this);
        activeDisruptionScheme = scheme;
    }
    public void clearDisruptionScheme() {
        clearDisruptionScheme(true);
    }
    public synchronized void clearDisruptionScheme(boolean ensureHealthyCluster) {
        if (activeDisruptionScheme != null) {
            TimeValue expectedHealingTime = activeDisruptionScheme.expectedTimeToHeal();
            logger.info("Clearing active scheme {}, expected healing time {}", activeDisruptionScheme, expectedHealingTime);
            if (ensureHealthyCluster) {
                activeDisruptionScheme.removeAndEnsureHealthy(this);
            } else {
                activeDisruptionScheme.removeFromCluster(this);
            }
        }
        activeDisruptionScheme = null;
    }
    private void applyDisruptionSchemeToNode(NodeAndClient nodeAndClient) {
        if (activeDisruptionScheme != null) {
            assert nodes.containsKey(nodeAndClient.name);
            activeDisruptionScheme.applyToNode(nodeAndClient.name, this);
        }
    }
    private void removeDisruptionSchemeFromNode(NodeAndClient nodeAndClient) {
        if (activeDisruptionScheme != null) {
            assert nodes.containsKey(nodeAndClient.name);
            activeDisruptionScheme.removeFromNode(nodeAndClient.name, this);
        }
    }
    private Collection&lt;NodeAndClient&gt; dataNodeAndClients() {
        return filterNodes(nodes, DATA_NODE_PREDICATE);
    }
    private static Collection&lt;NodeAndClient&gt; filterNodes(Map&lt;String, InternalTestCluster.NodeAndClient&gt; map,
            Predicate&lt;NodeAndClient&gt; predicate) {
        return map
            .values()
            .stream()
            .filter(predicate)
            .collect(Collectors.toCollection(ArrayList::new));
    }
    private static final class NodeNamePredicate implements Predicate&lt;NodeAndClient&gt; {
        private final String nodeName;
        NodeNamePredicate(String nodeName) {
            this.nodeName = nodeName;
        }
        @Override
        public boolean test(NodeAndClient nodeAndClient) {
            return nodeName.equals(nodeAndClient.getName());
        }
    }
    synchronized String routingKeyForShard(Index index, int shard, Random random) {
        assertThat(shard, greaterThanOrEqualTo(0));
        assertThat(shard, greaterThanOrEqualTo(0));
        for (NodeAndClient n : nodes.values()) {
            Node node = n.node;
            IndicesService indicesService = getInstanceFromNode(IndicesService.class, node);
            ClusterService clusterService = getInstanceFromNode(ClusterService.class, node);
            IndexService indexService = indicesService.indexService(index);
            if (indexService != null) {
                assertThat(indexService.getIndexSettings().getSettings().getAsInt(IndexMetadata.SETTING_NUMBER_OF_SHARDS, -1),
                        greaterThan(shard));
                OperationRouting operationRouting = clusterService.operationRouting();
                while (true) {
                    String routing = RandomStrings.randomAsciiLettersOfLength(random, 10);
                    final int targetShard = operationRouting
                            .indexShards(clusterService.state(), index.getName(), null, routing)
                            .shardId().getId();
                    if (shard == targetShard) {
                        return routing;
                    }
                }
            }
        }
        fail("Could not find a node that holds " + index);
        return null;
    }
    @Override
    public Iterable&lt;Client&gt; getClients() {
        return () -&gt; {
            ensureOpen();
            final Iterator&lt;NodeAndClient&gt; iterator = nodes.values().iterator();
            return new Iterator&lt;Client&gt;() {
                @Override
                public boolean hasNext() {
                    return iterator.hasNext();
                }
                @Override
                public Client next() {
                    return iterator.next().client();
                }
                @Override
                public void remove() {
                    throw new UnsupportedOperationException("");
                }
            };
        };
    }
    @Override
    public NamedWriteableRegistry getNamedWriteableRegistry() {
        return getInstance(NamedWriteableRegistry.class);
    }
    public static Predicate&lt;Settings&gt; nameFilter(String... nodeNames) {
        final Set&lt;String&gt; nodes = Set.of(nodeNames);
        return settings -&gt; nodes.contains(settings.get("node.name"));
    }
    public static class RestartCallback {
        public Settings onNodeStopped(String nodeName) throws Exception {
            return Settings.EMPTY;
        }
        public void doAfterNodes(int n, Client client) throws Exception {
        }
        public void onAllNodesStopped() throws Exception {
        }
        public boolean clearData(String nodeName) {
            return false;
        }
        public boolean validateClusterForming() { return true; }
    }
    public Settings getDefaultSettings() {
        return defaultSettings;
    }
    @Override
    public void ensureEstimatedStats() {
        for (NodeAndClient nodeAndClient : nodes.values()) {
            final String name = nodeAndClient.name;
            final CircuitBreakerService breakerService = getInstanceFromNode(CircuitBreakerService.class, nodeAndClient.node);
            try {
                assertBusy(() -&gt; {
                    CircuitBreaker acctBreaker = breakerService.getBreaker(CircuitBreaker.ACCOUNTING);
                    assertThat("Accounting breaker not reset to 0 on node: " + name + ", are there still Lucene indices around?",
                        acctBreaker.getUsed(), equalTo(0L));
                });
            } catch (Exception e) {
                throw new AssertionError("Exception during check for accounting breaker reset to 0", e);
            }
            try {
                assertBusy(() -&gt; {
                    CircuitBreaker reqBreaker = breakerService.getBreaker(CircuitBreaker.REQUEST);
                    assertThat("Request breaker not reset to 0 on node: " + name, reqBreaker.getUsed(), equalTo(0L));
                });
            } catch (Exception e) {
                throw new AssertionError("Exception during check for request breaker reset to 0", e);
            }
            try {
                assertBusy(() -&gt; {
                    CircuitBreaker crateQueryBreaker = breakerService.getBreaker("query");
                    if (crateQueryBreaker != null) {
                        assertThat("Query breaker not reset to 0 on node: " + name,
                                    crateQueryBreaker.getUsed(),
                                    equalTo(0L));
                    }
                });
            } catch (Exception e) {
                throw new AssertionError("Exception during check for query breaker reset to 0", e);
            }
        }
    }
    @Override
    public synchronized void assertAfterTest() throws IOException {
        super.assertAfterTest();
        assertRequestsFinished();
        for (NodeAndClient nodeAndClient : nodes.values()) {
            NodeEnvironment env = nodeAndClient.node().getNodeEnvironment();
            Set&lt;ShardId&gt; shardIds = env.lockedShards();
            for (ShardId id : shardIds) {
                try {
                    env.shardLock(id, "InternalTestCluster assert after test", TimeUnit.SECONDS.toMillis(5)).close();
                } catch (ShardLockObtainFailedException ex) {
                    throw new AssertionError("Shard " + id + " is still locked after 5 sec waiting", ex);
                }
            }
        }
    }
    private void assertRequestsFinished() {
        assert Thread.holdsLock(this);
        for (NodeAndClient nodeAndClient : nodes.values()) {
            CircuitBreaker inFlightRequestsBreaker = getInstance(CircuitBreakerService.class, nodeAndClient.name)
                .getBreaker(CircuitBreaker.IN_FLIGHT_REQUESTS);
            try {
                assertBusy(() -&gt; {
                    long bytesUsed = inFlightRequestsBreaker.getUsed();
                    assertThat("All incoming requests on node [" + nodeAndClient.name + "] should have finished. Expected 0 but got " +
                        bytesUsed, bytesUsed, equalTo(0L));
                });
            } catch (Exception e) {
                logger.error("Could not assert finished requests within timeout", e);
                fail("Could not assert finished requests within timeout on node [" + nodeAndClient.name + "]");
            }
        }
    }
    public int numNodes() {
        return nodes.size();
    }
}
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
