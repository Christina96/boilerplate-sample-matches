<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html><head><title>Matches for UpdateIntegrationTest.java &amp; InternalTestCluster.java</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<style>.modal {display: none;position: fixed;z-index: 1;left: 0;top: 0;width: 100%;height: 100%;overflow: auto;background-color: rgb(0, 0, 0);background-color: rgba(0, 0, 0, 0.4);}  .modal-content {height: 250%;background-color: #fefefe;margin: 5% auto;padding: 20px;border: 1px solid #888;width: 80%;}  .close {color: #aaa;float: right;font-size: 20px;font-weight: bold;}  .close:hover, .close:focus {color: black;text-decoration: none;cursor: pointer;}  .column {float: left;width: 50%;}  .row:after {content: ;display: table;clear: both;}  #column1, #column2 {white-space: pre-wrap;}</style></head>
<body>
<div style="align-items: center; display: flex; justify-content: space-around;">
<div>
<h3 align="center">
Matches for UpdateIntegrationTest.java &amp; InternalTestCluster.java
      </h3>
<h1 align="center">
        7.9%
      </h1>
<center>
<a href="#" target="_top">
          INDEX
        </a>
<span>-</span>
<a href="#" target="_top">
          HELP
        </a>
</center>
</div>
<div>
<table bgcolor="#d0d0d0" border="1" cellspacing="0">
<tr><th><th>UpdateIntegrationTest.java (14.670897%)<th>InternalTestCluster.java (5.4588375%)<th>Tokens
<tr onclick='openModal("#0000ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#0000ff"><font color="#0000ff">-</font><td><a href="#" name="0">(24-50)<td><a href="#" name="0">(129-165)</a><td align="center"><font color="#ff0000">23</font>
<tr onclick='openModal("#f63526")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f63526"><font color="#f63526">-</font><td><a href="#" name="1">(1006-1016)<td><a href="#" name="1">(337-342)</a><td align="center"><font color="#850000">12</font>
<tr onclick='openModal("#980517")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#980517"><font color="#980517">-</font><td><a href="#" name="2">(587-598)<td><a href="#" name="2">(1062-1067)</a><td align="center"><font color="#850000">12</font>
<tr onclick='openModal("#53858b")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#53858b"><font color="#53858b">-</font><td><a href="#" name="3">(1042-1046)<td><a href="#" name="3">(1228-1233)</a><td align="center"><font color="#790000">11</font>
<tr onclick='openModal("#6cc417")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#6cc417"><font color="#6cc417">-</font><td><a href="#" name="4">(338-347)<td><a href="#" name="4">(1503-1504)</a><td align="center"><font color="#790000">11</font>
<tr onclick='openModal("#151b8d")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#151b8d"><font color="#151b8d">-</font><td><a href="#" name="5">(97-106)<td><a href="#" name="5">(1904-1910)</a><td align="center"><font color="#790000">11</font>
<tr onclick='openModal("#8c8774")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#8c8774"><font color="#8c8774">-</font><td><a href="#" name="6">(77-89)<td><a href="#" name="6">(439-443)</a><td align="center"><font color="#790000">11</font>
<tr onclick='openModal("#38a4a5")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#38a4a5"><font color="#38a4a5">-</font><td><a href="#" name="7">(54-65)<td><a href="#" name="7">(473-476)</a><td align="center"><font color="#790000">11</font>
<tr onclick='openModal("#c58917")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#c58917"><font color="#c58917">-</font><td><a href="#" name="8">(734-738)<td><a href="#" name="8">(1387-1389)</a><td align="center"><font color="#6e0000">10</font>
<tr onclick='openModal("#83a33a")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#83a33a"><font color="#83a33a">-</font><td><a href="#" name="9">(66-73)<td><a href="#" name="9">(1084-1098)</a><td align="center"><font color="#6e0000">10</font>
<tr onclick='openModal("#ad5910")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#ad5910"><font color="#ad5910">-</font><td><a href="#" name="10">(1039-1042)<td><a href="#" name="10">(1068-1071)</a><td align="center"><font color="#630000">9</font>
<tr onclick='openModal("#b041ff")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#b041ff"><font color="#b041ff">-</font><td><a href="#" name="11">(1031-1037)<td><a href="#" name="11">(719-722)</a><td align="center"><font color="#630000">9</font>
<tr onclick='openModal("#571b7e")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#571b7e"><font color="#571b7e">-</font><td><a href="#" name="12">(1020-1022)<td><a href="#" name="12">(549-552)</a><td align="center"><font color="#630000">9</font>
<tr onclick='openModal("#3b9c9c")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#3b9c9c"><font color="#3b9c9c">-</font><td><a href="#" name="13">(167-175)<td><a href="#" name="13">(1710-1711)</a><td align="center"><font color="#630000">9</font>
<tr onclick='openModal("#842dce")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#842dce"><font color="#842dce">-</font><td><a href="#" name="14">(154-158)<td><a href="#" name="14">(1005-1008)</a><td align="center"><font color="#630000">9</font>
<tr onclick='openModal("#f52887")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#f52887"><font color="#f52887">-</font><td><a href="#" name="15">(133-139)<td><a href="#" name="15">(1391-1396)</a><td align="center"><font color="#630000">9</font>
<tr onclick='openModal("#2981b2")' onmouseleave='this.style.backgroundColor = "#D0D0D0"' onmouseover='this.style.backgroundColor = "yellow"' style="cursor:pointer"><td bgcolor="#2981b2"><font color="#2981b2">-</font><td><a href="#" name="16">(114-121)<td><a href="#" name="16">(989-993)</a><td align="center"><font color="#630000">9</font>
</td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></td></td></a></td></td></tr></th></th></th></th></tr></table>
</div>
</div>
<hr/>
<div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>UpdateIntegrationTest.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
/*
 * Licensed to Crate.io GmbH ("Crate") under one or more contributor
 * license agreements.  See the NOTICE file distributed with this work for
 * additional information regarding copyright ownership.  Crate licenses
 * this file to you under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.  You may
 * obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
 * License for the specific language governing permissions and limitations
 * under the License.
 *
 * However, if you have executed another commercial license agreement
 * with Crate these terms will supersede the license and you may use the
 * software solely pursuant to the terms of the relevant commercial agreement.
 */
<a name="0"></a>
package io.crate.integrationtests;

<font color="#0000ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>import io.crate.exceptions.VersioningValidationException;
import io.crate.testing.TestingHelpers;
import io.crate.testing.UseJdbc;
import io.crate.common.collections.MapBuilder;
import org.hamcrest.Matchers;
import org.hamcrest.core.IsNull;
import org.junit.Test;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.Map;

import static com.carrotsearch.randomizedtesting.RandomizedTest.$;
import static com.carrotsearch.randomizedtesting.RandomizedTest.$$;
import static io.crate.protocols.postgres.PGErrorStatus.INTERNAL_ERROR;
import static io.crate.testing.Asserts.assertThrowsMatches;
import static io.crate.testing.SQLErrorMatcher.isSQLError;
import static io.crate.testing.TestingHelpers.mapToSortedString;
import static io.crate.testing.TestingHelpers.printedTable;
import static io.netty.handler.codec.http.HttpResponseStatus.BAD_REQUEST;
import static io.netty.handler.codec.http.HttpResponseStatus.INTERNAL_SERVER_ERROR;
import static org.hamcrest.core.Is.is;
import static org.hamcrest.core.IsNot.not;

public class UpdateIntegrationTest extends SQLIntegrationTestCase {

    private Setup setup = new Setup(sqlExecutor)</b></font>;
<a name="7"></a>
    @Test
    public void testUpdate() throws Exception {
        <font color="#38a4a5"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>execute("create table test (message string) clustered into 2 shards");
        execute("insert into test values('hello'),('again'),('hello'),('hello')");
        assertEquals(4, response.rowCount());
        refresh();

        execute("update test set message='b' where message = 'hello'");

        assertEquals(3, response.rowCount());
        refresh();
<a name="9"></a>
        execute("select message from test where message='b'");
        assertEquals</b></font>(3, response.rowCount());
        <font color="#83a33a"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>assertEquals("b", response.rows()[0][0]);
    }

    @Test
    public void testUpdateByPrimaryKeyUnknownDocument() {
        execute("create table test (id int primary key, message string)");
        execute("update test set message='b' where id = 1");
        assertEquals</b></font>(0, response.rowCount());
<a name="6"></a>    }

    @Test
    public void testUpdateNotNullColumn() <font color="#8c8774"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>{
        execute("create table test (id int primary key, message string not null)");
        execute("insert into test (id, message) values(1, 'Ford'),(2, 'Arthur')");
        assertEquals(2, response.rowCount());
        refresh();

        assertThrowsMatches(() -&gt; execute(
            "update test set message=null where id=1"),
                     isSQLError(Matchers.is("\"message\" must not be null"),
                                INTERNAL_ERROR,
                                BAD_REQUEST,
                                4000));
    }</b></font>

    @Test
    public void testUpdateWithNotNull1LevelNestedColumn() {
        execute("create table test (" +
<a name="5"></a>                "stuff object(dynamic) AS (" +
                "  level1 string not null" +
                ") not null)");
        <font color="#151b8d"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>execute("insert into test (stuff) values('{\"level1\":\"value\"}')");
        assertEquals(1, response.rowCount());
        refresh();

        assertThrowsMatches(() -&gt; execute(
            "update test set stuff['level1']=null"),
                     isSQLError(Matchers.is("\"stuff['level1']\" must not be null"), INTERNAL_ERROR, BAD_REQUEST, 4000));
    }

    @Test</b></font>
    public void testUpdateWithNotNull2LevelsNestedColumn() {
        execute("create table test (" +
                "stuff object(dynamic) AS (" +
                "  level1 object(dynamic) AS (" +
<a name="16"></a>                "    level2 string not null" +
                "  ) not null" +
                ") not null)");
        <font color="#2981b2"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>execute("insert into test (stuff) values('{\"level1\":{\"level2\":\"value\"}}')");
        assertEquals(1, response.rowCount());
        refresh();

        assertThrowsMatches(() -&gt; execute(
            "update test set stuff['level1']['level2']=null"),
                     isSQLError(Matchers.is("\"stuff['level1']['level2']\" must not be null"), INTERNAL_ERROR, BAD_REQUEST, 4000));
    }</b></font>

    @Test
    public void testUpdateNullDynamicColumn() {
        /*
         * Regression test
         * validating dynamically generated columns with NULL values led to NPE
         */
        execute("create table test (id int primary key) with (column_policy = 'dynamic')");
<a name="15"></a>        execute("insert into test (id) values (1)");
        refresh();

        <font color="#f52887"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>execute("update test set dynamic_col=null");
        refresh();
        assertEquals(1, response.rowCount());
    }

    @Test
    public void testUpdateWithExpression() throws Exception {</b></font>
        execute("create table test (id integer, other_id long, name string)");
        execute("insert into test (id, other_id, name) values(1, 10, 'Ford'),(2, 20, 'Arthur')");
        assertEquals(2, response.rowCount());
        refresh();

        execute("update test set id=(id+10)*cast(other_id as integer)");

        assertEquals(2, response.rowCount());
        refresh();

        execute("select id, other_id, name from test order by id");
<a name="14"></a>        assertEquals(2, response.rowCount());
        assertEquals(110, response.rows()[0][0]);
        assertEquals(10L, response.rows()[0][1]);
        <font color="#842dce"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>assertEquals("Ford", response.rows()[0][2]);
        assertEquals(240, response.rows()[1][0]);
        assertEquals(20L, response.rows()[1][1]);
        assertEquals("Arthur", response.rows()[1][2]);
    }</b></font>

    @Test
    public void testUpdateWithExpressionReferenceUpdated() throws Exception {
        // test that expression in update assignment always refer to existing values, not updated ones

<a name="13"></a>        execute("create table test (dividend integer, divisor integer, quotient integer)");
        execute("insert into test (dividend, divisor, quotient) values(10, 2, 5)");
        assertEquals(1, response.rowCount());
        <font color="#3b9c9c"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>refresh();

        execute("update test set dividend = 30, quotient = dividend/divisor");
        assertEquals(1, response.rowCount());
        refresh();

        execute("select quotient name from test");
        assertEquals(5, response.rows()[0][0]);
    }</b></font>

    @Test
    public void testUpdateByPrimaryKeyWithExpression() throws Exception {
        execute("create table test (id integer primary key, other_id long)");
        execute("insert into test (id, other_id) values(1, 10),(2, 20)");
        assertEquals(2, response.rowCount());
        refresh();

        execute("update test set other_id=(id+10)*id where id = 2");

        assertEquals(1, response.rowCount());
        refresh();

        execute("select other_id from test order by id");
        assertEquals(2, response.rowCount());
        assertEquals(10L, response.rows()[0][0]);
        assertEquals(24L, response.rows()[1][0]);
    }

    @Test
    public void testUpdateMultipleDocuments() throws Exception {
        execute("create table test (message string)");
        execute("insert into test values('hello'),('again'),('hello')");
        assertEquals(3, response.rowCount());
        refresh();

        execute("update test set message='b' where message = 'hello'");

        assertEquals(2, response.rowCount());
        refresh();

        execute("select message from test where message='b'");
        assertEquals(2, response.rowCount());
        assertEquals("b", response.rows()[0][0]);

    }

    @Test
    public void testTwoColumnUpdate() throws Exception {
        execute("create table test (col1 string, col2 string)");
        execute("insert into test values('hello', 'hallo'), ('again', 'nochmal')");
        assertEquals(2, response.rowCount());
        refresh();

        execute("update test set col1='b' where col1 = 'hello'");

        assertEquals(1, response.rowCount());
        refresh();

        execute("select col1, col2 from test where col1='b'");
        assertEquals(1, response.rowCount());
        assertEquals("b", response.rows()[0][0]);
        assertEquals("hallo", response.rows()[0][1]);

    }

    @Test
    public void testUpdateWithArgs() throws Exception {
        execute("create table test (" +
                "  coolness float, " +
                "  details array(object)" +
                ")");
        execute("insert into test values(1.1, ?),(2.2, ?)", new Object[]{new Object[0],
            new Object[]{
                new HashMap&lt;String, Object&gt;(),
                new HashMap&lt;String, Object&gt;() {{
                    put("hello", "world");
                }}
            }
        });
        assertEquals(2, response.rowCount());
        refresh();

        execute("update test set coolness=3.3, details=? where coolness = ?", new Object[]{new Object[0], 2.2});

        assertEquals(1, response.rowCount());
        refresh();

        execute("select coolness from test where coolness=3.3");
        assertEquals(1, response.rowCount());
        assertEquals(3.3f, response.rows()[0][0]);

    }

    @Test
    public void testUpdateNestedObjectWithoutDetailedSchema() throws Exception {
        execute("create table test (coolness object)");
        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();
        map.put("x", "1");
        map.put("y", 2);
        Object[] args = new Object[]{map};

        execute("insert into test values (?)", args);
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set coolness['x'] = '3'");

        assertEquals(1, response.rowCount());
        refresh();

        waitForMappingUpdateOnAll("test", "coolness.x");
        execute("select coolness['x'], coolness['y'] from test");
        assertEquals(1, response.rowCount());
        assertEquals("3", response.rows()[0][0]);
        // integer values for unknown columns will be result in a long type for range safety
        assertEquals(2L, response.rows()[0][1]);
    }

    @Test
    public void testUpdateWithFunctionWhereArgumentIsInIntegerRangeInsteadOfLong() {
        execute(
            "create table t (" +
            "   ts timestamp with time zone," +
            "   day int" +
            ") with (number_of_replicas = 0)");
        execute("insert into t (ts, day) values (0, 1)");
        execute("refresh table t");

        execute("update t set day = extract(day from ts)");
        assertThat(response.rowCount(), is(1L));
    }

    @Test
    public void testInsertIntoWithOnConflictKeyWithFunctionWhereArgumentIsInIntegerRangeInsteadOfLong() {
        execute(
            "create table t (" +
            "   id int primary key," +
            "   ts timestamp with time zone, day int" +
            ") with (number_of_replicas = 0)");
        execute("insert into t (id, ts, day) values (1, 0, 0)");
        execute("refresh table t");
        execute("insert into t (id, ts, day) (select id, ts, day from t) " +
                "on conflict (id) do update set day = extract(day from ts)");
        assertThat(response.rowCount(), is(1L));
    }

    @Test
    public void testUpdateNestedNestedObject() throws Exception {
        execute("create table test (" +
                "coolness object as (x object as (y object as (z int), a string, b string))," +
                "a object as (x string, y int)," +
                "firstcol int, othercol int" +
                ") with (number_of_replicas=0)");
        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();
        map.put("x", "1");
        map.put("y", 2);
        Object[] args = new Object[]{map};

        execute("insert into test (a) values (?)", args);
        refresh();

        execute("update test set coolness['x']['y']['z'] = 3");

        assertEquals(1, response.rowCount());
        refresh();

        execute("select coolness['x'], a from test");
        assertEquals(1, response.rowCount());
<a name="4"></a>        assertEquals("{y={z=3}}", response.rows()[0][0].toString());
        assertEquals(map, response.rows()[0][1]);

        <font color="#6cc417"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>execute("update test set firstcol = 1, coolness['x']['a'] = 'a', coolness['x']['b'] = 'b', othercol = 2");
        assertEquals(1, response.rowCount());
        refresh();
        waitNoPendingTasksOnAll();

        execute("select coolness['x']['b'], coolness['x']['a'], coolness['x']['y']['z'], " +
                "firstcol, othercol from test");
        assertEquals(1, response.rowCount());
        Object[] firstRow = response.rows()[0];
        assertEquals</b></font>("b", firstRow[0]);
        assertEquals("a", firstRow[1]);
        assertEquals(3, firstRow[2]);
        assertEquals(1, firstRow[3]);
        assertEquals(2, firstRow[4]);
    }

    @Test
    public void testUpdateNestedObjectDeleteWithArgs() throws Exception {
        execute("create table test (a object as (x object as (y int, z int))) with (number_of_replicas=0)");
        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();
        Map&lt;String, Object&gt; nestedMap = new HashMap&lt;&gt;();
        nestedMap.put("y", 2);
        nestedMap.put("z", 3);
        map.put("x", nestedMap);
        Object[] args = new Object[]{map};

        execute("insert into test (a) values (?)", args);
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set a['x']['z'] = ?", new Object[]{null});

        assertEquals(1, response.rowCount());
        refresh();

        execute("select a['x']['y'], a['x']['z'] from test");
        assertEquals(1, response.rowCount());
        assertEquals(2, response.rows()[0][0]);
        assertNull(response.rows()[0][1]);
    }

    @Test
    public void testUpdateNestedObjectDeleteWithoutArgs() throws Exception {
        execute("create table test (a object as (x object as (y int, z int))) with (number_of_replicas=0)");
        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();
        Map&lt;String, Object&gt; nestedMap = new HashMap&lt;&gt;();
        nestedMap.put("y", 2);
        nestedMap.put("z", 3);
        map.put("x", nestedMap);
        Object[] args = new Object[]{map};

        execute("insert into test (a) values (?)", args);
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set a['x']['z'] = null");

        assertEquals(1, response.rowCount());
        refresh();

        execute("select a['x']['z'], a['x']['y'] from test");
        assertEquals(1, response.rowCount());
        assertNull(response.rows()[0][0]);
        assertEquals(2, response.rows()[0][1]);
    }

    @Test
    public void testUpdateNestedObjectWithDetailedSchema() throws Exception {
        execute("create table test (coolness object as (x string, y string))");
        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();
        map.put("x", "1");
        map.put("y", "2");
        Object[] args = new Object[]{map};

        execute("insert into test values (?)", args);
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set coolness['x'] = '3'");

        assertEquals(1, response.rowCount());
        refresh();

        execute("select coolness from test");
        assertEquals(1, response.rowCount());
        //noinspection unchecked
        assertEquals("x=3, y=2", mapToSortedString((Map&lt;String, Object&gt;) response.rows()[0][0]));
    }

    /**
     * Disable JDBC/PSQL as object values are streamed via JSON on the PSQL wire protocol which is not type safe.
     */
    @UseJdbc(0)
    @Test
    public void testUpdateResetNestedObject() throws Exception {
        execute("create table test (coolness object)");
        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();
        map.put("x", "1");
        map.put("y", 2);
        Object[] args = new Object[]{map};

        execute("insert into test values (?)", args);
        assertEquals(1, response.rowCount());
        refresh();

        // update with different map
        Map&lt;String, Object&gt; new_map = new HashMap&lt;&gt;();
        new_map.put("z", 1L);

        execute("update test set coolness = ?", new Object[]{new_map});
        assertEquals(1, response.rowCount());
        refresh();

        execute("select coolness from test");
        assertEquals(1, response.rowCount());
        assertEquals(new_map, response.rows()[0][0]);

        // update with empty map
        Map&lt;String, Object&gt; empty_map = new HashMap&lt;&gt;();

        execute("update test set coolness = ?", new Object[]{empty_map});
        assertEquals(1, response.rowCount());
        refresh();

        execute("select coolness from test");
        assertEquals(1, response.rowCount());
        assertEquals(empty_map, response.rows()[0][0]);
    }

    @Test
    public void testUpdateResetNestedObjectUsingUpdateRequest() throws Exception {
        execute("create table test (id string, data object(ignored))");
        Map&lt;String, Object&gt; data = new HashMap&lt;&gt;() {{
            put("foo", "bar");
            put("days", new ArrayList&lt;String&gt;() {{
                add("Mon");
                add("Tue");
                add("Wen");
            }});
        }};
        execute("insert into test (id, data) values (?, ?)", new Object[]{"1", data});
        refresh();

        execute("select data from test where id = ?", new Object[]{"1"});
        assertEquals(data, response.rows()[0][0]);

        Map&lt;String, Object&gt; new_data = new HashMap&lt;String, Object&gt;() {{
            put("days", new ArrayList&lt;String&gt;() {{
                add("Mon");
                add("Wen");
            }});
        }};
        execute("update test set data = ? where id = ?", new Object[]{new_data, "1"});
        assertEquals(1, response.rowCount());
        refresh();

        execute("select data from test where id = ?", new Object[]{"1"});
        assertEquals(new_data, response.rows()[0][0]);
    }

    /**
     * Disable JDBC/PSQL as object values are streamed via JSON on the PSQL wire protocol which is not type safe.
     */
    @UseJdbc(0)
    @Test
    public void testUpdateResetNestedNestedObject() throws Exception {
        execute("create table test (coolness object)");
        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;() {{
            put("x", "1");
            put("y", new HashMap&lt;String, Object&gt;() {{
                put("z", 3);
            }});
        }};

        execute("insert into test values (?)", new Object[]{map});
        assertEquals(1, response.rowCount());
        refresh();

        Map&lt;String, Object&gt; new_map = new HashMap&lt;&gt;();
        new_map.put("a", 1L);

        execute("update test set coolness['y'] = ?", new Object[]{new_map});
        assertEquals(1, response.rowCount());
        refresh();

        waitForMappingUpdateOnAll("test", "coolness.x");
        execute("select coolness['y'], coolness['x'] from test");
        assertEquals(1, response.rowCount());
        assertEquals(new_map, response.rows()[0][0]);
        assertEquals("1", response.rows()[0][1]);
    }

    @Test
    public void testUpdateToUpdateRequestByPlanner() throws Exception {
        this.setup.createTestTableWithPrimaryKey();

        execute("insert into test (pk_col, message) values ('123', 'bar')");
        assertEquals(1, response.rowCount());
        waitNoPendingTasksOnAll(); // wait for new columns to be available
        refresh();

        execute("update test set message='bar1' where pk_col='123'");
        assertEquals(1, response.rowCount());
        refresh();

        execute("select message from test where pk_col='123'");
        assertEquals(1, response.rowCount());
        assertEquals("bar1", response.rows()[0][0]);
    }

    @Test
    public void testUpdateByIdWithMultiplePrimaryKeyAndClusteredBy() throws Exception {
        execute("create table quotes (id integer primary key, author string primary key, " +
                "quote string) clustered by(author) with (number_of_replicas=0)");
        execute("insert into quotes (id, author, quote) values(?, ?, ?)",
            new Object[]{1, "Ford", "I'd far rather be happy than right any day."});
        assertEquals(1L, response.rowCount());

        execute("update quotes set quote=? where id=1 and author='Ford'",
            new Object[]{"Don't panic"});
        assertEquals(1L, response.rowCount());
        refresh();
        execute("select quote from quotes where id=1 and author='Ford'");
        assertEquals(1L, response.rowCount());
        assertThat((String) response.rows()[0][0], is("Don't panic"));
    }

    @Test
    public void testUpdateByQueryWithMultiplePrimaryKeyAndClusteredBy() throws Exception {
        execute("create table quotes (id integer primary key, author string primary key, " +
                "quote string) clustered by(author) with (number_of_replicas=0)");
        execute("insert into quotes (id, author, quote) values(?, ?, ?)",
            new Object[]{1, "Ford", "I'd far rather be happy than right any day."});
        assertEquals(1L, response.rowCount());
        refresh();

        execute("update quotes set quote=? where id=1",
            new Object[]{"Don't panic"});
        assertEquals(1L, response.rowCount());
        refresh();

        execute("select quote from quotes where id=1 and author='Ford'");
        assertEquals(1L, response.rowCount());
        assertThat((String) response.rows()[0][0], is("Don't panic"));
    }

<a name="2"></a>    @Test
    public void testUpdateVersionHandling() throws Exception {
        execute("create table test (id int primary key, c int) with (number_of_replicas=0, refresh_interval=0)");
        <font color="#980517"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>execute("insert into test (id, c) values (1, 1)");
        execute("refresh table test");
        execute("select _version, c from test");

        long version = (Long) response.rows()[0][0];
        assertThat(version, is(1L));

        // with primary key optimization:

        execute("update test set c = 2 where id = 1 and _version = 1"); // this one works
        assertThat(response.rowCount(), is(1L));
        execute</b></font>("update test set c = 3 where id = 1 and _version = 1"); // this doesn't
        assertThat(response.rowCount(), is(0L));

        execute("refresh table test");
        execute("select _version, c from test");
        assertThat((Long) response.rows()[0][0], is(2L));
        assertThat((Integer) response.rows()[0][1], is(2));

    }

    @Test
    public void testMultiUpdateWithSequenceConflict() {
        execute("create table test (id int primary key, c int)");
        execute("insert into test (id, c) values (1, 1), (2, 1)");
        refresh();

        execute("select id, _seq_no, _primary_term from test order by id");

        // 2nd will result in conflict, but 1st one was successful and must be replicated
        long wrongSeqNoForSecondRow = (long) response.rows()[1][1] - 1;
        execute(
            "update test set c = 3 where (id = ? and _seq_no = ? and _primary_term = ?) or (id = ? and _seq_no = ? and _primary_term = ?)",
            new Object[]{response.rows()[0][0], response.rows()[0][1], response.rows()[0][2],
                response.rows()[1][0], wrongSeqNoForSecondRow, response.rows()[1][2]});
        assertThat(response.rowCount(), is(1L));
    }

    @Test
    public void testMultiUpdateWithVersionAndConflict() throws Exception {
        execute("create table test (id int primary key, c int)");
        execute("insert into test (id, c) values (1, 1), (2, 1)");
        refresh();

        // update 2nd row in order to increase version
        execute("update test set c = 2 where id = 2");
        refresh();

        // now update both rows, 2nd will result in conflict, but 1st one was successful and must be replicated
        execute("update test set c = 3 where (id = 1 and _version = 1) or (id = 2 and _version = 1)");
        assertThat(response.rowCount(), is(1L));

        refresh();
        execute("select _version from test order by id");
        assertThat((Long) response.rows()[0][0], is(2L));
        assertThat((Long) response.rows()[1][0], is(2L));
    }

    @Test
    public void testUpdateVersionOrOperator() throws Exception {
        execute("create table test (id int primary key, c int) with (number_of_replicas=0, refresh_interval=0)");
        execute("insert into test (id, c) values (1, 1)");
        execute("refresh table test");

        assertThrowsMatches(() -&gt; execute(
            "update test set c = 4 where _version = 2 or _version=1"),
                     isSQLError(Matchers.is(VersioningValidationException.VERSION_COLUMN_USAGE_MSG),
                                INTERNAL_ERROR,
                                BAD_REQUEST,
                                4000));
    }

    @Test
    public void testUpdateVersionInOperator() throws Exception {
        execute("create table test (id int primary key, c int) with (number_of_replicas=0, refresh_interval=0)");
        ensureGreen();
        execute("insert into test (id, c) values (1, 1)");
        execute("refresh table test");

        assertThrowsMatches(() -&gt; execute(
            "update test set c = 4 where _version in (1,2)"),
                     isSQLError(Matchers.is(VersioningValidationException.VERSION_COLUMN_USAGE_MSG),
                                INTERNAL_ERROR,
                                BAD_REQUEST,
                                4000));
    }


    @Test
    public void testUpdateRetryOnVersionConflict() throws Exception {
        // issue a bulk update request updating the same document to force a version conflict
        execute("create table test (a string, b int) with (number_of_replicas=0)");
        execute("insert into test (a, b) values ('foo', 1)");
        assertThat(response.rowCount(), is(1L));
        refresh();

        long[] rowCounts = execute("update test set a = ? where b = ?",
            new Object[][]{
                new Object[]{"bar", 1},
                new Object[]{"baz", 1},
                new Object[]{"foobar", 1}});
        assertThat(rowCounts, is(new long[] { 1L, 1L, 1L }));
        refresh();

        // document was changed 4 times (including initial creation), so version must be 4
        execute("select _version from test where b = 1");
        assertThat(response.rows()[0][0], is(4L));
    }

    @Test
    public void testUpdateByIdPartitionColumnPartOfPrimaryKey() throws Exception {
        execute("create table party (" +
                "  id int primary key, " +
                "  type byte primary key, " +
                "  value string" +
                ") partitioned by (type) with (number_of_replicas=0)");
        execute("insert into party (id, type, value) values (?, ?, ?)", new Object[][]{
            {1, 2, "foo"},
            {2, 3, "bar"},
            {2, 4, "baz"}
        });
        execute("refresh table party");

        execute("update party set value='updated' where (id=1 and type=2) or (id=2 and type=4)");
        assertThat(response.rowCount(), is(2L));

        execute("refresh table party");

        execute("select id, type, value from party order by id, value");
        assertThat(TestingHelpers.printedTable(response.rows()), is(
            "1| 2| updated\n" +
            "2| 3| bar\n" +
            "2| 4| updated\n"));

    }

    @Test
    public void testBulkUpdateWithOnlyOneBulkArgIsProducingRowCountResult() throws Exception {
        execute("create table t (name string) with (number_of_replicas = 0)");
        // regression test, used to throw a ClassCastException because the JobLauncher created a
        // QueryResult instead of RowCountResult
        long[] rowCounts  = execute("update t set name = 'Trillian' where name = ?", $$($("Arthur")));
        assertThat(rowCounts.length, is(1));
    }
<a name="8"></a>
    @Test
    public void testBulkUpdateWithPKAndMultipleHits() throws Exception {
        <font color="#c58917"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>execute("create table t (id integer primary key, name string) with (number_of_replicas = 0)");
        execute("insert into t values (?, ?)", $$($(1, "foo"), $(2, "bar"), $(3, "hoschi"), $(4, "crate")));
        refresh();

        long[] rowCounts = execute</b></font>("update t set name = 'updated' where id = ? or id = ?", $$($(1, 2), $(3, 4)));
        assertThat(rowCounts, is(new long[] { 2L, 2L }));
    }

    @Test
    public void testUpdateWithGeneratedColumn() {
        execute("create table generated_column (" +
                " id int primary key," +
                " ts timestamp with time zone," +
                " day as date_trunc('day', ts)," +
                " \"user\" object as (name string)," +
                " name as concat(\"user\"['name'], 'bar')" +
                ") with (number_of_replicas=0)");
        execute("insert into generated_column (id, ts, \"user\") values (?, ?, ?)", new Object[]{
            1, "2015-11-18T11:11:00", MapBuilder.newMapBuilder().put("name", "foo").map()});
        refresh();
        execute("update generated_column set ts = ?, \"user\" = ? where id = ?", new Object[]{
            "2015-11-19T17:06:00", MapBuilder.newMapBuilder().put("name", "zoo").map(), 1});
        refresh();
        execute("select day, name from generated_column");
        assertThat((Long) response.rows()[0][0], is(1447891200000L));
        assertThat((String) response.rows()[0][1], is("zoobar"));
    }

    @Test
    public void testGeneratedColumnWithoutRefsToOtherColumnsComputedOnUpdate() {
        execute("create table generated_column (" +
                " \"inserted\" TIMESTAMP WITH TIME ZONE GENERATED ALWAYS AS current_timestamp(3), " +
                " \"message\" STRING" +
                ")");
        execute("insert into generated_column (message) values (?)", new Object[]{"str"});
        refresh();
        execute("select inserted from generated_column");
        long ts = (long) response.rows()[0][0];
        execute("update generated_column set message = ?", new Object[]{"test"});
        refresh();
        execute("select inserted from generated_column");
        assertThat(response.rows()[0][0], not(ts));
    }

    @Test
    public void testUpdateSetInvalidGeneratedColumnOnly() {
        execute("create table computed (" +
                " ts timestamp with time zone," +
                " gen_col as extract(year from ts)" +
                ") with (number_of_replicas=0)");
        execute("insert into computed (ts) values (1)");
        refresh();

        assertThrowsMatches(() -&gt; execute(
            "update computed set gen_col=1745"),
                     isSQLError(Matchers.is("Given value 1745 for generated column gen_col does not match calculation extract(YEAR FROM ts) = 1970"),
                                INTERNAL_ERROR,
                                BAD_REQUEST,
                                4000));
    }

    @Test
    public void testUpdateNotNullSourceGeneratedColumn() {
        execute("create table generated_column (" +
                " id int primary key," +
                " ts timestamp with time zone," +
                " gen_col as extract(year from ts) not null" +
                ") with (number_of_replicas=0)");
        execute("insert into generated_column (id, ts) values (1, '2015-11-18T11:11:00')");
        assertEquals(1, response.rowCount());
        refresh();

        assertThrowsMatches(() -&gt; execute(
            "update generated_column set ts=null where id=1"),
                     isSQLError(Matchers.is("\"gen_col\" must not be null"), INTERNAL_ERROR, INTERNAL_SERVER_ERROR, 5000));

    }

    @Test
    public void testUpdateNotNullTargetGeneratedColumn() {
        execute("create table generated_column (" +
                " id int primary key," +
                " ts timestamp with time zone," +
                " gen_col as extract(year from ts) not null" +
                ") with (number_of_replicas=0)");
        execute("insert into generated_column (id, ts) values (1, '2015-11-18T11:11:00')");
        assertEquals(1, response.rowCount());
        refresh();

        assertThrowsMatches(() -&gt; execute(
            "update generated_column set gen_col=null where id=1"),
                     isSQLError(Matchers.is("\"gen_col\" must not be null"),
                                INTERNAL_ERROR,
                                BAD_REQUEST,
                                4000));

    }

    @Test
    public void testUpdateWithGeneratedColumnSomeReferencesUpdated() throws Exception {
        execute("create table computed (" +
                " firstname string," +
                " surname string," +
                " name as concat(surname, ', ', firstname)" +
                ") with (number_of_replicas=0)");
        execute("insert into computed (firstname, surname) values ('Douglas', 'Adams')");
        refresh();
        execute("update computed set firstname = 'Ford'");
        refresh();
        execute("select name from computed");
        assertThat((String) response.rows()[0][0], is("Adams, Ford"));
    }

    @Test
    public void testUpdateExpressionReferenceGeneratedColumn() throws Exception {
        execute("create table computed (" +
                " a int," +
                " b int," +
                " c as (b + 1)" +
                ") with (number_of_replicas=0)");
        execute("insert into computed (a, b) values (1, 2)");
        refresh();
        execute("update computed set a = c + 1");
        refresh();
        execute("select a from computed");
        assertThat((Integer) response.rows()[0][0], is(4));
    }

    @Test
    public void testUpdateReferencedByGeneratedColumnWithExpressionReferenceGeneratedColumn() throws Exception {
        execute("create table computed (" +
                " a int," +
                " b as (a + 1)" +
                ") with (number_of_replicas=0)");
        execute("insert into computed (a) values (1)");
        refresh();
        execute("update computed set a = b + 1");
        refresh();
        execute("select a from computed");
        assertThat((Integer) response.rows()[0][0], is(3));
    }

    @Test
    public void testFailingUpdateBulkOperation() throws Exception {
        execute("create table t (x string) clustered into 1 shards with (number_of_replicas = 0)");
        execute("insert into t (x) values ('1')");
        execute("refresh table t");

        // invalid regex causes failure in prepare phase, causing a failure row-count in each individual response
        Object[][] bulkArgs = new Object[][] {
            new Object[] { 1, "+123" },
            new Object[] { 2, "+123" },
        };
        long[] rowCounts = execute("update t set x = ? where x ~* ?", bulkArgs);
        assertThat(rowCounts, is(new long[] { -2L, -2L }));
    }

    @Test
    public void testUpdateByQueryWithSubQuery() throws Exception {
        execute("create table t1 (x int)");
        execute("insert into t1 (x) values (1), (2)");
        execute("refresh table t1");
        execute("update t1 set x = (select 3) where x = (select 1)");
        assertThat(response.rowCount(), is(1L));

        execute("refresh table t1");
        execute("select x from t1 order by x asc");
        assertThat(printedTable(response.rows()), is("2\n" +
                                                     "3\n"));
    }

    @Test
    public void testUpdateByIdWithSubQuery() throws Exception {
        execute("create table t1 (id int primary key, name string)");
        execute("insert into t1 (id, name) values (1, 'Arthur'), (2, 'Trillian')");
        execute("refresh table t1");
        execute("update t1 set name = (select 'Slartibartfast') where id = (select 1)");
        assertThat(response.rowCount(), is(1L));

        execute("refresh table t1");
        execute("select id, name from t1 order by id asc");
        assertThat(printedTable(response.rows()), is("1| Slartibartfast\n" +
                                                     "2| Trillian\n"));
    }

    @Test
    public void test_update_by_id_returning_id() throws Exception {
        execute("create table test (id int primary key, message string) clustered into 2 shards");
        execute("insert into test values(1, 'msg');");
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set message='msg' where id = 1 returning id");

        assertThat((response.cols()[0]), is("id" ));
        assertThat(printedTable(response.rows()), is("1\n" ));
    }

    @Test
    public void test_update_by_id_returning_id_with_outputname() throws Exception {
        execute("create table test (id int primary key, message string) clustered into 2 shards");
        execute("insert into test values(1, 'msg');");
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set message='msg' where id = 1 returning id as renamed");

        assertThat((response.cols()[0]), is("renamed" ));
        assertThat(printedTable(response.rows()), is("1\n" ));
    }

    @Test
    public void test_update_by_id_with_subquery_returning_id() throws Exception {
        execute("create table test (id int primary key, message string) clustered into 2 shards");
        execute("insert into test values(1, 'msg');");
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set message='updated' where id = (select 1) returning id");

        assertThat(printedTable(response.rows()), is("1\n" ));
    }

    @Test
    public void test_update_by_id_where_no_row_is_matching() throws Exception {
        execute("create table test (id int primary key, message string) clustered into 2 shards");
        execute("insert into test values(1, 'msg');");
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set message='updated' where id = 99 returning id");

        assertThat(response.cols()[0], is("id"));
        assertThat(response.rowCount(), is(0L));
    }

    @Test
    public void test_update_by_query_returning_single_field_with_outputputname() throws Exception {
        execute("create table test (id int primary key, message string) clustered into 2 shards");
        execute("insert into test values(1, 'msg');");
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set message='updated' where message='msg' returning message as message_renamed");

        assertThat((response.rowCount()), is(1L));
        assertThat((response.cols()[0]), is("message_renamed"));
        assertThat(response.rows()[0][0], is("updated"));
    }


    @Test
    public void test_update_by_query_with_subquery_returning_multiple_fields() throws Exception {
        execute("create table test (id int primary key, message string) clustered into 2 shards");
        execute("insert into test values(1, 'msg');");
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set message='updated' where message= (select 'msg') returning id, message");

        assertThat((response.rowCount()), is(1L));
        assertThat((response.cols()[0]), is("id"));
        assertThat((response.cols()[1]), is("message"));
        assertThat(response.rows()[0][0], is(1));
        assertThat(response.rows()[0][1], is("updated"));

    }

    @Test
<a name="1"></a>    public void test_update_by_query_returning_multiple_results() throws Exception {
        execute("create table test (id int primary key, x int, message string) clustered into 2 shards");
        execute("insert into test values(1, 1, 'msg') returning _seq_no;");
        long fstSeqNo = (long) <font color="#f63526"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>response.rows()[0][0];
        execute("insert into test values(2, 1, 'msg') returning _seq_no;");
        long sndSeqNo = (long) response.rows()[0][0];
        assertEquals(1, response.rowCount());
        refresh();

        execute("update test set message='updated' where message='msg' and x &gt; 0 " +
                "returning id, _seq_no as seq, message as message_renamed");

        assertThat((response.rowCount()), is(2L));
        assertThat</b></font>((response.cols()[0]), is("id"));
<a name="12"></a>        assertThat((response.cols()[1]), is("seq"));
        assertThat((response.cols()[2]), is("message_renamed"));

        <font color="#571b7e"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>int fstRowIndex = response.rows()[0][0].equals(1) ? 0 : 1;
        assertThat((long) response.rows()[fstRowIndex][1], Matchers.greaterThan(fstSeqNo));
        assertThat(response.rows</b></font>()[fstRowIndex][2], is("updated"));

        int sndRowIndex = fstRowIndex == 0 ? 1 : 0;

        assertThat((long) response.rows()[sndRowIndex][1], Matchers.greaterThan(sndSeqNo));
        assertThat(response.rows()[sndRowIndex][2], is("updated"));
<a name="11"></a>    }

    @Test
    public void test_update_sys_tables_returning_values_with_expressions_and_outputnames() throws Exception <font color="#b041ff"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>{
        execute("update sys.node_checks set acknowledged = true where id = 1 " +
                "returning id, UPPER(description) as description, acknowledged as ack");

        long numberOfNodes = this.clusterService().state().getNodes().getSize();
<a name="10"></a>
        assertThat((response.rowCount</b></font>()), is(numberOfNodes));
        assertThat((response.cols()[0]), is("id"));
<a name="3"></a>        assertThat((response.cols()[1]), <font color="#ad5910"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>is("description"));
        assertThat((response.cols()[2]), is("ack"));
        for (int i = 0; i &lt; numberOfNodes; i++) {
            assertThat(response.rows</b></font>()[i][0], <font color="#53858b"><a href="#"><img align="right" alt="other" border="0" src="forward.gif"/></a><b>is(1));
            assertThat(response.rows()[i][1], is(IsNull.notNullValue()));
            assertThat(response.rows()[i][2], is(true));
        }
    }</b></font>
}
</pre>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>InternalTestCluster.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<hr/>
<pre>
/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the "License"); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
package org.elasticsearch.test;

import static io.crate.common.unit.TimeValue.timeValueSeconds;
import static org.apache.lucene.util.LuceneTestCase.TEST_NIGHTLY;
import static org.apache.lucene.util.LuceneTestCase.rarely;
import static org.elasticsearch.cluster.coordination.ClusterBootstrapService.INITIAL_MASTER_NODES_SETTING;
import static org.elasticsearch.discovery.DiscoveryModule.DISCOVERY_TYPE_SETTING;
import static org.elasticsearch.discovery.DiscoveryModule.ZEN2_DISCOVERY_TYPE;
import static org.elasticsearch.node.Node.INITIAL_STATE_TIMEOUT_SETTING;
import static org.elasticsearch.discovery.FileBasedSeedHostsProvider.UNICAST_HOSTS_FILE;
import static org.elasticsearch.indices.breaker.HierarchyCircuitBreakerService.TOTAL_CIRCUIT_BREAKER_LIMIT_SETTING;
import static org.elasticsearch.test.ESTestCase.assertBusy;
import static org.elasticsearch.test.ESTestCase.randomFrom;
import static org.hamcrest.Matchers.equalTo;
import static org.hamcrest.Matchers.greaterThan;
import static org.hamcrest.Matchers.greaterThanOrEqualTo;
import static org.hamcrest.Matchers.not;
import static org.hamcrest.Matchers.nullValue;
import static org.junit.Assert.assertThat;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;

import java.io.Closeable;
import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.NavigableMap;
import java.util.Objects;
import java.util.Random;
import java.util.Set;
import java.util.TreeMap;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.function.Predicate;
import java.util.stream.Collectors;
import java.util.stream.IntStream;
import java.util.stream.Stream;

import javax.annotation.Nullable;

import com.carrotsearch.hppc.ObjectLongMap;
import com.carrotsearch.hppc.cursors.IntObjectCursor;
import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
import com.carrotsearch.randomizedtesting.RandomizedTest;
import com.carrotsearch.randomizedtesting.SeedUtils;
import com.carrotsearch.randomizedtesting.generators.RandomNumbers;
import com.carrotsearch.randomizedtesting.generators.RandomPicks;
import com.carrotsearch.randomizedtesting.generators.RandomStrings;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.apache.lucene.store.AlreadyClosedException;
import org.elasticsearch.action.admin.cluster.configuration.AddVotingConfigExclusionsAction;
import org.elasticsearch.action.admin.cluster.configuration.AddVotingConfigExclusionsRequest;
import org.elasticsearch.action.admin.cluster.configuration.ClearVotingConfigExclusionsAction;
import org.elasticsearch.action.admin.cluster.configuration.ClearVotingConfigExclusionsRequest;
import org.elasticsearch.client.Client;
import org.elasticsearch.cluster.ClusterName;
import org.elasticsearch.cluster.ClusterState;
import org.elasticsearch.cluster.action.index.MappingUpdatedAction;
import org.elasticsearch.cluster.coordination.ClusterBootstrapService;
import org.elasticsearch.cluster.metadata.IndexMetadata;
import org.elasticsearch.cluster.node.DiscoveryNode;
import org.elasticsearch.cluster.node.DiscoveryNodeRole;
import org.elasticsearch.cluster.node.DiscoveryNodes;
import org.elasticsearch.cluster.routing.IndexRoutingTable;
import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
import org.elasticsearch.cluster.routing.OperationRouting;
import org.elasticsearch.cluster.routing.ShardRouting;
import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;
import org.elasticsearch.cluster.routing.allocation.decider.ThrottlingAllocationDecider;
import org.elasticsearch.cluster.service.ClusterService;
import org.elasticsearch.common.Randomness;
import org.elasticsearch.common.Strings;
import org.elasticsearch.common.breaker.CircuitBreaker;
import org.elasticsearch.common.component.LifecycleListener;
import org.elasticsearch.common.io.FileSystemUtils;
import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
import org.elasticsearch.common.lease.Releasables;
import org.elasticsearch.common.settings.Settings;
import org.elasticsearch.common.settings.Settings.Builder;
import org.elasticsearch.common.unit.ByteSizeUnit;
import org.elasticsearch.common.unit.ByteSizeValue;
import org.elasticsearch.common.util.PageCacheRecycler;
import org.elasticsearch.common.util.concurrent.EsExecutors;
import org.elasticsearch.common.util.concurrent.FutureUtils;

import org.elasticsearch.env.Environment;
import org.elasticsearch.env.NodeEnvironment;
import org.elasticsearch.env.ShardLockObtainFailedException;
import org.elasticsearch.http.HttpServerTransport;
import org.elasticsearch.index.Index;
import org.elasticsearch.index.IndexService;
<a name="0"></a>import org.elasticsearch.index.engine.CommitStats;
import org.elasticsearch.index.engine.DocIdSeqNoAndSource;
import org.elasticsearch.index.engine.Engine;
<font color="#0000ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>import org.elasticsearch.index.engine.InternalEngine;
import org.elasticsearch.index.seqno.SeqNoStats;
import org.elasticsearch.index.seqno.SequenceNumbers;
import org.elasticsearch.index.shard.IndexShard;
import org.elasticsearch.index.shard.IndexShardTestCase;
import org.elasticsearch.index.shard.ShardId;
import org.elasticsearch.indices.IndicesService;
import org.elasticsearch.indices.breaker.CircuitBreakerService;
import org.elasticsearch.indices.breaker.HierarchyCircuitBreakerService;
import org.elasticsearch.indices.recovery.RecoverySettings;
import org.elasticsearch.node.MockNode;
import org.elasticsearch.node.Node;
import org.elasticsearch.node.NodeValidationException;
import org.elasticsearch.plugins.Plugin;
import org.elasticsearch.test.disruption.ServiceDisruptionScheme;
import org.elasticsearch.test.transport.MockTransportService;
import org.elasticsearch.transport.TransportService;
import org.elasticsearch.transport.TransportSettings;

import io.crate.common.io.IOUtils;
import io.crate.common.unit.TimeValue;
import static org.junit.Assert.assertEquals;

/**
 * InternalTestCluster manages a set of JVM private nodes and allows convenient access to them.
 * The cluster supports randomized configuration such that nodes started in the cluster will
 * automatically load asserting services tracking resources like file handles or open searchers.
 * &lt;p&gt;
 * The Cluster is bound to a test lifecycle where tests must call {@link #beforeTest(java.util.Random)} and
 * {@link #afterTest()} to initialize and reset the cluster in order to be more reproducible. The term "more" relates
 * to the async nature of Elasticsearch in combination with randomized testing. Once Threads and asynchronous calls
 * are involved reproducibility is very limited. This class should only be used through {@link ESIntegTestCase}.
 * &lt;/p&gt;
 */
public final class InternalTestCluster extends TestCluster {

    private final Logger logger = LogManager.getLogger(getClass())</b></font>;

    private static final Predicate&lt;NodeAndClient&gt; DATA_NODE_PREDICATE =
        nodeAndClient -&gt; DiscoveryNode.isDataNode(nodeAndClient.node.settings());

    private static final Predicate&lt;NodeAndClient&gt; NO_DATA_NO_MASTER_PREDICATE = nodeAndClient -&gt;
        DiscoveryNode.isMasterEligibleNode(nodeAndClient.node.settings()) == false
            &amp;&amp; DiscoveryNode.isDataNode(nodeAndClient.node.settings()) == false;

    private static final Predicate&lt;NodeAndClient&gt; MASTER_NODE_PREDICATE =
        nodeAndClient -&gt; DiscoveryNode.isMasterEligibleNode(nodeAndClient.node.settings());

    public static final int DEFAULT_LOW_NUM_MASTER_NODES = 1;
    public static final int DEFAULT_HIGH_NUM_MASTER_NODES = 3;

    static final int DEFAULT_MIN_NUM_DATA_NODES = 1;
    static final int DEFAULT_MAX_NUM_DATA_NODES = TEST_NIGHTLY ? 6 : 3;

    static final int DEFAULT_NUM_CLIENT_NODES = -1;
    static final int DEFAULT_MIN_NUM_CLIENT_NODES = 0;
    static final int DEFAULT_MAX_NUM_CLIENT_NODES = 1;

    /* Sorted map to make traverse order reproducible.
     * The map of nodes is never mutated so individual reads are safe without synchronization.
     * Updates are intended to follow a copy-on-write approach. */
    private volatile NavigableMap&lt;String, NodeAndClient&gt; nodes = Collections.emptyNavigableMap();

    private final Set&lt;Path&gt; dataDirToClean = new HashSet&lt;&gt;();

    private final String clusterName;

    private final AtomicBoolean open = new AtomicBoolean(true);

    private final Settings defaultSettings;

    private final AtomicInteger nextNodeId = new AtomicInteger(0);

    /* Each shared node has a node seed that is used to start up the node and get default settings
     * this is important if a node is randomly shut down in a test since the next test relies on a
     * fully shared cluster to be more reproducible */
    private final long[] sharedNodesSeeds;


    // if set to 0, data nodes will also assume the master role
    private final int numSharedDedicatedMasterNodes;

    private final int numSharedDataNodes;

    private final int numSharedCoordOnlyNodes;

    private final NodeConfigurationSource nodeConfigurationSource;

    private final ExecutorService executor;

    private final boolean autoManageMasterNodes;

    private final Collection&lt;Class&lt;? extends Plugin&gt;&gt; mockPlugins;

    private final boolean forbidPrivateIndexSettings;

    private final int numDataPaths;

    /**
     * All nodes started by the cluster will have their name set to nodePrefix followed by a positive number
     */
    private final String nodePrefix;
    private final Path baseDir;

    private ServiceDisruptionScheme activeDisruptionScheme;

    private int bootstrapMasterNodeIndex = -1;

    public InternalTestCluster(
            final long clusterSeed,
            final Path baseDir,
            final boolean randomlyAddDedicatedMasters,
            final boolean autoManageMasterNodes,
            final int minNumDataNodes,
            final int maxNumDataNodes,
            final String clusterName,
            final NodeConfigurationSource nodeConfigurationSource,
            final int numClientNodes,
            final String nodePrefix,
            final Collection&lt;Class&lt;? extends Plugin&gt;&gt; mockPlugins) {
        this(
                clusterSeed,
                baseDir,
                randomlyAddDedicatedMasters,
                autoManageMasterNodes,
                minNumDataNodes,
                maxNumDataNodes,
                clusterName,
                nodeConfigurationSource,
                numClientNodes,
                nodePrefix,
                mockPlugins,
                true);
    }

    public InternalTestCluster(
            final long clusterSeed,
            final Path baseDir,
            final boolean randomlyAddDedicatedMasters,
            final boolean autoManageMasterNodes,
            final int minNumDataNodes,
            final int maxNumDataNodes,
            final String clusterName,
            final NodeConfigurationSource nodeConfigurationSource,
            final int numClientNodes,
            final String nodePrefix,
            final Collection&lt;Class&lt;? extends Plugin&gt;&gt; mockPlugins,
            final boolean forbidPrivateIndexSettings) {
        super(clusterSeed);
        this.autoManageMasterNodes = autoManageMasterNodes;
        this.forbidPrivateIndexSettings = forbidPrivateIndexSettings;
        this.baseDir = baseDir;
        this.clusterName = clusterName;
        if (minNumDataNodes &lt; 0 || maxNumDataNodes &lt; 0) {
            throw new IllegalArgumentException("minimum and maximum number of data nodes must be &gt;= 0");
        }

        if (maxNumDataNodes &lt; minNumDataNodes) {
            throw new IllegalArgumentException("maximum number of data nodes must be &gt;= minimum number of  data nodes");
        }

        Random random = new Random(clusterSeed);

        boolean useDedicatedMasterNodes = randomlyAddDedicatedMasters &amp;&amp; random.nextBoolean();

        this.numSharedDataNodes = RandomNumbers.randomIntBetween(random, minNumDataNodes, maxNumDataNodes);
        assert this.numSharedDataNodes &gt;= 0;

        if (numSharedDataNodes == 0) {
            this.numSharedCoordOnlyNodes = 0;
            this.numSharedDedicatedMasterNodes = 0;
        } else {
            if (useDedicatedMasterNodes) {
                if (random.nextBoolean()) {
                    // use a dedicated master, but only low number to reduce overhead to tests
                    this.numSharedDedicatedMasterNodes = DEFAULT_LOW_NUM_MASTER_NODES;
                } else {
                    this.numSharedDedicatedMasterNodes = DEFAULT_HIGH_NUM_MASTER_NODES;
                }
            } else {
                this.numSharedDedicatedMasterNodes = 0;
            }
            if (numClientNodes &lt; 0) {
                this.numSharedCoordOnlyNodes =  RandomNumbers.randomIntBetween(random,
                        DEFAULT_MIN_NUM_CLIENT_NODES, DEFAULT_MAX_NUM_CLIENT_NODES);
            } else {
                this.numSharedCoordOnlyNodes = numClientNodes;
            }
        }
        assert this.numSharedCoordOnlyNodes &gt;= 0;

        this.nodePrefix = nodePrefix;

        assert nodePrefix != null;

        this.mockPlugins = mockPlugins;

        sharedNodesSeeds = new long[numSharedDedicatedMasterNodes + numSharedDataNodes + numSharedCoordOnlyNodes];
        for (int i = 0; i &lt; sharedNodesSeeds.length; i++) {
            sharedNodesSeeds[i] = random.nextLong();
        }

        logger.info("Setup InternalTestCluster [{}] with seed [{}] using [{}] dedicated masters, " +
                "[{}] (data) nodes and [{}] coord only nodes (master nodes are [{}])",
            clusterName, SeedUtils.formatSeed(clusterSeed),
<a name="1"></a>            numSharedDedicatedMasterNodes, numSharedDataNodes, numSharedCoordOnlyNodes,
            autoManageMasterNodes ? "auto-managed" : "manual");
        this.nodeConfigurationSource = nodeConfigurationSource;
        numDataPaths = <font color="#f63526"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>random.nextInt(5) == 0 ? 2 + random.nextInt(3) : 1;
        Builder builder = Settings.builder();
        builder.put(Environment.PATH_HOME_SETTING.getKey(), baseDir);
        builder.put(Environment.PATH_REPO_SETTING.getKey(), baseDir.resolve("repos"));
        builder.put(TransportSettings.PORT.getKey(), 0);
        builder.put</b></font>("http.port", 0);
        if (Strings.hasLength(System.getProperty("tests.es.logger.level"))) {
            builder.put("logger.level", System.getProperty("tests.es.logger.level"));
        }
        if (Strings.hasLength(System.getProperty("es.logger.prefix"))) {
            builder.put("logger.prefix", System.getProperty("es.logger.prefix"));
        }

        builder.put(TOTAL_CIRCUIT_BREAKER_LIMIT_SETTING.getKey(), "100%");

        // Default the watermarks to absurdly low to prevent the tests
        // from failing on nodes without enough disk space
        builder.put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK_SETTING.getKey(), "1b");
        builder.put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK_SETTING.getKey(), "1b");
        builder.put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_DISK_FLOOD_STAGE_WATERMARK_SETTING.getKey(), "1b");
        if (TEST_NIGHTLY) {
            builder.put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_INCOMING_RECOVERIES_SETTING.getKey(),
                    RandomNumbers.randomIntBetween(random, 5, 10));
            builder.put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_OUTGOING_RECOVERIES_SETTING.getKey(),
                    RandomNumbers.randomIntBetween(random, 5, 10));
        } else if (random.nextInt(100) &lt;= 90) {
            builder.put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_INCOMING_RECOVERIES_SETTING.getKey(),
                    RandomNumbers.randomIntBetween(random, 2, 5));
            builder.put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_OUTGOING_RECOVERIES_SETTING.getKey(),
                    RandomNumbers.randomIntBetween(random, 2, 5));
        }
        // always reduce this - it can make tests really slow
        builder.put(RecoverySettings.INDICES_RECOVERY_RETRY_DELAY_STATE_SYNC_SETTING.getKey(), TimeValue.timeValueMillis(
                RandomNumbers.randomIntBetween(random, 20, 50)));
        builder.put(RecoverySettings.INDICES_RECOVERY_MAX_CONCURRENT_FILE_CHUNKS_SETTING.getKey(),
                    RandomNumbers.randomIntBetween(random, 1, 5));
        defaultSettings = builder.build();
        executor = EsExecutors.newScaling(
            "internal_test_cluster_executor",
            0,
            Integer.MAX_VALUE,
            0,
            TimeUnit.SECONDS,
            EsExecutors.daemonThreadFactory("test_" + clusterName));
    }

    /**
     * Sets {@link #bootstrapMasterNodeIndex} to the given value, see {@link #bootstrapMasterNodeWithSpecifiedIndex(List)}
     * for the description of how this field is used.
     * It's only possible to change {@link #bootstrapMasterNodeIndex} value if autoManageMasterNodes is false.
     */
    public void setBootstrapMasterNodeIndex(int bootstrapMasterNodeIndex) {
        assert autoManageMasterNodes == false || bootstrapMasterNodeIndex == -1
            : "bootstrapMasterNodeIndex should be -1 if autoManageMasterNodes is true, but was " + bootstrapMasterNodeIndex;
        this.bootstrapMasterNodeIndex = bootstrapMasterNodeIndex;
    }

    @Override
    public String getClusterName() {
        return clusterName;
    }

    public String[] getNodeNames() {
        return nodes.keySet().toArray(Strings.EMPTY_ARRAY);
    }

    private Settings getSettings(int nodeOrdinal, long nodeSeed, Settings others) {
        Builder builder = Settings.builder().put(defaultSettings)
            .put(getRandomNodeSettings(nodeSeed));
        Settings settings = nodeConfigurationSource.nodeSettings(nodeOrdinal);
        if (settings != null) {
            if (settings.get(ClusterName.CLUSTER_NAME_SETTING.getKey()) != null) {
                throw new IllegalStateException("Tests must not set a '" + ClusterName.CLUSTER_NAME_SETTING.getKey()
                        + "' as a node setting set '" + ClusterName.CLUSTER_NAME_SETTING.getKey() + "': ["
                        + settings.get(ClusterName.CLUSTER_NAME_SETTING.getKey()) + "]");
            }
            builder.put(settings);
        }
        if (others != null) {
            builder.put(others);
        }
        builder.put(ClusterName.CLUSTER_NAME_SETTING.getKey(), clusterName);
        return builder.build();
    }

    public Collection&lt;Class&lt;? extends Plugin&gt;&gt; getPlugins() {
        Set&lt;Class&lt;? extends Plugin&gt;&gt; plugins = new HashSet&lt;&gt;(nodeConfigurationSource.nodePlugins());
        plugins.addAll(mockPlugins);
        return plugins;
    }

    private static Settings getRandomNodeSettings(long seed) {
        Random random = new Random(seed);
        Builder builder = Settings.builder();
        builder.put(TransportSettings.TRANSPORT_COMPRESS.getKey(), rarely(random));
        if (random.nextBoolean()) {
            builder.put("cache.recycler.page.type", RandomPicks.randomFrom(random, PageCacheRecycler.Type.values()));
        }

<a name="6"></a>        builder.put(EsExecutors.PROCESSORS_SETTING.getKey(), 1 + random.nextInt(3));

        // randomize tcp settings
        if (random.nextBoolean()) <font color="#8c8774"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>{
            builder.put(TransportSettings.CONNECTIONS_PER_NODE_RECOVERY.getKey(), random.nextInt(2) + 1);
            builder.put(TransportSettings.CONNECTIONS_PER_NODE_BULK.getKey(), random.nextInt(3) + 1);
            builder.put(TransportSettings.CONNECTIONS_PER_NODE_REG.getKey(), random.nextInt(6) + 1);
        }</b></font>

        if (random.nextBoolean()) {
            builder.put(MappingUpdatedAction.INDICES_MAPPING_DYNAMIC_TIMEOUT_SETTING.getKey(),
                    timeValueSeconds(RandomNumbers.randomIntBetween(random, 10, 30)).getStringRep());
        }

        if (random.nextInt(10) == 0) {
            builder.put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_TYPE_SETTING.getKey(), "noop");
        }

        if (random.nextBoolean()) {
            if (random.nextInt(10) == 0) { // do something crazy slow here
                builder.put(RecoverySettings.INDICES_RECOVERY_MAX_BYTES_PER_SEC_SETTING.getKey(),
                        new ByteSizeValue(RandomNumbers.randomIntBetween(random, 1, 10), ByteSizeUnit.MB));
            } else {
                builder.put(RecoverySettings.INDICES_RECOVERY_MAX_BYTES_PER_SEC_SETTING.getKey(),
                        new ByteSizeValue(RandomNumbers.randomIntBetween(random, 10, 200), ByteSizeUnit.MB));
            }
        }

        if (random.nextBoolean()) {
            builder.put(TransportSettings.PING_SCHEDULE.getKey(), RandomNumbers.randomIntBetween(random, 100, 2000) + "ms");
        }

        return builder.build();
    }
<a name="7"></a>
    public static String clusterName(String prefix, long clusterSeed) {
        StringBuilder builder = new StringBuilder(prefix);
        <font color="#38a4a5"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>builder.append("-TEST_WORKER_VM=[").append(ESTestCase.TEST_WORKER_VM_ID).append(']');
        builder.append("-CLUSTER_SEED=[").append(clusterSeed).append(']');
        // if multiple maven task run on a single host we better have an identifier that doesn't rely on input params
        builder.append("-HASH=[").append(SeedUtils.formatSeed(System.nanoTime</b></font>())).append(']');
        return builder.toString();
    }

    private void ensureOpen() {
        if (!open.get()) {
            throw new RuntimeException("Cluster is already closed");
        }
    }

    private NodeAndClient getOrBuildRandomNode() {
        assert Thread.holdsLock(this);
        final NodeAndClient randomNodeAndClient = getRandomNodeAndClient();
        if (randomNodeAndClient != null) {
            return randomNodeAndClient;
        }
        final Runnable onTransportServiceStarted = () -&gt; {}; // do not create unicast host file for this one node.

        final int nodeId = nextNodeId.getAndIncrement();
        final Settings settings = getNodeSettings(nodeId, random.nextLong(), Settings.EMPTY);
        final Settings nodeSettings = Settings.builder()
                .putList(INITIAL_MASTER_NODES_SETTING.getKey(), Node.NODE_NAME_SETTING.get(settings))
                .put(settings)
                .build();
        final NodeAndClient buildNode = buildNode(nodeId, nodeSettings, false, onTransportServiceStarted);
        assert nodes.isEmpty();
        buildNode.startNode();
        publishNode(buildNode);
        return buildNode;
    }

    private NodeAndClient getRandomNodeAndClient() {
        return getRandomNodeAndClient(nc -&gt; true);
    }

    private synchronized NodeAndClient getRandomNodeAndClient(Predicate&lt;NodeAndClient&gt; predicate) {
        ensureOpen();
        List&lt;NodeAndClient&gt; values = nodes.values().stream().filter(predicate).collect(Collectors.toList());
        if (values.isEmpty() == false) {
            return randomFrom(random, values);
        }
        return null;
    }

    /**
     * Ensures that at least &lt;code&gt;n&lt;/code&gt; data nodes are present in the cluster.
     * if more nodes than &lt;code&gt;n&lt;/code&gt; are present this method will not
     * stop any of the running nodes.
     */
    public synchronized void ensureAtLeastNumDataNodes(int n) {
        int size = numDataNodes();
        if (size &lt; n) {
            logger.info("increasing cluster size from {} to {}", size, n);
            if (numSharedDedicatedMasterNodes &gt; 0) {
                startDataOnlyNodes(n - size);
            } else {
                startNodes(n - size);
            }
            validateClusterFormed();
        }
    }

    /**
     * Ensures that at most &lt;code&gt;n&lt;/code&gt; are up and running.
     * If less nodes that &lt;code&gt;n&lt;/code&gt; are running this method
     * will not start any additional nodes.
     */
    public synchronized void ensureAtMostNumDataNodes(int n) throws IOException {
        int size = numDataNodes();
        if (size &lt;= n) {
<a name="12"></a>            return;
        }
        // prevent killing the master if possible and client nodes
        <font color="#571b7e"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>final Stream&lt;NodeAndClient&gt; collection = n == 0
                ? nodes.values().stream()
                : nodes.values().stream()
                        .filter(DATA_NODE_PREDICATE.and(new NodeNamePredicate(getMasterName()).negate</b></font>()));
        final Iterator&lt;NodeAndClient&gt; values = collection.iterator();

        logger.info("changing cluster size from {} data nodes to {}", size, n);
        Set&lt;NodeAndClient&gt; nodesToRemove = new HashSet&lt;&gt;();
        int numNodesAndClients = 0;
        while (values.hasNext() &amp;&amp; numNodesAndClients++ &lt; size - n) {
            NodeAndClient next = values.next();
            nodesToRemove.add(next);
        }

        stopNodesAndClients(nodesToRemove);
        if (!nodesToRemove.isEmpty() &amp;&amp; size() &gt; 0) {
            validateClusterFormed();
        }
    }

    private Settings getNodeSettings(final int nodeId, final long seed, final Settings extraSettings) {
        final Settings settings = getSettings(nodeId, seed, extraSettings);

        final String name = buildNodeName(nodeId, settings);

        final Settings.Builder updatedSettings = Settings.builder();

        updatedSettings.put(Environment.PATH_HOME_SETTING.getKey(), baseDir);

        if (numDataPaths &gt; 1) {
            updatedSettings.putList(Environment.PATH_DATA_SETTING.getKey(), IntStream.range(0, numDataPaths).mapToObj(i -&gt;
                baseDir.resolve(name).resolve("d" + i).toString()).collect(Collectors.toList()));
        } else {
            updatedSettings.put(Environment.PATH_DATA_SETTING.getKey(), baseDir.resolve(name));
        }

        updatedSettings.put(Environment.PATH_SHARED_DATA_SETTING.getKey(), baseDir.resolve(name + "-shared"));

        // allow overriding the above
        updatedSettings.put(settings);
        // force certain settings
        updatedSettings.put("node.name", name);
        updatedSettings.put(NodeEnvironment.NODE_ID_SEED_SETTING.getKey(), seed);

        if (autoManageMasterNodes) {
            assertThat("if master nodes are automatically managed then nodes must complete a join cycle when starting",
                updatedSettings.get(INITIAL_STATE_TIMEOUT_SETTING.getKey()), nullValue());
        }

        return updatedSettings.build();
    }

    /**
     * builds a new node
     *
     * @param nodeId                    node ordinal
     * @param settings                  the settings to use
     * @param reuseExisting             if a node with the same name is already part of {@link #nodes}, no new node will be built and
     *                                  the method will return the existing one
     * @param onTransportServiceStarted callback to run when transport service is started
     */
    private synchronized NodeAndClient buildNode(int nodeId, Settings settings,
                                    boolean reuseExisting, Runnable onTransportServiceStarted) {
        assert Thread.holdsLock(this);
        ensureOpen();
        Collection&lt;Class&lt;? extends Plugin&gt;&gt; plugins = getPlugins();
        String name = settings.get("node.name");

        final NodeAndClient nodeAndClient = nodes.get(name);
        if (reuseExisting &amp;&amp; nodeAndClient != null) {
            onTransportServiceStarted.run(); // reusing an existing node implies its transport service already started
            return nodeAndClient;
        }
        assert reuseExisting || nodeAndClient == null : "node name [" + name + "] already exists but not allowed to use it";

        MockNode node = new MockNode(
                settings,
                plugins,
                nodeConfigurationSource.nodeConfigPath(nodeId),
                forbidPrivateIndexSettings);
        node.injector().getInstance(TransportService.class).addLifecycleListener(new LifecycleListener() {
            @Override
            public void afterStart() {
                onTransportServiceStarted.run();
            }
        });
        return new NodeAndClient(name, node, settings, nodeId);
    }

    private String getNodePrefix(Settings settings) {
        return nodePrefix + getRoleSuffix(settings);
    }

    private String buildNodeName(int id, Settings settings) {
        return getNodePrefix(settings) + id;
    }

    /**
     * returns a suffix string based on the node role. If no explicit role is defined, the suffix will be empty
     */
    private static String getRoleSuffix(Settings settings) {
        String suffix = "";
        if (Node.NODE_MASTER_SETTING.exists(settings) &amp;&amp; Node.NODE_MASTER_SETTING.get(settings)) {
            suffix = suffix + DiscoveryNodeRole.MASTER_ROLE.roleNameAbbreviation();
        }
        if (Node.NODE_DATA_SETTING.exists(settings) &amp;&amp; Node.NODE_DATA_SETTING.get(settings)) {
            suffix = suffix + DiscoveryNodeRole.DATA_ROLE.roleNameAbbreviation();
        }
        if (Node.NODE_MASTER_SETTING.exists(settings) &amp;&amp; Node.NODE_MASTER_SETTING.get(settings) == false &amp;&amp;
            Node.NODE_DATA_SETTING.exists(settings) &amp;&amp; Node.NODE_DATA_SETTING.get(settings) == false
            ) {
            suffix = suffix + "c";
        }
        return suffix;
    }

    @Override
    public synchronized Client client() {
        ensureOpen();
        /* Randomly return a client to one of the nodes in the cluster */
        return getOrBuildRandomNode().client();
    }

    /**
     * Returns a node client to a data node in the cluster.
     * Note: use this with care tests should not rely on a certain nodes client.
     */
    public Client dataNodeClient() {
        /* Randomly return a client to one of the nodes in the cluster */
        return getRandomNodeAndClient(DATA_NODE_PREDICATE).client();
    }

    /**
     * Returns a node client to the current master node.
     * Note: use this with care tests should not rely on a certain nodes client.
     */
    public Client masterClient() {
        NodeAndClient randomNodeAndClient = getRandomNodeAndClient(new NodeNamePredicate(getMasterName()));
        if (randomNodeAndClient != null) {
            return randomNodeAndClient.nodeClient(); // ensure node client master is requested
        }
        throw new AssertionError("No master client found");
    }

    /**
     * Returns a node client to random node but not the master. This method will fail if no non-master client is available.
     */
    public Client nonMasterClient() {
        NodeAndClient randomNodeAndClient = getRandomNodeAndClient(new NodeNamePredicate(getMasterName()).negate());
        if (randomNodeAndClient != null) {
            return randomNodeAndClient.nodeClient(); // ensure node client non-master is requested
        }
        throw new AssertionError("No non-master client found");
    }

    /**
     * Returns a client to a coordinating only node
     */
    public synchronized Client coordOnlyNodeClient() {
        ensureOpen();
        NodeAndClient randomNodeAndClient = getRandomNodeAndClient(NO_DATA_NO_MASTER_PREDICATE);
        if (randomNodeAndClient != null) {
            return randomNodeAndClient.client();
        }
        int nodeId = nextNodeId.getAndIncrement();
        Settings settings = getSettings(nodeId, random.nextLong(), Settings.EMPTY);
        startCoordinatingOnlyNode(settings);
<a name="11"></a>        return getRandomNodeAndClient(NO_DATA_NO_MASTER_PREDICATE).client();
    }

    public synchronized String startCoordinatingOnlyNode(Settings settings) <font color="#b041ff"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>{
        ensureOpen(); // currently unused
        Builder builder = Settings.builder().put(settings).put(Node.NODE_MASTER_SETTING.getKey(), false)
            .put(Node.NODE_DATA_SETTING.getKey</b></font>(), false);
        return startNode(builder);
    }

    /**
     * Returns a node client to a given node.
     */
    public Client client(String nodeName) {
        NodeAndClient nodeAndClient = nodes.get(nodeName);
        if (nodeAndClient != null) {
            return nodeAndClient.client();
        }
        throw new AssertionError("No node found with name: [" + nodeName + "]");
    }


    /**
     * Returns a "smart" node client to a random node in the cluster
     */
    public Client smartClient() {
        NodeAndClient randomNodeAndClient = getRandomNodeAndClient();
        if (randomNodeAndClient != null) {
            return randomNodeAndClient.nodeClient();
        }
        throw new AssertionError("No smart client found");
    }

    @Override
    public synchronized void close() throws IOException {
        if (this.open.compareAndSet(true, false)) {
            if (activeDisruptionScheme != null) {
                activeDisruptionScheme.testClusterClosed();
                activeDisruptionScheme = null;
            }
            try {
                IOUtils.close(nodes.values());
            } finally {
                nodes = Collections.emptyNavigableMap();
                executor.shutdownNow();
            }
        }
    }

    private final class NodeAndClient implements Closeable {
        private MockNode node;
        private final Settings originalNodeSettings;
        private Client nodeClient;
        private final AtomicBoolean closed = new AtomicBoolean(false);
        private final String name;
        private final int nodeAndClientId;

        NodeAndClient(String name, MockNode node, Settings originalNodeSettings, int nodeAndClientId) {
            this.node = node;
            this.name = name;
            this.originalNodeSettings = originalNodeSettings;
            this.nodeAndClientId = nodeAndClientId;
            markNodeDataDirsAsNotEligibleForWipe(node);
        }

        Node node() {
            if (closed.get()) {
                throw new RuntimeException("already closed");
            }
            return node;
        }

        public int nodeAndClientId() {
            return nodeAndClientId;
        }

        public String getName() {
            return name;
        }

        public boolean isMasterEligible() {
            return Node.NODE_MASTER_SETTING.get(node.settings());
        }

        Client client() {
            return getOrBuildNodeClient();
        }

        Client nodeClient() {
            if (closed.get()) {
                throw new RuntimeException("already closed");
            }
            return getOrBuildNodeClient();
        }

        private Client getOrBuildNodeClient() {
            synchronized (InternalTestCluster.this) {
                if (closed.get()) {
                    throw new RuntimeException("already closed");
                }
                if (nodeClient == null) {
                    nodeClient = node.client();
                }
                return nodeClient;
            }
        }

        void resetClient() {
            if (closed.get() == false) {
                Releasables.close(nodeClient);
                nodeClient = null;
            }
        }

        void startNode() {
            boolean success = false;
            try {
                node.start();
                success = true;
            } catch (NodeValidationException e) {
                throw new RuntimeException(e);
            } finally {
                if (success == false) {
                    IOUtils.closeWhileHandlingException(node);
                }
            }
        }

        /**
         * closes the node and prepares it to be restarted
         */
        Settings closeForRestart(RestartCallback callback) throws Exception {
            assert callback != null;
            close();
            removeNode(this);
            Settings callbackSettings = callback.onNodeStopped(name);
            assert callbackSettings != null;
            Settings.Builder newSettings = Settings.builder();
            if (autoManageMasterNodes) {
                newSettings.putList(INITIAL_MASTER_NODES_SETTING.getKey());
            }
            newSettings.put(callbackSettings);
            // delete data folders now, before we start other nodes that may claim it
            clearDataIfNeeded(callback);
            return newSettings.build();
        }

        private void clearDataIfNeeded(RestartCallback callback) throws IOException {
            if (callback.clearData(name)) {
                NodeEnvironment nodeEnv = node.getNodeEnvironment();
                if (nodeEnv.hasNodeFile()) {
                    final Path[] locations = nodeEnv.nodeDataPaths();
                    logger.debug("removing node data paths: [{}]", Arrays.toString(locations));
                    IOUtils.rm(locations);
                }
            }
        }

        private void recreateNode(final Settings newSettings, final Runnable onTransportServiceStarted) {
            if (closed.get() == false) {
                throw new IllegalStateException("node " + name + " should be closed before recreating it");
            }
            // use a new seed to make sure we generate a fresh new node id if the data folder has been wiped
            final long newIdSeed = NodeEnvironment.NODE_ID_SEED_SETTING.get(node.settings()) + 1;
            Settings finalSettings = Settings.builder()
                    .put(originalNodeSettings)
                    .put(newSettings)
                    .put(NodeEnvironment.NODE_ID_SEED_SETTING.getKey(), newIdSeed)
                    .build();
            Collection&lt;Class&lt;? extends Plugin&gt;&gt; plugins = node.getClasspathPlugins();
            node = new MockNode(finalSettings, plugins);
            node.injector().getInstance(TransportService.class).addLifecycleListener(new LifecycleListener() {
                @Override
                public void afterStart() {
                    onTransportServiceStarted.run();
                }
            });
            closed.set(false);
            markNodeDataDirsAsNotEligibleForWipe(node);
        }

        @Override
        public void close() throws IOException {
            assert Thread.holdsLock(InternalTestCluster.this);
            try {
                resetClient();
            } finally {
                closed.set(true);
                markNodeDataDirsAsPendingForWipe(node);
                node.close();
                try {
                    if (node.awaitClose(10, TimeUnit.SECONDS) == false) {
                        throw new IOException("Node didn't close within 10 seconds.");
                    }
                } catch (InterruptedException e) {
                    throw new AssertionError("Interruption while waiting for the node to close", e);
                }
            }
        }

        private void markNodeDataDirsAsPendingForWipe(Node node) {
            assert Thread.holdsLock(InternalTestCluster.this);
            NodeEnvironment nodeEnv = node.getNodeEnvironment();
            if (nodeEnv.hasNodeFile()) {
                dataDirToClean.addAll(Arrays.asList(nodeEnv.nodeDataPaths()));
            }
        }

        private void markNodeDataDirsAsNotEligibleForWipe(Node node) {
            assert Thread.holdsLock(InternalTestCluster.this);
            NodeEnvironment nodeEnv = node.getNodeEnvironment();
            if (nodeEnv.hasNodeFile()) {
                dataDirToClean.removeAll(Arrays.asList(nodeEnv.nodeDataPaths()));
            }
        }
    }

    @Override
    public synchronized void beforeTest(Random random) throws IOException, InterruptedException {
        super.beforeTest(random);
        reset(true);
    }

    private synchronized void reset(boolean wipeData) throws IOException {
        // clear all rules for mock transport services
        for (NodeAndClient nodeAndClient : nodes.values()) {
            TransportService transportService = nodeAndClient.node.injector().getInstance(TransportService.class);
            if (transportService instanceof MockTransportService) {
                final MockTransportService mockTransportService = (MockTransportService) transportService;
                mockTransportService.clearAllRules();
            }
        }
        randomlyResetClients();
        final int newSize = sharedNodesSeeds.length;
        if (nextNodeId.get() == newSize &amp;&amp; nodes.size() == newSize) {
            if (wipeData) {
                wipePendingDataDirectories();
            }
            logger.debug("Cluster hasn't changed - moving out - nodes: [{}] nextNodeId: [{}] numSharedNodes: [{}]",
                    nodes.keySet(), nextNodeId.get(), newSize);
            return;
        }
        logger.debug("Cluster is NOT consistent - restarting shared nodes - nodes: [{}] nextNodeId: [{}] numSharedNodes: [{}]",
                nodes.keySet(), nextNodeId.get(), newSize);

        // trash all nodes with id &gt;= sharedNodesSeeds.length - they are non shared
        final List&lt;NodeAndClient&gt; toClose = new ArrayList&lt;&gt;();
        for (NodeAndClient nodeAndClient : nodes.values()) {
            if (nodeAndClient.nodeAndClientId() &gt;= sharedNodesSeeds.length) {
                logger.debug("Close Node [{}] not shared", nodeAndClient.name);
                toClose.add(nodeAndClient);
            }
        }
        stopNodesAndClients(toClose);

        // clean up what the nodes left that is unused
        if (wipeData) {
            wipePendingDataDirectories();
        }

        assertTrue("expected at least one master-eligible node left in " + nodes,
            nodes.isEmpty() || nodes.values().stream().anyMatch(NodeAndClient::isMasterEligible));

        final int prevNodeCount = nodes.size();

        // start any missing node
        assert newSize == numSharedDedicatedMasterNodes + numSharedDataNodes + numSharedCoordOnlyNodes;
        final List&lt;NodeAndClient&gt; toStartAndPublish = new ArrayList&lt;&gt;(); // we want to start nodes in one go
        final Runnable onTransportServiceStarted = () -&gt; rebuildUnicastHostFiles(toStartAndPublish);

<a name="16"></a>        final List&lt;Settings&gt; settings = new ArrayList&lt;&gt;();

        for (int i = 0; i &lt; numSharedDedicatedMasterNodes; i++) {
            final Settings.Builder extraSettings = <font color="#2981b2"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>Settings.builder();
            extraSettings.put(Node.NODE_MASTER_SETTING.getKey(), true);
            extraSettings.put(Node.NODE_DATA_SETTING.getKey(), false);
            settings.add(getNodeSettings(i, sharedNodesSeeds[i], extraSettings.build()));
        }</b></font>
        for (int i = numSharedDedicatedMasterNodes; i &lt; numSharedDedicatedMasterNodes + numSharedDataNodes; i++) {
            final Settings.Builder extraSettings = Settings.builder();
            if (numSharedDedicatedMasterNodes &gt; 0) {
                // if we don't have dedicated master nodes, keep things default
                extraSettings.put(Node.NODE_MASTER_SETTING.getKey(), false).build();
                extraSettings.put(Node.NODE_DATA_SETTING.getKey(), true).build();
            }
            settings.add(getNodeSettings(i, sharedNodesSeeds[i], extraSettings.build()));
<a name="14"></a>        }
        for (int i = numSharedDedicatedMasterNodes + numSharedDataNodes;
             i &lt; numSharedDedicatedMasterNodes + numSharedDataNodes + numSharedCoordOnlyNodes; i++) {
            final Builder extraSettings = <font color="#842dce"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>Settings.builder().put(Node.NODE_MASTER_SETTING.getKey(), false)
                .put(Node.NODE_DATA_SETTING.getKey(), false);
            settings.add(getNodeSettings(i, sharedNodesSeeds[i], extraSettings.build()));
        }</b></font>

        int autoBootstrapMasterNodeIndex = -1;
        final List&lt;String&gt; masterNodeNames = settings.stream()
                .filter(Node.NODE_MASTER_SETTING::get)
                .map(Node.NODE_NAME_SETTING::get)
                .collect(Collectors.toList());

        if (prevNodeCount == 0 &amp;&amp; autoManageMasterNodes) {
            if (numSharedDedicatedMasterNodes &gt; 0) {
                autoBootstrapMasterNodeIndex = RandomNumbers.randomIntBetween(random, 0, numSharedDedicatedMasterNodes - 1);
            } else if (numSharedDataNodes &gt; 0) {
                autoBootstrapMasterNodeIndex = RandomNumbers.randomIntBetween(random, 0, numSharedDataNodes - 1);
            }
        }

        final List&lt;Settings&gt; updatedSettings = bootstrapMasterNodeWithSpecifiedIndex(settings);

        for (int i = 0; i &lt; numSharedDedicatedMasterNodes + numSharedDataNodes + numSharedCoordOnlyNodes; i++) {
            Settings nodeSettings = updatedSettings.get(i);
            if (i == autoBootstrapMasterNodeIndex) {
                nodeSettings = Settings.builder().putList(INITIAL_MASTER_NODES_SETTING.getKey(), masterNodeNames).put(nodeSettings).build();
            }
            final NodeAndClient nodeAndClient = buildNode(i, nodeSettings, true, onTransportServiceStarted);
            toStartAndPublish.add(nodeAndClient);
        }

        startAndPublishNodesAndClients(toStartAndPublish);

        nextNodeId.set(newSize);
        assert size() == newSize;
        if (autoManageMasterNodes &amp;&amp; newSize &gt; 0) {
            validateClusterFormed();
        }
        logger.debug("Cluster is consistent again - nodes: [{}] nextNodeId: [{}] numSharedNodes: [{}]",
                nodes.keySet(), nextNodeId.get(), newSize);
    }

    /** ensure a cluster is formed with all published nodes. */
    public synchronized void validateClusterFormed() {
        final Set&lt;DiscoveryNode&gt; expectedNodes = new HashSet&lt;&gt;();
        for (NodeAndClient nodeAndClient : nodes.values()) {
            expectedNodes.add(getInstanceFromNode(ClusterService.class, nodeAndClient.node()).localNode());
        }
        logger.trace("validating cluster formed, expecting {}", expectedNodes);

        try {
            assertBusy(() -&gt; {
                final List&lt;ClusterState&gt; states = nodes.values().stream()
                    .map(node -&gt; getInstanceFromNode(ClusterService.class, node.node()))
                    .map(ClusterService::state)
<a name="2"></a>                    .collect(Collectors.toList());
                final String debugString = ", expected nodes: " + expectedNodes + " and actual cluster states " + states;
                // all nodes have a master
                <font color="#980517"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>assertTrue("Missing master" + debugString, states.stream().allMatch(cs -&gt; cs.nodes().getMasterNodeId() != null));
                // all nodes have the same master (in same term)
                assertEquals("Not all masters in same term" + debugString, 1,
<a name="10"></a>                    states.stream().mapToLong(ClusterState::term).distinct().count());
                // all nodes know about all other nodes
                states.forEach</b></font>(cs -&gt; {
                    DiscoveryNodes discoveryNodes = <font color="#ad5910"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>cs.nodes();
                    assertEquals("Node size mismatch" + debugString, expectedNodes.size(), discoveryNodes.getSize());
                    for (DiscoveryNode expectedNode : expectedNodes) {
                        assertTrue("Expected node to exist: " + expectedNode + debugString, discoveryNodes.nodeExists</b></font>(expectedNode));
                    }
                });
            }, 30, TimeUnit.SECONDS);
        } catch (AssertionError ae) {
            throw new IllegalStateException("cluster failed to form", ae);
        } catch (Exception e) {
            throw new IllegalStateException(e);
        }
    }
<a name="9"></a>
    @Override
    public synchronized void afterTest() {
        <font color="#83a33a"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>wipePendingDataDirectories();
        randomlyResetClients(); /* reset all clients - each test gets its own client based on the Random instance created above. */
    }

    @Override
    public void beforeIndexDeletion() throws Exception {
        // Check that the operations counter on index shard has reached 0.
        // The assumption here is that after a test there are no ongoing write operations.
        // test that have ongoing write operations after the test (for example because ttl is used
        // and not all docs have been purged after the test) and inherit from
        // ElasticsearchIntegrationTest must override beforeIndexDeletion() to avoid failures.
        assertNoPendingIndexOperations();
        //check that shards that have same sync id also contain same number of documents
        assertSameSyncIdSameDocs();
        assertOpenTranslogReferences</b></font>();
    }

    private void assertSameSyncIdSameDocs() {
        Map&lt;String, Long&gt; docsOnShards = new HashMap&lt;&gt;();
        final Collection&lt;NodeAndClient&gt; nodesAndClients = nodes.values();
        for (NodeAndClient nodeAndClient : nodesAndClients) {
            IndicesService indexServices = getInstance(IndicesService.class, nodeAndClient.name);
            for (IndexService indexService : indexServices) {
                for (IndexShard indexShard : indexService) {
                    try {
                        CommitStats commitStats = indexShard.commitStats();
                        String syncId = commitStats.getUserData().get(Engine.SYNC_COMMIT_ID);
                        if (syncId != null) {
                            long liveDocsOnShard = commitStats.getNumDocs();
                            if (docsOnShards.get(syncId) != null) {
                                assertThat("sync id is equal but number of docs does not match on node "
                                    + nodeAndClient.name + ". expected " + docsOnShards.get(syncId) + " but got "
                                    + liveDocsOnShard, docsOnShards.get(syncId), equalTo(liveDocsOnShard));
                            } else {
                                docsOnShards.put(syncId, liveDocsOnShard);
                            }
                        }
                    } catch (AlreadyClosedException e) {
                        // the engine is closed or if the shard is recovering
                    }
                }
            }
        }
    }

    private void assertNoPendingIndexOperations() throws Exception {
        assertBusy(() -&gt; {
            for (NodeAndClient nodeAndClient : nodes.values()) {
                IndicesService indexServices = getInstance(IndicesService.class, nodeAndClient.name);
                for (IndexService indexService : indexServices) {
                    for (IndexShard indexShard : indexService) {
                        List&lt;String&gt; operations = indexShard.getActiveOperations();
                        if (operations.size() &gt; 0) {
                            throw new AssertionError(
                                "shard " + indexShard.shardId() + " on node [" + nodeAndClient.name + "] has pending operations:\n --&gt; " +
                                    String.join("\n --&gt; ", operations)
                            );
                        }
                    }
                }
            }
        }, 60, TimeUnit.SECONDS);
    }

    private void assertOpenTranslogReferences() throws Exception {
        assertBusy(() -&gt; {
            for (NodeAndClient nodeAndClient : nodes.values()) {
                IndicesService indexServices = getInstance(IndicesService.class, nodeAndClient.name);
                for (IndexService indexService : indexServices) {
                    for (IndexShard indexShard : indexService) {
                        try {
                            if (IndexShardTestCase.getEngine(indexShard) instanceof InternalEngine) {
                                IndexShardTestCase.getTranslog(indexShard).getDeletionPolicy().assertNoOpenTranslogRefs();
                            }
                        } catch (AlreadyClosedException ok) {
                            // all good
                        }
                    }
                }
            }
        }, 60, TimeUnit.SECONDS);
    }

    /**
     * Asserts that the document history in Lucene index is consistent with Translog's on every index shard of the cluster.
     * This assertion might be expensive, thus we prefer not to execute on every test but only interesting tests.
     */
    public void assertConsistentHistoryBetweenTranslogAndLuceneIndex() throws IOException {
        for (NodeAndClient nodeAndClient : nodes.values()) {
            IndicesService indexServices = getInstance(IndicesService.class, nodeAndClient.name);
            for (IndexService indexService : indexServices) {
                for (IndexShard indexShard : indexService) {
                    try {
                        IndexShardTestCase.assertConsistentHistoryBetweenTranslogAndLucene(indexShard);
                    } catch (AlreadyClosedException ignored) {
                        // shard is closed
                    }
                }
            }
        }
    }

    private IndexShard getShardOrNull(ClusterState clusterState, ShardRouting shardRouting) {
        if (shardRouting == null || shardRouting.assignedToNode() == false) {
            return null;
        }
        final DiscoveryNode assignedNode = clusterState.nodes().get(shardRouting.currentNodeId());
        if (assignedNode == null) {
            return null;
        }
        return getInstance(IndicesService.class, assignedNode.getName()).getShardOrNull(shardRouting.shardId());
    }

    public void assertSeqNos() throws Exception {
        assertBusy(() -&gt; {
            final ClusterState state = clusterService().state();
            for (ObjectObjectCursor&lt;String, IndexRoutingTable&gt; indexRoutingTable : state.routingTable().indicesRouting()) {
                for (IntObjectCursor&lt;IndexShardRoutingTable&gt; indexShardRoutingTable : indexRoutingTable.value.shards()) {
                    ShardRouting primaryShardRouting = indexShardRoutingTable.value.primaryShard();
                    final IndexShard primaryShard = getShardOrNull(state, primaryShardRouting);
                    if (primaryShard == null) {
                        continue; //just ignore - shard movement
                    }
                    final SeqNoStats primarySeqNoStats;
                    final ObjectLongMap&lt;String&gt; syncGlobalCheckpoints;
                    try {
                        primarySeqNoStats = primaryShard.seqNoStats();
                        syncGlobalCheckpoints = primaryShard.getInSyncGlobalCheckpoints();
                    } catch (AlreadyClosedException ex) {
                        continue; // shard is closed - just ignore
                    }
                    assertThat(primaryShardRouting + " should have set the global checkpoint",
                        primarySeqNoStats.getGlobalCheckpoint(), not(equalTo(SequenceNumbers.UNASSIGNED_SEQ_NO)));
                    for (ShardRouting replicaShardRouting : indexShardRoutingTable.value.replicaShards()) {
                        final IndexShard replicaShard = getShardOrNull(state, replicaShardRouting);
                        if (replicaShard == null) {
                            continue; //just ignore - shard movement
                        }
                        final SeqNoStats seqNoStats;
                        try {
                            seqNoStats = replicaShard.seqNoStats();
<a name="3"></a>                        } catch (AlreadyClosedException e) {
                            continue; // shard is closed - just ignore
                        }
                        <font color="#53858b"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>assertThat(replicaShardRouting + " seq_no_stats mismatch", seqNoStats, equalTo(primarySeqNoStats));
                        // the local knowledge on the primary of the global checkpoint equals the global checkpoint on the shard
                        assertThat(replicaShardRouting + " global checkpoint syncs mismatch", seqNoStats.getGlobalCheckpoint(),
                            equalTo(syncGlobalCheckpoints.get(replicaShardRouting.allocationId().getId())));
                    }
                }</b></font>
            }
        }, 60, TimeUnit.SECONDS);
    }

    /**
     * Asserts that all shards with the same shardId should have document Ids.
     */
    public void assertSameDocIdsOnShards() throws Exception {
        assertBusy(() -&gt; {
            ClusterState state = client().admin().cluster().prepareState().get().getState();
            for (ObjectObjectCursor&lt;String, IndexRoutingTable&gt; indexRoutingTable : state.routingTable().indicesRouting()) {
                for (IntObjectCursor&lt;IndexShardRoutingTable&gt; indexShardRoutingTable : indexRoutingTable.value.shards()) {
                    ShardRouting primaryShardRouting = indexShardRoutingTable.value.primaryShard();
                    IndexShard primaryShard = getShardOrNull(state, primaryShardRouting);
                    if (primaryShard == null) {
                        continue;
                    }
                    final List&lt;DocIdSeqNoAndSource&gt; docsOnPrimary;
                    try {
                        docsOnPrimary = IndexShardTestCase.getDocIdAndSeqNos(primaryShard);
                    } catch (AlreadyClosedException ex) {
                        continue;
                    }
                    for (ShardRouting replicaShardRouting : indexShardRoutingTable.value.replicaShards()) {
                        IndexShard replicaShard = getShardOrNull(state, replicaShardRouting);
                        if (replicaShard == null) {
                            continue;
                        }
                        final List&lt;DocIdSeqNoAndSource&gt; docsOnReplica;
                        try {
                            docsOnReplica = IndexShardTestCase.getDocIdAndSeqNos(replicaShard);
                        } catch (AlreadyClosedException ex) {
                            continue;
                        }
                        assertThat("out of sync shards: primary=[" + primaryShardRouting + "] num_docs_on_primary=[" + docsOnPrimary.size()
                                + "] vs replica=[" + replicaShardRouting + "] num_docs_on_replica=[" + docsOnReplica.size() + "]",
                            docsOnReplica, equalTo(docsOnPrimary));
                    }
                }
            }
        });
    }

    private void randomlyResetClients() {
        assert Thread.holdsLock(this);
        // only reset the clients on nightly tests, it causes heavy load...
        if (RandomizedTest.isNightly() &amp;&amp; rarely(random)) {
            final Collection&lt;NodeAndClient&gt; nodesAndClients = nodes.values();
            for (NodeAndClient nodeAndClient : nodesAndClients) {
                nodeAndClient.resetClient();
            }
        }
    }

    public synchronized void wipePendingDataDirectories() {
        if (!dataDirToClean.isEmpty()) {
            try {
                for (Path path : dataDirToClean) {
                    try {
                        FileSystemUtils.deleteSubDirectories(path);
                        logger.info("Successfully wiped data directory for node location: {}", path);
                    } catch (IOException e) {
                        logger.info("Failed to wipe data directory for node location: {}", path);
                    }
                }
            } finally {
                dataDirToClean.clear();
            }
        }
    }

    /**
     * Returns a reference to a random node's {@link ClusterService}
     */
    public ClusterService clusterService() {
        return clusterService(null);
    }

    /**
     * Returns a reference to a node's {@link ClusterService}. If the given node is null, a random node will be selected.
     */
    public ClusterService clusterService(@Nullable String node) {
        return getInstance(ClusterService.class, node);
    }

    /**
     * Returns an Iterable to all instances for the given class &amp;gt;T&amp;lt; across all nodes in the cluster.
     */
    public &lt;T&gt; Iterable&lt;T&gt; getInstances(Class&lt;T&gt; clazz) {
        return nodes.values().stream().map(node -&gt; getInstanceFromNode(clazz, node.node)).collect(Collectors.toList());
    }

    /**
     * Returns an Iterable to all instances for the given class &amp;gt;T&amp;lt; across all data nodes in the cluster.
     */
    public &lt;T&gt; Iterable&lt;T&gt; getDataNodeInstances(Class&lt;T&gt; clazz) {
        return getInstances(clazz, DATA_NODE_PREDICATE);
    }

    public synchronized &lt;T&gt; T getCurrentMasterNodeInstance(Class&lt;T&gt; clazz) {
        return getInstance(clazz, new NodeNamePredicate(getMasterName()));
    }

    /**
     * Returns an Iterable to all instances for the given class &amp;gt;T&amp;lt; across all data and master nodes
     * in the cluster.
     */
    public &lt;T&gt; Iterable&lt;T&gt; getDataOrMasterNodeInstances(Class&lt;T&gt; clazz) {
        return getInstances(clazz, DATA_NODE_PREDICATE.or(MASTER_NODE_PREDICATE));
    }

    private &lt;T&gt; Iterable&lt;T&gt; getInstances(Class&lt;T&gt; clazz, Predicate&lt;NodeAndClient&gt; predicate) {
        Iterable&lt;NodeAndClient&gt; filteredNodes = nodes.values().stream().filter(predicate)::iterator;
        List&lt;T&gt; instances = new ArrayList&lt;&gt;();
        for (NodeAndClient nodeAndClient : filteredNodes) {
            instances.add(getInstanceFromNode(clazz, nodeAndClient.node));
        }
        return instances;
    }

    /**
     * Returns a reference to the given nodes instances of the given class &amp;gt;T&amp;lt;
     */
    public &lt;T&gt; T getInstance(Class&lt;T&gt; clazz, final String node) {
        return getInstance(clazz, nc -&gt; node == null || node.equals(nc.name));
    }

    public &lt;T&gt; T getDataNodeInstance(Class&lt;T&gt; clazz) {
        return getInstance(clazz, DATA_NODE_PREDICATE);
    }

    public &lt;T&gt; T getMasterNodeInstance(Class&lt;T&gt; clazz) {
        return getInstance(clazz, MASTER_NODE_PREDICATE);
    }

    private synchronized &lt;T&gt; T getInstance(Class&lt;T&gt; clazz, Predicate&lt;NodeAndClient&gt; predicate) {
        NodeAndClient randomNodeAndClient = getRandomNodeAndClient(predicate);
        assert randomNodeAndClient != null;
        return getInstanceFromNode(clazz, randomNodeAndClient.node);
    }

    /**
     * Returns a reference to a random nodes instances of the given class &amp;gt;T&amp;lt;
     */
    public &lt;T&gt; T getInstance(Class&lt;T&gt; clazz) {
        return getInstance(clazz, nc -&gt; true);
    }

    private static &lt;T&gt; T getInstanceFromNode(Class&lt;T&gt; clazz, Node node) {
        return node.injector().getInstance(clazz);
<a name="8"></a>    }

    public Settings dataPathSettings(String node) {
        return <font color="#c58917"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>nodes.values()
<a name="15"></a>            .stream()
            .filter(nc -&gt; nc.name.equals</b></font>(node))
            .findFirst().get().node().settings()
            .filter(key -&gt; <font color="#f52887"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>key.equals(Environment.PATH_DATA_SETTING.getKey()) ||  key.equals(Environment.PATH_SHARED_DATA_SETTING.getKey()));
    }


    @Override
    public int size() {</b></font>
        return nodes.size();
    }

    @Override
    public InetSocketAddress[] httpAddresses() {
        List&lt;InetSocketAddress&gt; addresses = new ArrayList&lt;&gt;();
        for (HttpServerTransport httpServerTransport : getInstances(HttpServerTransport.class)) {
            addresses.add(httpServerTransport.boundAddress().publishAddress().address());
        }
        return addresses.toArray(new InetSocketAddress[0]);
    }

    /**
     * Stops a random data node in the cluster. Returns true if a node was found to stop, false otherwise.
     */
    public synchronized boolean stopRandomDataNode() throws IOException {
        ensureOpen();
        NodeAndClient nodeAndClient = getRandomNodeAndClient(DATA_NODE_PREDICATE);
        if (nodeAndClient != null) {
            logger.info("Closing random node [{}] ", nodeAndClient.name);
            stopNodesAndClient(nodeAndClient);
            return true;
        }
        return false;
    }

    /**
     * Stops a random node in the cluster that applies to the given filter or non if the non of the nodes applies to the
     * filter.
     */
    public synchronized void stopRandomNode(final Predicate&lt;Settings&gt; filter) throws IOException {
        ensureOpen();
        NodeAndClient nodeAndClient = getRandomNodeAndClient(nc -&gt; filter.test(nc.node.settings()));
        if (nodeAndClient != null) {
            if (nodeAndClient.nodeAndClientId() &lt; sharedNodesSeeds.length &amp;&amp; nodeAndClient.isMasterEligible() &amp;&amp; autoManageMasterNodes
                &amp;&amp; nodes.values().stream()
                        .filter(NodeAndClient::isMasterEligible)
                        .filter(n -&gt; n.nodeAndClientId() &lt; sharedNodesSeeds.length)
                        .count() == 1) {
                throw new AssertionError("Tried to stop the only master eligible shared node");
            }
            logger.info("Closing filtered random node [{}] ", nodeAndClient.name);
            stopNodesAndClient(nodeAndClient);
        }
    }

    /**
     * Stops the current master node forcefully
     */
    public synchronized void stopCurrentMasterNode() throws IOException {
        ensureOpen();
        assert size() &gt; 0;
        String masterNodeName = getMasterName();
        final NodeAndClient masterNode = nodes.get(masterNodeName);
        assert masterNode != null;
        logger.info("Closing master node [{}] ", masterNodeName);
        stopNodesAndClient(masterNode);
    }

    /**
     * Stops any of the current nodes but not the master node.
     */
    public synchronized void stopRandomNonMasterNode() throws IOException {
        NodeAndClient nodeAndClient = getRandomNodeAndClient(new NodeNamePredicate(getMasterName()).negate());
        if (nodeAndClient != null) {
            logger.info("Closing random non master node [{}] current master [{}] ", nodeAndClient.name, getMasterName());
            stopNodesAndClient(nodeAndClient);
        }
    }

    private synchronized void startAndPublishNodesAndClients(List&lt;NodeAndClient&gt; nodeAndClients) {
        if (nodeAndClients.size() &gt; 0) {
            final int newMasters = (int) nodeAndClients.stream().filter(NodeAndClient::isMasterEligible)
                .filter(nac -&gt; nodes.containsKey(nac.name) == false) // filter out old masters
                .count();
            rebuildUnicastHostFiles(nodeAndClients); // ensure that new nodes can find the existing nodes when they start
            List&lt;Future&lt;?&gt;&gt; futures = nodeAndClients.stream().map(node -&gt; executor.submit(node::startNode)).collect(Collectors.toList());

            try {
                for (Future&lt;?&gt; future : futures) {
                    future.get();
                }
            } catch (InterruptedException e) {
                throw new AssertionError("interrupted while starting nodes", e);
            } catch (ExecutionException e) {
                RuntimeException re = FutureUtils.rethrowExecutionException(e);
                re.addSuppressed(new RuntimeException("failed to start nodes"));
                throw re;
            }
            nodeAndClients.forEach(this::publishNode);

            if (autoManageMasterNodes &amp;&amp; newMasters &gt; 0) {
                // update once masters have joined
                validateClusterFormed();
            }
        }
    }

    private final Object discoveryFileMutex = new Object();

    private void rebuildUnicastHostFiles(List&lt;NodeAndClient&gt; newNodes) {
        // cannot be a synchronized method since it's called on other threads from within synchronized startAndPublishNodesAndClients()
        synchronized (discoveryFileMutex) {
<a name="4"></a>            try {
                final Collection&lt;NodeAndClient&gt; currentNodes = nodes.values();
                Stream&lt;NodeAndClient&gt; unicastHosts = Stream.concat(currentNodes.stream(), newNodes.stream());
                List&lt;String&gt; discoveryFileContents = <font color="#6cc417"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>unicastHosts.map(
                    nac -&gt; nac.node.injector</b></font>().getInstance(TransportService.class)
                ).filter(Objects::nonNull)
                    .map(TransportService::getLocalNode).filter(Objects::nonNull).filter(DiscoveryNode::isMasterEligibleNode)
                    .map(n -&gt; n.getAddress().toString())
                    .distinct().collect(Collectors.toList());
                Set&lt;Path&gt; configPaths = Stream.concat(currentNodes.stream(), newNodes.stream())
                    .map(nac -&gt; nac.node.getEnvironment().configFile()).collect(Collectors.toSet());
                logger.debug("configuring discovery with {} at {}", discoveryFileContents, configPaths);
                for (final Path configPath : configPaths) {
                    Files.createDirectories(configPath);
                    Files.write(configPath.resolve(UNICAST_HOSTS_FILE), discoveryFileContents);
                }
            } catch (IOException e) {
                throw new AssertionError("failed to configure file-based discovery", e);
            }
        }
    }

    private void stopNodesAndClient(NodeAndClient nodeAndClient) throws IOException {
        stopNodesAndClients(Collections.singleton(nodeAndClient));
    }

    private synchronized void stopNodesAndClients(Collection&lt;NodeAndClient&gt; nodeAndClients) throws IOException {
        final Set&lt;String&gt; excludedNodeIds = excludeMasters(nodeAndClients);

        for (NodeAndClient nodeAndClient: nodeAndClients) {
            removeDisruptionSchemeFromNode(nodeAndClient);
            final NodeAndClient previous = removeNode(nodeAndClient);
            assert previous == nodeAndClient;
            nodeAndClient.close();
        }

        removeExclusions(excludedNodeIds);
    }

    /**
     * Restarts a random data node in the cluster
     */
    public void restartRandomDataNode() throws Exception {
        restartRandomDataNode(EMPTY_CALLBACK);
    }

    /**
     * Restarts a random data node in the cluster and calls the callback during restart.
     */
    public synchronized void restartRandomDataNode(RestartCallback callback) throws Exception {
        ensureOpen();
        NodeAndClient nodeAndClient = getRandomNodeAndClient(InternalTestCluster.DATA_NODE_PREDICATE);
        if (nodeAndClient != null) {
            restartNode(nodeAndClient, callback);
        }
    }

    /**
     * Restarts a node and calls the callback during restart.
     */
    public synchronized void restartNode(String nodeName, RestartCallback callback) throws Exception {
        ensureOpen();
        NodeAndClient nodeAndClient = nodes.get(nodeName);
        if (nodeAndClient != null) {
            restartNode(nodeAndClient, callback);
        }
    }

    public static final RestartCallback EMPTY_CALLBACK = new RestartCallback();

    /**
     * Restarts all nodes in the cluster. It first stops all nodes and then restarts all the nodes again.
     */
    public void fullRestart() throws Exception {
        fullRestart(EMPTY_CALLBACK);
    }

    /**
     * Restarts all nodes in a rolling restart fashion ie. only restarts on node a time.
     */
    public synchronized void rollingRestart(RestartCallback callback) throws Exception {
        int numNodesRestarted = 0;
        for (NodeAndClient nodeAndClient : nodes.values()) {
            callback.doAfterNodes(numNodesRestarted++, nodeAndClient.nodeClient());
            restartNode(nodeAndClient, callback);
        }
    }

    private void restartNode(NodeAndClient nodeAndClient, RestartCallback callback) throws Exception {
        assert Thread.holdsLock(this);
        logger.info("Restarting node [{}] ", nodeAndClient.name);

        if (activeDisruptionScheme != null) {
            activeDisruptionScheme.removeFromNode(nodeAndClient.name, this);
        }

        final Set&lt;String&gt; excludedNodeIds = excludeMasters(Collections.singleton(nodeAndClient));
        final Settings newSettings = nodeAndClient.closeForRestart(callback);
        removeExclusions(excludedNodeIds);

        nodeAndClient.recreateNode(newSettings, () -&gt; rebuildUnicastHostFiles(Collections.singletonList(nodeAndClient)));
        nodeAndClient.startNode();
        publishNode(nodeAndClient);

        if (callback.validateClusterForming() || excludedNodeIds.isEmpty() == false) {
            // we have to validate cluster size to ensure that the restarted node has rejoined the cluster if it was master-eligible;
            validateClusterFormed();
        }
    }

    private NodeAndClient removeNode(NodeAndClient nodeAndClient) {
        assert Thread.holdsLock(this);
        final NavigableMap&lt;String, NodeAndClient&gt; newNodes = new TreeMap&lt;&gt;(nodes);
        final NodeAndClient previous = newNodes.remove(nodeAndClient.name);
        nodes = Collections.unmodifiableNavigableMap(newNodes);
        return previous;
    }

    private Set&lt;String&gt; excludeMasters(Collection&lt;NodeAndClient&gt; nodeAndClients) {
        assert Thread.holdsLock(this);
        final Set&lt;String&gt; excludedNodeIds = new HashSet&lt;&gt;();
        if (autoManageMasterNodes &amp;&amp; nodeAndClients.size() &gt; 0) {

            final long currentMasters = nodes.values().stream().filter(NodeAndClient::isMasterEligible).count();
            final long stoppingMasters = nodeAndClients.stream().filter(NodeAndClient::isMasterEligible).count();

            assert stoppingMasters &lt;= currentMasters : currentMasters + " &lt; " + stoppingMasters;
            if (stoppingMasters != currentMasters &amp;&amp; stoppingMasters &gt; 0) {
                // If stopping few enough master-nodes that there's still a majority left, there is no need to withdraw their votes first.
                // However, we do not yet have a way to be sure there's a majority left, because the voting configuration may not yet have
                // been updated when the previous nodes shut down, so we must always explicitly withdraw votes.
                // TODO add cluster health API to check that voting configuration is optimal so this isn't always needed
                nodeAndClients.stream().filter(NodeAndClient::isMasterEligible).map(NodeAndClient::getName).forEach(excludedNodeIds::add);
                assert excludedNodeIds.size() == stoppingMasters;

                logger.info("adding voting config exclusions {} prior to restart/shutdown", excludedNodeIds);
                try {
                    client().execute(AddVotingConfigExclusionsAction.INSTANCE,
                            new AddVotingConfigExclusionsRequest(excludedNodeIds.toArray(Strings.EMPTY_ARRAY))).get();
                } catch (InterruptedException | ExecutionException e) {
                    throw new AssertionError("unexpected", e);
                }
            }
        }
        return excludedNodeIds;
    }

    private void removeExclusions(Set&lt;String&gt; excludedNodeIds) {
        assert Thread.holdsLock(this);
        if (excludedNodeIds.isEmpty() == false) {
            logger.info("removing voting config exclusions for {} after restart/shutdown", excludedNodeIds);
            try {
                Client client = getRandomNodeAndClient(node -&gt; excludedNodeIds.contains(node.name) == false).client();
                client.execute(ClearVotingConfigExclusionsAction.INSTANCE, new ClearVotingConfigExclusionsRequest()).get();
            } catch (InterruptedException | ExecutionException e) {
                throw new AssertionError("unexpected", e);
            }
        }
    }

    /**
     * Restarts all nodes in the cluster. It first stops all nodes and then restarts all the nodes again.
     */
    public synchronized void fullRestart(RestartCallback callback) throws Exception {
        int numNodesRestarted = 0;
        final Settings[] newNodeSettings = new Settings[nextNodeId.get()];
        final List&lt;NodeAndClient&gt; toStartAndPublish = new ArrayList&lt;&gt;(); // we want to start nodes in one go
        for (NodeAndClient nodeAndClient : nodes.values()) {
            callback.doAfterNodes(numNodesRestarted++, nodeAndClient.nodeClient());
            logger.info("Stopping and resetting node [{}] ", nodeAndClient.name);
            if (activeDisruptionScheme != null) {
                activeDisruptionScheme.removeFromNode(nodeAndClient.name, this);
            }
            final Settings newSettings = nodeAndClient.closeForRestart(callback);
            newNodeSettings[nodeAndClient.nodeAndClientId()] = newSettings;
            toStartAndPublish.add(nodeAndClient);
        }


        callback.onAllNodesStopped();

        // randomize start up order
        Randomness.shuffle(toStartAndPublish);

        for (NodeAndClient nodeAndClient : toStartAndPublish) {
            logger.info("recreating node [{}] ", nodeAndClient.name);
            nodeAndClient.recreateNode(newNodeSettings[nodeAndClient.nodeAndClientId()], () -&gt; rebuildUnicastHostFiles(toStartAndPublish));

        }
        startAndPublishNodesAndClients(toStartAndPublish);

        if (callback.validateClusterForming()) {
            validateClusterFormed();
        }
    }

    /**
     * Returns the name of the current master node in the cluster.
     */
    public String getMasterName() {
        return getMasterName(null);
    }

    /**
     * Returns the name of the current master node in the cluster and executes the request via the node specified
     * in the viaNode parameter. If viaNode isn't specified a random node will be picked to the send the request to.
     */
<a name="13"></a>    public String getMasterName(@Nullable String viaNode) {
        try {
            Client client = viaNode != null ? client(viaNode) : client();
            return <font color="#3b9c9c"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>client.admin().cluster().prepareState().get().getState().nodes().getMasterNode().getName();
        }</b></font> catch (Exception e) {
            logger.warn("Can't fetch cluster state", e);
            throw new RuntimeException("Can't get master node " + e.getMessage(), e);
        }
    }

    synchronized Set&lt;String&gt; allDataNodesButN(int count) {
        final int numNodes = numDataNodes() - count;
        assert size() &gt;= numNodes;
        Map&lt;String, NodeAndClient&gt; dataNodes =
            nodes
                .entrySet()
                .stream()
                .filter(entry -&gt; DATA_NODE_PREDICATE.test(entry.getValue()))
                .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
        final HashSet&lt;String&gt; set = new HashSet&lt;&gt;();
        final Iterator&lt;String&gt; iterator = dataNodes.keySet().iterator();
        for (int i = 0; i &lt; numNodes; i++) {
            assert iterator.hasNext();
            set.add(iterator.next());
        }
        return set;
    }

    /**
     * Returns a set of nodes that have at least one shard of the given index.
     */
    public synchronized Set&lt;String&gt; nodesInclude(String index) {
        if (clusterService().state().routingTable().hasIndex(index)) {
            List&lt;ShardRouting&gt; allShards = clusterService().state().routingTable().allShards(index);
            DiscoveryNodes discoveryNodes = clusterService().state().getNodes();
            Set&lt;String&gt; nodes = new HashSet&lt;&gt;();
            for (ShardRouting shardRouting : allShards) {
                if (shardRouting.assignedToNode()) {
                    DiscoveryNode discoveryNode = discoveryNodes.get(shardRouting.currentNodeId());
                    nodes.add(discoveryNode.getName());
                }
            }
            return nodes;
        }
        return Collections.emptySet();
    }

    /**
     * Performs cluster bootstrap when node with index {@link #bootstrapMasterNodeIndex} is started
     * with the names of all existing and new master-eligible nodes.
     * Indexing starts from 0.
     * If {@link #bootstrapMasterNodeIndex} is -1 (default), this method does nothing.
     */
    private List&lt;Settings&gt; bootstrapMasterNodeWithSpecifiedIndex(List&lt;Settings&gt; allNodesSettings) {
        assert Thread.holdsLock(this);
        if (bootstrapMasterNodeIndex == -1) { // fast-path
            return allNodesSettings;
        }

        int currentNodeId = numMasterNodes() - 1;
        List&lt;Settings&gt; newSettings = new ArrayList&lt;&gt;();

        for (Settings settings : allNodesSettings) {
            if (Node.NODE_MASTER_SETTING.get(settings) == false) {
                newSettings.add(settings);
            } else {
                currentNodeId++;
                if (currentNodeId != bootstrapMasterNodeIndex) {
                    newSettings.add(settings);
                } else {
                    List&lt;String&gt; nodeNames = new ArrayList&lt;&gt;();

                    for (Settings nodeSettings : getDataOrMasterNodeInstances(Settings.class)) {
                        if (Node.NODE_MASTER_SETTING.get(nodeSettings)) {
                            nodeNames.add(Node.NODE_NAME_SETTING.get(nodeSettings));
                        }
                    }

                    for (Settings nodeSettings : allNodesSettings) {
                        if (Node.NODE_MASTER_SETTING.get(nodeSettings)) {
                            nodeNames.add(Node.NODE_NAME_SETTING.get(nodeSettings));
                        }
                    }

                    newSettings.add(Settings.builder().put(settings)
                            .putList(ClusterBootstrapService.INITIAL_MASTER_NODES_SETTING.getKey(), nodeNames)
                            .build());

                    setBootstrapMasterNodeIndex(-1);
                }
            }
        }

        return newSettings;
    }

    /**
     * Starts a node with default settings and returns its name.
     */
    public String startNode() {
        return startNode(Settings.EMPTY);
    }

    /**
     * Starts a node with the given settings builder and returns its name.
     */
    public String startNode(Settings.Builder settings) {
        return startNode(settings.build());
    }

    /**
     * Starts a node with the given settings and returns its name.
     */
    public String startNode(Settings settings) {
        return startNodes(settings).get(0);
    }

    /**
     * Starts multiple nodes with default settings and returns their names
     */
    public List&lt;String&gt; startNodes(int numOfNodes) {
        return startNodes(numOfNodes, Settings.EMPTY);
    }

    /**
     * Starts multiple nodes with the given settings and returns their names
     */
    public List&lt;String&gt; startNodes(int numOfNodes, Settings settings) {
        return startNodes(Collections.nCopies(numOfNodes, settings).toArray(new Settings[0]));
    }

    /**
     * Starts multiple nodes with the given settings and returns their names
     */
    public synchronized List&lt;String&gt; startNodes(Settings... extraSettings) {
        final int newMasterCount = Math.toIntExact(Stream.of(extraSettings).filter(Node.NODE_MASTER_SETTING::get).count());
        final List&lt;NodeAndClient&gt; nodes = new ArrayList&lt;&gt;();
        final int prevMasterCount = getMasterNodesCount();
        int autoBootstrapMasterNodeIndex = autoManageMasterNodes &amp;&amp; prevMasterCount == 0 &amp;&amp; newMasterCount &gt; 0
            &amp;&amp; Arrays.stream(extraSettings)
                    .allMatch(s -&gt; Node.NODE_MASTER_SETTING.get(s) == false || ZEN2_DISCOVERY_TYPE.equals(DISCOVERY_TYPE_SETTING.get(s)))
            ? RandomNumbers.randomIntBetween(random, 0, newMasterCount - 1) : -1;

        final int numOfNodes = extraSettings.length;
        final int firstNodeId = nextNodeId.getAndIncrement();
        final List&lt;Settings&gt; settings = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; numOfNodes; i++) {
            settings.add(getNodeSettings(firstNodeId + i, random.nextLong(), extraSettings[i]));
        }
        nextNodeId.set(firstNodeId + numOfNodes);

        final List&lt;String&gt; initialMasterNodes = settings.stream()
                .filter(Node.NODE_MASTER_SETTING::get)
                .map(Node.NODE_NAME_SETTING::get)
                .collect(Collectors.toList());

        final List&lt;Settings&gt; updatedSettings = bootstrapMasterNodeWithSpecifiedIndex(settings);

        for (int i = 0; i &lt; numOfNodes; i++) {
            final Settings nodeSettings = updatedSettings.get(i);
            final Builder builder = Settings.builder();
            if (Node.NODE_MASTER_SETTING.get(nodeSettings)) {
                if (autoBootstrapMasterNodeIndex == 0) {
                    builder.putList(INITIAL_MASTER_NODES_SETTING.getKey(), initialMasterNodes);
                }
                autoBootstrapMasterNodeIndex -= 1;
            }

            final NodeAndClient nodeAndClient =
                    buildNode(firstNodeId + i, builder.put(nodeSettings).build(), false, () -&gt; rebuildUnicastHostFiles(nodes));
            nodes.add(nodeAndClient);
        }
        startAndPublishNodesAndClients(nodes);
        if (autoManageMasterNodes) {
            validateClusterFormed();
        }
        return nodes.stream().map(NodeAndClient::getName).collect(Collectors.toList());
    }

    public List&lt;String&gt; startMasterOnlyNodes(int numNodes) {
        return startMasterOnlyNodes(numNodes, Settings.EMPTY);
    }

    public List&lt;String&gt; startMasterOnlyNodes(int numNodes, Settings settings) {
        Settings settings1 = Settings.builder()
                .put(settings)
                .put(Node.NODE_MASTER_SETTING.getKey(), true)
                .put(Node.NODE_DATA_SETTING.getKey(), false)
                .build();
        return startNodes(numNodes, settings1);
    }

    public List&lt;String&gt; startDataOnlyNodes(int numNodes) {
        return startDataOnlyNodes(numNodes, Settings.EMPTY);
<a name="5"></a>    }

    public List&lt;String&gt; startDataOnlyNodes(int numNodes, Settings settings) {
        return <font color="#151b8d"><div style="position:absolute;left:0"><a href="#"><img align="left" alt="other" border="0" src="back.gif"/></a></div><b>startNodes(
            numNodes,
            Settings.builder().put(settings).put(Node.NODE_MASTER_SETTING.getKey(), false)
                .put(Node.NODE_DATA_SETTING.getKey(), true).build());
    }

    private int getMast</b></font>erNodesCount() {
        return (int) nodes.values().stream().filter(n -&gt; Node.NODE_MASTER_SETTING.get(n.node().settings())).count();
    }

    public String startMasterOnlyNode() {
        return startMasterOnlyNode(Settings.EMPTY);
    }

    public String startMasterOnlyNode(Settings settings) {
        Settings settings1 = Settings.builder()
                .put(settings)
                .put(Node.NODE_MASTER_SETTING.getKey(), true)
                .put(Node.NODE_DATA_SETTING.getKey(), false)
                .build();
        return startNode(settings1);
    }

    public String startDataOnlyNode() {
        return startDataOnlyNode(Settings.EMPTY);
    }

    public String startDataOnlyNode(Settings settings) {
        Settings settings1 = Settings.builder()
                .put(settings)
                .put(Node.NODE_MASTER_SETTING.getKey(), false)
                .put(Node.NODE_DATA_SETTING.getKey(), true)
                .build();
        return startNode(settings1);
    }

    private synchronized void publishNode(NodeAndClient nodeAndClient) {
        assert !nodeAndClient.node().isClosed();
        final NavigableMap&lt;String, NodeAndClient&gt; newNodes = new TreeMap&lt;&gt;(nodes);
        newNodes.put(nodeAndClient.name, nodeAndClient);
        nodes = Collections.unmodifiableNavigableMap(newNodes);
        applyDisruptionSchemeToNode(nodeAndClient);
    }

    public void closeNonSharedNodes(boolean wipeData) throws IOException {
        reset(wipeData);
    }

    @Override
    public int numDataNodes() {
        return dataNodeAndClients().size();
    }

    @Override
    public int numDataAndMasterNodes() {
        return filterNodes(nodes, DATA_NODE_PREDICATE.or(MASTER_NODE_PREDICATE)).size();
    }

    public int numMasterNodes() {
      return filterNodes(nodes, NodeAndClient::isMasterEligible).size();
    }

    public void setDisruptionScheme(ServiceDisruptionScheme scheme) {
        assert activeDisruptionScheme == null :
            "there is already and active disruption [" + activeDisruptionScheme + "]. call clearDisruptionScheme first";
        scheme.applyToCluster(this);
        activeDisruptionScheme = scheme;
    }

    public void clearDisruptionScheme() {
        clearDisruptionScheme(true);
    }

    // synchronized to prevent concurrently modifying the cluster.
    public synchronized void clearDisruptionScheme(boolean ensureHealthyCluster) {
        if (activeDisruptionScheme != null) {
            TimeValue expectedHealingTime = activeDisruptionScheme.expectedTimeToHeal();
            logger.info("Clearing active scheme {}, expected healing time {}", activeDisruptionScheme, expectedHealingTime);
            if (ensureHealthyCluster) {
                activeDisruptionScheme.removeAndEnsureHealthy(this);
            } else {
                activeDisruptionScheme.removeFromCluster(this);
            }
        }
        activeDisruptionScheme = null;
    }

    private void applyDisruptionSchemeToNode(NodeAndClient nodeAndClient) {
        if (activeDisruptionScheme != null) {
            assert nodes.containsKey(nodeAndClient.name);
            activeDisruptionScheme.applyToNode(nodeAndClient.name, this);
        }
    }

    private void removeDisruptionSchemeFromNode(NodeAndClient nodeAndClient) {
        if (activeDisruptionScheme != null) {
            assert nodes.containsKey(nodeAndClient.name);
            activeDisruptionScheme.removeFromNode(nodeAndClient.name, this);
        }
    }

    private Collection&lt;NodeAndClient&gt; dataNodeAndClients() {
        return filterNodes(nodes, DATA_NODE_PREDICATE);
    }

    private static Collection&lt;NodeAndClient&gt; filterNodes(Map&lt;String, InternalTestCluster.NodeAndClient&gt; map,
            Predicate&lt;NodeAndClient&gt; predicate) {
        return map
            .values()
            .stream()
            .filter(predicate)
            .collect(Collectors.toCollection(ArrayList::new));
    }

    private static final class NodeNamePredicate implements Predicate&lt;NodeAndClient&gt; {
        private final String nodeName;

        NodeNamePredicate(String nodeName) {
            this.nodeName = nodeName;
        }

        @Override
        public boolean test(NodeAndClient nodeAndClient) {
            return nodeName.equals(nodeAndClient.getName());
        }
    }

    synchronized String routingKeyForShard(Index index, int shard, Random random) {
        assertThat(shard, greaterThanOrEqualTo(0));
        assertThat(shard, greaterThanOrEqualTo(0));
        for (NodeAndClient n : nodes.values()) {
            Node node = n.node;
            IndicesService indicesService = getInstanceFromNode(IndicesService.class, node);
            ClusterService clusterService = getInstanceFromNode(ClusterService.class, node);
            IndexService indexService = indicesService.indexService(index);
            if (indexService != null) {
                assertThat(indexService.getIndexSettings().getSettings().getAsInt(IndexMetadata.SETTING_NUMBER_OF_SHARDS, -1),
                        greaterThan(shard));
                OperationRouting operationRouting = clusterService.operationRouting();
                while (true) {
                    String routing = RandomStrings.randomAsciiLettersOfLength(random, 10);
                    final int targetShard = operationRouting
                            .indexShards(clusterService.state(), index.getName(), null, routing)
                            .shardId().getId();
                    if (shard == targetShard) {
                        return routing;
                    }
                }
            }
        }
        fail("Could not find a node that holds " + index);
        return null;
    }

    @Override
    public Iterable&lt;Client&gt; getClients() {
        return () -&gt; {
            ensureOpen();
            final Iterator&lt;NodeAndClient&gt; iterator = nodes.values().iterator();
            return new Iterator&lt;Client&gt;() {

                @Override
                public boolean hasNext() {
                    return iterator.hasNext();
                }

                @Override
                public Client next() {
                    return iterator.next().client();
                }

                @Override
                public void remove() {
                    throw new UnsupportedOperationException("");
                }

            };
        };
    }

    @Override
    public NamedWriteableRegistry getNamedWriteableRegistry() {
        return getInstance(NamedWriteableRegistry.class);
    }

    /**
     * Returns a predicate that only accepts settings of nodes with one of the given names.
     */
    public static Predicate&lt;Settings&gt; nameFilter(String... nodeNames) {
        final Set&lt;String&gt; nodes = Set.of(nodeNames);
        return settings -&gt; nodes.contains(settings.get("node.name"));
    }

    /**
     * An abstract class that is called during {@link #rollingRestart(InternalTestCluster.RestartCallback)}
     * and / or {@link #fullRestart(InternalTestCluster.RestartCallback)} to execute actions at certain
     * stages of the restart.
     */
    public static class RestartCallback {

        /**
         * Executed once the give node name has been stopped.
         */
        public Settings onNodeStopped(String nodeName) throws Exception {
            return Settings.EMPTY;
        }

        /**
         * Executed for each node before the {@code n + 1} node is restarted. The given client is
         * an active client to the node that will be restarted next.
         */
        public void doAfterNodes(int n, Client client) throws Exception {
        }

        public void onAllNodesStopped() throws Exception {
        }

        /**
         * If this returns &lt;code&gt;true&lt;/code&gt; all data for the node with the given node name will be cleared including
         * gateways and all index data. Returns &lt;code&gt;false&lt;/code&gt; by default.
         */
        public boolean clearData(String nodeName) {
            return false;
        }

        /** returns true if the restart should also validate the cluster has reformed */
        public boolean validateClusterForming() { return true; }
    }

    public Settings getDefaultSettings() {
        return defaultSettings;
    }

    @Override
    public void ensureEstimatedStats() {
        // Checks that the breakers have been reset without incurring a
        // network request, because a network request can increment one
        // of the breakers
        for (NodeAndClient nodeAndClient : nodes.values()) {
            final String name = nodeAndClient.name;
            final CircuitBreakerService breakerService = getInstanceFromNode(CircuitBreakerService.class, nodeAndClient.node);
            try {
                assertBusy(() -&gt; {
                    CircuitBreaker acctBreaker = breakerService.getBreaker(CircuitBreaker.ACCOUNTING);
                    assertThat("Accounting breaker not reset to 0 on node: " + name + ", are there still Lucene indices around?",
                        acctBreaker.getUsed(), equalTo(0L));
                });
            } catch (Exception e) {
                throw new AssertionError("Exception during check for accounting breaker reset to 0", e);
            }
            // Anything that uses transport or HTTP can increase the
            // request breaker (because they use bigarrays), because of
            // that the breaker can sometimes be incremented from ping
            // requests from other clusters because Jenkins is running
            // multiple ES testing jobs in parallel on the same machine.
            // To combat this we check whether the breaker has reached 0
            // in an assertBusy loop, so it will try for 10 seconds and
            // fail if it never reached 0
            try {
                assertBusy(() -&gt; {
                    CircuitBreaker reqBreaker = breakerService.getBreaker(CircuitBreaker.REQUEST);
                    assertThat("Request breaker not reset to 0 on node: " + name, reqBreaker.getUsed(), equalTo(0L));
                });
            } catch (Exception e) {
                throw new AssertionError("Exception during check for request breaker reset to 0", e);
            }

            // RamAccounting release operations can run asynchronous after clients already received results.
            try {
                assertBusy(() -&gt; {
                    CircuitBreaker crateQueryBreaker = breakerService.getBreaker("query");
                    if (crateQueryBreaker != null) {
                        assertThat("Query breaker not reset to 0 on node: " + name,
                                    crateQueryBreaker.getUsed(),
                                    equalTo(0L));
                    }
                });
            } catch (Exception e) {
                throw new AssertionError("Exception during check for query breaker reset to 0", e);
            }
        }
    }

    @Override
    public synchronized void assertAfterTest() throws IOException {
        super.assertAfterTest();
        assertRequestsFinished();
        for (NodeAndClient nodeAndClient : nodes.values()) {
            NodeEnvironment env = nodeAndClient.node().getNodeEnvironment();
            Set&lt;ShardId&gt; shardIds = env.lockedShards();
            for (ShardId id : shardIds) {
                try {
                    env.shardLock(id, "InternalTestCluster assert after test", TimeUnit.SECONDS.toMillis(5)).close();
                } catch (ShardLockObtainFailedException ex) {
                    throw new AssertionError("Shard " + id + " is still locked after 5 sec waiting", ex);
                }
            }
        }
    }

    private void assertRequestsFinished() {
        assert Thread.holdsLock(this);
        for (NodeAndClient nodeAndClient : nodes.values()) {
            CircuitBreaker inFlightRequestsBreaker = getInstance(CircuitBreakerService.class, nodeAndClient.name)
                .getBreaker(CircuitBreaker.IN_FLIGHT_REQUESTS);
            try {
                // see #ensureEstimatedStats()
                assertBusy(() -&gt; {
                    // ensure that our size accounting on transport level is reset properly
                    long bytesUsed = inFlightRequestsBreaker.getUsed();
                    assertThat("All incoming requests on node [" + nodeAndClient.name + "] should have finished. Expected 0 but got " +
                        bytesUsed, bytesUsed, equalTo(0L));
                });
            } catch (Exception e) {
                logger.error("Could not assert finished requests within timeout", e);
                fail("Could not assert finished requests within timeout on node [" + nodeAndClient.name + "]");
            }
        }
    }

    public int numNodes() {
        return nodes.size();
    }
}
</pre>
</div>
</div>
<div class="modal" id="myModal" style="display:none;"><div class="modal-content"><span class="close">x</span><p></p><div class="row"><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 1</div><div class="column" style="font-weight: bold;text-decoration: underline">Fragment from File 2</div></div><div class="row"><div class="column" id="column1">Column 1</div><div class="column" id="column2">Column 2</div></div></div></div><script>var modal=document.getElementById("myModal"),span=document.getElementsByClassName("close")[0];span.onclick=function(){modal.style.display="none"};window.onclick=function(a){a.target==modal&&(modal.style.display="none")};function openModal(a){console.log("the color is "+a);let b=getCodes(a);console.log(b);var c=document.getElementById("column1");c.innerText=b[0];var d=document.getElementById("column2");d.innerText=b[1];c.style.color=a;c.style.fontWeight="bold";d.style.fontWeight="bold";d.style.color=a;var e=document.getElementById("myModal");e.style.display="block"}function getCodes(a){for(var b=document.getElementsByTagName("font"),c=[],d=0;d<b.length;d++)b[d].attributes.color.nodeValue===a&&"-"!==b[d].innerText&&c.push(b[d].innerText);return c}</script><script>const params=window.location.search;const urlParams=new URLSearchParams(params);const searchText=urlParams.get('lines');let lines=searchText.split(',');for(let line of lines){const elements=document.getElementsByTagName('td');for(let i=0;i<elements.length;i++){if(elements[i].innerText.includes(line)){elements[i].style.background='green';break;}}}</script></body>
</html>
