<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for SingleRowSubselectAnalyzerTest.java & SelectPlannerTest.java</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for SingleRowSubselectAnalyzerTest.java & SelectPlannerTest.java
      </h3>
      <h1 align="center">
        9.5%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>SingleRowSubselectAnalyzerTest.java (76.42857%)<TH>SelectPlannerTest.java (5.092813%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match2358194-0.html#0',2,'match2358194-1.html#0',3)" NAME="0">(96-109)<TD><A HREF="javascript:ZweiFrames('match2358194-0.html#0',2,'match2358194-1.html#0',3)" NAME="0">(530-541)</A><TD ALIGN=center><FONT COLOR="#ff0000">27</FONT>
<TR><TD BGCOLOR="#f63526"><FONT COLOR="#f63526">-</FONT><TD><A HREF="javascript:ZweiFrames('match2358194-0.html#1',2,'match2358194-1.html#1',3)" NAME="1">(76-91)<TD><A HREF="javascript:ZweiFrames('match2358194-0.html#1',2,'match2358194-1.html#1',3)" NAME="1">(1350-1376)</A><TD ALIGN=center><FONT COLOR="#ff0000">27</FONT>
<TR><TD BGCOLOR="#980517"><FONT COLOR="#980517">-</FONT><TD><A HREF="javascript:ZweiFrames('match2358194-0.html#2',2,'match2358194-1.html#2',3)" NAME="2">(22-42)<TD><A HREF="javascript:ZweiFrames('match2358194-0.html#2',2,'match2358194-1.html#2',3)" NAME="2">(22-41)</A><TD ALIGN=center><FONT COLOR="#aa0000">18</FONT>
<TR><TD BGCOLOR="#53858b"><FONT COLOR="#53858b">-</FONT><TD><A HREF="javascript:ZweiFrames('match2358194-0.html#3',2,'match2358194-1.html#3',3)" NAME="3">(55-65)<TD><A HREF="javascript:ZweiFrames('match2358194-0.html#3',2,'match2358194-1.html#3',3)" NAME="3">(221-229)</A><TD ALIGN=center><FONT COLOR="#8d0000">15</FONT>
<TR><TD BGCOLOR="#6cc417"><FONT COLOR="#6cc417">-</FONT><TD><A HREF="javascript:ZweiFrames('match2358194-0.html#4',2,'match2358194-1.html#4',3)" NAME="4">(110-116)<TD><A HREF="javascript:ZweiFrames('match2358194-0.html#4',2,'match2358194-1.html#4',3)" NAME="4">(119-123)</A><TD ALIGN=center><FONT COLOR="#5e0000">10</FONT>
<TR><TD BGCOLOR="#151b8d"><FONT COLOR="#151b8d">-</FONT><TD><A HREF="javascript:ZweiFrames('match2358194-0.html#5',2,'match2358194-1.html#5',3)" NAME="5">(66-71)<TD><A HREF="javascript:ZweiFrames('match2358194-0.html#5',2,'match2358194-1.html#5',3)" NAME="5">(108-112)</A><TD ALIGN=center><FONT COLOR="#5e0000">10</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>SingleRowSubselectAnalyzerTest.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Crate.io GmbH (&quot;Crate&quot;) under one or more contributor
 * license agreements.  See the NOTICE file distributed with this work for
 * additional information regarding copyright ownership.  Crate licenses
 * this file to you under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.  You may
 * obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
 * License for the specific language governing permissions and limitations
 * under the License.
 *
 * However, if you have executed another commercial license agreement
 * with Crate these terms will supersede the license and you may use the
<A NAME="2"></A> * software solely pursuant to the terms of the relevant commercial agreement.
 */

<FONT color="#980517"><A HREF="javascript:ZweiFrames('match2358194-1.html#2',3,'match2358194-top.html#2',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>package io.crate.analyze;

import io.crate.analyze.relations.AnalyzedRelation;
import io.crate.expression.operator.EqOperator;
import io.crate.expression.symbol.MatchPredicate;
import io.crate.expression.symbol.SelectSymbol;
import io.crate.test.integration.CrateDummyClusterServiceUnitTest;
import io.crate.testing.SQLExecutor;
import org.hamcrest.Matchers;
import org.junit.Before;
import org.junit.Test;

import java.io.IOException;

import static io.crate.testing.SymbolMatchers.isFunction;
import static io.crate.testing.SymbolMatchers.isLiteral;
import static io.crate.testing.SymbolMatchers.isReference;
import static io.crate.testing.TestingHelpers.isSQL;
import static org.hamcrest.Matchers.hasEntry;
import static org.hamcrest.Matchers.instanceOf;
import</B></FONT> static org.hamcrest.Matchers.is;

public class SingleRowSubselectAnalyzerTest extends CrateDummyClusterServiceUnitTest {

    private SQLExecutor e;

    @Before
    public void prepare() throws IOException {
        e = SQLExecutor.builder(clusterService).enableDefaultTables().build();
    }
<A NAME="3"></A>
    @Test
    public void testSingleRowSubselectInWhereClause() throws Exception {
        <FONT color="#53858b"><A HREF="javascript:ZweiFrames('match2358194-1.html#3',3,'match2358194-top.html#3',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>QueriedSelectRelation relation = e.analyze(&quot;select * from t1 where x = (select y from t2)&quot;);
        assertThat(relation.where(),
            isSQL(&quot;(doc.t1.x = (SELECT y FROM (doc.t2)))&quot;));
    }

    @Test
    public void testSingleRowSubselectInWhereClauseNested() throws Exception {
        QueriedSelectRelation relation = e.analyze(
<A NAME="5"></A>            &quot;select a from t1 where x = (select y from t2 where y = (select z from t3))&quot;);
        assertThat(relation.where(),
            isSQL</B></FONT>(&quot;(doc.t1.x = (SELECT y FROM (doc.t2)))&quot;));
    <FONT color="#151b8d"><A HREF="javascript:ZweiFrames('match2358194-1.html#5',3,'match2358194-top.html#5',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>}

    @Test
    public void testSingleRowSubselectInSelectList() {
        AnalyzedRelation relation = e.analyze(&quot;select (select b from t2 limit 1) from t1&quot;);
        assertThat(relation.outputs(), isSQL</B></FONT>(&quot;(SELECT b FROM (doc.t2))&quot;));
    }
<A NAME="1"></A>
    @Test
    public void testSubselectWithMultipleColumns() throws Exception {
        <FONT color="#f63526"><A HREF="javascript:ZweiFrames('match2358194-1.html#1',3,'match2358194-top.html#1',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>expectedException.expectMessage(&quot;Subqueries with more than 1 column are not supported.&quot;);
        e.analyze(&quot;select (select b, b from t2 limit 1) from t1&quot;);
    }

    @Test
    public void testSingleRowSubselectInAssignmentOfUpdate() throws Exception {
        AnalyzedUpdateStatement stmt = e.analyze(&quot;update t1 set x = (select y from t2)&quot;);
        assertThat(
            stmt.assignmentByTargetCol().values().iterator().next(),
            Matchers.instanceOf(SelectSymbol.class));
    }

    @Test
    public void testSingleRowSubselectInWhereClauseOfDelete() throws Exception {
        AnalyzedDeleteStatement delete = e.analyze(&quot;delete from t1 where x = (select y from t2)&quot;);
        assertThat(delete.query(), isFunction(EqOperator.NAME, isReference(&quot;x&quot;), instanceOf</B></FONT>(SelectSymbol.class)));
    }
<A NAME="0"></A>
    @Test
    public void testMatchPredicateWithSingleRowSubselect() throws Exception {
        QueriedSelectRelation relation = <FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match2358194-1.html#0',3,'match2358194-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>e.analyze(
            &quot;select * from users where match(shape 1.2, (select shape from users limit 1))&quot;);
        assertThat(relation.where(), instanceOf(MatchPredicate.class));
        MatchPredicate match = (MatchPredicate) relation.where();
        assertThat(match.identBoostMap(), hasEntry(isReference(&quot;shape&quot;), isLiteral(1.2)));
        assertThat(match.queryTerm(), instanceOf(SelectSymbol.class));
        assertThat(match.matchType(), is(&quot;intersects&quot;));
    }

    @Test
    public void testLikeSupportsSubQueries() {
<A NAME="4"></A>        QueriedSelectRelation relation = e.analyze(&quot;select * from users where name like (select 'foo')&quot;);
        assertThat(relation.where(),
            isSQL</B></FONT>(&quot;(doc.users.name LIKE (SELECT 'foo' FROM (empty_row)))&quot;));
    <FONT color="#6cc417"><A HREF="javascript:ZweiFrames('match2358194-1.html#4',3,'match2358194-top.html#4',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>}

    @Test
    public void testAnySupportsSubQueries() {
        QueriedSelectRelation relation = e.analyze(&quot;select * from users where (select 'bar') = ANY (tags)&quot;);
        assertThat(relation.where(),
            isSQL</B></FONT>(&quot;((SELECT 'bar' FROM (empty_row)) = ANY(doc.users.tags))&quot;));

        relation = e.analyze(&quot;select * from users where 'bar' = ANY (select 'bar')&quot;);
        assertThat(relation.where(),
            isSQL(&quot;('bar' = ANY((SELECT 'bar' FROM (empty_row))))&quot;));
    }
}
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>SelectPlannerTest.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Crate.io GmbH (&quot;Crate&quot;) under one or more contributor
 * license agreements.  See the NOTICE file distributed with this work for
 * additional information regarding copyright ownership.  Crate licenses
 * this file to you under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.  You may
 * obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
 * License for the specific language governing permissions and limitations
 * under the License.
 *
 * However, if you have executed another commercial license agreement
 * with Crate these terms will supersede the license and you may use the
<A NAME="2"></A> * software solely pursuant to the terms of the relevant commercial agreement.
 */

<FONT color="#980517"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2358194-0.html#2',2,'match2358194-top.html#2',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>package io.crate.planner;

import static io.crate.planner.operators.LogicalPlannerTest.isPlan;
import static io.crate.testing.Asserts.assertThrowsMatches;
import static io.crate.testing.SymbolMatchers.isFunction;
import static io.crate.testing.SymbolMatchers.isLiteral;
import static io.crate.testing.SymbolMatchers.isReference;
import static io.crate.testing.TestingHelpers.isSQL;
import static java.util.Collections.singletonList;
import static org.hamcrest.Matchers.contains;
import static org.hamcrest.Matchers.equalTo;
import static org.hamcrest.Matchers.instanceOf;
import static org.hamcrest.Matchers.is;
import static org.hamcrest.Matchers.not;
import static org.hamcrest.Matchers.notNullValue;
import static org.hamcrest.Matchers.nullValue;

import java.util.Arrays;
import java.util.HashSet;
import</B></FONT> java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.UUID;
import java.util.stream.Collectors;

import com.carrotsearch.hppc.IntIndexedContainer;
import com.carrotsearch.randomizedtesting.RandomizedTest;

import org.hamcrest.Matchers;
import org.junit.Test;

import io.crate.analyze.TableDefinitions;
import io.crate.data.RowN;
import io.crate.exceptions.UnsupportedFeatureException;
import io.crate.exceptions.VersioningValidationException;
import io.crate.execution.dsl.phases.ExecutionPhase;
import io.crate.execution.dsl.phases.MergePhase;
import io.crate.execution.dsl.phases.NodeOperation;
import io.crate.execution.dsl.phases.NodeOperationTree;
import io.crate.execution.dsl.phases.PKLookupPhase;
import io.crate.execution.dsl.phases.RoutedCollectPhase;
import io.crate.execution.dsl.projection.AggregationProjection;
import io.crate.execution.dsl.projection.EvalProjection;
import io.crate.execution.dsl.projection.FilterProjection;
import io.crate.execution.dsl.projection.GroupProjection;
import io.crate.execution.dsl.projection.MergeCountProjection;
import io.crate.execution.dsl.projection.OrderedTopNProjection;
import io.crate.execution.dsl.projection.Projection;
import io.crate.execution.dsl.projection.TopNDistinctProjection;
import io.crate.execution.dsl.projection.TopNProjection;
import io.crate.execution.dsl.projection.WindowAggProjection;
import io.crate.execution.engine.NodeOperationTreeGenerator;
import io.crate.execution.engine.aggregation.impl.CountAggregation;
import io.crate.expression.symbol.AggregateMode;
import io.crate.expression.symbol.Aggregation;
import io.crate.expression.symbol.Function;
import io.crate.expression.symbol.InputColumn;
import io.crate.expression.symbol.Literal;
import io.crate.expression.symbol.Symbol;
import io.crate.expression.symbol.SymbolType;
import io.crate.metadata.PartitionName;
import io.crate.metadata.Reference;
import io.crate.metadata.RelationName;
import io.crate.metadata.Routing;
import io.crate.metadata.RowGranularity;
import io.crate.planner.node.dql.Collect;
import io.crate.planner.node.dql.CountPlan;
import io.crate.planner.node.dql.QueryThenFetch;
import io.crate.planner.node.dql.join.Join;
import io.crate.planner.node.dql.join.JoinType;
import io.crate.planner.operators.LogicalPlan;
import io.crate.statistics.Stats;
import io.crate.statistics.TableStats;
import io.crate.test.integration.CrateDummyClusterServiceUnitTest;
import io.crate.testing.SQLExecutor;
import io.crate.testing.T3;
import io.crate.testing.TestingHelpers;
import io.crate.types.DataTypes;

public class SelectPlannerTest extends CrateDummyClusterServiceUnitTest {

    @Test
    public void testHandlerSideRouting() throws Exception {
<A NAME="5"></A>        SQLExecutor e = SQLExecutor.builder(clusterService).build();
        // just testing the dispatching here.. making sure it is not a ESSearchNode
        e.plan(&quot;select * from sys.cluster&quot;);
    <FONT color="#151b8d"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2358194-0.html#5',2,'match2358194-top.html#5',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>}

    @Test
    public void testWherePKAndMatchDoesNotResultInESGet() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom</B></FONT>(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

<A NAME="4"></A>        ExecutionPlan plan = e.plan(&quot;select * from users where id in (1, 2, 3) and match(text, 'Hello')&quot;);
        assertThat(plan, instanceOf(Merge.class));
        assertThat(((Merge) plan).subPlan(), instanceOf(Collect.class));
    <FONT color="#6cc417"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2358194-0.html#4',2,'match2358194-top.html#4',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>}

    @Test
    public void testGetPlan() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom</B></FONT>(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select name from users where id = 1&quot;);
        assertThat(plan, isPlan(
            &quot;Get[doc.users | name | DocKeys{1::bigint} | (id = 1::bigint)]&quot;));
    }

    @Test
    public void testGetWithVersion() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select name from users where id = 1 and _version = 1&quot;);
        assertThat(plan, isPlan(
            &quot;Get[doc.users | name | DocKeys{1::bigint, 1::bigint} | ((id = 1::bigint) AND (_version = 1::bigint))]&quot;));
    }

    @Test
    public void testGetPlanStringLiteral() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.TEST_CLUSTER_BY_STRING_TABLE_DEFINITION)
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select name from bystring where name = 'one'&quot;);
        assertThat(plan, isPlan(
            &quot;Get[doc.bystring | name | DocKeys{'one'} | (name = 'one')]&quot;
        ));
    }

    @Test
    public void testGetPlanPartitioned() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addPartitionedTable(
                TableDefinitions.PARTED_PKS_TABLE_DEFINITION,
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted_pks&quot;), singletonList(&quot;1395874800000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted_pks&quot;), singletonList(&quot;1395961200000&quot;)).asIndexName()
            )
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select name, date from parted_pks where id = 1 and date = 0&quot;);
        assertThat(plan, isPlan(
            &quot;Get[doc.parted_pks | name, date | DocKeys{1, 0::bigint} | ((id = 1) AND (date = 0::bigint))]&quot;
        ));
    }

    @Test
    public void testMultiGetPlan() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select name from users where id in (1, 2)&quot;);
        assertThat(plan, isPlan(
            &quot;Get[doc.users | name | DocKeys{1::bigint; 2::bigint} | (id = ANY([1::bigint, 2::bigint]))]&quot;
        ));
    }

    @Test
    public void testGlobalAggregationPlan() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge globalAggregate = e.plan(&quot;select count(name) from users&quot;);
        Collect collect = (Collect) globalAggregate.subPlan();
        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) collect.collectPhase());

        assertEquals(CountAggregation.LongStateType.INSTANCE, collectPhase.outputTypes().get(0));
        assertThat(collectPhase.maxRowGranularity(), is(RowGranularity.DOC));
        assertThat(collectPhase.projections().size(), is(1));
        assertThat(collectPhase.projections().get(0), instanceOf(AggregationProjection.class));
        assertThat(collectPhase.projections().get(0).requiredGranularity(), is(RowGranularity.SHARD));

        MergePhase mergePhase = globalAggregate.mergePhase();

        assertEquals(CountAggregation.LongStateType.INSTANCE, mergePhase.inputTypes().iterator().next());
        assertEquals(DataTypes.LONG, mergePhase.outputTypes().get(0));
    }

    @Test
    public void testShardSelectWithOrderBy() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            // need to have at least one table so there are some shards to have a distributed plan
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge merge = e.plan(&quot;select id from sys.shards order by id limit 10&quot;);
        Collect collect = (Collect) merge.subPlan();
        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) collect.collectPhase());

        assertEquals(DataTypes.INTEGER, collectPhase.outputTypes().get(0));
        assertThat(collectPhase.maxRowGranularity(), is(RowGranularity.SHARD));
<A NAME="3"></A>
        assertThat(collectPhase.orderBy(), notNullValue());

        <FONT color="#53858b"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2358194-0.html#3',2,'match2358194-top.html#3',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>List&lt;Projection&gt; projections = collectPhase.projections();
        assertThat(projections, contains(
            instanceOf(TopNProjection.class)
        ));
    }

    @Test
    public void testCollectAndMergePlan() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom</B></FONT>(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        QueryThenFetch qtf = e.plan(&quot;select name from users where name = 'x' order by id limit 10&quot;);
        Merge merge = (Merge) qtf.subPlan();
        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) ((Collect) merge.subPlan()).collectPhase());
        assertThat(collectPhase.where().toString(), is(&quot;(name = 'x')&quot;));

        TopNProjection topNProjection = (TopNProjection) collectPhase.projections().get(0);
        assertThat(topNProjection.limit(), is(10));

        MergePhase mergePhase = merge.mergePhase();
        assertThat(mergePhase.outputTypes().size(), is(1));
        assertEquals(DataTypes.STRING, mergePhase.outputTypes().get(0));
    }

    @Test
    public void testCollectAndMergePlanNoFetch() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        // testing that a fetch projection is not added if all output symbols are included
        // at the orderBy symbols
        Merge merge = e.plan(&quot;select name from users where name = 'x' order by name limit 10&quot;);
        Collect collect = (Collect) merge.subPlan();
        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) collect.collectPhase());
        assertThat(collectPhase.where().toString(), is(&quot;(name = 'x')&quot;));

        MergePhase mergePhase = merge.mergePhase();
        assertThat(mergePhase.outputTypes().size(), is(1));
        assertEquals(DataTypes.STRING, mergePhase.outputTypes().get(0));

        assertTrue(mergePhase.finalProjection().isPresent());

        Projection lastProjection = mergePhase.finalProjection().get();
        assertThat(lastProjection, instanceOf(TopNProjection.class));
        TopNProjection topNProjection = (TopNProjection) lastProjection;
        assertThat(topNProjection.outputs().size(), is(1));
    }

    @Test
    public void testCollectAndMergePlanHighLimit() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        QueryThenFetch qtf = e.plan(&quot;select name from users limit 100000&quot;);
        Merge merge = (Merge) qtf.subPlan();
        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) ((Collect) merge.subPlan()).collectPhase());
        assertThat(collectPhase.nodePageSizeHint(), is(100_000));

        MergePhase mergePhase = merge.mergePhase();
        assertThat(mergePhase.projections().size(), is(2));
        TopNProjection topN = (TopNProjection) mergePhase.projections().get(0);
        assertThat(topN.limit(), is(100_000));
        assertThat(topN.offset(), is(0));

        // with offset
        qtf = e.plan(&quot;select name from users limit 100000 offset 20&quot;);
        merge = ((Merge) qtf.subPlan());

        collectPhase = ((RoutedCollectPhase) ((Collect) merge.subPlan()).collectPhase());
        assertThat(collectPhase.nodePageSizeHint(), is(100_000 + 20));

        mergePhase = merge.mergePhase();
        assertThat(mergePhase.projections().size(), is(2));
        topN = (TopNProjection) mergePhase.projections().get(0);
        assertThat(topN.limit(), is(100_000));
        assertThat(topN.offset(), is(20));
    }


    @Test
    public void testCollectAndMergePlanPartitioned() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addPartitionedTable(
                TableDefinitions.PARTED_PKS_TABLE_DEFINITION,
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted_pks&quot;), singletonList(&quot;1395874800000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted_pks&quot;), singletonList(&quot;1395961200000&quot;)).asIndexName()
            )
            .build();

        QueryThenFetch qtf = e.plan(&quot;select id, name, date from parted_pks where date &gt; 0 and name = 'x' order by id limit 10&quot;);
        Merge merge = (Merge) qtf.subPlan();
        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) ((Collect) merge.subPlan()).collectPhase());

        Set&lt;String&gt; indices = new HashSet&lt;&gt;();
        Map&lt;String, Map&lt;String, IntIndexedContainer&gt;&gt; locations = collectPhase.routing().locations();
        for (Map.Entry&lt;String, Map&lt;String, IntIndexedContainer&gt;&gt; entry : locations.entrySet()) {
            indices.addAll(entry.getValue().keySet());
        }
        assertThat(indices, Matchers.containsInAnyOrder(
            new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted_pks&quot;), Arrays.asList(&quot;1395874800000&quot;)).asIndexName(),
            new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted_pks&quot;), Arrays.asList(&quot;1395961200000&quot;)).asIndexName()));

        assertThat(collectPhase.where().toString(), is(&quot;(name = 'x')&quot;));

        MergePhase mergePhase = merge.mergePhase();
        assertThat(mergePhase.outputTypes().size(), is(3));
    }

    @Test
    public void testCollectAndMergePlanFunction() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        QueryThenFetch qtf = e.plan(&quot;select format('Hi, my name is %s', name), name from users where name = 'x' order by id limit 10&quot;);
        Merge merge = (Merge) qtf.subPlan();
        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) ((Collect) merge.subPlan()).collectPhase());

        assertThat(collectPhase.where().toString(), is(&quot;(name = 'x')&quot;));

        MergePhase mergePhase = merge.mergePhase();
        assertThat(mergePhase.outputTypes().size(), is(2));
        assertEquals(DataTypes.STRING, mergePhase.outputTypes().get(0));
        assertEquals(DataTypes.STRING, mergePhase.outputTypes().get(1));
    }

    @Test
    public void testCountDistinctPlan() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge globalAggregate = e.plan(&quot;select count(distinct name) from users&quot;);
        Collect collect = (Collect) globalAggregate.subPlan();

        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) collect.collectPhase());
        Projection projection = collectPhase.projections().get(0);
        assertThat(projection, instanceOf(AggregationProjection.class));
        AggregationProjection aggregationProjection = (AggregationProjection) projection;
        assertThat(aggregationProjection.aggregations().size(), is(1));
        assertThat(aggregationProjection.mode(), is(AggregateMode.ITER_PARTIAL));

        Aggregation aggregation = aggregationProjection.aggregations().get(0);
        Symbol aggregationInput = aggregation.inputs().get(0);
        assertThat(aggregationInput.symbolType(), is(SymbolType.INPUT_COLUMN));

        assertThat(collectPhase.toCollect().get(0), instanceOf(Reference.class));
        assertThat(((Reference) collectPhase.toCollect().get(0)).column().name(), is(&quot;name&quot;));

        MergePhase mergePhase = globalAggregate.mergePhase();
        assertThat(mergePhase.projections().size(), is(2));
        Projection projection1 = mergePhase.projections().get(1);

        assertThat(projection1, instanceOf(EvalProjection.class));
        Symbol collection_count = projection1.outputs().get(0);
        assertThat(collection_count, instanceOf(Function.class));
    }

    @Test
    public void testGlobalAggregationHaving() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge globalAggregate = e.plan(
            &quot;select avg(date) from users having min(date) &gt; '1970-01-01'&quot;);
        Collect collect = (Collect) globalAggregate.subPlan();
        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) collect.collectPhase());
        assertThat(collectPhase.projections().size(), is(1));
        assertThat(collectPhase.projections().get(0), instanceOf(AggregationProjection.class));

        MergePhase localMergeNode = globalAggregate.mergePhase();

        assertThat(localMergeNode.projections(), contains(
            instanceOf(AggregationProjection.class),
            instanceOf(FilterProjection.class),
            instanceOf(EvalProjection.class)));

        AggregationProjection aggregationProjection = (AggregationProjection) localMergeNode.projections().get(0);
        assertThat(aggregationProjection.aggregations().size(), is(2));

        FilterProjection filterProjection = (FilterProjection) localMergeNode.projections().get(1);
        assertThat(filterProjection.outputs().size(), is(2));
        assertThat(filterProjection.outputs().get(0), instanceOf(InputColumn.class));
        InputColumn inputColumn = (InputColumn) filterProjection.outputs().get(0);
        assertThat(inputColumn.index(), is(0));

        EvalProjection evalProjection = (EvalProjection) localMergeNode.projections().get(2);
        assertThat(evalProjection.outputs().size(), is(1));
    }

    @Test
    public void testCountOnPartitionedTable() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addPartitionedTable(
                &quot;create table parted (&quot; +
                &quot;   id int,&quot; +
                &quot;   name string,&quot; +
                &quot;   date timestamp without time zone,&quot; +
                &quot;   obj object&quot; +
                &quot;) partitioned by (date) clustered into 1 shards &quot;,
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(&quot;1395874800000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(&quot;1395961200000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(null)).asIndexName()
            )
            .build();

        CountPlan plan = e.plan(&quot;select count(*) from parted where date = 1395874800000&quot;);
        assertThat(
            plan.countPhase().routing().locations().entrySet().stream()
                .flatMap(x -&gt; x.getValue().keySet().stream())
                .collect(Collectors.toSet()),
            Matchers.contains(
                is(&quot;.partitioned.parted.04732cpp6ks3ed1o60o30c1g&quot;)
            )
        );
    }

    @Test(expected = UnsupportedOperationException.class)
    public void testSelectPartitionedTableOrderByPartitionedColumnInFunction() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addPartitionedTable(
                &quot;create table parted (&quot; +
                &quot;   id int,&quot; +
                &quot;   name string,&quot; +
                &quot;   date timestamp without time zone,&quot; +
                &quot;   obj object&quot; +
                &quot;) partitioned by (date) clustered into 1 shards &quot;,
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(&quot;1395874800000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(&quot;1395961200000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(null)).asIndexName()
            )
            .build();

        e.plan(&quot;select name from parted order by year(date)&quot;);
    }

    @Test(expected = UnsupportedFeatureException.class)
    public void testQueryRequiresScalar() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .build();

        // only scalar functions are allowed on system tables because we have no lucene queries
        e.plan(&quot;select * from sys.shards where match(table_name, 'characters')&quot;);
    }

    @Test
    public void testSortOnUnknownColumn() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.IGNORED_NESTED_TABLE_DEFINITION)
            .build();

        expectedException.expect(UnsupportedOperationException.class);
        expectedException.expectMessage(&quot;Cannot ORDER BY 'details['unknown_column']': invalid data type 'undefined'.&quot;);
        e.plan(&quot;select details from ignored_nested order by details['unknown_column']&quot;);
    }

    @Test
    public void testSelectAnalyzedReferenceInFunctionAggregation() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        expectedException.expect(IllegalArgumentException.class);
        expectedException.expectMessage(&quot;Cannot select analyzed column 'text' within grouping or aggregations&quot;);
        e.plan(&quot;select min(substr(text, 0, 2)) from users&quot;);
    }

    @Test
    public void testGlobalAggregateWithWhereOnPartitionColumn() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addPartitionedTable(
                &quot;create table parted (&quot; +
                &quot;   id int,&quot; +
                &quot;   name string,&quot; +
                &quot;   date timestamp without time zone,&quot; +
                &quot;   obj object&quot; +
                &quot;) partitioned by (date) clustered into 1 shards &quot;,
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(&quot;1395874800000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(&quot;1395961200000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(null)).asIndexName()
            )
            .build();

        ExecutionPlan plan = e.plan(
            &quot;select min(name) from parted where date &gt;= 1395961200000&quot;);
        Collect collect;
        if (plan instanceof Merge) {
            collect = ((Collect) ((Merge) plan).subPlan());
        } else {
            collect = (Collect) plan;
        }
        Routing routing = ((RoutedCollectPhase) collect.collectPhase()).routing();

        assertThat(
            routing.locations().values()
                .stream()
                .flatMap(shardsByIndex -&gt; shardsByIndex.keySet().stream())
                .collect(Collectors.toSet()),
            contains(
                is(&quot;.partitioned.parted.04732cpp6ksjcc9i60o30c1g&quot;)
            ));
    }
<A NAME="0"></A>
    @Test
    public void testHasNoResultFromHaving() throws Exception {
        SQLExecutor e = <FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2358194-0.html#0',2,'match2358194-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge merge = e.plan(&quot;select min(name) from users having 1 = 2&quot;);
        assertThat(merge.mergePhase().projections().get(1), instanceOf(FilterProjection.class));
        assertThat(((FilterProjection) merge.mergePhase().projections().get(1)).query(), isSQL(&quot;false&quot;));
    }

    @Test
    public void testShardQueueSizeCalculation() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom</B></FONT>(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge merge = e.plan(&quot;select name from users order by name limit 500&quot;);
        Collect collect = (Collect) merge.subPlan();
        int shardQueueSize = ((RoutedCollectPhase) collect.collectPhase()).shardQueueSize(
            collect.collectPhase().nodeIds().iterator().next());
        assertThat(shardQueueSize, is(375));
    }

    @Test
    public void testQAFPagingIsEnabledOnHighLimit() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge plan = e.plan(&quot;select name from users order by name limit 1000000&quot;);
        assertThat(plan.mergePhase().nodeIds().size(), is(1)); // mergePhase with executionNode = paging enabled

        Collect collect = (Collect) plan.subPlan();
        assertThat(((RoutedCollectPhase) collect.collectPhase()).nodePageSizeHint(), is(750000));
    }

    @Test
    public void testQAFPagingIsEnabledOnHighOffset() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge merge = e.plan(&quot;select name from users order by name limit 10 offset 1000000&quot;);
        Collect collect = (Collect) merge.subPlan();
        assertThat(merge.mergePhase().nodeIds().size(), is(1)); // mergePhase with executionNode = paging enabled
        assertThat(((RoutedCollectPhase) collect.collectPhase()).nodePageSizeHint(), is(750007));
    }

    @Test
    public void testQTFPagingIsEnabledOnHighLimit() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        QueryThenFetch qtf = e.plan(&quot;select name, date from users order by name limit 1000000&quot;);
        Merge merge = (Merge) qtf.subPlan();
        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) ((Collect) merge.subPlan()).collectPhase());
        assertThat(merge.mergePhase().nodeIds().size(), is(1)); // mergePhase with executionNode = paging enabled
        assertThat(collectPhase.nodePageSizeHint(), is(750000));
    }

    @Test
    public void testSelectFromUnnestResultsInTableFunctionPlan() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .build();

        Collect collect = e.plan(&quot;select * from unnest([1, 2], ['Arthur', 'Trillian'])&quot;);
        assertNotNull(collect);
        assertThat(collect.collectPhase().toCollect(), contains(isReference(&quot;col1&quot;), isReference(&quot;col2&quot;)));
    }

    @Test
    public void testReferenceToNestedAggregatedField() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService)
            .addTable(T3.T1_DEFINITION)
            .build();

        Collect collect = e.plan(&quot;select ii, xx from ( &quot; +
                                 &quot;  select i + i as ii, xx from (&quot; +
                                 &quot;    select i, sum(x) as xx from t1 group by i) as t) as tt &quot; +
                                 &quot;where (ii * 2) &gt; 4 and (xx * 2) &gt; 120&quot;);
        assertThat(&quot;would require merge with more than 1 nodeIds&quot;, collect.nodeIds().size(), is(1));
        List&lt;Projection&gt; projections = collect.collectPhase().projections();
        assertThat(projections, contains(
            instanceOf(GroupProjection.class), // parallel on shard-level
            instanceOf(GroupProjection.class), // node-level
            instanceOf(EvalProjection.class),
            instanceOf(FilterProjection.class),
            instanceOf(EvalProjection.class)
        ));
    }

    @Test
    public void test3TableJoinQuerySplitting() throws Exception {
        TableStats tableStats = new TableStats();
        tableStats.updateTableStats(
            Map.of(new RelationName(&quot;doc&quot;, &quot;users&quot;), new Stats(20, 20, Map.of())));
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .setTableStats(tableStats)
            .build();

        Join outerNl = e.plan(&quot;select&quot; +
                                    &quot;  u1.id as u1, &quot; +
                                    &quot;  u2.id as u2, &quot; +
                                    &quot;  u3.id as u3 &quot; +
                                    &quot;from &quot; +
                                    &quot;  users u1,&quot; +
                                    &quot;  users u2,&quot; +
                                    &quot;  users u3 &quot; +
                                    &quot;where &quot; +
                                    &quot;  u1.name = 'Arthur'&quot; +
                                    &quot;  and u2.id = u1.id&quot; +
                                    &quot;  and u2.name = u1.name&quot;);
        Join innerNl = (Join) outerNl.left();

        assertThat(innerNl.joinPhase().joinCondition(), isSQL(&quot;((INPUT(0) = INPUT(2)) AND (INPUT(1) = INPUT(3)))&quot;));
        assertThat(innerNl.joinPhase().projections().size(), is(1));
        assertThat(innerNl.joinPhase().projections().get(0), instanceOf(EvalProjection.class));

        assertThat(outerNl.joinPhase().joinCondition(), nullValue());
        assertThat(outerNl.joinPhase().projections().size(), is(2));
        assertThat(outerNl.joinPhase().projections(), contains(
            instanceOf(EvalProjection.class),
            instanceOf(EvalProjection.class)
        ));
    }

    @Test
    public void testOuterJoinToInnerJoinRewrite() throws Exception {
        TableStats tableStats = new TableStats();
        tableStats.updateTableStats(
            Map.of(new RelationName(&quot;doc&quot;, &quot;users&quot;), new Stats(20, 20, Map.of())));
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .setTableStats(tableStats)
            .build();

        // disable hash joins otherwise it will be a distributed join and the plan differs
        e.getSessionContext().setHashJoinEnabled(false);
        Merge merge = e.plan(&quot;select u1.text, concat(u2.text, '_foo') &quot; +
                                    &quot;from users u1 left join users u2 on u1.id = u2.id &quot; +
                                    &quot;where u2.name = 'Arthur'&quot; +
                                    &quot;and u2.id &gt; 1 &quot;);
        Join nl = (Join) merge.subPlan();
        assertThat(nl.joinPhase().joinType(), is(JoinType.INNER));
        Collect rightCM = (Collect) nl.right();
        assertThat(((RoutedCollectPhase) rightCM.collectPhase()).where(),
            isSQL(&quot;((doc.users.name = 'Arthur') AND (doc.users.id &gt; 1::bigint))&quot;));
    }

    @Test
    public void testShardSelect() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            // Need to have at least one table to have some shards for a distributed plan
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge merge = e.plan(&quot;select id from sys.shards&quot;);
        Collect collect = (Collect) merge.subPlan();
        RoutedCollectPhase collectPhase = ((RoutedCollectPhase) collect.collectPhase());
        assertThat(collectPhase.maxRowGranularity(), is(RowGranularity.SHARD));
    }

    @Test
    public void testGlobalCountPlan() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        CountPlan plan = e.plan(&quot;select count(*) from users&quot;);

        assertThat(plan.countPhase().where(), equalTo(Literal.BOOLEAN_TRUE));

        assertThat(plan.mergePhase().projections().size(), is(1));
        assertThat(plan.mergePhase().projections().get(0), instanceOf(MergeCountProjection.class));
    }

    @Test
    public void testLimitThatIsBiggerThanPageSizeCausesQTFPUshPlan() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        QueryThenFetch qtf = e.plan(&quot;select * from users limit 2147483647 &quot;);
        Merge merge = (Merge) qtf.subPlan();
        assertThat(merge.mergePhase().nodeIds().size(), is(1));
        String localNodeId = merge.mergePhase().nodeIds().iterator().next();
        NodeOperationTree operationTree = NodeOperationTreeGenerator.fromPlan(merge, localNodeId);
        NodeOperation nodeOperation = operationTree.nodeOperations().iterator().next();
        // paging -&gt; must not use direct response
        assertThat(nodeOperation.downstreamNodes(), not(contains(ExecutionPhase.DIRECT_RESPONSE)));


        qtf = e.plan(&quot;select * from users limit 2&quot;);
        merge = (Merge) qtf.subPlan();
        localNodeId = merge.subPlan().resultDescription().nodeIds().iterator().next();
        operationTree = NodeOperationTreeGenerator.fromPlan(merge, localNodeId);
        nodeOperation = operationTree.nodeOperations().iterator().next();
        // no paging -&gt; can use direct response
        assertThat(nodeOperation.downstreamNodes(), contains(ExecutionPhase.DIRECT_RESPONSE));
    }

    @Test
    public void testAggregationOnGeneratedColumns() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(
                &quot;create table doc.gc_table (&quot; +
                &quot;   revenue integer,&quot; +
                &quot;   cost integer,&quot; +
                &quot;   profit as revenue - cost&quot; +
                &quot;)&quot;
            ).build();

        Merge merge = e.plan(&quot;select sum(profit) from gc_table&quot;);
        Collect collect = (Collect) merge.subPlan();
        List&lt;Projection&gt; projections = collect.collectPhase().projections();
        assertThat(projections, contains(
            instanceOf(AggregationProjection.class) // iter-partial on shard level
        ));
        assertThat(
            merge.mergePhase().projections(),
            contains(instanceOf(AggregationProjection.class))
        );
        assertThat(
            ((AggregationProjection)projections.get(0)).aggregations().get(0).inputs().get(0),
            isSQL(&quot;INPUT(0)&quot;));
    }

    @Test
    public void testGlobalAggregationOn3TableJoinWithImplicitJoinConditions() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge plan = e.plan(&quot;select count(*) from users t1, users t2, users t3 &quot; +
                            &quot;where t1.id = t2.id and t2.id = t3.id&quot;);
        assertThat(plan.subPlan(), instanceOf(Join.class));
        Join outerNL = (Join)plan.subPlan();
        assertThat(outerNL.joinPhase().joinCondition(), isSQL(&quot;(INPUT(1) = INPUT(2))&quot;));
        assertThat(outerNL.joinPhase().projections().size(), is(2));
        assertThat(outerNL.joinPhase().projections().get(0), instanceOf(EvalProjection.class));
        assertThat(outerNL.joinPhase().projections().get(1), instanceOf(AggregationProjection.class));
        assertThat(outerNL.joinPhase().outputTypes().size(), is(1));
        assertThat(outerNL.joinPhase().outputTypes().get(0), is(CountAggregation.LongStateType.INSTANCE));

        Join innerNL = (Join) outerNL.left();
        assertThat(innerNL.joinPhase().joinCondition(), isSQL(&quot;(INPUT(0) = INPUT(1))&quot;));
        assertThat(innerNL.joinPhase().projections().size(), is(1));
        assertThat(innerNL.joinPhase().projections().get(0), instanceOf(EvalProjection.class));
        assertThat(innerNL.joinPhase().outputTypes().size(), is(2));
        assertThat(innerNL.joinPhase().outputTypes().get(0), is(DataTypes.LONG));

        plan = e.plan(&quot;select count(t1.other_id) from users t1, users t2, users t3 &quot; +
                      &quot;where t1.id = t2.id and t2.id = t3.id&quot;);
        assertThat(plan.subPlan(), instanceOf(Join.class));
        outerNL = (Join)plan.subPlan();
        assertThat(outerNL.joinPhase().joinCondition(), isSQL(&quot;(INPUT(2) = INPUT(3))&quot;));
        assertThat(outerNL.joinPhase().projections().size(), is(2));
        assertThat(outerNL.joinPhase().projections().get(0), instanceOf(EvalProjection.class));
        assertThat(outerNL.joinPhase().projections().get(1), instanceOf(AggregationProjection.class));
        assertThat(outerNL.joinPhase().outputTypes().size(), is(1));
        assertThat(outerNL.joinPhase().outputTypes().get(0), is(CountAggregation.LongStateType.INSTANCE));

        innerNL = (Join) outerNL.left();
        assertThat(innerNL.joinPhase().joinCondition(), isSQL(&quot;(INPUT(1) = INPUT(2))&quot;));
        assertThat(innerNL.joinPhase().projections().size(), is(1));
        assertThat(innerNL.joinPhase().projections().get(0), instanceOf(EvalProjection.class));
        assertThat(innerNL.joinPhase().outputTypes().size(), is(3));
        assertThat(innerNL.joinPhase().outputTypes().get(0), is(DataTypes.LONG));
        assertThat(innerNL.joinPhase().outputTypes().get(1), is(DataTypes.LONG));
    }

    @Test
    public void test2TableJoinWithNoMatch() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Join nl = e.plan(&quot;select * from users t1, users t2 WHERE 1=2&quot;);
        assertThat(nl.left(), instanceOf(Collect.class));
        assertThat(nl.right(), instanceOf(Collect.class));
        assertThat(((RoutedCollectPhase)((Collect)nl.left()).collectPhase()).where(), isSQL(&quot;false&quot;));
        assertThat(((RoutedCollectPhase)((Collect)nl.right()).collectPhase()).where(), isSQL(&quot;false&quot;));
    }

    @Test
    public void test3TableJoinWithNoMatch() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Join outer = e.plan(&quot;select * from users t1, users t2, users t3 WHERE 1=2&quot;);
        assertThat(((RoutedCollectPhase)((Collect)outer.right()).collectPhase()).where(), isSQL(&quot;false&quot;));
        Join inner = (Join) outer.left();
        assertThat(((RoutedCollectPhase)((Collect)inner.left()).collectPhase()).where(), isLiteral(false));
        assertThat(((RoutedCollectPhase)((Collect)inner.right()).collectPhase()).where(), isLiteral(false));
    }

    @Test
    public void testGlobalAggregateOn2TableJoinWithNoMatch() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Join nl = e.plan(&quot;select count(*) from users t1, users t2 WHERE 1=2&quot;);
        assertThat(nl.left(), instanceOf(Collect.class));
        assertThat(nl.right(), instanceOf(Collect.class));
        assertThat(((RoutedCollectPhase)((Collect)nl.left()).collectPhase()).where(), isLiteral(false));
        assertThat(((RoutedCollectPhase)((Collect)nl.right()).collectPhase()).where(), isLiteral(false));
    }

    @Test
    public void testGlobalAggregateOn3TableJoinWithNoMatch() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Join outer = e.plan(&quot;select count(*) from users t1, users t2, users t3 WHERE 1=2&quot;);
        Join inner = (Join) outer.left();
        assertThat(((RoutedCollectPhase)((Collect)outer.right()).collectPhase()).where(), isLiteral(false));
        assertThat(((RoutedCollectPhase)((Collect)inner.left()).collectPhase()).where(), isLiteral(false));
        assertThat(((RoutedCollectPhase)((Collect)inner.right()).collectPhase()).where(), isLiteral(false));
    }

    @Test
    public void testFilterOnPKSubsetResultsInPKLookupPlanIfTheOtherPKPartIsGenerated() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(
                &quot;create table t_pk_part_generated (&quot; +
                &quot;   ts timestamp with time zone,&quot; +
                &quot;   p as date_trunc('day', ts),&quot; +
                &quot;   primary key (ts, p))&quot;)
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select 1 from t_pk_part_generated where ts = 0&quot;);
        assertThat(plan, isPlan(
            &quot;Get[doc.t_pk_part_generated | 1 | DocKeys{0::bigint, 0::bigint} | ((ts = 0::bigint) AND (p AS date_trunc('day', ts) = 0::bigint))]&quot;
        ));
    }

    @Test
    public void testInnerJoinResultsInHashJoinIfHashJoinIsEnabled() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(T3.T1_DEFINITION)
            .addTable(T3.T2_DEFINITION)
            .build();

        e.getSessionContext().setHashJoinEnabled(true);
        Merge merge = e.plan(&quot;select t2.b, t1.a from t1 inner join t2 on t1.i = t2.i order by 1, 2&quot;);
        Join join = (Join) merge.subPlan();
        assertThat(join.joinPhase().type(), is(ExecutionPhase.Type.HASH_JOIN));
    }

    @Test
    public void testUnnestInSelectListResultsInPlanWithProjectSetOperator() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select unnest([1, 2])&quot;);
        assertThat(plan, isPlan(
            &quot;ProjectSet[unnest([1, 2])]\n&quot; +
            &quot;   TableFunction[empty_row | [] | true]&quot;));
        Symbol output = plan.outputs().get(0);
        assertThat(output.valueType(), is(DataTypes.INTEGER));
    }

    @Test
    public void testScalarCanBeUsedAroundTableGeneratingFunctionInSelectList() {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select unnest([1, 2]) + 1&quot;);
        assertThat(plan, isPlan(
            &quot;Eval[(unnest([1, 2]) + 1)]\n&quot; +
            &quot;   ProjectSet[unnest([1, 2])]\n&quot; +
            &quot;     TableFunction[empty_row | [] | true]&quot;));
    }

    @Test
    public void testAggregationOnTopOfTableFunctionIsNotPossibleWithoutSeparateSubQuery() {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .build();

        expectedException.expectMessage(&quot;Cannot use table functions inside aggregates&quot;);
        e.logicalPlan(&quot;select sum(unnest([1, 2]))&quot;);
    }

    @Test
    public void testTableFunctionIsExecutedAfterAggregation() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select count(*), generate_series(1, 2) from users&quot;);
        assertThat(plan, isPlan(
            &quot;Eval[count(*), pg_catalog.generate_series(1, 2)]\n&quot; +
            &quot;   ProjectSet[pg_catalog.generate_series(1, 2), count(*)]\n&quot; +
            &quot;     Count[doc.users | true]&quot;));
    }

    @Test
    public void testAggregationCanBeUsedAsArgumentToTableFunction() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select count(name), generate_series(1, count(name)) from users&quot;);
        assertThat(plan, isPlan(
            &quot;Eval[count(name), pg_catalog.generate_series(1::bigint, count(name))]\n&quot; +
            &quot;   ProjectSet[pg_catalog.generate_series(1::bigint, count(name)), count(name)]\n&quot; +
            &quot;     HashAggregate[count(name)]\n&quot; +
            &quot;       Collect[doc.users | [name] | true]&quot;));
    }

    @Test
    public void testOrderByOnTableFunctionMustOrderAfterProjectSet() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .build();

        LogicalPlan plan = e.logicalPlan(&quot;select unnest([1, 2]) from sys.nodes order by 1&quot;);
        assertThat(plan, isPlan(
            &quot;OrderBy[unnest([1, 2]) ASC]\n&quot; +
            &quot;   ProjectSet[unnest([1, 2])]\n&quot; +
            &quot;     Collect[sys.nodes | [] | true]&quot;));
    }

    @Test
    public void testWindowFunctionsWithPartitionByAreExecutedDistributed() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge localMerge = e.plan(&quot;select sum(ints) OVER (partition by awesome) from users&quot;);
        Merge distMerge = (Merge) localMerge.subPlan();
        assertThat(distMerge.nodeIds().size(), is(2));
        assertThat(distMerge.mergePhase().projections(), contains(
            instanceOf(WindowAggProjection.class),
            instanceOf(EvalProjection.class)
        ));
        Collect collect = (Collect) distMerge.subPlan();
        assertThat(collect.nodeIds().size(), is(2));
    }

    @Test
    public void testSeqNoAndPrimaryTermFilteringRequirePrimaryKey() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        expectedException.expect(VersioningValidationException.class);
        expectedException.expectMessage(VersioningValidationException.SEQ_NO_AND_PRIMARY_TERM_USAGE_MSG);
        e.plan(&quot;select * from users where _seq_no = 2 and _primary_term = 1&quot;);
    }


    @Test
    public void testTablePartitionsAreNarrowedToMatchWhereClauseOfParentQuery() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addPartitionedTable(
                &quot;create table parted (&quot; +
                &quot;   id int,&quot; +
                &quot;   name string,&quot; +
                &quot;   date timestamp without time zone,&quot; +
                &quot;   obj object&quot; +
                &quot;) partitioned by (date) clustered into 1 shards &quot;,
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(&quot;1395874800000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(&quot;1395961200000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted&quot;), singletonList(null)).asIndexName()
            )
            .build();

        String statement = &quot;select * from (select * from parted) t where date is null&quot;;
        LogicalPlan logicalPlan = e.logicalPlan(statement);
        assertThat(logicalPlan, isPlan(
            &quot;Rename[id, name, date, obj] AS t\n&quot; +
            &quot;   Collect[doc.parted | [id, name, date, obj] | (date IS NULL)]&quot;));
        ExecutionPlan plan = e.plan(statement);
        Collect collect = plan instanceof Collect ? (Collect) plan : ((Collect) ((Merge) plan).subPlan());
        RoutedCollectPhase routedCollectPhase = (RoutedCollectPhase) collect.collectPhase();

        int numShards = 0;
        for (String node : routedCollectPhase.routing().nodes()) {
            numShards += routedCollectPhase.routing().numShards(node);
        }
        assertThat(numShards, is(1));
    }

    @Test
    public void test_match_used_on_table_with_alias_is_resolved_to_a_function() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge merge = e.plan(&quot;select name from users as u where match(u.text, 'yalla') order by 1&quot;);
        Collect collect = (Collect) merge.subPlan();
        assertThat(((RoutedCollectPhase) collect.collectPhase()).where(), isFunction(&quot;match&quot;));
    }

    @Test
    public void test_distinct_with_limit_is_optimized_to_topn_distinct() throws Exception {
        TableStats tableStats = new TableStats();
        tableStats.updateTableStats(
            Map.of(new RelationName(&quot;doc&quot;, &quot;users&quot;), new Stats(20, 20, Map.of())));
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .setTableStats(tableStats)
            .build();

        String stmt = &quot;select distinct name from users limit 1&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        assertThat(plan, isPlan(
            &quot;TopNDistinct[1::bigint;0 | [name]]\n&quot; +
            &quot;   Collect[doc.users | [name] | true]&quot;));
    }

    @Test
    public void test_group_by_without_aggregates_and_with_limit_is_optimized_to_topn_distinct() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        String stmt = &quot;select id, name from users group by id, name limit 1&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        assertThat(plan, isPlan(
            &quot;TopNDistinct[1::bigint;0 | [id, name]]\n&quot; +
            &quot;   Collect[doc.users | [id, name] | true]&quot;));
    }

    @Test
    public void test_distinct_with_limit_and_offset_keeps_offset() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        String stmt = &quot;select id, name from users group by id, name limit 1 offset 3&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        assertThat(plan, isPlan(
            &quot;TopNDistinct[1::bigint;3::bigint | [id, name]]\n&quot; +
            &quot;   Collect[doc.users | [id, name] | true]&quot;));

        Merge merge = e.plan(stmt);
        List&lt;Projection&gt; collectProjections = ((Collect) merge.subPlan()).collectPhase().projections();;
        assertThat(
            collectProjections,
            contains(
                instanceOf(TopNDistinctProjection.class)
            )
        );
        List&lt;Projection&gt; mergeProjections = merge.mergePhase().projections();
        assertThat(
            mergeProjections,
            contains(
                instanceOf(TopNDistinctProjection.class),
                instanceOf(TopNProjection.class)
            )
        );
    }

    @Test
    public void test_group_by_on_subscript_on_obj_output_of_sub_relation() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        String stmt = &quot;SELECT address['postcode'] FROM (SELECT address FROM users) AS u GROUP BY 1&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        assertThat(plan, isPlan(
            &quot;GroupHashAggregate[address['postcode']]\n&quot; +
            &quot;   Rename[address] AS u\n&quot; +
            &quot;     Collect[doc.users | [address] | true]&quot;));
    }

    @Test
    public void test_order_by_on_subscript_on_obj_output_of_sub_relation() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        String stmt = &quot;SELECT address['postcode'] FROM (SELECT address FROM users) AS u ORDER BY 1&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        assertThat(plan, isPlan(
            &quot;Eval[address['postcode']]\n&quot; +
            &quot;   OrderBy[address['postcode'] ASC]\n&quot; +
            &quot;     Rename[address] AS u\n&quot; +
            &quot;       Collect[doc.users | [address] | true]&quot;));
        Merge merge = e.plan(stmt);
        Collect collect = (Collect) merge.subPlan();
        RoutedCollectPhase collectPhase = (RoutedCollectPhase) collect.collectPhase();
        assertThat(collectPhase.projections(), contains(
            instanceOf(OrderedTopNProjection.class),
            instanceOf(EvalProjection.class)
        ));
    }

    @Test
    public void test_join_with_no_match_where_clause_pushes_down_no_match() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .build();

        String stmt = &quot;SELECT n.* &quot; +
                      &quot;FROM &quot; +
                      &quot;   pg_catalog.pg_namespace n,&quot; +
                      &quot;   pg_catalog.pg_class c &quot; +
                      &quot;WHERE &quot; +
                      &quot;   n.nspname LIKE E'sys' &quot; +
                      &quot;   AND c.relnamespace = n.oid &quot; +
                      &quot;   AND (false)&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        String expectedPlan =
            &quot;NestedLoopJoin[CROSS]\n&quot; +
            &quot;   Rename[nspacl, nspname, nspowner, oid] AS n\n&quot; +
            &quot;     Collect[pg_catalog.pg_namespace | [nspacl, nspname, nspowner, oid] | false]\n&quot; +
            &quot;   Rename[] AS c\n&quot; +
            &quot;     Collect[pg_catalog.pg_class | [] | false]&quot;;
        assertThat(plan, isPlan(expectedPlan));
    }

    @Test
    public void test_window_function_with_function_used_in_order_by_injects_eval_below_window_agg_ordering() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .build();

        // `WindowProjector.createUpdateProbeValueFunction` doesn't support function evaluation
        // because it is not using the InputFactory to evaluate the order by expressions
        // Injecting an Eval operator as a workaround
        String stmt =
            &quot;SELECT\n&quot; +
            &quot;   col1,\n&quot; +
            &quot;   sum(col1) OVER(ORDER BY power(col1, 2) RANGE BETWEEN 3 PRECEDING and CURRENT ROW)\n&quot; +
            &quot;FROM\n&quot; +
            &quot;   unnest(ARRAY[2.5, 4, 5, 6, 7.5, 8.5, 10, 12]) as t(col1)&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        String expectedPlan =
            &quot;Eval[col1, sum(col1) OVER (ORDER BY power(col1, 2.0) ASC RANGE BETWEEN 3 PRECEDING AND CURRENT ROW)]\n&quot; +
            &quot;   WindowAgg[col1, power(col1, 2.0), sum(col1) OVER (ORDER BY power(col1, 2.0) ASC RANGE BETWEEN 3 PRECEDING AND CURRENT ROW)]\n&quot; +
            &quot;     Eval[col1, power(col1, 2.0)]\n&quot; +
            &quot;       Rename[col1] AS t\n&quot; +
            &quot;         TableFunction[unnest | [col1] | true]&quot;;
        assertThat(plan, isPlan(expectedPlan));
    }

    @Test
    public void test_select_from_table_function_with_filter_on_not_selected_column() {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .build();

        String stmt =
            &quot;SELECT word &quot; +
            &quot;FROM pg_catalog.pg_get_keywords() &quot; +
            &quot;WHERE catcode = 'R' &quot; +
            &quot;ORDER BY 1&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        String expectedPlan =
            &quot;Eval[word]\n&quot; +
            &quot;   OrderBy[word ASC]\n&quot; +
            &quot;     Filter[(catcode = 'R')]\n&quot; +
            &quot;       TableFunction[pg_get_keywords | [word, catcode] | true]&quot;;
        assertThat(plan, isPlan(expectedPlan));
    }

    @Test
    public void test_group_by_on_pk_lookup_uses_shard_projections() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        String stmt = &quot;SELECT name, count(*) FROM users WHERE id in (1, 2, 3, 4, 5) GROUP BY name&quot;;
        LogicalPlan logicalPlan = e.logicalPlan(stmt);
        String expectedPlan =
            &quot;GroupHashAggregate[name | count(*)]\n&quot; +
            &quot;   Get[doc.users | name | DocKeys{1::bigint; 2::bigint; 3::bigint; 4::bigint; 5::bigint} | (id = ANY([1::bigint, 2::bigint, 3::bigint, 4::bigint, 5::bigint]))]&quot;;
        assertThat(logicalPlan, isPlan(expectedPlan));
        Merge coordinatorMerge = e.plan(stmt);
        Merge distributedMerge = (Merge) coordinatorMerge.subPlan();
        Collect collect = (Collect) distributedMerge.subPlan();
        assertThat(
            collect.collectPhase().projections(),
            contains(instanceOf(GroupProjection.class))
        );
        assertThat(collect.collectPhase().projections().get(0).requiredGranularity(), is(RowGranularity.SHARD));
    }

    @Test
    public void test_order_by_on_aggregation_with_alias_in_select_list() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        String stmt = &quot;SELECT count(id) as cnt FROM users GROUP BY name ORDER BY count(id) DESC&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        String expectedPlan =
            &quot;Eval[count(id) AS cnt]\n&quot; +
            &quot;   OrderBy[count(id) DESC]\n&quot; +
            &quot;     GroupHashAggregate[name | count(id)]\n&quot; +
            &quot;       Collect[doc.users | [id, name] | true]&quot;;
        assertThat(plan, isPlan(expectedPlan));
    }


    @Test
    public void test_equi_join_with_scalar_using_parameter_placeholders() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        String stmt = &quot;SELECT u1.name FROM users u1 JOIN users u2 ON (u1.name || ?) = u2.name&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        String expectedPlan =
            &quot;Eval[name]\n&quot; +
            &quot;   HashJoin[(name = concat(name, $1))]\n&quot; +
            &quot;     Rename[name] AS u1\n&quot; +
            &quot;       Collect[doc.users | [name] | true]\n&quot; +
            &quot;     Rename[name] AS u2\n&quot; +
            &quot;       Collect[doc.users | [name] | true]&quot;;
        assertThat(plan, isPlan(expectedPlan));

        // this must not fail
        e.plan(stmt, UUID.randomUUID(), 0, new RowN(&quot;foo&quot;));
    }

    @Test
    public void test_non_euqi_join_with_scalar_using_parameter_placeholders() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        String stmt = &quot;SELECT u1.name FROM users u1 JOIN users u2 ON (u1.name || ?) != u2.name&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        String expectedPlan =
            &quot;Eval[name]\n&quot; +
            &quot;   NestedLoopJoin[INNER | (NOT (name = concat(name, $1)))]\n&quot; +
            &quot;     Rename[name] AS u1\n&quot; +
            &quot;       Collect[doc.users | [name] | true]\n&quot; +
            &quot;     Rename[name] AS u2\n&quot; +
            &quot;       Collect[doc.users | [name] | true]&quot;;
        assertThat(plan, isPlan(expectedPlan));

        // this must not fail
        e.plan(stmt, UUID.randomUUID(), 0, new RowN(&quot;foo&quot;));
    }


    @Test
    public void test_columns_used_in_hash_join_condition_are_not_duplicated_in_outputs() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(T3.T1_DEFINITION)
            .addTable(T3.T2_DEFINITION)
            .build();

        String stmt =
            &quot;SELECT * FROM &quot; +
            &quot;   (SELECT a FROM (SELECT * FROM t1) a1) v1 &quot; +
            &quot;   JOIN &quot; +
            &quot;   (SELECT b FROM (SELECT * FROM t2) a2) v2 &quot; +
            &quot;   ON (v1.a = v2.b) &quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        String expectedPlan =
            &quot;HashJoin[(a = b)]\n&quot; +
            &quot;   Rename[a] AS v1\n&quot; +
            &quot;     Eval[a]\n&quot; +
            &quot;       Rename[a] AS a1\n&quot; +
            &quot;         Collect[doc.t1 | [a] | true]\n&quot; +
            &quot;   Rename[b] AS v2\n&quot; +
            &quot;     Eval[b]\n&quot; +
            &quot;       Rename[b] AS a2\n&quot; +
            &quot;         Collect[doc.t2 | [b] | true]&quot;;
        assertThat(plan, isPlan(expectedPlan));
    }

    @Test
    public void test_columns_used_in_nl_join_condition_are_not_duplicated_in_outputs() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(T3.T1_DEFINITION)
            .addTable(T3.T2_DEFINITION)
            .build();

        String stmt =
            &quot;SELECT * FROM &quot; +
            &quot;   (SELECT a FROM (SELECT * FROM t1) a1) v1 &quot; +
            &quot;   JOIN &quot; +
            &quot;   (SELECT b FROM (SELECT * FROM t2) a2) v2 &quot; +
            &quot;   ON (v1.a &gt; v2.b) &quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        String expectedPlan =
            &quot;NestedLoopJoin[INNER | (a &gt; b)]\n&quot; +
            &quot;   Rename[a] AS v1\n&quot; +
            &quot;     Eval[a]\n&quot; +
            &quot;       Rename[a] AS a1\n&quot; +
            &quot;         Collect[doc.t1 | [a] | true]\n&quot; +
            &quot;   Rename[b] AS v2\n&quot; +
            &quot;     Eval[b]\n&quot; +
            &quot;       Rename[b] AS a2\n&quot; +
            &quot;         Collect[doc.t2 | [b] | true]&quot;;
        assertThat(plan, isPlan(expectedPlan));
    }

    @Test
    public void test_collect_execution_plan_is_narrowed_to_matching_generated_partition_columns() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addPartitionedTable(
                &quot;create table doc.parted_by_generated (&quot; +
                &quot;   ts timestamp without time zone, &quot; +
                &quot;   p as date_trunc('month', ts) &quot; +
                &quot;) partitioned by (p)&quot;,
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted_by_generated&quot;), singletonList(&quot;1577836800000&quot;)).asIndexName(),
                new PartitionName(new RelationName(&quot;doc&quot;, &quot;parted_by_generated&quot;), singletonList(&quot;1580515200000&quot;)).asIndexName())
            .build();

        String stmt = &quot;SELECT * FROM parted_by_generated WHERE ts &gt;= '2020-02-01'&quot;;
        LogicalPlan plan = e.logicalPlan(stmt);
        String expectedPlan =
            &quot;Collect[doc.parted_by_generated | [ts, p AS date_trunc('month', ts)] | (ts &gt;= 1580515200000::bigint)]&quot;;
        assertThat(plan, isPlan(expectedPlan));

        Collect collect = (Collect) ((Merge) e.plan(stmt)).subPlan();;
        RoutedCollectPhase routedCollectPhase = (RoutedCollectPhase) collect.collectPhase();
        Symbol where = routedCollectPhase.where();
<A NAME="1"></A>        assertThat(where, TestingHelpers.isSQL(&quot;(doc.parted_by_generated.ts &gt;= 1580515200000::bigint)&quot;));
        assertThat(routedCollectPhase.routing().locations().values().stream()
            .flatMap(x -&gt; x.keySet().stream())
            .collect(<FONT color="#f63526"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2358194-0.html#1',2,'match2358194-top.html#1',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>Collectors.toSet()),
            contains(
                &quot;.partitioned.parted_by_generated.04732d9o60qj2d9i60o30c1g&quot;
            )
        );
    }

    @Test
    public void test_select_where_id_and_seq_missing_primary_term() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        assertThrowsMatches(
            () -&gt; e.plan(&quot;select id from users where id = 1 and _seq_no = 11&quot;),
            VersioningValidationException.class,
            VersioningValidationException.SEQ_NO_AND_PRIMARY_TERM_USAGE_MSG
        );
    }

    @Test
    public void test_select_where_seq_and_primary_term_missing_id() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        assertThrowsMatches</B></FONT>(
            () -&gt; e.plan(&quot;select id from users where _seq_no = 11 and _primary_term = 1&quot;),
            VersioningValidationException.class,
            VersioningValidationException.SEQ_NO_AND_PRIMARY_TERM_USAGE_MSG
        );
    }


    @Test
    public void test_filter_and_eval_on_get_operator_use_shard_projections() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService, 2, RandomizedTest.getRandom(), List.of())
            .addTable(TableDefinitions.USER_TABLE_DEFINITION)
            .build();

        Merge merge = e.plan(&quot;&quot;&quot;
            SELECT count(*) FROM (
                SELECT
                    name
                FROM
                    users
                WHERE
                    id = 10 AND (name = 'bar' or name IS NULL)
                ) u
        &quot;&quot;&quot;);
        Collect collect = (Collect) merge.subPlan();
        var pkLookup = (PKLookupPhase) collect.collectPhase();
        assertThat(pkLookup.projections(), Matchers.contains(
            Matchers.instanceOf(FilterProjection.class),
            Matchers.instanceOf(EvalProjection.class),
            Matchers.instanceOf(AggregationProjection.class)
        ));
        for (var projection : pkLookup.projections()) {
            assertThat(projection.requiredGranularity(), is(RowGranularity.SHARD));
        }
    }

    @Test
    public void test_queries_in_count_operator_are_optimized() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService)
            .addTable(&quot;create table tbl (xs array(varchar(1)))&quot;)
            .build();

        CountPlan plan = e.plan(&quot;select count(*) from tbl where 'a' = ANY(xs)&quot;);
        assertThat(plan.countPhase().where(), isSQL(&quot;(_cast('a', 'text(1)') = ANY(doc.tbl.xs))&quot;));
    }

    @Test
    public void test_collect_phase_narrows_shard_selection_based_on_clustered_by_columns() throws Exception {
        SQLExecutor e = SQLExecutor.builder(clusterService)
            .addTable(&quot;create table tbl (x int, y int) clustered by (x) into 2 shards&quot;)
            .build();

        Collect collect = e.plan(&quot;select * from tbl where x = 1&quot;);
        RoutedCollectPhase routedCollectPhase = (RoutedCollectPhase )collect.collectPhase();

        int numShards = routedCollectPhase.routing().locations().values().stream()
            .flatMap(x -&gt; x.values().stream())
            .mapToInt(x -&gt; x.size())
            .sum();
        assertThat(numShards, is(1));
    }
}
</PRE>
</div>
  </div>
</body>
</html>
