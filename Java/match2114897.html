<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for SrvUnicastHostsProvider.java & PrimaryTermsTests.java</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for SrvUnicastHostsProvider.java & PrimaryTermsTests.java
      </h3>
      <h1 align="center">
        10.4%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>SrvUnicastHostsProvider.java (11.721612%)<TH>PrimaryTermsTests.java (9.411765%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match2114897-0.html#0',2,'match2114897-1.html#0',3)" NAME="0">(22-46)<TD><A HREF="javascript:ZweiFrames('match2114897-0.html#0',2,'match2114897-1.html#0',3)" NAME="0">(20-45)</A><TD ALIGN=center><FONT COLOR="#ff0000">23</FONT>
<TR><TD BGCOLOR="#f63526"><FONT COLOR="#f63526">-</FONT><TD><A HREF="javascript:ZweiFrames('match2114897-0.html#1',2,'match2114897-1.html#1',3)" NAME="1">(173-179)<TD><A HREF="javascript:ZweiFrames('match2114897-0.html#1',2,'match2114897-1.html#1',3)" NAME="1">(113-117)</A><TD ALIGN=center><FONT COLOR="#630000">9</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>SrvUnicastHostsProvider.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Crate.io GmbH (&quot;Crate&quot;) under one or more contributor
 * license agreements.  See the NOTICE file distributed with this work for
 * additional information regarding copyright ownership.  Crate licenses
 * this file to you under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.  You may
 * obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
 * License for the specific language governing permissions and limitations
 * under the License.
 *
 * However, if you have executed another commercial license agreement
 * with Crate these terms will supersede the license and you may use the
<A NAME="0"></A> * software solely pursuant to the terms of the relevant commercial agreement.
 */

<FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match2114897-1.html#0',3,'match2114897-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>package io.crate.discovery;

import io.netty.buffer.ByteBuf;
import io.netty.channel.EventLoopGroup;
import io.netty.channel.nio.NioEventLoopGroup;
import io.netty.channel.socket.nio.NioDatagramChannel;
import io.netty.handler.codec.dns.DefaultDnsQuestion;
import io.netty.handler.codec.dns.DefaultDnsRawRecord;
import io.netty.handler.codec.dns.DefaultDnsRecordDecoder;
import io.netty.handler.codec.dns.DnsRecord;
import io.netty.handler.codec.dns.DnsRecordType;
import io.netty.resolver.dns.DnsNameResolver;
import io.netty.resolver.dns.DnsNameResolverBuilder;
import io.netty.resolver.dns.SingletonDnsServerAddressStreamProvider;
import io.netty.util.ReferenceCounted;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.elasticsearch.common.Strings;
import org.elasticsearch.common.inject.Inject;
import org.elasticsearch.common.inject.Singleton;
import org.elasticsearch.common.settings.Setting;
import org.elasticsearch.common.settings.Settings;
import org.elasticsearch.common.transport.TransportAddress;
import</B></FONT> io.crate.common.unit.TimeValue;
import org.elasticsearch.discovery.SeedHostsProvider;
import org.elasticsearch.transport.TransportService;

import java.net.InetSocketAddress;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;

import static org.elasticsearch.common.util.concurrent.EsExecutors.daemonThreadFactory;

@Singleton
public class SrvUnicastHostsProvider implements AutoCloseable, SeedHostsProvider {

    private static final Logger LOGGER = LogManager.getLogger(SrvUnicastHostsProvider.class);

    public static final Setting&lt;String&gt; DISCOVERY_SRV_QUERY = Setting.simpleString(
        &quot;discovery.srv.query&quot;, Setting.Property.NodeScope);
    public static final Setting&lt;String&gt; DISCOVERY_SRV_RESOLVER = Setting.simpleString(
        &quot;discovery.srv.resolver&quot;, Setting.Property.NodeScope);
    private static final Setting&lt;TimeValue&gt; DISCOVERY_SRV_RESOLVE_TIMEOUT =
        Setting.positiveTimeSetting(&quot;discovery.srv.resolve_timeout&quot;, TimeValue.timeValueSeconds(5), Setting.Property.NodeScope);

    private final TransportService transportService;
    private final String query;
    private final TimeValue resolveTimeout;
    private final DnsNameResolver resolver;
    private final EventLoopGroup eventLoopGroup;

    @Inject
    public SrvUnicastHostsProvider(Settings settings, TransportService transportService) {
        this.transportService = transportService;
        this.query = DISCOVERY_SRV_QUERY.get(settings);
        this.resolveTimeout = DISCOVERY_SRV_RESOLVE_TIMEOUT.get(settings);

        eventLoopGroup = new NioEventLoopGroup(1, daemonThreadFactory(settings, &quot;netty-dns-resolver&quot;));
        resolver = buildResolver(settings);
    }

    EventLoopGroup eventLoopGroup() {
        return eventLoopGroup;
    }

    InetSocketAddress parseResolverAddress(Settings settings) {
        String hostname;
        int port = 53;
        String resolverAddress = DISCOVERY_SRV_RESOLVER.get(settings);
        if (!Strings.isNullOrEmpty(resolverAddress)) {
            String[] parts = resolverAddress.split(&quot;:&quot;);
            if (parts.length &gt; 0) {
                hostname = parts[0];
                if (parts.length &gt; 1) {
                    try {
                        port = Integer.parseInt(parts[1]);
                    } catch (Exception e) {
                        LOGGER.warn(&quot;Resolver port '{}' is not an integer. Using default port 53&quot;, parts[1]);
                    }
                }
                try {
                    return new InetSocketAddress(hostname, port);
                } catch (IllegalArgumentException e) {
                    LOGGER.warn(&quot;Resolver port '{}' is out of range. Using default port 53&quot;, parts[1]);
                    return new InetSocketAddress(hostname, 53);
                }
            }
        }
        return null;
    }

    private DnsNameResolver buildResolver(Settings settings) {
        DnsNameResolverBuilder resolverBuilder = new DnsNameResolverBuilder(eventLoopGroup.next());
        resolverBuilder.channelType(NioDatagramChannel.class);

        InetSocketAddress resolverAddress = parseResolverAddress(settings);
        if (resolverAddress != null) {
            try {
                resolverBuilder.nameServerProvider(new SingletonDnsServerAddressStreamProvider(resolverAddress));
            } catch (IllegalArgumentException e) {
                LOGGER.warn(&quot;Could not create custom dns resolver. Using default resolver.&quot;, e);
            }
        }
        return resolverBuilder.build();
    }

    @Override
    public List&lt;TransportAddress&gt; getSeedAddresses(HostsResolver hostsResolver) {
        if (query == null) {
            LOGGER.error(&quot;DNS query must not be null. Please set '{}'&quot;, DISCOVERY_SRV_QUERY);
            return Collections.emptyList();
        }
        try {
            List&lt;DnsRecord&gt; records = lookupRecords();
            try {
                LOGGER.trace(&quot;Building dynamic unicast discovery nodes...&quot;);
                if (records == null || records.size() == 0) {
                    LOGGER.debug(&quot;No nodes found&quot;);
                } else {
                    List&lt;TransportAddress&gt; transportAddresses = parseRecords(records);
                    LOGGER.info(&quot;Using dynamic nodes {}&quot;, transportAddresses);
                    return transportAddresses;
                }
            } finally {
                for (var record : records) {
                    if (record instanceof ReferenceCounted) {
                        ((ReferenceCounted) record).release();
                    }
                }
            }
        } catch (InterruptedException | ExecutionException | TimeoutException e) {
            LOGGER.error(&quot;DNS lookup exception:&quot;, e);
        }
        return Collections.emptyList();
    }

    private List&lt;DnsRecord&gt; lookupRecords() throws InterruptedException, ExecutionException, TimeoutException {
        return resolver.resolveAll(new DefaultDnsQuestion(query, DnsRecordType.SRV), Collections.emptyList())
            .get(resolveTimeout.getMillis(), TimeUnit.MILLISECONDS);
    }

    List&lt;TransportAddress&gt; parseRecords(List&lt;DnsRecord&gt; records) {
        List&lt;TransportAddress&gt; addresses = new ArrayList&lt;&gt;(records.size());
<A NAME="1"></A>        for (DnsRecord record : records) {
            if (record instanceof DefaultDnsRawRecord) {
                DefaultDnsRawRecord rawRecord = (DefaultDnsRawRecord) record;
                <FONT color="#f63526"><A HREF="javascript:ZweiFrames('match2114897-1.html#1',3,'match2114897-top.html#1',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>ByteBuf content = rawRecord.content();
                // first is &quot;priority&quot;, we don't use it
                content.readUnsignedShort();
                // second is &quot;weight&quot;, we don't use it
                content.readUnsignedShort();
                int port = content.readUnsignedShort();
                String hostname = DefaultDnsRecordDecoder.decodeName</B></FONT>(content).replaceFirst(&quot;\\.$&quot;, &quot;&quot;);
                String address = hostname + &quot;:&quot; + port;
                try {
                    for (TransportAddress transportAddress : transportService.addressesFromString(address)) {
                        if (LOGGER.isTraceEnabled()) {
                            LOGGER.trace(&quot;adding {}, transport_address {}&quot;, address, transportAddress);
                        }
                        addresses.add(transportAddress);
                    }
                } catch (Exception e) {
                    LOGGER.warn(&quot;failed to add &quot; + address, e);
                }
            }
        }
        return addresses;
    }

    @Override
    public void close() {
        resolver.close();
    }

}
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>PrimaryTermsTests.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the &quot;License&quot;); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
<A NAME="0"></A> * under the License.
 */

<FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2114897-0.html#0',2,'match2114897-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>package org.elasticsearch.cluster.routing;

import org.elasticsearch.Version;
import org.elasticsearch.cluster.ClusterState;
import org.elasticsearch.cluster.ESAllocationTestCase;
import org.elasticsearch.cluster.health.ClusterStateHealth;
import org.elasticsearch.cluster.metadata.IndexMetadata;
import org.elasticsearch.cluster.metadata.Metadata;
import org.elasticsearch.cluster.node.DiscoveryNodes;
import org.elasticsearch.cluster.node.DiscoveryNodes.Builder;
import org.elasticsearch.cluster.routing.allocation.AllocationService;
import org.elasticsearch.cluster.routing.allocation.FailedShard;
import org.elasticsearch.common.settings.Settings;

import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.UUID;

import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
import static org.hamcrest.Matchers.equalTo;
import</B></FONT> static org.hamcrest.Matchers.not;

public class PrimaryTermsTests extends ESAllocationTestCase {

    private static final String TEST_INDEX_1 = &quot;test1&quot;;
    private static final String TEST_INDEX_2 = &quot;test2&quot;;
    private int numberOfShards;
    private int numberOfReplicas;
    private AllocationService allocationService;
    private ClusterState clusterState;

    private final Map&lt;String, long[]&gt; primaryTermsPerIndex = new HashMap&lt;&gt;();

    @Override
    public void setUp() throws Exception {
        super.setUp();
        this.allocationService = createAllocationService(Settings.builder()
                                                             .put(&quot;cluster.routing.allocation.node_concurrent_recoveries&quot;, Integer.MAX_VALUE) // don't limit recoveries
                                                             .put(&quot;cluster.routing.allocation.node_initial_primaries_recoveries&quot;, Integer.MAX_VALUE)
                                                             .build());
        this.numberOfShards = randomIntBetween(1, 5);
        this.numberOfReplicas = randomIntBetween(0, 5);
        logger.info(&quot;Setup test with {} shards and {} replicas.&quot;, this.numberOfShards, this.numberOfReplicas);
        this.primaryTermsPerIndex.clear();
        Metadata metadata = Metadata.builder()
            .put(createIndexMetadata(TEST_INDEX_1))
            .put(createIndexMetadata(TEST_INDEX_2))
            .build();

        RoutingTable routingTable = new RoutingTable.Builder()
            .add(new IndexRoutingTable.Builder(metadata.index(TEST_INDEX_1).getIndex()).initializeAsNew(metadata.index(TEST_INDEX_1))
                     .build())
            .add(new IndexRoutingTable.Builder(metadata.index(TEST_INDEX_2).getIndex()).initializeAsNew(metadata.index(TEST_INDEX_2))
                     .build())
            .build();

        this.clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY))
            .metadata(metadata).routingTable(routingTable).build();
    }

    /**
     * puts primary shard indexRoutings into initializing state
     */
    private void initPrimaries() {
        logger.info(&quot;adding {} nodes and performing rerouting&quot;, this.numberOfReplicas + 1);
        Builder discoBuilder = DiscoveryNodes.builder();
        for (int i = 0; i &lt; this.numberOfReplicas + 1; i++) {
            discoBuilder = discoBuilder.add(newNode(&quot;node&quot; + i));
        }
        this.clusterState = ClusterState.builder(clusterState).nodes(discoBuilder).build();
        ClusterState rerouteResult = allocationService.reroute(clusterState, &quot;reroute&quot;);
        assertThat(rerouteResult, not(equalTo(this.clusterState)));
        applyRerouteResult(rerouteResult);
        primaryTermsPerIndex.keySet().forEach(this::incrementPrimaryTerm);
    }

    private void incrementPrimaryTerm(String index) {
        final long[] primaryTerms = primaryTermsPerIndex.get(index);
        for (int i = 0; i &lt; primaryTerms.length; i++) {
            primaryTerms[i]++;
        }
    }

    private void incrementPrimaryTerm(String index, int shard) {
        primaryTermsPerIndex.get(index)[shard]++;
<A NAME="1"></A>    }

    private boolean startInitializingShards(String index) {
        <FONT color="#f63526"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2114897-0.html#1',2,'match2114897-top.html#1',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>final List&lt;ShardRouting&gt; startedShards = clusterState.getRoutingNodes().shardsWithState(index, INITIALIZING);
        logger.info(&quot;start primary shards for index [{}]: {} &quot;, index, startedShards);
        ClusterState rerouteResult = startShardsAndReroute(allocationService, clusterState, startedShards);
        boolean changed = rerouteResult.equals(clusterState) == false;
        applyRerouteResult</B></FONT>(rerouteResult);
        return changed;
    }

    private void applyRerouteResult(ClusterState newClusterState) {
        ClusterState previousClusterState = this.clusterState;
        ClusterState.Builder builder = ClusterState.builder(newClusterState).incrementVersion();
        if (previousClusterState.routingTable() != newClusterState.routingTable()) {
            builder.routingTable(RoutingTable.builder(newClusterState.routingTable()).version(newClusterState.routingTable().version() + 1)
                                     .build());
        }
        if (previousClusterState.metadata() != newClusterState.metadata()) {
            builder.metadata(Metadata.builder(newClusterState.metadata()).version(newClusterState.metadata().version() + 1));
        }
        this.clusterState = builder.build();
        final ClusterStateHealth clusterHealth = new ClusterStateHealth(clusterState);
        logger.info(&quot;applied reroute. active shards: p [{}], t [{}], init shards: [{}], relocating: [{}]&quot;,
                    clusterHealth.getActivePrimaryShards(), clusterHealth.getActiveShards(),
                    clusterHealth.getInitializingShards(), clusterHealth.getRelocatingShards());
    }

    private void failSomePrimaries(String index) {
        final IndexRoutingTable indexShardRoutingTable = clusterState.routingTable().index(index);
        Set&lt;Integer&gt; shardIdsToFail = new HashSet&lt;&gt;();
        for (int i = 1 + randomInt(numberOfShards - 1); i &gt; 0; i--) {
            shardIdsToFail.add(randomInt(numberOfShards - 1));
        }
        logger.info(&quot;failing primary shards {} for index [{}]&quot;, shardIdsToFail, index);
        List&lt;FailedShard&gt; failedShards = new ArrayList&lt;&gt;();
        for (int shard : shardIdsToFail) {
            failedShards.add(new FailedShard(indexShardRoutingTable.shard(shard).primaryShard(), &quot;test&quot;, null, randomBoolean()));
            incrementPrimaryTerm(index, shard); // the primary failure should increment the primary term;
        }
        applyRerouteResult(allocationService.applyFailedShards(this.clusterState, failedShards,Collections.emptyList()));
    }

    private void addNodes() {
        DiscoveryNodes.Builder nodesBuilder = DiscoveryNodes.builder(clusterState.nodes());
        final int newNodes = randomInt(10);
        logger.info(&quot;adding [{}] nodes&quot;, newNodes);
        for (int i = 0; i &lt; newNodes; i++) {
            nodesBuilder.add(newNode(&quot;extra_&quot; + i));
        }
        this.clusterState = ClusterState.builder(clusterState).nodes(nodesBuilder).build();
        applyRerouteResult(allocationService.reroute(this.clusterState, &quot;nodes added&quot;));

    }

    private IndexMetadata.Builder createIndexMetadata(String indexName) {
        primaryTermsPerIndex.put(indexName, new long[numberOfShards]);
        Settings settings = Settings.builder()
            .put(IndexMetadata.SETTING_VERSION_CREATED, Version.CURRENT)
            .put(IndexMetadata.SETTING_INDEX_UUID, UUID.randomUUID().toString())
            .build();
        final IndexMetadata.Builder builder = new IndexMetadata.Builder(indexName)
            .settings(settings)
            .numberOfReplicas(this.numberOfReplicas)
            .numberOfShards(this.numberOfShards);
        for (int i = 0; i &lt; numberOfShards; i++) {
            builder.primaryTerm(i, randomInt(200));
            primaryTermsPerIndex.get(indexName)[i] = builder.primaryTerm(i);
        }
        return builder;
    }

    private void assertAllPrimaryTerm() {
        primaryTermsPerIndex.keySet().forEach(this::assertPrimaryTerm);
    }

    private void assertPrimaryTerm(String index) {
        final long[] terms = primaryTermsPerIndex.get(index);
        final IndexMetadata indexMetadata = clusterState.metadata().index(index);
        for (IndexShardRoutingTable shardRoutingTable : this.clusterState.routingTable().index(index)) {
            final int shard = shardRoutingTable.shardId().id();
            assertThat(&quot;primary term mismatch between indexMetadata of [&quot; + index + &quot;] and shard [&quot; + shard + &quot;]'s routing&quot;,
                       indexMetadata.primaryTerm(shard), equalTo(terms[shard]));
        }
    }

    public void testPrimaryTermMetadataSync() {
        assertAllPrimaryTerm();

        initPrimaries();
        assertAllPrimaryTerm();

        startInitializingShards(TEST_INDEX_1);
        assertAllPrimaryTerm();

        startInitializingShards(TEST_INDEX_2);
        assertAllPrimaryTerm();

        // now start all replicas too
        startInitializingShards(TEST_INDEX_1);
        startInitializingShards(TEST_INDEX_2);
        assertAllPrimaryTerm();

        // relocations shouldn't change much
        addNodes();
        assertAllPrimaryTerm();
        boolean changed = true;
        while (changed) {
            changed = startInitializingShards(TEST_INDEX_1);
            assertAllPrimaryTerm();
            changed |= startInitializingShards(TEST_INDEX_2);
            assertAllPrimaryTerm();
        }

        // primary promotion
        failSomePrimaries(TEST_INDEX_1);
        assertAllPrimaryTerm();

        // stablize cluster
        changed = true;
        while (changed) {
            changed = startInitializingShards(TEST_INDEX_1);
            assertAllPrimaryTerm();
            changed |= startInitializingShards(TEST_INDEX_2);
            assertAllPrimaryTerm();
        }
    }
}
</PRE>
</div>
  </div>
</body>
</html>
