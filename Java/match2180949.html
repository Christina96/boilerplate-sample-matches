<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML><HEAD><TITLE>Matches for NetworkDisruption.java & InsertFromValues.java</TITLE>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<body>
  <div style="align-items: center; display: flex; justify-content: space-around;">
    <div>
      <h3 align="center">
Matches for NetworkDisruption.java & InsertFromValues.java
      </h3>
      <h1 align="center">
        10.1%
      </h1>
      <center>
        <a href="index.html" target="_top">
          INDEX
        </a>
        <span>-</span>
        <a href="help-en.html" target="_top">
          HELP
        </a>
      </center>
    </div>
    <div>
<TABLE BORDER="1" CELLSPACING="0" BGCOLOR="#d0d0d0">
<TR><TH><TH>NetworkDisruption.java (14.048338%)<TH>InsertFromValues.java (7.9965606%)<TH>Tokens
<TR><TD BGCOLOR="#0000ff"><FONT COLOR="#0000ff">-</FONT><TD><A HREF="javascript:ZweiFrames('match2180949-0.html#0',2,'match2180949-1.html#0',3)" NAME="0">(22-50)<TD><A HREF="javascript:ZweiFrames('match2180949-0.html#0',2,'match2180949-1.html#0',3)" NAME="0">(94-117)</A><TD ALIGN=center><FONT COLOR="#ff0000">21</FONT>
<TR><TD BGCOLOR="#f63526"><FONT COLOR="#f63526">-</FONT><TD><A HREF="javascript:ZweiFrames('match2180949-0.html#1',2,'match2180949-1.html#1',3)" NAME="1">(496-507)<TD><A HREF="javascript:ZweiFrames('match2180949-0.html#1',2,'match2180949-1.html#1',3)" NAME="1">(846-857)</A><TD ALIGN=center><FONT COLOR="#b60000">15</FONT>
<TR><TD BGCOLOR="#980517"><FONT COLOR="#980517">-</FONT><TD><A HREF="javascript:ZweiFrames('match2180949-0.html#2',2,'match2180949-1.html#2',3)" NAME="2">(378-383)<TD><A HREF="javascript:ZweiFrames('match2180949-0.html#2',2,'match2180949-1.html#2',3)" NAME="2">(837-842)</A><TD ALIGN=center><FONT COLOR="#790000">10</FONT>
<TR><TD BGCOLOR="#53858b"><FONT COLOR="#53858b">-</FONT><TD><A HREF="javascript:ZweiFrames('match2180949-0.html#3',2,'match2180949-1.html#3',3)" NAME="3">(173-180)<TD><A HREF="javascript:ZweiFrames('match2180949-0.html#3',2,'match2180949-1.html#3',3)" NAME="3">(817-824)</A><TD ALIGN=center><FONT COLOR="#790000">10</FONT>
<TR><TD BGCOLOR="#6cc417"><FONT COLOR="#6cc417">-</FONT><TD><A HREF="javascript:ZweiFrames('match2180949-0.html#4',2,'match2180949-1.html#4',3)" NAME="4">(56-63)<TD><A HREF="javascript:ZweiFrames('match2180949-0.html#4',2,'match2180949-1.html#4',3)" NAME="4">(118-126)</A><TD ALIGN=center><FONT COLOR="#790000">10</FONT>
<TR><TD BGCOLOR="#151b8d"><FONT COLOR="#151b8d">-</FONT><TD><A HREF="javascript:ZweiFrames('match2180949-0.html#5',2,'match2180949-1.html#5',3)" NAME="5">(477-488)<TD><A HREF="javascript:ZweiFrames('match2180949-0.html#5',2,'match2180949-1.html#5',3)" NAME="5">(732-736)</A><TD ALIGN=center><FONT COLOR="#6d0000">9</FONT>
<TR><TD BGCOLOR="#8c8774"><FONT COLOR="#8c8774">-</FONT><TD><A HREF="javascript:ZweiFrames('match2180949-0.html#6',2,'match2180949-1.html#6',3)" NAME="6">(250-254)<TD><A HREF="javascript:ZweiFrames('match2180949-0.html#6',2,'match2180949-1.html#6',3)" NAME="6">(656-660)</A><TD ALIGN=center><FONT COLOR="#6d0000">9</FONT>
<TR><TD BGCOLOR="#38a4a5"><FONT COLOR="#38a4a5">-</FONT><TD><A HREF="javascript:ZweiFrames('match2180949-0.html#7',2,'match2180949-1.html#7',3)" NAME="7">(180-186)<TD><A HREF="javascript:ZweiFrames('match2180949-0.html#7',2,'match2180949-1.html#7',3)" NAME="7">(825-831)</A><TD ALIGN=center><FONT COLOR="#6d0000">9</FONT>
</TABLE>
    </div>
  </div>
  <hr>
  <div style="display: flex;">
<div style="flex-grow: 1;">
<h3>
<center>
<span>NetworkDisruption.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the &quot;License&quot;); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
<A NAME="0"></A>
package org.elasticsearch.test.disruption;

<FONT color="#0000ff"><A HREF="javascript:ZweiFrames('match2180949-1.html#0',3,'match2180949-top.html#0',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>import com.carrotsearch.randomizedtesting.generators.RandomPicks;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.elasticsearch.cluster.ClusterState;
import org.elasticsearch.cluster.NodeConnectionsService;
import org.elasticsearch.cluster.service.ClusterService;
import io.crate.common.unit.TimeValue;
import io.crate.common.collections.Sets;
import org.elasticsearch.test.InternalTestCluster;
import org.elasticsearch.test.transport.MockTransportService;
import org.elasticsearch.transport.ConnectTransportException;
import org.elasticsearch.transport.TransportService;

import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.Random;
import java.util.Set;
import java.util.concurrent.CountDownLatch;
import java.util.function.BiConsumer;

/**
 * Network disruptions are modeled using two components:
 * 1) the {@link DisruptedLinks} represents the links in the network that are to be disrupted
 * 2) the {@link NetworkLinkDisruptionType} represents the failure mode that is to be applied to the links
 */
public class NetworkDisruption implements ServiceDisruptionScheme {

    private final Logger logger = LogManager.getLogger(NetworkDisruption.class)</B></FONT>;

    private final DisruptedLinks disruptedLinks;
<A NAME="4"></A>    private final NetworkLinkDisruptionType networkLinkDisruptionType;

    protected volatile InternalTestCluster cluster;
    <FONT color="#6cc417"><A HREF="javascript:ZweiFrames('match2180949-1.html#4',3,'match2180949-top.html#4',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>protected volatile boolean activeDisruption = false;

    public NetworkDisruption(DisruptedLinks disruptedLinks, NetworkLinkDisruptionType networkLinkDisruptionType) {
        this.disruptedLinks = disruptedLinks;
        this.networkLinkDisruptionType = networkLinkDisruptionType;
    }

    public DisruptedL</B></FONT>inks getDisruptedLinks() {
        return disruptedLinks;
    }

    public NetworkLinkDisruptionType getNetworkLinkDisruptionType() {
        return networkLinkDisruptionType;
    }

    @Override
    public void applyToCluster(InternalTestCluster cluster) {
        this.cluster = cluster;
    }

    @Override
    public void removeFromCluster(InternalTestCluster cluster) {
        stopDisrupting();
    }

    @Override
    public void removeAndEnsureHealthy(InternalTestCluster cluster) {
        removeFromCluster(cluster);
        ensureHealthy(cluster);
    }

    /**
     * ensures the cluster is healthy after the disruption
     */
    public void ensureHealthy(InternalTestCluster cluster) {
        assert activeDisruption == false;
        ensureNodeCount(cluster);
        ensureFullyConnectedCluster(cluster);
    }

    /**
     * Ensures that all nodes in the cluster are connected to each other.
     *
     * Some network disruptions may leave nodes that are not the master disconnected from each other.
     * {@link org.elasticsearch.cluster.NodeConnectionsService} will eventually reconnect but it's
     * handy to be able to ensure this happens faster
     */
    public static void ensureFullyConnectedCluster(InternalTestCluster cluster) {
        final String[] nodeNames = cluster.getNodeNames();
        final CountDownLatch countDownLatch = new CountDownLatch(nodeNames.length);
        for (String node : nodeNames) {
            ClusterState stateOnNode = cluster.getInstance(ClusterService.class, node).state();
            cluster.getInstance(NodeConnectionsService.class, node).reconnectToNodes(stateOnNode.nodes(), countDownLatch::countDown);
        }

        try {
            countDownLatch.await();
        } catch (InterruptedException e) {
            throw new AssertionError(e);
        }
    }

    protected void ensureNodeCount(InternalTestCluster cluster) {
        cluster.validateClusterFormed();
    }

    @Override
    public synchronized void applyToNode(String node, InternalTestCluster cluster) {

    }

    @Override
    public synchronized void removeFromNode(String node1, InternalTestCluster cluster) {
        logger.info(&quot;stop disrupting node (disruption type: {}, disrupted links: {})&quot;, networkLinkDisruptionType, disruptedLinks);
        applyToNodes(new String[]{ node1 }, cluster.getNodeNames(), networkLinkDisruptionType::removeDisruption);
        applyToNodes(cluster.getNodeNames(), new String[]{ node1 }, networkLinkDisruptionType::removeDisruption);
    }

    @Override
    public synchronized void testClusterClosed() {

    }

    @Override
    public synchronized void startDisrupting() {
        logger.info(&quot;start disrupting (disruption type: {}, disrupted links: {})&quot;, networkLinkDisruptionType, disruptedLinks);
        applyToNodes(cluster.getNodeNames(), cluster.getNodeNames(), networkLinkDisruptionType::applyDisruption);
        activeDisruption = true;
    }

    @Override
    public synchronized void stopDisrupting() {
        if (!activeDisruption) {
            return;
        }
        logger.info(&quot;stop disrupting (disruption scheme: {}, disrupted links: {})&quot;, networkLinkDisruptionType, disruptedLinks);
        applyToNodes(cluster.getNodeNames(), cluster.getNodeNames(), networkLinkDisruptionType::removeDisruption);
        activeDisruption = false;
    }

    /**
     * Applies action to all disrupted links between two sets of nodes.
     */
    private void applyToNodes(String[] nodes1, String[] nodes2, BiConsumer&lt;MockTransportService, MockTransportService&gt; consumer) {
        for (String node1 : nodes1) {
            if (disruptedLinks.nodes().contains(node1)) {
                for (String node2 : nodes2) {
                    if (disruptedLinks.nodes().contains(node2)) {
                        if (node1.equals(node2) == false) {
                            if (disruptedLinks.disrupt(node1, node2)) {
                                consumer.accept(transport(node1), transport(node2));
                            }
                        }
                    }
<A NAME="3"></A>                }
            }
        }
    <FONT color="#53858b"><A HREF="javascript:ZweiFrames('match2180949-1.html#3',3,'match2180949-top.html#3',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>}

    @Override
    public TimeValue expectedTimeToHeal() {
<A NAME="7"></A>        return networkLinkDisruptionType.expectedTimeToHeal();
    }

    private M</B></FONT>ockTransportService transport(String node) <FONT color="#38a4a5"><A HREF="javascript:ZweiFrames('match2180949-1.html#7',3,'match2180949-top.html#7',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>{
        return (MockTransportService) cluster.getInstance(TransportService.class, node);
    }

    @Override
    public String toString() {
        return</B></FONT> &quot;network disruption (disruption type: &quot; + networkLinkDisruptionType + &quot;, disrupted links: &quot; + disruptedLinks + &quot;)&quot;;
    }

    /**
     * Represents a set of nodes with connections between nodes that are to be disrupted
     */
    public abstract static class DisruptedLinks {
        private final Set&lt;String&gt; nodes;

        protected DisruptedLinks(Set&lt;String&gt;... nodeSets) {
            Set&lt;String&gt; allNodes = new HashSet&lt;&gt;();
            for (Set&lt;String&gt; nodeSet : nodeSets) {
                allNodes.addAll(nodeSet);
            }
            this.nodes = allNodes;
        }

        /**
         * Set of all nodes that can participate in disruptions
         */
        public Set&lt;String&gt; nodes() {
            return nodes;
        }

        /**
         * Returns true iff network should be disrupted between the two nodes
         */
        public abstract boolean disrupt(String node1, String node2);
    }

    /**
     * Creates two partitions with symmetric failures
     */
    public static class TwoPartitions extends DisruptedLinks {

        protected final Set&lt;String&gt; nodesSideOne;
        protected final Set&lt;String&gt; nodesSideTwo;

        public TwoPartitions(String node1, String node2) {
            this(Collections.singleton(node1), Collections.singleton(node2));
        }

        public TwoPartitions(Set&lt;String&gt; nodesSideOne, Set&lt;String&gt; nodesSideTwo) {
            super(nodesSideOne, nodesSideTwo);
            this.nodesSideOne = nodesSideOne;
            this.nodesSideTwo = nodesSideTwo;
            assert nodesSideOne.isEmpty() == false;
            assert nodesSideTwo.isEmpty() == false;
            assert Sets.haveEmptyIntersection(nodesSideOne, nodesSideTwo);
        }

        public static TwoPartitions random(Random random, String... nodes) {
            return random(random, Set.of(nodes));
        }

        public static TwoPartitions random(Random random, Set&lt;String&gt; nodes) {
            assert nodes.size() &gt;= 2 : &quot;two partitions topology requires at least 2 nodes&quot;;
            Set&lt;String&gt; nodesSideOne = new HashSet&lt;&gt;();
            Set&lt;String&gt; nodesSideTwo = new HashSet&lt;&gt;();
            for (String node : nodes) {
                if (nodesSideOne.isEmpty()) {
<A NAME="6"></A>                    nodesSideOne.add(node);
                } else if (nodesSideTwo.isEmpty()) {
                    nodesSideTwo.add(node);
                } else if (<FONT color="#8c8774"><A HREF="javascript:ZweiFrames('match2180949-1.html#6',3,'match2180949-top.html#6',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>random.nextBoolean()) {
                    nodesSideOne.add(node);
                } else {
                    nodesSideTwo.add(node);
                }</B></FONT>
            }
            return new TwoPartitions(nodesSideOne, nodesSideTwo);
        }

        @Override
        public boolean disrupt(String node1, String node2) {
            if (nodesSideOne.contains(node1) &amp;&amp; nodesSideTwo.contains(node2)) {
                return true;
            }
            if (nodesSideOne.contains(node2) &amp;&amp; nodesSideTwo.contains(node1)) {
                return true;
            }
            return false;
        }

        public Set&lt;String&gt; getNodesSideOne() {
            return Collections.unmodifiableSet(nodesSideOne);
        }

        public Set&lt;String&gt; getNodesSideTwo() {
            return Collections.unmodifiableSet(nodesSideTwo);
        }

        public Collection&lt;String&gt; getMajoritySide() {
            if (nodesSideOne.size() &gt;= nodesSideTwo.size()) {
                return getNodesSideOne();
            } else {
                return getNodesSideTwo();
            }
        }

        public Collection&lt;String&gt; getMinoritySide() {
            if (nodesSideOne.size() &gt;= nodesSideTwo.size()) {
                return getNodesSideTwo();
            } else {
                return getNodesSideOne();
            }
        }

        @Override
        public String toString() {
            return &quot;two partitions (partition 1: &quot; + nodesSideOne + &quot; and partition 2: &quot; + nodesSideTwo + &quot;)&quot;;
        }
    }

    /**
     * Creates two partitions with symmetric failures and a bridge node that can connect to both of the partitions
     */
    public static class Bridge extends DisruptedLinks {

        private final String bridgeNode;
        private final Set&lt;String&gt; nodesSideOne;
        private final Set&lt;String&gt; nodesSideTwo;

        public Bridge(String bridgeNode, Set&lt;String&gt; nodesSideOne, Set&lt;String&gt; nodesSideTwo) {
            super(Collections.singleton(bridgeNode), nodesSideOne, nodesSideTwo);
            this.bridgeNode = bridgeNode;
            this.nodesSideOne = nodesSideOne;
            this.nodesSideTwo = nodesSideTwo;
            assert nodesSideOne.isEmpty() == false;
            assert nodesSideTwo.isEmpty() == false;
            assert Sets.haveEmptyIntersection(nodesSideOne, nodesSideTwo);
            assert nodesSideOne.contains(bridgeNode) == false &amp;&amp; nodesSideTwo.contains(bridgeNode) == false;
        }

        public static Bridge random(Random random, String... nodes) {
            return random(random, Set.of(nodes));
        }

        public static Bridge random(Random random, Set&lt;String&gt; nodes) {
            assert nodes.size() &gt;= 3 : &quot;bridge topology requires at least 3 nodes&quot;;
            String bridgeNode = RandomPicks.randomFrom(random, nodes);
            Set&lt;String&gt; nodesSideOne = new HashSet&lt;&gt;();
            Set&lt;String&gt; nodesSideTwo = new HashSet&lt;&gt;();
            for (String node : nodes) {
                if (node.equals(bridgeNode) == false) {
                    if (nodesSideOne.isEmpty()) {
                        nodesSideOne.add(node);
                    } else if (nodesSideTwo.isEmpty()) {
                        nodesSideTwo.add(node);
                    } else if (random.nextBoolean()) {
                        nodesSideOne.add(node);
                    } else {
                        nodesSideTwo.add(node);
                    }
                }
            }
            return new Bridge(bridgeNode, nodesSideOne, nodesSideTwo);
        }

        @Override
        public boolean disrupt(String node1, String node2) {
            if (nodesSideOne.contains(node1) &amp;&amp; nodesSideTwo.contains(node2)) {
                return true;
            }
            if (nodesSideOne.contains(node2) &amp;&amp; nodesSideTwo.contains(node1)) {
                return true;
            }
            return false;
        }

        public String getBridgeNode() {
            return bridgeNode;
        }

        public Set&lt;String&gt; getNodesSideOne() {
            return nodesSideOne;
        }

        public Set&lt;String&gt; getNodesSideTwo() {
            return nodesSideTwo;
        }

        public String toString() {
            return &quot;bridge partition (super connected node: [&quot; + bridgeNode + &quot;], partition 1: &quot; + nodesSideOne +
                &quot; and partition 2: &quot; + nodesSideTwo + &quot;)&quot;;
        }
    }

    public static class IsolateAllNodes extends DisruptedLinks {
<A NAME="2"></A>
        public IsolateAllNodes(Set&lt;String&gt; nodes) {
            super(nodes);
        <FONT color="#980517"><A HREF="javascript:ZweiFrames('match2180949-1.html#2',3,'match2180949-top.html#2',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>}

        @Override
        public boolean disrupt(String node1, String node2) {
            return true;
        }</B></FONT>
    }

    /**
     * Abstract class representing various types of network disruptions. Instances of this class override the {@link #applyDisruption}
     * method to apply their specific disruption type to requests that are send from a source to a target node.
     */
    public abstract static class NetworkLinkDisruptionType {

        /**
         * Applies network disruption for requests send from the node represented by the source transport service to the node represented
         * by the target transport service.
         *
         * @param sourceTransportService source transport service from which requests are sent
         * @param targetTransportService target transport service to which requests are sent
         */
        public abstract void applyDisruption(MockTransportService sourceTransportService, MockTransportService targetTransportService);

        /**
         * Removes network disruption that was added by {@link #applyDisruption}.
         *
         * @param sourceTransportService source transport service from which requests are sent
         * @param targetTransportService target transport service to which requests are sent
         */
        public void removeDisruption(MockTransportService sourceTransportService, MockTransportService targetTransportService) {
            sourceTransportService.clearOutboundRules(targetTransportService);
        }

        /**
         * Returns expected time to heal after disruption has been removed. Defaults to instant healing.
         */
        public TimeValue expectedTimeToHeal() {
            return TimeValue.timeValueMillis(0);
        }

    }

    /**
     * Simulates a network disconnect. Sending a request from source to target node throws a {@link ConnectTransportException}.
     */
    public static class NetworkDisconnect extends NetworkLinkDisruptionType {

        @Override
        public void applyDisruption(MockTransportService sourceTransportService, MockTransportService targetTransportService) {
            sourceTransportService.addFailToSendNoConnectRule(targetTransportService);
        }

        @Override
        public String toString() {
            return &quot;network disconnects&quot;;
        }
    }

    /**
     * Simulates an unresponsive target node by dropping requests sent from source to target node.
     */
    public static class NetworkUnresponsive extends NetworkLinkDisruptionType {

        @Override
        public void applyDisruption(MockTransportService sourceTransportService, MockTransportService targetTransportService) {
            sourceTransportService.addUnresponsiveRule(targetTransportService);
        }

        @Override
        public String toString() {
            return &quot;network unresponsive&quot;;
        }
    }

    /**
     * Simulates slow or congested network. Delivery of requests that are sent from source to target node are delayed by a configurable
     * time amount.
     */
    public static class NetworkDelay extends NetworkLinkDisruptionType {

        public static TimeValue DEFAULT_DELAY_MIN = TimeValue.timeValueSeconds(10);
        public static TimeValue DEFAULT_DELAY_MAX = TimeValue.timeValueSeconds(90);

        private final TimeValue delay;

        /**
         * Delays requests by a fixed time value.
         *
         * @param delay time to delay requests
         */
        public NetworkDelay(TimeValue delay) {
            this.delay = delay;
        }

        /**
         * Delays requests by a random but fixed time value between {@link #DEFAULT_DELAY_MIN} and {@link #DEFAULT_DELAY_MAX}.
<A NAME="5"></A>         *
         * @param random instance to use for randomization of delay
         */
        public static NetworkDelay random(<FONT color="#151b8d"><A HREF="javascript:ZweiFrames('match2180949-1.html#5',3,'match2180949-top.html#5',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>Random random) {
            return random(random, DEFAULT_DELAY_MIN, DEFAULT_DELAY_MAX);
        }

        /**
         * Delays requests by a random but fixed time value between delayMin and delayMax.
         *
         * @param random   instance to use for randomization of delay
         * @param delayMin minimum delay
         * @param delayMax maximum delay
         */
        public static NetworkDelay random(Random random, TimeValue delayMin</B></FONT>, TimeValue delayMax) {
            return new NetworkDelay(TimeValue.timeValueMillis(delayMin.millis() == delayMax.millis() ?
                    delayMin.millis() :
                    delayMin.millis() + random.nextInt((int) (delayMax.millis() - delayMin.millis()))));
        }
<A NAME="1"></A>
        @Override
        public void applyDisruption(MockTransportService sourceTransportService, MockTransportService targetTransportService) {
            <FONT color="#f63526"><A HREF="javascript:ZweiFrames('match2180949-1.html#1',3,'match2180949-top.html#1',1)"><IMG SRC="forward.gif" ALT="other" BORDER="0" ALIGN="right"></A><B>sourceTransportService.addUnresponsiveRule(targetTransportService, delay);
        }

        @Override
        public TimeValue expectedTimeToHeal() {
            return delay;
        }

        @Override
        public String toString() {
            return &quot;network delays for [&quot; + delay + &quot;]&quot;;
        }</B></FONT>
    }

}
</PRE>
</div>
<div style="flex-grow: 1;">
<h3>
<center>
<span>InsertFromValues.java</span>
<span> - </span>
<span></span>
</center>
</h3>
<HR>
<PRE>
/*
 * Licensed to Crate.io GmbH (&quot;Crate&quot;) under one or more contributor
 * license agreements.  See the NOTICE file distributed with this work for
 * additional information regarding copyright ownership.  Crate licenses
 * this file to you under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.  You may
 * obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
 * License for the specific language governing permissions and limitations
 * under the License.
 *
 * However, if you have executed another commercial license agreement
 * with Crate these terms will supersede the license and you may use the
 * software solely pursuant to the terms of the relevant commercial agreement.
 */

package io.crate.planner.operators;

import static io.crate.data.SentinelRow.SENTINEL;
import static io.crate.execution.engine.indexing.ShardingUpsertExecutor.BULK_REQUEST_TIMEOUT_SETTING;
import static org.elasticsearch.cluster.metadata.IndexMetadata.INDEX_CLOSED_BLOCK;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.UUID;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;
import java.util.function.Consumer;
import java.util.function.Function;
import java.util.function.Supplier;
import java.util.stream.StreamSupport;

import javax.annotation.Nullable;

import com.carrotsearch.hppc.IntArrayList;

import org.elasticsearch.action.ActionListener;
import org.elasticsearch.action.admin.indices.create.CreatePartitionsRequest;
import org.elasticsearch.action.admin.indices.create.TransportCreatePartitionsAction;
import org.elasticsearch.action.bulk.BackoffPolicy;
import org.elasticsearch.action.support.master.AcknowledgedResponse;
import org.elasticsearch.cluster.ClusterState;
import org.elasticsearch.cluster.block.ClusterBlock;
import org.elasticsearch.cluster.block.ClusterBlockException;
import org.elasticsearch.cluster.metadata.Metadata;
import org.elasticsearch.cluster.routing.ShardIterator;
import org.elasticsearch.cluster.routing.ShardRouting;
import org.elasticsearch.cluster.service.ClusterService;
import org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper;
import org.elasticsearch.index.IndexNotFoundException;

import io.crate.action.FutureActionListener;
import io.crate.analyze.OrderBy;
import io.crate.analyze.SymbolEvaluator;
import io.crate.analyze.relations.AbstractTableRelation;
import io.crate.analyze.relations.TableFunctionRelation;
import io.crate.breaker.RamAccounting;
import io.crate.breaker.TypeGuessEstimateRowSize;
import io.crate.concurrent.limits.ConcurrencyLimit;
import io.crate.data.CollectionBucket;
import io.crate.data.InMemoryBatchIterator;
import io.crate.data.Input;
import io.crate.data.Row;
import io.crate.data.Row1;
import io.crate.data.RowConsumer;
import io.crate.data.RowN;
import io.crate.exceptions.ColumnValidationException;
import io.crate.exceptions.SQLExceptions;
import io.crate.execution.dml.ShardRequest;
import io.crate.execution.dml.ShardResponse;
import io.crate.execution.dml.upsert.InsertSourceFromCells;
import io.crate.execution.dml.upsert.ShardUpsertRequest;
import io.crate.execution.dml.upsert.TransportShardUpsertAction;
import io.crate.execution.dsl.projection.ColumnIndexWriterProjection;
import io.crate.execution.dsl.projection.builder.InputColumns;
import io.crate.execution.dsl.projection.builder.ProjectionBuilder;
import io.crate.execution.engine.collect.CollectExpression;
<A NAME="0"></A>import io.crate.execution.engine.collect.RowShardResolver;
import io.crate.execution.engine.indexing.GroupRowsByShard;
import io.crate.execution.engine.indexing.IndexNameResolver;
<FONT color="#0000ff"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2180949-0.html#0',2,'match2180949-top.html#0',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>import io.crate.execution.engine.indexing.ShardLocation;
import io.crate.execution.engine.indexing.ShardedRequests;
import io.crate.execution.jobs.NodeLimits;
import io.crate.execution.support.RetryListener;
import io.crate.expression.InputFactory;
import io.crate.expression.InputRow;
import io.crate.expression.symbol.Assignments;
import io.crate.expression.symbol.SelectSymbol;
import io.crate.expression.symbol.Symbol;
import io.crate.metadata.IndexParts;
import io.crate.metadata.Reference;
import io.crate.metadata.doc.DocTableInfo;
import io.crate.metadata.table.Operation;
import io.crate.metadata.tablefunctions.TableFunctionImplementation;
import io.crate.planner.DependencyCarrier;
import io.crate.planner.ExecutionPlan;
import io.crate.planner.PlannerContext;
import io.crate.statistics.TableStats;
import io.crate.types.DataType;


<A NAME="4"></A>public class InsertFromValues implements LogicalPlan {

    private final TableFunctionRelation tableFunctionRelation</B></FONT>;
    <FONT color="#6cc417"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2180949-0.html#4',2,'match2180949-top.html#4',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>private final ColumnIndexWriterProjection writerProjection;

    InsertFromValues(TableFunctionRelation tableFunctionRelation,
                     ColumnIndexWriterProjection writerProjection) {
        this.tableFunctionRelation = tableFunctionRelation;
        this.writerProjection = writerProjection;
    }

    @Ove</B></FONT>rride
    public StatementType type() {
        return StatementType.INSERT;
    }

    @Override
    public void execute(DependencyCarrier dependencies,
                        PlannerContext plannerContext,
                        RowConsumer consumer,
                        Row params,
                        SubQueryResults subQueryResults) {
        DocTableInfo tableInfo = dependencies
            .schemas()
            .getTableInfo(writerProjection.tableIdent(), Operation.INSERT);

        // For instance, the target table of the insert from values
        // statement is the table with the following schema:
        //
        // CREATE TABLE users (
        //      dep_id TEXT,
        //      name TEXT,
        //      id INT,
        //      country_id INT,
        //      PRIMARY KEY (dep_id, id, country_id))
        // CLUSTERED BY (dep_id)
        // PARTITIONED BY (country_id)
        //
        // The insert from values statement below would have the column
        // index writer projection of its plan that contains the column
        // idents and symbols required to create corresponding inputs.
        // The diagram below shows the projection's column symbols used
        // in the plan and relation between symbols sub-/sets.
        //
        //                        +------------------------+
        //                        |          +-------------+  PK symbols
        //    cluster by +------+ |          |      +------+
        //    symbol            | |          |      |
        //                      + +          +      +
        // INSERT INTO users (dep_id, name, id, country_id) VALUES (?, ?, ?, ?)
        //                       +      +    +     +   +
        //               +-------+      |    |     |   |
        //   all target  +--------------+    |     |   +---+  partitioned by
        //   column      +-------------------+     |          symbols
        //   symbols     +-------------------------+

        InputFactory inputFactory = new InputFactory(dependencies.nodeContext());
        InputFactory.Context&lt;CollectExpression&lt;Row, ?&gt;&gt; context =
            inputFactory.ctxForInputColumns(plannerContext.transactionContext());

        var allColumnSymbols = InputColumns.create(
            writerProjection.allTargetColumns(),
            new InputColumns.SourceSymbols(writerProjection.allTargetColumns()));

        ArrayList&lt;Input&lt;?&gt;&gt; insertInputs = new ArrayList&lt;&gt;(allColumnSymbols.size());
        for (Symbol symbol : allColumnSymbols) {
            insertInputs.add(context.add(symbol));
        }

        ArrayList&lt;Input&lt;?&gt;&gt; partitionedByInputs = new ArrayList&lt;&gt;(writerProjection.partitionedBySymbols().size());
        for (Symbol partitionedBySymbol : writerProjection.partitionedBySymbols()) {
            partitionedByInputs.add(context.add(partitionedBySymbol));
        }

        ArrayList&lt;Input&lt;?&gt;&gt; primaryKeyInputs = new ArrayList&lt;&gt;(writerProjection.ids().size());
        for (Symbol symbol : writerProjection.ids()) {
            primaryKeyInputs.add(context.add(symbol));
        }

        Input&lt;?&gt; clusterByInput;
        if (writerProjection.clusteredBy() != null) {
            clusterByInput = context.add(writerProjection.clusteredBy());
        } else {
            clusterByInput = null;
        }

        String[] updateColumnNames;
        Symbol[] assignmentSources;
        if (writerProjection.onDuplicateKeyAssignments() == null) {
            updateColumnNames = null;
            assignmentSources = null;
        } else {
            Assignments assignments = Assignments.convert(
                writerProjection.onDuplicateKeyAssignments(),
                dependencies.nodeContext()
            );
            assignmentSources = assignments.bindSources(tableInfo, params, subQueryResults);
            updateColumnNames = assignments.targetNames();
        }
        var indexNameResolver = IndexNameResolver.create(
            writerProjection.tableIdent(),
            writerProjection.partitionIdent(),
            partitionedByInputs);

        GroupRowsByShard&lt;ShardUpsertRequest, ShardUpsertRequest.Item&gt; grouper =
            createRowsByShardGrouper(
                assignmentSources,
                insertInputs,
                indexNameResolver,
                context,
                plannerContext,
                dependencies.clusterService());

        ArrayList&lt;Row&gt; rows = new ArrayList&lt;&gt;();
        evaluateValueTableFunction(
            tableFunctionRelation.functionImplementation(),
            tableFunctionRelation.function().arguments(),
            writerProjection.allTargetColumns(),
            tableInfo,
            params,
            plannerContext,
            subQueryResults
        ).forEachRemaining(rows::add);

        List&lt;Symbol&gt; returnValues = this.writerProjection.returnValues();

        ShardUpsertRequest.Builder builder = new ShardUpsertRequest.Builder(
            plannerContext.transactionContext().sessionSettings(),
            BULK_REQUEST_TIMEOUT_SETTING.get(dependencies.settings()),
            writerProjection.isIgnoreDuplicateKeys()
                ? ShardUpsertRequest.DuplicateKeyAction.IGNORE
                : ShardUpsertRequest.DuplicateKeyAction.UPDATE_OR_FAIL,
            rows.size() &gt; 1, // continueOnErrors
            updateColumnNames,
            writerProjection.allTargetColumns().toArray(new Reference[0]),
            returnValues.isEmpty() ? null : returnValues.toArray(new Symbol[0]),
            plannerContext.jobId(),
            false);

        var shardedRequests = new ShardedRequests&lt;&gt;(builder::newRequest, RamAccounting.NO_ACCOUNTING);
        HashMap&lt;String, InsertSourceFromCells&gt; validatorsCache = new HashMap&lt;&gt;();
        for (Row row : rows) {
            grouper.accept(shardedRequests, row);

            try {
                checkPrimaryKeyValuesNotNull(primaryKeyInputs);
                checkClusterByValueNotNull(clusterByInput);
                checkConstraintsOnGeneratedSource(
                    row.materialize(),
                    indexNameResolver.get(),
                    tableInfo,
                    plannerContext,
                    validatorsCache);
            } catch (Throwable t) {
                consumer.accept(null, t);
                return;
            }
        }
        validatorsCache.clear();

        var actionProvider = dependencies.transportActionProvider();
        createIndices(
            actionProvider.transportBulkCreateIndicesAction(),
            shardedRequests.itemsByMissingIndex().keySet(),
            dependencies.clusterService(),
            plannerContext.jobId()
        ).thenCompose(acknowledgedResponse -&gt; {
            var shardUpsertRequests = resolveAndGroupShardRequests(
                shardedRequests,
                dependencies.clusterService()).values();
            return execute(
                dependencies.nodeLimits(),
                dependencies.clusterService().state(),
                shardUpsertRequests,
                actionProvider.transportShardUpsertAction(),
                dependencies.scheduler());
        }).whenComplete((response, t) -&gt; {
            if (t == null) {
                if (returnValues.isEmpty()) {
                    consumer.accept(InMemoryBatchIterator.of(new Row1((long) response.numSuccessfulWrites()), SENTINEL),
                                    null);
                } else {
                    consumer.accept(InMemoryBatchIterator.of(new CollectionBucket(response.resultRows()), SENTINEL, false), null);
                }
            } else {
                consumer.accept(null, t);
            }
        });
    }

    @Override
    public List&lt;CompletableFuture&lt;Long&gt;&gt; executeBulk(DependencyCarrier dependencies,
                                                     PlannerContext plannerContext,
                                                     List&lt;Row&gt; bulkParams,
                                                     SubQueryResults subQueryResults) {
        DocTableInfo tableInfo = dependencies
            .schemas()
            .getTableInfo(writerProjection.tableIdent(), Operation.INSERT);

        String[] updateColumnNames;
        Assignments assignments;
        if (writerProjection.onDuplicateKeyAssignments() == null) {
            assignments = null;
            updateColumnNames = null;
        } else {
            assignments = Assignments.convert(writerProjection.onDuplicateKeyAssignments(), dependencies.nodeContext());
            updateColumnNames = assignments.targetNames();
        }

        InputFactory inputFactory = new InputFactory(dependencies.nodeContext());
        InputFactory.Context&lt;CollectExpression&lt;Row, ?&gt;&gt; context =
            inputFactory.ctxForInputColumns(plannerContext.transactionContext());

        var allColumnSymbols = InputColumns.create(
            writerProjection.allTargetColumns(),
            new InputColumns.SourceSymbols(writerProjection.allTargetColumns()));

        ArrayList&lt;Input&lt;?&gt;&gt; insertInputs = new ArrayList&lt;&gt;(allColumnSymbols.size());
        for (Symbol symbol : allColumnSymbols) {
            insertInputs.add(context.add(symbol));
        }

        ArrayList&lt;Input&lt;?&gt;&gt; partitionedByInputs = new ArrayList&lt;&gt;(writerProjection.partitionedBySymbols().size());
        for (Symbol partitionedBySymbol : writerProjection.partitionedBySymbols()) {
            partitionedByInputs.add(context.add(partitionedBySymbol));
        }

        ArrayList&lt;Input&lt;?&gt;&gt; primaryKeyInputs = new ArrayList&lt;&gt;(writerProjection.ids().size());
        for (Symbol symbol : writerProjection.ids()) {
            primaryKeyInputs.add(context.add(symbol));
        }
        Input&lt;?&gt; clusterByInput;
        if (writerProjection.clusteredBy() != null) {
            clusterByInput = context.add(writerProjection.clusteredBy());
        } else {
            clusterByInput = null;
        }

        var indexNameResolver = IndexNameResolver.create(
            writerProjection.tableIdent(),
            writerProjection.partitionIdent(),
            partitionedByInputs);

        ShardUpsertRequest.Builder builder = new ShardUpsertRequest.Builder(
            plannerContext.transactionContext().sessionSettings(),
            BULK_REQUEST_TIMEOUT_SETTING.get(dependencies.settings()),
            writerProjection.isIgnoreDuplicateKeys()
                ? ShardUpsertRequest.DuplicateKeyAction.IGNORE
                : ShardUpsertRequest.DuplicateKeyAction.UPDATE_OR_FAIL,
            true, // continueOnErrors
            updateColumnNames,
            writerProjection.allTargetColumns().toArray(new Reference[0]),
            null,
            plannerContext.jobId(),
            true);
        var shardedRequests = new ShardedRequests&lt;&gt;(builder::newRequest, RamAccounting.NO_ACCOUNTING);

        HashMap&lt;String, InsertSourceFromCells&gt; validatorsCache = new HashMap&lt;&gt;();
        IntArrayList bulkIndices = new IntArrayList();
        List&lt;CompletableFuture&lt;Long&gt;&gt; results = createUnsetFutures(bulkParams.size());
        for (int bulkIdx = 0; bulkIdx &lt; bulkParams.size(); bulkIdx++) {
            Row param = bulkParams.get(bulkIdx);

            final Symbol[] assignmentSources;
            if (assignments != null) {
                assignmentSources = assignments.bindSources(tableInfo, param, subQueryResults);
            } else {
                assignmentSources = null;
            }

            GroupRowsByShard&lt;ShardUpsertRequest, ShardUpsertRequest.Item&gt; grouper =
                createRowsByShardGrouper(
                    assignmentSources,
                    insertInputs,
                    indexNameResolver,
                    context,
                    plannerContext,
                    dependencies.clusterService());

            try {
                Iterator&lt;Row&gt; rows = evaluateValueTableFunction(
                    tableFunctionRelation.functionImplementation(),
                    tableFunctionRelation.function().arguments(),
                    writerProjection.allTargetColumns(),
                    tableInfo,
                    param,
                    plannerContext,
                    subQueryResults);

                while (rows.hasNext()) {
                    Row row = rows.next();
                    grouper.accept(shardedRequests, row);

                    checkPrimaryKeyValuesNotNull(primaryKeyInputs);
                    checkClusterByValueNotNull(clusterByInput);
                    checkConstraintsOnGeneratedSource(
                        row.materialize(),
                        indexNameResolver.get(),
                        tableInfo,
                        plannerContext,
                        validatorsCache);
                    bulkIndices.add(bulkIdx);
                }
            } catch (Throwable t) {
                for (CompletableFuture&lt;Long&gt; result : results) {
                    result.completeExceptionally(t);
                }
                return results;
            }
        }
        validatorsCache.clear();

        var actionProvider = dependencies.transportActionProvider();
        createIndices(
            actionProvider.transportBulkCreateIndicesAction(),
            shardedRequests.itemsByMissingIndex().keySet(),
            dependencies.clusterService(), plannerContext.jobId()
        ).thenCompose(acknowledgedResponse -&gt; {
            var shardUpsertRequests = resolveAndGroupShardRequests(
                shardedRequests,
                dependencies.clusterService()).values();
            return execute(
                dependencies.nodeLimits(),
                dependencies.clusterService().state(),
                shardUpsertRequests,
                actionProvider.transportShardUpsertAction(),
                dependencies.scheduler());
        }).whenComplete((response, t) -&gt; {
            if (t == null) {
                long[] resultRowCount = createBulkResponse(response, bulkParams.size(), bulkIndices);
                for (int i = 0; i &lt; bulkParams.size(); i++) {
                    results.get(i).complete(resultRowCount[i]);
                }
            } else {
                for (CompletableFuture&lt;Long&gt; result : results) {
                    result.completeExceptionally(t);
                }
            }
        });
        return results;
    }

    private GroupRowsByShard&lt;ShardUpsertRequest, ShardUpsertRequest.Item&gt;
        createRowsByShardGrouper(Symbol[] assignmentSources,
                                 ArrayList&lt;Input&lt;?&gt;&gt; insertInputs,
                                 Supplier&lt;String&gt; indexNameResolver,
                                 InputFactory.Context&lt;CollectExpression&lt;Row, ?&gt;&gt; collectContext,
                                 PlannerContext plannerContext,
                                 ClusterService clusterService) {
        InputRow insertValues = new InputRow(insertInputs);
        Function&lt;String, ShardUpsertRequest.Item&gt; itemFactory = id -&gt;
            new ShardUpsertRequest.Item(
                id,
                assignmentSources,
                insertValues.materialize(),
                null, null, null);

        var rowShardResolver = new RowShardResolver(
            plannerContext.transactionContext(),
            plannerContext.nodeContext(),
            writerProjection.primaryKeys(),
            writerProjection.ids(),
            writerProjection.clusteredByIdent(),
            writerProjection.clusteredBy());

        return new GroupRowsByShard&lt;&gt;(
            clusterService,
            rowShardResolver,
            new TypeGuessEstimateRowSize(),
            indexNameResolver,
            collectContext.expressions(),
            itemFactory,
            true
        );
    }

    private static void checkPrimaryKeyValuesNotNull(ArrayList&lt;Input&lt;?&gt;&gt; primaryKeyInputs) {
        for (var primaryKey : primaryKeyInputs) {
            if (primaryKey.value() == null) {
                throw new IllegalArgumentException(&quot;Primary key value must not be NULL&quot;);
            }
        }
    }

    private static void checkClusterByValueNotNull(@Nullable Input&lt;?&gt; clusterByInput) {
        if (clusterByInput != null &amp;&amp; clusterByInput.value() == null) {
            throw new IllegalArgumentException(&quot;Clustered by value must not be NULL&quot;);
        }
    }

    private void checkConstraintsOnGeneratedSource(Object[] cells,
                                                   String indexName,
                                                   DocTableInfo tableInfo,
                                                   PlannerContext plannerContext,
                                                   HashMap&lt;String, InsertSourceFromCells&gt; validatorsCache) throws Throwable {
        var validator = validatorsCache.computeIfAbsent(
            indexName,
            index -&gt; new InsertSourceFromCells(
                plannerContext.transactionContext(),
                plannerContext.nodeContext(),
                tableInfo,
                index,
                true,
                writerProjection.allTargetColumns()));
        validator.generateSourceAndCheckConstraints(cells);
    }

    private static Iterator&lt;Row&gt; evaluateValueTableFunction(TableFunctionImplementation&lt;?&gt; funcImplementation,
                                                            List&lt;Symbol&gt; arguments,
                                                            List&lt;Reference&gt; allTargetReferences,
                                                            DocTableInfo tableInfo,
                                                            Row params,
                                                            PlannerContext plannerContext,
                                                            SubQueryResults subQueryResults) {
        SymbolEvaluator symbolEval = new SymbolEvaluator(
            plannerContext.transactionContext(),
            plannerContext.nodeContext(),
            subQueryResults);
        Function&lt;? super Symbol, Input&lt;?&gt;&gt; eval = (symbol) -&gt; symbol.accept(symbolEval, params);

        ArrayList&lt;Input&lt;?&gt;&gt; boundArguments = new ArrayList&lt;&gt;(arguments.size());
        for (int i = 0; i &lt; arguments.size(); i++) {
            boundArguments.add(eval.apply(arguments.get(i)));
        }
        //noinspection unchecked
        Iterable&lt;Row&gt; rows = funcImplementation.evaluate(
            plannerContext.transactionContext(),
            plannerContext.nodeContext(),
            boundArguments.toArray(new Input[0]));

        return StreamSupport.stream(rows.spliterator(), false)
            .map(row -&gt; cast(row, allTargetReferences, tableInfo))
            .iterator();
    }

    private static Row cast(Row row, List&lt;Reference&gt; columnReferences, DocTableInfo tableInfo) {
        if (row == null) {
            return null;
        }
        Object[] cells = new Object[row.numColumns()];
        for (int i = 0; i &lt; cells.length; i++) {
            Reference reference = columnReferences.get(i);
            DataType&lt;?&gt; targetType = reference.valueType();
            Object value = row.get(i);
            try {
                cells[i] = targetType.implicitCast(value);
            } catch (IllegalArgumentException | ClassCastException e) {
                throw new ColumnValidationException(
                    reference.column().name(),
                    tableInfo.ident(),
                    &quot;Invalid value '&quot; + value + &quot;' for type '&quot; + targetType + &quot;'&quot;);
            }
        }
        return new RowN(cells);
    }

    private static ShardLocation getShardLocation(String indexName,
                                                  String id,
                                                  @Nullable String routing,
                                                  ClusterService clusterService) {
        ShardIterator shardIterator = clusterService.operationRouting().indexShards(
            clusterService.state(),
            indexName,
            id,
            routing);

        final String nodeId;
        ShardRouting shardRouting = shardIterator.nextOrNull();
        if (shardRouting == null) {
            nodeId = null;
        } else if (shardRouting.active() == false) {
            nodeId = shardRouting.relocatingNodeId();
        } else {
            nodeId = shardRouting.currentNodeId();
        }
        return new ShardLocation(shardIterator.shardId(), nodeId);
    }

    private static &lt;TReq extends ShardRequest&lt;TReq, TItem&gt;, TItem extends ShardRequest.Item&gt;
        Map&lt;ShardLocation, TReq&gt; resolveAndGroupShardRequests(ShardedRequests&lt;TReq, TItem&gt; shardedRequests,
                                                          ClusterService clusterService) {
        var itemsByMissingIndex = shardedRequests.itemsByMissingIndex().entrySet().iterator();
        while (itemsByMissingIndex.hasNext()) {
            var entry = itemsByMissingIndex.next();
            var index = entry.getKey();
            var requestItems = entry.getValue();

            var requestItemsIterator = requestItems.iterator();
            while (requestItemsIterator.hasNext()) {
                var itemAndRoutingAndSourceInfo = requestItemsIterator.next();
                ShardLocation shardLocation;
                try {
                    shardLocation = getShardLocation(
                        index,
                        itemAndRoutingAndSourceInfo.item().id(),
                        itemAndRoutingAndSourceInfo.routing(),
                        clusterService);
                } catch (IndexNotFoundException e) {
                    if (IndexParts.isPartitioned(index)) {
                        requestItemsIterator.remove();
                        continue;
                    } else {
                        throw e;
                    }
                }
                shardedRequests.add(itemAndRoutingAndSourceInfo.item(), 0, shardLocation, null);
                requestItemsIterator.remove();
            }
            if (requestItems.isEmpty()) {
                itemsByMissingIndex.remove();
            }
        }

        return shardedRequests.itemsByShard();
    }

    private CompletableFuture&lt;ShardResponse.CompressedResult&gt; execute(NodeLimits nodeLimits,
                                                                      ClusterState state,
                                                                      Collection&lt;ShardUpsertRequest&gt; shardUpsertRequests,
                                                                      TransportShardUpsertAction shardUpsertAction,
                                                                      ScheduledExecutorService scheduler) {
        ShardResponse.CompressedResult compressedResult = new ShardResponse.CompressedResult();
        if (shardUpsertRequests.isEmpty()) {
            return CompletableFuture.completedFuture(compressedResult);
        }

        CompletableFuture&lt;ShardResponse.CompressedResult&gt; result = new CompletableFuture&lt;&gt;();
        AtomicInteger numRequests = new AtomicInteger(shardUpsertRequests.size());
        AtomicReference&lt;Throwable&gt; lastFailure = new AtomicReference&lt;&gt;(null);

        Consumer&lt;ShardUpsertRequest&gt; countdown = request -&gt; {
            if (numRequests.decrementAndGet() == 0) {
                Throwable throwable = lastFailure.get();
                if (throwable == null) {
                    result.complete(compressedResult);
                } else {
                    throwable = SQLExceptions.unwrap(throwable, t -&gt; t instanceof RuntimeException);
                    // we want to report duplicate key exceptions
<A NAME="6"></A>                    if (!SQLExceptions.isDocumentAlreadyExistsException(throwable) &amp;&amp;
                            (partitionWasDeleted(throwable, request.index())
                                    || partitionClosed(throwable, request.index())
                                    || <FONT color="#8c8774"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2180949-0.html#6',2,'match2180949-top.html#6',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>mixedArgumentTypesFailure(throwable))) {
                        result.complete(compressedResult);
                    } else {
                        result.completeExceptionally(throwable);
                    }</B></FONT>
                }
            }
        };
        for (ShardUpsertRequest request : shardUpsertRequests) {
            String nodeId;
            try {
                nodeId = state.routingTable()
                    .shardRoutingTable(request.shardId())
                    .primaryShard()
                    .currentNodeId();
            } catch (IndexNotFoundException e) {
                lastFailure.set(e);
                if (!IndexParts.isPartitioned(request.index())) {
                    synchronized (compressedResult) {
                        compressedResult.markAsFailed(request.items());
                    }
                }
                countdown.accept(request);
                continue;
            }
            final ConcurrencyLimit nodeLimit = nodeLimits.get(nodeId);
            final long startTime = nodeLimit.startSample();

            ActionListener&lt;ShardResponse&gt; listener = new ActionListener&lt;&gt;() {
                @Override
                public void onResponse(ShardResponse shardResponse) {
                    Throwable throwable = shardResponse.failure();
                    if (throwable == null) {
                        nodeLimit.onSample(startTime, false);
                        synchronized (compressedResult) {
                            compressedResult.update(shardResponse);
                        }
                    } else {
                        nodeLimit.onSample(startTime, true);
                        lastFailure.set(throwable);
                    }
                    countdown.accept(request);
                }

                @Override
                public void onFailure(Exception e) {
                    nodeLimit.onSample(startTime, true);
                    Throwable t = SQLExceptions.unwrap(e);
                    if (!partitionWasDeleted(t, request.index())) {
                        synchronized (compressedResult) {
                            compressedResult.markAsFailed(request.items());
                        }
                    }
                    lastFailure.set(t);
                    countdown.accept(request);
                }
            };

            shardUpsertAction.execute(
                request,
                new RetryListener&lt;&gt;(
                    scheduler,
                    l -&gt; shardUpsertAction.execute(request, l),
                    listener,
                    BackoffPolicy.limitedDynamic(nodeLimit)
                )
            );
        }
        return result;
    }

    private static boolean mixedArgumentTypesFailure(Throwable throwable) {
        return throwable instanceof ClassCastException
<A NAME="5"></A>               || throwable instanceof NotSerializableExceptionWrapper;
    }

    private static boolean partitionWasDeleted(Throwable throwable, <FONT color="#151b8d"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2180949-0.html#5',2,'match2180949-top.html#5',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>String index) {
        return throwable instanceof IndexNotFoundException &amp;&amp; IndexParts.isPartitioned(index);
    }

    private static boolean partitionClosed(Throwable throwable, String index</B></FONT>) {
        if (throwable instanceof ClusterBlockException &amp;&amp; IndexParts.isPartitioned(index)) {
            for (ClusterBlock clusterBlock : ((ClusterBlockException) throwable).blocks()) {
                if (clusterBlock.equals(INDEX_CLOSED_BLOCK)) {
                    return true;
                }
            }
        }
        return false;
    }

    private static CompletableFuture&lt;AcknowledgedResponse&gt; createIndices(TransportCreatePartitionsAction createPartitionsAction,
                                                                         Set&lt;String&gt; indices,
                                                                         ClusterService clusterService,
                                                                         UUID jobId) {
        Metadata metadata = clusterService.state().getMetadata();
        List&lt;String&gt; indicesToCreate = new ArrayList&lt;&gt;();
        for (var index : indices) {
            if (IndexParts.isPartitioned(index) &amp;&amp; metadata.hasIndex(index) == false) {
                indicesToCreate.add(index);
            }
        }
        if (indicesToCreate.isEmpty()) {
            return CompletableFuture.completedFuture(new AcknowledgedResponse(true));
        }
        FutureActionListener&lt;AcknowledgedResponse, AcknowledgedResponse&gt; listener = new FutureActionListener&lt;&gt;(r -&gt; r);
        createPartitionsAction.execute(new CreatePartitionsRequest(indicesToCreate, jobId), listener);
        return listener;
    }

    /**
     * Create bulk-response depending on number of bulk responses
     * &lt;pre&gt;
     *     compressedResult
     *          success: [1, 1, 1, 1]
     *          failure: []
     *
     *     insert into t (x) values (?), (?)   -- bulkParams: [[1, 2], [3, 4]]
     *     Response:
     *      [2, 2]
     *
     *     insert into t (x) values (?)        -- bulkParams: [[1], [2], [3], [4]]
     *     Response:
     *      [1, 1, 1, 1]
     * &lt;/pre&gt;
     */
    private static long[] createBulkResponse(ShardResponse.CompressedResult result,
                                             int bulkResponseSize,
                                             IntArrayList bulkIndices) {
        long[] resultRowCount = new long[bulkResponseSize];
        Arrays.fill(resultRowCount, 0L);
        for (int i = 0; i &lt; bulkIndices.size(); i++) {
            int resultIdx = bulkIndices.get(i);
            if (result.successfulWrites(i)) {
                resultRowCount[resultIdx]++;
            } else if (result.failed(i)) {
                resultRowCount[resultIdx] = Row1.ERROR;
            }
        }
        return resultRowCount;
    }

    private static &lt;T&gt; List&lt;CompletableFuture&lt;T&gt;&gt; createUnsetFutures(int num) {
        ArrayList&lt;CompletableFuture&lt;T&gt;&gt; results = new ArrayList&lt;&gt;(num);
        for (int i = 0; i &lt; num; i++) {
            results.add(new CompletableFuture&lt;&gt;());
        }
        return results;
    }

    @Override
    public ExecutionPlan build(PlannerContext plannerContext,
                               Set&lt;PlanHint&gt; hints,
                               ProjectionBuilder projectionBuilder,
                               int limit,
                               int offset,
                               @Nullable OrderBy order,
                               @Nullable Integer pageSizeHint,
<A NAME="3"></A>                               Row params,
                               SubQueryResults subQueryResults) {
        return null;
    <FONT color="#53858b"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2180949-0.html#3',2,'match2180949-top.html#3',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>}

    @Override
    public List&lt;Symbol&gt; outputs() {
        return List.of();
<A NAME="7"></A>    }

    @Override</B></FONT>
    public List&lt;AbstractTableRelation&lt;?&gt;&gt; baseTables() <FONT color="#38a4a5"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2180949-0.html#7',2,'match2180949-top.html#7',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>{
        return List.of();
    }

    @Override
    public List&lt;LogicalPlan&gt; sources() {
        return</B></FONT> List.of();
    }

<A NAME="2"></A>    @Override
    public LogicalPlan replaceSources(List&lt;LogicalPlan&gt; sources) {
        return this;
    <FONT color="#980517"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2180949-0.html#2',2,'match2180949-top.html#2',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>}

    @Override
    public LogicalPlan pruneOutputsExcept(TableStats tableStats, Collection&lt;Symbol&gt; outputsToKeep) {
        return this;
    }</B></FONT>
<A NAME="1"></A>
    @Override
    public Map&lt;LogicalPlan, SelectSymbol&gt; dependencies() {
        return <FONT color="#f63526"><div style="position:absolute;left:0"><A HREF="javascript:ZweiFrames('match2180949-0.html#1',2,'match2180949-top.html#1',1)"><IMG SRC="back.gif" ALT="other" BORDER="0" ALIGN="left"></A></div><B>Map.of();
    }

    @Override
    public long numExpectedRows() {
        return -1L;
    }

    @Override
    public long estimatedRowSize() {
        return 0L;
    }</B></FONT>

    @Override
    public &lt;C, R&gt; R accept(LogicalPlanVisitor&lt;C, R&gt; visitor, C context) {
        return visitor.visitInsert(this, context);
    }
}
</PRE>
</div>
  </div>
</body>
</html>
